1
00:00:00,090 --> 00:00:07,920
All right, let's continue. So last time we were talking about the classification of states.

2
00:00:08,280 --> 00:00:16,080
So the most important thing, obviously, is the the topology of the state space.

3
00:00:16,560 --> 00:00:19,200
So this is a kind of a connected and not connected.

4
00:00:19,230 --> 00:00:32,300
There is always one way connection is defined by accessibility and then the two way connections can find the by communication of relationship.

5
00:00:32,850 --> 00:00:39,850
And now we have stated that the communication relationship is a equivalence relationship.

6
00:00:39,870 --> 00:00:41,760
Therefore they define the partitions.

7
00:00:42,830 --> 00:00:54,170
Um, the next the important thing is related to the transient versus recurrent states, right to the recurrent state.

8
00:00:54,180 --> 00:01:06,560
So the definition to classify into either defined as the end or recurrent state is by definition is depending on the the ever return probability,

9
00:01:07,410 --> 00:01:18,180
the Markov chain stars of state and then the average probability eventually that there was certainty that the Markov came well referred.

10
00:01:18,180 --> 00:01:21,820
Then we call this state a recurrent state.

11
00:01:21,840 --> 00:01:29,520
Otherwise, if there is none, the zero probability that the Markoff train will never visit the state again.

12
00:01:29,580 --> 00:01:32,130
We call this as a transient. Right.

13
00:01:32,140 --> 00:01:48,390
So the the most important conclusion for transient versus recurrent states, last time we said this is also on communication class property and so.

14
00:01:48,390 --> 00:01:58,970
Right. So that's the corollary three. I'm not so used.

15
00:02:01,760 --> 00:02:07,790
I and J.R. communicate with each other. And then they share this recurrent.

16
00:02:20,790 --> 00:02:37,920
Either the recurrence for youth or so.

17
00:02:38,250 --> 00:02:44,790
Simply put, they are either both recurrent states or they're both transient states.

18
00:02:44,820 --> 00:02:48,650
There is no possibility one of this state is recurrence.

19
00:02:48,660 --> 00:02:53,280
The other is transient, right? As long as they are communicate with each other.

20
00:02:53,850 --> 00:02:57,150
So the proof is pretty simple. So the first thing we did,

21
00:02:57,450 --> 00:03:07,769
but it's getting into a little bit details is we connect the and find this is an ever return probability starting

22
00:03:07,770 --> 00:03:19,520
from state and then return back to the state by to this quantity separation VII and and one to infinity.

23
00:03:20,310 --> 00:03:27,060
So this one we make the connection of these two the equivalent.

24
00:03:27,540 --> 00:03:39,840
So we explained this is the expanded visit to the state.

25
00:03:39,860 --> 00:03:43,139
I right.

26
00:03:43,140 --> 00:03:49,770
So, so the conclusion is if a state is a recurrent state,

27
00:03:50,070 --> 00:04:04,590
then we have an equivalent well the necessary and then sufficient condition is not expected to be to state is also in infinite ends.

28
00:04:07,620 --> 00:04:12,360
Another way is also true if expected to a particular state.

29
00:04:13,660 --> 00:04:26,100
For this particular Markov chain is infinite, then the Das state is a recurrent state and that you have a version for transient state as well.

30
00:04:26,880 --> 00:04:33,720
In that case, they expect that they will be finite and then improve.

31
00:04:33,720 --> 00:04:44,070
Corollary three We use this particular condition and then use oh so used the check

32
00:04:44,070 --> 00:04:48,450
meant for a member of the equation and then that proves the corollary three.

33
00:04:48,450 --> 00:04:52,889
So at the end of the day, I mean, at the end of the day,

34
00:04:52,890 --> 00:04:59,710
last week we establish this the recurrence of work funds in property is a class property, right?

35
00:04:59,820 --> 00:05:12,870
So if you have a communication class that every single state share the same recurrent slack or transient state property,

36
00:05:13,260 --> 00:05:24,890
that's all there are two or more. 4 hours old can be inferred from or deduce the from.

37
00:05:24,900 --> 00:05:31,410
It's from far lower three.

38
00:05:31,620 --> 00:05:39,240
So the corollary for me because briefly goes to movies.

39
00:05:40,770 --> 00:05:44,770
So now we're going to talk about a finite state, Markov chain.

40
00:05:44,790 --> 00:05:59,640
So we're talking about finite states. Is X is a finite it's a finite state.

41
00:06:02,400 --> 00:06:08,040
Markov chain. Then there.

42
00:06:11,690 --> 00:06:23,340
The existence of at least one recurrent state.

43
00:06:35,940 --> 00:06:41,159
All right. So if we have finite space, so this this is not is an a state situation.

44
00:06:41,160 --> 00:06:45,780
We have a finite state Markov chain. Then there exists at least one recurrent state.

45
00:06:46,110 --> 00:06:56,840
How do we prove that? So usually this type of thing that we can prove by contradiction of another in this particular case,

46
00:06:57,030 --> 00:07:03,720
again, we're going to use the connection to the expected visit, the equivalent of the.

47
00:07:03,940 --> 00:07:06,000
Well, it's not a good relationship,

48
00:07:06,450 --> 00:07:13,470
the necessary and sufficient relationship between the average return probability and the expected visit to the state.

49
00:07:14,170 --> 00:07:23,640
So if you have a finite state, Markov chain, you could run the chain forever and then actually count the number,

50
00:07:23,700 --> 00:07:27,689
the expected well, the count, the number of visit to each state.

51
00:07:27,690 --> 00:07:37,740
Right at the end of the day, if you run the train long enough, the number of the total visits to all states should go to infinity.

52
00:07:38,640 --> 00:07:45,780
Right. Just to formally write that we can do this summation by equal to one.

53
00:07:45,790 --> 00:07:57,990
So this is a with respect to the number of the states I'm to K and then we can comment.

54
00:07:58,920 --> 00:08:07,950
This is an indicator the number of visits to States i.

55
00:08:14,710 --> 00:08:20,110
We can make it also make it conditional conditional on an, you know, start with state.

56
00:08:20,130 --> 00:08:26,890
I think that's not really necessary in this case, but this will be a random variable.

57
00:08:26,920 --> 00:08:31,090
I would look at the number to the states to indicate.

58
00:08:31,090 --> 00:08:38,600
And then we need another summation. Right. Let's just write this in the.

59
00:08:41,790 --> 00:08:55,330
We're. All right.

60
00:08:55,690 --> 00:09:08,770
So so, for instance, for any finite steps, let's say, going to track the first steps of the Markov train models, moves so on.

61
00:09:09,340 --> 00:09:14,410
And then we focus on the state by the number of visit to US State J.

62
00:09:16,790 --> 00:09:29,480
An important one to earn and then the number of days that it's going to stay.

63
00:09:30,820 --> 00:09:39,100
JAY So this will be a random number, your focus, our state.

64
00:09:39,130 --> 00:09:46,470
JAY And then you start your Markov chain and we can conditional that to and then the expected number.

65
00:09:46,480 --> 00:09:49,510
Let's just calculate the expected number of this number.

66
00:10:02,260 --> 00:10:27,450
What I'm honored to have to do is just this conditional at 0.2.

67
00:10:27,490 --> 00:10:30,690
I see. All right.

68
00:10:30,760 --> 00:10:35,639
We can calculate this not. This conditional expectation.

69
00:10:35,640 --> 00:10:40,200
Sorry, this is probably your right two lines.

70
00:10:41,920 --> 00:10:52,829
And so this thing is a random variable.

71
00:10:52,830 --> 00:10:57,690
And then we are calculate the expected number given back to the zero.

72
00:11:00,600 --> 00:11:04,180
Right. We can calculate this. Yes.

73
00:11:11,000 --> 00:11:20,570
So this is a form of particular state. J And where track in the first one steps how many visits or expected visits to the state.

74
00:11:21,320 --> 00:11:25,750
And then the other thing we could do.

75
00:11:25,940 --> 00:11:30,800
So this is going to be a finite number if it's fixed, right?

76
00:11:31,400 --> 00:11:38,680
So this quantity, let's call it. Try to use a notation here.

77
00:11:40,130 --> 00:11:48,560
So let's say that B I find in this way, let's put the animal here in the first.

78
00:11:51,170 --> 00:11:54,680
So this will be a valid expectation.

79
00:11:54,680 --> 00:11:59,060
So that's is just the number of visits. And then as a matter of fact.

80
00:12:10,100 --> 00:12:24,530
That's enough. Yes. As a matter of fact, if I enumerate all possible JS I should get.

81
00:12:24,860 --> 00:12:33,230
So this is what I'm trying to say. So if I could sum over from one to k, let's say we have K states.

82
00:12:33,770 --> 00:12:38,180
Vijay and what should I get?

83
00:12:39,800 --> 00:12:46,400
We shall get k, we shall get right. So this is a basically a different way to convert.

84
00:12:47,360 --> 00:12:50,270
The Markov chain has to stop at a certain state.

85
00:12:50,720 --> 00:12:58,810
And then if you are basically trying to classify these visits into the destinations and then if you enumerate the destinations,

86
00:13:00,110 --> 00:13:04,700
A has to add up to one here. Right. So that's the has to be true.

87
00:13:05,540 --> 00:13:18,320
And then the thing we want to do is we cannot make the N goes to infinity if the limit goes to infinity and equal to one through K.

88
00:13:18,350 --> 00:13:22,040
So that means we're going to run the chain for Africa.

89
00:13:22,880 --> 00:13:29,480
So this one the same thing and going to. So the right hand side world goes to infinity, right?

90
00:13:30,650 --> 00:13:35,400
So the total number of visit. Well, I'm going to run the train for Africa, essentially.

91
00:13:35,420 --> 00:13:42,980
That's all I'm going to say. However, if you look at the right hand side, if the corollary is not true.

92
00:13:44,470 --> 00:13:47,920
Then the number of visit to certain state.

93
00:13:48,400 --> 00:13:51,430
There is not a single one being.

94
00:13:52,480 --> 00:13:59,620
So if every state is transient, then the right hand side of that expectation.

95
00:14:00,790 --> 00:14:05,350
Vijay. Vijay.

96
00:14:05,880 --> 00:14:15,940
And so this one you can see is the same thing.

97
00:14:24,760 --> 00:14:37,150
So you need to see this and that if every states are transient and then every single vijay will be finite.

98
00:14:38,660 --> 00:14:46,580
That's just the conclusion from the equivalence of transient recurrent state versus the number of visits.

99
00:14:46,610 --> 00:14:50,800
Right, the pie. Pie and the more pie. All right.

100
00:14:50,810 --> 00:15:01,370
Now you see the contradiction. If the right hand side, the equal, if it's all transient, then this one, the left hand side will get to the.

101
00:15:01,850 --> 00:15:09,710
Because your summation with respect to a finite number of states and every state you can summation of.

102
00:15:12,980 --> 00:15:17,810
That converts to some finite number. So the life on the site will be finite.

103
00:15:17,870 --> 00:15:23,660
And then the right hand side you got infinite. It wasn't a number.

104
00:15:23,670 --> 00:15:29,480
So that's a contradiction. Yeah. So if you run the trains wherever they have to.

105
00:15:29,510 --> 00:15:35,720
Well, I mean, intuitively, it has to stop some states in finite times.

106
00:15:36,800 --> 00:15:43,490
We just put that word into the term expectation, so we formally calculate that expectation.

107
00:15:45,050 --> 00:15:52,400
So this is a what we need to the we need to define big and the number of expected the visit to state j.

108
00:15:54,380 --> 00:16:02,090
And then if I take and goes to infinity, it's not necessarily true for each individual state that that expectation is infinite.

109
00:16:03,470 --> 00:16:10,250
However, for the first recurrence state that goes to in in finite.

110
00:16:10,820 --> 00:16:18,050
The question here is if you have a finite state space, you cannot have every state of being transient.

111
00:16:19,050 --> 00:16:25,500
Right. That's just impossible. So the train has to stop somewhere up here, even in times.

112
00:16:25,800 --> 00:16:35,310
So therefore, if you have a finite state space Markov chain, then at least there is a recurrent state.

113
00:16:35,400 --> 00:16:38,880
So that's the minimum requirement, right? So think about.

114
00:16:43,080 --> 00:16:50,340
So think about the the the Ray Fisher model without limitation.

115
00:16:50,380 --> 00:16:55,320
So everything is connected, right? That's a finite state space, Markov chain.

116
00:16:55,770 --> 00:17:01,920
And then there is no other relationship, but at least there is a one recurrent state.

117
00:17:03,690 --> 00:17:06,509
So there was current state that we charged the recurrent states.

118
00:17:06,510 --> 00:17:12,450
In that particular case, we can identify either the state zero or the state and others.

119
00:17:13,050 --> 00:17:19,560
The Leos are become completely dominant. Those two states are swarming states are recurrent states.

120
00:17:19,740 --> 00:17:23,490
Right. Okay. So we can take a look.

121
00:17:23,490 --> 00:17:28,130
That's true for every finite state space.

122
00:17:28,140 --> 00:17:35,129
Mark, change any questions? I'm just realize this.

123
00:17:35,130 --> 00:17:40,800
This is the the connection, the key things. And then this intuition is really straightforward.

124
00:17:53,910 --> 00:18:01,830
Right. So then so based on this, the next coral reef.

125
00:18:01,830 --> 00:18:06,240
That's coral reef for. I'm sorry.

126
00:18:06,250 --> 00:18:10,060
Corollary five in the lecture notes become straightforward.

127
00:18:11,020 --> 00:18:15,550
So I'm going to add in a little bit more property to my Markov chain.

128
00:18:16,150 --> 00:18:20,170
So that's more like five.

129
00:18:22,210 --> 00:18:48,250
So those things involve a finite, usable Markov chain are recurrent.

130
00:18:54,830 --> 00:19:02,649
Right? So if you have a irreducible Markov chain, then they happen to be a finite state space.

131
00:19:02,650 --> 00:19:06,870
Markov in that all states are. Our recurrence.

132
00:19:06,870 --> 00:19:11,790
So this is the combination of the two conclusions you can draw from Carlo three and four.

133
00:19:12,210 --> 00:19:17,620
So firstly you can argue at least a one state. Is recurrent.

134
00:19:17,770 --> 00:19:19,620
That's my corollary for. Right.

135
00:19:19,630 --> 00:19:30,250
So the the minimum requirement that you have finite state space Margo and the corollary for says that at least one state is recurrent.

136
00:19:31,360 --> 00:19:40,480
And then if one state is a recurrent because of recurrences or the recurrent property, it's a state property.

137
00:19:42,430 --> 00:19:46,780
So they shared by every single member in the same communication class.

138
00:19:47,440 --> 00:19:51,370
Now you need to remember what it's is irreducible Markov chain.

139
00:19:51,820 --> 00:19:55,150
By definition that means there's a single communication clause.

140
00:19:55,570 --> 00:20:01,330
So every state in this irreducible Markov chain communicate with each other.

141
00:20:01,690 --> 00:20:06,130
Therefore, they share the same recurrent or transient property.

142
00:20:06,340 --> 00:20:09,340
So in this case, they all share the same recurrent property.

143
00:20:09,340 --> 00:20:13,390
So every state is recurrent.

144
00:20:17,320 --> 00:20:21,190
That's the importance I think this is tells you a lot about.

145
00:20:21,460 --> 00:20:24,370
Um, again, go back to the,

146
00:20:25,000 --> 00:20:33,969
the basic property why we care about the recurrent versus transient because all of these things are going to determine the stationary distribution,

147
00:20:33,970 --> 00:20:44,140
which we'll discuss today. And more importantly, those property to be is also uniquely determined by the ones that transition col.

148
00:20:45,160 --> 00:20:51,580
Right. So some of that is if you have the P, so this isn't determined by pie.

149
00:20:51,620 --> 00:21:05,260
And here the pie one that's just one step transition col p to three, so on and so forth can be calculated from chair but from a growth equation.

150
00:21:05,890 --> 00:21:13,450
And then from here from the one step transition col, we essentially can determine a single state is transient or recurrent.

151
00:21:14,020 --> 00:21:19,630
And then coupled with this connection structure, the topology of the state space,

152
00:21:20,410 --> 00:21:26,140
then you would know a lot of things about the underlying Markov chain, their behavior.

153
00:21:30,090 --> 00:21:37,350
A lot of these are relevant while we discuss the stationary behavior of stationary distribution on the market.

154
00:21:39,210 --> 00:21:43,140
Before get are any questions about this?

155
00:21:44,310 --> 00:21:54,820
Makes sense. Good. We have one more state property before we get to the station or distribution on this one is a little bit odd.

156
00:21:54,970 --> 00:21:58,780
I'm not going to make a little. Not going to take all the time.

157
00:22:02,620 --> 00:22:06,940
Just the the bare minimum about the the definition.

158
00:22:19,840 --> 00:22:25,540
So we are now in the like tramlines in the territory first that is us.

159
00:22:29,890 --> 00:22:46,299
So the periodicity of the states. So this concept, it's a bit counterintuitive.

160
00:22:46,300 --> 00:22:57,010
Why do we care about that? Well, I mean, the definition seems a little bit number theoretic, but let's go for that.

161
00:22:57,790 --> 00:23:01,060
So the definition of a period of a state.

162
00:23:01,210 --> 00:23:04,210
So the definition of.

163
00:23:07,420 --> 00:23:14,980
So the period of state I in the Markov chain.

164
00:23:16,720 --> 00:23:27,800
So for each. So this a period is defined with respect to individual state at this point is the de vie.

165
00:23:27,850 --> 00:23:33,070
So this is a notation. So this is a defined a period of state.

166
00:23:33,100 --> 00:23:36,270
I thought it was great.

167
00:23:36,280 --> 00:23:52,570
Is the common values that are among all integers and greater than one high and greater than zero?

168
00:23:55,270 --> 00:24:01,520
All right. So if you're a start, a markov can add a State II and then you can calculate one.

169
00:24:01,550 --> 00:24:05,350
Basically given and given the ones that transition col,

170
00:24:05,350 --> 00:24:18,030
you can calculate all the P-I and write to Chapman from a graph equation and then you expect, oh, the pie that's strictly greater than zero.

171
00:24:18,040 --> 00:24:22,090
That means there is a non-zero probability if you start from this state.

172
00:24:22,120 --> 00:24:31,690
I and then you kind of get back to state I think other steps with non-zero probability and the where are looking for.

173
00:24:31,960 --> 00:24:38,970
So you may get a new equals two three, six, seven.

174
00:24:38,980 --> 00:24:43,420
So just an example. So those are the the numbers you may get.

175
00:24:43,840 --> 00:24:47,890
So what is the quickest common divisor here?

176
00:24:49,030 --> 00:24:52,920
So in this case, the period is defined as one, right?

177
00:24:52,990 --> 00:25:04,090
One is the greatest common divisor, particularly notice the uncapped take one.

178
00:25:04,570 --> 00:25:09,400
So you can have a state the first, which is number one state, transition back to itself.

179
00:25:09,790 --> 00:25:16,900
In that case, in the United States space like Markov transition matrix, you have a diagonal element.

180
00:25:16,930 --> 00:25:22,060
It's not a zero in all these cases. The period is simply just one.

181
00:25:22,530 --> 00:25:28,570
Right. So you have a one step transition to P. If you just write it down formally.

182
00:25:32,760 --> 00:25:44,610
It's not a special case. But just as if I was greater than zero, the AI equals.

183
00:25:45,360 --> 00:25:52,850
Otherwise, the AI is you can use this definition to calculate.

184
00:25:55,760 --> 00:26:05,530
This is a relevant in the science. In a sense if we talk about the stationary distribution.

185
00:26:05,830 --> 00:26:15,600
So something can only work if the structure or the topology of the chain is such, then this thing, this period,

186
00:26:15,620 --> 00:26:26,680
can play an important role in terms of determining the position of the state on the states of the stationary distribution or the.

187
00:26:27,670 --> 00:26:32,740
So the example of that is actually the simple random walk, right?

188
00:26:32,830 --> 00:26:41,710
So think of all simple random walk. We have sort of a structure or the quality of the states connection like this.

189
00:26:42,040 --> 00:27:03,580
So from the original state, let's say zero, one, two, so on and so forth, and the number of this side is the same, negative one and so on, so forth.

190
00:27:03,790 --> 00:27:11,500
So what's the period before I say 0 to 2?

191
00:27:11,530 --> 00:27:18,610
Yes, you cannot possibly get back to the zero in all steps.

192
00:27:18,940 --> 00:27:28,929
Right. So you can always so the the P to the end is strictly greater than zero, only four, but even numbers to four.

193
00:27:28,930 --> 00:27:32,620
And so in that case, so these are the run the chain long enough.

194
00:27:32,800 --> 00:27:38,260
You can know that if you know the distribution is not a trivial one.

195
00:27:38,440 --> 00:27:43,270
So you need to specify all of the all steps they want.

196
00:27:43,390 --> 00:27:47,650
The Markov chain won't land on the the even numbers.

197
00:27:47,650 --> 00:27:56,380
And the same thing if you start from a even if you start with start with all number,

198
00:27:56,770 --> 00:28:03,579
then after even number of transition, they can only land on the even numbers.

199
00:28:03,580 --> 00:28:07,630
So those sort of things are important. Therefore this is the.

200
00:28:09,450 --> 00:28:14,250
We need to talk about. Pure decency.

201
00:28:14,550 --> 00:28:19,440
And I don't plan to talk too much about this.

202
00:28:19,680 --> 00:28:25,140
Just just to know. But the important fact of this is.

203
00:28:28,970 --> 00:28:35,330
So the periodicity is also a sign of a communication class problem.

204
00:28:36,440 --> 00:28:39,800
So there is that alarm. This is not long one.

205
00:28:42,270 --> 00:28:51,620
There is a proposition that like journals, I'm not given the the full proof.

206
00:28:51,630 --> 00:28:55,600
I think the proof is on the lecture circuit. Take a look at.

207
00:28:56,070 --> 00:29:07,820
So if all. Okay.

208
00:29:07,820 --> 00:29:19,520
So this one has to go first. So if I and Jay are communicate with each other, then we have the conclusion that the time equals the day.

209
00:29:20,450 --> 00:29:26,090
So that's a rather strong this isn't all as intuitive as some other conclusions,

210
00:29:26,600 --> 00:29:36,380
but this basically saying the periodicity is shared among all communicated classes.

211
00:29:36,870 --> 00:29:44,000
Right. So if you have us, you have the the two states are communicate with each other.

212
00:29:44,510 --> 00:29:48,470
If you know the period of one state, then you know the period of the other.

213
00:29:49,670 --> 00:29:59,149
Okay. So this proof can be done based on again, the champion chromatography creation crescendo mean the proof is provided in like journals.

214
00:29:59,150 --> 00:30:12,080
Take a look of that. So now we know the two different things are said.

215
00:30:13,700 --> 00:30:19,260
So the two state property we talk about other than their connection.

216
00:30:19,390 --> 00:30:26,340
Class is a connection. Class state it partition the oldest states space, but they are on top of that.

217
00:30:26,340 --> 00:30:36,840
They own all the communication costs shares. Despite this, the end versus your current property.

218
00:30:44,310 --> 00:30:59,870
And at the same time they share the. There is an issue which is so dear communication class within the communication class.

219
00:30:59,870 --> 00:31:03,170
These two things are there's two different properties are share.

220
00:31:03,650 --> 00:31:11,760
So this is the importance of proposition.

221
00:31:16,610 --> 00:31:23,390
And then finally, before we talk about stationary distribution,

222
00:31:23,990 --> 00:31:32,090
we need to revisit the trends in the recurrent state property, especially the recurrent.

223
00:31:33,410 --> 00:31:38,710
Now the recurrent states are the number of the recurrent states are the same.

224
00:31:39,200 --> 00:31:45,710
You can further classify recurrent states depending on the following property.

225
00:31:48,020 --> 00:31:56,540
So there is a positive versus normal recurrent.

226
00:32:07,280 --> 00:32:17,600
So we also encountered this concept as he for his simple reason walk in there, we ask the question If a state is recurrence,

227
00:32:17,990 --> 00:32:32,720
so if there is a the first return probability is the one or is first return, the state probability is strictly less than one.

228
00:32:32,780 --> 00:32:37,250
Right? So one that mentioned or random walk we said that every state.

229
00:32:37,460 --> 00:32:40,700
Well, I mean, now you can use the market train to that.

230
00:32:40,970 --> 00:32:50,750
So every state if you have a. If I was symmetric or random walk in one dimension, every state is recurrent.

231
00:32:51,530 --> 00:32:55,610
So think about ever return. Probability will be strictly one.

232
00:32:56,720 --> 00:33:02,810
However, we also said the expected number is the expected time to return.

233
00:33:03,290 --> 00:33:12,020
It's infinite, right? So that gave this the positive versus null recurrence definition.

234
00:33:12,530 --> 00:33:30,530
So the positive recurrence fighting to distinguish the different mode expected is the first return.

235
00:33:30,530 --> 00:33:53,100
Time is finite and the null recurrence is now you can imagine it has to be complement complementary for this thing.

236
00:33:53,450 --> 00:34:01,800
So the expected the first return time is infinite and.

237
00:34:08,890 --> 00:34:17,110
All right. So. So conceptually, we have to be clear what we are talking about here.

238
00:34:17,230 --> 00:34:24,460
So how do you calculate the expected first return time, given all the patients we have?

239
00:34:24,670 --> 00:34:29,559
Right. So we'll use this in mind to the first return.

240
00:34:29,560 --> 00:34:49,040
They expected the first return time for its return to IE given as you're doing.

241
00:34:49,070 --> 00:34:54,190
Right. All right. So how do we calculate that?

242
00:34:56,560 --> 00:35:00,850
We have done this quite a few times. So first the right amount.

243
00:35:02,380 --> 00:35:06,600
So the notation I have one to infinity infinite.

244
00:35:06,820 --> 00:35:14,860
So what we're going to do is going to be well, we're going to enumerate all possible first return time.

245
00:35:15,140 --> 00:35:24,550
Right. So that is could be FII and it could be, you know, if you go to once.

246
00:35:26,080 --> 00:35:31,620
If it's equal to one, then the first return, that's the first return in one step.

247
00:35:31,620 --> 00:35:44,080
Then this one times I find. So if I if I is to your first two step retire then the the you have a factor to multiply my.

248
00:35:44,800 --> 00:35:51,040
So this one equals and so this is the first return time and then the probability of first

249
00:35:51,040 --> 00:35:58,630
return taken at this particular high right over the fire and are mutually exclusive.

250
00:35:59,500 --> 00:36:06,040
Yes. So this is because this is the first return after returning one in particular.

251
00:36:06,040 --> 00:36:09,819
So let's say you cannot do that in five plus one anymore.

252
00:36:09,820 --> 00:36:21,370
So so this is the quantity you are calculating is one and times I find so immediately you see this is very different than.

253
00:36:22,600 --> 00:36:24,879
The average return probability. Right.

254
00:36:24,880 --> 00:36:34,780
So the the i, i, i on the other side, if you're trying to define this quantity is well, this particular state is transient.

255
00:36:35,350 --> 00:36:40,330
You will have, I find an important one for you.

256
00:36:41,230 --> 00:36:46,660
So mathematically speaking, you couldn't have the right hand side.

257
00:36:47,020 --> 00:36:54,309
This one is converged being one right ever return.

258
00:36:54,310 --> 00:36:59,230
So this is an average return probability. This is expected of that.

259
00:37:01,800 --> 00:37:08,460
First return time. So they are your song over two different sequences.

260
00:37:09,000 --> 00:37:18,110
And so even this one is converged and you can have this one diverge given rise giving rise to an.

261
00:37:19,570 --> 00:37:23,710
Another recurrent now a recurrent situation.

262
00:37:25,900 --> 00:37:29,250
Just to give you an example, this is a manufacturing.

263
00:37:34,480 --> 00:37:44,530
So it really is subtle. The reason a recurrent state being a now recurrent is really not something intuitive.

264
00:37:44,680 --> 00:37:53,500
It's rather mathematical, but the consequence of two different series is infinite series.

265
00:37:57,730 --> 00:38:03,850
So if you're trying to find the intuition that people don't understand, this is a rather a consequence.

266
00:38:03,920 --> 00:38:11,260
Let's say the example. So the example of this where I have one.

267
00:38:11,350 --> 00:38:15,670
The real world example is symmetric, simple, random block.

268
00:38:16,120 --> 00:38:27,500
Okay, but you can construct one. For instance, if you have if I constructed as one over and minus and one.

269
00:38:28,090 --> 00:38:36,100
So let's say the first return in one step is one minus a half.

270
00:38:36,220 --> 00:38:42,150
So that will be a half. And then in two steps, then there will be a half minus the third.

271
00:38:42,160 --> 00:38:45,940
Right. So this one is the second thing.

272
00:38:48,550 --> 00:38:58,840
All right. So if you have a fire and you cross this, then you can calculate the summation by one to infinity.

273
00:38:59,260 --> 00:39:02,920
So you get one minus half plus a half.

274
00:39:03,190 --> 00:39:08,770
Minus a third, plus or minus a force.

275
00:39:09,160 --> 00:39:13,380
So on. So force, especially this one, is limited.

276
00:39:14,800 --> 00:39:19,360
And so we got cancelation in a JSON terms.

277
00:39:19,970 --> 00:39:25,040
One minus one, which is one.

278
00:39:25,240 --> 00:39:32,860
The limit is one. So that means if you have this set on what going to happen what going to happen is the.

279
00:39:34,750 --> 00:39:45,480
You know, this particular state is going to be a recurrent state because the I hear the summation of that is one is probability, one is one.

280
00:39:48,990 --> 00:39:52,110
It's a different story. What are we trying to calculate?

281
00:39:53,280 --> 00:40:04,080
Expected the return time and now the top line on the right hand side becomes useful.

282
00:40:04,590 --> 00:40:08,910
And I use this formula I find, am I right?

283
00:40:09,750 --> 00:40:16,530
So I'm on separation. I come to an and times I.

284
00:40:19,530 --> 00:40:31,980
All right. So you have times and times one over and one plus one.

285
00:40:32,760 --> 00:40:46,760
So you get Charles. All right, so you get something like this as a half plus a third plus a fourth, so on and so forth.

286
00:40:47,130 --> 00:40:50,730
And then this is a well known as a harmonica sequence. Right.

287
00:40:50,730 --> 00:40:53,790
So that they will diverge. So this one, this infinite.

288
00:40:56,930 --> 00:41:02,080
There's no particular reason you can figure out, you know, a recurrence.

289
00:41:02,090 --> 00:41:07,490
Even this risk state is recurrent that there are positive recurrence or not recurrence.

290
00:41:08,210 --> 00:41:11,750
The mathematics will determine that. It's not really intuitive.

291
00:41:12,350 --> 00:41:13,580
That's what I'm trying to say.

292
00:41:14,720 --> 00:41:25,250
If you're given the job of determining one status, positive, recurrent or not recurrent, you have to go through this type of the calculation, right?

293
00:41:25,520 --> 00:41:30,950
There's no easy way. It's not trying to make sense of all the things that's feeling intuitive.

294
00:41:30,950 --> 00:41:38,030
But this is not one of those mathematical details matters.

295
00:41:39,980 --> 00:41:45,110
But luckily, given your given job to determine that,

296
00:41:45,530 --> 00:41:54,980
you only need to do that for one state because now recurrent and then positive recurrent are also class property.

297
00:41:55,430 --> 00:42:04,910
So this is the proposition to positive recurrence.

298
00:42:06,770 --> 00:42:22,750
This is a communication class, procedure class.

299
00:42:29,420 --> 00:42:38,660
All right. So if you know, one of the stage in the communication class is positive for recurrence of every status positive recurrent.

300
00:42:40,370 --> 00:42:45,500
It's. Oh.

301
00:42:45,550 --> 00:42:48,570
The other thing I think can leave us a.

302
00:42:54,000 --> 00:43:01,270
A homework problem is you can think about every currency in the United States space, right?

303
00:43:01,430 --> 00:43:07,680
If you have a finite state, Markov chain. Is that possible to have a null recurrence situation?

304
00:43:09,360 --> 00:43:17,129
Okay. I'll leave that to you alone.

305
00:43:17,130 --> 00:43:25,070
If you cannot figure out the answer, obviously can't do it all. So we're not trying to any questions about this.

306
00:43:25,560 --> 00:43:39,210
So just think about this is a tree structure.

307
00:43:39,630 --> 00:43:57,810
We first determine based on I find we classify all states into either recurrent versus transient.

308
00:44:03,780 --> 00:44:09,210
So for these I it's strictly less than one.

309
00:44:10,050 --> 00:44:17,310
All right. For these I equals one.

310
00:44:17,940 --> 00:44:28,170
Okay. And now we can further classify recurrent states into two positive, recurrent and recurrent.

311
00:44:39,790 --> 00:44:58,030
If I my vision is finite and this is not now, I'm unable to be credited.

312
00:44:58,840 --> 00:45:06,250
What about this? Can we calculate the expected return here in my equals one?

313
00:45:12,180 --> 00:45:22,410
This is a simple case. And I ask a similar question before in the class.

314
00:45:25,630 --> 00:45:34,060
If I find less than one, what is the expected number of first rate term?

315
00:45:36,400 --> 00:45:40,110
Speak up. I think you're right. Someone say something?

316
00:45:40,870 --> 00:45:44,080
No. Sorry.

317
00:45:44,250 --> 00:45:47,610
Speak. Listen. Infinitive is infinity.

318
00:45:48,750 --> 00:45:55,500
Y is infinity. Because this one has non-zero probability, i.e. the finite number.

319
00:45:55,980 --> 00:46:02,430
So basically this sense of the finite return is strictly less than one.

320
00:46:02,430 --> 00:46:06,450
So that means there is a non-zero probability one never return.

321
00:46:06,560 --> 00:46:15,020
That means the equivalence speaking that the first return probability is in fact it's non-zero.

322
00:46:15,030 --> 00:46:19,200
So you have a term with infinite infinity has a.

323
00:46:20,320 --> 00:46:24,340
Non-zero probability. So this one is always positive.

324
00:46:24,460 --> 00:46:28,120
So this way you see that there is a tree structure.

325
00:46:28,120 --> 00:46:40,240
We, we define the recurrence. So we classify the space into this type of the, you know, it's pretty complex.

326
00:46:40,630 --> 00:46:56,620
And then the reason is we can only make statements about stationary distribution for a special class and then that state class is this nicest one.

327
00:46:56,620 --> 00:47:09,850
So they have every time probability one, and then they have expected return time, the return time being finite.

328
00:47:10,210 --> 00:47:15,310
And then we are not going to talk about these.

329
00:47:15,970 --> 00:47:22,690
And these for these are not easy to consider this a long run behavior.

330
00:47:22,690 --> 00:47:29,950
Right. So if you are talking about state and there is a possibility you are never return, what can you say?

331
00:47:29,950 --> 00:47:35,230
You can say, well, maybe, maybe there is in the long run you will never return.

332
00:47:35,580 --> 00:47:39,399
Right? So the distribution of visit the state is zero.

333
00:47:39,400 --> 00:47:45,700
That that's not interesting. And then for the non recurrent it's even complicated, although you know,

334
00:47:45,700 --> 00:47:54,549
they will ever they will come back to return but they expect the time to reach that return could be infinity.

335
00:47:54,550 --> 00:48:00,040
That's also not something newer we can take advantage of.

336
00:48:01,210 --> 00:48:09,580
So this is a more about using the Markov chain in statistical computing, like, let's say, building a markov chain, Monte Carlo.

337
00:48:10,000 --> 00:48:18,520
So we are more focused on this part. Of the partition positive recurrent.

338
00:48:20,720 --> 00:48:26,960
And then the ozone you coupled with the other nights, probably that is a periodic problem.

339
00:48:28,100 --> 00:48:38,120
So we say some stay there's a periodic if they have the the period 1000 the period of the state equals one,

340
00:48:39,710 --> 00:48:44,600
you can kind of look out to see the rest of terminology periodically.

341
00:48:50,030 --> 00:49:00,900
All right. So. All right, so so think about this.

342
00:49:01,110 --> 00:49:12,220
The whole market. Well, I don't want to call that homework exercise or a call for peace.

343
00:49:12,550 --> 00:49:29,320
I mean, I know that's not.

344
00:49:41,570 --> 00:49:47,570
Maybe the simplest question, the most relevant question is irreducible.

345
00:49:48,260 --> 00:50:01,310
I used to the simple things because those things are sometimes not really relevant.

346
00:50:01,430 --> 00:50:06,040
You reduce, see?

347
00:50:09,470 --> 00:50:16,460
So this you should have a good intuition. It's just thinking about running the chain of whatever that be possible.

348
00:50:16,640 --> 00:50:23,260
Right. All right. Think about this when not reviewing answers for discussing this.

349
00:50:28,710 --> 00:50:39,690
And so despite our obsession with, you know, an infinite state space, most useful thing,

350
00:50:39,930 --> 00:50:45,540
I think in real life, our finite state space marvel like the tools we're building.

351
00:50:45,960 --> 00:50:49,050
So this is a problem more practical, more relevant.

352
00:50:49,800 --> 00:50:59,550
Okay. So just summarize the movements before moving to the movie.

353
00:50:59,760 --> 00:51:05,010
The probably the most important part of Markov chain.

354
00:51:05,430 --> 00:51:10,760
We have discussed the class property classification of states.

355
00:51:10,770 --> 00:51:21,180
Right. So mostly based on their connec, uh, connectivity or their, um, in the state space.

356
00:51:21,480 --> 00:51:26,730
So based on their connectivity, we define their accessibility, we define the communications.

357
00:51:26,730 --> 00:51:30,209
The communication is our equivalence relationship.

358
00:51:30,210 --> 00:51:34,300
Therefore, we define the partition. That's the thing.

359
00:51:34,320 --> 00:51:40,860
And then in every partition, obviously the Mars the state space share.

360
00:51:42,730 --> 00:51:54,000
The the import and the properties. One of these are the recurrence, either being null recurrence or positive recurrence they are shown.

361
00:51:54,520 --> 00:52:03,060
We see that I think of. I just want to thank you for you.

362
00:52:07,460 --> 00:52:12,110
Oh, yes. We did say that the positive recurrence is a class property.

363
00:52:12,110 --> 00:52:19,639
The same thing for the normal recurrence. Right. So you can prove that by that contradiction again,

364
00:52:19,640 --> 00:52:29,150
so that either positive recurrence or no recurrence is a class property and then the periodicity is also shared among the classes.

365
00:52:29,660 --> 00:52:40,880
Right. Now you see the once you inspect the the Markov chain, you are given the Markov chain, you get the the the transition kernel.

366
00:52:44,870 --> 00:52:49,790
This allows you to construct the diagram, the connectivity diagram, right.

367
00:52:49,790 --> 00:52:54,830
That the connect connectivity is defined by these one step transition kernels.

368
00:52:55,070 --> 00:52:58,370
Right. They also define the periodicity.

369
00:52:58,730 --> 00:53:03,110
They also defined the recurrence versus transient property.

370
00:53:04,190 --> 00:53:20,340
So everything is encoded here. So there is a one type of the Markov chain where particularly interested in this is called a quartet mark.

371
00:53:23,100 --> 00:53:54,450
But we have a similar definition for things, for definition positive, for recurrent and a periodic state of call on which I refer to us.

372
00:54:02,250 --> 00:54:14,100
So morning. All right.

373
00:54:14,110 --> 00:54:22,560
So aborting is just another jargon is going to say, if I say a state is aborting, that means the state is as a pure race one.

374
00:54:22,710 --> 00:54:25,770
And that is a positive recurrent. Okay.

375
00:54:26,490 --> 00:54:37,030
So we know that, um. You know, you can go back to the definition of what the period means, and then you also can tell me that,

376
00:54:37,030 --> 00:54:44,800
you know, this particular state, it will have every time probability of one and expected to return.

377
00:54:44,830 --> 00:55:05,680
Time is finite. On the other designation, if all states in an embassy are according.

378
00:55:11,810 --> 00:55:25,430
Then the chain. The Markov chain dependency, Markov chain is referred to as a tick mark on the chain.

379
00:55:32,810 --> 00:55:39,790
All right. Yes.

380
00:55:41,170 --> 00:55:44,440
All right. So we define that. Okay. You take this.

381
00:55:44,530 --> 00:55:51,340
All right. All right. So.

382
00:55:51,670 --> 00:55:55,950
Well, the definition is pretty clear.

383
00:55:55,960 --> 00:56:08,200
So you can define a single state as a body state. And that is if there is a markov chain consisting of all on a more states.

384
00:56:09,130 --> 00:56:16,500
That means if an M.C. are aboard all states, in times they are boarded, then the item is called up according to Mark.

385
00:56:17,650 --> 00:56:28,480
The equivalent definition is if you have a markov chain that is irreducible, it's a periodic.

386
00:56:29,260 --> 00:56:32,980
So irreducible means every states are connected with each other.

387
00:56:33,010 --> 00:56:37,840
Right. A periodic because they are all connected together.

388
00:56:37,850 --> 00:56:43,060
If you define just one state that every state is share, that's probably Asia.

389
00:56:43,780 --> 00:56:48,630
And a positive recurrent. Then this underlying Markov chain is also a Gornick.

390
00:56:49,990 --> 00:56:53,680
That's a equivalent definition to this.

391
00:56:54,190 --> 00:56:58,570
All states in the mark reported that the IOC is caught awarding Markov chain.

392
00:56:59,670 --> 00:57:05,520
One of the important thing, I think, is they write this two different versions in the lecture notes we did,

393
00:57:06,450 --> 00:57:12,300
and then the off confusions, which one is their equivalent if all stays in the mark?

394
00:57:12,750 --> 00:57:19,380
Gornick They must have irreducible class in a second.

395
00:57:20,190 --> 00:57:25,200
Homework problem. Try to figure out if you have to communication class.

396
00:57:26,330 --> 00:57:29,580
Okay. Well, this is trying to show.

397
00:57:29,580 --> 00:57:36,000
You can show if you have two communication class in the mark, then you cannot have a according to Markov chain.

398
00:57:36,030 --> 00:57:40,170
I mean, it's not every state's being a Borg. Right.

399
00:57:40,210 --> 00:57:46,740
So the thing is you have a wide communication class and then you have another communication class.

400
00:57:47,070 --> 00:57:58,880
And then by definition, there need to be something kind of a once that transition not coming back if they're coming back.

401
00:57:58,900 --> 00:58:03,530
So so you have a one pull by contradiction.

402
00:58:03,540 --> 00:58:09,660
Okay. So everything is connected within this partition of the state space.

403
00:58:09,840 --> 00:58:17,430
So we're trying to prove if all the states in the Markov chains are operating, then the the underlying Markov chain must be.

404
00:58:18,450 --> 00:58:25,259
Irreducible. Okay, then you have another indication clause.

405
00:58:25,260 --> 00:58:33,420
Communicate with each other. If you want to construct a counterexample, it has to have some structure like this.

406
00:58:33,960 --> 00:58:37,650
If you have a you know, if you have a new state, go back.

407
00:58:37,890 --> 00:58:43,140
They make a whole two things, but the two communication class communicate with each other.

408
00:58:43,800 --> 00:58:47,040
Therefore, this contradiction to your construction.

409
00:58:47,040 --> 00:58:50,910
So you must have this one step transition. Right.

410
00:58:52,130 --> 00:58:59,780
Ah, we all agree on that. So if you're trying to disapprove that, so we need to have a structure like this.

411
00:59:00,080 --> 00:59:05,120
However, if you have a structure like this, if you start within this tray,

412
00:59:05,360 --> 00:59:10,790
this part of the partition, you will never get to this part of the partition.

413
00:59:10,790 --> 00:59:14,570
So that's contradict that. To say this, any of these are a warning.

414
00:59:15,630 --> 00:59:19,710
Right. That's just impossible. They don't know, you know.

415
00:59:21,150 --> 00:59:28,260
Or if you start from here, if they translate out, it will never get back to here it is again.

416
00:59:28,410 --> 00:59:34,160
It's is a contradiction to the end of the state of here is a according.

417
00:59:34,620 --> 00:59:39,000
So if you have every state is according, it must be the case.

418
00:59:39,690 --> 00:59:44,730
The whole Markov chain is has only one communication clause.

419
00:59:44,760 --> 00:59:46,860
They are all communicate with each other.

420
00:59:47,220 --> 00:59:58,190
So the equivalence of the the definition for according Markov chain is the underlying Markov has to be irreducible.

421
00:59:58,200 --> 01:00:03,000
So this is a more clear definition, right? So one can big communication clause.

422
01:00:03,810 --> 01:00:06,840
Every state has a period one a periodic.

423
01:00:07,560 --> 01:00:13,260
It's a state property under the irreducible Markov chain assumption.

424
01:00:13,260 --> 01:00:22,070
There's also a, you know, the communication clause property, also the chain property, you know, and then there has to be oh positively for.

425
01:00:23,810 --> 01:00:32,340
So I think it's important to point out that because later on people can get confused by reading like criminals,

426
01:00:32,560 --> 01:00:36,120
students are all in fascination to, say,

427
01:00:37,020 --> 01:00:49,110
irreducible and pure all day positive recurrent Markov chain and then to say according Markov chain, as all the states are for meaning a periodic.

428
01:00:51,640 --> 01:00:57,010
Positive for recurrence. So you see there's a result going backwards.

429
01:00:57,010 --> 01:01:01,980
If your asserts everything, share the period, the falsity,

430
01:01:02,380 --> 01:01:08,680
and then the recurrence property that might seem like everything being connected with each other.

431
01:01:10,780 --> 01:01:20,800
All right. So for algorithm, Markov chain, if you run this train long enough that you can expect some equilibrium behavior.

432
01:01:21,070 --> 01:01:24,990
Okay. So this is a to call the. The theorem.

433
01:01:25,010 --> 01:01:29,160
What is the most important thing?

434
01:01:29,670 --> 01:01:36,910
Because we have been curious about this property.

435
01:01:36,930 --> 01:01:40,690
If you run the chain long enough, what can happen? Right.

436
01:01:41,250 --> 01:01:45,150
So for awarding Markov chain, I think we can study what's going to happen.

437
01:01:45,450 --> 01:01:46,680
So one thing, you know.

438
01:01:47,910 --> 01:01:58,230
So if you run the train long enough, every six is going to be from time to time frequently visited by them, by the Markov chain.

439
01:01:58,260 --> 01:02:08,280
Well, I'm just saying the transition going to get back. And then so you would hypothesize if there is some sort of a stationary distribution,

440
01:02:08,280 --> 01:02:19,410
meaning some states will be or every state is going to be visited in a fixed frequency.

441
01:02:20,610 --> 01:02:44,280
So let's first the right objects. If a markov chain is irreducible appear all day long.

442
01:02:48,680 --> 01:02:57,360
Here. And positive for encouraging.

443
01:02:58,620 --> 01:03:02,270
Basically, the Markov chain is a boarding school.

444
01:03:05,010 --> 01:03:16,810
I'm. Then this is the conclusion.

445
01:03:18,040 --> 01:03:30,000
It only goes to infinity three times and equals pi, which is strictly less than.

446
01:03:30,610 --> 01:03:38,830
So I don't need to write this.

447
01:03:43,660 --> 01:03:56,890
So the page. Well be a number is strictly a strictly less so this is a more.

448
01:04:03,060 --> 01:04:11,700
This is a this is a more precise definition for the page where concerning hygiene is that.

449
01:04:12,300 --> 01:04:23,430
So if you're starting with Markov chain in the AI and then you are interested in after is that it is a J and then you take and goes to infinity,

450
01:04:23,430 --> 01:04:26,610
meaning while implying you run the chain long enough.

451
01:04:27,030 --> 01:04:33,450
What is this page? And you go, you could always calculate this by the format of equation.

452
01:04:33,990 --> 01:04:37,020
But when you have it goes to infinity.

453
01:04:37,620 --> 01:04:41,820
It seems like the calculation becomes practically impossible.

454
01:04:42,210 --> 01:04:49,770
But this limit size, you know, if you're doing that calculation, you will see that converge to a number importance.

455
01:04:50,400 --> 01:04:54,440
This number is a property this only rely on j.

456
01:04:54,450 --> 01:04:57,500
Now i. Right.

457
01:04:57,510 --> 01:05:05,250
So this is a pay off, AJ. So the first observation is irrelevant.

458
01:05:05,400 --> 01:05:13,620
So this is irrelevant. So this statement shows that the relevance of the initial state.

459
01:05:21,020 --> 01:05:27,950
So because there is no constraint find, no matter which state that you start, you can change it to eight plus one.

460
01:05:27,950 --> 01:05:31,850
You contribute to k. The limit will be the same.

461
01:05:32,210 --> 01:05:43,070
Will always pay off. Thank. The other thing is, what is this hygiene?

462
01:05:47,450 --> 01:05:52,400
So there is a direct interpretation of this pilot journey.

463
01:05:57,200 --> 01:06:01,430
Remember in the the first the literature of Markov chain.

464
01:06:01,910 --> 01:06:08,260
We said we can calculate the marginal distribution for any accident.

465
01:06:08,360 --> 01:06:18,830
Right. So if we trying to calculate the probability of text and you call it to check exactly like that, what should we do?

466
01:06:19,310 --> 01:06:27,690
Right. So remember, this is we need to enumerate the whole possible starting point across all possible.

467
01:06:27,710 --> 01:06:32,810
I. I love t i j and right.

468
01:06:32,930 --> 01:06:36,430
So that's exactly what we I mean, this is nothing new here.

469
01:06:36,440 --> 01:06:42,049
We already know how to calculate this. So can we.

470
01:06:42,050 --> 01:06:53,390
If we have this awarded theorem, which is the name of this theorem, and that in coupled with this quantity we're going to get now we know.

471
01:06:53,390 --> 01:06:56,990
So the limit goes to infinity.

472
01:06:57,770 --> 01:07:02,960
The probability of X and equal to j cannot be.

473
01:07:04,250 --> 01:07:11,500
Well, just to take on both the ability of the summation on i, i,

474
01:07:11,600 --> 01:07:21,319
g I know we're going to do is switch this assumption and then the limit is not always valid to do that,

475
01:07:21,320 --> 01:07:26,960
but because here everything is positive and then you could actually switch that.

476
01:07:27,830 --> 01:07:39,740
So this is summation. So what can I get to the point where we have a summation of I limit and go to Infinity

477
01:07:40,670 --> 01:07:50,330
by J and which from the according theorem that is summation time after time J.

478
01:07:53,680 --> 01:08:07,640
Sorry. I forgot something. It's so strong.

479
01:08:07,820 --> 01:08:14,830
Okay. Up. Correct.

480
01:08:14,920 --> 01:08:22,300
Right. Why don't we just plug in this and then this pi over j with respect to I, it's a constant.

481
01:08:22,600 --> 01:08:29,710
It's not a function of time. So we just need to sum over here, which is exactly how.

482
01:08:37,360 --> 01:08:45,830
Any questions? We just applied this just to trying to calculate the marginal distribution instead of Exxon.

483
01:08:45,850 --> 01:08:51,760
That's the number one variable. All right. So this one gave us high off, Jane.

484
01:08:53,890 --> 01:09:02,150
So this one has a very form interpretation of this, what this stationary distribution is.

485
01:09:02,170 --> 01:09:07,749
Right. So this is a basically the distribution of X and Y.

486
01:09:07,750 --> 01:09:14,140
You run the chain long enough. It says it converge to this pie of J.

487
01:09:14,170 --> 01:09:21,270
That's you know, that's affects the distribution thinking about o possible state.

488
01:09:21,280 --> 01:09:27,129
J Right. Every state. So first of all, this one has nothing to do with.

489
01:09:27,130 --> 01:09:31,660
And so every state's become identically distributed.

490
01:09:32,140 --> 01:09:39,190
So every state, every random variable in the Markov chain where you run the train long enough, there are no independent.

491
01:09:39,190 --> 01:09:52,139
No. But this new dependance that the dependency is still is controlled by the Markov chain accident still correlated with some plus one hierarchy.

492
01:09:52,140 --> 01:10:02,520
There are identical distributed. The X equal to j equals to this defined determinant by this particular distribution has nothing to do with j.

493
01:10:02,580 --> 01:10:06,510
All right, so this is why we call this stationary distribution.

494
01:10:06,870 --> 01:10:16,889
Second of all, the what I'm trying to say, I forgot the interpretation.

495
01:10:16,890 --> 01:10:22,530
Okay, so this is basically the frequency of the mark of chain in the long run.

496
01:10:22,800 --> 01:10:26,250
How frequent the mark of chain going up is that the state?

497
01:10:26,250 --> 01:10:32,460
J That's exactly this probability statement, right backs and equal to J is going to be page.

498
01:10:33,750 --> 01:10:42,510
All right. So we need to have a additional requirement to say this.

499
01:10:50,530 --> 01:11:06,580
And so this is something we have a tool but it's actually it is true that is the pie is a valid probability distribution.

500
01:11:13,270 --> 01:11:20,640
Probability distribution in the sense summation of the page load.

501
01:11:24,820 --> 01:11:39,380
All right. All right.

502
01:11:39,500 --> 01:11:42,640
So. Well, I mean, obviously, if the.

503
01:11:42,710 --> 01:11:48,710
Okay, we have 6 minutes, I need to tell you how to solve the the number four in the homework problem.

504
01:11:50,200 --> 01:11:53,270
So how do we actually find paging? Right.

505
01:11:53,480 --> 01:12:00,290
So well, first of all, it's a it's a it's a property of the one type transition kernel.

506
01:12:00,290 --> 01:12:03,709
So far, everything is built upon the one step transition kernel.

507
01:12:03,710 --> 01:12:12,740
So there is should be a way to find the pi of J if it's a well, first of all, you need to check the underlying train if it's a warning, Markov chain.

508
01:12:12,980 --> 01:12:17,180
Right. But if you're confirmed about aborting Markov, how do you find the page?

509
01:12:17,210 --> 01:12:22,160
Here is how we do it. Thinking about the train has run long enough.

510
01:12:22,910 --> 01:12:27,950
All right. So it's just transit from maximum to X and plus one.

511
01:12:29,780 --> 01:12:40,370
So we all know how to do this. Right. So, you know, the probability of X plus one, let's say, equal to J.

512
01:12:41,030 --> 01:12:50,420
Well, be equal to the probability x do I summation of ODI and then T of J.

513
01:12:50,750 --> 01:12:54,530
Just one step transition. Yes. Thanks a lot.

514
01:12:54,840 --> 01:13:02,239
Okay. So this one, I'm I'm going to take the limit here because that's a equation I'm allowed to take,

515
01:13:02,240 --> 01:13:16,460
plus one that when you take the limit, the right on the left hand side, this is becomes pi j according to what we just said here.

516
01:13:16,670 --> 01:13:21,370
The limit goes to infinity x, you go through J, it's page eight and plus one.

517
01:13:21,380 --> 01:13:25,400
The same thing. That's nothing. So the left hand side is pi over J.

518
01:13:25,730 --> 01:13:29,270
On the right hand side, you have a summation, right?

519
01:13:30,140 --> 01:13:34,310
And then you swap the the summation of the limit.

520
01:13:34,310 --> 01:13:40,600
Here you get the probability, the limit and goes to an X or Y.

521
01:13:40,610 --> 01:13:44,370
So that's just pi up on another page.

522
01:13:49,110 --> 01:13:54,350
Right. So this is exactly how do you find.

523
01:13:54,860 --> 01:14:01,610
Hi. You need to solve a series of equation involving just once that transition kernel.

524
01:14:02,090 --> 01:14:06,410
So you have a page. So, say, for a finite state space Markov chain.

525
01:14:06,470 --> 01:14:10,100
So you have case that then you have the key equation.

526
01:14:10,100 --> 01:14:16,510
Here, it's all linear. So there's only a linear algebra you should be able to solve.

527
01:14:16,520 --> 01:14:28,520
This is a older kind of a linear equation so you can set this also have the the another implication probably will should talk about this next time.

528
01:14:29,180 --> 01:14:38,150
So once the Markov chain enter into this stationary distribution, then there was stuck in this stationary distribution forever.

529
01:14:38,240 --> 01:14:48,290
So this is just what we did, right? We look at the X and plus one, so all the subsequent states will have the same stationary distribution.

530
01:14:48,440 --> 01:14:52,810
Find the by this page. Right.

531
01:14:52,880 --> 01:14:57,640
What is a stationary distribution that means marginal deal. Every single state.

532
01:14:58,580 --> 01:15:08,120
I'm sorry, every single random the variable subsequent random variable identically distributed with this particular distribution.

533
01:15:08,120 --> 01:15:13,100
So this is a like if you're looking into a corollary that random variables,

534
01:15:13,160 --> 01:15:28,040
they all have the same distribution so they may be looks yes but the equation for the stationary distribution the second by to the right hand side.

535
01:15:28,100 --> 01:15:31,589
Sorry. Yes, yes, yes. That's very important.

536
01:15:31,590 --> 01:15:35,210
That is the wrong formula. You will never get the correct answer.

537
01:15:35,660 --> 01:15:39,520
Thank you. From the parenthesis with my IPG.

538
01:15:39,830 --> 01:15:47,969
Right. Right. So so you can think about this as a kind of a one step transition where you can think about that multi-step transition.

539
01:15:47,970 --> 01:15:51,470
Once you enter into a stationary distribution,

540
01:15:51,480 --> 01:16:02,309
you just want to know the next random variable and the next 100 times that, and then they have the same distribution.

541
01:16:02,310 --> 01:16:05,790
So you can use this to solve the equation of.

542
01:16:09,140 --> 01:16:18,070
Right. The things we did say is this is a unique and then this is a distribution that we did improve what we did in annual fees.

543
01:16:18,160 --> 01:16:22,610
But that's probably beyond this class.

544
01:16:22,610 --> 01:16:27,679
But this is a valid distribution and this is a unique distribution.

545
01:16:27,680 --> 01:16:32,750
And also we did a pool, but you cannot take it for granted.

546
01:16:33,890 --> 01:16:39,200
Solving other problems, solving over the whole or examine problems.

547
01:16:40,140 --> 01:16:46,310
Um, we'll say a few more words about this on Wednesday.

548
01:16:46,370 --> 01:16:55,819
I will get into the next part. So this is a key part before the midterm one about the stationary distribution and most importantly,

549
01:16:55,820 --> 01:17:05,540
how you compute or identify a stationary distribution from once that transition control the

550
01:17:06,140 --> 01:17:12,740
idea that the stationary distribution is uniquely is permeated by the transition countries.

551
01:17:13,340 --> 01:17:16,730
Okay. You see everybody on Wednesday.

