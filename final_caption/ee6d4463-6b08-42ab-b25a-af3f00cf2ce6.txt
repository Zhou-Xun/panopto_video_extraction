1
00:00:00,750 --> 00:00:12,930
I'm sorry. Just say it again. One day I could start distributing paper on 825.

2
00:00:12,930 --> 00:00:16,170
We are here, but technically we should do the test.

3
00:00:17,160 --> 00:00:20,520
830 to 950.

4
00:00:20,520 --> 00:00:25,020
So exactly the class time. We have to collect all the papers.

5
00:00:27,390 --> 00:00:37,260
If there is no class after us, maybe there is a possibility of 5 minutes extension, but otherwise prepare to be just in time.

6
00:00:38,430 --> 00:00:45,780
Just some general things. You could bring a paper letter size, full size.

7
00:00:45,780 --> 00:00:47,910
How small you want to write? I don't really care.

8
00:00:50,130 --> 00:00:58,230
You know, I think the the process of preparing prepare a cheat sheet is probably more important than to actually bring it.

9
00:00:58,710 --> 00:01:11,520
Right. So that gives you a that's a the that's a process for you to review some concepts or some of the materials you are not familiar with.

10
00:01:11,670 --> 00:01:24,060
I think during the exam, if you still need to look for the cheat sheet for formulas, probably not ideal, but that's your right.

11
00:01:24,090 --> 00:01:29,129
You can use it. Okay.

12
00:01:29,130 --> 00:01:34,230
So what I want to say one thing you do well, do over, prepare it.

13
00:01:35,400 --> 00:01:40,350
I don't expect you to. You know, I really don't have the expectation.

14
00:01:40,350 --> 00:01:53,040
You know, every footnote under the lecture notes and from my perspective is I want to see you understand the the concept, understand the,

15
00:01:53,580 --> 00:02:05,040
you know, the thought process from point A to point B, how it is derived and not really interested in, you know, the non for example what is.

16
00:02:07,860 --> 00:02:19,890
The consequences of a right fissure mode of that sort. It's not really about particular examples of.

17
00:02:21,820 --> 00:02:27,860
It's hard to. There's a message about, you know, don't over prepare it.

18
00:02:28,640 --> 00:02:31,280
If so, today we'll go through the topics.

19
00:02:31,970 --> 00:02:39,260
If you feel comfortable about all of these and then you can naturally connect all of these, then you're in a good position.

20
00:02:39,770 --> 00:02:46,460
Right? Okay. So we we probably won't use the whole lecture.

21
00:02:46,640 --> 00:02:53,600
So whatever time we we are left with, we could do all this, all work.

22
00:02:53,600 --> 00:03:00,020
And then there will be another sort of a last minute office hour tomorrow from 4 to 5.

23
00:03:01,130 --> 00:03:08,900
You should be able to get the the zoom link from the either the announcement or just the zoom link.

24
00:03:10,670 --> 00:03:15,650
All right. Any other questions? Okay.

25
00:03:21,530 --> 00:03:21,889
All right.

26
00:03:21,890 --> 00:03:35,450
So I'll do backwards in terms of the chapters, reviewing the chapters, the most important topic we have discussed, obviously, is Markov chain.

27
00:03:36,590 --> 00:03:48,260
So there are roughly four areas that you should look into in your review.

28
00:03:48,620 --> 00:04:08,870
So the first part is the basic, or you should say the general properties or any type of some article so that including the definition.

29
00:04:11,480 --> 00:04:22,480
The fascination of. Mark off the property right way.

30
00:04:23,200 --> 00:04:30,190
You know, this is should be simple and easy, but given the present, the past and future are independent.

31
00:04:31,090 --> 00:04:41,590
There is also a variant of it's a markov of property and the strong form of property.

32
00:04:48,820 --> 00:04:53,590
So you should be able to tell the difference between the two and then generally

33
00:04:53,590 --> 00:04:58,240
understand the relationship between the two with a strong mark on the property.

34
00:04:59,170 --> 00:05:06,730
So for a markov chain, with Markov for a stochastic process, with Mark Hall property,

35
00:05:07,150 --> 00:05:15,370
if you impose a starting time, what that means, well then you get yourself a strong mark on property.

36
00:05:15,460 --> 00:05:22,030
So this is always false. It's not really something you need to distinguish.

37
00:05:22,030 --> 00:05:27,159
Some mark of trade off this or some other Markov chain doesn't have the strong Mark O'Mara

38
00:05:27,160 --> 00:05:34,450
can have a strong mark off property if you are additionally conditioning on a stalling time.

39
00:05:34,660 --> 00:05:41,320
Right. So those are the important things. Definition one is okay.

40
00:05:41,950 --> 00:05:49,540
And then the other concept that they were in for the basic general properties of the time homogeneity.

41
00:05:52,430 --> 00:06:02,590
It's important because I realize with all the things we discussed that they all have a time invariant transition kernel.

42
00:06:02,620 --> 00:06:10,150
So if you're talking about so this is an important property in the for the second half of the class when we talk about stochastic processes and

43
00:06:10,210 --> 00:06:22,480
it's not necessarily time homogeneous before here almost all the the problems we all almost all the problems we have in common are homogeneous.

44
00:06:23,650 --> 00:06:28,060
But the Markov chains have a homogeneous transition kernel.

45
00:06:28,600 --> 00:06:54,700
And so what that means, you should know, is lastly, given there is a time homogeneous Markov chain, how do we represent this transition or transition?

46
00:07:01,480 --> 00:07:25,600
Right. So there are a few different things. So for the transition, Colonel, the most important thing is to go from one step transition probabilities.

47
00:07:25,840 --> 00:07:39,940
How do we arrive unstuck? Right.

48
00:07:39,940 --> 00:07:46,720
So this is a probably the most important thing for the general property for Markov chain.

49
00:07:46,730 --> 00:08:00,270
So this is obviously the CBA version. So you have CIJ and POS and it's nice to i,

50
00:08:06,070 --> 00:08:20,020
i so this question should natural to you should be felt natural for you at this point because until all of the things are based on this equation and

51
00:08:20,260 --> 00:08:29,200
this is a just a so the way to think all this is how do you derive this from the first from your first from the first principle is pretty easy.

52
00:08:29,200 --> 00:08:37,860
All right. So this is just conditional on this on the staff of the Markov steps, right?

53
00:08:37,960 --> 00:08:50,590
So you do this. So lastly, so we have the definition type of homogeneity, transition kernel.

54
00:08:50,980 --> 00:08:58,840
The last approach you should know or the thing you should know is marginal

55
00:08:58,840 --> 00:09:09,510
distribution computation of the marginal distribution or distribution of axons.

56
00:09:10,450 --> 00:09:14,600
So a number of these stochastic process, right?

57
00:09:15,160 --> 00:09:25,120
So you remember this X and equal to the K comes on the two things I show you.

58
00:09:25,810 --> 00:09:34,209
All right. So this is so here.

59
00:09:34,210 --> 00:09:38,110
This again, this is not hard at all.

60
00:09:39,430 --> 00:09:44,829
You get you need to consider conditional on the initial state and then the Q of

61
00:09:44,830 --> 00:09:50,800
II is the initial state distribution and then P and in step transition kernel.

62
00:09:51,490 --> 00:10:02,380
So I think with these that's every mark done with the property so shared by all the market, the most general one.

63
00:10:03,070 --> 00:10:07,960
And then this magnitude. Oh, these are expected to.

64
00:10:12,760 --> 00:10:20,590
It's just. Okay, so this is a general thing.

65
00:10:21,170 --> 00:10:24,310
So next topic. Any questions?

66
00:10:25,420 --> 00:10:28,420
So the next topic is about the class property.

67
00:10:28,420 --> 00:10:38,020
So the class property is built up for where the class property is trying to.

68
00:10:39,180 --> 00:10:49,140
This to prepare really for as a preparation for the aborted theorem that doesn't replace this.

69
00:10:50,070 --> 00:10:53,210
Right. So this is the general basic.

70
00:10:53,220 --> 00:11:03,960
Probably the second area we're going to look into is the class property here.

71
00:11:14,670 --> 00:11:17,280
So the most fundamental of.

72
00:11:21,830 --> 00:11:36,620
So the foremost among them, the most fundamental thing about the class property is, oh, define every single aspect of class and class property.

73
00:11:36,620 --> 00:11:40,730
So we define the by the corresponding transition curve.

74
00:11:41,510 --> 00:11:48,470
So that's one step transition. Colonel will tell you everything about the class properties we're going to talk about.

75
00:11:49,400 --> 00:12:08,420
Right, the connectivity, the now recurrent and then the so or transient states or pure the all city, so on, so forth.

76
00:12:08,420 --> 00:12:11,479
Everything is defined by transition property.

77
00:12:11,480 --> 00:12:23,000
So you need to link back to that form. So if I gave you the transition currently, in theory, you should be able to examine all these class properties.

78
00:12:23,300 --> 00:12:30,140
So specifically we have so the communication class.

79
00:12:31,630 --> 00:12:42,760
So the detail of the properties is to say the properties of the first one is.

80
00:12:44,770 --> 00:12:54,669
Communication class. Right.

81
00:12:54,670 --> 00:13:03,250
So this is a talking about from state to state B, the possibility of move from state to state.

82
00:13:03,550 --> 00:13:10,209
So for finite state, Markov chain, the most effective way to inspect that,

83
00:13:10,210 --> 00:13:15,160
to connect the communication classes or the connectivity between the states,

84
00:13:15,160 --> 00:13:21,490
is using a diagram right through that and by looking at the transition kernel.

85
00:13:21,760 --> 00:13:34,720
So this one. And then so during this communication class, we also define the irreducible Markov chain, right?

86
00:13:34,730 --> 00:13:43,000
So what does that mean? So only one communication class per second.

87
00:13:55,410 --> 00:13:59,399
Recurrent and transient sites, so forth.

88
00:13:59,400 --> 00:14:06,700
These are a bit complicated.

89
00:14:06,930 --> 00:14:13,710
But but there are two different things. One is you need to be very clear about the destination.

90
00:14:14,160 --> 00:14:18,120
What is a transient? So there are some multiple ways you make a judgment.

91
00:14:18,750 --> 00:14:30,990
State is transient or recurrent, but the destination is supposed to be very you should be very clear either using the first return time or using.

92
00:14:35,010 --> 00:14:49,860
Just first the right bits. So the second properties rebound versus transient.

93
00:14:58,680 --> 00:15:03,520
All right. So once you have this. So the definition obviously is important.

94
00:15:03,540 --> 00:15:11,030
And then you can go back to the first item, the bullet points, why this is defined by the transition colonel.

95
00:15:11,040 --> 00:15:18,180
So we have that theorem tells you how to make a judgment of a state that is recurring or transient.

96
00:15:18,270 --> 00:15:29,700
Right. And then for the recurrent class, we have a refinement we have now recurrent versus positive recurrent I.

97
00:15:33,520 --> 00:15:39,140
So there is. Let me just. I'm fine.

98
00:15:40,460 --> 00:15:44,420
So this is ever return probability. So they are defined.

99
00:15:44,720 --> 00:15:50,150
So the ever return probability for start from state on the ever return probability is

100
00:15:50,150 --> 00:15:56,840
one that impacts the public or state is recurrent state otherwise is a transient state.

101
00:15:56,880 --> 00:16:05,810
If there is a problem that there is a probability that the Markov chain never returned back to state,

102
00:16:05,810 --> 00:16:13,790
I think this thing I a transient state like on the other thing is I'm I this is the

103
00:16:13,790 --> 00:16:24,019
expected a return time so if I related to the first return time you should also know.

104
00:16:24,020 --> 00:16:27,059
So that's basically probability is defined.

105
00:16:27,060 --> 00:16:31,910
That's probability. The return time is finite.

106
00:16:32,630 --> 00:16:41,630
And so if you have a transient, this one is less than one.

107
00:16:41,780 --> 00:16:50,299
And my I has to be infinite. Right? So you have a probability that never returns that may be expected.

108
00:16:50,300 --> 00:17:05,720
A return time is now recurrent, so the Markov chain will return with probability one.

109
00:17:05,990 --> 00:17:10,790
But the expectation could be infinite.

110
00:17:11,270 --> 00:17:19,999
So. So the infinity here. So the example you should remember on this is the, the simple random walk, right?

111
00:17:20,000 --> 00:17:22,850
So the symmetric simple random one on one dimension,

112
00:17:23,900 --> 00:17:31,640
although this is a recurrent state about is nevertheless and now recurrence state and lastly a positive.

113
00:17:37,850 --> 00:17:46,729
So this is one this is probably the most designer of property for mathematical reasons.

114
00:17:46,730 --> 00:17:51,560
One, we start a warning here we will we require positive recurrence.

115
00:17:53,300 --> 00:18:02,090
Right. So there are some conclusions about finite, irreducible, finite state Markov chain.

116
00:18:02,090 --> 00:18:06,979
So you need to make sure how they're on recurrence.

117
00:18:06,980 --> 00:18:13,100
So, for example, if there are irreducible than the finite state, Markov chain must be.

118
00:18:16,100 --> 00:18:21,710
All the states has to be recurrent. At the same time, it has to be all positive recurrent.

119
00:18:22,160 --> 00:18:25,580
You should convince yourself that's the case. If you can.

120
00:18:29,430 --> 00:18:34,140
Probably should come to the office. Maybe I can discuss that.

121
00:18:35,880 --> 00:18:43,810
Right. So. So I didn't say this that the first the bullet points how the trends in the recurrent that connect to the FBI.

122
00:18:43,830 --> 00:18:49,049
Right. And then I think we have a way to make the connection.

123
00:18:49,050 --> 00:18:52,300
That's the bureau using generating function.

124
00:18:52,650 --> 00:19:00,060
Connect I to the PI and that's in the lecture and also not repeating but the point is.

125
00:19:01,480 --> 00:19:14,600
All these points are connected. So if you're. So the third class property and this is a class property means that if in a communication class,

126
00:19:14,600 --> 00:19:24,380
one particular class has this property, every member of this community education class share shares this problem.

127
00:19:26,330 --> 00:19:30,680
The last one is of of pure the all citizens.

128
00:19:31,370 --> 00:19:42,829
So the period of the state for this I think is really you just need to know the definition and the understanding of that.

129
00:19:42,830 --> 00:19:50,719
So that's also a class of property share all of these.

130
00:19:50,720 --> 00:20:00,380
The important thing is you could after you go examine the connect connectivity class, communication class,

131
00:20:00,740 --> 00:20:20,690
then you understand that this whole sort of bash so how from a state property you can it to a class

132
00:20:22,430 --> 00:20:33,410
communication class and so you don't necessarily need to do all of the states just stay on one.

133
00:20:34,820 --> 00:20:50,240
And then so lastly, we need to know the definition of according according states and as a board mark.

134
00:20:50,240 --> 00:20:54,680
Okay. All right. So the recording state is a state.

135
00:20:56,840 --> 00:21:14,030
So if a particular state is is positive, a recurrent and then a periodic, then we call either a boarding state and on boarding Markov chain,

136
00:21:14,030 --> 00:21:24,319
as if every state in the mark is positive, recurrent and then a periodic recall.

137
00:21:24,320 --> 00:21:33,350
It's a gaudy Markov chain. So well, this definition implies if you have every states are awarding states that must have irreducible.

138
00:21:33,950 --> 00:21:42,650
So we did not prove one sort of argument during the lecture, but in general you could also remember this more.

139
00:21:42,680 --> 00:21:45,799
Just remember what is according Markov chain, right?

140
00:21:45,800 --> 00:21:51,350
It requires to be irreducible. So it's just a simple single communication class.

141
00:21:51,350 --> 00:22:04,339
Every state connected with other states, and then every state is positive, recurrent, and they all share in the same returns property.

142
00:22:04,340 --> 00:22:10,190
And then they are. Every state is a periodic. So that gave you the awarded Markov chain.

143
00:22:10,550 --> 00:22:18,320
So only for this class after the Markov change, we can talk about stationary distribution.

144
00:22:19,550 --> 00:22:29,060
So the second topic is really about classify the states and then furthermore classify different Markov chains.

145
00:22:29,720 --> 00:22:34,880
So the gaudy Markov chain is the lowest holding for that.

146
00:22:36,080 --> 00:22:48,520
Is that really better? All right.

147
00:22:48,610 --> 00:22:54,070
So the third one, it's really the 40 theorem.

148
00:22:58,930 --> 00:23:14,980
So stationary distribution theorem.

149
00:23:22,090 --> 00:23:28,680
So the most important thing is to understand what the Burdick theorem says for awarding general awarding Markov chain.

150
00:23:28,690 --> 00:23:34,120
So that means you have to make sure the marginal chain through the transition kernel,

151
00:23:34,360 --> 00:23:41,860
you inspect all these class properties and then come to the conclusion the underlying Markov chain is actually operative Markov chain.

152
00:23:41,870 --> 00:23:49,190
Then you have the support theorem. So you can just remember the the problem as the to infinity.

153
00:23:50,500 --> 00:23:53,590
Yeah, you can.

154
00:23:58,240 --> 00:24:04,479
All right. So this is apparently the simplest form to remember.

155
00:24:04,480 --> 00:24:09,940
So this we talk about the implications of this simple expression.

156
00:24:09,940 --> 00:24:13,960
There's actually very rich content in 2 minutes.

157
00:24:14,390 --> 00:24:21,490
Right? So this is a one the mark. So first of all, it has nothing to do with the initial state distribution.

158
00:24:22,030 --> 00:24:27,600
So this is just IGG. And then from the general property, you can copy,

159
00:24:27,610 --> 00:24:36,469
you can see if it's set into the stationary distribution and then the Markov chain will remain so on, so forth.

160
00:24:36,470 --> 00:24:44,230
So there's a bunch of interpretation. The most important is probably this one, like this one.

161
00:24:44,230 --> 00:24:53,740
This actually pulls limit and goes to infinity profitability x equal to J, right?

162
00:24:54,760 --> 00:25:00,940
So I would hope you can establish the relationship from here to here, right?

163
00:25:01,810 --> 00:25:08,200
You should be able to do that. If you are, it's okay.

164
00:25:08,200 --> 00:25:15,730
For now. I feel like I'm uncertain how you get there easily, but there are multiple ways you can make the arguments.

165
00:25:16,360 --> 00:25:21,250
If you find a way that I find most convincing for itself, that's important.

166
00:25:21,490 --> 00:25:37,240
So that basically saying so if you run the chain long enough, every so every random variable will have identically distributed distribution,

167
00:25:37,330 --> 00:25:45,580
which is the stationary distribution, but they are not the right because being on the Markov chain, it's not independent.

168
00:25:46,920 --> 00:26:00,400
All right. I would just tell you right, this, there is a multiple interpretation pation of hygiene of the equations.

169
00:26:03,340 --> 00:26:06,460
Or does it mean the things I have said?

170
00:26:06,760 --> 00:26:11,790
If you're a markov to enter into a stationary distribution, you will never get hot.

171
00:26:11,920 --> 00:26:16,540
What that means. Okay.

172
00:26:16,960 --> 00:26:23,800
The other thing is how to solve for it. So solve for pi j.

173
00:26:27,280 --> 00:26:30,309
It cannot be emphasized enough.

174
00:26:30,310 --> 00:26:33,790
It's not just the equation you need to solve or set of equations.

175
00:26:33,790 --> 00:26:43,270
In Ubisoft, you need a first verified underlying Markov chain is a Gornick marvel and then go on to solve for the duration,

176
00:26:44,080 --> 00:26:51,250
solve for the and then these are basically implication of this and then use one particular implication

177
00:26:51,250 --> 00:26:57,240
of the avoiding theorem that is once the Markov to enter into it and then we'll never get it all.

178
00:26:57,250 --> 00:27:02,620
So you get this sort of equation, PI equals the summation.

179
00:27:02,620 --> 00:27:13,390
Okay, so let's just consider once that transition, let's say you are, as I understand you are in any of those case state K Okay, okay.

180
00:27:13,870 --> 00:27:21,250
A has to be an X and plus one has to be in the same stationary distribution.

181
00:27:21,880 --> 00:27:27,830
So this will help. So you can say you can solve a system like these.

182
00:27:27,850 --> 00:27:34,240
It is a linear equation systems the pi AJ That's one step transition are null.

183
00:27:35,680 --> 00:27:38,860
So the pi case I'll know. So this is the most general way.

184
00:27:39,250 --> 00:27:46,480
Well for sure. Give you if you make the correct judgment, be the underlying Markov chains of authority,

185
00:27:46,540 --> 00:27:53,020
then this equation will for sure give you the right answer for the stationary distribution.

186
00:27:53,200 --> 00:27:59,450
Right? So this is more general than the detailed balance equation, which was hockey commitments.

187
00:28:01,300 --> 00:28:08,470
So that's how you get this. And then you should also know this is a unit.

188
00:28:08,920 --> 00:28:13,810
So this is this solution, this unit if it's supported. So we didn't move it.

189
00:28:14,380 --> 00:28:20,470
You can invoke that anytime you have you see a property.

190
00:28:20,530 --> 00:28:30,430
So the page is a unique solution or the other way to say it, according to Markov chain, has a unique stationary distribution.

191
00:28:31,290 --> 00:28:39,760
And that's it for the. All right.

192
00:28:39,770 --> 00:28:43,940
Finally. Uh, don't think there is a final, uh.

193
00:28:47,690 --> 00:28:53,270
Oh, and I think, okay, I put the tiny reversible mark in this category as well.

194
00:28:53,330 --> 00:29:00,990
So. And then. Well, I think so.

195
00:29:05,540 --> 00:29:09,070
So we have kind of a narrowed down far older Markov chain.

196
00:29:09,080 --> 00:29:13,760
That's topic number one to a Baltic Markov chain.

197
00:29:14,180 --> 00:29:19,610
That's topic three, five connections through the top to the second topic.

198
00:29:20,330 --> 00:29:28,610
But you can further divide over these awarded Markov chains into time, reversible Markov chain and the others.

199
00:29:28,640 --> 00:29:45,080
Right. So time reversible mark is really a soft class of Markov chain and some kind of reversible terms.

200
00:29:47,960 --> 00:29:55,250
So the general definition of the idea is actually you look backwards off the sequence.

201
00:29:55,340 --> 00:29:58,220
Right. So the sequence has to be a infinite sequence.

202
00:29:58,550 --> 00:30:08,510
So if you look backwards off a stationary sorry, according to Markov chain, there has to be already in the stationary distribution.

203
00:30:08,870 --> 00:30:15,860
So that's sort of the general idea you need to know. But most important thing, probably the detail balance equation.

204
00:30:24,810 --> 00:30:28,380
So you feel all right, even though the underlying Markov chain is a Gornick marvel.

205
00:30:28,560 --> 00:30:38,220
And the only way you can make a justification that the chain is timed reversible margin opportunities through the detail balance equation.

206
00:30:38,760 --> 00:30:49,980
So high grade II because of high high j for arbitrary pairs of i j in the state space.

207
00:30:50,880 --> 00:30:56,400
So that's pretty straightforward. And I you should, you know, look.

208
00:30:58,310 --> 00:31:05,630
Anywhere else if you need to to verify the chain, it's according to part of chain.

209
00:31:05,690 --> 00:31:09,080
This is the thing. You should do that, right? Right.

210
00:31:09,530 --> 00:31:13,550
So the usual consequence is you find the Nordic Markov chain.

211
00:31:14,810 --> 00:31:20,810
So you make a judgment that the chain is all connected and then they are all recurrent and so on and so forth.

212
00:31:21,140 --> 00:31:26,690
And so first the is that make sure that the chain is aborting something and then

213
00:31:26,690 --> 00:31:32,970
probably find the the pie page and then go with and then further examine the,

214
00:31:33,410 --> 00:31:39,229
um, the detail balance equation. So this is kind of a logical connection of all these things.

215
00:31:39,230 --> 00:31:49,400
This is the most special thing, right? Occasionally there is a theorem like you to do this is you verify it's awarding Markov

216
00:31:49,400 --> 00:31:55,560
chain and then you can go directly through check if detail balance equation satisfy,

217
00:31:55,820 --> 00:32:01,160
right? So if it does also tells you this is fine, this is a boarding pass.

218
00:32:01,790 --> 00:32:10,849
But of course locations in the Delta buying trains is just a boarding pass and often times reversible.

219
00:32:10,850 --> 00:32:14,780
Then you waste your time trying to do this.

220
00:32:15,530 --> 00:32:18,740
It's more like an exam situation if you don't.

221
00:32:19,750 --> 00:32:24,890
And so this is a safe way to get arbitrary stationary distribution.

222
00:32:25,160 --> 00:32:29,690
This is only works to get the stationary distribute.

223
00:32:29,700 --> 00:32:37,220
If you're trying to solve from here, there has to be a time, a reversible mark on the chain, which not generally true.

224
00:32:46,150 --> 00:32:54,580
Yeah. So one of the things you need to convince yourself, if this one is satisfied, that job is also satisfied.

225
00:32:55,180 --> 00:33:01,870
We did this during the class. So find out that you have to be able to prove that.

226
00:33:04,180 --> 00:33:10,540
So the last politicking mark of change the application.

227
00:33:15,650 --> 00:33:32,270
Applications on time. The reimbursement technology is actually just the synapses for them, so you need to know a few things.

228
00:33:33,020 --> 00:33:37,850
The last large number for a markov chain.

229
00:33:41,690 --> 00:33:45,950
I would not want to test you to write the theorem or prove anything,

230
00:33:45,950 --> 00:33:54,020
but you need to understand that this is a this is a how long there is a version of law of large nonverbal Markov chain.

231
00:33:54,050 --> 00:34:00,890
Right. So they are not I suppose they're identically distributed in sample from a avoiding Markov chain

232
00:34:00,890 --> 00:34:09,590
on is not as identically distributed random variables but they are correlated right so I expect,

233
00:34:09,590 --> 00:34:18,500
you know, I chose a this Hastings algorithm, I expect, you know.

234
00:34:20,160 --> 00:34:28,320
If something goes some meaning,

235
00:34:28,860 --> 00:34:41,210
if the problem is state like and how can you build a Metropolis Hastings algorithm that you should be able to lay out the algorithm, right?

236
00:34:41,220 --> 00:34:44,460
So what you need composable distribution.

237
00:34:45,150 --> 00:34:53,070
And so that's the only thing you need to for additional thing for Metropolis Hastings for give some power,

238
00:34:53,070 --> 00:34:56,610
you need the for conditionals if you know what that means.

239
00:34:58,500 --> 00:35:09,330
Okay. That's all for the Markov chain. So we won't go backwards.

240
00:35:13,800 --> 00:35:20,520
We can talk about some of the things.

241
00:35:22,380 --> 00:35:31,830
So there are two distributions we discussed before we got into the General Markov chain discussion about visit.

242
00:35:31,860 --> 00:35:43,290
So if you go back and then see so the simple random walk is a that's the second topic, a simple run a line.

243
00:35:45,720 --> 00:35:53,730
So you well look backwards. You should see a lot of similarities because simple random walk is a markov chain.

244
00:35:54,940 --> 00:35:58,520
Right. It's not necessarily a boarding Markov chain, but it should be clear.

245
00:35:58,530 --> 00:36:07,580
So if you have done the review for the Markov chain, you should look into the simple random walk and then ask the question, why?

246
00:36:07,590 --> 00:36:14,370
That's it's not a boring Markov chain, right? So that's basically the second topic in the markup.

247
00:36:14,550 --> 00:36:24,830
You can check. Those concept like non recurrent positive recurrence versus the Helsinki.

248
00:36:25,180 --> 00:36:28,290
What is the period for the random walk?

249
00:36:28,300 --> 00:36:32,470
This is a you know, it's a pretty clear example.

250
00:36:32,470 --> 00:36:38,410
This is not because the pure V, a simple random walk is not one.

251
00:36:38,500 --> 00:36:52,120
So it's not a periodic but specifically related to symptoms of what we have talk about first the passage time.

252
00:36:55,060 --> 00:37:10,740
That's actually the foundations for us to you know, to think about China recurrence versus ones in state in the in the culture.

253
00:37:10,960 --> 00:37:21,790
So so the technique we compute about we used to compute the expected time for how first passage

254
00:37:21,790 --> 00:37:31,730
time and that's second once again the the actual conclusion about what that how localized

255
00:37:31,930 --> 00:37:38,400
what the the garment looks like the first three parts it's not important but the technique

256
00:37:38,450 --> 00:37:48,160
we can derive this from the first piece is this sort of a recursive thinking right.

257
00:37:48,250 --> 00:37:54,730
Conditional on the first step and either recreate that the problem.

258
00:37:55,000 --> 00:38:06,219
It's more critical in this context so similarly so that that's read you this is just a symbol and this

259
00:38:06,220 --> 00:38:14,379
one lecture and then what we did is about these two things if you can set up the equation again,

260
00:38:14,380 --> 00:38:22,490
this is not algebra test. So I'm not really interested to see how you can solve some complicated equations.

261
00:38:22,510 --> 00:38:27,399
And so the important thing is you can set up that equation and then justify that.

262
00:38:27,400 --> 00:38:35,460
So. It's called an awesome process.

263
00:38:42,930 --> 00:38:51,110
First of all, this is also a mark of training and that you should always think about.

264
00:38:51,120 --> 00:38:55,350
Think back now, especially you would go backwards on the material.

265
00:38:55,710 --> 00:39:02,040
If this Markov chain is what type of the Markov chain is, what the state space.

266
00:39:02,450 --> 00:39:07,620
Right. Think about that. And then there's that look for Markov training.

267
00:39:09,330 --> 00:39:13,030
Right. Is that aborted Marvel?

268
00:39:13,150 --> 00:39:16,390
Actually. No. Why?

269
00:39:17,080 --> 00:39:20,080
This period isn't necessarily one.

270
00:39:21,410 --> 00:39:25,980
It's not a periodic. That's a ceremony for all states.

271
00:39:28,000 --> 00:39:39,240
It is not necessarily one. It could be one or it would depend on what the offspring distribution think about it.

272
00:39:40,100 --> 00:39:45,700
So fun questions and think about it. If you don't know the answer, that's fine.

273
00:39:45,720 --> 00:40:02,200
I don't know the answer off my head either. But in some of the Markov chain.

274
00:40:02,200 --> 00:40:10,839
So, you know, he well, I mean, I know the law there is absorbing states is possible for a class of golf.

275
00:40:10,840 --> 00:40:20,320
It wasn't processes absorbing state that make the basically eliminate basis according to our country if you have absorbing state then it's it's not

276
00:40:20,620 --> 00:40:27,210
usually a irreducible markup I think about that I think both right Fisher model

277
00:40:27,370 --> 00:40:36,910
it's also it's property but the important thing is that how we define it.

278
00:40:37,000 --> 00:40:40,930
We did this a pretty complicated problem during the second Cold War.

279
00:40:40,960 --> 00:40:44,770
I think the key there is you need to identify first of all,

280
00:40:45,520 --> 00:40:53,200
you need to identify all spring distribution or explicitly define amount of spring distribution.

281
00:41:00,340 --> 00:41:13,100
And the second leading right is Z of plus one as this Hong Kong variable expert in my right I to.

282
00:41:13,540 --> 00:41:22,029
So there are two different things. And so if you're given the task to identify the the underlying processes golden blossom process,

283
00:41:22,030 --> 00:41:25,629
then you need to clearly define what is the offspring.

284
00:41:25,630 --> 00:41:30,610
Distribution is actually just z you want to think about this in you one was you

285
00:41:30,610 --> 00:41:34,150
want to look like you don't need to look further on this you don't need to

286
00:41:34,510 --> 00:41:42,280
handle this to is two topics but you need to first clearly defines you one

287
00:41:42,880 --> 00:41:49,340
on top of it and then you get this right you got this compound equation and.

288
00:41:53,520 --> 00:41:54,990
Other than defamation.

289
00:41:55,200 --> 00:42:04,920
I think some of the interesting thing connecting the Gulf, the loss of the process to the convolution as the general politics is.

290
00:42:11,700 --> 00:42:16,920
So you can put those up in your chargesheet probably there will be a couple of those.

291
00:42:17,310 --> 00:42:26,580
So for example, the 2G was a mess because she added So the convolution.

292
00:42:27,960 --> 00:42:43,350
So that's really a consequence of the the compound was apparently right there this one was because she has.

293
00:42:49,250 --> 00:43:01,850
So this is a from the probability generating information for the ambulance.

294
00:43:02,300 --> 00:43:08,390
So you can break it down to ZM and then see that generating function for it.

295
00:43:10,220 --> 00:43:13,610
So the last thing we did is extinction probability. How do we.

296
00:43:20,840 --> 00:43:35,450
So here we need to know this is that you want hi so so we spent a lot of time prove how you can so that the nature of this

297
00:43:35,450 --> 00:43:46,450
extinction probability right is the smallest the root of this a fixed point equation pi code which you want to write the.

298
00:43:48,080 --> 00:43:51,860
So you probably need to know how to. So then.

299
00:43:52,610 --> 00:44:01,220
So if you've got multiple routes, multiple solutions we're trying to pick and why else?

300
00:44:02,630 --> 00:44:07,250
So generally the extinction probability will be one is.

301
00:44:10,440 --> 00:44:18,269
You from the offspring distribution they expected a number of offspring is just the first and the expected.

302
00:44:18,270 --> 00:44:21,600
A valuable easy one is less than strictly less than one.

303
00:44:22,290 --> 00:44:29,790
Yeah, that makes intuitive sense, right? So for every generation, the expected offspring are less than one.

304
00:44:29,790 --> 00:44:34,980
But eventually this whole family or this whole population will die out.

305
00:44:36,000 --> 00:44:42,690
But those are more conclusion, I think, for the and Wilson process, the most important thing is the definition.

306
00:44:43,690 --> 00:44:50,150
Okay. All right.

307
00:44:50,270 --> 00:44:56,470
So that's the last. The topic for us is a general foundational things.

308
00:44:56,990 --> 00:45:18,860
That's basically the tools we're building from the TOS or building to study all these stochastic processes and then Markov chains.

309
00:45:19,520 --> 00:45:38,730
So. So foundations of probability formation, foundations and tools, obviously conditional.

310
00:45:38,750 --> 00:45:44,570
This expectation. What is the modern definition?

311
00:45:46,160 --> 00:45:53,900
How do we get from a conditional expectation to conditional probability?

312
00:45:55,430 --> 00:46:06,020
All the definition of the properties think most of the properties.

313
00:46:06,020 --> 00:46:11,510
You see the similarity where the unconditional expectation except on the cold law

314
00:46:12,020 --> 00:46:25,610
and then the total expectation law that doesn't really deserve a bullet points.

315
00:46:25,610 --> 00:46:32,810
But over these numerical recipe we learn in elementary probability still warms.

316
00:46:33,260 --> 00:46:43,400
So if you're dealing with continuous random variable or discrete random variable, so your original recipe still works.

317
00:46:43,820 --> 00:46:47,930
And then the last thing is the probability generated.

318
00:46:48,260 --> 00:46:51,589
And it's a sort of a broad topic.

319
00:46:51,590 --> 00:47:03,229
We use it multiple ways. But the important thing is this is a really just a mathematical tool to connect a sequence of function, use a function.

320
00:47:03,230 --> 00:47:08,090
This is a not new idea in this class and in calculus, this is a powerful idea.

321
00:47:08,660 --> 00:47:12,530
Right. But yet here we particularly lose.

322
00:47:12,860 --> 00:47:16,130
You have to deal with convolution.

323
00:47:17,180 --> 00:47:21,170
It doesn't mean so in most cases, this is the whole piece of.

324
00:47:22,800 --> 00:47:27,080
So there's the sum of independent random variables.

325
00:47:27,350 --> 00:47:34,090
How do we use that? Because in the probability generating function, that's pretty straightforward, right?

326
00:47:34,250 --> 00:47:39,630
So then it just becomes the right.

327
00:47:39,650 --> 00:47:55,740
We have this uncertainty and plus y impulse to act on the y axis.

328
00:47:56,180 --> 00:48:05,180
So we have this. So this will give you a quick sort of shorthand.

329
00:48:05,330 --> 00:48:12,739
Yes. This is the kind of effective tool to deal with the sum of the the random.

330
00:48:12,740 --> 00:48:15,920
Everything exists a convolution, but there is a restriction.

331
00:48:15,920 --> 00:48:20,150
This is not general, right? So the X or Y has to be non-negative.

332
00:48:22,760 --> 00:48:26,480
Integers. Actually, it's not just not non-negative.

333
00:48:26,690 --> 00:48:34,249
It has to be non-negative integers. Well, this one is true for general probability.

334
00:48:34,250 --> 00:48:43,129
But when we talk about pgf, we've focused mostly on the net negative integer value run the variables.

335
00:48:43,130 --> 00:48:48,020
And so that's that, that's really about the the midterm.

336
00:48:48,100 --> 00:48:55,820
What if you think it's a little too then you know. It's actually, from my perspective, it's not a lot.

337
00:48:58,700 --> 00:49:01,040
I could only choose a few topics.

338
00:49:01,040 --> 00:49:09,840
I think most of things you're going to see is from Markov chain because over the three all the foundations are going to be embedded into it.

339
00:49:10,100 --> 00:49:18,739
And so you're going to use those techniques so you feel have a clear, logical connection of all of these topics.

340
00:49:18,740 --> 00:49:26,800
You are in a good position and that's really it.

341
00:49:26,880 --> 00:49:30,340
And I think I need questions about it.

342
00:49:31,760 --> 00:49:38,690
I think we just discussed that where you want to, you can ask me anything.

343
00:49:38,690 --> 00:49:46,490
I don't have to answer those. So if you ask me what the the problem is, yeah, it's your right to ask, but I'm not going to answer, obviously.

344
00:49:47,150 --> 00:49:50,710
So. But that shouldn't stop you asking questions.

345
00:49:50,720 --> 00:50:00,410
Right? Okay. Go ahead. Or you want to if you want to talk to me privately, we can end the lecture here.

346
00:50:00,410 --> 00:50:03,410
I have to do the office. All right.

