1
00:00:10,280 --> 00:00:12,420
This is Matt Zawistowski,

2
00:00:12,420 --> 00:00:15,210
back to talk about
longitudinal data analysis.

3
00:00:15,210 --> 00:00:18,180
We've already fit numerous
mixed models in this class,

4
00:00:18,180 --> 00:00:20,615
but we haven't actually
performed inference on them.

5
00:00:20,615 --> 00:00:22,490
Statistical inference, is making

6
00:00:22,490 --> 00:00:25,480
decisions between different
models based on the data.

7
00:00:25,480 --> 00:00:27,750
In this lecture, we'll
learn how to use

8
00:00:27,750 --> 00:00:29,490
the likelihood ratio test to

9
00:00:29,490 --> 00:00:32,700
perform inference
on mixed models.

10
00:00:32,700 --> 00:00:35,925
We're going to focus on
inference for group effect.

11
00:00:35,925 --> 00:00:37,650
But the ideas presented hold

12
00:00:37,650 --> 00:00:39,645
for any fixed effect parameter.

13
00:00:39,645 --> 00:00:42,645
The group effect mixed
model provided a framework

14
00:00:42,645 --> 00:00:44,175
for repeated measured data

15
00:00:44,175 --> 00:00:45,920
and samples from
different groups.

16
00:00:45,920 --> 00:00:48,460
We interpreted the
group fixed effect term

17
00:00:48,460 --> 00:00:51,120
to quantify differences in
the outcome between groups.

18
00:00:51,120 --> 00:00:53,620
We even compared the
mixed modal analysis

19
00:00:53,620 --> 00:00:55,025
to standard regression,

20
00:00:55,025 --> 00:00:56,450
to get a sense of why it's so

21
00:00:56,450 --> 00:00:58,540
important to account
for correlation.

22
00:00:58,540 --> 00:01:00,780
But we haven't been able
to formally perform

23
00:01:00,780 --> 00:01:03,030
hypothesis testing of a
regression parameter,

24
00:01:03,030 --> 00:01:05,410
like the group term
for mixed models.

25
00:01:05,410 --> 00:01:08,465
In hypothesis testing, we relate

26
00:01:08,465 --> 00:01:11,615
a scientific question to
a parameter in our model,

27
00:01:11,615 --> 00:01:13,880
and test whether
there is evidence to

28
00:01:13,880 --> 00:01:16,825
reject a null assertion
about that parameter.

29
00:01:16,825 --> 00:01:20,250
For example, in this case
of the group effect term,

30
00:01:20,250 --> 00:01:22,455
the null hypothesis
would typically be,

31
00:01:22,455 --> 00:01:23,730
that there is no difference in

32
00:01:23,730 --> 00:01:25,695
mean outcomes between
the two groups,

33
00:01:25,695 --> 00:01:29,460
which corresponds to a Beta
2 parameter equaling zero.

34
00:01:29,460 --> 00:01:32,330
The hypothesis test
usually entails computing

35
00:01:32,330 --> 00:01:35,090
a test statistic based
on parameter estimates

36
00:01:35,090 --> 00:01:36,980
and standard errors and deriving

37
00:01:36,980 --> 00:01:39,320
a p-value using the
sampling distribution

38
00:01:39,320 --> 00:01:41,165
of the test statistic.

39
00:01:41,165 --> 00:01:43,100
We do this routinely in

40
00:01:43,100 --> 00:01:46,205
standard linear regression
using the Wald statistic.

41
00:01:46,205 --> 00:01:49,100
For example, imagine a
cross-sectional study

42
00:01:49,100 --> 00:01:51,785
of measurements taken on
subjects from two groups,

43
00:01:51,785 --> 00:01:53,450
in which the
measurements across time

44
00:01:53,450 --> 00:01:55,879
are taken on
independent subjects.

45
00:01:55,879 --> 00:01:57,590
We would analyze these data

46
00:01:57,590 --> 00:01:59,450
using a standard
linear regression.

47
00:01:59,450 --> 00:02:02,255
If we were interested in
testing for a group difference,

48
00:02:02,255 --> 00:02:05,555
corresponding to the Beta
2 parameter equaling zero,

49
00:02:05,555 --> 00:02:07,850
we would commonly use
the Wald statistic

50
00:02:07,850 --> 00:02:09,865
and p-value from
the output table.

51
00:02:09,865 --> 00:02:11,220
We were able to do this,

52
00:02:11,220 --> 00:02:13,010
because the sampling distribution

53
00:02:13,010 --> 00:02:15,165
for the Wald statistic
is well-known.

54
00:02:15,165 --> 00:02:16,860
A t-statistic of negative

55
00:02:16,860 --> 00:02:19,530
9.195 could be compared

56
00:02:19,530 --> 00:02:22,705
to that distribution
to obtain a p-value.

57
00:02:22,705 --> 00:02:25,310
Unfortunately, that's no longer

58
00:02:25,310 --> 00:02:27,170
the case for mixed models.

59
00:02:27,170 --> 00:02:30,830
Although the t-statistic can
still be computed as before,

60
00:02:30,830 --> 00:02:33,650
the sampling distribution
is not well known.

61
00:02:33,650 --> 00:02:36,880
So it is not clear what
the p-value actually is.

62
00:02:36,880 --> 00:02:39,914
This is why the lmer function
does not print a p-value

63
00:02:39,914 --> 00:02:43,830
in the output table for fixed
effect regression terms.

64
00:02:43,830 --> 00:02:46,445
How can we perform inference on

65
00:02:46,445 --> 00:02:48,995
fixed effect parameters
from mixed models?

66
00:02:48,995 --> 00:02:53,275
Well, one answer is to use
a likelihood ratio test.

67
00:02:53,275 --> 00:02:56,685
The likelihood ratio test or LRT,

68
00:02:56,685 --> 00:02:58,910
is a statistical test
for comparing two

69
00:02:58,910 --> 00:03:01,450
nested models fit
on the same data.

70
00:03:01,450 --> 00:03:04,860
LRTs can be applied to any
type of regression model.

71
00:03:04,860 --> 00:03:07,045
But when we apply
it to a mixed model

72
00:03:07,045 --> 00:03:09,290
for testing fixed
effect parameters,

73
00:03:09,290 --> 00:03:11,405
we want to ensure that
the random effects

74
00:03:11,405 --> 00:03:13,370
in the nested models
are the same.

75
00:03:13,370 --> 00:03:16,100
That is, we should decide
on the appropriateness of

76
00:03:16,100 --> 00:03:20,360
random intercepts and/or slopes
independently of the LRT.

77
00:03:20,360 --> 00:03:24,380
Let's define exactly what
we mean by nested models.

78
00:03:24,380 --> 00:03:27,405
Nested models consists
of a pair of models,

79
00:03:27,405 --> 00:03:29,550
a full model, and
a reduced model.

80
00:03:29,550 --> 00:03:30,974
As the name implies,

81
00:03:30,974 --> 00:03:32,130
the full model contains

82
00:03:32,130 --> 00:03:34,085
a larger set of
regression parameters,

83
00:03:34,085 --> 00:03:36,020
including for the
specific variables

84
00:03:36,020 --> 00:03:37,400
you are interested in testing,

85
00:03:37,400 --> 00:03:39,510
as well as any
additional covariates

86
00:03:39,510 --> 00:03:41,395
or important
confounding variables.

87
00:03:41,395 --> 00:03:43,190
The reduced model contains

88
00:03:43,190 --> 00:03:45,860
parameters for all the
variables in the full model,

89
00:03:45,860 --> 00:03:48,680
except the variables
you want to test.

90
00:03:48,680 --> 00:03:52,400
Let's take a look at an
example of nested models.

91
00:03:52,400 --> 00:03:54,110
Imagine we want to test for

92
00:03:54,110 --> 00:03:56,165
a group effect in
longitudinal data.

93
00:03:56,165 --> 00:03:57,890
We'll use mixed
models, of course,

94
00:03:57,890 --> 00:03:59,585
to account for the correlation,

95
00:03:59,585 --> 00:04:02,330
and we'll have a fixed
effect term for time.

96
00:04:02,330 --> 00:04:04,040
The question is, do we

97
00:04:04,040 --> 00:04:05,900
need to include a
group effect term?

98
00:04:05,900 --> 00:04:07,850
Is there sufficient
evidence to claim

99
00:04:07,850 --> 00:04:10,285
that the group effect
term is non-zero?

100
00:04:10,285 --> 00:04:12,195
The full model would contain

101
00:04:12,195 --> 00:04:13,995
fixed effects for intercepts,

102
00:04:13,995 --> 00:04:15,645
slope, and group effects,

103
00:04:15,645 --> 00:04:18,425
along with appropriate
random effect terms.

104
00:04:18,425 --> 00:04:20,765
The reduced model
would then eliminate

105
00:04:20,765 --> 00:04:23,485
the group effect term
from the full model.

106
00:04:23,485 --> 00:04:26,870
As you can see, the term nested
comes from the fact that

107
00:04:26,870 --> 00:04:28,370
the regression parameters from

108
00:04:28,370 --> 00:04:29,945
the reduced model are nested

109
00:04:29,945 --> 00:04:32,315
or fit inside the full model.

110
00:04:32,315 --> 00:04:34,940
The LRT is based on model fit,

111
00:04:34,940 --> 00:04:36,830
specifically the deviance metric

112
00:04:36,830 --> 00:04:39,320
found in the lmer
function output.

113
00:04:39,320 --> 00:04:41,870
Deviance is a goodness
of fit statistic,

114
00:04:41,870 --> 00:04:43,070
that describes how well

115
00:04:43,070 --> 00:04:45,935
the fitted model explains
the observed data.

116
00:04:45,935 --> 00:04:48,110
By definition, is
equal to negative

117
00:04:48,110 --> 00:04:51,565
two times the likelihood
value for the fitted model.

118
00:04:51,565 --> 00:04:53,960
The LRT works by comparing

119
00:04:53,960 --> 00:04:56,980
the deviance values between
the full and reduced models,

120
00:04:56,980 --> 00:05:00,150
essentially comparing how
well the models fit the data,

121
00:05:00,150 --> 00:05:01,520
accounting for the fact that

122
00:05:01,520 --> 00:05:04,265
the full model has a larger
number of parameters.

123
00:05:04,265 --> 00:05:06,379
In order to perform an LRT,

124
00:05:06,379 --> 00:05:07,640
we first fit both

125
00:05:07,640 --> 00:05:10,445
the full, and reduced
models to the data.

126
00:05:10,445 --> 00:05:13,445
We then compute
the LRT statistic,

127
00:05:13,445 --> 00:05:15,020
which is simply the difference in

128
00:05:15,020 --> 00:05:17,460
the deviance values
from the nested models.

129
00:05:17,460 --> 00:05:19,800
Importantly, the
sampling distribution

130
00:05:19,800 --> 00:05:22,155
for this statistic is well-known.

131
00:05:22,155 --> 00:05:25,165
It's Chi-square distribution
with degrees of freedom

132
00:05:25,165 --> 00:05:26,740
equal to the difference
in the number of

133
00:05:26,740 --> 00:05:28,835
parameters between
the two models.

134
00:05:28,835 --> 00:05:31,985
In our example, the degrees
of freedom would be one,

135
00:05:31,985 --> 00:05:34,090
because there is only
one parameter difference

136
00:05:34,090 --> 00:05:35,830
between the full
and reduced models,

137
00:05:35,830 --> 00:05:38,705
namely the group
effect term, Beta 2.

138
00:05:38,705 --> 00:05:41,490
We then compute the
p-value by looking up

139
00:05:41,490 --> 00:05:44,250
the LRT statistic in the
sampling distribution.

140
00:05:44,250 --> 00:05:47,190
Luckily, R will handle
all of that for us.

141
00:05:47,190 --> 00:05:48,895
Once we have a p-value,

142
00:05:48,895 --> 00:05:50,650
we now have quantitative
evidence for

143
00:05:50,650 --> 00:05:52,670
considering the null hypothesis.

144
00:05:52,670 --> 00:05:54,300
If the p-value is less than

145
00:05:54,300 --> 00:05:56,080
some pre-specified Alpha level,

146
00:05:56,080 --> 00:05:57,670
say five percent, then we

147
00:05:57,670 --> 00:05:59,575
would reject the
null at that level.

148
00:05:59,575 --> 00:06:02,675
Otherwise, we would fail
to reject the null.

149
00:06:02,675 --> 00:06:04,980
We now have a formal method of

150
00:06:04,980 --> 00:06:06,450
hypothesis testing for

151
00:06:06,450 --> 00:06:09,045
fixed effect parameters
in mixed models.

152
00:06:09,045 --> 00:06:13,455
A critical piece of most
longitudinal data analyses.

153
00:06:13,455 --> 00:06:15,470
The critical element, is that

154
00:06:15,470 --> 00:06:17,090
opposed to the Wald statistic,

155
00:06:17,090 --> 00:06:18,380
the sampling distribution of

156
00:06:18,380 --> 00:06:20,765
the LRT is known
for mixed models,

157
00:06:20,765 --> 00:06:24,325
meaning we can compute valid,
well-calibrated p-values.

158
00:06:24,325 --> 00:06:26,185
The drawback of the LRT,

159
00:06:26,185 --> 00:06:29,050
is that it is restricted to
comparison of nested models,

160
00:06:29,050 --> 00:06:31,760
and only two models can
be compared to the time.

161
00:06:31,760 --> 00:06:33,455
In most cases, however,

162
00:06:33,455 --> 00:06:34,550
this will be sufficient to

163
00:06:34,550 --> 00:06:38,016
achieve the goals
of the analysis.

