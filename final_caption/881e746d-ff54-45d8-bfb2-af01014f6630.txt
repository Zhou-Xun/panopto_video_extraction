1
00:00:00,750 --> 00:00:38,410
But it would seem to imply that any and all she likes to include lots of things to help the animals.

2
00:00:47,790 --> 00:01:18,780
So it's just, you know, you're open to everything.

3
00:01:26,340 --> 00:01:38,070
Let's pick up where we left off last time before we got started.

4
00:01:38,700 --> 00:01:46,500
One of the things I got a couple of questions from was what about integration?

5
00:01:47,490 --> 00:02:01,350
Yes. This example. So one question that I got is, what is our integration of this point before this multiple integration?

6
00:02:01,890 --> 00:02:10,350
Why do we not carry over this trend 21 day to the three all the way through and for every integration?

7
00:02:11,100 --> 00:02:17,970
Right. So the reason is really I mean, it's a multivariate calculus problem.

8
00:02:18,900 --> 00:02:26,140
The way that you break down this multipoint integration into this univariate integration one time,

9
00:02:27,360 --> 00:02:31,860
the way how it works is you focus on one variable of happiness.

10
00:02:31,860 --> 00:02:36,420
This case, you first integrate all that they want, then all the other.

11
00:02:36,720 --> 00:02:37,560
The two is the.

12
00:02:37,800 --> 00:02:47,910
They are basically just the way you decide the range or the intervals or integrate out the you want all the other variables, each of those,

13
00:02:48,000 --> 00:02:59,040
and you can treat them as follows that we decide what is the appropriate intervals of the you want to be integrate out always easier to consider.

14
00:02:59,720 --> 00:03:04,060
There's an example where you have two variables, right?

15
00:03:04,080 --> 00:03:08,340
If you want to do this double integration your first you integrate out why.

16
00:03:08,340 --> 00:03:16,740
One When deciding what is the valid interval of that integration, you can basically treat y two as a constant.

17
00:03:17,340 --> 00:03:28,850
So for East Haven Valley Y two. So far, each area might have way too high.

18
00:03:29,390 --> 00:03:33,950
So this is the interval that is need to integrate now this one.

19
00:03:35,240 --> 00:03:43,340
And once you do that integration, essentially that I gave you a value at this point y two and you do it for every value.

20
00:03:43,340 --> 00:03:50,240
Y to this interval from 0 to 1. You got another function, a function of Y to essentially zero,

21
00:03:50,280 --> 00:03:58,850
the first start of integrate out y one as doing a projection of this function from a two dimensional space down to the one dimensional space.

22
00:03:59,930 --> 00:04:05,270
And then in the second step, we integrate a y integrate with respect to y two.

23
00:04:05,510 --> 00:04:07,970
You do not have y want to to worry about it.

24
00:04:08,480 --> 00:04:18,350
Y y just disappears the way you decide the interval for y one way decide the interval for y to it has nothing to do with the y one.

25
00:04:19,430 --> 00:04:24,980
Right? So similarly for this multiple integration, each step you integrate out of one variable.

26
00:04:25,310 --> 00:04:32,750
So you do this protection of the original item as an all function down by one dimension.

27
00:04:35,780 --> 00:04:41,000
For example, here you have this a minus one dimensional integration.

28
00:04:41,720 --> 00:04:45,620
Each step you reduce the damage one by one by doing this projection.

29
00:04:46,160 --> 00:04:53,540
And once you project it to the lower dimension, you do not have to worry about the variable that you have already integrated out.

30
00:04:54,560 --> 00:04:59,660
But that's why for the subsequent intervals, you do not need to.

31
00:05:02,660 --> 00:05:10,370
For example, when you integrate the Z two, you do not need to decide the interval based on C one.

32
00:05:10,460 --> 00:05:18,230
You only have to consider the lower limit as zero and upper limit as the 3d1

33
00:05:18,230 --> 00:05:22,850
disappear from this equation that has been taken care of in the first step.

34
00:05:24,740 --> 00:05:30,469
Not clarify this this problem and get more and more details.

35
00:05:30,470 --> 00:05:34,790
You have to go back and check your lecture notes from calculus class.

36
00:05:34,940 --> 00:05:38,090
And so this is how is multiplying integration towards.

37
00:05:42,060 --> 00:05:48,480
Right now. Let's continue from where we left off last time.

38
00:05:48,720 --> 00:05:53,400
So we talked about a convolution formula, formulation, formula.

39
00:05:54,150 --> 00:06:03,960
And of course, essentially the convolution formula is a shortcut to this distribution of this summation of independent random barrels.

40
00:06:06,360 --> 00:06:09,270
In particular, if you have to run variables that are independent,

41
00:06:11,400 --> 00:06:17,850
we can easily write out this summation of this to run about that distribution by the summation of this, to run of barrels.

42
00:06:18,450 --> 00:06:30,980
If both are discrete, we can write out the PM of this summation to be these infinite summation of J from negative infinity to infinity of F of x,

43
00:06:31,880 --> 00:06:37,670
the PMMA for ax, evaluate g and have a y value at z minus three.

44
00:06:38,490 --> 00:06:43,020
Thereafter, you'll be following our to find out the distribution for summation.

45
00:06:44,460 --> 00:06:53,520
And the way that we grab this is you can either prove this by total probability or you can grab this through this joint transformation.

46
00:06:54,480 --> 00:06:57,720
If you want to prove it by drawn out confirmation,

47
00:06:58,350 --> 00:07:06,299
make sure that I introduce an additional round about so that it how about our two to our to transformation based on use what we've

48
00:07:06,300 --> 00:07:20,400
learned to first kind of try and try and pump or this new pairs of event variables and then Vadim to got this so the PD of the piano on

49
00:07:20,400 --> 00:07:31,170
this summation okay similarly if it's both are continuous random variable now you can write all the PDL as clockwise as the integration

50
00:07:33,330 --> 00:07:45,690
of X divided would add a z minus y y about about that y or you can get the honor of x if I have an x and y about even at z minus x,

51
00:07:46,900 --> 00:07:56,730
the poles are equivalent. So that's how we can directly write out the the distribution for the summation of independent roundabout.

52
00:07:57,270 --> 00:08:00,270
The key is the have to be independent of the uses.

53
00:08:02,790 --> 00:08:13,439
And last time we used this result, it's to show a couple of interesting results or distributions that we learned before,

54
00:08:13,440 --> 00:08:24,239
for example the sum of its and then so is a common distribution and the sum of two comma

55
00:08:24,240 --> 00:08:31,860
around a variable is another common random variable and the ratio takes some beta form.

56
00:08:32,130 --> 00:08:37,050
Okay. So we have some additional results from this convolution.

57
00:08:38,220 --> 00:08:47,490
For example, if ax is binomial lies binomial with the same parameter P, then we can show that if they are both independent,

58
00:08:47,790 --> 00:08:53,339
then the summation also follows the binomial with the total number of trials

59
00:08:53,340 --> 00:08:59,220
being imposed and the success rate being p and so this is one of the results.

60
00:09:00,540 --> 00:09:07,590
Um, so as a practice, I'll give you a couple of minutes.

61
00:09:07,830 --> 00:09:16,830
Just try to plug in the Pena for the ax and y and say what you can do to show that this summation actually

62
00:09:16,830 --> 00:09:24,900
also balances binomial directly using this result convolution results of this pretty random variable.

63
00:09:25,530 --> 00:09:32,490
And so you want to go through that summation of this to independent binomial is also a final.

64
00:10:56,820 --> 00:12:22,460
It's. All right.

65
00:12:22,820 --> 00:12:32,750
I hope you get it. The truth is, essentially, they just dropped a bug in this convolution formula about this sort of unknowable.

66
00:12:33,680 --> 00:12:40,520
So if we can note this X plus Y, we want to evaluate this PMF at Z.

67
00:12:40,940 --> 00:12:48,590
Then we know we can use this convolution formula to right on the right hand side of this equation.

68
00:12:49,010 --> 00:12:58,530
In particular, this J does not go from negative entity infinity because proposed binomial random variable, the support is not all the containers.

69
00:12:59,350 --> 00:13:07,700
So we have a finite support. So you have to work out this appropriate ground for this j index.

70
00:13:08,180 --> 00:13:14,440
Basically that lower bound is going to be the maximum of zero and z minus and the minus M and

71
00:13:14,450 --> 00:13:22,100
upper bound is a minimum white balance that is to balance based on support of accidental loss.

72
00:13:22,520 --> 00:13:29,240
And then inside this summation is basically just the protocol to our functions, right?

73
00:13:29,630 --> 00:13:32,840
Y value out of g, the other evaluate Z minus G.

74
00:13:33,950 --> 00:13:38,900
And once you do this multiplication, you will see that this term that involves P,

75
00:13:39,350 --> 00:13:46,399
you move the parameter does not really involve the does not has has nothing to do with this summation.

76
00:13:46,400 --> 00:13:50,300
And that's G. So it can be taken outside of the summation.

77
00:13:51,020 --> 00:13:56,210
And what's inside the summation that's going to be the particle to enter was k terms.

78
00:13:56,720 --> 00:14:02,630
What is interest g as the others ambiguous z minus chain z is a concept.

79
00:14:02,840 --> 00:14:09,900
And then how about constants? And now you have to notice that these.

80
00:14:12,060 --> 00:14:17,670
Summation actually is equal to this and plus M should be Z.

81
00:14:18,540 --> 00:14:28,780
So the reason why it's equal is you can think about you have this M plus and distinct balls, right?

82
00:14:29,430 --> 00:14:38,010
And this summation basically tells us how many ways that we can choose Z balls from this M plus and balls.

83
00:14:40,760 --> 00:14:49,080
You can choose zero out of the first models and then choose the z balls out of the the last embossed.

84
00:14:50,110 --> 00:14:58,880
And you got many different ways. Then you can also choose the one balls from the first and balls and z minus one balls from the Los Angles.

85
00:14:58,940 --> 00:15:07,640
You also have many ways, if you sum up all these possibilities, that's how many ways that I choose Z balls out of this and plus and balls.

86
00:15:08,800 --> 00:15:20,780
So that's why you have this equation summation over T and just g times which z minus chain is equal to and plus and just z.

87
00:15:22,580 --> 00:15:28,450
So that's the how we can establish the relation between this concept.

88
00:15:29,270 --> 00:15:31,970
And once you put everything together and notice that,

89
00:15:32,240 --> 00:15:41,660
that essentially if the plot function for a new binomial distribution was parameter I'm plus and and p then

90
00:15:42,380 --> 00:15:48,980
basically we use that convolution to prove that the summation of two independent binomial is also binomial.

91
00:15:53,710 --> 00:16:04,230
Any questions? Similarly, you can use this convolution to approve other properties for other distributions.

92
00:16:04,440 --> 00:16:08,640
For example, with access calls. All was great.

93
00:16:08,940 --> 00:16:12,090
That's why it's bustling with raids. Why?

94
00:16:12,420 --> 00:16:17,940
Both are. And then the summation is also on raid being the summation of the two events.

95
00:16:19,200 --> 00:16:32,099
And that also says from an alternative perspective, it tells us, y you know, if you are, you know, the number, you know,

96
00:16:32,100 --> 00:16:39,800
y unit of time follows across all that number of events and units of time follows a plus all and comes along

97
00:16:40,970 --> 00:16:46,800
so they can consider that different time units to be the summation of independent cosine random variables.

98
00:16:47,820 --> 00:16:57,930
Add them up. They are still causal. Right. And the only difference is of a new rate going to be the summation of the individual rates so that this

99
00:16:57,930 --> 00:17:07,820
result provide a reason why we can model the number of events and units of time using a close on with prime.

100
00:17:09,550 --> 00:17:19,200
And so this results this plus all the results we can also show using the convolution formula and for continuous random variables,

101
00:17:19,440 --> 00:17:25,350
the summation of gamma independent data is also gone, given the second parameter are the same,

102
00:17:26,790 --> 00:17:31,319
and the special case is the summation of exponential, which has become a one.

103
00:17:31,320 --> 00:17:36,210
Lambda is a combination of more square.

104
00:17:36,420 --> 00:17:40,130
Uh. Moreover, you can sum of.

105
00:17:42,180 --> 00:17:47,250
You can sum up multiple exponential independent exponential rate environments,

106
00:17:47,640 --> 00:17:53,520
and that still follows a common distribution because you can do this summation over and over again.

107
00:17:54,000 --> 00:18:00,540
The summation of an independent exponential random arrow was going to become a common distribution parameter,

108
00:18:00,540 --> 00:18:05,910
and that allows us and that's another result.

109
00:18:06,150 --> 00:18:11,760
Again, for all this results. I want to show you that approach here in class,

110
00:18:11,760 --> 00:18:16,680
but I hope you can do that exercise after class by using a convolution to show that

111
00:18:16,680 --> 00:18:25,259
actually is the case and the next property has for normal distribution of life.

112
00:18:25,260 --> 00:18:29,999
Those are normal different parameters than the summation of this to independent.

113
00:18:30,000 --> 00:18:37,500
Normal is also a novel with new medium being the summation of the two means and numerous being the summation of the two viruses.

114
00:18:42,030 --> 00:18:43,940
They can prove it to you within a couple of seconds.

115
00:18:45,030 --> 00:18:52,019
And actually, if you think about how Z is constructed, let's see why the mean summation of individual meaning.

116
00:18:52,020 --> 00:18:55,790
That is the summation of individual variance. Right?

117
00:18:56,310 --> 00:19:03,430
Because the expectation of Z. By the linearity of expectation.

118
00:19:03,520 --> 00:19:13,860
We know it has passed since partition, not one which is new as far as UI and the variance of the z,

119
00:19:14,860 --> 00:19:26,020
the variance of x plus y since they are independent, it's the variance of x plus the variance of what the best statement of square my wise.

120
00:19:27,580 --> 00:19:31,020
That makes sense, but it turns out y is that normal.

121
00:19:31,030 --> 00:19:46,010
You have to show that even in a convolution. So this service before it hangs tend some many of his results to more summations.

122
00:19:46,130 --> 00:19:53,150
Now just summation of two out of our ones plus the summation now and then random animals in each

123
00:19:53,150 --> 00:20:00,630
random variable I is a gala with the same lambda but different first parameter denoted by T.

124
00:20:00,950 --> 00:20:10,879
Then the summation of this independent variable is a cell comma with the first parameter being the summation of the second one being one and similar.

125
00:20:10,880 --> 00:20:15,350
For now, the square of normal is Chi Square.

126
00:20:16,400 --> 00:20:24,380
So the summation of Chi Square is also a Chi Square statement, whereas all Freedom Square is essentially a common distribution.

127
00:20:27,250 --> 00:20:33,550
All right. So all this results again, as I said, I hope you can show it after class doing the derivation.

128
00:20:33,820 --> 00:20:39,700
Familiarize yourself with this convolution compilation and any questions.

129
00:20:40,240 --> 00:20:43,420
Feel free to stop by the office hours to clarify.

130
00:20:45,220 --> 00:20:52,270
Right, any questions or we move on to the next chapter.

131
00:20:54,960 --> 00:21:05,700
All right. They were going to continue and start the last chapter for this course.

132
00:21:07,200 --> 00:21:16,410
Chapter five, also the most challenging and a most important chapter for this course, that is the properties of random samples.

133
00:21:16,770 --> 00:21:26,700
So in this chapter, we're going to talk about the topics like what is the random sample and the sum sampling distributions,

134
00:21:27,210 --> 00:21:33,270
especially for normal distributed, normal distributed and random samples of all our statistics.

135
00:21:33,600 --> 00:21:42,000
And lastly, most importantly, we're going to talk about convergence on the words where your sample size goes to infinity.

136
00:21:42,480 --> 00:21:46,380
What would happen to those statistics?

137
00:21:48,480 --> 00:21:53,250
Probably have already heard the term of some parties. That's what I'm gonna talk about.

138
00:21:53,730 --> 00:22:01,630
And we're also going to introduce a large, a large, large number of large numbers and a central limit thereof.

139
00:22:02,250 --> 00:22:06,780
Those are the most important mathematical statistics.

140
00:22:09,170 --> 00:22:15,450
Let's start with some basic concepts to lay the foundation for later of this far.

141
00:22:15,900 --> 00:22:19,290
First one is random samples.

142
00:22:24,420 --> 00:22:30,810
So random examples comes from the concept of sampling from the population.

143
00:22:31,560 --> 00:22:36,600
If you are interested in some quantities from the population, for example,

144
00:22:36,780 --> 00:22:45,960
if I'm interested in that in human age, I the longevity of human of human beings.

145
00:22:46,590 --> 00:23:00,510
Then I can sample from the population and say how the person can be before an individual dies and and that with multiple samples.

146
00:23:00,900 --> 00:23:07,860
I got a sense of what the distribution would be. What is the average going to be, what the variance is going to be and things like that.

147
00:23:09,480 --> 00:23:14,910
So those samples that I like to draw from the population is called a random sample and it has

148
00:23:14,910 --> 00:23:21,180
to satisfy some conditions in order to become a valid sample to represent the population.

149
00:23:22,530 --> 00:23:34,230
If I didn't know it x1x2 or 2xn as the set of a random sample or a random sample size n from the population, they have to be, first of all.

150
00:23:35,760 --> 00:23:43,110
Are mutually independent and they have to have the same distribution.

151
00:23:44,980 --> 00:23:53,980
And if you think about sampling the hide from the population by sampling the population is all the students from Michigan.

152
00:23:55,210 --> 00:24:02,140
We can draw a random sample. You can either draw samples from, you know, well, it is individuals.

153
00:24:02,320 --> 00:24:06,550
That's not a random sample. You have to draw it randomly from the population.

154
00:24:06,910 --> 00:24:12,610
So they are mutually independent and also they have to represent order to represent the entire population.

155
00:24:12,910 --> 00:24:20,800
They have each random, random variable out to have the same distribution with that variables in this population.

156
00:24:21,490 --> 00:24:30,160
So it's almost the two most important conditions for a run of arrivals to be a random sample is first we have to be independent.

157
00:24:30,490 --> 00:24:37,060
Second, their marginal distribution has to be the same or they have to be identical distributed.

158
00:24:39,580 --> 00:24:45,700
Alternatively, we can say there's x12x and they are independent and identically distributed random

159
00:24:45,700 --> 00:24:52,990
variables or typically denoted as are the independent and identical distributed.

160
00:24:53,770 --> 00:25:01,000
And we can write it as x12x and follow the same distribution, which is denoted by this PDA or piano.

161
00:25:01,990 --> 00:25:04,840
And we put an I.D. on top of this.

162
00:25:04,840 --> 00:25:12,970
The US, I'm showing that all of these random variable, they are independent and identical and distributed with this distribution power.

163
00:25:16,150 --> 00:25:23,890
If they are independent and are identical distributed, we can write out their joint distribution, their truncated or drawn PMF.

164
00:25:24,280 --> 00:25:33,070
I just multiply the individual PMA and they not only will learn that this is the likelihood,

165
00:25:33,790 --> 00:25:45,790
the likelihood of us of this random sample and we may have parameters in this PDA function and we can

166
00:25:45,790 --> 00:25:52,750
talk about our maximum likelihood estimate for those parameters for using this likelihood function.

167
00:25:53,200 --> 00:25:57,550
So the likelihood of the essentially drawing PDA of the random sample.

168
00:26:00,430 --> 00:26:04,840
So that's what I run the sample. Nothing mysterious. It's just two conditions that I have to check.

169
00:26:05,140 --> 00:26:08,920
One is they are and a second they are identical distributed.

170
00:26:09,820 --> 00:26:12,640
That becomes a random sample.

171
00:26:14,710 --> 00:26:23,170
And once we have a random a sample, we can calculate a lot of statistics to tell us useful information about the population.

172
00:26:25,180 --> 00:26:34,150
We call that in the probability. In the first couple of lectures, we have learned there are many important statistics that people care about.

173
00:26:34,690 --> 00:26:40,600
For example, I can calculate the means of amount of our we can calculate the variance coronavirus.

174
00:26:40,960 --> 00:26:47,080
Now it this random samples, although we do not know the exact mean errors of this random variables,

175
00:26:47,530 --> 00:26:52,300
but we can use these samples to get an approximate of those quantities.

176
00:26:53,920 --> 00:27:02,350
Again, assuming that you are interesting that in the in the height for students in Michigan,

177
00:27:03,160 --> 00:27:08,080
this rhinovirus, each rhinovirus is the high or one student.

178
00:27:08,950 --> 00:27:12,820
Assuming that you collect 100 samples from the population,

179
00:27:13,210 --> 00:27:18,370
you can calculate the average height of this one of students and that number

180
00:27:18,550 --> 00:27:23,709
is going to be a good approximate for the population mean for the population,

181
00:27:23,710 --> 00:27:27,260
average height for all students in Michigan.

182
00:27:28,300 --> 00:27:41,590
So that's a sample. Okay. So if this do this sample average of this random sample that give you this X bar, which is the sample, similarly,

183
00:27:41,740 --> 00:27:50,649
you can calculate the balance based on this random samples using this formula one over and minus one times.

184
00:27:50,650 --> 00:27:59,800
The summation of I from one to an x in minus x bar where this as far as just a sample being squared,

185
00:28:00,970 --> 00:28:03,970
we got a quantity and that quantity is called the sample variance.

186
00:28:05,650 --> 00:28:14,750
If you look at how it's calculated, forget about this and minus one part, we're going to explain why we're two and minus one later.

187
00:28:15,400 --> 00:28:25,690
But essentially, that is just the average of this quantities as I am, minus as far as as far approximated the expectation.

188
00:28:26,560 --> 00:28:34,450
But that is just that approximating expectation of the squared difference between Iran overall and its population.

189
00:28:36,040 --> 00:28:40,240
So that's why it's approximating the population variance.

190
00:28:40,960 --> 00:28:51,540
So this is called the sample variance. And one thing that you may notice is that the coulson frown is one over and minus one.

191
00:28:53,220 --> 00:28:56,460
You may wonder why there is a minus one. We're going to see that in the second.

192
00:28:59,090 --> 00:29:07,070
But that's how we define the parents. And if you take the square root of the sample parents, we can have the sample standard deviation.

193
00:29:08,510 --> 00:29:13,910
So again, these sample mean is approximating a population median.

194
00:29:17,790 --> 00:29:20,280
Which is an expectation of each one of our lives.

195
00:29:21,060 --> 00:29:29,220
And this simple virus is approximating the sample beat the population virus, which is the virus of each random.

196
00:29:29,740 --> 00:29:36,360
All right. And lastly, this is approximating the standard deviation, which is the square root.

197
00:29:39,490 --> 00:29:42,970
Abhorrence of alcohol. And so.

198
00:29:49,370 --> 00:29:52,790
So the mean sample means sample Baron's sample standard deviation.

199
00:29:53,180 --> 00:30:00,260
These are all called statistics because they are functions of this random sample.

200
00:30:00,500 --> 00:30:08,310
So they are called statistics. There are other statistics that we can construct based on this random sample.

201
00:30:10,200 --> 00:30:13,560
For example, we're going to talk about order statistic later.

202
00:30:14,350 --> 00:30:21,780
Our statistics is also, instead of statistics that are functions of this, random samples.

203
00:30:24,550 --> 00:30:37,530
In particular, as this process is one means the smallest amount out of this and random barrel random variables modifier.

204
00:30:37,530 --> 00:30:46,740
What I mean is that the minimum of I want to add about three out of these samples are objects and random parallels.

205
00:30:47,190 --> 00:30:54,329
Which one is the smallest what is the smallest five of this amount of animals that

206
00:30:54,330 --> 00:31:00,659
give us this x parenthesis one end and as parenthesis two is the second smallest,

207
00:31:00,660 --> 00:31:09,600
that size and so on, so forth. So the last one x parentheses end is the largest by our office and samples.

208
00:31:14,630 --> 00:31:19,790
Now sometimes these are hobby interests to quantify some statistics of interest.

209
00:31:20,490 --> 00:31:25,400
For example, you may again taking this height example.

210
00:31:25,790 --> 00:31:28,970
You may be wondering what is the shortest?

211
00:31:31,950 --> 00:31:37,260
Well, what is the shortest, shortest height of the students in Michigan?

212
00:31:37,830 --> 00:31:45,210
So you can collect the random sample and use the first order statistics to produce something, a quantity of interest.

213
00:31:46,290 --> 00:31:52,830
Or you may be interested in knowing the median height for the students in Michigan so that

214
00:31:52,840 --> 00:31:59,880
you can use the middle one of this order statistics to approximate that quantity of interest.

215
00:32:00,600 --> 00:32:04,499
So that's how you can use these different statistics to answer the question.

216
00:32:04,500 --> 00:32:07,170
Something interesting, right?

217
00:32:08,220 --> 00:32:19,920
After all, all this statistics, they are useful for approximating some quantity of interest that you can use that you want to get from the population.

218
00:32:20,670 --> 00:32:24,629
So you cannot evaluate the entire population.

219
00:32:24,630 --> 00:32:33,840
You use this random samples to help you approximate those quantities of interest, and that's the purpose of the random samples and the statistics.

220
00:32:38,610 --> 00:32:43,020
Here again, a recap on our statistics.

221
00:32:43,470 --> 00:32:45,870
The simple meal is as parenthesis.

222
00:32:45,870 --> 00:32:58,439
One simple maths as princess and orange is the difference between the two and and the sum comedian is, if any is odd.

223
00:32:58,440 --> 00:33:07,460
If the number of samples you cut is odd, then it just adds this process and plus one over to it.

224
00:33:07,470 --> 00:33:14,400
And it's given that just that the average of the middle two quantities and over

225
00:33:14,400 --> 00:33:20,970
two and over two plus one does not give you the median for your random sample.

226
00:33:32,940 --> 00:33:39,850
You. In general. Now we can formally define what is what a statistic is.

227
00:33:40,360 --> 00:33:54,339
As you have seen from the previous examples, a statistic is typically a function of this random samples which is denoted by this t of x

228
00:33:54,340 --> 00:34:02,200
one to access here x one to our on is the random sample which are high the sum distribution.

229
00:34:04,450 --> 00:34:16,480
Any function as a function of this random sample is called a statistic, and this function could be a real adding or a real macro value.

230
00:34:20,160 --> 00:34:25,380
For example, if this t function is just the average of the arguments,

231
00:34:25,950 --> 00:34:37,260
then that give us the sample mean which is a statistic at this t function is a real vector by function of ordering this n samples.

232
00:34:38,700 --> 00:34:44,370
Now give us the order statistics, which is also a set of statistics.

233
00:34:45,690 --> 00:34:54,999
Right. Whatever the function is, as long as it's a function, a real value to our real value about a function of OS x12x.

234
00:34:55,000 --> 00:35:08,840
And it gave us a statistic. And the probability distribution of the statistic is called the sampling distribution of Y,

235
00:35:09,710 --> 00:35:17,660
then the distribution of Y is called the sampling distribution of what we is based on this random sample.

236
00:35:21,140 --> 00:35:28,490
And essentially we can derive the distribution for Y or any given Y because we know the joint distribution for X, one,

237
00:35:28,490 --> 00:35:40,400
two X and any transformation of that, we should be able to provide the of the distribution to other words or any statistic.

238
00:35:41,360 --> 00:35:47,900
Given the distribution of the random samples, we can derive the distribution for these statistics.

239
00:35:48,440 --> 00:35:53,120
And once we have the distribution of the statistic, they can help us answer a lot of questions.

240
00:35:53,750 --> 00:36:03,440
If we know the distribution of mean right, we can quantify where the population means is likely to lie in that distribution.

241
00:36:04,640 --> 00:36:12,350
The quantification of how the population means going to be if they have the distribution for this.

242
00:36:12,350 --> 00:36:21,840
Our statistics, we have a good sense of what will be the smallest body right of the general population, what will be the largest fact?

243
00:36:21,860 --> 00:36:30,470
What would be the median? We all we can all get a pretty good sense given the sampling distribution of that statistics.

244
00:36:42,610 --> 00:36:55,480
Many questions about this concept. So some of the concept may be a little bit abstract at this point, but later on we will introduce some examples.

245
00:36:55,720 --> 00:37:00,879
We're going to look at some examples to solidify some of this concepts.

246
00:37:00,880 --> 00:37:03,190
And hopefully along the way,

247
00:37:03,190 --> 00:37:14,560
you will be more familiar with why we need to define this random samples and why we need to derive distributions for these statistics.

248
00:37:15,400 --> 00:37:21,880
And for now, a two most important things to keep in mind is first, what is a random sample?

249
00:37:22,240 --> 00:37:31,540
Second, what is a statistic? Random sample is essentially random animals that are independent and identical to distribution,

250
00:37:32,290 --> 00:37:35,650
and a statistic is just a function of this random sample.

251
00:37:36,580 --> 00:37:43,280
Those are the two most important definitions. All right.

252
00:37:43,280 --> 00:37:50,440
So this is basically a recap of what I just said. As citizens, we're interested in distributions of statistic.

253
00:37:51,200 --> 00:37:53,409
For example, as far or as square,

254
00:37:53,410 --> 00:38:04,370
the supplement or the simple variance or the standardized statistics such as the sample mean minus the population mean divided by the standard sample,

255
00:38:04,640 --> 00:38:05,630
standard deviation.

256
00:38:06,310 --> 00:38:17,660
And so this is also sometimes also referred to as this for paying out this distribution directly using the theories that we have discussed so far.

257
00:38:19,010 --> 00:38:22,880
They are essentially just the transformation of the rhinovirus, always knowing distribution.

258
00:38:23,510 --> 00:38:32,470
And once we know this distributions for this newly constructed statistics, we can answer a lot of questions of interest.

259
00:38:32,810 --> 00:38:36,710
We can quantify the distributions for the parameters of interest.

260
00:38:38,810 --> 00:38:44,540
But that's why we need to define these random samples and the statistics.

261
00:38:48,090 --> 00:38:59,110
Sure. So we can knock out the exact solutions budget for this distribution in many cases because it involved this unknown parameters,

262
00:38:59,440 --> 00:39:06,280
for example, for this disease score. All right. These are these this score is also a statistic.

263
00:39:07,170 --> 00:39:11,399
As you can tell, because it's a function of this run of samples.

264
00:39:11,400 --> 00:39:17,610
I just want to access it. But it does involve some unknown parameters, the mute unit.

265
00:39:18,090 --> 00:39:24,000
So sometimes we cannot that exact distribution for it because it involves unknown parameters.

266
00:39:24,540 --> 00:39:33,330
But what we can do is we can get approximations, especially when the sample size of your sample is large.

267
00:39:33,720 --> 00:39:41,970
We can get the so called asymptotic distribution of the statistics, which does not involve this all known parameters.

268
00:39:42,420 --> 00:39:51,540
And those are some tiny distributions. Can help us even better approximate or quantify the distribution of interest.

269
00:39:52,920 --> 00:40:02,490
For example, later on we will show how to derive the asymptotic distributions for this sample mean for the sample variants and so on and so forth.

270
00:40:03,090 --> 00:40:11,280
And it will say that those some theta distributions can actually help us quantify how far the sample mean.

271
00:40:11,280 --> 00:40:15,450
That simple variance is from the actual population mean and population happens.

272
00:40:22,150 --> 00:40:27,040
So here are the topics that I'm going to cover in this chapter the properties of Novel Sound Point.

273
00:40:28,210 --> 00:40:33,790
We particularly focus on the normal sampling because normal distribution, as I mentioned,

274
00:40:34,030 --> 00:40:41,740
is the foundation of mathematical statistics, partially because it is the distribution for many.

275
00:40:45,440 --> 00:40:48,559
Many real, real quantities.

276
00:40:48,560 --> 00:40:55,180
Like if you aggregate those small errors or small deviations, it actually follows a novel computer.

277
00:40:55,490 --> 00:41:03,110
And also because of its nice properties summation, it's close to this linear transformation.

278
00:41:03,440 --> 00:41:08,660
And also it has this that multivariate versus marginal distribution relations.

279
00:41:08,990 --> 00:41:15,530
All this nice properties determines that normal distribution is really the foundation of the mathematical statistics.

280
00:41:15,890 --> 00:41:23,480
So we're going to focus on a normal sampling, and we also going to talk about the properties of order statistics.

281
00:41:24,530 --> 00:41:29,660
And then we're going to introduce three kinds of convergence as small size infinity.

282
00:41:30,080 --> 00:41:35,720
One is convergence in probability, one is almost sure it's convergence, and one is convergence in distribution.

283
00:41:36,210 --> 00:41:47,490
And with that, we tend to introduce large numbers, central limit theorem and Delta method, sometimes asymptotic.

284
00:41:47,840 --> 00:41:51,370
And you will learn more about us some topics that next semester.

285
00:41:51,950 --> 00:42:01,070
602 But here we kind of introduce the basics of some products to prepare you for that future course.

286
00:42:03,400 --> 00:42:13,450
And. All right.

287
00:42:13,840 --> 00:42:19,180
So first, let's take a look at this.

288
00:42:19,750 --> 00:42:28,590
Some call me a friend of ours because it's really. The most important statistic that people really care about from a random sample.

289
00:42:29,010 --> 00:42:35,370
When you when you are given a random sample, the very first thing that we calculate is the sample mean on sample balance,

290
00:42:35,850 --> 00:42:39,710
a sample mean recall that tells you where the population,

291
00:42:39,790 --> 00:42:47,310
what is the center of the population and the sample virus essentially tells you what is the degree of spread is for the population.

292
00:42:47,670 --> 00:42:52,829
Those two are the most important statistics and recall the definition of sample

293
00:42:52,830 --> 00:42:58,590
mean is just this summation of the individual random arrivals divided by hand.

294
00:42:58,740 --> 00:43:12,720
And the sum of errors in these has this formula and it has the following three properties which lay the foundation for subsequent results.

295
00:43:13,080 --> 00:43:22,710
That is as the 1000. They are random samples from a population with true me at population mean to be new population variants to basic square.

296
00:43:23,160 --> 00:43:28,500
Then we have the following three relations but first.

297
00:43:30,560 --> 00:43:35,810
Expectation of this sample mean is equal to the population.

298
00:43:37,640 --> 00:43:42,500
Second, the variance of the sample mean is this population is divided by ten.

299
00:43:43,040 --> 00:43:47,690
And lastly, expectation of this sample variance is the population.

300
00:43:49,760 --> 00:43:52,820
In particular, the first one and the last one.

301
00:43:52,830 --> 00:43:56,210
The third one are very important.

302
00:43:57,230 --> 00:44:09,560
And because it tells us that these population mean ladies vacation, the average of that population mean of that sample mean will be the population.

303
00:44:11,090 --> 00:44:14,540
So to that extent, it's a good approximation of the population.

304
00:44:15,230 --> 00:44:23,790
And also the last one says, if you do this experiment, draw this random samples multiple times, each time you calculate this similarity,

305
00:44:24,290 --> 00:44:33,920
then on average that sample is going to be equal to the population, is going to be equal to the population variance.

306
00:44:35,930 --> 00:44:41,810
And see this two properties on court. I'm biased in this for these two statistics.

307
00:44:45,710 --> 00:44:52,790
They are unbiased estimate are for the sample mean and the population mean and the population variance.

308
00:44:54,370 --> 00:45:00,500
And in fact, because my expectation of this square is equal to Sigma Square,

309
00:45:01,130 --> 00:45:05,360
that's why we actually need in this one over and minus one instead of one over it.

310
00:45:05,690 --> 00:45:12,350
Because if supplement this one over and minus one by one over and whatnot, have this nice property.

311
00:45:14,150 --> 00:45:17,540
If you replace one over and minus one by one over and.

312
00:45:18,950 --> 00:45:26,900
My expectation that quantity of that statistic won't be equal to that population bounds.

313
00:45:27,560 --> 00:45:33,410
So I'll be biased in the non particular constants one over and minus one.

314
00:45:33,800 --> 00:45:41,690
To make an unbiased, we can prove each one of them.

315
00:45:43,670 --> 00:45:47,900
Using what we have learned about the properties of men and the parents.

316
00:45:48,770 --> 00:45:59,210
Take our first look at a show that the expectation or this sample mean first we can break it down.

317
00:46:01,690 --> 00:46:07,510
But getting in while this statistic is really about by definition,

318
00:46:07,690 --> 00:46:19,060
that's the summation pie goes from one to end, some of it divided by and that's how we define the sample mean.

319
00:46:20,410 --> 00:46:31,240
And to calculate the expectation of that statistic, you just need to use the property of about patient that is a linear operator.

320
00:46:32,410 --> 00:46:36,879
So that is to say that is equal to one over an estimation.

321
00:46:36,880 --> 00:46:49,300
I goes from one to present expectation of each random variable, right as these x12x and they are a random sample.

322
00:46:50,050 --> 00:46:56,660
It just means we have the equal, we have the same distribution with the same mean in the population.

323
00:46:57,490 --> 00:47:10,240
So that gives us one over and some. I goes from one A and that's just me which is complete approve of the first property.

324
00:47:10,990 --> 00:47:14,710
The expectation of this sample which is the population.

325
00:47:15,820 --> 00:47:20,680
The other words sample mean it's an unbiased estimate of the population.

326
00:47:20,680 --> 00:47:30,270
We. Any question.

327
00:47:39,190 --> 00:47:46,510
All right. I have a question for you. So this X1 one to and they are a random sample from this population.

328
00:47:47,780 --> 00:47:53,860
They find one that got it. First of all, in this sample mean the only unbiased estimate of the population means.

329
00:47:59,870 --> 00:48:08,630
It's not right. Can I find construct other statistics with men equal to this meal?

330
00:48:08,930 --> 00:48:16,790
As long as the mean of a statistical community is an unbiased estimate, our community can consider another unbiased estimate.

331
00:48:16,850 --> 00:48:24,020
I mean, it's not very good if you just take one from this and samples.

332
00:48:24,980 --> 00:48:35,760
That's the unbiased estimate you. Right because that's speculation of any right now from this random sample.

333
00:48:36,110 --> 00:48:43,550
It's always equal to me. So any random random variable can serve as an unbiased estimate for me.

334
00:48:44,150 --> 00:48:49,850
Alternatively, you can take, for example, the average of the first five are the last six.

335
00:48:50,150 --> 00:48:57,590
They are all unbiased estimate. A later we all learn from a large number that central limit theorem.

336
00:48:57,890 --> 00:49:02,780
This X bar is the most efficient estimate for me.

337
00:49:03,160 --> 00:49:07,680
Probably learn that not semester efficiency, but ask minor.

338
00:49:08,060 --> 00:49:14,870
Although all of these are unbiased a some are better than the other in terms of we have the smallest amounts,

339
00:49:16,010 --> 00:49:21,590
it provides you the most accurate estimate with the smallest degree of surprise.

340
00:49:25,550 --> 00:49:40,900
And that's that. And the second we can show that the bearers of this X bar, the men, the sample mean is equal to a Sigma square over here and again.

341
00:49:40,900 --> 00:49:49,880
And we can show that by writing out the definition for sample mean that is white.

342
00:49:50,000 --> 00:49:57,100
And I now need to take into account the fact that these random samples there are independent, random variables.

343
00:49:58,210 --> 00:50:06,400
If they're independent, then we have one over and square the sum of individual variance.

344
00:50:11,450 --> 00:50:17,550
And that gave us one over square sum of sigma squares.

345
00:50:19,520 --> 00:50:32,840
That's just sigma squares for. And from this tour result, we can also notice another thing if your sample size goes to infinity,

346
00:50:33,320 --> 00:50:39,229
if our sample size become very large, does that affect the expectation of this step?

347
00:50:39,230 --> 00:50:42,230
I mean, it does not.

348
00:50:42,320 --> 00:50:46,210
Right. Because the expectation of the sample mean it's always mute.

349
00:50:46,220 --> 00:50:51,530
It does not have anything. But what it will affect is the variance of the sample.

350
00:50:52,760 --> 00:50:57,710
Right. If your angles to infinity, that just means the variance and a shrink or zero.

351
00:50:59,810 --> 00:51:08,660
And what that means is that the sample mean was for a very large sample size, going to have very small variability.

352
00:51:10,100 --> 00:51:21,650
But it's always going to be center around your true population that provides a good estimate for this population.

353
00:51:21,670 --> 00:51:27,290
Mean if you really care about this population mean, then it provides a way to estimate that.

354
00:51:27,440 --> 00:51:34,130
That is to collect a large enough sample size for this random sample and calculate the population mean.

355
00:51:34,430 --> 00:51:37,100
And that mean going to be centered around the population.

356
00:51:37,100 --> 00:51:45,740
Mean was a very small variance so that you can see how we can use this random sample to get an estimate.

357
00:51:45,980 --> 00:51:49,250
To get that to an estimate, the quantity. I'll be interested.

358
00:51:52,960 --> 00:51:56,560
All right. So let's take a break and come back to the show.

359
00:51:56,950 --> 00:52:54,940
The third property. We hope you had a lot of.

360
00:52:58,130 --> 00:53:28,410
I'm actually not sure you can use this result to outweigh the risks once you prove all this result based on what you do with.

361
00:53:44,670 --> 00:53:49,140
I've been at this for nine today.

362
00:53:49,880 --> 00:54:12,630
There's a of. I mean, you know, stop.

363
00:54:14,520 --> 00:54:24,150
It's not just what happens in the courtroom.

364
00:54:24,870 --> 00:54:41,080
How hard is it to look these people in front of your.

365
00:54:55,270 --> 00:54:56,200
With outcomes.

366
00:54:57,910 --> 00:56:10,450
I thought you would want everything you need to be simply, for example, to get the song, which is really, you know, I'm not sure how to question.

367
00:56:11,490 --> 00:56:35,120
I just want you to know that, you know, you know, it's important to you.

368
00:56:48,220 --> 00:57:19,660
But I didn't put you into it because she was in a place where they also brought us to the golden rule seem to make sense of it,

369
00:57:31,640 --> 00:57:51,630
which is a good thing to keep trying to do with services.

370
00:57:57,020 --> 00:58:29,740
And one of the things I used to challenge was to just putting something out to do

371
00:58:32,140 --> 00:58:57,370
is chance to go to the movies that were my initial for the audition and whatnot,

372
00:58:58,130 --> 00:59:07,180
which is it's just a new way to do this.

373
00:59:07,180 --> 00:59:16,930
My sources said he would choose me.

374
00:59:17,740 --> 00:59:37,980
It would not have nothing to do with you in some kind of relationship to his son.

375
00:59:49,500 --> 01:00:00,960
I would not have anything to do with someone who committed suicide.

376
01:00:02,900 --> 01:00:10,770
He said he should be working with you on your work.

377
01:00:11,190 --> 01:00:28,660
You should be able to write.

378
01:00:29,190 --> 01:00:46,970
So let's just take a look at the third property, which is one which has the expectation of a simple verity as equal to the population variance.

379
01:00:48,000 --> 01:00:53,549
Why don't we take a couple of minutes trying to prove the third properties of the

380
01:00:53,550 --> 01:01:00,210
sample balance show that it is actually a unbiased estimate of the population.

381
01:01:01,230 --> 01:01:07,110
Before that, the stamp of errors is defined by one over and minus one summation.

382
01:01:07,270 --> 01:01:13,100
I'm one two and it's all right. Minus X bar squared.

383
01:01:13,500 --> 01:01:23,399
So that's how we define the sample variance, show that this quantity has a citation equal to the population amounts and also provide

384
01:01:23,400 --> 01:01:31,130
the rationale why we use this constant of one over a minus one instead of one over.

385
01:04:45,720 --> 01:05:11,300
You got it. Show me your hand if.

386
01:05:11,410 --> 01:05:17,590
Got it. Minute.

387
01:06:04,820 --> 01:06:14,180
Okay. So let's look at this together. So to see how we can show that expectation of a simple balance is equal to the population amounts.

388
01:06:15,080 --> 01:06:26,380
And. So to show that the expectation of some of our fans, we first need to be in the definition of a simple words.

389
01:06:34,810 --> 01:06:41,640
Once you plug it in, you will say that especially if this is calculating, makes fractions of a sum run barrel.

390
01:06:43,580 --> 01:06:47,580
All right. And to simplify the calculation,

391
01:06:47,580 --> 01:06:57,710
one thing that we can do to take out this constant and use the linear linearity of expectations to move this expectation inside this summation.

392
01:06:58,740 --> 01:07:03,340
That should be the first step. And once you do that.

393
01:07:03,880 --> 01:07:10,000
This is what we are dealing with. This one over here, minus one some.

394
01:07:11,930 --> 01:07:19,160
I have one too. And the expectation of x minus x r squared.

395
01:07:21,090 --> 01:07:29,020
So that's I went to to deal with. Now in order to evaluate this quantity.

396
01:07:29,020 --> 01:07:34,750
It's not straightforward or what not, but it is equal to. So we need to further break down that square.

397
01:07:41,620 --> 01:07:51,670
But breaking it down and we're dealing with x squared minus 2xir us x bar square.

398
01:07:53,080 --> 01:07:57,550
All right. Now, we can use the linearity of this expectation one more time.

399
01:08:03,620 --> 01:08:14,560
You know, I square minus to the x i r us we are spa square.

400
01:08:18,950 --> 01:08:32,980
And now if you'll take a look at this terms the first one yard signs square that is the expectation of a single run of Marvel squared.

401
01:08:34,220 --> 01:08:39,490
And from what we have learned, we know that expression, right.

402
01:08:39,750 --> 01:08:43,520
Using you can express that using the baron and the mean.

403
01:08:44,480 --> 01:08:48,680
And what is that? Chi square?

404
01:08:51,560 --> 01:08:58,710
As the veterans. What's New Square?

405
01:08:59,880 --> 01:09:08,400
Right. Because the expectation of X squared minus the expectation of X height squared is the variance.

406
01:09:09,450 --> 01:09:13,110
So that is equal to the sigma squared plus minus square.

407
01:09:14,400 --> 01:09:26,150
And for the medium term, whether bring it down or you can know this summation inside to help you, the answer is understand this term, right?

408
01:09:26,670 --> 01:09:38,550
In particular, if you put this summation inside, in other words, you have this a minus to summation from one to an expectation of X.

409
01:09:39,420 --> 01:09:47,400
As far than that, give us to give to a patient of summation.

410
01:09:48,460 --> 01:09:52,510
One at a time as far.

411
01:09:54,930 --> 01:10:08,000
That is to find the Asian spa where we can move this emotion inside the always the center.

412
01:10:08,330 --> 01:10:10,070
And once you do that in a declaration,

413
01:10:10,100 --> 01:10:24,050
you will see that basically I spa square is going to be can be combined with the last turn to become minus E at Spa Square.

414
01:10:24,080 --> 01:10:30,410
In other words, as long as we can evaluate this E as spa squared, we can get.

415
01:10:33,610 --> 01:10:37,720
The third and the third term. So what is its R-squared?

416
01:10:39,120 --> 01:10:42,850
Again, we can use the same result. Right. So that's far.

417
01:10:43,300 --> 01:10:49,330
It is another round about which we do know the mean and the variance from property A and B.

418
01:10:49,820 --> 01:11:02,380
So yes, Bar Square is essentially the virus callbacks, bar plus e r squared.

419
01:11:03,430 --> 01:11:12,190
If you treat this as far as a new round of variable, you can write out that yeah, it's bar squared has balanced plus a mean squared.

420
01:11:12,910 --> 01:11:20,739
Okay. And then we can plug in what do we have learned from property and B to write that as not to earn

421
01:11:20,740 --> 01:11:33,640
Times Sigma Square over and plus New Square and put everything back together here and negative.

422
01:11:52,160 --> 01:12:04,130
Well, the signature terms. And finally, you can simplify this.

423
01:12:05,750 --> 01:12:17,930
It was, say, about the stimulus square just out and the summation and a B and minus one sigma squares and that and minus one cancels out.

424
01:12:18,410 --> 01:12:21,770
I just end up with Sigma Square. All right.

425
01:12:24,290 --> 01:12:30,870
So the proof. A crew.

426
01:12:33,190 --> 01:12:39,880
Only use the definition and the linear properties of the linear property of the application calculation.

427
01:12:40,690 --> 01:12:43,870
All right. Any questions about this proof?

428
01:12:48,950 --> 01:12:57,350
So from this proof that we can say why we made this call, said one over and minus one in front of the summation,

429
01:12:57,890 --> 01:13:06,290
because only when this one went over and minus one, we can get this unbiased estimate for Sigma Square.

430
01:13:07,430 --> 01:13:10,520
If you replace one over and minus one by one over n,

431
01:13:11,150 --> 01:13:19,070
you can say that the expectation of the new square is now going to be equal to your sigma squared,

432
01:13:19,190 --> 01:13:26,750
but rather an equal to a minus one times and over minus one times the Sigma Square.

433
01:13:29,220 --> 01:13:35,670
All right. So the meeting is now going to be exactly equal to the population variance.

434
01:13:38,060 --> 01:13:48,680
That's why we need this one over and minus one. And that's also the constant that is using most softwares we calculate the population variance.

435
01:13:48,920 --> 01:13:58,060
This one over the sample size minus one is the most common constants used to calculate the population balance and.

436
01:14:05,530 --> 01:14:08,770
So when the sample size and goes to infinity.

437
01:14:09,840 --> 01:14:17,280
You can say that the difference between this to ask the meters why use one over and one you as a one over and minus one will vanish.

438
01:14:18,210 --> 01:14:30,420
So that is that is to say, if you use one over n asymptotically one angle to infinity, that's asymptotically unbiased, but a finite sample is biased.

439
01:14:31,960 --> 01:14:38,280
And another remark is that of a third property, the expectation of the simple bearers.

440
01:14:41,120 --> 01:14:46,490
As and goes to infinity. It does not affect the mean stamp of arms.

441
01:14:47,390 --> 01:14:50,780
The stamp almost always have that means equal to the population.

442
01:14:52,610 --> 01:15:00,800
But as you can imagine, what does affect is the balance of this type of almonds, which we do not calculate here.

443
01:15:01,610 --> 01:15:09,200
But you can, if you want to, you can evaluate the balance of this sample balance.

444
01:15:09,770 --> 01:15:15,320
As you can imagine, that quantity should also have to be changed and in the denominator.

445
01:15:16,340 --> 01:15:17,570
So as an entity,

446
01:15:17,580 --> 01:15:26,710
the gross rights of that estimate are for the samples of the population average is also going to shrink to the true population balance.

447
01:15:32,630 --> 01:15:43,760
All right. To summarize, what do we have just in case you have a random sample size and you can construct this sample mean

448
01:15:43,760 --> 01:15:49,640
sample variance and use the sum of medium to serve as the unbiased estimate for the population.

449
01:15:49,650 --> 01:15:58,880
Mean you any of the sample parents to serve as an unbiased estimate of the population variance Sigma Square and

450
01:15:59,150 --> 01:16:07,160
in particular would need this constant one over and minus one instead of one over here for it to be unbiased.

451
01:16:08,750 --> 01:16:23,270
And in fact not minus one comes from the fact that we lost one degree of freedom in estimating the mean in this sample balance formula.

452
01:16:24,740 --> 01:16:30,440
If you do know the actual population mean, then you do not need this one over and minus one.

453
01:16:30,830 --> 01:16:36,510
You can replace the sample mean by the population mean and replace a minus one by a.

454
01:16:36,800 --> 01:16:42,580
You can prove that that estimate is also an unbiased estimate of the population.

455
01:16:42,590 --> 01:16:50,959
Max, since we do not typically we do not know the population of mean, so we have to replace the population mean by the sample.

456
01:16:50,960 --> 01:17:01,530
Q When calculating this balance that calls, that's one degree of freedom and that's why you need one over and minus one instead of one over.

457
01:17:01,610 --> 01:17:12,230
In other words, the effective number of samples for estimating the variance, it's just a minus one, not because you lost the one sample.

458
01:17:12,580 --> 01:17:25,129
You should calculate the population. So that is a deeper reason why we why would have this constant is that you are

459
01:17:25,130 --> 01:17:30,120
definitely learn more about this in 602 and you will learn more about that.

460
01:17:30,440 --> 01:17:39,470
The unbiased is the asymptotic number and is unbiased this deficiency and so on and so forth in six one, two,

461
01:17:40,220 --> 01:17:50,900
six and another remark is that the population me and actually minimize the quantity minimize

462
01:17:50,900 --> 01:17:59,059
this quantity the summation of assigned minus eight squared for a given random sample.

463
01:17:59,060 --> 01:18:09,950
I want to that that is to say if you are free to choose any value then setting a to be equal to x bar actually minimize this quantity.

464
01:18:12,080 --> 01:18:15,170
And we have proved this in the previous lectures.

465
01:18:15,350 --> 01:18:20,570
All right. So this X bar is the minimize error of this last function.

466
01:18:22,610 --> 01:18:32,510
Lastly, if you do some calculation, you will find that a minus one times this sample virus is equal to this quantity.

467
01:18:33,090 --> 01:18:37,850
If you try to bring it down and it can be written as the difference of this two terms.

468
01:18:38,210 --> 01:18:47,240
The sum of the sum of the sum of squares of the individual random samples minus end times x r squared.

469
01:18:47,360 --> 01:18:55,040
Sometimes these derivations, these that equivalent expression can be useful in some other derivations.

470
01:18:55,520 --> 01:19:01,280
So it's good to keep in mind that you have different ways of representing the same quantity.

471
01:19:07,580 --> 01:19:19,670
Any questions? So this resolves not only just talk about all the random samples,

472
01:19:19,680 --> 01:19:27,330
these are very generic as as you can say from this theorem, we do not require any particular distribution.

473
01:19:27,360 --> 01:19:35,280
All we require is that x one to access is a random sample as long as they are I.D. with a meme U at Sigma Square.

474
01:19:35,610 --> 01:19:41,420
This result always helps. So this is a very generic result.

475
01:19:42,180 --> 01:19:50,390
Now, what are we going to do? Is we going to focus on a very specific distribution that is normal distribution of this random samples.

476
01:19:50,870 --> 01:19:57,620
And the reason why we focus on these are normal distributions, again, as I said, a several reasons.

477
01:19:57,860 --> 01:20:01,910
One is that normal is one of the most widely used models.

478
01:20:03,050 --> 01:20:06,290
Second, normal distribution has many nice properties.

479
01:20:06,560 --> 01:20:16,670
And the third. Later on, some colleagues will see that normal distribution is actually the same chaotic distribution under this central limit theorem.

480
01:20:17,690 --> 01:20:25,270
So out of this considerations, we do focus on the normal distributions from now on.

481
01:20:26,210 --> 01:20:33,560
And you will say that there are actually many nice properties that I can derive from the normal distribution.

482
01:20:34,340 --> 01:20:44,549
What is the random samples? In particular, under this novel assumption, we can derive the full distribution for the sample.

483
01:20:44,550 --> 01:20:50,430
Be some of ours, not just the mean, and the barest of the sample means stuff about us.

484
01:20:51,120 --> 01:20:53,970
We can in fact derive that for distribution.

485
01:21:01,310 --> 01:21:11,570
So first let me introduce some nice properties over the normal distribution and how it's connected to some other distributions that we have learned,

486
01:21:11,720 --> 01:21:14,060
in particular Chi Square distribution,

487
01:21:14,510 --> 01:21:26,300
key distribution and app distribution and all these results, you can actually prove them now using what we learned, mostly just the transformation.

488
01:21:27,950 --> 01:21:33,080
All right. So first result is, if one random variable is normal,

489
01:21:33,890 --> 01:21:39,860
then the square of that random variable is a chi square distribution with the growth rate of one.

490
01:21:45,250 --> 01:21:51,760
If they is a novel with me, I'm zero. The square is a chi square.

491
01:21:51,970 --> 01:21:56,080
It's to grow up afraid of one. So how do you prove it?

492
01:22:06,070 --> 01:22:12,510
If we want to prove this result, how do you how would you start how would you proceed with the proof?

493
01:22:16,030 --> 01:22:22,960
And yes, I would do a variable transformation assignment here.

494
01:22:23,500 --> 01:22:27,100
Very good. Because in know the preamp or the stand up.

495
01:22:27,400 --> 01:22:30,460
Right. We also gave the pdf for the chi square.

496
01:22:31,030 --> 01:22:36,850
And what's that. What the gap is from z to z square.

497
01:22:37,390 --> 01:22:41,590
And that's a univariate transformation you can use.

498
01:22:41,590 --> 01:22:50,620
What do we learned from this univariate transformation to show that Z Square actually has that PDA or a Chi square

499
01:22:50,620 --> 01:22:58,630
with the graph that everyone was just directly use that univariate transformation to prove the first result.

500
01:23:00,520 --> 01:23:06,400
And secondly, if y12 while they are independent, each has a chi square distribution,

501
01:23:06,700 --> 01:23:15,340
then the summation as also has a Chi Square distribution with the growth rate on being the summation of individual degrees of freedom.

502
01:23:16,150 --> 01:23:23,800
How to improve that. We just learned we can use a combination.

503
01:23:24,610 --> 01:23:31,750
You can do it for each pair. And then once you have the parent show that it's Chi Square, you can add it at at more.

504
01:23:34,810 --> 01:23:40,030
Alternatively, we actually have already proved that for karma distribution.

505
01:23:40,690 --> 01:23:45,460
If the second and second parameter is the same, then the summation is also karma.

506
01:23:46,660 --> 01:23:55,390
So Chi Square is a special karma distribution, so you can directly use our results to show that the summation of Chi Square is also Chi Square.

507
01:23:57,280 --> 01:24:05,950
All right. So back to the first property.

508
01:24:07,260 --> 01:24:13,350
What is the mean for this kind of art distribution was to operate in one.

509
01:24:17,070 --> 01:24:23,650
That's right. They tell what the mean is this chi square with the growth rate of one.

510
01:24:25,280 --> 01:24:39,560
That's one, right, because this patient of this square is equal to the variance of the Z plus and not Z squared.

511
01:24:41,400 --> 01:24:45,900
And since Z is novel, the Baroness is one me zero.

512
01:24:47,250 --> 01:24:53,820
So if I give you one truth, that's true for any kind of art distribution.

513
01:24:54,420 --> 01:25:00,510
The mean of a chi square she is.

514
01:25:02,350 --> 01:25:08,370
Just this degrees of freedom. Okay. So y y y follows a chi square.

515
01:25:08,380 --> 01:25:19,600
Pi makes occasional eyes. So, you know, the expectation of this summation of the chi square is equal to the p one plus p two.

516
01:25:19,600 --> 01:25:29,310
All the way to put a square, as I said, is a special case of column parameters, p over two and a one over.

517
01:25:29,350 --> 01:25:35,230
You think about that and next T distribution.

518
01:25:38,330 --> 01:25:45,440
The tea distribution is constructed this way. Assume that we have two independent rent available z and A v.

519
01:25:45,860 --> 01:25:54,110
Z is a normal standard. Normal amount of arable B is a chi square with the growth rate of P and they are independent.

520
01:25:54,650 --> 01:26:05,600
Then the ratio between Z square root of V over p, over the degree of freedom and to follow a T distribution with the growth rate of P.

521
01:26:13,220 --> 01:26:16,880
So if I ask you to probe this, how you approach it.

522
01:26:27,710 --> 01:26:36,260
How to show that this tea is constructed as a ratio of the square root of V over P is a T distribution.

523
01:26:37,760 --> 01:26:43,780
Same idea you can use transformation a now instead of a univariate transformation,

524
01:26:43,790 --> 01:26:51,950
you need to refer to the bivariate transformations and the authority of the bivariate transformation that we learn about.

525
01:26:52,550 --> 01:26:58,700
We need to have a second round of variable, right? You cannot just do a R2 or two hour one.

526
01:26:59,180 --> 01:27:05,090
You have to do R2 two hour two and making sure that it's a 1 to 1 transformation.

527
01:27:07,040 --> 01:27:11,900
So one way to do it is you can transform z v.

528
01:27:12,350 --> 01:27:16,670
To t v. R t z.

529
01:27:19,450 --> 01:27:23,860
In a way, you have a are two, two and two, 1 to 1.

530
01:27:24,730 --> 01:27:33,730
All right. And once you have those transformation and you have that transformation, you can kind of join distribution opportunity and marginalize it.

531
01:27:34,000 --> 01:27:44,290
We got a marginal distribution party and show that that is review is actually follows at T distribution wants to grow up and that complete the proof.

532
01:27:46,840 --> 01:27:56,580
So that's just the high level idea. So you can try it out after class as an exercise to show that it actually is a T distribution

533
01:27:56,590 --> 01:28:02,380
and stick to anything refer to the previous likes knows to save actual PDA or TV.

534
01:28:03,100 --> 01:28:10,660
It's pretty tedious, but you got an idea and the idea is relatively straightforward.

535
01:28:10,690 --> 01:28:14,110
It's just that using this binary transformation, the grouping.

536
01:28:17,660 --> 01:28:21,360
Right now, I don't see how t distribution can be constructed.

537
01:28:21,600 --> 01:28:28,770
It's basically a novel in the numerator and a chi square in the denominator divided by the degree of freedom.

538
01:28:29,670 --> 01:28:37,650
In particular, if you have a chi square one it directly take the square root and use it as the denominator.

539
01:28:37,920 --> 01:28:46,980
Now he was t one and he was essentially just in a culture distribution of chi square to be divided by two.

540
01:28:47,070 --> 01:28:50,420
Take the square root that gave you at2 and so on, so forth.

541
01:28:51,240 --> 01:29:01,050
If you have Chi square with a very large degree of freedom, then that T distribution can also have a very large degree of freedom.

542
01:29:01,890 --> 01:29:07,020
And a large degree of freedom party is almost the same as a normal distribution.

543
01:29:09,040 --> 01:29:16,239
Okay. Okay.

544
01:29:16,240 --> 01:29:20,890
So that's that. And moving on the next one.

545
01:29:21,190 --> 01:29:29,140
If you have two chi square distributions. Both are independent and the numerator is chi square p.

546
01:29:29,480 --> 01:29:38,320
Nominate our chi square cube then the ratio of u over p v over q is called r

547
01:29:38,340 --> 01:29:46,059
distribution similar to the constructed r two to our to a transformation marginalize.

548
01:29:46,060 --> 01:29:51,550
It got this pdf at and of distribution.

549
01:29:51,730 --> 01:29:59,710
It has two degrees of freedom. One is P, one is Q, one is corresponding to the numerator, one corresponding to the denominator.

550
01:30:00,580 --> 01:30:13,450
And the reason why we need this distribution, this t this distribution later on you will see that we actually needed because you are somehow Barron's

551
01:30:14,290 --> 01:30:20,200
going to have a Chi square distribution and our sample mean going to have a normal distribution.

552
01:30:20,590 --> 01:30:27,670
If you want to construct a C, a Z-SCORE, then that's going to have this that normal over Chi Square.

553
01:30:28,180 --> 01:30:37,389
So in our form and we do need to know the exact distribution for the z-score to derive bands like confidence intervals,

554
01:30:37,390 --> 01:30:43,030
etc. and this result just tells us what exactly those distributions are.

555
01:30:44,070 --> 01:30:50,920
In particular, if you have a normal over Chi Square and both are dependent, you know that is a T distribution.

556
01:30:51,610 --> 01:31:01,330
So you can explicitly write out what the confidence interval is, what, what the confidence intervals are for that particular statistic.

557
01:31:03,100 --> 01:31:04,990
And so that's why it's useful.

558
01:31:05,950 --> 01:31:18,340
So you you probably also use this a lot in are 650 clause and when you derive this task statistics you do need this this construction of the.

559
01:31:20,570 --> 01:31:33,240
T distribution and distribution. So one direct result and then I can go from how I've run a variable is constructed is not if you take the numbers,

560
01:31:33,900 --> 01:31:39,300
if you take the the reverse of this random variable,

561
01:31:39,600 --> 01:31:50,040
then it's also going to be a random variable of distribution with the two degrees of freedom switched and Europe over V over.

562
01:31:50,040 --> 01:31:58,830
Q is now p q that v over q over you over t is going to be off two key and also these.

563
01:31:58,860 --> 01:32:06,090
If ax is T, the next square is going to be a aft distribution was the one.

564
01:32:07,410 --> 01:32:14,670
And why is that? Why the square bounty distribution is off distribution.

565
01:32:17,880 --> 01:32:21,510
I can refer to how a T distribution can be constructed.

566
01:32:22,210 --> 01:32:22,470
Right.

567
01:32:23,280 --> 01:32:41,220
If you have access to T distribution, you can you can consider that these ads can be written as the ratio of some normal divided by some chi square.

568
01:32:41,820 --> 01:32:44,340
Divided by t are queuing in this case.

569
01:32:47,570 --> 01:33:00,180
There exist random variable z and a random V where these are normal v is that chi square q that acts is equal to this z over square root of V over Q.

570
01:33:01,040 --> 01:33:09,140
So then if you take the square of this random variable, that's just going to be Z square over V over Q.

571
01:33:11,270 --> 01:33:17,430
So for normal square, what is not? Chi Square one.

572
01:33:17,700 --> 01:33:21,570
Right? And this way we know is Chi Square.

573
01:33:21,870 --> 01:33:27,930
Q says the Z and V they're are independent Z Square and V they are also mentioned.

574
01:33:28,900 --> 01:33:35,210
But that just means you have a Chi square one over the graph, right up one over Chi square.

575
01:33:35,220 --> 01:33:40,620
Q Already. Q And that is exactly how our distribution is constructed.

576
01:33:41,640 --> 01:33:47,610
That's why this guide follows IV distribution with Freedom one and.

577
01:33:47,610 --> 01:33:56,610
Q So that's why if you're taking a square on a T, that gives you a special distribution.

578
01:34:01,850 --> 01:34:04,309
Again, all this results, you can prove it.

579
01:34:04,310 --> 01:34:16,850
Using the transformation and the proof could be tedious in the sense the actual PDA 14 are pretty complicated.

580
01:34:17,270 --> 01:34:21,890
But no matter how complicated is it, it has an exquisite form.

581
01:34:22,850 --> 01:34:26,960
As I said, it's quite the form. It's very easy to use in practice.

582
01:34:27,590 --> 01:34:36,990
Okay. Any questions before we move on?

583
01:34:38,170 --> 01:34:44,560
These are all very important distributions that can be constructed from the normal distribution.

584
01:34:46,810 --> 01:34:52,330
Now we can take a look at these very important result from the normal sampling.

585
01:34:52,960 --> 01:35:04,330
Normal run of the sample. Assume x one to access our random sample from a normal distribution with a mean B meal variance being the sigma squared.

586
01:35:04,720 --> 01:35:08,170
And now still consider these two statistics.

587
01:35:08,290 --> 01:35:13,780
What is the sample mean? What is the sample parents? Then we do have the following result.

588
01:35:14,620 --> 01:35:24,190
Previously, for the generic case, we know that the sample mean has me Millburn Sigma Square over and sample Baron's mean sigma squared.

589
01:35:24,490 --> 01:35:34,090
So that's for the generic case. And now we have more conditions and we do have a stronger result, right?

590
01:35:34,450 --> 01:35:39,910
The more conditions we have is that these random sample, we have a particular distribution.

591
01:35:40,300 --> 01:35:47,550
They are from a normal distribution as the only additional condition that we add to this setting.

592
01:35:48,060 --> 01:35:54,010
Okay. But with that single additional condition, we do have much stronger results.

593
01:35:54,850 --> 01:36:03,430
In particular, our first result is that this x squared, this x bar and our square, they're going to be independent.

594
01:36:06,880 --> 01:36:08,290
So this is a very strong result.

595
01:36:08,920 --> 01:36:15,730
Previously we do not have this in abundance, but somehow me and the sum of ours do not necessarily have to be independent,

596
01:36:16,330 --> 01:36:23,770
but for normal sampling they are independent. So this is result number one and result number two.

597
01:36:26,950 --> 01:36:33,700
The sample mean I actually have this particular normal distribution with minimal variance being a Sigma Square overhead.

598
01:36:34,060 --> 01:36:40,360
Previously we just have the mean the barrens. Now we have the entire distribution for the sex part.

599
01:36:41,080 --> 01:36:47,050
All right. So, again, that's my swung stronger result and a result of number three.

600
01:36:47,350 --> 01:36:52,810
This as square also have an explicit distribution that is M minus one times that

601
01:36:52,820 --> 01:36:57,790
square of our Sigma Square follows a chi square distribution with the graph.

602
01:36:57,790 --> 01:37:01,480
Right. A minus one. Right.

603
01:37:02,380 --> 01:37:16,500
And lastly, this. Statistics at spa minus meal divided by as over square root and follows t distribution with to cooperate up and minus one.

604
01:37:18,260 --> 01:37:22,980
So these are four important results. And also we have additional results.

605
01:37:23,070 --> 01:37:32,130
That is if X one, two, x and a random sample from one distribution, one novel y12y an is a random sample from another not normal.

606
01:37:32,640 --> 01:37:41,740
Then we have these results. The sample varies divided by the corresponding population variance for each population.

607
01:37:42,160 --> 01:37:50,290
The ratio follows an apt distribution, so sometimes this could be very helpful in constructing hypothesis testing.

608
01:37:51,340 --> 01:37:55,600
But for now, let's first focus on this poor result for a single population.

609
01:37:58,240 --> 01:38:02,740
And next, we're going to try to prove this result.

610
01:38:03,100 --> 01:38:06,640
Okay. A bit further proof.

611
01:38:07,270 --> 01:38:13,300
Let's take a look at this poll results and see which ones you can actually directly see without proof.

612
01:38:13,900 --> 01:38:19,300
And the first one. Let's consider this result at a higher level.

613
01:38:20,710 --> 01:38:23,710
So the X bar as square. They are independent.

614
01:38:28,150 --> 01:38:34,210
Call us as a square is defined this way and minus one.

615
01:38:34,990 --> 01:38:47,200
Some time you want an x minus x bar squared, right?

616
01:38:48,100 --> 01:38:54,100
And x bar is just the average of this x high.

617
01:38:59,760 --> 01:39:05,190
So first of all, conceptually, let's consider why it is that this could be the case.

618
01:39:06,210 --> 01:39:09,510
Why independence? Why they can be independent?

619
01:39:10,440 --> 01:39:15,990
Well, the reason is really how this square is constructed.

620
01:39:16,560 --> 01:39:27,180
If you consider how a square is simple barriers as constructed, this building block is all this x I am minus x bar.

621
01:39:29,130 --> 01:39:34,770
Right. So the difference between the individual random variable with the population being.

622
01:39:36,390 --> 01:39:45,060
Since all this running battles are normal. One important property over the normal distribution is not the main part and the balance part.

623
01:39:45,300 --> 01:39:48,630
They are totally separate. The means does not affect the balance.

624
01:39:49,440 --> 01:39:55,020
You cannot have the same mean but different amounts. I'll give you a different normal distribution.

625
01:39:55,320 --> 01:39:59,520
Or you can fix the variants, censorship, the me, the media barons.

626
01:39:59,520 --> 01:40:03,360
They are all related. That's not always the case.

627
01:40:03,780 --> 01:40:08,790
Like our opposing distribution, the media is always equal to the parts of a normal.

628
01:40:09,030 --> 01:40:16,500
One nice property is that the media and the barons naturally suffer separate the ship, and the skimming are separable.

629
01:40:17,370 --> 01:40:19,769
All right. And due to that, a property.

630
01:40:19,770 --> 01:40:31,110
If you think about how this small business is constructed, it just matter how far part or of each run of arable to the population.

631
01:40:31,320 --> 01:40:40,170
Two of the sample mean. So you can arbitrarily shift the sample mean not difference at this from the individual random

632
01:40:40,170 --> 01:40:45,600
variable to the sample mean doesn't have to be affected by the shape of the sample mean.

633
01:40:46,830 --> 01:40:49,890
So that's why these two can be independent.

634
01:40:50,670 --> 01:40:59,070
Of course, more rigorously we have to follow the definition to show that the drawn PDF is actually the product of individual PDA.

635
01:40:59,310 --> 01:41:02,370
But conceptually, that's why they can be independent.

636
01:41:03,120 --> 01:41:11,100
The population mean the sample mean can be can vary.

637
01:41:12,090 --> 01:41:19,500
Three of this distance of individual random marbles, a distance between individual on a variable and this sample mean.

638
01:41:21,570 --> 01:41:35,640
So this x bar can be independent of x minus x bar and all these x bar is independent of all of this outside minus x bar.

639
01:41:35,820 --> 01:41:47,400
Now, of course, the square fell by itself from this I am minus x bar and be independent of x bar.

640
01:41:47,760 --> 01:41:54,450
So that's the reason why they can be independent. So later on I'll prove it more rigorously.

641
01:41:54,690 --> 01:41:58,230
Okay. But the high level, that's. That's why that's the case. Okay.

642
01:42:03,550 --> 01:42:17,980
And second result X bar follows a normal distribution with menu variance Sigma Square over and I hope at this point that is you can see that right.

643
01:42:18,040 --> 01:42:26,470
Because as far as a linear combination of this X, Y and Z and we have talk about the linear combination of novel will always be now.

644
01:42:27,010 --> 01:42:30,520
So that tells us it's always going to be a normal distribution.

645
01:42:30,970 --> 01:42:37,450
And also from the previous proof, we know what the mean is what the balance is for this X bar and in fact for

646
01:42:37,450 --> 01:42:41,320
normal distribution as long as you know the mean the variance that's fixed.

647
01:42:42,720 --> 01:42:49,410
So that the result two and four without three and four is less obvious,

648
01:42:50,460 --> 01:43:00,540
and four especially probably a result three that involves some using the induction to show the distribution.

649
01:43:01,530 --> 01:43:09,570
But assuming you've got a result three result four is straightforward from a result of 1 to 3.

650
01:43:10,230 --> 01:43:16,650
If you know the numerator is normal, denominator is chi square and they are independent.

651
01:43:16,950 --> 01:43:22,860
Now of course the ratio is going to be a t, so neither only follows proper result one, two and three.

652
01:43:23,970 --> 01:43:30,930
So all that boils down is we need to prove result one we are independent and from a result of one,

653
01:43:31,950 --> 01:43:39,180
hopefully we can get a marginal distribution points bar and a square for free from the proof of a result one.

654
01:43:40,110 --> 01:43:44,310
Okay. And that will complete the proof of all four results.

655
01:43:45,390 --> 01:43:58,860
So that's how we're going to proceed. So now let's see how to prove result one proof of our independent of our square.

656
01:44:19,680 --> 01:44:28,770
So to show that ISPA is independent of Square, first we need to rewrite as Square in the more friendly form.

657
01:44:54,880 --> 01:45:04,900
I recall that the idea of proving that these two are independent is we want to go to drawing this fusion of the two at the margin of each,

658
01:45:05,110 --> 01:45:12,400
showing that the joint is the product of the margin. That way we can prove that these two are independent.

659
01:45:14,590 --> 01:45:23,350
And in particular, if you consider how our square is constructed, it has these adding component oxide minus X bar, right?

660
01:45:24,430 --> 01:45:33,580
If we can somehow reduce this and components to a minus one component and consider this one additional component X bar,

661
01:45:33,790 --> 01:45:42,010
then we have our end to our end transformation from the original x12x end to this new and components.

662
01:45:42,790 --> 01:45:48,010
And then we can use this joint transformation to, to show what do we want.

663
01:45:48,730 --> 01:45:52,180
So that's the idea of why we want to rewrite this next part.

664
01:45:53,640 --> 01:46:07,360
Trying to express this as I trying to express this as square this simple virus using just a minus one component in particular,

665
01:46:07,390 --> 01:46:15,570
we want to show that a square can be expressed using x two minus X bar at three minus x bar all the way to x and minus x part.

666
01:46:16,560 --> 01:46:26,550
Without a using this x one minus x bar. If we can achieve that, then that is to say we can express as a square user and minus one components.

667
01:46:28,170 --> 01:46:37,520
I got always this x bar we have and components. Then we can refer to this joint transformation from our onto our end to try to prove the dependance.

668
01:46:38,610 --> 01:46:49,620
So that's what are we going to do? So first we tease out this x, y minus x bar part and carry over this I minus x are high from two to it.

669
01:46:50,530 --> 01:46:58,710
Now we can rewrite the first part, trying to express it, using this x two minus as part all the way to x and minus x bar.

670
01:46:59,760 --> 01:47:03,480
And the way to do it is you notice that this is.

671
01:47:18,950 --> 01:47:24,500
That's one minus X bar can be expressed as this quantity.

672
01:47:25,220 --> 01:47:39,470
All right. A summation I from two, two and I minus X bar because x one is just the summation of X to two x and.

673
01:47:53,710 --> 01:48:02,850
And notice that this one can be expressed as end time taxpayer minus a summation though I, I want to do.

674
01:48:02,850 --> 01:48:07,350
And so you plug it in, you will get this result and.

675
01:48:25,580 --> 01:48:30,170
With this result, we notice that this square is essentially a function.

676
01:48:33,620 --> 01:48:40,049
All of this and minus one component that's too many assets are minimized.

677
01:48:40,050 --> 01:48:46,060
Stocks are. And minus spa.

678
01:48:47,150 --> 01:48:51,150
So that square is a function of this and minus one component.

679
01:49:27,100 --> 01:49:31,280
Nice. Let's consider this transformation.

680
01:49:31,820 --> 01:49:37,070
Well, I want my two to win as a transformation of x one to accent.

681
01:49:37,490 --> 01:49:48,300
And so this y to to y I are the end minus one components and we just obtain from this square and y one is just the next part.

682
01:49:49,910 --> 01:49:59,524
So this is a R and so this is an R into our transformation from the x one to x and this random sample.

