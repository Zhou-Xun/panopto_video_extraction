1
00:00:04,770 --> 00:00:08,730
A. Mondul: Okay alright so we've alluded to some of these issues already.

2
00:00:11,700 --> 00:00:12,389
A. Mondul: When we're talking about.

3
00:00:13,950 --> 00:00:20,820
A. Mondul: we're talking about study design we've been alluding to some of these things but we're going to kind of talk about them in a little bit more explicit detail today.

4
00:00:21,780 --> 00:00:31,260
A. Mondul: So in general bias is a barrier to internal validity so remember, we talked about internal validity is being able to get the right answer in your study population.

5
00:00:31,770 --> 00:00:41,970
A. Mondul: So a bias is anything that basically gives you the wrong answer the wrong association between your factor or exposure of interest and your outcome Okay, and so there's kind of a few.

6
00:00:42,900 --> 00:00:53,490
A. Mondul: Basic sources of bias and we're going to go through them so remember that causality is a primary objective of epidemiological studies and we want to know does exposure clause, a health outcome.

7
00:00:54,660 --> 00:01:08,340
A. Mondul: And so, for example, if only she had been had the flu during her pregnancy her child, would not have had autism or woody right, so this is the question we don't know and if only we had a time machine, we could go back and get.

8
00:01:09,540 --> 00:01:11,910
A. Mondul: The true counterfactual right.

9
00:01:12,930 --> 00:01:20,910
A. Mondul: We could go back and redo it so she didn't get the flu and see what happened to that exact person that will be the counterfactual right if we had a time machine and could do this pretend thing.

10
00:01:21,480 --> 00:01:31,050
A. Mondul: But we can obviously do that, and so what we need is a comparison group to act as a proxy of what would have happened counter the fact that we could have gone back and prevented her from getting the flu and see what happened.

11
00:01:33,000 --> 00:01:43,470
A. Mondul: So we aim to emulate that counterfactual we want our exposed and unexposed people in a cohort study to be equally as likely to have the outcome in the absence of exposure.

12
00:01:44,400 --> 00:01:52,410
A. Mondul: Right same we want our cases and controls and a case control study to be equally as likely to have had the exposure or yeah.

13
00:01:53,850 --> 00:01:55,380
A. Mondul: Okay, so.

14
00:01:57,600 --> 00:02:01,950
A. Mondul: Age race weight exercise right if we're interested in diet.

15
00:02:03,210 --> 00:02:10,860
A. Mondul: We want to compare whether these people have diet is associated with our outcome, all of these things are related to diet right.

16
00:02:12,180 --> 00:02:15,840
A. Mondul: We want to make sure that these people are similar in all of these other ways.

17
00:02:17,460 --> 00:02:24,120
A. Mondul: We want controls in a case control study to have the same exposure distribution, as the population that gave rise rise to the cases so.

18
00:02:25,530 --> 00:02:35,040
A. Mondul: Any systematic error in the design conduct or analysis of a study that results in this distorted estimate of the relationship between an exposure and an outcome is.

19
00:02:36,390 --> 00:02:41,610
A. Mondul: A bias right and these observed results will be different than the truth.

20
00:02:43,770 --> 00:02:51,900
A. Mondul: So it can make it seem like there really is an association when they're truly isn't one, so this is called bias away from the knowledge exaggerating and association.

21
00:02:52,830 --> 00:03:03,000
A. Mondul: It can also bias can also mask and association when there really is one so maybe the truly is an association, but it can make it can bias toward the note wash out the association and make it look like nothing's going on.

22
00:03:04,080 --> 00:03:05,520
A. Mondul: So bias can create.

23
00:03:07,470 --> 00:03:11,580
A. Mondul: Incorrect answers in multiple directions from the truth.

24
00:03:12,960 --> 00:03:17,280
A. Mondul: So there's lots of ways to get the wrong answer, unfortunately.

25
00:03:17,880 --> 00:03:27,330
A. Mondul: And we're going to talk about kind of three big categories of ways to get the wrong answer and today we're going to talk about selection and information biases and then next week we're going to talk about confounding.

26
00:03:28,200 --> 00:03:34,500
A. Mondul: So selection bias is when who is selected or retained in a study distorts your estimates of the truth.

27
00:03:35,340 --> 00:03:43,230
A. Mondul: we've talked about this a little bit when we talked about control selection for a case control studies and how, if you kind of get people who aren't really from the source population.

28
00:03:43,650 --> 00:03:56,760
A. Mondul: You can have a bias, and that is a selection bias, the hospital births in the hospital based control selection, for instance by as the example with the McMahon paper and the coffee and the pancreatic cancer, that is a selection bias.

29
00:03:58,560 --> 00:04:05,490
A. Mondul: Information bias, on the other hand, is when the quality of your information, distorts your estimate of the truth and we're going to talk about that in some detail today.

30
00:04:06,840 --> 00:04:12,120
A. Mondul: And, confounding bias is when differences between cases and controls or you're exposed and unexposed.

31
00:04:12,930 --> 00:04:20,790
A. Mondul: distort your estimates of the truth so confounding bias is what we are trying to eliminate when we do randomization in a randomized control trial.

32
00:04:21,180 --> 00:04:29,610
A. Mondul: or when we do matching and a case control study right we're trying to make our groups have similar on everything else, aside from the factor of interest as possible.

33
00:04:30,630 --> 00:04:33,300
A. Mondul: And so we will talk more about this next week.

34
00:04:36,600 --> 00:04:49,560
A. Mondul: On top of bias, you can also just get the wrong answer by chance right the luck, of the draw get to a study sample that's not representative of the larger population, and this is why we repeat studies multiple times in epidemiology.

35
00:04:50,550 --> 00:04:55,350
A. Mondul: Because you can get one weird study that makes it look like there's something going on, when there really isn't.

36
00:04:57,990 --> 00:05:05,610
A. Mondul: Okay, so an important note about internal validity, so we talked about external validity as well generalize ability.

37
00:05:06,900 --> 00:05:18,690
A. Mondul: But if you have a study that is not internally valid if you have a bias study it is, by definition, also not externally valid, it is not generalizable generalizable to anyone right.

38
00:05:19,110 --> 00:05:24,210
A. Mondul: If they're not real if your results are not correct, they are not generalizable to anyone right.

39
00:05:24,600 --> 00:05:37,290
A. Mondul: So, if your study is not internally valid, it is, by definition, also not externally valid, you must have internal validity first and then you can start deciding whether you think it's generalizable or externally valid right.

40
00:05:38,730 --> 00:05:39,510
A. Mondul: That makes sense.

41
00:05:42,690 --> 00:05:53,640
A. Mondul: Alright, so that's kind of an overview of bias so let's talk in more detail now about selection bias remember this is when the individuals were selected are retained and your study distort your estimates of the truth.

42
00:05:54,630 --> 00:06:01,890
A. Mondul: So say we have an exposed population and unexposed population and some number of them get the outcome.

43
00:06:03,210 --> 00:06:15,540
A. Mondul: In both the exposed and unexposed Okay, so the green are those without the outcome and the orange or those with the outcome Okay, and there are 36 people who are exposed.

44
00:06:16,530 --> 00:06:31,290
A. Mondul: And there are 36 people who are unexposed so six out of the 36 in the exposures get the outcome that's the cumulative incidents and six out of 36 with the unexposed to get the outcome Okay, so the true risk ratio is one.

45
00:06:36,750 --> 00:06:38,670
A. Mondul: So let's say that you do a study.

46
00:06:39,840 --> 00:06:43,980
A. Mondul: You take some sample of the exposed and some sample of the unexposed.

47
00:06:45,000 --> 00:06:51,630
A. Mondul: We know that this is the truth and are observed associations are very similar to the truth now right we've got three.

48
00:06:51,870 --> 00:07:05,760
A. Mondul: With the outcome among our 18 that we sampled in the exposed have three with the outcome, among the 18 that we sampled in the unexposed so we get the correct observed relative risk right we have sampled correctly in our expose in her unexposed but now.

49
00:07:07,290 --> 00:07:17,190
A. Mondul: let's say, for some reason we got all of the people with the outcome in our unexposed population among our 18, for whatever reason, we happen to get.

50
00:07:18,090 --> 00:07:35,040
A. Mondul: All of because we did it incorrectly or for whatever reason, we ended up getting six cases among our 18 suddenly it looks like our observed risk ratio is point five right that the exposed population is about half as likely to get the outcome as the unexposed.

51
00:07:38,700 --> 00:07:55,830
A. Mondul: Or you can have the other way where you're much less likely to get outcomes in your unexposed population suddenly it looks like our observe ratio is three right that people in the exposed population are three times as likely to get the outcome as those in the unexposed population.

52
00:07:57,240 --> 00:08:00,120
A. Mondul: And it's all about who were sampling and who we're seeing.

53
00:08:01,650 --> 00:08:03,360
A. Mondul: In our in our study population.

54
00:08:04,560 --> 00:08:05,040
A. Mondul: Okay.

55
00:08:06,180 --> 00:08:16,290
A. Mondul: Now, in a real study, I want to point this out we're going to be talking about the truth versus what we observe a lot in this lecture and in this class.

56
00:08:18,360 --> 00:08:28,350
A. Mondul: The sun is that grippy and it's in this little holster and it doesn't want to come out okay so we're going to be talking about the truth, compared to the observed a lot.

57
00:08:30,330 --> 00:08:38,970
A. Mondul: When you do a study which pieces of this information, do you have do you have the truth, do you have the observed, what do you have when you're doing your study.

58
00:08:40,620 --> 00:08:43,950
A. Mondul: You only have the observed let's see what they said in chat.

59
00:08:45,120 --> 00:08:46,110
A. Mondul: Chelsea said that right.

60
00:08:47,280 --> 00:08:58,200
A. Mondul: that's exactly correct Okay, so you only know this piece, we are creating situations in which we have created.

61
00:08:58,530 --> 00:09:11,130
A. Mondul: A source population, where we are creating the truth and then showing you different scenarios, where we sample from that truth and how you can get the correct or incorrect answer Okay, so this truth.

62
00:09:11,640 --> 00:09:23,370
A. Mondul: You will not in a real situation, know that we're showing you this as a means for understanding these biases we are setting up underlying populations, where we know the truth from which we are.

63
00:09:24,420 --> 00:09:31,500
A. Mondul: Drawing observed population study populations in order to get an observed to compare to the truth to show you how bias happens.

64
00:09:32,040 --> 00:09:41,190
A. Mondul: But in real in the real world, all you have is the observed, so you cannot compare it to the truth you're assuming ideally you're finding out the truth, based on your study.

65
00:09:42,420 --> 00:09:47,970
A. Mondul: But you might be finding the wrong answer if you do the study incorrectly is kind of what we're showing you here does that make sense to everybody.

66
00:09:48,780 --> 00:10:03,840
A. Mondul: So this truth is hypothetical it's not it's what you're trying to learn about based on your observed data but you're not going to get a truth, if you did if you did the study around this basically the the take home point here okay.

67
00:10:05,550 --> 00:10:19,470
A. Mondul: All right, you can do this in case control study suit right, so you have your cases in your controls and some of them are exposed or unexposed right, so in this case you'd be sampling people with the disease and the blue would be the people who are exposed right.

68
00:10:20,760 --> 00:10:21,420
A. Mondul: same idea.

69
00:10:23,040 --> 00:10:34,650
A. Mondul: Okay, so let's give you an example of selection bias in a case control study, I will say that selection bias is generally a much bigger problem in a case control study than it is in a cohort study.

70
00:10:36,090 --> 00:10:41,280
A. Mondul: You can get selection bias in a cohort study, if you are losing people.

71
00:10:42,510 --> 00:10:50,340
A. Mondul: Generally, you will get selection bias, if you are losing people in your helpers day if you've got if you have a lot of loss to follow up.

72
00:10:51,360 --> 00:11:02,220
A. Mondul: It is more difficult to get selection bias at the beginning of a cohort study, particularly if you are doing the kind where you're just getting a sample of the population and you're not basing it on exposure.

73
00:11:03,630 --> 00:11:11,790
A. Mondul: If you're choosing exposed and unexposed to follow for your cohort study you can get selection bias kind of in the same way that we're going to talk about here with the case control.

74
00:11:12,810 --> 00:11:22,650
A. Mondul: But selection bias is much more probable comes up a lot more in case control studies if you have a cohort study and you have adequate follow up you have less of a chance of getting selection bias.

75
00:11:23,940 --> 00:11:24,720
A. Mondul: Does that make sense.

76
00:11:25,950 --> 00:11:30,270
A. Mondul: Alright, so let's talk about this case control example so say you're interested.

77
00:11:31,500 --> 00:11:33,540
A. Mondul: In alcohol as an exposure.

78
00:11:34,890 --> 00:11:37,500
A. Mondul: As a risk factor for diabetes okay.

79
00:11:39,270 --> 00:11:48,540
A. Mondul: So you have diabetics who drink one glass per day and the general population who drink one glass per day, so if you were to compare your cases to a sample of controls.

80
00:11:50,310 --> 00:11:53,850
A. Mondul: From the general population, if you sample a correctly, what should the relative risk it.

81
00:11:56,010 --> 00:11:58,530
A. Mondul: Are the odds ratio, I guess, since this is a case control study.

82
00:12:01,620 --> 00:12:02,910
A. Mondul: will be would the truth be.

83
00:12:03,000 --> 00:12:03,330
Nolaundron Harris: On.

84
00:12:03,990 --> 00:12:17,400
A. Mondul: It would be one right because diabetics your your cases have the same alcohol exposure as the general population but let's say that our selection of controls does not match the base population, so now we've got.

85
00:12:18,870 --> 00:12:29,010
A. Mondul: Members of the mormon church members of the Church of latter day saints, as our control so we've got our diabetics coming from you know just the general population to drink one glass per day.

86
00:12:30,480 --> 00:12:31,230
A. Mondul: and

87
00:12:32,670 --> 00:12:33,930
A. Mondul: Those of you who know.

88
00:12:35,130 --> 00:12:44,820
A. Mondul: Mormons are according to their religion, not supposed to drink alcohol, so I would imagine that the exposure to alcohol is lower in this population than in the general population agree.

89
00:12:47,280 --> 00:12:50,070
A. Mondul: So I would say somewhere quite a bit less than one glass per day.

90
00:12:51,390 --> 00:12:52,740
A. Mondul: Ideally, none right.

91
00:12:54,450 --> 00:13:04,620
A. Mondul: So if you compare your diabetics to your sample of controls from the mormon church, what is your real relative is going to be greater than one one or less than one.

92
00:13:05,400 --> 00:13:06,210
Someone.

93
00:13:07,950 --> 00:13:17,910
A. Mondul: Greater than one right because you're going to take the higher exposure in your cases you're going to have a higher odds and exposure in your cases and in your control so it's going to look like alcohol.

94
00:13:19,050 --> 00:13:22,500
A. Mondul: If you were not smart about it, you might say, it looks like alcohol is causing diabetes.

95
00:13:24,030 --> 00:13:24,450
A. Mondul: Okay.

96
00:13:29,370 --> 00:13:33,120
A. Mondul: Now let's do this say we have our.

97
00:13:35,310 --> 00:13:45,180
A. Mondul: cases have one glass per day, our source population has one glass per day we're going to for some weird reason we're choosing to pull our controls from a population of car crash victims.

98
00:13:46,500 --> 00:13:51,930
A. Mondul: What kind of exposure distribution, do you suppose there is among people who have been in a car crash with respect to alcohol.

99
00:13:52,350 --> 00:13:53,880
Nolaundron Harris: More than one glass per day.

100
00:13:54,420 --> 00:13:58,500
A. Mondul: Potentially more right because there's some correlation between.

101
00:14:00,150 --> 00:14:12,030
A. Mondul: Motor vehicle accidents and drinking alcohol right, and so in this case you're going to have a bias, where it looks like your relative risk is less than one because your distribution of exposure is fire in your controls and in your faces.

102
00:14:13,830 --> 00:14:19,440
A. Mondul: Okay, so I mean I think these are extreme examples I don't think most people are going to choose their controls from.

103
00:14:20,370 --> 00:14:29,190
A. Mondul: The mormon church when they're comparing the general population or per car crash victims when they're comparing to dive out to the general population, but there are sneakier ways that you can make this mistake.

104
00:14:30,390 --> 00:14:40,800
A. Mondul: Right, this is an extreme example to show you how this would happen, but there are you know sneakier ways to do this here's an example of selection bias in a cohort study.

105
00:14:41,670 --> 00:14:53,850
A. Mondul: This is generally when you were looking at like an occupational exposure you're choosing based on exposure and so you're going to look at occupational expose people compared to unexposed people in the general population.

106
00:14:54,480 --> 00:15:08,190
A. Mondul: Workers it's called the healthy worker effect so people who are working, and I think this came up in our Snr example in our age adjustment example, people who are working tend to just be healthier than the general population.

107
00:15:09,450 --> 00:15:11,520
A. Mondul: Because they are healthy enough to go do a job.

108
00:15:12,540 --> 00:15:18,000
A. Mondul: Frequently in occupational studies, we are looking at people who are working more visible types of jobs factory jobs where they might be.

109
00:15:18,570 --> 00:15:24,630
A. Mondul: exposed to chemicals or noise or something like that right so often and occupational studies, we are looking at people who are performing.

110
00:15:25,110 --> 00:15:36,300
A. Mondul: More physically demanding jobs even and so these people tend to be healthier than the general population, just because of the fact that they can get up and go to work and do that job right they're not disabled and unable to work, for example.

111
00:15:37,260 --> 00:15:52,470
A. Mondul: So this is a type of selection bias, that you can have in a cohort study when you are choosing based on exposure or you're choosing people it's not working status or you wouldn't want to compare workers exposed to people who are supposed to are also going to work every day right.

112
00:15:54,330 --> 00:15:58,620
A. Mondul: Because your your source population is people who are working.

113
00:16:00,600 --> 00:16:06,750
A. Mondul: That makes sense it's not the general population it's actually people who are working, a full time job, for example.

114
00:16:09,810 --> 00:16:10,230
A. Mondul: Okay.

115
00:16:13,110 --> 00:16:27,600
A. Mondul: here's an example of selection bias in a Cobra study different retention in the study, so that you're interested in smoking and dementia or alzheimer's disease right So if you have who do you suppose.

116
00:16:28,860 --> 00:16:30,660
A. Mondul: is more likely to.

117
00:16:32,610 --> 00:16:36,630
A. Mondul: drop out of your studies someone who gets all timers disease or someone who doesn't.

118
00:16:40,530 --> 00:16:55,410
A. Mondul: Former yeah people who are getting alzheimer's disease are more likely to be lost right in a first and smokers are also more likely to die right and so you're probably likely to this is also.

119
00:16:57,300 --> 00:17:09,120
A. Mondul: You can lose people just because they're not responding to your questionnaire anymore, and you may not find out if they have alzheimer's because they just kind of fall off the grid for you, the real problem here is also, this is a type of bias called.

120
00:17:10,500 --> 00:17:13,290
A. Mondul: Competing risks, so you have smokers.

121
00:17:15,030 --> 00:17:16,290
A. Mondul: And non smokers.

122
00:17:18,150 --> 00:17:20,250
A. Mondul: Which group is more likely to die first.

123
00:17:22,200 --> 00:17:36,630
A. Mondul: yeah so these guys die of something else, before you can find out that they had alzheimer's disease and these guys go on, so it may maybe it looks like all timers disease is higher in your non smoking group because they survive long enough to get it.

124
00:17:38,970 --> 00:17:44,010
A. Mondul: Right, so this is the selection bias problem that is known as competing risks.

125
00:17:45,150 --> 00:17:45,900
A. Mondul: That make sense.

126
00:17:52,080 --> 00:17:56,490
A. Mondul: Alright, so those are some examples of how selection bias can occur.

127
00:17:57,390 --> 00:18:06,210
A. Mondul: This is a fundamental The fundamental issue is the problems arise when you're exposed to not expose unexposed groups are differently likely to develop these for a reason other than exposure.

128
00:18:06,870 --> 00:18:12,210
A. Mondul: or when your cases and controls are differentially likely to have the exposure for a reason other than their outcome.

129
00:18:14,400 --> 00:18:19,830
A. Mondul: In other words, participation exclusion or retention cannot be associated with both your exposure and your outcome.

130
00:18:22,350 --> 00:18:24,510
A. Mondul: Okay, when I told you here.

131
00:18:25,560 --> 00:18:40,830
A. Mondul: The people who are developing alzheimer's disease might be more likely to drop out that's associated only with your outcome right so that would not cause a selection bias if you're smokers and non smokers who developed all timers disease were equally likely to drop out.

132
00:18:42,150 --> 00:18:51,240
A. Mondul: it's this problem where you're less likely to see all of these things are smokers because they're dying prematurely if something else is different in your smokers and your non smokers.

133
00:18:54,060 --> 00:18:58,860
A. Mondul: So it has to be associated with both the exposure and the outcome.

134
00:19:00,300 --> 00:19:01,260
A. Mondul: To be a bias.

135
00:19:02,820 --> 00:19:03,240
A. Mondul: yeah.

136
00:19:10,080 --> 00:19:15,540
A. Mondul: All right, this is not an issue of generalize ability, it is generalize ability, perhaps.

137
00:19:17,550 --> 00:19:27,720
A. Mondul: If it is associated with only one of those things like if you have a highly exposed population that you're looking at or next population that has a lot of your cases.

138
00:19:28,770 --> 00:19:39,870
A. Mondul: It might not be a generalizable population but it's not a bias unless its associated with both let's give you an example, I want to talk to you about the health professionals follow up study hdfs Has anybody heard of hdfs.

139
00:19:41,310 --> 00:19:47,850
A. Mondul: This is a prospective cohort study run out of Harvard where they recruited 51,000 ish men.

140
00:19:49,230 --> 00:19:51,720
A. Mondul: And they were all graduate level.

141
00:19:53,490 --> 00:20:01,080
A. Mondul: Health professionals so they're like osteopaths and things like that right not MDS but other health professionals with a graduate degree.

142
00:20:02,310 --> 00:20:07,590
A. Mondul: So they're all men they're all highly educated and I will tell you that there are about 96% white.

143
00:20:13,200 --> 00:20:15,750
A. Mondul: So let's think of an exposure.

144
00:20:20,820 --> 00:20:23,250
A. Mondul: We could look at potentially.

145
00:20:25,290 --> 00:20:27,240
A. Mondul: race and an outcome.

146
00:20:31,890 --> 00:20:33,390
A. Mondul: You could look at.

147
00:20:36,270 --> 00:20:45,540
A. Mondul: smoking and an outcome, do you think smoking levels are going to be higher or lower than the general population in this group lower yeah.

148
00:20:47,400 --> 00:20:49,800
Joshua Tucker: i'm not like crazy significantly right.

149
00:20:51,240 --> 00:20:51,780
A. Mondul: um.

150
00:20:52,860 --> 00:20:58,470
A. Mondul: This is an example let's imagine that it is, I mean smoking is strongly associated with.

151
00:21:00,600 --> 00:21:06,810
A. Mondul: You know, in this age group at time, maybe not but like now, smoking is strongly associate with education level and with race.

152
00:21:08,100 --> 00:21:20,910
A. Mondul: So let's pretend that we have lower smoking than the general population, so you have smoking, yes, no, you have same heart disease, yes, no right so you're going to have a higher number here than you should.

153
00:21:22,050 --> 00:21:24,270
A. Mondul: But it's not going to be different.

154
00:21:25,800 --> 00:21:36,450
A. Mondul: By heart disease, it is the the marginal that is higher than it should be, this is potentially a generalize ability problem, but you are going to get the correct answer.

155
00:21:38,340 --> 00:21:45,630
A. Mondul: For your study, because they have very high retention they don't have a lot of selection bias, they don't have a lot of the other kinds of bias that we're going to talk about.

156
00:21:45,870 --> 00:22:00,030
A. Mondul: So you are going to have an internally valid study for highly educated white Dudes looking at smoking and heart disease now is that generalizable to the general population that includes women and non white people and low fcs people.

157
00:22:01,920 --> 00:22:02,460
A. Mondul: Maybe.

158
00:22:03,510 --> 00:22:08,190
A. Mondul: Maybe not can we think of a good reason why smoking might behave differently in those groups of people.

159
00:22:08,670 --> 00:22:19,410
A. Mondul: that's a question that we're going to think about more and in a lecture to come, but note that just because you have this very select population does not mean you're getting wrong answers for this study population.

160
00:22:21,750 --> 00:22:28,230
A. Mondul: That is generalize ability, but you may very well be getting correct answers we're talking about whether you are getting the correct.

161
00:22:28,800 --> 00:22:45,270
A. Mondul: association between an exposure and an outcome in your study population of interest, this is your study population, we can have another conversation about whether getting whether the answer you get correct or not is generalizable, but you are getting the correct answer.

162
00:22:46,440 --> 00:22:48,960
A. Mondul: Right, these are two separate issues does that make sense.

163
00:22:51,210 --> 00:22:55,740
A. Mondul: I will tell you that this is something that even our PhD students struggle with on their on their COMP exam right.

164
00:22:58,020 --> 00:23:06,330
A. Mondul: Everyone hates selection bias, that the universal truth everyone hates selection bias and even I when I go to like when you're going to design a study also there go.

165
00:23:08,310 --> 00:23:14,010
A. Mondul: It isn't it is associated with the you know so there's a lot of everyone's still struggles it's okay.

166
00:23:14,670 --> 00:23:16,530
Nolaundron Harris: You put my mind at ease.

167
00:23:18,540 --> 00:23:25,770
A. Mondul: Good this it's not it's not an easy concept selection bias in particular is is very nebulous and it's hard to think through.

168
00:23:26,970 --> 00:23:27,330
A. Mondul: All right.

169
00:23:29,130 --> 00:23:35,910
A. Mondul: So, to reduce this kind of bias, you want to ensure proper selection of study subjects, you want to choose groups from the same source population.

170
00:23:36,150 --> 00:23:48,060
A. Mondul: Your source population is often theoretical right, you have to be thoughtful about what you think your source population is and whether you're really getting your cases Nicole controls from that same source population, and it is not easy.

171
00:23:48,510 --> 00:23:58,620
A. Mondul: There are very silly ways to get it very wrong that we've we've shown you in class, but there are subtle ways to get it wrong that are easy to make that mistake right.

172
00:23:59,700 --> 00:24:05,280
A. Mondul: You want to try listen people that are more inclusive, you want to result use methods that result in high recruitment rates right.

173
00:24:05,610 --> 00:24:15,000
A. Mondul: If you're getting very low recruitment rates if you're if you're getting like 10% of the people you're approaching, you should suspect that there's something special about those people, compared to the ones who were saying no right.

174
00:24:15,840 --> 00:24:24,990
A. Mondul: So high recruitment rates using lists of people that are more inclusive to try to get your controls or your seven subjects will help produce this bias.

175
00:24:25,860 --> 00:24:35,250
A. Mondul: want to minimize left follow up keep participants happy and in touch with the study team, and you want to review your non respondents to understand the differences between the people who are continuing to.

176
00:24:35,910 --> 00:24:41,100
A. Mondul: participate and who are choosing up for space in your study this will help you understand if there's some kind of bias going on.

177
00:24:42,570 --> 00:24:42,990
A. Mondul: Okay.

178
00:24:46,470 --> 00:24:48,840
A. Mondul: That is selection bias in a nutshell.

179
00:24:51,150 --> 00:24:54,060
A. Mondul: Any questions about that before we move on to information bias.

180
00:24:56,700 --> 00:25:03,030
Nolaundron Harris: Is there a cheat sheet for like a really good cheat sheet that has simpler language and what's in the book.

181
00:25:04,260 --> 00:25:07,050
A. Mondul: No, not really unfortunately um.

182
00:25:09,090 --> 00:25:13,380
A. Mondul: You know, you can you can sort of create one if it's about how you select or lose.

183
00:25:13,380 --> 00:25:13,920
Nolaundron Harris: Your study.

184
00:25:14,190 --> 00:25:15,900
A. Mondul: Events in a selection bias.

185
00:25:16,140 --> 00:25:19,710
A. Mondul: If it's about how you measure and categorize its information bias.

186
00:25:19,800 --> 00:25:22,710
A. Mondul: Okay, but you know, there are.

187
00:25:27,060 --> 00:25:36,210
A. Mondul: i'm presenting this to you in an overview and an a simplified way right i'm telling you there's these three types of bias selection information and compounding.

188
00:25:36,690 --> 00:25:48,120
A. Mondul: But there are a gazillion subset of those where people will argue about whether something is a select type of selection bias, or whether it's an information bias, or you know as you get deeper into EPI methods.

189
00:25:48,960 --> 00:25:58,230
A. Mondul: You know there's all kinds of biases that you can think oh that's actually a type of this bias and they can all sort of broadly be categorized into these three groups.

190
00:25:58,710 --> 00:26:09,300
A. Mondul: But it's actually more complicated than this, if that makes sense okay if it's about how you are recruiting retaining choosing your participants.

191
00:26:10,530 --> 00:26:12,000
A. Mondul: That is a selection bias.

192
00:26:15,000 --> 00:26:18,360
A. Mondul: And now, if it is about the quality of your data.

193
00:26:20,040 --> 00:26:22,530
A. Mondul: And particularly your outcome or exposure information.

194
00:26:23,640 --> 00:26:30,810
A. Mondul: And if the quality or lack thereof of your information is distorting your estimate of a true association that is information wise and this is a little less.

195
00:26:31,710 --> 00:26:39,960
A. Mondul: nebulous and esoteric we're going to actually do some math here to show you this one so maybe that's good or bad, depending upon where your brains out today.

196
00:26:41,370 --> 00:26:51,480
A. Mondul: So there's lots of sources of this kind of air it's also called measurement error so measurement error misclassification information by us Those are all the same thing okay.

197
00:26:52,650 --> 00:27:01,050
A. Mondul: You can have just normal variability or in precision and measure or there can be error due to subconscious or conscious decisions by the participant or investigator okay.

198
00:27:04,200 --> 00:27:14,100
A. Mondul: The impacts really depend on the differences between the group and we touched on this, I think, last time, but if the rate of misclassification does not differ between study groups.

199
00:27:14,490 --> 00:27:28,440
A. Mondul: Cases or controls in a case control study or expose not exposed typically but not always, it makes it more challenging to detect an association so generally business called non differential misclassification and it will bias toward the know.

200
00:27:31,440 --> 00:27:40,050
A. Mondul: The rate if the random best classification differs between study groups, it can go in either direction right and we can't necessarily predict which direction.

201
00:27:42,660 --> 00:27:44,160
A. Mondul: Alright, so let's do an example.

202
00:27:46,320 --> 00:27:53,400
A. Mondul: we've got these are the blood pressure, guidelines right you've got systolic and diastolic blood pressure, these may be old at this point the.

203
00:27:54,030 --> 00:28:09,720
A. Mondul: physician still get mad at me if these aren't quite right anymore, but you know, this is just to show you you've got a continuous measure and milk millimeters per millimeters mercury and then you are categorizing people have hypertension, based on those okay.

204
00:28:11,790 --> 00:28:24,990
A. Mondul: So here is our example of non differential this classification of hypertension, so our outcome in this case is hypertension, so in this case we are, this is an example where we're talking about misclassification of the outcome.

205
00:28:26,880 --> 00:28:34,080
A. Mondul: And you've got our exposure is either exposed or not exposed to noise Okay, so this is our true association.

206
00:28:35,670 --> 00:28:48,510
A. Mondul: Right, we know this, because this is an example that we made up and we said, this is the true association in our example that we made up in the real world, you would only know about your study observation right but we're comparing our observation to the truth.

207
00:28:49,410 --> 00:29:01,230
A. Mondul: So if you are assuming that among the exposed in unexposed there is 20% misclassification of hypertension Okay, so that means that this is the truth.

208
00:29:03,810 --> 00:29:17,670
A. Mondul: That 600 were exposed to noise and 200 of our of our 850 people with hypertension we're not exposed to noise but there's 20% disqualification so what that means is that if you take 600.

209
00:29:21,720 --> 00:29:22,350
let's see.

210
00:29:24,390 --> 00:29:26,340
A. Mondul: If you take those 600 times.

211
00:29:27,600 --> 00:29:36,690
A. Mondul: Point two you get 120 right so that means that there's 120 people who are moving from there to here, you see that.

212
00:29:37,890 --> 00:29:42,210
A. Mondul: And so you actually have 480 that you are calling exposed to noise.

213
00:29:44,460 --> 00:29:45,420
A. Mondul: Oh, excuse me i'm sorry.

214
00:29:49,290 --> 00:29:53,130
A. Mondul: That is an incorrect, let me try to ignore that that was a mistake, I apologize.

215
00:29:55,110 --> 00:29:57,360
A. Mondul: We are I we're miss classifying.

216
00:30:03,540 --> 00:30:14,790
A. Mondul: we're misclassified hypertension that's why so we have I went the wrong way I apologize see even even I can make mistakes so you've got 20% mystification of the outcome.

217
00:30:15,180 --> 00:30:26,010
A. Mondul: So among the exposed among our 1000 expose we are misclassified the outcome by 20% so 20% of 600 is 120 and they move here.

218
00:30:27,270 --> 00:30:29,790
A. Mondul: You see that, so we have 488 520.

219
00:30:30,990 --> 00:30:42,840
A. Mondul: We are misclassified this class applying the outcome, whether they have hypertension or not, the same way, among goes without noise exposure so again, we are taking 120 from here and moving them to hear.

220
00:30:44,010 --> 00:30:44,490
A. Mondul: Okay.

221
00:30:46,230 --> 00:30:47,220
A. Mondul: And that's how you get.

222
00:30:49,230 --> 00:30:51,810
A. Mondul: minus 50 and plus 50 yes.

223
00:30:52,800 --> 00:30:57,480
Sarah Ferri: which you are you doing that for the true association or for the observed study.

224
00:30:58,350 --> 00:31:00,570
A. Mondul: So we are taking.

225
00:31:06,210 --> 00:31:15,180
A. Mondul: We are taking from the truth and then going to the observed, so in so if we say that we have this is our third data and in it, we have 20% misclassification.

226
00:31:15,510 --> 00:31:27,450
A. Mondul: Of the high potential outcome in both the exposed and the unexposed That means that if you go back to hear from the truth 20% of the truth is moved to the wrong area.

227
00:31:28,140 --> 00:31:42,300
A. Mondul: Does that make sense, so if we start with the truth and we say 20% misclassification has happened 20% of 600 and 120 so 120 people are misclassified as not having hypertension, when they really have it and that's how we get these numbers.

228
00:31:43,440 --> 00:31:54,450
A. Mondul: 20% of 250 is 50 so we had 50 people who truly have hypertension, in your misclassified as not having hypertension and so are observed in numbers are these.

229
00:31:56,130 --> 00:31:56,850
A. Mondul: Does that help.

230
00:31:57,270 --> 00:32:06,510
Nolaundron Harris: OK OK, so the true true association is where if we have that 20% misclassification that's the side.

231
00:32:08,610 --> 00:32:09,930
Nolaundron Harris: Of the matrix we've with.

232
00:32:11,100 --> 00:32:13,260
A. Mondul: This is what we, this is what we observed.

233
00:32:14,460 --> 00:32:27,750
A. Mondul: And it's wrong by 20% The outcome is misclassified by 20%, this is what it should be, and we know it's misclassified by 20% because we have 120 people who.

234
00:32:28,200 --> 00:32:40,320
A. Mondul: should be hyper which should be 600 in here right that's the truth but there's only 480 so 120 people are mistakenly put in the know category when they should be in the S category right, because this is what it should be.

235
00:32:42,150 --> 00:32:42,690
Nolaundron Harris: OK.

236
00:32:43,860 --> 00:32:45,810
Nolaundron Harris: OK OK OK OK.

237
00:32:45,840 --> 00:32:59,040
A. Mondul: We had perfectly measured it, it should be this, but we measured it badly because I don't know we have someone who can use a Sigma amateur who is taking these calculation these these blood pressure readings so.

238
00:32:59,610 --> 00:33:06,570
A. Mondul: When when we get our data, this is what it looks like, but it should look like this, yes, so we have a rusty.

239
00:33:08,070 --> 00:33:09,780
opposite of it done so, for example, is.

240
00:33:11,100 --> 00:33:11,670
40% of.

241
00:33:14,760 --> 00:33:22,770
A. Mondul: Our potential wearables and is classified as not how would you present the other way around, so it would be 20% of 400 which is.

242
00:33:23,940 --> 00:33:25,500
A. Mondul: about what is that, like at.

243
00:33:27,210 --> 00:33:44,220
A. Mondul: Work yeah so you would take it away from here and put it here so be six at 320 you still wouldn't say that so those those there's a difference, you would get it would be in an exam question and you're going to you're going to grapple with this in your in your.

244
00:33:45,270 --> 00:33:51,180
A. Mondul: Groups today, it will tell you in what direction and as classification guys when you're being asked to do this table.

245
00:33:55,980 --> 00:33:56,190
A. Mondul: Okay.

246
00:33:59,520 --> 00:34:00,930
A. Mondul: All right, does that make sense to everybody.

247
00:34:03,300 --> 00:34:13,800
A. Mondul: So, because we have this this this classification is non differential right is the same degree of miss classification of the outcome among the exposed and the unexposed.

248
00:34:14,610 --> 00:34:29,580
A. Mondul: Which means that if we calculated our odds ratio here at 3.86 and in our misclassified observed data it's 3.55 we have biased towards the know we are getting a smaller association or an association closer to one, then we should.

249
00:34:32,340 --> 00:34:32,790
A. Mondul: Right.

250
00:34:35,370 --> 00:34:36,420
A. Mondul: A real example.

251
00:34:37,770 --> 00:34:46,620
A. Mondul: of how you might get differential misclassification is if you're interested in oral contraceptive use and DDT right deep vein thrombosis so.

252
00:34:46,920 --> 00:35:05,910
A. Mondul: Doctors will often watch their patients on oral contraceptives more carefully for deep vein thrombosis because they know they'll see us as a risk factor for dpt Okay, and so you are probably more likely to find cases in people using ocs than people who are not.

253
00:35:08,610 --> 00:35:10,380
A. Mondul: Because they're being surveilled more carefully.

254
00:35:12,810 --> 00:35:14,520
A. Mondul: So in this case.

255
00:35:16,800 --> 00:35:20,580
A. Mondul: This is the truth right, this is what we should find if we had a crystal ball.

256
00:35:22,410 --> 00:35:26,880
A. Mondul: No, no, no, nobody wants this what's happening.

257
00:35:31,680 --> 00:35:36,120
A. Mondul: Okay, if we have a crystal ball, this is what we should see.

258
00:35:38,070 --> 00:35:41,040
A. Mondul: If we were all knowing, this is the truth.

259
00:35:42,240 --> 00:35:48,690
A. Mondul: So i'ma go to the world contraceptives do we have any misclassification between the truth and what we actually observe.

260
00:35:56,460 --> 00:36:03,120
A. Mondul: We have 300 people with DDT and 600 with no DDT and then in our observed, again we have 360 yards, so we perfectly.

261
00:36:03,750 --> 00:36:15,600
A. Mondul: found everybody who's on oral contraceptives they're being watched really carefully so we're getting perfect data from them, people who are not on oral contraceptives, in truth, 200 head DVD and 400 did not.

262
00:36:16,770 --> 00:36:17,370
A. Mondul: But.

263
00:36:18,900 --> 00:36:28,230
A. Mondul: Only one in our observed data we only found 100 of those with DDT so we're saying 500 don't This includes 100 people who really did have a DDT.

264
00:36:29,400 --> 00:36:30,420
A. Mondul: Does that make sense.

265
00:36:32,190 --> 00:36:35,310
A. Mondul: And so, if you do your odds ratio, it should be one.

266
00:36:36,420 --> 00:36:51,060
A. Mondul: The truth is there's no association, but because we have in this case differential misclassification because the degree of misclassification is different, among those who are exposed and unexposed we see a higher iteration and we should.

267
00:36:57,300 --> 00:37:02,820
A. Mondul: So non differential misclassification can go in either direction, it does not you can't necessarily predict which way.

268
00:37:06,270 --> 00:37:11,250
A. Mondul: Unlike non differential where you can say it generally biases for the no.

269
00:37:13,050 --> 00:37:16,470
A. Mondul: differential can kind of cause wreak havoc.

270
00:37:17,520 --> 00:37:18,510
A. Mondul: causes chaos.

271
00:37:20,550 --> 00:37:20,910
A. Mondul: Okay.

272
00:37:22,230 --> 00:37:28,530
A. Mondul: So here's an example of reporting bias right so you're looking at sugar consumption and obesity.

273
00:37:30,180 --> 00:37:51,630
A. Mondul: And so, if you imagine there's some in this case we are talking about misclassification of the exposure alright so here's our truth we have 800 obese participants and 700 non obese participants okay.

274
00:37:53,940 --> 00:38:08,520
A. Mondul: And the truth is that, among the obese participants to 600 hundred high sugar consumption and 200 had done and in our not obese participants, it was 300 have high sugar consumption and 400 headline for a relative risk of to.

275
00:38:11,130 --> 00:38:11,640
A. Mondul: Now.

276
00:38:13,230 --> 00:38:15,870
A. Mondul: Those that are participants who are not obese.

277
00:38:17,010 --> 00:38:24,330
A. Mondul: had no misclassification of the exposure Okay, they reported accurately, but in our obese participants.

278
00:38:25,710 --> 00:38:28,170
A. Mondul: There are 150 of them.

279
00:38:31,740 --> 00:38:43,080
A. Mondul: Who reported rather than that they have high sugar consumption that they didn't right, which gives us 450 reporting high sugar consumption at 350 reporting, no, no sugar consumption.

280
00:38:44,670 --> 00:38:56,610
A. Mondul: This 350 includes 150 people who should be in this category okay remember reporting bias is when there's a socially acceptable or you know answer that is expected of the people, love to give.

281
00:38:59,430 --> 00:39:05,730
A. Mondul: The obese people might feel that they're being judged for their obesity and for their diet and therefore not being truthful about what they're consuming.

282
00:39:08,190 --> 00:39:09,390
A. Mondul: When they're reporting it right.

283
00:39:11,310 --> 00:39:16,500
A. Mondul: Is the idea here, and in this case, this is an example of the differential or non differential.

284
00:39:25,710 --> 00:39:34,920
A. Mondul: Is the degree of misclassification the same in the in those with and without the outcome, first of all we're talking about miss classifying what exposure or outcome.

285
00:39:37,980 --> 00:39:40,290
A. Mondul: yep we're talking about misclassification.

286
00:39:41,760 --> 00:39:54,210
A. Mondul: Of the exposure OK, so now, you have to say, is the degree of misclassification the same in are obese in or not obese in our cases in in our non cases, or is it different.

287
00:39:56,820 --> 00:39:59,340
A. Mondul: How much misclassification do we have in our non cases.

288
00:40:02,910 --> 00:40:04,920
A. Mondul: This is our truth, and this is our observed.

289
00:40:07,230 --> 00:40:10,410
A. Mondul: yeah no misclassification.

290
00:40:12,720 --> 00:40:14,910
A. Mondul: In our non cases.

291
00:40:16,380 --> 00:40:17,640
A. Mondul: But we do have.

292
00:40:18,810 --> 00:40:20,160
A. Mondul: misclassification.

293
00:40:21,480 --> 00:40:22,410
A. Mondul: In our cases.

294
00:40:23,700 --> 00:40:26,550
A. Mondul: Is this the same or different in our cases in our non cases.

295
00:40:28,590 --> 00:40:30,210
A. Mondul: For this is differential.

296
00:40:34,140 --> 00:40:42,600
A. Mondul: differential this classification of the exposure because of the differential can we say anything for sure about the expected direction of the bias.

297
00:40:43,650 --> 00:40:45,390
Nolaundron Harris: Oh cuz it can go in any direction.

298
00:40:45,540 --> 00:40:54,000
A. Mondul: That is correct, so this is an example where the differential misclassification actually does go toward the note, but like we said we couldn't have done that for sure.

299
00:40:55,500 --> 00:40:56,070
A. Mondul: Okay.

300
00:40:57,720 --> 00:40:58,710
A. Mondul: Does that make sense.

301
00:41:00,060 --> 00:41:02,550
Nolaundron Harris: hmm reporting okay.

302
00:41:04,110 --> 00:41:09,270
A. Mondul: let's talk about recall bias in this case we're talking to pesticide use an autism.

303
00:41:10,530 --> 00:41:21,990
A. Mondul: Alright, this is an example where you've got parents, maybe, whose children are artistic and you've chosen some controls, where the children are not autistic all right and you're asking them about pesticide use.

304
00:41:23,880 --> 00:41:28,260
A. Mondul: So we've got 200 This is our truth, this is our crystal ball.

305
00:41:30,510 --> 00:41:35,130
A. Mondul: association that's my crystal ball very shiny.

306
00:41:36,750 --> 00:41:39,030
A. Mondul: i'm an excellent artist that's why I chose science.

307
00:41:40,470 --> 00:41:51,660
A. Mondul: So if we had our crystal ball, we can see the truth, we would know it, we do have 200 children with autism and 1200 children without that we have chosen for our study.

308
00:41:53,760 --> 00:42:07,410
A. Mondul: So in this case, we were talking about miss classifying the exposure okay so let's look among our kids without autism do we have some misclassification there.

309
00:42:08,940 --> 00:42:10,020
Nolaundron Harris: Yes.

310
00:42:10,290 --> 00:42:16,020
A. Mondul: Yes, so in this case, we had 100 kids.

311
00:42:18,060 --> 00:42:23,700
A. Mondul: Who were supposed to have you who introduced their parents use pesticides, but they get misclassified over here.

312
00:42:26,130 --> 00:42:29,460
A. Mondul: we're supposed to have 101 hundred here do we have some misclassification.

313
00:42:30,060 --> 00:42:30,750
Nolaundron Harris: Yes, we do.

314
00:42:31,350 --> 00:42:38,070
A. Mondul: Yes, we do and it's in the other direction right in this case, there are some parents who didn't use pesticides to report that they did.

315
00:42:40,260 --> 00:42:49,530
A. Mondul: So you can imagine that this might happen because people who did not have a child, with autism aren't like extra motivated to remember and they just forgot that they use them into them think about it, that much.

316
00:42:50,010 --> 00:43:03,240
A. Mondul: In this case, you maybe have like parents who are really ruminating and they're like maybe I did use pesticides right because they are trying to find a reason for this to happen to their child and that's how you end up with in this in this direction right so.

317
00:43:04,650 --> 00:43:09,390
A. Mondul: Are we talking about miss classification of the outcome, or the exposure in this example.

318
00:43:16,140 --> 00:43:16,740
Nolaundron Harris: exposure.

319
00:43:17,070 --> 00:43:26,640
A. Mondul: that's correct, we are, we are getting the wrong answer in our observe study of the exposure right so we're talking about this classification of the exposure is it different.

320
00:43:28,230 --> 00:43:30,360
A. Mondul: In those with and without the disease.

321
00:43:33,420 --> 00:43:34,410
A. Mondul: Or is it the same.

322
00:43:42,900 --> 00:43:45,540
Nolaundron Harris: No, not answering that.

323
00:43:48,270 --> 00:43:49,260
A. Mondul: delay getting.

324
00:43:50,910 --> 00:43:57,180
A. Mondul: Right, the degree the percentage could be the same, but it doesn't even matter because it's going in different directions.

325
00:43:57,240 --> 00:44:09,300
A. Mondul: Different like you can almost think one is being positive one, is being negative so they're they're completely opposite each other, they can only be the same if they're the same degree and in the same direction so they're definitely not the same.

326
00:44:10,350 --> 00:44:12,780
A. Mondul: So this is what differential or non differential.

327
00:44:13,200 --> 00:44:15,420
A. Mondul: Different that's right.

328
00:44:16,980 --> 00:44:19,980
A. Mondul: This is the process you go through to decide what am I.

329
00:44:21,510 --> 00:44:25,590
A. Mondul: Am I miss classifying am I talking about miss classification of the exposure or the outcome.

330
00:44:26,310 --> 00:44:34,380
A. Mondul: Okay we're talking about this past five minutes soldier, then the question is, is the degree of this classification of the exposure the same and the cases i'm a non cases.

331
00:44:35,340 --> 00:44:47,640
A. Mondul: If the answer is yes it's non differential if the answer is no, it is differential and then you can make some judgment me if it is non differential you can say, I expect the bias toward the know.

332
00:44:49,710 --> 00:44:53,730
A. Mondul: If it is differential you can say everything is chaos and I have no idea.

333
00:44:55,530 --> 00:44:58,230
Nolaundron Harris: And this came on your fridge because it's going in one specific.

334
00:44:59,250 --> 00:45:02,310
Nolaundron Harris: It would be obvious if it's going, I mean like.

335
00:45:03,330 --> 00:45:03,990
Nolaundron Harris: That.

336
00:45:04,800 --> 00:45:10,590
A. Mondul: Okay, so in this case let's say let's look at even the degree right what percent misclassification do we have.

337
00:45:13,560 --> 00:45:22,230
A. Mondul: 190 601 is not correct.

338
00:45:24,270 --> 00:45:24,690
Stop.

339
00:45:26,190 --> 00:45:39,540
A. Mondul: So we have like 17% misclassification going industry direction right, I did 100 divided by 600 so 100 of the 600 votes here that's like 17% in this case we've got 25%.

340
00:45:40,680 --> 00:45:48,060
A. Mondul: misclassification but in the other direction, so it's actually different percentages of misclassification and in different directions right.

341
00:45:53,100 --> 00:45:53,940
A. Mondul: Does that make sense.

342
00:45:57,420 --> 00:46:08,340
A. Mondul: So, because it's differential you cannot say that it would biased would know, and in fact it didn't, because the truth is one and the observed is 2.33 which is not toward them now that's a way for them all right.

343
00:46:11,850 --> 00:46:12,660
A. Mondul: That makes sense.

344
00:46:13,890 --> 00:46:14,970
A. Mondul: what's gonna be with the.

345
00:46:15,270 --> 00:46:28,710
Nolaundron Harris: So the differential decision would be would it be with the out with the wrap up what is that the O R I can't think of a word right now will be based on that are based on the activity inside the.

346
00:46:29,250 --> 00:46:40,770
A. Mondul: degree that misclassification is based on the activity with the muscles, it should be set up like this, but it's actually like this, so you're getting people in the wrong box you put people in the wrong box.

347
00:46:42,090 --> 00:46:42,540
A. Mondul: Right.

348
00:46:44,340 --> 00:46:47,100
A. Mondul: 100 people who should be in this box or in this box.

349
00:46:50,190 --> 00:46:50,460
Okay.

350
00:46:53,460 --> 00:47:06,090
A. Mondul: So how do we keep this from happening, you have to make equal efforts to ascertain disease status in your exposed and your unexposed COPD cohort and randomized controlled trial participants right so.

351
00:47:09,660 --> 00:47:22,440
A. Mondul: Say say you're recruiting on exposure and you're going to a smoking cessation clinic and you're trying to get smokers from your smoking cessation clinic and you go into your clinic and you sit down and you interview your smokers in person.

352
00:47:23,910 --> 00:47:30,240
A. Mondul: And then you find out where they lived and they live far away, so you call up randomly people on the phone.

353
00:47:31,410 --> 00:47:38,580
A. Mondul: In the Community and start asking them stuff over the phone or you mail them a questionnaire instead let's say you don't even call them email them a questionnaire.

354
00:47:39,120 --> 00:47:46,830
A. Mondul: So now you have in person interview information from your exposed and from your unexposed you've got mailed questionnaire data.

355
00:47:48,450 --> 00:47:49,470
A. Mondul: that's not the same.

356
00:47:49,980 --> 00:47:59,880
A. Mondul: You would never want to do that right because you're probably going to get different answers, just because of how you ascertain your data, because you did it differently and you're exposed in your unexposed.

357
00:48:01,740 --> 00:48:07,770
A. Mondul: You want to make equal efforts to establish to exposure status in cases and controls in case control studies.

358
00:48:09,450 --> 00:48:13,950
A. Mondul: One example of doing this is.

359
00:48:15,420 --> 00:48:22,350
A. Mondul: I will measure biomarkers as a as a and you've got your batch right so you've got all these little tubes.

360
00:48:23,730 --> 00:48:27,510
A. Mondul: In this batch and then you've got X number of samples that can go in batch to.

361
00:48:30,270 --> 00:48:35,970
A. Mondul: You would absolutely never, never, never put all of your cases in batch one and all of your controls and batch to.

362
00:48:37,290 --> 00:48:50,190
A. Mondul: write, because you can have batch differences and then suddenly or like on the first day you measure all your cases and then you go home go to sleep and come back and run all your controls the next day in a different batch terrible idea right, you would mix them up.

363
00:48:51,810 --> 00:48:55,560
A. Mondul: So that your ascertaining exposure the same way in your cases and your controls.

364
00:48:56,700 --> 00:48:57,150
A. Mondul: Right.

365
00:48:58,470 --> 00:49:02,910
A. Mondul: So that really helps blinding helps.

366
00:49:03,960 --> 00:49:10,380
A. Mondul: right if you're investigators and interviewers don't know your case control or expose not expose data as a participant they can't.

367
00:49:12,000 --> 00:49:15,510
A. Mondul: unconsciously or consciously do anything different between them.

368
00:49:16,680 --> 00:49:21,960
A. Mondul: This is, we talked about blinding, that is what blinding is trying to guard against his information wise.

369
00:49:23,940 --> 00:49:32,790
A. Mondul: You standardized data collection tick techniques, you might use multiple sources for the same information repeated questions act as a built in double check, and so this is something that I think.

370
00:49:33,330 --> 00:49:41,190
A. Mondul: clifton brought up in the exercise the other day about the smoking question in this, I think it was yesterday, right the days are blending.

371
00:49:41,670 --> 00:49:42,930
A. Mondul: In the SIDS questionnaire right.

372
00:49:43,530 --> 00:49:48,930
A. Mondul: The idea that you know they asked about kind of do or do not smoke and then also frequency of smoking.

373
00:49:49,140 --> 00:49:57,300
A. Mondul: I think this was the idea that he was getting at, but if you ask ask in multiple ways, it can kind of ask it fact as a build a double check and you can make sure that you're getting the Info.

374
00:49:57,600 --> 00:50:02,520
Nolaundron Harris: hmm and then that gives you an option to make sure that the first answer matches up.

375
00:50:03,630 --> 00:50:04,710
Nolaundron Harris: Okay.

376
00:50:06,840 --> 00:50:09,930
A. Mondul: yeah it's pretty cool I mean and sometimes it can.

377
00:50:12,090 --> 00:50:15,030
A. Mondul: Sometimes it can help and sometimes it can just be confusing like.

378
00:50:16,620 --> 00:50:23,760
A. Mondul: I have to tell you that part of the reason I don't like studying female cancers is because there's so much confusion about like hysterectomy isn't a.

379
00:50:24,540 --> 00:50:37,710
A. Mondul: oophorectomy is where like moving the ovaries you asked women on a baseline question or they're like yep I had hysterectomies like fantastic check and then on a follow up question you're like if you had anything else removed and they're like yep I had one over he removed i'm like.

380
00:50:39,720 --> 00:50:42,750
A. Mondul: No, no, you only have to like you told me they were gone.

381
00:50:43,320 --> 00:50:53,670
A. Mondul: You don't get to have another one taken out and how did you only have one taken like you can you can say that she's telling me again that she had originally just like she did on the first budget, but now she's saying shelley i'm wondering what do you like.

382
00:50:54,600 --> 00:51:00,030
A. Mondul: what's going on, you only have to they don't go back like tell me what what's happening here so sometimes there's confusion.

383
00:51:01,710 --> 00:51:15,120
A. Mondul: But you know, generally, this is, this is an idea Okay, you want to build rapport with people in a shared privacy that will ensure that you're getting more truthful answers about things that might be sensitive right.

384
00:51:19,980 --> 00:51:25,680
A. Mondul: Alright, so that is information bias and selection bias in a whirlwind.

385
00:51:31,290 --> 00:51:41,880
A. Mondul: Any questions before we take our break and then move on to our exercise, so that you guys can have fun fun with tables and moving people in your tables.

386
00:51:47,010 --> 00:52:00,840
A. Mondul: Okay let's take a 10 minute break we'll come back at 335 just make it it'll make 1111 a break, but it'll be a nice round number will come back at 235 and we will get into our groups okay okay.

387
00:52:07,920 --> 00:52:09,120
A. Mondul: What have you pause the recording.

388
00:52:15,690 --> 00:52:19,410
amondul: Our friends are coming back from their rooms so we'll get started as soon as they're all here.

389
00:52:33,480 --> 00:52:34,350
Clifton Addison: being recorded.

390
00:52:42,150 --> 00:52:42,390
amondul: Okay.

391
00:52:43,650 --> 00:52:55,980
amondul: Alright guys so first of all, sorry for like the weird freak out that we had here with our Internet completely going out but we made between a mobile hotspot and things coming back on We made it work so that's.

392
00:52:57,150 --> 00:52:58,680
amondul: pretty good for a Friday i'd say.

393
00:53:01,200 --> 00:53:07,890
amondul: All right, the other thing I wanted to point out real quick before we get started, is on the canvas page for today, there is a.

394
00:53:09,000 --> 00:53:09,900
amondul: Little.

395
00:53:14,340 --> 00:53:16,500
amondul: like this, this link here.

396
00:53:18,120 --> 00:53:25,140
amondul: Research and practice projects for last day of class if you click on that it allows you to describe for us.

397
00:53:27,780 --> 00:53:31,530
amondul: You know kind of a project that you might want to discuss.

398
00:53:32,670 --> 00:53:38,430
amondul: That you were working on, so we thought that it might be helpful to kind of think about your project or your research that you're doing.

399
00:53:38,790 --> 00:53:44,850
amondul: That are going outside of the class and how the material learned in the class will support or enhance their activities those activities so.

400
00:53:45,210 --> 00:53:48,960
amondul: If you have a project that is planned that you might start thinking with us through like.

401
00:53:49,920 --> 00:53:59,400
amondul: What is the study design like are you choosing your people correctly what kinds of confounding should be you can be concerned about what kinds of information via should you be concerned about.

402
00:54:00,150 --> 00:54:07,020
amondul: You might start thinking through you know we talked about the publicly available data, we might start thinking through like what data sources.

403
00:54:08,070 --> 00:54:13,830
amondul: You know if you could use any of those publicly available data sources, to answer your question to those kinds of things right so.

404
00:54:14,130 --> 00:54:24,390
amondul: If you have some sort of research project or practice project that you want to think through how the material in this like in a group with with your peers and then in the larger group try to kind of think through what.

405
00:54:26,430 --> 00:54:33,840
amondul: How the material in this class will help inform that project, please put that down we don't expect that everybody will have one.

406
00:54:34,170 --> 00:54:44,400
amondul: Because not everybody's kind of at that place but that's great, because if we get like three we can get you guys in groups to discuss right, so you know, three, four or five people have one that's awesome.

407
00:54:45,810 --> 00:54:51,180
amondul: So if you have something that you think would be a good candidate for that, please let us know okay and that's where you do that.

408
00:54:52,680 --> 00:54:54,900
amondul: Any questions about that before we go through the exercise.

409
00:54:58,320 --> 00:54:58,740
amondul: alright.

410
00:54:59,880 --> 00:55:12,660
amondul: So this is going back to kind of that that stroke study with the new aces county where we originally had you know the kind of the original study was in this very defined geographic area that only had a certain number of hospitals that served it.

411
00:55:13,920 --> 00:55:23,010
amondul: Now they're going to go back and redo this but they've got a new hospital that some of the people are going to so you were asked to kind of look through this table and.

412
00:55:24,150 --> 00:55:28,860
amondul: calculate the the exposure, so what is the exposure of interest here.

413
00:55:31,530 --> 00:55:32,280
amondul: In this study.

414
00:55:44,550 --> 00:55:45,150
about our case.

415
00:55:46,320 --> 00:55:52,260
amondul: So, which is, I think that is our outcome actually I think you're you're right stroke cases are the outcome.

416
00:55:53,580 --> 00:56:10,680
amondul: And race, ethnicity is our exposure right because we're looking at the rate the risk ratio of stroke comparing Mexican Americans to non Hispanic whites right, so our our exposure is race, ethnicity and the outcome is stroke okay.

417
00:56:12,150 --> 00:56:20,490
amondul: So in scenario one you know you were asked to do it for the original studies about nervous ratio of 1.24.

418
00:56:22,200 --> 00:56:31,980
amondul: And then scenario one there's no ethnic segregation in the Community so 10% of all stroke cases, regardless of ethnicity, go to the new hospital aren't in our dust not captured by the study investigators.

419
00:56:32,370 --> 00:56:38,580
amondul: You were asked to figure out how the cumulative incidences and resulting risk ratio into the scenario compared to the true values.

420
00:56:39,300 --> 00:56:47,520
amondul: So, in order to get this, you would have said that okay 90% because 10% for the other hospital so we're capturing 90% of the Mexican American cases.

421
00:56:48,120 --> 00:56:56,730
amondul: And 90% of the non Hispanic white cases which is are deceiving as the table is being real weird I don't know why that's all the way down there sorry about that.

422
00:56:57,540 --> 00:57:10,200
amondul: that's 1211 and then you were supposed to calculate the cumulative incidence per 10,000 for each of these groups, and then the relative risk, and it should have been the same right.

423
00:57:13,560 --> 00:57:22,530
amondul: And then scenario to we have a different problem where the section of the sound is kind of geographically separate in terms of race, ethnicity and.

424
00:57:23,670 --> 00:57:26,640
Divya Manohar: So we just have one question, I think we.

425
00:57:27,870 --> 00:57:30,930
Divya Manohar: I think we did the calculation strong you've done.

426
00:57:33,060 --> 00:57:36,240
Divya Manohar: The risk ratio is 168.

427
00:57:37,530 --> 00:57:39,960
Divya Manohar: My protein is it now.

428
00:57:39,990 --> 00:57:55,920
amondul: The relative risk is 1.24 for the original study 1.24 for scenario one and 1.47 for scenario to so let's see where we went arrived here, so can you compare for why this is so weird and.

429
00:57:56,400 --> 00:58:02,220
Nolaundron Harris: I think that's where some of the numbers are not going all the way across that's what i'm thinking.

430
00:58:03,420 --> 00:58:06,180
Nolaundron Harris: For for some folks, but I think you really still.

431
00:58:10,890 --> 00:58:11,220
amondul: Better.

432
00:58:17,940 --> 00:58:18,420
Divya Manohar: Okay.

433
00:58:20,670 --> 00:58:23,820
Divya Manohar: Okay, the risk ratio I think we've done something to it.

434
00:58:23,940 --> 00:58:28,050
amondul: Okay, so let's let's take a look at the table so do you have the correct numbers in here.

435
00:58:28,410 --> 00:58:29,610
Divya Manohar: Yes, yes.

436
00:58:29,670 --> 00:58:31,890
Divya Manohar: Yes, we have the right numbers they're just.

437
00:58:32,310 --> 00:58:32,640
here.

438
00:58:33,720 --> 00:58:38,640
Divya Manohar: I think we've done 136 by 168 we've done the.

439
00:58:38,730 --> 00:58:40,530
amondul: Other way around Oh, I see.

440
00:58:40,920 --> 00:58:45,150
amondul: Okay So yes, expose group in this case, so it says that you.

441
00:58:48,090 --> 00:58:49,620
amondul: So it asks you.

442
00:58:51,060 --> 00:58:59,970
amondul: I guess it doesn't specifically say so, you could do it the way you did, and then essentially what you have is one over 1.24 So if you did it that.

443
00:58:59,970 --> 00:59:00,780
Divya Manohar: way yes.

444
00:59:01,410 --> 00:59:03,270
Divya Manohar: Yes, we have more.

445
00:59:04,050 --> 00:59:05,460
amondul: interpret it differently.

446
00:59:05,670 --> 00:59:06,750
Divya Manohar: mm hmm yeah.

447
00:59:07,350 --> 00:59:16,890
amondul: So rather than saying there's a 24% increased risk of stroke and Mexican Americans compared to non Hispanic whites you would say that there is a there's point.

448
00:59:16,920 --> 00:59:22,530
amondul: eight times right point eight times the risk of stroke and whites compared to Mexican Americans.

449
00:59:22,560 --> 00:59:23,550
Divya Manohar: Yes, yes.

450
00:59:24,060 --> 00:59:35,130
Divya Manohar: But much scenario is totally different for us because I think it's only Point six seven for us where is when you've calculated your way it's 1.47 so there's an increase.

451
00:59:35,130 --> 00:59:35,730
amondul: Right now.

452
00:59:36,720 --> 00:59:37,110
Divya Manohar: Okay.

453
00:59:37,200 --> 00:59:40,830
amondul: You take one divided by 1.4 7.68.

454
00:59:40,860 --> 00:59:41,820
Divya Manohar: Right yes.

455
00:59:42,240 --> 00:59:47,610
amondul: Separate thing you just again inverted and you did your reference group was Mexican Americans.

456
00:59:47,670 --> 00:59:54,180
amondul: And, and your comparison group was whites so that's fine, the point is still the same that the.

457
00:59:56,190 --> 01:00:02,910
amondul: That the the relative risk is not the risk ratio is not the same and scenario to as it is in the original study right.

458
01:00:03,000 --> 01:00:03,990
Divya Manohar: Yes, yes.

459
01:00:04,050 --> 01:00:04,950
amondul: That makes sense.

460
01:00:05,250 --> 01:00:06,750
Divya Manohar: Yes, thank you.

461
01:00:07,170 --> 01:00:12,570
amondul: So part of that is just thinking about like if you were going to write a paper on this would you want to say that.

462
01:00:13,590 --> 01:00:22,680
amondul: When you write the paper, would you want to write it saying white people have a lower risk of stroke, or would you want to write Mexican Americans in this, many have a higher risk of stroke.

463
01:00:23,190 --> 01:00:36,720
amondul: it's kind of about like how you would want to frame it it's the same information it's both correct right The numbers are correct either way what you make your reference group sometimes depends on how you want to frame it and what you want to say.

464
01:00:39,960 --> 01:00:45,240
amondul: We ran into this when I was doing vitamin D research right because you can either say that people who.

465
01:00:45,480 --> 01:00:55,950
amondul: have low vitamin D or increased risk of something in our case, we were finding that vitamin D this protective so you can say low vitamin D is bad or you can say hi or vitamin D is good.

466
01:00:56,610 --> 01:01:05,280
amondul: Right and you can flip it and say it either way both are right mathematically does that make sense it's kind of about like what message you want to say.

467
01:01:06,180 --> 01:01:07,890
Abby Sossen (she/her): Would you, I have a quick question.

468
01:01:09,540 --> 01:01:14,430
Abby Sossen (she/her): You guys use that as like a reason for people to.

469
01:01:15,450 --> 01:01:25,950
Abby Sossen (she/her): Use lower SPF or sunscreen or not wear sunscreen and beat like to i've heard people say they don't like sunscreen because they like to get their vitamin D is at like.

470
01:01:26,130 --> 01:01:27,840
Abby Sossen (she/her): bs or is that something.

471
01:01:28,620 --> 01:01:35,490
amondul: um, so there are better I mean you can get enough vitamin D with like 10 minutes of some exposure.

472
01:01:36,030 --> 01:01:41,190
amondul: Like even if you wear sunscreen you're still going to get plenty of rest of the day it's really should not be a big big deal.

473
01:01:41,790 --> 01:01:48,960
amondul: You do have to, of course, balance you don't want to be like vitamin D deficient, but you, you should not be getting a ton of sun exposure.

474
01:01:49,440 --> 01:02:04,380
amondul: I would say the be the increased risk of melanoma with high UV exposure is worse than the potential downsides of low vitamin D and if you're that worried about vitamin D, you can take a supplement and where are you ready.

475
01:02:05,580 --> 01:02:13,140
Abby Sossen (she/her): Okay, I always say that to people when they're like oh I don't wear sunscreen I like to my vitamin D i'm like I don't think that's a good idea.

476
01:02:13,140 --> 01:02:14,580
amondul: You can tell them I said, though.

477
01:02:16,620 --> 01:02:18,300
amondul: If the doctor said that's nonsense.

478
01:02:19,020 --> 01:02:19,320
Okay.

479
01:02:20,910 --> 01:02:21,240
amondul: Okay.

480
01:02:23,460 --> 01:02:24,120
amondul: So.

481
01:02:25,470 --> 01:02:31,410
amondul: Back to this we figured out our table and the inverse that's fine i'm boo boo boo so.

482
01:02:32,880 --> 01:02:41,400
amondul: We there was equal loss in scenario one right, so you, you did not have a bias, so I would call this an example of.

483
01:02:42,570 --> 01:02:43,950
amondul: Selection bias.

484
01:02:44,970 --> 01:02:50,430
amondul: Because it's about how you're picking your people, for your study you're picking your people, by going to these hospitals.

485
01:02:51,000 --> 01:03:06,210
amondul: And now we're thinking about who we are missing, by choosing that method of selecting our stroke cases right, so if this is the case in scenario one we're equally losing the the we are missing people equally from our.

486
01:03:07,470 --> 01:03:16,710
amondul: are exposed and unexposed we're missing cases equally from our exposure unexposed groups by, and so you don't have a bias.

487
01:03:17,730 --> 01:03:25,530
amondul: However, in scenario two you're not missing people equally from are exposed exposed groups, so you are getting a bias testament does that make sense.

488
01:03:29,700 --> 01:03:30,030
amondul: yeah.

489
01:03:32,700 --> 01:03:42,300
amondul: So it's all about bias occurs when when you select people differently you're selecting your cases differently, based on exposure right.

490
01:03:45,090 --> 01:03:48,090
amondul: If something happens different if you so yeah.

491
01:03:52,170 --> 01:04:00,270
amondul: All right, so how could they improve it, I mean they could have gone to the neighboring hospital to write and gotten anybody with a corpus Christi address.

492
01:04:01,320 --> 01:04:08,640
amondul: Right there's a well defined catchment area of the different hospitals, you could restrict your study population for those living in the catchment area right.

493
01:04:10,140 --> 01:04:12,600
amondul: So there's ways to maybe prevent this problem.

494
01:04:15,720 --> 01:04:17,580
amondul: Any questions about that before we move on.

495
01:04:22,350 --> 01:04:24,390
amondul: Alright, so we're back to since.

496
01:04:25,980 --> 01:04:30,480
amondul: i'm in here we're assuming that we're able to obtain the addresses of the parents.

497
01:04:30,720 --> 01:04:38,850
amondul: With children who died us is from death certificates for the hospitals and willing to give us the addresses of all the other women on the maternity Ward, so we are having a hard time contacting Trolls.

498
01:04:39,630 --> 01:04:51,420
amondul: And what we are saying, smoking is more common amongst us with low income, so what would be the consequences of using email to recruit the controls and using postal mail to contact the cases, you should already have it achy achy feeling about this.

499
01:04:51,720 --> 01:04:57,540
amondul: Because we're using totally different methods to recruit our cases and controls and we do not like it, not good.

500
01:04:59,160 --> 01:05:07,950
amondul: So we're thinking emails more likely to be used by higher income subgroups of the population and less by lower income because it requires somebody to have a computer or smartphone right.

501
01:05:09,060 --> 01:05:18,210
amondul: So, consequently, the controls, maybe wealthier than the cases, who were contacted and the different way, which only requires that they have an address so low income has been associated with greater rates of smoking.

502
01:05:18,840 --> 01:05:32,940
amondul: The controls recruited using email maybe less likely to smoke than the population that deprives gave rise to the cases resulting in an inflation of the odds ratio, even if there was no real association, so if we make a little picture of this, it might be a little bit easier.

503
01:05:34,860 --> 01:05:39,270
amondul: works okay so say we have SIDS yes and no.

504
01:05:40,590 --> 01:05:41,700
amondul: And we've got smoking.

505
01:05:44,280 --> 01:05:51,510
amondul: Yes, and no okay we're making a two by two table here, and so what you end up with is, if you recruit your cases.

506
01:05:52,230 --> 01:05:56,760
amondul: These are your cases right we're going to recruit them by mail so we're going to increase this.

507
01:05:57,510 --> 01:06:06,180
amondul: relative to the controls right because the people were printing by mail are more likely to be lower income were smoking is increased.

508
01:06:07,080 --> 01:06:26,370
amondul: Then we go by email for our controls and we end up having more nonsmoker excuse me more non smokers, this is increased more non smokers right because we're getting the higher income people were less likely to smoke Okay, so this causes a problem does that make sense to everybody.

509
01:06:28,980 --> 01:06:29,700
amondul: All right.

510
01:06:31,650 --> 01:06:44,280
amondul: So you're asking if you've been compromised the internal and external validity well in impacts, the internal validity because you're going to get by us results due to selection bias, the control group and if it's not internally valid I told you it's not externally valid right.

511
01:06:46,920 --> 01:06:54,210
amondul: When they're still be an issue with internal validity if email was used to recruit both the cases and the controls and that's less of a concern right.

512
01:06:54,660 --> 01:07:01,950
amondul: Both groups would be the same level of income and smoking cabins and the control should are closely matched the population to get five, so the cases so you've got says.

513
01:07:03,810 --> 01:07:05,430
amondul: It wants me to be on the paper, I think.

514
01:07:06,810 --> 01:07:10,380
amondul: says, plus and minus and the smoking, yes, now right.

515
01:07:11,760 --> 01:07:12,480
amondul: And so.

516
01:07:13,500 --> 01:07:27,810
amondul: What happens here is, if you have everybody recruited by email, you might have higher a little bit higher rate of smoking generally so you've got a higher marginal right but it's not different by exposure, so you have.

517
01:07:28,200 --> 01:07:36,810
amondul: Maybe a select population of higher income, people who are more likely to smoke, but you will get the right answer about the association between smoking it sits.

518
01:07:39,390 --> 01:07:41,610
amondul: So this gets you to question seven.

519
01:07:43,800 --> 01:07:46,290
amondul: Now, with this influence your external validity.

520
01:07:48,330 --> 01:07:52,290
amondul: And this is a thought provoking question right because.

521
01:07:53,730 --> 01:08:02,790
amondul: i'm curious to see what other groups, what did you guys say I had a conversation about this with group five and i'm curious what other groups came up with for this, what did you guys say.

522
01:08:05,340 --> 01:08:19,320
Abby Sossen (she/her): We said the same thing that they were dealing with generalize ability, because it would really only be like dinner is liable to the high income people you would miss all the low income people pretty much completely.

523
01:08:20,040 --> 01:08:26,070
Abby Sossen (she/her): me are the low income people that smoke and yeah so we said the same thing as you said.

524
01:08:26,850 --> 01:08:37,950
amondul: I guess, then the question is it's only not generalizable if you think that the relationship between smoking and SIDS is going to be different in low income people than it is in high income people.

525
01:08:40,560 --> 01:08:41,550
amondul: Do you think that's true.

526
01:08:43,140 --> 01:08:48,060
amondul: Do you think that low income babies babies of low income families are going to have a different.

527
01:08:49,620 --> 01:08:53,040
amondul: Different risk of SIDS that their parents smoke compared to high income babies.

528
01:08:57,300 --> 01:08:58,110
Abby Sossen (she/her): No.

529
01:08:58,980 --> 01:09:09,720
amondul: Maybe not right, so this is the thing is it's very easy you everybody does this you get your first fb methods class and you're like ah that's not possible because we looked in the select population.

530
01:09:11,220 --> 01:09:11,880
amondul: But.

531
01:09:13,140 --> 01:09:23,190
amondul: Sometimes you have to do a study that you can get done right you can't get the addresses of these women from the hospital they're not going to give them to you, so you have to do a study somehow.

532
01:09:24,480 --> 01:09:33,780
amondul: So emails your best bet and you can't email one group and do cml to the other group because that's going to create a bias and then it's not valid for anybody, so you do the email approach right.

533
01:09:34,650 --> 01:09:45,120
amondul: Because that's the study you can do, and then the question is like how bad of a general liability problem is this, I mean it's probably only the very lowest income people who don't have access to email right.

534
01:09:46,380 --> 01:09:57,090
amondul: Especially today, I don't know what your base did this study in right, it was a bigger gap before right, but now I think it's only the very lowest income people who probably wouldn't be contactable by email.

535
01:09:57,450 --> 01:10:09,930
amondul: So you're probably not missing a huge chunk of people, you probably still have some range of sex in this group and I guess the question is like if we found that since was that smoking, increase the resistance is.

536
01:10:11,160 --> 01:10:16,500
amondul: Is there a downside just going ahead and telling people even low income people you probably shouldn't smoke around your baby.

537
01:10:18,270 --> 01:10:37,440
Abby Sossen (she/her): I, I guess, I would just think that if you did it this way, you would have a much lower number of smokers in your sample size so just like you're an overall would be lower so your study would be like less powerful or valuable if you don't have as many smokers in your.

538
01:10:38,700 --> 01:10:50,490
amondul: True, I mean as possible, it could be that you would end up with not enough expose people to look at it, but if you had enough, and you found in us if you found an association that implies that you're studying had enough power to find it right.

539
01:10:50,970 --> 01:10:53,160
amondul: So you've got that smoking was bad the question.

540
01:10:53,190 --> 01:10:58,050
amondul: Then is is this general can we can we tell other groups, besides the exact people that we studied.

541
01:10:58,530 --> 01:11:08,970
amondul: That we found this and that they should change their behavior or whatever, based on this, I can we make a recommendation because that's the goal right if we think we found we did a valid study, because we use email only.

542
01:11:09,510 --> 01:11:17,460
amondul: We emailed the people we found that smoking was associated to the increased risk of sense yeah we studied a more affluent group than the general population.

543
01:11:17,820 --> 01:11:24,660
amondul: But is there a reason, we think that this is not true that this result is not true for less affluent people.

544
01:11:25,080 --> 01:11:27,960
amondul: And should we say we can't say anything about SIDS and low.

545
01:11:28,140 --> 01:11:36,600
amondul: Low income people we're going to tell the high income people to stop smoking rather babies, but we're not going to make that recommendation for low income people because we just don't know we have to do a study in them before we can say.

546
01:11:41,190 --> 01:11:50,400
amondul: I don't think that there's it now there are things where there's a good reason to think that i'm I can't can anybody come up with an example, my brain is is is not happy right now and can't think of one.

547
01:11:52,440 --> 01:11:57,600
amondul: we're truly like, if you look in one group it's not generalizable to another.

548
01:11:57,630 --> 01:12:04,200
Nolaundron Harris: What did you say about certain medication yesterday and how yes that's it was yesterday that's what I was thinking.

549
01:12:04,740 --> 01:12:07,560
amondul: So some medications that truly are not.

550
01:12:08,070 --> 01:12:18,660
amondul: don't work in, and I think there's one that's I cannot come up with it off the top of my head, I should have looked because I mentioned it, and said the same thing, the other day, but there is like I think it's a cardiovascular disease medication, if any physician so.

551
01:12:19,140 --> 01:12:34,470
amondul: interrupt me and tell me, I think there is a medication that works in like some ethnic groups and not in Asians because of like a genetic difference between the racial groups right, and I think there's other last like genetic based ones that you could come up with right where.

552
01:12:41,130 --> 01:12:45,840
amondul: Oh, so in my work we actually Thank you that's a good one, so in my work.

553
01:12:47,010 --> 01:12:51,990
amondul: We found that status were associated with lower risk of.

554
01:12:54,270 --> 01:13:07,140
amondul: A lower risk of dying of head and neck cancer, so people who were taking a stab at the time of diagnosis for less likely to die there had met cancer, but that was only in the HPV positive cases, so it wouldn't work in HPV negative cases.

555
01:13:08,220 --> 01:13:11,040
amondul: That wouldn't be generalizable to HPV negative cases.

556
01:13:11,970 --> 01:13:21,720
amondul: So I think you have to be i'm just asking i'm just i'm trying to get you guys, to be a little bit nuanced about this is good to recognize that there's the potential for an external validity problem here.

557
01:13:22,080 --> 01:13:27,090
amondul: But then I also want you to think about, but does that really make sense, and even if it weren't true.

558
01:13:27,930 --> 01:13:41,910
amondul: it's I mean it's not like smoking around your baby's going to be good for low income people right like what's the worst that happened, you tell people to stop smoking around their baby and you get him to quit smoking and nothing happens to the baby like great that's a win right so.

559
01:13:42,720 --> 01:13:51,870
amondul: I just I don't think I mean I i'm certainly not advocating that we don't need to do research in broad groups of people in lots of different.

560
01:13:52,260 --> 01:14:00,390
amondul: Racial social socio economic gender groups like I think we absolutely do, but sometimes like, in this case.

561
01:14:01,260 --> 01:14:14,730
amondul: You couldn't do it another way, and so you get what you get you don't throw fit you try to do the best we can, with the information you can get some information is better than no information and if we waited until we could do the perfect study we might never do a study right.

562
01:14:16,560 --> 01:14:20,820
amondul: That makes sense, so it's again like a balance, you have to do.

563
01:14:21,900 --> 01:14:31,260
amondul: You may not be able to do the perfect study now you don't want it to be so bad that you're getting the wrong answer and it's just trash and not useful that's not worth spending your money and time on but you know.

564
01:14:33,540 --> 01:14:38,640
amondul: Oh cool bro says joshua that's the drug and talk that's the dragon talking about apparently.

565
01:14:38,670 --> 01:14:39,240
Abby Sossen (she/her): have everything.

566
01:14:39,270 --> 01:14:42,090
Abby Sossen (she/her): My dad to expect drug keys about the animals.

567
01:14:43,290 --> 01:14:44,520
amondul: That Asian because I think.

568
01:14:44,640 --> 01:14:46,170
amondul: he's not going to work out.

569
01:14:48,390 --> 01:14:50,580
amondul: Perfect perfect I think that's fine.

570
01:14:50,970 --> 01:14:53,880
Divya Manohar: They prescribe that in the Indian population I don't know how.

571
01:14:54,510 --> 01:14:58,140
amondul: East Asians like i'm Chinese and Japanese and stuff like that.

572
01:14:58,230 --> 01:14:58,680
amondul: Okay.

573
01:14:59,250 --> 01:15:00,540
amondul: But, again, I don't know for sure.

574
01:15:01,050 --> 01:15:10,200
amondul: So i'm not that kind of doctor and I remember reading a paper about it, and then the name of the drug fell out of my head because they're all made up in my mind like they're all pretend names of anything anyway.

575
01:15:10,830 --> 01:15:15,960
amondul: Anyway, so that's that's just my thought about generalize ability just trying to be a little bit nuanced and thoughtful.

576
01:15:17,880 --> 01:15:27,750
amondul: Alright let's do part three real quick and then we will do the rest of this on Monday morning and i'll let you guys go okay well we'll do this and then.

577
01:15:28,950 --> 01:15:32,430
amondul: We have a little bit of slot time built in so it'll be okay.

578
01:15:33,780 --> 01:15:36,420
amondul: Alright, so you were given this.

579
01:15:37,560 --> 01:15:42,240
amondul: occupation occupational epidemiology study where we're concerned about healthy worker effect.

580
01:15:43,080 --> 01:15:50,700
amondul: This type of selection bias occurs when an investigator tries to compare the impacts of exposure by comparing expose workers to unexposed people from the general population.

581
01:15:51,090 --> 01:16:01,290
amondul: And in this example we're comparing the incidence rate of cardiovascular disease among miners who exposed to high level of diesel exhaust compared to the general population, which consists of individuals who don't work, as well as others.

582
01:16:01,860 --> 01:16:05,250
amondul: With jobs with no physical demands and people who have physical demanding jobs right.

583
01:16:06,120 --> 01:16:16,110
amondul: So here's The incidence rate of CBD per 100 person years and minors, and this is the overall for the general population, this is physically active workers and people who are unemployed have desk jobs, etc.

584
01:16:16,890 --> 01:16:23,490
amondul: Alright, so you're asked to calculate the ratio for exposure to diesel exhaust if you use the general population is the unexposed group.

585
01:16:24,360 --> 01:16:29,460
amondul: And how would this be different if you picked other physically active workers as the unexposed group okay so.

586
01:16:30,150 --> 01:16:36,780
amondul: If you use the general population, you get point five, so it looks like there's a lower incidence of CBD incidence rate of CBD and minors.

587
01:16:37,650 --> 01:16:47,280
amondul: But it's one if you use physically active laborers as the unexposed group and the bad suggests that there's no difference in the incidence rate of CBD between my miners and other physically active workers.

588
01:16:48,900 --> 01:16:54,660
amondul: And so the impact of exposure of your appears to be protective when the people who are exposed are healthier than the unexposed right.

589
01:16:55,080 --> 01:17:07,020
amondul: Usually people in the Labor force tend to be healthier than the general population, so when you can make the comparison with other healthy workers you no longer see that exposure, so the healthy worker effect may explain these five days right.

590
01:17:10,080 --> 01:17:12,360
amondul: Alright, so we will start with this part.

591
01:17:14,070 --> 01:17:16,290
amondul: Well let's just do this question, then we can do, part two.

592
01:17:17,910 --> 01:17:28,950
amondul: So if we follow a cohort of 1000 elderly smokers and and the thousand elderly nonsmokers for incident dementia over a 10 year period, although smoking is a risk factor for cognitive decline, they have no association.

593
01:17:30,330 --> 01:17:33,840
amondul: So, given that really 70% of the initial study population return for the.

594
01:17:34,080 --> 01:17:44,970
amondul: Final clinical examination what's a plausible explanation for the number results and so we're considering that cases a dimensional were captured because people with dementia were unable to continue participation and they didn't come back.

595
01:17:46,830 --> 01:17:54,420
amondul: So if you were only getting self report if you didn't have like medical records or information for family members, you can have a selection bias.

596
01:17:54,930 --> 01:18:11,430
amondul: Also, if you were losing people on the last follow up with new cases of dementia or greater in smokers and non smokers, it could also biased toward the knowledge and this could have happened because of the competing restless issue that we talked about in the lecture.

597
01:18:12,750 --> 01:18:13,590
amondul: That makes sense.

598
01:18:16,530 --> 01:18:25,440
amondul: Right, so we will start with section two on measurement error, at the beginning of next class will go over these answers, then we'll have our lecture and we'll do our next our next.

599
01:18:27,240 --> 01:18:27,960
amondul: exercise.

600
01:18:29,730 --> 01:18:30,150
amondul: hey.

601
01:18:34,260 --> 01:18:37,620
amondul: guys have a great weekend enjoy your two days of not listening to me talk.

602
01:18:39,450 --> 01:18:40,170
What kind of coffee.

603
01:18:43,650 --> 01:18:43,950
Nolaundron Harris: Like.

604
01:18:44,280 --> 01:18:45,510
Nolaundron Harris: Talk about know.

605
01:18:47,880 --> 01:18:50,820
amondul: You guys must be so sick of me by the end of these three weeks I swear.

606
01:18:51,270 --> 01:18:55,080
amondul: All right, you guys have a great weekend and I will see you back on Monday.

607
01:18:55,110 --> 01:18:56,310
Divya Manohar: Okay, thank you yeah.

608
01:18:56,460 --> 01:18:57,390
Divya Manohar: Go buy.

609
01:18:57,510 --> 01:18:57,960
A.

610
01:18:59,040 --> 01:18:59,610
Nolaundron Harris: Great weekend.

