1
00:00:00,180 --> 00:00:05,370
We are going to start up and today we have confounding.

2
00:00:05,370 --> 00:00:14,670
We do have a dangerous activity as well. And so this is one of the kind of concepts that people have a little bit more difficulty with.

3
00:00:15,060 --> 00:00:19,950
Although for those of you who've taken a vitamin ology first before, you should have seen it before.

4
00:00:21,980 --> 00:00:29,060
So Simpsons Paradox is this idea that correlation present in different groups is reversed when the groups are combined.

5
00:00:30,020 --> 00:00:38,110
This is a statistical phenomenon that occurs. An example of Simpsons Paradox is U.S. wages.

6
00:00:38,120 --> 00:00:43,220
So between the years 2020 13, the median wage for the US is 1%.

7
00:00:43,890 --> 00:00:46,820
Right. So that sounds good, right? Wages are going up.

8
00:00:48,080 --> 00:00:59,960
However, if you looked at the individual groups looking at at education levels, in fact, a very different picture emerged for each of the groups.

9
00:01:00,860 --> 00:01:03,860
The the income level actually dropped.

10
00:01:03,890 --> 00:01:07,550
So looking at high school dropouts, it dropped by 7.9%.

11
00:01:07,970 --> 00:01:11,150
High school graduates? No. College by 4.7%.

12
00:01:11,570 --> 00:01:18,200
Some college by 7.6%. And bachelor's or higher by 1.2%.

13
00:01:18,800 --> 00:01:21,890
So how can this be right that overall the wages are going up?

14
00:01:21,890 --> 00:01:25,760
But when you look at any individual group, the wages are decreasing.

15
00:01:26,450 --> 00:01:27,320
What do you think's happening?

16
00:01:36,190 --> 00:01:44,850
So every single group, when you break it up by education level, every single group has a decrease in wages, but overall wages increased in the US.

17
00:01:46,850 --> 00:01:50,540
Sorry. Yes, exactly.

18
00:01:50,540 --> 00:01:57,170
So. Well, it's not only just transfer between groups, but it's partly people retiring, the younger generation having more education.

19
00:01:57,180 --> 00:02:05,740
Right. And so what's happening is that the proportion of the population with a higher level of education is increasing.

20
00:02:05,750 --> 00:02:10,930
And people who have a higher level of education tend to make higher salaries.

21
00:02:10,940 --> 00:02:17,990
Right. So even though the salary levels inside each group were dropping because the proportions in each group were changing,

22
00:02:20,030 --> 00:02:27,129
then you see an overall increase. Right.

23
00:02:27,130 --> 00:02:30,940
So more college graduates, fewer individuals with high school or less.

24
00:02:32,680 --> 00:02:37,690
So this is another example of Simpson's paradoxes, his exercise and cholesterol level.

25
00:02:38,860 --> 00:02:44,710
So across the bottom here, it's the number of minutes of exercise per week.

26
00:02:45,460 --> 00:02:51,040
And here is the cholesterol level. And is this what you would expect to see as people exercise more?

27
00:02:51,040 --> 00:02:55,990
They have higher levels of cholesterol. So people who exercise more have higher levels of cholesterol.

28
00:02:56,920 --> 00:03:07,060
Now it's the reverse of what we would expect to see. Right. Well, when you break this up by group, this is now broken up by age group.

29
00:03:07,600 --> 00:03:15,010
Right. We have the this is individuals under 30, 30 to 40, 42, 50, 50 to 60, 60 plus.

30
00:03:15,490 --> 00:03:21,670
And in each age group. Well, except for maybe the last one, you see this slight downward trend.

31
00:03:21,670 --> 00:03:27,040
Right. Or people who exercise more have lower levels of cholesterol.

32
00:03:27,850 --> 00:03:33,700
That's actually what we would expect to see. Right. Because they also probably take better care of their diet as well.

33
00:03:34,630 --> 00:03:40,840
But as people get older, they tend to participate in more low intensity exercise.

34
00:03:41,290 --> 00:03:45,070
And so you tend to do low intensity exercise for greater length of time.

35
00:03:45,610 --> 00:03:51,510
Right. So these 30 year olds are exercising less, you know,

36
00:03:51,520 --> 00:03:57,580
but they may be running compared to these 60 plus year olds who are probably or exercising for longer periods of time,

37
00:03:57,880 --> 00:04:01,390
probably spending more time walking or lower intensity exercise.

38
00:04:01,960 --> 00:04:05,170
So there you go. So that's Simpson's paradox.

39
00:04:06,460 --> 00:04:10,000
Simpson's paradox is very similar to confounding.

40
00:04:10,330 --> 00:04:16,060
Right. And if we looked at this as a confounding problem, we would say that it was confounded by age.

41
00:04:16,540 --> 00:04:20,410
Right. The relationship between cholesterol and exercise.

42
00:04:22,570 --> 00:04:27,280
So this is a structural representation of Simpson's paradox. You should know what this is, right?

43
00:04:27,280 --> 00:04:34,630
It's a dag. Here we have the amount of weekly exercise, this relationship between cholesterol, between that and cholesterol level.

44
00:04:35,020 --> 00:04:42,340
And we have age, which is affecting both the amount of weekly exercise that people are doing as well as people's cholesterol levels.

45
00:04:45,550 --> 00:04:53,140
Okay. So confounding is a non causal association between an exposure and an outcome is observed as a result of

46
00:04:53,140 --> 00:04:58,030
the influence of a third variable or a group of variables because there can be multiple confounders.

47
00:04:59,380 --> 00:05:05,020
Another definition is the distortion of the true association between a given exposure and

48
00:05:05,020 --> 00:05:10,389
an outcome that is observed as a result of another associated variable or variables.

49
00:05:10,390 --> 00:05:16,840
Right. And so basically it's that you're seeing a different relationship than the true relationship as a result of something else.

50
00:05:19,000 --> 00:05:22,180
I always think of confounding, kind of as like a mixing of effects.

51
00:05:22,510 --> 00:05:26,169
Like if you're taking paint and pouring it into it, you know, a can, right?

52
00:05:26,170 --> 00:05:30,010
And you get a different color once you mix those two colors of paint.

53
00:05:33,050 --> 00:05:37,130
So four types of confounding we could have negative confounding.

54
00:05:37,550 --> 00:05:44,650
So that will underestimate the true association. We can have positive confounding, which overestimates the true association,

55
00:05:44,660 --> 00:05:49,730
or we can have qualitative confounding, which is an inversion of the true association.

56
00:05:50,240 --> 00:05:56,120
So something that is protective appears to be a risk factor or something that's a risk factor and appear to be protective.

57
00:05:59,330 --> 00:06:04,790
So confounding is more likely to occur in observational studies than experimental studies.

58
00:06:05,600 --> 00:06:08,780
But it really it can occur in both study design, in both study types.

59
00:06:11,120 --> 00:06:15,950
So in an RC t right we get random allocation of people to the groups.

60
00:06:16,490 --> 00:06:18,920
This is, for example, vaccine in a placebo.

61
00:06:20,540 --> 00:06:28,470
The sources of confounding for a nasty t are random differences between the groups for an observational study.

62
00:06:28,520 --> 00:06:32,959
So like a prospective cohort, for example, we've got nonrandom allocation here.

63
00:06:32,960 --> 00:06:38,870
We've got smokers and nonsmokers. We'll have both random differences between the groups.

64
00:06:38,870 --> 00:06:45,950
Right, which can be all responsible for confounding as well as other factors that are associated with the exposure of interest.

65
00:06:51,340 --> 00:06:54,610
We've seen multiple examples of compounding throughout the class already.

66
00:06:55,090 --> 00:07:01,690
So one thing that we did was age standardization, and that was really to deal with the effects of age confounding by age.

67
00:07:01,700 --> 00:07:10,150
So here we've got an example looking at crude mortality rates of a number of countries, including the United States.

68
00:07:10,600 --> 00:07:18,880
And what you'll notice right away is that some of the lower income countries have much lower crude mortality rates,

69
00:07:19,690 --> 00:07:28,180
and that's not what we would expect. Right. But the reason for that is, is because of their age structure.

70
00:07:28,580 --> 00:07:34,420
And we went over that a bit before. So what you had age adjust the mortality rates.

71
00:07:35,290 --> 00:07:41,920
You can see that the U.S. and Canada do indeed have lower mortality rates than some of these.

72
00:07:42,940 --> 00:07:46,180
Well, then I guess then all of these actually lower income countries.

73
00:07:48,430 --> 00:07:55,420
So here, age is a confounder. Or you could say that the crude mortality rates are confounded by age.

74
00:08:01,380 --> 00:08:04,020
Another example of compounding is compounding by severity.

75
00:08:04,770 --> 00:08:09,239
So it's been reported that certain types of medical or tertiary prevention interventions for chronic

76
00:08:09,240 --> 00:08:15,180
obstructive pulmonary disease for COPD are associated with unfavorable health health outcomes.

77
00:08:15,930 --> 00:08:21,659
Long term oxygen therapy undergoing respiratory rehabilitation and influenza vaccination.

78
00:08:21,660 --> 00:08:27,300
So all of those have been reported as being associated with bad health outcomes in people with COPD.

79
00:08:27,690 --> 00:08:34,589
But is that what you would expect to see? And these are treatments that should help them have better health outcomes.

80
00:08:34,590 --> 00:08:43,110
Right. But the reason that that this happens is that there's confounding by severity.

81
00:08:43,110 --> 00:08:51,750
That is the worse off the patients with COPD are, the more likely they are to get these treatments right or interventions.

82
00:08:54,300 --> 00:09:04,740
So because of this, it's also for a lot of diseases very important to evaluate, confounding by severity level as well in observational studies.

83
00:09:04,740 --> 00:09:07,320
Right and you wouldn't have this problem.

84
00:09:08,910 --> 00:09:15,630
Rounding by severity is also sometimes called confounding by indication depending on which textbook you're reading.

85
00:09:19,130 --> 00:09:22,370
All right. So there are different ways of thinking about confounding.

86
00:09:23,630 --> 00:09:28,390
You can think of it kind of as a mixing of effects or counterfactuals.

87
00:09:28,400 --> 00:09:33,500
We'll talk about both. So for mixing of effects,

88
00:09:33,500 --> 00:09:41,690
confounding can be thought of as mixing of the effect of the exposure under study on the disease with that of a third factor.

89
00:09:42,560 --> 00:09:54,700
Right. So. Kind of like I said, I think of it a little bit as like a mixing of paint cans, right, where you're actually adding in.

90
00:09:54,700 --> 00:09:59,769
Another factor changes the color of the paint.

91
00:09:59,770 --> 00:10:08,140
So it changes the the your estimate of the effect if you fail to adjust for that extraneous factor.

92
00:10:10,060 --> 00:10:13,870
All right. So the counterfactual model, the basic idea.

93
00:10:13,930 --> 00:10:19,870
Right. Is what would happen if we rewind and observe the outcome in the exposed individual without the exposure?

94
00:10:20,170 --> 00:10:26,770
This should sound familiar. You've seen these slides. We're going to go back over them, though, because it becomes very important for compounding.

95
00:10:28,300 --> 00:10:34,390
So for the kind of fractional model. Right, that is, we're looking at the risk of the outcome among exposed individuals.

96
00:10:36,880 --> 00:10:46,520
If the risk of exposure, if the risk of the outcome among exposed individuals would have been different had those individuals not been exposed.

97
00:10:49,450 --> 00:10:55,030
And as we discussed before, this is generally not possible. Right. And so instead, we use a comparison group.

98
00:10:57,490 --> 00:11:06,130
The assumption that we're making in using a comparison group is that the separate unexposed group is comparable to the exposed individuals.

99
00:11:06,520 --> 00:11:15,610
If they had not been exposed, that is that they would have the same outcome as those exposed to individuals had the exposed individuals not exposed.

100
00:11:18,600 --> 00:11:22,330
So confounding is present when the comparability assumption is not correct.

101
00:11:22,350 --> 00:11:29,309
That is when the unexposed individuals and the exposed individuals would not

102
00:11:29,310 --> 00:11:34,050
have the same outcome if they were both unexposed or if they were both exposed.

103
00:11:36,720 --> 00:11:43,379
That is the risk of the of the outcome in the control group is not the same as

104
00:11:43,380 --> 00:11:50,730
the unobserved counterfactual exposed group if the members had not been exposed.

105
00:11:54,360 --> 00:11:58,110
So when that happens, we say that those two groups are non exchangeable.

106
00:11:58,890 --> 00:12:02,190
Okay. All right.

107
00:12:03,960 --> 00:12:09,090
So back to our causal types. We've got our P ones, remember, those are doomed people.

108
00:12:09,420 --> 00:12:16,800
The effect that the exposure has no effect P two's or effect positive, that is that they're exposed.

109
00:12:16,830 --> 00:12:21,180
They become a case of if they're not exposed, they don't become a case p threes or preventatives.

110
00:12:21,190 --> 00:12:24,780
They're they're they're exposed. They do not develop your outcome.

111
00:12:24,780 --> 00:12:29,940
They don't become a case. But if they're unexposed, they do in their p force which are immune individuals.

112
00:12:30,060 --> 00:12:39,420
It doesn't matter if they have the exposure or not. So the causal risk ratio is the ratio representing the risk of disease.

113
00:12:39,420 --> 00:12:44,790
If everyone was exposed divided by the risk of disease, if everyone was unexposed, right?

114
00:12:44,790 --> 00:12:49,920
So that's actually seeing these outcomes for your p p ones, for people, individuals,

115
00:12:50,520 --> 00:12:53,489
the causal risk difference and we're going to write it in this kind of person.

116
00:12:53,490 --> 00:13:01,980
B Writing like that, right, is the difference in the risk of disease if everyone was exposed compared to if everyone was unexposed.

117
00:13:04,260 --> 00:13:06,419
So we've worked this out for for the relative risk.

118
00:13:06,420 --> 00:13:13,440
Remember in the board you end up with P one plus P two over P one plus three for the causal risk difference,

119
00:13:13,440 --> 00:13:18,330
we end up with P one plus P2 minus P one plus P three.

120
00:13:18,960 --> 00:13:22,470
And then for the causal odds ratio, it's a little bit uglier there,

121
00:13:22,470 --> 00:13:32,100
but p one plus p two over one minus p one plus P2 over p one plus p three over one minus p one plus p three.

122
00:13:35,220 --> 00:13:38,190
And that's, you know, using these up here, everybody's exposed.

123
00:13:38,190 --> 00:13:46,229
Everybody's not quite so confounding is quite simply or the simplest way to explain confounding is when your

124
00:13:46,230 --> 00:13:54,450
observed relative risk is not equal to your causal relative risk or the same thing for your observed risk.

125
00:13:54,450 --> 00:14:01,320
Difference is not equal to the causal risk difference or the odds ratio is not equal to the causal loss ratio.

126
00:14:02,940 --> 00:14:10,260
So typically we're going to see confounding discussed on a relative scale, but it can certainly be present on an absolute scale as well.

127
00:14:14,520 --> 00:14:14,820
All right.

128
00:14:15,000 --> 00:14:26,280
And with that, we are going to or only 15 minutes, then take a break and do the in class activity just to start working on identifying confounding.

129
00:14:34,570 --> 00:14:51,330
What? You hear them out sometimes. And.

130
00:15:02,876 --> 00:15:06,206
That's right. Okay.

131
00:15:06,246 --> 00:15:13,376
So for identifying confounding there are many data driven approaches that are used are used to identify confounding,

132
00:15:14,336 --> 00:15:18,596
that are based on statistical approaches to examine associations and study data.

133
00:15:19,466 --> 00:15:24,356
So how many of you have learned about stepwise regression, either forward or backward?

134
00:15:25,646 --> 00:15:31,975
Pretty common, right? Or the 10% rule, the changes, your estimate more than 10%.

135
00:15:31,976 --> 00:15:36,805
Then it's a confounder and we should include it. Right? These are not the rules that we're going to use in 601.

136
00:15:36,806 --> 00:15:40,286
Those are bad rules. Okay.

137
00:15:40,466 --> 00:15:47,636
So why, why why are we using that? Confounding is really about causal relationships, right?

138
00:15:48,506 --> 00:15:52,256
So it's best to identify confounding by using causal relationships.

139
00:15:53,156 --> 00:15:57,836
We can then use the study data to quantify the confounding.

140
00:15:58,436 --> 00:16:01,676
Right? So we're not using the study data to look for confounding.

141
00:16:04,256 --> 00:16:10,676
So when we talk about identifying and quantifying confounding, we'll talk about three different things.

142
00:16:10,676 --> 00:16:17,846
The three cut criteria which are put forward by Rothman are dags directed acyclic graphs.

143
00:16:17,846 --> 00:16:24,596
Those are really going to be your tool for looking at confounding and then collapse ability.

144
00:16:27,396 --> 00:16:38,816
So for the three criteria. Actually, I think you added plausibility that later there was a we'll talk more about plausibility next time as well.

145
00:16:39,356 --> 00:16:48,956
So for the three criteria, a confounding factor must be an extraneous risk factor for the disease to be associated with the exposure

146
00:16:48,956 --> 00:16:56,995
under study in the source population and must not be affected by the exposure or the disease in particular.

147
00:16:56,996 --> 00:17:04,146
It cannot be an intermediate step in the causal path between the exposure and the disease, but is extremely.

148
00:17:06,636 --> 00:17:15,185
It's a separate risk factor for the disease. So an extraneous risk factor for the disease.

149
00:17:15,186 --> 00:17:21,666
That may be an actual cause of the disease. It might be a surrogate cause of the disease.

150
00:17:23,106 --> 00:17:29,736
Prior knowledge, not the data itself is used to determine the relationship of the factor to the disease.

151
00:17:31,986 --> 00:17:35,676
And it has to cause the disease either directly or indirectly.

152
00:17:40,146 --> 00:17:45,096
So a confounder can be a marker of another unmeasured causal factor.

153
00:17:45,996 --> 00:17:50,346
So variables treated as confounders are occasionally surrogates for true confounding variables.

154
00:17:50,736 --> 00:17:56,526
An example of that is x. X is used as a surrogate for social factors that cause outcomes.

155
00:17:57,306 --> 00:18:00,336
Right. Another example is sex.

156
00:18:00,966 --> 00:18:06,306
So sex is a true confounder if it's reflecting the distinct sexual or hormonal differences.

157
00:18:07,836 --> 00:18:10,745
But it's often used actually as a surrogate confounder. Right.

158
00:18:10,746 --> 00:18:15,846
So and when it's used as a surrogate confounder, it's kind of incorporating in attitudes,

159
00:18:15,846 --> 00:18:22,866
behaviors or exposures that are associated with sex due to contextual or cultural circumstances.

160
00:18:23,736 --> 00:18:28,156
Right. Okay.

161
00:18:28,166 --> 00:18:37,075
So that's criteria one causing the disease we can use a surrogate criteria to the factor must be associated with the exposure

162
00:18:37,076 --> 00:18:43,196
in the source population account confounding factor must be associated with the exposure under study in the source population.

163
00:18:43,886 --> 00:18:46,916
Generally, this is data based. However, it varies a bit by design.

164
00:18:48,206 --> 00:18:51,776
In a cohort study of the cohort is our source population.

165
00:18:51,986 --> 00:18:59,546
Therefore, this relationship can be determined from the study data. In a case control study, the controls are selected from the source population.

166
00:19:00,086 --> 00:19:06,506
However, the control group needs to be very large and have no selection bias or measurement error,

167
00:19:06,536 --> 00:19:13,886
which we've already kind of went over, is unlikely in order to accurately reflect the association in the source population.

168
00:19:15,596 --> 00:19:20,726
But in the case control study, you're going to want to use external information when it's available.

169
00:19:22,766 --> 00:19:28,746
Okay. Criteria three The factor cannot be caused by the exposure or the disease.

170
00:19:29,556 --> 00:19:33,096
Confounding factor must not be affected by the exposure of the disease.

171
00:19:33,096 --> 00:19:38,646
In particular, it cannot be an intermediate step in the causal pathway between the exposure and the disease.

172
00:19:40,536 --> 00:19:45,696
This is automatically satisfied if the factor precedes the exposure and the disease.

173
00:19:46,236 --> 00:19:51,786
Right. Because we we can't go backwards in time because of that. All right.

174
00:19:52,956 --> 00:19:55,476
So an intermediate variable, not a causal pathway.

175
00:19:56,046 --> 00:20:05,526
Example here we've got we're looking at let's take that away instead of adding it, maternal smoking and the effect on infant mortality.

176
00:20:07,326 --> 00:20:12,516
And you say, well, maternal smoking causes low birth weight and low birth weight affects infant mortality.

177
00:20:13,146 --> 00:20:16,536
Right. So this would be on the causal pathway, right?

178
00:20:18,756 --> 00:20:28,906
So we would not say that low birth weight here is a confounder. What is low birth weight for people?

179
00:20:29,496 --> 00:20:32,826
What's it called? Starts with them. Mediator.

180
00:20:35,976 --> 00:20:50,616
All right, so when we condition on something more,

181
00:20:50,676 --> 00:20:57,996
when we can discern the effect of two variables what you can actually tell the outcome more of a sort of percentage of time and a third variable.

182
00:20:58,776 --> 00:21:04,896
And this is kind of important to know for why you induce the relationship between two variables that may not be related.

183
00:21:05,226 --> 00:21:11,106
Right. So we had two coins. They're not weighted. Right? You flip one coin, you flip another coin, or you get flip a coin.

184
00:21:11,106 --> 00:21:14,876
One should not have any relationship to what the flip complete two to.

185
00:21:14,886 --> 00:21:15,186
Right.

186
00:21:15,666 --> 00:21:30,186
But let's say now when we get heads right, the bell is going to bring and you've got a one point, you're flipping coin, number one, and you get tails.

187
00:21:31,326 --> 00:21:34,386
Okay. And somebody else in another room is flipping of the coin.

188
00:21:34,566 --> 00:21:39,276
You can't see it, right? They flip the coin and the bell rings.

189
00:21:39,576 --> 00:21:42,336
What can you tell me about what's happened with the with the coin in the other room?

190
00:21:42,696 --> 00:21:46,836
Remember, Bell is only going to ring if one of the coins has heads. So what was.

191
00:21:47,556 --> 00:21:55,776
You know what you got? Which was tails? Can you tell me what the other person got in this case, right?

192
00:21:55,806 --> 00:21:59,466
Yes. Because we've conditioned on the outcome here.

193
00:22:00,216 --> 00:22:06,545
Right. 50% of the time or proportion of the time you'll get correlation between those two.

194
00:22:06,546 --> 00:22:15,216
Right. Conditioning on that bell ringing. So knowing that outcome, this I would suggest that you read this paper.

195
00:22:15,546 --> 00:22:22,055
It's a really good example for like understanding why when you condition on the outcome,

196
00:22:22,056 --> 00:22:30,816
you you you get an association between these two variables when there was none before.

197
00:22:31,146 --> 00:22:35,256
This is extremely important to understand, you know, for this class.

198
00:22:36,576 --> 00:22:40,356
All right, we can.

199
00:22:40,596 --> 00:22:45,096
So in this case, you're right. You can only calculate a correlation from events when the bell rings.

200
00:22:49,386 --> 00:22:54,846
And yeah. So anyways, you end up with a -0.5 correlation.

201
00:22:55,346 --> 00:23:01,066
Okay. So here's another example. This is a really good example, too, from Joel's statistics in epidemiology.

202
00:23:01,086 --> 00:23:06,426
You can tell I went to Berkeley because a lot of the examples I use come from some of the professors there.

203
00:23:06,756 --> 00:23:10,206
So examples that I learned as a student, this is in his book.

204
00:23:10,716 --> 00:23:16,296
All right. So we're looking at tooth decay, dietary sugar and fluoridation.

205
00:23:17,316 --> 00:23:25,476
All right. And you're saying, like, well, I'm interested in studying tooth decay and maybe the effect of additional tooth decay, for example.

206
00:23:26,376 --> 00:23:29,666
But I know dietary sugar is also going to cause tooth decay.

207
00:23:29,676 --> 00:23:36,606
Right. So here we have some hypothetical data on water fluoridation, high sugar diet and tooth decay.

208
00:23:38,316 --> 00:23:45,126
And what you can see here is we have stratified by fluoridation, so it's either for fluoridated water or not.

209
00:23:46,026 --> 00:23:50,276
And we see the same odds ratio and this is excess risk here.

210
00:23:50,286 --> 00:23:59,016
So risk difference for high sugar diet when stratified by fluoridation.

211
00:24:00,486 --> 00:24:04,596
Okay. Here. We've done the inverse.

212
00:24:04,596 --> 00:24:08,946
So now we're looking at fluoridation, the effect of fluoridation on on tooth decay.

213
00:24:11,916 --> 00:24:23,526
And we've got, we've now stratified by high sugar diet and you can see that there you're getting the same relationship right when you split it out.

214
00:24:23,856 --> 00:24:27,786
And in fact, now we've looked at the relationship here between fluoridation, a high sugar diet.

215
00:24:28,086 --> 00:24:32,645
We don't see any any correlation. They're not like they're not associated.

216
00:24:32,646 --> 00:24:35,466
We get an odds ratio of one excess risk of zero.

217
00:24:36,456 --> 00:24:42,516
So here we can see that high sugar diet is associated with tooth decay and the presence of or absence of fluoridation.

218
00:24:43,206 --> 00:24:50,406
Right. The same is true for fluoridation, right? It's associated with tooth decay and the presence or absence of a high sugar diet.

219
00:24:51,996 --> 00:24:55,476
And there's actually there's no statistical interaction. We will get into that next time.

220
00:24:57,986 --> 00:25:05,486
All right. Now we're going to conditioned on tooth decay or conditioning on the outcome here.

221
00:25:05,876 --> 00:25:15,576
Okay. And we've done that by by stratifying right into tooth decay and tooth decay.

222
00:25:16,476 --> 00:25:20,766
And we now have an association between fluoridation and high sugar diet.

223
00:25:21,456 --> 00:25:24,936
When we didn't have one before. Right.

224
00:25:26,766 --> 00:25:35,616
So what we've done here is we've stratified on something caused by both the exposure and the disease.

225
00:25:35,616 --> 00:25:40,536
And we're so we're introducing confounding when in fact, there was no confounding present before.

226
00:25:42,936 --> 00:25:46,356
So why we care about that, right?

227
00:25:47,106 --> 00:25:54,396
We care about that because confounding is structural. Confounding arises because of how structurally the variables are related to each other,

228
00:25:55,326 --> 00:26:02,076
either how they're naturally related to one another or how they're related to each other.

229
00:26:02,076 --> 00:26:09,576
After an investigator, after we have changed the relationships by adjustment, matching or conditioning, etc.

230
00:26:10,116 --> 00:26:13,696
Right. So this 10% rule, right?

231
00:26:13,776 --> 00:26:16,806
When you think about that 10%, you say, okay, well, you know,

232
00:26:16,836 --> 00:26:22,836
or the stepwise regression you can actually be introducing confounding when there was no confounding present.

233
00:26:23,226 --> 00:26:31,476
Right. And that's why we don't want to use those rules. Instead, we want to think about this, the structural basis of the relationship.

234
00:26:32,106 --> 00:26:41,216
When we think about confounding. When do you take a second and explain that to somebody sitting next to you?

235
00:26:41,256 --> 00:26:48,816
Just give it a second to kind of sink in. So why why are we not wanting to use, like, the 10% rule or step wise?

236
00:26:52,686 --> 00:27:07,266
That's. All righty.

237
00:27:10,896 --> 00:27:20,156
Okay. So exchange ability exchange ability is what ties confounding to causal structures formally this formal equation.

238
00:27:20,166 --> 00:27:21,456
Right. So what does this mean?

239
00:27:22,866 --> 00:27:32,496
Potential outcomes under exposure are a are independent of the exposure actually given because the independence is not conditional.

240
00:27:33,186 --> 00:27:40,996
This is also known as marginal exchange ability. All right, so what is exchange ability?

241
00:27:41,506 --> 00:27:44,626
Imagine a randomized controlled trial. Right.

242
00:27:44,626 --> 00:27:49,005
If two large groups have been randomized to take a drug in expectation or

243
00:27:49,006 --> 00:27:53,686
expectation is that they have the same levels of measured and unmeasured factors.

244
00:27:54,076 --> 00:27:58,746
That's, of course, assuming quite large groups, right? So sex, height, hair color, etc.

245
00:27:58,756 --> 00:28:01,906
Right. So factors that matter, factors that may not matter for their outcomes.

246
00:28:04,246 --> 00:28:08,836
So if the unexposed group was instead assigned the drug, right?

247
00:28:08,836 --> 00:28:16,636
So if we switched the assignments, we expect them to have a very similar response as the actually exposed group because the factors are the same.

248
00:28:17,866 --> 00:28:25,216
The only difference is there should be due to random error and that's when two great groups are exchangeable, right?

249
00:28:25,216 --> 00:28:33,886
So that is if the unexposed group were counter to the fact exposed, we would expect them to have the same outcome as the actually exposed group.

250
00:28:37,416 --> 00:28:42,606
Or before treatment is given. Both the unexposed and the exposed groups are the same.

251
00:28:43,266 --> 00:28:49,086
So regardless of which treatment they are actually assigned, they have the same potential outcomes.

252
00:28:55,776 --> 00:28:57,276
So after randomization,

253
00:28:57,276 --> 00:29:04,986
then the key groups are going to be exchangeable because their potential outcomes are independent of the exposures they actually receive.

254
00:29:05,646 --> 00:29:09,396
So when we have exchange ability, we have no confounding present.

255
00:29:14,996 --> 00:29:20,336
So if the groups are truly exchangeable, then the only difference between the two groups in this example,

256
00:29:20,336 --> 00:29:29,036
right, is the treatment that they actually receive. So the difference in the outcome should then only reflect the exposure that they're given.

257
00:29:30,626 --> 00:29:34,106
So that difference cannot be attributed to confounding.

258
00:29:37,546 --> 00:29:41,225
So in the potential outcomes framework, the counterfactual framework,

259
00:29:41,226 --> 00:29:49,276
great confounding occurs when the two groups are not comparable to each other with respect to measured and or unmeasured factors.

260
00:29:51,616 --> 00:29:58,606
So confounding is occurring when there is a lack of exchange ability between the two groups being prepared compared.

261
00:30:01,516 --> 00:30:10,396
So in this class of confounders, any variable that is a common cause of the exposure and outcome which is responsible for a lack of exchange ability.

262
00:30:14,146 --> 00:30:18,926
All right. So what about conditional exchange ability?

263
00:30:21,656 --> 00:30:26,096
Conditional exchange ability. Right. We've got the same formula here. That's quite a change ability.

264
00:30:26,456 --> 00:30:31,796
But this is conditioned on a set of variables.

265
00:30:32,126 --> 00:30:38,546
W Right. So we've got the potential outcomes of Y under exposure.

266
00:30:38,576 --> 00:30:49,106
A Are independent of the exposure actually given conditioned on a variable or a set of variables here that we conditional.

267
00:30:49,116 --> 00:30:56,496
And so that exchange ability actually holds. So conditional exchange ability here.

268
00:30:56,806 --> 00:31:00,826
Right. Same situation that we had before. This time, however,

269
00:31:00,826 --> 00:31:07,696
pretend randomization work except that sex balance is not 5050 between the two groups and end sex

270
00:31:07,696 --> 00:31:13,906
is an important risk factor biological sex for for this outcome or is of respect for this outcome.

271
00:31:14,206 --> 00:31:19,575
So we don't have exchange ability but if we control for sex or and just for sex,

272
00:31:19,576 --> 00:31:25,786
then we would have exchange ability thus exchangeable equals conditionally on w, which in this case is sex.

273
00:31:30,786 --> 00:31:37,506
So in observational studies, we don't randomized people. Right. And so they we don't kind of naturally have exchange ability.

274
00:31:38,346 --> 00:31:44,166
But if we condition on the right confounders, we can get conditional exchange ability.

275
00:31:48,986 --> 00:31:56,696
So what does this mean? It means that understanding these structural relationships between factors is really key or dags are key.

276
00:31:58,226 --> 00:32:03,386
Conditional interchangeability means no confounding, which means that we actually identify the causal effect.

277
00:32:07,686 --> 00:32:12,636
So how do we know what proper structural relationships are we're going to use directed at cyclic grabs?

278
00:32:13,596 --> 00:32:18,306
Remember, this is not a method of data analysis. They're used to identify confounders.

279
00:32:20,436 --> 00:32:24,756
Dags help us to pick the temporal structure of the relationship between our factors.

280
00:32:29,706 --> 00:32:40,025
All right. So they'll both in the state of nature as well as after we have intervened.

281
00:32:40,026 --> 00:32:47,426
Right. As investigators on the natural structure by conditioning on a set of factors that will mark what we conditioned on.

282
00:32:47,436 --> 00:32:56,286
And with that, we're going to take a break. We will start back up at 1104 and go back through kind of a reminder of Dags.

283
00:32:56,286 --> 00:33:01,536
And then we're going to build up off of our prior prior knowledge of dogs from this class.

284
00:33:22,815 --> 00:33:25,845
So the exam is coming up. We still got a bit of time, right?

285
00:33:26,325 --> 00:33:34,274
We are going to post the practice exam kind of early. One of the things you have to do for the exam is we're going to we will give

286
00:33:34,275 --> 00:33:39,735
you papers at least a week ahead of time that you need to read for this exam.

287
00:33:40,185 --> 00:33:45,075
The reason is, is you're going to be, you know, using those papers to answer some questions.

288
00:33:45,075 --> 00:33:49,394
You get to bring the papers in with you. You can highlight, you can underline.

289
00:33:49,395 --> 00:33:55,634
You cannot take notes. All right. And underlining is okay, though, right on the paper.

290
00:33:55,635 --> 00:33:59,535
So make sure that you spend a good amount of time bonding with those papers.

291
00:34:00,015 --> 00:34:07,125
And if you're not used to reading research papers and looking for bias, you know,

292
00:34:07,155 --> 00:34:13,124
pulling that information out of whole papers, make sure that you well, even if you are used to it,

293
00:34:13,125 --> 00:34:18,674
I would highly recommend that you come to the in-class activity because that's what the in class activity day is going to be doing,

294
00:34:18,675 --> 00:34:21,705
will really be digging into some research papers.

295
00:34:22,005 --> 00:34:31,545
Also practicing on the practice exam early and utilizing office hours if you're having a difficult time pulling that information out of the papers.

296
00:34:33,765 --> 00:34:39,945
But yeah, as I said, we'll get those papers out to at least a week before the exam so that you have plenty of time to kind of figure out,

297
00:34:40,275 --> 00:34:43,785
you know, when to spend a little bit of time bonding with those papers.

298
00:34:44,175 --> 00:34:49,935
Every year we have a few people who decide not to read the papers ahead of time.

299
00:34:50,295 --> 00:34:52,875
We will have copies of the paper on the exam day.

300
00:34:53,145 --> 00:35:01,785
But trust me, you do not want to be trying to read that paper and pull the information out on the day of the exam.

301
00:35:02,415 --> 00:35:04,785
They're like some things that are going to be kind of obvious.

302
00:35:05,115 --> 00:35:12,845
You should look at what the exposure is, what the outcome is, what the study design is, look for potential sources of bias or error,

303
00:35:12,885 --> 00:35:21,645
like all of the topics we've been kind of covering now, that's what you're going to be going through, highlighting, underlining in the paper, right?

304
00:35:21,885 --> 00:35:26,265
And you'll see examples of practice exam. We'll have examples of what prior questions were like.

305
00:35:27,785 --> 00:35:30,805
Yes. So you can bring in a copy of.

306
00:35:31,915 --> 00:35:36,115
Please do. Yeah. Yeah.

307
00:35:36,125 --> 00:35:39,305
No, no. So. And bring in a paper copy.

308
00:35:39,305 --> 00:35:42,395
Right. Because you can't use your so you're going to need to print it up.

309
00:35:43,615 --> 00:35:50,194
We will have printed copies here for you in case you forget. But like I said, it'll be a big benefit to you to have read it ahead of time.

310
00:35:50,195 --> 00:35:56,765
Underlined, highlight the pertinent places that you can go and people will often use different color highlighters.

311
00:35:57,305 --> 00:36:04,835
Right is one like just to get a right way with notes like here's the exposure, information, bias and another color, etc. right?

312
00:36:04,835 --> 00:36:09,845
Like that's that's perfectly fine. All right.

313
00:36:11,705 --> 00:36:21,125
Okay, so dogs, right, where they're not a method of data analysis, we're going to use them to identify potential confounders.

314
00:36:24,155 --> 00:36:27,605
So how does conditioning on a DAG tell us about conditional exchange ability?

315
00:36:28,565 --> 00:36:35,075
So the aim of the game, what we're trying to do with this is to see if the exposure is associated with the outcome through a backdoor pathway.

316
00:36:35,915 --> 00:36:47,705
If such a backdoor path is open, meaning we haven't closed it right or we accidentally open it, then you don't get conditional exchange ability,

317
00:36:47,795 --> 00:36:54,395
right, because the outcome here or the potential outcomes is no longer independent of their assignment.

318
00:36:54,395 --> 00:37:02,405
X, which means confounding is present. So we want conditional exchange ability, right?

319
00:37:02,405 --> 00:37:05,644
So the goal is to block all backdoor pass from the exposure.

320
00:37:05,645 --> 00:37:09,874
Here we've got low income to the outcome, diabetes.

321
00:37:09,875 --> 00:37:12,935
This is our question. You know, is there an association here?

322
00:37:13,385 --> 00:37:18,124
Here we have mother has diabetes. We are now conditioning on.

323
00:37:18,125 --> 00:37:21,365
Mother has a diabetes means, which means we were adjusting for it.

324
00:37:21,875 --> 00:37:26,375
And when we do that, we are blocking that backdoor pathway.

325
00:37:29,865 --> 00:37:35,805
So basic DAG rules reminder errors represent causal relationships or lack thereof.

326
00:37:36,555 --> 00:37:41,805
Dogs are going to be temporarily ordered, very cyclic, and they have time flows.

327
00:37:42,885 --> 00:37:50,625
Remember, the relationships that we can show through dogs should all hopefully look familiar, but I find it's very helpful to highlight it again.

328
00:37:50,925 --> 00:37:54,735
You'll see it one more time in this class when we bring all of the dogs that we've used

329
00:37:54,735 --> 00:38:01,305
in the different lectures back together to do a kind of a full kind of workshop on dogs.

330
00:38:02,595 --> 00:38:05,955
Right. So we can show a direct causal effect. So here a causes.

331
00:38:05,955 --> 00:38:10,445
Why the absence of a causal effect? We've got no arrow, right?

332
00:38:10,545 --> 00:38:13,725
The indirect effect through B, so it causes Y.

333
00:38:14,655 --> 00:38:17,655
So it has a direct effect and an indirect effects through B.

334
00:38:18,075 --> 00:38:22,094
And here is an indirect effect in the absence of a direct causal effect,

335
00:38:22,095 --> 00:38:28,575
because we don't have an arrow from A to Y, remember, factors are going to be temporally ordered.

336
00:38:29,445 --> 00:38:34,755
So we've got the outcome of type one leading to the outcome at 10.2, leading to an outcome of 10.3.

337
00:38:35,325 --> 00:38:40,245
So you're never going to have an arrow from a future factor into a positive factor.

338
00:38:42,945 --> 00:38:49,095
We don't have any feedback loops and Dak's very cyclic, so we don't want to see anything right here, poverty and infection.

339
00:38:49,665 --> 00:38:52,154
Instead, we'll use time points. So here we've got time one.

340
00:38:52,155 --> 00:38:58,725
So poverty at time one leads to an infection at time point one also leads to poverty at 10.2.

341
00:38:59,325 --> 00:39:03,915
Right. And section 2.1 leads to poverty at 10.2, an infection at 10.2.

342
00:39:03,915 --> 00:39:05,835
And of course, you can keep going with that. Right.

343
00:39:06,795 --> 00:39:17,024
So that's how we deal with feedback loops, time flows, index time usually flows from north to south and from left to right.

344
00:39:17,025 --> 00:39:31,575
And that just helps with organizing your doc, right? So all common causes of the exposure and the disease must be included in the DAG.

345
00:39:32,535 --> 00:39:37,095
This includes unmeasured factors, right? Because those are potential pathways.

346
00:39:38,025 --> 00:39:41,205
E.g. intermediate steps do not need to be included in the DAG.

347
00:39:41,595 --> 00:39:52,245
Does depend on your research question though. So dad rules for identifying confounding to get from a to y through a backdoor path.

348
00:39:52,485 --> 00:39:56,205
You can move along any path regardless of the arrow's directionality.

349
00:39:57,615 --> 00:40:04,694
So here we low income. We go against this arrow to mother diabetes are crossed, and then down here to diabetes,

350
00:40:04,695 --> 00:40:09,255
right that these red arrows or a backdoor path from low income to diabetes.

351
00:40:10,215 --> 00:40:19,525
So in this particular case, a backdoor path is open and we're not going to be isolating the information on the effect of low income on diabetes here.

352
00:40:21,015 --> 00:40:30,185
So the effect of and why is not identified. So conditioning on a common cause of an exposure and an outcome closes a backdoor path.

353
00:40:30,945 --> 00:40:37,065
Right. So here we've conditioned on mother has diabetes that's going to close this backdoor path.

354
00:40:37,785 --> 00:40:46,275
And then the effect of a on Y here, low income on diabetes is now identified right now.

355
00:40:49,515 --> 00:40:58,635
Because we conditioned on mother has diabetes. We could also condition here on unhealthy nutrition, but there are issues with that.

356
00:40:59,145 --> 00:41:08,325
All right. Because of some measure. All right. So rules for identifying, confounding on fat measured factors may still lead to confounding,

357
00:41:08,325 --> 00:41:12,314
even if you close the backdoor path through measured factors.

358
00:41:12,315 --> 00:41:17,114
So here we closed one backdoor path, but we've got socioeconomic status.

359
00:41:17,115 --> 00:41:25,695
It's not measured in this case. Right. But we think that earlier socioeconomic status will lead to lower income.

360
00:41:26,085 --> 00:41:29,554
Right. And it impacts your risk of diabetes.

361
00:41:29,555 --> 00:41:32,385
So this is childhood socioeconomic status.

362
00:41:34,815 --> 00:41:41,715
So we've blocked one backdoor path here, but a backdoor path is open through you through this unmeasured factor.

363
00:41:41,925 --> 00:41:45,075
So the effect on a on Y is not identified.

364
00:41:45,525 --> 00:41:54,684
So we have confounding present. The existence of a collider will block a back door path.

365
00:41:54,685 --> 00:41:58,825
So once a collider collider here now we've promised differently.

366
00:41:59,155 --> 00:42:04,915
Now mother has diabetes is a collider. So low income causes the mother to have diabetes.

367
00:42:05,345 --> 00:42:10,615
Unhealthy nutrition is also leading to the other has diabetes because these arrows going into both that's a collider.

368
00:42:12,295 --> 00:42:16,585
When you have a collider, the back door path is closed. Right.

369
00:42:17,485 --> 00:42:20,545
And so the effect on NY is identified.

370
00:42:21,445 --> 00:42:28,524
However, if we condition on a collider, we'll open up that backdoor path.

371
00:42:28,525 --> 00:42:32,845
And the reason is think of that bell example or the fluoride and.

372
00:42:37,415 --> 00:42:46,065
High sugar diet example, right? With tooth decay, we've now conditioned on a common effect of these two variables.

373
00:42:46,095 --> 00:42:49,745
We're inducing an association between those variables.

374
00:42:53,555 --> 00:43:00,425
So when you condition right on the collider, you may open a back door path.

375
00:43:00,815 --> 00:43:04,265
There was another collider in it and you wouldn't, but in this case, there was not.

376
00:43:04,925 --> 00:43:08,515
All right. So that's red arrows, meaning a backdoor path is opening.

377
00:43:09,695 --> 00:43:12,815
The effect on a a on Y is not identified.

378
00:43:14,765 --> 00:43:19,985
So conditioning on a descendant of a collider will also open a backdoor path.

379
00:43:21,305 --> 00:43:27,785
So here the descendant of the collider is medical care, right?

380
00:43:28,805 --> 00:43:39,335
So we've conditioned on medical care and we've so we've now opened this backdoor path because we conditioned on a descendant of the collider.

381
00:43:41,765 --> 00:43:46,835
So then the effect of iron wise or the effect of low income on diabetes is not being identified.

382
00:43:52,855 --> 00:43:57,115
All right. So here we have an example of vaccination and pneumonia.

383
00:43:58,685 --> 00:44:03,595
Our question is, does vaccination prevent pneumonia?

384
00:44:05,245 --> 00:44:09,205
Maybe this the PCB vaccine could be a different vaccine.

385
00:44:10,195 --> 00:44:16,915
So we've got a few different factors we've drawn back. Right. Remember, you kind of use existing knowledge what you think is occurring, right?

386
00:44:16,915 --> 00:44:22,585
So we've got access to medical care, which we think directly impacts vaccination,

387
00:44:22,585 --> 00:44:28,725
pneumonia, SARS also directly impacts vaccination and it impacts access to medical care.

388
00:44:28,735 --> 00:44:31,944
Here, we don't have an arrow directly from SARS to pneumonia.

389
00:44:31,945 --> 00:44:35,815
You could argue that there should be one, but we don't have it in this example.

390
00:44:37,915 --> 00:44:43,915
And then we have family history of impacts, pneumonia and access to medical care.

391
00:44:44,605 --> 00:44:49,945
All right. So we've got one pathway here, right?

392
00:44:49,945 --> 00:44:56,065
Access to medical care is a confounder pretty typical confounder.

393
00:44:56,065 --> 00:45:00,925
Right. So we're going to adjust for access to medical care.

394
00:45:02,575 --> 00:45:05,905
But what what have we now done? The red arrows gives it away.

395
00:45:08,905 --> 00:45:10,704
We've opened the backdoor path, right?

396
00:45:10,705 --> 00:45:17,725
Because we conditioned on a confounder in the pathway from vaccination to pneumonia that goes through family history.

397
00:45:21,505 --> 00:45:31,825
And so now. I need to drink a glass of water to try to prevent a coughing fit.

398
00:45:33,955 --> 00:45:37,635
We're going to need to do a second adjustment on the way back.

399
00:45:56,515 --> 00:46:03,285
I know there was a strike there. All right.

400
00:46:04,085 --> 00:46:08,115
Back. Sorry about that. Okay. So.

401
00:46:13,275 --> 00:46:17,505
So we had a collider, right? We adjusted her the collider, which was access to medical care.

402
00:46:18,405 --> 00:46:22,095
And by that through that, we then opened up a pathway.

403
00:46:22,425 --> 00:46:28,755
So our choices were to then adjust for either sex or family history to close that back to a pathway.

404
00:46:29,235 --> 00:46:41,385
In this particular case, we adjust for X. All right, so why don't you work on this quickly?

405
00:46:41,625 --> 00:46:47,385
What would you control for in the stag? Our question is, does soda lead to obesity?

406
00:47:55,555 --> 00:48:04,475
I guess we can just vote. Who wants to adjust for us? Just one person who wants to adjust for city of residence.

407
00:48:07,495 --> 00:48:15,815
Who wants to adjust for a visit? A dentist. He's adjusting for multiple things.

408
00:48:16,865 --> 00:48:20,495
Some of you raise your hand, multiply value. So you should be adjusting for multiple things here.

409
00:48:21,515 --> 00:48:27,665
All right. Let's talk about the pathways here. So I like to look at them kind of individually first.

410
00:48:27,665 --> 00:48:31,415
So we've got this right, has a direct here from to soda.

411
00:48:31,565 --> 00:48:34,745
Obesity, very classic confounder here. Right.

412
00:48:34,745 --> 00:48:44,495
So we definitely want to adjust for this. City of residence also has that classic confounder there.

413
00:48:44,495 --> 00:48:48,425
Right? It also you can go from soda to X to city of your residence to obesity.

414
00:48:50,345 --> 00:48:54,305
You can close that pathway by either adjusting for size in city of residence.

415
00:48:54,305 --> 00:49:02,405
But since both assistance in residence costs are is a cause of your whether or not

416
00:49:02,405 --> 00:49:08,675
you or it impacts whether or not you drink soda and whether or not you're obese,

417
00:49:08,705 --> 00:49:14,645
you actually need to adjust for both of these. In this example, what about visit of this dentist?

418
00:49:17,605 --> 00:49:29,815
No. Right. In this case, you would not want to adjust for as to do this because visited in the way you drew the bag.

419
00:49:30,415 --> 00:49:35,035
Right. Drinking soda causes cavities, which causes you've got a deficit.

420
00:49:35,515 --> 00:49:41,335
And obesity here is also related to whether or not you visit a dentist.

421
00:49:41,335 --> 00:49:44,785
Right. So you'd be adjusting for a collider.

422
00:49:45,745 --> 00:49:49,225
And so you would be you wouldn't want to do that.

423
00:49:51,465 --> 00:49:54,885
Um. Any questions about that?

424
00:49:56,835 --> 00:50:00,305
I should probably put an extra one out here to just, you know.

425
00:50:02,045 --> 00:50:07,885
Throw in something extra that like not only does not need to be on the dad, but certainly would not want to adjust for.

426
00:50:10,545 --> 00:50:17,055
All right. So issues with data driven use of confounding the traditional confounder criteria are

427
00:50:17,095 --> 00:50:21,795
insufficient to identify all confounders and may lead to incorrect analysis decisions.

428
00:50:25,575 --> 00:50:28,094
And though the 10% rule says the confounders identified,

429
00:50:28,095 --> 00:50:32,775
if the adjusted estimate differs from the crude by at least 10%, it's not theoretically justified.

430
00:50:32,775 --> 00:50:36,165
It's just somebody was like, Wow, I don't know how much of a difference was low. 10%.

431
00:50:36,675 --> 00:50:37,065
Right.

432
00:50:38,595 --> 00:50:49,335
Basically, the thing to remember is that by following these those kind of traditional rules or going with the 10% rule, you may actually be inducing.

433
00:50:49,335 --> 00:50:53,505
Confounding, right. Rather than adjusting for it and fixing it.

434
00:50:53,805 --> 00:50:59,655
And there's no way to know if you just go through those rules.

435
00:51:01,755 --> 00:51:08,475
So the traditional view of confounding does not always work, since it does not mean confounding as a structural issue.

436
00:51:09,465 --> 00:51:13,365
So here we have an example of bias called in bias.

437
00:51:15,165 --> 00:51:19,095
It's named in bias because of the way that the variables are related to one another.

438
00:51:19,905 --> 00:51:26,565
And this is one of those examples where the investigator here.

439
00:51:27,135 --> 00:51:30,375
Right. Has adjusted for whether has diabetes,

440
00:51:31,005 --> 00:51:38,925
because it's a confounder but has actually induced an open backdoor pathway in this case through two unmeasured variables.

441
00:51:38,925 --> 00:51:42,735
So there's no way for you to adjust for it. Right. That bias is going to stay in your estimate.

442
00:51:49,225 --> 00:51:55,015
So this is a selection bias that is introduced by the investigator because they conditioned on a collider.

443
00:51:55,465 --> 00:52:02,695
Right. And it opens up a back door path from A to Y through U, one, W and you to Fisher.

444
00:52:03,025 --> 00:52:11,455
Now, I've got an association between you wanting me to cause you conditioned on the outcome of those two variables.

445
00:52:14,765 --> 00:52:19,355
All right. And bias is covered in more detail in 824.

446
00:52:20,525 --> 00:52:25,205
Or at least used to be the kid they like who's teaching him 28.

447
00:52:25,265 --> 00:52:31,545
24 has changed. So. Could be updated but should be still in the course.

448
00:52:31,565 --> 00:52:34,715
All right. So quantifying, confounding.

449
00:52:35,915 --> 00:52:43,085
So when we talk about quantifying confounding, we'll look at the non collapse ability of strata when the association of exposure and is different

450
00:52:43,085 --> 00:52:47,365
between the state of a third variable identified as a confounder and the crude association,

451
00:52:47,375 --> 00:52:52,235
the non-traded stratified in the data are not collapsible.

452
00:52:56,395 --> 00:53:03,625
So for reducing compounding, we've got three methods that are used in the study design phase for reducing confounding,

453
00:53:04,735 --> 00:53:11,424
and then three methods that are used in the analytic phase. One thing you will notice for others if you've taken in every class before, right?

454
00:53:11,425 --> 00:53:14,455
We are not talking about interaction in effect modification yet.

455
00:53:14,795 --> 00:53:18,535
So what do you what do you do when when it actually varies by that third variable?

456
00:53:18,865 --> 00:53:21,955
We will talk about that in the next class and kind of bring that all together.

457
00:53:22,495 --> 00:53:28,645
All right. So the three methods during the step, the study design, you can use randomization if that's possible.

458
00:53:28,655 --> 00:53:33,565
Not always possible, right? Restriction or matching also helps to control confounding.

459
00:53:34,435 --> 00:53:41,185
And then the three methods during the analysis phase, you can do a stratified analysis and you can do standardization,

460
00:53:41,185 --> 00:53:45,115
which we've already seen or a multivariable analysis.

461
00:53:45,565 --> 00:53:53,754
These, by the way, are not either or. You'll do a range of the use in any study and actually for matching you usually do have

462
00:53:53,755 --> 00:54:02,935
to do a multivariable analysis depending on the type of matching for randomization,

463
00:54:03,415 --> 00:54:08,965
right? Randomization attempts to equalize differences between groups with respect to known and unknown risk factors for the outcome.

464
00:54:09,565 --> 00:54:15,415
That is, it attempts to remove confounding by May and make the groups exchangeable.

465
00:54:17,155 --> 00:54:17,634
However,

466
00:54:17,635 --> 00:54:29,605
there can be residual confounding with randomization it it may be present even when the randomization was properly performed and compliance is high,

467
00:54:29,905 --> 00:54:33,025
especially true for small studies, but can happen in large studies too.

468
00:54:34,525 --> 00:54:40,825
Thus, confounders should be considered in any analysis for a randomized controlled trials.

469
00:54:44,235 --> 00:54:50,684
So you would question any study that you'd like, older studies you will see often they are not.

470
00:54:50,685 --> 00:54:55,355
They randomize people and then they just don't adjust for any confounders like very old age.

471
00:54:55,365 --> 00:54:58,844
But you'll see more recent papers, even the last 30 years.

472
00:54:58,845 --> 00:55:02,145
Right? They're generally adjusting for potential confounders.

473
00:55:02,565 --> 00:55:09,495
So not necessarily assuming that the randomization dealt with all of that restriction is to

474
00:55:09,495 --> 00:55:15,675
restrict the study so that all persons either have or do not have the possible confounders.

475
00:55:16,965 --> 00:55:22,065
So we're just going to say, like, oh, it's too hard to control for it in a way.

476
00:55:22,815 --> 00:55:26,624
So we will not enroll anybody who's a smoker in our study.

477
00:55:26,625 --> 00:55:30,645
Then we don't have to worry about smoking as confounder and levels of smoking, etc.

478
00:55:31,245 --> 00:55:37,755
So you could limit a study to alcohol drinkers or to nondrinkers you could restrict to males or females, which we see a lot.

479
00:55:38,115 --> 00:55:48,675
So a little bit less now since the it used to be pretty typical that studies were restricted to men quite often.

480
00:55:49,245 --> 00:55:52,304
Right. But there's obviously issues with that.

481
00:55:52,305 --> 00:55:57,945
We still see a lot of issues with kids. Right. Kids are often excluded from randomized controlled trials of treatments.

482
00:55:58,875 --> 00:56:02,465
And so then we don't have any evidence of whether or not that treatment actually works in kids.

483
00:56:02,475 --> 00:56:06,615
So the same thing kind of with males and females, there are important biological differences.

484
00:56:07,185 --> 00:56:12,345
Right. Hormonal differences where where treatments may work differently.

485
00:56:13,695 --> 00:56:19,245
And but women were often being excluded from those trials.

486
00:56:19,515 --> 00:56:25,485
So that's no longer acceptable unless it's scientifically justifiable by the NIH.

487
00:56:26,655 --> 00:56:32,955
Does mean, though, that your study has to be larger, right, to deal with being able to adjust for those differences.

488
00:56:33,795 --> 00:56:38,565
You can also limit to certain age groups. So restriction.

489
00:56:38,565 --> 00:56:41,265
Some of the advantages are straightforward and inexpensive.

490
00:56:42,135 --> 00:56:50,205
Some disadvantages are, though, that you cannot evaluate the relationship between the restricted variable and the variable of interest and outcome.

491
00:56:50,415 --> 00:56:55,365
Right. Because we now restricted it down, it limits eligible participants.

492
00:56:56,355 --> 00:56:59,684
Residual confounding may be present and restriction is not narrow enough.

493
00:56:59,685 --> 00:57:03,375
So if you are restricted to people, you know, 50 to 59,

494
00:57:03,855 --> 00:57:14,505
you could still see an age effect inside that group in restriction of course effects, generalizability, matching, right.

495
00:57:15,455 --> 00:57:18,825
Which is where subjects and controls are matched on confounders.

496
00:57:20,175 --> 00:57:22,635
There's an efficiency in adjusting for confounder.

497
00:57:23,745 --> 00:57:31,665
It's really good for variables that are hard to measure, and it can be especially useful in small studies with multiple possible confounders.

498
00:57:32,775 --> 00:57:37,754
We'll have a whole lecture on matching soon, but briefly,

499
00:57:37,755 --> 00:57:43,245
some of the disadvantages of matching are that it can be difficult and expensive to find a match.

500
00:57:43,255 --> 00:57:50,415
It might reduce the sample size, it may require special analysis or matched analysis or conditional logistic regression.

501
00:57:51,855 --> 00:57:53,665
Depends on how you match going about.

502
00:57:53,685 --> 00:58:01,844
On the matching lecture, you cannot examine the factors matched on and it only controls the variables matched on.

503
00:58:01,845 --> 00:58:10,185
It's difficult to add in other confounders. In a matched analysis you start to lose power quickly stratified analysis.

504
00:58:10,485 --> 00:58:15,165
Right. Another way to deal with confounding relationships of exposure of interest in disease is

505
00:58:15,165 --> 00:58:20,054
examined in strata of individuals with the same exposure in relation to the confounders.

506
00:58:20,055 --> 00:58:25,065
Right. We did that with well we did that in the fluoride example.

507
00:58:28,245 --> 00:58:32,894
By stratifying on a factor it is possible to control for its effect on stratification also

508
00:58:32,895 --> 00:58:36,945
allows for the assessment of the possible presence of interaction or effect modification.

509
00:58:37,815 --> 00:58:43,875
We will go over that next lecture. And so a quick note on terminology.

510
00:58:44,175 --> 00:58:54,195
You will see all of these terms used. I will even sometimes use all of these terms, crude, unadjusted, pooled, those are all the same thing, right?

511
00:58:54,405 --> 00:58:57,615
Adjusted or summary are also the same thing.

512
00:59:00,105 --> 00:59:08,095
So for stratification steps, we're going to divide by our confounder or potential confounder of interest.

513
00:59:08,415 --> 00:59:12,435
Calculate the association of the exposure and the disease within each strata.

514
00:59:13,305 --> 00:59:20,114
Right. Just kind of like we did with that example of the Simpson's paradox example with the hospitals, right?

515
00:59:20,115 --> 00:59:23,835
We did the the good health outcome and the bad health outcome separately.

516
00:59:24,885 --> 00:59:31,995
If the stratum specific measures of association are similar and the stratum specific measures of association are different from the crude,

517
00:59:32,685 --> 00:59:36,645
then you can calculate an adjusted measure of association.

518
00:59:38,775 --> 00:59:47,934
So there's two ways. You mean ways to do this out by hand, which is also used in statistical programs, right?

519
00:59:47,935 --> 00:59:49,945
The manual hands on method and the Wolfe method.

520
00:59:51,865 --> 00:59:58,765
So the Manual Hansell method for adjusting measures of association is a weighted average of the stratum specific measures of association.

521
01:00:00,475 --> 01:00:03,505
This can be done for both relative and absolute measures.

522
01:00:05,485 --> 01:00:11,095
So what does that look like? Here is the manual handle formula for the odds ratio.

523
01:00:12,175 --> 01:00:17,365
Relative risk and risk difference.

524
01:00:18,265 --> 01:00:27,235
Right. Using this this table here. So here's an example.

525
01:00:27,245 --> 01:00:29,915
So I'll go through an example of how you calculate this out.

526
01:00:30,605 --> 01:00:38,045
The Restaurant Collaborative Study Group Data example from June also comes from that same statistics and epidemiology textbook.

527
01:00:38,765 --> 01:00:44,465
So it's a prospective cohort study of employed men in ten Californian companies aged 39 to 59 years old.

528
01:00:45,855 --> 01:00:48,935
Recruitment occurred in 1960 to 1961.

529
01:00:50,105 --> 01:00:56,045
Men were followed for around nine years. It was designed to look at risk factors for incident coronary heart disease.

530
01:00:56,375 --> 01:01:00,305
CHC behavior type was a variable of interest.

531
01:01:00,605 --> 01:01:09,455
So Type A is characterized by aggressiveness and competitiveness in type B is more relaxed and noncompetitive.

532
01:01:12,045 --> 01:01:16,215
Yes. This is where like the type A personality thing comes from is this study.

533
01:01:17,115 --> 01:01:22,934
Right. All right. So we're looking at coronary heart disease.

534
01:01:22,935 --> 01:01:29,745
We've got the behavior type A and B, cumulative incidence ratio, the risk difference and the odds ratio.

535
01:01:29,745 --> 01:01:33,405
You can calculate all of those out from this study. Right.

536
01:01:35,685 --> 01:01:44,375
Because it's a cohort. So we're interested in this is our dad, right?

537
01:01:44,375 --> 01:01:47,795
Behavior type in coronary heart disease disease.

538
01:01:50,135 --> 01:02:00,145
And we postulate that or they postulate that body weight is going to impact both your behavior type and your risk of coronary heart disease.

539
01:02:04,185 --> 01:02:09,555
You could also, though, say, like, maybe it's not it doesn't go that way.

540
01:02:09,555 --> 01:02:14,325
Maybe, in fact, behavior type impacts your body weight, which impacts coronary heart disease.

541
01:02:15,225 --> 01:02:20,264
Right. Or maybe body weight directly impacts coronary heart disease.

542
01:02:20,265 --> 01:02:27,375
But some other unmeasured factor impacts both your behavior type and your body weight.

543
01:02:28,695 --> 01:02:36,345
Anybody have any good hypotheses on what what possible unmeasured factors could impact this?

544
01:02:37,305 --> 01:02:41,535
I think this one's a little bit more probable for the relationship. But.

545
01:02:46,155 --> 01:02:55,635
Genetics, right? You can say, well, maybe genetics is one that could impact both your behavior type and your body weight and childhood experiences.

546
01:02:56,805 --> 01:03:01,185
Another thing you probably think of a bunch of other ones, right?

547
01:03:03,435 --> 01:03:11,174
But remember, when we're kind of thinking about confounding and the proper way to deal with potential confounding, we need to draw out our dags.

548
01:03:11,175 --> 01:03:16,215
So I draw a few different possible dags for how you might postulate it works.

549
01:03:16,245 --> 01:03:20,505
Obviously, if this was your dad, would we want to adjust for body weight?

550
01:03:21,015 --> 01:03:28,395
No, because now we're saying body weight as a mediator. We're going to go with this tag, though, for this example.

551
01:03:31,425 --> 01:03:42,615
So they stratify by body weight and calculate out both the odds ratio and the risk ratio here.

552
01:03:43,965 --> 01:03:56,655
And what you can see is that there is some difference by body weight here across the odds ratio or the risk ratio.

553
01:04:00,345 --> 01:04:04,335
So there may be some confounding by body weight.

554
01:04:08,845 --> 01:04:13,855
So what we're going to do is we're going to calculate a summary statistic right here.

555
01:04:13,855 --> 01:04:18,745
We're doing the odds ratio. So this is the formula, right?

556
01:04:20,275 --> 01:04:26,965
So you need obviously all these strata data here, right?

557
01:04:28,285 --> 01:04:40,975
So here you can substitute n so eight times D divided by N in here is 22 plus ten plus 23 plus 3 to 5.

558
01:04:41,395 --> 01:04:48,985
We end up with 11.373 in the top and then on the bottom 253.

559
01:04:50,215 --> 01:04:57,925
So B times C times ten divided by that same number, you end up with 4.288.

560
01:04:58,645 --> 01:05:02,724
Right. So you'll calculate that out for each trader.

561
01:05:02,725 --> 01:05:09,865
Yes. This is the volume sample. Right. And then you will calculate the total.

562
01:05:10,855 --> 01:05:21,295
So the middle hands will be 82.36, seven over 35.4 or five eight, which is the male handle odds ratio of 2.3 to.

563
01:05:23,445 --> 01:05:31,935
2.3 to 3. Right. So this is just a weighted average, right.

564
01:05:33,585 --> 01:05:39,735
Based on the straight ahead. And here we just have multiple straight up. We end up with what, five straight up for bodyweight?

565
01:05:44,775 --> 01:05:50,355
Of course, you can calculate confidence intervals for me, a handful as well.

566
01:05:51,255 --> 01:05:54,795
And you can think prior students for their evaluations of the course that you will

567
01:05:54,795 --> 01:05:59,325
not be made to calculate a confidence interval for male hands estimate on the exam.

568
01:05:59,835 --> 01:06:06,105
But I do believe there's probably an example still in the assignments for you to go through and do that.

569
01:06:07,305 --> 01:06:12,165
This just kind of walks through how you do that here.

570
01:06:16,105 --> 01:06:19,825
All right. And then we can do the same thing for health risk.

571
01:06:20,545 --> 01:06:25,255
Same process. Right. We're going to calculate out these.

572
01:06:28,465 --> 01:06:35,004
This factor for each strata, for the numerator and denominator,

573
01:06:35,005 --> 01:06:47,745
add them together and then divide it to come up with the mental handle the risk ratio and we get 2.169.

574
01:06:47,755 --> 01:06:57,725
So once again, just a weighted average of the difference rate of. I have a general question what I'm thinking about that, Dag.

575
01:06:57,815 --> 01:07:04,845
We have the unmeasured factors. Like, my thought is like, oh, it's high, high school is there.

576
01:07:05,225 --> 01:07:12,395
And so I guess we do like assessing which thing would seem to me to be like a better variable for this progressivity, this relationship.

577
01:07:13,085 --> 01:07:16,505
So I guess, like, I don't know.

578
01:07:19,055 --> 01:07:25,475
But I guess like in doing that, like, would you like be able to figure out, oh, actually body weight is not a great,

579
01:07:26,805 --> 01:07:31,955
uh, measure here and I have to actually look at height like, is there a way to figure that out?

580
01:07:33,195 --> 01:07:40,844
Um. Well, so what I normally think about like,

581
01:07:40,845 --> 01:07:49,435
like if this is your dog and you're going to say instead of unmeasured factors as its height, you would then put height in here.

582
01:07:49,435 --> 01:07:53,235
And now you want to think about your other unmeasured factors. Right.

583
01:07:53,235 --> 01:07:58,934
So there could still be, you know, genetics that impacts all of it, right?

584
01:07:58,935 --> 01:08:05,145
So you start to think of like drop the full dag and see where you can intervene to

585
01:08:05,175 --> 01:08:10,185
hopefully control all of those back door pathways that exist when you have an exit.

586
01:08:10,185 --> 01:08:14,325
Like if this were just height, there's nothing else. So you have two variables.

587
01:08:14,325 --> 01:08:18,405
You can choose to either variable, or you can choose height or body weight.

588
01:08:24,855 --> 01:08:32,925
If it's like pure body weight, there's probably a little bit less error nowadays in measuring body weight than height,

589
01:08:33,615 --> 01:08:38,215
which is you might find surprising. But that's what I discovered in my studies at least, right?

590
01:08:38,265 --> 01:08:41,685
Because there's something about like a little bit or a like, you know,

591
01:08:41,685 --> 01:08:46,905
you have to like have them like they like measure and then you have them step away and then they step back and you know,

592
01:08:46,935 --> 01:08:50,265
you measure again, although there's some error in body weight, too, because if you don't have them,

593
01:08:51,075 --> 01:08:54,285
you know, they could be wearing different amounts of clothing, etc.

594
01:08:54,585 --> 01:09:01,965
So what you would think about though, in that case is which variable can you measure better?

595
01:09:03,225 --> 01:09:06,794
And you might decide it's not it's not really body weight that you care about.

596
01:09:06,795 --> 01:09:10,095
Maybe it's BMI needed something around muscle mass, you know.

597
01:09:10,815 --> 01:09:17,745
So then you might be using body weight as a proxy for that, but you would draw that band into the bag to kind of take the problem.

598
01:09:21,565 --> 01:09:26,125
But I usually just try to figure out which is the easiest one to measure.

599
01:09:26,305 --> 01:09:29,454
This is like a proxy for a lot of different things.

600
01:09:29,455 --> 01:09:32,245
So if you can control something else that is easily measurable,

601
01:09:32,455 --> 01:09:36,085
sometimes there's something in your dog that you're like, Yeah, that's measured with a ton of error.

602
01:09:36,415 --> 01:09:43,165
That's going to be my last choice for what I what I adjust for when given the choice.

603
01:09:47,405 --> 01:09:50,915
All right. So this just goes through.

604
01:09:51,035 --> 01:09:56,614
The risk difference, right? We have a formula a little bit more complicated, but kind of going through the same thing.

605
01:09:56,615 --> 01:10:00,125
So we'll just calculate out those terms for each strata.

606
01:10:01,025 --> 01:10:09,395
Right. And then add them together, divide, and you end up with the male hands or risk difference.

607
01:10:11,885 --> 01:10:13,475
So that's the male hands, old method.

608
01:10:14,735 --> 01:10:20,315
There's also a Wolfe method for summary estimates averages the individual stratum effects of the measure of effect.

609
01:10:21,155 --> 01:10:26,645
It's going to take into account the differing variability associated with each trait of a specific measure of effect.

610
01:10:27,485 --> 01:10:31,595
The Woolf method is going to be sensitive to cells with zero or small cells.

611
01:10:34,595 --> 01:10:38,855
Here we have you here.

612
01:10:38,855 --> 01:10:50,265
Right. This plus one half is a small sample size, a gesture or zero solid gesture there.

613
01:10:50,735 --> 01:10:59,415
Right. And so this is just that weighting method. And of course, you can do the confidence intervals for these two.

614
01:11:01,775 --> 01:11:07,925
So you just get the fact that this is just a alternate way of doing this or obvious difference.

615
01:11:08,585 --> 01:11:16,205
You can do the confidence intervals here, but I did not actually do that on these slides because I'm not trying to torture you.

616
01:11:16,835 --> 01:11:20,405
All right. So multivariable analysis,

617
01:11:20,715 --> 01:11:26,555
a way to adjust for multiple factors and adjust for confounding many different types

618
01:11:26,555 --> 01:11:34,175
of multi variable analysis and in multivariate sneak snuck in there I should say.

619
01:11:39,115 --> 01:11:46,065
So the types of multivariate analysis, we've got multiple linear regression, so that would be for a continuous outcome.

620
01:11:46,515 --> 01:11:50,945
So blood pressure and birth weight is an example,

621
01:11:51,345 --> 01:11:59,175
multiple logistic regression for dichotomous outcomes or something like death or hospitalization or a COVID 19 case.

622
01:11:59,925 --> 01:12:07,725
Cox Proportional hazards model, which is survival time, right time to event push on regressions for account data.

623
01:12:07,725 --> 01:12:13,395
The number of asthma attacks would be example or number of colds we all get this year.

624
01:12:15,525 --> 01:12:18,555
So those are just different types of analysis.

625
01:12:18,555 --> 01:12:19,845
But you can do.

626
01:12:28,485 --> 01:12:37,665
So for residual confounding, residual confounding occurs when you've adjusted for a confounder, but some confounding remains in the system.

627
01:12:38,715 --> 01:12:40,094
This can occur in two ways.

628
01:12:40,095 --> 01:12:47,265
So one way is that while you've adjusted for measure or you didn't have the data to control for an unmeasured confounder, right?

629
01:12:47,535 --> 01:12:50,745
So the second factor is still leading to some confounding.

630
01:12:51,495 --> 01:12:59,775
So that can always happen. Now you can also get residual confounding because you use a proxy measure.

631
01:13:00,555 --> 01:13:08,325
So this one has an example of X. So if you suppose a confounders unmeasured, do you have a proxy measure for that confounder?

632
01:13:09,105 --> 01:13:18,435
So education would be a proxy for X, for example, since education is related to x, but x includes a lot more than education.

633
01:13:21,255 --> 01:13:24,675
If you chose to control for education as a proxy for us, yes,

634
01:13:25,185 --> 01:13:32,205
you'd be conditioning on only a part of x, and what's left over is then residual confounding.

635
01:13:36,265 --> 01:13:39,235
So four types of confounding. We've got negative confounding, right,

636
01:13:39,235 --> 01:13:48,415
where we underestimate the true association positive confounding or we're overestimating the true association and then qualitative confounding.

637
01:13:48,415 --> 01:13:51,645
Right. An inversion of the true association.

638
01:13:53,745 --> 01:14:04,855
All right. So here we've got example one, we've got an unadjusted risk ratio of 3.5 and an adjusted risk ratio of 1.0.

639
01:14:05,485 --> 01:14:09,745
Right. Is this positive, negative or qualitative?

640
01:14:13,085 --> 01:14:22,475
Compounding. Positive.

641
01:14:22,545 --> 01:14:35,465
Right. Because we're overestimating the effect. What about, for example, number two, positive or negative or positive sample?

642
01:14:35,465 --> 01:14:44,965
Number three. Now this is a protective factor.

643
01:14:44,985 --> 01:14:50,115
So remember that. Are we overestimating or underestimating the effect of the protective factor?

644
01:14:51,345 --> 01:14:57,915
We're overestimating, right. So this would be positive even though it's taking it, you know, towards zero.

645
01:14:59,505 --> 01:15:07,455
Okay. What about number four? Positive, negative or positive?

646
01:15:11,585 --> 01:15:15,205
We will do. Thumbs down for a negative, thumbs up for positive. And we will do it.

647
01:15:15,215 --> 01:15:18,395
We'll go in the middle for qualitative. Thumbs down, right?

648
01:15:18,395 --> 01:15:22,025
Negative. All right. What about number six?

649
01:15:24,705 --> 01:15:28,575
Number five. Sorry, I'm skipping ahead. Negative.

650
01:15:28,575 --> 01:15:38,294
Good. Number six. Negative.

651
01:15:38,295 --> 01:15:48,865
Yep. Number seven. I see some qualitative.

652
01:15:49,015 --> 01:15:52,285
That's qualitative. All right. Number eight.

653
01:15:53,785 --> 01:16:02,305
Qualitative. Right. All right. So this table which we'll go through.

654
01:16:05,615 --> 01:16:07,855
Yeah. This is less like we'll go through it really quickly.

655
01:16:08,515 --> 01:16:13,795
Just goes over the association, the confounder with the exposure and the association of the confounder with the outcome,

656
01:16:14,245 --> 01:16:18,905
the type of confounding and the expectation of the change from the content invested.

657
01:16:19,465 --> 01:16:26,155
So if we have a positive association of the confounder with the exposure or a positive association of the value with the outcome,

658
01:16:26,155 --> 01:16:33,895
we would expect positive, confounding. So the unadjusted will be greater than the adjusted the effect of it.

659
01:16:34,715 --> 01:16:43,765
If we have a positive association of the cofounder with the exposure and negative of the confounder, with the outcome, we expect the negative.

660
01:16:44,455 --> 01:16:47,215
So the unadjusted would be smaller in the adjusted.

661
01:16:49,105 --> 01:16:56,844
And if we have a negative association of the confounder with the exposure and a negative association of the compound over the outcome,

662
01:16:56,845 --> 01:17:05,305
we'd expect positive. So the unadjusted will be larger than the adjusted and then a negative association

663
01:17:05,305 --> 01:17:11,515
of the compound of the exposure in a positive association with the counter. With the outcome we expect negative or the unadjusted.

664
01:17:11,635 --> 01:17:17,004
The adjusted will be larger than the unadjusted. There is a multiplication trick that you can use.

665
01:17:17,005 --> 01:17:23,365
I don't tell. I never tended to use the multiplication trick. I actually wasn't aware of it until I started teaching this class.

666
01:17:23,365 --> 01:17:32,065
Funny enough, I just like think through the associations of which and how I would expect that to impact my effect estimate.

667
01:17:32,545 --> 01:17:36,624
But you can multiply it out so positive.

668
01:17:36,625 --> 01:17:43,495
Ten So positive, because your positive negative times of negative gives you a positive, positive times of negative gives a negative, right?

669
01:17:43,495 --> 01:17:50,905
So if you just want to try these out, it will tell you the direction in which the type of compounding that you get.

670
01:17:56,585 --> 01:17:59,855
All right. And with that, we are done.

671
01:17:59,915 --> 01:18:07,535
Just in time. All right. And stick around for a few minutes at this for any any questions.

