1
00:00:37,550 --> 00:00:41,320
Okay. I think we can start going over the quiz again.

2
00:00:41,330 --> 00:00:45,200
I'm going to do the present. So if you have not finished already, it'll cut.

3
00:00:45,200 --> 00:00:53,530
You are. Oh.

4
00:00:53,620 --> 00:00:58,870
Information bias, confounding and selection bias typically operate in the same direction.

5
00:00:59,590 --> 00:01:07,660
And the answer is false. And the implication of this is if you are trying to do some sort of sensitivity analysis or some sort of a bias analysis,

6
00:01:08,230 --> 00:01:18,280
if you don't think about all of these all at the same time, you might actually be coming up with a worse result in a biased result.

7
00:01:20,360 --> 00:01:28,330
So, you know, the homework assignment for well, you know, you don't need to have completed it before today, but it's due next week.

8
00:01:29,830 --> 00:01:33,610
That will have you deal with information about confounding and selection bias all together.

9
00:01:35,630 --> 00:01:39,770
Okay. So what is Z here?

10
00:01:40,460 --> 00:01:45,680
Z. And this is terminology from the past lecture.

11
00:01:46,400 --> 00:01:56,090
So obviously this is some sort of third variable. And typically when we put parentheses around it, that means we do not measure it.

12
00:01:56,510 --> 00:02:01,250
But Z does mean that we know what it is we would say you if we do not know what it is.

13
00:02:01,760 --> 00:02:04,520
So this would be an unmeasured but known confounder.

14
00:02:05,630 --> 00:02:12,350
And again, people have different kind of traditions for how they how they how they use this, this terminology.

15
00:02:12,350 --> 00:02:15,600
But I think this is kind of more of a standard one and.

16
00:02:16,640 --> 00:02:20,630
Okay. What does this arrow represent?

17
00:02:21,020 --> 00:02:24,980
I think this could be either of these. Misclassification or information bias.

18
00:02:25,730 --> 00:02:30,620
Again, X is like what we want to know. This is, you know, what are your coffee drinking habits?

19
00:02:31,610 --> 00:02:38,220
Do you have diabetes or not? But we don't have perfect access to that information.

20
00:02:38,240 --> 00:02:44,960
Instead, we get it through surveys, we get it through clinical records, and there can be bias in how we ascertain that information.

21
00:02:45,350 --> 00:02:52,580
And so this era of means that, you know, hopefully there's a very strong relationship between what we really want and what we're actually able to get.

22
00:02:54,230 --> 00:03:02,760
But there could be error. There could be bias. Okay.

23
00:03:03,180 --> 00:03:07,020
I was looking through this and I think most of you were able to get it.

24
00:03:07,320 --> 00:03:15,870
I got a value of around 4.43 as well. So what does the P value refer to?

25
00:03:21,470 --> 00:03:27,530
So the first one, the value of the exposure confounder relationship to completely explain away the exposure outcome relationship,

26
00:03:27,530 --> 00:03:32,540
that's not really sufficient because we're not just looking at the exposure confounder relationship.

27
00:03:36,500 --> 00:03:37,850
The values of the exposure, content,

28
00:03:37,850 --> 00:03:43,520
relationship and the confounder outcome relationship would have to be completely explained with the exposure outcome relationship.

29
00:03:44,300 --> 00:03:48,820
Yeah, this is what I would say. What is this occurring person should. Relationship.

30
00:03:51,600 --> 00:03:55,260
Are these just the same thing? This is completely what's inside.

31
00:03:55,740 --> 00:03:59,069
Okay. Yeah.

32
00:03:59,070 --> 00:04:02,680
So thank you. Because I was like, wait, what is what is the difference in this?

33
00:04:02,970 --> 00:04:06,540
So it completely is the correct answer.

34
00:04:06,540 --> 00:04:10,229
So some is incorrect here because, you know,

35
00:04:10,230 --> 00:04:15,600
you could the value could be you could have a confounder which isn't as strong

36
00:04:15,600 --> 00:04:20,130
as what the value of closet which could explain away some of the relationship.

37
00:04:20,520 --> 00:04:28,830
So when I say completely explain away the relationship, that means that, you know, your exposure outcome relationship is no longer significant.

38
00:04:29,130 --> 00:04:32,400
So the e value is like, is there the third variable out there?

39
00:04:32,400 --> 00:04:37,590
Is there this unmeasured confounder or an unknown confounder? Does that exist?

40
00:04:37,920 --> 00:04:42,930
And what value would it need to have to make our main results completely non-significant?

41
00:04:44,760 --> 00:04:51,670
And so the completely is important here. Any questions about any of these questions?

42
00:04:53,850 --> 00:04:57,800
I think you're doing well. Okay.

43
00:04:58,070 --> 00:05:08,150
So today we are going to talk about men and I'll season P hacking.

44
00:05:08,420 --> 00:05:12,020
But first off I found this this tweet and I thought it was really interesting.

45
00:05:12,020 --> 00:05:17,060
So the screenshot in an article and I don't know what article it is,

46
00:05:17,660 --> 00:05:26,240
but this article says that propensity score matching is a statistical technique that deals with unmeasured residual confounding.

47
00:05:28,220 --> 00:05:33,550
And just as a heads up propensity score matching is very similar to what we did with marginal structural models.

48
00:05:33,560 --> 00:05:42,480
It's just like a different type of using propensity scores. Anyone have any idea what?

49
00:05:42,480 --> 00:06:05,639
What's wrong with this quoted text? Silence.

50
00:06:05,640 --> 00:06:13,370
That's okay. So if you remember from our marginal structural model lecture.

51
00:06:13,970 --> 00:06:21,020
Marginal structure model is a deal is a way of dealing with measured confounders, not with unmeasured confounders.

52
00:06:21,020 --> 00:06:29,900
So you cannot use any type of G method, be it marginal structural models or propensity score matching that doesn't deal with unmeasured confounding.

53
00:06:30,980 --> 00:06:33,560
So really the only way to deal with unmeasured confounding?

54
00:06:34,670 --> 00:06:41,420
Well, there's a couple of different ways, but I think through a quantitative bias analysis, that's probably the the biggest thing that you could do.

55
00:06:42,590 --> 00:06:47,030
But this is all to say that people write articles and they say crazy things all the time.

56
00:06:47,030 --> 00:06:52,070
So, you know, just be don't be completely trusting what people put in articles.

57
00:06:56,270 --> 00:07:08,240
So today, I think the big part of today is just like how do we go about understanding things and coming up with with knowledge?

58
00:07:09,050 --> 00:07:15,290
So knowledge synthesis. So in our current system, especially in frequentist statistics,

59
00:07:16,640 --> 00:07:23,900
the problem is that many studies will say that there is a cause and effect relationship, but there actually isn't one.

60
00:07:26,280 --> 00:07:29,640
Or they could see that there's not a cause and effect relationship where there actually is.

61
00:07:32,320 --> 00:07:37,450
So I want us to be especially careful with these words cause and effect.

62
00:07:38,500 --> 00:07:44,440
So let's think about different kind of study designs that are out there.

63
00:07:44,830 --> 00:07:48,010
And, you know, what kind of words could we use with them?

64
00:07:48,490 --> 00:07:51,610
And this goes back to one of our first small group discussions.

65
00:07:51,910 --> 00:07:58,690
I think association and relationship. Those are like pretty vague words as those are pretty ambiguous.

66
00:07:59,020 --> 00:08:06,309
And so those can be kind of used in a variety of settings regardless of how much how much

67
00:08:06,310 --> 00:08:10,240
weight you want to place towards the causality and towards the methods that you have.

68
00:08:12,100 --> 00:08:17,080
I also think the word impact is fine, like saying the impact of coffee drinking on diabetes.

69
00:08:17,530 --> 00:08:22,870
I think that's okay. But I will say that sometimes I've used that word before and peer reviewers have not really

70
00:08:22,870 --> 00:08:27,400
liked it because they think it infers some sort of or implies some sort of causality.

71
00:08:29,200 --> 00:08:33,129
So if we're thinking about different types of things like observational studies,

72
00:08:33,130 --> 00:08:37,450
randomized controlled trials, causal inference methods, meta analysis, you know,

73
00:08:37,450 --> 00:08:42,879
I would say cause and effect are something that we should be careful about and maybe only use in

74
00:08:42,880 --> 00:08:48,760
a well-designed meta analysis where we're able to incorporate a number of different studies.

75
00:08:50,170 --> 00:08:56,409
I will say that, you know, sometimes people will use cause and effect with with with certain causal inference studies.

76
00:08:56,410 --> 00:09:00,730
They might use it in randomized controlled trials. And I think that's okay much of the time.

77
00:09:01,810 --> 00:09:06,160
But, you know, it might be in some situations that we only want to use it with meta analysis.

78
00:09:06,700 --> 00:09:12,069
So there is some ambiguity in this table. I think it's important for you to understand, like especially where the holes are,

79
00:09:12,070 --> 00:09:15,160
like we don't want to be using cause and effect with observational studies,

80
00:09:15,490 --> 00:09:21,970
but there is some discussion in the literature and among researchers about how we should be using words like impact, effect and cause.

81
00:09:22,870 --> 00:09:27,400
But I see that especially because, you know, when I read a lot of students work,

82
00:09:27,760 --> 00:09:32,440
sometimes they will use these words constant, in fact, more often than they maybe should be.

83
00:09:32,650 --> 00:09:37,780
And just a reminder that, you know, association relationship can be used in very similar settings.

84
00:09:37,780 --> 00:09:40,960
And those are kind of the things that you probably should be using instead.

85
00:09:42,700 --> 00:09:47,620
So Effect has an absence here because you can use words like effect modification or effect measure modification.

86
00:09:47,620 --> 00:09:54,910
That's totally fine. You can use that in a situation or study. Sometimes people will say like an aim.

87
00:09:54,970 --> 00:09:59,440
Like our aim is to estimate the effect of coffee, drinking on diabetes.

88
00:10:01,270 --> 00:10:07,659
And maybe then in your methods and your results, you talk about how this is just more of an observational thing.

89
00:10:07,660 --> 00:10:13,720
You're only able to look at associations. I probably would still stay away from using effects, even in like an aim.

90
00:10:16,810 --> 00:10:21,940
Okay. So knowledge synthesis, what are the different types of knowledge synthesis which are out there?

91
00:10:22,300 --> 00:10:27,040
There are things like literature reviews, narrative reviews, systematic reviews, meta analysis and scoping reviews.

92
00:10:28,630 --> 00:10:36,820
So what do these all mean? I would say, like the most general and the easiest to do would be the literature review and a little reviews maybe.

93
00:10:36,820 --> 00:10:40,719
But you. Well, I'm sure all of you at this point in time have done a literature review.

94
00:10:40,720 --> 00:10:44,620
If you're writing a paper, maybe you're wanting to do a literature review of a topic.

95
00:10:45,370 --> 00:10:52,870
So you just kind of type in some keywords on Google Scholar or PubMed, you look through a few different articles.

96
00:10:53,500 --> 00:10:54,490
That's, that's a literature.

97
00:10:55,750 --> 00:11:05,080
And if you're working with, if you for your alley or for some sort of research project, you might be getting paid for this semester.

98
00:11:05,350 --> 00:11:08,200
There might be something that your advisor is having to do.

99
00:11:09,160 --> 00:11:16,990
A narrative review, I would say is kind of pretty much the same thing as the literature review.

100
00:11:17,230 --> 00:11:25,690
The difference is that a narrative review is when somebody's an expert in the field is doing a literature review.

101
00:11:27,130 --> 00:11:32,560
So what would happen in the past, maybe, you know, decades ago is the journal would,

102
00:11:32,950 --> 00:11:38,049
you know, call up somebody who was a famous scientist in the field and say,

103
00:11:38,050 --> 00:11:43,390
oh, can you write a paper like, you know, your thoughts on the state of knowledge of a topic?

104
00:11:45,250 --> 00:11:52,090
So basically that person would, you know, probably highly cited some of their own research, but to kind of do their own literature review.

105
00:11:52,660 --> 00:12:00,190
So, you know, I to be honest, I don't think there's much of a a big scientific difference between a lecture review and a narrative review.

106
00:12:00,190 --> 00:12:05,740
Except, again, a negative review is not when a student is doing it, but like one, not when a professor is doing it.

107
00:12:06,670 --> 00:12:14,200
And I think that we see very few little reviews and negative reviews being published in the in the literature anymore,

108
00:12:14,200 --> 00:12:18,070
just because they're not that there are some biases which come up with them.

109
00:12:19,030 --> 00:12:27,370
Although I will say early on in the COVID 19 pandemic, I worked on what we called the rapid literature review of COVID 19 with some colleagues,

110
00:12:27,370 --> 00:12:31,659
and that passed through the peer review process just as it was very early on.

111
00:12:31,660 --> 00:12:35,680
And we wanted to get this information out there. And doing systematic reviews takes a lot of time.

112
00:12:37,240 --> 00:12:43,360
Okay. So a systematic review is when we add some when we're doing things a bit more systematically, as the name implies.

113
00:12:43,360 --> 00:12:50,770
So it's not just typing in random words in a in a Google Scholar search and hoping that they come up with something.

114
00:12:51,010 --> 00:12:53,589
It's, you know, it's thinking thoughtfully.

115
00:12:53,590 --> 00:13:03,489
Both those words are you probably will have, you know, ten, 20 words which are going to be in your your search.

116
00:13:03,490 --> 00:13:08,980
And there will be a lot of like hands and pause and parentheses just to make sure that you are doing things correctly.

117
00:13:09,280 --> 00:13:12,430
You probably will be working with the librarians to come up with your search terms.

118
00:13:12,730 --> 00:13:16,750
So, you know, there's systematic, nice in how you are searching for things.

119
00:13:19,440 --> 00:13:25,400
A meta analysis is a type of systematic review where we pull together data.

120
00:13:25,410 --> 00:13:29,040
So in a systematic review you could just say, oh, there are 20 studies which looked at coffee,

121
00:13:29,040 --> 00:13:33,770
drinking and diabetes, and you can kind of just summarize their results with the meta analysis.

122
00:13:33,780 --> 00:13:40,350
This is where you actually collect the the data or at least like kind of the risk ratios of the odds ratios from those studies.

123
00:13:40,680 --> 00:13:43,710
And then you incorporate them and you kind of do some analysis of your own.

124
00:13:46,280 --> 00:13:50,930
So a scoping review, I would say it's a subset of a systematic review.

125
00:13:51,020 --> 00:13:55,190
And the difference between them is not super, super clear to me,

126
00:13:55,190 --> 00:14:00,470
but a scoping review is more so looking at what is the state of literature and potentially what's missing from the literature.

127
00:14:00,710 --> 00:14:04,790
Whereas the systematic review is like defining what is actually in the literature or scoping review

128
00:14:04,790 --> 00:14:09,110
as maybe being a bit more preliminary about what do we exactly know and what don't you know?

129
00:14:12,130 --> 00:14:18,850
Okay. So when you were doing a systematic review, one of the things that you should be doing is using multiple databases.

130
00:14:18,890 --> 00:14:22,990
So, for instance, I know we all love Google Scholar.

131
00:14:23,000 --> 00:14:27,190
I use it, you know, weekly, if not daily.

132
00:14:28,750 --> 00:14:35,469
It's very easy to find things through Google Scholar, especially things which might be called the gray literature.

133
00:14:35,470 --> 00:14:42,580
In the gray literature are things which aren't peer reviewed but could be various technical reports or policies,

134
00:14:43,900 --> 00:14:48,400
or there are some journals which are not peer reviewed, or there might be abstracts from conferences, things like that.

135
00:14:48,610 --> 00:14:56,170
Show up in Google Scholar. The problem with Google Scholar is that Google's search algorithm is proprietary, and we don't really know how they do it.

136
00:14:56,470 --> 00:15:02,500
So if you're thinking about how a systematic review has to be like systematic and we need to be able to replicate the results,

137
00:15:03,460 --> 00:15:09,280
that's hard to do with Google Scholar. So because, you know, in the future, basically what should happen is if you do a systematic review,

138
00:15:09,280 --> 00:15:16,240
somebody should be able to take your exact methods in your search terms and be able to use your databases and find the same articles that you did.

139
00:15:16,690 --> 00:15:19,930
Whereas with Google Scholar, it's kind of unclear how that would that would happen.

140
00:15:20,530 --> 00:15:25,360
But there are, you know, other databases out there like PubMed puppet.

141
00:15:25,590 --> 00:15:30,730
You might hear the word Medline. This used to kind of be separate, but now Medline is incorporated into PubMed.

142
00:15:31,240 --> 00:15:41,680
There's also the same citation index. The library here at the University of Michigan has a database of all these different databases.

143
00:15:42,070 --> 00:15:45,330
So that's also a place that you could look to.

144
00:15:47,560 --> 00:15:55,090
So my tip for you, if you have not done this already, is to link to the databases through the University of Michigan's library.

145
00:15:55,480 --> 00:16:03,070
So I actually just have these links in my browser. So, you know, when I go to Google Scholar, I don't type in like Scholar Google.com.

146
00:16:03,400 --> 00:16:04,960
I click on this link in my browser.

147
00:16:05,320 --> 00:16:12,160
And that just means that I will have already been logged in through the University of Michigan and I will have easier access to full text articles.

148
00:16:12,160 --> 00:16:19,750
Whereas, you know, if you just go straight to Google Scholar, you won't necessarily be able to find those PDFs all the time.

149
00:16:23,760 --> 00:16:25,860
Okay. So met analysis. Like I said,

150
00:16:25,860 --> 00:16:36,330
this is where we are combining data from previously published studies and we're creating a pooled estimate and we have to use multi-level methods.

151
00:16:36,600 --> 00:16:42,600
Basically what we're trying to say is that each of these different studies, maybe we found ten different studies on coffee, drinking and diabetes.

152
00:16:42,990 --> 00:16:45,690
We will want to account for clustering.

153
00:16:45,690 --> 00:16:50,580
So basically people who showed up in one study will be different than those who showed up in a different study.

154
00:16:50,880 --> 00:16:55,220
And we should account that account for that through our methods.

155
00:16:58,040 --> 00:17:02,780
Okay. So what kind of graphs can you put in meta analysis or what kind of analysis can you do?

156
00:17:03,450 --> 00:17:07,309
Um, there's pictures and we'll be talking about that in the last half.

157
00:17:07,310 --> 00:17:10,910
The class, we'll skip over that for now. There are forest plots.

158
00:17:10,910 --> 00:17:14,150
Forest plots. Look at the heterogeneity of results.

159
00:17:15,110 --> 00:17:21,710
And one of the statistical items or outputs you can have from a forest plot is the Higgins Square test,

160
00:17:22,100 --> 00:17:26,329
which is just a test of whether something is heterogeneous or homogeneous.

161
00:17:26,330 --> 00:17:33,410
So the null value for that, the null hypothesis is that there is homogeneity of results.

162
00:17:33,770 --> 00:17:38,300
If you get a significant value for the Higgins XYZ for a test, the results are heterogeneous.

163
00:17:38,900 --> 00:17:44,000
So what that means is when you do a systematic review, you probably want your results to be homogeneous.

164
00:17:44,630 --> 00:17:49,940
Heterogeneity would mean that the studies are different or there's something like different about each of these studies,

165
00:17:50,180 --> 00:17:54,620
or like the results from one study don't necessarily map onto the results of another study.

166
00:17:54,860 --> 00:17:58,700
So you can't really pool results like you only want to pull results if they're homogeneous.

167
00:18:00,290 --> 00:18:04,220
And again, we'll have an example of that in a few minutes.

168
00:18:04,940 --> 00:18:08,240
Funnel plots look at the symmetry of results.

169
00:18:08,930 --> 00:18:14,390
And the reason why we look at the symmetry of results is it's a visual way of looking at are we missing anything?

170
00:18:15,230 --> 00:18:21,800
And by missing anything, like, are there any papers out there in the universe which we did not incorporate into our systematic review?

171
00:18:22,280 --> 00:18:30,260
And if there is an issue with if symmetry, if there are missing papers, then we call that reporting bias.

172
00:18:30,560 --> 00:18:37,070
And reporting bias is like reporting as in it wasn't reported in our systematic review.

173
00:18:39,020 --> 00:18:44,480
So it's not like a social desirability bias. This isn't like, you know how people are reporting answers.

174
00:18:45,110 --> 00:18:51,740
The reporting here is what is going on in between us, like the actual studies which are out there.

175
00:18:51,860 --> 00:18:58,009
And then what are we find in for a systematic review in the way you test for that is through an adverse test.

176
00:18:58,010 --> 00:19:07,310
So if they exist, the null hypothesis for an adverse test is that there is symmetry of results, that there is no reporting bias.

177
00:19:07,790 --> 00:19:15,290
If we reject the null hypothesis, then we might see that there is there is some degree of reporting bias.

178
00:19:16,490 --> 00:19:19,550
And again, we will go over these in detail.

179
00:19:19,970 --> 00:19:22,220
The examples today are from these links.

180
00:19:22,220 --> 00:19:29,270
I would recommend you do not click on these because I did change some of the questions so you might get a bit confused.

181
00:19:30,110 --> 00:19:33,950
I will also say that these examples come from a clinical journal.

182
00:19:34,790 --> 00:19:42,800
So Sedgwick is writing to a clinical audience. So, you know, doctors, physicians, nurse practitioners, so on and so forth.

183
00:19:43,070 --> 00:19:48,469
And they kind of use slightly different language. And I wanted to leave some of that in just for us to talk about.

184
00:19:48,470 --> 00:19:53,120
But if you're a bit confused by some of the questions, that's okay. We will we will talk about them.

185
00:19:54,800 --> 00:20:00,200
But the first thing that I want you to do in your groups is to review these forms of thought.

186
00:20:00,200 --> 00:20:10,820
So in the Google drive, there is a there is a write up about these first plots and then there is this graph as well.

187
00:20:11,120 --> 00:20:14,029
And then there are these true and false questions.

188
00:20:14,030 --> 00:20:18,260
I would love for you to discuss them with your group and I will go round to each group and you know,

189
00:20:18,470 --> 00:20:22,460
have you explain why you think it's true or false. So each group will respond to at least one of these.

190
00:20:23,300 --> 00:20:31,820
I will also put the pool everywhere up for you to individually respond to what you think your answer is for each of these.

191
00:20:32,660 --> 00:20:36,370
So I will give you maybe 10 minutes to read through that.

192
00:20:37,370 --> 00:20:42,230
Any questions? Also, where is the attendance sheet?

193
00:20:44,330 --> 00:20:47,720
Okay. Does anyone need the attendance sheet? Okay.

194
00:20:47,750 --> 00:20:52,190
Yeah, if you could pass that around. Okay.

195
00:21:12,270 --> 00:21:21,959
Okay. So this is a study looking at each pylori eradication in gastric cancer.

196
00:21:21,960 --> 00:21:28,100
And, you know, the idea is that each pylori is a bacteria which could cause cancer.

197
00:21:28,110 --> 00:21:32,790
So, you know, is eradicating it like through the use of some antimicrobial therapy.

198
00:21:32,820 --> 00:21:37,980
Is that what is important for reducing the risk of gastric cancer?

199
00:21:39,980 --> 00:21:42,800
Okay. Well, we start in this corner over here.

200
00:21:43,400 --> 00:21:50,870
First question, all six trials showed a significant difference between eradication, therapy and controlled treatment in the risk of gastric cancer.

201
00:21:51,410 --> 00:22:06,460
What do you say and why? Yeah, exactly.

202
00:22:06,470 --> 00:22:15,260
So, you know, falls and we see these confidence intervals all go across one and we can see that visually or numerically here.

203
00:22:15,260 --> 00:22:17,479
You know, they could have had a p value or something,

204
00:22:17,480 --> 00:22:27,080
but I think it's pretty obvious to see that all of these cross one proc freaks, the forest plot is drawn on a logarithmic scale.

205
00:22:27,080 --> 00:22:37,699
True or false? Yeah.

206
00:22:37,700 --> 00:22:43,400
And I mean, like, you can kind of eyeball it because, you know, like these numbers are not equidistant.

207
00:22:43,400 --> 00:22:48,290
Like the distance between five and ten is certainly, you know, less than two and five.

208
00:22:50,330 --> 00:22:53,590
And like you said, this is what you'd want to do for the risk ratio.

209
00:22:53,600 --> 00:22:56,600
So any time you have a ratio measure, you want things on a logarithmic scale.

210
00:22:58,660 --> 00:23:01,510
Okay. Let's go here in front fun frequencies.

211
00:23:01,600 --> 00:23:09,610
A risk ratio greater than one indicates an increased risk of gastric cancer with the control treatment compared with eradication therapy.

212
00:23:09,610 --> 00:23:17,960
True or false? And why? It would indicate increased risk.

213
00:23:20,710 --> 00:23:29,110
Yeah. So I mean, I think this is probably the thing which people will get confused about the most.

214
00:23:31,070 --> 00:23:35,830
And of course not. Okay. So what we see here.

215
00:23:36,820 --> 00:23:44,260
Yeah, I think some people get caught up in this word like favors, control and favors eradication.

216
00:23:44,260 --> 00:23:50,860
And this is very clinically oriented and maybe this is even British oriented with their spelling and whatnot.

217
00:23:51,670 --> 00:23:56,800
But favors control would mean that we would say that you do not need you could

218
00:23:56,810 --> 00:24:00,789
use the placebo like you don't need to do the eradication therapy favors.

219
00:24:00,790 --> 00:24:07,300
Eradication means that you should be doing the eradication therapy and you know, with any risk ratio,

220
00:24:07,300 --> 00:24:18,430
what we're trying to say is like the risk in the eradication group over the risk in the control group.

221
00:24:20,350 --> 00:24:28,030
So if this number is greater than one, then we, you know, prefer the just to do the placebo or just not do anything at all.

222
00:24:29,930 --> 00:24:34,770
Any questions about that? Okay.

223
00:24:35,230 --> 00:24:38,780
Um, let's just move over here to me.

224
00:24:39,840 --> 00:24:45,059
The total overall estimate of the population risk ratio indicated that the eradication

225
00:24:45,060 --> 00:24:48,930
therapy led 2.66 times the risk of gastric cancer compared to the control group.

226
00:24:50,390 --> 00:24:54,010
So that's because that's what's going to happen in the.

227
00:24:55,710 --> 00:25:01,350
Yeah. Yeah. And again, so the idea here is that in a meta analysis,

228
00:25:01,350 --> 00:25:13,559
you can pool all of this data together and you can come up with this like composite number and it can be like relatively tiny confidence intervals.

229
00:25:13,560 --> 00:25:17,520
And that's just because we have more data than any one of these individual figures.

230
00:25:17,970 --> 00:25:23,930
So intuitively, I hope that makes sense. Okay.

231
00:25:24,370 --> 00:25:31,480
Tim progress. Significant heterogeneity existed between the sample estimates of the population risk ratio for gastric cancer.

232
00:25:39,440 --> 00:25:46,590
And what did you look at for the false? Yeah.

233
00:25:48,840 --> 00:25:57,899
So the test for heterogeneity we have a P value associated with that in that is point six in the null hypothesis here is that there is homogeneity.

234
00:25:57,900 --> 00:26:01,290
So you know, we would reject or we would not reject the null hypothesis.

235
00:26:01,860 --> 00:26:10,889
The Hagans, I swear, is just kind of like a continuous measure of like how much heterogeneity there possibly could be, you know, from zero, 100%.

236
00:26:10,890 --> 00:26:14,879
So, you know, this this is obviously a 0%.

237
00:26:14,880 --> 00:26:19,740
So there is like no heterogeneity that they detect. But if it were higher than that, simply you might see.

238
00:26:21,170 --> 00:26:29,750
So I think this this is like a very compelling story told by hazmat analysis because each of the individual studies didn't show significant results.

239
00:26:30,380 --> 00:26:35,420
And in some cases they showed that like maybe the control is better,

240
00:26:35,420 --> 00:26:40,580
like maybe a placebo or maybe like doing nothing at all is better for gastric cancer outcomes.

241
00:26:41,720 --> 00:26:49,280
But when we pooled these data together, we have more statistical power and we can get like a more robust estimate.

242
00:26:50,960 --> 00:26:59,000
And beyond that, we can test within our study of like, are there differences across these across these individual studies?

243
00:26:59,000 --> 00:27:02,390
And we're not seeing that. We're seeing that these are homogeneous.

244
00:27:02,660 --> 00:27:07,100
And I think you can see that just visually the confidence intervals kind of encompass each other.

245
00:27:07,490 --> 00:27:14,090
So basically the problem is that in these previous studies, there just was a lack of enough data.

246
00:27:14,330 --> 00:27:22,459
There just weren't enough people. And really the the only study which showed comparable results is these.

247
00:27:22,460 --> 00:27:28,640
Like you go in more studies where and I'm sure this is just like a longitudinal study where they're, they're following with people over time.

248
00:27:29,960 --> 00:27:34,430
And you see so in the study, which has the most people, this is where you're seeing the most comparable results.

249
00:27:37,080 --> 00:27:49,420
It's one time. One thing that you'll often see in these four spots are like the size of this interval is inversely proportional to the variance.

250
00:27:49,750 --> 00:27:55,240
So like here. So the larger the confidence interval is, the smaller the dot will be.

251
00:27:56,290 --> 00:28:01,960
And that's just another visual reminder of like how much weight is given to this study.

252
00:28:02,410 --> 00:28:08,350
So oftentimes in in these studies, when you are combining multiple data sets together,

253
00:28:08,800 --> 00:28:17,080
you will you will provide less weight to those studies which have wide conference intervals.

254
00:28:20,280 --> 00:28:25,610
Any other questions about this forest, but. Okay.

255
00:28:25,790 --> 00:28:30,560
Then let's move on to the next one, which is looking at funnel plots.

256
00:28:30,560 --> 00:28:36,402
And again, I'll give you about 10 minutes to go over that with your. Not.

257
00:28:44,090 --> 00:28:47,720
So this is all about blood pressure tests.

258
00:28:47,750 --> 00:28:55,540
And I think what the researchers. We're trying to do.

259
00:29:03,930 --> 00:29:08,040
So we're trying to reduce blood pressure.

260
00:29:08,080 --> 00:29:13,409
We're trying to reduce hypertension. So, you know, obviously, that's that's a very important thing.

261
00:29:13,410 --> 00:29:16,620
And you can measure systolic blood pressure. You can measure diastolic blood pressure.

262
00:29:17,730 --> 00:29:20,250
Okay. Let's start with the first question.

263
00:29:20,250 --> 00:29:29,250
Failure to include in the meta analysis, all of the relevant trials that have been conducted may have been due to reporting bias.

264
00:29:30,770 --> 00:29:41,330
Dan, what do you have to say? Yeah.

265
00:29:41,340 --> 00:29:48,030
So these first two ones are. I will discuss both them after we get to the second one.

266
00:29:48,030 --> 00:29:51,630
So. Wagner, what do you have to say about b a funnel plot?

267
00:29:51,630 --> 00:29:57,600
Can I suggest whether relevant trials were not included in the meta analysis only as a result of publication bias?

268
00:29:58,020 --> 00:30:01,550
Careful. And this isn't something we super discussed.

269
00:30:01,560 --> 00:30:10,850
So it's okay if you're kind of going out on a limb here. Any particular reason why?

270
00:30:10,860 --> 00:30:14,350
Or is it just a. But.

271
00:30:21,210 --> 00:30:26,390
Yeah. So this is something which, you know, we didn't discuss as a class.

272
00:30:26,400 --> 00:30:30,300
This is like you're kind of your first time learning about this.

273
00:30:30,300 --> 00:30:36,600
But when we think about reporting bias, reporting bias is.

274
00:30:39,810 --> 00:30:53,340
You know, any reason for the reporting bias is kind of looking at like all studies ever conducted and those that are included in your analysis.

275
00:30:54,420 --> 00:30:57,870
So this this arrow here is the reporting bias.

276
00:30:57,890 --> 00:31:07,620
So if there's any problem with, you know, how you been able to include all studies related to a topic that would be reporting bias.

277
00:31:07,650 --> 00:31:12,900
So to answer a you know, I would also say true.

278
00:31:13,290 --> 00:31:20,820
And the idea here is that reporting bias means that not all the relevant trials were included.

279
00:31:23,980 --> 00:31:28,930
But one thing that, you know, I have not mentioned is that there's different types of reporting bias.

280
00:31:29,290 --> 00:31:32,020
One of them is called publication bias.

281
00:31:37,420 --> 00:31:51,220
So publication bias happens when journals don't want to publish publish papers which like go against the status quo or which,

282
00:31:51,220 --> 00:31:54,910
you know, aren't significant for. So for whatever reason, like the Journal doesn't want them.

283
00:31:56,710 --> 00:32:05,830
So that could be bias. So like, if the Journal isn't publishing them, then we're just like not going to get them in our ah ah ah review.

284
00:32:07,210 --> 00:32:15,550
Another type of reporting bias could be a citation bias because part of a systematic

285
00:32:15,550 --> 00:32:20,500
review is that you will review the work cited section of each of the papers.

286
00:32:20,980 --> 00:32:25,630
So if there are certain papers which just are like being cited a lot, you're more likely to include them.

287
00:32:25,900 --> 00:32:33,790
If a paper isn't going to be cited as much, then you might miss it in that review of the of the reference list of different papers.

288
00:32:34,150 --> 00:32:43,570
There could be a language bias in that, like maybe you are only including English language articles and maybe you know the Spanish

289
00:32:43,570 --> 00:32:46,840
language or the Chinese language articles are the ones which are showing different results.

290
00:32:47,530 --> 00:32:53,170
That could be something. Another type of reporting bias could be like a time lag bias.

291
00:32:54,960 --> 00:32:59,900
I don't know if that like is absolutely necessary. So there's two issues here.

292
00:32:59,920 --> 00:33:04,960
One is that generally in a systematic review, you will define or you have to define,

293
00:33:05,230 --> 00:33:09,010
you know, what is the time period for you searching for publications?

294
00:33:09,580 --> 00:33:17,830
And you can, you know, maybe you put a hard stop at like 2000 or 1990 and you're just not going to look at things prior to that.

295
00:33:18,070 --> 00:33:23,920
But maybe prior to that period there were papers out there which showed a different association.

296
00:33:24,610 --> 00:33:29,829
Time like also can refer to the fact that sometimes if you've have results which are against

297
00:33:29,830 --> 00:33:36,070
the status quo or which are not significant or you know which which for whatever reason,

298
00:33:36,790 --> 00:33:39,820
some studies might just take a bit longer to be published.

299
00:33:40,990 --> 00:33:46,300
And so the timeline could also refer to, you know, this this paper is under review somewhere.

300
00:33:46,630 --> 00:33:53,890
So it's not in the public literature, but like it's out there, but we just aren't able to get it through our systematic review.

301
00:33:56,020 --> 00:34:00,940
So again, this is, you know, my first time talking to you about this.

302
00:34:00,940 --> 00:34:04,210
So it's okay if this be kind of tripped you up.

303
00:34:04,720 --> 00:34:12,579
But here is just seeing only as a result of publication by so it's kind of saying that this is the only type of reporting bias,

304
00:34:12,580 --> 00:34:18,340
whereas there's all these other ones as well. So this one would be false.

305
00:34:21,780 --> 00:34:27,509
Which is all to say, like these plots right here, these funnel plots have to do with reporting bias.

306
00:34:27,510 --> 00:34:31,739
And probably publication bias is the predominant reason for reporting bias.

307
00:34:31,740 --> 00:34:37,150
But there's these other things as well. Okay.

308
00:34:37,810 --> 00:34:43,030
Let's move to heterogeneity the funnel plots versus all in diastolic blood pressure.

309
00:34:43,420 --> 00:34:49,150
Indicate that not all of the relevant trials have been that have been conducted where identified.

310
00:34:59,070 --> 00:35:03,150
Do any thoughts on this in the back or are you confused?

311
00:35:03,900 --> 00:35:22,770
Which is okay? Okay.

312
00:35:22,830 --> 00:35:30,420
Well, let's talk about then. So the systolic blood pressure, we have a p value of 0.038 for diastolic blood pressure.

313
00:35:30,420 --> 00:35:35,760
We have a value of 0.095. So let me talk through what an aggregate test actually is.

314
00:35:35,760 --> 00:35:45,390
So an Eggers test is actually just a linear regression of these two values, like your your outcome or whatever and your variance.

315
00:35:46,500 --> 00:35:56,790
So in Eggers test is just the slope. So, you know, maybe the slope is like here and maybe it's closer to like this.

316
00:35:59,790 --> 00:36:03,810
So this is what the Eggers test is. The Eggers test is the slope linear regression.

317
00:36:08,070 --> 00:36:18,780
And what this Eggers test is saying is that it is significant for systolic, but it is not significant for diastolic.

318
00:36:19,800 --> 00:36:25,650
So what it's saying is that there is a significant slope here, but there's not a significant slope for diastolic blood pressure.

319
00:36:28,110 --> 00:36:39,960
And the slope indicates that there's no that there is not symmetry because like, if there is a perfectly even value,

320
00:36:39,960 --> 00:36:44,580
if this is like just straight across, that would mean that there it's completely symmetrical.

321
00:36:46,930 --> 00:36:52,540
Whereas like the more that there is like an actual slope, that would be that there's like no symmetry.

322
00:36:53,760 --> 00:36:58,810
So I mean, what that, what this is saying, which, you know, is kind of a bit convoluted,

323
00:36:59,770 --> 00:37:04,460
it's saying that we identified all the studies for is diastolic blood pressure but we did not.

324
00:37:04,510 --> 00:37:12,390
For systolic blood pressure. So maybe an easier way of thinking about this is that the last question is.

325
00:37:17,140 --> 00:37:21,940
Okay. I guess this kind of goes into the D as well. So I'll just talk through that for a moment.

326
00:37:21,940 --> 00:37:27,790
But the thing about visualizing these plots is to think about like where is the missing?

327
00:37:28,180 --> 00:37:35,410
Where are the missing studies, if any? And for me, the missing studies, because, you know, we want things to be completely symmetrical.

328
00:37:35,710 --> 00:37:38,710
The missing study would be like around here or here.

329
00:37:39,070 --> 00:37:44,790
And I would argue even like for here. Does that make sense?

330
00:37:44,790 --> 00:37:52,290
Like what we're trying to do is like, how would we create a perfectly symmetrical result or a reasonably symmetrical result?

331
00:37:53,460 --> 00:37:58,480
And that would be by finding these. So what this funnel plot is saying is that these studies are out there.

332
00:37:59,280 --> 00:38:05,490
But through reporting bias, they're just not in our study. They're not in our media houses.

333
00:38:08,420 --> 00:38:13,400
But the added layer to this is the Eggers tester saying that this actually is significant, that these ones are actually out there.

334
00:38:13,730 --> 00:38:18,320
The are one is saying that like, oh, this one storm that we identified everything,

335
00:38:19,400 --> 00:38:24,350
which is a bit nonsensical because this seems like should be, you know, relatively equivalent.

336
00:38:25,370 --> 00:38:28,970
But again, just, you know, whenever you have a p value, take it with a grain of salt.

337
00:38:29,780 --> 00:38:34,340
I would say visually, this is like a stark reminder that we are lacking some data.

338
00:38:37,740 --> 00:38:45,480
So again, the process is just like a nice way of figuring out like, are we missing studies in our analysis?

339
00:38:45,510 --> 00:38:53,490
Any questions about that, though? Yep.

340
00:38:53,670 --> 00:38:58,240
Good luck. I just like the studies.

341
00:38:59,040 --> 00:39:02,580
Just talk to me about this.

342
00:39:05,100 --> 00:39:09,120
Yeah. And I mean, so what this is saying, it's like, what? Where where are these studies?

343
00:39:10,140 --> 00:39:15,630
So maybe these studies were conducted years ago and just, like, never were published.

344
00:39:16,410 --> 00:39:24,660
Maybe the authors did them in a different language. Maybe the authors tried to publish these, but then just were unable to because, you know,

345
00:39:24,660 --> 00:39:31,590
maybe the dogma is that like you should have a positive mean difference and a negative one just wouldn't make any sense.

346
00:39:31,980 --> 00:39:35,010
So that's the idea here. And I did conceptually.

347
00:39:35,010 --> 00:39:42,989
It's like weird to kind of think about like, how do we know that these studies haven't been conducted in like maybe thinking across time,

348
00:39:42,990 --> 00:39:47,250
maybe these studies are being conducted right now and just like the results haven't come out yet,

349
00:39:49,230 --> 00:39:53,260
but generally, you know, what you should see in your results is this symmetry.

350
00:39:53,260 --> 00:39:56,670
And this kind of goes back to a frequentist framework of like when we do a study,

351
00:39:56,910 --> 00:40:05,340
it's kind of in reference to a lot of other studies being conducted using similar methods, and all of our statistics are kind of based around that.

352
00:40:06,210 --> 00:40:10,140
So that's that's also a way of intuitively thinking about this.

353
00:40:10,170 --> 00:40:13,860
Does that make sense? Do you ever use.

354
00:40:19,910 --> 00:40:23,450
So the null hypothesis for the Eggers test is that.

355
00:40:28,160 --> 00:40:32,150
The null hypothesis is that there is symmetry.

356
00:40:32,450 --> 00:40:40,850
So the null hypothesis is that there is light. So the null hypothesis is that there, you know, like basically the, the.

357
00:40:43,050 --> 00:40:46,500
But I want to say no, slow, but like kind of the slope with like equal wine or whatever.

358
00:40:47,430 --> 00:41:07,030
And that would just mean that there is. That there is there is symmetry, so there's symmetry results in the implication of that.

359
00:41:07,110 --> 00:41:17,460
The null hypothesis is that all relevant studies have been identified and identified.

360
00:41:18,780 --> 00:41:22,830
Does that make sense? Okay.

361
00:41:23,400 --> 00:41:28,710
I'll give you a ten, ten minute break. Let's come back at 210 to go over pee.

362
00:41:51,227 --> 00:41:56,267
And so, you know, this this is a meta analysis that you looked at.

363
00:41:56,657 --> 00:42:02,027
They mentioned using a multilevel analysis of random effects models, just a type of multilevel analysis.

364
00:42:03,287 --> 00:42:07,426
They looked at the degree of heterogeneity using the I squared statistics.

365
00:42:07,427 --> 00:42:13,547
That's something that we talk about today. And here they say that they quantified publication bias using an Eggers regression model.

366
00:42:14,747 --> 00:42:21,556
Although I will say that more precisely, they say they quantified a reporting bias because publication bias is one type of reporting bias.

367
00:42:21,557 --> 00:42:26,227
But there's other types as well. Oh.

368
00:42:26,427 --> 00:42:31,427
So for the rest of the class, we're going to go over something called P hacking.

369
00:42:33,107 --> 00:42:41,327
And this is an explanation of what I'm talking about.

370
00:42:41,417 --> 00:42:47,746
So a P curve is the distribution of P values across all the studies.

371
00:42:47,747 --> 00:42:55,187
So, you know, we had a forest plot and a funnel plot which were kind of looking at different measures of association.

372
00:42:55,187 --> 00:43:04,486
But if you looked at those studies and found what is the p value that they found for a certain association, this is what we should be able to graph.

373
00:43:04,487 --> 00:43:07,997
We should kind of be able to graph a histogram of the P values.

374
00:43:09,137 --> 00:43:14,777
So if we take a further step back and for whatever reason we knew that there was no effects,

375
00:43:15,107 --> 00:43:18,226
then there would just be a straight line across because this is what a p value is.

376
00:43:18,227 --> 00:43:25,607
Saying a p value is saying is that under a null hypothesis, 5% of your results will be as extreme or more extreme.

377
00:43:28,737 --> 00:43:32,577
So again, under a no effect situation, the PE curve should just be straight across.

378
00:43:34,437 --> 00:43:43,537
If there was an effect, what we should see is there are going to be more values which are lower.

379
00:43:43,557 --> 00:43:47,997
There's going to be, you know, low p values which are president is part of this.

380
00:43:47,997 --> 00:43:56,397
But there still will be values like above 25. Like our tests are not 100% perfect in distinguishing whether something is in effect or not.

381
00:43:58,167 --> 00:44:04,797
Do these groups make sense? Okay.

382
00:44:05,307 --> 00:44:10,407
So publication bias, as I was mentioning before, is why in journal editors don't want to publish an article.

383
00:44:10,947 --> 00:44:16,837
And there could be a lot of reasons why this is the case, but often it is because there are studies with insignificant results.

384
00:44:17,487 --> 00:44:25,107
So if we had a p curve in reality, if there is publication bias, what we would see is there is a drop off after .05.

385
00:44:28,957 --> 00:44:34,207
And you know, this is kind of like a bit hard to gauge, especially if there actually is an effect because like things are going down anyway.

386
00:44:34,717 --> 00:44:40,696
But this is, you know, what we would see. P hacking is what researchers do.

387
00:44:40,697 --> 00:44:45,017
So publication bias is from the journal editors perspective.

388
00:44:45,257 --> 00:44:52,877
P Hacking is from the researchers perspective, and the idea is that researchers desperately want to show an association to be significant.

389
00:44:53,837 --> 00:44:58,967
And I'm sure that's not just the case with just like researchers in general, but maybe you,

390
00:44:58,977 --> 00:45:03,557
as you are putting together your illy project or various things that you're working on.

391
00:45:04,097 --> 00:45:07,397
We all want to have a significant result. We all want a p value in point of five.

392
00:45:08,537 --> 00:45:11,567
And, you know, we we teach different methods.

393
00:45:11,927 --> 00:45:17,477
You know, like I was showing you earlier in this class, you can do odds ratios, you can do risk ratios, you can do risk differences.

394
00:45:17,807 --> 00:45:23,177
You could like specify your model in different ways. You could build your model different ways in terms of what covariates you use.

395
00:45:23,447 --> 00:45:28,967
So you can kind of like manipulate things and massage your data into having a lower p value.

396
00:45:30,467 --> 00:45:44,837
So P hacking, you can visualize this if there is, you know, a, an increase in publications which have a P value, just a naught point of five.

397
00:45:45,077 --> 00:45:52,577
And the idea here is that it's easier to p hack your way from like a .06 to a point of four or five than it is to go from like 0.06 to like 0.01.

398
00:45:53,387 --> 00:45:59,387
So that's why there's going to be extra numbers here, just because it's easier to get here than to push your P value all the way down.

399
00:46:03,407 --> 00:46:09,347
Okay. So let me put up this pool for you to do.

400
00:46:12,977 --> 00:46:18,197
I just want to make sure that you understand this concept. So this should be live.

401
00:46:18,237 --> 00:46:39,777
I mean, if you don't have access to it. Also last call.

402
00:46:39,777 --> 00:47:28,617
Has everyone signed the attendance sheet? Okay.

403
00:47:28,637 --> 00:47:44,887
Let's go through this. Okay.

404
00:47:45,817 --> 00:47:54,177
First one, when we have a decrease rate after point five, that is very much a sign of publication bias.

405
00:47:54,177 --> 00:47:59,916
So that is what we would see here. And, you know, we'd also say that there's probably no effect.

406
00:47:59,917 --> 00:48:08,587
There's there's kind of no actual relationship between like the exposure variable and the outcome, whatever it is.

407
00:48:09,647 --> 00:48:21,787
So this is publication bias. You know, if you have questions about that, the next one is like, so, um,

408
00:48:22,207 --> 00:48:34,327
and I would say that it's not really clear from this whether there is publication bias or not, but I do not think there is p hacking.

409
00:48:34,897 --> 00:48:39,967
So packing is not the case. There might be publication bias, there may not be.

410
00:48:40,267 --> 00:48:42,576
This is one of those things where there if there actually is an effect,

411
00:48:42,577 --> 00:48:47,857
it's kind of hard to tell just because, you know, there is going to be a decrease after point of five anyway.

412
00:48:47,857 --> 00:48:56,457
So I would say like these two answers are correct. And again, it's not because we don't see a bump right before, in fact.

413
00:49:00,557 --> 00:49:04,657
Okay. So this is very much what we would see in line with hacking.

414
00:49:04,697 --> 00:49:08,177
So I would say this is P hacking and not publication bias.

415
00:49:09,227 --> 00:49:14,597
Again, it's always hard to tell that with the publication bias because that is just like a slight decrease earned here.

416
00:49:14,597 --> 00:49:23,937
But I would say this is more so this one. And this is just a straight up example.

417
00:49:23,937 --> 00:49:28,347
If there's no publication bias, there's no hacking, and there's clearly no effect.

418
00:49:30,407 --> 00:49:35,867
So from Checkers, there's kind of three things you should be able to determine whether there's publication bias,

419
00:49:35,867 --> 00:49:41,597
whether there's P hacking, and then whether there actually is an effect. The new questions are.

420
00:49:48,217 --> 00:49:58,266
Okay. So how can we do hacking? You could look at many different response variables and selectively report associations.

421
00:49:58,267 --> 00:50:05,556
You could drop outliers, you could manipulate your model building process to include or exclude certain covariates.

422
00:50:05,557 --> 00:50:14,347
And frankly, I think this is what stepwise selection does. So I would say stepwise selection is a type of hacking in randomized controlled trials.

423
00:50:14,347 --> 00:50:17,166
There are several things that you could do. You could stop data collection.

424
00:50:17,167 --> 00:50:22,867
You could this is something which I see sometimes, which is really here when there are multiple arms, like maybe there is the control arm,

425
00:50:22,867 --> 00:50:30,457
but then there are like two different types of drugs which are given or maybe like the dosage is differently.

426
00:50:30,457 --> 00:50:33,787
Sometimes you see those combined and I'm not sure why that's ever happened.

427
00:50:34,867 --> 00:50:36,696
And there could be like bad randomization.

428
00:50:36,697 --> 00:50:45,397
Maybe there is uncontrolled confounding because, you know, there's not actual people weren't randomly assigned correctly.

429
00:50:48,127 --> 00:50:54,547
Okay. So let me give you some examples of this. So say that you're really interested in this outcome of blood pressure.

430
00:50:55,327 --> 00:50:59,976
And I am not a blood pressure person, but just, you know, from Googling around and from reading different articles,

431
00:50:59,977 --> 00:51:01,807
there's different ways that you can report blood pressure.

432
00:51:02,197 --> 00:51:07,666
You could analyze it continuously, kind of like what they did in the funnel plots for today.

433
00:51:07,667 --> 00:51:16,746
And just by looking at the MM mercury increase, you can look at things categorically so you could,

434
00:51:16,747 --> 00:51:19,267
you know, categorize people to have normal blood pressure or not.

435
00:51:19,267 --> 00:51:24,427
You could look at whether they're elevated or not or like stage one or stage two hypertension.

436
00:51:24,847 --> 00:51:27,517
You can even look at whether they have a hypertensive crisis or not.

437
00:51:27,787 --> 00:51:35,977
So already, just for the simple construct of blood pressure, you have like five or six different variables that you could actually analyze.

438
00:51:36,547 --> 00:51:44,047
The problem comes into play when maybe, you know, you're looking at maybe you're looking at stressors like,

439
00:51:44,137 --> 00:51:47,107
you know, how much homework does your professor give you, you treatment? What is your blood pressure?

440
00:51:49,207 --> 00:51:55,477
Maybe what you find is that for some of the outcomes, there's a significant result, but for some of them there's not.

441
00:51:56,737 --> 00:52:01,207
So if you're selectively reporting associations, then that could be a type of P hacking.

442
00:52:04,167 --> 00:52:10,087
Okay. So we're going to skip us now for the sake of time, and we'll skip this one as well.

443
00:52:10,107 --> 00:52:15,267
So what do we mean by outliers? Oftentimes there's ways of like hooks, distances, a way to measure outliers.

444
00:52:17,067 --> 00:52:27,557
My own sense of outliers is that if you find outliers in your data, definitely look at them, because maybe there's just a problem in data input.

445
00:52:27,567 --> 00:52:31,887
Like maybe, you know, instead of saying somebody is ten years old, you said that they were 100 years old or,

446
00:52:31,887 --> 00:52:41,337
you know, like there could be something really weird and off about it. I would be very careful about removing them wholesale from the data set.

447
00:52:41,787 --> 00:52:45,207
And if you do, you need to be really clear about it. So you could put in your methods.

448
00:52:45,207 --> 00:52:53,187
You know, we removed two people who had a large two outliers because they had a large cook's distance.

449
00:52:53,547 --> 00:53:00,237
And if you do that, probably what I would do is in your supplementary appendix, I would report results of the study with them included.

450
00:53:02,007 --> 00:53:05,237
And, you know, you should have it you should ideally have a good reason for.

451
00:53:08,427 --> 00:53:11,547
Okay. I'm going to do this to you as well.

452
00:53:13,047 --> 00:53:18,977
Yeah. So this is one that I do on your site, in your groups. When should you start data collection?

453
00:53:18,987 --> 00:53:23,757
Midway through trial. I mean, let me give you a concrete example of this.

454
00:53:23,757 --> 00:53:31,646
I think in, you know, 2015 or so, this is when there was an Ebola outbreak in West Africa.

455
00:53:31,647 --> 00:53:41,726
And I went to an infectious disease conference and some people were reporting about preliminary results from an Ebola vaccine trial.

456
00:53:41,727 --> 00:53:45,597
And there was an ethicist who raised his hand and he he asked like,

457
00:53:45,597 --> 00:53:51,926
why aren't you stopping the trial early and vaccinating everybody in the study population then,

458
00:53:51,927 --> 00:53:59,367
like rolling out this Ebola vaccine to, you know, to the entire population, because there was some like good preliminary results from that study.

459
00:54:00,267 --> 00:54:06,217
So should you start data collection midway through trial? Think about, you know, when you should or when you shouldn't.

460
00:54:06,217 --> 00:54:10,847
And I'll give you just a few minutes as a group to talk about and what we can gain in like four or five months.

461
00:54:58,077 --> 00:55:12,037
Else. There's another type of taxidermy.

462
00:55:13,927 --> 00:55:19,857
Last year. Getting started.

463
00:55:21,697 --> 00:55:30,407
In order to that. Oh, yeah, yeah, yeah, yeah, yeah.

464
00:55:30,627 --> 00:55:36,107
That. It's.

465
00:55:38,407 --> 00:55:50,707
You know the data show that so. So can you.

466
00:56:09,667 --> 00:56:17,247
It's really sick the way that. That.

467
00:56:22,707 --> 00:56:33,387
So it's no. She's like, you know, controversial.

468
00:56:34,247 --> 00:56:37,406
And I'm like, yeah, okay.

469
00:56:37,407 --> 00:56:43,316
So, I mean, there's a lot that we can go for here. I mean, just call on one group, the dengue.

470
00:56:43,317 --> 00:56:48,927
If I don't know if you've heard of you today, what are your thoughts on stopping data collection midway through a trial?

471
00:56:56,497 --> 00:57:00,747
And that that was the reason that so.

472
00:57:03,887 --> 00:57:17,557
We were so. So a few point series which are good.

473
00:57:17,567 --> 00:57:20,957
So there are obvious reasons why we should stop data collection.

474
00:57:20,957 --> 00:57:26,527
Like if there are severe adverse events which are happening, you know, great reason to stop Trump.

475
00:57:28,847 --> 00:57:42,827
Let me give you a situation where we are looking at erm erm this analysis of our keyword.

476
00:57:44,147 --> 00:57:54,467
So if we have on the x axis time which basically is also like the number of participants in a study.

477
00:57:59,057 --> 00:58:02,327
And then we could look at the p value for our main test.

478
00:58:04,697 --> 00:58:14,687
So one thing to note is that generally p values decrease the number of you know that there is this relationship between p value and your sample size.

479
00:58:16,077 --> 00:58:20,447
So say then that this is our.

480
00:58:23,677 --> 00:58:29,487
Neither side can really see that this is like a P-value of .05.

481
00:58:30,207 --> 00:58:35,067
So these are P values and they're like right this quick that the program and get angry at me.

482
00:58:37,317 --> 00:58:46,707
Well we could have in a situation is like you know we're monitoring over time and then all of a sudden we drop below .05.

483
00:58:46,707 --> 00:58:51,747
So that would be like great. So then we're like, oh, this, this is significant.

484
00:58:57,917 --> 00:59:00,597
So at this point in time, this is like all the information that we know.

485
00:59:00,647 --> 00:59:04,637
So maybe this is like when you're presenting at that conference, that infectious disease conference,

486
00:59:04,637 --> 00:59:10,727
you're seeing that there is a significant relationship between Ebola vaccination and protection against Ebola.

487
00:59:12,077 --> 00:59:16,937
And so that ethicist says, oh, you should stop your trial.

488
00:59:17,357 --> 00:59:25,697
And, you know, one of the one of the the tenets of any randomized controlled trial is that if you find a benefit, it should be stopped.

489
00:59:25,697 --> 00:59:34,577
And then people who were in the placebo group should be given the option of giving the are being given the the treatment or whatever it is.

490
00:59:34,847 --> 00:59:40,607
And then also, you know, you can roll this out to the population as a whole. You can get like FDA approval or emergency use authorization, whatever.

491
00:59:42,407 --> 00:59:53,777
What we are not knowing is what happens after this, because it could be that this was just a blip where there was low p values.

492
00:59:53,777 --> 01:00:00,347
And then maybe at the end of the trial, it actually ends up with a P value of like 0.25 or something like that.

493
01:00:00,587 --> 01:00:08,177
So maybe if we would have continued with the study, we would have gotten like really bad, bad results.

494
01:00:09,527 --> 01:00:13,837
Or it could be that, you know, we end up with like really, you know, a nice p value.

495
01:00:13,847 --> 01:00:23,107
It's under point five. This is, you know, obviously what the FDA would want to see to authorize something for use in the United States.

496
01:00:24,407 --> 01:00:25,187
But we just don't know.

497
01:00:26,897 --> 01:00:38,327
So that is the problem with with cutting down the size of randomized controlled trials is we just don't know what happens after that point in time.

498
01:00:38,777 --> 01:00:42,316
And this is the number that we put in our grant application.

499
01:00:42,317 --> 01:00:48,017
This is the number which, you know, we base all of our frequentist statistics around.

500
01:00:51,707 --> 01:00:54,496
So, you know, potentially I would argue that like in the middle of a trial,

501
01:00:54,497 --> 01:01:01,157
we shouldn't even be doing, you know, testing for people because, like, it's maybe a bit irrelevant.

502
01:01:02,507 --> 01:01:12,047
At the same time, you know, I understand if somebody is, you know, this is like we're in the middle of this this COVID19 pandemic.

503
01:01:12,047 --> 01:01:15,106
There's also like an epidemic among kids.

504
01:01:15,107 --> 01:01:18,457
And then there's like this RSV vaccine on the horizon.

505
01:01:18,467 --> 01:01:26,687
Wouldn't it be nice if we stopped those trials early and, you know, we're able to roll out two RS five extra.

506
01:01:27,377 --> 01:01:32,777
So like, there are a lot of ethical issues at play here, so there isn't an easy answer.

507
01:01:35,057 --> 01:01:38,477
So, you know, in this example, a few things.

508
01:01:38,477 --> 01:01:46,097
One is like before we do any study, before we do randomized controlled trials, of course, do a sample size calculation or be funded based on that.

509
01:01:46,427 --> 01:01:52,127
In in our protocol, we should have something, some procedure for what to do to stop a study.

510
01:01:52,337 --> 01:01:56,377
And of course, you stop it if like bad things are happening, if there's lots of adverse events,

511
01:01:56,387 --> 01:02:00,797
if people are getting really sick or dying, you know, those are great reasons to stop the study.

512
01:02:02,207 --> 01:02:11,176
But if you're thinking of stopping it for other reasons, like maybe you think that you have positive evidence and you know,

513
01:02:11,177 --> 01:02:16,336
everybody should be getting your intervention that should be decided by somebody else and not you.

514
01:02:16,337 --> 01:02:24,287
And so maybe that's an RB. There is also an external data safety board for every randomized controlled trial.

515
01:02:24,647 --> 01:02:32,476
They could also be making those decisions, but it shouldn't be you as an individual researcher who maybe even has a conflict of interest in terms of,

516
01:02:32,477 --> 01:02:37,787
you know, if you're part of the pharmaceutical company which wants to go out this drug or this vaccine.

517
01:02:40,857 --> 01:02:45,027
Okay. Well, any questions about this, like stopping trials early?

518
01:02:46,347 --> 01:02:52,047
I just think, you know, the first time that I think about and like, oh, of course, yeah, we should stop trials, really.

519
01:02:52,047 --> 01:02:57,687
We should, you know, get the drug out there. But I think it's a bit more nuanced than that.

520
01:03:00,037 --> 01:03:04,327
I think the hacking can also be exacerbated by general demands.

521
01:03:05,047 --> 01:03:07,356
So this is from the Lancet family of journals.

522
01:03:07,357 --> 01:03:18,267
And they see that they want to publish things which have a strong or unexpected beneficial adverse response or a novel mechanism of action.

523
01:03:18,277 --> 01:03:23,707
So they like new things, so they like low key values and new results.

524
01:03:26,257 --> 01:03:28,447
So, you know, that's unfortunate.

525
01:03:28,447 --> 01:03:37,497
Anything potentially this sort of philosophy was one of the reasons why in the mid 1990s, Andrew Wakefield was able to publish his study linking.

526
01:03:39,067 --> 01:03:45,157
I mean, like overall it's kind of working this idea of MMR vaccination to autism, but you know, it's a bit messier than that.

527
01:03:45,487 --> 01:03:50,467
But, you know, maybe he was able to get through because that is like unexpectedly an adverse response.

528
01:03:51,577 --> 01:03:57,757
And so I think this kind of culture in journals to look for novelty of results is like a bit disappointing

529
01:03:58,687 --> 01:04:04,297
because I think instead it should be the robustness of the methods and the clarity of the aims.

530
01:04:06,667 --> 01:04:10,957
So, you know, there are some proposals out there.

531
01:04:12,337 --> 01:04:13,117
For instance,

532
01:04:13,117 --> 01:04:21,607
one of them could be that journals should do a preliminary pass on whether to accept paper just based on the introduction of the methods,

533
01:04:22,057 --> 01:04:27,247
and then look later on at the results and the discussion section.

534
01:04:27,937 --> 01:04:36,727
I don't know of any journal that actually does do that. Right now, I'm an associate editor of the The Plus Global Public Health Journal.

535
01:04:37,057 --> 01:04:45,487
And one thing that we do is that we evaluate journals or we evaluate publications based on their methods.

536
01:04:45,487 --> 01:04:49,597
So we you know, we do look at like the introduction through the discussion right away.

537
01:04:49,597 --> 01:04:54,457
But, you know, I'm not rejecting things because they are not novel.

538
01:04:54,847 --> 01:04:59,717
I'm just looking at like, are the methods sound enough? Okay.

539
01:04:59,767 --> 01:05:04,707
So you know this, of course, everyone wants to be published in The Lancet.

540
01:05:04,707 --> 01:05:05,897
Like, I want to be published an answer.

541
01:05:06,777 --> 01:05:14,367
So, you know, if if this is the driver, then, you know, we're going to be manipulating our data consciously or unconsciously.

542
01:05:16,197 --> 01:05:21,447
One thing that also I want to be aware of is using small study populations, attacks many relationships.

543
01:05:22,317 --> 01:05:28,467
So ideally, we have this this pathway in our frequency system where we develop a hypothesis,

544
01:05:28,887 --> 01:05:36,407
we do a sample size calculation for that one aim, we collect data and then we analyze data for that one thing.

545
01:05:39,447 --> 01:05:45,026
But I think what actually happens is that we might find like a secondary source of data and then

546
01:05:45,027 --> 01:05:49,707
we might be analyzing it for an entirely different hypothesis than what the original authors did.

547
01:05:50,007 --> 01:05:58,467
So our aim is disconnected from how the sample is put together and what the sample size was actually.

548
01:05:59,337 --> 01:06:06,267
So that's one problem. So what can you do as researchers to behave ethically in your research?

549
01:06:06,567 --> 01:06:09,777
There's a few things that I would recommend.

550
01:06:09,897 --> 01:06:14,637
One is to correct some of the testing that we had a previous lecture on that

551
01:06:16,047 --> 01:06:21,686
we could think as a field to decrease the alpha level to maybe like .05 or,

552
01:06:21,687 --> 01:06:28,767
you know, maybe even more. But I think this is actually like a big one is to distinguish between exploratory and confirmatory research,

553
01:06:29,097 --> 01:06:33,416
because a lot of our statistics is based on confirmatory research. And by that I mean that, you know,

554
01:06:33,417 --> 01:06:41,217
you have developed like a rigorous theory and a rigorous dag for what you are analyzing, and this is what you found.

555
01:06:41,937 --> 01:06:47,367
Exploratory stuff is like, Oh, you know, I'm kind of interested in like why something might happen, but I'm not exactly sure.

556
01:06:47,367 --> 01:06:51,476
I don't really have a guiding hypothesis. In an exploratory research,

557
01:06:51,477 --> 01:06:59,037
you are much more likely to get you are much more likely to to like people because you're

558
01:06:59,037 --> 01:07:02,547
kind of looking for things which are significant instead of in confirmatory research,

559
01:07:02,757 --> 01:07:06,147
you already know what you're looking for and then you just see what is significant or not.

560
01:07:08,127 --> 01:07:14,877
So I would, you know, just like saying in your study, this is an exploratory study we were interested in,

561
01:07:14,877 --> 01:07:19,076
just like wondering we were wondering why this outcome was happening.

562
01:07:19,077 --> 01:07:22,227
And so we tested a lot of different things. I think that's fair.

563
01:07:23,487 --> 01:07:28,077
But in exploratory research, you do need to display the results of all your associations.

564
01:07:28,077 --> 01:07:34,767
So for the blood pressure example, even if only like hypertensive crisis was significant,

565
01:07:35,847 --> 01:07:41,367
I would want you to also show results of like your continuous blood pressure or,

566
01:07:41,367 --> 01:07:45,557
you know, looking at those other different categories like stage one or stage two hypertension.

567
01:07:45,567 --> 01:07:51,447
So don't just like cherry pick what you actually show for a confirmatory research.

568
01:07:51,447 --> 01:07:58,377
This is kind of like this whole pathway here. Please do mention your sample size calculation in your methods.

569
01:08:01,277 --> 01:08:08,267
Yeah, I think I think you mentioned this kind of as well. So when we're talking about our results.

570
01:08:08,537 --> 01:08:12,047
One word, which is is key here is consistency.

571
01:08:13,907 --> 01:08:21,017
And we can measure this in a number of different ways. Repeatability is like, are you able to find the same results?

572
01:08:21,467 --> 01:08:27,736
So like you have your Ailey project and you know, I code myself.

573
01:08:27,737 --> 01:08:29,056
I work with a lot of students who code.

574
01:08:29,057 --> 01:08:37,247
And often what happens is by the end of the year there is like a jumbled mess of like several different ah markdown files or

575
01:08:37,247 --> 01:08:45,047
like SAS things which like are a bit of a mess and a bit like difficult to kind of read through as a repeatability is just like,

576
01:08:45,497 --> 01:08:54,017
you know, at the end of this year in April, are you able to look at the method section of your elite project and are you able to recreate it?

577
01:08:54,407 --> 01:09:00,527
Are you able to get the same results? So repeated repeatability breaks down when like your code is kind of messing up,

578
01:09:00,527 --> 01:09:09,676
or if you're not really consistent in how you are putting together replicability is if you give your dataset to somebody else,

579
01:09:09,677 --> 01:09:18,947
maybe in your lab group or like another classmate, and you give them your methods, you give them your dataset, but you don't give them your code.

580
01:09:19,757 --> 01:09:25,397
And you see like, are they able to come up with the same results? And ideally your results are replicable.

581
01:09:26,897 --> 01:09:31,247
Reproducibility is when people use a different dataset.

582
01:09:31,247 --> 01:09:41,147
So say that you here are looking at this relationship between stress and blood pressure here at the University of Michigan,

583
01:09:42,377 --> 01:09:43,927
at the University of Chicago,

584
01:09:43,937 --> 01:09:50,117
here at the University of Wisconsin or at Harvard, are they able to find the same results using their own student populations?

585
01:09:50,447 --> 01:09:59,237
That is what reproducibility is also. So we have kind of entered an era of a reproducibility crisis,

586
01:09:59,627 --> 01:10:10,367
and this has been really publicized within the social sciences in psychology, but I frankly think it affects epidemiology as well.

587
01:10:11,387 --> 01:10:14,477
And so there's like a number of thought pieces out about this.

588
01:10:14,867 --> 01:10:22,367
And basically, you know, there are all these studies conducted decades ago or even more recently when people have tried to reproduce them.

589
01:10:22,697 --> 01:10:25,127
They have not been able to find the same results.

590
01:10:25,787 --> 01:10:34,217
And one of the things is like, if we go back to this Lancet article, they want new mechanisms of of action.

591
01:10:34,227 --> 01:10:38,477
They don't want you to recreate studies from like a decade ago or two decades ago.

592
01:10:38,477 --> 01:10:46,487
They want new things. But what this whole reproducibility crisis is suggesting is that we actually should be going back through like

593
01:10:46,487 --> 01:10:52,457
our back catalog studies and maybe trying to recreate those studies and make sure that we find similar results.

594
01:10:52,817 --> 01:10:59,237
Because it could be that those were like people to death. It could be that they're sampling bias or that there's a problem with, you know,

595
01:10:59,237 --> 01:11:05,687
like the the people who were in the original study, you know, our measurements could have improved over time.

596
01:11:05,687 --> 01:11:11,567
Like our data analysis certainly has improved over time. So there can be a number of different reasons for reproducibility.

597
01:11:12,317 --> 01:11:22,477
And maybe you've heard of I believe it's this acronym Weird and it's like Western educated or maybe the students who white,

598
01:11:22,487 --> 01:11:25,757
it's like very educated, industrialized research.

599
01:11:25,757 --> 01:11:34,816
And the idea is that like a lot of psychology has come out of people doing tests as like undergrad students.

600
01:11:34,817 --> 01:11:39,077
And I don't know if you ever took like a psychology class as an undergrad or were part of a study,

601
01:11:39,077 --> 01:11:44,807
but that, like a lot of our big theories in psychology are based off of, you know,

602
01:11:45,287 --> 01:11:51,586
this this psychology study that was conducted two decades ago or three decades ago at the University of Michigan,

603
01:11:51,587 --> 01:11:54,047
or a lot of them, you know, like at Harvard or Yale or whatever.

604
01:11:54,467 --> 01:12:00,076
And you're like, how much can those actually be generalized to the United States population or to like the world?

605
01:12:00,077 --> 01:12:05,547
And I would say the answer is probably not very. Okay.

606
01:12:05,547 --> 01:12:14,057
So a cautionary tale. Has anyone heard of Brian LAMB saying, I promise not to call on you, but I'm just curious if anyone has that.

607
01:12:14,097 --> 01:12:22,887
There's like a number of interesting podcasts about this podcast episodes and in certainly, you know, there is a lot of recording a few years ago.

608
01:12:23,007 --> 01:12:28,887
But, you know, a prominent nutritionist, he was at Cornell,

609
01:12:29,787 --> 01:12:38,246
he was often on Oprah and like other things and he had like easily digested pieces of knowledge.

610
01:12:38,247 --> 01:12:45,207
So he came up with things like, Oh, if you have a bigger plate, you will eat more at dinner than if you have a smaller plate.

611
01:12:45,597 --> 01:12:49,527
Like if you go to a grocery store hungry, you'll get more food than if you don't.

612
01:12:50,757 --> 01:12:57,207
He had this one study where if you're sitting down at a table and you have a bowl of

613
01:12:57,207 --> 01:13:00,447
soup which is constantly being refilled and this is what he's demonstrating here,

614
01:13:00,777 --> 01:13:10,827
you will eat more of the soup than if you have to like go yourself and like find the into like add seconds to your to your bowl.

615
01:13:11,667 --> 01:13:15,986
So all of these, like, kind of like intuitively make sense. You're like, oh, yeah, there's like a larger plate.

616
01:13:15,987 --> 01:13:19,107
Like, of course I'll eat more. You know, like the soup is constantly being refilled.

617
01:13:19,107 --> 01:13:23,067
Of course I will do that. So it turns out that all this research is bunk.

618
01:13:23,337 --> 01:13:28,077
It might be that, like some of these hypotheses, you know, are true.

619
01:13:29,547 --> 01:13:37,947
But like he used very horrible methods. And I love the story of the soup because it's really interesting because he you know,

620
01:13:38,157 --> 01:13:45,027
you'd think that he would compare two groups like one person getting chicken noodle soup where the bowl was getting refilled and one bird was not.

621
01:13:45,567 --> 01:13:49,226
And even then, it's like like how do you completely randomize that?

622
01:13:49,227 --> 01:13:56,577
Because presumably you as an individual would like notice like gurgling from the tubes as like your soup is getting refilled.

623
01:13:56,577 --> 01:13:59,487
And maybe that's a bit like disconcerting as you're eating,

624
01:13:59,847 --> 01:14:06,267
but it actually turns out that there were actually two different types of soup because you kind of need a very thin soup to go through the the tube.

625
01:14:06,267 --> 01:14:11,427
So it was kind of like people got a hearty stew in one group and then the other got this like very light soup.

626
01:14:12,717 --> 01:14:18,086
So things like that were very off. But he was also like an expert at stopping clinical trials early.

627
01:14:18,087 --> 01:14:27,507
So this is going back to our small group discussion. So one thing that he would do is he would be constantly looking for significant P values.

628
01:14:27,507 --> 01:14:29,576
And the moment that there was a significant P value,

629
01:14:29,577 --> 01:14:36,087
he would cut off that stem and he would he would stop the trial and he'd like keep it towards the end of his career.

630
01:14:36,087 --> 01:14:40,107
He just wasn't really publishing results. He's kind of just like going on Oprah.

631
01:14:41,487 --> 01:14:46,347
Then the, the, the other thing he would be doing is he'd be like cutting down his sample size.

632
01:14:46,347 --> 01:14:55,166
So you, you know, instead of analyzing the maybe in the entire dataset, there was not a significant association,

633
01:14:55,167 --> 01:14:59,967
but maybe among like Asian-American women, there was a significant association.

634
01:14:59,967 --> 01:15:03,266
So then he would kind of just show the results from Asian-American women and

635
01:15:03,267 --> 01:15:06,597
then broadcast that as like being generalizable to the rest of the population.

636
01:15:08,627 --> 01:15:11,956
So it actually turns out that he was found out because well,

637
01:15:11,957 --> 01:15:17,957
he actually had like all sorts of like blog posts up on his website about, you know, him actually doing all these things.

638
01:15:17,957 --> 01:15:19,787
But I just don't think anyone really looked into it.

639
01:15:20,477 --> 01:15:25,967
But he was found out and it was eventually reported because he wasn't like paying his grad students very well.

640
01:15:25,967 --> 01:15:30,256
And then some of them were just like, Oh, we're not getting paid. We're doing sketchy science like this.

641
01:15:30,257 --> 01:15:34,576
This isn't great. So he was fired from his position.

642
01:15:34,577 --> 01:15:38,207
But, you know, I he was he was a tenured professor.

643
01:15:38,207 --> 01:15:41,596
And I am sure he's he's he's doing quite fine this life.

644
01:15:41,597 --> 01:15:47,987
There wasn't like legal repercussions or anything, even though I'm sure he, like, misused a lot of grant funds and things like that.

645
01:15:48,377 --> 01:15:53,537
So like a cautionary tale of like maybe the system catching up to you at some point in time,

646
01:15:53,837 --> 01:16:00,437
but also kind of disappointing because like the repercussions to Bryan are very little,

647
01:16:00,437 --> 01:16:06,347
you know, I think, you know, not not certainly he doesn't have his job anymore but like it,

648
01:16:08,417 --> 01:16:11,777
he has not suffered in in a jail cell or anything like that.

649
01:16:14,227 --> 01:16:19,487
Okay. So that is one reason why I think about unless these are important because, you know,

650
01:16:19,487 --> 01:16:23,957
if you're Bryan Cranston, can you have this one weird study about like a refillable Super Bowl?

651
01:16:24,827 --> 01:16:33,107
If you can have like compare that to ten other studies in the literature, then you can kind of see whether there whether there are outliers or not.

652
01:16:35,027 --> 01:16:42,106
So that is what I have for you today. There is one final homework assignment related to MIT analysis.

653
01:16:42,107 --> 01:16:52,397
So, you know, next Sunday, you do need to submit that along with your your previous one on quantitative bias analysis.

654
01:16:53,627 --> 01:16:58,606
I will put up the final after class next time.

655
01:16:58,607 --> 01:17:03,047
But again, next time we'll be meeting on Zoom. So if you have any questions, I'll stay after class.

656
01:17:03,047 --> 01:17:05,537
But otherwise I hope that you have a wonderful person. Go.

