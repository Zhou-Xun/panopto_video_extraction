1
00:00:03,170 --> 00:00:14,050
But. Oh, great.

2
00:00:23,510 --> 00:00:33,590
Danielle, can you hear us? No.

3
00:00:34,180 --> 00:00:41,900
All right, hang on. Danielle, can you hear us?

4
00:00:51,410 --> 00:01:22,750
It's not today. What is an this to report?

5
00:01:23,240 --> 00:01:27,040
So I think I have it set up.

6
00:01:28,090 --> 00:01:40,720
What went to the media? It was the same as what it the submission on the side who submitted the so who submitted that time.

7
00:01:41,140 --> 00:01:46,260
So I was trying to say, we've got Danielle on. Zoom.

8
00:01:47,280 --> 00:01:51,130
So who's your partner? Sarah and Sarah's out.

9
00:01:51,150 --> 00:01:54,870
Okay. And Zoom's not working.

10
00:01:54,870 --> 00:02:03,030
Of course it's not, because that would be too easy. She means she's in the room.

11
00:02:04,860 --> 00:02:10,910
Oh. But she has not responded.

12
00:02:12,490 --> 00:02:18,470
She might not. Could be. But the owl camera won't start.

13
00:02:18,710 --> 00:02:22,160
And the speaker is also part of the owl. So I'm wondering.

14
00:02:24,730 --> 00:02:29,080
Looks like it's registering or voice the market. That's true.

15
00:02:45,230 --> 00:02:50,950
So, Hannah, do you want to join another group to discuss or do you think you are needed that would justify your.

16
00:02:51,150 --> 00:03:23,030
Yeah, so. So. They?

17
00:03:26,740 --> 00:03:31,520
George. He.

18
00:03:34,180 --> 00:03:42,030
Oh, yeah. Thank you.

19
00:03:55,650 --> 00:04:04,040
Hey, can you hear us? Wife and kids have been here.

20
00:04:04,430 --> 00:04:09,320
Yeah, I know it's not. I can't hear what's going on. I wasn't working and I'm on my actual laptop and it's not working.

21
00:04:10,190 --> 00:04:21,040
So, um, Danielle, your partner is also not in today, so, um,

22
00:04:21,290 --> 00:04:29,689
I don't know if you would like to join another twosome here to work on it or if you would like to work on your work on it on your own.

23
00:04:29,690 --> 00:04:36,470
And then join us for the discussion. I'm happy to do whatever you would like.

24
00:04:40,330 --> 00:04:45,190
Sorry. Hang on. I think I've got you muted. Go ahead. I'm good either way.

25
00:04:46,030 --> 00:04:51,460
Okay. You let me know what you'd like to do. It's just that I tried to do so.

26
00:04:51,610 --> 00:04:57,370
Okay, so who would like to hop on Zoom and have Daniel going there for today?

27
00:04:59,620 --> 00:05:10,450
Okay, great. Somebody tell me their unique name and I will email you the Zoom link.

28
00:05:21,350 --> 00:05:24,470
Who am I sending it to? Really good.

29
00:05:24,890 --> 00:05:40,200
I mean, I wish that, you know, those two guys who who's going to get on Zoom who shouldn't be able to wake up one day and see you.

30
00:05:48,720 --> 00:05:55,210
To answer this question. It's very rarely how you.

31
00:05:58,060 --> 00:06:13,000
Immigration is down. Not as much as I had hoped, but I'm not sure exactly what the conceptual models or the underlying hypotheses, such as how basic.

32
00:06:14,840 --> 00:06:26,100
I'm really proud of you. No, it isn't.

33
00:06:27,490 --> 00:06:43,960
I mean, I remember driving through the whole industry wearing Asian saris in this country, in their groups for all the work.

34
00:06:44,170 --> 00:06:52,350
Yes, but you got it. Excellent for the way that that I suggest you change that.

35
00:06:52,800 --> 00:06:58,530
I'm sure that is just the way that I presented it to them.

36
00:06:58,560 --> 00:07:07,950
I think that meeting your vote in the election as the conditions to face it without your consent.

37
00:07:10,080 --> 00:07:15,810
And so I don't see the apprehension that happens here. Yeah.

38
00:07:16,180 --> 00:07:21,030
Yeah, I guess I'm thinking about that maybe a little bit more.

39
00:07:22,990 --> 00:07:40,230
You. That's right. But then on social media, too, and it's quite a different site, which is a branching rather than like what you saw.

40
00:07:44,280 --> 00:07:55,860
Right. Yeah. Did you did you get the like I'd say whatever you bring out of your own personal some people have

41
00:07:56,760 --> 00:08:10,410
that is completely accurate and I'm not exactly not one to consider how it relates to my girlfriend.

42
00:08:11,820 --> 00:08:18,080
True. Yeah.

43
00:08:38,670 --> 00:08:44,510
I have a question about. Sorry, you know.

44
00:08:49,430 --> 00:08:54,680
Yes. So when you're talking about counterfactual, is it right?

45
00:08:54,800 --> 00:09:00,240
Is it synonymous to say you're talking about the dolphins, like you're talking about the conceptual framework?

46
00:09:00,260 --> 00:09:05,329
Is that synonymous with the potential of this framework? I don't think so exactly.

47
00:09:05,330 --> 00:09:15,130
Because it seems like this framework is saying. I don't think it's necessarily referring to the exact person if that exposure wasn't there.

48
00:09:15,140 --> 00:09:21,590
It's more like a trial kind of thing. Right. But is a good question.

49
00:09:21,600 --> 00:09:54,120
Let me think about that for a moment and I'll give you a better answer. Sure.

50
00:10:01,270 --> 00:10:11,430
There. That is. But I don't know.

51
00:10:12,250 --> 00:10:19,850
I've never seen you. I.

52
00:10:39,790 --> 00:10:51,230
Compared to many other concepts of.

53
00:10:53,250 --> 00:11:01,440
Yeah, that's well, I really like the way they have to potentially continue his announcement.

54
00:11:02,190 --> 00:11:16,670
They're like, okay, let's. Yes.

55
00:11:16,700 --> 00:11:23,550
So the potential outcomes model is a way of sort of expanding on that actual idea.

56
00:11:23,640 --> 00:11:30,320
Right. It's a way of of formalizing this kind of actually in sort of thinking, really.

57
00:11:30,320 --> 00:11:32,110
Oh, what if this happens? This happens, right?

58
00:11:32,120 --> 00:11:37,999
But potential outcomes, I was assigning for these different this notation to it and thinking it through in that way.

59
00:11:38,000 --> 00:11:41,690
Does that make sense? Yes. So it's like a more formalized.

60
00:11:42,960 --> 00:11:49,920
It's like an extension of that, right? You can think of the counterfactual kind of a more abstract way, like what if that hadn't have happened?

61
00:11:49,920 --> 00:11:52,710
Or what if that person hadn't had that exposure and think it through in that way?

62
00:11:53,040 --> 00:12:01,520
But that's a little bit more of a, I don't know, specifying in a mathematical kind of notation sort of way.

63
00:12:01,530 --> 00:12:08,680
Yeah. Okay. So is that this is not what you.

64
00:12:08,810 --> 00:12:27,360
It never. And the things I.

65
00:12:32,890 --> 00:12:39,120
The mission. The person.

66
00:12:39,410 --> 00:12:50,230
It's not. That's true.

67
00:13:01,680 --> 00:13:22,190
But eventually. It's pretty much covered all over the horizon, even though.

68
00:13:28,940 --> 00:13:52,290
I love her that I think about that but I really like know she was a dad who is a presence I.

69
00:13:56,320 --> 00:14:13,810
I don't know how it might sound. I would like to hear my answer, but I guess I just can't do that either.

70
00:14:14,270 --> 00:14:24,170
Or is it more like I said before, you really can't bed.

71
00:14:24,470 --> 00:14:30,950
I mean, you have to have more conviction, so.

72
00:14:35,010 --> 00:14:47,430
But I suppose there is more in that little place and the importance of it that we heard what you said today.

73
00:14:57,520 --> 00:15:05,310
Yeah. Maybe you want to try something.

74
00:15:06,810 --> 00:15:11,850
I can see that the mute button is not on because when I click it it goes boop and shows me like a little red bar.

75
00:15:11,850 --> 00:15:18,600
But when I it was unclipped, so it was not muted. It's just that when I actually watched this was Yeah, yeah.

76
00:15:18,600 --> 00:15:27,210
But little eyes are on and everything. It's just that when I go into the Zoom meetings, if I try to unmute my video, it says that it can't start it.

77
00:15:27,430 --> 00:15:36,540
You don't have to right to the potentially you know so.

78
00:15:43,630 --> 00:15:49,550
Yeah. Yeah, that's fine. I don't like the way that.

79
00:15:53,530 --> 00:16:05,960
All right, I'll give that a shot. And if it doesn't work, I call you back, okay? And see the pictures that I put out of the president.

80
00:24:20,080 --> 00:32:12,830
You are. I need the towel.

81
00:32:13,040 --> 00:32:18,650
And then I think you can probably hear everybody pretty well from the owl, and we will be able to hear you.

82
00:32:20,120 --> 00:32:25,250
Daniel, can you hear us online? Sure. Somebody else talk.

83
00:32:26,210 --> 00:32:31,610
We have something. We owe you an email.

84
00:32:32,540 --> 00:32:39,560
Does that work? Yeah. Okay.

85
00:32:40,280 --> 00:32:43,280
We are also recording, so if you need to go back, you can do that.

86
00:32:43,700 --> 00:32:49,250
But maybe you can speak a little bit so that we can try to get Daniel to here.

87
00:32:49,280 --> 00:32:52,550
Okay. Go for it.

88
00:32:53,430 --> 00:32:54,410
I don't know. Like,

89
00:32:54,410 --> 00:33:05,680
maybe a third question is obviously in the back of his head or is it tensions between these different ways of thinking about causality and wondering,

90
00:33:05,690 --> 00:33:10,900
like, if anything, really this is like getting ready to go like once into the circumstance.

91
00:33:10,940 --> 00:33:23,330
Like this actually really works for me. So that's why I consider this together with other lives or something like this is like where I feel

92
00:33:23,330 --> 00:33:35,510
like I'm tired or do you want to do this to the average person who may have been through this before?

93
00:33:35,540 --> 00:33:39,620
It sort of recognizes that it's really hard.

94
00:33:48,410 --> 00:33:52,150
Well, yeah, I think so.

95
00:33:52,160 --> 00:33:55,070
I think so when I was reading these figures.

96
00:33:55,490 --> 00:34:02,570
My main objective is trying to orient in my head in a way that makes sense, like they're all interconnected in some way,

97
00:34:04,850 --> 00:34:09,230
and I think it's good to do them to start with and think about them separately.

98
00:34:09,230 --> 00:34:17,090
Right? Because for me, that would have always been the graphical extension of the problem.

99
00:34:17,480 --> 00:34:21,140
That's always how I've used it. I've never thought about it as any other way.

100
00:34:22,220 --> 00:34:33,529
And the sufficient component possible to me is always the appeal in a sense that represents interactions between different causes or

101
00:34:33,530 --> 00:34:46,120
different factors that something that thousand and I have been reading some papers about like how to represent interactions like that,

102
00:34:46,130 --> 00:34:54,350
that kind of confusion, that same thing that conversation frankly in the done within the conceptual framework.

103
00:34:55,010 --> 00:35:08,030
And there was a paper that was published like last year but that I think did a really good job of explaining interaction and in that format.

104
00:35:08,540 --> 00:35:15,439
So now to me the sufficient point was kind of loses all skill and especially I

105
00:35:15,440 --> 00:35:22,480
think the appeal of the current model is it is it turns you all the way through,

106
00:35:22,520 --> 00:35:30,680
carries you from thinking about all the way down to the equations to the structural model equations.

107
00:35:31,280 --> 00:35:39,980
That is like it's very easy to go from the dark for me to the Dawkins thinking the die or vice versa or whatever,

108
00:35:40,400 --> 00:35:48,200
and then go straight into the structural models and plug it into that source theta.

109
00:35:48,740 --> 00:35:52,520
And so that's. Yeah.

110
00:35:52,910 --> 00:35:57,500
So those are my $0.02. Does that make sense?

111
00:35:58,970 --> 00:36:04,010
Then we also do different things. But. Is there one that you really need?

112
00:36:05,430 --> 00:36:12,370
So for me, I struggle with that. Come out of this and get the gist of it I get as well.

113
00:36:12,380 --> 00:36:22,400
But I think it puts too much of the story. I think about the complexity of the problem and I do think about it.

114
00:36:22,400 --> 00:36:32,900
And so it's apparently quite productive. At the same time, I think that like it's good, it's good for you to, you know,

115
00:36:32,900 --> 00:36:44,090
it really sort of makes you focus on this sort of explosion in understanding and those who are faced with that and interested in like,

116
00:36:45,890 --> 00:36:57,199
where is this idea to bring her with her, which I think is very sensitive and so pluralistic approach.

117
00:36:57,200 --> 00:37:03,980
Any kind of thinking through all of these sort of different ways that there's like different pieces of the puzzle?

118
00:37:04,900 --> 00:37:08,809
Yeah, yeah. I think that's appealing to me too.

119
00:37:08,810 --> 00:37:12,860
It's like a concept consensus whenever people say that I just don't understand how to do it.

120
00:37:12,970 --> 00:37:15,140
Like like people I read a lot.

121
00:37:15,140 --> 00:37:23,570
We heard some people say such as this, but I don't ever read any papers where I see it being done and I see it being communicated.

122
00:37:24,670 --> 00:37:32,450
And, you know, I think that sometimes when let's say like it's the vision is like extra logical.

123
00:37:32,750 --> 00:37:44,029
But I think there's so much that I can do in terms of think the writer matters in terms of like using theory to like every and I mean,

124
00:37:44,030 --> 00:37:51,530
is it just that we discover that we don't do very well in terms of like to have like,

125
00:37:52,040 --> 00:37:53,150
I mean, these networks,

126
00:37:54,230 --> 00:38:05,900
these people that are like where is the thing years of taking specific measures that are presented at the state level so we get them.

127
00:38:06,350 --> 00:38:21,710
So she was mentioning like disability and people and the relationship between autism spectrum and Medicaid funding, how states that are distributed.

128
00:38:21,710 --> 00:38:34,010
They're going to be like if you think about like you're going to say, oh, people have bad opinions about people, it affects my kids.

129
00:38:34,280 --> 00:38:42,900
But she was like, We have to think about this, like in the context of history and of the future decision, like, oh, just different avenues.

130
00:38:43,440 --> 00:38:53,950
Then that suggests that these are about implicit bias in our sisters, which are issues, right?

131
00:38:55,490 --> 00:38:55,910
So like,

132
00:38:55,910 --> 00:39:09,420
that's really what like I feel like that's sort of shows to the side sometimes and I think that you really have to engage with the scientists.

133
00:39:10,610 --> 00:39:20,750
I think to that like to me all of these different all of the people who have kind of suggested these different approaches,

134
00:39:20,750 --> 00:39:26,000
they all come from a different scientific question area, right?

135
00:39:26,750 --> 00:39:32,119
So one person might be an infectious disease person, one person might be a cancer person, one person might be more of a social epidemiologist.

136
00:39:32,120 --> 00:39:38,810
Right. And so I think I think depending upon your question, some of these have more value than others.

137
00:39:39,350 --> 00:39:46,310
And I think that's why they all sort of land in a slightly different place maybe

138
00:39:46,310 --> 00:39:50,500
is because the person who gambles is like this is this is this is perfect.

139
00:39:50,510 --> 00:39:57,229
This really helps me think this through. But then the next person comes along is like the ones that really fit my question that I'm asking.

140
00:39:57,230 --> 00:40:01,470
It doesn't really help me for that question, you know what I mean? Like, so I think it's a good sign.

141
00:40:01,730 --> 00:40:05,299
That's probably why there's lots of approaches, because there's lots of different questions, right?

142
00:40:05,300 --> 00:40:10,519
And you're right. Like for something like you were just talking about, all of that context makes a huge difference.

143
00:40:10,520 --> 00:40:15,860
And some of these models are better at taking them into account than others, right?

144
00:40:16,370 --> 00:40:24,170
Yeah. Do you guys want to try question one to actually like or like questions one through?

145
00:40:24,950 --> 00:40:36,200
Yeah, I guess one like in a timeline format, we want to kind of list out the ones I mean so we started with the philosophy.

146
00:40:36,470 --> 00:40:36,770
Yeah.

147
00:40:36,860 --> 00:40:49,040
So her reference textbook sort of the notion of teaching, right, you have this operations and you try to make generalizations for all the universe,

148
00:40:49,190 --> 00:40:57,620
some of those observations, but that kind of thinking doesn't necessarily fit with hypothesis generation.

149
00:40:57,620 --> 00:41:01,130
So then we went into like the Russian mission.

150
00:41:02,480 --> 00:41:10,420
Clear the way to an incredibly long view of how we do something now where you have no hypotheses

151
00:41:11,860 --> 00:41:17,320
and your goal is to reject the null and you can't ever say an alternative hypothesis is true.

152
00:41:17,320 --> 00:41:20,680
You can just say that the noise you think is not true.

153
00:41:21,130 --> 00:41:35,350
Right. And then we went into the in theory, we were discussing this as long or I don't really understand necessarily how we can interact with like.

154
00:41:38,140 --> 00:41:45,550
The conceptual thinking, like the vision so busy enjoys walking through.

155
00:41:45,580 --> 00:41:55,290
What are you thinking? So Bayesian is where you have prior assumptions and that changes your interior assumptions and a certain

156
00:41:55,390 --> 00:42:06,620
number of interior for higher and posterior prior to posterior probabilities where they probably there.

157
00:42:07,630 --> 00:42:16,870
Are we? Sure. So you have. So your probability is your posterior probabilities are influenced by your prior knowledge.

158
00:42:16,890 --> 00:42:20,500
Yeah. So yeah.

159
00:42:20,500 --> 00:42:31,000
So that I understand Bayesian in terms of like when you're thinking about like just like thinking about probabilities,

160
00:42:31,000 --> 00:42:44,560
but I don't really understand it in context with the way that all things and statistics and also because I think pretty much everything we do is yeah,

161
00:42:45,370 --> 00:42:48,850
yeah, we don't actually do a lot of Bayesian modeling, you know, practice.

162
00:42:49,090 --> 00:42:56,079
And I feel like, I don't know, it's right to place a kind of control within three countries or Bayesian.

163
00:42:56,080 --> 00:43:03,340
But I mean, to me, it's, it's, it doesn't flow from either really perfectly.

164
00:43:03,370 --> 00:43:06,450
Which one does or doesn't support the counterfactual. Yeah.

165
00:43:07,150 --> 00:43:11,490
Well, I mean, it seems the way it's often described feels more deterministic, right?

166
00:43:11,500 --> 00:43:17,890
Like if you this person kind of exposure and they got the disease, if they didn't have it, would they have got the disease?

167
00:43:18,310 --> 00:43:22,730
I guess you could say if they if everything had been the same,

168
00:43:22,730 --> 00:43:27,459
but they hadn't had the exposure with their probability of disease have been less right.

169
00:43:27,460 --> 00:43:36,580
And that gets rid of a more probabilistic kind of framework as opposed to deterministic the Bayesian versus frequentist thing I guess of,

170
00:43:36,690 --> 00:43:41,520
you know, probabilistic the Bayesian and the.

171
00:43:41,560 --> 00:43:50,799
Yes, yes. So I guess if we're talking about just terms of thinking about things in terms of qualities,

172
00:43:50,800 --> 00:43:56,590
I guess you could say that as opened up in thus we now think that yeah,

173
00:43:56,590 --> 00:44:00,489
I guess I was thinking like if you can think of the counterfactual in probabilistic way,

174
00:44:00,490 --> 00:44:07,480
then you can add the piece of and my prior knowledge influences that probability in some way as well.

175
00:44:07,840 --> 00:44:12,490
But the point of the counterfactual is that your prior knowledge is networks.

176
00:44:13,330 --> 00:44:20,139
Yeah, I guess that's true because you're just it's more so a way of thinking about like intervention, like randomized trials.

177
00:44:20,140 --> 00:44:20,500
Yes.

178
00:44:20,710 --> 00:44:29,530
So it's like number one and also thinking about study design to read, like how would we find a comparison group that emulates that counterfactual?

179
00:44:29,620 --> 00:44:40,010
Right. But I think it's you're citing a category to like the premise of the argument.

180
00:44:40,660 --> 00:44:47,309
So you're thinking that the reason sort of like the project like principle is that it checks that

181
00:44:47,310 --> 00:44:58,570
people sometimes televisions cause homicides in places where there are more TV per 100% probability.

182
00:44:58,580 --> 00:45:14,260
So like deduction group says you must assume that that's 100% true if you go, whereas the basic research shows a good insight into that to 60%.

183
00:45:15,700 --> 00:45:19,570
So think about this other similar conflicts.

184
00:45:23,410 --> 00:45:27,930
Well, the contractual is not necessarily deterministic, but it's true.

185
00:45:28,030 --> 00:45:34,660
It's not necessarily saying, you know, like for every single person, it can change this and it will that.

186
00:45:34,820 --> 00:45:38,949
It's just more even think of like the individual as like a group of people as well.

187
00:45:38,950 --> 00:45:51,490
So, um, but I think it is like, I think what you were saying before about your area of research and how you think about it very differently for me.

188
00:45:52,300 --> 00:46:01,000
For me, well, I think what maybe a lot of those things are like when I think of studies, I always think of them in the way that we're taught.

189
00:46:01,000 --> 00:46:09,410
I think a lot of it is always the thing about the gold standard of person can get right, and that's like the whole foundation of a paragraph.

190
00:46:10,150 --> 00:46:18,490
But what more, describe to me that you weren't really thinking of it at all, and you work with me as like much more, much different study.

191
00:46:18,490 --> 00:46:22,629
I don't know what I would hope that kind of study, but I think that I think would be good.

192
00:46:22,630 --> 00:46:35,240
But yeah, like, I just like, totally I reject this idea other than because, like, I don't think.

193
00:46:36,380 --> 00:46:45,670
On pieces. I got one of them for the example that, like I was saying, like I was like this church thing, that like program now.

194
00:46:46,040 --> 00:46:56,850
So when I go back to this place that's going to say something like the context or that I would say, okay, let's take those people.

195
00:46:57,230 --> 00:46:58,910
Then imagine that they didn't smoke.

196
00:46:59,270 --> 00:47:08,680
It's just like the first one was in Central Park for like all these conditions that would make them more likely to smoke.

197
00:47:08,690 --> 00:47:12,770
And I don't want to make that comparison. So like, that's where I am then.

198
00:47:13,220 --> 00:47:17,780
But you're always rather than thinking about your your life,

199
00:47:19,550 --> 00:47:24,859
you're thinking about you're trying to think about how you would actually achieve the counterfactual.

200
00:47:24,860 --> 00:47:33,170
Right. And that that is possible. So I think if you're thinking about sort of just from a biological point of view, if they did not smoke,

201
00:47:33,170 --> 00:47:39,260
would they have like what our health problem that helps you think about whether the smoking is the

202
00:47:39,260 --> 00:47:43,010
thing you would want to intervene on and then you can start thinking about how would you do that?

203
00:47:43,010 --> 00:47:49,170
It's very difficult in this population. There's so many different things. It almost doesn't even make sense to be able to get them so they not smoke.

204
00:47:49,200 --> 00:47:58,939
Right. So I guess. I guess, yeah. You're almost wrapping in the how would you achieve an intervention with the is this the cause?

205
00:47:58,940 --> 00:48:02,179
Right. Which I guess is the ultimate goal. Right.

206
00:48:02,180 --> 00:48:09,500
But you have to first decide. I mean, I think the idea is just to try to pull out the piece of is this the thing causing the problem?

207
00:48:09,800 --> 00:48:21,620
Right. Yeah. But I mean, I guess the place where I struggle with like the question has to be the like the progress or whatever I say.

208
00:48:22,170 --> 00:48:27,380
Right. I would argue that it could actually be harmful to go in.

209
00:48:27,860 --> 00:48:39,680
So some people that look like, you know, if you really quit smoking, you're like, right, there should be no harm reduction, more harm.

210
00:48:39,830 --> 00:48:46,820
So yeah, I guess addiction there is like when people are publishing these like causal like the tone of the fact

211
00:48:47,250 --> 00:48:54,690
that they're obsessively in the same paper or saying things like saying we should intervene on this.

212
00:48:54,810 --> 00:48:59,350
Well, I think that's the next piece. Right. That helps you decide if that's what you should intervene on.

213
00:48:59,360 --> 00:49:05,630
But then there's if you were to draw that right, then there's all of the other stuff that leads to that outcome.

214
00:49:06,020 --> 00:49:11,750
Right. Smoking is there, but other things are related to the smoking and other things can lead to that outcome that you're interested in.

215
00:49:11,750 --> 00:49:15,090
And then there's other outcomes that can also be bad. And it's all kind of a web.

216
00:49:15,170 --> 00:49:24,889
Right. Yeah. But I think like, you know, the way that maybe we're trained like we don't want to sensationalize is that we're still with,

217
00:49:24,890 --> 00:49:32,630
you know, that there's still I want to know that like explicit times in a relationship rather than all these we get like,

218
00:49:33,290 --> 00:49:40,740
you know, some people would say we're ready for this sort of extraneous information because you just wanna understand this one, right?

219
00:49:42,050 --> 00:49:46,510
Yeah. And I think that that is the causal frameworks are to try to understand the relationship, right.

220
00:49:46,520 --> 00:49:49,910
That sort of what we're talking about, what exposure to this relationship.

221
00:49:50,240 --> 00:49:56,360
The next step, I think that isn't part of the conversation in these papers, is that what do you do with that information?

222
00:49:56,390 --> 00:50:00,679
Right. And I think they touch on it. Right. They talk about like bringing it to the public or whatever.

223
00:50:00,680 --> 00:50:05,270
But it's not like you could write ten papers about that piece, too.

224
00:50:05,560 --> 00:50:08,810
Right. Yeah. And so.

225
00:50:11,310 --> 00:50:13,110
All right. So we got up to Bayesian.

226
00:50:19,770 --> 00:50:26,070
Is there is there a is there a on the timeline that anybody else has something that we have a session that you think is important.

227
00:50:26,070 --> 00:50:29,070
But what do I do with.

228
00:50:34,150 --> 00:50:38,590
Because the guy is like easy of and then now we're going to get into like that is insufficient for that.

229
00:50:38,620 --> 00:50:49,240
And the other ones that were in fact is actually the location of the dock or what the dolphins are now with the YJ or the what.

230
00:50:49,240 --> 00:50:52,750
My favorite number. Yeah. That's within the outcomes. Clinical outcomes.

231
00:50:52,750 --> 00:50:58,780
Yeah. Sorry, I swear to God I heard you saying Dropbox. I know what you're talking about that that's not a causal framework.

232
00:50:59,810 --> 00:51:07,380
Sorry. Yeah. Oh so yeah we, we are pretty sure you know what I'm saying.

233
00:51:07,390 --> 00:51:10,960
I just decided that I couldn't really grab a fisherman.

234
00:51:11,610 --> 00:51:15,550
I say, like in notorious weaknesses.

235
00:51:15,700 --> 00:51:26,170
Why not? Just like I would just like to see how there's a lot of that in science history, public health, especially.

236
00:51:26,170 --> 00:51:29,590
It's not that it's there. There's a lot of it. It's it's real.

237
00:51:29,590 --> 00:51:34,119
GROSS I agree. And that's a whole other question, right?

238
00:51:34,120 --> 00:51:39,790
Do we take is any of what they said valuable in in that context?

239
00:51:39,790 --> 00:51:59,670
Right. Um, I don't know the answer to that. Um, so some of the things I put in there was actually that I was new to do that that was approved for now.

240
00:51:59,680 --> 00:52:01,120
We're not super confident about that. Yeah.

241
00:52:01,120 --> 00:52:07,150
What about we will we will we will all become more confident about that right in our program from our friends,

242
00:52:07,150 --> 00:52:13,220
if it's done so in an automatic way or for many years.

243
00:52:14,970 --> 00:52:25,510
Well, I think it's well, I think like in a basic sense, I mean, I think we're thinking more how you're thinking basics and starting with visual.

244
00:52:25,510 --> 00:52:37,720
And to me it's like always like looking at a diagram if you see something is like it's just looking at the dog and getting rid of all the confounders.

245
00:52:38,290 --> 00:52:42,550
It doesn't just as potentially interesting for all the things that you need to adjust for to have a proper relationship.

246
00:52:43,480 --> 00:52:46,090
So that's why I think those two are so compatible.

247
00:52:46,270 --> 00:52:53,140
Yeah, I always draw that is because when I look at this dog especially you have like, you know, 20, 30 variables.

248
00:52:53,500 --> 00:53:01,500
I can look at that and I can come up with an equation to plug into your structural over the original look based on that.

249
00:53:02,380 --> 00:53:06,910
But I think like it could be much more complicated I guess.

250
00:53:06,910 --> 00:53:11,109
But the basic level, that's how your brain is.

251
00:53:11,110 --> 00:53:19,390
Yeah, that makes sense. It looks like why one like this like zero and see you know.

252
00:53:20,680 --> 00:53:28,580
Yeah exactly. And you can see exactly or to adjust for what's not just for one thing,

253
00:53:28,690 --> 00:53:36,700
just something like if you're trying to do it at one of the papers or in the paper mentioned something that I thought was really important.

254
00:53:36,700 --> 00:53:43,090
And I don't think anyone really emphasizes this, but when you adjust for like an intermediate, the people will tell you to do that all the time.

255
00:53:43,090 --> 00:53:45,490
Interviews, they'll say, you know, just an intermediate.

256
00:53:46,210 --> 00:53:54,699
But the best case scenario is that you get the doctor, right, the direct association between exposure outcomes.

257
00:53:54,700 --> 00:54:02,440
Yeah, but oftentimes that's not the whole picture because there could be other variables like confounders that affect the behavior and outcomes.

258
00:54:02,800 --> 00:54:12,609
And by adjusting for the mediator, you also are doing like wider stratification and then you're introducing confounding.

259
00:54:12,610 --> 00:54:21,760
So it's got to hold us back. So I will also tell you, though, the vast majority of people who are going to be reviewing your neighbors,

260
00:54:21,760 --> 00:54:25,330
that you really are not going to have thought about it in that level of detail.

261
00:54:25,810 --> 00:54:31,389
How are you to adjust for me here and I had this argument with Kayla,

262
00:54:31,390 --> 00:54:34,960
maybe it's because she was like, no, that's a mediator and it does work like here.

263
00:54:35,160 --> 00:54:41,410
But in order to get the same answer, just do it. Put it in there as like and also read it this way.

264
00:54:41,410 --> 00:54:45,049
Look, we did it didn't change anything, but you and I know it's wrong, but like,

265
00:54:45,050 --> 00:54:50,650
do you even either have a methods master class in your review responses or you

266
00:54:50,650 --> 00:54:55,689
can do what they ask if you only want to die on the hill if it actually matters,

267
00:54:55,690 --> 00:55:01,900
right? So if you put it in there, it doesn't change anything like that. It doesn't for nothing happens, you know, sort of saying.

268
00:55:01,900 --> 00:55:05,220
But then then it's I do have mixed feelings about.

269
00:55:05,240 --> 00:55:11,830
Right. Because you're you're not changing the way we do science.

270
00:55:11,830 --> 00:55:14,920
You're just sort of propagating this error that keeps happening.

271
00:55:15,610 --> 00:55:21,280
But on the other hand, like particularly if you're not going to be the LNG Journal and your reviewers,

272
00:55:21,280 --> 00:55:26,560
maybe your clinicians like I might get an oncologist who has met cancer research and this review in my head and neck cancer paper,

273
00:55:27,640 --> 00:55:31,510
I want to get this paper published. I think it's important for the results to be out there.

274
00:55:31,890 --> 00:55:36,600
Is it wrong? You wouldn't want me to do, especially since it's not getting around.

275
00:55:36,620 --> 00:55:42,100
I can tell it's not getting a wrong answer. Right? It's placating and then we go forward.

276
00:55:42,980 --> 00:55:48,109
It's a really I think that's a hard to me. That's a great question. Right, because we learn all this stuff.

277
00:55:48,110 --> 00:55:55,700
We know how to do it. We know the right way to do it. And you could have the argument, but it's probably not going to get you where you want to be.

278
00:55:55,850 --> 00:55:59,390
Right. I guess that's part of the argument, this issue.

279
00:55:59,390 --> 00:56:04,770
And I think now because there are there is a mediation model.

280
00:56:04,790 --> 00:56:10,760
And yet what we ended up doing is someone as good as her intermediate variable.

281
00:56:11,060 --> 00:56:17,360
So we have to do like a completely financial table to do across the mediation and said,

282
00:56:17,750 --> 00:56:21,400
well, we could have just included in the model and it would have been like 2 seconds.

283
00:56:21,410 --> 00:56:24,139
But yeah, it was a lot more work.

284
00:56:24,140 --> 00:56:32,450
But I think, I mean ultimately the answer was pretty much the same graphically, but I still think it's important to do the mediation because.

285
00:56:33,650 --> 00:56:37,090
Yeah, so again, I think it depends on context that yeah, that's true.

286
00:56:37,100 --> 00:56:42,530
There are some audiences that are not going to understand it and they're not going to be able to evaluate it critically.

287
00:56:42,530 --> 00:56:47,810
And so here would be very specific, like, you know, and you might know everything, okay?

288
00:56:47,810 --> 00:56:48,889
They probably know what they're talking about.

289
00:56:48,890 --> 00:56:53,519
Remind of the universe, like, I don't know what this means, so I'm going to protect the paper and maybe that's fine.

290
00:56:53,520 --> 00:56:57,380
You've got an external I don't know. But, you know, maybe like it's hard.

291
00:57:01,540 --> 00:57:07,270
Okay. So are we done with our timeline? Is anybody have any anything to add that they really didn't get added to the timeline appropriately?

292
00:57:12,020 --> 00:57:16,970
Well. So I heard that's, you know, with Karl Rove about the situation.

293
00:57:17,120 --> 00:57:20,480
But I was not all that involved in 1974.

294
00:57:22,400 --> 00:57:36,350
And then like in 1998, the whole causal principal theory was kind of spearheaded by Raymond Robbins and.

295
00:57:38,050 --> 00:57:47,810
Um, but I think that's pretty much this in a pluralistic approach that was in front of it right then.

296
00:57:49,490 --> 00:57:52,610
But again, when I was reading that, people are just going to know what they were talking about really.

297
00:57:52,940 --> 00:57:59,060
Like, I understand the idea and understand the thought. I just don't understand how to do it.

298
00:57:59,390 --> 00:58:01,010
Or like a plan. I don't why?

299
00:58:01,010 --> 00:58:09,170
It's like, yes, I understand that all modeling is inherently limited because you're modeling something in numbers and you're not numbers.

300
00:58:10,010 --> 00:58:19,160
But I just when they say like using rabbit evidence, incorporating the messiness, it's like I do that right now.

301
00:58:19,370 --> 00:58:30,010
So yeah. And I think that's a big issue for him.

302
00:58:30,670 --> 00:58:46,630
I do. And he will actually have stronger, even stronger assumptions about each other the of possibly that which is also subjective at the same time.

303
00:58:47,500 --> 00:58:54,390
It is more a logical sense that we're going to have to have lots of consistent

304
00:58:54,760 --> 00:58:59,470
disinformation campaigns and concepts about interactions and for example,

305
00:58:59,680 --> 00:59:02,920
that so many people have interactions.

306
00:59:04,240 --> 00:59:08,349
Yeah. So yeah. So that's that's a practical thing too, right?

307
00:59:08,350 --> 00:59:14,440
You need a really big sample size to replicate interactions. Like there's a lot of places that love to do interactions, but I just don't have,

308
00:59:15,490 --> 00:59:21,250
you know, verbal interaction by my race is a very good example, right?

309
00:59:21,280 --> 00:59:28,090
Like so many cancer studies that are now mature that have enough cases to do anything with are like 95% white.

310
00:59:29,170 --> 00:59:32,289
And so how would you ever do for a rare cancer?

311
00:59:32,290 --> 00:59:36,600
How would you ever stratify your sample size enough to actually iterate an interaction by race?

312
00:59:36,610 --> 00:59:49,150
You can't do it right. So I think a lot of it and I think if you do the math for like statistical significance and sample size for interactions,

313
00:59:49,150 --> 00:59:59,099
it's not just like twice as like some sort of. Multiplicative amount, the easy right is to find an interaction.

314
00:59:59,100 --> 01:00:03,390
You need an even bigger sample size. Then it's a kind of a meta fact.

315
01:00:04,050 --> 01:00:09,300
So yeah, it's a problem. I mean, you know what?

316
01:00:09,300 --> 01:00:15,590
I tend to try to regulate, whereas the,

317
01:00:15,750 --> 01:00:28,320
the researchers idea that like are kind of like the entirety of evidence actually does not serve or never reflect the reality.

318
01:00:28,890 --> 01:00:34,140
It doesn't serve our endeavors.

319
01:00:34,890 --> 01:00:45,210
And I think also it sort of forecloses opportunities to like consider other forms of evidence outside of our field.

320
01:00:45,540 --> 01:00:56,310
It's sort of like this place is very sort of narrow niche operation that like doesn't consider like I

321
01:00:56,310 --> 01:01:06,030
think I always think of like everything reality is like one piece of work that is needed to advance.

322
01:01:08,040 --> 01:01:11,220
And I think sort of like you say, you know,

323
01:01:11,270 --> 01:01:19,920
your your study in order to have to study questioning in some way reflects the premises the person is doing,

324
01:01:20,550 --> 01:01:28,110
you know, something that's just like within the some of the stuff that I want to stress.

325
01:01:30,030 --> 01:01:39,420
You know, what I think about this quote tomorrow, it would be like sometimes are stories that are greater than the truth, you know?

326
01:01:39,420 --> 01:01:48,270
And I think that science is really a very rigid notion that, like, what are the clauses that sort of miss the forest?

327
01:01:49,330 --> 01:01:53,429
Yeah, well, and to me, this idea of pragmatic pluralism, I agree.

328
01:01:53,430 --> 01:01:56,340
They didn't, like, give you a roadmap for it, but it was all to me.

329
01:01:56,340 --> 01:02:07,620
It was almost like permission to use whatever tools are most that make the most sense to you, that make the most sense for your question.

330
01:02:07,980 --> 01:02:15,030
I mean, it was kind of it's like, hey, there's lots of to me when I read it, I read, hey, there's there's lots of choices here.

331
01:02:15,330 --> 01:02:19,709
They all have some good some bad like use.

332
01:02:19,710 --> 01:02:23,789
What makes the most sense for you to help you make the best decision you can?

333
01:02:23,790 --> 01:02:29,170
Sort of like giving mostly the control back to the researcher, right?

334
01:02:29,170 --> 01:02:33,060
To kind of make your own decision about what you think. These are all tools you can use.

335
01:02:33,300 --> 01:02:37,680
You can pick and choose. I'm going to use the one that helps you get to what you think is the best answer.

336
01:02:38,030 --> 01:02:40,260
I was giving you back some agency or some.

337
01:02:40,830 --> 01:02:47,429
What's the word I'm try to come up with like like making it your like you get the decision making power, right?

338
01:02:47,430 --> 01:02:52,770
You're not, like, beholden to this model and you kind of get to decide, ideally, this is the totality.

339
01:02:52,770 --> 01:02:58,980
What you're saying is like the totality of everything I've you try to use tools at my disposal to kind of come up with this.

340
01:02:59,850 --> 01:03:04,350
This answer is that I think that summary because I'm so right.

341
01:03:05,100 --> 01:03:16,800
Yeah. I mean, to echo in both your parents point, I think everything else is kind of confused or maybe I'm confused, but I'm really confused.

342
01:03:16,800 --> 01:03:21,870
It's like about what what we are in terms of a scientific discipline.

343
01:03:22,380 --> 01:03:22,680
Right.

344
01:03:22,800 --> 01:03:35,940
You know, I always I assumed that we were wanted to make this point, but but I also feel like most of our coursework are necessarily quantitative.

345
01:03:36,720 --> 01:03:47,459
And then if we're doing it, we're expected to like do more qualitative research with more nuance.

346
01:03:47,460 --> 01:03:50,490
I just don't know how to do it because we haven't been taught that either.

347
01:03:50,820 --> 01:03:55,410
So it's like I'm kind of like I'm like, this is what we've been taught.

348
01:03:55,980 --> 01:04:03,330
I am aware that it's probably not like the the complete picture, but I just don't know what else to do.

349
01:04:03,600 --> 01:04:08,950
Yeah, I mean, what do you guys think of this? I feel like we are a logical discipline.

350
01:04:09,100 --> 01:04:20,160
This is not a project like epidemiology is almost like this is this way of thinking through logical questions and logical research questions.

351
01:04:20,160 --> 01:04:23,549
And then you use a lot of quantitative tools to help you build on that.

352
01:04:23,550 --> 01:04:29,279
But it's like you take it when you integrate like quantitative results plus the biological knowledge and

353
01:04:29,280 --> 01:04:33,480
kind of all of this causality thinking as well to kind of come up with what you think the answer is.

354
01:04:34,890 --> 01:04:39,360
And to me, it's kind of like integration and it's almost a system of logic rather than.

355
01:04:43,710 --> 01:04:49,980
Yeah. That's what I figured it was like when I worked for the state in Arkansas.

356
01:04:50,340 --> 01:04:58,740
I mean, that's pretty much what it was, but we would do a lot but, you know, plenty back then trying to figure out,

357
01:04:59,040 --> 01:05:04,200
you know, what we're doing and what we're doing and then all the questions.

358
01:05:04,440 --> 01:05:14,110
That's neat. No, but. At the same time, in looking at that, you have to give the recommendation.

359
01:05:14,170 --> 01:05:17,890
You have to make choices with it to keep things going.

360
01:05:18,470 --> 01:05:28,210
So I felt like my job, even though I was at the training, was like, you're not just only doing that.

361
01:05:28,510 --> 01:05:38,290
Like, you have to do it to look at the whole picture because you can look at the numbers, but they only tell me a little bit of the story.

362
01:05:39,160 --> 01:05:44,920
So. Somehow there is great and I feel it too.

363
01:05:44,940 --> 01:05:50,070
It's like, I don't know. It's not for me. I feel like I always kind of have one foot in each camp.

364
01:05:50,070 --> 01:05:55,320
Like, I really like the science and the biology and I think all this stuff is very interesting and understand.

365
01:05:55,710 --> 01:06:00,000
I'm very interested in understanding how all this works and what causes cancer.

366
01:06:01,290 --> 01:06:04,199
I also want to be able to do something about it. Do you know what I mean?

367
01:06:04,200 --> 01:06:07,230
So it's like you're almost pulled in two directions because you have to come up

368
01:06:07,230 --> 01:06:11,520
with the science answer and then decide what you can do with that information.

369
01:06:11,550 --> 01:06:15,929
Right. And it's I don't know, it's a little bit of a it's a hard place to be.

370
01:06:15,930 --> 01:06:20,770
And it involves a lot of like kind of logic and decision making, I think.

371
01:06:20,790 --> 01:06:26,970
And that's kind of that's kind the role, I think, of the Ph.D. researcher as opposed to the master's level.

372
01:06:26,970 --> 01:06:32,400
Right at the master's level, you're kind of like creating the number piece, right?

373
01:06:33,030 --> 01:06:36,689
You're like managing the data. You're doing the quantitative work. Come up with the numbers.

374
01:06:36,690 --> 01:06:41,640
And I'm at the Ph.D. level. It's more deciding what it means and what to do about it next.

375
01:06:44,530 --> 01:06:47,740
Which is sometimes uncomfortable, I think, but important.

376
01:06:47,980 --> 01:06:54,460
Right. Sometimes it makes you go, Oh, oh, no, it's me.

377
01:06:55,240 --> 01:07:00,010
I'm the adult. Is there an adult here? No, no, no.

378
01:07:00,010 --> 01:07:04,659
It's me. Okay. All right. I guess I'll, um. I guess I'll design something that.

379
01:07:04,660 --> 01:07:12,210
Wow. Okay. Yeah.

380
01:07:12,280 --> 01:07:16,200
There you go. Yeah. We can all decide together. Absolutely.

381
01:07:18,700 --> 01:07:22,540
All right. So do you want to think through? We have about a little over 5 minutes left.

382
01:07:22,540 --> 01:07:26,380
So what was the example that you guys thought through and what was like the the.

383
01:07:29,320 --> 01:07:32,710
Oh, yes. The method you decided to apply.

384
01:07:33,110 --> 01:07:40,900
All right, so maybe you have 3000. So, like I alluded to there, just like it frightens opponent.

385
01:07:40,910 --> 01:07:45,930
Fractional part of the ways in which a strain is like smoking.

386
01:07:46,330 --> 01:07:55,659
Yeah. Which is how we like to think these other approaches and making we're going

387
01:07:55,660 --> 01:08:02,740
to rally around those this causes of the causes a very sensible approach so

388
01:08:06,300 --> 01:08:09,939
that any other groups have a different example to be thought through and a

389
01:08:09,940 --> 01:08:13,660
different the different causal frameworks that they use to think it through.

390
01:08:17,760 --> 01:08:23,650
Somebody just did like six or something like that.

391
01:08:24,150 --> 01:08:27,440
That's okay. Yeah.

392
01:08:27,610 --> 01:08:33,030
Yeah. But yeah, I would like to. But did you feel like it helped or do you feel like it was missing a piece?

393
01:08:33,150 --> 01:08:36,540
Like, what was your what was your question that you were wanting to read?

394
01:08:36,720 --> 01:08:41,730
It's something known. Right?

395
01:08:43,500 --> 01:08:47,740
Yeah. One quick question.

396
01:08:48,030 --> 01:08:51,210
Did you feel like there was. Did you feel like it worked? What did you feel like?

397
01:08:51,210 --> 01:08:55,250
There was a limitation to it that that a different approach would address.

398
01:08:56,130 --> 01:08:59,970
Yeah. You did work for them? Yeah.

399
01:09:04,580 --> 01:09:11,600
Well, I think that I mean, I think what this illustrates is that there are some things that are better suited to some of these problems than others.

400
01:09:11,990 --> 01:09:19,939
And so I think kind of the more traditional the more traditional AP you get with your exposure to these outcomes, kind of the better.

401
01:09:19,940 --> 01:09:27,230
A lot of these, especially earlier ones that, you know, I mean, you're talking about a very social AP kind of question,

402
01:09:27,230 --> 01:09:32,719
like in the context of homelessness and all of these social determinants and social pressures,

403
01:09:32,720 --> 01:09:36,500
like is this thing that we think of as an obvious thing that should be improved?

404
01:09:36,500 --> 01:09:43,219
But is that really that we should be afraid of? Right. And that's a more it's a more moderate kind of.

405
01:09:43,220 --> 01:09:52,370
QUESTIONER Jeremy, like in terms of I think traditionally when we think of AP originally, I think we're thinking about infectious disease questions.

406
01:09:52,670 --> 01:09:57,800
Right. Which are certainly more I would say, more straightforward in terms of causality.

407
01:09:57,860 --> 01:10:06,260
Right. It's easier to there's one thing mostly that causes this disease.

408
01:10:06,260 --> 01:10:12,230
It's close in time to generally get the infectious agent diseases produced.

409
01:10:12,260 --> 01:10:20,179
It's a little more I mean, a little more clear cut, I would say then when you're trying to then go to more of a chronic disease situation where

410
01:10:20,180 --> 01:10:24,440
there's like lots and lots of things that contribute and the timeline is a lot longer.

411
01:10:24,480 --> 01:10:30,920
And I think a lot of these later paradigms that these later models,

412
01:10:30,920 --> 01:10:37,010
these later ideas that of what we're trying to then incorporate more and more and more complexity with varying levels of success.

413
01:10:37,010 --> 01:10:44,839
So that even through that many proponents of sort of a counterfactual the radical exam

414
01:10:44,840 --> 01:10:51,800
instead of actually determining potential outcomes here or least is more mechanistic.

415
01:10:54,860 --> 01:11:01,460
Yes. But it's not what causes something, but how it causes that.

416
01:11:01,460 --> 01:11:05,230
You're making more assumptions based on existing evidence.

417
01:11:05,280 --> 01:11:09,890
Yeah. So but then, you know, the question of what to do about it becomes even more complicated.

418
01:11:10,070 --> 01:11:13,880
Like even if you could hear that and they say this causes that, but you can't hold that back.

419
01:11:14,030 --> 01:11:19,520
Right. And it structures in them. And so we should just stop that.

420
01:11:20,180 --> 01:11:25,500
But we should. Yes. But also not something that is straightforward.

421
01:11:25,500 --> 01:11:29,680
It's just. Right. What were you going to say?

422
01:11:29,720 --> 01:11:33,530
It didn't interrupt. Sorry. Oh, no, you're fine. So you're just, like, looking at which are.

423
01:11:37,640 --> 01:11:43,030
I said, I think I can give you a reason to like some counterfactuals that were conditional.

424
01:11:43,490 --> 01:11:47,330
And the counterfactual that you're imagining requires changing of an entire system.

425
01:11:47,900 --> 01:11:52,270
So if you're thinking of some intervention that generates that,

426
01:11:52,430 --> 01:11:55,610
if you're if you're trying to block the intervention that would generate the current factual,

427
01:11:55,610 --> 01:12:01,540
that's impossible when you're thinking of systemic change, because then everything changes something else, right?

428
01:12:01,550 --> 01:12:05,480
It's almost like there's too much that the butterfly or the butterfly effect, right?

429
01:12:05,660 --> 01:12:09,970
Change one thing and then suddenly everything else is actually different and then you get the outcome a different way, right?

430
01:12:09,980 --> 01:12:16,670
So we're back to humans going back in friendship together with that idea and two

431
01:12:16,670 --> 01:12:24,320
separate questions like what is saying if this happens in this context with this,

432
01:12:24,590 --> 01:12:27,800
they're not saying it will happen. If they're going to say it should happen.

433
01:12:27,960 --> 01:12:35,090
Are you saying it is and you're saying, yeah, that's true, has happened to this outcome.

434
01:12:35,090 --> 01:12:41,830
But then kind of because I think a lot of it is like we can't anticipate like what it is we can say like,

435
01:12:41,840 --> 01:12:47,410
oh, this was the exposure and oh, this is the effect. But we're doing that based on.

436
01:12:50,450 --> 01:12:56,840
And like other people that have established that, not necessarily like our cities or Newark,

437
01:12:56,840 --> 01:13:02,600
that has established that, like when I say all of this, like structural policy has generated today's outcome.

438
01:13:02,960 --> 01:13:09,190
I'm building off of work about that policy and not necessarily about the health outcomes.

439
01:13:10,040 --> 01:13:18,140
Any sentence. So like for me, the health outcomes isn't necessarily a counterfactual because there is the counterfactual

440
01:13:18,140 --> 01:13:24,730
to the upstream policy is that I can't I can't actually change that with it.

441
01:13:25,160 --> 01:13:30,610
And so it's kind of understanding like the mechanism by which that policy is actually held outcomes.

442
01:13:30,830 --> 01:13:41,850
It's almost like an effect modification approach to future interventions as opposed to trying to revert to the counterfactual, the initial exposure.

443
01:13:42,620 --> 01:13:49,760
What we found is that one of the one of the requirements for an actual framework is that interventions have to be clear cut.

444
01:13:50,040 --> 01:13:52,070
Like. Right. That's like saying that's what it is. Yeah, right.

445
01:13:52,340 --> 01:14:01,190
And so you're saying like, okay, but even if the counterfactual is like, oh, well, what if we just hadn't passed this law?

446
01:14:01,850 --> 01:14:06,210
But almost everything we had written that you can't just undo it.

447
01:14:06,240 --> 01:14:17,269
Right. Right. As opposed to a lot of stuff is, you know, now that you're just not smoking or taking a supplement or do anything,

448
01:14:17,270 --> 01:14:25,429
I guess that's much more clear or specific that somehow you didn't argue with that.

449
01:14:25,430 --> 01:14:36,380
Like to take out the context from what was like in the way that, you know,

450
01:14:36,380 --> 01:14:41,209
if it has an effect on the way that you think about moving the system because if

451
01:14:41,210 --> 01:14:46,730
we're not looking at this described like we're not improving the architecture.

452
01:14:47,540 --> 01:15:01,320
Okay. Yeah. I think also that the way you generate counterfactual based on that and like up here, I feel incredible.

453
01:15:01,340 --> 01:15:06,829
But it's like I said before because looking back, I think you could kind of divorce those two, right?

454
01:15:06,830 --> 01:15:11,959
If you just want to know if the smoking was causing the outcome, that's fine.

455
01:15:11,960 --> 01:15:15,670
But then the question of what to do about it, I think the validity issue and the like,

456
01:15:15,690 --> 01:15:22,450
I think what you're thinking of a lot of like social activist structural issues that matter here is that exposure from

457
01:15:22,460 --> 01:15:30,130
relationships that facilitated question like kind of like if we know from our species what smoking impacts one another,

458
01:15:30,470 --> 01:15:34,080
that's one we have about that. We don't we don't get around lots of pictures out.

459
01:15:34,240 --> 01:15:37,640
No, no. You know, from like more.

460
01:15:38,030 --> 01:15:44,540
I know. I'm like pure. Yes. Study is like more controlled studies where like smoking is the one thing that

461
01:15:44,540 --> 01:15:49,550
we are isolating that when we try to apply it to a situation where you can't.

462
01:15:49,550 --> 01:15:52,820
Are you similar? Yeah. Well and I think that's true in a lot of situations.

463
01:15:52,820 --> 01:15:55,850
Do I mean, that's the difference between efficacy and effectiveness, right?

464
01:15:57,200 --> 01:16:02,630
Efficacy can be proven in our city is that if you try to apply it, it doesn't work.

465
01:16:02,630 --> 01:16:08,720
Right. And I think you're talking about almost a more a bigger, messier version of that.

466
01:16:11,240 --> 01:16:16,040
All right. Well, that was an interesting discussion, guys. Thanks. Remember no.

467
01:16:16,790 --> 01:16:22,820
To Tuesday. You're going to do actually, you can get all your reading done.

468
01:16:23,030 --> 01:16:27,600
Oh, no class on Tuesday. I hope I have an all day video clip.

469
01:16:28,550 --> 01:16:34,370
So what does that mean for Thursday? Thursday's episode from now on Thursday will be the lecture.

470
01:16:34,850 --> 01:16:42,560
Tuesday will be the second time when I hear those things which I think I should get my fingers and you get the weekend.

471
01:16:42,560 --> 01:16:46,680
So yeah, that's a little bit too. Are you enjoying anything?

472
01:16:47,510 --> 01:16:49,650
Yeah, I did. I told you I'd be all right by the.

