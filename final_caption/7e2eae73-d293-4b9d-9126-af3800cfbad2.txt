1
00:00:01,140 --> 00:00:08,040
All right. Let's continue our discussion on the mark of chain Monte Carlo.

2
00:00:09,730 --> 00:00:13,270
So last time we established this theoretical resolves,

3
00:00:14,290 --> 00:00:26,620
which is if you want to use the Monte Carlo method to do statistical computing or you want basically use sampling based on method,

4
00:00:27,070 --> 00:00:30,220
you don't have to rely on the assumptions, right?

5
00:00:31,240 --> 00:00:36,400
There is a law of large number for Markov chain.

6
00:00:36,730 --> 00:00:40,750
So you could design Markov chain and sample from it.

7
00:00:40,930 --> 00:00:53,740
So you have the theoretical result from the law of large numbers that gave you the sampling result will converge to the expectation.

8
00:00:53,950 --> 00:01:07,419
I, I, yeah. I don't want to write the whole thing again, but you get that part one of the often used applications,

9
00:01:07,420 --> 00:01:14,620
or this is the most of most common application scenario.

10
00:01:16,800 --> 00:01:22,920
It's the following. So let's talk about the implementation of this.

11
00:01:23,220 --> 00:01:33,750
So in theory, we know we could do it, but we still need a general recipe to carry out the sampling rhythm.

12
00:01:33,780 --> 00:01:38,730
So this is what we got in top today from the Los.

13
00:01:41,510 --> 00:01:57,380
Hastings. I believe both of them are physicists.

14
00:01:58,470 --> 00:02:04,590
Um. So this is the application scenario.

15
00:02:04,610 --> 00:02:18,670
We have a target distribution we want to sample from, but we only know the target distribution up to a normalizing constant.

16
00:02:19,120 --> 00:02:23,770
So this is a pie of J equal to each.

17
00:02:28,450 --> 00:02:40,020
So this is a example. So the word, you know, currently focusing on, we're focusing on the a discrete distribution, right.

18
00:02:40,030 --> 00:02:47,020
So this. Well, the reason is we can do that discrete state Markov chain to achieve the goal.

19
00:02:47,560 --> 00:02:52,810
So pie of J is essentially this probability.

20
00:02:56,980 --> 00:03:02,720
So this isn't a target distribution, but you only know this distribution up to the normal, I think.

21
00:03:02,980 --> 00:03:11,170
Well, you know, but V is unknown. So this is the normalizing constant, the B of J you can calculate.

22
00:03:12,370 --> 00:03:19,810
So last time we gave a example, this is a very common scenarios in Bayesian calculation.

23
00:03:21,220 --> 00:03:26,500
One of the disclaimer is you could extend this to continuous distribution.

24
00:03:26,500 --> 00:03:29,830
There is no issue because, well, think about this way.

25
00:03:30,400 --> 00:03:37,000
If you do some porting method, are you essentially or discrete inside?

26
00:03:38,710 --> 00:03:41,890
But continuous distribution to a very fine scale.

27
00:03:42,250 --> 00:03:50,650
So this is the. So you that you are also kind of at some point from a discrete distribution,

28
00:03:50,660 --> 00:03:55,640
trying to use a discrete distribution to approximate a continuous distribution.

29
00:03:57,080 --> 00:04:02,270
So even the target distribution is continuous. This, this type of thing still works.

30
00:04:04,910 --> 00:04:17,270
So we know this distribution, we know V of J. So in the Bayesian situation, the BFG essentially is the prior multiplied by the.

31
00:04:18,270 --> 00:04:23,420
Right. So you have seen a lot of well,

32
00:04:23,450 --> 00:04:33,559
maybe you have seen some of the phasing calculation the prior usually is and then the likelihood that usually I know I think retractable.

33
00:04:33,560 --> 00:04:44,810
So you can directly calculate that but the difficulty is compute this B which is requires that you sum over all possible scenarios.

34
00:04:44,900 --> 00:04:47,900
So that's it's a really intractable part of that.

35
00:04:49,190 --> 00:05:06,470
So this is acceptable in using communication clear on.

36
00:05:14,000 --> 00:05:20,240
So without the capital B, you cannot do what we cannot do.

37
00:05:20,420 --> 00:05:27,560
It is unfolding and not preventing us to perform any sort of policy or inference.

38
00:05:28,250 --> 00:05:32,080
We cannot draw the policy or some point alone.

39
00:05:32,660 --> 00:05:44,250
So this is the situation where we can use mark of training to.

40
00:05:57,150 --> 00:06:03,660
All right, so this is the setup. Any questions about this? So B.J. is computable.

41
00:06:03,840 --> 00:06:11,570
We could just easily evaluate. You don't know the capital B, and this is a target distribution.

42
00:06:11,610 --> 00:06:19,560
Want to draw a sample from it? Right. So the idea the key idea here for.

43
00:06:25,030 --> 00:06:32,410
So we need to design a boarding.

44
00:06:37,470 --> 00:06:53,820
With stationary distribution being high energy.

45
00:06:56,830 --> 00:07:01,780
So what we can do is just simply. Well, I mean, that's one way to think, right?

46
00:07:01,810 --> 00:07:05,049
You need to exhaust all these available tools.

47
00:07:05,050 --> 00:07:11,590
One of the things, if you see this type of thing that can now be done through I.D. sampling,

48
00:07:11,590 --> 00:07:17,110
through the so called rejection, at some point, then you need to resort to the turn of the way.

49
00:07:17,470 --> 00:07:22,390
One of the alternative way you have is this based on the theoretical result.

50
00:07:22,390 --> 00:07:27,400
If we have a markov chain and then that stationary distribution is the target distribution,

51
00:07:28,180 --> 00:07:35,650
then we can also sample from it the base of the law of large number for Markov chain.

52
00:07:35,680 --> 00:07:43,839
We still cannot achieve our goal. So the issue here is we are asked to design a awarded Markov chain.

53
00:07:43,840 --> 00:07:50,980
So we have that flexibility to make the chain, to make this design as convenient as possible.

54
00:07:51,550 --> 00:08:02,290
Right. So among all the awards, Markov chains, the things is most of frankly, for designing is indeed the time reversible Markov chain.

55
00:08:03,250 --> 00:08:07,660
Right. So we make this rewarded y obviously high numbers.

56
00:08:13,680 --> 00:08:26,060
So this is a different type of the problem than what we have seen from the point that we start investigating markups.

57
00:08:26,260 --> 00:08:34,740
Right. Right. So usually you get a translation kernel and then we ask the question, what is the stationary distribution?

58
00:08:35,160 --> 00:08:40,210
So this is completely different, this kind of reverse type of the problem.

59
00:08:40,230 --> 00:08:49,530
So you have a target distribution in mind well up to a normalizing constant.

60
00:08:49,650 --> 00:08:54,340
Nevertheless. But you need to find that transition kernel.

61
00:08:55,360 --> 00:08:58,620
Right. So the trunk, what is the underlying transition kernel?

62
00:08:59,520 --> 00:09:05,670
More directly, you need a recipe to create this actual transition kernel.

63
00:09:06,360 --> 00:09:11,429
And then so this recipe will carry out the sampling process.

64
00:09:11,430 --> 00:09:15,150
And then you can do the inference based on.

65
00:09:17,460 --> 00:09:24,690
So you can do the inference based on the based on you are based on your samples from the market.

66
00:09:27,210 --> 00:09:32,370
All right. So is so that why I say is this so if you have a page.

67
00:09:32,550 --> 00:09:41,190
So the idea is this is also a tiny reversible chain and we always have the detailed balance.

68
00:09:42,000 --> 00:10:00,810
So we need to find the corresponding. So for arbitrary age a pair of think we should have detailed balanced accretion pi pi jj pgi.

69
00:10:01,410 --> 00:10:04,700
Right. So it's. Now is the problem.

70
00:10:04,720 --> 00:10:08,670
You sure you can get from the pi to the corresponding pi?

71
00:10:09,870 --> 00:10:14,760
So one thing should be clear. This there isn't all the pi.

72
00:10:15,030 --> 00:10:19,860
The satisfying pi is not unique. There is of many of those.

73
00:10:20,130 --> 00:10:23,640
But you still need a principled way to find it.

74
00:10:24,600 --> 00:10:34,940
So this is the. So Metropolis Hastings algorithm provides such a recipe.

75
00:10:36,440 --> 00:10:40,310
So let's first let's talk about the algorithm itself.

76
00:10:41,060 --> 00:10:47,570
The components of the algorithm, but a procedural of the algorithm.

77
00:10:47,700 --> 00:10:52,340
Now we can take a log copy. The theoretical problem is.

78
00:11:03,780 --> 00:11:11,910
So you. So they are aware that it's actually a set of procedures.

79
00:11:12,300 --> 00:11:23,910
So why wouldn't you know any situation where you describe an algorithm, you may or may not review the underlying theory, right?

80
00:11:23,910 --> 00:11:31,530
So this is just what you do first, what you do second, and then you need to some utilities along the way.

81
00:11:32,130 --> 00:11:35,190
So this is the description of the algorithm, right?

82
00:11:36,540 --> 00:11:45,510
So to carry out a Metropolis Hastings algorithm, what you need and the first thing is a so called proposal distribution.

83
00:11:46,140 --> 00:11:59,070
So the first thing is applying a proposal. So the role of proposal distribution later on,

84
00:11:59,070 --> 00:12:11,790
we will see it's not necessarily the transition matrix or the underlying time reversible Markov chain, but it's an important component anyway.

85
00:12:11,800 --> 00:12:15,360
So this is a defined in the context of this algorithm.

86
00:12:15,840 --> 00:12:22,560
What it does is if you are in the position, you consider your sampling from a markov chain.

87
00:12:22,920 --> 00:12:27,950
So consider your so the the possible space is all integers.

88
00:12:27,960 --> 00:12:33,350
Let's just make the problem that is a bit easy to discuss for discussion.

89
00:12:34,380 --> 00:12:40,560
Let's say I'm currently in the position I am and I'm going to go into the move.

90
00:12:40,560 --> 00:12:47,820
According to the underlying the procedure, the procedure will tell me what, where to move next.

91
00:12:48,390 --> 00:12:51,420
So this proposal distribution is like a dice.

92
00:12:51,420 --> 00:12:57,300
I'm going to roll at this position and the dice is going to tell me where I can move to the next.

93
00:12:57,870 --> 00:13:03,720
But it's only as a proposal. Right. So this proposal, distribution, this has a this form.

94
00:13:06,460 --> 00:13:10,510
Q I did. All right.

95
00:13:10,900 --> 00:13:18,250
So you feel a position I that this proposal distribution is your sample from this proposal distribution.

96
00:13:18,520 --> 00:13:27,579
It tells you you're going to draw another valid value j from this proposal distribution.

97
00:13:27,580 --> 00:13:34,840
Right. So that's the potential target, the potential destination for your next amendment right.

98
00:13:36,670 --> 00:13:41,980
So to make it more formal, some conditional on.

99
00:13:47,930 --> 00:13:58,990
Thanks. Bye. All right. So the algorithm is actually trying to construct time reversible Markov chain axon here.

100
00:13:59,450 --> 00:14:04,189
So the proposed distribution, according to this notation, is conditional axon.

101
00:14:04,190 --> 00:14:07,880
You CO two I propose.

102
00:14:13,540 --> 00:14:23,860
Why did you come to Jack for the Boston Fair and all the same thing I propose from it.

103
00:14:24,100 --> 00:14:33,950
It doesn't. Well, I'm not. I'm not forced to move that to the position, JAY, at this point.

104
00:14:34,070 --> 00:14:42,560
But Jay is one of the propulsive distribution, so I'm going to make a decision if I follow this proposal or not.

105
00:14:42,780 --> 00:14:52,980
This is the key of the the alphabet. But you need to first have a proposal once you have the proposal.

106
00:14:52,990 --> 00:15:01,480
So think about this is the Marshall Plan already in the that you are in the position right now that you draw from this proposal of distribution,

107
00:15:01,960 --> 00:15:17,410
drawing from the right or dies or does draw something from a black box and that you get your destination that you need to make a decision.

108
00:15:20,860 --> 00:15:28,240
Do I move or not move? So make a decision.

109
00:15:36,160 --> 00:15:40,560
Make a decision on the proposal. So this is the second step on the.

110
00:15:43,540 --> 00:15:46,840
How do I make the decision? All right.

111
00:15:46,930 --> 00:15:51,400
So this sounds overly complicated, but you need to flip a coin.

112
00:15:52,300 --> 00:15:57,190
All right? So the coin is a bias avoidance. So this coin is defined by this.

113
00:15:57,190 --> 00:16:04,430
So called a Hastings Regional. Some compute.

114
00:16:07,540 --> 00:16:12,640
Hastings ratio, which is defined as.

115
00:16:22,260 --> 00:16:29,820
Hi, Jake. Which is the destination. So the high of J is the target distribution page.

116
00:16:32,010 --> 00:16:36,960
Q j divided by i.

117
00:16:37,170 --> 00:16:43,420
Q. J. All right. So this quantity is known as Hastings.

118
00:16:43,420 --> 00:16:51,840
The ratio among the pie pages of the are from the the target distribution.

119
00:16:52,560 --> 00:16:57,210
The. Q. J. I. Q. I. J. Come from the proposal distribution.

120
00:16:57,870 --> 00:17:05,910
The proposal distributed I didn't say anything about it is actually a pretty arbitrary need to satisfy certain conditions.

121
00:17:06,780 --> 00:17:12,660
We will say later on. But let's say it, this is known. So but we said we don't know.

122
00:17:13,440 --> 00:17:21,570
J Right. How could we calculate is for example, the numerator or denominator.

123
00:17:21,900 --> 00:17:25,290
So separately it cannot be calculated.

124
00:17:25,740 --> 00:17:32,700
But we do know the the target distribution except that that normalizing constant.

125
00:17:32,700 --> 00:17:35,880
So when you calculate this, this is a form of a ratio.

126
00:17:36,330 --> 00:17:39,809
So you see the normalizing constant canceled out, right?

127
00:17:39,810 --> 00:17:49,170
So you only need. So this one is essentially equals b j q j i divide it by beyond.

128
00:17:50,520 --> 00:17:54,420
Q I think which is computable.

129
00:17:56,010 --> 00:17:59,030
All right. So that's really the key.

130
00:18:00,030 --> 00:18:05,580
And then this valuable bj a huge Q by an API.

131
00:18:05,610 --> 00:18:10,470
Q. Q AIG is a ratio and a known as the Hastings ratio.

132
00:18:12,000 --> 00:18:15,840
It's not necessarily bad. It's always positive.

133
00:18:16,140 --> 00:18:23,910
So all these values are come from distribution, from the density, or come from the probability that they are positive.

134
00:18:24,230 --> 00:18:30,600
A There is no guarantee that they are always bounded by one.

135
00:18:30,630 --> 00:18:35,700
So we try to make this ratio reflect the coin toss.

136
00:18:35,790 --> 00:18:48,560
So what we need to do is define the Hastings ratio because to do the minimum of let's just write A.J.

137
00:18:49,750 --> 00:18:57,600
Q I divided by the Q IAG and one.

138
00:18:58,320 --> 00:19:03,770
So if this ratio is greater than one, the minimum one will be one.

139
00:19:03,780 --> 00:19:10,110
So I take one. So you have a coin that's basically a fixed rate.

140
00:19:10,170 --> 00:19:15,390
Otherwise, if it's less than one, then this is just a bias, the coin.

141
00:19:15,630 --> 00:19:19,500
So you may have some uncertainty.

142
00:19:21,810 --> 00:19:29,310
So the idea is you flip such a coin and you make a decision based on the coin toss result.

143
00:19:29,760 --> 00:19:36,150
So if I flip a coin and then there's a hand that you move it, you move to the destination.

144
00:19:36,480 --> 00:19:44,450
Otherwise you stay. I'd be an excellent equal to I.

145
00:19:44,840 --> 00:19:56,900
I just reject. All right, so let's say there's three.

146
00:20:00,560 --> 00:20:07,450
So if a three is not equal to Y, yeah, I say y.

147
00:20:07,460 --> 00:20:11,750
Okay. So proposed X plus y equals y is.

148
00:20:13,910 --> 00:20:19,790
So if you do opportunity of 5ij.

149
00:20:21,080 --> 00:20:28,970
So those are the points equal to one and then it's equal to x otherwise.

150
00:20:30,980 --> 00:20:36,620
Right. Sorry. I'm just writing you. All right.

151
00:20:36,630 --> 00:20:40,050
So the number three is really the what I just said.

152
00:20:40,100 --> 00:20:47,810
So you flip that coin because I like a sample from a binary distribution with the probability equal to off.

153
00:20:48,260 --> 00:20:52,310
So that is a valid probability bounded between zero and one.

154
00:20:52,820 --> 00:21:04,490
So if you get you flip such a coin and then you get one that you do that moves to move to your destination, the proposed destination.

155
00:21:04,940 --> 00:21:07,970
Otherwise you're stuck. Okay.

156
00:21:08,360 --> 00:21:13,610
So this kind of a three steps defines the whole transition.

157
00:21:14,330 --> 00:21:18,889
There's not a single distribution if you find the transition is really a three step.

158
00:21:18,890 --> 00:21:25,050
So you need a a proposal distribution that tells you what you propose, the destination.

159
00:21:25,070 --> 00:21:37,930
That's important. Right. So you can only move to the places being proposed or the your current position, essentially.

160
00:21:37,940 --> 00:21:49,310
So the proposal distribution proposal distribution eliminates a lot of the possible states you have moved to.

161
00:21:49,760 --> 00:21:57,410
And then secondly, with the proposed distribution, the current history, sorry, with the proposed the destination of the current position,

162
00:21:57,800 --> 00:22:09,590
you need to pick if you accepted the proposed distribution by compute this Hastings original, which come from this pretty complicated form.

163
00:22:09,590 --> 00:22:21,230
Let's see why that makes sense. Later on that gave you and then we need to constrain that being zero one then we flip such a coin,

164
00:22:21,800 --> 00:22:28,220
essentially draw from a part only based on this probability and then make a decision.

165
00:22:28,400 --> 00:22:35,990
So think about this. It's it's all too complicated, but everything is necessary.

166
00:22:36,740 --> 00:22:43,300
So. One thing for sure is the description of this transition.

167
00:22:43,570 --> 00:22:52,690
And you will see this is a markov chain, right? So the X and plus one will only depends on X and we don't even talk about anything.

168
00:22:53,670 --> 00:22:56,700
With X and minus one x0x1.

169
00:22:56,710 --> 00:23:04,320
So everything conditional on x and can you know the you that determines that the.

170
00:23:06,270 --> 00:23:12,240
The accent plus one. Right. So first of all, this is a this is a markov chain where what we are doing,

171
00:23:13,110 --> 00:23:18,780
we still need to figure out what is the transition probability for this underlying Markov chain.

172
00:23:18,780 --> 00:23:24,870
It's complicated. There's three steps, so we need to start it off of what exactly is.

173
00:23:25,500 --> 00:23:37,110
And then finally, I think the the goal the overall goal is to make sure this Markov chain is a morning and then time reversal.

174
00:23:42,990 --> 00:24:03,120
So Y but that's basically the Montreal the metropolis Hastings and why doesn't work work all right

175
00:24:03,480 --> 00:24:11,940
so what I didn't say is about the the general description of what could be a proposal distribution.

176
00:24:12,480 --> 00:24:16,310
So it's rather arbitrary. There is no fix the formula.

177
00:24:16,320 --> 00:24:20,129
You have to choose anything as of proposal distribution.

178
00:24:20,130 --> 00:24:31,590
But there are certain restrictions or requirement for the proposal of distribution because you have the freedom to choose proposal distribution.

179
00:24:32,760 --> 00:24:44,310
So the way we choose proposal distribution is make sure the the underlying Markov check should be irreducible any periodic positive recurrence.

180
00:24:44,460 --> 00:24:52,950
All of these things we talk about that later. Let's assume the Q that the proposal of distribution does provide all these.

181
00:24:54,060 --> 00:24:59,940
Yeah. So the next question is are these steps guarantee the underlying Markov chain.

182
00:25:00,360 --> 00:25:10,019
It's a tiny reversible Markov training. And how do we prove that we need to go back to the detail balanced equation,

183
00:25:10,020 --> 00:25:15,030
but more importantly, we need to first to figure out what is the true transition kernel.

184
00:25:16,610 --> 00:25:23,630
Behind this rather complicated or simple, depending how you see it, the procedure.

185
00:25:25,130 --> 00:25:29,810
Right. So let's just compute the underlying marginal, shall I say, from day to day.

186
00:25:31,070 --> 00:25:42,610
What is the probability I move in this in this algorithm, in this Markov chain from position I to position J Right.

187
00:25:42,830 --> 00:25:50,630
How do I do that? So first of all, you don't need to say anything about AI or conditional on the AI.

188
00:25:51,050 --> 00:25:59,020
So from AI to J, how do you get there? So first thing is you have to have the proposal distribution gave you.

189
00:25:59,730 --> 00:26:05,970
Right. So that means the probability that the proposal for the distribution maybe, which is.

190
00:26:06,010 --> 00:26:29,020
Q ideas are so wrong. Not only that, you also have to have the coin toss results in your favor so that probability is off.

191
00:26:29,060 --> 00:26:32,940
I let's see. Right.

192
00:26:32,940 --> 00:26:41,190
So this is a probability you get j propose and then this one is the probability you get j accepted.

193
00:26:42,030 --> 00:26:47,940
Right. You need to flip a coin. That coin the the off AJ has a probability off.

194
00:26:48,260 --> 00:26:52,350
J So, so everything there says is conditional.

195
00:26:52,350 --> 00:26:55,730
You propose. J The probability of you accept J is off.

196
00:26:56,340 --> 00:26:59,490
These two things are independent. Right.

197
00:26:59,640 --> 00:27:08,250
So the coin calls and then the the proposed distribution are not are you independent?

198
00:27:08,490 --> 00:27:15,420
So similarly you can calculate J to I it's the same thing now is just swap

199
00:27:15,420 --> 00:27:21,090
the position of your position J and then you want to get back to position II.

200
00:27:21,510 --> 00:27:26,100
The two thing to happen. First, you need to propose the total distribution.

201
00:27:26,590 --> 00:27:32,940
Well game UI and then Hastings ratio or current.

202
00:27:33,210 --> 00:27:37,710
Well, in the probability this proposal will be accepted.

203
00:27:37,710 --> 00:27:41,610
It's j i. Why do I care about this?

204
00:27:42,890 --> 00:27:55,820
I had to j and MJ to I because I as I said, we can I, I, I were trying to improve the detail balance equations and this slide.

205
00:27:56,210 --> 00:28:00,050
That's why I care about I do genealogy in the right. Okay.

206
00:28:01,760 --> 00:28:06,739
All right. So, so well, this is the true kernel, right?

207
00:28:06,740 --> 00:28:19,020
So with this this whole procedure, the I to J and then j to what is really the transition probabilities for the underlying market,

208
00:28:19,340 --> 00:28:27,950
not just q i j US proposal distribution, not just AIG, but the whole thing.

209
00:28:29,030 --> 00:28:34,489
All right. So we have a target distribution and then we have the transition probability.

210
00:28:34,490 --> 00:28:41,120
Now the problem becomes very straightforward. We just need to check if the detail balance equation satisfies.

211
00:28:41,570 --> 00:28:53,510
All right, so let's do that as calculate the pie i p i j what that involves, too.

212
00:28:53,520 --> 00:29:02,220
And so that equals. High Times.

213
00:29:03,690 --> 00:29:10,829
Q I am okay and I want need to rewrite the alpha into that minimum form, right.

214
00:29:10,830 --> 00:29:20,520
So that the definition of the office on the. So I'm just trying to minimize the number of high.

215
00:29:20,530 --> 00:29:26,580
Jay. Q Jay II divided by high.

216
00:29:26,970 --> 00:29:30,390
qiji1.

217
00:29:33,030 --> 00:29:43,440
Right. So that will be. One of the things on the one side of the detailed balance equation and high energy supply items.

218
00:29:44,070 --> 00:29:49,440
Q AJ, and that is the Hastings ratio, right?

219
00:29:49,450 --> 00:29:55,530
So well, I mean, there's a pretty neat algebra trick.

220
00:29:56,130 --> 00:30:00,060
So the pie. Q AJ are both positive or non-negative.

221
00:30:00,270 --> 00:30:10,580
I think this is going to be strictly positive. And then you have a minimum function of the two positive numbers as well.

222
00:30:10,590 --> 00:30:16,830
So you can distribute this into this function well, not change anything.

223
00:30:17,430 --> 00:30:22,170
Right. So it's like the minimum of.

224
00:30:23,280 --> 00:30:29,100
So you feel. So this one I'm trying to say is equals the amount of.

225
00:30:29,640 --> 00:30:33,420
So you'll distribute this multiply by this first term.

226
00:30:33,440 --> 00:30:36,900
It's a positive term. Right. So you get paid.

227
00:30:38,240 --> 00:30:43,580
Q j i. And then the, the next term is a pie.

228
00:30:44,600 --> 00:30:48,770
Q Right, right. So check it yourself.

229
00:30:48,770 --> 00:30:53,060
They are the same thing. And this is a equation. It doesn't change anything.

230
00:30:53,420 --> 00:30:59,030
So these are the constant, positive, constant then that you can distribute into the minimum function.

231
00:30:59,570 --> 00:31:08,450
But you already see some of the symmetry in this form so that this is a pie IPA page equal to a minimum of pie.

232
00:31:08,510 --> 00:31:11,660
J. J And then the pie.

233
00:31:12,380 --> 00:31:18,770
So this one, if you want to check this way, you quote pie.

234
00:31:18,770 --> 00:31:23,240
J. J. I. Let me just do it again.

235
00:31:23,690 --> 00:31:36,590
This is. Make it easier to fall.

236
00:31:49,070 --> 00:31:53,640
All right, so what about Jay? Jay?

237
00:31:54,740 --> 00:32:01,880
All right, the same thing. You're right. This is the Q Jay II and then the minimum.

238
00:32:02,330 --> 00:32:05,980
So the Hastings ratio sometimes is easier to remember.

239
00:32:05,990 --> 00:32:16,190
It's always the destination. Q Jay, divide by the starting point.

240
00:32:18,620 --> 00:32:25,040
So because this is a James Y. So this is the destination, the high stakes ratio.

241
00:32:26,840 --> 00:32:33,890
And then the same thing. So if you distribute this, multiply this term into the two men.

242
00:32:41,510 --> 00:32:45,710
So you get a minimum of I.

243
00:32:46,700 --> 00:32:54,200
Q Jay. Jay which is the same.

244
00:32:54,380 --> 00:33:04,760
So what we establish essentially and we have shown the detailed balance equation is satisfied and it is high.

245
00:33:05,120 --> 00:33:09,390
The OJ equals high.

246
00:33:13,440 --> 00:33:23,310
Right. And then that's the end of the piece.

247
00:33:29,610 --> 00:33:41,070
This is a pretty straightforward. So what we establish is the following the of the recipe of Metro Metropolis Hastings.

248
00:33:41,580 --> 00:33:48,690
We're going to get ourselves a tiny, reversible Markov chain because of the detailed, balanced equation.

249
00:33:48,810 --> 00:33:58,920
We know if the transition kernel is PJ, then the stationary distribution has to be planted right on, although we cannot.

250
00:33:59,640 --> 00:34:15,150
So so that means the parts are you name stationary distribution.

251
00:34:27,510 --> 00:34:36,810
Right. So this is a based on the of the time reversible Markov chain and a unique in itself a stationary distribution.

252
00:34:37,800 --> 00:34:43,230
This is guaranteed. Um, so that's pretty amazing, right?

253
00:34:43,320 --> 00:34:53,670
So you don't really know anything about the normalizing constants, but you still can sample from this the underlying Markov chain,

254
00:34:54,060 --> 00:34:58,920
which guarantees this the stationary distribution being your target distribution.

255
00:35:00,180 --> 00:35:08,920
Okay. Any questions?

256
00:35:11,790 --> 00:35:18,629
So a few comments here is it looks like the only thing.

257
00:35:18,630 --> 00:35:27,900
So if you know that the target distribution, the Hastings ratio is relatively straightforward to compute.

258
00:35:27,960 --> 00:35:31,040
Right. The Hastings original involves two parts.

259
00:35:31,050 --> 00:35:37,230
One is you are the ratio of the the target distribution.

260
00:35:37,740 --> 00:35:41,520
So the important thing is the Q IJ How do you choose?

261
00:35:41,550 --> 00:35:47,870
Q Okay, right. So here we don't have any explicit constraints on.

262
00:35:47,880 --> 00:35:52,490
Q But you need to be careful there.

263
00:35:52,740 --> 00:35:56,969
There are some things depending on the Q. YJ So the Q.

264
00:35:56,970 --> 00:36:04,380
IJ As I said initially, I think the Q which is the instrumental part,

265
00:36:04,680 --> 00:36:14,100
you need to make sure the underlying Markov chain is aborting Markov, meaning they have to be irreducible.

266
00:36:14,100 --> 00:36:17,639
So if you have the whole state space, your Q,

267
00:36:17,640 --> 00:36:26,280
I need to make sure you kind of reach from any point from that state space to the other point to the state space,

268
00:36:26,730 --> 00:36:35,810
not necessarily through one step transition, but because you are have be the flexibility here, you can't make that happen, right?

269
00:36:35,830 --> 00:36:45,840
So there's some flexibility. But the the minimum requirement is you need to make sure the underlying Markov chain is indeed irreducible.

270
00:36:48,770 --> 00:36:54,470
You know, I think if you make it irreducible, I think own this finite space.

271
00:36:54,650 --> 00:37:00,889
Well, let's not talk about financement and then the positive a recurrent and then be a pure.

272
00:37:00,890 --> 00:37:06,770
All that is relatively easy to achieve if you have the control of the design, if you like.

273
00:37:07,610 --> 00:37:16,939
All I'm trying to say is it's not without. And so the Q needs to have some constraints, but it's relatively flexible.

274
00:37:16,940 --> 00:37:21,540
You can choose anything you like. As a matter of fact, the queue J.

275
00:37:23,610 --> 00:37:29,750
Initial version is this algorithm is named after two people, but not a problem.

276
00:37:30,350 --> 00:37:45,130
And Hastings so much homeless. The initial version of the algorithm has QIP and just uniform distribution, right?

277
00:37:45,160 --> 00:37:55,050
There is no proposal of distribution. And I see that the the ratio, the Hastings ratio just becomes pi j and then pi.

278
00:37:55,060 --> 00:38:01,250
So that present in a special case of the current version of Metropolis Hastings algorithm.

279
00:38:01,250 --> 00:38:05,680
Right. So is basically SAS conditional your current position?

280
00:38:05,680 --> 00:38:13,960
You are uniformly likely to pick any of the destination, but you still end calculate this type of the ratio.

281
00:38:14,530 --> 00:38:20,710
And now we're going to see a different version later on that's Give Some Power is also a special case of that.

282
00:38:21,160 --> 00:38:25,720
So in that case, this Hastings the ratio is always one.

283
00:38:25,840 --> 00:38:29,740
So that means you're always excited about the proposal.

284
00:38:30,040 --> 00:38:37,120
So there's there always a proposal distribution in this type of the algorithm.

285
00:38:37,270 --> 00:38:42,640
There is some relatively flexible, but there are minimum requirements need to match.

286
00:38:48,900 --> 00:39:00,870
All right. So after the midterm, you're going to get a chance to design a remarkable change in Monte Carlo algorithm.

287
00:39:02,890 --> 00:39:14,200
There you can see why this is sometimes designing a cue, which is really an art form, that society assigns the importance of these.

288
00:39:21,070 --> 00:39:27,440
So the theory about Markov chain Monte Carlo is really neat and it's not that too difficult.

289
00:39:27,530 --> 00:39:32,350
Right. So everything's free with a highly reversible Marc-Andre.

290
00:39:32,710 --> 00:39:42,160
But if you think about the practical issues as thinking about like we have a one dimensional distribution we want to sample from this is that,

291
00:39:42,160 --> 00:39:46,990
that is on the basis the, in the acts.

292
00:39:48,580 --> 00:39:54,280
It's just one dimension. So the most of the mark of Monte Carlo use the multidimensional space.

293
00:39:54,280 --> 00:40:04,650
But this is just trying to other. So the simple case is your sample from something like the bell shape like normal distribution.

294
00:40:04,660 --> 00:40:16,090
So you don't have to use Marco following this case you can do you know in the IAP some of the most naive Monte Carlo methods.

295
00:40:16,630 --> 00:40:22,360
So Markov chain Monte Carlo is pretty effective in this type of thing.

296
00:40:23,260 --> 00:40:29,770
Like you have a multimodal case. You just trying to make it more complicated.

297
00:40:30,040 --> 00:40:35,790
And I'm trying to emphasize the the practical implications of the proposal distribution.

298
00:40:35,890 --> 00:40:51,070
Right. So the the algorithm itself doesn't concern any type only types of the the target distribution is so that you and your model or multi

299
00:40:51,070 --> 00:41:01,570
multiple in that the one dimensional the all works in all you know the the all the algorithm applicable in in both situations.

300
00:41:02,260 --> 00:41:16,040
But from here you going to see. There is some critical impact about this about this proposal distribution.

301
00:41:16,590 --> 00:41:31,010
Okay. So the idea of using a markov chain to sample this, the target space, it's not very different than using ivy samples.

302
00:41:31,520 --> 00:41:36,310
One of the requirement is you should cover this space very well.

303
00:41:36,320 --> 00:41:39,020
Right. So if you only take samples from here,

304
00:41:41,480 --> 00:41:48,230
that's not good because you're calculating in expectation of the whole rail line, but you only get a sample from here.

305
00:41:48,740 --> 00:41:53,600
So the theory says if you run the chain long enough, you're going to get everywhere.

306
00:41:53,690 --> 00:42:01,070
But the practical impact is you want to achieve that convergence or the reaching.

307
00:42:01,490 --> 00:42:05,720
You're trying to reach that stationary state as fast as possible.

308
00:42:06,500 --> 00:42:19,490
So thinking about the you'll have a markov training on this sample space is really like you can think about a random walk in the ocean, right?

309
00:42:19,510 --> 00:42:26,960
So if you start here and so you're kind of moving around like a markov chain or like a random walk.

310
00:42:27,320 --> 00:42:35,350
So you may propose to move to here and now, if you accept that you got here, and then you may move up here again.

311
00:42:35,420 --> 00:42:39,620
So here, come here, go here and then so on, so forth.

312
00:42:39,650 --> 00:42:46,040
So the idea is you can think about the random walk and then you can reverse the whole sample space.

313
00:42:46,250 --> 00:42:52,570
Right. Like a markov chain. Right. Independent sampling is more like arbitrary.

314
00:42:52,580 --> 00:43:04,610
This get from the points. So this is a different and you see that what where the queuing come in for this efficiency of the sampling is.

315
00:43:05,000 --> 00:43:15,760
So you've got the valleys and then you've got the hilltops right where you want is you traverse the and traverse this whole sample space efficiently.

316
00:43:15,770 --> 00:43:22,010
That means you you go to the valleys and then you go to the hilltops.

317
00:43:23,000 --> 00:43:29,850
So you can imagine if you were to I'd only make this kind of a big jump, right?

318
00:43:29,870 --> 00:43:39,900
So the Q YJ So if you are in the position II, you'll only make big jumps if you only propose that far away from the I.

319
00:43:39,920 --> 00:43:44,880
That's one type of the sun point and that tends to get.

320
00:43:45,770 --> 00:43:49,070
So the consequence of this is if you are on the top.

321
00:43:50,680 --> 00:44:00,190
So this is like the density, right? So if you're if you're on the top and then you propose constantly, you propose these type of the move.

322
00:44:01,050 --> 00:44:08,680
Almost all of these moves have little chance to pass the proposal to pass the the queen float.

323
00:44:09,310 --> 00:44:14,110
Right. Because you are moving from a high density state into a low density state,

324
00:44:14,560 --> 00:44:21,580
that Hastings ratio going to be less than one in sometimes less, severely less than one.

325
00:44:21,590 --> 00:44:26,800
So it's a pure chance. The chance that you actually make a move is low.

326
00:44:27,430 --> 00:44:32,590
So you can see it there. So you're kind of stuck in this kind of a contretemps, the same thing here.

327
00:44:32,860 --> 00:44:43,480
So if you're trying to move, but if you are so in this case, you're very much in the in the top of a mountain.

328
00:44:43,840 --> 00:44:47,140
The small for the small proposal.

329
00:44:47,230 --> 00:44:50,730
The smallest. That proposal will move your wrong more efficiently.

330
00:44:50,740 --> 00:44:59,680
Right. Because these densities or it's kind of a the pie page values are similar are wrong this tall.

331
00:44:59,710 --> 00:45:07,990
So if you propose swarms when they say small staff in the neighborhood that how you to move are wrong.

332
00:45:08,020 --> 00:45:18,570
But the issue here is you can you can, too. It's kind of obvious that you stuck in this mountain top and you don't see there is a valley, right?

333
00:45:18,580 --> 00:45:25,540
You don't see that there is another maybe a higher holding in them behind this valley.

334
00:45:25,960 --> 00:45:37,660
So the practical difficulty of Markov chain Monte Carlo is always moving a more effectively.

335
00:45:38,740 --> 00:45:43,360
So this is determined by the proposal distribution.

336
00:45:43,900 --> 00:45:47,650
So as I said, you can propose big jumps or small steps.

337
00:45:48,070 --> 00:45:51,399
None of these are ideal for all situations.

338
00:45:51,400 --> 00:46:00,670
So you need to some sort of a mix the up. And then there are also other things people find out help you like the tampering idea.

339
00:46:01,750 --> 00:46:04,940
If you read into the literature, you will get part.

340
00:46:05,560 --> 00:46:10,990
Nevertheless, for the purpose of this course, though, if you run the Markov chain long enough,

341
00:46:11,650 --> 00:46:16,990
we have that guarantee that the Markov chain will achieve a stationary distribution.

342
00:46:16,990 --> 00:46:20,080
So theoretically you don't worry about this things.

343
00:46:20,380 --> 00:46:30,540
But if you really use Markov chain Monte Carlo to do any realistic calculation, you have a concern about how do you choose AJ Right.

344
00:46:30,680 --> 00:46:35,110
How do you how do you design your underlying Markov chain, right?

345
00:46:35,740 --> 00:46:40,350
For those of you, you are not going to do this in the basic computations.

346
00:46:40,360 --> 00:46:44,490
All you need to know is if you run this long enough, that's okay.

347
00:46:45,160 --> 00:46:56,990
We'll get there. But. As I said, the design of the Markoff train sometimes is an art.

348
00:46:57,320 --> 00:47:05,730
It's not really a. Forsyth plot is what distribution you should use.

349
00:47:07,950 --> 00:47:42,540
And so I would just summarize, there are either proposal distribution, so all you can control is this proposal distribution.

350
00:47:42,930 --> 00:47:48,810
So there are just because the target is prefixed by the problem you have, right?

351
00:47:49,230 --> 00:47:52,260
So the high page target is in the assumption.

352
00:47:52,650 --> 00:47:57,570
So you have the flexibility to choose the proposal distribution.

353
00:47:57,840 --> 00:48:16,320
So what I just said here is there are better proposal distributions to achieve the target distribution just by J.

354
00:48:17,190 --> 00:48:28,830
Foster. So essentially we're talking about the impact on the convergence rate of the underlying market, which we haven't talked about yet.

355
00:48:30,210 --> 00:48:31,590
We have a lecture 12.

356
00:48:31,590 --> 00:48:40,620
I'm talking about the convergence rate, how we think about this problem, how we formulate that problem that's not required before in any of the exam.

357
00:48:40,620 --> 00:48:46,050
Probably next Monday, we're going to briefly talk about the idea of convergence rate.

358
00:48:46,770 --> 00:48:52,550
And these are some impact on our like not everyday life, but like.

359
00:48:53,100 --> 00:49:01,740
So one of the most famous example of this is if you're shuffle a deck of cards and then you do this kind of a fancy shuffle,

360
00:49:02,930 --> 00:49:06,270
I don't know what that called and how many shuffle the ripple.

361
00:49:07,260 --> 00:49:10,650
Okay. Yeah, probably. Okay.

362
00:49:10,680 --> 00:49:14,310
So how many, how many, how many shuffles? How many wrongs do you need?

363
00:49:15,420 --> 00:49:20,860
Right. So, so well, I mean, the idea is you have you purchase a new deck of cards.

364
00:49:20,860 --> 00:49:27,240
It's always ordered. What you want is some sort of a uniform distribution in terms of card ordering.

365
00:49:27,570 --> 00:49:31,320
So do this shuffle in how many time. So the idea is the same.

366
00:49:31,930 --> 00:49:40,049
Your your target distribution is more or less uniform distribution and oh, possible ordering how many times of shuffles to work out.

367
00:49:40,050 --> 00:49:46,740
And so you run each of this shuffle ways like moving from the state of a markov chain to another state.

368
00:49:47,340 --> 00:49:54,270
So how many shuffles you need to achieve that stationary distribution, which is uniform, right?

369
00:49:54,270 --> 00:50:00,179
So mathematics are usually it's useless for our everyday life, but this one, this useful,

370
00:50:00,180 --> 00:50:06,020
they tell you like 7 to 8 times you should get to district of four for a car shop.

371
00:50:06,030 --> 00:50:13,319
All you should get two best stationary distribution, that sort of idea.

372
00:50:13,320 --> 00:50:19,410
This is a related to the convergence rate and then that's a big part of the statistical computing.

373
00:50:21,060 --> 00:50:28,620
But for now, we just need to know if there is a better proposal distribution to achieve the target distribution faster.

374
00:50:29,760 --> 00:50:36,839
The analogous thing about this proposal, distribution on the shuffling is there's different way to shuffle, right?

375
00:50:36,840 --> 00:50:38,190
This is a fancy shuffle.

376
00:50:38,490 --> 00:50:48,899
And now you're going to see some well, I mean you can always achieve so the that you so there's a like bottom to top shuffle or random to top shuffle.

377
00:50:48,900 --> 00:51:00,750
So this is a very silly type of the shuffle. So you get the order that that you pull one randomly from the deck and move it to the top, right?

378
00:51:00,960 --> 00:51:04,350
And then you do the same thing. So that's a mark of change.

379
00:51:04,560 --> 00:51:14,220
So eventually if you do this every time, just moving one card at a time, you also can achieve the uniform distribution.

380
00:51:14,550 --> 00:51:23,490
But what the so this is like representing a different type of the proposal distribution and representing a different type of the transition kernel,

381
00:51:23,490 --> 00:51:31,350
right. Because that that proposal distribution defines the transition kernel.

382
00:51:31,920 --> 00:51:36,000
So this is a much slower it's pretty obvious.

383
00:51:36,120 --> 00:51:44,130
It's a much slower. Right. You know, so those are the things of practical application.

384
00:51:47,330 --> 00:51:51,470
Yeah. So that's sort of interesting. We'll talk about that playfully.

385
00:51:59,350 --> 00:52:07,210
How many of you have taken the the bathing clause or have designed the Markov chain before?

386
00:52:08,140 --> 00:52:13,950
Good. So in the homework, we're going to see a completely different application scenario.

387
00:52:13,960 --> 00:52:17,980
We're going to use Markov chain Monte Carlo to do P value computation.

388
00:52:19,900 --> 00:52:32,650
So this is also happened. So you will you know, I think this is a usually occurred in this type of the situation.

389
00:52:33,520 --> 00:52:40,960
You have a constrained sample space and then the problem you're going to have is a such case.

390
00:52:41,290 --> 00:52:49,780
But so let's say something like if you want to create a lot of so Cluedo that type of the game.

391
00:52:50,140 --> 00:52:56,950
Right. So there are constraints. So although they so like just just rearrange zero ones.

392
00:52:57,550 --> 00:53:02,379
So sorry. So let's just rearrange the numbers 1 to 9 in the columns.

393
00:53:02,380 --> 00:53:06,550
And but now you cannot just do it without.

394
00:53:06,670 --> 00:53:10,710
There is there is a constraints, right? So what is a valid game?

395
00:53:10,720 --> 00:53:13,900
What is invalid game? So you have to follow the rules.

396
00:53:14,380 --> 00:53:21,850
So once the constraints are put into that space, if you do this kind of a random sample,

397
00:53:22,930 --> 00:53:26,860
worse this so called a rejection sample is not very efficient.

398
00:53:27,430 --> 00:53:31,900
Why? Because your constraint, the sample space is much smaller.

399
00:53:31,990 --> 00:53:35,740
If you just do a random sample. So the rejection sample.

400
00:53:35,950 --> 00:53:41,170
Let me just say a few words on the rejection samples. The idea of a rejection sample is very simple.

401
00:53:41,620 --> 00:53:49,540
You draw from the the uniform or whatever the draw the IAB samples are from the unconstrained state.

402
00:53:49,930 --> 00:53:58,520
That's the space. And then you check if this particular sample satisfy the predefined constraint.

403
00:53:58,520 --> 00:54:02,650
And if it does, you accept that that's a sample. Otherwise you throw that away.

404
00:54:03,460 --> 00:54:09,850
The issue here is if you have a low in the high dimensional space and you have a pretty.

405
00:54:11,370 --> 00:54:19,319
Non-trivial constraints. You're going to throw away most of the things that efficiency extremely low for application.

406
00:54:19,320 --> 00:54:29,670
Like if you want to calculate something like a p value in the constraints on pole, you will never have enough time by executing the rejection simply.

407
00:54:30,350 --> 00:54:36,090
All right, so you might want to try that in the homework problem, but that's after the midterm.

408
00:54:38,340 --> 00:54:49,230
So in that type of the situation, you could think about Markov Che y, because the Markov chain will be B with a pass on this constraint.

409
00:54:49,250 --> 00:54:57,570
The impulse by every move you have going to make sure the Markov chain moving around the constraints of space phase.

410
00:54:58,230 --> 00:55:03,570
Right. So that requires your movement will respect the all these constraints.

411
00:55:03,580 --> 00:55:15,840
You will never move out of the constraint space that is actually more you cannot wait to sample from a constrained space.

412
00:55:17,370 --> 00:55:20,729
We'll talk about that later. All right.

413
00:55:20,730 --> 00:55:30,090
We have. So the next thing you need to know and then you're going to use it pretty frequently is so-called keep something.

414
00:55:43,710 --> 00:55:56,580
All right. So in terms of a some polling, we're generally pretty confident of sample univariate random variables from univariate distributions.

415
00:55:57,060 --> 00:56:01,710
We're not so good sample from multivariate distributions, right?

416
00:56:02,100 --> 00:56:07,440
If it's for special distribution, like multivariate normal,

417
00:56:07,560 --> 00:56:16,320
we always have a way to turn that into some sort of independent by doing some matrix operation, but not in general.

418
00:56:16,800 --> 00:56:24,930
It's difficult, some polling problem. So the problem I have is something from a coin distribution.

419
00:56:32,970 --> 00:56:36,470
I'd say hi x one, two, three.

420
00:56:38,010 --> 00:56:41,720
So the P doesn't need to be has to be very large.

421
00:56:41,970 --> 00:56:45,150
You'll find yourself getting into trouble. All right.

422
00:56:45,570 --> 00:56:50,340
So we just you may, you know, pi, it's sometimes it's hard.

423
00:56:50,730 --> 00:56:57,210
And then more often this this pi.

424
00:56:59,550 --> 00:57:03,360
It's difficult to compute in terms of joint distribution.

425
00:57:05,400 --> 00:57:08,490
Well, let's just make the problem a little bit simpler to say.

426
00:57:08,790 --> 00:57:15,410
It's difficult to to to sample from the joint distribution or multivariate distributions you can think about.

427
00:57:15,870 --> 00:57:18,239
You know, it's really hard to well, I mean,

428
00:57:18,240 --> 00:57:28,940
you almost don't see like staged a use of some direct sampling for multivariate except for the multivariate normal category multivariate normal.

429
00:57:30,570 --> 00:57:34,670
There is a some competition on trade. You can turn that into independent something.

430
00:57:34,740 --> 00:57:44,570
So these are not independent. That means you can all factor this into univariate distributions in general and.

431
00:57:45,870 --> 00:57:49,410
All right. So, so.

432
00:57:50,660 --> 00:57:54,410
If you want. So this isn't really the target distribution now.

433
00:57:54,470 --> 00:58:07,490
You have a multivariate X1 to XP. If this I the simple idea doesn't work that we can think about how to work it using a markov chain.

434
00:58:07,490 --> 00:58:18,140
Monte Carlo. So now the question is, consider drawing this sample from a markov chain.

435
00:58:18,890 --> 00:58:30,230
And we can see there. All we need is at one track speed, moving to a different position.

436
00:58:35,550 --> 00:58:42,930
All right. So one of the things we need to know when you to know our ability and we need to know our limitation.

437
00:58:44,010 --> 00:58:54,030
So if you move to another multivariate position, so this is a this is a different the locations in the multi dimensional space.

438
00:58:55,020 --> 00:59:01,830
What we could do is we can change this one coordinate at a time based on the argument.

439
00:59:02,010 --> 00:59:08,600
So we know how to which I already know how to sample from a univariate distribution.

440
00:59:08,970 --> 00:59:14,000
Right. So we can make this move a little bit easier for us.

441
00:59:14,010 --> 00:59:18,090
Let's change this one. Coordinate at a time.

442
00:59:18,730 --> 00:59:22,980
Right. And how do we.

443
00:59:25,260 --> 00:59:34,560
Well, how do we change to the x one prime? So in this particular case, the the old position is x one all the way up to exp.

444
00:59:34,590 --> 00:59:40,470
And then in the new position I just change x one to x one prime, just change one coordinate.

445
00:59:41,310 --> 00:59:44,910
How do I generate this x one prime? Right.

446
00:59:45,210 --> 00:59:50,340
So this is the key sampling of the or the deep sampler algorithm.

447
00:59:50,790 --> 00:59:56,910
So they propose to change to x one prime based on this so called the full conditional.

448
00:59:57,630 --> 01:00:13,290
So the x one prime. There is some fallout from this from this conditional distribution.

449
01:00:13,500 --> 01:00:23,380
Explain that time frame. Well, police are going to be able to access to XP, XP.

450
01:00:27,270 --> 01:00:32,910
So the reason of doing this is we know how to sample you and might.

451
01:00:33,240 --> 01:00:38,850
So this is a conditional probability, but it is a univariate distribution.

452
01:00:38,880 --> 01:00:42,210
Right. So the only random variable here is x one.

453
01:00:43,440 --> 01:00:52,510
Right. So if we know this conditional distribution, we can just sample from the univariate distribution sample X1 prime from here.

454
01:00:55,180 --> 01:01:01,960
So X1 prime in sample from this distribution with the probability with a conditional distribution.

455
01:01:02,890 --> 01:01:06,040
With this probability x1 x1.

456
01:01:07,210 --> 01:01:19,210
All right. So that's it. And then next. So first and then you change the X to after you change X1 to x1 prime and you fix everything the next time you

457
01:01:19,210 --> 01:01:30,730
change its do the similar things but you change x to prime all the way up to x next theorem you change x three.

458
01:01:30,940 --> 01:01:35,260
So after p wrong you change every coordinate.

459
01:01:36,290 --> 01:01:41,550
Right. Compare it to the starting point and then you go on, keep doing this.

460
01:01:42,290 --> 01:01:45,860
So this is actually this so called a sampler.

461
01:01:46,250 --> 01:01:50,420
So the deep sampler remember the application this year the for some.

462
01:01:52,300 --> 01:01:56,560
So I learned the recipe is pretty simple.

463
01:01:57,040 --> 01:02:11,169
All you need to do is sample each coordinate based on a so-called conditional sample from the full conditional.

464
01:02:11,170 --> 01:02:17,230
So you need to know upfront what is x one conditional approval.

465
01:02:17,860 --> 01:02:26,040
You have to execute and you need to know x two conditional on x1x3 up to XP, so on and so forth.

466
01:02:26,040 --> 01:02:32,799
And so every time you could sample from the univariate argument again is the full condition.

467
01:02:32,800 --> 01:02:37,630
Those are all univariate distributions and they're relatively easy to get.

468
01:02:38,110 --> 01:02:44,650
And then you usually have analytic expressions for those distribution.

469
01:02:46,660 --> 01:02:48,790
All right. So why this is a valid.

470
01:02:50,170 --> 01:03:01,330
So if you look at this the position moving from the first to the from the original point to the x one prime position,

471
01:03:02,920 --> 01:03:05,140
it's just like a markov chain, right?

472
01:03:05,560 --> 01:03:14,020
So the whole thing is a markov chain because the position, given the the present, the positive future becomes independent.

473
01:03:14,140 --> 01:03:18,430
The next movement that way depends on the one immediately before it.

474
01:03:19,360 --> 01:03:22,990
So we can see if this is the case. Right.

475
01:03:23,320 --> 01:03:36,370
So what we need to do is trying to calculate, to see if this is a this is a if this is a highly reversible Markov chain.

476
01:03:36,380 --> 01:03:44,070
So the target distribution we have is X1, X2 to XP.

477
01:03:44,500 --> 01:03:51,610
Right. So this is the density for that, for the multivariate distribution, for the P component.

478
01:03:51,610 --> 01:03:58,750
And then this is our starting point and then we move from this point to it.

479
01:03:58,810 --> 01:04:04,060
So let's say e.g. x one.

480
01:04:04,570 --> 01:04:09,720
So. Just want to create something.

481
01:04:23,090 --> 01:04:26,300
It's new, which is a factor.

482
01:04:26,960 --> 01:04:33,090
It's just one. With one coordinate author.

483
01:04:35,470 --> 01:04:47,950
And then I'm looking to the probability so the transition of over to more.

484
01:04:51,300 --> 01:05:09,140
What? And according to the algorithm, you only need to change one quarter.

485
01:05:09,220 --> 01:05:19,660
And you know, that's the first the quality. So this one, this the probability is same as x1 prime given x2 all the way up to exponential.

486
01:05:25,130 --> 01:05:30,150
Right. I think the notation a bit messy here, but you understand what I'm doing.

487
01:05:30,200 --> 01:05:33,330
So this is the transition probability. Right.

488
01:05:33,350 --> 01:05:39,650
So from a condition like so I fix everything on the condition of the things I condition all.

489
01:05:40,070 --> 01:05:45,980
And then I propose this new position based on this conditional distribution.

490
01:05:46,550 --> 01:05:54,260
So now you can calculate the apply x old and you see.

491
01:05:55,320 --> 01:06:04,230
Yes. It was a nice new addition.

492
01:06:04,680 --> 01:06:09,270
I sold this watch, of course, once.

493
01:06:09,270 --> 01:06:23,760
So this is my next one all the way up to actually a lot of times he just wanted to find an audience to not do X, right.

494
01:06:27,320 --> 01:06:32,270
All right, so all we need to do is rewrite this one into the following form.

495
01:06:37,870 --> 01:06:43,330
This is how we write the conditions. So we have drawn.

496
01:06:52,220 --> 01:06:56,450
Divide it by the margin of.

497
01:07:01,450 --> 01:07:05,010
I'm sorry you had a speech.

498
01:07:09,690 --> 01:07:14,820
This is just simple algebra, I think. Not much need to be explained.

499
01:07:23,850 --> 01:07:32,100
Right. The last line just rewrite that conditionals into a ratio to mark a well to joint distributions.

500
01:07:32,790 --> 01:07:41,040
All right. So I'm gonna to move that denominator to the first term and then rewrite the first term a little bit so that when you close from high.

501
01:07:44,340 --> 01:07:48,620
I just won prime access to XP.

502
01:07:49,340 --> 01:07:53,310
Right? So that's the second term on the numerator.

503
01:07:54,270 --> 01:08:05,940
And then as I said, I'm going to combine the first term in the numerator and denominator, which we got the next one given rise to.

504
01:08:09,740 --> 01:08:23,330
We champion to reiterate this US High Tax New Mexico Commission on Taxpayer.

505
01:08:28,340 --> 01:08:40,739
Right. So what we have to establish again is a detailed balance equation so that across all the times that transition kernel equals the pie,

506
01:08:40,740 --> 01:08:45,090
new times, the transition colonel. But moving from the new to old.

507
01:08:46,380 --> 01:08:47,590
Right. What does it mean?

508
01:08:47,670 --> 01:08:55,410
So first of all, this is a mark of change would define the transition colonel right here by changing one coordinate at a time.

509
01:08:56,670 --> 01:09:02,819
Second of all, the target distribution will be the joint distribution,

510
01:09:02,820 --> 01:09:08,790
the multivariate distribution that we have we have in mind that we trying to sample from.

511
01:09:09,330 --> 01:09:14,790
So by changing this one at a time, you actually sampling your samples, your height,

512
01:09:14,790 --> 01:09:21,480
you know, your multidimensional samples actually come from the the target distribution.

513
01:09:23,580 --> 01:09:33,809
So third, you can view this armed as so this calculation.

514
01:09:33,810 --> 01:09:43,950
You can interpret that as a childless Hastings algorithm where you have a proposal distribution.

515
01:09:44,250 --> 01:09:53,910
Given this, the PI's and there's a few conditionals and then the target distribution is PI because we have this equation,

516
01:09:55,440 --> 01:09:59,819
you see, we never calculate the Hastings reasonable reason.

517
01:09:59,820 --> 01:10:05,660
As you can interpret in this process, the Hastings ratio is always one, right?

518
01:10:06,250 --> 01:10:14,969
That if you see this as a proposal distribution, the pi times, the parallel distribution equals the pi over times.

519
01:10:14,970 --> 01:10:27,629
But the proposal distribution and always equal implies this is a trivial case of Metropolis Hastings, with the Hastings ratio always equals one.

520
01:10:27,630 --> 01:10:32,860
So you always accept that the move. So we don't even need to check that anymore.

521
01:10:32,880 --> 01:10:37,800
Just keep moving. So this is a deep sampler.

522
01:10:37,830 --> 01:10:48,990
So when you have something you need to sample from a multivariate distribution and deep sampler is probably the most convenient sampler out there.

523
01:10:49,890 --> 01:10:53,370
It is not without its own problem. Right.

524
01:10:53,490 --> 01:11:03,950
So the if you are kind of accept everything, it tends to have this the situation we just discussed that in this one dimensional space.

525
01:11:03,950 --> 01:11:07,590
So you are making small moves. It is rightfully so.

526
01:11:07,920 --> 01:11:14,069
So every time you're just changing one coordinate, you think about very high dimensional space.

527
01:11:14,070 --> 01:11:19,860
You only change one coordinate. You cannot be very far away from your overall position.

528
01:11:20,130 --> 01:11:25,350
Right. So this the issue of this is they're moving small move.

529
01:11:26,100 --> 01:11:30,170
They're moving in small steps. It tends to be very speech.

530
01:11:30,660 --> 01:11:36,180
Right. The sneaky these are kind of wondering or wrong in the one part of your assembly space.

531
01:11:36,180 --> 01:11:44,030
It's really hard to get to the whole space in a short amount of time.

532
01:11:44,040 --> 01:11:52,829
Obviously, if you run this long enough, the theory always tells you if you run this long enough, you get to the stationary distribution and then.

533
01:11:52,830 --> 01:11:59,549
That's right. But you usually well, we care about, you know, limited computing time.

534
01:11:59,550 --> 01:12:00,540
So that's it you issue.

535
01:12:01,320 --> 01:12:15,810
But this is the case I think and you should understand to keep some part is a special case of Metropolis Hastings and then the truth is

536
01:12:15,990 --> 01:12:30,420
through a time reversible Markov chain and you should be able to demonstrate that the target distribution is achieved under this design.

537
01:12:32,650 --> 01:12:39,560
Okay, that's all the way with again, I think just emphasize this is we're going to cover.

538
01:12:40,950 --> 01:12:45,150
So this is a point in point of the previous one.

539
01:12:45,870 --> 01:12:57,360
I do expect you understand that the all of these different CMC algorithms at least identify what is the underlying transition curve and why.

540
01:12:59,910 --> 01:13:08,610
It's all right, I'll see everybody next Monday for you and then let me know if I don't have office.

541
01:13:08,610 --> 01:13:13,250
I'll work on the job question.

542
01:13:13,260 --> 01:13:14,580
Let me know. Three emails.

