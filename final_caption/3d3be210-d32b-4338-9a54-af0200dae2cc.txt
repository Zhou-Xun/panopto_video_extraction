1
00:03:04,240 --> 00:03:08,040
I know. All right.

2
00:03:10,380 --> 00:03:16,080
Good morning, everyone. Let's get started now.

3
00:03:18,480 --> 00:03:29,370
So some good news. We have fixed all the technical glitches and the lecture is being recorded right now.

4
00:03:31,620 --> 00:03:37,739
And hopefully we won't have any of those problems from Monday, for which I apologize.

5
00:03:37,740 --> 00:03:51,090
But now we are ready to go. So I will begin with a brief recap of what we went through Monday and then move on.

6
00:03:51,510 --> 00:04:04,680
We will finalize really Monday's lecture because there was something still that we need to cover and and then move on with today's topic.

7
00:04:05,880 --> 00:04:14,820
So as you may recall, last time we discussed our.

8
00:04:16,320 --> 00:04:20,580
Yes, I'm sorry. Okay.

9
00:04:21,090 --> 00:04:25,280
Maybe I can increase the volume of the. Uh huh.

10
00:04:37,790 --> 00:04:41,040
Is that any better? Yeah. Okay.

11
00:04:41,070 --> 00:04:44,730
Let me know if you still need me to yell.

12
00:04:45,900 --> 00:04:51,600
Okay. So what we do in beam is to estimate parameters which are this?

13
00:04:55,370 --> 00:05:06,230
Underlying natural truths that cannot really be ascertained using a procedure of sampling and measurement to obtain random variables.

14
00:05:06,440 --> 00:05:10,550
So in our real world, this is what we have to work with.

15
00:05:10,700 --> 00:05:15,110
Random violence. Random variables have three attributes you may recall.

16
00:05:15,530 --> 00:05:20,330
They have a conceptual definition. They have an operational definition, and they have a scale.

17
00:05:20,750 --> 00:05:27,890
And the scale is critical because the scale determines the way in which a random variable is summarized.

18
00:05:28,820 --> 00:05:39,890
Basically determines the statistics that we need to write and we summarize these variables for groups of people like population write off.

19
00:05:41,630 --> 00:05:46,820
We also described ways to summarize random variables depending on their scale.

20
00:05:47,000 --> 00:05:55,220
So for continued level, you may recall, we can use the arithmetic mean of individual values or realizations of the variable.

21
00:05:55,790 --> 00:06:03,410
And we noted that as the expected value of the random variable, the continuous random variable.

22
00:06:05,210 --> 00:06:12,620
We also describe dichotomous variables, which are those that can take only one of two possible values,

23
00:06:12,620 --> 00:06:16,610
and if they are coded zero or one, they are called binary values.

24
00:06:19,300 --> 00:06:28,600
Typically we code we assign the code zero when let's say a person in a population does not have a characteristic that

25
00:06:28,600 --> 00:06:36,870
we are evaluating and we are saying the value of one when the person does have the characteristic that you may be.

26
00:06:37,480 --> 00:06:48,240
Right. Oh, and you may also recall that we describe how to summarize binary variables so we can simply

27
00:06:48,240 --> 00:06:56,940
use estimate the proportion of people out of the total population who have that given value.

28
00:06:56,940 --> 00:07:03,420
We are interested in typically we estimate the probability of people having a value of one given random variable.

29
00:07:03,960 --> 00:07:13,110
So that would be the proportion, the probability. We also mention that when the variable is coded zero one,

30
00:07:13,860 --> 00:07:19,950
we can actually also take the arithmetic mean and the expected value from the arithmetic mean will be

31
00:07:19,950 --> 00:07:26,549
exactly the same as the probability as counting the ones putting them in the numerator and denominator.

32
00:07:26,550 --> 00:07:31,980
Everybody in the population was evaluated. Okay. So nothing new under the sun yet.

33
00:07:33,640 --> 00:07:41,710
Sometimes you may be interested in determining the proportion of people with a value of zero in that variable.

34
00:07:42,490 --> 00:07:47,320
And we also mention that because the maximum value of a proportion is one,

35
00:07:49,210 --> 00:07:53,920
the probability of people having a value of zero in a variable is equal to one,

36
00:07:53,920 --> 00:07:59,740
minus the probability of people having the other value, which is typically one or.

37
00:08:02,060 --> 00:08:05,900
So what was missing was two.

38
00:08:07,720 --> 00:08:16,090
But these probabilities for binary variables into context in terms of the types of probabilities that we use in epidemiology.

39
00:08:19,010 --> 00:08:27,650
There are three types of probabilities that are marginal probabilities, that are joint probabilities, and there are conditional probabilities.

40
00:08:28,370 --> 00:08:32,960
Right. So I'm going to start describing each one of these with examples.

41
00:08:34,580 --> 00:08:41,590
Suppose we have a population. Of 100 people, a total population, whole population.

42
00:08:42,310 --> 00:08:44,740
That's all the people we have to work with.

43
00:08:44,740 --> 00:08:51,310
And we may be interested in determining the value of a random variable in each person within this population.

44
00:08:52,060 --> 00:08:55,660
Let's call that random variable. White again, binary variable.

45
00:08:56,530 --> 00:09:02,470
You know, you can think of a real example, let's say. Why?

46
00:09:02,490 --> 00:09:06,660
Could be whether a person has ever been.

47
00:09:07,810 --> 00:09:13,390
Ever tested positive for COVID 19. Know a very real and current issue.

48
00:09:14,380 --> 00:09:20,680
So we go about 100 people asking each one of them, Have you ever tested positive for COVID 19?

49
00:09:21,100 --> 00:09:24,190
And at the end, you know, we collect our data and we have some totals.

50
00:09:24,580 --> 00:09:33,310
And in this example, it turns out that Y equals one represents people who say, yes, I have sometime ever tested positive.

51
00:09:34,030 --> 00:09:40,480
So 30 of the 100 have a value of one on Y, which is testing positive for COVID 19.

52
00:09:41,230 --> 00:09:47,590
And obviously the remaining 70 have a value of zero and they are the ones who said no.

53
00:09:47,590 --> 00:09:53,020
I have never tested positive for COVID 19. Right. How do we summarize those probabilities?

54
00:09:53,560 --> 00:10:02,890
Well, if we want to summarize the probability of Y equals one, we simply divide 30 the number of people with a value of one and y on the total.

55
00:10:02,950 --> 00:10:07,660
And that's between three or 30%. You recall just the same concept as a percentage.

56
00:10:08,290 --> 00:10:11,740
We could also summarize the probability of.

57
00:10:13,270 --> 00:10:18,190
Not having tested positive for COVID 19 as 70.

58
00:10:18,250 --> 00:10:22,390
In the numerator, people who reported not having ever tested positive.

59
00:10:22,660 --> 00:10:26,440
Divided by again the total that's point seven or 70%.

60
00:10:28,870 --> 00:10:32,020
That probabilities called those probabilities.

61
00:10:32,530 --> 00:10:35,740
Each one of these, they are called marginal probabilities.

62
00:10:37,870 --> 00:10:42,849
And these are the characteristics they represent the proportion of people with a given

63
00:10:42,850 --> 00:10:48,340
value of one variable out of everybody in the population or the whole population.

64
00:10:50,050 --> 00:10:53,830
The numerator are people with a given value on one variable?

65
00:10:55,080 --> 00:11:00,180
Sometimes you find that referred to as the marginal total because it's the overall total at the margins.

66
00:11:00,240 --> 00:11:03,610
Right. At the margins of a possible table.

67
00:11:04,480 --> 00:11:07,570
The denominator is everyone in the whole population.

68
00:11:08,700 --> 00:11:14,980
Okay. These marginal probabilities typically involve only one variable.

69
00:11:15,670 --> 00:11:21,790
We are just dealing with a variable. We call. Why have you ever tested positive for COVID 19?

70
00:11:21,820 --> 00:11:31,680
Yes, sir. So. Um, because they only involve one variable sometimes they are also called and conditional probabilities.

71
00:11:32,550 --> 00:11:35,850
And we will see by contrast what.

72
00:11:36,860 --> 00:11:40,250
Are not unconditional probabilities. All right.

73
00:11:41,330 --> 00:11:52,160
But for now, that's a marginal probability. Now, obviously, when we conduct a study, we typically assess values of more than one variable.

74
00:11:52,790 --> 00:11:56,510
We could assess the value of any number of variables that we want.

75
00:11:57,260 --> 00:12:04,130
So we could evaluate the values of another variable in this same population, let's say.

76
00:12:05,060 --> 00:12:08,780
Have you ever received a COVID vaccine?

77
00:12:10,580 --> 00:12:18,740
Let's call that random variable. Also, binary possible answers are yes or no is going to be coded as one.

78
00:12:19,040 --> 00:12:22,610
No, it's going to be called a zero. Let's call it a.

79
00:12:23,930 --> 00:12:30,950
And then after we go and ask one by one this question, we find out that 60 people report.

80
00:12:31,730 --> 00:12:36,860
Yes, I have ever received a COVID vaccine and 40 people report.

81
00:12:37,310 --> 00:12:40,430
I have never been vaccinated. Okay.

82
00:12:41,180 --> 00:12:50,780
So how we could summarize this probabilities or this data again, we could estimate the probability of a equals one as these 60 people who said,

83
00:12:50,780 --> 00:12:56,390
yes, I received the COVID vaccine divided by the total and that would be point six or 60%.

84
00:12:57,110 --> 00:13:02,300
And on the other hand, we could also, if we wish to report the probability of.

85
00:13:04,890 --> 00:13:12,390
Saying No, I have never received the COVID vaccine as 40 divided by 100 or four 40%.

86
00:13:12,660 --> 00:13:18,450
Right. Another marginal probability is that we used a different version.

87
00:13:18,900 --> 00:13:24,170
Okay. Any questions so far? Relatively straightforward.

88
00:13:25,540 --> 00:13:29,410
Okay. Now in epidemiology.

89
00:13:30,590 --> 00:13:39,170
Very often we are actually interested in assessing the values of more than one random variable on the same people.

90
00:13:40,320 --> 00:13:48,320
So. We could go about the 100 people and ask them each the two questions.

91
00:13:48,740 --> 00:13:55,910
Right? One, regarding values of why have you ever tested positive for COVID?

92
00:13:56,960 --> 00:14:00,950
Another Regarding the values of a Have you ever been vaccinated?

93
00:14:01,520 --> 00:14:07,490
So how many possible combinations of values could we have if we assess two binary variables?

94
00:14:12,820 --> 00:14:16,060
Four. Right. So some people may say, hmm.

95
00:14:17,030 --> 00:14:23,210
Yes, I have tested positive for COVID and yes, I have had the vaccine.

96
00:14:23,480 --> 00:14:27,740
So they will say, yes, I have this positive or go with it. I have not had a vaccine.

97
00:14:28,070 --> 00:14:31,970
I would say no. I have never tested positive for COVID vaccines.

98
00:14:32,110 --> 00:14:35,540
I say no, I have never tested positive for COVID and I have never had a vaccine.

99
00:14:36,020 --> 00:14:45,620
Those are the four possible combinations, right? So when we have that sort of combination of values of, let's say two variables,

100
00:14:46,100 --> 00:14:58,460
we typically summarize them in this structure that, you know, you will see a lot in your life if you call the two by two table.

101
00:14:59,510 --> 00:15:09,830
Across State Oak. And this glass table allows us to examine the joint distribution of the two variants, in other words.

102
00:15:11,100 --> 00:15:14,340
How many people out of the 100 have?

103
00:15:15,680 --> 00:15:19,730
Each of those four possible four combinations, right.

104
00:15:20,700 --> 00:15:29,340
So let's say in this particular example, then people have values of Y equals one and a equals one.

105
00:15:30,150 --> 00:15:43,210
The question is, how can we summarize? That probability, in other words, was the probability of people having a value of one in both a and way.

106
00:15:44,170 --> 00:15:47,670
Well, we simply. Estimate.

107
00:15:49,240 --> 00:15:56,950
That probability is then the number of people with values of one in the two variables out of the total population.

108
00:15:56,950 --> 00:16:03,429
So that's point one or 10% notation wise.

109
00:16:03,430 --> 00:16:07,690
You may see that here we have probability of.

110
00:16:08,890 --> 00:16:14,560
The values of one in the two variables separated by a comma that is read.

111
00:16:14,980 --> 00:16:27,110
The coma is. Read as. And. So the probability of y equals one and eight equals one is ten out of 100.

112
00:16:30,910 --> 00:16:34,990
What would be the probability of a equals one and y equals one?

113
00:16:41,360 --> 00:16:45,679
This ain't the same, right? Because, you know, the order doesn't matter.

114
00:16:45,680 --> 00:16:49,190
It is always going to lead you to the same cell, right?

115
00:16:49,910 --> 00:16:55,190
So if this is equal to, you know, obviously the same thing in reverse or.

116
00:16:57,360 --> 00:17:03,300
So we also learned then that 20 people have values of y equals one.

117
00:17:04,280 --> 00:17:07,400
Ever tested positive for COVID but did not have a vaccine.

118
00:17:07,910 --> 00:17:16,100
So to summarize that, we would say probably two equals one and equals zero is 20 divided by 100.2 20%.

119
00:17:17,300 --> 00:17:21,710
And we can proceed in the exactly the same way with the remaining cells.

120
00:17:22,430 --> 00:17:27,410
Okay. The only thing that will be changing here is the identifier of this cell.

121
00:17:27,910 --> 00:17:40,620
Right. Those probabilities are called joint probabilities because again, they describe the joint distribution of two variables in a population.

122
00:17:41,070 --> 00:17:41,400
Okay.

123
00:17:43,260 --> 00:17:51,570
So here are the characteristics they represent the proportion of people with given values of more than one variable out of everyone in the population.

124
00:17:51,630 --> 00:17:57,180
Again, there's the whole population. The numerator are people with given values on more than one variable.

125
00:17:58,640 --> 00:18:04,670
The numbers in the cells, the joint distribution, and the denominator is everyone in the whole population.

126
00:18:05,750 --> 00:18:09,020
And again, they do involve more than one variable.

127
00:18:09,410 --> 00:18:16,420
So you always will be dealing with cross tables when you are calculating joint probabilities.

128
00:18:17,710 --> 00:18:22,070
Okay. Now.

129
00:18:23,330 --> 00:18:34,220
Sometimes it's also very helpful for us in epidemiology to estimate the probability of one

130
00:18:34,760 --> 00:18:41,870
value of a variable in a subset of people who fulfill a condition on another variable.

131
00:18:44,310 --> 00:18:55,800
So in a subset of people who may already have a given value of the other party, to give you an a graphical example here, this is our original table.

132
00:18:56,790 --> 00:19:01,290
I may be interested in restricting. The population.

133
00:19:03,220 --> 00:19:08,410
The only people who reported having had a COVID vaccine.

134
00:19:08,770 --> 00:19:13,240
That would be restricting the population to those with a value of one and variable eight.

135
00:19:14,110 --> 00:19:21,610
And it may be of interest to me to estimate the probability of having ever tested for COVID.

136
00:19:21,640 --> 00:19:25,000
Y equals one in this subset.

137
00:19:25,630 --> 00:19:30,850
So these 60 people in whom equals one represent this subset of the population.

138
00:19:30,850 --> 00:19:36,580
Again, who received the COVID vaccine at some point.

139
00:19:37,950 --> 00:19:55,410
Okay. So to do that, I'm going to estimate what's called a conditional probability.

140
00:19:57,470 --> 00:20:09,470
And the notation for such conditional probabilities like this is the probability of y equals one among people whose value of a equals one.

141
00:20:10,700 --> 00:20:15,600
So this bar. Denotes the condition.

142
00:20:17,410 --> 00:20:23,920
This subset of the population that fulfills the condition and it's typically read as given.

143
00:20:24,310 --> 00:20:29,230
So probability of equals when given a equals one in this case is going to be ten.

144
00:20:29,560 --> 00:20:34,150
Right. And then later divided by 60.70.

145
00:20:38,020 --> 00:20:40,030
This is, again, a conditional probability.

146
00:20:40,060 --> 00:20:52,030
We could also estimate, obviously, the probability of Y equals zero in this subset, and it would be this 50 divided by 60 or point 83.

147
00:20:52,150 --> 00:21:02,230
So within this subset, obviously, these are the complement of each other, and they would add up to one within that subset that fulfills the condition.

148
00:21:09,500 --> 00:21:12,530
It is also of interest to examine what's happening.

149
00:21:12,530 --> 00:21:19,880
The other subset. Right. So we could also restrict our population to those who fulfill the condition of.

150
00:21:21,260 --> 00:21:24,680
Having never received a COVID vaccine, eight equals zero.

151
00:21:25,910 --> 00:21:29,569
So we knew that we could estimate the probability of y equals one.

152
00:21:29,570 --> 00:21:40,760
Given that a equals zero is 20, this divided by the total of the subset and the probability of y equals zero among these subset,

153
00:21:40,760 --> 00:21:47,620
which would be another different 20 divided by a total or 50 percentage.

154
00:21:48,650 --> 00:21:53,090
All right. So these are the characteristics of a conditional probabilities.

155
00:21:53,090 --> 00:21:57,770
The proportion of people with given values variable out of people with given values,

156
00:21:57,770 --> 00:22:03,200
values on another variable or a subset of people who fulfill a condition.

157
00:22:04,930 --> 00:22:11,440
The numerator is people with a given value in a variable, but the denominator is people with a given value on another variable.

158
00:22:12,580 --> 00:22:18,340
So those would be the marginal totals marginal because they are at the margins of the table.

159
00:22:20,020 --> 00:22:26,990
All right. And again, as they join probabilities, these roles involve more than one variable.

160
00:22:27,170 --> 00:22:29,870
So you will always have cross states.

161
00:22:32,430 --> 00:22:46,140
You could also, of course, nothing prevents you from estimating the probabilities of a values among subsets of the population with given Y values.

162
00:22:46,260 --> 00:22:51,450
Right. So we'll be sort of going in the other direction of the table and you do that like this.

163
00:22:51,450 --> 00:22:58,919
For example, here we have subset the population to having values of like was one and you could estimate the probability

164
00:22:58,920 --> 00:23:05,910
of a equals one among people with y equals one or a equals zero among people with like was one.

165
00:23:06,300 --> 00:23:10,410
And you could do obviously the same for the other level of y, right?

166
00:23:11,310 --> 00:23:16,060
So you could estimate. Eight.

167
00:23:16,480 --> 00:23:19,360
Conditional probabilities in a two by two date.

168
00:23:22,460 --> 00:23:35,450
Question is the probability of y equals one given a equals one the same as the probability of a equals when given y equals one no.

169
00:23:36,050 --> 00:23:42,650
So in this particular case, you have to be very mindful that the order of the notation matters,

170
00:23:42,650 --> 00:23:48,140
obviously, because what's after the bar is what's telling you the condition.

171
00:23:49,280 --> 00:23:52,910
And if the condition changes, that means the denominator changes.

172
00:23:53,150 --> 00:23:56,720
And you cannot expect that the probabilities will be necessarily the same.

173
00:23:57,890 --> 00:24:02,860
Right. All right.

174
00:24:03,340 --> 00:24:08,500
Any questions on this or any of the material we covered on Monday?

175
00:24:20,430 --> 00:24:28,050
Great question, if I may repeat it. Is there ever a limit on the number of variables that we can consider on a data set?

176
00:24:28,890 --> 00:24:32,430
And the answer, I would say, is probably not if you.

177
00:24:33,150 --> 00:24:35,550
Is any of you working with big data?

178
00:24:37,470 --> 00:24:45,990
So that's more or less the principle of big data that you can assess millions of variables on each person at a time.

179
00:24:46,800 --> 00:24:58,230
For example, genetic polymorphisms on a vast array of genes or epigenomic loci.

180
00:24:59,190 --> 00:25:04,680
So yeah, I think it's it's, it's conceptually there is really no limit.

181
00:25:04,950 --> 00:25:09,690
Now, practically, there might be limits set by statistics.

182
00:25:12,520 --> 00:25:19,479
And again, I guess the exciting thing is that, you know, you could learn all of these in your more advanced courses,

183
00:25:19,480 --> 00:25:27,850
but for the sort of for the sake of this course, I just brought the simplest example to illustrate these initial concepts.

184
00:25:27,850 --> 00:25:35,129
Okay. Sorry.

185
00:25:35,130 --> 00:25:42,100
Say it again. If the condition changes, the probability changes.

186
00:25:43,840 --> 00:25:48,920
Right. Because the denominator is likely to be different.

187
00:25:50,120 --> 00:25:58,460
Unless you have a table in which every cell is exactly the same, says that that's seldom the case.

188
00:26:02,380 --> 00:26:06,570
I actually have a question about your product.

189
00:26:06,800 --> 00:26:13,440
Found out why? I will do it for.

190
00:26:14,510 --> 00:26:17,930
Around 4 a.m. Okay. I'm.

191
00:26:23,290 --> 00:26:29,710
Sure. So a parameter is what we actually want to measure.

192
00:26:31,120 --> 00:26:35,200
But conceptually is really not something that is measurable.

193
00:26:35,890 --> 00:26:49,090
We could only. Try to. Take our best guess as to what that value might be, depending on the tools that we have to sample and to measure.

194
00:26:51,780 --> 00:26:59,710
So. Whatever we do with our means is always going to be an approximation.

195
00:27:01,420 --> 00:27:08,890
And as we progress and toward the end of the course when we study certain statistical measures.

196
00:27:10,130 --> 00:27:19,910
We could only get a sense of how much confidence we have that we have actually captured the parliament using statistics.

197
00:27:20,880 --> 00:27:26,160
But conceptually, something that is is not perfectly measure.

198
00:27:28,070 --> 00:27:33,950
Thank you. Sure. Anything else? Okay.

199
00:27:34,790 --> 00:27:46,340
So at the end of each session, I like to provide what I call a progress report to sort of make you feel empowered with what you have learned.

200
00:27:47,060 --> 00:27:53,750
So as of now, you should have learned three key uses of epidemiology.

201
00:27:53,780 --> 00:27:57,839
You remember. Description, prediction and causal inference.

202
00:27:57,840 --> 00:28:01,140
And which one are we crazy about causally?

203
00:28:03,090 --> 00:28:06,660
Describe the difference between a parameter and an estimate. I guess we just.

204
00:28:08,110 --> 00:28:14,920
Review that define a random variable named it three attributes of a variable, which I did at the beginning of this one.

205
00:28:15,640 --> 00:28:18,400
Then the scales of measurement for a variable and again,

206
00:28:18,400 --> 00:28:23,590
appreciate the value or the importance of the scale because that determines how you treat the variable.

207
00:28:24,760 --> 00:28:30,310
Describe a summary measure of a of a continuous variable so the arithmetic mean

208
00:28:30,730 --> 00:28:34,660
or expected value and describe two summary measures of a customer's value,

209
00:28:35,470 --> 00:28:40,510
the probability or the expected value. Arithmetic mean if it's coded zero one minus.

210
00:28:41,670 --> 00:28:49,020
Distinguish marginal and conditional probabilities. So do you feel that you got all this?

211
00:28:50,280 --> 00:28:58,250
Great. Okay, then let's move on. With our introduction to cost elements.

212
00:28:58,380 --> 00:29:02,910
So. Faster than your seat belts.

213
00:29:04,560 --> 00:29:09,550
Um. There will be two sessions on this.

214
00:29:09,910 --> 00:29:13,540
And and it's I think it's very important.

215
00:29:13,540 --> 00:29:16,540
It's probably going to be new material.

216
00:29:16,550 --> 00:29:19,990
So feel free to stop me and ask questions.

217
00:29:19,990 --> 00:29:28,900
I trust you did the readings for today. I was going to send you a reminder, but I sort of felt, well, that's probably not very welcoming.

218
00:29:29,500 --> 00:29:36,990
Do we already breathing down your nix on the first week? But I guess if you did the readings, they might help me.

219
00:29:37,490 --> 00:29:41,470
It's. Come on, you please.

220
00:29:42,670 --> 00:29:45,710
It is being recorded. Yes. Yeah.

221
00:29:46,730 --> 00:29:50,900
Thank you. Yeah. Yeah, we sorted it out. All right.

222
00:29:52,190 --> 00:29:55,940
So this is what I hope to cover. What's the goal?

223
00:29:55,940 --> 00:30:03,290
Of course, Olympians. Then we will talk about individual causal effects and introduce the concept of counterfactual potential outcome.

224
00:30:04,550 --> 00:30:06,400
Perhaps we will do this today.

225
00:30:06,410 --> 00:30:17,120
If we have, then we will continue with average causal effects, ideal randomized trials, the concept of exchange ability, which is key, obviously.

226
00:30:17,750 --> 00:30:20,960
And what happens when we have nonrandomized exposures?

227
00:30:21,410 --> 00:30:28,069
Fear not. If these are all new words and you know, that's it doesn't seem to make any sense at all.

228
00:30:28,070 --> 00:30:31,190
It's all right. It's okay that that's why we are here.

229
00:30:32,000 --> 00:30:37,790
And it's just, you know, it's a it's a process step with.

230
00:30:38,840 --> 00:30:44,810
So first of all, again, I would like to provide a glossary,

231
00:30:44,840 --> 00:30:55,620
meaning another sort of recap or summary of, of, of the, uh, terminology that we are going to recall.

232
00:30:55,820 --> 00:31:00,520
Probability of y equals one is a marginal probability, right.

233
00:31:01,130 --> 00:31:05,380
Also call and conditional because the denominator is the whole population.

234
00:31:05,870 --> 00:31:13,430
You remember in conditional probabilities. The denominator was people who fulfilled a condition within the population.

235
00:31:14,360 --> 00:31:17,479
Okay. Annotation like this.

236
00:31:17,480 --> 00:31:21,710
Probability Y equals one given equals one is is a conditional probability.

237
00:31:22,220 --> 00:31:26,360
Denominator is a subset of people in the population who fulfill a specific condition.

238
00:31:26,960 --> 00:31:44,710
Their condition is described after the by. Now the possible values of a discrete variable are referred to as levels, categories or classes.

239
00:31:45,850 --> 00:31:49,480
So I will use those terms interchangeably.

240
00:31:50,520 --> 00:31:55,230
So even though the levels of variable these are these then that the categories of this variable isn't it.

241
00:31:55,840 --> 00:32:10,030
But that's what those words referred. Exposure is a determinant from the definition of epidemiology, a possible cause of a health outcome.

242
00:32:11,480 --> 00:32:14,720
An exposure is a possible cause of a health outcome.

243
00:32:15,140 --> 00:32:19,610
It may or may not be a cause, but it's a possible cause. That's what is called exposure.

244
00:32:19,740 --> 00:32:30,600
Right. It is also referred to in the causal inference literature as it treatment or an intervention.

245
00:32:31,290 --> 00:32:35,460
So exposure treatment intervention will be used interchangeably.

246
00:32:37,740 --> 00:32:49,680
Exposures can be represented as random variables, and the notation used to follow the book of Herrmann and Robbins is going to be a.

247
00:32:51,450 --> 00:32:58,800
It could be any letter doesn't have to be a but we will be using a to follow on the book.

248
00:32:59,400 --> 00:33:03,780
Some people use X as the exposure.

249
00:33:04,410 --> 00:33:07,379
Um, you may think of exposure sometimes.

250
00:33:07,380 --> 00:33:17,430
Also as you know, you have more statistical minus the independent variable, you know, the one you typically represent on the x axis.

251
00:33:17,430 --> 00:33:24,560
So some people are going to call it a. Now.

252
00:33:26,310 --> 00:33:39,100
Four. Are they good the most viral representing an exposure. Binary variable, the levels, categories or classes are going to be coded as follows zero.

253
00:33:40,420 --> 00:33:45,580
If the person is unexposed or untreated.

254
00:33:49,190 --> 00:33:58,249
Unknown. If the person is exposed or treated, you could link back to the previous example on COVID.

255
00:33:58,250 --> 00:34:01,370
So the exposure could be COVID vaccine.

256
00:34:02,660 --> 00:34:10,190
Zero would be people who did not have a COVID vaccine. One would be people who did have a COVID vaccine.

257
00:34:12,020 --> 00:34:16,610
Okay. Outcome. An outcome is a health state.

258
00:34:16,970 --> 00:34:20,360
Like a disease. Right. Or death.

259
00:34:21,790 --> 00:34:26,140
Or having high volumes of blood sugar.

260
00:34:29,880 --> 00:34:33,650
It is typically the result of one or more exposures.

261
00:34:36,010 --> 00:34:40,720
It is also a random variable and we are going to notated.

262
00:34:40,730 --> 00:34:48,400
That's why again for consistency with the readings.

263
00:34:49,990 --> 00:34:56,260
If. Why is dichotomous as we will be mostly using here.

264
00:34:56,920 --> 00:35:02,800
The code will be like this zero if the person does not have or does not develop the outcome.

265
00:35:03,340 --> 00:35:12,370
If the person does not have a disease their son does not have COVID has never tested positive for COVID one if the person has.

266
00:35:13,410 --> 00:35:16,469
Or has developed the disease in the previous example.

267
00:35:16,470 --> 00:35:27,740
One The person has ever tested positive for COVID. You know, we with that in mind,

268
00:35:27,770 --> 00:35:41,540
we that sort of refresh the goal of console inference is to determine whether an exposure or treatment a actually causes an outcome.

269
00:35:41,810 --> 00:35:56,730
What? That's it. Now let's let's get into this matter with a couple of examples from very neatly mythology and pharmacopeia.

270
00:35:56,730 --> 00:36:00,620
Emil. We have two women.

271
00:36:02,100 --> 00:36:06,390
Hypothetical case one. Women 18.

272
00:36:07,640 --> 00:36:10,670
Takes an antidepressant at gestation week 12.

273
00:36:11,030 --> 00:36:18,710
So 18 was pregnant and at week 12 of gestation took an antidepressant, you know, a pill to treat depression.

274
00:36:20,090 --> 00:36:24,560
And two weeks later, she miscarries. She loses the pregnancy.

275
00:36:25,540 --> 00:36:35,930
Okay. There is another person, Jane, who did not take antidepressants, a gestation week plus, and she did not miscarry.

276
00:36:40,000 --> 00:36:49,630
So. We could define the exposure A as taking antidepressants at week 12 of gestation.

277
00:36:49,930 --> 00:36:54,760
Right. And the possible values are one.

278
00:36:54,790 --> 00:37:01,180
If the person takes an antidepressant zero, the person does not take on the present and the outcome.

279
00:37:01,750 --> 00:37:04,780
We can define miscarriage, losing the pregnancy.

280
00:37:05,290 --> 00:37:08,590
The calling would be one if the person loses the pregnancy. Zero.

281
00:37:08,890 --> 00:37:13,150
If the person does not lose the pregnancy. Right. Okay.

282
00:37:14,050 --> 00:37:25,940
So for this actual date of these two people, we could summarize their exposure and outcome situation as follows for Irene.

283
00:37:26,200 --> 00:37:32,920
So recall the capital letter, the notes, the name of the random variable,

284
00:37:33,640 --> 00:37:41,950
the low that that denotes the realizations, meaning the value that variable takes on each individual person.

285
00:37:43,120 --> 00:37:49,710
Yeah. The capital letter is just the name of the variable.

286
00:37:52,350 --> 00:37:57,690
The lowercase letter is the value that that variable takes for a given person.

287
00:37:58,860 --> 00:38:03,690
And I am telling you who the giving person is using this subscript.

288
00:38:04,200 --> 00:38:09,750
So I'm using A for Irene and J for Jane.

289
00:38:11,790 --> 00:38:17,780
So. Exposure. Taking an antidepressant is a.

290
00:38:18,870 --> 00:38:25,890
The value of taking an antidepressant for 18 is one because she took an antidepressant.

291
00:38:27,150 --> 00:38:34,860
The value for taking an antidepressant for Jane is zero because Jane did not take an antidepressant.

292
00:38:37,410 --> 00:38:43,350
So that's the notation for exposure. What would be the notation for outcome?

293
00:38:44,630 --> 00:38:49,160
Well, the name of the variable is way. Miscarriages.

294
00:38:50,470 --> 00:39:00,580
So for 18 the value of weigh is one because she did miscarry for gain the value zero because she did not.

295
00:39:04,480 --> 00:39:11,620
You could summarize, organize this data of your little dataset, you know, a little table.

296
00:39:11,860 --> 00:39:25,750
You were doing some Excel. Uh, so here you have the ID, you know, some arbitrary, uh, name or number.

297
00:39:25,870 --> 00:39:31,200
And then for each person you have the value of exposure A And the value of outcome way.

298
00:39:32,890 --> 00:39:36,700
Okay. Okay, let's.

299
00:39:37,030 --> 00:39:51,670
Yes. None of them yet because we are still talking about individuals is a very good question.

300
00:39:52,590 --> 00:39:56,130
Very good question, because, yes, it should.

301
00:39:57,520 --> 00:40:01,480
Help us clarify that we are not talking about population.

302
00:40:01,570 --> 00:40:03,970
We are just talking about two people.

303
00:40:04,940 --> 00:40:12,980
So I guess there was an interesting question last time also about probabilities, ones versus ones or zeros in individuals and so on.

304
00:40:13,670 --> 00:40:16,910
So in individuals, there are really no probabilities.

305
00:40:18,730 --> 00:40:23,709
Just ones or zeros. But we will we will get there.

306
00:40:23,710 --> 00:40:27,010
So, yes, it will get very interesting.

307
00:40:27,910 --> 00:40:37,510
So let's focus on the case of Irene for a few minutes. Irene takes advantage of present at your station week 12, and two weeks later she miscarries.

308
00:40:38,710 --> 00:40:41,950
Here is the $1 million question.

309
00:40:43,510 --> 00:40:51,070
What do we need to know to determine whether taking an antidepressant caused Irene to miscarry?

310
00:40:52,120 --> 00:40:58,840
This is called the causal question and is important because this is how.

311
00:40:59,980 --> 00:41:03,250
We currently understand causation.

312
00:41:04,550 --> 00:41:09,680
You may have read, you may have heard, you may have been told, for example, Bradford Hill criteria.

313
00:41:10,280 --> 00:41:14,010
Has anybody heard about Bradford Hill criteria? Right.

314
00:41:15,820 --> 00:41:29,530
I'm not going to talk about that anymore. It's it's no longer really a valid or a commonly agreed on way of thinking about causation.

315
00:41:30,070 --> 00:41:33,370
This is it. So this is the causal quest.

316
00:41:35,840 --> 00:41:40,460
Well. The answer to this coastal question is.

317
00:41:41,600 --> 00:41:45,200
I mean, you could be the head in your slide, right?

318
00:41:45,200 --> 00:41:51,290
Gorgeous. Or if somebody has in their head and wants to give it a try.

319
00:41:53,030 --> 00:41:56,220
Why do we need to know to determine where they're taking take the present course.

320
00:41:56,240 --> 00:42:00,470
I mean, don't be scared of you have to think outside the box.

321
00:42:02,280 --> 00:42:07,830
No. Yes.

322
00:42:08,400 --> 00:42:15,240
If not, what is your name? No, Hannah. If not, taking an antidepressant would have caused a miscarriage.

323
00:42:15,240 --> 00:42:19,230
To see if I can reward this, perhaps in a slightly more general way.

324
00:42:20,070 --> 00:42:26,880
All other things being equal at 18, not taking an antidepressant would have she miscarriage.

325
00:42:28,200 --> 00:42:33,390
That's the only way to know if.

326
00:42:34,290 --> 00:42:38,250
Her taking the antidepressant caused her miscarriage.

327
00:42:39,480 --> 00:42:45,690
And how can we determine this? So here is the bad news.

328
00:42:47,770 --> 00:42:55,150
We will need a time machine. And their machines have not yet been invented.

329
00:42:56,470 --> 00:43:03,350
I mean, there are people working on that. Luckily for us epidemiology, but for the most part they are not having.

330
00:43:04,670 --> 00:43:09,680
Okay. Now. And now I have to invite you to sort of again, think outside the box with me,

331
00:43:09,680 --> 00:43:14,360
and I'm going to be giving you sort of number of theoretical examples and so on.

332
00:43:14,370 --> 00:43:21,200
But please just play along with, um, and at the end I will reveal why this is important.

333
00:43:21,470 --> 00:43:30,290
There is one thing that's very practical in your potential future professional lives of understanding this, I'll tell you.

334
00:43:31,070 --> 00:43:39,080
Wow. So if we could run a time machine experiment, what we would do.

335
00:43:40,050 --> 00:43:58,380
Would be to take Irene back in time to when she was 12 weeks pregnant and change only one thing which is not give her an antidepressant.

336
00:44:02,370 --> 00:44:09,420
And then we would record the result of the experiment with respect to her having a miscarriage or not.

337
00:44:11,610 --> 00:44:14,980
That's exact. And then we would compare. Right.

338
00:44:20,020 --> 00:44:27,740
So the result of the time machine experiment where we determine the outcome after changing the exposure,

339
00:44:27,790 --> 00:44:33,850
only all other things being equal is called a counterfactual outcome.

340
00:44:35,200 --> 00:44:40,239
So if we could conduct the time machine experiment and record what happened

341
00:44:40,240 --> 00:44:44,560
with respect to miscarriage to aid in after we withheld their antidepressant,

342
00:44:45,340 --> 00:44:49,400
that miscarriage, yes or no would be a counterfactual.

343
00:44:50,610 --> 00:44:57,060
So why did you find it's variable or is to talk about.

344
00:44:59,090 --> 00:45:06,830
It's still a repeat. Well, it is a dependent variable. But here, what would be would we be concerned about this low case way?

345
00:45:07,750 --> 00:45:13,210
Because that would be the realization for a given person.

346
00:45:17,590 --> 00:45:21,790
But it is it is the outcome. It's still the dependent variable outcome.

347
00:45:22,270 --> 00:45:28,730
Yeah. So outcomes apply to both individuals and populations.

348
00:45:29,540 --> 00:45:33,080
Exposures also apply to both individuals and populations.

349
00:45:41,890 --> 00:45:49,180
So in other words, the counterfactual outcome is the outcome that would have been observed under an

350
00:45:49,180 --> 00:45:57,220
exposure value that the person in real life did not actually experience in the.

351
00:45:58,790 --> 00:46:05,540
So, in other words, is counter to the fact. Because the fact, you know, is never better said.

352
00:46:05,870 --> 00:46:14,690
We only live once. So we can only experience one type of exposure, right?

353
00:46:14,720 --> 00:46:27,900
One. One level of exposure. The outcome that is observed at the exposure value that the person actually experienced is called the factual right.

354
00:46:29,090 --> 00:46:33,500
But unfortunately, to complicate a bit, the terminology.

355
00:46:35,560 --> 00:46:41,110
Both output possible outcomes are called referred to as counterfactual.

356
00:46:41,920 --> 00:46:45,400
So you will very rarely or never read in the literature.

357
00:46:46,150 --> 00:46:51,880
Factual to refer to what happens during the experienced exposure.

358
00:46:52,450 --> 00:46:56,500
You will hear both referred to as counterfactual.

359
00:46:57,440 --> 00:47:04,220
Because both are potential outcomes, either absurd or non absurd.

360
00:47:11,980 --> 00:47:15,520
Right. Right. Right. Exactly. Right. Right.

361
00:47:16,480 --> 00:47:22,330
So in this case of, you know, because the outcome is defined as miscarriage or no miscarriage.

362
00:47:23,430 --> 00:47:28,300
There is two potential outcomes. One of each, right.

363
00:47:28,890 --> 00:47:33,120
They represent the two potential outcomes in this case for each person.

364
00:47:33,660 --> 00:47:38,700
In real life, we can only get to know what.

365
00:47:40,640 --> 00:47:47,180
Right. We will never be able to ascertain what the other outcome would have been on the day or the level of exposure.

366
00:47:53,080 --> 00:47:58,200
Is there any way to. No.

367
00:47:58,980 --> 00:48:02,520
No, at the individual level, there is really no way. Yeah.

368
00:48:08,260 --> 00:48:13,660
No. No, no. Nothing to. Ingles.

369
00:48:16,460 --> 00:48:19,800
Okay. Now.

370
00:48:20,900 --> 00:48:27,530
There is also a notation for counter-factual. And again here you will find that things changed a little bit.

371
00:48:28,770 --> 00:48:32,940
The notation for counterfactual is more synthetic.

372
00:48:33,800 --> 00:48:40,940
Because it has integrated both the outcome and the exposure level in a single expression.

373
00:48:42,680 --> 00:48:53,060
So at least in in Ron's book, the counterfactual notation involves a capital letter representing the outcome.

374
00:48:54,450 --> 00:48:59,340
Obviously the counterfactual outcome and in a superscript superscript.

375
00:49:01,790 --> 00:49:04,970
The level of exposure at which.

376
00:49:06,120 --> 00:49:12,640
That counterfactual outcome was evaluated. So in this case.

377
00:49:13,520 --> 00:49:19,670
Why? Superscript eight equals zero means the outcome that would have been observed.

378
00:49:20,870 --> 00:49:30,890
Meaning miscarriage or not. If the woman had not taken her name and the prison had not because eight equals zero.

379
00:49:32,690 --> 00:49:36,690
The level of exposure is set. At.

380
00:49:37,960 --> 00:49:43,960
A equals zero at not being exposed at not taking them the prison.

381
00:49:45,160 --> 00:49:48,010
And in the literature of the school.

382
00:49:49,630 --> 00:50:00,190
At UCLA, which is the other big school that developed this theory, would actually use the word set sort of instead of this.

383
00:50:01,700 --> 00:50:11,540
Superscript. But again, we are following the Harvard notation, which is this, okay, so we can actually.

384
00:50:14,730 --> 00:50:23,040
Define. Or at least notate the counter-factual outcomes for these two women.

385
00:50:24,500 --> 00:50:33,520
At each level of exposure. So these would be the annotation of the counterfactual outcome for Irene at level of exposure set to zero.

386
00:50:34,030 --> 00:50:46,040
No exposure. This would be for Jane. And for the exposure set at a level equal to one, we could have the same.

387
00:50:46,040 --> 00:50:53,060
And this would be the outcome that would have been observed in the women if the woman had taken an antidepressant.

388
00:50:56,280 --> 00:51:04,070
Let me bring back. The summary table with a little addition here, which is, uh.

389
00:51:05,340 --> 00:51:09,240
The counter-factual outcomes at each level of exposure.

390
00:51:10,200 --> 00:51:14,340
Okay. And here is a question for you. It's really easy.

391
00:51:15,240 --> 00:51:21,730
So don't you know, don't don't stress me. We said we only live once, right?

392
00:51:23,080 --> 00:51:26,700
So from that statement. Can we guess?

393
00:51:28,880 --> 00:51:33,600
Some of these counterfactual outcomes. Okay.

394
00:51:36,550 --> 00:51:39,960
That. So let's see.

395
00:51:40,770 --> 00:51:47,690
For 18. What was her real life experience?

396
00:51:47,720 --> 00:51:53,920
Level of exposure. Taking down the prison equals one.

397
00:51:55,060 --> 00:51:59,230
Can we guess at least one of the two potential outcomes for her?

398
00:52:00,180 --> 00:52:05,550
Which one? Yes. The counterfactual outcome evaluated.

399
00:52:06,850 --> 00:52:11,020
At exposure said to one because it was one, you see.

400
00:52:11,620 --> 00:52:15,730
So we actually. Can Casey then have it here?

401
00:52:16,240 --> 00:52:22,720
How about for Jane? So what level of exposure did she actually experience in real life?

402
00:52:23,890 --> 00:52:28,150
Not to the prison. Which counterfactual outcome could we guess for her?

403
00:52:30,560 --> 00:52:36,630
Equally. Okay. No.

404
00:52:37,260 --> 00:52:40,860
It is slight conceptual premises.

405
00:52:41,820 --> 00:52:45,870
That intuitive exercise you just did very wonderfully.

406
00:52:46,920 --> 00:53:01,030
Actually has a name. So our ability to guess a counterfactual outcome from the observed outcome at the set level of exposure is called.

407
00:53:03,570 --> 00:53:07,560
Consistency. Consistency.

408
00:53:10,900 --> 00:53:17,229
And actually afterwards, she's going to be one of the conditions for this theory to work.

409
00:53:17,230 --> 00:53:22,090
But turns out if you leave aside quantum mechanics.

410
00:53:23,490 --> 00:53:28,400
And you actually had a time machine. Every time you pass.

411
00:53:29,760 --> 00:53:34,890
A person through a time machine experiment at the same level of exposure.

412
00:53:35,520 --> 00:53:41,350
You should get the same outcome. Because of this of consistency.

413
00:53:43,480 --> 00:53:48,910
Now again, is there any physics major here and nuclear physicist.

414
00:53:51,370 --> 00:53:55,149
You know, they would argue, they would say, no, no, no, no, there is actually a probability.

415
00:53:55,150 --> 00:54:01,120
But this we have to leave. I say we have to assume that these theories deterministic,

416
00:54:01,420 --> 00:54:09,880
which means we believe every time the person will pass the damaging experiment at the same level of exposure, they would get exactly the same outcome.

417
00:54:10,180 --> 00:54:15,640
Right. And that determinism is what supports the consistency,

418
00:54:15,880 --> 00:54:24,250
this ability that we just demonstrated intuitively to be able to guess the counterfactual outcomes out of the actual.

419
00:54:26,850 --> 00:54:32,850
Real life situations. So there is a bit of annotation here.

420
00:54:32,850 --> 00:54:42,000
But, you know, this is sort of straightforward. If they actually experienced exposure, this a given one,

421
00:54:42,930 --> 00:54:47,879
then the counterfactual outcome at that given level of exposure is going to be the

422
00:54:47,880 --> 00:54:53,730
same as the counterfactual outcome at the level of exposure experienced in reality.

423
00:54:54,360 --> 00:54:59,390
And it's just going to be the same as the one outcome for that person.

424
00:55:03,630 --> 00:55:07,920
Now again, I ask you to please.

425
00:55:10,430 --> 00:55:18,180
Uh, stay with me. And. So follow my made up data and experiments here.

426
00:55:18,180 --> 00:55:26,790
So here I'm going to give you some made up date, but let's assume they actually did have a time machine.

427
00:55:28,690 --> 00:55:34,810
And I did run the time machine experiments and I bring you the results for each of these two people.

428
00:55:37,080 --> 00:55:45,040
So the factual situation that Chile experienced and observed situation was a dating to an antidepressant decision.

429
00:55:45,840 --> 00:55:50,579
And two weeks later, she got a pass this person through the time machine.

430
00:55:50,580 --> 00:55:57,500
And I withheld. Then take the press. I observe what happened with respect to miscarriage.

431
00:55:58,040 --> 00:56:05,420
Turns out all other things being equal, because if you travel back in time, everything, everything should be the same.

432
00:56:06,230 --> 00:56:09,830
All other things being equal, they re not taking that they were present.

433
00:56:10,280 --> 00:56:13,910
She would have not been okay. And this is made up.

434
00:56:14,300 --> 00:56:27,340
But believe me. As if for gain this is the factual situation did not take an antidepressant registration report and need not miscarry.

435
00:56:28,740 --> 00:56:33,870
I ran the Damascene experiment with Jane, and I bring you the results.

436
00:56:35,120 --> 00:56:42,590
All other things being equal had Jane taken then take the present because she originally did not in real life did not give it.

437
00:56:43,760 --> 00:56:49,720
She would have not miscarried. So.

438
00:56:51,250 --> 00:56:58,970
We could now fill in. Those new data I gathered for you in my imaginary experiment.

439
00:56:59,360 --> 00:57:05,120
That's what I made up. Oh. So this is, uh.

440
00:57:07,230 --> 00:57:10,830
Zero for Jane and zero for in.

441
00:57:12,350 --> 00:57:17,480
Okay. These are the results of my.

442
00:57:18,800 --> 00:57:25,300
Expect. And now comes the the question, really?

443
00:57:27,010 --> 00:57:33,110
You ready? Did the antidepressant cause it to miscarry?

444
00:57:37,970 --> 00:57:41,240
What do you have? What do you have to do to find out?

445
00:57:42,470 --> 00:57:55,910
You have to compare the counter-factual outcomes in the case of in the counterfactual outcomes at different levels of exposure where different.

446
00:57:59,770 --> 00:58:04,480
Because they are different for then they the present.

447
00:58:05,530 --> 00:58:17,080
Cost. Demi, Scottish. Because when you changed the exposure level, only the outcome changed.

448
00:58:21,030 --> 00:58:27,690
So this is. The definition of an individual causal effect.

449
00:58:28,530 --> 00:58:34,480
If you could gather data on a counterfactual. You would be able to identify.

450
00:58:35,680 --> 00:58:40,170
Causal effects on every individual. Now, from my example, made up.

451
00:58:41,050 --> 00:58:44,260
Didn't take the present course, Jane, not to miscarry.

452
00:58:47,130 --> 00:58:56,650
Compare the counterfactuals. For her, the outcome was the same regardless of the level of exposure.

453
00:58:58,940 --> 00:59:02,700
She did not miscarry when she did not take a anti-depressant.

454
00:59:02,810 --> 00:59:10,880
She did not miscarry when she took the antidepressant. So does the antidepressant have anything to do with Jane's miscarriage or not miscarriage?

455
00:59:10,940 --> 00:59:19,490
No. Right. So because they are the same controversial outcomes for Jane, then in the present does not have a causal effect.

456
00:59:22,440 --> 00:59:30,509
So again, we can formalize the definition of a causal effect that is an individual causal

457
00:59:30,510 --> 00:59:36,420
effect when the counterfactual outcomes at different levels of exposure differ.

458
00:59:38,950 --> 00:59:55,520
Right. You cannot find him.

459
00:59:55,910 --> 01:00:01,970
You cannot find him. So I know this is bad news. And you may be wondering why on earth were we going through this?

460
01:00:03,230 --> 01:00:06,710
So this is a foundation to understand what's coming.

461
01:00:06,980 --> 01:00:10,930
But the question in all my honesty, that's it.

462
01:00:11,750 --> 01:00:15,470
Your question is, we cannot find counterfactuals at the individual level.

463
01:00:17,310 --> 01:00:21,360
I mean, you know, there is a technical note or whatever in in the readings.

464
01:00:21,360 --> 01:00:28,290
I said, well, there are some cases and there's some assumptions, you know, crossovers, stuff and so on.

465
01:00:28,290 --> 01:00:37,800
But that for the sake of this class, the assumption is we cannot really determine individual counterfactuals without assumptions.

466
01:00:39,450 --> 01:00:49,189
It's not just. Okay.

467
01:00:49,190 --> 01:00:53,030
So two things. Again, these are made up data and examples.

468
01:00:53,760 --> 01:01:00,329
And I just said, you know, the actual situation with Jane is that she did not take an antidepressant and she did

469
01:01:00,330 --> 01:01:07,800
not miscarry later when I changed her exposure status to taking it to the prison.

470
01:01:08,070 --> 01:01:13,150
She also did not miscarry. Yeah.

471
01:01:13,390 --> 01:01:22,160
That I invented. So under my imagination, the anti-depressant does not have a causal effect on J.

472
01:01:22,840 --> 01:01:37,290
Right. What is it?

473
01:01:52,740 --> 01:02:02,650
Thank you for. Yeah well that that sort of coming up and it's it's it's a bit of a different chapter but if you if you keep up with me,

474
01:02:02,660 --> 01:02:08,229
we will we'll get there soon enough. I know you are anxious to find out what happens.

475
01:02:08,230 --> 01:02:16,150
And, you know, that's quite flattering, actually. But for now, let's make sure that we are all on the same page with with this theory.

476
01:02:16,510 --> 01:02:20,169
So here you have an example of a hill that they didn't think they present at this station.

477
01:02:20,170 --> 01:02:23,140
We drove, and two weeks later, she says,

478
01:02:24,790 --> 01:02:33,670
I run the time machine experiment and found that all other things being equal had held and not taken an antidepressant.

479
01:02:33,880 --> 01:02:38,620
She would have miscarried. Question for you, didn't they?

480
01:02:38,620 --> 01:02:44,200
The present goes. He let to miscarry. So here is the.

481
01:02:45,200 --> 01:02:54,889
A notation that you have to compare. And because I actually had brought a pole everywhere, uh, thing.

482
01:02:54,890 --> 01:03:00,260
But it seems you all pretty much answered no. So let's keep that.

483
01:03:00,290 --> 01:03:03,320
Yeah, the answer is no, because the two counter-factual outcomes are the same.

484
01:03:03,650 --> 01:03:08,600
Right. So, yeah, I had both. Okay, great.

485
01:03:09,050 --> 01:03:15,500
You. Um, so turns out you,

486
01:03:15,570 --> 01:03:23,979
you can defined causal types and if you were able to know how people would behave

487
01:03:23,980 --> 01:03:28,270
with respect to outcomes after being said to one or another exposure level,

488
01:03:29,260 --> 01:03:32,440
there are actually four possible causal types.

489
01:03:33,840 --> 01:03:38,550
The first two of them represent no causal effect of exposure.

490
01:03:39,180 --> 01:03:42,480
So the first one that is going to be an outcome.

491
01:03:44,030 --> 01:03:49,490
At both level of exposures. And these people sometimes are called doomed.

492
01:03:50,420 --> 01:03:55,430
I mean, they are they are meant to get the outcome regardless of the particular exposure.

493
01:03:57,290 --> 01:04:05,360
When the outcome is not going to happen at either level of exposure, then they are called immune.

494
01:04:07,970 --> 01:04:13,250
But then there are two situations in which you can actually identify an individual causal effect.

495
01:04:13,880 --> 01:04:21,350
The first one, the person gets the outcome when it's unexposed and doesn't get the outcome when it's exposed.

496
01:04:21,500 --> 01:04:25,640
Therefore, oops, I'm sorry, but it's susceptible.

497
01:04:26,090 --> 01:04:36,330
But in this case, the exposure is preventive. Because being exposed saved the person from getting the outcome right.

498
01:04:37,970 --> 01:04:44,960
And then the last time. Does not get the outcome when it's unexposed, but gets the outcome when it's exposed.

499
01:04:45,710 --> 01:04:52,400
So in this particular case, the person is susceptible and the exposure is causative meaning.

500
01:04:52,400 --> 01:04:58,760
In these two situations, the exposure is caused by the direction of the effect is right.

501
01:04:59,360 --> 01:05:02,240
So in this case, is protective. In this case is harmful.

502
01:05:04,890 --> 01:05:09,300
Now I said that there are some assumptions that we need to be mindful of for this theory to work.

503
01:05:09,960 --> 01:05:15,990
The first is that the exposures, the treatments have to be well defined.

504
01:05:16,230 --> 01:05:20,790
So these these assumptions call the well-defined interventions assumption.

505
01:05:21,360 --> 01:05:26,850
That means only one version of the treatment.

506
01:05:28,040 --> 01:05:33,800
Should exist every time you pass the person through a counterfactual experiment.

507
01:05:34,100 --> 01:05:38,899
In practical terms, that means this will only work if, let's say,

508
01:05:38,900 --> 01:05:49,010
the antidepressant that Irene took was always the same pill with the same composition, the same dose, the same color.

509
01:05:49,010 --> 01:05:52,880
This took it at the same time of the day, etc. Right.

510
01:05:53,630 --> 01:05:59,700
Well, divine intervention example of an ill divine intervention that you probably read in the book.

511
01:06:00,440 --> 01:06:06,169
Body mass index as an exposure or let's say, of obesity weight,

512
01:06:06,170 --> 01:06:13,280
because you can get to a high body mass index through many ways that do not represent the same thing.

513
01:06:14,740 --> 01:06:19,990
Body mass index greater than 30 years indicator of obesity is not as good as a pill.

514
01:06:21,090 --> 01:06:27,890
Uh, of the same. Those same colors. Same. As indicator of an antidepressant.

515
01:06:28,830 --> 01:06:34,350
You can have a BMI of 30 because you are muscular, because you are pregnant or, you know,

516
01:06:35,130 --> 01:06:40,950
for many other reasons that may not need to do with what people believe leads to obesity.

517
01:06:42,230 --> 01:06:46,340
So that's an ill defined intervention set back by the divine intervention.

518
01:06:46,940 --> 01:06:51,890
So the theory may break down when you have these ill defined interventions.

519
01:06:55,680 --> 01:06:59,460
The second is an assumption of no interference, although there is.

520
01:07:00,590 --> 01:07:04,190
Active work on integrating interference into the theory.

521
01:07:04,190 --> 01:07:07,660
What's interference? Interference is also called carryover.

522
01:07:07,670 --> 01:07:15,260
It means a subject. Factual outcome should not depend on other person's exposure or treatment.

523
01:07:15,590 --> 01:07:21,590
So obviously, as you may be thinking, this may break down for infectious diseases.

524
01:07:22,610 --> 01:07:32,500
Because a person's. Chances of getting COVID depends on some other people's vaccination status.

525
01:07:33,950 --> 01:07:38,840
Even to some extent independently of their own vaccination status.

526
01:07:39,740 --> 01:07:42,290
So, again, this may break down for infectious diseases.

527
01:07:44,890 --> 01:07:54,940
And the final assumption is that this theory, again, is deterministic, which means it needs to ignore quantum mechanics.

528
01:07:54,970 --> 01:08:01,390
It means you have to assume that every time you pass somebody's three counterfactual experiments,

529
01:08:02,320 --> 01:08:09,460
if you always set the exposure level at the same level, the outcome will be the same.

530
01:08:10,000 --> 01:08:14,170
Turns out in quantum mechanics, the outcome may not be the same.

531
01:08:14,290 --> 01:08:18,760
There is a probability. So it's not one or zeroes anymore.

532
01:08:21,500 --> 01:08:30,739
And I saw a paper from last year from Jamie Robbins at an event there, but I saw the title,

533
01:08:30,740 --> 01:08:35,330
and it seems he's already thinking about integrating quantum mechanics into this field.

534
01:08:36,740 --> 01:08:40,650
Um. No.

535
01:08:42,050 --> 01:08:45,950
In real life. Let's say we have an extended dataset with more people.

536
01:08:46,340 --> 01:08:50,720
In this example of taking antidepressants in early pregnancy and miscarriage.

537
01:08:52,070 --> 01:08:56,250
So I have brought you the data here. And which counterfactuals.

538
01:08:56,520 --> 01:09:01,710
Controversial outcomes are known assuming consistency so well for a reason we know.

539
01:09:02,460 --> 01:09:08,940
And their exposure equals one. The outcome is one for Jane because she was actually unexposed.

540
01:09:08,940 --> 01:09:14,040
The outcome is was zero. So this one for the other women.

541
01:09:14,100 --> 01:09:21,210
These would be the counterfactual outcomes as we could guess from what they actually experienced in real life.

542
01:09:24,350 --> 01:09:34,820
But again, in real life, we cannot determine their counterfactual outcomes and we cannot determine individual causal effects.

543
01:09:35,990 --> 01:09:43,790
So. In a way, colossal inference is a missing data problem.

544
01:09:45,530 --> 01:09:51,890
Is missing because we will always be missing half of the.

545
01:09:52,950 --> 01:09:56,790
Outcomes under the alternative level of exposure.

546
01:09:58,180 --> 01:10:08,350
How do we actually make a difference? Well, we need another definition of causal effect that requires weaker assumptions.

547
01:10:10,120 --> 01:10:17,290
So we still have 10 minutes. And I will I will move on with with that.

548
01:10:18,500 --> 01:10:26,200
So what? What's that other definition of causal effects that requires weaker assumptions and

549
01:10:26,200 --> 01:10:31,030
that we can actually implement by doing in addition to understanding what's coming.

550
01:10:31,450 --> 01:10:44,590
One very practical ramification of understanding the impossibility of determining individual causal effects is you guys are called to testify.

551
01:10:46,120 --> 01:10:56,300
In. Lawsuits. Against, for example, companies that expose people.

552
01:10:58,060 --> 01:11:02,560
To give an end contaminants, whatever. And then.

553
01:11:03,590 --> 01:11:07,580
Somebody says my exposure to that thing caused.

554
01:11:09,150 --> 01:11:16,310
My concern. These will come in handy if that's ever the case.

555
01:11:19,600 --> 01:11:32,960
Okay. So. That alternative way to do causal inference is through what we call average causal effects.

556
01:11:33,200 --> 01:11:37,130
And these these years can be implemented in real life.

557
01:11:37,170 --> 01:11:45,680
Yeah. So average causal effects are estimated in populations, not in individuals.

558
01:11:47,250 --> 01:11:53,100
They are similar to the counterfactual theory. And here we go with with my example.

559
01:11:54,390 --> 01:12:01,110
Let's say we are interested in the effect of marijuana smoking on the risk of Alzheimer's disease.

560
01:12:02,630 --> 01:12:09,340
Okay. So how would we go about. Um, making counseling pretty well.

561
01:12:09,340 --> 01:12:14,870
We can identify a group of people. With daily marijuana smoking.

562
01:12:16,980 --> 01:12:26,060
And after 30 years, we go back to the people and find out how many have got Alzheimer's.

563
01:12:26,070 --> 01:12:31,420
Right. Castle.

564
01:12:31,420 --> 01:12:40,450
Question What do we need to know to determine whether marijuana is smoking, let's say the exposure or a causes Alzheimer's?

565
01:12:40,600 --> 01:12:49,440
Let's say the outcome or what? So the answer is exactly the same as Hannah's, except that now it would apply to the group, to the population.

566
01:12:49,450 --> 01:12:58,510
Right. So how many of these people would have developed Alzheimer's had they not smoking marijuana, everything else being equal?

567
01:13:00,160 --> 01:13:06,600
Right. Would you agree? I think that's an extension of your financial to the individual cause of question.

568
01:13:06,610 --> 01:13:14,650
Right. Except for the group, you're the only thing you can have you need to do is to change these people's exposure.

569
01:13:17,330 --> 01:13:26,360
Now. You recall, to identify an individual causal effect, you had to compare the counterfactual outcomes for each individual.

570
01:13:27,200 --> 01:13:35,780
Well, guess what? To determine the average population effect, you would have to compare the counterfactual probabilities.

571
01:13:37,480 --> 01:13:45,040
So you would you would have to summarize the results of the counterfactual experiment on each person for the whole group.

572
01:13:45,850 --> 01:13:51,630
When he did experience the exposure in real life and when counterfactual,

573
01:13:53,050 --> 01:13:58,660
he did not experience the exposure or experienced a different level of exposure.

574
01:14:00,370 --> 01:14:03,100
But the definition of the effect would be the same.

575
01:14:03,760 --> 01:14:10,570
If the counterfactual probabilities of the outcome at different levels of exposure differ, you have a causal effect.

576
01:14:10,840 --> 01:14:18,600
You have an average causal right. By contrast.

577
01:14:19,850 --> 01:14:24,319
If the counter-factual probabilities at different levels of exposure are the

578
01:14:24,320 --> 01:14:29,720
same or the expected values depending on the scale of your outcome variable.

579
01:14:30,700 --> 01:14:43,750
There is no causal effect. And when there is no causal effect in causal lingo, it's it's said that the null hypothesis of no average effect holds.

580
01:14:45,880 --> 01:14:49,540
No causal effect means null hypothesis holds.

581
01:14:51,230 --> 01:15:01,990
Okay. Correct. There are two ways in which you can have no population of average effect.

582
01:15:04,020 --> 01:15:12,930
The first way in which this may happen is when you have a complete balance of individual causal effects in opposite directions.

583
01:15:12,960 --> 01:15:24,000
In other words, when you have only the causal types, but they are in the same proportion in opposing directions.

584
01:15:24,450 --> 01:15:33,600
So in this case, for example, you have a dataset for people and for AIDS one and three.

585
01:15:34,080 --> 01:15:39,270
You have a protective effect of exposure right now.

586
01:15:39,750 --> 01:15:42,990
Yes, you have a protective effect of exposure.

587
01:15:43,620 --> 01:15:47,610
And for individuals, two and four, you have a harmful effect for exposure.

588
01:15:47,700 --> 01:15:53,700
So because you have two people with a protective effect and two people with a harmful effect, they cancel out.

589
01:15:54,150 --> 01:15:58,880
And if you actually do the math. The probability of.

590
01:16:00,280 --> 01:16:09,640
The counterfactual outcome evaluated at the exposure level equals zero is to this one and three right divided by four,

591
01:16:10,540 --> 01:16:17,200
and the probability of the counterfactual outcome evaluated at exposure equals one is also two.

592
01:16:17,560 --> 01:16:21,010
These individuals two and four divided by four.

593
01:16:21,070 --> 01:16:24,840
The total number of people who went through the counterfactual experiment.

594
01:16:27,720 --> 01:16:32,340
So again, these probabilities had equal because there is an equilibrium of individual effects in

595
01:16:32,340 --> 01:16:38,550
opposite directions that cancel out equal proportions of causal types protective and harmful.

596
01:16:40,630 --> 01:16:49,770
But there is another possibility. If you look at this dataset, there is actually no causal effect on anyone.

597
01:16:50,640 --> 01:16:53,760
Right. The counterfactual outcomes for each people.

598
01:16:55,990 --> 01:17:00,070
In this dataset are the same, whether they are exposed or unexposed.

599
01:17:00,820 --> 01:17:07,240
So for this guy. The controversial outcomes are one, they get the outcome regardless.

600
01:17:07,690 --> 01:17:12,070
So, you know, they are doomed and the other three are immune.

601
01:17:13,510 --> 01:17:21,010
So if you do the math again, you will find that the counterfactual probabilities at each level of exposure are the same.

602
01:17:22,870 --> 01:17:30,400
So when you have a complete absence of individual effects for every person in your population.

603
01:17:32,040 --> 01:17:37,260
The theory calls this the sharp causal null hypothesis.

604
01:17:40,510 --> 01:17:45,220
A. Now. Well, regardless of that is the problem.

605
01:17:46,930 --> 01:17:51,550
All people in the group we observed were exposed to daily marijuana smoke.

606
01:17:52,980 --> 01:17:56,910
And we don't have a time machine. So let's get real.

607
01:17:57,810 --> 01:18:02,730
We can never directly observe what would have happened to them in the absence of exposure.

608
01:18:04,320 --> 01:18:12,020
Right. What is the solution to the problem?

609
01:18:12,080 --> 01:18:23,300
Well, we need to identify a group of unexposed people that is presumed to be identical to the exposed group in all other respects,

610
01:18:24,350 --> 01:18:29,089
identical to be able to faithfully represent their counterfactual experience.

611
01:18:29,090 --> 01:18:35,750
Because recall, we always had that condition, of all things being equal, everything else being equal.

612
01:18:36,080 --> 01:18:41,950
So we have to find more or less clones of those people who have lived through exactly the same experiences.

613
01:18:41,960 --> 01:18:53,540
Right. If we were able to find that group, a group that represents the counterfactual experience of the other at the different level of exposure,

614
01:18:54,380 --> 01:18:58,610
we would say that the two groups are exchangeable.

615
01:18:59,700 --> 01:19:08,340
The two groups are exchangeable with respect to any characteristics that might differ between them other than the exposure level.

616
01:19:12,650 --> 01:19:20,570
All right. So you're looking a little bit scared now, so maybe we could stop, but are there any questions?

617
01:19:32,320 --> 01:19:36,100
Right? Right. We'll get real next time.

618
01:19:38,410 --> 01:19:41,980
See you Wednesday. Have a good weekend.

619
01:19:54,940 --> 01:19:58,670
Yes. That's how you ask the question.

620
01:19:59,120 --> 01:19:59,380
Of course.

