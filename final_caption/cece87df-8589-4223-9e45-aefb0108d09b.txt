1
00:00:00,030 --> 00:00:07,169
Was that you learned something? Yeah. But again, we have a full Democratic House and Senate the first time for 40 years.

2
00:00:07,170 --> 00:00:10,940
That's nuts. Yeah. Is that like.

3
00:00:11,450 --> 00:00:14,550
It's, like, pretty close. It's pretty much. I was looking at.

4
00:00:17,950 --> 00:00:24,080
House. Senate asked them to move it. One of them was talking to me.

5
00:00:25,360 --> 00:00:32,350
It's like close by possibility and for all I can see is the kind of effort to do so.

6
00:00:32,590 --> 00:00:36,670
So how about the tops? He made it time to spare.

7
00:00:37,300 --> 00:00:41,620
Just the time we sat by home. How significant is this loss?

8
00:00:42,430 --> 00:00:58,130
Yeah, that was tough. But yeah, I think yeah, I think it was very disappointed in the sense that I don't think it was a great football.

9
00:00:58,480 --> 00:01:02,170
I know. I don't really I just don't like to look at it.

10
00:01:02,170 --> 00:01:07,830
But I mean, it was something that never called the market the whole world for a while.

11
00:01:07,930 --> 00:01:15,100
It's like, Yeah, that's where they used to be.

12
00:01:15,250 --> 00:01:21,670
That was pretty big, like accidental.

13
00:01:21,820 --> 00:01:30,550
I appreciate that. You just looked at the results for like 35 minutes and then went back to my gosh, I was like 1230.

14
00:01:30,700 --> 00:01:35,499
I was like watching it and I was like, I'm not going to lose a lot of sleep.

15
00:01:35,500 --> 00:01:38,890
But like, I'm very curious. I was it was like a nightmare.

16
00:01:38,920 --> 00:01:43,900
She said to me, I woke up at like 5 a.m., I think we're going to get started.

17
00:01:44,680 --> 00:01:46,420
So I'm going to do something a little bit different today.

18
00:01:46,900 --> 00:01:53,740
We're going to go through this kind of case study, and it's really talking about comparative effectiveness evidence.

19
00:01:54,160 --> 00:02:02,799
And I think it draws on some areas and some interesting questions about how should we be communicating evidence,

20
00:02:02,800 --> 00:02:05,350
information, how should we interpret evidence,

21
00:02:06,610 --> 00:02:15,610
and how should different people think about that evidence or have access to that evidence or, you know, communicate that evidence to other people.

22
00:02:17,740 --> 00:02:22,030
So I want to kind of quick before we get into too much detail here,

23
00:02:22,030 --> 00:02:25,450
kind of give an overview of comparative effectiveness research and really discuss that

24
00:02:25,450 --> 00:02:29,530
with you here and talk about different organizations that have interest in that.

25
00:02:30,070 --> 00:02:33,250
And then then we'll get into kind of the case.

26
00:02:33,340 --> 00:02:38,140
So first of all, comparative effectiveness research and all this talk to you guys.

27
00:02:38,230 --> 00:02:44,020
What do you know about comparative effectiveness research? What is comparative effectiveness research?

28
00:02:48,730 --> 00:02:53,870
Probably Herbert, who's heard of comparative effectiveness research. Actually.

29
00:02:54,070 --> 00:02:57,580
Okay. What do you think it is here?

30
00:02:57,860 --> 00:03:01,210
There's two. There's three words. Suit comparative effectiveness research.

31
00:03:02,740 --> 00:03:06,600
Just like comparing, like, different studies and, like, the results, maybe the methods that they go about doing it.

32
00:03:07,240 --> 00:03:10,250
So you could be comparing studies.

33
00:03:10,270 --> 00:03:13,330
So that's and that's almost meta analysis, right?

34
00:03:13,360 --> 00:03:18,430
You're you're studying many different studies. But let's think about the studies themselves.

35
00:03:18,820 --> 00:03:23,650
So a particular study might be a comparative effectiveness study or research.

36
00:03:23,920 --> 00:03:29,640
So what do you mean? I guess like comparative effectiveness that you think that.

37
00:03:30,130 --> 00:03:33,240
Like how? Well, two different interventions work. Yeah.

38
00:03:33,250 --> 00:03:36,730
So the first thing is comparative. And so we have to compare something to something else.

39
00:03:37,080 --> 00:03:40,310
You can't just say. Tylenol.

40
00:03:40,850 --> 00:03:44,600
It's great. Now you need to compare Tylenol versus Advil or something, right?

41
00:03:44,810 --> 00:03:48,920
So it has to be comparative. And then the other part is effectiveness.

42
00:03:48,920 --> 00:03:53,210
And what do we mean by effectiveness or who's heard of efficacy?

43
00:03:55,130 --> 00:03:59,600
I've heard of efficacy and then there's effectiveness. Are they the same thing or are they different?

44
00:03:59,650 --> 00:04:06,050
What is? And if so, what is the difference? Also, consider about the safety and adverse events.

45
00:04:06,650 --> 00:04:09,710
So safety and adverse events are also something we might care about.

46
00:04:09,990 --> 00:04:15,500
Right. And I guess I would I would put adverse events under the umbrella of safety.

47
00:04:17,210 --> 00:04:23,330
And actually that FDA's mission is to look at safety and and and effectiveness.

48
00:04:25,040 --> 00:04:32,540
So what is. Or efficacy, really? So what is and is there a difference in efficacy and effectiveness?

49
00:04:32,540 --> 00:04:40,450
And if so, what does that look like? Yeah.

50
00:04:40,660 --> 00:04:48,820
So is it we're mainly looking at like the marginal differences in efficacy between two interventions.

51
00:04:49,030 --> 00:04:52,120
Well yeah. So that's, that's the comparative part of this. Exactly.

52
00:04:52,120 --> 00:04:56,919
You are looking at the differences. So you're talking about, you know, Tylenol versus Advil.

53
00:04:56,920 --> 00:04:59,180
And so what are the differences between the two?

54
00:04:59,200 --> 00:05:04,120
So one might be a little bit better at managing your pain, but maybe has some additional side effects.

55
00:05:04,660 --> 00:05:08,200
Yeah. So you're looking at those marginal differences between those products.

56
00:05:08,200 --> 00:05:12,549
What are the the differences? And you were saying products, but it really doesn't have to be products.

57
00:05:12,550 --> 00:05:17,740
It could be. It could be. You know, we talk about so much about drugs in this class, and this is another example of that.

58
00:05:17,740 --> 00:05:22,780
But you could talk about devices, you could talk about surgical procedures, you could talk about public health interventions.

59
00:05:23,050 --> 00:05:26,400
Should we put fluoride in the water or sucrose in the water?

60
00:05:26,710 --> 00:05:29,890
You know? Right. I mean, you could say, you know, what are we going to put in the water? Yeah.

61
00:05:31,270 --> 00:05:35,679
So it's kind of the main difference between comparative effectiveness and cost effectiveness.

62
00:05:35,680 --> 00:05:42,070
Like you're just for comparative effectiveness, you're more just worried about efficacy in general, not considering the cost as much.

63
00:05:42,760 --> 00:05:45,850
So so yeah, comparative effectiveness.

64
00:05:45,850 --> 00:05:51,610
I would think of comparative effectiveness as a a superset here.

65
00:05:51,610 --> 00:05:55,000
So it's really comparative effectiveness research here.

66
00:05:55,300 --> 00:06:00,280
And then cost effectiveness analysis, I would say is a subset of that.

67
00:06:00,520 --> 00:06:05,350
So again, cost effectiveness analysis of course looks at cost.

68
00:06:05,980 --> 00:06:11,800
Comparative effectiveness analysis can really look at anything I would consider cost forms a subset of that.

69
00:06:12,070 --> 00:06:19,800
That specifically does look at cost. And then, you know, cost, as I mentioned earlier, kind of cost utility analysis, you know,

70
00:06:20,080 --> 00:06:27,970
is a subset of cost effectiveness analysts, that is and that is measuring health outcomes in terms of quality adjusted life years.

71
00:06:28,330 --> 00:06:32,379
Yeah. So, but cost effectiveness analysis, you know, it would be a subset of that, but comparative effectiveness,

72
00:06:32,380 --> 00:06:37,840
I would argue is kind of broader because it doesn't necessarily have to look at cost.

73
00:06:38,350 --> 00:06:42,550
Just be, you know, what's your pain score with Technavio versus Tylenol?

74
00:06:45,320 --> 00:06:55,670
But what is this? So I will say that although the words are very similar, in fact, there is an efficacy in the kind of medical health world.

75
00:06:56,180 --> 00:07:00,830
Oftentimes there is in public health for others. There is a slight difference between efficacy and effectiveness.

76
00:07:01,010 --> 00:07:10,520
And the idea is efficacy might be some sort of scientific biological effect, or is this drug efficacious?

77
00:07:10,580 --> 00:07:14,870
Does it actually shrink your tumor size?

78
00:07:15,290 --> 00:07:21,619
Does it actually reduce pain? And that really is a focus of what the FDA is interested in.

79
00:07:21,620 --> 00:07:28,730
Is is technically is there some sort of efficacy of this instead of some sort of snake oil that does nothing?

80
00:07:29,060 --> 00:07:34,730
Does this product actually have efficacy? Does it lower your pain score or reduce your tumor volume?

81
00:07:35,420 --> 00:07:40,130
So forth. So that is what the FDA is looking at now.

82
00:07:40,280 --> 00:07:50,330
Effectiveness is a little bit broader than that. And maybe another word of saying that we're saying this would be real world effectiveness.

83
00:07:50,630 --> 00:07:56,180
So in the real world, which is outside of kind of the clinical laboratory environment,

84
00:07:57,050 --> 00:08:03,440
does does this have real world efficacy in the real world where people forget to take their pills?

85
00:08:03,440 --> 00:08:10,759
Every every so often in the real world, where people don't have very precisely controlled co-morbidities,

86
00:08:10,760 --> 00:08:16,520
they might have some extra co-morbidities in the real world where this is used off label in the real world.

87
00:08:16,520 --> 00:08:24,650
And that's kind of real world effectiveness. And and so that's the idea behind this push in the last decade or so for

88
00:08:24,890 --> 00:08:29,990
comparative effectiveness research is kind of looking at real world effectiveness.

89
00:08:31,070 --> 00:08:31,880
Is there a cautionary?

90
00:08:34,400 --> 00:08:41,960
So comparative outcomes research so key things are comparative were comparing something to something else and kind of real world effectiveness.

91
00:08:42,590 --> 00:08:48,460
And that's part of what you hear about in the evergreen example is the idea is that they wanted to get some more kind of

92
00:08:48,470 --> 00:08:55,190
real world effectiveness versus clinical efficacy in a very tightly controlled and a laboratory controlled environment.

93
00:08:57,290 --> 00:09:02,179
So [INAUDIBLE], you may have heard of Pachauri Patient-centered Outcome Research Institute in Sweden.

94
00:09:02,180 --> 00:09:08,060
They're very much interested in outcomes research and and comparative effectiveness research.

95
00:09:09,410 --> 00:09:16,910
And maybe on the second question, you guys, so what what do you think what when when you hear pain patient centered this what does that mean to you?

96
00:09:19,550 --> 00:09:27,590
Yeah, it's like responding to a stated need or desire or question that stems from patients,

97
00:09:27,590 --> 00:09:33,050
like it's being driven by patient needs as opposed to, like, researcher needs.

98
00:09:33,530 --> 00:09:37,460
Mm hmm. Yeah. And so this is. Yeah, it's.

99
00:09:37,490 --> 00:09:44,360
What do the patients really care about? So again, if it's, you know, Advil versus Tylenol, do they care about these side effects?

100
00:09:44,360 --> 00:09:49,489
Do they care about the pain? Do they care and maybe have over styles on a good example?

101
00:09:49,490 --> 00:09:53,690
But oftentimes it might be do I take a pill for my pain medication or some sort of injection?

102
00:09:54,440 --> 00:09:59,149
And there are real patients. There are things that patients care about.

103
00:09:59,150 --> 00:10:02,170
You know, maybe they don't want to get stuck with needles every 6 hours or whatever.

104
00:10:02,180 --> 00:10:10,340
Maybe they prefer to take a pill orally so and maybe they'd prefer to take a small pill versus a really large one that's difficult to swallow.

105
00:10:11,120 --> 00:10:14,540
So patient centered is can mean a lot of things that the patients really care about.

106
00:10:14,540 --> 00:10:19,759
Then maybe somebody in a white coat hasn't really thought of and the people in white coats might say,

107
00:10:19,760 --> 00:10:24,229
Oh, your lab values are X, Y, and Z, where the patient doesn't care what their lab values are.

108
00:10:24,230 --> 00:10:27,620
They care what? How do I feel? Am I going to die next week?

109
00:10:27,990 --> 00:10:30,230
You know, those are the things that that the patients might care.

110
00:10:30,350 --> 00:10:37,669
So patients really take into account the things that the patients really do care about and also outcomes.

111
00:10:37,670 --> 00:10:41,960
Research is again just outcomes that we care about as well. Think it's tied to that as well.

112
00:10:43,700 --> 00:10:46,610
But that's something that is very interesting and I guess tied to that.

113
00:10:46,820 --> 00:10:56,750
As part of that, we often, very often will require that the research actually has patients involved in the process,

114
00:10:57,490 --> 00:10:59,840
in enrollment, in designing the research as well.

115
00:11:00,230 --> 00:11:06,500
So that so that it actually is patients that are coming are not going to say and like my reading like it mentioned how like they wanted to

116
00:11:06,500 --> 00:11:13,399
engage patients in like the research questions process like to determine like specific like biometrics that they wanted to see like optics.

117
00:11:13,400 --> 00:11:22,900
And so yeah, and again, you have clinicians who are so deeply involved in this research, so they're like, Oh,

118
00:11:22,910 --> 00:11:30,469
I really want to make sure that EGFR goes from a 32.6 to 27.4, and they're really into the weeds of the details of that.

119
00:11:30,470 --> 00:11:34,880
But does the patient care whether their EGFR is a 23.6 or 23.7?

120
00:11:35,180 --> 00:11:40,020
No, the patient doesn't necessarily care about that, but the researchers might be really involved in.

121
00:11:40,040 --> 00:11:46,580
And now with that said, EGFR or something like that in kidney disease is really important in my understanding of that.

122
00:11:46,730 --> 00:11:51,650
But but I think we need the bigger picture here for the patient about what do they really care about.

123
00:11:53,680 --> 00:11:58,850
Same. So that's that's one thing that Primary cares about and that FDA.

124
00:11:59,660 --> 00:12:03,319
FDA is really when we think about it again, historically,

125
00:12:03,320 --> 00:12:09,700
it was it was designed in response to people selling snake oil that was going to cure your cancers or whatever it is.

126
00:12:09,710 --> 00:12:16,340
And so they're designed to really prevent marketing and information here.

127
00:12:16,580 --> 00:12:21,620
And if there is marketing, it's it has to have what's known as substantial evidence.

128
00:12:22,520 --> 00:12:25,970
Also, they can disseminate health care, economic information.

129
00:12:26,450 --> 00:12:33,740
So that's, you know, cost free resources, all of that that's typically to payers rather than than physicians.

130
00:12:34,340 --> 00:12:38,540
So anyway, there are a lot of, you know, that's highly regulated.

131
00:12:38,540 --> 00:12:40,849
And I guess maybe the next next slide here is important.

132
00:12:40,850 --> 00:12:50,210
Here is if the drug companies go afoul of that, if they're sharing information, that isn't substantial evidence.

133
00:12:52,850 --> 00:12:55,490
They they can pay a big price for this.

134
00:12:56,150 --> 00:13:03,110
And so these are just a few examples in the last 20 years or so of big fines that have been given to pharmaceutical

135
00:13:03,110 --> 00:13:15,140
companies for for really this for promoting drugs where there wasn't considered substantial evidence of its efficacy.

136
00:13:15,170 --> 00:13:21,319
So, you know, saying, you know, and this is know the drug representatives, you know,

137
00:13:21,320 --> 00:13:26,000
talking doctors saying, hey, you know, Zyprexa works well for young people.

138
00:13:26,360 --> 00:13:28,220
Maybe you should also give it to the old people.

139
00:13:28,490 --> 00:13:33,830
And and then, you know, so that you know, but maybe there wasn't a study that said, hey, this actually works in all people.

140
00:13:35,630 --> 00:13:37,250
And so, by the way,

141
00:13:37,910 --> 00:13:47,180
there is a well-known professor at the University of San Francisco who's really into clinical trials and clinical trials that goes into reference,

142
00:13:47,180 --> 00:13:58,790
etc., etc., etc., who doesn't feel that the that some of the observational studies of the most recent corporate boosters are substantial evidence.

143
00:13:59,000 --> 00:14:05,090
And so because, you know, they're they might not be studied in large human trials and so forth.

144
00:14:05,090 --> 00:14:11,120
And outcomes they're looking for are things like antibody response, but not necessarily clinical endpoints that we care about.

145
00:14:12,110 --> 00:14:23,630
And so is tweeting about how the FDA commissioner is promoting, you know, if you know, the FDA is saying, hey, get these boosters.

146
00:14:24,050 --> 00:14:27,290
And and he's saying, like, if pharma said, hey, get these boosters,

147
00:14:27,920 --> 00:14:31,970
they're actually saying things that are not mandatory based on substantial evidence.

148
00:14:32,570 --> 00:14:41,940
So we have to be careful that, you know, because, you know, again, the pharmaceutical companies have to say thing, you know,

149
00:14:41,990 --> 00:14:49,520
when they're promoting these medications, you know, they have to say, hey, this new cancer medication, you should give it to your cancer patients.

150
00:14:50,210 --> 00:14:58,310
And here's the randomized controlled trial, clinical trial that says we reduce tumor volumes and we improve life expectancy and so forth.

151
00:14:58,640 --> 00:15:02,200
So they have to have that kind of level.

152
00:15:02,570 --> 00:15:09,860
Yes. So Margaret said this in their readings. But these fines or these lawsuits or the FDA is imposing these.

153
00:15:09,860 --> 00:15:16,250
Have you heard of these kids? Yeah, typically, I think that I think there are lawsuits.

154
00:15:16,760 --> 00:15:24,020
I don't know if that actually is good question around precisely how that works legally, if the FDA is able to just levy them where they have to go.

155
00:15:24,150 --> 00:15:28,190
Of course, I'm sure. I'm sure there's some sort of a process for, you know, something that's like $2 billion.

156
00:15:28,190 --> 00:15:34,340
The FDA chickens can always say, thank you very much, but I think they would initiate the action.

157
00:15:38,300 --> 00:15:46,010
Yeah. So and and this would be different, I think from and this is different for then, you know,

158
00:15:46,010 --> 00:15:50,450
some sort of harmful drug that kills people, you know, that would be something different.

159
00:15:50,450 --> 00:15:55,700
This is these are fines for marketing, you know, for for saying, hey,

160
00:15:56,660 --> 00:16:01,910
you should use Paxil for pediatric use when it when it's only been studied in adults,

161
00:16:01,910 --> 00:16:05,600
for example, and has efficacy in adults, but, but has not been shown.

162
00:16:05,690 --> 00:16:12,010
Now, maybe it is efficacious in kids, but there's no there is no substantial evidence of that, at least the time when they did this.

163
00:16:12,200 --> 00:16:16,270
So that's what they're getting sued for here. They're getting the fines with that.

164
00:16:16,310 --> 00:16:22,670
And I mean, at least for the first one, it said in 2012, the Justice Department announced that the company agreed to pay the fines.

165
00:16:22,680 --> 00:16:26,810
I think there was like a pending lawsuit and then they disagreed to pay the fine.

166
00:16:29,950 --> 00:16:39,690
So again, this is this is different than something saying that it's that it was harmful to kill people.

167
00:16:39,700 --> 00:16:48,290
But this is for market. Yes. Is there any evidence that these fines work, that they change their practices?

168
00:16:48,310 --> 00:16:57,970
Because I feel like basically our entire media atmosphere is just like covered with like bad pharma behavior that is basically unchecked.

169
00:16:58,960 --> 00:17:02,440
So that's a good question. So how does this affect behavior?

170
00:17:02,440 --> 00:17:08,620
I mean, these a lot of these were from like ten or 15 years ago.

171
00:17:08,860 --> 00:17:13,180
I actually look to see if there are any more recent ones. I didn't find any recent ones in the last five years or so.

172
00:17:13,570 --> 00:17:20,590
I have a feeling that the response to this is, is education of their sales staff saying, Hey, guys,

173
00:17:20,590 --> 00:17:27,970
when you talk to that doctor, you are only allowed to talk about studies A, B and C, you can't talk about anything else.

174
00:17:29,170 --> 00:17:33,399
You know, you can imagine if you're a drug salesperson, you're taking this doctor out to lunch or saying,

175
00:17:33,400 --> 00:17:39,729
hey, you know, I know you're interested in using Paxil for your your your patients.

176
00:17:39,730 --> 00:17:45,510
It's really great. And then the doctor says, hey, what about the 16 year old? Should I use Paxil for the 16 year old?

177
00:17:45,510 --> 00:17:51,860
Well. I can't say anything about that because, you know, the drug is only approved for this now.

178
00:17:52,530 --> 00:17:55,950
That's the that's the kind of innocent way of thinking about it.

179
00:17:55,960 --> 00:18:02,670
But you can also imagine this drug salesperson saying he was thinking, hey, I get, you know, X amount of commission on these sort of things.

180
00:18:02,770 --> 00:18:09,630
Well, don't you have a lot of children who boy. When perhaps it'll be nice to give to those children, too.

181
00:18:09,990 --> 00:18:19,500
You know, I'm not sure how devious a lot of these issues are, but but I would think, you know, I think I think this is, you know, $2 billion.

182
00:18:19,500 --> 00:18:24,899
That's a big deal to these companies. I mean, I know, you know, they can have some blockbuster drugs that exceed revenue and this.

183
00:18:24,900 --> 00:18:31,020
But, you know, these actually are big numbers to these drug companies, even though they're they are not a ton of revenue.

184
00:18:31,830 --> 00:18:34,700
And so I think they would they would take this very seriously.

185
00:18:34,710 --> 00:18:41,130
I mean, they certainly invest I'm sure they invest billions of dollars in training for their sales staff to make sure they know legally.

186
00:18:41,760 --> 00:18:47,490
You can talk about this. You can't talk about that. I think that's kind of what this influences.

187
00:18:48,210 --> 00:18:54,930
Yes. And to give credence, I actually just Google this over Eli Lilly in 2009 when this suit was filed, they had a profit margin of like 22 billion.

188
00:18:55,630 --> 00:19:00,460
So, yes, in the last five years of mostly trophy.

189
00:19:00,570 --> 00:19:04,790
So it's like covered. So they've got like other issues to deal.

190
00:19:05,860 --> 00:19:10,250
Yeah. But I mean, yeah. So this is, you know, they still were profitable that year.

191
00:19:10,260 --> 00:19:17,790
It didn't bankrupt them, but it was, you know, it's a substantial number that that the CEO would care about, I would think.

192
00:19:18,000 --> 00:19:23,340
You know, and so this when you're worried about it, you know, $2 billion fine or something like that,

193
00:19:23,850 --> 00:19:30,480
you're not hesitant to send all those freshly minted pharmaceutical salespeople into,

194
00:19:30,870 --> 00:19:34,589
you know, weeklong training about all the legal rules of what you can talk about this.

195
00:19:34,590 --> 00:19:43,170
You can't talk about that. I'm just curious about how they come up with this number, this fight.

196
00:19:44,310 --> 00:19:49,100
That's that's a good question. I'm not. It's probably, you know, two parts to it.

197
00:19:49,110 --> 00:19:54,780
They probably looked at, you know, so how much did they sell promoting, you know, off label use of these medications.

198
00:19:55,050 --> 00:20:02,010
And then they probably had that. So there's a probably a they probably made them pay at least that and then some sort

199
00:20:02,010 --> 00:20:06,060
of penalty on top of that to disincentivize doing that kind of thing in the future.

200
00:20:06,190 --> 00:20:13,890
I mean, because it wouldn't be much of a disincentive if they just said, oh, you sold $1,000,000 of this drug, okay, you pay $1,000,000 fine.

201
00:20:14,050 --> 00:20:18,510
No, they're going to say, okay, you saw the million dollars with this drug and then we're gonna make you pay a $10

202
00:20:18,510 --> 00:20:22,320
Million penalty on top to discourage you for doing that kind of thing in the future.

203
00:20:25,560 --> 00:20:30,190
Yeah. Anyway, so that is a big deal for the FDA and for these pharmaceutical companies.

204
00:20:30,210 --> 00:20:36,060
I mean, it doesn't bankrupt them, but it is something they do care about. So I guess I would say so.

205
00:20:36,390 --> 00:20:45,420
Let's move on to the case study here of Hammer Crane. So for you guys, I mean, what our let's kind of set the stage of this all hypothetical.

206
00:20:45,420 --> 00:20:49,620
Of course, this is not a real treatment for for migraines.

207
00:20:49,620 --> 00:20:56,850
But in this hypothetical scenario, what are the the treatments for migraine in this example?

208
00:20:59,670 --> 00:21:11,909
What are the therapies that are discussed in this article? Yes, the new drug, which is a crane compared to the like existing,

209
00:21:11,910 --> 00:21:20,730
which is a weekly prophylactic treatment and then the existing prophylactic treatment, which is a daily pill called snuffle or something.

210
00:21:21,000 --> 00:21:26,100
Right. So the idea is these several on Remicade are preventive drugs.

211
00:21:26,100 --> 00:21:31,530
You take several once a day, you take a screen once a week, and it's designed to prevent a migraine.

212
00:21:31,620 --> 00:21:39,360
So they're not if you get a mild migraine, you might take Imitrex or something to try to manage the pain and issues with the migraine.

213
00:21:39,600 --> 00:21:43,089
But hammer and sickle all are designed to prevent the migraine in the first place.

214
00:21:43,090 --> 00:21:49,920
So they're prophylactic. Okay. And then so what was what went on?

215
00:21:50,100 --> 00:21:54,120
So heparin is the newer medication, and it just went through FDA approval.

216
00:21:54,870 --> 00:22:00,509
So what did that FDA approval process look like? Or, you know, how did they navigate that process?

217
00:22:00,510 --> 00:22:29,890
What kind of trials or evidence do they generate for that? Answer your question.

218
00:22:30,860 --> 00:22:36,440
Ask the question again. So so heparin got FDA approval.

219
00:22:36,860 --> 00:22:41,090
But how did they do that? What kind of evidence they have to generate to get FDA approval?

220
00:22:42,480 --> 00:22:49,670
And we learned earlier this year the FDA wants substantial evidence, so presumably to produce some substantial evidence to get FDA approval.

221
00:22:49,970 --> 00:22:56,090
Are you suggesting. Yes, but they conducted a clinical trials, double blind randomized step first,

222
00:22:56,510 --> 00:23:02,839
and then they took data after that to conduct cost effectiveness research.

223
00:23:02,840 --> 00:23:09,200
They took data from I think one of them was for pharmacy benefit,

224
00:23:12,800 --> 00:23:19,880
but then they took data from like two different data sets to kind of do like observational studies after the fact, after that clinical trial.

225
00:23:20,040 --> 00:23:27,710
So yeah, so there are several things going on here. And before they did the observational data, they did a clinical trial to get FDA approval.

226
00:23:28,160 --> 00:23:32,390
And so in that so they conduct a randomized controlled trial.

227
00:23:32,810 --> 00:23:40,430
So they randomize people and and you remember what they what they how they structured that trial besides randomizing people.

228
00:23:40,430 --> 00:23:44,840
So they randomized people in. And what did people get when they randomized.

229
00:23:46,820 --> 00:23:50,959
There are three categories. One is the new drug almost looks like the existing one.

230
00:23:50,960 --> 00:23:54,830
And then two. Yeah. So they had three arms.

231
00:23:55,220 --> 00:23:59,360
One where they got hammered and one there were they got several all in one where they got a placebo.

232
00:23:59,810 --> 00:24:10,440
And what did those results of the randomized trial show that follow was preferred and have like lower migraines.

233
00:24:13,540 --> 00:24:20,660
In the original randomized trial. So they could have had three arms they had.

234
00:24:22,830 --> 00:24:31,140
Emma Crane. They had several, and then they had a placebo.

235
00:24:36,760 --> 00:24:41,379
Oh, patients who took chemistry and had a clinical, clinically significant reduction in the frequency,

236
00:24:41,380 --> 00:24:45,620
severity and duration of headaches compared to placebo, but not to suffer alone.

237
00:24:46,120 --> 00:24:56,420
Right. So basically from this trial, they said, you know him, a crane is better that colors here than the placebo.

238
00:24:56,890 --> 00:25:00,190
And then but they couldn't say anything about Cam occurring versus Cephalon.

239
00:25:04,050 --> 00:25:15,690
So so really from the study here, however, plain and simple, presumably they were pretty similar in their in their results.

240
00:25:15,690 --> 00:25:19,499
They said there was not, you know, statistically significant difference, I think,

241
00:25:19,500 --> 00:25:26,340
between between have a range in terms of duration and severity, frequency of of these these headaches.

242
00:25:26,610 --> 00:25:30,000
And they also in in the study have a study like this.

243
00:25:30,240 --> 00:25:35,850
You know, it's quite expensive. There are, you know, get people and they and actually they exclude people.

244
00:25:36,060 --> 00:25:39,330
So they say, okay, if you have renal, you know, certain things like renal disease and stuff,

245
00:25:39,330 --> 00:25:47,250
you're not allowed to enroll in our trial people you people who are probably usually otherwise healthy but only have migraines.

246
00:25:47,640 --> 00:25:53,459
And so they randomize them to have a great Teflon placebo. They actually gave them diaries every day.

247
00:25:53,460 --> 00:25:58,290
You know, you got to write in your diary how you're feeling. If you had a migraine, how long duration, all this kind of stuff.

248
00:25:59,910 --> 00:26:04,620
We probably have armies of nurses and clinical study coordinators who are counting these,

249
00:26:04,680 --> 00:26:09,180
contacting these people every day, and you fill out your diary and you take your pills.

250
00:26:09,990 --> 00:26:17,280
So it's a very intense experience. And there are a few things. One is it's it's a very restricted population.

251
00:26:17,290 --> 00:26:20,879
Again, people who who don't have any of basically kind of any other diseases except

252
00:26:20,880 --> 00:26:26,400
for the migraine because they want to really focus this study on efficacy.

253
00:26:26,670 --> 00:26:29,370
Is this efficacious at reducing migraines?

254
00:26:29,370 --> 00:26:40,979
They don't want anything else like someone's kidney disease or whatever to or heart disease to interfere with studying that efficacy of hammer,

255
00:26:40,980 --> 00:26:43,350
crane versus placebo and several.

256
00:26:44,640 --> 00:26:52,770
So typically in this type of a study, they'll they want to show how working is better than the placebo which hopefully isn't too hard to show.

257
00:26:53,190 --> 00:27:02,099
And and typically they want to show that hammer pain is inferior to the existing product on the market now.

258
00:27:02,100 --> 00:27:04,470
Well, what do I mean? What does that mean? Go ahead.

259
00:27:05,340 --> 00:27:13,530
So if someone does develop some kind of condition during the trial that would impact the frequency of migraines or the intensity,

260
00:27:14,430 --> 00:27:18,870
could they withdraw that person from the trial in the results or where they have to mention it?

261
00:27:18,990 --> 00:27:24,630
So typically those people should be imputed so that these trials, you call it intention to treat.

262
00:27:24,750 --> 00:27:32,760
So once we randomize you, you are in the hammer group and if you develop Crazy Syndrome X or whatever, that's still part of it.

263
00:27:32,760 --> 00:27:39,000
And in fact, they want to look for that. You know, maybe heroin does cause crazies in remarks and so they want to look for that.

264
00:27:41,210 --> 00:27:47,210
And so, you know, that is once you're randomized, you are in that group and that is considered.

265
00:27:47,210 --> 00:27:53,360
And the gold standard is to evaluate you based on whether you're randomized to your hammer in several of your randomized.

266
00:27:53,720 --> 00:27:59,600
Now, there are some other types of analyzes that you can do something called a per protocol analysis.

267
00:27:59,990 --> 00:28:07,550
So and maybe you'd say our protocol is you take a crane every, every week and you take several every every day.

268
00:28:07,970 --> 00:28:11,120
And then sometimes in a per protocol analysis,

269
00:28:11,300 --> 00:28:20,000
the people who forget to take their several pills every day or someone who forgets to take their pill some week,

270
00:28:20,270 --> 00:28:23,660
those people are excluded in what's called the per protocol analysis.

271
00:28:24,080 --> 00:28:33,409
Now that that is something sometimes people will do, but that's strongly discouraged because because then it is.

272
00:28:33,410 --> 00:28:38,830
You can imagine the people who take their who are better at taking their pills, maybe they're different in in systematic ways.

273
00:28:38,830 --> 00:28:42,740
And the people don't take their pills. And actually.

274
00:28:43,160 --> 00:28:52,610
And is that, as the maker of Hippocrates argues, maybe having to take a pill each day is kind of part of the of the therapy.

275
00:28:52,610 --> 00:28:59,929
And if it's difficult to take the pill every day, you know, maybe that does affect real world effectiveness for those patients.

276
00:28:59,930 --> 00:29:03,570
If you can't remember to take the pill every day, then maybe that's just me.

277
00:29:03,620 --> 00:29:08,000
That's not a good medication. Imagine you had to take a pill every 5 minutes, something like that.

278
00:29:08,210 --> 00:29:11,780
You now be really burdensome and maybe you forget to take them and that it's not efficacious.

279
00:29:11,780 --> 00:29:17,630
And so that would be that's I would argue that should be part of the real world effectiveness of that intervention.

280
00:29:20,270 --> 00:29:23,360
Anyway, so I want to highlight the details of this trial here,

281
00:29:23,390 --> 00:29:28,219
also to highlight why people are interested in this compared real world comparative effectiveness research.

282
00:29:28,220 --> 00:29:36,620
Yes. So one of the things that I was mentioned in both the general article and the sub one I was assigned,

283
00:29:36,830 --> 00:29:46,070
my last name was about how women experience migraines at like three X like the rates that men do and that I was just curious like.

284
00:29:47,250 --> 00:29:53,970
I mean now. I mean, I am curious why that is, but I'm more curious like why is that not in the trial?

285
00:29:55,140 --> 00:30:01,080
I mean, like. Like they. Because that's like a differential like rates or prevalence that like.

286
00:30:01,080 --> 00:30:05,620
Why wouldn't you have. Like a trial for women and a trial for men or something like that.

287
00:30:07,240 --> 00:30:11,980
That's a good question. I'm not sure. I mean, I. I don't know what I'm so I'm not in it.

288
00:30:13,150 --> 00:30:14,080
But there might, you know,

289
00:30:14,080 --> 00:30:22,180
there maybe maybe I'm not sure if there are some sort of biological reasons why you'd want to study men and women differently.

290
00:30:22,180 --> 00:30:30,610
And then maybe there might be you might think that there's a differential effect because of some sort of biological pathways or something like that,

291
00:30:30,920 --> 00:30:36,730
I don't know. But then there are. But then there might be other issues of equity or something like that too.

292
00:30:37,090 --> 00:30:43,600
You know, maybe if this is a a condition that affects is it has a higher burden on women, you might want to think of that.

293
00:30:43,750 --> 00:30:50,530
I'm not sure that would that, you know, breaking up the study into two populations might help that I don't know I haven't thought about that too much.

294
00:30:51,280 --> 00:30:55,170
I guess like I just I'm just so curious because like historically,

295
00:30:55,180 --> 00:31:02,079
like women are very underrepresented in clinical trials and that when it's something like this where there's like a very clear gender imbalance,

296
00:31:02,080 --> 00:31:11,979
that there wouldn't be a way to correct for that. And also that, like women of childbearing age, are mostly using some kind of birth control.

297
00:31:11,980 --> 00:31:18,160
And like that might be a huge I mean, it just seems like there's so much in here that's like not addressed, which is like to me,

298
00:31:18,160 --> 00:31:23,130
what the weakest part of the studies were like, not what's the articles that were the weakest part of the studies were.

299
00:31:23,650 --> 00:31:29,520
Yeah. And then this is the hypothetical study. So they probably didn't get into, although, you know, they didn't really think about that and that.

300
00:31:29,530 --> 00:31:31,089
But that might be something important to think about.

301
00:31:31,090 --> 00:31:40,480
I mean, maybe there are some interactions between birth control and and this drug and migraines that somehow are interesting biologically.

302
00:31:40,720 --> 00:31:46,270
And maybe you maybe you would want to do a special study in women on or off birth control or

303
00:31:46,270 --> 00:31:52,690
something like that to understand interactions between birth control and and these medications.

304
00:31:53,170 --> 00:31:59,470
You know, that might be something interesting, I would guess. I would guess, though, that even if the researchers were not.

305
00:32:00,710 --> 00:32:04,910
It did not kind of stratify the results by what? By by gender or sex.

306
00:32:05,660 --> 00:32:14,090
They if they're let's say there are let's say, you know, the rate is twice, twice that in women and men.

307
00:32:14,300 --> 00:32:21,410
And so in the in the general population, if you got 100 migraine sufferers, 67 would be women and 33 would be men.

308
00:32:21,680 --> 00:32:27,190
And so if you were getting your population out of the well,

309
00:32:27,230 --> 00:32:33,620
I think it was a couple of thousand let's say a thousand people, you'd have 667 women, 334 men.

310
00:32:34,010 --> 00:32:41,209
And then and presumably that would that should be balanced in each arm if you randomizing properly and so on.

311
00:32:41,210 --> 00:32:47,630
But yeah, the results then would give you an average okay, immigrants better than placebo for everyone.

312
00:32:47,690 --> 00:32:50,420
Not necessarily saying anything about women versus men.

313
00:32:50,660 --> 00:32:56,750
Same thing with Hamilton versus people would say, yeah, they're about the same, or we can't tell us they're different.

314
00:32:58,490 --> 00:33:01,490
But you're right, maybe there would be some some biological differences.

315
00:33:01,490 --> 00:33:05,780
Maybe they would do would say chemistry is better for women and safer or worse.

316
00:33:06,440 --> 00:33:10,940
Yeah. In there. Yeah. This this study doesn't really look at that.

317
00:33:11,570 --> 00:33:13,730
Yeah. But that's an interesting thing here, though.

318
00:33:13,880 --> 00:33:19,760
Maybe that's maybe that is a in some ways kind of a patient centered thing that people might be interested in is,

319
00:33:19,970 --> 00:33:25,580
you know, really for me as a patient, which one is the right, right drug?

320
00:33:25,790 --> 00:33:28,850
And the studies weren't designed to help answer that question.

321
00:33:29,480 --> 00:33:35,600
Yeah, but going back to this noninferiority.

322
00:33:38,510 --> 00:33:52,110
First of all, what does Noninferior mean? Thoughts on if you hear something is noninferior that this is at least as good.

323
00:33:54,360 --> 00:33:57,569
At least as good. Well, it kind of means you're kind of as good.

324
00:33:57,570 --> 00:34:01,290
So. So let's say let's say this.

325
00:34:01,470 --> 00:34:04,890
I'm going to make a graph here of.

326
00:34:10,340 --> 00:34:17,330
Micrograph of migraine frequency.

327
00:34:23,800 --> 00:34:28,850
This is hypothetical, but let's say by frequency and with the placebo.

328
00:34:28,870 --> 00:34:32,050
A lot of people had a lot of migraines. More migraines is worse.

329
00:34:32,470 --> 00:34:41,860
And we don't want to be at the forefront of that. And then Hammer, Crane and C-4 all or something like that, only like this.

330
00:34:42,160 --> 00:34:49,530
And so when we say something is statistically significant, we're basically we're saying, yeah, we think these distributions are far enough apart.

331
00:34:49,540 --> 00:34:55,180
We don't think they're this they have the same mean. Right. That's that's basically what statistically significant means.

332
00:34:55,510 --> 00:35:02,740
Now, NON-INFERIOR means we can't statistically say that this is worse than this.

333
00:35:04,930 --> 00:35:13,870
I guess the way I drew this actually hammered meaning would have a lower average than and CFL all.

334
00:35:16,360 --> 00:35:20,440
But they are so close and there's so much variation here, we probably couldn't say.

335
00:35:20,740 --> 00:35:25,270
Statistically, those have different average numbers of binary frequency.

336
00:35:28,820 --> 00:35:34,400
And in fact, if we say Noninferior, Hamer Crane could have been worse.

337
00:35:37,040 --> 00:35:41,599
But it wasn't bad enough that that you could kind of tease out that yes.

338
00:35:41,600 --> 00:35:46,010
Precisely was worse than C4. Given the kind of statistical uncertainty.

339
00:35:46,970 --> 00:35:55,640
So this noninferior is means. Yeah, it's it's similar, but we know it's not bad enough that it actually is statistically worse than C4.

340
00:35:56,000 --> 00:35:57,740
That's what noninferior kind of means.

341
00:35:58,100 --> 00:36:05,660
Now, we don't know from from what they gave us in this report was emigrating trending to be better but just wasn't statistically better,

342
00:36:05,780 --> 00:36:09,320
was in trending to be worse. But it wasn't statistically worse. We don't really know.

343
00:36:10,190 --> 00:36:18,830
I will say, though, in order finally, how would you what is one way you could try to figure out if helmet grade and C4 were

344
00:36:18,860 --> 00:36:22,880
better or worse if you designed a clinical randomized controlled trial to do that?

345
00:36:26,480 --> 00:36:35,180
What's one way? If money is no object to figure out which one really does have a lower true rate of vibrating frequency, I mean.

346
00:36:36,340 --> 00:36:42,010
You should be more patient with your patients, right? They could have just recorded ten times, 100 times more patients.

347
00:36:42,370 --> 00:36:47,110
When you recruit more and more patients, you get more statistical precision in what those averages are.

348
00:36:47,530 --> 00:36:50,950
And you can actually precisely say which one is better or worse.

349
00:36:51,520 --> 00:36:54,850
Now, I guess I would argue that if I were the manufacturer,

350
00:36:55,060 --> 00:37:02,440
if I were working for the manufacturer of Hammer Brain, I was doing a bigger study is more expensive.

351
00:37:03,130 --> 00:37:08,680
Right. And so you don't want to have a $30 billion clinical trial that enrolls everyone on the face of the planet.

352
00:37:10,090 --> 00:37:14,469
And so, you know, if you're working for the pharmaceutical company, you don't want to have a giant trial.

353
00:37:14,470 --> 00:37:20,350
That's that's really, really expensive. You want to have a trial that's just sized enough to show you're better than placebo.

354
00:37:21,760 --> 00:37:24,670
And by the way, if you're developing a new drug campaign,

355
00:37:25,540 --> 00:37:34,030
you maybe don't want to know if it's if it's precisely how it compares to C4, because you might find out it's worse than C4.

356
00:37:35,200 --> 00:37:42,550
So maybe you don't want to design a really giant trial that would be able to precisely tell you if it's better or worse than C4,

357
00:37:42,790 --> 00:37:49,269
because you might actually you might find a way to better. And that would be great for you, that you have been better statistically than people.

358
00:37:49,270 --> 00:37:53,230
That would be great for you. But you also do run the risk if you had a giant enough trial.

359
00:37:53,380 --> 00:37:58,240
Maybe you find out everything is worse than C4. And now you now you're not going to have any market share.

360
00:37:58,630 --> 00:38:02,800
So that that might be I mean, I would think that if you're working for the drug company,

361
00:38:03,190 --> 00:38:09,940
you probably power your study to show you're better than placebo and then show that it's similar to Cyflog.

362
00:38:10,150 --> 00:38:14,680
And so you think you can grab half the market share or whatever from from C4.

363
00:38:17,610 --> 00:38:22,229
And. And then presumably, as you see in this in this article, they're making other arguments.

364
00:38:22,230 --> 00:38:26,040
As for why people should choose hem grain, because it's only once a week easier to take, etc.

365
00:38:26,280 --> 00:38:33,830
So so even if it has kind of equivalent efficacy to see for a while they may would make other arguments to try to get more market share the civil.

366
00:38:36,360 --> 00:38:41,579
Oh. But, you know, in the end, though, these are but we don't in the end,

367
00:38:41,580 --> 00:38:50,870
we don't really know what is the true efficacy of campaign versus evil because they it wasn't powered on or it was the big enough trial to power.

368
00:38:50,940 --> 00:38:58,290
Tell us which one is better. And so but even efficacy is I mean, that's interesting.

369
00:38:58,530 --> 00:39:04,859
But we want also want to know real world effectiveness. And that's kind of where they got these where the observational studies come in.

370
00:39:04,860 --> 00:39:08,790
So we are in charge of the randomized trial. So the observational studies, though.

371
00:39:11,220 --> 00:39:14,340
Well, the first is, what were those?

372
00:39:14,750 --> 00:39:18,420
And you started telling us what the operational sites wanted to tell us a little more about those observational studies.

373
00:39:19,620 --> 00:39:24,360
One of them, they gathered data from an insurance company.

374
00:39:25,410 --> 00:39:28,889
Of patients that suffer from migraines.

375
00:39:28,890 --> 00:39:32,790
And then another one was from a pharmacy benefit management company.

376
00:39:33,860 --> 00:39:42,720
Yeah. So anyone with insurance? And that pharmacy benefits.

377
00:39:48,310 --> 00:39:52,980
Well. So presumably these studies took place maybe a couple of years after the drug was

378
00:39:52,980 --> 00:39:56,610
approved because people were actually using these in kind of clinical practice.

379
00:39:57,390 --> 00:40:05,820
And so when someone went to explain what went on, how they did the kind of insurance study.

380
00:40:11,030 --> 00:40:19,210
Yeah. So they, um, for the insurance study, they were looking at things like hospitalization.

381
00:40:19,370 --> 00:40:23,300
Like getting prescribed. Like other kinds of pain medication, like codeine.

382
00:40:24,860 --> 00:40:29,179
And like basically because, like health care usage related to migraines.

383
00:40:29,180 --> 00:40:36,590
And see if like one had another, like one had less sort of financial draw on the system.

384
00:40:37,790 --> 00:40:40,939
And then I can't remember if this was for the insurance or the pharmacy benefits one,

385
00:40:40,940 --> 00:40:46,310
but they also managed to get some employer data as well about like missed days of work.

386
00:40:49,670 --> 00:40:55,800
And then, yeah, they had employer. Days off, I guess, right?

387
00:40:59,030 --> 00:41:07,549
So they were able to look at different outcomes in the two different studies. So I guess why why would you even do these observational studies?

388
00:41:07,550 --> 00:41:10,790
And what are some of the strengths and limitations of these observational studies?

389
00:41:12,140 --> 00:41:16,970
I mean, they already had the randomized controlled trial. They got FDA approval. Why even do these observational studies?

390
00:41:25,070 --> 00:41:28,870
Close to the. Yeah.

391
00:41:28,900 --> 00:41:30,430
So these are closer in real world practice.

392
00:41:30,430 --> 00:41:40,059
So in the clinical trial, again, they have people with no kidney disease and no other problems and they've got nurses and clinical coordinators,

393
00:41:40,060 --> 00:41:44,180
you know, calling people up and say, hey, did you did you take your drugs today?

394
00:41:44,210 --> 00:41:47,530
You take your drugs today. What's mail you your drugs? Make sure you have them.

395
00:41:47,530 --> 00:41:50,409
And, you know, and people coming in for frequent visits.

396
00:41:50,410 --> 00:41:55,360
And actually the people who enroll in a clinical trial typically are are motivated and so forth.

397
00:41:55,360 --> 00:42:00,340
And so what you see in a clinical trial might not be what you actually see in the real world.

398
00:42:00,730 --> 00:42:12,730
And and actually the manufacturer also felt that their once a week mode administration or frequency would be better,

399
00:42:13,210 --> 00:42:17,680
that people it would be easier to take a pill once a week than actually have to take a pill once a day.

400
00:42:17,710 --> 00:42:22,960
Although I think you could argue the other way too, that if I've got something where it's like every day at eight in the morning, I take my pills.

401
00:42:23,290 --> 00:42:28,830
That might be easier than remembering every Saturday in the morning I have to take my pill, but they can figure out.

402
00:42:28,840 --> 00:42:32,860
Yes, I was going to say like different types of data collection because I think the PBM one looked at

403
00:42:32,860 --> 00:42:36,280
medication adherence more and I think that they're better equipped to do that and insurance would.

404
00:42:36,670 --> 00:42:40,389
So I think maybe that's another reason why. Yeah. And then then these two are very different.

405
00:42:40,390 --> 00:42:46,390
So the insurance company they have, it's, you know, it's designed to pay for health.

406
00:42:46,390 --> 00:42:51,640
And so it has a lot of payment information about specific types of health care activities.

407
00:42:51,940 --> 00:42:57,729
And insurance company typically have information about office visits, furniture visits, hospitalizations, things like that.

408
00:42:57,730 --> 00:43:07,090
So they have very good data about that. And so you can track things like health emergency visits with the insurance claims data,

409
00:43:07,240 --> 00:43:13,900
but the pharmacy benefits manager has better information about precisely which pharmaceuticals were people taking.

410
00:43:14,200 --> 00:43:17,649
And so you can and and they can track, you know, a couple of different things.

411
00:43:17,650 --> 00:43:21,970
One, are you take are you getting your your pain or your C4 pills.

412
00:43:22,270 --> 00:43:31,059
But then and so that can track and and the idea again was that people would be better at taking their hammer pain pills than taking the C4 pills.

413
00:43:31,060 --> 00:43:38,080
Right. But and presumably in that, they showed that they were better at taking the heavier pain pills.

414
00:43:38,210 --> 00:43:43,390
There's something called the medication possession ratio, which is basically how many pills do we give you each month?

415
00:43:43,810 --> 00:43:49,150
And typically people in the pharmacy world want to see you take getting at

416
00:43:49,150 --> 00:43:53,020
least 80% of the pills that you're supposed to be taking per per unit of time,

417
00:43:53,020 --> 00:43:59,549
in this case, a month. So so they had that, but also they could look at other medications.

418
00:43:59,550 --> 00:44:03,880
So are you taking these medications for migraine relief?

419
00:44:04,210 --> 00:44:07,870
So if you do have migraine, oftentimes people might take Imitrex, for example,

420
00:44:07,870 --> 00:44:12,520
to treat the symptoms of the migraine so they can track, you know, how often were people taking medication?

421
00:44:12,910 --> 00:44:17,830
And they weren't asking people to do use diaries because you guys are probably all members of insurance.

422
00:44:18,430 --> 00:44:21,670
Did you fill in your diaries for the insurance company last night? No.

423
00:44:21,850 --> 00:44:24,280
So you don't do that as part of just the real world.

424
00:44:24,490 --> 00:44:27,910
You don't fill out your symptom diaries in the real world only if you're part of a clinical trial.

425
00:44:27,910 --> 00:44:33,910
So they didn't have that symptom diary information. So they tried to use what they found were good proxies for migraines,

426
00:44:34,210 --> 00:44:41,260
like hospital visits and taking Imitrex, things like that, and then also employer days off too.

427
00:44:41,290 --> 00:44:48,040
So they started this pharmacy benefit manager also had some some data on on days off.

428
00:44:48,850 --> 00:44:51,390
So so this is it's, you know,

429
00:44:51,730 --> 00:44:58,900
the pro of this the good part of this is it is getting something maybe a little closer to real world experience with these medications.

430
00:45:00,610 --> 00:45:06,550
So what are some of the downsides of some of these observational studies?

431
00:45:07,690 --> 00:45:19,610
Are there any. These are perfect. You're for something like this where you're comparing like a well-established drug compared to a new drug.

432
00:45:19,910 --> 00:45:25,100
Like the people who take the new drug are probably people who haven't had success with the existing drug.

433
00:45:25,110 --> 00:45:30,020
So they're just fundamentally different that than the people who.

434
00:45:31,160 --> 00:45:36,080
Take the existing drug and then when you like one of the things I mentioned in my article was

435
00:45:36,080 --> 00:45:41,450
that they didn't do the sort of randomization based on new patients presenting with migraines.

436
00:45:41,480 --> 00:45:46,280
It was like these people have had migraines and some of them switched to this new drug.

437
00:45:46,280 --> 00:45:50,650
Some of them are taking the current drug. It wasn't like the first time they showed up at the doctor's office.

438
00:45:50,660 --> 00:45:53,960
That was like a 5050 chance that they could be assigned to either of these.

439
00:45:55,910 --> 00:46:02,059
Yeah. And so, you know, selection is a huge concern with observational studies.

440
00:46:02,060 --> 00:46:07,410
And so you want it, you know, if you're observing in the real world, oh, these are people who to see,

441
00:46:07,490 --> 00:46:13,650
all these are people to emigrate in my insurance database that those people might be systematically different from each other.

442
00:46:13,670 --> 00:46:19,130
And again, like you said, if you've been taking C4 for five or ten years and it's seems to work for you,

443
00:46:19,850 --> 00:46:24,350
you might just stick with that and say, Hey, see if it was working great for me, I'm going to stay with C4.

444
00:46:24,360 --> 00:46:31,370
But if you've been taking C4 for five years and it hasn't been working very well for you, you might be more likely to switch to emigrate.

445
00:46:31,730 --> 00:46:40,820
Right. And so those people might be qualitatively different than the people who've been doing well on C4 the entire time.

446
00:46:42,560 --> 00:46:50,840
In the article, they kind of argue that that potentially those people who switched to emigrating might have somehow worse migraines because,

447
00:46:51,040 --> 00:46:56,520
you know, the medications weren't working for them. And so this suggests that immigrants even better.

448
00:46:56,540 --> 00:47:03,890
Now, I'm not really, you know, not a neurologist or whatever, so I don't I don't know precisely how that might all work.

449
00:47:04,490 --> 00:47:07,970
But but the key thing is that those populations might be different from each other.

450
00:47:09,140 --> 00:47:12,200
Yeah. Also, immigration is more expensive.

451
00:47:12,560 --> 00:47:19,400
And so maybe you have to have a better insurance plan to to get hammered or you might be wealthier to pay the copays for memory,

452
00:47:19,700 --> 00:47:27,110
things like that, so that in the real world those things are messy, you know, and might lead to different selection of people who are.

453
00:47:27,380 --> 00:47:32,870
We're taking immigration receivable. Yes. Or even for like PBMs determining like which drug would be in which formulary tier.

454
00:47:32,870 --> 00:47:38,030
So like different like copays and co-insurance, like what patient populations can actually afford those drugs.

455
00:47:39,050 --> 00:47:44,570
Yeah. And so yes, the pharmaceutical benefits manager has them and different tiers for copays.

456
00:47:44,570 --> 00:47:48,770
And so if I'm wealthier, maybe I don't mind the extra $10 a month co-pay or whatever it is.

457
00:47:50,340 --> 00:47:59,110
Yeah. Yeah. So there are a lot of things here that, that, that make this more complex and actually could lead to a different selection.

458
00:47:59,270 --> 00:48:07,309
Now, one way around, some of these issues, like you said, is, is what if people are just newly starting treatment for for migraines?

459
00:48:07,310 --> 00:48:11,330
So maybe they don't have that ten year history of see for work and great for them or not working for them.

460
00:48:11,570 --> 00:48:16,700
These are new patients you're presenting with newly as initiating migraines, saying,

461
00:48:16,700 --> 00:48:20,509
please give me something that will help prevent migraines and then just assume that

462
00:48:20,510 --> 00:48:24,080
it's kind of a flip of the coin about whether they can save a little or hammer brain.

463
00:48:26,090 --> 00:48:30,260
But that might be one way to to reduce some of those selection effects.

464
00:48:30,800 --> 00:48:35,030
Yeah. And so so there's an interesting things here in the study design that help

465
00:48:35,030 --> 00:48:39,610
that potentially can help avoid some of these issues of selection that will,

466
00:48:39,830 --> 00:48:43,460
in the end, lead to bias in your estimates of effectiveness.

467
00:48:45,660 --> 00:48:50,069
Other thoughts about the, um, these observational studies?

468
00:48:50,070 --> 00:48:58,469
Yeah. Um, it's said that like the clinical trial at least had patient diaries kind of like include patients and they experienced what would be

469
00:48:58,470 --> 00:49:06,600
observational studies like patient experiences and like the real world and like other factors to take into consideration were really a thing.

470
00:49:06,600 --> 00:49:10,739
Like they were patient experience. They lacked patient experience. Yeah.

471
00:49:10,740 --> 00:49:17,150
So this isn't of the patient. I mean, it's trying to get at it through very indirect ways.

472
00:49:17,170 --> 00:49:24,120
So it's saying, well, we guess that your migraines are better because these people didn't take as many days off of work or

473
00:49:24,120 --> 00:49:28,380
they didn't take as many of these medications or didn't have a decent number of emergency room visits.

474
00:49:28,800 --> 00:49:32,580
But that doesn't really get at the core things that patients care about.

475
00:49:32,580 --> 00:49:39,540
I mean, maybe someone had a migraine, but they didn't go to the emergency department, maybe someone had a migraine, but they didn't take Imitrex.

476
00:49:40,350 --> 00:49:44,950
Maybe people had a milder migraine and so so they didn't do these things.

477
00:49:46,740 --> 00:49:53,280
Yeah. So there are a lot of things here that if it's not in the patient diaries, we don't really know about frequency and severity.

478
00:49:53,280 --> 00:49:55,860
We're making some inferences about it. We don't truly know that.

479
00:49:56,130 --> 00:50:02,190
And also, there are other things that patients may care about besides emergency room visits, taking Imitrex and being off work.

480
00:50:05,970 --> 00:50:07,050
And patients weren't really.

481
00:50:07,200 --> 00:50:13,620
And one of the, you know, patient advocacy or, you know, argument, too, is patients were involved in designing the research.

482
00:50:13,630 --> 00:50:18,240
So we don't really know, is this really tracking the outcomes that patients care about?

483
00:50:25,920 --> 00:50:28,230
Other thoughts on these observational studies.

484
00:50:34,060 --> 00:50:38,770
So I think, you know, talking to a lot of really good, important things about these these observational studies, I mean,

485
00:50:38,770 --> 00:50:47,499
they are trying to do something good here where they're trying to evaluate real world experience with these medications.

486
00:50:47,500 --> 00:50:51,790
But they do have some limitations in terms of what they can really say about the real world effectiveness.

487
00:50:52,130 --> 00:50:57,250
And in the end, what we want to know from real effectiveness is, hey, if, you know,

488
00:50:57,280 --> 00:51:03,340
should we give patients C4 or hematocrit, you know, which one really is better for patients in the real world?

489
00:51:06,280 --> 00:51:11,379
And and I actually one of the thing to I will say that I liked in this in this article,

490
00:51:11,380 --> 00:51:23,260
the way they they put this together here in the very end here, they say, I actually need to say a few other things about the.

491
00:51:26,830 --> 00:51:37,120
The analysis here that they say. So they say to protect against data fishing in fishing expeditions.

492
00:51:43,710 --> 00:51:48,090
My yield distorted view of the data. A research protocol was developed before the data were examined.

493
00:51:49,920 --> 00:51:53,010
So what does that mean? This.

494
00:51:54,360 --> 00:51:59,230
This sentence here. Yeah.

495
00:51:59,590 --> 00:52:08,530
So it's preventing them from doing kind of like post hoc analysis to try and like hack their way to some kind of statistically significant finding,

496
00:52:08,530 --> 00:52:12,129
like when they didn't find anything from their first question. Yeah.

497
00:52:12,130 --> 00:52:21,350
So you guys know what P hacking is? So hacking is up.

498
00:52:22,010 --> 00:52:26,360
So who and tell us what a p value is.

499
00:52:27,260 --> 00:52:30,860
This is kind of the scientific world, medical world.

500
00:52:30,860 --> 00:52:37,429
Certainly we treat this as gospel like it came down from Mt. from Moses on these big stone tablets plus a final five

501
00:52:37,430 --> 00:52:45,419
is some sort of magical number but but really you know plus 2.5 or something someone chose 100 years ago or so,

502
00:52:45,420 --> 00:52:48,830
I was like, Oh, that's probably a good rule of thumb. And it's kind of stuck ever since then.

503
00:52:49,580 --> 00:52:53,330
But what is P plus in point of five or the P value kind of mean?

504
00:52:53,690 --> 00:52:58,850
It's also statistically significant. Your findings are. Yeah, so we call that statistically significant.

505
00:52:59,150 --> 00:53:04,910
And it basically means that if there is if there were no effect,

506
00:53:05,870 --> 00:53:12,080
we would only expect something this extreme or this value or more extreme in 5% of cases.

507
00:53:13,530 --> 00:53:15,809
That's kind of what p hacking or the P value means.

508
00:53:15,810 --> 00:53:22,860
And so if there if there really is no effect, there's only maybe a 5% chance we would we would call this statistically significant.

509
00:53:23,490 --> 00:53:25,980
There's a 5% chance of that making that error.

510
00:53:27,360 --> 00:53:35,430
Now, let's say I have something with no effect whatsoever, but I have 20 different types of measurements.

511
00:53:35,440 --> 00:53:44,070
I can I can look at look at length and height and width and lab value a, b, c, d, e, f g h i, j k on a, b, and so forth.

512
00:53:44,220 --> 00:53:54,360
So I've got 20 different things I can measure. And this I'm going to give someone a placebo that does nothing if I'm looking at 20 different things,

513
00:53:55,380 --> 00:54:02,520
while on average one of them might show a p value of less than .05 because just due to chance,

514
00:54:02,520 --> 00:54:08,250
there's a one in 20 chance that something will show so that p value s and .05.

515
00:54:09,270 --> 00:54:18,989
So p hacking is if I is kind of looking at a bunch of different things and then maybe 99 of them show no effect,

516
00:54:18,990 --> 00:54:25,500
no significant said nothing statistically 77, but five of them do show something statistically significant.

517
00:54:25,740 --> 00:54:29,250
And so when I write my research paper, I really focus on one, two,

518
00:54:29,280 --> 00:54:34,410
these five things that were statistically salient and ignore the other 95 that weren't statistically significant.

519
00:54:35,100 --> 00:54:40,950
So that's p hacking. But to avoid that, like they say, you're they said, okay, we're going to look for this thing,

520
00:54:40,950 --> 00:54:44,100
this thing and that, you know, base prespecified, what are we going to look for?

521
00:54:44,280 --> 00:54:50,729
So they couldn't so they couldn't fish for 100 different things and then choose the ones that actually were statistically.

522
00:54:50,730 --> 00:54:57,660
So they have to before they they do the statistical analysis say, I'm looking for this and and this is the thing.

523
00:54:57,660 --> 00:55:02,430
I'm looking to be statistically salient. So that's one of the things I did, which is good.

524
00:55:03,000 --> 00:55:07,470
That's a that's a good protocol here are good process process in the analysis.

525
00:55:09,750 --> 00:55:17,530
And then they say statistical adjustments were also made to balance the three groups to be studied of heavier grains.

526
00:55:17,580 --> 00:55:27,420
If all I know is with nothing here, say a so-called propensity score method which estimates the probability of persons being in one of three groups,

527
00:55:27,660 --> 00:55:29,250
was used to balance on age,

528
00:55:29,250 --> 00:55:36,660
sex and number of previous migraine emergency room visits and the extent of prior medication use and selected comorbidities.

529
00:55:37,080 --> 00:55:40,870
Does anyone know what this sentence is saying? This is kind of ResearchGate gobbledygook.

530
00:55:41,380 --> 00:55:47,640
Anyone know they can even translate health services researcher into English flu estimates?

531
00:55:48,030 --> 00:55:53,459
Yes, I should try, because I guess there's a paper at work where we had to do propensity score matching,

532
00:55:53,460 --> 00:55:57,180
and I admittedly cannot use the code, but I should know.

533
00:55:58,260 --> 00:56:04,889
But yeah, so I mean, it's kind of what it's saying, right? You're kind of seeing, you know, the probability of people being in three groups.

534
00:56:04,890 --> 00:56:10,410
And I don't know if this is exactly saying they match them because I just know that's how we did it in the

535
00:56:10,410 --> 00:56:15,209
work I'm familiar with where you kind of have a person outside the group in a prison inside the group,

536
00:56:15,210 --> 00:56:18,390
and then you match them to kind of make the equivalent across a lot of dimensions.

537
00:56:18,390 --> 00:56:21,930
I'm was a little unclear when I read this if that's exactly what they're doing here.

538
00:56:22,410 --> 00:56:27,030
Yeah. And I think, you know, this is all hypothetical. So I don't think they really went to all the details.

539
00:56:27,030 --> 00:56:30,479
But they they said why they they did this to try to account for that.

540
00:56:30,480 --> 00:56:38,520
And so, you know, one of the potential concerns might be that that people in the immigration,

541
00:56:38,520 --> 00:56:46,979
C4 and the placebo or that or the no placebo and the no drug group might be different in terms of important characteristics.

542
00:56:46,980 --> 00:56:51,480
So we mentioned this earlier maybe that the people who take sci fi are different from the people who take hammering.

543
00:56:51,810 --> 00:56:59,070
And with these this method called propensity score matching, you can use observed variables like age, sex,

544
00:56:59,370 --> 00:57:04,889
number of previous might these things that they have in their database and they can try to adjust for that.

545
00:57:04,890 --> 00:57:15,150
And so let's say civil, all people are older than hematocrit people and more likely to be female and male and maybe have more

546
00:57:15,150 --> 00:57:22,260
previous migraine emergency room visits and maybe have lower prior medication use or something like that,

547
00:57:22,650 --> 00:57:27,330
or more or different co-morbidities if you have people versus immigrants.

548
00:57:28,080 --> 00:57:37,800
So what they did, you know, right here, what they did was they tried to if they if they got a heartbroken person who is age 34 female,

549
00:57:38,850 --> 00:57:45,690
and they also tried to find a 34 year old female in the C4 group to kind of match them, if you will.

550
00:57:45,900 --> 00:57:49,050
So that's kind of, you know, roughly speaking, it's more sophisticated that.

551
00:57:49,290 --> 00:57:58,170
But roughly speaking, what they tried to do is, is match these people based on their these characteristics.

552
00:57:58,410 --> 00:58:08,730
And and actually it's propensity to to be in in the hammer and C4 or the no medication groups based on these other characteristics.

553
00:58:09,900 --> 00:58:18,150
So anyway, they tried to adjust for that, I would say. At the time, especially at the time this this paper was written a decade ago.

554
00:58:18,510 --> 00:58:23,610
You know, propensity score matching is one of the more sophisticated methods to do observational research,

555
00:58:23,610 --> 00:58:29,939
to try to adjust for balance that the people who are who are in those different groups and try to

556
00:58:29,940 --> 00:58:35,820
account for some of these characteristics that might be imbalanced in the Democrat and support groups.

557
00:58:36,690 --> 00:58:43,590
One thing to be careful of, though, is, of course, in this propensity score matching, you're matching on an information you have.

558
00:58:44,400 --> 00:58:47,730
So they had data on, you know, age and sex and all these other characteristics.

559
00:58:48,630 --> 00:58:52,080
There might be other unmeasured things, though, that you can't match on.

560
00:58:52,110 --> 00:58:56,969
So if someone really motivated to take a pills every day, that's something that's not in the database.

561
00:58:56,970 --> 00:59:02,700
Like Mrs. Jones really loves taking pills every day in the morning with her grapefruit and breakfast or whatever it is.

562
00:59:03,100 --> 00:59:07,530
You don't have that data in the in their insurance, the claims database or something like that.

563
00:59:08,370 --> 00:59:14,850
So there are even though you don't process for matching, of course, you can never completely make sure that groups are totally balanced.

564
00:59:16,740 --> 00:59:23,580
But I would argue that this is know kind of state of the art type of statistical analysis.

565
00:59:24,240 --> 00:59:31,440
You know, they weren't just, you know, getting an undergrad who finished stats one on one and like, oh, I think I'll do a T test or something.

566
00:59:31,990 --> 00:59:35,280
It really isn't totally appropriate. Yeah.

567
00:59:35,610 --> 00:59:43,590
You know. If there's kind of a standard because you have to kind of do like standards differences, I think, to measure the imbalance.

568
00:59:43,650 --> 00:59:50,610
You know, if there's like a standard metric number that they use, I don't know, because this is all hypothetical.

569
00:59:50,610 --> 00:59:59,040
I think they gloss over a lot of those details here and just and so, yeah, they I mean, and there are there are a few other things here, though.

570
00:59:59,040 --> 01:00:01,780
They they don't want to highlight here, too.

571
01:00:02,200 --> 01:00:11,250
And I think highlight that I think that the people who set up this case study tried to, you know, make this a a good.

572
01:00:15,460 --> 01:00:19,030
A good example here because they say, you know,

573
01:00:19,030 --> 01:00:29,830
the comparative fairness study can a seemingly well constructed study and then funded by a philanthropy.

574
01:00:29,890 --> 01:00:34,630
So this wasn't necessarily something that the drug company funded.

575
01:00:35,110 --> 01:00:39,670
Remember, it was funded by a migrant advocacy group.

576
01:00:39,940 --> 01:00:42,310
Right. That provided some of the funding for this analysis.

577
01:00:42,550 --> 01:00:49,720
By the way, because the migrant funding group funded it, they probably didn't have $100 million to run a really, really big randomized trial.

578
01:00:49,730 --> 01:00:54,580
Right. They these types of analyzes are cheaper to do if you can get access to the data.

579
01:00:54,820 --> 01:01:03,730
I mean, it's it's a few statisticians to, you know, properly, you know, massage the data and do the analysis.

580
01:01:04,060 --> 01:01:10,420
But it isn't, you know, $100 million study to do. So a large philanthropic organization could do something like this.

581
01:01:11,350 --> 01:01:16,990
You know, they say executed by strong and eligible partners, an academic institution, a payer manufacturer.

582
01:01:17,770 --> 01:01:23,409
And this is this is something, you know, presumably done by a I think they said Harvard, like an academic institution.

583
01:01:23,410 --> 01:01:29,320
So this isn't the drug manufacturer doing their own analysis, kind of in a dark, dark, smoky room.

584
01:01:31,360 --> 01:01:39,070
So these are but I highlight this is, you know, this in this hypothetical example, they tried to kind of remove those issues.

585
01:01:39,250 --> 01:01:43,299
But in the real world, those are things to be aware of when you're interpreting evidence, you know,

586
01:01:43,300 --> 01:01:49,990
is this something it was just done kind of behind closed doors by a manufacturer that might have

587
01:01:49,990 --> 01:01:54,160
less weight than something done by an independent third party or something funded by nature.

588
01:01:54,520 --> 01:01:56,379
And I don't know, although full disclosure,

589
01:01:56,380 --> 01:02:01,630
I am an academic person who would benefit from more funding being sent to academics to do these kind of research projects.

590
01:02:01,630 --> 01:02:10,180
And I have colleagues in my department who do that. So full disclosure, you know, if people did more of that, I and my colleagues would benefit.

591
01:02:13,060 --> 01:02:16,990
So but those are things to think about when you're interpreting.

592
01:02:17,830 --> 01:02:21,100
Entering any kind of evidence is, you know, where did that come from?

593
01:02:21,100 --> 01:02:27,100
Who was doing it? Do they have the incentives to try to avoid bias, etc.?

594
01:02:27,430 --> 01:02:36,340
And I would argue actually, the the philanthropic organization that was trying it was a patient advocacy organization.

595
01:02:36,710 --> 01:02:41,110
You know, presumably they really do care about patients and they really do want to know

596
01:02:41,380 --> 01:02:45,520
is have a great balance before because they want to know for our patients

597
01:02:45,520 --> 01:02:57,680
which one is is better they now they did some of this in partnership with the manufacturers so you have to consider that but that that is yeah.

598
01:02:58,270 --> 01:03:05,440
So you know, it's something to think about, but presumably not a huge issue in this in this particular case.

599
01:03:10,560 --> 01:03:18,180
And they see here they are results in precisely that protocol.

600
01:03:18,540 --> 01:03:22,470
Drawing some employee some approaches to adjust for threats and so forth.

601
01:03:23,580 --> 01:03:30,090
Okay. Well, let's go next to you for the last ten, 15 minutes to talk about how different organizations might think about this.

602
01:03:30,450 --> 01:03:38,160
So we have there are interested parties here, FDA, bakery companies, payors, patients, academic teachers, ethicists and so forth.

603
01:03:39,360 --> 01:03:45,420
So FDA, what should FDA do with all this evidence we have?

604
01:03:45,740 --> 01:03:49,050
Randomized trials. We have these observational studies.

605
01:03:50,400 --> 01:03:58,820
What does FDA think about this information? So those of you who are reading the FDA readings, what are your thoughts?

606
01:04:03,260 --> 01:04:05,420
Should we use this observational data or not?

607
01:04:07,940 --> 01:04:13,820
If I'm a pharmaceutical drug rep and I start talking to down way here physician about him or her patients,

608
01:04:14,840 --> 01:04:20,090
I can talk about the clinical trial, randomized trial. What can I say, if anything, about these other studies?

609
01:04:27,780 --> 01:04:31,440
Anyone have any thoughts? Even if you didn't do, the FDA assigned the FDA group.

610
01:04:32,050 --> 01:04:38,340
Could you put the question, please? So if you're the FDA, then what do you what should pharmaceutical companies be allowed to?

611
01:04:38,940 --> 01:04:44,009
How should pharmaceuticals how should pharmaceutical companies be allowed to use this observational data,

612
01:04:44,010 --> 01:04:48,090
if at all, when they're talking to payers or providers?

613
01:04:52,840 --> 01:04:56,980
I do not have FDA, but I think maybe I can kind of speak to that. I am the pharmaceutical,

614
01:04:57,400 --> 01:05:06,010
but the article that I that I read was about the substantial of experience and how that needs to be further regulated by FDA to make it like.

615
01:05:08,370 --> 01:05:15,900
Yeah. So there's this substantial evidence and and I guess as the pharmaceutical company though you're concerned about that, right?

616
01:05:15,910 --> 01:05:20,310
You, you want to you want more clarity about what is substantial evidence, right?

617
01:05:21,300 --> 01:05:23,670
Yeah. And. Right. If you're the pharmacy company,

618
01:05:23,880 --> 01:05:31,890
you don't want to get hit with a $3 billion fine if you're if your pharmaceutical drug reps start talking about these observational studies.

619
01:05:32,550 --> 01:05:35,910
And so you want some clarity from the FDA. Am I allowed to talk about this or not?

620
01:05:38,270 --> 01:05:47,420
Should I mean, should should the FDA regulate what the drug companies can or who the drug companies can communicate with?

621
01:05:49,280 --> 01:05:54,409
Yeah. Yeah, I would say absolutely. Yes, they should have stricter rules than they do now.

622
01:05:54,410 --> 01:05:57,650
And there isn't substantial evidence from like this.

623
01:05:57,770 --> 01:06:01,069
These studies. The observational studies. Yeah. And so then yeah.

624
01:06:01,070 --> 01:06:11,480
The question for the FDA is probably if, you know, is this substantial evidence and and and the assessment is, you know, these.

625
01:06:11,750 --> 01:06:14,660
Well, they're. Well, there are some good aspects of these.

626
01:06:14,990 --> 01:06:19,390
You say they're not really substantial evidence, especially compared to kind of gold standard brain rice trial.

627
01:06:19,670 --> 01:06:25,190
And so then then those are studies that, you know, they shouldn't be allowed to you know,

628
01:06:25,720 --> 01:06:29,750
if I'm having lunch with the doctor, I can't say, hey, did you see this observational study?

629
01:06:29,760 --> 01:06:33,020
Everything's easier to take and people have better outcomes and so forth.

630
01:06:33,440 --> 01:06:36,950
I think they shouldn't be allowed to, you know, make those arguments.

631
01:06:38,280 --> 01:06:47,130
Other thoughts, but the FDA. I mean, I guess I would argue that that is kind of the FDA stance today.

632
01:06:47,520 --> 01:06:50,310
Yeah. I mean, you have to have a randomized controlled trial.

633
01:06:50,460 --> 01:06:56,940
Now, interestingly, there is this health care economic information which they can share with payers.

634
01:06:57,480 --> 01:07:03,570
And I think this kind of data could be part of kind of health care, economic information that they can share with payers.

635
01:07:03,610 --> 01:07:04,770
They could say, hey, look, payer,

636
01:07:05,430 --> 01:07:11,399
you should put us in a better part of your formulary because actually we're going to save you money because we're reduced emergency room visits.

637
01:07:11,400 --> 01:07:17,130
We're going to keep pay, keep people in work so they're not going be absent from work and this kind of stuff.

638
01:07:18,840 --> 01:07:21,450
You know, there is a kind of lower standard of evidence for that.

639
01:07:25,110 --> 01:07:35,250
So, Corey, how does the Corey think about this, these observational studies that you want to use?

640
01:07:36,420 --> 01:07:45,960
I don't know. So curious, the patient centered Outcomes Research Institute, it was new with the ACA, right?

641
01:07:46,410 --> 01:07:54,930
It's a new it's relatively new. It was it was created with the production Affordable Care Act in 2010.

642
01:07:56,220 --> 01:08:01,050
Yeah. So yeah, I mean, is this is this patient centered research?

643
01:08:01,260 --> 01:08:03,870
If not, what are some of limitations did you have.

644
01:08:04,340 --> 01:08:11,819
So this was my article and they said it was not patient centered because there weren't patients involved in the study development.

645
01:08:11,820 --> 01:08:19,020
And it wasn't like addressing addressing an outstanding patient question about which is more effective.

646
01:08:20,490 --> 01:08:28,680
And to me, this was like, I'm taking a class in with Barbara Israel on community based participatory research.

647
01:08:28,680 --> 01:08:33,570
And like this is the first instance I've seen of like a federally mandated,

648
01:08:34,020 --> 01:08:39,149
like CPR approach to doing like health care research as opposed to just like some,

649
01:08:39,150 --> 01:08:46,950
like liberal academics being like, yeah, maybe we should talk to people instead of just looking at our like number crunching screenings, you know?

650
01:08:48,330 --> 01:08:55,979
Yeah, like NIH study section reviewers are interested in that, but it's not mandated versus McCary it is.

651
01:08:55,980 --> 01:09:02,639
You know, that is their mission is that the research they found should be patient centered and that is really community based.

652
01:09:02,640 --> 01:09:10,640
Participatory research is is maybe a gold standard for what is, you know, this patient centered community.

653
01:09:10,840 --> 01:09:20,670
I mean, it's it's very similar. Yeah. So this this study, I think I'm not going to say in this hypothetical, the name was maybe necessary as well.

654
01:09:21,180 --> 01:09:24,780
Not well intentioned, but yeah, they didn't involve patients in the process.

655
01:09:24,780 --> 01:09:30,150
They didn't ask them, you know, really what are your needs and what are the outcomes you care about?

656
01:09:30,810 --> 01:09:39,300
They weren't involved in the design process. Other thoughts on kind of patient centered ness.

657
01:09:44,180 --> 01:09:52,030
So what about we heard a little bit of the pharmaceutical companies. So, you know, they want to know what they can share with who.

658
01:09:52,970 --> 01:09:57,800
More some more more clarity about what is what's allowed and what's not allowed.

659
01:09:57,830 --> 01:10:02,270
I think that was one of their concerns. Anything else that pharmaceutical companies.

660
01:10:04,420 --> 01:10:08,210
I can add anyone else from the article. Yeah.

661
01:10:08,570 --> 01:10:12,920
I mean, yeah. But one thing I thought was really interesting about this one was they brought in like the

662
01:10:12,920 --> 01:10:16,909
constitutional imperative of trying to make this information more clear because there's been some,

663
01:10:16,910 --> 01:10:24,680
like, businessmen, like, high profile lawsuits around this. Mm hmm. But that is in the sphere of litigation overseen, like, providing evidence.

664
01:10:24,950 --> 01:10:31,029
That is like, from the pharmaceutical perspective, the fear of litigation that you're going to say something that's wrong and be sued.

665
01:10:31,030 --> 01:10:34,950
And they're saying that. Because the guidance is so unclear.

666
01:10:34,960 --> 01:10:46,750
They're just avoiding that process altogether and doing things behind closed doors, which is let's see what it's like yet.

667
01:10:46,750 --> 01:10:50,649
So it's leading to more like less visible case by case enforcement is what this article was arguing.

668
01:10:50,650 --> 01:10:55,270
And so that this is still in favor of the substantial evidence.

669
01:10:55,630 --> 01:11:06,010
But actually it was interesting perspective that because it's so poorly defined, what you can and cannot say that it's from farms,

670
01:11:06,190 --> 01:11:10,870
from other farms, people correct in others that pharmaceutical companies are just being sneakier about it so that they don't get.

671
01:11:12,340 --> 01:11:18,500
Yeah, well it's that I mean and that probably is part of, you know, I would guess that if, if,

672
01:11:19,130 --> 01:11:26,080
if, if I know I am not a pharmaceutical or drug representative or never, I had I had been one.

673
01:11:26,080 --> 01:11:27,290
I really know anyone who has one.

674
01:11:27,520 --> 01:11:33,849
But I would imagine that when you're in, you know, legal training, one or one that week long training session, that you're you know,

675
01:11:33,850 --> 01:11:38,950
when you start a job as a pharmaceutical sales rep, they probably tell you, you know,

676
01:11:38,950 --> 01:11:42,430
don't talk about this, don't talk about this, don't talk about this, only talk about this.

677
01:11:42,790 --> 01:11:46,180
And whatever you do, don't document that you ever talked about.

678
01:11:46,450 --> 01:11:52,540
You know, don't send an email that says, hey, you should read this article is observational study, you know,

679
01:11:52,540 --> 01:11:59,530
and email that to a doctor because that's a that's kind of a paper trail that will get them sued or is definitely if you're the manager don't say hey,

680
01:11:59,920 --> 01:12:05,830
hey, hey, sales team please send this to your doctors because that that then that leads to the $3 billion fine.

681
01:12:06,910 --> 01:12:14,590
But if they're out at lunch and they get to the doctor tipsy, they say, hey, you hear about that study that's off the record.

682
01:12:14,590 --> 01:12:21,400
And, you know, maybe, maybe then it's hard for the doctor to to, you know, tie that back to them and sue them.

683
01:12:21,670 --> 01:12:25,930
So it's probably just making sure there's no paper trail of this.

684
01:12:25,930 --> 01:12:31,780
Yeah, well, about so because like migraines are, as far as I know, not life threatening.

685
01:12:32,110 --> 01:12:39,939
And like I'm thinking about this like the recent like A.L.S. drug that just got approved as well as like the I can I

686
01:12:39,940 --> 01:12:48,340
can't say the the Alzheimer's drug is like because like this is like lower stakes that the pharmaceutical companies,

687
01:12:49,090 --> 01:12:57,879
they're more willing to sort of like color in the lines and this kind of like less sort of hacking approach is necessary because it's not

688
01:12:57,880 --> 01:13:05,020
life threatening or I just like I think I'm just still reeling from like these new drug approvals that don't really have any evidence.

689
01:13:05,020 --> 01:13:09,339
And it's like, I understand that there's not good alternatives and that's why they got approved, basically,

690
01:13:09,340 --> 01:13:16,450
because it's sort of like a hope and a miracle that they work as opposed to a migraine where it's like it's terrible, but people don't die from it.

691
01:13:18,600 --> 01:13:28,139
Yeah. I mean, yeah, I'm not sure how the severity I mean, how the severity might affect that.

692
01:13:28,140 --> 01:13:38,610
I mean, I think the the kind of sales potential might affect pharmaceutical companies more than than whether it's like the severity of it.

693
01:13:38,610 --> 01:13:48,570
I mean, I think, again, if you if I were a pharmaceutical salesperson and I had a a drug that works well in,

694
01:13:48,870 --> 01:13:52,290
you know, and we've got a study that shows well, it works in people in their twenties and thirties.

695
01:13:52,950 --> 01:14:01,020
But man, I know there are a ton of kids with this condition and I could double my sales if I was able to convince doctors to prescribe this off label.

696
01:14:01,290 --> 01:14:09,600
That's a that's a bigger incentive because there's a bigger kind of market share for that, whether it's for a deadly condition or or a migraine.

697
01:14:10,410 --> 01:14:14,820
I think it's it's the incentive or that the motivation or incentives are still there.

698
01:14:19,830 --> 01:14:26,690
So what about payers like insurance companies? How would they, you know, do they want this information from these arbitration studies?

699
01:14:26,700 --> 01:14:32,670
Do they want to want to set their firewalls to block these studies from their employees?

700
01:14:33,960 --> 01:14:39,090
I don't know if your insurance company how would you use this data if at all these these data from these studies it.

701
01:14:41,090 --> 01:14:56,120
If we cross Medicare and Medicaid. Get to determine like coverage rates potentially.

702
01:14:56,600 --> 01:15:01,520
Yeah. I mean, so if you're, you know, or you're your best trips or whatever the the pharmaceutical benefits, if,

703
01:15:01,820 --> 01:15:06,710
you know, how do you use this to help you set, you know, figure where in which tier this should go in.

704
01:15:09,010 --> 01:15:12,220
How, you know, how should you figure out what tier to put it in? You know what?

705
01:15:12,400 --> 01:15:16,180
You know, presumably the randomized trial said it's about the same as people. It's more expensive.

706
01:15:17,950 --> 01:15:21,700
So do you automatically put it in a worse tier, or do you look at these studies and say,

707
01:15:21,700 --> 01:15:24,640
well, it might have some other benefits, maybe I do move it up into a different tier.

708
01:15:28,760 --> 01:15:39,870
They hope to like assess these research data so that they can, like, deeply explore to their particular interest population.

709
01:15:40,700 --> 01:15:52,579
And also, they emphasize more peer review setting for publication because like they mentioned this observation,

710
01:15:52,580 --> 01:15:59,510
all of our code based editors took only like 4 hours, which is not past the peer review publication standard.

711
01:15:59,990 --> 01:16:10,310
So Hope Commission could do something like us general public using own data to publish like peer review studies.

712
01:16:11,390 --> 01:16:15,140
Yes, actually, that's another concern is is maybe these studies haven't been peer reviewed.

713
01:16:15,140 --> 01:16:17,270
And so yeah, they sound nice,

714
01:16:17,270 --> 01:16:24,830
but it would be nice to have this round of this set of peer review to to that to make sure that there aren't any egregious errors.

715
01:16:25,400 --> 01:16:31,160
I will say the peer review process is not infallible. So, you know, a lot of stuff can get through peer review that does have flaws in it.

716
01:16:31,850 --> 01:16:38,030
But you actually as a payer, too, if you're a payer, you could probably do this analysis on your own dataset as well.

717
01:16:40,460 --> 01:16:47,270
If you have people taking have opinions, if all you could try to replicate the analysis in-house and do it,

718
01:16:47,570 --> 01:16:53,480
maybe customize it to your particular patient population and adjust for different things if you felt they lacked some things out.

719
01:16:54,500 --> 01:16:58,790
If you think your database is better than a database, and again,

720
01:16:58,790 --> 01:17:06,650
maybe your population is slightly different and you could you can split up by men and women if you think that was an important characteristics to say,

721
01:17:06,680 --> 01:17:14,200
hey, does this work better for women? Are the thoughts on the pair's.

722
01:17:16,030 --> 01:17:22,749
Yeah. So to me, I'm wondering if they don't care as much about comparative effectiveness as they do

723
01:17:22,750 --> 01:17:27,630
about the cost effectiveness just because that's like they're looking at money.

724
01:17:27,640 --> 01:17:30,660
That's what they. Yeah. Yeah.

725
01:17:30,670 --> 01:17:36,850
So the payers do care about cost and so I mean I would argue that they probably would include this in their cost effectiveness analyzes.

726
01:17:36,850 --> 01:17:44,650
Right. I mean if they Yes. Have kids more expensive but if they want actually it's more expensive, just average monthly cost.

727
01:17:44,800 --> 01:17:48,520
But if people are actually if the medication possession ratio is higher,

728
01:17:48,700 --> 01:17:52,990
they're actually using more pills versus if all maybe they're using fewer pills,

729
01:17:53,380 --> 01:17:58,690
if that really, truly is what's happening, you know, afraid they're going to spend more on these migraine prevention drugs.

730
01:17:59,290 --> 01:18:04,059
But if you're if you're BlueCross, you're also paying for those emergency visits.

731
01:18:04,060 --> 01:18:11,530
You're also paying for Imitrex prescriptions. And so you do want to say, hey, do we think we can save some money?

732
01:18:11,530 --> 01:18:14,740
And actually, if you're Ford, if you're the payer, you're self-insured.

733
01:18:15,580 --> 01:18:18,400
You also care about those employee absences. Right.

734
01:18:18,550 --> 01:18:26,920
And so you might want to take that into consideration if you think those are real based on the bias, you know, is a concern.

735
01:18:27,220 --> 01:18:32,410
But if you think those actually are true effects, which, again, we don't really know for sure because they're observational studies,

736
01:18:32,770 --> 01:18:41,050
but those might be things you care about in terms of think about the overall total cost of of getting people to use campaign versus people.

737
01:18:44,590 --> 01:18:49,330
Any other thoughts from the patients, the academic details or ethicists?

738
01:18:52,940 --> 01:19:02,440
Yeah, for the patients, the article that I read basically talked about like the credibility of the research and how useful

739
01:19:02,440 --> 01:19:07,780
the research is when it comes to like making more informed decisions on like the medications.

740
01:19:08,200 --> 01:19:14,319
And the reading also talked about like usability criteria and how establishing like a certain

741
01:19:14,320 --> 01:19:18,820
usability criteria before the fact would actually help make the research more credible.

742
01:19:19,420 --> 01:19:26,140
And the criteria included things like, you know, like including patients in the research questions,

743
01:19:26,770 --> 01:19:32,620
what like social factors that they would want to include in observational research and.

744
01:19:34,180 --> 01:19:44,380
Just a translation of the research itself. So like more patients, I can understand like which medication is better when some of the signs typical.

745
01:19:44,440 --> 01:19:51,410
So that's good that for Korean the patients seem to have similar things that they're concerned about.

746
01:19:51,430 --> 01:19:56,250
Yeah. But the patients who are involved in the research question. Yeah. And then piggyback off that to the same reading.

747
01:19:56,620 --> 01:19:59,324
I mean that the ACA had set standards for like.

