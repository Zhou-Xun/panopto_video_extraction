1
00:00:00,630 --> 00:00:06,140
Cord. All right.

2
00:00:07,620 --> 00:00:11,340
So we are going to get back to exams. I know a lot of you already saw it.

3
00:00:11,670 --> 00:00:18,780
So we're going to try to in class about 15 minutes early at that time, hopefully, then the key will pose to the exam.

4
00:00:20,130 --> 00:00:25,860
And yeah, we'll just kind of organize it and put our put them up here for people.

5
00:00:28,680 --> 00:00:36,930
The other big announcement is that the dean's office has asked us not to give exams on November the eighth,

6
00:00:37,920 --> 00:00:41,610
and that is when the second exam for this class was planned.

7
00:00:42,960 --> 00:00:49,650
So my so it's Election Day. I realize a lot of people are absentee voters, but not everybody is.

8
00:00:50,430 --> 00:00:58,050
So my solution to that is that we are going to move the matching lecture up, but it will not be on the exam.

9
00:00:58,920 --> 00:01:05,660
All right. So we're going to do I think it's November 1st is an in class activity.

10
00:01:05,670 --> 00:01:09,270
We're going to hold that in class activity there because that one is really valuable for

11
00:01:09,270 --> 00:01:13,889
bringing together kind of everything you've learned in module two and starting to kind of,

12
00:01:13,890 --> 00:01:22,740
you know, just really to bring all those concepts together. After that, I will give the matching lecture, but hold off on the quiz on matching,

13
00:01:22,740 --> 00:01:26,340
and we're going to hold up and we're not going to put it on the exam. Okay.

14
00:01:28,080 --> 00:01:35,630
The review session will be on November 8th and the exam will be on November 10th.

15
00:01:35,640 --> 00:01:39,730
We will change this on the syllabus and on the candidates website.

16
00:01:39,750 --> 00:01:47,430
Now, if you had plans and you were going to be out of town on November 10th, you are welcome to take the exam on November 8th.

17
00:01:48,060 --> 00:01:53,630
Just let me know that that is your preference, that you'd prefer to go ahead and take the exam on November 8th.

18
00:01:53,640 --> 00:01:56,760
You have to, of course, promise not to tell your classmates what's on the exam,

19
00:01:57,210 --> 00:02:02,850
and we will set up like a separate proxy, proxy or proxy room three proctored room.

20
00:02:02,850 --> 00:02:08,480
Sorry for you to take that exam on November 8th if it's inconvenient for you to, you know, to take it on the 10th.

21
00:02:09,360 --> 00:02:16,530
So this is kind of the best of all worlds that I could devise while not giving the exam on November eight.

22
00:02:17,040 --> 00:02:19,379
So that's the plan.

23
00:02:19,380 --> 00:02:29,610
We will put it out in an announcement, will also change the canvas web page and we will update the syllabus to show that new schedule.

24
00:02:29,610 --> 00:02:34,709
And once again, if you would prefer to just take the exam on November 8th, we can accommodate that.

25
00:02:34,710 --> 00:02:40,980
You just won't have a review session before the exam, but you will at least focus any class materials to do that.

26
00:02:42,300 --> 00:02:47,550
Okay. So with that, we're going to start module two error and bias.

27
00:02:49,770 --> 00:02:53,400
So lecture outline like I always have, we're going to go over the basics.

28
00:02:53,880 --> 00:02:56,160
We're going to talk about random error and precision.

29
00:02:57,000 --> 00:03:07,260
We're going to talk about study populations and validity, systematic error a.k.a bias, types of selection bias, and then dealing with selection bias.

30
00:03:07,260 --> 00:03:12,750
That's today you look through the entire lecture, you will notice that information bias is also in this lecture.

31
00:03:13,380 --> 00:03:18,090
I am not planning on getting to information bias today. As I said already, we're going to try to end a little bit early,

32
00:03:19,800 --> 00:03:28,590
but I like to put it all together into 211 slide deck as we often don't get all the way through selection bias today.

33
00:03:29,400 --> 00:03:34,290
All right. So sources of error and phenomenological studies, right?

34
00:03:34,290 --> 00:03:39,660
We've got random error, which can always happen. Bias and confounding.

35
00:03:43,530 --> 00:03:47,190
So those are the three different types of error that we're going to be talking about.

36
00:03:48,960 --> 00:03:56,580
So when we talk about measurement, measurement is the assignment of a numerical value or category of a variable to each subject.

37
00:03:56,580 --> 00:04:04,680
According to a specified rule, the objective is to represent the quantity or type of a particular underlying construct.

38
00:04:04,680 --> 00:04:10,860
The contract and you're measuring right contracts may be concrete or they can be more abstract.

39
00:04:13,000 --> 00:04:20,950
So that's measurement classification. On the other hand, is a type of measurement in which the variable but not necessarily the under the construct.

40
00:04:20,980 --> 00:04:26,610
So that's the underlying value, right, is categorical and may involve nominal.

41
00:04:26,620 --> 00:04:30,910
So unordered scales or ordinal order scales.

42
00:04:31,510 --> 00:04:35,320
It's often derived by categorizing a continuous variable.

43
00:04:35,590 --> 00:04:43,180
Not always, but often. Right. So you might do things like classify disease status by a case or non case.

44
00:04:43,180 --> 00:04:47,169
Right. You might classify by severity.

45
00:04:47,170 --> 00:04:50,880
Mild, moderate, severe. Right. Those are two examples.

46
00:04:53,210 --> 00:04:56,750
Okay. So all measurements have error, right?

47
00:04:57,560 --> 00:05:03,890
So measurement error is the major concern with measurement is the quality of that measurement that, that, that you're getting.

48
00:05:04,910 --> 00:05:11,270
Misclassification is measurement error in categorical variables.

49
00:05:11,990 --> 00:05:17,120
Right. So you're switching somebody or misclassifying them. You're switching them from one category to another.

50
00:05:18,260 --> 00:05:21,860
So sources of measurement error, you've got the observer.

51
00:05:21,980 --> 00:05:25,850
So that's the interviewer, the examiner or the person recording the information.

52
00:05:25,850 --> 00:05:29,860
They can always make a mistake. Right. The system.

53
00:05:29,870 --> 00:05:35,030
So the system for codifying or classifying or observations might have some error in it.

54
00:05:35,450 --> 00:05:45,230
The subject's right. People can kind of not quite recall what happened, or they may have a tendency to answer questions in a certain way on purpose,

55
00:05:45,620 --> 00:05:52,279
you know, particularly if it's like a stigmatizing behavior or something. People like to make other people happy for the most part.

56
00:05:52,280 --> 00:05:58,129
So they they do tend to try to sometimes slide towards giving interviewers answers,

57
00:05:58,130 --> 00:06:03,770
but they think that the interviewer wants to hear the instrument or the AC.

58
00:06:04,310 --> 00:06:10,700
You can have a faulty, faulty apparatus. There's inherent variability in any AC.

59
00:06:11,180 --> 00:06:16,249
Right. People think, oh, I got this clinical test result. Like I absolutely, you know, that's my value.

60
00:06:16,250 --> 00:06:21,230
I have that disease. Not necessarily. Right. There's inherent variability that will happen with it.

61
00:06:23,090 --> 00:06:25,169
And then there's data processing errors.

62
00:06:25,170 --> 00:06:31,430
So if you've done analysis before, you have probably made a data processing error, hopefully that you detected.

63
00:06:31,430 --> 00:06:40,550
Right. But you can have errors in coding. You can have errors in data entry, or you can have errors when people are abstracting the data.

64
00:06:44,910 --> 00:06:51,540
Okay. So those are all of our different sources of measurement error that you you know, you always kind of have to think about.

65
00:06:52,050 --> 00:06:58,800
You have to think about it when you're designing a study, when you're analyzing a study, and obviously when you're reading other people's studies,

66
00:06:58,800 --> 00:07:02,910
you need to start thinking about like, what are the sources of error that might have come into play,

67
00:07:04,120 --> 00:07:07,640
you know, and what did they do to kind of try to minimize those sources of error?

68
00:07:10,360 --> 00:07:13,490
Okay. So precision versus validity.

69
00:07:14,320 --> 00:07:18,310
So here we've got a bullseye, right? I don't have a pointer.

70
00:07:19,390 --> 00:07:23,380
Second point here. All right. So we have a bullseye, right?

71
00:07:23,740 --> 00:07:27,910
We've got this first one is not precise and it's also not valid.

72
00:07:28,360 --> 00:07:34,360
Right. For something to be valid, you want to, on the average, be getting the answer.

73
00:07:34,360 --> 00:07:39,370
Right, which is here in the bullseye. The second one, it's not precise.

74
00:07:39,370 --> 00:07:45,940
Our dots are not together. Right? We're not getting the same measurement every time, but we're actually centering in around the bullseye.

75
00:07:46,360 --> 00:07:49,990
So if you average them, you would get kind of you get a valid answer, right?

76
00:07:51,880 --> 00:07:55,360
The third one over here is an example of precise but not valid.

77
00:07:55,360 --> 00:07:57,640
We're getting more or less the same answer each time.

78
00:07:58,390 --> 00:08:04,660
However, unfortunately, it is systematically different from the true answer that we would like to get or what we'd like to measure.

79
00:08:06,100 --> 00:08:10,719
And then, last but not least, we have precise and valid right here.

80
00:08:10,720 --> 00:08:18,490
We are kind of zeroing in on that center value, the bull's eye and all of the dots are relatively close together.

81
00:08:19,750 --> 00:08:29,620
So precision is the lack of random error and validity is going to be the lack of systematic error, right?

82
00:08:32,560 --> 00:08:38,650
So here we've got a lot of random error. We're still centering it around the bullseye here.

83
00:08:39,760 --> 00:08:43,180
We don't have a lot of random error. The dots are relatively close together.

84
00:08:43,180 --> 00:08:47,350
Right. But we have systematic error because we're off from that bullseye.

85
00:08:52,190 --> 00:08:57,650
Okay. So a quick note on validity. There are two conception validity.

86
00:08:58,100 --> 00:09:04,600
There's estimation validity, which is going to be the lack of bias and there is measurement validity.

87
00:09:04,610 --> 00:09:08,150
So that's high test performance or the correctness of a measurement.

88
00:09:12,500 --> 00:09:16,790
Right. So those are some of the basics around error. Precision and validity.

89
00:09:16,790 --> 00:09:21,230
Are there any questions so far? No.

90
00:09:21,340 --> 00:09:25,810
You got this. Okay. Okay. So random error in precision.

91
00:09:27,430 --> 00:09:30,640
So random errors are going to be non systematic error.

92
00:09:31,600 --> 00:09:35,170
Random error is typically thought to result in conservative estimates.

93
00:09:35,560 --> 00:09:39,070
That is the relative risk or the or will go towards one.

94
00:09:40,900 --> 00:09:44,080
It's not always the case, but it's typically thought to be the case.

95
00:09:45,250 --> 00:09:51,580
Random error is going to be present in all studies, right? This is because all studies, even if they're perfectly conducted,

96
00:09:52,060 --> 00:09:57,640
are a sample of the population and therefore may still differ from the true causal association.

97
00:09:58,390 --> 00:10:04,180
Right. Statistics are used to quantify the role of chance in studies.

98
00:10:08,940 --> 00:10:17,820
Okay. So precision and power, so precision is going to refer to that lack of random error in estimating a population parameter.

99
00:10:18,480 --> 00:10:23,969
Right. And power reflects the lack of statistical error and in testing the null

100
00:10:23,970 --> 00:10:29,459
hypothesis against an alternative hypothesis regarding a parameter of interest,

101
00:10:29,460 --> 00:10:38,490
whatever we're trying to estimate. So we'll talk about power for a given alpha probability of type one error per is the probability of correctly

102
00:10:38,490 --> 00:10:44,850
rejecting a false null hypothesis or correctly accepting the alternative hypothesis when it's true.

103
00:10:45,660 --> 00:10:50,490
Right? And then one minus probability of a of a type to our error.

104
00:10:50,940 --> 00:10:54,030
This should all be familiar from by our steps class. Right.

105
00:10:57,270 --> 00:11:03,390
Okay. So for epi, when we think about this, we're going to really kind of think about like how does this make up?

106
00:11:03,540 --> 00:11:07,350
How do we think about study designs, the sample size you need.

107
00:11:08,130 --> 00:11:14,970
Also, how do we think about potential bias that can come into our our studies or errors?

108
00:11:15,960 --> 00:11:20,310
So thus, for a given parameter, the more precise the estimate of what we're going to ignore bias for the moment,

109
00:11:20,580 --> 00:11:25,319
the more powerful the test for rejecting the null hypothesis. So that's kind of precision and power continued.

110
00:11:25,320 --> 00:11:34,020
Sorry. All right. So for precision, it's going to be a function of two different criteria, the sample size and the statistical efficiency.

111
00:11:34,500 --> 00:11:41,250
And we'll go through that. The statistical efficiency is going to be the amount of statistical information per subject.

112
00:11:44,160 --> 00:11:50,010
So if you think about two studies are being done with the same sample size to estimate the same effect,

113
00:11:52,080 --> 00:12:00,030
the estimate that comes out with the narrower confidence interval is going to be more statistically efficient.

114
00:12:00,030 --> 00:12:09,000
Right. Same sample size. We will go through this. That is that it's more precise given a specific sample size, there's less variability.

115
00:12:10,980 --> 00:12:17,970
All right. So sample size and precision generally, the larger the sample size, the more precise the estimate.

116
00:12:19,260 --> 00:12:19,589
Okay.

117
00:12:19,590 --> 00:12:25,829
So if I asked you a question like how can you make this estimate more precise, you would just say, well, we could increase the sample size, right?

118
00:12:25,830 --> 00:12:28,620
That's an easy way to do it if you have enough resources to do so.

119
00:12:29,910 --> 00:12:38,340
However, there is diminishing return in added precision and as the sample size increases indefinitely.

120
00:12:38,350 --> 00:12:41,700
So you remember we talked about this a little bit with case control studies.

121
00:12:42,060 --> 00:12:50,850
I kind of I didn't go into a lot of detail as to why, but I said kind of, you know, you don't really go beyond maybe four key four controls per case.

122
00:12:50,850 --> 00:12:57,480
Right. Or wonderful ratio could be the opposite depending on how hard it is sometimes maybe five.

123
00:12:57,810 --> 00:13:00,990
Right. But that has to do with that kind of diminishing return.

124
00:13:00,990 --> 00:13:04,350
And I'll go through some examples of that now. All right.

125
00:13:05,610 --> 00:13:11,490
So sample size and precision. We've got three case control studies involving different numbers of controls.

126
00:13:12,210 --> 00:13:17,580
So here's study one. So one thing you'll notice right away, right, is all of them have the same number of cases.

127
00:13:17,580 --> 00:13:24,300
Right? They all have 20 cases. They all have the same proportion of exposed cases.

128
00:13:25,170 --> 00:13:33,180
Okay. And we get the same odds ratio with any of these study designs.

129
00:13:33,180 --> 00:13:36,540
One of them has 40 participants, another one has 120.

130
00:13:36,870 --> 00:13:39,929
And over here we had 220 participants. Right?

131
00:13:39,930 --> 00:13:45,780
So getting much larger. But one thing you'll notice really quickly.

132
00:13:45,780 --> 00:13:47,270
Right. Odds ratios are the same.

133
00:13:47,280 --> 00:13:55,379
We've got pretty wide confidence interval in that first study, right where we've got one control per case, that's study one, right?

134
00:13:55,380 --> 00:14:03,060
We go from 0.79 to 11.4. If this was your study, you would say that the result was not statistically significant.

135
00:14:03,660 --> 00:14:12,600
Right. Or we might use different language around it, but that's essentially it crosses the null value of one right here.

136
00:14:12,840 --> 00:14:16,590
Right. We've now done five controls per case.

137
00:14:17,850 --> 00:14:21,899
And what you can see as a result, we don't get a change in the odds ratio.

138
00:14:21,900 --> 00:14:26,880
Right, because the the exposure prevalence in the controls is the same.

139
00:14:27,540 --> 00:14:34,079
Right. We've just increased the number of controls and now we've narrowed down that that confidence interval.

140
00:14:34,080 --> 00:14:37,620
So now we have 1.0128.88.

141
00:14:38,100 --> 00:14:43,170
Right. So that would be considered statistically significant because it doesn't cross one.

142
00:14:44,910 --> 00:14:48,790
And then we have study three, right? We're going to add another. We're going to double the number of controls.

143
00:14:48,790 --> 00:14:51,900
So now we're doing ten controls per case.

144
00:14:52,530 --> 00:14:59,100
And what do you notice here between study two and three? There's almost no difference, right?

145
00:14:59,580 --> 00:15:03,840
Right. That's why we're not going to go beyond four, maybe five.

146
00:15:04,740 --> 00:15:07,860
Right. A ratio of 1 to 4 or 1 to 5.

147
00:15:08,250 --> 00:15:15,540
Right. Because as you increase that, you're not really gaining much power or you're not going to gain much statistical efficiency,

148
00:15:15,960 --> 00:15:19,260
not getting a lot of extra information from each person that you're adding.

149
00:15:21,630 --> 00:15:22,440
And, you know, of course,

150
00:15:22,440 --> 00:15:28,739
it's important to remember what happens as we increase the number of people in our study in addition to our confidence intervals.

151
00:15:28,740 --> 00:15:32,280
Narrowing it gets bigger. What?

152
00:15:33,000 --> 00:15:39,870
Yeah, our costs go up, right? Like it's going to cost a lot more money, probably to do study three than study to.

153
00:15:40,200 --> 00:15:45,300
Right. It certainly makes sense to pay the extra money from study one to study to write,

154
00:15:45,630 --> 00:15:51,030
you know, to be able to answer our question with a reasonable amount of precision.

155
00:15:51,510 --> 00:15:58,530
But beyond that, it doesn't really make sense to to spend that extra money because you're getting very little return here.

156
00:15:59,460 --> 00:16:05,910
All right. So statistical efficiency and precision subject selection, in effect,

157
00:16:05,910 --> 00:16:10,950
estimation affects statistical efficiency and thus the precision of the effect estimate.

158
00:16:12,060 --> 00:16:17,190
I will go through an example of what that would mean. So estimation of effect can often be made more efficient by.

159
00:16:17,220 --> 00:16:22,890
So there's different things we can do to try to make it more efficient using all of the available information.

160
00:16:22,890 --> 00:16:28,320
So this means not categorizing a continuous exposure that can make things more efficient.

161
00:16:29,490 --> 00:16:35,790
You can make mathematical assumptions that permit the use of more efficient statistical model methods, right?

162
00:16:36,690 --> 00:16:41,819
You can restrict eligibility of subjects to narrow categories of other risk factors of the disease.

163
00:16:41,820 --> 00:16:45,690
You're going to remove some variability there. What you have to adjust for potentially.

164
00:16:45,690 --> 00:16:49,380
Right. And that will make it more statistically efficient.

165
00:16:50,460 --> 00:16:54,840
Or you can balance or equalize the number of subjects in comparing groups.

166
00:16:55,560 --> 00:17:00,450
And that's another way. And matching we're really doing that matching, which we will talk about later.

167
00:17:00,450 --> 00:17:05,600
Right. All right. So here we have an example, right?

168
00:17:05,610 --> 00:17:13,360
We have three case control studies. Again, same prevalence of exposure in both the cases, 60% and the controls 40%.

169
00:17:13,790 --> 00:17:17,340
All right. We get this so we get the same odds ratio in all of them.

170
00:17:18,390 --> 00:17:21,420
The first two studies have the same number of participants, right?

171
00:17:21,420 --> 00:17:25,370
They each have a hundred. But here, study one is balanced.

172
00:17:25,380 --> 00:17:28,830
Right. We have a 1 to 1 ratio, which is our ideal ratio.

173
00:17:28,830 --> 00:17:36,149
In fact, for statistical efficiency, all else being equal, right cases and controls can cost different amounts to enroll.

174
00:17:36,150 --> 00:17:44,070
To collect the information, you may not be able to have enough cases, etc. Like so there are reasons to not stick with that 1 to 1 ratio.

175
00:17:44,430 --> 00:17:49,110
But if you have the choice, if it makes sense, 1 to 1 ratio would be your first choice, right?

176
00:17:49,590 --> 00:17:56,430
So here when we have a 1 to 1 ratio, our confidence interval is 1.01 to 5.01.

177
00:17:56,760 --> 00:18:03,959
Right. Study two. On the other hand, we have ten cases and 90 controls, right?

178
00:18:03,960 --> 00:18:05,340
So a 1 to 9 ratio.

179
00:18:05,700 --> 00:18:13,230
And here you can see that that significantly widens the confidence interval, even though we have the same number of participants in the study.

180
00:18:14,700 --> 00:18:22,049
Study three, we have now increased the study size overall.

181
00:18:22,050 --> 00:18:30,660
So we have 180 participants. We have a 1 to 5 ratio, so one case per control.

182
00:18:31,230 --> 00:18:38,580
And that gets us back actually to the same confidence interval that we had with Study one, right?

183
00:18:39,000 --> 00:18:45,030
So as we change that ratio, the number of like from 1 to 1 to 1 to 3,

184
00:18:45,030 --> 00:18:50,010
the number of participants actually has to increase to get the same level of statistical efficiency.

185
00:18:54,170 --> 00:18:58,170
This same principle is going to apply to extraneous risk factors as well.

186
00:18:59,120 --> 00:19:03,919
So you can match on such factors and subject selection will tend to make effect

187
00:19:03,920 --> 00:19:09,890
estimation more efficient by balancing the ratio of comparison subjects across strata.

188
00:19:10,250 --> 00:19:14,270
There are, of course, always concerns about over matching and stuff, which we'll talk about more.

189
00:19:15,890 --> 00:19:21,700
Remember we talked about this a little bit or I think it was probably cover hopefully I usually covered in the trials lecture.

190
00:19:21,710 --> 00:19:32,470
Was it covered in the trials lecture? And then we'll talk about it a lot more in the in the matching lecture.

191
00:19:34,870 --> 00:19:40,090
Okay. Any question about statistical efficiency in subject selection?

192
00:19:44,670 --> 00:19:48,390
Okay. So study populations and validity.

193
00:19:48,990 --> 00:19:53,069
So next. So the hierarchy of study populations that should look familiar, right?

194
00:19:53,070 --> 00:19:55,980
You've seen this before in the beginning of the class, right?

195
00:19:56,250 --> 00:20:03,610
We've got our study population, which is nested inside of our source population, which is part of our base population.

196
00:20:03,620 --> 00:20:07,380
And then we kind of want to extrapolate out to this target population.

197
00:20:08,760 --> 00:20:13,830
So the study population is the group of subjects on whom we make observations and collect data.

198
00:20:14,340 --> 00:20:19,650
It's going to be a subset of the source population. The source population is our sampling frame.

199
00:20:20,040 --> 00:20:23,310
That is the group of individuals that were eligible to be sampled.

200
00:20:24,480 --> 00:20:35,370
Right. The base population is the group of persons who are at risk of developing the disease or outcome event of interest during a given time period.

201
00:20:35,760 --> 00:20:40,530
It is the group of people for which we would like to make a causal inference, right?

202
00:20:40,530 --> 00:20:44,249
And then our target population is the larger population,

203
00:20:44,250 --> 00:20:49,860
the group of individuals to which we'd like to generalize our results and possibly apply our knowledge.

204
00:20:51,120 --> 00:20:55,230
The target population is typically not going to be observed by the investigator.

205
00:20:58,050 --> 00:21:06,120
As a side note, some text and some papers like to call the base population the target population.

206
00:21:06,810 --> 00:21:12,150
And then those particular sources call the target population the external population.

207
00:21:13,110 --> 00:21:21,270
So just to be aware, I try to stick with the language that both is used in 600 as well as what's in our main textbooks for this course.

208
00:21:22,440 --> 00:21:25,440
But you can see that in other text.

209
00:21:26,130 --> 00:21:30,210
I think Heineken's does a lot of wells, but nobody ever uses hurricanes anymore.

210
00:21:32,550 --> 00:21:35,370
Or I mean, you you all don't use kind of kids,

211
00:21:35,370 --> 00:21:40,199
people of my age to look back to hurricanes all the time because it's one of the effects we learned out of.

212
00:21:40,200 --> 00:21:43,709
So. All right.

213
00:21:43,710 --> 00:21:44,970
Internal validity.

214
00:21:45,660 --> 00:21:54,750
So internal validity is the extent to which the results of an investigation accurately reflect reflect the true situation within the study population.

215
00:21:55,200 --> 00:22:02,070
Like, did you actually get the results that you should have gotten from your study population?

216
00:22:02,580 --> 00:22:06,570
Now, this is different from external validity, which we will talk about in a moment.

217
00:22:07,560 --> 00:22:12,780
So internal validity is really going to be defined by the boundaries of the study itself.

218
00:22:13,710 --> 00:22:21,420
A study is going to be internally valid if it provides a true estimate of the effect given the elements of the population being studied.

219
00:22:23,010 --> 00:22:30,240
If the results are not valid in the study population, then there is little reason to suspect they should apply to other populations.

220
00:22:30,720 --> 00:22:34,870
That is, that they should have external validity, right?

221
00:22:35,490 --> 00:22:42,060
So external validity is the extent to which the results of a study are applicable to other populations,

222
00:22:43,350 --> 00:22:47,100
or results obtained in a tightly controlled environment or in a given study.

223
00:22:47,100 --> 00:22:52,950
Population may not be applicable to more general situations or to other populations.

224
00:22:53,310 --> 00:22:56,580
This actually happens a lot with randomized controlled trials, right?

225
00:22:56,580 --> 00:23:02,070
People who have a particular effect in one setting, you know, under tightly controlled conditions.

226
00:23:02,520 --> 00:23:06,480
And then they roll out the intervention and it doesn't appear to work. Right.

227
00:23:06,490 --> 00:23:09,990
And that may be because it's not as tightly a controlled environment,

228
00:23:09,990 --> 00:23:16,799
because the people that they are now giving that intervention to or that treatment to have a lot of, you know, perhaps as a treatment.

229
00:23:16,800 --> 00:23:23,400
Right. Maybe a whole host of other health problems. Right. Where they really limited who could come in to the study to begin with.

230
00:23:23,820 --> 00:23:29,430
Or it just may be that you're rolling on an intervention in another setting and the local conditions are really different.

231
00:23:30,030 --> 00:23:33,690
Right. All right.

232
00:23:34,110 --> 00:23:36,419
So statistical inference, right.

233
00:23:36,420 --> 00:23:43,860
Where for a study population to our source population, internal validity is going to be our study population to our base population.

234
00:23:44,700 --> 00:23:51,389
And then external validity is trying to like generalize out to that target population.

235
00:23:51,390 --> 00:23:52,020
So once again,

236
00:23:52,020 --> 00:23:59,370
it's going to be internally valid if it provides a true estimate of the effects given the limits of the population that we are studying,

237
00:23:59,370 --> 00:24:06,450
which is our our base population. Any questions about that?

238
00:24:07,920 --> 00:24:12,300
You're all like me, and the study populations are coming back. I thought we were past that.

239
00:24:12,510 --> 00:24:22,050
So when one thing about six, everyone is basically almost everything you learn in the first module follows you through the rest of the class.

240
00:24:22,080 --> 00:24:27,270
There are certain things like We won't make you calculate risk four different ways, but three different ways.

241
00:24:27,270 --> 00:24:35,009
Right? Probably not going to ask you to standardize anything but all of your basic measures.

242
00:24:35,010 --> 00:24:43,710
You know the discussion about causal inference, substantiation, measures of disease, measures of impact.

243
00:24:44,460 --> 00:24:47,700
The study designs are here with us for the rest of the class.

244
00:24:47,700 --> 00:24:52,469
Right. And it's going to kind of show up again and again. All right.

245
00:24:52,470 --> 00:24:55,710
So systematic error, a.k.a. bias.

246
00:24:57,750 --> 00:25:03,750
So systematic errors, a systematic difference between the observed association and the true causal effect.

247
00:25:05,550 --> 00:25:12,180
It's difficult to quantify the exact effect of bias on findings, but of course, we will make guesses to that.

248
00:25:12,180 --> 00:25:15,239
You know, when you're analyzing a paper or in your discussion,

249
00:25:15,240 --> 00:25:20,520
you will talk about potential biases that you could have had and the effect that you expect that would have had on your findings.

250
00:25:21,450 --> 00:25:25,530
Bias or systematic error is going to play a role in all epidemiologic studies.

251
00:25:27,740 --> 00:25:31,010
Okay. So bias cannot be completely avoided, unfortunately.

252
00:25:32,240 --> 00:25:40,280
So you must discuss it in any manuscript. Bias is best to control at the design phase.

253
00:25:40,910 --> 00:25:46,670
If you can do that right, if you have a census, can you completely avoid it?

254
00:25:47,510 --> 00:25:50,690
If you had a census, complete the complete population.

255
00:25:51,980 --> 00:25:58,430
Even there you can still have some bias that is introduced because people might drop out of your study.

256
00:26:00,830 --> 00:26:06,889
People could choose to enroll or not enroll. So there's kind of always going to be some bias.

257
00:26:06,890 --> 00:26:09,770
There's going to be information bias potentially happening as well.

258
00:26:10,820 --> 00:26:16,879
So yeah, the more complete information you can get on everybody who is eligible to enroll in your study,

259
00:26:16,880 --> 00:26:20,750
right like that can help you minimize selection biases in particular.

260
00:26:21,920 --> 00:26:26,420
But then you still have information biases that come in. And of course, we'll try to take care of each of those.

261
00:26:26,420 --> 00:26:31,579
But, you know, it's kind of almost like playing Twister, right? You can never quite cover all of the spots.

262
00:26:31,580 --> 00:26:34,610
Eventually there's something that gets you. Okay.

263
00:26:34,670 --> 00:26:44,030
So bias can can affect the estimate in either a positive or a negative direction, meaning kind of.

264
00:26:45,650 --> 00:26:49,100
And we'll talk about positive or negative or towards or away from the null.

265
00:26:49,130 --> 00:26:52,820
Two different ways to talk about bias, and we will talk about it both ways in this class.

266
00:26:53,900 --> 00:26:57,440
All right. So random error versus systematic error, right?

267
00:26:57,440 --> 00:27:01,550
So we said all studies are going to have some error. We've got random error.

268
00:27:02,060 --> 00:27:06,710
Random error is the lack of or there lack of random error is is precision.

269
00:27:07,250 --> 00:27:10,970
Right. And then all studies will have some systematic error.

270
00:27:11,540 --> 00:27:16,100
Right. And we're trying to control that systematic error as much as we can in the design phase.

271
00:27:16,520 --> 00:27:22,550
And so the systematic error that we're going to be concerned about in this class and talking about the different types are selection bias,

272
00:27:23,000 --> 00:27:28,159
information bias and confounding. Some people call it confounding bias.

273
00:27:28,160 --> 00:27:32,300
I was not brought up calling it confounding bias might just call it confounding for the most part,

274
00:27:33,200 --> 00:27:41,959
but you'll see some of the text called Finding other numbers. But all of these three things are bias and the lack of bias.

275
00:27:41,960 --> 00:27:46,850
Right, is going to be is validity. Okay.

276
00:27:46,850 --> 00:27:50,690
So I've already kind of alluded to this, but there are two manners of discussing bias.

277
00:27:51,560 --> 00:28:00,230
You can bias towards or away from them all, or you can talk about a positive or a negative bias, right?

278
00:28:02,450 --> 00:28:07,250
So for bias towards a weight in the null and in epidemiology, we typically try to be conservative.

279
00:28:09,200 --> 00:28:17,149
So what that means is that if we must have a bias, we try to bias towards the null rather than away from the null.

280
00:28:17,150 --> 00:28:23,540
So, you know, and you will often be making these decisions, well, do I put them here or there?

281
00:28:23,540 --> 00:28:29,090
Right. And then you have to think, well, would it bias it towards the null or away from the null?

282
00:28:29,270 --> 00:28:37,340
I'm going to make the if I'm not sure on how to classify this particular group of people or which decision to make on the analysis.

283
00:28:37,700 --> 00:28:42,439
I will make the decision to bias it towards the no. All right.

284
00:28:42,440 --> 00:28:45,620
So the null we have already gone over this.

285
00:28:45,620 --> 00:28:49,339
But just to remind you, the null for a relative measure.

286
00:28:49,340 --> 00:28:55,050
What is it? I see people mouthing it and fingers one.

287
00:28:55,440 --> 00:28:58,460
Right. And what's the first difference?

288
00:28:59,670 --> 00:29:03,180
Zero. Yeah. All right. Okay.

289
00:29:04,080 --> 00:29:08,820
So towards and away from the is one that people usually have a really easy time with.

290
00:29:09,000 --> 00:29:12,299
Positive and negative bias tends to be a little bit more challenging.

291
00:29:12,300 --> 00:29:17,580
Sometimes it's like it seems really clear when we talk about it and then when we ask you to turn it that way,

292
00:29:17,580 --> 00:29:21,569
you're like, Oh, so just make sure you do the assignments.

293
00:29:21,570 --> 00:29:24,750
That kind of practice talking about positive and negative bias.

294
00:29:25,890 --> 00:29:33,300
So positive biases of upward bias relative to the value of the effect estimate.

295
00:29:35,160 --> 00:29:41,489
A negative bias is a downward bias relative to the a value of the effect estimate.

296
00:29:41,490 --> 00:29:46,590
So what does this look like? Here we have example one.

297
00:29:47,400 --> 00:29:53,070
Our effect estimate is above one. Right? This is a positive bias, right?

298
00:29:53,070 --> 00:29:57,240
Because it's upward and it is also a bias away from the null.

299
00:29:58,860 --> 00:30:04,200
Here's another example. This is also a, you know, like a risk factor, right?

300
00:30:04,200 --> 00:30:09,480
It's a value above one. We've got a negative bias and we're biasing it towards the norm.

301
00:30:10,980 --> 00:30:16,050
However, you can have a negative bias that biases it beyond the null.

302
00:30:17,490 --> 00:30:22,290
Right. And you can also have a positive bias right here, though.

303
00:30:22,290 --> 00:30:25,920
It's a protective factor. We're actually biasing it towards the null.

304
00:30:26,610 --> 00:30:30,810
Right. So here is our true value theta.

305
00:30:31,110 --> 00:30:34,610
And then here it is with a little squiggly line above. That's the estimate that we get.

306
00:30:35,370 --> 00:30:43,330
Right. So. Can you have a negative bias away from the law?

307
00:30:44,470 --> 00:30:51,390
You can have a negative bias away from them all year. So if you already had a protective factor and you did a negative bias, it would be a with.

308
00:30:51,470 --> 00:31:01,870
No, I just didn't include all the different examples. I'm thinking of it in positive and negative is actually really helpful when you

309
00:31:01,870 --> 00:31:07,690
start to think about what the actual effect will be on your effect estimate.

310
00:31:08,290 --> 00:31:15,910
Right. But people are typically like in prior classes, probably used to this kind of a way or towards the null.

311
00:31:16,150 --> 00:31:23,049
The problem is then you have to think about it in a different way for protective factors, comparative risk factors.

312
00:31:23,050 --> 00:31:26,620
Right. So. All right.

313
00:31:27,340 --> 00:31:33,700
So our types of bias that we're going to be talking about, our selection bias and information bias.

314
00:31:39,590 --> 00:31:43,630
All right. So for selection bias, okay.

315
00:31:43,730 --> 00:31:49,940
We've got individuals have different probabilities of being included in the study sample according to relevant study characteristics.

316
00:31:50,690 --> 00:31:56,090
It's typically the exposure or the outcome of interest that may be related to both.

317
00:31:56,540 --> 00:32:04,130
Right. It's going to distort the measure of association between the outcome of the between the exposure and the outcome.

318
00:32:04,850 --> 00:32:10,430
So here's my little picture of selection bias. For people who like pictures, right?

319
00:32:11,060 --> 00:32:12,680
I like both words and pictures.

320
00:32:13,500 --> 00:32:21,740
So here we've selected kind of evenly from healthy, exposed, healthy not exposed and disease not exposed from our reference population.

321
00:32:22,130 --> 00:32:25,760
But we've over selected people who are disease and exposed.

322
00:32:26,210 --> 00:32:35,390
When do you think that might happen? Any thoughts on when that might occur?

323
00:32:36,410 --> 00:32:46,740
Do you think that's a common problem? I think it's usually when exposed, people are more likely to be monitored and seen as being at higher risk.

324
00:32:47,010 --> 00:32:50,010
Yeah. That immunosuppressants. Yeah, exactly.

325
00:32:50,010 --> 00:32:53,159
That is one really good example of when you would see that happen.

326
00:32:53,160 --> 00:32:56,820
Right. Exposed people are going to people are going to be looking for the disease.

327
00:32:57,300 --> 00:33:05,820
Right. And they're going to be going into the doctor more if you if people in your study or something going with the disease.

328
00:33:06,120 --> 00:33:10,979
I guess I don't know if this is exactly selection bias of a different type of bias involved,

329
00:33:10,980 --> 00:33:15,980
but they're more and more likely to have a role that is a selection bias.

330
00:33:15,990 --> 00:33:20,320
If if they're if it's affecting selection into the study, that's a selection bias.

331
00:33:20,340 --> 00:33:27,900
So, yeah, what about if you're doing a case control study?

332
00:33:28,200 --> 00:33:33,419
Right. So one thing about this, this is selection bias depends a little bit on the study design.

333
00:33:33,420 --> 00:33:40,050
I will point it out as we go, whether it's a a selection bias or an information bias,

334
00:33:40,920 --> 00:33:48,150
because there are some things that are a selection bias in a in a case control study or actually an information bias in a cohort study.

335
00:33:48,660 --> 00:33:56,340
Right. So if this were a case control study that we're enrolling here and people who have the exposure are likely to be sicker.

336
00:33:57,000 --> 00:34:03,840
Right. And thus more likely to go seek medical care for the disease of interest or more likely to be detected with the disease because they're sicker,

337
00:34:05,040 --> 00:34:08,310
then that would be another selection bias.

338
00:34:08,760 --> 00:34:12,540
However, I would say if it was a cohort study, right,

339
00:34:12,540 --> 00:34:16,439
it would actually be an information bias because you would you would be misclassifying some

340
00:34:16,440 --> 00:34:21,090
people as not disease when they're actually disease because you're not detecting them.

341
00:34:21,810 --> 00:34:27,660
But we'll go through those examples in a moment and I will try to point out whenever I remember, which hopefully will be all the time,

342
00:34:28,560 --> 00:34:36,660
which ones are not a selection bias when it's, you know, in another study design and what type of bias it is when you turn that study results.

343
00:34:37,860 --> 00:34:41,550
All right. So selection bias occurs when subject selection,

344
00:34:42,090 --> 00:34:53,070
participation or loss to follow up is affected by exposure status and disease status or an unmeasured risk factor for the disease.

345
00:34:53,100 --> 00:35:00,989
Right. It has to be related to both. Just having unequal loss to follow up will not necessarily bias your estimate.

346
00:35:00,990 --> 00:35:05,250
It will decrease precision.

347
00:35:05,730 --> 00:35:08,219
Right. But it won't necessarily bias the instrument.

348
00:35:08,220 --> 00:35:13,170
It has to be related to both the disease and the exposure or something that's related to the disease.

349
00:35:13,800 --> 00:35:24,610
Right. Okay. So here we have a hypothetical, uh, case control study, including all cases and all non cases of a defined population.

350
00:35:24,610 --> 00:35:29,820
This is from school, so we're assuming no confounding, no information bias.

351
00:35:30,180 --> 00:35:33,360
So the only bias we're going to possibly introduce here is selection bias.

352
00:35:33,360 --> 00:35:38,520
But we're starting with a completely unbiased. So these are all the cases and all the controls that occur in the populate.

353
00:35:39,510 --> 00:35:43,050
All the non cases are controls in the population. Right.

354
00:35:45,030 --> 00:35:47,880
And we get an odds ratio of 4.0.

355
00:35:48,330 --> 00:35:54,600
This is the gold standard against which we're going to look at all the other studies when we're going to now introduce a selection bias.

356
00:35:55,590 --> 00:36:04,470
So let's say you are an investigator and you perform a perfectly unbiased selection using 50% of the cases and 10% of the controls.

357
00:36:05,880 --> 00:36:10,470
I just went back to the last slide. We haven't done that. What do we expect the odds ratio to be?

358
00:36:12,180 --> 00:36:16,740
Completely unbiased. 50% of the cases, 10% of the controls.

359
00:36:18,540 --> 00:36:22,790
What would the odds ratio be? I heard the answer.

360
00:36:26,110 --> 00:36:32,560
Hold up your fingers. What do you think the odds ratio is going to be or right should be the same because it's perfectly unbiased.

361
00:36:32,830 --> 00:36:37,480
All right. So let's see. So we'll do that. We're going to take 50% of the control.

362
00:36:37,490 --> 00:36:43,720
So we take 500. We're going to keep the exposure odds for C and we're going to take 10% of the cases.

363
00:36:44,080 --> 00:36:47,709
Sorry of the control. Sorry. Instead of 9000, we now have 900.

364
00:36:47,710 --> 00:36:50,710
I think I said controls over here. What I said cases.

365
00:36:51,310 --> 00:36:55,120
But you plug in the numbers, you'll get the same odds ratio.

366
00:36:55,120 --> 00:36:59,860
Right. And that's because we've done a completely unbiased selection,

367
00:37:00,130 --> 00:37:08,980
even though we're selecting different proportions for the cases because we're taking 50% of them and only 10% of the controls.

368
00:37:10,240 --> 00:37:16,330
All right. So we've got an honest, unbiased exposure odds in the cases and controls.

369
00:37:16,660 --> 00:37:20,470
So we've got an unbiased odds ratio. Okay.

370
00:37:20,950 --> 00:37:27,249
Now we're going to go back to the original population of all cases and controls, and we're going to redo the selection this time.

371
00:37:27,250 --> 00:37:34,570
The selection is going to be biased. We're once again going to select 50% of the cases and 10% of the controls.

372
00:37:35,710 --> 00:37:40,960
This time, though, the cases with the exposure are more likely to be selected.

373
00:37:41,500 --> 00:37:49,630
So do you think this is going to increase the odds ratio or decrease the odds ratio, or is it going to do the same increase decreasing?

374
00:37:50,950 --> 00:37:57,219
It's going to increase, right, because we're making the exposure more likely among the cases.

375
00:37:57,220 --> 00:38:04,390
So here. What does that look like? We've got the same number of cases, but now we've changed the exposure odds.

376
00:38:05,410 --> 00:38:09,400
Right. For the cases to be selected in the controls, it is staying the same.

377
00:38:09,940 --> 00:38:14,800
We end up with an odds ratio of 6.0. So it has increased, right?

378
00:38:15,070 --> 00:38:21,370
We've got a biased exposure odds in the cases, an unbiased exposure odds and the controls.

379
00:38:21,970 --> 00:38:29,490
Right. And that leads to a biased odds ratio. Any questions?

380
00:38:33,140 --> 00:38:40,190
Example, positive bias. This would be a positive bias or and what we can also call it a away from the mall.

381
00:38:42,740 --> 00:38:47,360
All right. So types of selection bias. We've got a lot of different types of selection bias.

382
00:38:49,940 --> 00:38:53,540
Fine. Okay. We can have an inappropriate reference group.

383
00:38:54,620 --> 00:39:00,349
The comparison group is not appropriate for testing the hypothesis that issue this basic

384
00:39:00,350 --> 00:39:04,370
form of selection bias typically occurs in retrospective cohort or cross sectional.

385
00:39:04,370 --> 00:39:07,820
Studies could occur to the winds, but that's where it mostly occurs.

386
00:39:08,780 --> 00:39:10,280
So I'll give you a few examples.

387
00:39:12,410 --> 00:39:19,000
So this first example is basically like the group that you are wanting to study is mixed in with your comparison group, essentially.

388
00:39:19,010 --> 00:39:26,390
So you want to you want to do a study to assess the effect of employment outside of the home on total mortality among adult women.

389
00:39:27,980 --> 00:39:33,049
Comparing the estimated mortality rate in employed women with the corresponding rate in all,

390
00:39:33,050 --> 00:39:40,820
women both employed and unemployed in the population would result in a misleading estimate of the effect of employment on total mortality.

391
00:39:40,970 --> 00:39:47,870
You will see people do this all the time, though, right? Partly because that's the information that's easiest to come by.

392
00:39:47,870 --> 00:39:52,940
It's hard. It's fairly easy to come by mortality data among employed people.

393
00:39:53,330 --> 00:39:58,970
Relatively easy, right? It's relatively easy to come by mortality data for the entire population.

394
00:39:59,360 --> 00:40:07,490
But mortality information for unemployed individuals may be much harder to come by the severity of the issue,

395
00:40:07,520 --> 00:40:14,300
how much how much selection bias for introducing really depends on the proportion of the female population that is employed.

396
00:40:14,690 --> 00:40:22,129
It's a very small proportion. Won't make a big difference. If it's a really large proportion, then it would make a big difference, right?

397
00:40:22,130 --> 00:40:29,990
Or could make a big difference. So who should we be comparing here, if that's our question, the fact of employment.

398
00:40:34,110 --> 00:40:43,920
Total mortality among adult women. We should compare adult women who are employed to whom unemployed adult women who are unemployed.

399
00:40:46,170 --> 00:40:54,750
All right. Another example of an inappropriate reference group is the effect of repetitive hand and wrist movements on carpal tunnel syndrome.

400
00:40:56,280 --> 00:41:01,980
That's right. But drumming your wrist can lead to numbness of your arm, all sorts of nerve problems.

401
00:41:03,060 --> 00:41:08,100
So you compare the frequency of carpal tunnel syndrome symptoms between two groups of female workers,

402
00:41:08,730 --> 00:41:11,960
grocery checkers, who you hypothesized to be a high risk rate.

403
00:41:11,970 --> 00:41:17,010
They're doing this all day long than their job. And teachers or your reference group.

404
00:41:18,900 --> 00:41:25,050
Right. The problem here is the reference group is not entirely unexposed to repetitive hand movements.

405
00:41:25,590 --> 00:41:29,549
Right. Teachers can be grading. They're going to be doing other things, you know, maybe typing.

406
00:41:29,550 --> 00:41:35,970
Right. So they'll have a lot of repetitive movements, too. What do you think we do here?

407
00:41:38,880 --> 00:41:43,650
Do you think anybody has, like, a complete lack of repetitive hand movements?

408
00:41:47,920 --> 00:41:54,070
Probably not. Right. So what do you think we'd want to do then?

409
00:41:56,260 --> 00:41:59,920
We're looking at an exposure that everybody has, at least some level of it.

410
00:42:02,070 --> 00:42:05,330
Sorry. Categorize. Yep. So.

411
00:42:05,490 --> 00:42:10,140
But we will want to measure the exposure. Right. So here it's.

412
00:42:10,230 --> 00:42:16,860
This is kind of a interplay between like a selection bias and a measurement problem, right?

413
00:42:16,860 --> 00:42:20,490
An underlying measurement problem that we have. Okay.

414
00:42:23,550 --> 00:42:25,500
All right. Self-Selection bias.

415
00:42:27,270 --> 00:42:36,030
Those who choose to participate in the study may be and often are systematically different from those that do not choose to participate in a study.

416
00:42:37,320 --> 00:42:41,850
So you've got a problem of self-referral of subjects reasons for self referral.

417
00:42:41,850 --> 00:42:46,530
When people come to enroll in your study may be associated with the outcome of interest.

418
00:42:47,010 --> 00:42:52,470
Right. They heard about the study from somebody else and they know there's a high risk of that disease in their family.

419
00:42:52,480 --> 00:42:56,100
So they would love to be in your cohort study to study X, Y or Z.

420
00:42:59,060 --> 00:43:03,380
Self-Selection becomes an increasing concern as participation rates decline.

421
00:43:03,950 --> 00:43:16,479
So if I say I sent out 10,000 debate invitations and 9900 people agreed to participate in my study, probably not going to be super concerned.

422
00:43:16,480 --> 00:43:24,680
Great. But if I send out 10,000 invitations and 120 people agree to participate in my study,

423
00:43:25,220 --> 00:43:29,630
then we're going to be very concerned about what the effects of self-selection might be.

424
00:43:30,170 --> 00:43:38,990
Right. So that's why it becomes an increasing concern as participation rates decline.

425
00:43:40,010 --> 00:43:45,440
This is also sometimes called non-response bias in cross-sectional studies.

426
00:43:46,670 --> 00:43:50,780
All right. But self-selection bias is a concern that we have in all our study designs.

427
00:43:54,050 --> 00:43:59,600
So self-selection bias can occur when the group of exposed or treated individuals is selected from a group of

428
00:43:59,600 --> 00:44:07,310
persons who voluntarily choose to be exposed or treated before they are selected for participation as well.

429
00:44:07,760 --> 00:44:14,000
Right. Volunteers and non volunteers are likely to be different in many ways, some of which might be related to disease risk.

430
00:44:14,450 --> 00:44:18,470
So if you think about I'm going to do a study inside of all these people getting the screening test,

431
00:44:18,980 --> 00:44:27,469
people who choose to get screened and don't and don't get screened if they both qualify may and probably do differ in systematic ways.

432
00:44:27,470 --> 00:44:31,320
Partly like how high risk do they consider themselves?

433
00:44:31,340 --> 00:44:36,950
Of course there are other things to do. They have health insurance to cover the screening, you know, etc.

434
00:44:37,100 --> 00:44:44,600
So, so an example of self-selection bias is the desire to test the effectiveness of a company

435
00:44:44,600 --> 00:44:49,490
related alcohol treatment program on subsequent worker absenteeism due to illness.

436
00:44:50,780 --> 00:44:56,510
Right. You might compare alcoholics who voluntarily participate in that to those who don't.

437
00:44:56,540 --> 00:44:59,989
Don't worry about us figuring out who is an alcoholic who doesn't participate.

438
00:44:59,990 --> 00:45:03,200
Right. But we'll just assume we did that perfectly. All right.

439
00:45:03,590 --> 00:45:13,280
So a lower absentee rate here among participants in the program might actually reflect a greater motivation to stop drinking.

440
00:45:13,700 --> 00:45:15,709
Right? They're seeking out that program.

441
00:45:15,710 --> 00:45:22,160
They're wanting to participate because they would like to stop drinking rather than any actual benefit of the program itself.

442
00:45:23,840 --> 00:45:30,200
So that is, if you did that study, you, you and you just said, okay, you know, if you you know, for the alcoholics,

443
00:45:30,560 --> 00:45:34,820
you know, please raise your hand if you'd like to participate in this program, then you followed them for six months.

444
00:45:34,820 --> 00:45:41,200
You might get the actual same results, you know. So that's kind of always a concern.

445
00:45:45,540 --> 00:45:49,290
Healthy worker effect. It's funny you of it being an infectious diseases.

446
00:45:49,800 --> 00:45:57,030
I used to not worry very much about self selection bias like like I work down in Nicaragua and I like to study things like flu and dengue,

447
00:45:57,150 --> 00:46:01,559
like everybody gets flu and dengue. It used to be by the time kids were in fifth grade.

448
00:46:01,560 --> 00:46:04,710
Right. 99% of them would have dengue fever.

449
00:46:06,870 --> 00:46:13,140
But now, like I also do, these big studies on stars code to write and Nicaragua.

450
00:46:13,590 --> 00:46:19,829
Still, don't worry about self-selection bias that much either because the rates were so high or people didn't do that much to protect themselves.

451
00:46:19,830 --> 00:46:28,710
I'm not sure. But like basically everybody, almost everybody, there were a lot of people got to come to in the first year, year and a half.

452
00:46:29,430 --> 00:46:37,200
But here I also have a study called I Also, which is Immunity Associated Research CO two and all the first participants.

453
00:46:37,200 --> 00:46:41,549
It was really interesting. We were enrolling in 2020 like pre vaccine, right?

454
00:46:41,550 --> 00:46:48,000
And the people who are willing to be in the study were mostly either or we we were trying to get people who are working in person,

455
00:46:48,600 --> 00:46:53,579
but people were very concerned about kind of the risk of going in for the extra medical interaction.

456
00:46:53,580 --> 00:47:01,010
So people who were in medical fields were really comfortable with it, you know, so they were much more likely to say yes than other groups.

457
00:47:01,010 --> 00:47:10,410
Sure. They're also qualified for the study. And so then, you know, a little bit later, as we started getting kind of into vaccination,

458
00:47:11,130 --> 00:47:15,660
still a lot of people were super hesitant to be in the study if they didn't yet qualify to be vaccinated,

459
00:47:15,660 --> 00:47:17,190
because we kind of opened it up to everybody,

460
00:47:17,190 --> 00:47:24,159
regardless of whether they worked on campus, in person or not during the pandemic, kind of thinking like, well,

461
00:47:24,160 --> 00:47:29,430
all the higher risk people have now been vaccinated, so we need to get all these other people into the study, right.

462
00:47:30,060 --> 00:47:40,860
And then at a certain point, once vaccination became really, really available to the entire population, like I think everybody or not everybody,

463
00:47:40,860 --> 00:47:46,260
a lot of people are going into my study were doing it because they were actually kind of hyper vigilant and really careful.

464
00:47:46,590 --> 00:47:50,070
And so you can almost see, like if you look at the behavior patterns,

465
00:47:50,340 --> 00:47:56,010
you can see differences in individuals in the study based on them self-selecting

466
00:47:56,010 --> 00:47:59,309
to participate in the study based on what was occurring with the disease.

467
00:47:59,310 --> 00:48:04,200
So anyways, I used to think that for at least the type of diseases I study,

468
00:48:04,200 --> 00:48:09,930
which are ones that you typically cannot avoid forever or cannot avoid for very long,

469
00:48:11,790 --> 00:48:17,399
I used to think I didn't have to worry about it too much, but certainly with with COVID, we had to worry about that.

470
00:48:17,400 --> 00:48:28,950
I saw self-selection bias a lot. One of the things that we did to to kind of deal, well, like the best thing we could do to kind of deal with that.

471
00:48:28,950 --> 00:48:34,050
It's hard to measure for people that aren't enrolling or a study what their risk taking behaviors are.

472
00:48:34,740 --> 00:48:39,389
But one of the things that we did was we tried to get as much information from the university sort of role in the study.

473
00:48:39,390 --> 00:48:44,310
You had to be a university employee, you could be a grad student. Just you could be a professional student,

474
00:48:44,310 --> 00:48:51,600
but you had to be paid by the university or working in the hospitals in some way if you weren't being paid like medical students, for example.

475
00:48:54,240 --> 00:48:59,250
So we actually kept careful track of everybody that we invited to participate in the study.

476
00:48:59,250 --> 00:49:02,340
We enrolled by email, we got information on them.

477
00:49:02,340 --> 00:49:09,660
So we got like their job title, how old they were, where they worked on campus, you know, their sex,

478
00:49:09,990 --> 00:49:16,680
to try to figure out if we could kind of at least adjust a little bit for these differences and uptake of the study.

479
00:49:17,190 --> 00:49:20,370
But there are things that you can do to try to deal with that.

480
00:49:20,640 --> 00:49:25,140
There are other systems, like a lot of people offered differing incentives.

481
00:49:25,140 --> 00:49:30,510
We weren't allowed to offer incentives. But this kind of lottery incentive basis, right.

482
00:49:30,510 --> 00:49:41,969
To try to equal out like and the incentives you're offered are actually based somehow on what your probability of enrolling a study in a study is,

483
00:49:41,970 --> 00:49:45,990
which I find kind of interesting anyways. Okay, so there you go.

484
00:49:45,990 --> 00:49:49,740
Self-Selection a problem in all studies.

485
00:49:51,660 --> 00:49:56,430
All right, healthy worker effect. We'll go over this and then we'll take a break.

486
00:49:57,390 --> 00:50:04,650
So the healthy worker effect is that relatively healthy people remain in the workforce while those that are less healthy leave the labor force.

487
00:50:06,390 --> 00:50:14,070
In addition, healthier or sicker individuals may be systematically selected into or out of a particular industry, right?

488
00:50:15,030 --> 00:50:20,660
The type of self-selection bias that occurs before subjects are identified for study, right?

489
00:50:20,670 --> 00:50:27,360
But it's still selection bias and it's the selection bias is going to be very important in occupational epidemiology.

490
00:50:28,410 --> 00:50:36,260
So an example of a healthy worker effect is a retrospective study done to assess the effect of wood dust exposure in North Carolina,

491
00:50:36,270 --> 00:50:41,669
furniture workers on respiratory disease mortality rates.

492
00:50:41,670 --> 00:50:45,130
So they compare furniture workers to the. A general North Carolina population.

493
00:50:45,640 --> 00:50:48,910
They're going to match on age, sex and race. Right.

494
00:50:49,270 --> 00:50:54,100
And then they find that virtual workers have lower mortality rate than the general state population.

495
00:50:55,060 --> 00:51:01,930
Right. This could be due to a healthy worker effect because they're the comparison population,

496
00:51:01,930 --> 00:51:05,620
which is the general population, is going to include unemployed people.

497
00:51:06,040 --> 00:51:15,400
Right. Or partially employed people who maybe were selectively eliminated from the workforce because of poor health or high risk of becoming ill.

498
00:51:16,120 --> 00:51:17,769
And so you get a negative bias there.

499
00:51:17,770 --> 00:51:24,790
You'll see this bias like there were a bunch there are a bunch of studies of miners, other high risk groups where you see that strong bias, right?

500
00:51:24,790 --> 00:51:29,529
As people start to get sicker, they then drop out of that industry.

501
00:51:29,530 --> 00:51:32,770
That like has a big toll on their health. Right.

502
00:51:33,040 --> 00:51:36,820
And so you're selecting for these healthier individuals.

503
00:51:38,880 --> 00:51:46,260
All right. So with that, let's take a ten minute break and start back up at 1104.

