1
00:00:18,610 --> 00:01:59,719
What's. Okay.

2
00:01:59,720 --> 00:02:08,830
Good afternoon. Let's get started. So I well, we're a little bit for the sort of stabilization of the enrollment.

3
00:02:08,860 --> 00:02:17,660
I, I know some of your trying to see whether or not you like to take a course were not that I what I well

4
00:02:17,930 --> 00:02:24,909
basically I want to like sign up the groups because as I said that this course is project based.

5
00:02:24,910 --> 00:02:28,100
I want to see a lot of the group face to work.

6
00:02:28,100 --> 00:02:35,299
So I mean, this week it may not be very realistic to form groups and probably we can do a starting

7
00:02:35,300 --> 00:02:39,430
next week or so when people decide whether or not they want state class or not.

8
00:02:39,440 --> 00:02:46,240
Right. So anyway, that's one thing that I want to give you a sort of hazard.

9
00:02:46,850 --> 00:02:54,260
What do we need to do next form? My group and I contact Loyal and she took a course.

10
00:02:55,610 --> 00:03:06,800
She's current students to a course last year. She is very familiar with data capture and so I asked her to come here to give a ten minute presentation

11
00:03:07,190 --> 00:03:13,940
how she did for the data capture and how she sort of download data and process the data from that,

12
00:03:13,940 --> 00:03:20,960
you know, some popular pop like public health savings sort of database or website.

13
00:03:21,530 --> 00:03:28,880
And she could now make it Tuesday next week that she will come to talk about sort of in a lecture.

14
00:03:29,390 --> 00:03:32,590
So I think that's very essential thing that, you know,

15
00:03:32,630 --> 00:03:43,520
we need to work on the data capture and through which we should have shared responsibility in this course.

16
00:03:43,520 --> 00:03:44,749
Because, you know,

17
00:03:44,750 --> 00:03:57,500
the yesterday there was a big news about the authorization of new variants of vaccination with new variant from for the emergency use by FDA.

18
00:03:58,040 --> 00:04:01,759
So we can in the next three months or so,

19
00:04:01,760 --> 00:04:11,059
we can follow the sort of vaccination data and see how how many people are going to take

20
00:04:11,060 --> 00:04:19,070
the new type of the vaccination with the new variants and how that will be possible,

21
00:04:19,310 --> 00:04:24,740
effective to, you know, reduce number of cases or hospitalization or so on.

22
00:04:25,130 --> 00:04:33,500
So we're in this sort of a nice sort of timely situation where we can, you know, start to track that data.

23
00:04:33,500 --> 00:04:38,569
But of course, the data are fresh. You know, it's not all old data like data last year.

24
00:04:38,570 --> 00:04:43,969
So we can really track the new data coming and do a lot of timely analysis of

25
00:04:43,970 --> 00:04:49,790
the the new data for this new vaccination opportunity for the senior people.

26
00:04:49,790 --> 00:04:55,670
Right? So like, I think there's still quite a strong interest among the senior people who want to have

27
00:04:56,180 --> 00:05:01,880
some kind of additional protection by taking the vaccination with the new variant.

28
00:05:02,720 --> 00:05:06,709
So, so that's something really like when I saw that news, I say, great,

29
00:05:06,710 --> 00:05:13,010
that will be is really something we can investigate of you through this course in the fall semester.

30
00:05:13,520 --> 00:05:16,819
So Loyola will come to share her experience,

31
00:05:16,820 --> 00:05:30,370
how data was captured last last year and some of the data purpose processing code and I developed and they sort of refined to to do that data.

32
00:05:30,830 --> 00:05:37,400
It's not just downloading and there's additional step that it prepared data to analyze the data.

33
00:05:38,600 --> 00:05:46,819
So that's something she could share with you. And also data cleaning is quite essential.

34
00:05:46,820 --> 00:05:50,750
And there are some kind of misalignment of our, for example,

35
00:05:50,750 --> 00:06:01,700
age group that data from Michigan Department of Public Health has a different sort of categorization of grouping of age groups versus CDC.

36
00:06:01,970 --> 00:06:15,110
Okay. And so there is a little bit sort of data harmonization step by step in addition to data cleaning and so that we need to deal with it.

37
00:06:15,110 --> 00:06:18,560
And also we need to do a little bit better transformation.

38
00:06:18,830 --> 00:06:26,270
Sometimes instead of working on absolute number of cases, we can work on proportions like, you know, so you know,

39
00:06:26,270 --> 00:06:40,220
that is it's more sort of like appropriate or reflective to actually the other ongoing infections situation.

40
00:06:40,820 --> 00:06:48,990
When you adjust for the population size where you know the size of subgroups like aged 60 or older, right?

41
00:06:49,010 --> 00:06:58,590
So, so something like some variable transformation is required in part of data cleaning where data quality control and as I said that this.

42
00:06:58,970 --> 00:07:07,879
Reporting is very severe issue with data captured by CBC or other sort of public databases.

43
00:07:07,880 --> 00:07:10,430
And so so we need to I mean,

44
00:07:10,430 --> 00:07:22,400
I don't know if there's any good idea nowadays in the literature how we're going to find a way to model this, to quantify this gap.

45
00:07:22,550 --> 00:07:27,290
Right. So so underreported issue, how much of the reporting is going on?

46
00:07:27,290 --> 00:07:34,720
And that certainly evaluates over time. And how do you how we could find some way to really capture that.

47
00:07:34,730 --> 00:07:41,959
So it's a very, very tough problem without adjusting for that kind of bias in the actual data.

48
00:07:41,960 --> 00:07:50,210
It's certainly a problematic situation to really make a solid conclusion.

49
00:07:50,210 --> 00:08:01,220
So this sort of sampling buys or I'm only reporting if it's part of severity of data quality, but we get a data from the public domain.

50
00:08:01,220 --> 00:08:13,010
So so there are a lot of issues we will talk about over time in and it's not only modeling a perceived there are other data quality issues.

51
00:08:13,550 --> 00:08:23,420
And if you look at the statistics nowadays, when you take a 6 to 1 six or to a 650 or six feet one where order statistic courses where

52
00:08:23,420 --> 00:08:32,420
we do not really think about the data management or data quality as part of the modeling.

53
00:08:32,780 --> 00:08:41,580
But nowadays, because we have access to a lot of observational data, we do a lot of statistical analysis of, you know,

54
00:08:41,660 --> 00:08:50,900
of observational data where data management and data quality become a very essential things that we have to deal with.

55
00:08:50,930 --> 00:08:54,290
I mean, confounding control is, well, you know,

56
00:08:54,290 --> 00:09:02,989
very well known our sort of task at work duty we need to do when we do data sets but the data our students

57
00:09:02,990 --> 00:09:12,410
with or we also face when we when you have data like data coming from observations like for example,

58
00:09:12,410 --> 00:09:21,319
some data are coming from different sources like you have vaccinated, you only have vaccine vaccination data coming from CDC.

59
00:09:21,320 --> 00:09:31,610
You don't and you don't have hospitalization data from one source and you will have observational data of hospitalization from other source.

60
00:09:31,970 --> 00:09:44,600
So how do we merge them together? How do you come for the possible heterogeneity or discrepancies across different data sources at that thought,

61
00:09:45,170 --> 00:09:50,180
how do you model that possible optionality as part of model specification?

62
00:09:51,410 --> 00:09:55,549
So it models the choices we model to analyze data.

63
00:09:55,550 --> 00:09:59,150
So data become very interesting in many ways.

64
00:09:59,510 --> 00:10:06,139
So when you do this kind of data analysis, we need to keep those things in mind.

65
00:10:06,140 --> 00:10:09,709
So it's quite important to do that.

66
00:10:09,710 --> 00:10:19,730
And from a public health point of view in terms of some unique communication and so dissimulation of resolver,

67
00:10:19,730 --> 00:10:23,870
almost standard data, data visualization becomes very essential.

68
00:10:23,870 --> 00:10:30,260
And we visualize data not, you know, only just look in the summary statistic, meaning variance, standardization.

69
00:10:30,650 --> 00:10:35,120
We look we need to visualize patterns and dynamics.

70
00:10:35,120 --> 00:10:47,460
And so we will use a lot of the two boxes know developed in the context of spatial data analysis and time of data analysis to visualize data.

71
00:10:47,480 --> 00:10:57,340
Okay. So I will give you a couple of examples where I think New York Times has done a fantastic job to visualize data,

72
00:10:57,650 --> 00:11:15,140
make the sort of our COVID situation and very intuitive and kind of very plant sort of form to communicate the situation of pandemic general readers.

73
00:11:15,500 --> 00:11:22,010
So it's very important to see that data before we put the data into sufficiently the model.

74
00:11:22,370 --> 00:11:23,989
But this is a level course.

75
00:11:23,990 --> 00:11:37,970
Certainly we need to learn something more sophisticated to use the model data and to identify key features from the data than just visualization.

76
00:11:38,060 --> 00:11:47,180
Okay. So and of course that this all the confounding factors and and health condition that

77
00:11:47,960 --> 00:11:56,060
a lot of you know the all the those things are quite relevant in the data analysis.

78
00:11:58,320 --> 00:12:06,020
Well, I just wanted to give a quick sort of a display about spatial data visualization.

79
00:12:06,030 --> 00:12:10,050
I think The New York Times did excellent job, as I already mentioned, too.

80
00:12:10,470 --> 00:12:14,680
I mean, it's amazing to see that keep updating this every day.

81
00:12:14,720 --> 00:12:22,780
And I don't know how much resources that this New York Times has put into this effort.

82
00:12:22,800 --> 00:12:26,970
It's amazing to see that they are updating this on a daily basis.

83
00:12:26,980 --> 00:12:33,959
Like we start to I start to visit this website about three 2020 when they start to

84
00:12:33,960 --> 00:12:41,400
have the just launched this website and just follow this website periodically.

85
00:12:41,400 --> 00:12:45,300
And it's amazing to know that they're still updating this website.

86
00:12:46,740 --> 00:12:48,770
So why prepare this size?

87
00:12:48,780 --> 00:13:03,689
I had this capture of their most app, most recently updated sort of all these data visualization or maps or maps as of August 29th.

88
00:13:03,690 --> 00:13:10,469
And so they now have slightly modified sort of forms of display the data,

89
00:13:10,470 --> 00:13:19,020
but basically looked at hot spot number of hospitalizations that test positive and ICU and and deaths

90
00:13:19,020 --> 00:13:24,179
and nobody's I should mention that that's probably is more accurate than that the number of confirmed

91
00:13:24,180 --> 00:13:32,130
cases as I already mentioned that because availability of home testing kits right so people test

92
00:13:32,220 --> 00:13:40,680
positive that they do not report to any process and then people basically would just stay at home and,

93
00:13:40,890 --> 00:13:51,750
you know, just, you know, recover and so on. And so that there's a big underreporting issue for the number of infections or number of cases.

94
00:13:52,890 --> 00:14:00,719
But that is certainly a lot more accurate because when there's the mortality is somewhat captured at a

95
00:14:00,720 --> 00:14:09,840
population level and unless there is some misclassification issue going on that that's due to COVID 19 or not,

96
00:14:10,020 --> 00:14:19,350
I mean, there may be a little bit sort of potential risk classification here, but every deaths will be recorded.

97
00:14:19,620 --> 00:14:31,769
I mean, this in the system. But whether or not this test should be, you know, regarded, of course, the bias that there may be that misclassification,

98
00:14:31,770 --> 00:14:38,430
but this data certainly will be a lot more accurate and will be, you know, captured.

99
00:14:39,240 --> 00:14:49,320
So I think that when we do the data analysis, I think the the number of deaths will be a lot more, I will say,

100
00:14:49,620 --> 00:14:57,479
of what's worth the in actual model building that number of cases for this year and the beginning.

101
00:14:57,480 --> 00:15:05,820
Right, because we have limited number of confirmed cases and we don't have this people have no

102
00:15:05,820 --> 00:15:14,520
had no other choice but going to test centers or hospitals to fully test most of the,

103
00:15:14,520 --> 00:15:24,260
you know, confirmed cases were captured. But since the introduction to the at home testing kit, people just have their test at home.

104
00:15:24,270 --> 00:15:32,520
And no matter what, they don't typically report to the U.S. Center database or something like that.

105
00:15:32,520 --> 00:15:44,190
So, so so I think that for the data of 2022 and that's probably more hospitalization excuse it more accurate than the number of cases,

106
00:15:44,190 --> 00:15:54,810
but we can look at. And so so here is the one map that we generate that basically as of August 29th.

107
00:15:55,140 --> 00:16:03,290
So this is a heatmap of the country where they have this the scale of the of the magnitude.

108
00:16:03,300 --> 00:16:10,260
Right. So basically look at average daily cases per 100,000 people in the past a week.

109
00:16:10,710 --> 00:16:23,880
Okay. So so you can see the very, very intuitive decision to find in all the hotspots where we can clearly see that this Ohio Valley is from there.

110
00:16:23,880 --> 00:16:31,830
You know, here you can see that here you do have darker colors, right?

111
00:16:31,860 --> 00:16:40,709
So compared to other parts of that, you have a little bit of of things, more active things going on.

112
00:16:40,710 --> 00:16:45,000
You can see that our PAs are a little bit lighter than this.

113
00:16:45,000 --> 00:16:57,840
So by visualization, you can quickly spot out some of regions here suddenly from this Virginia, Kentucky, Tennessee, Mississippi, Alabama.

114
00:16:58,740 --> 00:17:08,480
I live on the south and part of Ohio. This past autumn, we would have would have some, you know, quite a bit activity.

115
00:17:08,680 --> 00:17:13,649
Right. So it's and there's a little bit like from North Dakota to Texas.

116
00:17:13,650 --> 00:17:16,930
This region is a little bit in the past week.

117
00:17:16,980 --> 00:17:25,440
Right. More active than other places, although this is very, very clear to you to see what was happening recently.

118
00:17:25,950 --> 00:17:32,249
Oh, it's. This isolates far flung fun here and here.

119
00:17:32,250 --> 00:17:34,770
But overall, you see this space,

120
00:17:34,770 --> 00:17:47,060
you sort of continuum across all the map that immediately you visualize what are the possible regions that may need more attention from you?

121
00:17:48,590 --> 00:17:55,160
Wealth loss. And if you want to travel from Ann Arbor to attend a conference.

122
00:17:55,700 --> 00:17:59,210
Okay, maybe we have in our next year. Nashville, Tennessee. Oh, my God.

123
00:17:59,360 --> 00:18:04,489
What's going on that you really see over here? I mean I mean, just you can visit the map.

124
00:18:04,490 --> 00:18:08,959
Should you have more costume of wear masks?

125
00:18:08,960 --> 00:18:12,050
I'm not seeing your. You should not going to travel.

126
00:18:12,170 --> 00:18:16,040
What were you trying to say? Also, I'd be more careful.

127
00:18:16,040 --> 00:18:19,429
Or wear a mask or wear sanitizer. My hands.

128
00:18:19,430 --> 00:18:28,669
When you travel to Nashville for a conference, for example, that gives you some kind of implication in terms of your behavior or some decision making.

129
00:18:28,670 --> 00:18:39,590
Right. That's something useful. And all this is hospitalization, although you can see that there are a lot of more activities in this region.

130
00:18:40,460 --> 00:18:48,230
But when you look at hospitalization data, right, this is, you know, the COVID 19 patients per 100,000 people.

131
00:18:48,800 --> 00:18:53,180
And so you can see that there's lots.

132
00:18:54,390 --> 00:19:02,670
A lot of standing out right in compared to other countries.

133
00:19:02,940 --> 00:19:14,500
Okay. So there is a little bit going on here with West Virginia and Kentucky and there are some spots here.

134
00:19:15,150 --> 00:19:19,709
You're here and the. Yeah.

135
00:19:19,710 --> 00:19:23,010
So so I don't know how this map is created.

136
00:19:23,010 --> 00:19:32,430
I don't have access to the data if this is based on the county or based on hospitals, if this data like because they're talking about fluoridation,

137
00:19:32,880 --> 00:19:38,250
if this so this data is coming from location hospital,

138
00:19:38,250 --> 00:19:48,270
then you know that you may not have all the hospitals that are having the capacity of treating COVID patients, infectious disease patients.

139
00:19:48,630 --> 00:19:54,720
So that could be a little bit more sort of concentrated or more sort of spots

140
00:19:55,080 --> 00:20:00,659
like scattered in some isolated spots because of the location of hospitals.

141
00:20:00,660 --> 00:20:09,149
I don't know if I'll do that. That's like those like the from like general counties or level spread or is coming from

142
00:20:09,150 --> 00:20:17,850
actual hospitals because you can be match that about your geographical locations.

143
00:20:17,850 --> 00:20:25,470
Hospitals are a lot more sparse and isolated locations.

144
00:20:25,860 --> 00:20:38,309
That could be the reason it's. Also around here, although you have more ran out of this cases in this region,

145
00:20:38,310 --> 00:20:42,720
but the hospitalization is more concentrated because of location of hospital.

146
00:20:43,170 --> 00:20:49,950
But anyway, you can see that there are something going on here as somewhat correct, but the correlation is not that strong.

147
00:20:49,950 --> 00:20:54,930
But you can see some of the things going on here a little bit.

148
00:20:57,180 --> 00:21:12,450
And also, you can look at the vaccination because this is so far the most effective way of inter introducing that immunity to to the population.

149
00:21:14,250 --> 00:21:22,080
Now you can see that this is the percentages, you know, this completion of.

150
00:21:25,890 --> 00:21:34,530
And you can see the map and where, how, how, how heterogeneous the country is at the moment.

151
00:21:34,980 --> 00:21:36,240
You saw those.

152
00:21:36,690 --> 00:21:47,970
Here, here, here, here are far more compliant being covered to this part where you see a little bit more activities as our issue and the here as well.

153
00:21:48,000 --> 00:21:52,200
So there is some kind of correlation.

154
00:21:52,440 --> 00:21:55,320
You can see just by eyes, you know,

155
00:21:55,950 --> 00:22:07,790
sort of some visualization from or you you some somehow your sense out there might be some relationships about this.

156
00:22:07,800 --> 00:22:13,800
But the question here is, as the discussion evolves, that is, how do you quantify this precisely?

157
00:22:14,670 --> 00:22:20,489
Okay. So you can have your first sense from sort of the visualization.

158
00:22:20,490 --> 00:22:25,200
There might be some potential, of course. But how you quantify this is this correlation.

159
00:22:25,690 --> 00:22:34,769
It is purely due to randomness or if there is a established underlying dependance between

160
00:22:34,770 --> 00:22:43,140
the recent vaccination versus number of cases or nominal hospitalization and also death.

161
00:22:43,780 --> 00:22:46,830
Right. Per capita. Okay.

162
00:22:46,840 --> 00:22:54,670
So that's up. So this is the overall situations and this is that's per capita.

163
00:22:54,720 --> 00:22:59,970
So you can see that where are the regions?

164
00:23:00,300 --> 00:23:03,330
You see more that's per capita.

165
00:23:03,460 --> 00:23:05,490
So. So in all.

166
00:23:08,900 --> 00:23:21,950
Basically those are very important visualizations that gives you some kind of ideas that how we're going to move to really establish your hypotheses,

167
00:23:22,550 --> 00:23:29,980
to establish the direction of research or establish something like you want to invest, right?

168
00:23:30,680 --> 00:23:43,340
So not only the vaccination but also the government initiate some social distancing and you know, and facemask use and so on.

169
00:23:43,370 --> 00:23:55,670
So for us, that should be also be part of that. Preventive measures of people are, you know, follow or take and so on.

170
00:23:56,060 --> 00:23:57,630
So, so anyway, I,

171
00:23:58,070 --> 00:24:09,530
I just tell you that data visualization in this case is very important because data are then that data are moving all the time and you

172
00:24:09,530 --> 00:24:22,970
really need to find a very effectively to display the data so that you can see some first sort of first level of evidence by visualization,

173
00:24:23,330 --> 00:24:30,230
what things you might be interested to investigate. So that's quite an amazing thing to see.

174
00:24:32,390 --> 00:24:37,370
So of course, you can do the side by side comparison that would be more convenient for you to see.

175
00:24:37,830 --> 00:24:44,830
You know what? What if you want to study the relationship of vaccination, the percent the percentage of fully that full,

176
00:24:44,870 --> 00:24:51,440
full vaccination and that's per capita you you wonder if this two maps of correlate

177
00:24:52,580 --> 00:24:58,190
you're not just doing external why right so you do core peers encouraging external eye.

178
00:24:58,190 --> 00:25:04,069
But now I gave you two maps, right? I asked you to give me a correlation of this.

179
00:25:04,070 --> 00:25:08,870
We have about 4007 countries in United States.

180
00:25:08,870 --> 00:25:11,930
Right. So? So so how do you correlate this to data?

181
00:25:11,990 --> 00:25:15,830
Because this is general data, right? And this general by Nano.

182
00:25:15,860 --> 00:25:19,040
So how do you correlate this to things?

183
00:25:19,250 --> 00:25:27,970
Right. And think about the spatial dependance and the temporal sort of overfishing of this spread.

184
00:25:27,980 --> 00:25:37,790
How do you do this correlation calculation? Right. So that's a much harder problem, death or task than just doing pure Pearson correlation.

185
00:25:38,480 --> 00:25:43,190
And also, here's the current hospitalization.

186
00:25:43,190 --> 00:25:53,660
This is the current sort of percentage of residents that are fully vaccinated of this two things of correlated or not.

187
00:25:54,770 --> 00:26:01,550
Okay. So can come up with a legitimate p value for for this for this correlation.

188
00:26:02,150 --> 00:26:05,360
Right, right. So so that's how our job essentially.

189
00:26:05,360 --> 00:26:09,559
Right. People can display data, but we can come to a scientific conclusion.

190
00:26:09,560 --> 00:26:16,040
You need to find some way to justify that. This correlation is not purely due to sampling randomness.

191
00:26:16,460 --> 00:26:22,760
There is a truly underlying relationship between this two variables.

192
00:26:22,820 --> 00:26:33,320
Okay, so you can see that, that the data with face are quite a complex and as, as, you know, good data and challenging data.

193
00:26:33,320 --> 00:26:39,680
But we need to figure out we can figure out ways to really study those data that are very,

194
00:26:39,680 --> 00:26:44,930
very important and of course, nowadays and to answer some of the important questions.

195
00:26:46,850 --> 00:26:50,140
So now if we really want to kill this noise debate,

196
00:26:50,220 --> 00:26:59,300
to kill this randomness and come up with some kind of valid statistic, we need statistic to back up.

197
00:26:59,720 --> 00:27:05,150
So kind of statistic models where whatever the two boxes that you would use,

198
00:27:05,450 --> 00:27:15,260
tell us what's going on and what is going to happen basically based on the happiness or this historical data, you know, and so on.

199
00:27:15,910 --> 00:27:23,389
So, so this is something like everybody would ask when we're talking about pandemic, right?

200
00:27:23,390 --> 00:27:28,969
So what has what's happening now and what's going to happen?

201
00:27:28,970 --> 00:27:35,150
But certainly. A lot of people are curious about this.

202
00:27:35,150 --> 00:27:38,840
And can we use data to tell? Right. So that's something.

203
00:27:39,590 --> 00:27:49,530
So one thing in the first homework, I want to you write a short essay where you identify one or two questions you like to invest in, right?

204
00:27:49,550 --> 00:27:58,640
So different people have a different exposure to different types of articles or data or experience and so on, the stories and so on.

205
00:27:58,640 --> 00:28:08,360
So for us, I think you have your own sort of, you know, experience or ideas of interest, what you want to invest, right?

206
00:28:09,500 --> 00:28:14,290
So I asked you like, what are a couple of questions you are interested in?

207
00:28:18,200 --> 00:28:28,670
Oh, my. So suggesting how to estimate, you know, causal effect of face mask or, you know, something you like to even ask.

208
00:28:29,090 --> 00:28:33,290
Right. So I asked you to write a short, maybe one picture.

209
00:28:33,290 --> 00:28:38,929
So just tell me that what you like to do. We do a little bit tailored to sort of project,

210
00:28:38,930 --> 00:28:49,759
sort of assigned where you form a group and you can talk to your sort of teammates that so I can while to important things

211
00:28:49,760 --> 00:29:00,590
you want to investigate together as a team so so yeah that's something before you actually see actually the data you you

212
00:29:00,860 --> 00:29:10,939
you could have some kind of interests that will drive you to really into data collection model choice and some of the statistical

213
00:29:10,940 --> 00:29:20,540
methods that you like to really learn and invest your time for to try to get some meaningful answers to any of this.

214
00:29:21,080 --> 00:29:31,190
And last year, there was one group who did this vaccination and, uh.

215
00:29:34,780 --> 00:29:41,800
Well, the state of Michigan. And this paper was submitted to Spatiale, a journal called Spatial Epidemiology.

216
00:29:42,190 --> 00:29:51,020
So there was a one group project that decided to really publish a paper, all of that from that project.

217
00:29:51,070 --> 00:29:52,330
So if you want,

218
00:29:52,330 --> 00:30:04,690
I think that we can also follow the the new data after this new sort of vaccination was just authorized by FDA for emergency use yesterday.

219
00:30:04,720 --> 00:30:11,380
So so something you think about it, right? Or I don't want to waste your time if you really invest your time, your effort.

220
00:30:11,740 --> 00:30:18,490
I want to you have something that you are proud of that you also want to send me to for publication.

221
00:30:18,520 --> 00:30:29,770
I think this is a very interesting topic. And then if you believe some spatial modeling, causal inference methods that are really more advanced,

222
00:30:29,770 --> 00:30:33,850
that could sort of the method people use in their publication already.

223
00:30:34,240 --> 00:30:40,840
So we offer something additional to general sort of descriptive statistical analysis.

224
00:30:41,050 --> 00:30:46,080
So that's an interesting learning journey, right?

225
00:30:46,100 --> 00:30:50,320
So what were some something like you're motivated to do?

226
00:30:51,970 --> 00:30:55,240
Questions? Sounds good. Okay.

227
00:30:58,900 --> 00:31:05,709
Just want to talk to you about this Maldon part, because there's a huge level.

228
00:31:05,710 --> 00:31:10,390
Of course, I really want you to see some of the models people have to use in this field.

229
00:31:13,920 --> 00:31:17,700
So I would talk about some models for your fashion designer.

230
00:31:19,140 --> 00:31:26,520
And I shall cross mathematical because we are going to talk about something beyond mathematical models.

231
00:31:26,620 --> 00:31:32,310
Okay, finally. So I'd like to give you a quick introduction to models.

232
00:31:32,400 --> 00:31:40,330
We will work on a lot of details about how we are going to do selection, how to do prom,

233
00:31:40,350 --> 00:31:45,510
dress, the meeting, and how to do things, prediction, using the ball and so on.

234
00:31:45,540 --> 00:31:51,160
But let me just give you a overall framework of modeling what you fashion.

235
00:31:51,180 --> 00:31:56,520
This is before we go into detail of, you know, different types of models.

236
00:31:59,050 --> 00:32:05,950
So talking about modeling, I think this is now new to you and you have to actually I turn to you.

237
00:32:06,190 --> 00:32:10,749
So that's that's basically what you see from this display to date.

238
00:32:10,750 --> 00:32:15,130
I like maps here. Maps in the maps, you have a lot of data collected.

239
00:32:15,730 --> 00:32:19,510
That's the reality. Okay, so what do you see?

240
00:32:19,990 --> 00:32:31,440
But do you know that there are some dumb boys and a lot of, you know, things that that you need to really work on to track right.

241
00:32:31,510 --> 00:32:38,620
To to really figure out the key features. The features that you can't establish some meaningful conclusions.

242
00:32:38,660 --> 00:32:41,740
Right? So so that, you know, you like when you see the data,

243
00:32:42,250 --> 00:32:51,639
one thing you want to do here is really try to define some concepts or some framework where you can really

244
00:32:51,640 --> 00:33:01,570
capture the most important dynamics or futures or components that can help us to understand what's going on.

245
00:33:02,050 --> 00:33:06,460
I mean, it machine learning. People always say, okay, here's data.

246
00:33:06,940 --> 00:33:11,530
What is your generative model, right? What is your generating model?

247
00:33:11,530 --> 00:33:22,440
The generating model is the that oh, you believe this is actually the mechanism that generate data plus a lot of noise in the way of data generation.

248
00:33:22,450 --> 00:33:29,740
So what is the most fundamental structural framework or mechanism that generated data?

249
00:33:30,100 --> 00:33:41,230
So from this site, the box to this box, you're really trying to conceptualize the the underlying mechanism.

250
00:33:41,410 --> 00:33:47,979
What what are the, the key things that are really responsible for the data.

251
00:33:47,980 --> 00:33:55,360
I see. Right. So you do an abstraction and we do this conceptualization.

252
00:33:55,360 --> 00:33:59,290
We're creating your framework or making it mechanistic model.

253
00:33:59,680 --> 00:34:06,790
You may, you know, make mistakes, right? So, so, so there should be a kind of collaboration between these two.

254
00:34:06,790 --> 00:34:12,729
Okay, I brought this from here. Here, but actually what the multiple rounds of this loop, right?

255
00:34:12,730 --> 00:34:23,709
You do this data put into a mechanism, always say, oh, this model is not really something, you know, compatible with my data.

256
00:34:23,710 --> 00:34:29,440
We're have a goodness good feeds or something or maybe some missing components.

257
00:34:29,800 --> 00:34:34,730
And they come back to, you know, a cat.

258
00:34:37,060 --> 00:34:43,330
To give you better sort of compatibility or interpretation of your data, right?

259
00:34:44,080 --> 00:34:50,380
As always, this is a multi loop effort, not just one.

260
00:34:50,410 --> 00:34:53,230
Okay, here is the data here. Small and back. That's it.

261
00:34:53,650 --> 00:35:02,160
You know, it's not that for this compact system, you'll always do multiple rounds of effort, you know, obstruction, interpretation or calibration.

262
00:35:02,170 --> 00:35:07,809
A problem for the calibration here. So obstruction, calibration, calibration and obstruction.

263
00:35:07,810 --> 00:35:15,920
And you just constantly want to find them all. And you can see that even though you have the mechanistic elements in your model,

264
00:35:16,720 --> 00:35:22,020
the elements can also time of year and depends on what you're going to use.

265
00:35:22,030 --> 00:35:32,690
For example, at the beginning of pandemic, you'll never see all of the vaccination will be a component that it's.

266
00:35:34,660 --> 00:35:40,360
Mechanism because usually it takes about, you know, 10 to 10, 20 years.

267
00:35:40,690 --> 00:35:44,660
You work to develop the vaccine, right, for an infectious disease.

268
00:35:44,680 --> 00:35:50,300
I wearing a very, very lucky situation. The vaccine was developed this way.

269
00:35:50,620 --> 00:35:57,600
But, you know, because of all the advanced technology, the effort of whole scientific community.

270
00:35:57,610 --> 00:36:07,270
Right. However, and the very beginning of this of the outbreak of the COVID 19, nobody knew when this vaccination would be.

271
00:36:07,630 --> 00:36:16,750
So when you establish your conceptualization where your model to capture data, you will not for the mass vaccination as part of the element.

272
00:36:16,960 --> 00:36:21,940
But it was a very, very one that will basically change the whole dynamics of the infection.

273
00:36:22,690 --> 00:36:34,270
But later on when this becomes available, then certainly you will revise this by adding their vaccination as very important part of the model.

274
00:36:35,410 --> 00:36:38,680
All that you really need to really go multiple rounds of things,

275
00:36:39,010 --> 00:36:49,150
constantly refining your conceptualization for the for the fourth framework that you use to explain the actuality.

276
00:36:49,920 --> 00:36:58,959
And in this whole thing and I tried to present states a little bit more reckless because nowadays when people talk about this model,

277
00:36:58,960 --> 00:37:06,260
we never pay attention to assumptions because we're serious scientists or data scientists.

278
00:37:06,260 --> 00:37:10,960
Those we are very, very serious. We need to always justify what we're doing.

279
00:37:11,620 --> 00:37:20,500
And so we also say, while the average assumptions that the the method could be applicable or could be a,

280
00:37:21,130 --> 00:37:27,880
you know, good method to use to analyze data, what our limitation, how we're going to validate the methods.

281
00:37:28,090 --> 00:37:38,770
So those things that are we always keep in mind so that we know where are the opportunities for better modeling,

282
00:37:39,100 --> 00:37:46,720
better a knowledge analytics and the better, you know, analysis that you like to do so.

283
00:37:47,110 --> 00:37:57,339
So that's it's always good. Besides the objectives and the model choices, we always ask, what are the indications,

284
00:37:57,340 --> 00:38:10,030
what are the assumptions that are under which we use our methods so that you have clear picture where to have better things,

285
00:38:11,020 --> 00:38:16,150
you know, to to be done or where you can improve whatever things you use.

286
00:38:16,840 --> 00:38:25,880
So, so that's something important. So I will cover this for important components.

287
00:38:26,780 --> 00:38:35,510
So mathematical model is the model that we use to sort of model the the underlying dynamics of the infection.

288
00:38:36,770 --> 00:38:41,150
Typically, this refers to our system of differential equations.

289
00:38:41,600 --> 00:38:48,860
So this is pretty much like the mean. Okay. So you know that it's the first novel since a war.

290
00:38:48,860 --> 00:38:51,950
How the Y you come to you plus is.

291
00:38:54,240 --> 00:38:58,560
Is there being any expectation of the distribution?

292
00:38:58,650 --> 00:39:04,330
Right. So so is this to some extent is a kind of.

293
00:39:07,370 --> 00:39:08,530
This is mathematical.

294
00:39:08,750 --> 00:39:18,020
Of course, here in an interrogation, you want to be the model for the meaning, which is accepted as opposed to you you introduce.

295
00:39:19,960 --> 00:39:25,390
You decide by any way you introduce a model or a model of.

296
00:39:29,750 --> 00:39:34,000
Or why. And this small is a function of your coverage.

297
00:39:34,220 --> 00:39:37,490
Like what? Oh.

298
00:39:37,790 --> 00:39:45,770
This is my central position of my distribution. How is it your position will change if I have different individuals?

299
00:39:45,860 --> 00:39:56,600
You may sound. So this is more deterministic if you consider a sort of deterministic design study.

300
00:39:57,850 --> 00:40:05,830
Would. When we think about the infectious disease mule is a set of differential equations.

301
00:40:06,790 --> 00:40:17,409
It's no longer x transpose. Veda is ordinary differential equations, so its complexity level goes up very much.

302
00:40:17,410 --> 00:40:24,550
And so so it requires a different method to do that because for the neither of which you mean is square, right?

303
00:40:25,210 --> 00:40:33,340
Because it's easy to get estimate the beta. But now I have a mathematical model based on a set of different ordinary differential equations.

304
00:40:33,760 --> 00:40:38,450
Okay. How do you estimate the parameters in the differential equation?

305
00:40:38,500 --> 00:40:42,940
So moves up to another level.

306
00:40:43,620 --> 00:40:52,899
But people have solved this problem. Okay. I just tell you, like how people have been able to solve this problem, estimation problem,

307
00:40:52,900 --> 00:41:03,370
and how we're going to learn the statistical approach and people have developed to solve this complex, dynamic system in terms estimates.

308
00:41:04,070 --> 00:41:10,660
So so that's something. Now, this is actually the mainstream of the university is modeling.

309
00:41:10,660 --> 00:41:12,250
They always use differential equations.

310
00:41:12,820 --> 00:41:24,560
But in reality you're right, the data collection must be subject to a lot of noise, measurement, aerial and the sampling mechanism and so on.

311
00:41:24,580 --> 00:41:37,720
So for us, even you do this, you know, confirmed cases, you have the sort of whatever PCR or human testing kit.

312
00:41:38,080 --> 00:41:42,130
There's always subject to error. Right. There's a randomness going on.

313
00:41:42,610 --> 00:41:49,300
So the classical literature of mathematical model based on differential equations, they only talk about IMU.

314
00:41:50,050 --> 00:41:59,600
Okay. This is absolutely necessary from our statistician point of view.

315
00:42:00,050 --> 00:42:06,800
We always think that you cannot have perfect data. You cannot have a data that perfect fit your differential equation.

316
00:42:07,220 --> 00:42:12,860
There are always some deviations from the system that you want to model.

317
00:42:13,550 --> 00:42:16,580
And so how do you capture that?

318
00:42:16,580 --> 00:42:25,430
How what are distributions? What are how do you characterize the randomness, the uncertainty associated with the data collection?

319
00:42:25,490 --> 00:42:33,020
And how do you explain the deviations of your data points versus actually the differential equation you specify?

320
00:42:33,200 --> 00:42:36,620
So we need statistical models. Okay.

321
00:42:37,070 --> 00:42:43,640
That's basically a something. When we begin with opposite outcome, like if you don't have.

322
00:42:45,790 --> 00:42:51,970
Distribution. How do you use mail? You were M.S. or whatever, the statistical proxies.

323
00:42:52,420 --> 00:43:02,469
And now one thing we are trying to figure out is whether or not the introduction of Noyce into mathematical model was a legitimate,

324
00:43:02,470 --> 00:43:11,040
legitimate thing to do, but also say, why not? I mean, how could you have a perfect model to explain the underlying things?

325
00:43:11,050 --> 00:43:14,500
And so so this is pretty new.

326
00:43:14,500 --> 00:43:24,390
And to the whole infatuated community, they believe there are some noises, but they just don't know how to handle this.

327
00:43:24,400 --> 00:43:31,400
Right. So that's something we can contribute out here and tell them because you call, you add a noise.

328
00:43:31,930 --> 00:43:37,329
There are many ways in statistics we can handle noise and then basically make

329
00:43:37,330 --> 00:43:46,990
your result more of our festival because we have quantification of uncertainty.

330
00:43:47,440 --> 00:43:56,080
Uncertainty. Quantification. So so that at the very end, when you make a prediction, you're not really predicting a single value.

331
00:43:56,890 --> 00:44:00,400
You predict interval or set of values.

332
00:44:00,400 --> 00:44:08,290
Right? With some kind of guaranteed coverage of something like the opens a new door for

333
00:44:09,490 --> 00:44:18,979
statisticians to bring some sort of powerful toolboxes to deal with uncertainty.

334
00:44:18,980 --> 00:44:26,950
You deal with sampling bias to quantify randomness, to quantify uncertainty in the prediction.

335
00:44:29,800 --> 00:44:44,550
And of course, the data naturally, you know, as a socialist tempo, stochastic, you have this sort of evolution involving process, right?

336
00:44:44,560 --> 00:44:49,150
So you have daily data, weekly data and so on, so forth.

337
00:44:49,150 --> 00:44:52,660
So, so, so you have time source data essentially, right?

338
00:44:53,590 --> 00:45:06,160
So that that certainly the tempo stochastic is, is very important to feature as part of data and in the applied mathematics where people, you know,

339
00:45:07,350 --> 00:45:15,009
the differential question to study data, they never they know that they're safe in time,

340
00:45:15,010 --> 00:45:21,459
very functional, but they never thought how do you know, bring this Markov structure.

341
00:45:21,460 --> 00:45:33,940
Because in statistics. Right. And we we know that there are many sort of the ways that we can model this

342
00:45:34,360 --> 00:45:39,729
time dependance where these tempos temporal spasticity using Markov process.

343
00:45:39,730 --> 00:45:47,460
Right so so that's something that's quite important and also of course that you have the spatial stochastic city.

344
00:45:48,070 --> 00:45:56,320
AB Or is different from Detroit there even though under same policy, you know very,

345
00:45:56,320 --> 00:46:07,120
very nearby geographical location there are always some special is regionality is the cost is how do you do that right so that's part of the modeling.

346
00:46:08,230 --> 00:46:18,100
So so we will start this meal and if so and put these two important features the cases stochastic city into the

347
00:46:18,100 --> 00:46:27,880
modeling so that that we can have more sort of trustworthy result as the result of your estimation and prediction.

348
00:46:28,720 --> 00:46:33,920
So this is a architecture we designed for a temple modeling.

349
00:46:34,690 --> 00:46:41,110
And what happens here is so the right one.

350
00:46:41,110 --> 00:46:45,820
Here are the mathematical models. So you have different compartments.

351
00:46:46,630 --> 00:46:58,300
At a given time like today individual will be either you the the population of assessed susceptible of being so simple

352
00:46:58,390 --> 00:47:08,410
individual like me today I probably would in this compartment in this subpopulation I'm accessible to the infection but

353
00:47:08,410 --> 00:47:15,129
you could be a one person could be in the the group of in fact that about it tested positive this morning and this

354
00:47:15,130 --> 00:47:27,160
person will be in this group like in fact it or this person just recovered right so this is the compartment recovered.

355
00:47:27,880 --> 00:47:32,860
So so someone would probably just move out from this group to not recover.

356
00:47:33,370 --> 00:47:37,630
Of course, you could have other subpopulations.

357
00:47:38,140 --> 00:47:44,020
You have 100 individuals could be who could be like divided into different subgroups.

358
00:47:44,410 --> 00:47:47,410
Each person will be one of those subgroups.

359
00:47:47,500 --> 00:47:55,329
Okay, here, I just have three subgroups of susceptible infected to cover or to have more, whichever.

360
00:47:55,330 --> 00:48:00,310
Okay. So this is the underlying structure, you know.

361
00:48:00,460 --> 00:48:06,940
Right? So for another 100,000 individuals, do you actually know who is in which compartment?

362
00:48:06,940 --> 00:48:15,250
You don't know. Right. And you don't know how this structure will evolve to next date.

363
00:48:15,910 --> 00:48:24,219
Okay. You know, that is happening, but you don't have that kind of precise measurement for the entire population.

364
00:48:24,220 --> 00:48:30,430
I mean, an number probably if you ask everybody to do this like COVID test,

365
00:48:31,330 --> 00:48:40,059
which I will spend a lot of money, I guess that's what like some of saving China are trying to do.

366
00:48:40,060 --> 00:48:43,970
Like ask everybody go out to have the test, right?

367
00:48:43,990 --> 00:48:50,260
So maybe you can figure out the the population level of this sort of grouping, who is seeing which group.

368
00:48:50,320 --> 00:49:02,620
Right. But you also know possible you go with who is going to spend the money, like doing this sort of COVID positive test for everyone.

369
00:49:02,620 --> 00:49:06,020
Every day is not possible. It's just okay.

370
00:49:06,460 --> 00:49:17,320
So anyway, this is the underlying choose. You don't you cannot directly observe what you observe is some kind of data captured by surveillance.

371
00:49:18,670 --> 00:49:23,650
So at a given day, we do have number of confirmed cases.

372
00:49:23,950 --> 00:49:27,820
That's basically number of the of the observed. This is your wide.

373
00:49:28,150 --> 00:49:37,860
Okay so the. The number of confirmed cases recorded by the public like public health surveillance system.

374
00:49:38,190 --> 00:49:45,389
So there's something you can observe, of course, that this will this data is coming from the compartment,

375
00:49:45,390 --> 00:49:49,800
the underlying compartment of infected individual in population.

376
00:49:49,810 --> 00:49:55,590
But you have the data here. Maybe some people are asymptomatic.

377
00:49:56,790 --> 00:50:04,860
So the did not go to to the test. What you get here is really the people who have the test and really report to the public system.

378
00:50:05,160 --> 00:50:11,230
So there is a randomness and there's a possible underreporting because some people are asymptomatic.

379
00:50:11,250 --> 00:50:16,230
They are not going to go the clinic or doing whatever the testing.

380
00:50:16,540 --> 00:50:21,030
Okay. So this lie and state are different things.

381
00:50:21,450 --> 00:50:32,580
See, that is the tool number of infected individual in population that you don't know that and why t is the number of

382
00:50:33,060 --> 00:50:40,800
the observed number of infected cases or confirmed cases that which can be captured from the surveillance system.

383
00:50:41,400 --> 00:50:46,950
So now in mathematical modeling, this is the same.

384
00:50:48,220 --> 00:50:54,180
Okay. Like people, if you do not bring this episode into this modeling,

385
00:50:54,570 --> 00:51:04,940
you essentially treated why you call to say that guy, which is kind of, in my view, are not very good choice of this.

386
00:51:04,950 --> 00:51:07,620
You make this assumption, this something is huge.

387
00:51:08,100 --> 00:51:18,089
Rarity also applied mathematically they don't have the knowledge of modeling from stochastic part of video so

388
00:51:18,090 --> 00:51:24,600
that what they're trying to do is really treat white t I see I see that which I totally disagree with them.

389
00:51:26,160 --> 00:51:34,510
So that's why I start to draw a at the very beginning in 2020 we I started drawing the all from this to.

390
00:51:37,250 --> 00:51:43,970
Saying the assumption is that the number of cases as the number of people that have the disease.

391
00:51:45,160 --> 00:51:48,790
Yeah. Right. So what? I agree.

392
00:51:49,480 --> 00:51:54,549
So they basically assume that the the observed number of infected by confirmed

393
00:51:54,550 --> 00:52:00,430
cases is actually the same as number of the cases in the current population,

394
00:52:01,120 --> 00:52:05,530
which is not true. Right. So there is a big gap between those two.

395
00:52:05,710 --> 00:52:12,880
So what they are trying to do here is you need to bring the Epsilon into the game because you say that they're down to the same thing.

396
00:52:12,890 --> 00:52:13,150
Right.

397
00:52:13,600 --> 00:52:23,710
There is a data generation mechanism, given this current number of that, in fact, is in the population which you would like to link to variable.

398
00:52:25,690 --> 00:52:29,080
All this y could be observed.

399
00:52:30,370 --> 00:52:34,230
So can you build a statistic model on the top of this for this board?

400
00:52:36,760 --> 00:52:45,640
Well, now you can believe that the differential equation that the mathematical model tries to do is something to do with this.

401
00:52:47,140 --> 00:52:57,130
You know, this is a triangle which basically describes the dynamics, how how the population evolves over time.

402
00:52:57,520 --> 00:53:04,720
But what you capture here is the two whys that the data coming from the surveillance system can.

403
00:53:05,880 --> 00:53:16,830
No. All this. This thing like this, this, this, this triangle one in the body evolves in a continuous time every second.

404
00:53:16,830 --> 00:53:21,450
This system would be different. It's really evolved in a continuous time.

405
00:53:21,450 --> 00:53:25,650
Every second this system will change in principle.

406
00:53:26,580 --> 00:53:29,080
But the data you captured here is data. Data.

407
00:53:29,170 --> 00:53:41,490
Why t you you only have the data recorded an end of the day where this database will be updated and something it takes time really for the

408
00:53:41,970 --> 00:53:53,890
surveillance system to capture the whys so you cannot capital Y those observed the numbers every second is not logistic you just not possible right.

409
00:53:53,910 --> 00:53:59,310
So we only have daily data, but here the system itself evolves in continuous time.

410
00:53:59,460 --> 00:54:13,260
Okay. So now this system will be somewhat intervened by some like intervention like introduction to vaccination into the system.

411
00:54:13,860 --> 00:54:18,150
And that will change the dynamics will change the distribution here.

412
00:54:19,620 --> 00:54:32,190
So for example, now if you have vaccination, maybe more and more people will stay in the most susceptible individuals.

413
00:54:32,730 --> 00:54:37,560
Okay. In comparison to the situation with no vaccinations.

414
00:54:37,830 --> 00:54:45,210
So the dynamics will be different when you have vaccination available for people or you people start to wear a mask.

415
00:54:45,330 --> 00:54:55,250
Right? So this charge certainly is of a function of of of converts or some kind of interventions.

416
00:54:55,410 --> 00:55:06,180
Okay. So now you get a lot of data coming right through this system and then what you want here is really what's going to happen.

417
00:55:08,730 --> 00:55:12,930
A week after. Right. So, so, so next week.

418
00:55:13,050 --> 00:55:18,300
So you want to make a prediction. Okay. So forecast is quite essential in this.

419
00:55:18,300 --> 00:55:26,610
Especially the smartest people really want won't understand the risk in your future so that it can make planning work.

420
00:55:26,850 --> 00:55:32,400
They can decide what to do. Okay. So it's not only to understand the system, but also.

421
00:55:35,650 --> 00:55:38,380
IT system at a future time point.

422
00:55:38,530 --> 00:55:48,820
So this is something that the architecture that we are going to sort of study how to build up this using statistic models.

423
00:55:49,130 --> 00:55:58,959
Okay. How do you estimate the the dynamics or the parameters involved here in the triangle and also the

424
00:55:58,960 --> 00:56:06,700
blue from this circles to the blue to to the observed data and the how do you build up this tempo?

425
00:56:06,700 --> 00:56:10,230
Stochastic, still using Mark Colvin law.

426
00:56:10,510 --> 00:56:14,530
And how do you make a prediction through this system?

427
00:56:14,650 --> 00:56:19,560
Okay. So that's something we work on to work. Yes.

428
00:56:19,590 --> 00:56:25,980
Only at Temple Dynamics. Right. And you could have special right.

429
00:56:27,180 --> 00:56:30,390
And a given time and a given time. Right.

430
00:56:31,560 --> 00:56:40,050
People are moving around and then, you know, then so there's a sort of spatial interaction,

431
00:56:40,410 --> 00:56:49,640
spatial sort of that math mix or mechanism that are placed.

432
00:56:52,110 --> 00:56:59,950
So even though you are living in the neighboring counties and you know the things a little bit different,

433
00:56:59,970 --> 00:57:09,120
for example, if you're if you you've got county that has here has not is now near to any of the infected counties.

434
00:57:09,510 --> 00:57:18,780
Maybe this county will be temporarily safe because there is no you know, in fact, it, you know, spots around of it.

435
00:57:19,110 --> 00:57:29,850
But if the one that is near the, you know, the effected county, then this county will have the higher risk of being affected next time.

436
00:57:30,360 --> 00:57:37,960
Right. So there's a kind of a spatial structure and this three compartment split susceptible state.

437
00:57:37,980 --> 00:57:46,830
In fact, the state and remove state are also very in a quasi spatial locations.

438
00:57:46,920 --> 00:57:50,340
And this is another layer of complexity.

439
00:57:50,340 --> 00:57:58,050
So that's why we need to build up this sort of spatial, stochastic city in all the in addition to the Tempel one.

440
00:57:58,290 --> 00:58:04,770
Okay. Oh. So your risk prediction would be different if you predicted the risk of this country versus,

441
00:58:05,310 --> 00:58:10,290
you know, this just looking at what's going to happen next day or next week.

442
00:58:12,810 --> 00:58:18,150
Look at the surrounding situations where locations,

443
00:58:18,360 --> 00:58:26,730
the status of locations surrounded of particularly a target county for prediction that you would decide what are the possible,

444
00:58:27,270 --> 00:58:30,510
you know, risk in the future.

445
00:58:30,540 --> 00:58:36,160
So so this spatial sagacity is important in protection.

446
00:58:39,860 --> 00:58:43,970
Okay. Let's talk about the the more detailed the mathematical model.

447
00:58:45,590 --> 00:58:55,010
As I said, that mathematical model is our view is a non stochastic model is a very model because you have this dynamics.

448
00:58:55,430 --> 00:59:02,690
But dynamics is a function that changes over time or changes over space.

449
00:59:03,440 --> 00:59:13,069
But it's not a stochastic. Stochastic is a stochastic, very spatial type of dynamics.

450
00:59:13,070 --> 00:59:19,070
It's the Costa Dynamics here. We're talking about like the mining model is a model.

451
00:59:19,160 --> 00:59:25,370
It thinks that it is a function is a function that change over time or change over space.

452
00:59:25,880 --> 00:59:33,350
So it's not stochastic model that describes the model people in the population migrating moving from one position.

453
00:59:34,190 --> 00:59:39,469
Okay, position could be subgroup. Okay, not necessarily spatial location.

454
00:59:39,470 --> 00:59:46,190
One group termed as compartment to another one over time.

455
00:59:46,700 --> 00:59:58,219
Okay. And such susceptible to infected infected to hospitalized and hospitalized to discharge or to deaths or to recover.

456
00:59:58,220 --> 01:00:08,840
There are lot of possible compartments that we can define the system and what are all the we are able to estimate those parameters in this dynamics.

457
01:00:09,020 --> 01:00:12,020
That's different story from model in point of view.

458
01:00:12,020 --> 01:00:19,219
You put in other possible compartments that you like to study and sometimes you are not able

459
01:00:19,220 --> 01:00:25,760
to find sufficient or should the data to really figure out the the underlying parameters.

460
01:00:26,510 --> 01:00:35,480
So but anyway, so from modeling point of view, we could, you know, set up the esophagus or compartment that you reach.

461
01:00:36,710 --> 01:00:40,400
So this can be regarded as a systematic component model like you.

462
01:00:40,790 --> 01:00:45,319
And this term has to be used the g r m right generalized need a regression model.

463
01:00:45,320 --> 01:00:52,280
We have systematic component, random component. And this is similar term that you see in the in fascist model.

464
01:00:54,500 --> 01:00:59,810
Plus migration dynamics to my system are all interactive questions I would.

465
01:01:01,100 --> 01:01:08,780
Because y you use differential equation only because this system changes every second.

466
01:01:10,130 --> 01:01:12,110
Okay, so it's not discrete.

467
01:01:12,110 --> 01:01:25,280
The Times is not a time series that takes the snapshots every second and every day is a system that's supposed to change, evolve in continuous time.

468
01:01:25,760 --> 01:01:35,660
So every second of this is to make different. So that's why you need a differential equation to capture this continuous time mechanism or dynamics.

469
01:01:35,960 --> 01:01:43,560
So this is the reason that I mean, has to be established about 100 years ago, that people always follow this ordinary definition.

470
01:01:45,070 --> 01:01:58,470
Starting from the. I'm all for all these movies who basically wrote down the first sort of serum all of about 100 years ago.

471
01:01:58,920 --> 01:02:02,910
And he basically use ordinary differentiation to do that.

472
01:02:02,950 --> 01:02:10,820
And this becomes a tradition, especially this malady, that this becomes a something we first learned.

473
01:02:11,010 --> 01:02:18,580
In fact, it was a small. And variables in this mathematical model cannot be directly measured.

474
01:02:19,530 --> 01:02:24,879
And that's basically thethings that I've talked about cannot be directly measured.

475
01:02:24,880 --> 01:02:31,570
And underlying dynamics in fashion in the population is operating in very complex way over continuous time.

476
01:02:31,860 --> 01:02:38,840
Okay. We'll. So interpreting and estimating parameters in this model is one of the primary task.

477
01:02:39,300 --> 01:02:46,010
Okay. So that's something you know, this last point is our job.

478
01:02:46,550 --> 01:02:53,700
Okay. So how do you estimate the so you work of his epidemiologists who set up this model,

479
01:02:53,700 --> 01:02:58,880
then then you have data and then how are we going to figure out those parameters in the model?

480
01:02:58,890 --> 01:03:08,270
That's our job. So. Well, talking about this statistic, all of basically you want to add some kind of uncertainty,

481
01:03:08,270 --> 01:03:15,380
not randomness as part of data collection, how data are generated from this underlying mathematical model.

482
01:03:19,870 --> 01:03:24,940
To explain the sampling error or data generated mechanism with uncertainty.

483
01:03:25,310 --> 01:03:30,070
Okay, this is important. As I said, the Y and state are not the same thing.

484
01:03:33,220 --> 01:03:40,790
Okay. So essentially, if you want to build up this statistic, all you need to really.

485
01:03:44,290 --> 01:03:47,799
And assumptions around the distribution to this flight model,

486
01:03:47,800 --> 01:03:54,650
explaining how observed observations like caseload recoveries are generally from a mathematical model.

487
01:03:54,700 --> 01:04:06,010
Basically, I look at a some kind of mathematical equations that allow you to describe the the blue vertical bar.

488
01:04:06,760 --> 01:04:13,530
So you basically model this part. So you have this mathematical model based on ultimate differential equation.

489
01:04:13,780 --> 01:04:24,910
And now how, how wise are observed, you basically won't have much distribution to describe this vertical blue line stuff.

490
01:04:25,240 --> 01:04:27,700
That's basically what you're trying to do.

491
01:04:30,490 --> 01:04:37,570
So data collection takes place on discrete time points daily, weekly, monthly, whatever depends on the actual study.

492
01:04:38,140 --> 01:04:44,680
In contrast, the continuous time evolution is governed by mathematical model replacing that point.

493
01:04:45,400 --> 01:04:51,400
The probability loss of data generation is bases to form statistical quantities,

494
01:04:51,400 --> 01:05:01,150
procedures like likelihood pseudo likelihood estimate functions, MSI Basing inference for estimation and inference and prediction, of course.

495
01:05:01,570 --> 01:05:15,940
So this is the sort of the platform that we would use to create some kind of object function that we can

496
01:05:15,940 --> 01:05:24,820
optimize in order to estimate the parameters in the mathematical models and additional modeling distributions.

497
01:05:25,960 --> 01:05:36,250
So in the literature, many publications do not distinguish this two models and incorrectly tweak the mathematics model as a statistical model.

498
01:05:36,610 --> 01:05:39,700
Thus, the resulting estimation inference is problematic.

499
01:05:39,710 --> 01:05:50,440
This is something I have repeatedly emphasizing that we are doing something different more than this because we know ever since we know this method,

500
01:05:50,680 --> 01:05:59,320
we know how to estimate parameters. Rudder To avoid the issue of certainty of sampling noise sampling error.

501
01:05:59,560 --> 01:06:05,020
We do not want avoid that. We do not thought that we run it directly,

502
01:06:05,020 --> 01:06:16,240
face it and try to use our static method to build epsilon into this small only so that we can better quantify the uncertainty in actually modeling.

503
01:06:18,710 --> 01:06:31,070
Okay. So for this Templestowe pass, this is the issue into this mall to reflect the nature of this evolution capturing time search

504
01:06:31,070 --> 01:06:38,900
data and this is required for the need of forecasting for disease spread in future times.

505
01:06:40,760 --> 01:06:53,240
So. So because the reason you can make a prediction for a future sort of infectious situation is that you do have this temporal, stochastic sea right.

506
01:06:53,540 --> 01:07:00,320
If you think of the data, what's going to happen tomorrow is independent of what has happened in the past.

507
01:07:00,590 --> 01:07:07,480
You can now make forecasting what the reason you can make a forecast is that what's going to happen tomorrow is dependent.

508
01:07:08,090 --> 01:07:12,440
What has happened in the history today or before.

509
01:07:13,220 --> 01:07:16,400
This essentially is called temporal dependance.

510
01:07:16,730 --> 01:07:22,940
And this dependent temple dependance is a blessing for flow, for forecasting.

511
01:07:23,180 --> 01:07:27,139
Right. This is complicated. But this complication is what we want.

512
01:07:27,140 --> 01:07:36,380
Because of this complexity, because of the Temple State custody, we are able to use the data in history to predict something in future.

513
01:07:36,560 --> 01:07:42,590
Okay. So this is a blessing or a curse in the data analysis.

514
01:07:42,980 --> 01:07:46,490
So Markov in Stochastic is primary transition law.

515
01:07:46,640 --> 01:07:52,990
Why do you use literature? All use Markov. I mean, maybe that relates to it, but you look at.

516
01:07:54,080 --> 01:08:04,549
Our coffees to customers instead of considering a general more coffee nor a specific transition model is specified to address temples.

517
01:08:04,550 --> 01:08:12,440
The caste that you work to calculate likelihood for estimation and to establish a favorable forecasting procedure.

518
01:08:12,500 --> 01:08:22,310
This is the place that involves the modeling of the transition structure or transition models.

519
01:08:23,630 --> 01:08:28,010
So Markov you properties forecast is very general basically says that the

520
01:08:28,010 --> 01:08:35,180
distribution are distribution today is depend on data yesterday or or before.

521
01:08:35,510 --> 01:08:43,160
But this is such a generic definition of. Mark Colvin Stochastic remarkable chart or Markov property dependance.

522
01:08:43,640 --> 01:08:49,459
But if you want to make a forecasting, you need a really something more specific than this generic statement.

523
01:08:49,460 --> 01:08:55,070
You need to see under which structure I'm really can figure out this dependance and

524
01:08:55,070 --> 01:09:00,559
see how the historical data can be utilized to figure out the values in future.

525
01:09:00,560 --> 01:09:09,260
Work prediction in future. So you need to have a little modeling of the transition transition model that's basically a model for you.

526
01:09:09,300 --> 01:09:12,680
Mark Colvin Stochastic. So that opens the door.

527
01:09:13,280 --> 01:09:17,270
John will say, okay, I'm all this way. And Peter says, I model this.

528
01:09:17,750 --> 01:09:22,670
Now this opens the door. Okay, which one is better?

529
01:09:22,940 --> 01:09:31,339
Which one is more realistic? This probability depends on culverts, vaccination, you know, where summertime is.

530
01:09:31,340 --> 01:09:35,300
This transition a seasonal in transition,

531
01:09:35,330 --> 01:09:39,860
the winter is more severe because all what people are staying inside or this

532
01:09:39,860 --> 01:09:47,929
transition is more severe in hospitals or in more popular of more crowded places.

533
01:09:47,930 --> 01:09:52,680
I don't know. This opens a lot of different choices.

534
01:09:52,700 --> 01:09:55,970
What how are you going to specify this transition structure?

535
01:09:56,000 --> 01:10:11,210
Right. Is it's it's not just one of what you have is all it's it's dependent actually the environment and and look at h look at location look at,

536
01:10:11,900 --> 01:10:13,280
you know, even polluted.

537
01:10:13,610 --> 01:10:22,339
So people have different mindset and how strong they believe this of the consequences being the fact that a lot of things are going on.

538
01:10:22,340 --> 01:10:29,640
Right. So in this situation that really a place that you can introduce some kind of modeling.

539
01:10:30,110 --> 01:10:36,950
Okay, can go very small, but that's the place that we could talk a little bit more with.

540
01:10:40,200 --> 01:10:44,250
Formulation. And you can go.

541
01:10:46,470 --> 01:10:57,690
You're not you have the right statistical two boxes to get estimation of that system or you have enough data that allow you to assess that.

542
01:10:57,960 --> 01:11:01,590
That's something we can discuss more specifically at that point.

543
01:11:02,790 --> 01:11:08,400
Now, this issue model would be operated on assumed, or are these the ordinary differential equations?

544
01:11:08,820 --> 01:11:12,780
Mathematic model is more in transition over time. That's obvious.

545
01:11:13,770 --> 01:11:19,250
So. Boats spacious for Cassidy.

546
01:11:19,580 --> 01:11:28,910
Likewise model disease spread over spatial location. Essential to build a certain space course stochastic along into infection.

547
01:11:28,960 --> 01:11:37,480
This model and this requires understand interplay and focus on disease spread on special locations.

548
01:11:39,460 --> 01:11:44,230
So a lot of time people use census or to his United States.

549
01:11:44,590 --> 01:11:50,410
We don't have household data because we have this sort of the data countries are able to issue.

550
01:11:51,070 --> 01:12:00,490
We are not allowed to go. I mean, the public available data would not give you that level of resolution at a hospital level.

551
01:12:01,720 --> 01:12:05,560
But, you know, we always get this sort of aggregate data.

552
01:12:05,560 --> 01:12:16,270
I come to level sense of track. So spatial Markov use for custody, conditional distribution on the neighboring location on arrow data.

553
01:12:16,270 --> 01:12:27,400
It's quite a use the future. So in this spatial statistic, we have three major ways to model spatial data area our spatial data analysis.

554
01:12:27,420 --> 01:12:32,760
One, those you have also point process, right? Look at the for example, what of the point process.

555
01:12:32,770 --> 01:12:37,180
You look at car accidents when a car accident happens, right,

556
01:12:37,480 --> 01:12:44,800
police will come and record what's the land to longitude of the location where the car accident happened.

557
01:12:45,370 --> 01:12:53,360
Right. So so that's basically a very special point in the space that is not aggregated.

558
01:12:53,770 --> 01:12:58,899
They just give you exact location in space like a point right in this space.

559
01:12:58,900 --> 01:13:02,050
So I call point passes.

560
01:13:02,380 --> 01:13:08,560
So you actually have all the points, each representing a one car accident at a given time.

561
01:13:08,920 --> 01:13:11,889
So if you look at us that you will have a lot of points.

562
01:13:11,890 --> 01:13:21,670
Most points are probably constituted highways or some, you know, interstate sort of ways where you have more traffic and so on.

563
01:13:21,820 --> 01:13:29,830
But I'm just telling that kind of data, that's point process is not a major sort of spatial data analysis that people do.

564
01:13:30,430 --> 01:13:40,899
And in the number this would talk about spatial transcriptome genetics where the they can go either error data look at a small

565
01:13:40,900 --> 01:13:52,479
region in the tissue and look at dependance or look how to actually be a spot some of some some position of of your body.

566
01:13:52,480 --> 01:14:00,190
Right. So so anyway, it depends on what kind of the spatial data you collect and for your facilities.

567
01:14:00,190 --> 01:14:06,400
Mostly we focus on country level or hospital level resolution as everything that.

568
01:14:09,180 --> 01:14:18,149
Well. Um, I, I think you can use a lot of spatial data analysis methods I will introduce,

569
01:14:18,150 --> 01:14:24,600
particularly from knowing that Seurat model as Y to use to specify a transition

570
01:14:24,600 --> 01:14:29,910
model for spatial stochastic mimicking the movement of particles in this space.

571
01:14:30,390 --> 01:14:34,140
So so this is something I would that you I oriented.

572
01:14:36,710 --> 01:14:38,060
Which modeling approach.

573
01:14:38,540 --> 01:14:49,270
But I spend significant time talking about CMO CEO as a model, so I don't know if this can be used in the spatial transcriptome data analysis.

574
01:14:49,280 --> 01:14:54,320
I never saw this application in genetics. Maybe people are not even aware of this method.

575
01:14:54,620 --> 01:15:06,799
In genetics, they're always looking at the very obviously Gaussian kernels, facial Gaussian kernel or Latin class modeling,

576
01:15:06,800 --> 01:15:22,750
very, very traditional spatial modeling like but but single out model is to me is genius idea which is better than you fit and.

577
01:15:24,830 --> 01:15:28,460
In some cases, in particular, an infectious disease situation that.

578
01:15:30,580 --> 01:15:34,390
It's quite a special disease infection.

579
01:15:36,660 --> 01:15:40,100
Issues. Not.

580
01:15:40,230 --> 01:15:48,090
So maybe this could be a way that you can introduce to people who are working at special transcriptome and I don't know,

581
01:15:48,090 --> 01:15:53,700
like how this can be done there. And, and I,

582
01:15:54,800 --> 01:16:08,220
I wish that more and more advances in technology collecting data like spatial or that may be they have of more and more dense measurements over time

583
01:16:08,220 --> 01:16:18,910
or over locations that somehow you could introduce of differential equation into it rather than just doing this very discrete time sort of modeling.

584
01:16:19,720 --> 01:16:23,160
But anyway, that's an option that people can consider.

585
01:16:26,290 --> 01:16:38,740
It. Get her. You know, we will do this combination of mathematical and statistical, this combined multiple.

586
01:16:38,760 --> 01:16:46,740
We call you families this model that will vary over time and variable over locations.

587
01:16:49,450 --> 01:16:54,640
So let's just quickly mention about a couple of tasks we would like to achieve.

588
01:16:55,060 --> 01:17:04,720
So this is a example from a Hubei province during January 20 and March 12th.

589
01:17:04,750 --> 01:17:10,210
This is very old data. I mean, probably the data itself is no longer so interesting.

590
01:17:10,450 --> 01:17:13,029
We're in a totally different phase of the pandemic,

591
01:17:13,030 --> 01:17:20,140
but I just use the data to illustrate some basic task we need to carry out in this infection based modeling.

592
01:17:20,790 --> 01:17:26,349
So this is the daily number of daily COVID contract cases.

593
01:17:26,350 --> 01:17:37,270
So you also have to switch. Okay, so here it's access all the time from January 20, up to March 12.

594
01:17:37,420 --> 01:17:39,070
Okay, this is the time window.

595
01:17:39,430 --> 01:17:52,640
Why go through this time whether because of days that there was no reported cases is regarded that the disease control or.

596
01:17:54,640 --> 01:18:03,370
Or any time outbreak that this is actually a number of cases happening in this province of wee we Jones from

597
01:18:03,370 --> 01:18:10,060
this province so probably province and just I don't know a random pick of the province to see the data.

598
01:18:10,510 --> 01:18:15,180
I didn't. But.

599
01:18:17,250 --> 01:18:21,900
Really? So. So what do you say? The dead rise?

600
01:18:21,990 --> 01:18:25,070
You know, these are not non-zero cases.

601
01:18:25,110 --> 01:18:31,560
And you you your first question here will be see what causes the invasion of the.

602
01:18:32,960 --> 01:18:42,260
So in populous, what happened? Why suddenly this is coming from Hubei province or this or from thinking by Beijing?

603
01:18:42,860 --> 01:18:47,139
Or where is it from? Identify.

604
01:18:47,140 --> 01:19:03,990
Can you trace back? His words were and this is something you first asked why the causes in this why I start to observe cases like this is very,

605
01:19:03,990 --> 01:19:11,610
very important in the very early stage to understand and tweets, the early cases to understand what's going on, why happen.

606
01:19:12,200 --> 01:19:19,769
But does this in fact, it is has this error r0 number one person can infect multiple people,

607
01:19:19,770 --> 01:19:25,349
view this with no control and no like stay home, order whatever.

608
01:19:25,350 --> 01:19:32,440
The disease will be naturally spread out according to its power, the power of the virus.

609
01:19:32,790 --> 01:19:46,180
So suddenly you will see a quick increase. Oh, so, so valid from the public health's point of view that what does this gross rate implies?

610
01:19:47,500 --> 01:19:53,410
We saw only from like one to a couple of days later, you fall to 15 and 20, you see.

611
01:19:53,470 --> 01:20:01,890
Wow. What? So what location of this world going rate?

612
01:20:03,570 --> 01:20:07,560
It. Yeah. It's going to cost a pandemic.

613
01:20:07,770 --> 01:20:12,599
What's going on? Right. So. So you really need to figure out, is this something we need to do,

614
01:20:12,600 --> 01:20:19,590
something to intervene or something we need to really report to general residents in this.

615
01:20:20,960 --> 01:20:24,890
Politics in this country. So this is very critical period.

616
01:20:25,760 --> 01:20:36,150
So. You work to control things.

617
01:20:36,170 --> 01:20:40,810
Right. So suddenly that the I think that there is some a.

618
01:20:42,720 --> 01:20:47,790
I think that I think that understanding or consensus that this is going to be something very

619
01:20:47,790 --> 01:20:56,820
dangerous so that there must be some kind of intervention goes in place maybe around here.

620
01:20:57,120 --> 01:21:02,490
So you kind of see that this new faction comes to a equilibrium point.

621
01:21:03,120 --> 01:21:10,860
So you have it up and down. If you do not have a control, this will continue to go right into an exponential rate.

622
01:21:11,160 --> 01:21:14,880
So very fast. But now somehow this turn around.

623
01:21:15,250 --> 01:21:20,370
Okay, so then you start to have this sort of fluctuation uptown.

624
01:21:20,370 --> 01:21:28,790
Uptown. This is very natural, right? This vibration, it's kind of an equilibrium point at the system.

625
01:21:29,040 --> 01:21:34,620
There's a human intervention. And then the virus itself, this fight against the human intervention.

626
01:21:34,860 --> 01:21:39,360
So there is a two forces fighting each other during this a period of time.

627
01:21:40,260 --> 01:21:47,550
Okay. So now you have this update left. Up until that, the the human intervention went over.

628
01:21:48,720 --> 01:21:54,720
Then you start to see the drop. Okay, so then so slow down.

629
01:21:54,720 --> 01:21:59,400
You'll see why you could not control it up to this point.

630
01:22:00,000 --> 01:22:03,690
You wander. What determines the turn of the 20?

631
01:22:04,880 --> 01:22:07,920
What? What policy? What factors?

632
01:22:09,710 --> 01:22:16,300
The. So that's something very important for people to learn.

633
01:22:16,300 --> 01:22:28,540
So this knowledge, whatever conclusion will be transferable to other situations and for other places when they have this outbreak.

634
01:22:29,170 --> 01:22:40,659
So now after you do this and you you get to the at the control of this and this is finally distinct in this region.

635
01:22:40,660 --> 01:22:45,040
And they will say, well, why it goes to the extinct.

636
01:22:45,610 --> 01:22:53,590
So, so, so, and, you know, so there are beautiful questions, just the dynamics.

637
01:22:54,580 --> 01:23:04,890
How is begins why you grew so why this can be are controlled and how this goes to extinct.

638
01:23:05,020 --> 01:23:06,819
So what are the dynamics?

639
01:23:06,820 --> 01:23:14,970
Can we use a differential equation or some mathematical model of this trajectory to model this process, to model this journey?

640
01:23:15,160 --> 01:23:18,280
Right. And if you have intervention.

641
01:23:22,090 --> 01:23:26,350
Others to understand the effectiveness of intervention.

642
01:23:26,770 --> 01:23:30,670
Okay. Well, that's something we we need to use model to figure out.

643
01:23:35,750 --> 01:23:39,979
Oh. Okay. Time's up. And so we can. Okay, just.

644
01:23:39,980 --> 01:23:43,730
Just one more. Just show where this location is.

645
01:23:44,050 --> 01:23:47,420
This is. This is the Hubei province.

646
01:23:48,080 --> 01:23:53,270
Beijing is surrounded here is is north some part of China.

647
01:23:53,570 --> 01:24:01,150
Okay. Here's Beijing as capital of the country. And this is the province that surround this, you know, Beijing.

648
01:24:01,160 --> 01:24:05,000
So this is the problem, is that question. Okay. So that's it for today.

