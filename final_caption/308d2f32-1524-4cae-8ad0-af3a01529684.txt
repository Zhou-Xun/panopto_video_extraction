1
00:00:03,190 --> 00:00:06,410
20 minutes.

2
00:00:10,240 --> 00:00:16,370
Yeah, yeah, yeah.

3
00:00:19,480 --> 00:00:46,230
James sounds like he's super smart and walks into the studio where it all started, as is for the likes of something I wanted to include last time.

4
00:00:47,250 --> 00:00:57,690
I just think it's just another useful type of command for for nobody a raise or a method for numpy arrays.

5
00:00:57,690 --> 00:01:14,519
So this is where it tells you kind of where the index of where certain condition is true, basically that's often useful.

6
00:01:14,520 --> 00:01:24,719
So again, you might you might have kind of like the maximum number in your array, for example,

7
00:01:24,720 --> 00:01:36,690
is 100 and you want to find the index in the array where it where the element equals 100.

8
00:01:36,990 --> 00:01:47,580
That's often kind of a useful thing, that type of thing where so, you know, we're basically like if you look at this example,

9
00:01:48,930 --> 00:01:57,180
you have this array here, if I want to find well you can find one index or multiple indexes.

10
00:01:58,140 --> 00:02:05,610
So if I want to find all of the all of the indexes where the elements are positive,

11
00:02:05,670 --> 00:02:10,410
you would just do me kind of where, you know, are greater than zero.

12
00:02:12,390 --> 00:02:18,230
So you're saying that index. Q.

13
00:02:23,390 --> 00:02:27,250
You guys. Oh, yeah.

14
00:02:27,280 --> 00:02:32,379
Greater than zero. Greater than or equal to. Or greater than zero.

15
00:02:32,380 --> 00:02:37,960
So that's only on this index. And then next three points is the index five.

16
00:02:42,460 --> 00:02:46,650
So basically, it tells you every way this is true.

17
00:02:46,660 --> 00:02:56,740
So I guess what's really going on is that this Boolean expression that returns an array with all of the elements.

18
00:02:57,550 --> 00:03:07,150
So kind of this expression here returns like an array, which is false, false, false, true, false, true.

19
00:03:07,900 --> 00:03:13,870
And then when you run an import where on integers it is returns in indexes where

20
00:03:15,160 --> 00:03:26,740
kind of the values of this array of true is as all it does is as another example.

21
00:03:28,570 --> 00:03:35,050
Let's see, we wanted to find kind of the.

22
00:03:38,970 --> 00:03:48,960
Where the indexes where are the index, where the the the rate is because it's a minimum value.

23
00:03:50,010 --> 00:03:57,060
You could do it this way. Like if you just did, you picked where a or R is equal to compute at the moment.

24
00:03:57,480 --> 00:04:04,740
It's basically searching for the the index the index where the.

25
00:04:10,450 --> 00:04:14,530
Where you had minimal value on that. Okay. So that's what it's doing.

26
00:04:14,980 --> 00:04:23,140
So I guess what? But it's really returning support where it's it's really a tuple.

27
00:04:23,830 --> 00:04:33,270
It just basically depends on whether or not you're using like a one dimensional array or a two dimensional array for these examples,

28
00:04:33,290 --> 00:04:39,550
or you're just using a one dimensional space kind of returns something in the first dimension of the tuple.

29
00:04:40,840 --> 00:04:47,410
Another example. Oh, yeah.

30
00:04:47,430 --> 00:04:50,669
And this is just kind of the same thing.

31
00:04:50,670 --> 00:04:59,430
It's just if you wanted to extract it in a certain way as a number rather than a tuple,

32
00:04:59,850 --> 00:05:06,870
if you wanted to, if you wanted to return a number of the index rather than like a tuple format,

33
00:05:06,870 --> 00:05:18,089
you can just do kind of this syntax, sort of kind of the first component of the tuple was actually an array itself.

34
00:05:18,090 --> 00:05:28,770
So you have to do kind of this double zero thing because you're extracting kind of the first index of the tuple and then the first index of the,

35
00:05:29,280 --> 00:05:37,409
of, of the, the array of that, of the array that's in the first index of the tuple, right?

36
00:05:37,410 --> 00:05:42,960
Because the first, the first element of the tuple is actually an array itself.

37
00:05:45,570 --> 00:05:51,510
So basically what you're doing is extracting like the first element of the tuple,

38
00:05:52,260 --> 00:05:55,770
which is itself an array and then you're extracting the first element of that.

39
00:05:55,770 --> 00:06:03,480
And that then gives you the number which you.

40
00:06:09,810 --> 00:06:12,510
It's not it's not super important, you know,

41
00:06:12,510 --> 00:06:21,300
that it's just if you just if you want to extract the actual number itself in your code, you can do it that way.

42
00:06:23,790 --> 00:06:28,440
But otherwise it should. When it prints things out, it should.

43
00:06:28,650 --> 00:06:33,990
It's fairly clear what the result is that the index two equals of minimum.

44
00:06:35,580 --> 00:06:41,670
Let's just note I think in P and P, whereas in p dot, where's the crystal method to know about?

45
00:06:42,390 --> 00:06:49,680
I just I forgot to add it to the last slides for the stuff on Monday.

46
00:06:51,480 --> 00:07:00,090
So this for today is the show just a reminder about the stuff that to do the

47
00:07:01,050 --> 00:07:06,570
quiz in a sense to tomorrow and then this second homework is due on Friday.

48
00:07:09,050 --> 00:07:15,330
So just keep that in mind. So I think today was talk about reading in text files in the python.

49
00:07:15,330 --> 00:07:22,770
So basically. Things like CSB files.

50
00:07:24,300 --> 00:07:29,070
So we'll do that fairly quickly and then we'll just talk about it.

51
00:07:29,550 --> 00:07:36,570
And as the rest of the rest of it applies, it's pretty much the the main focus today is pandas.

52
00:07:36,690 --> 00:07:43,680
So. Oh, yeah, I had another I've just done this,

53
00:07:43,800 --> 00:07:53,879
another kind of review exercise for nobody just to wrap up all of the main concepts we talked about last time.

54
00:07:53,880 --> 00:08:04,110
So let's say I wanted to generate a 2D array or you think of it as a ten by 20 matrix with random numbers, you can do it this way.

55
00:08:04,980 --> 00:08:10,350
So normal kind of standard, normal normally distribute around random numbers.

56
00:08:11,250 --> 00:08:15,510
You can do that with the input random dot normal function.

57
00:08:16,320 --> 00:08:23,309
So that's how you you can do it with numpy and then the look and the scale with zero and one.

58
00:08:23,310 --> 00:08:31,020
And so just means the normal distributed distribution that you're using to generate

59
00:08:31,020 --> 00:08:37,200
these random numbers has a mean zero and the LI scale should be standard deviation.

60
00:08:38,040 --> 00:08:47,490
The standard deviation is one, and then the size just means the kind of the dimension of the array that you want to generate.

61
00:08:48,120 --> 00:08:59,010
This is just a ten by 20 array or two dimensional array, since it is just a matrix, it has ten rows and 20 columns.

62
00:09:00,600 --> 00:09:06,030
Okay, so these are just various things you could do with this array.

63
00:09:06,270 --> 00:09:10,680
Calling it a one thing you might want to do first is compute the row.

64
00:09:11,550 --> 00:09:14,790
Row means and all the column means.

65
00:09:15,660 --> 00:09:22,739
And then for those rows and columns let me in larger than zero.

66
00:09:22,740 --> 00:09:26,520
Compute the maximum of that row in column part.

67
00:09:28,110 --> 00:09:31,590
Well, we're going to do this separately from rows and columns. Yes.

68
00:09:35,730 --> 00:09:40,770
So the first thing that we wanted to do was compute the row and column mean.

69
00:09:40,780 --> 00:09:45,180
So remember, you can do that with the the axis argument.

70
00:09:45,720 --> 00:09:54,990
If you do the if you're doing a computing a mean for a two dimensional array, you could do it without an axis.

71
00:09:54,990 --> 00:10:04,230
It'll just compute kind of the meaningful thing. But often you want to compute lines for each column or each row.

72
00:10:07,950 --> 00:10:13,150
So if you're doing it for each column you want to, the axis equals zero.

73
00:10:13,380 --> 00:10:19,770
So that would be I would return like 20 numbers or 20 numbers inside of an array.

74
00:10:20,040 --> 00:10:26,820
If you're doing it for each of the 20 columns, if you want to do it for each row, you have to do axis equals one.

75
00:10:27,150 --> 00:10:31,500
Okay? So that just means you're computing a means of each of the rows.

76
00:10:33,300 --> 00:10:41,200
So if you use this, these two variables here call underscore means and two,

77
00:10:41,240 --> 00:10:48,270
which means these are both not be afraid of one dimensional and only arrays.

78
00:10:52,770 --> 00:10:54,309
So it's just something to keep in mind.

79
00:10:54,310 --> 00:11:06,820
So what's the next thing you want to do was to kind of look at the maximum value for each column where the mean of that column is greater than zero.

80
00:11:10,330 --> 00:11:18,130
So for that, you're going to use this type of Boolean expression called means greater than zero.

81
00:11:18,880 --> 00:11:31,810
So that's that's going to indicate where kind of the elements of column means, where the column mean that is greater than zero.

82
00:11:33,100 --> 00:11:41,589
So you can look here in a separate state and this is just looking at I guess you can think of this like the sum

83
00:11:41,590 --> 00:11:52,510
matrix or that of a it's just all the including the columns where the call the column name is greater than zero.

84
00:11:53,470 --> 00:11:56,080
So that's how you can compute that kind of set of matrix,

85
00:11:56,080 --> 00:12:02,260
which is basically only keeping the columns where the, the column means are greater than zero.

86
00:12:02,450 --> 00:12:08,470
Just use this syntax kind of using Boolean upsetting.

87
00:12:09,040 --> 00:12:15,700
And so this is saying that ten of the columns have a column mean greater than zero.

88
00:12:17,800 --> 00:12:18,130
Okay.

89
00:12:18,700 --> 00:12:31,030
And then if you wanted to do that, the maximum of each of the rows maximally of each of the columns where the column means are greater than zero.

90
00:12:31,360 --> 00:12:37,919
You could just do import max of this like sub matrix, sub matrix only.

91
00:12:37,920 --> 00:12:41,830
And that only includes the columns where the column needs are greater than zero.

92
00:12:43,000 --> 00:12:46,270
And then here you have to you have to include it. Axis equals zero.

93
00:12:47,530 --> 00:12:53,960
If you're doing input max on to the array, you have to include the well.

94
00:12:54,920 --> 00:13:02,440
If you want to do column wise or row wise maximum, you have to include the axis argument.

95
00:13:02,450 --> 00:13:08,550
So again, axis equals zero. That just means that you're computing the maximum for each column.

96
00:13:08,560 --> 00:13:13,690
So this is going to give us basically the maximum for each of those columns.

97
00:13:13,690 --> 00:13:17,559
So these are all the maximum each of those columns.

98
00:13:17,560 --> 00:13:22,610
So again. We have ten of those.

99
00:13:23,810 --> 00:13:28,129
The other thing we wanted to do was the love and the romance thing.

100
00:13:28,130 --> 00:13:40,310
So we wanted to. A look at the maximum of the rows where the row means was greater than C was greater than zero.

101
00:13:40,310 --> 00:13:48,139
Sorry. So if you want to look at length is some matrix that only includes the row for that

102
00:13:48,140 --> 00:13:56,060
row new there will be zero A and then this means greater than zero in the expression.

103
00:13:56,880 --> 00:14:05,480
We just keep we're keeping all the columns. So that matrix has six, six rows and 20 points.

104
00:14:08,900 --> 00:14:13,730
So only six six of the rows had a roaming greater than zero.

105
00:14:14,300 --> 00:14:22,850
And if we want to just to compute the maximum for each of those rows, again, just it can be max for that same sun matrix.

106
00:14:22,850 --> 00:14:30,980
And then if that include that axis equals one arguments during these things for every row.

107
00:14:33,040 --> 00:14:36,749
Okay. So that was just kind of a useful review.

108
00:14:36,750 --> 00:14:45,210
I'm just kind of some of this syntax for working with None of you is sort of kind of computing

109
00:14:46,860 --> 00:14:55,650
row wise or column wise statistics doing these and doing these weird sub setting arguments.

110
00:14:56,960 --> 00:15:05,730
So I just wanted to say a few things about reading in text files and the first class I do in practice,

111
00:15:05,730 --> 00:15:13,290
we're just going to use kind of the pandas read does see USB function or read read underscores

112
00:15:13,290 --> 00:15:17,760
the USB function at least for the kind of the real data sets that we'll be using.

113
00:15:18,660 --> 00:15:29,489
But I'm just going to mention some a few of kind of a few other ways, just kind of the classic ways of reading in some text files.

114
00:15:29,490 --> 00:15:35,400
So I think text files are basically just things that when you open them up,

115
00:15:36,780 --> 00:15:46,440
they have kind of have readable characters more basically kind of kind of stuff that you can read and it kind of makes sense.

116
00:15:46,710 --> 00:15:57,900
It's basically a text file. So they just, you know, when you open them up, perhaps letters from the alphabet numbers,

117
00:15:58,440 --> 00:16:06,060
special characters, things like that, like a pi python files, an example of a text file.

118
00:16:07,290 --> 00:16:14,640
That text is an example of a text file that CSP files another example of a text file.

119
00:16:15,330 --> 00:16:34,860
I mean, I think the sense that you will be using that will be there like that text or or that seems to be basically I was just saying

120
00:16:34,860 --> 00:16:47,700
that there are other files that are that are not text files that in some cases you may have you may want to work with,

121
00:16:47,700 --> 00:16:55,380
but when you first start out, you definitely mostly be using textiles.

122
00:16:56,280 --> 00:16:56,669
Okay?

123
00:16:56,670 --> 00:17:13,070
So to access a file at least using kind of the built in classic way in Python is to use like open reader close so to defer to read in the context

124
00:17:13,680 --> 00:17:26,340
the contents from a text file you first have to use open and then to read it and kind of do the contents of the file you have to use read.

125
00:17:26,850 --> 00:17:31,530
And then when you finish and reading the finished reading and the contents,

126
00:17:31,950 --> 00:17:46,670
you have to do clothes you can also use with kind of with open and that kind of automatically closes the file after everything is finished reading in.

127
00:17:47,070 --> 00:17:52,740
So in that case you don't have to use clothes. So let's just kind of one alternative.

128
00:17:54,090 --> 00:18:00,380
Okay, so let's see. Okay.

129
00:18:00,630 --> 00:18:07,440
So let's see. This is just an example. So I have this text file called Bold Text.

130
00:18:08,280 --> 00:18:15,360
I did put it on canvas. It's it's under the files folder and then there's like a data folder.

131
00:18:16,230 --> 00:18:17,520
This is just an example.

132
00:18:18,600 --> 00:18:40,050
So to read it and the way you have to do it is at least you have to start out with with open and then phone that text and then the way you do it,

133
00:18:42,630 --> 00:18:42,980
I mean,

134
00:18:43,050 --> 00:18:55,260
the next kind of thing you have to do is you kind of have to assign you want to assign the contents of the file to like a variable, for example.

135
00:18:55,260 --> 00:18:59,250
So I just called it contents here and then.

136
00:19:02,460 --> 00:19:08,900
You have to do this file object. So, again, you don't have to name this.

137
00:19:09,170 --> 00:19:18,600
You could have name is something else. But for whatever you name it here, well, for whatever name you give it here, you have to do that name.

138
00:19:18,600 --> 00:19:21,990
Don't read with open, closed parentheses.

139
00:19:22,620 --> 00:19:37,440
Okay. So basically this once I run this line of code in a file object kind of represents both text and the.

140
00:19:39,550 --> 00:19:51,430
Line immediately following open. Okay. And then you do not need to close it.

141
00:19:51,450 --> 00:20:00,360
I guess once you've done this, if you're using with open, you don't really need to to kind of close the file after that and would.

142
00:20:02,170 --> 00:20:06,730
So I think this is really you can this is really the only two lines of code you need.

143
00:20:11,470 --> 00:20:19,780
And so, you know, once you've run this kind of everything in the bone, text file is kind of stored in contents.

144
00:20:20,200 --> 00:20:27,880
It's stored in the variable contents of if you print contents, note that you know, this will print kind of everything.

145
00:20:28,690 --> 00:20:32,400
Or at least until it kind of. Truncated.

146
00:20:32,420 --> 00:20:36,710
So this is this file is not super big, but it's it's fairly big.

147
00:20:37,460 --> 00:20:42,260
So it'll turn on a lot of stuff here. It's only permanent here.

148
00:20:42,910 --> 00:20:50,710
So we have space to print out a few lines. Oh, maybe more recently.

149
00:20:51,290 --> 00:20:54,970
Our next slide. Okay.

150
00:20:55,130 --> 00:20:58,670
I guess one thing to keep in mind generally.

151
00:21:09,160 --> 00:21:17,100
Basically the way I would do this is if you have a kind of a program or a script that's running.

152
00:21:17,590 --> 00:21:24,520
I would put the data set in the same folder that you see in the script, and that's probably the easiest way to do it,

153
00:21:26,410 --> 00:21:36,460
because then Python will kind of automatically looks in the same folder where the current the program that's currently running.

154
00:21:37,300 --> 00:21:46,690
Okay. So I think that just makes it much easier when you don't have to worry about them figuring out the file name or anything.

155
00:21:46,690 --> 00:21:50,560
You can just give it the name of the, of the, of the text file itself.

156
00:21:53,260 --> 00:22:04,600
Okay. So I guess the first thing to notice about this once you run after running this, is that this content's variable here,

157
00:22:04,600 --> 00:22:14,700
it just stores it as it's basically just so it's just a single string, basically stores it as a kind of a huge long string like this.

158
00:22:15,880 --> 00:22:25,330
So you can see that here. If we print out the time, it's just a string variable, but it's it's a huge string variable.

159
00:22:25,330 --> 00:22:30,550
So you look at the length and it's over 14,000.

160
00:22:31,390 --> 00:22:34,930
So there's like there's 14,000 characters in this text file.

161
00:22:35,410 --> 00:22:40,930
So it just stores it as a huge yeah, basically a huge long string.

162
00:22:42,760 --> 00:22:54,669
So I mean, if we're thinking of this as like a text file representing some data set, that's usually not an ideal way to store your data.

163
00:22:54,670 --> 00:23:01,410
You want to organize it in a better way eventually.

164
00:23:03,610 --> 00:23:05,530
So I guess the, you know,

165
00:23:07,000 --> 00:23:16,840
probably at least a somewhat better way of kind of organizing that data is to at least kind of separate things into different lines.

166
00:23:16,840 --> 00:23:22,540
So like different lines in a text file list if it's storing a data set.

167
00:23:23,620 --> 00:23:27,370
Separate lines usually represent separate observations.

168
00:23:28,030 --> 00:23:35,920
Okay. So one way to do that is just to use read the top, read lines instead of that read.

169
00:23:36,040 --> 00:23:39,160
So here in this case, we use dot read.

170
00:23:39,700 --> 00:23:45,940
But if we do without reading the lines instead, it'll kind of read everything in line by line.

171
00:23:46,750 --> 00:23:50,600
Okay so that'll it'll store do list instead.

172
00:23:50,700 --> 00:24:01,660
So each kind of, each element of the list will be a block will contain the contents from a single line in that file.

173
00:24:01,900 --> 00:24:14,110
Okay. So if you see that you see this example here, you're going to have the same thing with with open as file object.

174
00:24:14,800 --> 00:24:18,640
But here I'm using three lines instead.

175
00:24:19,300 --> 00:24:25,820
So here in this case, Bowen OBS will be a this is going to be a list placement.

176
00:24:27,190 --> 00:24:31,540
And so the length of that list is like the number of lines in the text file.

177
00:24:32,440 --> 00:24:41,020
And so here I've done a loop where I just print it out the first, the first three elements of the list, basically.

178
00:24:41,980 --> 00:24:47,740
So that's going to print out the first three lines of the text file.

179
00:24:48,430 --> 00:24:51,540
And that's what's done. That's what's printed out here.

180
00:24:51,550 --> 00:24:54,550
This is like the if you are open up the text file.

181
00:24:54,550 --> 00:24:57,580
This is the first line of the text file.

182
00:24:58,090 --> 00:25:01,950
This is the second line of the text file. This is the third line.

183
00:25:03,700 --> 00:25:12,249
So it's basically on each element of the list is, I think, extremely strange.

184
00:25:12,250 --> 00:25:18,760
And what should the strangest just hold of the contents from a single line in the text file on.

185
00:25:21,890 --> 00:25:25,060
Okay. Okay.

186
00:25:25,100 --> 00:25:36,770
So this is just to make things look a little bit nicer. So those four lines and the gaps, I think in the previous one,

187
00:25:36,770 --> 00:25:46,860
that's just because it's including like all of the like the whitespace in the text file as part of the string or,

188
00:25:47,000 --> 00:25:51,530
you know, part of the string that it's extracting for each line.

189
00:25:52,010 --> 00:26:01,940
So you can, you can avoid that by using our strip method.

190
00:26:02,570 --> 00:26:06,020
So here we did.

191
00:26:09,860 --> 00:26:14,940
Oh yeah. I guess there's an easier way to do it when we first read it in length.

192
00:26:15,680 --> 00:26:30,530
I guess I just did it this way. Like after you read in the data set, I just created kind of another I created another list,

193
00:26:30,530 --> 00:26:41,659
I'm going to call it bog cleaning and that's just going to have the catch is going to have a list that stores the information from each line,

194
00:26:41,660 --> 00:26:47,180
but it's not going to have all of that extra whitespace. So I just did that with a loop.

195
00:26:47,810 --> 00:26:59,390
I have a loop that loops over and starting from zero up to the the length of the first list that we have extracted bone jobs.

196
00:26:59,990 --> 00:27:11,809
And then I just do our strip that kind of just takes the it takes this list here and

197
00:27:11,810 --> 00:27:16,680
it kind of removes all of the the whitespace that's that's at the end of it all,

198
00:27:16,720 --> 00:27:21,950
the up space to the right, it's kind of at the end of the string.

199
00:27:22,070 --> 00:27:26,180
Okay. So it basically just removes all of the whitespace at the end of the string.

200
00:27:26,750 --> 00:27:31,760
And then I'm just using the append method to add it to the bone clean list.

201
00:27:32,390 --> 00:27:38,840
Okay. Okay. So now thumb clean is also a list.

202
00:27:38,960 --> 00:27:46,040
It has the same number of elements as both jobs, but it just doesn't have all that kind of extra whitespace on each of the strings.

203
00:27:46,040 --> 00:27:55,090
So in that here, if we print it out, if we print out like the first five elements of a bold clean, it kind of looks a lot nicer.

204
00:27:55,400 --> 00:28:04,600
So everything's going to be looks a lot closer to what you would expect in open up on the baseline.

205
00:28:05,900 --> 00:28:15,020
Okay. Now, is it for just the basic open of and read ingredient?

206
00:28:15,530 --> 00:28:21,990
That's kind of how it works, at least for if you're just opening kind of a text file or you know,

207
00:28:22,010 --> 00:28:27,290
kind of each row represents like a separate observation from a data set.

208
00:28:31,190 --> 00:28:39,589
I guess the the only kind of one of the other major type of text file is a C USB file.

209
00:28:39,590 --> 00:28:44,900
So it's, it's a text file with comma separated values.

210
00:28:45,540 --> 00:28:53,270
So, you know, kind of all of the individual kind of data points are separated by commas in this case.

211
00:28:56,480 --> 00:29:05,510
So you can still use like open and all of that and read lines to read in the CSP file number here.

212
00:29:06,050 --> 00:29:17,450
So I'm just I didn't read lines from the CSP file and I'm assigning it to the variable Bowen CSP.

213
00:29:17,840 --> 00:29:24,590
So now Bowen CSP should be a list and then I'm done here.

214
00:29:24,590 --> 00:29:27,770
I'm just putting out the first five elements of that list.

215
00:29:28,370 --> 00:29:35,710
So you can see here again, we have all of this extra whitespace that I used.

216
00:29:35,730 --> 00:29:41,750
One of the main differences now is that we have kind of commas between all of the kind of the individual

217
00:29:41,750 --> 00:29:49,010
data points because it's just it's just reading it and it's reading in the CSP file directly.

218
00:29:49,010 --> 00:29:57,230
It's not really removing the commas or anything that's kind of just reading all of the all of all of the text.

219
00:29:57,920 --> 00:30:07,610
Okay. Okay. So, again, if you want to use it again, we want to do the same thing.

220
00:30:07,610 --> 00:30:17,060
We want to kind of remove all the whitespace to the right. I guess the only other thing that we want to do is remove these commas.

221
00:30:18,080 --> 00:30:27,950
So to remove the whitespace, you can use this ah, strip that removes the whitespace.

222
00:30:27,950 --> 00:30:34,429
And then also at the same time you can use to replace the method in the replace method

223
00:30:34,430 --> 00:30:41,210
replaces a character with your first argument as the like the character you want to replace,

224
00:30:43,520 --> 00:30:48,410
the character you want to replace. And then the right is like the thing you want to replace it with.

225
00:30:49,190 --> 00:30:58,510
So kind of what this is saying is that we want to replace all of the comments within a single or a single whitespace.

226
00:30:58,520 --> 00:31:09,559
Okay. So that's all that is saying. So that's all that's saying.

227
00:31:09,560 --> 00:31:12,980
I guess we needed another. I added this because we need another replace.

228
00:31:12,980 --> 00:31:17,600
I also want to replace the quote, the quotation marks with whitespace as well.

229
00:31:18,800 --> 00:31:28,180
So I kind of did it in two steps, like in the first case, first it was ours, and then this next thing I get rid of.

230
00:31:28,710 --> 00:31:34,830
The quotes from registry is in the previous one, we have these kind of quotes on there.

231
00:31:35,180 --> 00:31:43,130
These are like variable names. And then we had quotes on this on the values for this variable here.

232
00:31:43,890 --> 00:31:48,290
So I just want to get rid of those so I can just do replace twice.

233
00:31:49,410 --> 00:31:54,770
So first case, we're getting rid of the commas and we get rid of the quote being quotation marks.

234
00:31:55,370 --> 00:32:05,420
Okay, so now I print things out, which it looks like this is just kind of a little bit of a better looking dataset.

235
00:32:06,920 --> 00:32:23,840
So that's yeah, that's how you can use open and a few of the other cases kind of string cleaning functions to,

236
00:32:23,870 --> 00:32:30,800
to read in the contents of the text file. I would say that for like CSP files, you're generally,

237
00:32:32,690 --> 00:32:41,420
especially if you're doing like so if they're like at the CSP files are if

238
00:32:41,540 --> 00:32:45,920
they represent data that can be separated into like rows and columns nicely,

239
00:32:49,610 --> 00:32:52,870
I would just use read up, read, underscore CSP from pamphlets.

240
00:32:52,940 --> 00:33:01,190
Basically, if you if you just use that directly, it kind of reads everything else into a data frame that we're going to talk about later.

241
00:33:01,190 --> 00:33:05,750
It kind of just reads everything into a data frame nicely, so I probably just use that.

242
00:33:07,940 --> 00:33:17,390
I mean, there are other, I think, packages that kind of specialize in reading and system files nicely, such as the CSP package.

243
00:33:17,450 --> 00:33:22,460
But if you're doing like a lot of data analysis on.

244
00:33:26,010 --> 00:33:33,079
Data sets that have that are kind of organizing the rows and columns, you're probably going to use pandas anyway.

245
00:33:33,080 --> 00:33:39,620
So I would just use B and C, USB from pandas basically is the way to go.

246
00:33:39,620 --> 00:33:45,440
I would really I would say. Yeah.

247
00:33:45,530 --> 00:33:58,310
I just had a little comment about writing files or writing a text to a text file.

248
00:34:02,180 --> 00:34:20,780
So basically this is as important if you want to write something like a collection of strings to a to a text file.

249
00:34:21,380 --> 00:34:25,190
So basically you write it to a file like each.

250
00:34:25,820 --> 00:34:34,070
Each string will be on a separate line. I can use kind of the same kind of the same syntax you do with open.

251
00:34:36,560 --> 00:34:40,850
However, you have to add the second argument and then give it a W in quotes.

252
00:34:40,850 --> 00:34:47,840
That just means that it's saying you're going to write something to a file and then.

253
00:34:54,950 --> 00:35:02,360
If you have kind of a if you have multiple strings that you want to write to a file, you're going to have to flip things inside of a loop like this.

254
00:35:02,960 --> 00:35:10,970
And then you kind of each time you go inside the loop, you write the name of the name you have here.

255
00:35:10,970 --> 00:35:20,780
Dot Right. And then each time you go inside the loop, you're basically writing a separate string to that line.

256
00:35:21,260 --> 00:35:27,530
And then you have to include this character here and it's this new line character backslash.

257
00:35:27,530 --> 00:35:36,589
N You can just make sure that just makes sure that each kind of string that you write is on a separate line.

258
00:35:36,590 --> 00:35:46,460
It's just not just one big string on a single line, which is to me, in most cases, you usually want it to be kind of everything on a separate line.

259
00:35:48,230 --> 00:35:52,969
So that's how you can do, that's how you can write something to a file.

260
00:35:52,970 --> 00:36:03,140
So for example, if you save the contents, have up in a big list to some text file, this is how you would do it.

261
00:36:08,260 --> 00:36:14,709
You think this is just printing out kind of like the length, the number of characters when it does this, when you do this writing,

262
00:36:14,710 --> 00:36:21,430
it turns out that these characters in the string that it's written, that's kind of why I'm showing them.

263
00:36:22,480 --> 00:36:30,710
Okay. So that's yeah, that's just some basics about reading in the contents of text files.

264
00:36:33,100 --> 00:36:39,890
The rest of the class, basically, the pattern is really just pandas data frames.

265
00:36:39,910 --> 00:36:46,190
Taito data frames are really kind of the main, main feature of, of of pandas.

266
00:36:46,210 --> 00:36:53,770
So basically what the pandas data frames are and how to learn how to work with them.

267
00:36:54,490 --> 00:37:01,270
Okay, so let's do this one to do this iris data set again.

268
00:37:02,050 --> 00:37:11,500
So again, this is kind of the same. This is from s k learned on data sets library.

269
00:37:14,290 --> 00:37:23,619
So it's kind of trying to do the same thing, but they have an option to load in the iris data set as a data frame.

270
00:37:23,620 --> 00:37:28,870
That's basically. So I think last time we loaded it in as a as a numpy array.

271
00:37:29,980 --> 00:37:34,389
So they had different options for how to load in the load in the data.

272
00:37:34,390 --> 00:37:45,430
So one option was the numpy, was it not the array, which we did last time, but one option is to load it in as a pandas data frame instead.

273
00:37:45,910 --> 00:38:00,730
So if you add this argument as frame equals true, that will mean that it loads the data and has a pandas dataframe.

274
00:38:00,880 --> 00:38:10,740
Okay, so if we run this code basically iris underscore def, that's going to be a it's going to be a pandas dataframe, basically.

275
00:38:14,270 --> 00:38:20,350
So one, one of the methods that you can use with pandas data frames is the head method.

276
00:38:20,890 --> 00:38:30,880
And just that just is something that is a command that lets you look at the first few rows of the dataset basically.

277
00:38:31,510 --> 00:38:37,270
So finding like Iris underscored DF Dot Head and I put five in parentheses.

278
00:38:37,930 --> 00:38:44,650
All that means is, is it's just going to print out the first five rows of the data.

279
00:38:45,520 --> 00:38:55,659
Okay. So this is this doesn't really do anything in terms of ventilating the dataset.

280
00:38:55,660 --> 00:39:04,600
But this is I mean, it's just useful. A lot of times I do this 1/1 read in a data set just to just to see what the

281
00:39:04,600 --> 00:39:09,790
dataset looks like and kind of check that everything is right in properly.

282
00:39:10,510 --> 00:39:20,590
So this just gives you a sense of kind of what the variables are, what kind of what what typical numbers in the dataset look like.

283
00:39:20,600 --> 00:39:25,719
So if you just do have a something, it's just kind of useful to see what the dataset looks like.

284
00:39:25,720 --> 00:39:33,100
So this has the leave. It has like last time you should have four variables.

285
00:39:33,220 --> 00:39:36,220
So here you have these four variables.

286
00:39:37,300 --> 00:39:42,370
We loaded the data frame and the variable name show nicely when we print it out.

287
00:39:43,120 --> 00:39:48,520
And these are kind of the first four observations for each of these four variables.

288
00:39:49,240 --> 00:39:53,050
Okay. Okay.

289
00:39:53,060 --> 00:40:03,129
So I would say often you usually wait for data frames.

290
00:40:03,130 --> 00:40:11,320
You're often going to be reading in a data frame either from like some library or reading it directly from a text file.

291
00:40:12,310 --> 00:40:20,390
However, you can kind of can create it directly almost by typing it in, although it's, you know,

292
00:40:20,680 --> 00:40:28,150
it's probably not as common, it's not that practical, a large dataset, but you can do it.

293
00:40:29,020 --> 00:40:36,340
The way you would do it is just to like convert and basically convert a dictionary directly into a data frame.

294
00:40:37,210 --> 00:40:41,800
So if you're converting like a dictionary directly into a data frame,

295
00:40:42,340 --> 00:40:54,190
the keys of the dictionary play the role of the the variable names and then add the values for each key user, like the observations for that variable.

296
00:40:54,940 --> 00:41:04,120
So basically you're typically going to have a string as one of the keys in the dictionary.

297
00:41:04,210 --> 00:41:09,850
So be like the variable names and the associated value will be like a list of something.

298
00:41:09,850 --> 00:41:13,780
And so those are the, the observations for that key.

299
00:41:13,930 --> 00:41:18,010
Okay. So I've just done a little example here.

300
00:41:18,430 --> 00:41:24,190
I had first create this dictionary called State 77 underscore dict.

301
00:41:25,420 --> 00:41:33,430
So this is a dictionary, it has like four TS for each key.

302
00:41:34,210 --> 00:41:44,290
I have a list of, of like five. So these kids are going to be the names of variables in like the data set.

303
00:41:44,860 --> 00:41:49,360
And they and these are like the, the values.

304
00:41:49,590 --> 00:41:55,510
The values are like the kind of the the observations, basically.

305
00:41:58,060 --> 00:42:02,560
So that's how it's going to look when we convert this into a data frame.

306
00:42:03,310 --> 00:42:10,030
So if I want to convert this dictionary into a data frame, you just use the data frame function.

307
00:42:10,030 --> 00:42:19,450
Although I mean I usually have to write it as PDX data frame because this is the how we're using it from the PANDAS library.

308
00:42:20,890 --> 00:42:28,150
So that's again, if you import PANDAS as PD, which is usually kind of the typical way for importing pandas.

309
00:42:28,150 --> 00:42:37,000
So import pandas, as all of the functions are used from the PANDAS library, you have to do something.

310
00:42:37,000 --> 00:42:47,920
So to convert this dictionary into a data frame and just do PDI DataFrame and then the name of the dictionary.

311
00:42:47,920 --> 00:42:59,620
So this when you run this now state 77 underscore DFA this should be a like a pandas dataframe.

312
00:43:01,660 --> 00:43:03,370
So you can see that when we print it out,

313
00:43:04,150 --> 00:43:16,450
you just turn out state 77 underscore D.F. that prints out and prints out the entire data frame the data frames not that big.

314
00:43:17,110 --> 00:43:20,890
There's only four variables name, region, pop and area.

315
00:43:21,520 --> 00:43:27,250
And then there's like five rows of different observations.

316
00:43:27,880 --> 00:43:32,020
So one, two, three, four, five rows, right?

317
00:43:34,180 --> 00:43:43,210
So you can see that if you want to see the dimensions of your data frame, you can just do that shape.

318
00:43:43,780 --> 00:43:51,400
So if I do, for instance, 77, the dot shape that prints out a number of rows and columns.

319
00:43:52,120 --> 00:43:55,300
So here we have the number of rose five.

320
00:43:55,960 --> 00:44:01,630
Number of columns is four. So shape that shape gives you the dimensions of your data frame.

321
00:44:02,510 --> 00:44:07,200
So useful to know. I mean, it's more useful if you have a larger data for him.

322
00:44:07,390 --> 00:44:11,170
In this case, you could just you can just see indirectly how big it is.

323
00:44:11,170 --> 00:44:18,760
But a few of the larger data are useful to see how many rows and columns you have.

324
00:44:22,400 --> 00:44:33,740
So I just point out one thing. So each column of each column, all the elements from that column have to have the same have to have the same type.

325
00:44:34,460 --> 00:44:41,810
So like if we look at the population column, all of these are numbers, same thing for the area.

326
00:44:42,600 --> 00:44:51,110
This column, all of these are numbers and the name variable, all of these are like strings.

327
00:44:52,940 --> 00:44:57,740
So within each column, all of the kind of all of the elements have to have the same type.

328
00:44:58,490 --> 00:45:08,900
It's kind of a rule for data frames. So they can have different types of like looking at different columns like region versus pop.

329
00:45:10,340 --> 00:45:13,790
One of them is a string one. One of them has strings. One of them has numbers.

330
00:45:14,270 --> 00:45:20,929
Within a column, they all have to have the same type. Okay.

331
00:45:20,930 --> 00:45:24,040
So it's just kind of normal for data frames.

332
00:45:24,050 --> 00:45:31,790
Each column column tend to have the same type. You can see the types of each of the columns.

333
00:45:31,790 --> 00:45:41,269
If you just look at the name of the data frame and then you've got D types that'll print out the problem type.

334
00:45:41,270 --> 00:45:50,960
So I think you can get close stranger or character type variables as it considers an object.

335
00:45:53,480 --> 00:46:03,550
And then the property we are both numeric in this area is a float and then pop is integer.

336
00:46:03,570 --> 00:46:12,780
These are all integers. So another useful method is describe.

337
00:46:13,430 --> 00:46:23,149
So that basically just I think summarizes your dataset or at least summarizes your numeric variables.

338
00:46:23,150 --> 00:46:29,810
Basically there's a dozen to summarize the non numeric variables.

339
00:46:30,800 --> 00:46:36,620
So like this data set has two numeric variables, pop and area.

340
00:46:37,280 --> 00:46:49,040
So if I just do state 77 default describe that just prints out kind of like summary measures for each of the each of the numeric variables.

341
00:46:49,040 --> 00:46:57,480
So just tells you. Oh, well, you know, Kelvin's not really.

342
00:46:58,560 --> 00:47:06,310
I mean, you already know the number of roles that just really the number of observation observations tells you that in fact,

343
00:47:06,330 --> 00:47:13,740
the mean of the numbers in that variable. Standard deviation, the minimum maximum, the median.

344
00:47:14,430 --> 00:47:20,190
And then the first quartile, 25%, third quartile, 75%.

345
00:47:20,200 --> 00:47:26,270
So just kind of gives you a summary of kind of the numbers of that in that column, basically.

346
00:47:27,510 --> 00:47:33,900
So you get the median standard deviation, median 25th 57 percentiles.

347
00:47:34,470 --> 00:47:40,800
So it's often useful just to get to get a sense of what the spread of the numbers and certainly in certain columns.

348
00:47:43,380 --> 00:47:45,370
Okay. So yeah, I think I said before,

349
00:47:45,370 --> 00:47:55,589
for if you're if you're working with pandas and you have a text file where kind of everything's organized into rows and columns,

350
00:47:55,590 --> 00:48:06,240
I think the best way to read in that data is just to use read mean CSB, basically read, underscore CSB.

351
00:48:07,200 --> 00:48:16,290
And that just basically reads in the CSB file quite directly as a data frame kind of automatically you don't really have to do any extra work.

352
00:48:17,070 --> 00:48:18,510
I mean, that's makes it easy.

353
00:48:20,100 --> 00:48:30,210
So the basic networks, you just do feed, dot, read, underscore CSB and then you give it kind of file path in quotation marks.

354
00:48:31,890 --> 00:48:44,520
So I have that bone, that CSV file, it's often stored on my computer at home and kind of has this file, this file path, which is where it's stored.

355
00:48:44,820 --> 00:48:47,520
It's kind of in this older stuff.

356
00:48:47,520 --> 00:48:59,759
I just want to read that into Python and you can just do barn equals B PD dot where can see as B is given this file path name inside courts.

357
00:48:59,760 --> 00:49:06,870
And then now once you run this code once, once you've run this line, bond should be a pandas dataframe.

358
00:49:08,860 --> 00:49:16,600
Okay. So I've got to run that.

359
00:49:16,610 --> 00:49:20,690
And, you know, one of the first things you might do is just to look at the first few rows.

360
00:49:21,350 --> 00:49:22,820
So again, you could do that head.

361
00:49:23,180 --> 00:49:36,560
And I think so if I print out both the head, if you don't give it a number here, as it just turns out, the first five rows by default.

362
00:49:39,830 --> 00:49:46,340
I think if you give it a different number, if you want it to print out the first eight rows here by default,

363
00:49:46,340 --> 00:49:49,790
if you don't give it a number, it is print out the first five rows.

364
00:49:49,790 --> 00:49:53,660
So this is what the first five rows of this data set looks like.

365
00:49:56,930 --> 00:50:19,130
It looks like, oh, I had another I guess another somewhat common type of text file might be a tab separated file that's stored as a stock TSB file.

366
00:50:19,760 --> 00:50:23,480
So in that case, you can still then read it on your score.

367
00:50:23,600 --> 00:50:29,089
Yes. B, you have to include kind of the right centimeter.

368
00:50:29,090 --> 00:50:37,250
So this stands for separator. So it's just saying that the separator between different combinations is kind of there's a tab.

369
00:50:39,380 --> 00:50:47,930
I think there's there's other, other types of text files that re does read underscore CSP can handle.

370
00:50:50,480 --> 00:50:54,080
And for most of those cases you just have to include a different separator.

371
00:50:54,650 --> 00:51:02,390
So I thought I just mentioned this JSON and I just say that read underscore CSP can handle it can handle,

372
00:51:03,050 --> 00:51:06,650
you know non CSP files but I guess you just have to check.

373
00:51:08,390 --> 00:51:22,340
Can Google just help file for read CSP just to check these and the other did you check the syntax you have to use for for other type of text files?

374
00:51:22,370 --> 00:51:30,200
Okay. But for CSP files, you don't really have to include the extra the kind of handle CSP files directly.

375
00:51:38,810 --> 00:51:43,400
I'm not really doing runs on time.

376
00:51:43,400 --> 00:51:54,670
So I guess the rest of the class, I think there's two different ways of looking at, you know,

377
00:51:55,160 --> 00:52:01,130
looking at different subsets of data frames or manipulating data frames in certain ways.

378
00:52:02,540 --> 00:52:10,549
So that's really what kind of what you're really doing when you're doing data analysis,

379
00:52:10,550 --> 00:52:16,040
or at least if you're kind of preparing for your data set to do some type of analysis,

380
00:52:16,040 --> 00:52:27,710
you and the main steps are kind of sub setting or transforming variables or rearranging your data set in certain ways.

381
00:52:28,640 --> 00:52:37,770
Okay. So the first thing you might want to do is kind of just extract a certain variable by itself.

382
00:52:39,930 --> 00:52:46,770
So one way to do it is just to use the kind of the variable name itself inside of quotes.

383
00:52:49,500 --> 00:52:54,270
So let's say I had a variable named called var underscore name.

384
00:52:54,840 --> 00:53:04,770
We can just access the data from that single column is just to use that the name of the data frame and then put that inside of single quotes.

385
00:53:06,600 --> 00:53:16,669
You do? Right now, I'll just kind of extract the data from that single column.

386
00:53:16,670 --> 00:53:25,909
So for example, if we had this state 77 ADF data frame and then I knew inside of brackets I'd put the name of the

387
00:53:25,910 --> 00:53:33,530
variable inside a single quotes that'll basically return all of the data from the public column.

388
00:53:33,740 --> 00:53:43,340
Okay, so this is the data from the pop column and you can also do kind of multiple variables.

389
00:53:44,130 --> 00:53:49,490
And at one time in that case, you want to use like a list of names.

390
00:53:50,360 --> 00:53:56,630
So if you want to extract like the data from only the pop and area variables,

391
00:53:57,440 --> 00:54:05,890
you can use a similar thing in the name of the data frame and then inside of bracket the brackets, I give it a name.

392
00:54:06,660 --> 00:54:11,150
You had a list of strings rather than like a single string. Okay, so this will return.

393
00:54:11,960 --> 00:54:17,990
This will return a data frame with two columns and it's all going to include data

394
00:54:17,990 --> 00:54:26,090
from these two columns pop in area from the original like state 77 PDF DataFrame.

395
00:54:26,090 --> 00:54:31,130
So this is, this is, this is a data frame with two columns.

396
00:54:33,310 --> 00:54:44,470
You can see that here. If I look at the type of this subset of state 77 def you know type of it is a pandas dataframe.

397
00:54:45,190 --> 00:54:52,030
Right. So that's what it's saying there. Okay.

398
00:54:57,650 --> 00:55:08,150
Okay. So, yeah, this is just I didn't mention this just because, you know, often in some cases you have a lot of variables.

399
00:55:08,150 --> 00:55:12,110
And if you look at just the first five rows, it's hard to say.

400
00:55:13,790 --> 00:55:15,950
It's hard to see all of the variable names at once.

401
00:55:16,000 --> 00:55:28,220
If you just want to make a list of the the full list of the variable names, you could just do the name of the dataframe dot columns.

402
00:55:28,820 --> 00:55:33,440
Okay. So if I just do write the name of the data frame columns.

403
00:55:38,180 --> 00:55:44,930
That should return list to the column names.

404
00:55:44,930 --> 00:55:49,310
Basically, these are all the column names from our data frame.

405
00:55:49,850 --> 00:55:53,630
Okay. That's how you can like extract all of the column names.

406
00:55:54,380 --> 00:56:04,820
Okay. So the other thing I mentioned, this is just an alternative way to access specific columns of a data frame.

407
00:56:04,890 --> 00:56:11,960
So the first one we mentioned was accessing the columns by the names of the variables.

408
00:56:12,440 --> 00:56:17,110
The other way is accessing by like the index number.

409
00:56:17,120 --> 00:56:26,040
So if you want to access like the first variable, you can use the index zero or the third variable by the index to contribute.

410
00:56:26,070 --> 00:56:35,300
So that's in some cases a, you know, a better way to access certain columns from a data frame.

411
00:56:36,350 --> 00:56:47,630
Okay. So the way you do that is you give it the name of the data frame that is Select, Evoke, and then kind of access,

412
00:56:48,260 --> 00:56:55,639
access to the contents in kind of the same way you would with like a numpy array here or just

413
00:56:55,640 --> 00:57:01,550
getting all of the of the data for all the rows and we're getting it from like a specific column.

414
00:57:02,360 --> 00:57:06,580
Specific column. Okay. So this is useful.

415
00:57:07,010 --> 00:57:16,640
If the columns like don't have neighbors, you don't necessarily have to give, have, have you don't necessarily have to give the columns names.

416
00:57:17,780 --> 00:57:30,670
And then just some cases, depending on where you've written your code, and it's just easier to work with the index values rather than column names.

417
00:57:30,680 --> 00:57:42,050
It's just, it's just more convenient. So it's, it's good to be able to access different columns this way rather than only using variable names.

418
00:57:43,710 --> 00:57:46,820
Oh. Why don't I put it here?

419
00:57:48,250 --> 00:58:00,220
That was the first thing. Oh, that's a tiny.

420
00:58:01,690 --> 00:58:10,180
Yeah. So that's the first you want to look at the first variable of state 77 if you would use the use of this dot I look.

421
00:58:13,930 --> 00:58:18,910
Holden zero carbon 0.7 index zero gives us the first column.

422
00:58:20,140 --> 00:58:25,920
So that's just an alternative way to access the data from the first the first column.

423
00:58:26,600 --> 00:58:31,360
So yeah, this is like the first variable.

424
00:58:31,360 --> 00:58:32,440
I would say it that way.

425
00:58:35,350 --> 00:58:43,750
If you're using alone, you can basically kind of access elements from your data frame, basically the same way as you would with like a numpy array.

426
00:58:45,510 --> 00:58:48,670
You know, if you're thinking of your data frame, it has rows and columns,

427
00:58:49,300 --> 00:58:57,430
so you can access all of the elements kind of using data with the exact same syntax as you would with a computer.

428
00:58:57,610 --> 00:59:10,120
So you wanted to access kind of all the data for all the rows from columns and column index, zero and 1/1 and the second variables.

429
00:59:10,540 --> 00:59:19,300
You could do it this way if all them then have the colon here and then in the first position and comma zero colon to.

430
00:59:23,950 --> 00:59:26,350
Alternatively, if you wanted to look at the variable,

431
00:59:26,360 --> 00:59:35,169
starting with the variable index one all the way to the last variable, you could do one colon with nothing after it.

432
00:59:35,170 --> 00:59:38,889
So one is column index one.

433
00:59:38,890 --> 00:59:52,890
So that's kind of like the second variable and you actually use the exact same slicing syntax that you would use with NumPy as long as you have this.

434
00:59:53,320 --> 00:59:59,200
But I'll look here. Okay. So index location is maybe one way to think about it.

435
01:00:02,380 --> 01:00:09,050
Okay. And again, you can access like subsets of rows using I look as well.

436
01:00:09,220 --> 01:00:19,270
You don't you don't have to extract entire columns by themselves and you can access everything exactly as you would with a number to the array.

437
01:00:19,270 --> 01:00:24,820
So if I wanted to look at just like the first two rows, I could do zero column too.

438
01:00:25,930 --> 01:00:28,810
So that's going to give us all the data from the first two rows.

439
01:00:30,370 --> 01:00:37,990
If I want to look at the first three rows and first two columns, I could do it this way.

440
01:00:38,560 --> 01:00:43,959
This is going to extract all the data from the first three rows and first two

441
01:00:43,960 --> 01:00:48,220
columns of all the data from the first three rows and the first two columns.

442
01:00:51,550 --> 01:01:00,520
Okay. Oh, yeah. So you can do a rose or a little bit?

443
01:01:01,830 --> 01:01:17,190
Uh, yeah. You can access things by name with row names, but you have to use and you have to use this this low, rather,

444
01:01:17,650 --> 01:01:26,290
just to indicate that you're using the rose rather than just giving it the variable name itself when we're accessing columns.

445
01:01:26,950 --> 01:01:30,700
Okay, Carlos. By themselves. Okay. Okay.

446
01:01:30,700 --> 01:01:36,520
So let's just say we wanted to access certain rows using the row names.

447
01:01:37,330 --> 01:01:44,170
So I printed it out for the for this for this data frame.

448
01:01:45,310 --> 01:01:48,550
The rows are the row names are just zero, one and two.

449
01:01:49,330 --> 01:01:55,600
So you see, turn it off. Here are are the row names of the data frame.

450
01:01:58,930 --> 01:02:10,360
If you don't specifically gives you the row names, it usually just gives numbers starting from 0012 up to the and then the data set over.

451
01:02:10,620 --> 01:02:16,570
You can can give it, you know, special note row names if you want.

452
01:02:17,380 --> 01:02:30,310
Kind of by default, you need to be thrown into these numbers here.

453
01:02:30,490 --> 01:02:43,510
Okay. So in this case, the row names are just these these characters, zero in quotes, one in calls, etc., etc.

454
01:02:48,040 --> 01:02:57,610
Okay. So if I wanted to make this kind of maybe slightly more realistic, you can you can give it row names.

455
01:02:58,300 --> 01:03:07,240
So the way you give it row names is like this this dot index are you kind of give it kind of real row names.

456
01:03:08,590 --> 01:03:12,700
So here I'm changing the rotate.

457
01:03:12,710 --> 01:03:26,530
So the you know the index part is state 77 DF that stores the row names so if I say state 77 DF that index equals this list of strings,

458
01:03:27,250 --> 01:03:33,430
that just means that now the row names are row one, row 203 or 405.

459
01:03:36,750 --> 01:03:45,360
If I want to access all of the data from like all the row with row name row one,

460
01:03:45,870 --> 01:03:54,320
I can just do state 77 def dot loke and then I give it row one in the first position and column.

461
01:03:55,470 --> 01:04:05,820
Oh crap. So that just basically extracting all of the data from the row with row name, row one.

462
01:04:07,030 --> 01:04:13,310
So that's what's printed here. This is like all of the data from row one of.

463
01:04:16,350 --> 01:04:21,180
So that's yeah, I think that's basically all I wanted to say about real names.

464
01:04:23,460 --> 01:04:33,950
So you can extract data from a specific row if you want to use the row name rather than the index location metrics.

465
01:04:36,280 --> 01:04:44,020
Okay. So the next thing we wanted to get into is boolean indexing.

466
01:04:44,620 --> 01:04:59,310
So. You can use boolean indexing with low to take kind of take a subset of rows of your data frame.

467
01:05:01,770 --> 01:05:13,020
So for example, in this case, let's say we wanted to subset the data frame only keeping the rows where the region is equal to south.

468
01:05:13,680 --> 01:05:21,030
Right. So in that case, you can use the following syntax, which is the dot lock.

469
01:05:21,030 --> 01:05:31,620
But here I'm using have a boolean expression in the in kind of the row position of the, of the brackets.

470
01:05:32,250 --> 01:05:35,370
Okay. So I have a boolean expression.

471
01:05:35,970 --> 01:05:39,210
So this is going to say the shift.

472
01:05:39,390 --> 01:05:44,700
This is just true where the elements of the the region column.

473
01:05:44,880 --> 01:05:49,050
So this is this is how we extract the region column, right?

474
01:05:49,080 --> 01:05:57,690
State 77 F region And this Boolean expression is saying whether or not the region is equal to south.

475
01:05:58,650 --> 01:06:04,260
So this is going to always keep the rows where this kind of boolean expression evaluates to.

476
01:06:04,260 --> 01:06:13,490
True. Okay. So you can see here. This is basically a data frame.

477
01:06:14,070 --> 01:06:26,770
It's only keeping the two rows where the region itself. Okay.

478
01:06:26,770 --> 01:06:34,329
So for you, this is just basically another example of Boolean sub setting Boolean indexing.

479
01:06:34,330 --> 01:06:39,370
So here is our the bone data that we loaded in earlier.

480
01:06:39,760 --> 01:06:41,020
This is kind of what it looks like.

481
01:06:41,020 --> 01:06:49,450
Just a reminder, let's say we wanted to create another like a subset of this state of brain called bone underscore alt 12.

482
01:06:49,870 --> 01:06:54,850
It's basically going to contain only the observation where age is less than 12.

483
01:06:55,510 --> 01:07:01,000
So you can see here some of these some of the ages are less than 12, some are greater than 12.

484
01:07:01,510 --> 01:07:06,100
Let's just say we're only interested in the observations where age is less than 12.

485
01:07:07,090 --> 01:07:18,760
So if you create that smaller data frame only t 12 by just doing bone look then in kind of the real position, I give it this Boolean expression,

486
01:07:20,290 --> 01:07:31,029
this boolean expression should what it should return is like a boolean array with the same length as the number of rows in the dataframe.

487
01:07:31,030 --> 01:07:39,370
So here we have we're looking at the age variable for born and then just whether or not that is less than 12.

488
01:07:41,800 --> 01:07:47,290
So you can see here now once we've tried it, once they have created this other data frame,

489
01:07:47,290 --> 01:07:51,460
when we print it out, after we print out the first five rows, it looks like this.

490
01:07:52,240 --> 01:07:57,310
So you can see here all all of the ages in the first five rows are less than 12.

491
01:07:58,660 --> 01:08:05,140
And you can see it. And I mean, even if we print out the full dataset, all of the age it should be should be less than 12.

492
01:08:09,460 --> 01:08:15,690
And then. I'm.

493
01:08:22,950 --> 01:08:28,140
Why is it not included? I have to check the code again, not print out.

494
01:08:31,480 --> 01:08:35,460
I'm just wondering why I didn't print out the age variable.

495
01:08:43,110 --> 01:08:54,269
Cut off. How do you describe? Oh, I think I don't think I forgot to put the code here.

496
01:08:54,270 --> 01:08:57,690
I think. I think I only described the.

497
01:09:00,780 --> 01:09:07,760
I think I probably did describe only for the. But this is this variable span.

498
01:09:08,310 --> 01:09:18,390
BMD is variable as being indeed one of the numeric variables if it gets like mineral density change.

499
01:09:19,050 --> 01:09:27,240
So I think I'll fix the slide the beginning and something like what I did describe only for that variable.

500
01:09:28,110 --> 01:09:31,110
So here is just this kind of the summary measures for that variable.

501
01:09:31,890 --> 01:09:36,270
It's only for the for the observations with age less than 12.

502
01:09:36,540 --> 01:09:43,170
Okay. So this is kind of the summary measures mean median max and then.

503
01:09:47,720 --> 01:09:51,220
Okay. So here's yet another way to access columns.

504
01:09:51,290 --> 01:09:54,470
There's kind of there's a number of ways to do the same thing.

505
01:09:55,220 --> 01:10:02,420
And another way to do it is just to use the name of the DataFrame and just dot the name of the variable.

506
01:10:02,510 --> 01:10:10,700
It's also another way to access the data from a data frame.

507
01:10:11,630 --> 01:10:15,110
So here in this example where we have the phone data, again,

508
01:10:15,590 --> 01:10:25,399
if you wanted to access the data from the ESPN BMD variable, I can just do Bumble Dot, SP and BMT.

509
01:10:25,400 --> 01:10:36,740
So I think in many cases this may be more kind of an easier way to extract data from a particular, particular column.

510
01:10:38,120 --> 01:10:44,900
And so here, if you wanted to compute the mean, I can just do in PDB.

511
01:10:45,650 --> 01:10:54,620
So again, when you extract a specific, specific column from your PANDAS data frame,

512
01:10:55,130 --> 01:11:08,000
you can think of it as a one day numpy array and take out a single column from your data frame base and see a one dimensional numpy array.

513
01:11:09,230 --> 01:11:12,590
So then you can use kind of numpy methods on that array.

514
01:11:12,600 --> 01:11:28,100
So if I do import mean of bound span BMD, it's just taking the mean of that one de array 0.039 is the mean of that variable.

515
01:11:29,360 --> 01:11:37,010
I can use all the other numpy methods if you want to compute the median, you just do p median of the number.

516
01:11:37,070 --> 01:11:42,110
The array is the specific variable.

517
01:11:43,040 --> 01:11:46,220
So here the median is about 1026.

518
01:11:47,370 --> 01:11:57,260
I think that's it. That's it for extracting a specific variable from the main the main methods for doing that.

519
01:12:00,050 --> 01:12:05,480
Okay. So I guess another thing, let's say you wanted to add a mover variable to a data frame.

520
01:12:09,080 --> 01:12:12,739
So that often comes up if you want to create a new variable.

521
01:12:12,740 --> 01:12:18,620
That's a combination of the other variables in some ways.

522
01:12:19,800 --> 01:12:29,250
So maybe just like the sum of two other variables, you want to compute that and store that as a new variable in your data frame.

523
01:12:29,810 --> 01:12:35,110
So it's useful to know how to add a new variable to a data frame.

524
01:12:37,520 --> 01:12:42,169
So to do that, you just have to give it.

525
01:12:42,170 --> 01:12:48,020
You just have to basically use this like the name of the variable sorry, the name of the data frame,

526
01:12:48,500 --> 01:12:54,020
and then just put the name of the new variable that you want inside of quotation marks.

527
01:12:54,620 --> 01:12:58,940
That's really all you have to do, but you have to you have to assign it some value.

528
01:12:59,300 --> 01:13:08,420
Okay. So you just you're basically going to put this on the left hand side of an equals sign,

529
01:13:08,900 --> 01:13:19,490
and then whatever is to the right of the equals sign is kind of what's what you're assigning to that, which is to that new variable that.

530
01:13:26,790 --> 01:13:36,460
So for example, like in this case, let's say we wanted to calculate how to do variable call.

531
01:13:37,580 --> 01:13:43,139
You can do it this way. I can do state 77 def and then new pop equals ten.

532
01:13:43,140 --> 01:13:46,590
So you don't have to give it a single number.

533
01:13:47,130 --> 01:13:52,050
You also want to give it a bunch of different values, like an array, for example.

534
01:13:52,860 --> 01:13:59,910
But if you do give a single number, it's just going to fill in all of the other rows, basically with that.

535
01:14:01,380 --> 01:14:09,180
So you can see that here. If I look at the first four rows, all of the entries for new pop have the value ten.

536
01:14:09,790 --> 01:14:18,180
Okay. So if I if you just give it a single number, all of the entries will have that same number.

537
01:14:19,500 --> 01:14:27,719
So all they have, all values equals ten, you know, you know, sometimes you want to do that, say usually you don't.

538
01:14:27,720 --> 01:14:33,080
Usually you're defining a new variable.

539
01:14:33,100 --> 01:14:41,400
You want the entries to have different values. So for that, you're going to just assign it to a number in some way.

540
01:14:44,040 --> 01:14:52,710
So in this case I have assigned State 77 def have signed this new pop variable.

541
01:14:53,130 --> 01:14:59,800
I have assigned elements of that variable to two.

542
01:15:00,180 --> 01:15:02,520
So the components of this numpy array. Okay.

543
01:15:03,300 --> 01:15:20,400
And you can see that this numpy array has five elements, five, those are kind of the elements in and this new population pairs the six three, 11, etc.

544
01:15:24,100 --> 01:15:29,470
So it's kind of hard to assign a new variable where not everything is the same thing.

545
01:15:31,680 --> 01:15:47,260
We're basically done. But like you just mentioned, how how pandas usually represents missing values since missing bind come up quite often in.

546
01:15:50,560 --> 01:15:57,670
Real world data sets. So pandas just used as the symbol have in and to represent missing values.

547
01:15:58,270 --> 01:16:04,000
That's the way it usually handles it.

548
01:16:04,660 --> 01:16:15,819
If you're kind of typing in things by hand, like when you're creating a data frame, you would use this import in a in syntax.

549
01:16:15,820 --> 01:16:23,740
So for example, if I'm creating a new variable called VI that has two missing values,

550
01:16:25,660 --> 01:16:32,470
I would I would code that in as in Peter in a n in like a numpy array, just kind of a way to do it.

551
01:16:33,550 --> 01:16:38,700
And then when you read that and it treats that as an okay.

552
01:16:39,530 --> 01:16:44,020
You see that here when we printed out this data frame,

553
01:16:44,920 --> 01:16:57,340
these missing entries are turning out as you saw this in figure it and it's kind of a separate data type thing that's valid for a bit.

554
01:16:57,820 --> 01:17:03,730
It's kind of a separate basically data type that's meant to represent missing values.

555
01:17:05,620 --> 01:17:11,500
You know, often you're going to read in data from a CSB.

556
01:17:12,130 --> 01:17:18,010
Like, for example, I have this data, this CSB file.

557
01:17:18,010 --> 01:17:25,840
I think I also upload it to canvas in the data folder and it has kind of the same values stored as in A's.

558
01:17:26,320 --> 01:17:36,820
And again, it should read in the in A's automatically as in a solid file you're finding if I read in this CSB file using read CSB,

559
01:17:39,820 --> 01:17:49,000
it should kind of automatically, you know, put it in and wherever there are any values in the C has to be file.

560
01:17:49,990 --> 01:17:53,139
As you can see out here, I turn out the first five rows.

561
01:17:53,140 --> 01:17:58,690
It has some missing values here in a a in here.

562
01:17:59,500 --> 01:18:02,680
Okay. So that's yeah.

563
01:18:02,770 --> 01:18:12,099
Starting in a and is kind of the thing that PANDAS uses to represent missing values.

564
01:18:12,100 --> 01:18:16,710
So we're out of time.

565
01:18:16,750 --> 01:18:22,570
So. The questions are are.

566
01:18:24,110 --> 01:18:36,800
Research is ongoing because we'll stop there from today for any concerns about.

