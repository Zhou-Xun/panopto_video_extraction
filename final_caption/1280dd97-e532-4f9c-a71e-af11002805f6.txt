1
00:00:01,040 --> 00:00:07,760
okay. sorry about that.

2
00:00:07,760 --> 00:00:13,180
there's a lot more diagnostics you can do and if you have a course in statistics you should

3
00:00:13,180 --> 00:00:18,500
learn about for example regression diagnostics a lot of these tools are applicable to model

4
00:00:18,500 --> 00:00:24,140
of valuation. okay for example strata finding on particular factors which is what I'm showing

5
00:00:24,140 --> 00:00:29,240
here and one

6
00:00:29,240 --> 00:00:34,280
of the applications of statistics is

7
00:00:34,280 --> 00:00:39,280
to calculate Kim with chip density function CD ups or probability density functions

8
00:00:39,280 --> 00:00:44,340
or histograms and then compare the histogram of your model projections to

9
00:00:44,340 --> 00:00:50,620
what you're actually observe to see if the distribution match

10
00:00:50,620 --> 00:01:02,715
study test distributions. if they match what's the statistical test

11
00:01:02,715 --> 00:01:08,175
yeah what would you use for distribution

12
00:01:08,175 --> 00:01:13,195
now that THS is typically for me and

13
00:01:13,195 --> 00:01:22,935
weird distributions bathrooms. yeah.

14
00:01:22,935 --> 00:01:27,975
typically people you for the Kay asked test or something like that. so it's very statistical test

15
00:01:27,975 --> 00:01:33,155
that you could use. this is pretty rare and

16
00:01:33,155 --> 00:01:38,415
environmental model applications because of a problem. typically

17
00:01:38,415 --> 00:01:43,435
we would fail these tests. okay. and so this is kinda

18
00:01:43,435 --> 00:01:49,035
problematic. and the reason we might see

19
00:01:49,035 --> 00:01:59,887
what the distributions don't match. why don't they match

20
00:01:59,887 --> 00:02:04,887
yeah. so the actual data that you're looking at maybe pretty sparse and

21
00:02:04,887 --> 00:02:12,007
it may not be representative and then one these representative

22
00:02:12,007 --> 00:02:17,327
for example if I asked you guys how much I stuck it out p.m.

23
00:02:17,327 --> 00:02:23,887
to five how much p.m. two point five do you for you

24
00:02:23,887 --> 00:02:30,807
how to like figure that out.

25
00:02:30,807 --> 00:02:35,987
well I can put a pump on you or monitor you or something like that. but that's really

26
00:02:35,987 --> 00:02:41,367
really challenging to do and so it's hard to get good environmental data. alright

27
00:02:41,367 --> 00:02:46,367
so if you're taking a model which is obviously simplified and idealistic and then you're matching

28
00:02:46,367 --> 00:02:51,807
it's all the complexities in your life. about your p.m. two point five exposure. I didn't realize

29
00:02:51,807 --> 00:02:56,807
that you know you went into the kitchen and had a little fire and got

30
00:02:56,807 --> 00:03:01,949
a lot of p.m. two point five and the grease burned. I gonna match that right. it's just

31
00:03:01,949 --> 00:03:07,049
impossible. so representative data is defined down here. that

32
00:03:07,049 --> 00:03:12,529
has a wide range of applicability and this applies to even simpler measurements

33
00:03:12,529 --> 00:03:17,569
like wind speed and wind direction. if I ask you what size was where where was

34
00:03:17,569 --> 00:03:22,929
a wind blowing that day. when we get that data from represents what happened

35
00:03:22,929 --> 00:03:28,389
to you. even stuff like that can be challenging. okay.

36
00:03:28,389 --> 00:03:33,389
one of the terms that you'll hear a lot is outliers outliers are data point

37
00:03:33,389 --> 00:03:38,509
set difference for some reason and typically representative data we need

38
00:03:38,509 --> 00:03:43,529
to eat out what we think for the tires. so if you know anything about statistics and

39
00:03:43,529 --> 00:03:48,669
bias and you're censoring the data home I got you just created you just

40
00:03:48,669 --> 00:03:53,969
committed a cardinal soon. right censoring data which why because it looked

41
00:03:53,969 --> 00:04:03,003
like it out wired to me. don't tell your statistician failing

42
00:04:03,003 --> 00:04:08,083
sometimes linkage diagrams are used to establish because of the fact or your representation of cause

43
00:04:08,083 --> 00:04:13,783
and effect these can get fairly complicated. you can have

44
00:04:13,783 --> 00:04:20,623
actions that you might take in boxes and sort of processes occurring in

45
00:04:20,623 --> 00:04:26,123
whatever shape that is ovals and you know have different kinds of impacts and questions

46
00:04:26,123 --> 00:04:31,203
with diamonds and so forth. and you know typically

47
00:04:31,203 --> 00:04:36,563
in an environment impact statement there so many things going on. it's really really helpful to summarize

48
00:04:36,563 --> 00:04:42,243
results and this is an example of the impact matrix and you've seen these before

49
00:04:42,243 --> 00:04:47,423
and then because of the uncertainty. it's incumbent on you

50
00:04:47,423 --> 00:04:52,423
as professionals to represent the uncertainty and there's lots of ways to

51
00:04:52,423 --> 00:04:57,443
do this and this is language from one of

52
00:04:57,443 --> 00:05:02,725
the EIS is where they're fairly explicit about this and in fact they even

53
00:05:02,725 --> 00:05:08,885
talk about their assumptions for statistical test so things have really evolved

54
00:05:08,885 --> 00:05:14,225
you know I used to hear decision-makers wanna single number. don't tell me the uncertainty.

55
00:05:14,225 --> 00:05:19,305
this is gonna make people worse off. okay. and I think we've

56
00:05:19,305 --> 00:05:24,585
evolved the bids on that and I also used to be told all the time. simplified

57
00:05:24,585 --> 00:05:30,405
for the community. okay they don't have the scientific background and

58
00:05:30,405 --> 00:05:35,845
that's also seems to change. so take a lot of this. you know

59
00:05:35,845 --> 00:05:40,885
I think and communicated the lesson here. okay we talked about. building

60
00:05:40,885 --> 00:05:46,145
uncertainty and I actually do have a quip from Donald

61
00:05:46,145 --> 00:05:51,165
Rumsfeld which I could play for you. so motivated. basically he

62
00:05:51,165 --> 00:05:58,125
says there are no noes. so you probably wanna hear the quick who's gone room stilled

63
00:05:58,125 --> 00:06:06,027
your member

64
00:06:06,027 --> 00:06:11,087
yeah yeah yeah in fact. so anyway

65
00:06:11,087 --> 00:06:16,107
he says no noes users inside we know there are known unknowns.

66
00:06:16,107 --> 00:06:22,287
are there things that we know we don't know but there are also unknown unknowns.

67
00:06:22,287 --> 00:06:27,667
okay and these are things we don't know we don't know actually there's four categories

68
00:06:27,667 --> 00:06:33,007
that they're gonna replace us way the point is um you know obviously

69
00:06:33,007 --> 00:06:38,293
we have limits to what we're encapsulating in our knowledge base Milton Friedman

70
00:06:38,293 --> 00:06:43,653
of Noble laureate says about models they should be judged by the realism of the assumptions

71
00:06:43,653 --> 00:06:48,873
but by the realism of their predictions business and it your you where you doesn't

72
00:06:48,873 --> 00:06:54,653
really care so much about whether he's representing the mechanisms and processes

73
00:06:54,653 --> 00:07:01,713
correctly but he just cares about the result. what do you think

74
00:07:01,713 --> 00:07:07,033
about this. can we use models represent

75
00:07:07,033 --> 00:07:22,133
the predictions correctly. so I don't think protection

76
00:07:22,133 --> 00:07:27,273
will ever stop you know I mean if your date is that

77
00:07:27,273 --> 00:07:32,313
where you go from there. okay. or if

78
00:07:32,313 --> 00:07:37,594
you're in. sister not making assumptions except that the data can guide

79
00:07:37,594 --> 00:07:50,434
you yeah

80
00:07:50,434 --> 00:07:55,434
yeah yeah so I mean he's an economist so he might make a prediction

81
00:07:55,434 --> 00:08:06,114
that you know next year 's economy is gonna see a change in exports or something

82
00:08:06,114 --> 00:08:12,714
you're very hard. so

83
00:08:12,714 --> 00:08:17,794
as well. I mean you can use any of the statistical performance techniques distributions could

84
00:08:17,794 --> 00:08:23,614
master could be high correlation the means could match the coming.

85
00:08:23,614 --> 00:08:28,674
I mean I've done some projections where you know for example I predicted

86
00:08:28,674 --> 00:08:33,678
what I saw recruitment rate would be in a big study okay which is

87
00:08:33,678 --> 00:08:38,678
really important to know because you know you might have to talk to a hundred people before you get five people

88
00:08:38,678 --> 00:08:43,818
enrolled in the study. and I nailed. it okay. I was thrilled. alright.

89
00:08:43,818 --> 00:08:53,998
where did that come from how did I make that prediction.

90
00:08:53,998 --> 00:09:00,038
we had no data we had never tried to do this before in this city.

91
00:09:00,038 --> 00:09:05,218
expert judgment. I just got lucky. or

92
00:09:05,218 --> 00:09:10,758
are you know on the other hand I mean I could use a application of very sophisticated model NEPA model

93
00:09:10,758 --> 00:09:15,958
and I might be fifty percent off maybe fifty percent hot

94
00:09:15,958 --> 00:09:21,118
very different type of example. these

95
00:09:21,118 --> 00:09:26,498
are yet different approaches from Friedman is suggesting because he is. system

96
00:09:26,498 --> 00:09:31,646
basically putting the date and the big computer model and seeing what comes out and

97
00:09:31,646 --> 00:09:37,786
these Davis with data science. we have tremendously sophisticated ways to learn from the past

98
00:09:37,786 --> 00:09:43,006
and maybe predict the future so you know I I mean it depends on what your goals.

99
00:09:43,006 --> 00:10:27,180
you know in in this particular case in this course. it's really doctor a

100
00:09:48,146 --> 00:10:27,180
and kind of thing you know easier. system here kind of first principle

101
00:09:53,286 --> 00:09:58,786
person where you're operating with an understanding of the mattress. this various philosophical.

102
00:09:58,786 --> 00:10:04,566
I bye. I guess for philosophical conversations.

103
00:10:04,566 --> 00:10:09,646
but you know questions asked or do models provide insights for the first principles and then if

104
00:10:09,646 --> 00:10:15,006
this is evidence that supports that and there should be.

105
00:10:15,006 --> 00:10:20,246
okay. so you know these are some of the main turns and I wanted you guys to learn this

106
00:10:20,246 --> 00:10:27,180
and um in fact I think

