1
00:00:03,700 --> 00:00:13,230
This. So I want folks to download.

2
00:00:13,240 --> 00:00:19,540
Let's see here. You're gonna need the either SPSS or CBS by Frank Lloyd SPSS if you want to follow my code,

3
00:00:19,840 --> 00:00:23,650
this is the trip file they're going to use and this is the codebook for the data.

4
00:00:24,370 --> 00:00:31,930
Okay, so it's going to have all of our information. Now, this is a dangerous way to pull people, but we have two options.

5
00:00:32,530 --> 00:00:37,270
I can let you go about your merry way and walk around and answer questions about this,

6
00:00:37,600 --> 00:00:44,740
or I can walk through it on my screen like this and we kind of start from scratch.

7
00:00:45,990 --> 00:00:49,570
Are there are strong preferences about how you would want to do this?

8
00:00:49,720 --> 00:00:53,050
In all fairness, if we're doing it my way, I'm going to ask you questions.

9
00:00:55,990 --> 00:01:02,020
Sure. Hands for what I guess I should do.

10
00:01:02,020 --> 00:01:06,790
I do it this way, your hands, and you want to do it on your own.

11
00:01:07,150 --> 00:01:12,160
I will walk around, answer questions. What are we laughing?

12
00:01:12,160 --> 00:01:15,550
Where you go about your business?

13
00:01:15,910 --> 00:01:23,290
Ask me questions. The goal is to get to. The goal is to get to did it at line 59?

14
00:01:23,710 --> 00:01:26,830
If you've gotten to 59, congratulations, you've reached the finish line.

15
00:01:27,700 --> 00:01:29,590
And then we will come back as a group.

16
00:01:29,650 --> 00:01:37,870
We'll talk about how we interpret this one more time and then we'll move on to what we do once we have this omnibus test completed.

17
00:01:41,240 --> 00:01:47,900
Think you can stop one episode if you are using your own computer and you can spell effects before.

18
00:01:47,930 --> 00:01:54,440
No, you can just call directly from your library. If you're using a university computer, you probably need to clear all of this every time.

19
00:01:55,250 --> 00:01:59,310
Yeah. Yeah. Oh, oh, yeah, yeah.

20
00:02:09,790 --> 00:02:16,720
And so that was just I just thinking, yeah, let's just type something.

21
00:02:20,830 --> 00:02:28,310
Actually, I'm sure it's some of the download stuff and with all of my friends down here,

22
00:02:29,300 --> 00:02:38,110
you know, and I think it's awesome that I did this to them and then.

23
00:02:40,790 --> 00:02:45,619
So when you said you needed do it, I didn't do anything. We're just trying to respond to it.

24
00:02:45,620 --> 00:02:49,850
Yes. No. But I think it probably.

25
00:02:53,500 --> 00:03:10,430
Just take it. Attorneys, attorneys for all of you know, the interesting way behind it is the fact that you want to sell your skull.

26
00:03:11,060 --> 00:03:16,250
One can think of your future as my lord.

27
00:03:17,360 --> 00:03:25,880
This is my department. Yes. And most of that is because SPSS has the different lengths of decimal places that it doesn't use,

28
00:03:25,890 --> 00:03:30,860
not so far as just indicating the scores are different.

29
00:03:32,210 --> 00:03:39,740
So when we get something like this in the U.S. where he drinks, you know, I mean, you're seeing so many times it's like 34 of them.

30
00:03:39,970 --> 00:03:50,870
And if you are pretty confident that they're not going to have problems that are here when you go to strip in this case, that's.

31
00:04:04,130 --> 00:04:10,190
He said. Yes. So I never heard of this.

32
00:04:10,780 --> 00:04:15,730
So that is a function from the foreign package saying that they should have the for.

33
00:04:19,940 --> 00:04:24,509
Can you call us here? Oh, okay.

34
00:04:24,510 --> 00:04:28,820
So that is because you need to recall that.

35
00:04:28,830 --> 00:04:44,370
So what I would do is go, you know what happens you just as a researcher working directly and working director, even if that's not the case.

36
00:04:44,430 --> 00:04:48,000
So then you can get rid of the C users. I don't know.

37
00:04:49,030 --> 00:05:01,020
You're almost always just starting here now because I think that's going to be the final question.

38
00:05:03,720 --> 00:05:07,120
Yeah, thank you. Because it's it's five very massive. Yeah.

39
00:05:08,620 --> 00:05:19,020
So those videos are your controlled environment and I do understand that does not mean that you really need this friend.

40
00:05:19,770 --> 00:05:28,770
You know, every time you need to be you, that is it.

41
00:05:28,790 --> 00:05:35,040
So it's agreed that this is this subspace thing.

42
00:05:35,680 --> 00:05:42,690
Yes, please. No, I get. Yeah, it's good for the session.

43
00:05:43,920 --> 00:05:51,820
Yes, yes. But let me add something that I'm to and it's been going on.

44
00:05:52,800 --> 00:06:02,240
I just yeah, I was I was thrilled with the notion that going on Star Trek.

45
00:06:02,670 --> 00:06:09,210
Yes, I was here. And then it's like so now you're right.

46
00:06:09,240 --> 00:06:14,260
And I was waiting. It was, I think believe.

47
00:06:14,910 --> 00:06:19,790
I don't know if I'm noticing that progress is ending.

48
00:06:23,540 --> 00:06:31,280
I think that was just because each one of these packages can have like a half dozen other small packages.

49
00:06:33,000 --> 00:06:37,560
I think that's what I mean. Yeah, that's what is decided in large part.

50
00:06:37,680 --> 00:06:42,290
They do it by regression, bringing in other very similar packages.

51
00:06:42,950 --> 00:06:53,180
So that can be interpreted by my side as brinkmanship. You know, as far as I know, I don't speak math very well, but it's a concern for me.

52
00:06:53,980 --> 00:06:57,860
Well, how do you know which the packet? How do you decide this package to do any meaningful?

53
00:06:58,250 --> 00:07:01,610
You know, this is a good question. You kind of toyed around with it.

54
00:07:01,610 --> 00:07:05,600
So you oftentimes I learned of a package because of a specific functionality.

55
00:07:05,960 --> 00:07:12,200
So I might say like run multiple comparisons in our and it's going to follow three different programs or packages that can do that.

56
00:07:12,680 --> 00:07:20,240
So I play around with the ones that I think are the most intuitive or the easiest to work with, the kind of data that I might use and go from there.

57
00:07:20,420 --> 00:07:24,739
Okay. So there are yeah. So we're running for starts right after this.

58
00:07:24,740 --> 00:07:28,310
There are at least at least three packages that I know of that can do the same thing.

59
00:07:29,100 --> 00:07:38,219
So I look for a one that is as generalizable as possible rather than very, very specific here, but very, very good question.

60
00:07:38,220 --> 00:07:45,440
And you might end up working with packages around human agencies.

61
00:07:45,650 --> 00:07:50,300
Okay. So I just like the question because sometimes I.

62
00:07:54,820 --> 00:07:59,080
Yeah. But I haven't tried it. Something.

63
00:07:59,380 --> 00:08:03,430
So I had to do it so I didn't have to do it right?

64
00:08:03,490 --> 00:08:09,100
Yes. Is that right? So they all have to really hear a hit run individually from.

65
00:08:09,400 --> 00:08:13,880
Yeah. Versus like. What's it to why is it there's.

66
00:08:13,900 --> 00:08:20,110
Oh, maybe because it's been mentioned very well.

67
00:08:20,980 --> 00:08:25,930
You can always try later and start at the beginning and show it.

68
00:08:26,820 --> 00:08:30,820
Oh, maybe I'll just do that. But it's the best way to look.

69
00:08:31,150 --> 00:08:39,570
There is nothing to indicate the second row to somebody like nine or ten and start on the plus instrument.

70
00:08:39,640 --> 00:08:46,540
I think that this class should be a student like like my brain or maybe at target.

71
00:08:46,910 --> 00:08:49,630
Oh, that's okay. I feel they like it. It's so different than for me.

72
00:08:49,720 --> 00:09:02,799
Go into so and if I run this way up here to the library, so when it's when you're up on the left hand side or like if I went all the way after okay.

73
00:09:02,800 --> 00:09:09,760
Yeah. And put her on, it was a every 20. So when I'm using my little control center, it's just running the lines themselves.

74
00:09:10,810 --> 00:09:17,020
So I guess if you really wanted to, I think you could do something like this and it should run from here all the way down to here.

75
00:09:17,470 --> 00:09:21,020
But the other option is just. Okay. Okay.

76
00:09:21,160 --> 00:09:33,260
Yeah, that's it. Thank you. Anybody having trouble getting data in at least.

77
00:09:37,670 --> 00:09:43,080
So you. So I heard this.

78
00:09:43,090 --> 00:09:49,230
And so what it's saying is that it does not find that file name in this folder.

79
00:09:49,890 --> 00:09:54,090
So what I'm suggesting we set a working directory is a network.

80
00:09:59,240 --> 00:10:02,560
Yes. So let's go up to the file menu and find.

81
00:10:04,940 --> 00:10:09,320
Under session. Said Working directory.

82
00:10:10,430 --> 00:10:18,200
You can either choose directories that I think might be the easiest or the source of directories, whereas this would misuse the computer it.

83
00:10:21,160 --> 00:10:27,360
You find your downloads folder, ensuring you open all apps.

84
00:10:27,370 --> 00:10:32,890
And now this is where I are going to look for anything, any files that you call from your screen.

85
00:10:33,580 --> 00:10:42,650
So because of that, no longer. Forward flash points all the way through yet forward action.

86
00:10:42,980 --> 00:10:56,020
Just the name of the file. So you never know all of the things that you can use gender.

87
00:10:56,020 --> 00:11:02,860
And then in this thing the causation is zero that you and I need to put in our petition.

88
00:11:04,300 --> 00:11:07,900
Yes, I mean that in the French quotations, but I'm not sure that.

89
00:11:08,840 --> 00:11:17,739
It's like, Oh, God. Yeah, he laughed. All right, so this is good because the errors are all about the decimal.

90
00:11:17,740 --> 00:11:22,840
Places like SPSS stops at like 308 decimal places or something.

91
00:11:23,650 --> 00:11:28,450
That's just trying to figure out how least you should be able to now see that mass somewhere in here.

92
00:11:29,080 --> 00:11:40,030
Is that the observations of the variables we view in this night you see here on the bottom 39.

93
00:11:51,040 --> 00:11:56,710
So do I draw your attention if you are getting into this subset area of search?

94
00:12:01,030 --> 00:12:06,570
I show you two different ways to do the exact same thing. So you don't have to do both of them.

95
00:12:06,730 --> 00:12:12,060
It'll get you to the same place. But you only run this one.

96
00:12:12,570 --> 00:12:17,050
Or you can run this 127 through essentially 29.

97
00:12:18,450 --> 00:12:21,450
And if anybody wants me to talk through that, we can a little bit later on today.

98
00:12:22,020 --> 00:12:27,030
So instead of using the variable names, which for me takes a long time, especially since I use long variable names,

99
00:12:27,120 --> 00:12:31,650
sometimes it's easier just to use the column numbers like we did with the homework assignment.

100
00:13:37,210 --> 00:13:40,250
Yeah. Because if these.

101
00:13:45,090 --> 00:13:48,590
Any preference between script and one.

102
00:13:49,610 --> 00:14:15,180
Now. I just.

103
00:14:18,810 --> 00:14:28,620
Actually, I heard. Just.

104
00:14:35,930 --> 00:14:45,090
Yeah. I think I'll have to uncover a few things.

105
00:14:47,950 --> 00:14:53,860
Where are we supposed to step in this?

106
00:14:54,050 --> 00:14:58,780
But more to talk about.

107
00:15:01,450 --> 00:15:06,950
And if you're moving forward, what I would hope is that as you read each line and you run each line,

108
00:15:06,950 --> 00:15:10,960
you're not just running off line because it's on your script file, but you're understanding what's going on behind it.

109
00:15:12,700 --> 00:15:18,550
Yeah, I know. I didn't. I think we wanted to shift this to five, right?

110
00:15:19,210 --> 00:15:25,180
Yeah. Two, two. Yes, we did. But it's not exactly as much as it's.

111
00:15:25,660 --> 00:15:29,770
That's great. So it's been four, right? You get over there.

112
00:15:30,010 --> 00:15:33,879
Could you get something like, is that a point? Or like, it's completely arbitrary.

113
00:15:33,880 --> 00:15:37,060
That's a linear transformation. So it's not going to affect your correlation at all.

114
00:15:37,390 --> 00:15:44,410
Not that I know that you you were crazy with, you know, but, you know, I just wanted to know, like, it would be nice to show.

115
00:15:44,420 --> 00:15:49,690
You have to use a whole nother. Just don't forget what you did. And that was.

116
00:15:50,500 --> 00:15:55,670
I would do this. Why would you take something? Okay.

117
00:15:55,760 --> 00:16:02,820
So we created this group. Yeah. And I spent some. No.

118
00:16:04,680 --> 00:16:07,880
Probably like. Okay. So.

119
00:16:11,190 --> 00:16:16,549
Let's talk about five things because first.

120
00:16:16,550 --> 00:16:22,970
So long time. Yes. Oh, okay.

121
00:16:22,970 --> 00:16:27,530
So you probably want to update your car at some point, but that's not critical if you.

122
00:16:28,220 --> 00:16:31,540
So that foreign bank, which was Korean data, which you already did.

123
00:16:31,610 --> 00:16:36,160
So if it's an issue, I'm not sure because we hold out for a very well, if you are, you know,

124
00:16:36,170 --> 00:16:41,850
you haven't installed so you don't need to do anything once you've done this, once it's dying inflation, it was mortgages.

125
00:16:43,510 --> 00:16:48,060
And so that goes on to suggest that, look, this isn't so sure.

126
00:16:48,220 --> 00:16:54,170
So there it is. I'm not sure exactly why you're saying it doesn't mean it doesn't exist when you can click on it.

127
00:16:54,640 --> 00:17:06,680
The only thing we have to decide whether or not you want to do a kind of work on that can only work like this.

128
00:17:07,640 --> 00:17:11,210
Yeah. So this is mainly for you have it is working out for sure whether there says it's not

129
00:17:11,240 --> 00:17:17,450
possible you live in a come here so I think there are you run your statistics in for I don't

130
00:17:17,870 --> 00:17:25,669
want it no but you can you would prefer to work in Python run things in this class is

131
00:17:25,670 --> 00:17:31,850
something to consider just because it might be helpful for you to continue the same language.

132
00:17:32,270 --> 00:17:34,849
If you're going to be doing other sort of coding, you're there and then you want to run.

133
00:17:34,850 --> 00:17:39,889
This is something that you're managing, but I'm going to teach this and you are.

134
00:17:39,890 --> 00:17:43,390
So if it's hard to translate something to consider,

135
00:17:43,410 --> 00:17:49,420
but I have worked with some of my other staff to do some things like vector analysis and regression,

136
00:17:49,430 --> 00:18:00,520
and I think it's okay to jump in here and do this stuff for you to do.

137
00:18:02,060 --> 00:18:10,340
I hope they like describing something. So yes, I am here.

138
00:18:10,340 --> 00:18:21,319
Electronic code fingering is why these illustrators things that we're finding are all in between.

139
00:18:21,320 --> 00:18:24,500
There's nothing good here if you want. Yeah. Yeah.

140
00:18:25,220 --> 00:18:28,250
Three and. Okay. Question.

141
00:18:32,680 --> 00:18:38,630
So seriously, I. So they describe like we had two, three years ago.

142
00:18:38,660 --> 00:18:54,889
There's two groups and it's not because there's between the kind of people you know and I think it's because, you know,

143
00:18:54,890 --> 00:19:03,860
so that's that's not enough because it was described by divorce worse trying to not I think it's showing us all the drought in the U.S.

144
00:19:04,440 --> 00:19:09,850
Right. Right. Oh, by the way, so.

145
00:19:10,070 --> 00:19:15,490
Yeah, that's right. Right.

146
00:19:15,940 --> 00:19:21,490
So because the human race very broadly wanted to be has three levels and groups,

147
00:19:22,000 --> 00:19:32,450
it's showing you three different sets of expect from a script it so it's taking the function that's in described is going to be variance but a lot.

148
00:19:32,480 --> 00:19:37,420
Yeah. And for every single group so we used sex which is a two level variable.

149
00:19:37,580 --> 00:19:45,520
First instead of a race we get to go to, you can try, especially if you want to use what we want to actually normalize.

150
00:19:45,520 --> 00:20:01,620
I don't use them so well, you know that's the one as a but I might be able to describe by and if I wanted to use sex which is where you wanted me to,

151
00:20:02,080 --> 00:20:05,680
well, how would I do that in this command language?

152
00:20:07,060 --> 00:20:11,350
You'd have to do the $80 a week. So let's see what happens when you try that.

153
00:20:11,770 --> 00:20:14,970
Okay? Yeah.

154
00:20:16,750 --> 00:20:27,280
You said a way to do. Or just that name?

155
00:20:28,340 --> 00:20:38,740
You know, I don't know. You are trying to use the described by command to tell me what to do.

156
00:20:39,820 --> 00:20:45,310
I said it was the best. So you think it'd be really okay?

157
00:20:45,460 --> 00:20:49,930
I think it would be in place of things. Yeah, well, that's, you know.

158
00:20:50,710 --> 00:20:57,040
Yeah, I get that. If we're trying to work right now.

159
00:20:57,880 --> 00:21:01,209
Yes. You've done this absolutely right. You're right.

160
00:21:01,210 --> 00:21:11,550
It's going to give you an error. Whereas if you give us an error. Maybe because we didn't.

161
00:21:12,120 --> 00:21:14,340
Do this time of year. All right.

162
00:21:15,990 --> 00:21:26,990
So, Christopher, jumping ahead and let's let's run and see, I think what is the what is this made it to a successful male female.

163
00:21:27,150 --> 00:21:31,410
No working very well puts it right so we should have done like what do you think.

164
00:21:31,500 --> 00:21:34,260
You will have to do that and then you're also going to have to think about this,

165
00:21:34,270 --> 00:21:39,750
something that we did when we created that data set originally we took six variables.

166
00:21:39,840 --> 00:21:44,940
Yeah, not one of which was two. So that is not in your own data.

167
00:21:45,210 --> 00:21:53,730
Okay. So to when we go back and do is we will rerun our line 22 here now they wanted eight and

168
00:21:54,390 --> 00:21:59,810
then we would which is just like the number of groups minus one and then the different,

169
00:22:00,720 --> 00:22:03,990
although you're right. ROSKAM And then make sure I remember, okay.

170
00:22:03,990 --> 00:22:09,660
So very basically, you may not have any major instructed to go ahead of us,

171
00:22:09,660 --> 00:22:15,660
but the fact that I did this because I did comma and add another thing we're going to just do the reason kinds of.

172
00:22:16,000 --> 00:22:22,550
Yes. So I think we're done well if you believe is then when you reset over the idea that variable

173
00:22:22,590 --> 00:22:25,740
which is not be the message that we're going to need all of those because I would just.

174
00:22:25,920 --> 00:22:31,940
Yeah. So the problem is if we did anything kind of post our calculation where it is not for you on all three.

175
00:22:31,990 --> 00:22:36,600
That's right. That's right. And that's the advantages and disadvantages kind of script is correct.

176
00:22:36,600 --> 00:22:41,050
I said, okay, good. Yeah, I don't hear that.

177
00:22:41,070 --> 00:22:46,680
Yes. So I just don't understand anything at all.

178
00:22:46,890 --> 00:22:53,460
Why didn't I want to make a comment on you have to visit us many times.

179
00:22:53,850 --> 00:23:07,130
Plus, I don't think so. So I am running the correlations because in this case I would like to know exactly if I remember.

180
00:23:07,140 --> 00:23:10,240
We have much you just see here. I can just.

181
00:23:10,680 --> 00:23:14,510
Yeah, the one of them was the first thing. That was great. I feel the same as the.

182
00:23:14,650 --> 00:23:23,260
The school says. I'm afraid I was never able to be sure that there are no difference there.

183
00:23:24,240 --> 00:23:29,460
Yeah, well, let's look at. I want to.

184
00:23:36,430 --> 00:23:53,210
Okay. So I guess it has occurred to you that so many examples of these as a result of too much planning tax reform.

185
00:23:54,030 --> 00:24:01,170
Yes. Yes. They're going to look at the frame and the above.

186
00:24:01,190 --> 00:24:06,360
Yeah. You can write down like, you know, if that means everything is okay.

187
00:24:07,250 --> 00:24:10,340
So they are going to have literally every side. Yes.

188
00:24:11,660 --> 00:24:22,340
If they're on the right side and everything is very grainy and you're right, you got you know, you're falling asleep.

189
00:24:22,660 --> 00:24:26,040
This means very quickly. Yes. Like you can have like not having.

190
00:24:28,790 --> 00:24:33,110
I have no idea. I was so excited.

191
00:24:33,890 --> 00:24:46,730
Like, I always worried about my friends because I feel like I didn't feel like I having my little planner because it's not happening to with me.

192
00:24:46,880 --> 00:24:59,550
Yeah, I know. I mean, even though you write about Jekyll and Hyde, he doesn't want to sit up in these things.

193
00:25:00,530 --> 00:25:04,560
So I'm going to do another that, you know, I'm not know. Yeah.

194
00:25:05,150 --> 00:25:11,450
Oh, no, I think you're right. So he doesn't benefit today with this price difference between right and the.

195
00:25:12,590 --> 00:25:16,130
I think you're right. Yeah, I can relate to that if you want, actually.

196
00:25:17,390 --> 00:25:27,220
Directly. Directly, because actually because such a big difference anywhere in the world.

197
00:25:27,650 --> 00:25:35,870
But I'm not likely to find by the end of the first thing.

198
00:25:36,770 --> 00:25:40,730
I mean, first kind of first things like that. Why didn't you tell me? All right.

199
00:25:40,740 --> 00:25:46,180
I really enjoy that. And I'm really happy that you're going to choose someone.

200
00:25:46,400 --> 00:25:59,540
Yeah. You couldn't disagree more for me to figure out what's going to forward versus points in diversity as well.

201
00:25:59,570 --> 00:26:15,520
And that's because everything that you do says requires that I know who I really am, which is think right now and that tells you something.

202
00:26:15,650 --> 00:26:21,610
And then you've got to think about how, you know.

203
00:26:22,340 --> 00:26:26,569
So this is this will be an issue where you have to install on that in our package.

204
00:26:26,570 --> 00:26:30,580
But now you should be able to run this great company, the first person, this package.

205
00:26:30,590 --> 00:26:43,669
So she has only 2020 1000083263.

206
00:26:43,670 --> 00:26:54,110
We're already beginning to before and then every now and then of and forth.

207
00:26:55,940 --> 00:27:01,610
How is your time life in Virginia humorous or are we getting close to here?

208
00:27:05,290 --> 00:27:16,279
What else and how how close are folks to getting the here and now you are in the five more minutes.

209
00:27:16,280 --> 00:27:20,600
Are we ready? Yeah. All right.

210
00:27:22,310 --> 00:27:27,320
Right. With such as five observations deleted due to.

211
00:27:28,630 --> 00:27:31,750
Right. I was. I don't have that much.

212
00:27:35,180 --> 00:27:39,169
You've you've got your ends. You've got the codes.

213
00:27:39,170 --> 00:27:45,090
It's just the that by the. Interesting.

214
00:27:48,400 --> 00:27:55,640
But I think that was a very large welcome that we can't really think of that.

215
00:27:56,180 --> 00:28:01,670
All right. So just to refresh everybody's mind, but I want to just run through this real quick.

216
00:28:02,310 --> 00:28:23,170
It's on your screen. It's online. What does this tell us? Where are the values have to reject but know that the groups are no different.

217
00:28:24,460 --> 00:28:33,630
That's pretty technical. Once you get layperson's terms, what is what is just telling us that there is a lot of within the group.

218
00:28:34,720 --> 00:28:39,880
I mean, between groups. There's a difference between the groups.

219
00:28:40,000 --> 00:28:41,580
There is a difference between the groups. Right.

220
00:28:41,600 --> 00:28:50,420
So we created a scale, if we recall the wave one ITI scale it was based off of let's see here, how are we going to get there?

221
00:28:50,440 --> 00:28:53,470
It was based off of these three items. Where do they go?

222
00:28:54,130 --> 00:28:57,910
Right. So we wanted to ask people, is my neighborhood a safe place to be?

223
00:28:58,300 --> 00:29:02,080
Do I feel safe at my school? Am I afraid of violence in my neighborhood?

224
00:29:02,590 --> 00:29:06,510
This one was our little double star here, because if we're thinking about a scale,

225
00:29:06,510 --> 00:29:11,350
if we're going to combine these three pieces of information together, we want the violence to be the same across these areas.

226
00:29:11,350 --> 00:29:16,719
Right. An endorsement I strongly agree to any of these items should mean the same thing

227
00:29:16,720 --> 00:29:20,950
in terms of their relative position or endorsement of the construct as a whole.

228
00:29:21,560 --> 00:29:27,830
If these are all about safety, more response, fire response, strongly agree that means I feel safer.

229
00:29:27,850 --> 00:29:30,620
Or you could have flipped it immediately like a stronger response.

230
00:29:30,620 --> 00:29:34,600
Say I feel less safe, but we can't have items that are going in different directions.

231
00:29:35,080 --> 00:29:37,390
All right. We'll do a lot of scale creation in this class.

232
00:29:37,720 --> 00:29:42,490
So thinking about the items that are comprising your construct, remember, this stuff doesn't exist.

233
00:29:43,030 --> 00:29:48,640
It does not exist. We have three pieces of information that are responses to a question.

234
00:29:48,880 --> 00:29:56,740
I'm telling you that if we combine those pieces of information, we now have a new unobservable construct that's called what feelings of safety.

235
00:29:57,130 --> 00:30:00,340
Right. And really, it's feelings of safety and your neighborhood, your school,

236
00:30:00,850 --> 00:30:04,600
because that's kind of what these items are, these descriptions kind of tell us.

237
00:30:05,590 --> 00:30:11,170
That's what we're asking about. So we made those we made those that scale.

238
00:30:11,620 --> 00:30:16,300
We ultimately ran this ANOVA. Our grouping variable in this case was race.

239
00:30:17,140 --> 00:30:27,880
And we do find relatives like Clara say that across these different groups there do do appear to be varying levels of exposure to balance.

240
00:30:28,720 --> 00:30:36,930
Right. Grouping variable does matter between group variation if you must relative to the within.

241
00:30:36,930 --> 00:30:42,310
Group variability is quite large. So large in fact, that it's unlikely we'd observed this by chance.

242
00:30:47,280 --> 00:30:50,370
Okay, folks, questions about this.

243
00:30:51,540 --> 00:30:54,660
Questions about this. All right. Which groups are exposed to the highest level of violence?

244
00:30:59,510 --> 00:31:02,900
Maybe we can't tell how.

245
00:31:08,320 --> 00:31:11,830
Individual teachers don't have to.

246
00:31:14,660 --> 00:31:19,610
We can just take a peek, right? So right before you do this, we look descriptively.

247
00:31:20,000 --> 00:31:26,810
Which of these groups has the highest level of exposure, violence or feelings or feelings of safety?

248
00:31:28,580 --> 00:31:33,210
So it is. I forget.

249
00:31:36,300 --> 00:31:39,780
My neighborhood is a safe place to be. Do I feel safe in school? I'm not afraid of violence.

250
00:31:40,170 --> 00:31:47,610
So if there is a safety oops, which group has the highest feelings of safety?

251
00:31:52,780 --> 00:31:59,799
Too good to write too, is what you write.

252
00:31:59,800 --> 00:32:03,940
So if we look at our if we look at our code book here,

253
00:32:04,270 --> 00:32:14,950
we can look for where 1a3 right is going to tell us the different levels of our variable, at least in this case.

254
00:32:16,180 --> 00:32:22,570
The two is white, Caucasian, mixed race, Afro-American, black,

255
00:32:23,320 --> 00:32:33,500
at least under the group differences we see relatively small in a five point scale, right.

256
00:32:33,580 --> 00:32:39,760
You know, difference of .03 and a difference of 1.19.

257
00:32:40,390 --> 00:32:50,170
Now, Amy, to your point, the post hoc thing where post hoc comparisons remember from the video, your post hoc comparisons.

258
00:33:06,490 --> 00:33:12,930
So I thought that's what we use to figure out which one is different.

259
00:33:12,940 --> 00:33:18,280
But it looks like we were able to just just look at that, describe function, keep going.

260
00:33:19,330 --> 00:33:23,650
What does that mean? So our described function gives us kind of these groups.

261
00:33:26,900 --> 00:33:30,110
It does give us kind of these mean differences. Right.

262
00:33:30,800 --> 00:33:35,720
But what do we need here? We don't want to just use our descriptive statistics.

263
00:33:35,960 --> 00:33:40,460
We're going to try to make some sort of inferential judgment about whether these are

264
00:33:41,000 --> 00:33:47,030
truly different or if these differences are within kind of the realm of chance.

265
00:33:47,720 --> 00:33:54,080
Right. Are these differences large enough that they're unexpected and they would be unexpected if our null hypothesis

266
00:33:54,380 --> 00:33:58,550
is that actually all three of these groups have the same feelings of safety in their neighborhoods in school.

267
00:33:59,150 --> 00:34:02,960
Okay. So they're telling us exactly what groups are different.

268
00:34:03,080 --> 00:34:07,190
Exactly. Okay. So rather than just saying descriptively, these are the highest and lowest.

269
00:34:07,470 --> 00:34:15,170
We're going to use an inferential technique to essentially run a T test, a T test and a T test.

270
00:34:16,040 --> 00:34:19,410
So we're getting around the the family wise ear piece.

271
00:34:19,970 --> 00:34:25,160
This is what's called an omnibus, a nova omnibus, just meaning everything.

272
00:34:25,700 --> 00:34:32,150
All this test tells us the only thing that this test tells us is that somewhere there is a difference between groups.

273
00:34:32,690 --> 00:34:36,650
It's not going to say specifically statistically, which are the different groups.

274
00:34:37,280 --> 00:34:44,240
Okay. So this is our first step. The next step is to use some form of post-hoc comparison.

275
00:34:45,200 --> 00:34:53,960
All right. So now we are getting into the very specific group comparisons that are going to be adjusted for the fact that we're doing more than one.

276
00:34:54,650 --> 00:35:02,930
So this is going to help us avoid the problem of family wise error in making a typo in error, assuming that these are all independent tests.

277
00:35:03,540 --> 00:35:09,860
Right. So it's kind of behind the scenes going to change essentially the point of five level that we're all used to seeing.

278
00:35:10,520 --> 00:35:15,560
It's going to make that a little bit more conservative so that when you run three of them in a row,

279
00:35:16,250 --> 00:35:19,970
it's saying, okay, well, knowing that I am running three instead of just one.

280
00:35:20,420 --> 00:35:25,879
How much do I need to adjust my rejection level in order to say yes?

281
00:35:25,880 --> 00:35:31,430
In fact, these are different. Okay. Like many things in are, there are many ways to do this.

282
00:35:32,840 --> 00:35:41,930
The easiest one is the tukey's honestly significant difference test, which we can just run based off the object that we already created.

283
00:35:42,950 --> 00:35:48,250
Outcome is going to be for discussion, but I have completely different values.

284
00:35:48,920 --> 00:35:51,979
Starting back. Okay, this is not just me starting back in.

285
00:35:51,980 --> 00:35:58,190
Like to describe the numbers or how different your numbers.

286
00:35:58,550 --> 00:36:07,640
Well, it starts with the first line is 2.8%, 3.759 and 2.77.

287
00:36:08,060 --> 00:36:12,820
Yeah, but I have 2.3 and 2.4425, six, seven.

288
00:36:13,280 --> 00:36:18,560
And they want to do this on their own. If you're not just. Um.

289
00:36:18,940 --> 00:36:26,710
All right, so the best I can say is we would start here to diagnose this problem.

290
00:36:27,400 --> 00:36:34,810
Right. So, do you have 850 people? Do you have these missing data representing different things?

291
00:36:37,550 --> 00:36:46,100
I have at least one. I would be very surprised if these top five are different.

292
00:36:47,030 --> 00:36:52,490
The w1e ten d my mean is 2.9% 3.9.

293
00:36:52,880 --> 00:36:56,660
That is because this would never reverse coming in. Right?

294
00:36:59,030 --> 00:37:02,180
And then w want it to be different.

295
00:37:02,630 --> 00:37:06,680
And that's because this w what it is, is a combination of these three values.

296
00:37:06,800 --> 00:37:12,020
Yeah, I read that part that I have in my own right.

297
00:37:12,920 --> 00:37:16,310
Oh, right. So you see here, starting with.

298
00:37:19,740 --> 00:37:22,720
And this is why these group files are going to be good, good, good.

299
00:37:22,740 --> 00:37:30,809
So if I give you a script file and it returns something different than we know, there's some some sort of error.

300
00:37:30,810 --> 00:37:38,190
And either the way I'm running things, you're running things or the script file itself. And I assume that this piece this is important, right?

301
00:37:38,190 --> 00:37:43,750
Just because of the value labels part, but that shouldn't affect any of the numbers themselves.

302
00:37:44,580 --> 00:37:52,410
But you can view as you can make sure that there there are in fact, let's see here, 850 observations, 399 variables.

303
00:37:53,670 --> 00:38:01,830
That's kind of my first check. You can use the view command to kind of to scan briefly, make sure that everything looks relatively within order.

304
00:38:02,310 --> 00:38:06,000
You can also compare anything that we're seeing in R to the code book,

305
00:38:06,000 --> 00:38:10,980
which is the formal kind of test because that's where it's been processed or whatever.

306
00:38:11,760 --> 00:38:15,560
And think about these analogs that you're going to do in practice, because this would be the same.

307
00:38:15,870 --> 00:38:19,770
This would be a major error if we were working in different places in the country.

308
00:38:20,040 --> 00:38:25,890
And I'm saying here's my data file and script and you're getting some kind of different result than I am here.

309
00:38:26,370 --> 00:38:29,459
This should not be the place where we're we're getting divergences.

310
00:38:29,460 --> 00:38:34,920
But this is just creating a smaller data frame you can make to make sure that these all look the same for you.

311
00:38:36,570 --> 00:38:44,760
This is prior to changing the coding of the wave one e ten variable because we just haven't done that yet.

312
00:38:45,300 --> 00:38:49,740
You can ignore 26 through 29 because that's just redundant with this information.

313
00:38:50,160 --> 00:38:58,770
It's just a different way to create a subset. This should also be the same for everybody at this point, if not done any sort of manipulations.

314
00:38:59,220 --> 00:39:04,680
All right. So this would be a place to check the correlations the same.

315
00:39:06,000 --> 00:39:10,440
Recall that this variable is a little nonsensical to have in a correlation table.

316
00:39:10,920 --> 00:39:16,560
I'm just being lazy. We could have just asked for these four items, but that's a lot more work.

317
00:39:18,360 --> 00:39:24,180
Why is this? Why is this nonsensical, this common security variable?

318
00:39:24,330 --> 00:39:32,400
Right. Even though our right now is interpreting it as one, two, three, it doesn't make any sense because these are qualitative categories.

319
00:39:36,340 --> 00:39:40,290
Are we seeing divergences yet? My life is good.

320
00:39:40,800 --> 00:39:46,380
36 The era where, if you recall, the way I originally ran the script was six minus this.

321
00:39:50,970 --> 00:39:56,190
So my results are still going to look as though I use six instead of five.

322
00:39:57,300 --> 00:40:03,000
This is probably the more appropriate way to do it, but this is the way if you want to look identical to my results.

323
00:40:05,190 --> 00:40:13,500
What is line 36 doing its reverse coding an item that doesn't make sense to include in the scale as written

324
00:40:13,680 --> 00:40:18,150
because the way that you would endorse that item would suggest you feel less safe in your neighborhood.

325
00:40:18,480 --> 00:40:21,700
We want to flip it to almost like a negative or a double negative.

326
00:40:21,720 --> 00:40:28,980
I don't feel not safe in my neighborhood. Oh, my memories are the same as yours.

327
00:40:28,980 --> 00:40:32,940
But for each vote. Six variables, not five.

328
00:40:34,460 --> 00:40:39,800
At 850 observations at six. But everything else is the same.

329
00:40:40,550 --> 00:40:47,120
The reason why? Tell me why I actually quit. I swear I'm not immune.

330
00:40:47,450 --> 00:40:54,650
I I'm pretty sure it's because they're still reading the one three man in the fabric.

331
00:40:54,740 --> 00:41:01,370
We haven't done that part yet. I think it's because I'm making my way through the script file.

332
00:41:01,820 --> 00:41:05,180
This is where I'm creating my brand new variable. Right.

333
00:41:05,420 --> 00:41:09,020
So these should these five should still match yours. Yes.

334
00:41:09,260 --> 00:41:12,980
All right. So that six variable is going to pop up as soon as I run this monitor.

335
00:41:13,590 --> 00:41:18,620
Oh. Because we've already ran it. You guys are all eight steps ahead.

336
00:41:18,880 --> 00:41:21,890
I've never had the two never had an R like that.

337
00:41:23,420 --> 00:41:29,330
All right, so line 40. I, i this probably feels like, seriously, we go way, way.

338
00:41:29,510 --> 00:41:30,200
But this is good.

339
00:41:30,200 --> 00:41:37,879
These are kind of diagnosing things that we have to do and better to understand how we can kind of make some of these changes or recognize when,

340
00:41:37,880 --> 00:41:41,300
for example, our data frame should change from five variables to six.

341
00:41:43,490 --> 00:41:45,710
Hopefully you're still seeing 850 observations.

342
00:41:46,490 --> 00:41:53,300
If at any point you wanted to take a peek at your your data set, you can use summary, you can use head.

343
00:41:55,260 --> 00:42:02,930
Right. It's going to give you the first five or ten or however many you want. These should now all be pretty consistent across all of us.

344
00:42:13,180 --> 00:42:24,520
Sam is the Treasurer here to. That's furrowed concentration.

345
00:42:24,520 --> 00:42:27,870
That's good, you know. Oh, my.

346
00:42:27,880 --> 00:42:32,340
Some very good friends. Everything.

347
00:42:34,050 --> 00:42:44,430
So where are the where are the divergences? So meet him first March five.

348
00:42:44,940 --> 00:42:52,919
And. Everything is different. Okay. Was it different when it was your correlation matrix?

349
00:42:52,920 --> 00:42:56,640
Different? No.

350
00:43:05,320 --> 00:43:14,710
No, it doesn't. Yeah, no question.

351
00:43:15,010 --> 00:43:19,150
Yeah. So when I read code is a negative variable.

352
00:43:19,370 --> 00:43:24,880
Hmm. I think I put it like I was doing this on Tuesday too.

353
00:43:25,240 --> 00:43:31,150
You said like you could put in, like, w1e ten and then a little R to make it different.

354
00:43:31,390 --> 00:43:35,230
Yeah. Something different. And so I did that. So I have an extra variable, right?

355
00:43:35,440 --> 00:43:39,930
So I think I coded around, but now it's using all of it, using the one,

356
00:43:40,180 --> 00:43:46,060
the negative one, and then the one I recoded to really, really like delete the old one.

357
00:43:47,440 --> 00:43:51,460
So what I'm hearing is that you did something like this.

358
00:43:52,450 --> 00:43:58,720
Yes. Yes. Yeah. All right. So now we have an entity that has seven variables.

359
00:43:59,470 --> 00:44:03,850
The reason why is because we now have this.

360
00:44:06,370 --> 00:44:20,170
We have this way one eaten or recoded, which should be perfectly reversed, coated with all I should ask everybody who recorded my own.

361
00:44:20,470 --> 00:44:28,000
But if you wanted to run, the correlation between an original variable and a recorded variable I think would be good after you do it.

362
00:44:28,030 --> 00:44:33,190
So here, instead of just making this, instead of saving over WAVELAN e 1/10,

363
00:44:34,210 --> 00:44:39,670
I added an R to indicate that it is reverse coded, so I'd keep all variables in my data set.

364
00:44:40,120 --> 00:44:46,030
But then I would want a quick correlation between the one with the R and the original variable.

365
00:44:46,390 --> 00:44:51,310
And I would expect those to be what if the correlation between the two if you reverse coded it correctly?

366
00:44:55,150 --> 00:45:02,880
Yeah. Which the correlation would be know. 91, right?

367
00:45:03,640 --> 00:45:05,430
Right. So if you were in this now,

368
00:45:05,810 --> 00:45:15,990
if you created a second variable instead of the original set of saving over the original and you ran this value and then in this value,

369
00:45:18,120 --> 00:45:25,529
it's not going to be for me as this is going to be a perfect positive correlation because I've already saved over this value the same right?

370
00:45:25,530 --> 00:45:29,700
So now these are the same to do the complete ops thing or whatever.

371
00:45:34,800 --> 00:45:45,870
If you're in a console, you press object, it's going to return the same. Oh, it's because I didn't actually run those lines.

372
00:45:50,790 --> 00:45:53,190
All right. They had already done there.

373
00:45:54,300 --> 00:46:02,450
So what I would do, I mean, in a situation like this, again, it's so easy to just go right back to where we want to do this.

374
00:46:02,470 --> 00:46:11,070
Now, I'm just saving back over all this stuff. Um, create a mini variable, you know?

375
00:46:11,870 --> 00:46:15,380
So that's like, the summary thing. My numbers are all way.

376
00:46:18,650 --> 00:46:31,090
And so it's one that seems like that could be like, okay, maybe you didn't include the parentheses or something.

377
00:46:33,220 --> 00:46:38,200
I can take a look in a in a couple of minutes here. So I'm running this.

378
00:46:39,130 --> 00:46:42,520
This is where we're supposed to be. If you're not here, don't worry.

379
00:46:43,630 --> 00:46:48,100
I'll. I'll come around in just a sec. Uh, where are we now?

380
00:46:49,150 --> 00:46:53,650
Saving as a factor so that we have a group of variables. Which factor?

381
00:46:53,650 --> 00:47:05,110
Here is my number. Okay, so I will make sure that we stop in about 10 minutes, and I'll walk around and try to help folks who are not here.

382
00:47:05,110 --> 00:47:13,780
But this is if this is looking different, just make a note and I'll come around, see if we can figure out what's going on.

383
00:47:15,130 --> 00:47:19,300
Notice that describe is hopefully tells us that one of these is a factor which

384
00:47:19,300 --> 00:47:24,400
I love because you don't want to just say that our race value mean was 1.23,

385
00:47:24,760 --> 00:47:30,879
which doesn't make sense, but it does tell us an idea of the proportion of the sample sample down here.

386
00:47:30,880 --> 00:47:37,450
677 one 4226 Those are our five missing observations if you add them all up to about 845.

387
00:47:37,870 --> 00:47:41,590
The reason why we have missing data down there is because we have missing data up here.

388
00:47:42,010 --> 00:47:46,960
We're missing data here because some combination of these are missing.

389
00:47:47,410 --> 00:47:49,510
So people didn't respond to these three variables.

390
00:47:49,900 --> 00:47:54,490
We can't just assume because 847 across the board that there's three people who didn't respond to all three items.

391
00:47:54,910 --> 00:48:03,010
This tells us that there is at least one person who responded or didn't respond to one, but not all three, probably two people.

392
00:48:05,270 --> 00:48:11,550
To our post, our comparisons again, they're going to they're going to do this work for us.

393
00:48:11,940 --> 00:48:19,170
You told me that this is the highest if you want to say the second, highest, third highest is the significantly different structure.

394
00:48:20,250 --> 00:48:24,510
Here it is. It calculates the difference for us.

395
00:48:24,520 --> 00:48:28,469
Isn't that nice of it? So if you're calling it this anyway, this is everywhere.

396
00:48:28,470 --> 00:48:31,770
Black, white, Caucasian. The difference is about 0.19.

397
00:48:32,130 --> 00:48:36,120
Is that a significant difference? That's essentially what this test is going to tell us.

398
00:48:36,450 --> 00:48:41,070
It calculates an upper and lower bound confidence interval for where this point estimate could be

399
00:48:41,400 --> 00:48:47,490
and gives us a p value of what we think is the likelihood that we could be making a typo here.

400
00:48:48,270 --> 00:48:57,089
So in this case, we could say that white Caucasian participant or three white Caucasian participants in the sample felt

401
00:48:57,090 --> 00:49:01,590
significantly safer in their schools and neighborhoods than African-American blacks in the century.

402
00:49:03,120 --> 00:49:08,580
Essentially what this is telling us, right? We did not know that information from this.

403
00:49:09,150 --> 00:49:17,670
All we knew is that there were group differences. We can follow down the line looking at the specific comparisons, one versus three, two versus three.

404
00:49:18,210 --> 00:49:23,850
Right. And we see that none of those differences are a signal are statistically significant.

405
00:49:24,300 --> 00:49:34,620
You might be surprised by that last convert over to the the comparison of 3.1 to 2.94, but it's also fairly large in magnitude.

406
00:49:35,250 --> 00:49:40,460
The difference, I think, is almost certainly because we only have 26 people who identified as multiracial.

407
00:49:42,480 --> 00:49:47,969
And of those people who did, the the combinations were all white or African-American.

408
00:49:47,970 --> 00:49:51,150
So no Hispanic, no Asian-American.

409
00:49:51,180 --> 00:49:56,130
I think in the sample when they originally started collecting the data which.

410
00:49:59,110 --> 00:50:06,130
Really this just a good thing to know about.

411
00:50:07,510 --> 00:50:13,660
I like this pairwise t test because it allows you to change the type of post hoc that you want to run.

412
00:50:14,170 --> 00:50:19,420
There are probably about a half dozen different ways that you can run post hoc comparisons,

413
00:50:19,780 --> 00:50:22,990
and they range from more conservative to very, very liberal.

414
00:50:23,620 --> 00:50:29,440
Bonferroni. I just want to highlight here is the most conservative post-hoc test that you can run.

415
00:50:30,160 --> 00:50:39,310
It literally takes your p value of .05 divided by the number of tests that you're going to run, and that becomes your new rejection of value.

416
00:50:40,600 --> 00:50:51,220
So if you want to be as sure as you can based on your your level of comfort .05.01.001 and then introduce post-hoc comparisons,

417
00:50:51,550 --> 00:50:57,940
use different Tukey and all the other ones means that the differences are so marginal.

418
00:50:58,150 --> 00:51:03,850
What I would suggest is if you're ever going to run, run a couple of them, I would not expect to see major differences.

419
00:51:04,450 --> 00:51:08,170
Don't keep running different tests until you find one that works right.

420
00:51:08,530 --> 00:51:15,040
If you see that three of them don't work, you're done. If you see that you're at two of them and they both work fabulous.

421
00:51:15,310 --> 00:51:19,660
If you see that this one works, but for whatever reason, the more conservative one doesn't work.

422
00:51:20,170 --> 00:51:24,550
Maybe that's a decision point that you can make. Yes.

423
00:51:25,000 --> 00:51:35,800
So for the p value. So that's telling us that the only the African-American exposure to violence was significantly different feelings of safety.

424
00:51:35,890 --> 00:51:40,420
Only African-American, black, white, Caucasian.

425
00:51:40,780 --> 00:51:44,320
Okay. Oh, a 1 to 1 versus that's the only significant difference.

426
00:51:44,440 --> 00:51:49,620
Yep. Yes. So in the second section, you changed it to 930.

427
00:51:49,630 --> 00:51:58,060
And so if we wanted to remember for a new look mean. Yeah, that's what this whole mumbo jumbo is right here.

428
00:51:58,930 --> 00:52:06,280
So we have yet to use this function. Um, you say which date it is, what your grouping variable is.

429
00:52:06,700 --> 00:52:13,360
So this is the outcome. Variable grouping. Variable paired is just whether or not these are paired observations, which in this case they're not.

430
00:52:13,390 --> 00:52:16,300
So like if you were running a paired t test, you could do something similar.

431
00:52:17,770 --> 00:52:22,960
And then it's the adjustment method that we are specifying the type of post-hoc we want to run.

432
00:52:23,920 --> 00:52:30,310
So I'm only showing you this line of code because that's the easiest way to get the method I know of, to get the bonferroni.

433
00:52:30,520 --> 00:52:35,260
And that's the whole reason why we downloaded that specific packages package for price comparisons.

434
00:52:35,470 --> 00:52:41,530
Hmm. Um. And probably I'm just.

435
00:52:43,360 --> 00:52:47,920
The PPI adjusted. When I'm looking at those values, I'm still looking for a less than.

436
00:52:48,100 --> 00:52:52,899
Yeah, exactly. Yeah. Yeah. I can just be simple and say.

437
00:52:52,900 --> 00:52:57,010
Exactly. Still looking for our critical carousel. Yep. And we're just in.

438
00:52:57,010 --> 00:53:00,790
It's already done the hard work behind the scenes to tell us what this really is,

439
00:53:01,480 --> 00:53:05,070
whether or not that's a true point of view versus an inflated point of.

440
00:53:09,630 --> 00:53:16,650
How I feel. Aside from some disparities in the numbers that you got versus what I got from I'm not sure for anyone else.

441
00:53:16,650 --> 00:53:21,060
But once we went back through it and maybe it's because they didn't run something, the numbers started.

442
00:53:21,360 --> 00:53:26,280
Yeah, yeah. Yes. That's what I'd like to see is what you're seeing here.

443
00:53:27,480 --> 00:53:34,380
And if it is okay, it is okay. When we when we when we find discrepancies or when you make mistakes,

444
00:53:34,620 --> 00:53:39,480
we're going to go back through we're going to look at our code a little more carefully, and we're going to work to resolve those things.

445
00:53:39,840 --> 00:53:47,130
It's actually when we have script that works out beautifully that sometimes we can make the biggest errors because we're like, Oh, life is good.

446
00:53:47,550 --> 00:53:51,330
I'm not seeing any risk. Therefore, my analysis must be right.

447
00:53:51,840 --> 00:53:56,070
You still need to do the same kind of due diligence and looking through it to make sure that your code all works.

448
00:53:56,790 --> 00:54:00,270
And I might even have an example of where I've done that. It's that kind of skill creation.

449
00:54:00,780 --> 00:54:08,970
It would be very easy in this line of code to make a little bit of a mistake and come up with something completely different.

450
00:54:09,600 --> 00:54:15,300
A parentheses here or there.

451
00:54:15,970 --> 00:54:23,100
And you have a good example. I'll show you a great example when we look at residuals where you're just it's the smallest little stupid thing,

452
00:54:23,880 --> 00:54:27,600
but it results in a major, major difference if it's the butterfly in Central Park, everything.

453
00:54:30,950 --> 00:54:34,640
Other questions about NOVA and postdocs right now.

454
00:54:38,060 --> 00:54:51,060
Yeah. So let's say you decided that you didn't want to do that for me and go back and let's say you did it and you're like,

455
00:54:51,060 --> 00:54:56,549
Oh, and then to run something else or to give or something like that, you're like, Okay, I want to fix this.

456
00:54:56,550 --> 00:55:01,140
How do you go back? You just input the same thing and put in close to you.

457
00:55:01,470 --> 00:55:10,049
Yeah. So for like if you wanted to use this exact same, the same function, what I would say is go to help menu and look up pairwise t test.

458
00:55:10,050 --> 00:55:12,030
That's a function that's built into that package.

459
00:55:12,210 --> 00:55:20,360
It's going to come up with a whole bunch of information and it's going to tell you the other ways to specify the kind of test that you want to write.

460
00:55:21,510 --> 00:55:33,690
So when you're looking at the the box in the bottom, right, the 0.751 for the three one relationship versus the .487, that's not a big difference.

461
00:55:34,110 --> 00:55:39,420
Well, I mean, they're they're both non-significant, so I'm not paying too much attention to all of them.

462
00:55:39,600 --> 00:55:46,340
But it would make sense that these are all a little bit higher than these the conservative approaches.

463
00:55:46,470 --> 00:55:52,480
Okay. How are you doing?

464
00:55:54,040 --> 00:55:58,420
You understand why we want to use an ANOVA and when to potentially using ANOVA.

465
00:55:59,320 --> 00:56:05,740
I know you have groups out there that you care about, whether natural, socially constructed or whatever.

466
00:56:06,280 --> 00:56:15,219
So we're using over quite a bit. And then also next week we'll start to see how that same kind of idea of between group and within group air.

467
00:56:15,220 --> 00:56:18,370
And we're going to change the we're going to change the language a little bit,

468
00:56:18,850 --> 00:56:23,500
but we're going to start talking about like kind of model explained variance because this is a statistical model.

469
00:56:23,890 --> 00:56:29,290
It's saying that a model where group is our predictor variable explains outcome variation.

470
00:56:30,010 --> 00:56:41,330
So we'll use that same. What does our model explain? Over here.

471
00:56:43,750 --> 00:56:50,300
It's gonna be the same thing as between groups or an end group.

472
00:56:51,790 --> 00:57:00,340
Right. It's going to the same kind of idea, and it's going to be some squares regression, some of squared.

473
00:57:02,920 --> 00:57:13,260
Air. When we get bogged down by the language here, you know, this stuff, what our model predicts relative to what it doesn't predict,

474
00:57:14,040 --> 00:57:22,230
what our model in this case we think groups are driving the relationship are driving the information versus not groups.

475
00:57:23,670 --> 00:57:33,390
What our model can explain, what our model can't explain. I was just thinking about the real life implications of reverse coding.

476
00:57:34,500 --> 00:57:42,600
Like, I have a database that I kind of created just nothing, and I have a lot of different measures in there.

477
00:57:43,050 --> 00:57:52,070
So would it be better to just go back and see if I can make more often than not go in the same direction?

478
00:57:52,080 --> 00:57:57,000
Or is it better to preserve, I guess, the nature of the question.

479
00:57:57,400 --> 00:58:00,680
Yeah. Yeah. So that's a that's a fabulous question.

480
00:58:00,690 --> 00:58:05,400
I love it. It's where we're going to spend a lot of time. When we get into the measurement section in a few weeks,

481
00:58:05,820 --> 00:58:13,770
it's going to be a there's a combination of kind of theoretical or your own understanding that's going to inform that answer.

482
00:58:14,010 --> 00:58:18,530
But then we can also supplement that with some of the empiricism that we can use here.

483
00:58:18,540 --> 00:58:22,770
So we can run reliability checks, we can run factor analysis to ensure that, in fact,

484
00:58:23,100 --> 00:58:32,370
having these three items paired together as they are makes sense and that they not just conceptually but analytically load together,

485
00:58:32,370 --> 00:58:36,420
traveled together means something similar to participants who responded.

486
00:58:36,690 --> 00:58:40,470
And we can infer that from some of our data. So that's what we'll do in three or four weeks.

487
00:58:41,700 --> 00:58:45,840
Yeah, I'm still unsure about the damping the dummy variable.

488
00:58:48,150 --> 00:59:03,360
So the idea here is that our can't just use coded behind the scenes to 1 to 3 in a linear way, like an integer as it would with a normal regression.

489
00:59:03,840 --> 00:59:10,710
What it can do is create a bunch of zero one categories or indicator variables that's going to tell it.

490
00:59:11,190 --> 00:59:18,899
Whether or not we were talking about somebody in group, one group to a group three dummy coatings.

491
00:59:18,900 --> 00:59:25,470
Is the process behind the scenes that will help it say, All right, now I'm talking about people in group one.

492
00:59:25,950 --> 00:59:29,010
Now I'm talking about people I'm going to talk about people under three.

493
00:59:29,370 --> 00:59:33,570
We will use dummy coding to essentially get to these kinds of coefficients.

494
00:59:34,200 --> 00:59:40,200
They're going to we're going to find out that those dummy codes will give us regression coefficients,

495
00:59:40,530 --> 00:59:45,330
those data values that are equal to the differences between groups.

496
00:59:46,080 --> 00:59:48,780
That's how it's going to use dummy coding to say, basically,

497
00:59:48,960 --> 00:59:54,810
you're going to multiply anybody who gets it, who says they are black African-American by 0.19.

498
00:59:55,480 --> 01:00:00,240
Right. And that's or whatever the difference is going to be in the alpha variable because we would expect them to have or sorry,

499
01:00:00,480 --> 01:00:07,530
I guess it would be white here because we would expect them to have about a 0.19 higher predicted value of I feel safe.

500
01:00:08,010 --> 01:00:15,750
In fact, why don't we go ahead and do this? In fact, probably fail.

501
01:00:15,780 --> 01:00:19,860
I hate coding on the fly, but we'll try it. We'll try. We'll try it, folks.

502
01:00:22,680 --> 01:00:36,990
So formula is going to be wave one E TV squiggly wave one.

503
01:00:45,370 --> 01:00:51,680
So I'm going to do this for you. All right, well, what else do we need here?

504
01:00:52,250 --> 01:01:01,130
We need data. Right. Data equals the CTV.

505
01:01:09,770 --> 01:01:13,370
Doing this because we need to save it as a regression object. Sure.

506
01:01:13,370 --> 01:01:19,120
Hands you think is going to work. I think you're doing it.

507
01:01:22,190 --> 01:01:29,510
All right. So what we see here is the exact same model that we just ran.

508
01:01:30,110 --> 01:01:35,629
It doesn't look the same in terms of its output because we're not we're not using that ANOVA function.

509
01:01:35,630 --> 01:01:46,480
We're using the linear model function. That's why we ran it, because I got excited about my self.

510
01:01:47,210 --> 01:01:55,070
Sorry. I think that I'm just assuming that's not mad at me.

511
01:01:56,290 --> 01:02:02,510
All right. So what we're going to see here is all of that information just distilled in a slightly different way.

512
01:02:02,900 --> 01:02:09,010
So we now have our outcome variable for events.

513
01:02:09,380 --> 01:02:13,070
We have our predictor variable race. We have two coefficients.

514
01:02:13,070 --> 01:02:18,810
Why do we have two coefficients? I love it.

515
01:02:18,930 --> 01:02:23,580
I like one. Why do we have to go fishing?

516
01:02:23,760 --> 01:02:29,580
That means I don't know. Oh, why do we have two conditions?

517
01:02:29,870 --> 01:02:36,210
One. It's a race to win races, right?

518
01:02:37,830 --> 01:02:41,700
Exactly. This is dummy by in action. All right.

519
01:02:41,910 --> 01:02:51,330
So if we recall with our dummy Coney, we're going to have a variable, one variable to refer to category one.

520
01:02:52,500 --> 01:02:57,590
I forget how to get it. So we're going to have.

521
01:03:01,550 --> 01:03:07,860
Yeah, I him. Right.

522
01:03:08,360 --> 01:03:11,540
And so we had a very good one, too.

523
01:03:13,070 --> 01:03:19,670
The way our dummy coating is going to work is our reverend category in this case is just the default.

524
01:03:20,720 --> 01:03:24,380
They, I believe, are goes by the letter of the alphabet.

525
01:03:25,370 --> 01:03:29,390
And so it's going to choose B for variable one.

526
01:03:29,780 --> 01:03:34,730
We're going to have one zero. The variable two are for the third category.

527
01:03:34,890 --> 01:03:42,800
And that's by knowing these two values, you know, whether or not you're talking about someone in this group, this group or this group.

528
01:03:43,640 --> 01:03:46,250
If you said one, two, variable one, you know, you're white, Caucasian.

529
01:03:46,250 --> 01:03:52,700
If you said one, variable two, we know that you're messing around with your variable one and you say no to all of these.

530
01:03:57,800 --> 01:04:09,740
We were me and I was really fine as we can start to figure out based on our understanding of all regression.

531
01:04:10,220 --> 01:04:16,100
Of regression. What these different values mean.

532
01:04:16,700 --> 01:04:19,820
Now tell me. Intercept in regression.

533
01:04:20,270 --> 01:04:24,499
How do we interpret the intercept? It is our predictive value.

534
01:04:24,500 --> 01:04:32,890
The outcome variable. When? You got to get a nice and loud stand up.

535
01:04:32,900 --> 01:04:37,990
And I think on the 01110 and it crosses over the wire.

536
01:04:38,260 --> 01:04:48,760
Yeah. Yeah. And when does it cross the y axis? When the dependent variables are when all of our predictor variables are zero.

537
01:04:49,060 --> 01:04:54,940
This is our expected value for our outcome variable. Now this is what are some of our dummy code?

538
01:04:55,390 --> 01:05:01,240
I'm sorry, because I think this is kind of cool. This is our predicted value of the outcome variable.

539
01:05:01,480 --> 01:05:06,100
For whom? Who are we talking about when these two values are zero?

540
01:05:08,340 --> 01:05:17,690
But. Right. By adding a predictor, we've changed fundamentally what our intercept value needs.

541
01:05:19,100 --> 01:05:25,040
This is the predictive value of feelings of safety for African-Americans in our sample.

542
01:05:28,210 --> 01:05:33,980
Now, if life is good to me. Oh, it is good to me.

543
01:05:35,050 --> 01:05:43,650
It is good to me. It's a good day. We get their descriptive information.

544
01:05:48,720 --> 01:05:55,470
The it is very important for these coefficients.

545
01:05:55,470 --> 01:05:58,860
Do they start to look familiar now? Where did we see those?

546
01:06:00,700 --> 01:06:09,180
Oh, yeah, absolutely. These are literally just the subtracted differences between these means.

547
01:06:10,020 --> 01:06:15,030
So, you know, small, which we also saw postdocs wasn't doing it.

548
01:06:19,230 --> 01:06:24,480
They're not doing any sort of magic here. We are literally just subtracting the two needs and saying, Is this?

549
01:06:24,980 --> 01:06:25,680
Are these different?

550
01:06:26,100 --> 01:06:34,110
Can we infer that these are different and not just a chance calculation of 1.9 based on the responses of African-Americans in a way, in the sample?

551
01:06:34,830 --> 01:06:42,980
What is that difference kind of big? Or is it, you know, within the realm of chance or within the purview of, you know,

552
01:06:42,990 --> 01:06:47,910
we could have just happened to sample and get people whose feelings of safety were still roughly the same,

553
01:06:48,360 --> 01:06:50,850
not so large that we would say that there's a difference because of their group.

554
01:06:52,470 --> 01:07:01,040
We get the exact same information here, folks, 1.9, 1.6, seven, and mean if we're talking about in the thousands column, I'm not too worried about it.

555
01:07:01,050 --> 01:07:07,050
And that's kind of a just the the algorithm behind the scenes that might be making the smallest differences.

556
01:07:08,010 --> 01:07:11,400
But this tells us to, in effect, our post-hoc.

557
01:07:12,270 --> 01:07:21,300
This tells us that our second category for our race variable relative to our referent category, African-American black.

558
01:07:22,440 --> 01:07:30,240
This group has a higher predicted mean than our roughly significantly higher predicted the mean.

559
01:07:31,620 --> 01:07:34,590
Contrast that in the third group relative to our referent category.

560
01:07:35,070 --> 01:07:41,580
What we don't have in this case is the comparison between Caucasian, white and mixed African-American.

561
01:07:43,860 --> 01:07:47,070
That's really that's a potential of a piece of lost information.

562
01:07:47,490 --> 01:07:54,450
But we could change our response if we wanted. ANOVA and regression are the exact same thing, the exact same.

563
01:07:55,410 --> 01:08:01,230
It's presented a little differently. We kind of tend to use them in different cases and it's completely okay.

564
01:08:02,010 --> 01:08:06,540
But the underlying model fit all that stuff is going to be exact.

565
01:08:06,540 --> 01:08:09,990
Same here. I agree with you.

566
01:08:10,410 --> 01:08:15,090
How do we explain the all the outcome variable? This percentage of variance?

567
01:08:15,090 --> 01:08:22,160
Explain. Yeah.

568
01:08:22,400 --> 01:08:28,520
About 1% of the outcome variable with an emphatic.

569
01:08:28,520 --> 01:08:34,160
Yes, that's correct. So we are explaining next to no variability in our outcome variable.

570
01:08:34,640 --> 01:08:40,820
I'm not thinking that race is a strong predictor of understanding the feelings of safety you might have in your neighborhood.

571
01:08:41,480 --> 01:08:45,950
Another piece of information that you can kind of get from the regression framework that you might lose with an ANOVA,

572
01:08:46,250 --> 01:08:52,460
but we can also use ANOVA to essentially come up with what is our kind of R-squared value.

573
01:08:53,240 --> 01:08:55,700
But what this tells us, interestingly enough,

574
01:08:55,700 --> 01:09:05,180
is even though this result suggests that there's there's a group difference and group really matters in the grand scheme of things.

575
01:09:06,140 --> 01:09:09,280
1% of your variability, risk and feelings of safety.

576
01:09:09,830 --> 01:09:14,570
I'll let you decide whether or not that is kind of a, if you will, clinically or practically significant difference.

577
01:09:15,530 --> 01:09:18,140
And what we might do about it maybe still is correct.

578
01:09:18,590 --> 01:09:31,970
So when you said you can tell that the other two are higher than The Intercept, how do you see that from those not?

579
01:09:32,100 --> 01:09:36,020
What would it look like if they were lower the same? The difference.

580
01:09:36,650 --> 01:09:44,719
Oh, you're one of these groups is lower. Yes, Z a negative. So we think about our think about Y equals an X plus B, right?

581
01:09:44,720 --> 01:10:02,480
So what this is going to be is EDV equals 2.91 plus our beta coefficient which is 0.19 times when you're your weight plus .16 times we're there.

582
01:10:03,430 --> 01:10:11,660
Right. So if one of these groups is lower because these are religious differences, this would be a negative instead of a positive.

583
01:10:11,930 --> 01:10:19,700
Oh, take an individual. If I am white, I plug in one for here, a zero for here.

584
01:10:20,120 --> 01:10:25,460
I take 2.94 and one times 2.9, which is two or 3.13.

585
01:10:25,880 --> 01:10:30,470
I get a zero here. So this cancels out and I'm going to end up my predicted value for you.

586
01:10:30,470 --> 01:10:34,410
TV is going to be at 3.13 if.

587
01:10:40,460 --> 01:10:44,150
Good stuff. Well, the nice thing about that is.

588
01:10:48,830 --> 01:10:57,920
The last thing I kind of wanted to talk about was penultimate thing, I guess because this is some of the assumption checking that we need to do.

589
01:10:58,490 --> 01:11:01,280
We'll spend a lot of time not next week, but the week after doing this.

590
01:11:01,550 --> 01:11:08,540
Any time that we are creating a statistical model, it's all based on a set of assumptions that I think you've probably been introduced to in the past.

591
01:11:08,540 --> 01:11:11,960
We're thinking about like normal distributed variables.

592
01:11:12,230 --> 01:11:13,940
We're thinking about homogeneity, variance.

593
01:11:14,390 --> 01:11:21,890
These are some terms that you haven't heard about in a little while, don't feel bad, but essentially we have a couple of tests that we want to run.

594
01:11:22,190 --> 01:11:28,400
Namely, we do want to see that the groups have roughly equal variance across those items.

595
01:11:28,850 --> 01:11:35,509
So if it's the feelings of safety, we want to look at those variables in the described by a command and see if there's

596
01:11:35,510 --> 01:11:40,250
like a lot of change in the variability in those responses based on your group.

597
01:11:40,710 --> 01:11:44,570
Right. That's essentially what the equal variance assumption is going to tell us.

598
01:11:45,380 --> 01:11:48,920
But the nice thing is there are ways around it if we know that, for example,

599
01:11:48,920 --> 01:11:57,350
African-Americans in the sample vary quite largely on how they respond to those items, whereas mixed race folks in the sample don't very much.

600
01:11:58,220 --> 01:12:08,960
There's not a lot of variability in their responses. We could use something like this which will take into account that that unmet assumption.

601
01:12:09,830 --> 01:12:14,630
So homogeneity of variance is kind of the same sort of idea.

602
01:12:14,960 --> 01:12:20,750
If we look at different levels, we would expect that the variability in the residuals is going to be kind of the

603
01:12:20,750 --> 01:12:26,660
same if it's again been a year or more since you heard some of these terms.

604
01:12:28,190 --> 01:12:35,240
We'll talk about them in a lot of like in a couple of weeks. But just know that we will do this for almost any sort of linear models that we run.

605
01:12:35,780 --> 01:12:41,140
Okay. So for that. You want that value to be lower.

606
01:12:42,400 --> 01:12:53,260
In this case, we would want that value to be non-significant because the null hypothesis is that the variance is the same across groups.

607
01:12:53,410 --> 01:12:57,010
So it doesn't matter how high that value is. Nope. Yeah.

608
01:12:59,350 --> 01:13:05,200
Okay. But this is what I wanted to just make kind of a quick connection and cover

609
01:13:05,200 --> 01:13:12,370
has its own kind of lexicon that people use to describe its purpose and use,

610
01:13:12,790 --> 01:13:18,400
for your intents and purposes on these is adding a control variable or a covariate to the analysis.

611
01:13:18,940 --> 01:13:24,280
So if we were originally interested in the same question, does group matter for feelings of safety?

612
01:13:24,700 --> 01:13:29,290
I might also think, well, what are some of the other things that might influence whether someone feels safe?

613
01:13:29,980 --> 01:13:33,730
So regardless of your neighborhood or your school or even your race,

614
01:13:34,720 --> 01:13:40,510
having had someone threatened to hurt you in the past could influence these responses.

615
01:13:41,290 --> 01:13:46,030
So I might want to know, after accounting for whether you've been threatened with violence.

616
01:13:46,600 --> 01:13:51,790
Does your race still predict your feelings of safety in your school neighborhood?

617
01:13:53,530 --> 01:13:57,790
Makes sense. This is our first kind of multivariate analysis.

618
01:13:59,950 --> 01:14:05,620
The nice thing about all these linear models is that they're easy to add new variables.

619
01:14:06,910 --> 01:14:10,930
We're still using the analysis of variance command. We're going to regress.

620
01:14:11,500 --> 01:14:16,090
I'm just going to go ahead and use that language. So now we need to do the exact same thing.

621
01:14:16,600 --> 01:14:20,890
We're going to regress exposure to violence on race.

622
01:14:22,480 --> 01:14:26,230
And this variable. Has anyone threatened to hurt me?

623
01:14:27,340 --> 01:14:34,780
Okay. What this is going to do is run the same test, but it's going to wash out.

624
01:14:35,590 --> 01:14:39,850
Ideally, some of the error that we don't know.

625
01:14:40,270 --> 01:14:48,520
Right. So some of the variability in the outcome variable that's attributable to something other than race, that's the goal of Vancouver.

626
01:14:48,970 --> 01:14:52,660
We want some of that variability that we wouldn't be able to explain with our

627
01:14:52,660 --> 01:14:57,549
grouping variable to get to get kind of knocked out or cancel out explained,

628
01:14:57,550 --> 01:15:03,640
if you will. So we add covariates that we believe are associated with the outcome,

629
01:15:04,540 --> 01:15:09,550
but ideally not associated with the other independent variable or the grouping variable.

630
01:15:10,090 --> 01:15:15,100
That doesn't matter you a three.

631
01:15:15,880 --> 01:15:19,690
So you've regressed on race and then you add in the covariate.

632
01:15:20,410 --> 01:15:26,840
Does it matter if those are flipped? It will.

633
01:15:27,630 --> 01:15:31,350
And in a specific context, I'm going to give you a bunch.

634
01:15:31,830 --> 01:15:36,930
So generally speaking, this does the order doesn't matter.

635
01:15:36,960 --> 01:15:40,590
Shouldn't matter. Right. When we do regression.

636
01:15:40,800 --> 01:15:44,630
It absolutely does not matter. Weird.

637
01:15:44,640 --> 01:15:47,910
And Kobra, I'm going to show you in just a second how it can happen.

638
01:15:48,810 --> 01:15:53,250
All right. So for the script, you can do it anywhere you want.

639
01:15:54,270 --> 01:15:57,960
But what we're going to see here now is we have a new subject square term

640
01:15:58,410 --> 01:16:01,350
because these are both trying to explain variability in the outcome variable.

641
01:16:02,070 --> 01:16:08,310
Ideally, again, this is someone threatened me is explaining some chunk of the time to be explained.

642
01:16:08,760 --> 01:16:14,280
This one is going to explain its own variability and then there still some error that we can't explain.

643
01:16:14,790 --> 01:16:19,580
So it's going to be trying to make this term be very large relative to this one.

644
01:16:20,440 --> 01:16:25,170
What this covariate is doing is making this even smaller.

645
01:16:26,100 --> 01:16:33,420
It's ticking away at our denominator so that this relative to this gets even larger.

646
01:16:33,870 --> 01:16:40,980
So when we add a covariate that's doing a good job, we should see our F statistic for our grouping variable go away.

647
01:16:42,870 --> 01:16:48,570
If you have an intervention that you're testing and you want your treatment group to be better than your to control conditions,

648
01:16:49,230 --> 01:16:55,950
including covariance can make the likelihood of us of detecting a treatment effect go up.

649
01:16:56,910 --> 01:17:00,930
If you don't remember anything else for my cohort, remember that piece of it.

650
01:17:01,470 --> 01:17:04,710
That's why we like to have. That's the goal here.

651
01:17:10,090 --> 01:17:14,550
All right. So to Heather's question, and this is only true for a note.

652
01:17:15,570 --> 01:17:23,640
The default output for ANOVA is to use what's called type one sums of squares.

653
01:17:25,170 --> 01:17:30,330
So ultimately, we're trying to, in variability, explain a few type one sums of squares.

654
01:17:30,750 --> 01:17:35,040
So let's take our first one, see how much of the pie you can explain.

655
01:17:36,120 --> 01:17:43,860
And it's going to take the second one. The question is essentially going to be of what's left, of what's left to be explained.

656
01:17:44,760 --> 01:17:51,959
How much does my second variable explain that puts the later variables in your analysis at a

657
01:17:51,960 --> 01:17:58,150
little bit of a disadvantage because it's giving priority to the first explanatory power,

658
01:17:58,190 --> 01:18:03,230
the first variable, and then so on and so forth. Right.

659
01:18:05,880 --> 01:18:10,170
I know how much this is sticking with folks. We can review it because it is to a certain extent important.

660
01:18:10,170 --> 01:18:12,700
This is kind of a semi partial and partial correlations.

661
01:18:12,720 --> 01:18:19,620
If you watch the video, you're trying to make a case for why independent of other variables are grouping variable matters.

662
01:18:20,370 --> 01:18:29,730
This is a more stringent test of the effectiveness of our behavior and how important every variable is to get around it.

663
01:18:30,480 --> 01:18:40,590
We can specify type three sums of squares, which is basically going to account for the order in which we put the variables in there,

664
01:18:41,250 --> 01:18:44,460
which you notice then changes these sums of squares.

665
01:18:45,570 --> 01:18:49,680
This is what regression is going to do for us, that linear model command automatically.

666
01:18:49,980 --> 01:18:54,809
So we don't have to think about ANOVA. As far as I can recall in recent memory,

667
01:18:54,810 --> 01:19:00,450
move right now is the only context where we have to be specific about the order in which we take these values.

668
01:19:02,010 --> 01:19:09,270
Okay. So, Heather, your question. If you if my script says the reverse, you're going to probably see different numbers here.

669
01:19:09,840 --> 01:19:15,390
You see a different order and probably different numbers. This, on the other hand, should be the same.

670
01:19:16,480 --> 01:19:20,760
Your might be flipped, but the numbers should be the same. That makes sense.

671
01:19:23,080 --> 01:19:32,910
Hmm. Ish. Ish. All right. So you have a homework assignment for this week, and KOVA is not part of that homework assignment.

672
01:19:33,390 --> 01:19:38,520
Your homework assignment is to get to where you were today, as well as run some postdocs.

673
01:19:39,180 --> 01:19:47,640
It's taken, I think, pretty much the same example from SARS and just twist, just tweaking it just a teeny tiny bit.

674
01:19:48,450 --> 01:19:51,680
All right. So I'm thinking of Sydney within your purview.

675
01:19:51,690 --> 01:19:55,770
I'm hoping folks are fairly confident if they're not, reach out to me sooner rather than later.

676
01:19:56,010 --> 01:19:59,250
And I'm happy just to help folks. My office hours are on Tuesdays.

677
01:19:59,490 --> 01:20:02,550
If you can make my Tuesday, Officer Cimino not be Happy New Year.

678
01:20:03,750 --> 01:20:09,390
Next week I'm going to actually be here every day, so I'll be around a lot next week if folks have questions.

679
01:20:09,720 --> 01:20:17,820
But really what I want to see is here and being able to say something about your grouping variable and how it's affecting the outcome variable.

680
01:20:18,120 --> 01:20:21,990
I want you to do this. Tell me a little something about this post talks.

681
01:20:22,380 --> 01:20:27,000
This stuff is on there, but it's not it's not required.

682
01:20:27,360 --> 01:20:32,280
All right. It's like a bonus. And if you want to take a shot at it, go for it. Honestly, any of this stuff, it's a good faith effort.

683
01:20:32,280 --> 01:20:35,670
I'm not going to imagine. I just want to help you learn what what to do. Okay.

684
01:20:36,270 --> 01:20:42,600
Yeah, you can post answers, and then we won't do too late, but.

685
01:20:42,630 --> 01:20:50,580
Yeah, yeah. Uh, all right.

686
01:20:50,580 --> 01:20:58,320
Well, we're not out of time for this, but the first encode is also kind of our first thought about around interaction variables.

687
01:20:58,500 --> 01:21:00,809
And this is just presaging what we're going to do in about three weeks when we

688
01:21:00,810 --> 01:21:04,620
start to talk about how variables can interact and what that is statistically.

689
01:21:04,620 --> 01:21:07,919
But we'll be we'll we'll get a chance to do that later.

690
01:21:07,920 --> 01:21:13,710
So the next week or two, we'll spend some time reviewing some of these key concepts.

691
01:21:13,950 --> 01:21:15,779
And then we are going to start with regression,

692
01:21:15,780 --> 01:21:21,359
which you can see is already really closely related to what we've already what we've been doing with correlation.

693
01:21:21,360 --> 01:21:27,660
And so so thank you all. I really appreciate your time. We have a great weekend and we'll see you next Tuesday.

694
01:21:28,690 --> 01:21:31,830
No, man, I don't know if you have a second. I'm happy to look to see if I can get your.

695
01:21:37,760 --> 01:21:40,870
Yeah. They should all be those in ones. Oh yeah.

696
01:21:40,880 --> 01:21:45,730
They're, they are here now in the car.

697
01:21:46,180 --> 01:21:49,670
Yeah. They're all the same ones. I think they're starting to win.

698
01:21:50,630 --> 01:21:55,190
Were you able to get to say the numbers or. No, no.

699
01:22:05,520 --> 01:22:22,070
Know. Yeah, but I don't we I for this is all I was getting.

700
01:22:27,020 --> 01:22:31,600
And the thing with it, it was this one, right?

701
01:22:32,290 --> 01:22:36,890
No. Um, so let's see if we can get to.

702
01:22:37,490 --> 01:22:44,690
Can you do this if you happen to. Okay.

703
01:22:44,690 --> 01:22:49,490
So there's all the good news at sea, right?

704
01:22:50,600 --> 01:22:55,270
Sure. Oh, no.

705
01:22:55,530 --> 01:22:58,720
Oh, shoot. All right. Paper towels?

706
01:22:58,740 --> 01:23:05,490
Yeah. Yes. Right.

707
01:23:09,470 --> 01:23:16,800
And you're pretty good about quitting the World Cup. What?

708
01:23:27,650 --> 01:23:31,430
Okay. So so going to show you lead area.

709
01:23:34,650 --> 01:23:46,190
All right. So how far off are we here? I'd prefer to have that all look worth 4.23.

710
01:23:46,190 --> 01:23:49,540
2.39, 2.62 points.

711
01:23:49,610 --> 01:23:54,950
Okay, so what's happening here? The reason why these are different is because this variable is recoded.

712
01:23:55,430 --> 01:23:59,299
So if you go to this line right here, that's where we change.

713
01:23:59,300 --> 01:24:02,680
Or we reverse coded that value to five. Nope.

714
01:24:02,780 --> 01:24:07,010
So six minus that value before we do. So this one.

715
01:24:07,160 --> 01:24:10,170
Yes. Right. Yeah. I think I'd run into. Interesting.

716
01:24:10,640 --> 01:24:15,650
All right. Now, let's get this further. Let's rerun that 41.

717
01:24:17,600 --> 01:24:22,520
Mm hmm. All right. Can you clear this room 43 real quick?

718
01:24:25,160 --> 01:24:32,930
Oh, okay. Oh, okay. I think I gave the speech, and I didn't do that.

719
01:24:33,110 --> 01:24:36,650
I didn't do anything. Okay.

720
01:24:36,680 --> 01:24:42,589
Yeah, that would make sense. So that's using the three variables and combining them, adding them up divided by three.

721
01:24:42,590 --> 01:24:49,550
And that's going to give us a mean score. That's what we're using as our exposure to violence variable or feelings of safety variable.

722
01:24:49,940 --> 01:24:54,350
Oh, okay. That makes sense. So then from there, I think you're going to be you're going to have similar numbers.

723
01:24:54,470 --> 01:24:57,890
You can run it if you want. But I think that was the divergence.

724
01:24:59,690 --> 01:25:04,130
Does it mean that if you do anything at the top, they have to run everything?

725
01:25:04,640 --> 01:25:09,160
So if you go up into the top of your script and you make a change, I would start from there.

726
01:25:09,200 --> 01:25:11,330
Keep running. I've run down. Oh, okay.

727
01:25:11,700 --> 01:25:17,360
So that's just to make sure if there was any sort of manipulation that happened afterwards that it's given captured with your script.

728
01:25:18,390 --> 01:25:21,620
And then I have a question about the homework. Sure.

729
01:25:22,370 --> 01:25:28,160
I think on times like on the homework assignment thing.

730
01:25:28,470 --> 01:25:32,180
It's saying 830, but then it also says 1130.

731
01:25:32,180 --> 01:25:37,720
So that's from 1159 all the time.

732
01:25:38,780 --> 01:25:43,160
Yeah. Yeah, sure. But the copy. Oh, I'm so sorry.

733
01:25:44,970 --> 01:25:50,830
Yeah. Have you went to your.

734
01:25:50,910 --> 01:25:54,200
And I have to be your next notebook because I'm flying back from Hawaii.

735
01:25:54,230 --> 01:25:58,010
Oh, really? Conference in the morning. Oh, I know.

736
01:25:58,190 --> 01:26:01,340
I have as good life as inheritances. I know.

737
01:26:01,580 --> 01:26:05,150
Especially the surgical ones, I'm sure. But I just. I like.

738
01:26:05,540 --> 01:26:11,839
What is it the physicians have the right location says, like, I don't know what to tell you,

739
01:26:11,840 --> 01:26:17,270
but Pedes Trauma Society, I can send something there next year and it's going to be in New Orleans.

740
01:26:17,270 --> 01:26:21,140
And she's like, I think I could justify going to. No. Yeah, exactly.

741
01:26:21,400 --> 01:26:30,540
Ours are like in D.C. You're right. Yeah. The one that the there's one for firearms in D.C. and like the end of November.

742
01:26:30,580 --> 01:26:34,790
Yeah. You're going to go here? Yeah. Good. They told us all of us are going. It's like, great.

743
01:26:35,600 --> 01:26:37,360
Yeah, I have, like, this.

