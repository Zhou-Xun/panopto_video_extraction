1
00:00:02,650 --> 00:00:17,850
All right. So it's just.

2
00:00:20,260 --> 00:00:27,260
The briefing from the logistics sharing.

3
00:00:31,350 --> 00:01:34,450
You. One.

4
00:01:45,230 --> 00:01:54,230
It's very odd. Looks like what is on the screen, but it's not popping up.

5
00:02:01,950 --> 00:02:33,290
Well. Well.

6
00:02:39,120 --> 00:02:42,740
Yes. Did.

7
00:02:46,900 --> 00:02:50,620
A computer, but. They can do.

8
00:02:54,390 --> 00:03:12,730
You know. Sorry, folks, I've been carried this before, and the instructions here seem to be working.

9
00:04:01,630 --> 00:04:08,860
Hello? Oh, yeah. Um, I'm in IM 1112 Mike Elliott.

10
00:04:09,370 --> 00:04:15,519
And I'm starting to class, and for some weird reason, I cannot quite get the projector to work.

11
00:04:15,520 --> 00:04:21,850
It's. It's projecting a screen, but it's not what's on the screen on the, on the desktop.

12
00:04:22,180 --> 00:04:26,980
And I've tried everything here and I can't seem to figure out any way to get it to get fixed.

13
00:04:33,640 --> 00:04:54,270
Maybe. And then she got a little thing on the side there.

14
00:04:54,630 --> 00:04:58,020
Yeah. Okay. And then if you go to.

15
00:04:59,040 --> 00:05:04,919
There's a duplicate. Yes. I just do that and and click on that and then see if that works.

16
00:05:04,920 --> 00:05:07,950
Really does the trick. Thank you. All right.

17
00:05:07,990 --> 00:05:11,280
Awesome. Okay.

18
00:05:12,570 --> 00:05:17,420
All right. Sorry for that delay. Okay.

19
00:05:17,430 --> 00:05:20,280
So just in terms of logistics,

20
00:05:23,160 --> 00:05:33,390
I'll put up the list of the order which we randomly assigned for a post that today or tomorrow or for class on Wednesday.

21
00:05:34,920 --> 00:05:41,310
And I have my lost my last office hours today at the usual 330 time.

22
00:05:43,680 --> 00:05:50,010
Okay. So I was just going to finish up this discussion of time for an exposure with a little example.

23
00:05:54,150 --> 00:06:00,980
So he sort of talks about different approaches to dealing with this fact that the

24
00:06:01,050 --> 00:06:08,790
sort of traditional regression approaches conditioned on sort of covariates.

25
00:06:08,790 --> 00:06:12,930
And so we looked at inverse probability weighting in this G estimation approach.

26
00:06:14,040 --> 00:06:23,249
So I, from the very end, ultimately decided on a very simple example, basically kind of a randomized first step, right?

27
00:06:23,250 --> 00:06:33,060
So the probability of getting some initial treatment is, is 0.5, 0.5 for treatment, point five for control.

28
00:06:34,320 --> 00:06:35,520
And then you can think of this,

29
00:06:36,900 --> 00:06:45,930
the sort of X one is a sort of maybe a preliminary outcome or maybe a correlated biomarker that's going to affect the second the second assignment.

30
00:06:46,890 --> 00:06:51,420
The second assignment. Basically, if you get treated at time, one,

31
00:06:52,200 --> 00:07:00,990
you're more likely to get treated at time to both marginally and then even more likely if if the X one value is higher.

32
00:07:01,950 --> 00:07:03,600
And similarly for the value of x one.

33
00:07:04,770 --> 00:07:10,770
So both both have independent effects and then kind of an effect modification multiplier effect on this probability.

34
00:07:11,910 --> 00:07:20,760
And then the final outcome basically interacts is basically a function of the number of treatments, partly interacted with a value of X one.

35
00:07:20,760 --> 00:07:26,040
So if you get treated the first time, the next one has an impact.

36
00:07:26,750 --> 00:07:34,680
If you're and if you're treated both times X one has an impact and otherwise the treatment at the second times.

37
00:07:35,250 --> 00:07:42,930
So the only effect. So kind of analytically work out what the potential outcomes here are.

38
00:07:44,080 --> 00:07:48,360
Right. So you put that up there, you could see that.

39
00:07:49,170 --> 00:07:55,020
So if I have treatment at time, one of treatment at time to both Z one and Z two or equal to one.

40
00:07:55,980 --> 00:08:02,310
So I end up with 0.5 times one times two, one times x one.

41
00:08:02,880 --> 00:08:08,880
Well, it's expectation given az1 is equal to one and z two as 3 to 1.

42
00:08:08,880 --> 00:08:15,090
So I get that one there. The expected value of x one to z one is equal to one is just, just one, right?

43
00:08:15,540 --> 00:08:20,180
So a 2.0 and then so it goes together.

44
00:08:20,190 --> 00:08:26,459
You get two similar from treated the second time, only right to see 1 to 0.

45
00:08:26,460 --> 00:08:32,610
So this piece doesn't play a role. So that's just going to be one if I'm treated at the first time.

46
00:08:32,610 --> 00:08:39,010
Only then. Let's see here.

47
00:08:39,630 --> 00:08:44,470
Z2 is equal to zero. So. So this is just going to be one.

48
00:08:45,370 --> 00:08:52,570
And of course, that's one. So it's 0.5 times is expected by two X, Y, and Z one, which is we already know it is one.

49
00:08:52,630 --> 00:08:57,580
So 0.5. And then if Z one and Z two are both zero, all these terms go away.

50
00:08:57,620 --> 00:09:01,520
And so it's just zero. So.

51
00:09:02,980 --> 00:09:08,860
So that's our outcome. So looked at a couple of approaches.

52
00:09:09,310 --> 00:09:13,990
So first of all, I just this is the data generating mechanism correct here.

53
00:09:13,990 --> 00:09:25,720
So Z one is is basically random with probability point five and then X1 is basically centered at zero or one dependent on Z, one is.

54
00:09:26,800 --> 00:09:30,160
And then of course observed one corresponds to what I actually got.

55
00:09:31,240 --> 00:09:35,110
And then X2 follows this function here.

56
00:09:36,040 --> 00:09:50,380
And so just taking this expert's already back to probability measure and then trying that and then the actual values,

57
00:09:50,410 --> 00:09:54,400
you can follow this structure here. So basically it's.

58
00:09:56,880 --> 00:10:01,560
One plus one times. Whatever my drawbacks, one isn't under one right.

59
00:10:01,770 --> 00:10:12,390
If I feel both levels, if I'm treated only the first time, it's basically there's going to be one half times that x one after the first treatment.

60
00:10:13,380 --> 00:10:21,210
If I'm treated in only the second time and basically it's just going to be one and I'm not treated in time, it's zero.

61
00:10:22,560 --> 00:10:27,570
And then, of course, the actual value corresponds to what the actual treatment I received are.

62
00:10:28,320 --> 00:10:32,860
Right? So my one, I got both my one zero.

63
00:10:32,880 --> 00:10:39,570
I just got the first treatment by zero one. If I just got the second treatment, the my zero zero, I didn't get either one.

64
00:10:41,280 --> 00:10:45,700
So my unadjusted model.

65
00:10:47,100 --> 00:10:50,430
Right. So basically I,

66
00:10:50,790 --> 00:11:01,019
I just put in Z1 Z two and the interaction so one corresponds to the case where I have

67
00:11:01,020 --> 00:11:06,659
treatment only at the first time so that y10z2 way of treatment only the second time.

68
00:11:06,660 --> 00:11:11,070
So that y01 and then for both of them I just use this little.

69
00:11:12,720 --> 00:11:14,790
Yes, I did put the library in here. Sorry.

70
00:11:15,000 --> 00:11:27,479
There is a sort of a linear model combination thing, I just have to tell it where the linear model was fit and then I put in a vector of coefficients.

71
00:11:27,480 --> 00:11:35,220
So I basically want my intercept to be zero, but I get the y wouldn't want to need beta one, beta two plus the interaction.

72
00:11:36,210 --> 00:11:41,360
So. It gives me this value to shoot here.

73
00:11:44,730 --> 00:11:52,950
And then for the adjusted measures, I just did a sort of blind adjustment for x one and got the same of the same name here.

74
00:11:56,930 --> 00:12:06,620
So you can see the unadjusted approach doesn't doesn't look too good except for maybe the middle one here in particular.

75
00:12:06,620 --> 00:12:07,970
The first one is really far off.

76
00:12:10,400 --> 00:12:21,139
So it's it's even though x one is even though Z one is randomized because I'm looking at this potential outcome at the end where

77
00:12:21,140 --> 00:12:28,970
the impact where the decision for the second step was based in part on something that's associated with a potential outcome,

78
00:12:29,720 --> 00:12:36,350
then I've ended up damaging my my estimate of this of this initial treatment effect.

79
00:12:37,490 --> 00:12:41,750
And similarly here, it's also problematic.

80
00:12:43,310 --> 00:12:49,250
Once I did the adjustment for X, it sort of helped me be a little bit with with this joint outcome.

81
00:12:49,460 --> 00:12:56,120
It actually contains the true value, but the the first effect is really far off.

82
00:12:58,890 --> 00:13:02,190
So then for the propensity score, pretty simple.

83
00:13:02,200 --> 00:13:08,190
I'm just going to put in a plug in X and Z weight by the estimated probabilities.

84
00:13:09,030 --> 00:13:13,200
So I would note this is not quite correct. There's kind of an interaction term here and ignoring.

85
00:13:16,560 --> 00:13:21,780
So but I can still go ahead and get my weights and use the weighted linear regression.

86
00:13:23,110 --> 00:13:31,140
Right. I did have these Z given by Z one, Z two in the interaction and then of course my last two meters.

87
00:13:32,640 --> 00:13:36,630
So, so I go ahead and fit my propensity model.

88
00:13:38,310 --> 00:13:43,620
So I have, you know, my initial weight is basically just two for everybody.

89
00:13:45,030 --> 00:13:47,850
And then the second stage is based on this estimation,

90
00:13:49,170 --> 00:14:04,230
respect to the predicted assignment probability based on the initial treatment assignment and this intermediate outcome x.

91
00:14:05,490 --> 00:14:15,450
And so I put the two together to do my final weight. And you tell it what that weight is in this survey design function.

92
00:14:16,590 --> 00:14:18,210
And then with the variables I'm going to use.

93
00:14:19,560 --> 00:14:28,880
So I go ahead and do that and I get my summary measures again and kind of pick them off the same way and use this in general.

94
00:14:28,980 --> 00:14:38,139
Your hypothesis function here. So, so this did a little bit better in particular.

95
00:14:38,140 --> 00:14:49,710
It kind of fixed up the of the estimated effect of the of the treatment as to the first time I maybe overshot effects for the second treatment.

96
00:14:50,320 --> 00:14:57,150
I know that this propensity model is somewhat mis specified, so could be somewhat problematic in that way.

97
00:14:59,940 --> 00:15:07,950
So. And then finally, for the computation approach and just to remind everybody what this is,

98
00:15:08,370 --> 00:15:11,370
are basically going to be sort of imputing out all of the pieces.

99
00:15:12,570 --> 00:15:17,100
So I actually draw a picture here.

100
00:15:40,280 --> 00:15:46,860
So first I'm going to impute you. And basically so I have.

101
00:15:55,410 --> 00:16:02,030
And since he's served Texas, my reserve.

102
00:16:02,040 --> 00:16:08,340
Excuse me. So what I'm going to create is what I would have had the opposite treatment.

103
00:16:10,720 --> 00:16:15,190
Just generate a bunch of runway scenes and then just going to duplicate.

104
00:16:22,800 --> 00:16:26,420
People take this and leave things as messy.

105
00:16:32,460 --> 00:16:37,440
So I'm going to take this. I'm going to plug it in. Whatever my favorite coaches is computing.

106
00:16:37,750 --> 00:16:42,270
And it's going to use this nice function. Mark, fill this in.

107
00:16:46,010 --> 00:16:56,580
Because I know why it's so complicated.

108
00:17:05,070 --> 00:17:13,060
So I have a. So over here this.

109
00:17:22,110 --> 00:17:25,600
I'm going to have my one and see this one here.

110
00:17:29,050 --> 00:17:40,900
She's duplicating. And they have this filled in from.

111
00:17:53,600 --> 00:18:04,190
It's called a. And take this piece down here that killed somebody there.

112
00:18:09,950 --> 00:18:40,390
So I'm going to have. So.

113
00:19:01,490 --> 00:19:19,510
So. He's basically just bringing this down to getting this and this is missing.

114
00:19:20,710 --> 00:19:29,660
So basically what I'm doing here is I'm creating the potential outcome for whatever the opposite was.

115
00:19:30,010 --> 00:19:35,080
31. But you've actually observed two.

116
00:19:45,560 --> 00:19:51,260
To. Basically people get from their.

117
00:20:44,600 --> 00:21:09,620
One. This is going to be one minuses to here.

118
00:21:52,630 --> 00:22:04,810
Okay. So for this group keeping Z1 the same for next Tuesdays where it was here s one is always number two is.

119
00:22:05,940 --> 00:22:11,190
And then there's each, then they send it to the one minus whatever in my observatory to us.

120
00:22:13,530 --> 00:22:18,570
And then finally for this last part, I go back to one minus C one.

121
00:22:19,690 --> 00:22:22,730
I get my cue here first.

122
00:22:22,740 --> 00:22:26,520
It's constant, you see. Q So essentially.

123
00:22:32,760 --> 00:22:42,000
So this is corresponds with the wife observed scene once and includes.

124
00:22:46,730 --> 00:22:56,180
This corresponds to one of my Twitter and my initial people I want you to.

125
00:23:21,390 --> 00:23:25,740
Essentially trying to compute all the possible counterfactuals, rich observation.

126
00:23:25,980 --> 00:23:31,650
Right. So this is what happens if I switch my 1 to 2 opposite.

127
00:23:32,550 --> 00:23:39,270
I'm sorry. Someone wants to keep C1, switch C2 to its opposite switch.

128
00:23:41,220 --> 00:23:45,900
So essentially, why swap these?

129
00:23:50,640 --> 00:23:59,100
And I can just go ahead and analyze the point estimates by looking at the differences.

130
00:24:08,460 --> 00:24:15,420
I'm not going to worry about getting confidence intervals here so I can kind of ignore the fact that these are.

131
00:24:27,730 --> 00:24:32,190
Right. I mean, you could try to do multiple applications and then actually do bootstrapping.

132
00:24:34,200 --> 00:24:39,840
So. I think there are issues about the distributions of access.

133
00:24:41,250 --> 00:24:47,320
So I want to go back this preparation now. It's a huge.

134
00:24:50,550 --> 00:24:58,450
But it takes you to do. So let's see the conceptual idea.

135
00:24:59,350 --> 00:25:03,900
I want to pick up this intermediate variable in itself as an argument,

136
00:25:04,640 --> 00:25:10,080
and then I want to think of the outcome variable on all the four possible combinations.

137
00:25:10,900 --> 00:25:18,070
To what I'm using the observation server and see what I.

138
00:25:26,720 --> 00:25:34,800
Basically sort of trying to fill in this big missing big picture, sort of talk about how we can think about these potential outcomes.

139
00:25:34,820 --> 00:25:38,360
It's kind of a messy data structure, but this has made it really explosive.

140
00:25:51,170 --> 00:26:03,340
Students. One in the class.

141
00:26:05,050 --> 00:26:12,070
So. All right. So basically, once we have that done, we can just plug this into a regression.

142
00:26:12,070 --> 00:26:17,920
We could try to sort of, you know, I guess summarize these by individuals and subtract.

143
00:26:18,550 --> 00:26:20,380
But whether because expectations linear,

144
00:26:20,390 --> 00:26:26,799
whether I do this at the individual level and an average or just average across the entire sample doesn't really matter.

145
00:26:26,800 --> 00:26:39,130
So I can just use my own function and I want to do this a couple of hundred times in order to really get stable estimates of these expected values.

146
00:26:40,940 --> 00:26:48,550
So, so just to kind of go through this a little step by step, these two.

147
00:26:53,170 --> 00:26:57,190
Function's here. We're going to create this piece.

148
00:27:16,590 --> 00:27:20,820
And actually I realized that because I had this from an earlier version.

149
00:27:25,100 --> 00:27:35,390
This is Wilkinson. So if you had if you really had a baseline variable X1 one, two also, but we didn't have that size at this.

150
00:27:45,040 --> 00:27:50,209
So I'm going to write this was going to create this. Counterfactual.

151
00:27:50,210 --> 00:27:54,010
What was one of the bigger bunch of missing data to fill in?

152
00:28:02,480 --> 00:28:05,810
So it's actually with all three of these lines. Do you agree?

153
00:28:07,730 --> 00:28:11,540
So I'm going to use this mouse function.

154
00:28:12,440 --> 00:28:17,079
So missing data function or so I'm just going to kind of use defaults.

155
00:28:17,080 --> 00:28:21,379
So I have to tell it the data set and how many imputations I want.

156
00:28:21,380 --> 00:28:25,760
I'm just going to do a single imputation doesn't repeat this this many times,

157
00:28:25,760 --> 00:28:35,690
but I can't do it all at once because I want to know maybe you could, but it would require some sort of somewhat delicate data manipulation.

158
00:28:35,690 --> 00:28:37,190
I think so. I was just being lazy here,

159
00:28:37,190 --> 00:28:43,670
so I'm just going to generate once because I want to use those generated values then to generate the whys in the next step.

160
00:28:44,930 --> 00:28:49,970
So, so my source has different ways to do the imputation.

161
00:28:50,600 --> 00:28:58,400
I don't want to turn this into a missing data class. You could use a model based estimate, so you could just use like a normal assumption on this one.

162
00:28:59,060 --> 00:29:03,950
Be pretty simple because I only have a single covariate but you know, binary copy and c.

163
00:29:05,450 --> 00:29:08,120
So yet in this case would be very simple.

164
00:29:08,510 --> 00:29:22,590
The default is something called predictive mean matching actually, which basically looks at values that are so for fully observe covariates,

165
00:29:22,610 --> 00:29:33,889
tries to sort of take observations that are close and sum now nobis as distance to the to the set of covariates

166
00:29:33,890 --> 00:29:43,340
in the in the observation that has a missing element and then picks randomly from them from the observed,

167
00:29:43,820 --> 00:29:48,290
fully observed code of observations, a value to plug in there.

168
00:29:48,680 --> 00:29:56,600
So it's a sort of a little more non parametric than the for model based approach for the first step is not going to matter much.

169
00:29:58,070 --> 00:30:02,450
I then can just use this complete function which is kind of which is pulls out the.

170
00:30:06,290 --> 00:30:13,879
Foley observed that the approach of data, plus the values, has sort of been persnickety about treating as a matrix.

171
00:30:13,880 --> 00:30:27,780
And you see bind here to get to. So now then for this next step, I basically sort of had to do this in two pieces.

172
00:30:31,590 --> 00:30:37,250
So setting. Sorry.

173
00:30:44,150 --> 00:31:10,380
Yes. I actually ended up. Yes.

174
00:31:10,400 --> 00:31:24,880
So I'm basically going to set up. Instead of Z2 to be one minus Z2 and minus C and then A one minus c2 z two piece I pend on.

175
00:31:26,110 --> 00:31:30,660
So this one's my observe z two and I'm actually going to bring down my observes in one.

176
00:31:30,670 --> 00:31:35,530
So when I actually keep the Y there but then have missing observations.

177
00:31:37,130 --> 00:31:45,650
And put those together with this generator piece here and then flip everything around.

178
00:31:47,450 --> 00:31:55,310
But now, since I'm going to be working with my computer, my one minus the one piece is down here.

179
00:31:55,880 --> 00:31:59,090
You, though I have observed the twos. I want to keep that.

180
00:32:00,650 --> 00:32:05,030
Keep all of these is missing. Right. So basically the last two sets of columns there.

181
00:32:07,550 --> 00:32:14,750
So then I bind it altogether. So now, because I've already done the imputation of this step, everything here is observed except for the outcome.

182
00:32:15,770 --> 00:32:21,740
So I'm going to go ahead and run my.

183
00:32:21,950 --> 00:32:25,370
Now it's going to impute three fourths of the wise.

184
00:32:28,460 --> 00:32:35,670
And then I'm going to pull that out as to my Z ones, my Z tubes.

185
00:32:36,350 --> 00:32:42,650
So these have all been kind of constructed. These are my imputed y's along with my observed y.

186
00:32:44,060 --> 00:32:48,380
And this is, of course, just the construction of the interaction.

187
00:32:49,430 --> 00:32:54,860
So X is out of the way here. Now, I just want to look at this marginal effect of Z on Y.

188
00:32:57,210 --> 00:33:05,850
And so basically I do the linear model, right and so on, the joint outcome, all of these are equal to one.

189
00:33:05,850 --> 00:33:11,820
So all three of these coefficients get out of the other four.

190
00:33:14,140 --> 00:33:18,130
Z one equals zero, z two equals one. Just want to take the third coefficient.

191
00:33:18,910 --> 00:33:27,910
And similarly for the c one equals 0z2.

192
00:33:28,030 --> 00:33:36,250
I'm sorry. c141z2 or three zero. I just want to take the seven coefficient so I do that two times and then get the means.

193
00:33:37,540 --> 00:33:40,959
And so you can see here this kind of worked best in this case.

194
00:33:40,960 --> 00:33:46,120
So really pretty close. Although the intervals I didn't show you that actually did bootstrap 200 times.

195
00:33:46,780 --> 00:33:52,580
So the intervals here are pretty, pretty, pretty narrow. So I'm not quite sure what's going on here.

196
00:33:53,080 --> 00:34:03,060
There's still a little bit of miss on this. But the other man, the other animals are.

197
00:34:03,410 --> 00:34:08,220
Everything's much closer. It's much more stable. And.

198
00:34:11,460 --> 00:34:23,490
Two of the three intervals can include the true values. So again, we're not really using a necessarily fully correct model for the invitation.

199
00:34:23,490 --> 00:34:30,860
That might be part of the issue here. This is trying to sort of do the best it can from this productively imagined.

200
00:34:32,480 --> 00:35:15,630
So. I guess I should.

201
00:35:17,070 --> 00:35:22,110
Well, I think the way you actually put this together.

202
00:35:25,250 --> 00:35:31,010
Just trying to get this to my nephew the way I should put this together. This was this part, essentially this piece.

203
00:35:33,460 --> 00:35:41,980
This piece was now here. This piece.

204
00:35:47,760 --> 00:35:56,840
So what? Okay.

205
00:36:01,450 --> 00:36:11,230
So any questions? This one. Right.

206
00:36:13,190 --> 00:36:19,640
So I did put out a call for additional people, had the things they wanted additionally reviewed.

207
00:36:21,650 --> 00:36:35,990
So it only got one response. And that was basically not four things we had actually in class, but sort of a little extension on.

208
00:36:40,150 --> 00:36:47,500
Highly emotional mediation analysis. So I thought I would maybe do just do a quick review on this.

209
00:36:48,670 --> 00:36:54,850
So we're relatively recent paper biometrics.

210
00:36:56,560 --> 00:37:00,870
So I didn't put slides on this, but I will kind of like go through it here of.

211
00:37:02,530 --> 00:37:06,490
To tell people. See, that is that big enough.

212
00:37:06,670 --> 00:37:12,459
Okay. So. Okay.

213
00:37:12,460 --> 00:37:17,920
So the the basic concept, this is actually gonna be pretty simple the machinery, but some.

214
00:37:18,190 --> 00:37:21,760
And the little pelican may or may not have encountered this before.

215
00:37:22,810 --> 00:37:29,770
But the setup is, is basically what if we talked about previously in this sort of causal effect settings,

216
00:37:30,520 --> 00:37:38,950
so we have some exposure and outcome and then a meeting variable and you could have more than one.

217
00:37:40,270 --> 00:37:44,530
And so this paper is actually going to focus on the place where we sort of looked at like the B to three,

218
00:37:45,370 --> 00:37:50,439
where P maybe, I think in this case, 121 or 12 or 21.

219
00:37:50,440 --> 00:37:53,920
I can remember that later in the paper. So.

220
00:37:55,960 --> 00:38:01,240
Oh point 81. Sorry. There it is. So they're basically so in this this example,

221
00:38:01,240 --> 00:38:13,600
they're going to consider body mass index or BMI as a exposure that is associated with what's

222
00:38:13,600 --> 00:38:18,670
called estrogen receptor positive breast cancer in a breast cancer case control study.

223
00:38:20,350 --> 00:38:29,800
So it's important for understanding treatments and to understand how this might be treated.

224
00:38:29,920 --> 00:38:34,990
I think it's their idea is that they're going to try to look to see which of these serum metabolites

225
00:38:35,800 --> 00:38:42,910
seem to really be mediating this relationship between BMI and this particular type of breast cancer.

226
00:38:44,740 --> 00:38:48,040
So, okay, so for 81, it's a lot, right?

227
00:38:49,090 --> 00:38:52,030
So basically the core picture kind of sits here.

228
00:38:53,290 --> 00:39:02,860
So this right, this is sort of the thing we talked about in class and you might have four different ways these things could could link together.

229
00:39:03,670 --> 00:39:12,520
So what they're going to do is try to collapse all of these mediators into a single or maybe a small set of factors.

230
00:39:14,850 --> 00:39:19,380
That basically sort of contain all this information about the mediator.

231
00:39:20,160 --> 00:39:29,580
But in a in a in a way that's sort of much more interpretable and also manageable in terms of the stability of the estimates.

232
00:39:30,720 --> 00:39:35,760
So you can imagine if we have 41 mediators, I can't remember the sample size here, but it's not like in the millions.

233
00:39:36,480 --> 00:39:42,299
So so that might be a lot. But if we can sort of boil it down to like two or three four factors,

234
00:39:42,300 --> 00:39:48,270
then maybe this would be more manageable in terms of understanding the sort of underlying science here.

235
00:39:49,290 --> 00:39:54,810
So what they're going to do here, the sort of trickiness is there's this little lambdas or what's called or what it's called loadings.

236
00:39:55,680 --> 00:39:59,140
So this is going to be a little bit related to factor analysis, if you've seen it before,

237
00:39:59,160 --> 00:40:04,950
principal components analysis with a little extra trick that they're going to do, a penalized version of it.

238
00:40:06,840 --> 00:40:15,150
So basically, this is sort of the measure of how important this this mediator is to this factor.

239
00:40:16,530 --> 00:40:21,120
So high values this suggests this factor is really a function of.

240
00:40:25,470 --> 00:40:28,710
Some of these mediators and logos of lambda suggest this.

241
00:40:29,010 --> 00:40:34,020
I'm sorry. This factor is a function of, you know, not a function of those mediators.

242
00:40:36,470 --> 00:40:40,460
Okay. So I can sort of see the basic setup.

243
00:40:43,550 --> 00:40:48,950
So they're going to have exposure to outcome and now they're adding this idea of the factor.

244
00:40:50,780 --> 00:40:55,739
So basically, they're going to define this, this this factor.

245
00:40:55,740 --> 00:41:11,810
Then it's also having a potential outcome. Right. It's the value under under II being set to the literally and then etc.

246
00:41:14,960 --> 00:41:17,120
I think that's a typo that you play really prime.

247
00:41:20,150 --> 00:41:33,050
So and then we can think about the potential outcome then being a joint function of the, the treatment or exposure I guess,

248
00:41:33,230 --> 00:41:40,550
and the mediator values now reduced the function so that once you've got the functional terms, the M's don't play a role here anymore.

249
00:41:41,600 --> 00:41:47,360
So and then they're going to assume sequentially more ability, which is the usual game,

250
00:41:47,360 --> 00:42:01,370
but given a set of covariates based on covariates that are potential outcome and either for the actual outcome or for the mediator,

251
00:42:01,370 --> 00:42:06,229
values are independent of the treatment assignment and then given treatment assignment and

252
00:42:06,230 --> 00:42:12,920
covariance that the potential outcomes of the factors in the mediators kind of independent.

253
00:42:12,920 --> 00:42:17,240
So we have this sort of media randomization. Okay.

254
00:42:17,250 --> 00:42:25,800
So. So the way the factor is defined is essentially.

255
00:42:30,960 --> 00:42:38,320
A weighted function. C. Well, we'll get to that later on.

256
00:42:38,530 --> 00:42:49,210
That's quite correct. So here's our old friends for a continuous pathways.

257
00:42:50,230 --> 00:42:57,129
Then the total effect will really.

258
00:42:57,130 --> 00:43:07,640
For. Even for. Commonly used for continuous outcomes, but could also be used for any form rights of the linear formulation of the total effect.

259
00:43:07,790 --> 00:43:14,210
Basically, what happens if we set exposure to some level prime?

260
00:43:15,020 --> 00:43:23,790
What's the potential outcome given those are set the prime and the set of mediators set up to that value and treat

261
00:43:23,810 --> 00:43:33,690
prime minus if we set the exposure to E and the potential outcomes to E national indirect effect I'm sorry,

262
00:43:33,690 --> 00:43:41,360
the natural direct effect we hold the mediator values constant at E and then consider changing

263
00:43:41,360 --> 00:43:50,270
from e prime to E for the exposure indirect effect over exposure at the e prime level,

264
00:43:51,470 --> 00:44:01,700
whatever sort of our first term was here and then let the mediator change from the E prime D or another mediators absorbed into these these factors.

265
00:44:03,080 --> 00:44:10,310
And then you can have the same game with the total effect, natural direct effect to natural indirect effect on the odds ratio scale.

266
00:44:16,780 --> 00:44:29,069
Okay. So. So we can't sort of point out, you know, these are these things are identifiable and they're mediators are factors,

267
00:44:29,070 --> 00:44:39,090
but they are going to be identifiable in this parametric model. The paramount model, we're going to assume, is that the.

268
00:44:47,990 --> 00:44:58,230
Factor. Well that our mediator.

269
00:45:02,820 --> 00:45:07,080
It's basically a function of of of factor loadings.

270
00:45:12,140 --> 00:45:18,320
It's probably distributed given those factor loadings and some sort of overall intercept.

271
00:45:19,790 --> 00:45:26,330
And the factor loadings themselves are going to be a function of the exposure plus error.

272
00:45:27,630 --> 00:45:31,370
The error is actually zero one kind of to keep things identified.

273
00:45:32,540 --> 00:45:41,620
And so the error on the mediators can be. Well, soon to be independent due to this factor loading.

274
00:45:42,610 --> 00:45:55,430
The variances can vary. So and I should add or exposure here is not is actually continuous this BMI measure.

275
00:45:56,240 --> 00:45:58,550
So there is an additional assumption that it's normally distributed.

276
00:46:03,050 --> 00:46:08,000
And then they're also increasingly they're not allowing for exposure in factory interactions here.

277
00:46:09,200 --> 00:46:13,750
So the whole thing boils down to the usual bearing some sense of very much the burning kitty assumption.

278
00:46:13,760 --> 00:46:19,760
So there's this data that goes directly from the exposure to the outcome.

279
00:46:20,600 --> 00:46:27,860
BD Why then sort of mediate a component that relates the factors to the outcome?

280
00:46:29,260 --> 00:46:37,790
B-raf Why? So the natural direct effect is the product of the exposure to the factor.

281
00:46:38,220 --> 00:46:46,490
That factor in the outcome and the total effect is of sum of the actual directly natural indirect effects, again in the absence of this interaction.

282
00:46:48,540 --> 00:46:51,540
I didn't read the paper quite carefully enough to see if they comment on that point.

283
00:46:55,290 --> 00:47:00,480
Okay. So they can kind of work through the likelihood in this case.

284
00:47:02,460 --> 00:47:05,370
There's a little twists and turns, basically,

285
00:47:05,370 --> 00:47:14,820
I think with he's basically get kind of a normally distributed marginal distribution if you integrate out over the factors.

286
00:47:15,570 --> 00:47:20,610
If you're assuming a continuous outcome. Otherwise you got to be messier.

287
00:47:20,610 --> 00:47:28,200
If this is if the binary outcome is if the outcomes binary because you sort of have this normal random effect with a binary outcome.

288
00:47:28,410 --> 00:47:40,390
So it's, it's it's not. Right.

289
00:47:40,400 --> 00:47:46,690
So one, it's not a col, the other, so you don't get this simple integration to get close to them.

290
00:47:49,850 --> 00:47:57,130
So which they wish they had over here. And there's a little twists and turns because of how the data was collected.

291
00:47:57,200 --> 00:48:00,500
So they did this kind of retrospective sampling.

292
00:48:04,330 --> 00:48:10,870
So they can kind of work out some of the components or the likelihood respect to that.

293
00:48:11,500 --> 00:48:16,570
But the big thing I wanted to focus on this is sort of where the magic comes in here.

294
00:48:16,990 --> 00:48:20,200
They have this penalty to incur in due sparsity factors. Right?

295
00:48:20,650 --> 00:48:33,430
So basically they've got the likelihood, but then they're going to penalize it basically based on the size of these betas.

296
00:48:35,530 --> 00:48:40,570
And with a little time to sort of determine exactly how much they want to penalize that.

297
00:48:41,380 --> 00:48:43,300
So this penalty function is basically.

298
00:48:46,530 --> 00:48:54,900
Basically looks for four large values to kind of shrink them down and four values are close to zero is just eliminate them.

299
00:48:56,310 --> 00:49:00,270
And there are sort of different ways for for doing that.

300
00:49:00,510 --> 00:49:06,749
They do, first of all, choose a total number of factors. So they assume there can't be more than 40 out of the 481.

301
00:49:06,750 --> 00:49:14,490
They're going to play a role. And then there are some ways to kind of choose these row components.

302
00:49:17,250 --> 00:49:30,080
And then they. And they work out the the estimation.

303
00:49:30,140 --> 00:49:36,799
There's a sort of somewhat complicated algorithm that they. They were basically told there's a page limit.

304
00:49:36,800 --> 00:49:40,220
So you have to put that in the appendix. No, they think it's important.

305
00:49:43,370 --> 00:49:47,510
So. And I think there is. Right.

306
00:49:47,540 --> 00:49:53,600
Okay. So I think it's the. So this is actually the key the key piece here.

307
00:49:56,370 --> 00:50:05,279
So there's a method for kind of choosing these values that kind of try to balance between foreseeing making the penalty so large

308
00:50:05,280 --> 00:50:12,300
that everything goes away and keeping it too small so that you're not really giving it sort of an effective dimension reduction.

309
00:50:13,950 --> 00:50:23,720
So. I kind of skipped through all this.

310
00:50:24,680 --> 00:50:29,839
They had a little data example going back to the day example. All right.

311
00:50:29,840 --> 00:50:36,710
So they actually had a case control study. The 410 observations cases weren't ten controls.

312
00:50:41,000 --> 00:50:44,030
Basically they just had a few baseline covariance.

313
00:50:47,790 --> 00:50:53,420
And the metabolite levels were. We picked up.

314
00:50:56,660 --> 00:51:06,650
After a year of follow up. So this kind of work is backwards somewhat here the.

315
00:51:13,940 --> 00:51:18,740
The sort of pathways they were able to find were pretty, pretty modest,

316
00:51:19,760 --> 00:51:33,230
so that the estrogen pathway component was maybe about 50% of that of the overall total effect.

317
00:51:34,980 --> 00:51:41,940
And I guess this is maybe on a one unit increase in BMI in terms of those.

318
00:51:48,540 --> 00:51:53,190
This is sort of single day, sort of focused on just the first the first factor,

319
00:51:54,090 --> 00:52:02,190
which they said had basically 111 non-zero loadings, but really only 16 were pretty substantial.

320
00:52:05,150 --> 00:52:11,810
So I kind of give those here and I'm definitely outside my comfort zone in terms of breast cancer knowledge.

321
00:52:12,790 --> 00:52:19,369
But but they do seem to kind of create a small set of metabolites that can then be focused

322
00:52:19,370 --> 00:52:25,860
on this natural components of this radiation flowing through the mediation effect.

323
00:52:25,880 --> 00:52:28,980
It's not all that large. So.

324
00:52:32,070 --> 00:52:38,120
All right. So that was my quick summary read of this weekend.

325
00:52:38,390 --> 00:52:43,170
I've posted it up on the on C tools so you can take a look.

326
00:52:45,790 --> 00:52:50,500
Sadness, but basic idea is kind of follows the same rules we had before.

327
00:52:51,040 --> 00:53:01,510
They're just getting a little fiddly with how they're actually constructing the mediator effect by using this penalized likelihood, too.

328
00:53:02,290 --> 00:53:05,830
So we're just plugging in 404 and 81.

329
00:53:06,670 --> 00:53:16,940
They are. The readiness of the component.

330
00:53:22,160 --> 00:53:27,070
Okay. Well.

331
00:53:29,060 --> 00:53:33,460
I think at the end of what I have to present it,

332
00:53:34,180 --> 00:53:40,959
obviously there's a whole this is a sort of the foundation is a very hot area with which a little

333
00:53:40,960 --> 00:53:45,850
hint we sort of looked at this universe probability weighting in this estimation approach.

334
00:53:46,240 --> 00:53:50,170
You can actually try to put those together. There's a you know, there's a dependance on the model.

335
00:53:51,760 --> 00:53:57,280
So there's something called double robust estimation,

336
00:53:58,300 --> 00:54:08,350
which basically essentially sort of uses weighted propensity weighted versions of the model estimates with

337
00:54:08,350 --> 00:54:15,020
the sort of residuals in the model estimates to try and come up with an estimate of the causal effect.

338
00:54:15,610 --> 00:54:24,820
That is not that that will be consistent even if one of the two models is wrong somewhat.

339
00:54:24,940 --> 00:54:28,470
There are some similar things in missing data in this missing data analogy.

340
00:54:29,860 --> 00:54:32,679
And there whether you use that through the weights.

341
00:54:32,680 --> 00:54:42,579
And then another approach that I actually worked on with with Rod, a little more students have been sort of trying to build the propensity.

342
00:54:42,580 --> 00:54:48,760
And as part of the modeling itself, I remember that I sort of gave a little hint of that at one point in my first discussing propensity score is that,

343
00:54:49,390 --> 00:54:53,980
you know, you're sort of conditioning on these things and get the weights, but you also maybe could condition the one in the model.

344
00:54:55,180 --> 00:55:00,850
And again, it doesn't it doesn't guarantee that if you have if you start modeling issues.

345
00:55:00,850 --> 00:55:05,200
But the nice thing is you can boil that down to a single scale or compete with measure.

346
00:55:05,650 --> 00:55:12,750
And there's all kinds of things like spines and. There's an extradition treaty and things like that that can be pretty robust.

347
00:55:13,650 --> 00:55:16,979
I mean, I guess the other thing is having to be focused on it.

348
00:55:16,980 --> 00:55:20,040
I think some of you as part of your projects are kind of moving this direction.

349
00:55:20,520 --> 00:55:26,309
But this is one of the great things about sort of machine learning or what I sort of think of as modern

350
00:55:26,310 --> 00:55:31,940
regression techniques are that they are really good for prediction as opposed to some very old school,

351
00:55:31,950 --> 00:55:39,360
you know, linear, generalized linear models. So they may not be so great for sometimes not interpretation,

352
00:55:40,380 --> 00:55:45,570
but but a lot of this has to do with prediction in particular, old times of doing sort of prediction reasons,

353
00:55:46,080 --> 00:55:52,290
maybe some sort of complicated modeling process to get a piece that boils down to something that in the end is pretty simple.

354
00:55:52,590 --> 00:55:57,090
Like basically when your model difference, it means so.

355
00:55:57,280 --> 00:56:01,800
So you can sort of build all that machinery into the prediction piece.

356
00:56:02,400 --> 00:56:09,000
And then for your actual estimation of what you want, you just go back to the very old school methods of ANOVA or whatever,

357
00:56:10,140 --> 00:56:13,380
because that's really what you're sort of interested in, in the complete data sense.

358
00:56:16,560 --> 00:56:26,000
So. Right. And so infants in those cases, I think, is essentially another area that I think is still kind of under studied.

359
00:56:27,000 --> 00:56:31,860
A lot of times we were just throwing up this positivity assumption.

360
00:56:33,360 --> 00:56:36,660
Right. But that in many cases may not be quite correct.

361
00:56:37,290 --> 00:56:44,280
If you were there for the speaker on Thursday, we sort of had a little discussion about this issue.

362
00:56:45,000 --> 00:56:49,560
In some ways, it has a little bit of a flavor of the no free lunch thing you often encounter in statistics,

363
00:56:50,100 --> 00:56:52,260
which is the richer your set of covariates are,

364
00:56:52,980 --> 00:57:00,299
the more likely you are to be able to make assumptions about essentially sort of effective randomization and those kinds of things,

365
00:57:00,300 --> 00:57:07,010
or sequentially more ability. But you also are probably paying a price in positivity rate because there may not be very,

366
00:57:07,050 --> 00:57:10,710
very many individuals that sort of fit into this current space.

367
00:57:11,190 --> 00:57:14,610
And so as you sort of reduce things down, especially if you're being pretty non parametric,

368
00:57:15,030 --> 00:57:19,920
you may be shrinking the set of the population you can make.

369
00:57:20,250 --> 00:57:24,360
You can make causal inference about. So yeah.

370
00:57:24,600 --> 00:57:29,610
So I think there's, there's a lot of room here for things in different directions.

371
00:57:29,610 --> 00:57:37,439
Some of them may simply be cautionary tales right to me to explain to an investigator that there are limitations as to what they can do.

372
00:57:37,440 --> 00:57:42,599
And some of that might be the sort of, you know, clever new ideas to sort of move things forward,

373
00:57:42,600 --> 00:57:46,740
a step to think about, to really be able to get broader inference.

374
00:57:47,960 --> 00:57:56,860
So. So I think it's an area that you all be doing stuff in, in your careers and reading about and playing with.

375
00:57:56,870 --> 00:58:04,680
And so whether you're starting at the Masters and going to work for us or going through a research, something in between.

376
00:58:06,320 --> 00:58:11,630
I think it's it's a really important topic. I hope I've been able to give at least a little taste of it this term.

377
00:58:12,500 --> 00:58:19,590
And yeah, so that's it. I'm looking forward to people's presentations on Wednesday.

378
00:58:20,000 --> 00:58:22,010
I hope you are looking forward to it as well,

379
00:58:22,010 --> 00:58:29,960
because I think you're gonna see you're beyond whatever you're doing that your classmates physical things and also try to bring a little lunch.

380
00:58:32,010 --> 00:58:35,060
So. Okay. Thank you.

