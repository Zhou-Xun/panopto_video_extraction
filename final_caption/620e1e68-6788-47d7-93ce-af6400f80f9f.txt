1
00:00:19,520 --> 00:00:33,470
Recording in progress. Okay.

2
00:00:33,860 --> 00:00:38,750
Good morning, everyone. So it's our last lecture.

3
00:00:39,320 --> 00:00:44,930
And so perhaps I should say what's going to happen for the rest of the course.

4
00:00:46,490 --> 00:00:54,890
So today I still have some left over from the previous stuff to remaining to complete.

5
00:00:55,370 --> 00:01:00,590
And this includes the, uh, the uh, asymptotic distribution for Mr.

6
00:01:01,340 --> 00:01:09,469
So the last lecture we looked at the estimate, uh, uh, so most of it is without proof, which is just the framework that I'm going to give you.

7
00:01:09,470 --> 00:01:13,340
And then Emily, uh, a theory as an example.

8
00:01:13,740 --> 00:01:20,960
Um, also, so you have a bunch of problems that I've posted a while ago.

9
00:01:21,260 --> 00:01:32,610
Right. Uh, so between now and Friday, I'm going to go over the solutions and tape, uh, kind of myself going over them, right?

10
00:01:32,630 --> 00:01:37,640
And post that as a, as a, uh, either Panopto Zoom video or both.

11
00:01:38,890 --> 00:01:43,580
And so the office hours will continue all the way through.

12
00:01:43,580 --> 00:01:49,219
That's right. So we have the, um, we have two exam dates, right?

13
00:01:49,220 --> 00:01:55,640
So one on the, uh, on Monday and another one, what is it, uh, Friday or Thursday.

14
00:01:55,640 --> 00:02:04,280
Thursday. Right, 4 to 6. So I'm going to have regular office hours all the way through, uh, the exam time.

15
00:02:04,640 --> 00:02:14,060
So I encourage you to review whatever I post. And also between now and Friday, a post the usual materials, uh, as I did for the midterm.

16
00:02:14,780 --> 00:02:24,800
Uh, except that, uh, so I'll make the, the kind of at least of topic slash index, uh, file right now for the whole course.

17
00:02:25,190 --> 00:02:28,370
So you have it for the first half of it.

18
00:02:29,100 --> 00:02:33,190
And in order to do that I'll be going. So all of the lectures, right?

19
00:02:33,200 --> 00:02:38,190
And while I do so, I'll make, uh, kind of another document.

20
00:02:39,220 --> 00:02:49,900
That has all the calculus facts kind of into collected in the same document so that you can use it as a cheat sheet.

21
00:02:51,890 --> 00:03:01,060
There's usually rules as as for the midterm and also as I'm doing.

22
00:03:03,570 --> 00:03:12,150
So it's. So as I go through the lectures, if I see something, I need to change.

23
00:03:13,350 --> 00:03:16,500
So I will do the small changes and edits.

24
00:03:17,220 --> 00:03:23,330
So if you want the latest and greatest, just look into the last version of the lectures that will be posted.

25
00:03:23,340 --> 00:03:27,570
Right. And I'm going to collate them all. So you have one file for the whole course.

26
00:03:28,740 --> 00:03:32,300
Okay. So that's sad.

27
00:03:33,770 --> 00:03:46,790
So last time we basically first look at consistency, we had the framework for the Zestimate as we looked at the consistency of both of them.

28
00:03:46,790 --> 00:03:58,940
And uh, we looked at the starting distribution for the Zestimate and formulated a framework there that you could put it as a theorem.

29
00:04:00,380 --> 00:04:07,250
And so before I go further, so we did it as if I was somewhat sloppy in writing,

30
00:04:08,270 --> 00:04:17,030
kind of hinting at multi variant cases sometimes, but the writing was mostly for a scalar parameter, right?

31
00:04:17,480 --> 00:04:20,570
And we had the results that looked like this, right?

32
00:04:20,600 --> 00:04:24,500
So this method of distribution of the normalized estimate.

33
00:04:25,640 --> 00:04:31,430
So again, as we develop estimate us, right,

34
00:04:31,430 --> 00:04:39,499
so we have a consistent estimate and that means that's the estimate that there

35
00:04:39,500 --> 00:04:48,440
was in probability two constants uh to the true parameter theta and I will.

36
00:04:50,590 --> 00:04:59,440
Though the star means the true parameter. The theta without the star is just an argument for family them.

37
00:05:00,100 --> 00:05:06,579
So the asymptotic distribution of theta m have is degenerate because it goes in

38
00:05:06,580 --> 00:05:12,370
probability to a number convergence and probability implies weak convergence.

39
00:05:12,370 --> 00:05:21,620
So, uh, so we do not have any distribution other than the gender at one, right?

40
00:05:21,970 --> 00:05:27,670
So in order to get a distribution, so we need to normalize this thing.

41
00:05:27,670 --> 00:05:35,860
So convergence in probability means again, it's somewhat sloppy language because it's the other way around,

42
00:05:35,860 --> 00:05:39,159
but it means that the variance goes to zero.

43
00:05:39,160 --> 00:05:44,730
Right. Of the estimate of. And the result, this is the other way around.

44
00:05:44,800 --> 00:05:48,980
Right. So if the variance goes to zero, then we have convergence of probability.

45
00:05:49,580 --> 00:05:56,620
So it's a somewhat stronger statement. But. Kind of as a general fact that is the case.

46
00:05:56,830 --> 00:06:02,250
Right. So in order to make the distribution non-digital,

47
00:06:02,490 --> 00:06:11,190
I need to multiply it by something that prevents the variance from going to zero and makes it instead go to a number.

48
00:06:11,880 --> 00:06:14,940
So it's kind of a consistency result, but now for the variance.

49
00:06:17,410 --> 00:06:24,830
And the most of the estimates that have so called regular synthetics, it's the square of the well that does that.

50
00:06:26,210 --> 00:06:33,470
Okay. And so you can look at the sample mean as as a quick thing that helps develop intuition.

51
00:06:33,470 --> 00:06:40,820
Why it's the square of the fan. Right. And that's because the variances in the regular estimate as is one of and right.

52
00:06:41,540 --> 00:06:48,409
So to make this one over and disappear. So if I multiply, they estimate them by the square of the van.

53
00:06:48,410 --> 00:06:53,850
When I take a variance of it that's going to get square, they'll cancel with them in the denominator.

54
00:06:53,850 --> 00:06:57,290
And that's the quick intuition and logic behind it.

55
00:06:58,130 --> 00:07:05,480
Certainly most estimates are more complicated than the sample mean, but this regularity still works.

56
00:07:05,900 --> 00:07:09,590
And so the result we have last time is that.

57
00:07:11,060 --> 00:07:20,330
So it goes to a normal with variance, uh, given by this thing.

58
00:07:23,820 --> 00:07:31,680
For the Zestimate. The right. The estimate that solves the equation.

59
00:07:32,190 --> 00:07:37,800
Expected value of phi that depends on theta hap is equal to zero.

60
00:07:39,050 --> 00:07:42,470
Ratings as an estimate. So this is the.

61
00:07:43,860 --> 00:07:51,569
So the notation is we use common empirical process notation that's this thing.

62
00:07:51,570 --> 00:07:59,280
And the estimate actually comes when we replace the true expectation by the empirical one.

63
00:08:01,290 --> 00:08:04,590
Actually, it's not no longer, say, the staff.

64
00:08:08,280 --> 00:08:11,960
It's going to be equal to zero. Right.

65
00:08:11,970 --> 00:08:15,540
And this is where we get the theater and have.

66
00:08:18,580 --> 00:08:22,900
So it's for this framework. And we had in the denominator the.

67
00:08:25,010 --> 00:08:28,380
Expectation of high pricing.

68
00:08:30,020 --> 00:08:34,250
Theta. Staff. Yeah.

69
00:08:34,300 --> 00:08:55,410
This thing is squared. I think the square is inside the right.

70
00:09:10,220 --> 00:09:15,320
No, that's okay. Okay. So that was it for the Zestimate.

71
00:09:16,010 --> 00:09:27,110
And so before we go forward with the estimate, uh, so I said we will look at the multivariate version of this fact.

72
00:09:40,490 --> 00:09:50,790
Some 30 distribution. Of the Z estimates the and with an estimate is the same story.

73
00:09:51,870 --> 00:09:57,030
This is simply to get you the intuition.

74
00:09:57,040 --> 00:10:06,810
So let's say my theta is a vector. That means it's a column with components data one, theta, two, and so on.

75
00:10:08,460 --> 00:10:16,920
Okay, then my function fi is, uh, the depends on theta is also a vector.

76
00:10:18,470 --> 00:10:23,690
And it's 31, 42 and so on.

77
00:10:29,390 --> 00:10:34,130
Then. Same thing for the five prime.

78
00:10:36,850 --> 00:10:42,239
So that's actually. The Matrix now.

79
00:10:42,240 --> 00:10:48,630
Right. Because I have I have a bunch of parameters in the sitting in the theta, right?

80
00:10:49,200 --> 00:10:53,850
And I have a bunch of components in the vector value of function phi.

81
00:10:53,910 --> 00:11:06,360
Right. So my derivative of phi with respect to theta is, well, I can differentiate each of the components of one of the components of theta.

82
00:11:06,360 --> 00:11:11,970
So it's got to be a matrix. And that's going to look like, uh.

83
00:11:13,200 --> 00:11:17,519
Derivative of phi of a derivative of theta j.

84
00:11:17,520 --> 00:11:27,400
Right, and i. J. We'll go over the dimensions of each of them.

85
00:11:27,550 --> 00:11:35,290
Right. Um, and so this matrix, these matrices of this form are usually called audience.

86
00:11:40,740 --> 00:11:45,770
And the notation, natural notation for it is the G, right?

87
00:11:46,750 --> 00:11:56,290
So then so I have the in the numerator, I have the expectation of a phi squared.

88
00:11:56,290 --> 00:12:03,610
So what is Phi Square phi is a active right. So the square thing is going to be a matrix.

89
00:12:05,270 --> 00:12:15,989
Um. So five squared will actually go to the multivariate case.

90
00:12:15,990 --> 00:12:19,620
That's going to be five times five transposed.

91
00:12:22,350 --> 00:12:26,640
So this is how a product of two vectors.

92
00:12:29,050 --> 00:12:36,870
So a matrix. Okay.

93
00:12:36,890 --> 00:12:44,090
And then the expected value of psi squared theta at the true model.

94
00:12:44,660 --> 00:12:48,590
So that's the expected value of that matrix.

95
00:12:50,690 --> 00:12:58,170
So the family. This would be the. The information matrix.

96
00:12:58,260 --> 00:13:06,350
Right. So we're not there yet. So that's how it looks like in the multivariate case.

97
00:13:06,830 --> 00:13:14,809
Now the univariate expression is no longer valid for the multivariate case, so put them in quotes.

98
00:13:14,810 --> 00:13:24,600
Right. And then finally so I can restate what we have here as a convergence statement.

99
00:13:24,610 --> 00:13:35,530
So now in the multivariate form, just follow the rules so that square of the and the end half line status.

100
00:13:35,550 --> 00:13:46,900
So that's going to do a weekly to now a multivariate normal with a zero mean and variance be the sandwich.

101
00:13:49,830 --> 00:13:52,830
This is where and which estimate has come from. Great.

102
00:13:57,920 --> 00:14:19,560
530. So this is a car being minus one, right?

103
00:14:20,680 --> 00:14:27,780
Uh. So I said, uh. I say this because everything is at the true model.

104
00:14:29,090 --> 00:14:33,770
So that's the. Analog of the information matrix.

105
00:14:34,250 --> 00:14:39,140
And then again, there's the same system which accepts.

106
00:14:41,150 --> 00:14:45,800
It's in the transposed form. So that so far I.

107
00:14:47,740 --> 00:14:52,370
They, Mr. Prime? Minus one.

108
00:14:55,420 --> 00:14:58,600
And this time is transposed.

109
00:15:02,910 --> 00:15:06,930
So that's why it's one of that's most.

110
00:15:08,780 --> 00:15:13,750
This is how it looks like. Okay, then.

111
00:15:15,580 --> 00:15:25,330
So occasionally we have to do with, uh, non parametric or semi parametric estimation.

112
00:15:35,620 --> 00:15:45,100
And if we want to apply this framework over there now the non parametric means theta is a function.

113
00:15:50,900 --> 00:15:57,350
Or in other words, another term for it, these infinite dimensional parameters.

114
00:16:00,010 --> 00:16:09,760
Allow me to. And a more mathematical term for it is that it's a functional parameter.

115
00:16:18,740 --> 00:16:23,750
Right. And, uh, kind of a quick example of when this is the case.

116
00:16:23,750 --> 00:16:29,360
We already considered, we already know it from other courses.

117
00:16:29,810 --> 00:16:32,990
This is what's called the empirical distribution function.

118
00:16:38,480 --> 00:16:48,130
And. The distribution function.

119
00:16:51,480 --> 00:16:57,120
It can be shown to be in Emily, actually. And so that's a CDF.

120
00:16:58,470 --> 00:17:02,880
So I have CDF, let's say of random variable X, that's F of X.

121
00:17:07,100 --> 00:17:11,350
Find the variable x and then the estimate for it had.

122
00:17:12,990 --> 00:17:20,910
Of yes, it is going to be one of and some of I, uh.

123
00:17:21,000 --> 00:17:28,080
And then we have indicator. It's, uh, I, that's the sample values that also equal x.

124
00:17:30,520 --> 00:17:34,810
So if you look what it does, it's simply a count.

125
00:17:37,900 --> 00:17:44,800
Observations left. Of acts of non street sense, right?

126
00:17:45,900 --> 00:17:51,210
According to the air quality. Because what's going on here is that.

127
00:17:51,780 --> 00:17:55,439
So we fix the small x, we have a binomial situation, right?

128
00:17:55,440 --> 00:18:05,220
So any observation from the sample is either left of x in the non strict sense or right of x in the strict sense right.

129
00:18:05,470 --> 00:18:10,750
And so we have a frequency estimate for the probability of the biological events.

130
00:18:10,950 --> 00:18:14,670
Well, we can see the frequency over the number of trials.

131
00:18:16,480 --> 00:18:24,280
Right. But as a result, so far, part of X will go to some true function of X.

132
00:18:24,280 --> 00:18:31,510
That's an CDF of the random variable, right? But our parameter in that sense is the full function.

133
00:18:31,690 --> 00:18:34,060
Right? So it's a functional parameter.

134
00:18:35,470 --> 00:18:47,950
And so just to give you an idea of a quick way to, uh, generalize the multivariate statement and carry it over to a functional one.

135
00:18:50,610 --> 00:18:55,830
It's kind of a useful intuition if you ever have to deal with non parametric estimates.

136
00:18:56,730 --> 00:19:09,360
So if I have X and y being two vectors, so a vector, let's say I have a vector F, right, that has components of one.

137
00:19:09,690 --> 00:19:20,490
I have two and so on. So another way to look at the vector would be to say that the vector is a function of an integer given.

138
00:19:22,910 --> 00:19:29,270
I could say that this is some function of I where I is index, right?

139
00:19:36,720 --> 00:19:45,000
And it's clear how I can generalize vector to a function of well, they'll make the index a continuous argument.

140
00:19:46,140 --> 00:19:50,190
Right. So I is. Natural.

141
00:19:52,380 --> 00:20:00,570
Number argument. And it would go in a functional.

142
00:20:04,390 --> 00:20:12,360
Case two a function of X. Instead of.

143
00:20:13,330 --> 00:20:19,110
Right then. So we have this scalar product of two vectors x.

144
00:20:19,110 --> 00:20:27,370
Y. And that was X transpose times Y, right?

145
00:20:27,370 --> 00:20:37,110
When they're vectors and if I write them using components, that's going to be some of I write x, y, times y.

146
00:20:37,210 --> 00:20:41,470
So that would be the the so-called inner products of two vectors.

147
00:20:42,510 --> 00:20:46,740
Right. I can also multiply it by Delta II.

148
00:20:48,330 --> 00:20:54,470
And Delta is, of course, one. And it's five plus one.

149
00:20:54,560 --> 00:20:57,690
Right. That's a change in the Knicks minus.

150
00:21:02,180 --> 00:21:07,370
And in that sense it already starts looking as a discrete approximation to agreement in the ground.

151
00:21:07,610 --> 00:21:10,840
So we had a problem like that in the homework, right?

152
00:21:10,850 --> 00:21:22,640
So I have function a function of the, of an index in the argument times, another function of the integer getting times the delta of that argument.

153
00:21:23,510 --> 00:21:30,710
Right. Then if I want to go to a smooth version of it, uh, where my eye goes to X.

154
00:21:32,070 --> 00:21:37,400
So instead of integer argument, I have a continuous argument that's part of our.

155
00:21:37,870 --> 00:21:43,050
Then this would go to an integral rate of.

156
00:21:44,400 --> 00:21:50,970
So one function. Let's say instead of X, I have F and g two functions, right?

157
00:21:51,860 --> 00:21:59,120
So then I have scalar product of pair for g and generalizing the vector view.

158
00:21:59,960 --> 00:22:06,720
Then I will have integrals by default and the first function of its arguments.

159
00:22:06,770 --> 00:22:14,000
So I will become x. Right? Then my second function I become x.

160
00:22:14,660 --> 00:22:18,020
And then the change in the argument is the X.

161
00:22:21,000 --> 00:22:29,610
Okay. So this would be a statement from the functional analysis how most in products are defined.

162
00:22:30,660 --> 00:22:34,440
It's an integral over the net because I have DMCA rights.

163
00:22:35,550 --> 00:22:43,060
But as a note. We already have that statement.

164
00:22:44,230 --> 00:22:53,940
Um. So we had an expectation of two random variables X and Y.

165
00:22:55,980 --> 00:22:59,940
Scalar product of them was defined as integral of X.

166
00:23:01,580 --> 00:23:18,989
For me to write my. This is kind of a statement of the same kind of pride, except that instead of X,

167
00:23:18,990 --> 00:23:25,380
I have the omega omega four center space, which was essentially the same thing as the x rate.

168
00:23:26,830 --> 00:23:35,620
So that way of generalizing things is consistent with what we have been using so far for and the variables that are also functions.

169
00:23:37,640 --> 00:23:44,300
Okay. Yeah. And this is expectations rate the random variable X times Y.

170
00:23:47,600 --> 00:23:51,560
Okay. Then we have linear operators.

171
00:23:56,320 --> 00:24:04,570
So for those of you who still remember linear algebra, so the linear operator for vectors is what?

172
00:24:04,690 --> 00:24:11,900
It's a matrix, right? So we have Y equals a times X, right?

173
00:24:11,950 --> 00:24:18,400
Where Y acts are vectors. And he's a matrix.

174
00:24:21,850 --> 00:24:29,820
And it serves as a linear operator. In linear spaces, which is what network spaces are.

175
00:24:31,020 --> 00:24:36,390
Okay, so if I now use that thing, so this means well.

176
00:24:37,300 --> 00:24:42,610
But what is it? So I take x x by the operator on it, then I get the y.

177
00:24:45,270 --> 00:24:51,020
And they all do it this year. Um, so what is a matrix?

178
00:24:51,240 --> 00:24:56,100
My matrix is a collection of elements. AJ Right.

179
00:24:57,590 --> 00:25:04,830
If I'm looking at the way I generalized vectors into a function so I can do the same thing with the matrix.

180
00:25:05,250 --> 00:25:11,130
So it's a function of two arguments that are indices of I and J, right?

181
00:25:11,700 --> 00:25:21,240
And then so as I want to make a continuous thing out of it, so a matrix will become a binary function of X and Y, for example, for it.

182
00:25:22,410 --> 00:25:26,970
So the eye will become X and the J will become Y.

183
00:25:28,280 --> 00:25:35,030
Right. So the analog of these, uh, the functional analog of this equation.

184
00:25:40,170 --> 00:25:43,430
Will be that my g of X, right?

185
00:25:43,440 --> 00:25:47,730
So that's the the what's the Y will become.

186
00:25:48,210 --> 00:25:53,730
So it's going to be an integral. So we want to spell this out, right?

187
00:25:53,730 --> 00:25:59,490
That's more of a j, right? A I g times.

188
00:25:59,490 --> 00:26:14,950
SJ Right. So I will have a of x, y, that's what J becomes and it's j becomes.

189
00:26:15,850 --> 00:26:18,890
Half of why. Right.

190
00:26:19,070 --> 00:26:28,010
And this is to be. Right.

191
00:26:28,010 --> 00:26:38,420
So I have f I have a linear now integral either in a functional space gives me the function g.

192
00:26:46,040 --> 00:26:57,430
Now, if you remember, I basically mentioned in passing that when I have a weak convergence result and I have some kind of an expression like that,

193
00:26:58,910 --> 00:27:02,180
and the Taylor series will have expressions like this as well.

194
00:27:02,950 --> 00:27:07,130
Uh, so I mentioned the ability of the differential operator, right?

195
00:27:07,640 --> 00:27:11,210
That's what I can get f from this equation.

196
00:27:12,680 --> 00:27:15,800
So we can see that if.

197
00:27:17,390 --> 00:27:24,910
Of why it is equal to a minus one acting on G.

198
00:27:28,660 --> 00:27:40,990
This is a solution. To the equations of this whole field of mathematics.

199
00:27:44,670 --> 00:27:58,280
That's related to the study of integral equations. This is the real equation.

200
00:27:58,370 --> 00:28:03,020
Right. So the G would be called the right part of the integral equation.

201
00:28:03,030 --> 00:28:08,770
Of course, in my writing it's the left part. So F is the unknown function.

202
00:28:08,780 --> 00:28:14,450
A is a known integral or very current of whatever.

203
00:28:18,870 --> 00:28:30,370
Right. So if the solution exists. A is called.

204
00:28:31,390 --> 00:28:44,850
Convertible. I'm just working on a bridge for you.

205
00:28:45,180 --> 00:28:54,540
So when you read papers where you have a semi parametric or nonparty metric estimate and you have this language so that.

206
00:28:55,450 --> 00:29:02,110
So let's kind of stop without understanding.

207
00:29:02,320 --> 00:29:06,640
So if the intuition is similar to vectors. This is how it works.

208
00:29:10,130 --> 00:29:17,840
Right in there. And so a typical statement of a functional convergence result would be like this.

209
00:29:18,890 --> 00:29:21,890
So now these two guys are functions.

210
00:29:25,970 --> 00:29:30,890
Right. So they will go instead of a multivariate normal distribution.

211
00:29:31,400 --> 00:29:38,629
I have I will have a continuous function instead of it that's random and is related to normal distribution.

212
00:29:38,630 --> 00:29:49,570
So that thing is called the Gaussian process. It's typically denoted by GP rates, the option process.

213
00:29:55,930 --> 00:30:02,980
So if you ever took six A.D., they must have talked about Gaussian processes in their properties.

214
00:30:03,550 --> 00:30:11,200
So it's a process with zero mean in some covariance that is a function of X and Y, right?

215
00:30:11,460 --> 00:30:18,400
It's covariance. Right.

216
00:30:18,420 --> 00:30:22,379
We understand that that's a bivariate function and it gives us the variance

217
00:30:22,380 --> 00:30:27,570
between the process value at the time X and the process value at the time Y.

218
00:30:27,720 --> 00:30:35,400
So they are correlated and it's the correlation structure of the processes given by the covariance.

219
00:30:35,400 --> 00:30:41,640
So Gaussian process, it's enough. Just like with the normal distribution, it's enough to give the mean and the covariance.

220
00:30:42,810 --> 00:30:47,459
For the multivariate normal random variable to specify.

221
00:30:47,460 --> 00:30:53,340
It's the same thing with the Gaussian process, except that covariance is not a matrix.

222
00:30:53,520 --> 00:30:56,790
It's a bivariate function here. Right.

223
00:30:56,800 --> 00:31:08,920
And they add that by variable function C of X and y has the form of a double integral and generally four minus infinity to infinity.

224
00:31:09,790 --> 00:31:14,560
Uh, they giacobbe. And it's just becomes a bivariate function.

225
00:31:16,740 --> 00:31:31,510
Times. Let's see.

226
00:31:31,660 --> 00:31:38,440
Somebody write the facts and weigh whatever is in the middle of the sandwich times and not the Jacoby.

227
00:31:39,420 --> 00:31:42,480
Why? D.

228
00:31:43,290 --> 00:31:47,200
A d d. This is how it would look like.

229
00:31:47,410 --> 00:31:52,180
So sand, which is matrix-m, which will become a double integral.

230
00:31:53,230 --> 00:32:03,030
Over by its functions. Okay.

231
00:32:04,950 --> 00:32:16,470
So this is it. So now let's say let's formulate without the proof of the theorem about an estimation.

232
00:32:17,960 --> 00:32:29,540
Amnesty me to my knowledge. You could call it the SEAL team for their estimate.

233
00:32:29,870 --> 00:32:33,200
It's a weak convergence result from their estimate.

234
00:32:34,170 --> 00:32:47,730
So here are the conditions, right? So we are in the usual framework, uh, where uh we have and of state uh, the expectation.

235
00:32:48,880 --> 00:32:53,780
Of some 30 to. And that's the framework.

236
00:32:53,780 --> 00:32:59,420
That's the problem. Right. And the estimates and and of data.

237
00:33:01,010 --> 00:33:17,740
Is. A result of maximizing some of the yellow metal is the empirical estimate the right.

238
00:33:27,210 --> 00:33:32,400
So that's p and m theta and that's the sample.

239
00:33:32,750 --> 00:33:37,110
Great. So I am so excited.

240
00:33:40,280 --> 00:33:44,269
This is just a reminder of what my estimation of the framework is now.

241
00:33:44,270 --> 00:33:48,470
I have conditions that make the asymptotic result work.

242
00:33:49,220 --> 00:33:56,780
So am theta is a function of x is a measurable function.

243
00:34:04,240 --> 00:34:13,410
Of Acts differentiable. It.

244
00:34:14,550 --> 00:34:19,950
The true parameter value at the Star. Then.

245
00:34:20,730 --> 00:34:25,080
So the fate of X is Lipschitz.

246
00:34:30,880 --> 00:34:38,270
With respect to Fatal. And this is for any fixed x.

247
00:34:39,050 --> 00:34:45,740
So X is considered fixed. So X is just the parameter here.

248
00:34:47,600 --> 00:34:59,480
So Lipschitz means that if I take a difference for two different Thetas, it seeks to x between am theta while and theta two.

249
00:35:02,000 --> 00:35:13,920
Then this is mesmerized by some constants that does not depend on theta depends on that parameter x times uh theta one minus state and so.

250
00:35:15,570 --> 00:35:22,770
Absolute value in this is for a theta one, theta two and ex fixed.

251
00:35:27,050 --> 00:35:33,500
So the usual Lipschitz condition doesn't have the X. Of course, but x is just the 16th year.

252
00:35:35,130 --> 00:35:45,030
You may notice that and you may remember from calculus that Lipschitz implies continuity and that simply so if you let theta one go to it,

253
00:35:45,030 --> 00:35:49,370
the two that will make em go to the limit.

254
00:35:49,400 --> 00:35:55,000
Right? Um, so it's a bit stronger than continuity.

255
00:35:58,200 --> 00:36:04,750
Stronger condition. The continuity.

256
00:36:12,020 --> 00:36:16,700
And is a function of theta because.

257
00:36:18,830 --> 00:36:24,000
It's. Implies.

258
00:36:26,420 --> 00:36:34,159
Continue to. Okay.

259
00:36:34,160 --> 00:36:37,370
Then we need to say something about the sea here.

260
00:36:38,300 --> 00:36:41,810
So sea is measurable.

261
00:36:45,510 --> 00:36:54,629
As a function of X. And such.

262
00:36:54,630 --> 00:36:59,670
That's the expected value of C squared.

263
00:37:00,510 --> 00:37:07,050
When I put the variable x, that's the one that follows the model it.

264
00:37:08,450 --> 00:37:12,560
Uh, so that thing is less than an infinity rate, so.

265
00:37:14,490 --> 00:37:17,580
Esqueda the promo for That's another way to put it.

266
00:37:19,910 --> 00:37:31,610
Then. Uh, now of course, we want the Taylor expansion to work because that was the main part of the SEAL team.

267
00:37:33,260 --> 00:37:37,860
As we consider it as an instrument to establish a symbiotic distribution result.

268
00:37:39,030 --> 00:37:45,450
So that's in of state I it has the second order.

269
00:37:48,320 --> 00:37:59,240
Taylor expansion. With the second derivative.

270
00:38:05,660 --> 00:38:11,650
Let's say the. So expansion is around the true parameters.

271
00:38:11,680 --> 00:38:20,040
And if you remember, so that second derivative term, uh, is uh, let's say V, so that's just notation for it.

272
00:38:20,850 --> 00:38:25,950
So we have the usual approximate maximizer condition.

273
00:38:38,430 --> 00:38:44,230
And that is that. And of.

274
00:38:47,070 --> 00:38:51,710
And stayed the stars. So that's the end of.

275
00:38:54,930 --> 00:39:01,580
It's, uh, that's the largest value because they estimate a maximizes human right.

276
00:39:01,750 --> 00:39:04,930
And so if we use.

277
00:39:06,890 --> 00:39:16,250
The true function. So anyhow, the fetal rates, instead of the estimate, are.

278
00:39:18,090 --> 00:39:24,610
It's going to be a mental state. And I have something that goes on.

279
00:39:24,610 --> 00:39:28,290
Probability to zero is, uh, goes to infinity.

280
00:39:50,730 --> 00:39:54,450
And then I have theta in my hat.

281
00:39:55,500 --> 00:40:21,280
These are consistent. This theta. So that needs they have the skills and probability to see the star.

282
00:40:22,740 --> 00:40:26,080
Okay, so that's all the conditions.

283
00:40:26,200 --> 00:40:35,470
So then we have that square of the difference between theta and higher minus theta star.

284
00:40:36,760 --> 00:40:44,020
He's. The inverse of the second derivative.

285
00:40:45,880 --> 00:40:52,030
It's one over. If we have the scalar parameter and it's inverse of the matrix.

286
00:40:53,370 --> 00:41:04,590
If we have matrix then p and. Ryan said the star was the one.

287
00:41:07,320 --> 00:41:13,520
You know, this is a result of SEAL team applied.

288
00:41:19,030 --> 00:41:34,090
This term. So if we apply Keelty to this term, it would follow that they will have the usual.

289
00:41:35,590 --> 00:41:39,300
Expressions. My stay to starve.

290
00:41:39,310 --> 00:41:46,900
So that's going to go weekly to a normal distribution with zero mean and the sandwich.

291
00:41:54,160 --> 00:41:59,010
Crime and. Right and transpose.

292
00:41:59,010 --> 00:42:02,870
So that's a matrix. And.

293
00:42:04,200 --> 00:42:08,730
The minus one. Transposed three The Star.

294
00:42:25,320 --> 00:42:30,390
So that's the multivariate. Statements.

295
00:42:35,810 --> 00:42:44,510
Okay. So with that, we have both the asymptotic result for the estimate and the one for the M estimate.

296
00:42:44,510 --> 00:43:00,920
And this is without proof. Okay then.

297
00:43:01,430 --> 00:43:05,960
So the most prominent example of my estimation is Emily's theory of rate.

298
00:43:08,380 --> 00:43:19,210
So and Lee is an example. An estimation.

299
00:43:22,990 --> 00:43:33,010
So the certain sounds. Emily's something that simplifies the framework because you may have seen her earlier for some types of estimates.

300
00:43:35,290 --> 00:43:40,660
Like the G methods and so on and estimation equations when they were mentioned.

301
00:43:41,170 --> 00:43:44,410
So you always get variance in the form of assembly.

302
00:43:44,800 --> 00:43:48,620
This is the consequence of. A general result.

303
00:43:48,860 --> 00:43:55,220
Right. But in the case of the family, you get the variance by inverting the information matrix, if you remember.

304
00:43:55,310 --> 00:44:03,920
Right. So the fact that this variance simplifies is the consequence of how the framework is set up,

305
00:44:04,550 --> 00:44:10,190
and namely that family's related to log of the PDA for the random variable.

306
00:44:11,300 --> 00:44:16,130
In your model for that particular instrument of coming up with a function.

307
00:44:17,360 --> 00:44:21,410
Um, so that would simplify the sense which into a single thing.

308
00:44:26,760 --> 00:44:36,330
But let's now because you usually look at the family so that that thing starts with formulating a likelihood for your mother.

309
00:44:36,570 --> 00:44:40,380
Right. And the likelihood. So you have a model.

310
00:44:46,510 --> 00:44:52,180
That's so you have some random variable following some pdf of x.

311
00:44:53,430 --> 00:44:57,480
Uh, and you have the Theta Star as the true barometer.

312
00:45:06,420 --> 00:45:13,140
Okay. Now, before this course. So the starting point was the likelihood, the log likelihood.

313
00:45:20,350 --> 00:45:33,160
That heads the forum. So you would sum up over the sample values from one to m log of the pdf uh evaluated

314
00:45:33,430 --> 00:45:40,420
at the sample value i this is how the like the log likelihood was defined.

315
00:45:40,870 --> 00:45:44,409
Now, of course, it's one of the simplest versions of Emily.

316
00:45:44,410 --> 00:45:53,320
There are versions with missing data and all sorts of things where so if you don't observe the exact observations of this sensor,

317
00:45:53,440 --> 00:45:57,180
like in survival analysis, so contributions can be different.

318
00:45:57,190 --> 00:46:06,510
Not a PDF but some other probability. Uh, but, uh, we're considering as an example, so it makes sense to go simple.

319
00:46:07,440 --> 00:46:13,500
And this is the far by far the most common way to formulate this, right?

320
00:46:14,070 --> 00:46:18,719
And, uh, so before this course, this was the starting point.

321
00:46:18,720 --> 00:46:22,530
We would maximize it over, say, to get something done,

322
00:46:22,530 --> 00:46:33,329
you would try to prove that the estimate that maximizes this thing is reasonable and you are actually using the properties of the estimate directly.

323
00:46:33,330 --> 00:46:41,760
So it was kind of a case by case. Uh. Scenario to some extent, at least for some problems, right?

324
00:46:42,360 --> 00:46:46,440
This course we start the framework a different way.

325
00:46:48,000 --> 00:46:57,180
So the framework starts by considering the true problem, problem for the true model and formulating the function,

326
00:46:57,180 --> 00:47:03,180
and that characterizes the solution to the maximization problem.

327
00:47:03,930 --> 00:47:09,060
That's the true problem and the true solution. That's the parameter Theta Star, right?

328
00:47:09,360 --> 00:47:21,930
So to be able to go to the starting point of M estimation in this course, we need to find out what this guy becomes asymptotic.

329
00:47:22,140 --> 00:47:29,340
Right? Because we need the true function and this would be a large sample limit of the likelihood you are used to working with.

330
00:47:29,460 --> 00:47:35,040
Right? So if I just take a large sample limit of this guy, it won't exist, right?

331
00:47:35,190 --> 00:47:39,960
Because it's not normalized correctly. So go to a deterministic thing.

332
00:47:40,920 --> 00:47:47,940
Uh, but I notice that if I put one of em here right, then I will have an empirical expectation.

333
00:47:49,360 --> 00:47:55,020
Empirical expectation will go to the true expectation. So what we will call.

334
00:47:57,590 --> 00:48:19,770
The function and. So we will say that first of all, our function in and of theta is going to be one over and.

335
00:48:21,460 --> 00:48:25,690
You know, and minus, you know, in Star.

336
00:48:29,540 --> 00:48:37,240
Right. That won't change my solution in any way. Right. Because so the Lone Star is a land of faith.

337
00:48:37,270 --> 00:48:41,600
The star. And there's nothing I'll know in this guy.

338
00:48:41,960 --> 00:48:45,740
It just is a function of the true parameter value.

339
00:48:46,190 --> 00:48:51,559
Now, of course, I don't know the true parameter value, but in the sense of maximizing this all the theta.

340
00:48:51,560 --> 00:49:01,200
So theta is only the alpha. Right and multiplying it by one Alam won't change my solution to the maximal problem.

341
00:49:01,680 --> 00:49:05,040
So I have say the star is.

342
00:49:07,100 --> 00:49:10,220
Max. And have they done?

343
00:49:13,070 --> 00:49:16,180
It is. Theta.

344
00:49:16,840 --> 00:49:20,190
Theta is up immediately. Our one. Right.

345
00:49:20,220 --> 00:49:25,950
So what is the. So this is my approximate problem.

346
00:49:37,500 --> 00:49:46,980
Okay. So before we start formulating the true one, I want to temper a little bit with this expression,

347
00:49:47,040 --> 00:49:55,740
uh, to bring it to a context for so my land, both land and land with the star.

348
00:49:56,310 --> 00:50:06,900
So they are sons of I so one and will make them into an empirical expectation and it's under the log.

349
00:50:06,900 --> 00:50:10,080
I have f faith. I write them as the the star.

350
00:50:10,470 --> 00:50:21,750
So that's log f theta that's from the alien minus log if for its the true parameter that.

351
00:50:21,930 --> 00:50:25,950
Right. So this is what my father is.

352
00:50:27,490 --> 00:50:31,800
If I spell out what elements align with a star or.

353
00:50:33,330 --> 00:50:48,389
Right. And so I can continue and say that it's the empirical expectation of the ratio of the PDF at some part of the value of a PDF.

354
00:50:48,390 --> 00:50:58,240
It's the true parameter value. And by construction.

355
00:50:58,720 --> 00:51:02,900
If my faith is equal to the true parameter value, this would be a zero.

356
00:51:02,930 --> 00:51:11,970
Right? So I just centered. This dysfunction in the sense by subtracting the value of the true part of the mail.

357
00:51:12,900 --> 00:51:17,000
So you may also sense of connection to the likelihood ratio here, right?

358
00:51:18,450 --> 00:51:25,910
So that's also true. Okay.

359
00:51:26,000 --> 00:51:31,610
And, uh, the way my problem looks like.

360
00:51:32,990 --> 00:51:38,820
Where is it? There. Right. So I have.

361
00:51:39,030 --> 00:51:44,850
So I'm now looking at the data. I want to represent it is not some function of theta.

362
00:51:45,330 --> 00:51:50,580
And I just did it right. It is it's clear that I have.

363
00:51:51,930 --> 00:51:56,670
My am theta being whatever is under PM.

364
00:51:56,940 --> 00:52:02,760
Right. This is in theta, so I now know how my m theta looks like.

365
00:52:07,670 --> 00:52:15,380
Now my true problem is an immediate consequence of this.

366
00:52:16,310 --> 00:52:23,600
So that's when my empirical expectation is replaced by.

367
00:52:25,110 --> 00:52:30,800
The true expectations of my am theta without the m is going to be expected.

368
00:52:30,810 --> 00:52:35,580
The value of this likelihood ratio blog if the.

369
00:52:37,030 --> 00:52:45,910
If they start. Now, it's not really a lock.

370
00:52:47,380 --> 00:52:52,850
It's not really a likelihood ratio because the whatever is under the expectation is for one subject.

371
00:52:53,210 --> 00:52:56,610
Right. That's. For one observation.

372
00:52:57,000 --> 00:53:04,290
Once I take expectation, you could look at it and say that is kind of a normalized likelihood ratio because there's one over here.

373
00:53:04,440 --> 00:53:07,820
Right, the expectation. When it was a man.

374
00:53:11,600 --> 00:53:15,710
Right. And that's simply replacing p m.

375
00:53:17,280 --> 00:53:21,120
By Pete White in this special.

376
00:53:24,350 --> 00:53:27,710
So now I have my original starting point.

377
00:53:30,270 --> 00:53:34,950
For their masturbation? Yes. So I now know how my function m looks like.

378
00:53:36,180 --> 00:53:42,360
So now let's find out what with where this function is maximized.

379
00:53:44,350 --> 00:53:47,560
So I will write my and theta.

380
00:53:48,430 --> 00:53:56,200
So that's p of log if the whole if the star.

381
00:53:57,700 --> 00:54:04,900
So expectation of the log is less of equal than log of the expectations.

382
00:54:04,990 --> 00:54:08,590
So that's Jensen. You want me to working here?

383
00:54:13,400 --> 00:54:16,870
If they eat or if. Say The star.

384
00:54:18,890 --> 00:54:29,510
Yeah. Now, if I spell out, uh, the p of that ratio, so I have log and these is the true expectation.

385
00:54:29,510 --> 00:54:38,920
So that's an integral if theta of, if theta star and expectation is taken over the true model.

386
00:54:38,930 --> 00:54:43,190
So that's times the true PDF which is F Theta Star.

387
00:54:44,270 --> 00:54:48,890
And the next. Right. So everything is a function of X.

388
00:54:50,270 --> 00:54:55,120
Here. And of course.

389
00:54:56,020 --> 00:55:05,860
So this. Uh, this guy will cancel integral of any PDF, even though even if I have the wrong set,

390
00:55:05,860 --> 00:55:12,390
it is still a PDF so the integral will be equal to one and log of one will be zero.

391
00:55:13,940 --> 00:55:26,380
So that's. And zero is the maximum value, right?

392
00:55:27,610 --> 00:55:31,720
Because they have this inequality. And this is not just magic.

393
00:55:32,170 --> 00:55:41,560
It's actually attained. So I see that if I put theta equal to theta star, I will get an equal to zero.

394
00:55:45,050 --> 00:55:51,260
So also clearly I am of the star.

395
00:55:52,440 --> 00:55:55,620
Is equal to T.

396
00:55:56,600 --> 00:56:01,630
Long. Yes, they are. Yesterday, the star.

397
00:56:02,610 --> 00:56:07,140
So that's a zero. So P of it is also zero, right?

398
00:56:07,770 --> 00:56:12,330
So that's the maximum value that's attained that the true parameter.

399
00:56:15,040 --> 00:56:20,530
So that means that my arm of theta looks something like this, right?

400
00:56:21,830 --> 00:56:26,930
So I have zero. I have it's equal to zero, it's the star.

401
00:56:27,590 --> 00:56:31,430
And then it's going to be less than this value everywhere else.

402
00:56:32,180 --> 00:56:35,700
So this is. Now it looks like.

403
00:56:38,020 --> 00:56:46,780
That's my true function. Okay then.

404
00:56:47,230 --> 00:56:51,070
So I need a condition that's called model identify ability.

405
00:56:59,840 --> 00:57:03,680
That is so when I have an equation F of x.

406
00:57:05,490 --> 00:57:08,910
Four states are uniformly equal.

407
00:57:09,960 --> 00:57:15,760
So that's over X. That means simultaneously for any ex.

408
00:57:18,060 --> 00:57:23,510
Then to f. Uh, the star of X.

409
00:57:24,680 --> 00:57:28,280
So this kind of equation is called the functional equation, right?

410
00:57:32,380 --> 00:57:36,460
So find fate such that this is to.

411
00:57:38,150 --> 00:57:46,460
Yeah. The solution to that functional equation is theta equal to, say, the star.

412
00:57:51,060 --> 00:57:58,680
So this uniform equality implies that data is equal to the star.

413
00:57:59,290 --> 00:58:08,060
Then the model is called identifiable. So he can be formulated in layman's terms as are.

414
00:58:08,440 --> 00:58:15,500
So paper star is the only value of data. That gives you a little piece.

415
00:58:18,920 --> 00:58:24,740
Okay. So that basically frames the, uh, the framework.

416
00:58:25,100 --> 00:58:33,670
There's another interesting thing. That said, I wanted to note about it, but we'll do it after the break.

417
00:58:46,150 --> 00:58:59,030
Mm hmm. So it's a function of both X and theta.

418
00:58:59,840 --> 00:59:06,200
Right. So the Lipschitz is a condition called M as a function of theta, not a function of X.

419
00:59:07,190 --> 00:59:10,570
And the conditional on it as a function of X is that it's measurable.

420
00:59:11,450 --> 00:59:12,560
As a function of its.

421
00:59:31,230 --> 00:59:41,220
The contribution of plus on distribution to the likelihood is supposed to be continuous a little more than continuous in the parameter value of.

422
00:59:43,080 --> 00:59:46,700
Because you oftentimes have them discrete and so on.

423
00:59:46,740 --> 00:59:51,930
Right. Over acts, of course. Right. But over the parameter that you think they need to be.

424
00:59:53,450 --> 00:59:57,260
And it's more than Tanzania's. So Lipschitz according to this theory.

425
00:59:57,380 --> 01:00:05,930
Right. Right?

426
01:00:06,260 --> 01:00:12,530
Right. Right. But this one is supposed to be Lipschitz for anything you type.

427
01:00:12,550 --> 01:00:20,660
That's an overall condition, right? On all of the functions behavior where the differential ability you need only adds that you're bound to the value.

428
01:00:21,730 --> 01:00:25,090
Because that's how your Taylor expansion is working, right?

429
01:00:25,720 --> 01:00:28,990
So it's not like if it's differentiable, then it's continuous.

430
01:00:29,960 --> 01:00:33,410
Everything is satisfied, right? That's not the case.

431
01:00:33,410 --> 01:00:36,500
Right? Because the search abilities only add to the star.

432
01:00:44,180 --> 01:00:49,010
Uh huh. Right.

433
01:00:50,110 --> 01:00:55,290
Right. And that's the dream, right? So we pretend that we know it, right?

434
01:00:55,540 --> 01:01:02,890
Then we have a true problem that characterizes that unknown thing as a solution to the problem.

435
01:01:03,520 --> 01:01:07,830
And then we have a way to represent to approximate the true problem using simple values.

436
01:01:07,850 --> 01:01:16,880
That gives us an estimate for. Uh huh.

437
01:01:29,630 --> 01:01:33,150
You're solving the problem of maximum employment. Yes.

438
01:01:33,750 --> 01:01:45,500
All right. Well, it is what it is.

439
01:01:45,590 --> 01:01:48,819
Right to the sound. I'm trying to give you intuition.

440
01:01:48,820 --> 01:01:51,970
Why? Likelihood works with all of this. Right.

441
01:01:52,960 --> 01:01:58,630
This is just a number that's inconsequential for your family estimation, right?

442
01:01:59,200 --> 01:02:02,800
Because it doesn't depend on the unknown parameter. Yes.

443
01:02:03,160 --> 01:02:07,540
In a sense that it's nothing to maximize over in the airline star.

444
01:02:08,680 --> 01:02:13,030
So I'm just using these to have some nice property to show you.

445
01:02:13,030 --> 01:02:21,370
That family's actually minimizing some distance between the true model and the model with, uh, arbitrary theta.

446
01:02:28,910 --> 01:02:32,660
What for? For the practice. You really don't need this.

447
01:02:32,660 --> 01:02:37,959
You don't need one. Over. Of course. Right. So it's there when you maximize.

448
01:02:37,960 --> 01:02:56,060
And that's it. Okay. But. Yeah.

449
01:03:03,740 --> 01:03:13,190
What? Yeah. Yeah. Just. Just as for the two sides that you can do on your own, and that will make the one man calculus.

450
01:03:16,860 --> 01:03:22,060
Right. The.

451
01:03:23,380 --> 01:03:29,320
Yeah. So theoretically, yes, but it's mostly focused on the second half of.

452
01:03:52,090 --> 01:03:57,100
Um, not really. And also the set of problems I posed to the UN general.

453
01:03:58,820 --> 01:04:01,820
What I would use for, for example, flights.

454
01:04:03,740 --> 01:04:09,620
So don't be scared by this sense of problems that I posted.

455
01:04:12,070 --> 01:04:18,430
Basically they say they would be the same type, but not the same content, of course.

456
01:04:20,870 --> 01:04:27,590
The difficulties are approximately the same, but at least I'll do my best to have them as equal as possible.

457
01:04:28,070 --> 01:04:31,850
Thanks. Yeah.

458
01:04:33,810 --> 01:04:39,540
At the same schedule. You can always write me an email if you want to meet outside of it.

459
01:04:51,350 --> 01:04:54,620
Okay. So.

460
01:04:58,320 --> 01:05:05,490
And I'm going to bring one more piece of intuition, because you may have got an intuition that.

461
01:05:06,750 --> 01:05:19,580
So the estimation problem as it relates to the family and outside of the family, actually,

462
01:05:20,140 --> 01:05:32,640
it's it's about the minimizing some kind of a distance that's based on likelihood ratio and you may have had in other courses.

463
01:05:34,050 --> 01:05:37,740
That's likelihood odds ratio.

464
01:05:39,830 --> 01:05:43,700
He's related to the so-called cool back.

465
01:05:47,630 --> 01:05:51,300
The. Distance.

466
01:05:53,000 --> 01:05:59,030
So if you haven't heard of it, this is just to give you a terminology, what to look for.

467
01:06:00,060 --> 01:06:10,460
Right. But the thing about it is that this is so even though it has distance in the name, this is not the real distance.

468
01:06:20,420 --> 01:06:24,300
So distance is a mathematical term. Right.

469
01:06:24,330 --> 01:06:31,760
And the axioms for it is basically is similar to because we defined it as norm of the square root.

470
01:06:31,760 --> 01:06:43,470
Right of the norm of. The squared norm of the difference between two objects with norms being defined in different ways.

471
01:06:43,480 --> 01:06:48,720
So cubic legal definition from the likelihood ratio.

472
01:06:49,790 --> 01:06:55,820
Um, that's, that's, uh, doesn't really satisfy the definition of distance.

473
01:06:56,390 --> 01:07:01,910
So the right distance for likelihood this inference is Hellinger.

474
01:07:08,740 --> 01:07:12,770
And also a derivation of how, uh, some.

475
01:07:12,840 --> 01:07:19,870
So the framework that we considered earlier is related to healing a distance that gives us antibiotics.

476
01:07:21,680 --> 01:07:25,370
That gives useful intuition for why Emily works.

477
01:07:26,630 --> 01:07:31,370
Okay. And so we'll start by considering a function.

478
01:07:37,860 --> 01:07:41,440
Unless you. Let's say.

479
01:07:43,970 --> 01:07:47,260
So we used AV. We use FI.

480
01:07:48,780 --> 01:07:54,120
So does anybody have a nice functional name? Okay.

481
01:07:54,340 --> 01:07:59,950
We use F of X. That's a different that's. So what?

482
01:07:59,960 --> 01:08:07,980
X minus x plus one? So at this point, we are into high school stuff.

483
01:08:09,810 --> 01:08:12,900
So I have a function like this. So how does it look like?

484
01:08:13,860 --> 01:08:21,870
Well, I'll take a derivative. That would be one over x minus one.

485
01:08:23,040 --> 01:08:26,880
So it's something so far x less than one.

486
01:08:27,750 --> 01:08:33,229
It's going to be negative. Uh. Flex.

487
01:08:33,230 --> 01:08:38,140
Flex less than one is going to be positive, right? X greater than one.

488
01:08:38,170 --> 01:08:42,770
It's going to be negative. So it has a maximum when X is equal to one.

489
01:08:50,770 --> 01:09:02,610
This is a point of maximum. And that maximum if I substituted x equals one.

490
01:09:02,610 --> 01:09:05,670
So log is zero. I have minus one plus one.

491
01:09:06,000 --> 01:09:12,040
So that's all right. So that function looks like this.

492
01:09:12,060 --> 01:09:15,250
I have. Why I'm here.

493
01:09:15,580 --> 01:09:20,640
That's why tax my F of x is something like it.

494
01:09:21,110 --> 01:09:29,310
Like this. In a sense, it's similar to the picture we did for the air.

495
01:09:29,410 --> 01:09:37,950
Right. And this is not a coincidence. Okay.

496
01:09:38,010 --> 01:09:42,030
So this is an observation now. Okay.

497
01:09:42,090 --> 01:09:51,709
I don't like the f because it's a pdf. Okay.

498
01:09:51,710 --> 01:10:02,390
I'll say it's new. Then I'll take.

499
01:10:03,860 --> 01:10:07,370
Yeah, it's equal to the square root.

500
01:10:09,860 --> 01:10:15,650
The ratio of the pdf. It's some theta over the pdf of the true model.

501
01:10:20,250 --> 01:10:24,210
Then. Um. So I have, uh.

502
01:10:25,290 --> 01:10:29,129
So from the properties of this function. Right. So I have.

503
01:10:29,130 --> 01:10:32,640
What's. I have longer, Max.

504
01:10:35,990 --> 01:10:39,450
The less equal. Yeah.

505
01:10:39,470 --> 01:10:45,920
X minus one. Right. This is simply from the behavior of this function.

506
01:10:46,940 --> 01:10:54,560
So my view of X is less than zero. So I just move minus X plus one to the right part.

507
01:10:56,530 --> 01:10:59,910
This is what they have in them.

508
01:11:00,100 --> 01:11:08,680
So if I use this equation with X. Being me is I can't rewrite it as long.

509
01:11:10,270 --> 01:11:15,700
The square root of the fate of the star.

510
01:11:18,470 --> 01:11:22,220
Last year, 12 square feet.

511
01:11:23,290 --> 01:11:27,310
They status are. Minus one.

512
01:11:29,580 --> 01:11:32,810
This guy is one half of the long.

513
01:11:35,400 --> 01:11:39,840
It's something that a lot of the square root of the ratio.

514
01:11:45,420 --> 01:11:50,639
Them. So there's an argument of all these PDFs.

515
01:11:50,640 --> 01:12:00,480
I have some facts, right? And I can always substitute the random variable for it and take expectation of that inequality.

516
01:12:00,480 --> 01:12:07,650
So then I will have. Take key.

517
01:12:10,140 --> 01:12:17,510
Yes. Those are demons. Yes.

518
01:12:20,510 --> 01:12:31,100
And I will have one half expected value of if they need to, if they are less people.

519
01:12:32,680 --> 01:12:35,770
Expected value of the square.

520
01:12:39,830 --> 01:12:44,330
Minus one. No.

521
01:12:44,750 --> 01:12:59,100
This guy was my function and. And I can see that rearranging terms that my firm theta is actually less equal to times.

522
01:13:00,400 --> 01:13:03,670
In the growth square.

523
01:13:03,690 --> 01:13:06,910
It's face to say the star.

524
01:13:09,770 --> 01:13:13,850
Times have. They start the ads.

525
01:13:14,960 --> 01:13:21,050
And I will have since I multiply this by two, I will have minus two.

526
01:13:22,760 --> 01:13:28,130
And minus two I will represented.

527
01:13:33,020 --> 01:13:44,550
Yes. One plus one. And one of the ones is going to be integral of square roots of theta.

528
01:13:45,630 --> 01:13:53,660
Squared the x. And another one is going to be integrals square with the Theta Star.

529
01:13:54,660 --> 01:13:58,150
Squared? Yes. Right.

530
01:13:58,170 --> 01:14:03,600
It's simply normalization. Condition. Right. So square root of PDF Square.

531
01:14:03,600 --> 01:14:09,030
That's PDF itself. Integral over the pdf is one and I have two versions of it.

532
01:14:09,030 --> 01:14:23,760
One for theta, one for the theta star. And then I can put these things as an expression under the integral right margins and so on.

533
01:14:24,910 --> 01:14:29,640
And this will be equal to.

534
01:14:30,770 --> 01:14:49,160
It's. This is equal to the glow of square root of a state of minus, where it's essentially the star squared.

535
01:14:49,430 --> 01:14:55,960
Yes. Because what I have found within the girl is.

536
01:14:58,400 --> 01:15:04,760
So square root of our faith and our faith will cancel out leaving the square root.

537
01:15:04,760 --> 01:15:10,550
So that's the product square or the state square with a status star times to.

538
01:15:11,540 --> 01:15:18,530
Uh. Right. And then minus these two, that's the square of each one of them.

539
01:15:18,540 --> 01:15:22,950
That's the full square. And there is a minus two. It's like that from getting.

540
01:15:30,750 --> 01:15:38,220
And the thing is that this integral without the minus is.

541
01:15:40,970 --> 01:15:47,840
Equal by definition, two one half square root of so called.

542
01:16:01,920 --> 01:16:06,140
Of these in the growth square index.

543
01:16:07,310 --> 01:16:16,570
This is by definition. It's called hailing distance.

544
01:16:25,100 --> 01:16:32,750
Between two functions, one statement and another one status.

545
01:16:35,790 --> 01:16:46,690
And it really fleshes out what happens when you maximize and fade because there's a minus to if you're minimizing a distance, right.

546
01:16:47,290 --> 01:16:52,030
And it becomes its maximum value of zero when theta is equal to theta star.

547
01:17:03,440 --> 01:17:11,450
And as a last thing. So a couple of notes and a E is simplification.

548
01:17:17,630 --> 01:17:29,610
Of an estimation. So it's just about devising the simplified version of the variance term.

549
01:17:30,090 --> 01:17:34,790
So I have the integral over the pdf equals one.

550
01:17:34,800 --> 01:17:39,870
You may have had this argument in six. So two. So.

551
01:17:40,010 --> 01:17:43,970
And this normalization means that if I differentiate it once.

552
01:17:44,960 --> 01:17:50,180
So then, uh, gets it equal to zero.

553
01:17:50,300 --> 01:17:57,600
Right. And if I differentiated yet another time.

554
01:17:57,610 --> 01:18:01,480
So I'm differentiating a uniform zero. So that's going to be a zero again.

555
01:18:02,500 --> 01:18:07,090
And all of these are consequences of normalization conditions for the PDF.

556
01:18:07,090 --> 01:18:15,310
It's just so what makes these two equations happen is simply that likelihood is based on a PDF.

557
01:18:17,020 --> 01:18:30,600
Okay then. So Imfinzi is going to be a prime of if theta and double prime is if.

558
01:18:30,640 --> 01:18:40,080
Double prime if. Mind us if Brian stayed home and stayed in the square.

559
01:18:43,100 --> 01:18:46,610
They and so p um.

560
01:18:46,640 --> 01:18:51,980
Frying seed that's impossible to try and say just.

561
01:18:52,860 --> 01:19:03,690
If they the star. So that's the classic dilemma argument is they eat the star index and that's a zero right from this guy.

562
01:19:12,050 --> 01:19:17,120
Then. P m double fine.

563
01:19:17,120 --> 01:19:28,780
Say the star. It's going to be integral if you double for me to see the sturdy x minus p.

564
01:19:30,330 --> 01:19:33,990
And Prime. Squared.

565
01:19:35,340 --> 01:19:41,070
So this is equal to zero. From this guy.

566
01:19:42,470 --> 01:19:59,570
Again, a consequence of normalization. And so what this is called is a minus information matrix evaluated that people start using the language.

567
01:19:59,690 --> 01:20:04,970
Right. And this is using language the variance of the score.

568
01:20:09,860 --> 01:20:15,660
So this guy is. Variance of the score.

569
01:20:18,300 --> 01:20:22,920
We get the familiar result.

570
01:20:23,430 --> 01:20:33,450
That's the information matrix is a negative information matrix is the variance.

571
01:20:35,760 --> 01:20:45,190
Of the score. Well, the variance of the score is the information matrix, right?

572
01:20:46,890 --> 01:21:00,850
Because there's minus two. So we had the variance.

573
01:21:01,780 --> 01:21:05,050
Asymptotic variance of the estimator.

574
01:21:16,090 --> 01:21:26,090
Yeah. It was, uh, uh, it's a the star of, uh, uh, I say the stars square, right?

575
01:21:26,110 --> 01:21:30,430
If I just interpreted the term we had from the very beginning.

576
01:21:32,770 --> 01:21:37,660
Is. So this thing.

577
01:21:40,280 --> 01:21:47,780
So for the family, it's all y squared because of the relationship we just derived.

578
01:21:56,210 --> 01:22:08,270
In these seas. I see the star minus one, the inverse of the information matrix in the multivariate case and the univariate case.

579
01:22:08,270 --> 01:22:15,950
It's just one over the. Information for the parameter.

580
01:22:16,140 --> 01:22:19,570
There's only one component of it. Okay.

581
01:22:19,820 --> 01:22:31,160
This is it. So pay attention to what I post so I'll do my best to post everything before Friday.

582
01:22:33,330 --> 01:22:55,280
And then we'll have the usual office hours on Friday. Just stop the recording.

