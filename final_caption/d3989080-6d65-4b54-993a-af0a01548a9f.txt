1
00:00:02,220 --> 00:00:08,490
It felt like overkill to you.

2
00:00:12,450 --> 00:00:20,220
Oh, okay. Do you want to know more about my old movies?

3
00:00:22,610 --> 00:00:31,780
Oh, yeah. I work for the army on the border.

4
00:00:31,890 --> 00:00:35,070
Oh, yeah. I better get us ahead of Sarah.

5
00:00:37,380 --> 00:00:43,350
As long as she never see her face or my face is all the.

6
00:00:45,210 --> 00:00:53,800
Wow. This is basically not going to be a chance to get into these things.

7
00:00:53,800 --> 00:01:06,720
You should probably find out what it is.

8
00:01:06,840 --> 00:01:15,560
Not right? Yeah. You know, there's, like, all these different old, like the other one.

9
00:01:15,990 --> 00:01:26,370
Yeah. Yeah. It's like you can see you have to respond to your parents to.

10
00:01:26,640 --> 00:01:29,670
That is so weird. It was just one guy.

11
00:01:30,160 --> 00:01:38,280
And then I think he was like, I tried to find like I realized confirmed, oh, my God.

12
00:01:38,490 --> 00:01:44,810
They were like, it's what you said. It was like it was like, they can be out.

13
00:01:45,250 --> 00:01:49,330
They can be harsh.

14
00:01:49,380 --> 00:02:03,210
I didn't see, you know, I mean, like once I was like, oh, my God, I can see that you're getting screwed.

15
00:02:05,460 --> 00:02:09,670
Oh, yeah, I know. Right.

16
00:02:10,680 --> 00:02:16,110
Know. So every mother and then would complain about it.

17
00:02:16,140 --> 00:02:19,930
All right, let's get started. So I'm Tuesday.

18
00:02:19,930 --> 00:02:26,730
I wasn't here. My student city taught hopefully and went through the derivation of the normal sample size.

19
00:02:27,840 --> 00:02:31,200
So we're going to take off from there soon.

20
00:02:31,200 --> 00:02:36,029
But I wanted to go back to the last lecture that I gave last Thursday about

21
00:02:36,030 --> 00:02:41,969
hypotheses and just some clarifying things and then do the people everywhere.

22
00:02:41,970 --> 00:02:47,670
So I don't think we got those right. And then also I'll just give an announcement.

23
00:02:47,670 --> 00:02:55,980
So next week, right, your homework for is due and that's finding an article and trying to calculate the sample size to match it.

24
00:02:56,550 --> 00:03:00,210
Go. We'll see a bunch of examples where we try to do that in class.

25
00:03:00,900 --> 00:03:07,320
Don't choose something that uses longitudinal analysis or has like a step towards design.

26
00:03:07,320 --> 00:03:10,320
Rightly, try to choose a two hour phase three trial.

27
00:03:10,680 --> 00:03:14,819
That's something that we've learned. If it's a little bit more complex,

28
00:03:14,820 --> 00:03:22,379
you can try using our calculation and then just describe why you couldn't match it with like because X, Y and Z or whatever.

29
00:03:22,380 --> 00:03:28,950
Right? But I want you to try to match it to say if you asked or not and if you didn't, to explain why you think that is.

30
00:03:31,890 --> 00:03:34,950
Let's see what else. And next Tuesday, actually, I'll also be out.

31
00:03:34,950 --> 00:03:38,520
And another one of my PhD students, Mari is going to teach the class.

32
00:03:39,180 --> 00:03:42,329
So I have study section all next Tuesday and Wednesday all day.

33
00:03:42,330 --> 00:03:46,950
So I unfortunately will not be here. But like I said, Mari Wong, who took this class.

34
00:03:48,150 --> 00:03:51,270
Last year. Two years ago. She's going to be here.

35
00:03:51,270 --> 00:03:56,920
And it's mostly going through a sample size exercise. Any questions before I get started?

36
00:03:59,090 --> 00:04:03,260
If you didn't pick up your test last week. I have them here so you can get them at the end of class.

37
00:04:04,270 --> 00:04:07,900
Okay. And so also next week, my office hours are going to be changed.

38
00:04:08,890 --> 00:04:13,240
I forget what they are now, so I'll post it. I think it's next.

39
00:04:15,440 --> 00:04:18,890
Thursday. I don't know. I'll post it out. I'll make an announcement.

40
00:04:19,670 --> 00:04:28,460
All right. So going back to lecture, I don't know what number this is, but lecture about hypothesis from last Thursday,

41
00:04:28,640 --> 00:04:32,360
we I didn't play this YouTube video because I couldn't figure out the sound.

42
00:04:32,360 --> 00:04:39,530
Right. Hopefully you watched it, but it's not. This is kind of a nice little graphic that explains it, which I added to the slides.

43
00:04:39,530 --> 00:04:44,750
So you would have to re download the PowerPoint if you wanted to get this.

44
00:04:45,350 --> 00:04:52,190
Essentially, it's trying to show the difference between an intent to treat analysis, a per protocol analysis, and an as treated analysis.

45
00:04:52,460 --> 00:04:58,490
By showing you right at first, if we have a two hour trial and we randomize to treatment versus control.

46
00:04:58,910 --> 00:05:06,860
Right, some of the treatment patients might actually have might take control or might stop the treatment.

47
00:05:07,190 --> 00:05:11,180
Right. Because they decided they didn't like it or something happened with randomization.

48
00:05:11,480 --> 00:05:16,639
And so they get the other thing. And similarly with control, they might actually receive the treatment again.

49
00:05:16,640 --> 00:05:20,209
Maybe something went wrong with allocating the treatment and or they stopped.

50
00:05:20,210 --> 00:05:25,670
They didn't want that control. They found some way to get the treatment. So this is somewhat simplified in terms of.

51
00:05:25,670 --> 00:05:32,270
Right, there's a lot of other things that could happen to patients, but this is a nice, clean example of the difference between these two types.

52
00:05:32,630 --> 00:05:40,670
So the usual analysis for a clinical trial is what we call an intention to treat analysis.

53
00:05:40,670 --> 00:05:48,649
And as we described, this means that we compare the groups as we intended to treat them or as being randomized.

54
00:05:48,650 --> 00:05:52,400
We're comparing the randomize like to what you were grant minus two groups.

55
00:05:52,760 --> 00:06:00,229
And so for everybody who was in the treatment group was randomized the treatment group, whether they actually received treatment or not,

56
00:06:00,230 --> 00:06:05,000
we analyzed them as if they got that treatment and then we compare it to everyone who was

57
00:06:05,000 --> 00:06:10,610
randomized to control whether or not they actually took that control right as the control group.

58
00:06:10,610 --> 00:06:14,389
And that's the intent to treat analysis intended to treat.

59
00:06:14,390 --> 00:06:20,420
That was what they were randomized to. Alternatively, something called a per protocol analysis.

60
00:06:20,630 --> 00:06:26,930
The per protocol means that you actually took the treatment as it was supposed to be taken,

61
00:06:26,930 --> 00:06:30,810
right as the protocol of the treatment, as the directions of the treatment states.

62
00:06:31,460 --> 00:06:35,080
And so this would be information that say we gave a pill, right?

63
00:06:35,090 --> 00:06:40,630
We could actually tabulate the full count. We could see that those people didn't take the pill.

64
00:06:40,640 --> 00:06:45,020
So we know that they didn't that they shouldn't be included in this per protocol analysis.

65
00:06:45,020 --> 00:06:48,020
Or we can ask people whether they took it or not and so on.

66
00:06:48,020 --> 00:06:52,760
Per protocol, anybody who was assigned to treatment but didn't actually take the treatment is ignored.

67
00:06:52,790 --> 00:06:58,219
They're excluded. Right. So we're basically trying to get at like the pure treatment effect.

68
00:06:58,220 --> 00:07:07,580
If the treatment is followed as perfectly as it's supposed to be the as treated group.

69
00:07:08,510 --> 00:07:17,000
Right. We would then say, well, whatever you actually took is now I'm going to reassign your treatment information.

70
00:07:17,300 --> 00:07:20,600
So whether you were randomized to treatment, but you actually took control.

71
00:07:20,600 --> 00:07:25,400
Now I'm going to say that you're a control person, even though I didn't you weren't randomized to that.

72
00:07:25,940 --> 00:07:29,959
Right. That would be as treated if you were randomized to control, but you actually ended up having the treatment.

73
00:07:29,960 --> 00:07:31,580
I would consider you in that treatment group.

74
00:07:32,180 --> 00:07:42,860
Now, you can imagine right when we do either per protocol or as treated and we start changing treatment groups and or ignoring people.

75
00:07:43,250 --> 00:07:46,700
Right. We're getting rid of all the great things that we had about randomization.

76
00:07:47,000 --> 00:07:54,080
We're no longer necessarily balanced across all of those confounders at the beginning that we had at randomization.

77
00:07:54,410 --> 00:07:59,930
And so per protocol and as treated can potentially have some issues in terms of introducing bias.

78
00:08:00,290 --> 00:08:03,529
And so we always have to be careful if we're going to do these analysis right.

79
00:08:03,530 --> 00:08:10,609
They're usually sensitivity analyzes and that we know that there are these limitations that the patients who are now analyzing may be different

80
00:08:10,610 --> 00:08:19,400
than that broader group or representative group and or not balanced on baseline characteristics as we initially intended with randomization.

81
00:08:21,690 --> 00:08:25,740
Okay. So let's move on to these questions.

82
00:08:27,290 --> 00:08:31,439
This is the first one. All right. So pull every word.

83
00:08:31,440 --> 00:08:37,050
Questions. Remember, there are these three types of hypotheses that we talked about superiority, equivalence and non-inferiority.

84
00:08:37,470 --> 00:08:44,130
So I'm testing your memory from last week about why we would use each one.

85
00:08:44,940 --> 00:08:52,050
So we expect treatment B may not be better, may not lead to better progression free survival for breast cancer patients, but it's less expensive.

86
00:08:52,440 --> 00:08:59,610
What type of hypothesis might be appropriate? You guys, you one here, even though perhaps more than one is appropriate plus you.

87
00:09:17,240 --> 00:09:27,860
Let's get like 15. Nothing it doing this weird thing.

88
00:09:27,980 --> 00:09:48,450
Okay, hold on. I got to switch the display settings. 21.

89
00:09:48,540 --> 00:09:53,410
That's the most we've ever had. Exciting. Okay. Not if you're already great.

90
00:09:53,430 --> 00:10:00,800
So you remember, right? We use a non-inferiority hypothesis when a treatment may not be as good, but it has some other benefits.

91
00:10:00,810 --> 00:10:04,770
So, for example, less expensive. Okay, how about this one?

92
00:10:36,440 --> 00:10:40,920
Why is it somebody like gave their answer and then took it away and then it was in 1458.

93
00:10:41,340 --> 00:10:46,970
What do you got? All right. Oh, this is somewhat all over the place.

94
00:10:48,620 --> 00:10:56,870
So it seems like most people agree that superiority is possible, and some people think more possibly not if you're already in equivalence.

95
00:10:57,890 --> 00:11:03,650
So we actually cannot have non-inferiority or equivalence here because we have placebo, right?

96
00:11:03,660 --> 00:11:07,280
So the fact that we now have a trial with a new treatment and a placebo,

97
00:11:07,280 --> 00:11:11,570
we would not be interested in a new treatment that's slightly worse than placebo.

98
00:11:11,720 --> 00:11:17,510
Right? We would not be interested in the treatment being equivalent to placebo because placebo is not actually effective.

99
00:11:18,050 --> 00:11:21,710
So there's only one option here. That's correct. And that's superiority.

100
00:11:27,960 --> 00:11:34,260
Okay. How about this question? A non-significant result from a superiority trial is proof of equivalence.

101
00:11:35,040 --> 00:11:50,420
True or false? False.

102
00:11:50,570 --> 00:11:53,420
All right. You got that? You got that one? That is correct. Right.

103
00:11:53,720 --> 00:12:02,680
That if you have a P-value greater than 0.05 from a superiority trial, you say that you don't have evidence to find superiority.

104
00:12:02,690 --> 00:12:08,870
You don't say that these things are equivalent. Right. It's that difference between we we reject the null verses.

105
00:12:08,870 --> 00:12:11,990
We do not reject the null. It's not that we have evidence for the null.

106
00:12:12,080 --> 00:12:15,840
Right. Okay.

107
00:12:15,840 --> 00:12:24,570
How about this one? Superiority was not reached, but the 95% confidence interval, the new treatment minus the control is around zero.

108
00:12:24,720 --> 00:12:32,190
And investigators feel like as long as the difference is what is greater than -2%, the new treatment is noninferior to control.

109
00:12:32,940 --> 00:12:39,450
Can the investigators now conclude noninferiority? So this was a superiority trial.

110
00:12:39,840 --> 00:12:44,670
They find the confidence interval. Can they can they say that they have non-inferiority?

111
00:13:10,840 --> 00:13:19,230
Okay. This is all over the place. Yes, no, maybe. So let me show you some slides and then we can explain this one.

112
00:13:20,640 --> 00:13:28,800
So for the most part, we always want the hypothesis to be pre specified or prescribed prior to the trial.

113
00:13:29,160 --> 00:13:33,830
So if you plan to do a superiority trial, right, you've said that it's a superiority trial.

114
00:13:33,880 --> 00:13:38,220
You powered on that superiority trial. If you plan to do equivalence, you've said it's equivalence.

115
00:13:38,220 --> 00:13:42,390
You've powered for that. You've set the analysis plan. Same for non-inferiority.

116
00:13:42,810 --> 00:13:50,340
We generally don't want to flip flop between what we're just deciding interpreting the results at the very end.

117
00:13:50,340 --> 00:13:58,550
And that's because we need to ensure that we have appropriate treatments, doses, patient populations and endpoints that they're all appropriate.

118
00:13:58,600 --> 00:14:03,210
We've predefined them. Our sample size depends on the primary hypothesis.

119
00:14:05,190 --> 00:14:12,479
We if we're going to choose equivalence in non-inferiority, we have to pre-specified the equivalence or non-inferiority margin.

120
00:14:12,480 --> 00:14:23,730
Remember that that small delta of the difference. And so if we don't pre-specified that and at the end try to justify that margin,

121
00:14:23,880 --> 00:14:28,080
people may not feel so strongly or believe you so strongly because they might think,

122
00:14:28,080 --> 00:14:32,160
Oh, you looked at your data and you chose the margin based on your data, right?

123
00:14:32,340 --> 00:14:39,330
And so really, I think the answer to this is somewhere between no and it depends.

124
00:14:40,950 --> 00:14:50,029
So. If this NONINFERIORITY margin had been prespecified prior to the trial, it was set up to be superior superiority.

125
00:14:50,030 --> 00:14:54,859
But they said if we find blah blah blah right, we could assume noninferiority as well.

126
00:14:54,860 --> 00:14:57,079
If that wasn't prespecified, then yes,

127
00:14:57,080 --> 00:15:03,800
you could now say that this is noninferior if it was not prespecified and we're just trying to make this claim at the end of the trial,

128
00:15:04,310 --> 00:15:10,850
I think we're going to run into some issues of other people not really feeling like we have justified our noninferiority margin.

129
00:15:11,360 --> 00:15:15,499
If we can somehow still very strongly justify that noninferiority margin,

130
00:15:15,500 --> 00:15:22,730
perhaps we could say noninferiority, but generally we always want to prespecified our hypothesis.

131
00:15:23,900 --> 00:15:36,590
So if we're trying to so this is the last that was a superiority trial that we would try to say is not have a noninferior result.

132
00:15:36,890 --> 00:15:39,620
Really, you should only do that if we define that margin ahead of time.

133
00:15:40,490 --> 00:15:47,809
If we have a noninferiority trial and actually see superiority, this is this is possible.

134
00:15:47,810 --> 00:15:52,280
So we can somewhat if we start noninferior, we powered for Noninferior,

135
00:15:52,280 --> 00:15:56,660
usually that has a smaller delta or effect size than a superiority trial would.

136
00:15:57,290 --> 00:16:05,570
And so often if you have a noninferiority trial and then actually see that that difference, if you remember, if we go back to one of the years.

137
00:16:11,090 --> 00:16:15,850
Let's go back. This one looks pretty cool. No.

138
00:16:17,140 --> 00:16:26,530
Okay. Right. Suppose we have one of these plots, and not only do we see that it's noninferior, but actually the confidence interval is to the.

139
00:16:28,070 --> 00:16:32,210
Right? Right. The lower bound of the confidence interval is to the right of zero.

140
00:16:32,690 --> 00:16:35,840
You could potentially also say that there is superiority.

141
00:16:37,590 --> 00:16:45,140
Again, it'd be most ideal to either start with a superiority hypothesis or a non-inferiority.

142
00:16:45,950 --> 00:16:54,170
But going from non-inferiority to superiority is not as big of an issue because usually you're powered for that superiority.

143
00:16:54,200 --> 00:17:00,230
It is possible that finding that little difference in terms of superiority would require a larger sample size.

144
00:17:04,250 --> 00:17:13,190
However, in in some respects, once you get that confidence interval at the end of the trial, it sort of supersedes your previous power calculation.

145
00:17:14,300 --> 00:17:25,160
And so if you find that your lower bound is above zero and you feel like that's enough of a difference to say that it's superior,

146
00:17:25,160 --> 00:17:33,620
you can calculate the superior p value. So there is this like caveat of potentially interpreting a noninferiority trial of superiority,

147
00:17:33,620 --> 00:17:38,000
but otherwise you really shouldn't exchange these hypotheses in any way.

148
00:17:38,460 --> 00:17:48,310
OC As the take home message. So again, I would have said that this is either no or it depends.

149
00:17:48,880 --> 00:17:53,800
Right. It depends. If that noninferiority margin was pre specified, then this would be okay.

150
00:17:57,080 --> 00:18:01,820
Okay. What if we want to compare a generic drug versus the original drug?

151
00:18:02,360 --> 00:18:25,469
Which type of hypothesis is most appropriate? Okay.

152
00:18:25,470 --> 00:18:34,530
So a generic drug, right, is if a drug goes off patent and now we're able to have the same kind of drug, but it's less money, right?

153
00:18:34,620 --> 00:18:39,060
Anybody can make it at that point, like the formula for the drug goes out and anybody can make that drug.

154
00:18:40,230 --> 00:18:44,650
So some people might choose noninferiority because it's supposed to be about same, but it's cheaper.

155
00:18:44,670 --> 00:18:49,979
However, actually, with generic drugs and original drugs, they're supposed to be the same formula.

156
00:18:49,980 --> 00:18:53,700
And so this is the whole area of bioequivalence in pharmaceutical companies.

157
00:18:54,090 --> 00:19:00,900
And so the most appropriate hypothesis here is actually equivalence that you want the generic to be exactly the same.

158
00:19:01,060 --> 00:19:05,790
Right. It's not you can never show exactly the same, but about the same as the original drug,

159
00:19:06,390 --> 00:19:10,290
because now there's actually like the company can no longer make their huge profits.

160
00:19:10,290 --> 00:19:14,370
Anybody can make this drug. And so it better it should be the same, whatever it is.

161
00:19:18,300 --> 00:19:22,410
Usually in terms of noninferiority, it's usually not the same drug.

162
00:19:22,410 --> 00:19:27,389
It's something different that has that has these other better things,

163
00:19:27,390 --> 00:19:32,910
like less toxicity, less expensive, but it's like a complete alternative of a drug.

164
00:19:32,910 --> 00:19:36,790
Not not the same. Okay.

165
00:19:37,330 --> 00:19:41,290
That's the end of that one. Those are some extra slides. Any questions on hypotheses?

166
00:19:43,460 --> 00:19:46,790
Okay. We're going to go into more pull up for questions and then we'll get on.

167
00:19:47,240 --> 00:19:51,050
So this is where I think you left off with Citi.

168
00:19:52,610 --> 00:19:56,030
So she, I think, went through the derivation of this.

169
00:19:56,420 --> 00:19:56,840
You know what?

170
00:19:56,840 --> 00:20:07,120
If you have a one arm, constant variance normally distributed, right, a continuous outcome, how do you figure out what end is needed for that trial?

171
00:20:07,130 --> 00:20:11,300
So, right, that's really like a phase, a confirmatory phase two space.

172
00:20:11,420 --> 00:20:16,760
It's not usually a space which is phase three, almost always be upper end position in phase three.

173
00:20:16,760 --> 00:20:23,210
Right. So we'd really be using this two arm version which all that it really does.

174
00:20:23,570 --> 00:20:30,890
Right, is we can add this allocation ratio and this is just the sample size for one of the arms.

175
00:20:31,100 --> 00:20:33,410
Right. And we have to double it for the total trial.

176
00:20:33,470 --> 00:20:42,980
So this are right is if it were that we're randomizing half half right, the r would be a half if we're randomizing.

177
00:20:44,760 --> 00:20:47,129
2 to 1 right there. You put that in there.

178
00:20:47,130 --> 00:20:55,620
And so that that's that's what we call the allocation ratio so that anybody could be some multiple or some fraction of a B.

179
00:20:57,030 --> 00:21:00,920
So once you get but once you do that one, our sample size right.

180
00:21:00,930 --> 00:21:07,350
Is really easy to get the rest of these. So if you have two arms, it's just that this is for one of the arms we have the allocation ratio.

181
00:21:07,350 --> 00:21:11,640
If you have non constant variance right, then we can't just assume one sigma squared.

182
00:21:12,000 --> 00:21:16,830
We actually have to have the variances of both a the two treatment arms.

183
00:21:17,310 --> 00:21:28,530
Right. And then if you have paired data that we have this correlation between the observations and so that's where this row comes into play.

184
00:21:28,860 --> 00:21:38,310
So what is that correlations? Now if you have paired data alternatively, right, you can take a difference and just use the one sample calculation.

185
00:21:38,640 --> 00:21:46,380
So these will be the same if you take the difference versus actually taking the two observations and using the row.

186
00:21:48,900 --> 00:21:58,889
Okay. So today we're going to first do pull over your questions on some of these and then move on to binary outcomes and talk about Noninferiority.

187
00:21:58,890 --> 00:22:01,260
I had a whole section on time to event outcomes,

188
00:22:01,260 --> 00:22:07,379
but I decided that I'm taking it out because usually when students take this class, they ticket simultaneously with survival.

189
00:22:07,380 --> 00:22:13,380
But that wasn't offered the semester. So most of you probably have zero background in survival.

190
00:22:13,380 --> 00:22:17,100
And so I don't think I'd have to teach you survival and these things.

191
00:22:17,100 --> 00:22:22,589
And that is not happening today. So they're all still there.

192
00:22:22,590 --> 00:22:26,430
All those slides are still there so that if you're interested in looking at it, learning it,

193
00:22:26,430 --> 00:22:31,950
if you want to talk to me about it, if you want to take survival and then ask me questions, happy to do so.

194
00:22:32,280 --> 00:22:37,320
But I don't think it's it's too much for this class alone when you don't have survival.

195
00:22:38,040 --> 00:22:41,549
Some of the class, some of the students don't have survival and still take it.

196
00:22:41,550 --> 00:22:46,770
But usually in this class, most of the people also are in survival in the previous years.

197
00:22:46,770 --> 00:22:49,320
And so it wasn't that many that were left behind. Okay.

198
00:22:50,400 --> 00:22:58,229
So again, I uploaded slightly modified slides for today before class, whereas if you've downloaded them prior to Tuesday,

199
00:22:58,230 --> 00:23:02,580
you're going to see all those slides and now they're all at the end. Okay, so how about this question?

200
00:23:02,580 --> 00:23:05,729
Every trial has 90% power for some treatment effect.

201
00:23:05,730 --> 00:23:24,220
Yes or no? True or false? Okay.

202
00:23:24,320 --> 00:23:30,860
So most people say no. So why does somebody say why does somebody say no?

203
00:23:33,500 --> 00:23:36,940
Why do most of you say no? Anybody want to say? Yeah.

204
00:23:37,390 --> 00:23:43,080
Like the power is something that you specify survive the sun. Uh huh. Few people said yes.

205
00:23:43,380 --> 00:23:48,050
Does anybody who said yes want to be? Brave and say why?

206
00:23:53,970 --> 00:23:57,650
No. I just wanted to be different or different.

207
00:24:01,380 --> 00:24:05,290
Okay. So, yes, I agree with you that power is something that we pre-specified.

208
00:24:05,310 --> 00:24:10,260
Right. However. Right. So we specify the power for some specific treatment effects.

209
00:24:10,770 --> 00:24:15,480
Now, if I actually increase that treatment effect.

210
00:24:15,960 --> 00:24:20,130
Right, I can have. Higher power.

211
00:24:20,520 --> 00:24:24,510
Right. If I decrease that treatment effect, I will have lower power.

212
00:24:25,350 --> 00:24:31,650
Right. So if I. I can change my treatment effect or I can change my type one error, and that will affect power.

213
00:24:32,250 --> 00:24:37,620
So, yes, the trial should be specifically powered for one specific treatment.

214
00:24:38,040 --> 00:24:43,070
However, I can tell you that I have 90% power for this treatment effect.

215
00:24:43,080 --> 00:24:47,490
I have 100%, 99% power for this 100% power.

216
00:24:47,850 --> 00:24:52,200
I have 99% power for this treatment. Fact I have 70% power for this treatment effect.

217
00:24:52,500 --> 00:24:58,620
Once I set my sample size, I can calculate power for across many different treatment effects.

218
00:24:59,040 --> 00:25:04,940
So this should actually be. Yes. So had some of you brave individuals spoken up, right?

219
00:25:04,950 --> 00:25:10,350
That were correct. Hopefully that would have been your reasoning that you can have.

220
00:25:10,860 --> 00:25:16,290
Every trial can have 90% power for some treatment effect. It just probably like it might not be the one that they were powered for.

221
00:25:16,590 --> 00:25:21,220
Right. But say you power the trial, you have 80% power.

222
00:25:21,250 --> 00:25:24,819
Let me let me try to explain then ask your question. Okay.

223
00:25:24,820 --> 00:25:27,320
The power of my trial. I have two arms.

224
00:25:27,340 --> 00:25:38,710
I'm interested in finally having 80% power with 5% type one error defined a standardized treatment effect of point eight right between A and B.

225
00:25:39,610 --> 00:25:52,360
So that's 80% power for that. Now, I could be at 90% powered for finding an even larger treatment effect, 90% power to find those 49%.

226
00:25:52,360 --> 00:25:54,909
I don't know what the actual thing is. Right? I have to get my copy right.

227
00:25:54,910 --> 00:26:02,230
But with the sample size, I have even greater power to find a bigger difference between 315 treatments.

228
00:26:02,590 --> 00:26:07,000
I have lower power to find a smaller difference between treatments.

229
00:26:07,180 --> 00:26:08,440
Right. With that sample size,

230
00:26:09,040 --> 00:26:17,320
remember that we have power type one error sample size and and standardized effect size or difference between treatment and the variance.

231
00:26:17,650 --> 00:26:24,700
And I can change, right for those or I can keep four of them the same and the fifth one change.

232
00:26:24,760 --> 00:26:27,880
Right. So it's the same thing here. So the question.

233
00:26:27,960 --> 00:26:34,020
Yeah. Mean like what if you have like a really poorly designed trial, like someone came to you and said I had two people in my trial, right.

234
00:26:34,270 --> 00:26:39,760
Yeah. Would you still have 90% power for something like insanely huge difference, right?

235
00:26:40,240 --> 00:26:46,930
So yes, you can always calculate as long as you have more than one person, you can calculate power.

236
00:26:46,930 --> 00:26:55,210
It's just going to be that your treatment effect is massive. So it's not it's not realistic, but it's there.

237
00:26:58,800 --> 00:26:59,150
Okay.

238
00:26:59,940 --> 00:27:07,740
I mean, maybe it's realistic if like, there's if these two people are like I mean, it's probably not actually it's the variability, but it's possible.

239
00:27:09,060 --> 00:27:15,630
Okay. How about this one? The in female or the largest lower bound for power of any trial is what?

240
00:27:32,730 --> 00:27:36,030
But for this one too, I have something I want to show you so I.

241
00:27:36,180 --> 00:27:54,910
You can keep voting and I'm not. Pull this out. Look.

242
00:27:56,910 --> 00:28:01,890
She? So let's see what's going on.

243
00:28:01,990 --> 00:28:05,230
Okay. No one knows, right? No one knows. Some people know.

244
00:28:05,250 --> 00:28:09,330
Maybe. But let. Let me. Let's look at this. Okay.

245
00:28:09,480 --> 00:28:13,210
So here's we consider a continuous outcome.

246
00:28:13,230 --> 00:28:16,470
Right. And we have our normally distributed our nice bell curves.

247
00:28:16,950 --> 00:28:22,110
And we have under a null hypothesis that that the the means are equal.

248
00:28:22,470 --> 00:28:26,580
Right. So this is like two treatments. The means are equal. You can assume this is even zero.

249
00:28:26,650 --> 00:28:31,740
Okay. And under the alternative. Right. The alternative is that one treatment is better than the other.

250
00:28:32,460 --> 00:28:37,410
Okay. And look, I have I'm showing you power and green and type one error and blue.

251
00:28:38,640 --> 00:28:41,640
My power is the lowest one.

252
00:28:43,260 --> 00:28:46,560
When? What? What about my alternative or my.

253
00:28:46,680 --> 00:28:54,160
No one's a power. The lowest. When the alternative is true or when the null is true.

254
00:28:55,640 --> 00:29:02,360
The null is true, right? So my power is the lowest when there's actually no difference between treatments.

255
00:29:03,200 --> 00:29:06,860
What's my power? Type one error.

256
00:29:06,890 --> 00:29:14,300
Yep. Right. And my power gets bigger as the difference in treatments gets larger.

257
00:29:14,540 --> 00:29:24,080
Right. But I can never go below my type one error because now the probability that I reject the null,

258
00:29:24,950 --> 00:29:28,639
given that the null is true, right is my type one error.

259
00:29:28,640 --> 00:29:32,990
Whereas the type power is a probability that rejecting the null given that the the null is false right.

260
00:29:32,990 --> 00:29:37,280
Or the alternative is true. So the smallest.

261
00:29:38,730 --> 00:29:42,810
The largest lower bound. Sorry, the largest lower bound for the power.

262
00:29:42,960 --> 00:29:47,970
Right. Is this alpha or the type one error rate, which many of you did say, but many of you had no idea.

263
00:29:49,140 --> 00:29:54,900
And maybe you even just guessed. But that's why. So having that nice like looking at those curves, right?

264
00:29:54,900 --> 00:30:02,040
Looking under your null and under the alternative and thinking about how those treatments differ and what power is versus what type one error is,

265
00:30:02,040 --> 00:30:05,070
that's how you can figure that one out. Okay.

266
00:30:05,970 --> 00:30:11,210
The reason why no trial ever has type one error and type two error rates equal to zero is because.

267
00:30:11,230 --> 00:30:47,410
Why? Okay.

268
00:30:47,500 --> 00:30:50,770
So it would be unethical to enroll patients in such a trial?

269
00:30:51,460 --> 00:30:58,390
I think it'd be great to enroll patients in a trial. Right. You never make errors, but that doesn't exist, right?

270
00:30:59,260 --> 00:31:04,239
Really? If you try to have I think both C and D are correct right there.

271
00:31:04,240 --> 00:31:10,910
They're related that. If you really had no errors, you wouldn't need the entire population.

272
00:31:10,940 --> 00:31:14,480
Right. And even then, you could maybe. Well.

273
00:31:15,780 --> 00:31:19,470
You would need everybody. Right? So this this sample size is infeasible.

274
00:31:19,500 --> 00:31:25,320
And if you think also right, in order to have no errors, right, there can't be.

275
00:31:26,590 --> 00:31:33,130
There can't be variants, right. Or you have to account for all variants of the variants of this test statistic would be zero.

276
00:31:33,550 --> 00:31:38,100
So I think both of these are fine answers. It's generally right, we can't do this.

277
00:31:38,110 --> 00:31:40,990
We have a finite number of individuals that we're working with.

278
00:31:42,580 --> 00:31:46,650
And so there's always the possibility that we make a mistake because we never know the truth.

279
00:31:50,100 --> 00:31:54,780
Okay. Which of the following best? I won't read the scheme.

280
00:32:04,240 --> 00:32:59,730
Seems. Okay.

281
00:33:00,540 --> 00:33:07,919
So you have a fixed experimental arm. Right. That sample size is a it's a sample of the population of this fixed size.

282
00:33:07,920 --> 00:33:12,120
But then you allow for the control arm to get arbitrarily large.

283
00:33:12,720 --> 00:33:17,620
So as the control arm gets larger and larger and larger, right.

284
00:33:17,670 --> 00:33:21,990
Eventually this becomes basically like you absolutely know, the control.

285
00:33:23,250 --> 00:33:27,490
Parameters. Right. And you're still estimating the treatment parameters.

286
00:33:27,750 --> 00:33:36,149
So C is the correct answer. Your power to detect any difference in the treatment effects can't approach one because you're still estimating.

287
00:33:36,150 --> 00:33:42,120
Right the the experimental arm and you don't actually know that it's different from the control arm.

288
00:33:42,660 --> 00:33:46,500
So similarly. Right, you can't always find a difference because what if there is no difference?

289
00:33:48,680 --> 00:33:55,580
So the correct answer is C, it's like going back to your second homework or whatever, right where you are comparing and phase two.

290
00:33:55,610 --> 00:34:04,640
One arm trial two a randomized to arm trial and thinking about the difference in efficiency there.

291
00:34:06,650 --> 00:34:10,490
Okay, this maybe is the last one now. It's like a test today.

292
00:34:10,880 --> 00:34:16,070
All right. Read through these sets. This is a little confusing, but essentially you're trying to figure out.

293
00:34:17,260 --> 00:34:25,230
Given these three things. If all of them is really if all of them are true.

294
00:34:25,270 --> 00:34:27,790
Right. How would that would that increase power?

295
00:34:30,320 --> 00:34:36,740
So say you set power, right for a specific treatment affect, sample size and type one error and then these three things happen.

296
00:34:38,320 --> 00:34:41,860
Which of these B, C, d would actually increase power?

297
00:34:58,100 --> 00:35:03,889
I think intuitively you might get caught up the most on a treatment effect estimate.

298
00:35:03,890 --> 00:35:09,890
So remember, as it increases, that means there's a bigger difference between treatments and as it decreases,

299
00:35:09,890 --> 00:35:17,440
it means that there's a smaller difference between treatments. Which is somewhat, I think, opposite of what you might intuitively.

300
00:35:18,450 --> 00:35:30,990
Think. Okay okay so as the tree so everybody agrees on treatment effects increases.

301
00:35:31,000 --> 00:35:37,299
Okay so that's great. So as a treatment effect increases, there's a bigger difference between the two groups.

302
00:35:37,300 --> 00:35:41,650
And so that would increase the power, right? So again, sample size increases.

303
00:35:41,650 --> 00:35:44,979
Everybody agrees about that. So a sample size. A sample size increases.

304
00:35:44,980 --> 00:35:48,370
That increases the power. Right. We have more people we can find.

305
00:35:48,940 --> 00:35:56,740
We can find differences. Okay. So the question is, is it if type one error decreases or if error variance decreases?

306
00:35:57,130 --> 00:36:03,010
So if type one error decreases, that means that type one error is smaller, right?

307
00:36:03,010 --> 00:36:07,300
You can make less type one errors. So that would not increase power.

308
00:36:07,510 --> 00:36:12,700
Right now, you actually have a harder top.

309
00:36:12,700 --> 00:36:18,400
You can't make as many errors. Right? So you need even like lots more so that that's a no.

310
00:36:18,850 --> 00:36:23,220
So then error variance decreases only the lower variance we have, right?

311
00:36:23,230 --> 00:36:28,840
The more precise we are, the more power we have. So D is the correct answer.

312
00:36:28,960 --> 00:36:33,490
So most of you are. At least you got the treatment effect in the sample size.

313
00:36:33,490 --> 00:36:36,760
It was just the difference between type one error and error variance.

314
00:36:37,810 --> 00:36:46,450
So this is important, right? These questions are getting at how do these different components of sample size play with each other?

315
00:36:46,540 --> 00:36:54,190
Right. How does power affect sample size, effect, type one error effect variance or treatment effect, etc.?

316
00:36:56,990 --> 00:37:00,190
Okay. Maybe this is the last one or this is this is a giveaway.

317
00:37:00,200 --> 00:37:05,300
A sample size goes up. What happens to power? Hopefully it's a give away after last question.

318
00:37:10,950 --> 00:37:15,570
Or else I'm just going to make anyone feel really terrible. Not the attention.

319
00:37:17,670 --> 00:37:22,440
Okay, great. I know what it feels bad you all got right. Okay, good. But you just didn't answer if you're worried about that.

320
00:37:23,040 --> 00:37:28,860
Okay, so a sample size goes up. We have higher power. So the more people we have, the smaller differences we can find.

321
00:37:29,820 --> 00:37:35,430
And this is why it's sort of like an ongoing joke with investigators that statistician statisticians are just saying,

322
00:37:35,430 --> 00:37:38,549
we need more, we need more people, we need a bigger size. Right.

323
00:37:38,550 --> 00:37:42,060
And that's like the ongoing thing is they say, no, no, no, let's do smaller.

324
00:37:42,060 --> 00:37:46,139
And you're like, no. And there's a reason because we want high power, right? So we want high power.

325
00:37:46,140 --> 00:37:49,230
We want to find differences. Oh, my gosh.

326
00:37:49,260 --> 00:37:53,280
Okay. Okay. Last one for real power is what?

327
00:37:56,700 --> 00:37:59,920
This? Definitely. Maybe it's not. Actually, definitely.

328
00:38:00,090 --> 00:38:04,560
Sorry. You could choose A, B or C, now choose.

329
00:38:41,590 --> 00:38:45,870
Okay. So.

330
00:38:47,550 --> 00:38:53,040
I said, it's definitely D, I think it is D So it's a function of an assumed treatment effect and sample size, right?

331
00:38:53,040 --> 00:38:58,319
When you think about the sample size calculation, that's also a formula for power, right?

332
00:38:58,320 --> 00:39:01,530
You can just interchange with one juror signing four. So it is so we got D.

333
00:39:01,770 --> 00:39:09,450
So the question is, is it also A, B or C? So some people think it's A and some people think it's C, D is out.

334
00:39:09,450 --> 00:39:12,230
Right. It's definitely not about a lack of a treatment effect. Right.

335
00:39:12,240 --> 00:39:17,670
It's the power is the probability that you rejects the null given the alternative is true.

336
00:39:17,670 --> 00:39:27,840
Right, or that the null is false. So is it a probability statement about the treatment effect or a probability statement about the null hypothesis?

337
00:39:28,560 --> 00:39:35,670
So it's kind of both, right? Is the probability that you have a treatment effect, right.

338
00:39:36,360 --> 00:39:41,880
That that you're conditioning on the treatment effects that you actually see that treatment effect.

339
00:39:42,840 --> 00:39:52,380
So I think this is actually a bad question because it is a it's a probability statement that you have the specific.

340
00:39:53,540 --> 00:39:56,780
But assuming you have this treatment effects that you've made the right decision.

341
00:39:56,930 --> 00:40:04,730
Right. But you can alternatively say that it's a statement about the null hypothesis, because you're saying that the null you reject the null.

342
00:40:04,880 --> 00:40:09,410
Right. So I think either one of those is fine. So everybody's.

343
00:40:11,900 --> 00:40:15,350
Okay. I won't I'll try not to put questions like that on the test.

344
00:40:16,640 --> 00:40:22,760
All right. Let's move on to the actual content for today. We still have a while.

345
00:40:23,060 --> 00:40:27,170
So we're going to just take all the stuff that you learned on Tuesday with Citi,

346
00:40:27,170 --> 00:40:32,570
with the continuous outcomes, and very nicely see how we can adapt that for binary outcomes.

347
00:40:32,900 --> 00:40:37,100
And then going back to continuous outcomes, what we do in noninferiority trials.

348
00:40:37,100 --> 00:40:41,989
Bless you. Okay. So if we have a binary outcome.

349
00:40:41,990 --> 00:40:46,460
So. Right, yes. No success failure, response, non-response.

350
00:40:47,750 --> 00:40:56,240
And at the end of the trial, we're trying to compare two groups. We've got these wise for one group and X is from another group.

351
00:40:56,720 --> 00:40:59,470
And we can if we have a big enough sample size. Right.

352
00:40:59,480 --> 00:41:06,950
And actually usually for the normal approximation because something like would I forget the rules and decide on an MP?

353
00:41:06,950 --> 00:41:11,690
But usually it's like even greater than like 20. You can use this normal approximation.

354
00:41:11,720 --> 00:41:16,910
We'll see some differences of how we can get better calculations, even with big ends.

355
00:41:17,360 --> 00:41:27,260
But essentially is if you're in the phase three space, you could use this normal approximation such that you can, right?

356
00:41:27,620 --> 00:41:31,490
We're going to assume that our probabilities are actually distributed normally.

357
00:41:31,880 --> 00:41:37,010
And so our null hypothesis here is that the proportions from two groups are the same.

358
00:41:37,010 --> 00:41:40,010
There's no difference between treatments. The proportion of responders is the same.

359
00:41:40,020 --> 00:41:44,540
And B, and the alternative is that there's actually some difference and we'll call it difference Delta.

360
00:41:45,200 --> 00:41:52,970
And you know that, right? If we have binary individual binary outcomes, then our variance is just that P times one minus P.

361
00:41:54,770 --> 00:42:03,559
So if we're going to assume that in large samples we can use this normal approximation and PS are just normally distributed with mean right?

362
00:42:03,560 --> 00:42:10,310
If P one is normally distributed with mean p one and variance P one times one minus p one,

363
00:42:10,640 --> 00:42:14,870
then I can just use my sample size calculation that city showed you.

364
00:42:14,900 --> 00:42:22,120
So if I have to go all the way back here right to groups, right, I can use this calculation.

365
00:42:22,130 --> 00:42:25,640
So now my delta is P one minus P two.

366
00:42:25,640 --> 00:42:30,850
And my variance is if I assume that if you want a p to are not the same, right,

367
00:42:30,860 --> 00:42:39,200
then I can do this p one times one minus p one plus p two times one minus p two.

368
00:42:39,560 --> 00:42:45,180
And if I have equal allocation. Oh, sorry. So if it's equal allocation, R is just one, right?

369
00:42:45,180 --> 00:42:48,440
It's 1 to 1. So this is just one there.

370
00:42:52,300 --> 00:43:00,370
So if I use that right I'm just plugging in now my, my variance p11 minus U on P to one minus P2.

371
00:43:00,370 --> 00:43:04,509
That's the variance. And my delta is just P1 minus P2.

372
00:43:04,510 --> 00:43:11,140
I have my Z one minus alpha and Z one minus beta and I can get 472.5 per group.

373
00:43:11,470 --> 00:43:16,959
So I'm just using a normal approximation. I've just taken the mean and variance from proportions,

374
00:43:16,960 --> 00:43:25,510
plugged it into my equation and I can also do this in R by using the power dot product test code.

375
00:43:27,460 --> 00:43:34,090
Such that here I'm trying to find a difference between 30% and 40% with 90% power and type one error of 5%.

376
00:43:34,720 --> 00:43:37,210
And we can see what pops out.

377
00:43:37,220 --> 00:43:42,670
We're not actually going to right now because I want to show you the difference between if I use a normal approximation versus if I don't.

378
00:43:44,110 --> 00:43:48,760
So the normal approximation is fine. It's it's in large samples.

379
00:43:48,820 --> 00:43:53,440
Binary variables are normally distributed in a phase three space.

380
00:43:53,440 --> 00:43:58,150
That's usually true. However, we can actually do better in terms of our approximation.

381
00:43:58,510 --> 00:44:03,640
And so we'll see very slight differences in the number needed if we use these other approximations.

382
00:44:04,000 --> 00:44:08,260
So there's a number I don't know if you remember one of the one of the lectures

383
00:44:08,680 --> 00:44:13,090
when we were going through the different the sample size of another paper,

384
00:44:13,270 --> 00:44:19,450
I showed you the confidence intervals based on the binary confidence, all based on all these different techniques.

385
00:44:19,450 --> 00:44:25,420
They're all different approximations. So one of them that is better is the Marxian approximation.

386
00:44:25,810 --> 00:44:35,740
And so instead of using P and saying that's normally distributed is actually that the arc sign of the square root of P is normally distributed.

387
00:44:35,750 --> 00:44:39,300
So it's essentially doing like a transformation right on P,

388
00:44:39,310 --> 00:44:45,250
remember if you think about like linear regression and it's not exactly normally distributed, you want to do some transformation.

389
00:44:45,250 --> 00:44:48,520
Like usually it's take the inverse or square root.

390
00:44:48,970 --> 00:44:53,890
So what we actually found or what somebody found, right, is that a better,

391
00:44:54,550 --> 00:45:02,260
a better normal approximation is that you take the arc sign of the square root of P and that's normally

392
00:45:02,260 --> 00:45:07,810
distributed and we can actually use the delta method then to figure out what the variance is.

393
00:45:08,560 --> 00:45:10,480
And I'll show you on the next slide how we get here.

394
00:45:10,900 --> 00:45:18,460
But actually the variance of the square root of n times, the arc sign of the square root of our estimate of proportion is one fourth.

395
00:45:18,760 --> 00:45:21,909
So it actually doesn't matter what the proportion is, right?

396
00:45:21,910 --> 00:45:27,760
It's invariant to the actual proportion, whereas usually the variance of p is p times one minus p,

397
00:45:28,360 --> 00:45:35,800
the variance of the square root of an arc sign of square root of p, it doesn't matter appears is always a quarter or approximately quarter.

398
00:45:37,150 --> 00:45:40,930
And so this is what we call a variance stabilizing transformation.

399
00:45:41,680 --> 00:45:47,559
And so again, if you remember back to linear regression, there are lots of different transformations you can use like box.

400
00:45:47,560 --> 00:45:53,770
COX Right. To figure out different transformations. One reason why you might perform a transformation is to stabilize the variance.

401
00:45:53,770 --> 00:46:01,690
And so this this particular arc sine transformation is to stabilize the variance such that it now doesn't depend on the actual proportion.

402
00:46:02,110 --> 00:46:10,509
It's always a quarter. So now we have our difference in proportions.

403
00:46:10,510 --> 00:46:13,000
Instead of saying we're interested in P one minus P two,

404
00:46:13,030 --> 00:46:18,400
we have the difference in the arc sine of the square root of p one minus the arc sign of the square root of P two.

405
00:46:18,790 --> 00:46:28,899
And that's normally distributed with this right arc sign of the actual population values with variance one over two times.

406
00:46:28,900 --> 00:46:34,150
And so the variance doesn't matter in P, it's just depends on the sample size.

407
00:46:35,380 --> 00:46:40,510
Okay, how do we get there? All of you hopefully have learned the delta method, right?

408
00:46:41,260 --> 00:46:44,020
Yeah. So thinking about again,

409
00:46:44,320 --> 00:46:50,680
what I like about this class is that you learn all these specific things in your 6016 or two and you're like, Why did I learn that?

410
00:46:50,680 --> 00:46:59,200
Right? Like, what was the point of that? This class shows you, Oh, actually, you need these things in order to to do better in trials, right?

411
00:46:59,200 --> 00:47:04,930
So like we needed the Delta method so that we could, we could do better in terms of this approximation,

412
00:47:05,410 --> 00:47:11,980
for this normal approximation, for binary outcomes to find better appropriate sample size for a clinical trial.

413
00:47:12,580 --> 00:47:20,380
So if you recall that she had is an estimate of P with an approximate normal distribution with our

414
00:47:21,490 --> 00:47:27,790
expected value of the difference between P had and P of zero in the variance of times one minus P,

415
00:47:28,150 --> 00:47:33,910
we can use the Taylor series approximation of as a p hat about f of p.

416
00:47:34,270 --> 00:47:43,839
Right? So this is just f a hat is f a p plus f prime of p times that bias right p hat minus p and then there's that's the first order,

417
00:47:43,840 --> 00:47:48,820
Taylor's approximation, if you can go farther, but those are so close to zero, it's not necessary.

418
00:47:49,810 --> 00:48:00,550
So our expected value here, right, of this F of the F prime of P times, the square root of P at minus p zero.

419
00:48:00,910 --> 00:48:08,560
And our variance is this of this is the variance of f prime of p times of squared event and p minus p.

420
00:48:09,280 --> 00:48:13,179
And so what we can see is that the delta method, right?

421
00:48:13,180 --> 00:48:18,620
We're trying to figure out the delta method of like we have the mean and variance of p hat.

422
00:48:18,640 --> 00:48:21,780
How do we find the mean of variance of arc sine square root of eight.

423
00:48:21,850 --> 00:48:26,730
Right? That's where we're using the delta for. How do we use this transformation and still find the mean of.

424
00:48:26,780 --> 00:48:34,300
Variance. And so we got to figure out, okay, well, what's actually the derivative of our sign?

425
00:48:34,340 --> 00:48:38,809
So you have to go back to your first calc test where you had to memorize these things, remember?

426
00:48:38,810 --> 00:48:42,230
And you're like, What? Why would I ever use that ever again? Look, it's here.

427
00:48:42,780 --> 00:48:47,180
Oh, so we have the change rule up here. I'm not going to ask you to do this on a test, but like,

428
00:48:47,210 --> 00:48:56,090
this is the point of why you learned that in high school or college that you actually have to remember what this derivative is and use the chain rule

429
00:48:56,090 --> 00:49:07,309
so that you can figure out now that the derivative of arc sine of square root of P is actually one over two times one over the square root of P,

430
00:49:07,310 --> 00:49:11,240
times one minus P. And we use this, right?

431
00:49:11,240 --> 00:49:15,049
We have to use this derivative of this thing to figure out what exactly the variance is.

432
00:49:15,050 --> 00:49:18,570
And so if you plug that in, right, you do some algebra.

433
00:49:18,590 --> 00:49:23,270
That's how you figure out that the variance is actually a quarter that all those P's cancel out.

434
00:49:23,390 --> 00:49:32,990
So using Taylor's right, using the Delta method, plus your good old calc from a long time ago with the arc sign which you learned in like.

435
00:49:34,150 --> 00:49:40,090
Middle school geometry. I don't know. You put it all together and you figure out that now we don't.

436
00:49:40,090 --> 00:49:46,360
Actually, it doesn't matter what P is. We have this very stabilizing transformation so that the variance is a quarter.

437
00:49:47,770 --> 00:50:00,550
Okay. So if we're now going to use this to sample normal sample size calculation that looks like this, right?

438
00:50:01,000 --> 00:50:05,590
And we're going to input our arc sine P and we have the variance is a quarter.

439
00:50:06,130 --> 00:50:08,980
We get that our sample size is here, right?

440
00:50:08,980 --> 00:50:14,920
So we have our type on error or power, we have our treatment effect, which is the difference in the transformations.

441
00:50:15,310 --> 00:50:20,260
Right. And our variance just very simply, we divide it by a quarter.

442
00:50:20,300 --> 00:50:22,960
We already had it two, so we got it. We got a two down here.

443
00:50:24,340 --> 00:50:33,040
So if we use that now in the same, we want to find a difference between 40% and 30% with 90% power and 5% type one error.

444
00:50:33,430 --> 00:50:42,219
And we use the arc sine transformation instead of having four 72.5, which by the way, you would never report that as your sample size, right?

445
00:50:42,220 --> 00:50:46,660
You can never have half a person. So you'd always say 473 per group.

446
00:50:46,660 --> 00:50:54,220
Okay, always round up, never random. So instead of having 473 per group, now you need 476 per group.

447
00:50:55,180 --> 00:51:04,360
So we got a little bit closer to a normal distribution by using the Arc Ixion transformation which required a few more people.

448
00:51:05,020 --> 00:51:11,640
Okay, so now we have 476 per group. All right.

449
00:51:11,670 --> 00:51:17,510
And if I opened up. Ah, see if you can do this.

450
00:51:21,480 --> 00:51:30,300
So you don't have to have any package to use this powered up propped up test or powered on to test for comparing two means or two proportions.

451
00:51:30,750 --> 00:51:33,959
You can just place it in there, run it.

452
00:51:33,960 --> 00:51:41,790
Oh, you like something? Because the quotes are always a problem when you copy and paste things.

453
00:51:45,860 --> 00:51:52,549
Okay. Right. So when you put it into R, you'll see that we actually get like four 76.00.

454
00:51:52,550 --> 00:51:57,410
So it's much closer to that, our Axion transformation than the normal approximation.

455
00:51:58,160 --> 00:52:06,770
I think this powered up product test is actually using an exact method, but you can see that our cosine transformation got us really, really close.

456
00:52:07,040 --> 00:52:12,350
If I calculated this, I probably still would round up, but if I use this I would say 477 per group.

457
00:52:14,240 --> 00:52:20,450
And then something that we haven't talked about yet is that there's also always

458
00:52:21,350 --> 00:52:25,880
dropout or loss of follow up that usually we account for in sample size calculations.

459
00:52:26,480 --> 00:52:33,379
And it's a little bit of a silly thing because we are going to account for dropout in our sample size calculations,

460
00:52:33,380 --> 00:52:38,060
but then in the analytic plan, we're going to account for missing data by usually imputation.

461
00:52:38,060 --> 00:52:43,040
And so it's a little silly that we're going to inflate our sample size, but also account for missing data.

462
00:52:43,040 --> 00:52:50,810
So some people have very specific views about not doing that, but for the most part and any trial,

463
00:52:51,020 --> 00:52:56,839
if you expect 10% dropout or loss to follow up, you inflate your sample size by that.

464
00:52:56,840 --> 00:53:01,580
So you would take this for 76 per group, which is the little thing.

465
00:53:08,260 --> 00:53:12,670
Or 76. Right. You multiply by two, that's a whole sample size.

466
00:53:13,000 --> 00:53:16,060
And then say you expect 10% dropout,

467
00:53:17,050 --> 00:53:20,860
which you would say you have that because you've done previous trials or other people

468
00:53:20,860 --> 00:53:25,089
have done trials in this population and this many people usually are lost follow up,

469
00:53:25,090 --> 00:53:28,150
right? They just stop and you you divide by.

470
00:53:30,540 --> 00:53:36,680
What's happening now? One minus that drop out rate.

471
00:53:36,820 --> 00:53:46,580
Okay. So you would take that for 76 times to and you divide by 0.9 and that's your actual full sample size.

472
00:53:47,210 --> 00:53:51,490
Right. And this dropout rate is usually between ten and 20% for the most part.

473
00:53:51,500 --> 00:53:57,829
Sometimes it's higher. I actually did a trial where we thought we were going to have 50% dropout, which is not usually ideal.

474
00:53:57,830 --> 00:54:07,010
Right. But it was a blood pressure trial and we thought lots of people would stop complying.

475
00:54:07,970 --> 00:54:14,090
And it was like a face to face to trial. You don't really want that in phase three, but anyway, you always want to.

476
00:54:14,150 --> 00:54:15,560
You usually want to inflate.

477
00:54:15,740 --> 00:54:22,850
Now, if you've taken missing data, if you know anything about imputation, right, usually we'd say hopefully we'll have missing data.

478
00:54:23,060 --> 00:54:27,950
Missing at random data. We can use multiple imputation, in which case you'd get back all that data, right?

479
00:54:28,370 --> 00:54:32,870
You would go from having 10% missing to having back to your end. So why did you inflate your sample size?

480
00:54:32,870 --> 00:54:41,449
But it's just sort of like the expectation that you do this little game of inflating, especially non statisticians will expect to see that.

481
00:54:41,450 --> 00:54:44,720
So we often do that. Okay.

482
00:54:45,830 --> 00:54:54,709
And then since we we went over Noninferiority designs, I just want to give you a reminder of that sample size.

483
00:54:54,710 --> 00:54:58,520
So remember, remember, noninferiority designs are like this.

484
00:54:58,520 --> 00:55:05,809
Treatment can be slightly worse, but not much worse and maybe even better than the previous treatment.

485
00:55:05,810 --> 00:55:13,850
And we'd use this because this new treatment is less toxic or easier to administer or significantly cheaper.

486
00:55:13,880 --> 00:55:18,380
Right. And it's it's almost always this, like, alternative. It's not it's not the same.

487
00:55:18,470 --> 00:55:23,540
Right. This is not a bioequivalence trial. This is there is this alternative treatment in this area.

488
00:55:23,930 --> 00:55:28,820
And we're interested in getting it to patients because it has these other benefits. It can be a little bit worse, but not much worse.

489
00:55:32,230 --> 00:55:36,840
And so. We have to figure out.

490
00:55:36,840 --> 00:55:43,530
So how do we. Right. We have to pick that NONINFERIORITY margin, which is really hard that that delta figuring out what that is.

491
00:55:43,530 --> 00:55:46,380
And then once we pick that, how do we size the trial?

492
00:55:48,310 --> 00:55:58,540
And so if you are actually trying in a superiority court and a superiority context, if the null hypothesis is that there is no difference, right?

493
00:55:58,540 --> 00:56:06,640
An underpowered trial would be wasteful and unethical that you didn't you didn't power, you didn't have enough people to see a difference.

494
00:56:08,950 --> 00:56:11,290
And so you wouldn't you wouldn't want to move forward.

495
00:56:14,380 --> 00:56:20,950
If you're if you have this noninferiority question and underpowered trial would also be wasteful and unethical.

496
00:56:21,220 --> 00:56:24,400
And so you need to make sure that you're not powering for superiority. Right.

497
00:56:24,400 --> 00:56:27,660
Going back to what we said earlier, that you're actually thinking about non-inferiority,

498
00:56:27,670 --> 00:56:36,670
you've chosen the noninferiority margin and you power for non-inferiority in order to say that you found non-inferiority in your trial.

499
00:56:37,750 --> 00:56:44,670
So again, right, we have this non-inferiority margin which here we could assume is like one unit, right?

500
00:56:44,680 --> 00:56:47,320
One one standardized unit of difference.

501
00:56:47,920 --> 00:57:02,860
And if we find that our treatment effect right, the lower bound is to the right of that negative delta, then we can say that we have non-inferiority.

502
00:57:05,420 --> 00:57:08,440
This plot, actually. Sorry, this one. It's to the left.

503
00:57:08,480 --> 00:57:11,540
This plot is flip flopped from the plots we've usually looked at.

504
00:57:11,750 --> 00:57:18,170
Right. The test drug is better is on the left as opposed to for the most part, it's been on the right.

505
00:57:18,620 --> 00:57:21,680
So in this one, we actually need to see the.

506
00:57:23,200 --> 00:57:27,629
It's different. The lower bound is not not passed.

507
00:57:27,630 --> 00:57:31,650
The right right has to be to the left because this this one is flip flop.

508
00:57:31,660 --> 00:57:37,320
So that not that inferiority is actually all the way to the right and superiority is always left.

509
00:57:40,630 --> 00:57:51,810
Okay. Okay. So say we have our outcomes from this experimental therapy, which we're going to call treatment A, we're going to call those outcomes Y.

510
00:57:52,200 --> 00:57:56,170
And then we have outcomes from the standard of care, not placebo.

511
00:57:56,190 --> 00:58:00,120
Right. From standard of care, some other active treatment. And we're going to call those all X's.

512
00:58:00,600 --> 00:58:08,969
So I've used a lot of times in the in this whole lecture, X's and Y's is outcomes as opposed to what we're normally seeing,

513
00:58:08,970 --> 00:58:14,340
which is why is outcome and X is a covariate is just trying to show you that there are two different treatment groups, right?

514
00:58:14,370 --> 00:58:17,519
It doesn't. These are not covariates for these people.

515
00:58:17,520 --> 00:58:27,810
These are from some treatment. B so we want to establish an average response is no more than delta in favor of the standard RB.

516
00:58:30,120 --> 00:58:35,850
So we have our null hypothesis. Remember, the null hypothesis here is not that there is no difference.

517
00:58:35,880 --> 00:58:39,720
So the big difference in noninferiority trials is not that new.

518
00:58:39,720 --> 00:58:46,290
A minus movie is zero, right? It's that new. A minus movie has to be less than Delta.

519
00:58:47,560 --> 00:58:51,820
And that mu a minus movie has to be greater than or equal to.

520
00:58:51,820 --> 00:59:01,020
Delta is the alternative. Though we can't go beyond that negative non-inferiority margin, we have to be better than it.

521
00:59:02,250 --> 00:59:13,650
So our test statistic. Looks just like essentially it would in this two arm space and a two arm comparison.

522
00:59:15,330 --> 00:59:21,850
And here. Right. We're assuming that there's the same variance between the two treatments, A and B,

523
00:59:21,870 --> 00:59:28,140
we could similarly write we could create this this self sample size calculation as if they had different variances.

524
00:59:29,310 --> 00:59:33,930
You would have sigma squared, a cure rate or sigma A and sigma be here.

525
00:59:35,190 --> 00:59:39,120
So the difficulty, remember again, is choosing that delta. That's a non-inferiority margin.

526
00:59:39,120 --> 00:59:44,669
So it can't be so big that you're actually doing a lot worse than the standard of care.

527
00:59:44,670 --> 00:59:52,260
You want to be very similar to the standard care just a little bit, potentially allow a little bit worse.

528
00:59:53,580 --> 01:00:01,440
So for example, suppose we have a treatment with a 30% response rate and that we'd allow.

529
01:00:01,770 --> 01:00:07,260
So that's the standard of care, right? 30% response rate. And this new treatment comes on and we'd let it be 5% lower.

530
01:00:07,920 --> 01:00:11,430
Okay. So the new response rate has to be at least 25%.

531
01:00:12,180 --> 01:00:18,900
So we'll allow this delta, right, is 5%. We allow it to be as big as 5%, but no bigger.

532
01:00:19,830 --> 01:00:21,570
So how do we figure out this power?

533
01:00:21,900 --> 01:00:29,729
So I'm using the normal approximation here because we have these the proportions even though we learn the arcs line transformations better.

534
01:00:29,730 --> 01:00:38,670
I'm just showing you the normal approximation. So have the variance is p times one minus p and I'm using that of the standard of care and assuming the

535
01:00:38,670 --> 01:00:51,390
variance is the same for the experimental treatment and I have my I want 90% power and a type one error of 5%.

536
01:00:51,990 --> 01:00:57,600
And so if you remember the non-inferiority design, right, it could actually be a one sided hypothesis.

537
01:00:58,710 --> 01:01:07,530
And so if I have a 5% type one error I can actually use this little table has type one error and type two error,

538
01:01:07,770 --> 01:01:11,550
but this type one error is actually based on if it's two, if it's a two sided test.

539
01:01:11,790 --> 01:01:15,720
So if I say I need 5% type one error. I'm getting this little 8.6.

540
01:01:16,230 --> 01:01:30,200
That's my. Critical values of a 5% two sided Z value, plus the power critical value, it's actually 8.6.

541
01:01:30,220 --> 01:01:33,640
So I'm just doing this little math calculation that's squared, right?

542
01:01:33,640 --> 01:01:39,310
I'm just doing this little calculation in this table. So if I have a one sided, it's a one sided 10%.

543
01:01:39,430 --> 01:01:44,020
Right. Or a two sided card. Tuesday, a51 sided 5%.

544
01:01:44,050 --> 01:01:47,800
Two sided 10% test. Right. I get this level.

545
01:01:47,800 --> 01:01:56,740
And so I see that a noninferiority design with a noninferiority margin of 5%, I need 100 and 1445 per group.

546
01:01:56,830 --> 01:02:02,920
So it's a very large trial to see that this that these treatments are not inferior

547
01:02:03,130 --> 01:02:06,430
or the treatment is not inferior to the control or the standard of care.

548
01:02:08,310 --> 01:02:11,700
Okay. So here's an example from literature.

549
01:02:12,570 --> 01:02:15,870
This is something that you would be doing for your homework, right?

550
01:02:15,900 --> 01:02:19,290
You could choose a non-inferiority design. You get this paper.

551
01:02:19,320 --> 01:02:23,100
You can actually choose this one. Okay. I don't use this one doing class.

552
01:02:23,800 --> 01:02:27,300
This is something that you could do, right? This is like what you can look at.

553
01:02:27,660 --> 01:02:31,260
I will assume for your homework. If you haven't already done this, you go to Google Scholar.

554
01:02:31,650 --> 01:02:34,670
You put in phase three to our trial.

555
01:02:34,680 --> 01:02:42,270
You can say superiority, non-inferiority. You could even say something like proportion or continuous or something.

556
01:02:42,280 --> 01:02:48,719
Right. Search. Click on song. You might even want to just go straight to like JAMA or New England Journal of Medicine.

557
01:02:48,720 --> 01:02:52,980
Search in there, find it, find a paper. And that's that's how you'll find your paper.

558
01:02:54,120 --> 01:03:04,830
Okay, so this one was a noninferiority trial looking at these two treatments for treating some sort of fungus.

559
01:03:05,340 --> 01:03:15,989
And so they they say that they needed to own roughly 255 patients for 80% power so that the upper limit of the 95% confidence

560
01:03:15,990 --> 01:03:25,380
interval would show their prespecified non-inferiority margin was that there was a 10% or less difference between these two,

561
01:03:25,830 --> 01:03:30,870
and they assumed that there was a 20% mortality rate for both drugs.

562
01:03:30,910 --> 01:03:35,250
Okay. So how do we take all this information? 80% power easily.

563
01:03:35,310 --> 01:03:40,050
Right. And then we have an upper limit of a 95% confidence interval.

564
01:03:40,290 --> 01:03:44,549
And so then we actually need to think about if it's 95% confidence or.

565
01:03:44,550 --> 01:03:50,280
All right, the upper limit, use that 97.5 alpha criteria.

566
01:03:50,310 --> 01:03:53,790
Right. So that's where we're getting this. This is the alpha one minus of over two.

567
01:03:54,540 --> 01:04:01,020
And this is the power, 80% power. Our non-inferiority margin that delta is 0.1.

568
01:04:01,680 --> 01:04:05,370
Right. And the the.

569
01:04:06,430 --> 01:04:15,549
We look back here. This, this, this stuff right to P times one minus P, that's at variance.

570
01:04:15,550 --> 01:04:18,790
And we're getting that from this 20% mortality rate.

571
01:04:19,390 --> 01:04:22,900
Right? We needed that to calculate the variance. So we get P point two times.

572
01:04:22,900 --> 01:04:24,310
One minus P is point eight.

573
01:04:25,060 --> 01:04:36,280
So if we put this and I took the ceiling, right, because we always round up, then I get that I need 252 participants and they had 255.

574
01:04:36,280 --> 01:04:37,599
Right. So we get about the same.

575
01:04:37,600 --> 01:04:46,899
So if I were writing up my homework, I would say, you know, this is what this I would essentially say this stuff right down here, right?

576
01:04:46,900 --> 01:04:51,070
This is what they're trying to do. Here's how I try to match it. I basically matched it.

577
01:04:51,070 --> 01:04:57,330
It was really close, you know, probably just some rounding or maybe the fact that I used a normal approximation for for my

578
01:04:57,330 --> 01:05:03,010
a proportion and maybe they use the arc sign or exact method and that's how they got to 55,

579
01:05:03,280 --> 01:05:07,390
right? So that's the kind of thing that I'm looking for in your in your homework.

580
01:05:09,170 --> 01:05:17,180
Here's one that I can't match. So here's an example where you might find an article and you just try as you may, just cannot match the sample size.

581
01:05:18,050 --> 01:05:25,610
So this is a Phase three NONINFERIORITY trial where it's actually two separate studies.

582
01:05:26,450 --> 01:05:30,210
And they say that they are interested in the two sided 95% confidence interval.

583
01:05:30,230 --> 01:05:37,970
They need 840 patients in each study to have at least 95% power, that the overall response rate,

584
01:05:38,190 --> 01:05:48,290
85% for viral suppression at week 48, that they're noninferior to this 85% by a noninferiority margin of 12%.

585
01:05:48,370 --> 01:05:54,860
Right. So they're actually allowing this new treatment to be 12%, up to 12% worse, but not worse than that.

586
01:05:55,490 --> 01:06:00,660
So if I were going. To calculate this.

587
01:06:02,100 --> 01:06:07,559
Where is the first calculation? Okay, so here I'm going to calculate this.

588
01:06:07,560 --> 01:06:10,560
I'm putting it into my normal approximation, right?

589
01:06:10,560 --> 01:06:15,510
So I'm getting that variance, that 85% viral suppression.

590
01:06:15,510 --> 01:06:20,999
So P times one minus P. Here I have my non-inferiority margin of 0.12.

591
01:06:21,000 --> 01:06:27,629
I want a 95% power and a two sided confidence interval, 95% confidence interval.

592
01:06:27,630 --> 01:06:32,520
So I actually get a sample size of 230 per.

593
01:06:35,880 --> 01:06:44,190
So I got the samples at the 230, they got a sample size of four, 420 per start, 840 and each day for 20 per group.

594
01:06:44,640 --> 01:06:50,420
Right. And I'm actually getting to 33 so that's way off like almost a factor of two off.

595
01:06:50,640 --> 01:06:55,560
Right. So it's, it's a little weird. So I'm trying to figure out what did they do different.

596
01:06:55,890 --> 01:07:00,090
So I use the actual binomial variance, right, based on that 85%.

597
01:07:00,090 --> 01:07:08,590
But what if they use the maximal binomial variance rate? The maximum variance you can have with the binomial variable is if P is point five.

598
01:07:08,610 --> 01:07:12,569
So if I plug point five in here, I get 454 group.

599
01:07:12,570 --> 01:07:17,520
So this is a lot closer. So I expect about 420, I get 450.

600
01:07:17,520 --> 01:07:26,010
So somehow right there assuming some way larger variance than I would have expected, given they're 85%.

601
01:07:27,010 --> 01:07:31,080
Population. So in my write up of this, I tried to match it.

602
01:07:31,090 --> 01:07:32,200
I was way off.

603
01:07:32,800 --> 01:07:40,660
If they assume maximal variance, I get closer, although actually I'm a little bit higher and like maybe you don't necessarily have to go this far,

604
01:07:40,690 --> 01:07:44,860
but like this is a me doing extra stuff to be like what's how is this so off, right?

605
01:07:45,190 --> 01:07:52,269
So if I this is, this is actually performing like a simulation, right?

606
01:07:52,270 --> 01:07:52,719
It says, well,

607
01:07:52,720 --> 01:08:04,480
what if I have for 20 like they said and in the arm a in R&B and I'm going to run 2000 of these iterations my true under the null write my

608
01:08:04,480 --> 01:08:13,150
true mortality rate for treatment A and treatment B is the same 85% and I have this non-inferiority boundary of 12% I want to figure out.

609
01:08:13,150 --> 01:08:14,980
Right, I'm going to simulate all the data from ARM.

610
01:08:15,370 --> 01:08:21,550
So this is give everybody in our mail for 20 people in our may figure out what was their mortality rate.

611
01:08:21,590 --> 01:08:28,600
Right. I'm taking from the binomial distribution I'm simulating for 20 people and I'm saying the true mortality rate is 85%.

612
01:08:28,630 --> 01:08:33,730
Tell me what it is. Right? Did these people die or not going to do the same thing for R&B?

613
01:08:34,180 --> 01:08:41,290
I'm going to calculate my mean probabilities of mortality in each group and I'm going to figure out how often.

614
01:08:41,470 --> 01:08:45,700
Right. I actually see that that margin is less than 12%.

615
01:08:45,940 --> 01:08:53,740
So I'm going to calculate my power. How often do I say that these things are non inferior and actually it's almost 100% right.

616
01:08:53,980 --> 01:08:57,610
So they will in 95% power.

617
01:08:57,610 --> 01:09:03,540
And yet with their numbers for 20 per group, I actually get 99.8% power.

618
01:09:04,270 --> 01:09:08,920
And if I look at the average width of the confidence interval which remember should be like the non-inferiority margin,

619
01:09:09,100 --> 01:09:15,940
right, because I am allowing the confidence interval to go down point one, two, that's actually smaller, right.

620
01:09:15,940 --> 01:09:19,030
Instead of 12% there with is 10%.

621
01:09:19,690 --> 01:09:23,319
So I don't know what they did or how they got that and maybe they just inflated

622
01:09:23,320 --> 01:09:26,500
the sample size based on some amount of dropout and they didn't tell us.

623
01:09:27,010 --> 01:09:31,750
But clearly, if I try to get it, I get way higher power with the number that they specify.

624
01:09:32,200 --> 01:09:36,759
Okay. So this is the kind of thing that I would that I would write up this send these checks is

625
01:09:36,760 --> 01:09:41,320
maybe extra stuff that I don't expect you to do because not all of you are familiar with.

626
01:09:41,920 --> 01:09:44,530
You've gotten a little practice, but not a lot with running simulations.

627
01:09:45,190 --> 01:09:53,540
But this is the kind of thing I do if I am consulting on a grant or if somebody else ran some calculations.

628
01:09:53,570 --> 01:09:57,460
Now I'm coming in as a biostatistician. I'm trying to figure out what the sample size is.

629
01:09:57,970 --> 01:10:00,640
I try to calculate it if it doesn't match. I'm trying to figure out why.

630
01:10:03,160 --> 01:10:09,399
And so if we actually use our calculation this two 3231 per group, what if it's just 230 per group, right?

631
01:10:09,400 --> 01:10:17,410
Do the same thing. We get that we have 95% power with this average with of a confidence interval just slightly above 0.12.

632
01:10:18,160 --> 01:10:22,209
Right. And so we're much closer, not surprisingly.

633
01:10:22,210 --> 01:10:26,830
So you use the calculation to what we would expect, then there are massive sample size.

634
01:10:27,370 --> 01:10:30,819
So it's a little confusing. Like if I were reviewing this article, right?

635
01:10:30,820 --> 01:10:34,060
If this article was not yet published and I reviewed it, I would probably write back.

636
01:10:35,020 --> 01:10:39,969
There needs to be some extra explanation about the sample size because I can't match this thing.

637
01:10:39,970 --> 01:10:48,490
I see that there's much higher power than given, you know, did they not did they account for some messiness that they didn't say, okay.

638
01:10:48,970 --> 01:10:52,550
And then. We solve, you still have 10 minutes.

639
01:10:53,870 --> 01:11:03,079
So in terms of sample size, again, we already talked a little bit about this of the allocation ratio being equal versus not.

640
01:11:03,080 --> 01:11:06,590
So we talked about that when we talked about randomized phase two designs.

641
01:11:07,220 --> 01:11:11,060
Remember that we have of that,

642
01:11:11,060 --> 01:11:19,250
the effect size estimate is going to be the most efficient or we're going to have the lowest variance when we have equal randomization.

643
01:11:19,250 --> 01:11:28,860
So half, half if we have two treatments, 1 to 1 randomization, the more we imbalanced randomization, the less precise estimates we get.

644
01:11:28,880 --> 01:11:35,810
And so power is going to decrease. However, we talked about that like it's not a massive decrease necessarily.

645
01:11:35,810 --> 01:11:46,459
And so, for example, right, this is assuming a fixed end at this fixed and I have 95% power to find this difference.

646
01:11:46,460 --> 01:11:53,480
Delta six delta between treatments. Now, if I decide instead of randomizing 1 to 1, I'm going to randomized 3 to 2.

647
01:11:53,480 --> 01:11:56,600
So there's going to be more participants in that first treatment arm.

648
01:11:57,320 --> 01:12:02,960
Right. My power goes down to 94%. So it's just a slight decrease in power for this unequal randomization.

649
01:12:03,500 --> 01:12:08,660
But the more unequal the randomization, the bigger decrease in power.

650
01:12:09,020 --> 01:12:15,920
So once I get to like 3 to 1, right, I'm now down to 88% power in this case, my power is high.

651
01:12:16,130 --> 01:12:23,720
Right? Regardless, whatever I chose for this delta, in this end, I still have really high power regardless of this randomization ratio.

652
01:12:23,720 --> 01:12:32,020
But you can imagine, right, that if you. If I started where the power was 80% for this 1 to 1.

653
01:12:32,230 --> 01:12:33,879
And now I'm showing you the decrease. Right?

654
01:12:33,880 --> 01:12:40,210
I'm going below 80% in power for this trade off in terms of getting more people on one treatment than another.

655
01:12:41,770 --> 01:12:49,180
So there are a bunch of reasons that we discussed when we talked about phase two of why you would have different allocation and why you wouldn't.

656
01:12:49,210 --> 01:12:55,570
So one of the reasons remember why we wouldn't is that that concept of equipoise at the beginning of the trial,

657
01:12:55,570 --> 01:13:01,960
you're not supposed to know which treatment is better. So if you don't know extreme is better, why would you put more patients on one treatment?

658
01:13:02,200 --> 01:13:10,630
Right. So that's a little funny. However, there are reasons why you might want to put more treatment, more people on one treatment,

659
01:13:11,200 --> 01:13:19,270
and that might be because if you have actually like pretty good data about the standard of care.

660
01:13:19,660 --> 01:13:28,120
And so you don't need you don't necessarily need to put as many individuals on that standard of care because you have pretty good historical data.

661
01:13:28,120 --> 01:13:33,920
And so you just want some concurrent controls to make sure that your previous estimate was correct.

662
01:13:34,240 --> 01:13:39,910
Right. And you think more people will actually enroll in your trial if you put more people in that new experimental therapy?

663
01:13:39,910 --> 01:13:43,420
That's one reason why you would do that.

664
01:13:44,890 --> 01:13:51,969
It could be that actually you go the opposite way that you put more people on the control as opposed to the new experimental therapy.

665
01:13:51,970 --> 01:13:57,730
If that new experimental therapy is really, really expensive or is limited,

666
01:13:58,060 --> 01:14:04,260
you might try to get actually potentially more precision because you're limited in the number you can have on the treatment.

667
01:14:04,270 --> 01:14:07,810
You can get more precision if you put more people in control.

668
01:14:08,740 --> 01:14:11,410
And so that might be a reason why you kind of switch that.

669
01:14:12,250 --> 01:14:21,490
But for the most part, we see equal randomization and we'll talk about changing that allocation ratio adaptively in future lectures.

670
01:14:23,380 --> 01:14:28,690
But the important thing to know here is that generally equal randomization is going to be the most powerful.

671
01:14:28,690 --> 01:14:36,340
And as you change that allocation ratio, you're going to have less power to detect that treatment effect for which you originally size the trial.

672
01:14:38,860 --> 01:14:45,790
Alternatively, right, if you have performance before you start the trial, you decide to change the allocation ratio.

673
01:14:45,790 --> 01:14:51,130
So that's an imbalance you're going to need more people than had you just on equal randomization, right?

674
01:14:51,760 --> 01:15:00,070
Okay. And so really sample size is a balance between.

675
01:15:00,310 --> 01:15:05,980
So ideally sample size is like we've looked at the literature, this is what Delta is effective.

676
01:15:06,250 --> 01:15:12,880
This is the type one error and the type two error that is most appropriate for this area based on the disease setting, etc.

677
01:15:13,240 --> 01:15:16,760
Okay. This is the the difference that we expect in the variance.

678
01:15:16,780 --> 01:15:22,090
Tell me the sample size and the statistician comes back 5000 and the person's like, whoa.

679
01:15:22,230 --> 01:15:31,660
Oh, right. So ideally, you have all this based on science and it's very rooted in like all the literature and expectations.

680
01:15:31,930 --> 01:15:35,470
But unfortunately, the reality of it is that we have limited resources.

681
01:15:35,770 --> 01:15:42,129
And so while that might be the first step, you're often having this like balance between what would you really like,

682
01:15:42,130 --> 01:15:47,530
what you have evidence for, you know, what would make the most sense versus like what can you actually afford and do?

683
01:15:47,800 --> 01:15:52,930
And trying to figure out how those can best go together so that you're not going to come down so much,

684
01:15:52,930 --> 01:15:56,050
that you never find the difference and waste people on the trial.

685
01:15:56,380 --> 01:16:03,340
But how can you hopefully, you know, figure out what is an acceptable sample size that you could actually accrue,

686
01:16:03,370 --> 01:16:07,809
get knowledge and still make a difference in clinical care? So it's often this balance.

687
01:16:07,810 --> 01:16:14,080
We don't want to think about these things as like tuning parameters just to change to whatever, to make it a sample size that's feasible.

688
01:16:14,440 --> 01:16:24,100
But you usually it's this dynamic process of going back and forth to settle on what makes the most sense also.

689
01:16:25,030 --> 01:16:33,820
So you can imagine, right, we have this power type on error effect size, the variance of that effect and a sample size.

690
01:16:34,120 --> 01:16:38,680
Right. We have to make a lot of assumptions. We have to make assumptions on effect size and the variance especially.

691
01:16:39,070 --> 01:16:47,350
And those are usually not rates, right. So in all cases, sample size is a total estimate is never exactly right.

692
01:16:47,470 --> 01:16:51,910
Right. It's always an estimate. So usually instead of just giving one sample size,

693
01:16:52,420 --> 01:16:59,649
we actually give like a table of sample sizes and or we show the sensitivity of our sample size to various measures,

694
01:16:59,650 --> 01:17:03,190
various standard deviations or variances, various treatment effects.

695
01:17:04,180 --> 01:17:16,780
And so often in a protocol or a grant application, we would show a power table as opposed to just like this sample size has this power.

696
01:17:19,360 --> 01:17:24,070
And then again, we'll talk about when we talk about adaptations or adaptive design.

697
01:17:24,250 --> 01:17:29,830
There are there is the possibility that we can actually change the sample size as the trial goes on.

698
01:17:30,280 --> 01:17:37,210
And it's only such that we can increase the sample size so we cannot start the trial and then decrease the sample size.

699
01:17:37,630 --> 01:17:42,760
But usually what happens is that we don't usually often we don't have a good estimate of the

700
01:17:42,760 --> 01:17:46,300
variance of the treatment effect or the variance of the difference in the treatment effect.

701
01:17:46,720 --> 01:17:54,070
And so we can start running the trial, look at the data, get the updated variance calculation, and then recalculate our sample size.

702
01:17:54,550 --> 01:18:01,960
And usually what happens is that we start with a smaller expected variance, and the variance is actually larger or very our sample size can increase.

703
01:18:03,640 --> 01:18:08,680
And then like I explained before, we typically inflate our sample size for drop out or loss of follow up.

704
01:18:08,980 --> 01:18:12,300
That's just sort of like an expectation. Okay.

705
01:18:12,310 --> 01:18:19,600
I'm going to start with those few. No, I'm just going to tell you, because we have 2 minutes and I'm not going to be here Tuesday.

706
01:18:19,780 --> 01:18:25,390
So the one other thing I want you to take away from power, great power, is something we calculate ahead of the trial.

707
01:18:25,720 --> 01:18:35,770
If you now are at the end of a study, whether it's observational study and or trial, and you've already gone through and calculated analysis,

708
01:18:35,770 --> 01:18:41,140
got an a p value and somebody says, Oh, what was the power for that effect that you found?

709
01:18:41,170 --> 01:18:43,120
You just say, That's ridiculous. I'm not doing that.

710
01:18:43,900 --> 01:18:50,200
You don't calculate post-hoc power because it just depends on what your test statistic was and your sample size.

711
01:18:50,200 --> 01:18:55,000
And so you're not actually giving any more information than the p value from your analysis.

712
01:18:56,290 --> 01:19:04,299
And so you don't you don't actually want to go back and calculate any kind of post-hoc power calculations.

713
01:19:04,300 --> 01:19:07,780
And I see this most often on journal articles.

714
01:19:08,020 --> 01:19:15,790
So people will submit, you know, they looked at retrospective data or they had some pilot of data or something or even in trial,

715
01:19:15,790 --> 01:19:19,000
and they didn't get to this the effect size they expected.

716
01:19:19,420 --> 01:19:25,149
But they found that the estimate was, you know, whatever journal reviewers who are not.

717
01:19:25,150 --> 01:19:30,250
So Sessions mainly will comment well what was your power for finding that difference, right?

718
01:19:30,250 --> 01:19:32,530
Or what was your power for whatever you found?

719
01:19:32,660 --> 01:19:38,080
And that's hard because sometimes, especially the clinical investigators will say, well, just calculate the power.

720
01:19:38,440 --> 01:19:42,759
You need to come back with something like, No, that's stupid. I'm not doing that. It's not meaningful, right?

721
01:19:42,760 --> 01:19:46,870
And you can even say like, I'm not going to give you that. I give you the confidence intervals.

722
01:19:46,870 --> 01:19:52,509
That's all the information, you know. And if you want to read more about it, these are three references,

723
01:19:52,510 --> 01:20:01,480
especially how to say that power is irrelevant in interpreting completed studies or power is not not needed, right?

724
01:20:01,490 --> 01:20:06,969
It's not useful after you've also after you've actually analyzed the data, right?

725
01:20:06,970 --> 01:20:13,720
You're just going in a circle. I'm giving you a p value that already has the information in it that you would have for power.

726
01:20:13,720 --> 01:20:17,440
And so it's no longer necessary. Okay.

727
01:20:17,440 --> 01:20:23,290
So just if you ever get that question, come back to this lecture and just like copy these three references,

728
01:20:23,320 --> 01:20:29,890
go read them and then give them to the person. I've done this. I would say at least four times in the last ten years.

729
01:20:30,310 --> 01:20:34,180
When people come back to me and ask for this and I've say no, and I've also given it to my husband,

730
01:20:34,180 --> 01:20:38,919
who's in psychology, he's gotten the same requests and I say, No serial references.

731
01:20:38,920 --> 01:20:44,290
Send it back. Don't do that. It doesn't mean anything. So star this page, right?

732
01:20:44,290 --> 01:20:48,579
You actually will likely well, depending on where you go, you might actually need this.

733
01:20:48,580 --> 01:20:52,180
It might be useful. And also I recommend I put these as recommended readings.

734
01:20:52,630 --> 01:20:56,530
They're all like 1 to 2 pages super fast.

735
01:20:56,530 --> 01:21:04,239
So I recommend these readings as well. Okay. So that sample size on Tuesday, again, I won't be here.

736
01:21:04,240 --> 01:21:07,480
Mari will be here is all about putting this in action.

737
01:21:07,630 --> 01:21:12,640
So getting more experience with calculating sample size and also I think randomization.

738
01:21:14,560 --> 01:21:19,060
And then I'll be back on Thursday and I don't remember what we talked about.

739
01:21:19,090 --> 01:21:24,370
The fun part how great rest of your week and I will see you.

740
01:21:25,630 --> 01:21:27,070
Hopefully I'll see you at the town hall.

741
01:21:27,070 --> 01:21:35,780
By the way, everyone, you have a town hall today at three and to discuss issues, whatever you want to talk about.

742
01:21:35,780 --> 01:21:40,170
So it's like we're going to go through some questions and then you can raise issues that you have with the heart.

743
01:21:40,450 --> 01:21:43,659
Problem is just a charitable element to find some solutions.

744
01:21:43,660 --> 01:21:51,620
So I recommend that you. Looks like at least one of these.

745
01:21:55,760 --> 01:22:29,300
Oh, yeah. If you didn't get your test the last time I have them up here, they're probably 133 because there wasn't one yesterday.

746
01:22:30,260 --> 01:22:33,560
Join us tomorrow. Oh, no, no, no.

747
01:22:33,700 --> 01:22:53,080
Actually, it's not just the same time I was doing that long ago.

748
01:22:54,920 --> 01:23:05,960
So I don't think I'm going to be like, oh my.

749
01:23:12,020 --> 01:23:20,630
Because I was thinking I thought it'd be a lot of doing work at work.

750
01:23:21,300 --> 01:23:24,610
Yeah, yeah, yeah.

751
01:23:28,280 --> 01:23:31,549
I saw myself. I did finally.

752
01:23:31,550 --> 01:23:37,370
Like I said, I haven't. So I didn't think it was hard for tonight.

753
01:23:37,490 --> 01:23:45,860
Exactly. For me to finish after one year because I only finish half of the homework so supposed to do yesterday.

754
01:23:46,250 --> 01:23:52,780
But I think I got through. I didn't want to read my mail about it, too.

755
01:23:53,090 --> 01:24:00,980
I have to say I was working my.

756
01:24:11,780 --> 01:24:31,050
Yeah. You know. Involvement.

757
01:24:33,520 --> 01:24:40,820
But. Yeah, well.

