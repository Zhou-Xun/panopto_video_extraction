1
00:00:01,710 --> 00:00:08,840
Somebody is really going to have to come in here.

2
00:00:10,430 --> 00:00:30,810
GIULIANI And they're always going to sit back and look at the man that was so bad.

3
00:00:35,400 --> 00:00:40,230
I was like, Oh, man, I'm just like that.

4
00:00:42,150 --> 00:00:52,500
Well, I mean, I don't think how could I respond?

5
00:00:54,360 --> 00:00:58,790
Why can't I know? And I think that's something I did not know.

6
00:00:59,160 --> 00:01:04,050
Yeah, I think so.

7
00:01:04,150 --> 00:01:29,250
Actually, I went to grad school because I was getting back then this semester.

8
00:01:33,150 --> 00:01:43,980
I want to pick his brain cells through it.

9
00:01:44,430 --> 00:01:56,640
Yes. Hello. I'm going to get mad at you.

10
00:01:58,070 --> 00:02:06,710
Oh, it's over. Let's go inside.

11
00:02:08,310 --> 00:02:12,900
Oh, I can open my mouth and my face.

12
00:02:14,370 --> 00:02:19,020
What do you think would happen?

13
00:02:19,130 --> 00:02:36,910
You know, if I was in my neck with you and I like just being taken.

14
00:02:37,800 --> 00:02:43,510
Yeah. But I'm like, I.

15
00:02:48,080 --> 00:03:03,540
Yeah, I. I was like, you know, like, I don't even think I what we want to say.

16
00:03:04,350 --> 00:03:10,740
There are so many things I go through.

17
00:03:14,850 --> 00:03:26,190
What I was trying to do was like, okay, tell me it's going to be uncomfortable.

18
00:03:27,300 --> 00:03:37,680
So I was like, Oh my God, I wasn't with you.

19
00:03:41,520 --> 00:03:49,800
So yeah. So that's like, we're doing something which really hasn't been part of the security.

20
00:03:50,520 --> 00:04:00,660
Oh, really? Yeah. I mean, like when I said, how about how you're going to do.

21
00:04:02,370 --> 00:04:10,590
Like I said, I'm just.

22
00:04:10,600 --> 00:04:18,110
I'm not like that.

23
00:04:25,860 --> 00:04:37,290
Of course I'm all right. It's just I feel bad about it inside on a day like this.

24
00:04:40,110 --> 00:04:45,330
But unfortunately, we are here to make the best we can, Dad can with natural sunlight.

25
00:04:48,300 --> 00:04:59,880
I am almost done grading the assignments from the decision details on a few sort of general comments of.

26
00:05:00,760 --> 00:05:08,500
Before I get back to you, there's a couple things that seem to be the things that people struggle with.

27
00:05:09,580 --> 00:05:15,550
So let me just pass them on more generally so that you're aware of what it is that is concerning.

28
00:05:18,490 --> 00:05:31,120
But probably the most common thing is a failure to give concrete probabilities for any side effects or risks.

29
00:05:31,660 --> 00:05:38,350
Simply listing that something could occur is not the same thing as giving somebody a sense as to how likely it is.

30
00:05:39,610 --> 00:05:42,850
There's a lot of that in the marketing for health things.

31
00:05:43,420 --> 00:05:47,260
That's part of the problem is that, you know, we think about drug ads.

32
00:05:47,740 --> 00:05:52,149
They list off that long list of side effects include blah, blah, blah, blah, blah.

33
00:05:52,150 --> 00:05:56,470
And you have absolutely no idea whether that's 40% of people or 0.4% of people.

34
00:05:57,160 --> 00:06:01,450
So that's one thing that pops up sometimes. That's really a problem.

35
00:06:03,760 --> 00:06:12,490
What's your format? One thing that I pay a lot of attention to on this assignment is, are you doing stuff consistently?

36
00:06:13,880 --> 00:06:17,200
Do people can make choices about it? Some people did percentages, some people did.

37
00:06:17,200 --> 00:06:25,990
Frequency is not a big deal for me. Flipping around or formats gets confusing really fast.

38
00:06:26,020 --> 00:06:27,580
We talked a lot about numeracy.

39
00:06:28,030 --> 00:06:35,470
As soon as you start changing the format you're using for people, then people with lower numeracy skills are much more likely to get confused.

40
00:06:37,660 --> 00:06:39,100
So that's another big one.

41
00:06:41,890 --> 00:06:50,530
Few people, and this is a subtle point, but I wanted to address it because it's not a big deal from a point standpoint or from a quality standpoint.

42
00:06:51,160 --> 00:07:00,430
A few people potentially replicated the drug facts box table that I have you all read that included both percentages and frequency.

43
00:07:01,690 --> 00:07:06,069
And we talked at one point in the class about the tension between providing multiple

44
00:07:06,070 --> 00:07:09,670
formats to reinforce what it is you're trying to communicate versus the volume

45
00:07:09,670 --> 00:07:14,200
of information that at least a couple of people where the volume of information

46
00:07:14,200 --> 00:07:17,590
really got sort of oppressive because of the volume of stuff in that context.

47
00:07:19,060 --> 00:07:25,420
And yeah, I noted it. It's not something I would have taken a lot of points off for, but that's something I want to pass out,

48
00:07:25,420 --> 00:07:29,829
like what you can get away with when you're really communicating one or two things in

49
00:07:29,830 --> 00:07:33,639
terms of let's reinforce the same number with a graphic or with multiple formats,

50
00:07:33,640 --> 00:07:41,980
etc., it becomes a lot harder and a lot more complicated to understand when you've got 30 rows

51
00:07:41,980 --> 00:07:46,150
of different risks and benefits and things that you're trying to understand in a table.

52
00:07:49,720 --> 00:07:53,980
So those are some of the themes that I wanted to reinforce.

53
00:07:56,390 --> 00:08:00,870
If you want to get back to that, I'll get it back within the next day or so.

54
00:08:00,890 --> 00:08:03,970
I just need to do one last pass to make sure I was consistent as I was going through.

55
00:08:06,570 --> 00:08:10,500
And you want to talk to me about them? Please let me know. I'm more than happy to do so.

56
00:08:12,750 --> 00:08:19,709
But what I hope you're taking away from this assignment is a sense of what is

57
00:08:19,710 --> 00:08:23,910
possible to really try to help somebody walk through a positive experience.

58
00:08:24,630 --> 00:08:28,410
Unfortunately, a lot of what's out there doesn't do all the things that I want you to do.

59
00:08:28,560 --> 00:08:36,360
So often the challenges is that you're having to go beyond the data that's available to you, and that's the real world.

60
00:08:36,360 --> 00:08:40,829
Situation is often the case that we're faced with situations where what you're going to

61
00:08:40,830 --> 00:08:48,090
get Googling or getting information from the manufacturer or etc. is going to be no.

62
00:08:48,090 --> 00:08:53,490
The likelihood is they're not going to provide a detailed description of what the minor side effects are, etc.

63
00:08:54,330 --> 00:08:57,390
And those are the kinds of things where I hope you're going to come back.

64
00:08:57,480 --> 00:09:04,140
But yeah, this isn't enough. Let's push forward. Let's try and make sure that we give people all they need to make a decision.

65
00:09:06,300 --> 00:09:17,140
All right. Today. I ask you to read this, this manual from the European Food Safety Commission on Food Safety,

66
00:09:17,140 --> 00:09:21,370
not because food safety is the be all and end all of health condition, although honestly,

67
00:09:21,370 --> 00:09:24,910
there's a heck of a lot of interesting problems when we think about food,

68
00:09:25,180 --> 00:09:33,900
ranging from food supply issues to contamination issues to cooking issues to broad health issues of consumption patterns.

69
00:09:33,910 --> 00:09:40,510
Like there's lots here, but there's a couple things I really wanted to emphasize from this,

70
00:09:40,510 --> 00:09:45,040
and I want to go through them first before we start to dive into the musings and talking about lots and lots of examples,

71
00:09:45,640 --> 00:09:50,620
because I want to both cover some of the examples that they gave us and got lots more good examples.

72
00:09:50,620 --> 00:09:53,380
We get to unpack and sort of analyze them in our framework.

73
00:09:54,660 --> 00:09:59,500
The first thing I want to talk about, which we haven't spent much time in this class talking about,

74
00:09:59,870 --> 00:10:03,490
which is an important idea to think about in communication is this idea of channels.

75
00:10:06,010 --> 00:10:13,120
How do you want to be communicated in a given situation to reach a given audience?

76
00:10:14,020 --> 00:10:24,370
And crisis situations are a good place to talk about this because you have multiple audiences and time it matters and uncertainty is common.

77
00:10:24,940 --> 00:10:34,599
So certain channels may be more or less appropriate in different situations because you are

78
00:10:34,600 --> 00:10:41,090
trying to figure out how do we achieve our communications goal in this evolving situation.

79
00:10:41,650 --> 00:10:50,559
I've listed a few of the lucky ones. The book, The Handbook has a few more detailed descriptions of them.

80
00:10:50,560 --> 00:10:58,570
But the main thing I want to highlight here is notice sort of the characteristics of each of these channels that.

81
00:11:00,290 --> 00:11:05,270
Fridge is permanent. It's like a change on you.

82
00:11:06,110 --> 00:11:16,850
It's a good record, but it's slow. So when you're mailing it, whether you're printing it, physically, giving it to people, etc.

83
00:11:17,630 --> 00:11:26,300
It works best when you want them to have a thing. They can go back to a reference and they need to have it.

84
00:11:27,320 --> 00:11:32,160
But. It's terrible for anything that's changing.

85
00:11:33,570 --> 00:11:37,770
So a classic example of miscommunication.

86
00:11:42,900 --> 00:11:48,950
Not forgetting about the opportunities that the baby safety sheets for like chemicals in labs.

87
00:11:49,170 --> 00:11:52,379
I forget what the acronym MSDS. What is it?

88
00:11:52,380 --> 00:11:55,440
MSDS material safety data sheets. That's it.

89
00:11:55,560 --> 00:11:58,580
Thank you. Why are those print?

90
00:11:59,810 --> 00:12:03,390
What? They're. They're static information like that.

91
00:12:03,410 --> 00:12:09,980
Nothing's really changing about that. Like, if you need a safety datasheet on benzene, you know, we know a lot.

92
00:12:10,340 --> 00:12:15,920
It's. It is what it is to. When are you going to want that information?

93
00:12:16,790 --> 00:12:22,270
What? Something is just happened in that room, so you better be able to get to it immediately like that.

94
00:12:22,280 --> 00:12:26,540
Those things are printed. They're stored in the rooms with those chemicals for a reason.

95
00:12:27,440 --> 00:12:31,459
You want it right there on a pillow. So it makes a lot of sense.

96
00:12:31,460 --> 00:12:34,760
You wouldn't want somebody to have to pull out their phone and look up a website to

97
00:12:34,760 --> 00:12:37,850
find out what the axis of chemical was or what they're supposed to do about it.

98
00:12:38,690 --> 00:12:44,620
You want it physically there? So that's what makes a lot of sense.

99
00:12:45,220 --> 00:12:55,750
On the other hand, you don't generally announce epidemics by sending everybody pieces of stuff in the mail like that is stupid.

100
00:12:57,790 --> 00:13:11,920
But that's the conversation we should be have. So if you want to think about more urgent things like news media is great for dissemination.

101
00:13:12,490 --> 00:13:20,200
Yes. The news media is going to care cause they think this is news.

102
00:13:20,770 --> 00:13:24,940
They will take whatever your messages and run with it and do a lot of your dissemination work for,

103
00:13:24,940 --> 00:13:29,110
you know, put it on their websites, they'll put it on the radio or TV, etc.

104
00:13:30,910 --> 00:13:34,720
But if they don't think it's interesting. You're not going to get anywhere.

105
00:13:36,530 --> 00:13:44,090
So now you have a filter there. You're only going to tap into the news media when when it's going to be serving both their interests and yours.

106
00:13:45,700 --> 00:13:53,800
And the news media is likely to amplify fear because that will get people to pay attention to them.

107
00:13:54,640 --> 00:14:01,840
Sometimes that's a good thing. Like, if you want to do a hurricane evacuation warning, I have no problem using the news media.

108
00:14:02,450 --> 00:14:05,500
Like, I want to get people riled up and moving.

109
00:14:06,460 --> 00:14:13,090
On the other hand, we've had plenty of conversations about situations which the news media basically take some

110
00:14:13,690 --> 00:14:18,040
little piece of science and blows it up into something way beyond what it actually is.

111
00:14:19,000 --> 00:14:24,580
So there is a situation in which using the news media maybe is not necessarily the right pathway.

112
00:14:27,780 --> 00:14:35,170
Websites and music websites sort of capture all that sort of stuff you can put online where somebody could search for high.

113
00:14:39,530 --> 00:14:48,080
Good for situations in which people will know what to look for, like they've got to go looking for it.

114
00:14:49,700 --> 00:14:59,450
Just because you put up a website doesn't mean anybody's going to find it. It's good for situations where.

115
00:15:01,600 --> 00:15:09,550
Some of the change you'd like by the minute, but maybe it's evolving like so it's not that hard to update a website every six months.

116
00:15:10,660 --> 00:15:14,470
It's new science comes out, etc. So let's think about where do we get science?

117
00:15:14,620 --> 00:15:19,600
Well, information on science and what's new about different types of risks.

118
00:15:20,440 --> 00:15:26,950
You know, National Cancer Institute had all kinds of patient information pages about different types of diseases.

119
00:15:27,280 --> 00:15:32,740
You want to learn about chronic myelogenous leukemia.

120
00:15:33,150 --> 00:15:36,219
Go to the website. There is a page. It gives you a general update.

121
00:15:36,220 --> 00:15:41,020
It gives you the you sort of what the current treatments are. You've been updated after a year.

122
00:15:41,290 --> 00:15:45,160
No problem. It's very useful for things that people are going to go looking for.

123
00:15:45,880 --> 00:15:54,080
What's the problem? Who's going to go looking for? That's you know it's a type of resource where.

124
00:15:55,200 --> 00:15:59,070
It's available, but if somebody doesn't know that it's there, they're not going to go looking for it.

125
00:15:59,940 --> 00:16:04,470
So if you want to give sort of like let's talk about how this has been used in crisis.

126
00:16:07,460 --> 00:16:15,980
COVID 19 counts. Lots of websites, but COVID 19 counts at a local level, at a national level, at a global level.

127
00:16:16,310 --> 00:16:20,510
Great. If you want to know those statistics, you go looking for them.

128
00:16:21,050 --> 00:16:28,400
You can keep them updated. Very useful. That's useful for pushing stuff out.

129
00:16:29,890 --> 00:16:40,379
Audiences that don't know it exist. Yes, I do.

130
00:16:40,380 --> 00:16:47,360
I have meetings out here. Think about.

131
00:16:49,960 --> 00:16:56,740
But the Flint water situation. People know that something's going on.

132
00:16:56,780 --> 00:16:59,830
People know that there is an issue and that there's uncertainty.

133
00:17:01,180 --> 00:17:05,360
It's simply just providing information isn't enough. There's an issue of trust.

134
00:17:05,380 --> 00:17:10,860
There's an issue of people have questions. If you're not sure how to plan for this situation,

135
00:17:10,860 --> 00:17:20,760
etc. Some sort of interactive context is necessary and those kinds of crises to meet the needs of certain audiences.

136
00:17:21,690 --> 00:17:30,480
So if a school is contaminated, let's say a school has their water tested and it shows that there's some kind of chemical in the water in that school.

137
00:17:30,990 --> 00:17:36,479
You can bet that at some point there's going to be a meeting where people can come and ask questions and

138
00:17:36,480 --> 00:17:41,700
yell and and there will be back and forth because that back and forth has to be is part of what's needed.

139
00:17:42,090 --> 00:17:47,760
It's not enough to just simply say, okay, here's what we know. We need that bi directional conversation.

140
00:17:48,690 --> 00:17:53,009
And so whether that's a Zoom meeting or it's a personal, in-person meeting isn't the issue.

141
00:17:53,010 --> 00:18:00,469
It's the idea of when do you need interactivity? And now, of course, we've got social media.

142
00:18:00,470 --> 00:18:04,970
And I have to say this right now. Yes, I know that document is now like ten years old.

143
00:18:05,390 --> 00:18:11,360
And what it talks about in terms of social media and what the social media landscape is for today are obviously two quite different things.

144
00:18:12,430 --> 00:18:20,410
But the larger theme is still right in the sense of what is social media good for?

145
00:18:20,890 --> 00:18:26,360
Why is it not good for? Social media tends to be good for me.

146
00:18:26,380 --> 00:18:32,920
It's rapid, really fast forms of disseminating information.

147
00:18:34,160 --> 00:18:44,010
It's good for directing people to other information. But whether you're talking about Twitter or Facebook or Instagram or whatever.

148
00:18:45,060 --> 00:18:50,610
If you want to drive people to a website or to a meeting.

149
00:18:51,180 --> 00:18:53,670
Social media can be a really powerful tool for doing that.

150
00:18:57,600 --> 00:19:05,160
And it has all the biases of sort of like what goes big and what doesn't that news media has.

151
00:19:05,340 --> 00:19:11,190
Except now you're not talking about journalists. Now you're talking about whatever anybody thinks they want to put on social

152
00:19:11,190 --> 00:19:16,440
media and what stories can how they can distort that to achieve their own goals,

153
00:19:16,440 --> 00:19:22,120
whatever those are. But there are absolutely times in which.

154
00:19:23,840 --> 00:19:31,219
Public health agencies intentionally push messages out in social media contexts because

155
00:19:31,220 --> 00:19:35,390
they know it's one of the fastest ways to reach a large segment of the population.

156
00:19:36,560 --> 00:19:39,110
And he might do that differently if you're talking about.

157
00:19:43,490 --> 00:19:54,649
Risks of AP with teens, social media usage is very high versus if you're talking about risks of continuing to consume, you know,

158
00:19:54,650 --> 00:20:01,190
aspirin amongst older adults to prevent heart attacks where your rates of use may be, patterns of use are very different.

159
00:20:04,080 --> 00:20:08,760
So one of the things I want to do, we're going to talk about lots of very specific examples.

160
00:20:09,360 --> 00:20:12,780
One of things I want to do today is anytime an example comes up.

161
00:20:13,910 --> 00:20:21,380
I want to have at least some conversation around. Okay, what channels would we want to use for this?

162
00:20:22,070 --> 00:20:30,140
Risk for this kind of crisis? What category would you put like a text message is?

163
00:20:35,330 --> 00:20:36,860
A good question, I.

164
00:20:38,990 --> 00:20:51,620
I would put it mostly in social media because it's driven by who are you able to text and that social network of who has signed up or otherwise.

165
00:20:53,540 --> 00:21:02,930
The pattern of dissemination is driven by somebody signed up in with the organization to get those messages for participation in some form of network.

166
00:21:05,670 --> 00:21:13,290
So if we think about U of M emergency alerts, which would go out on text, the anchor point is.

167
00:21:15,160 --> 00:21:21,730
Of that community and the intentional she was in to be part of that network to get those alerts.

168
00:21:22,150 --> 00:21:26,920
I get I live in Washtenaw County, I get the Washtenaw County traffic alerts on my phone,

169
00:21:27,640 --> 00:21:32,860
which sometimes is really annoying and about once out of 30 or 40 times is super helpful.

170
00:21:33,370 --> 00:21:37,630
Like, I have to be going, Oh no, I'm not going that way. Okay, that was really helpful.

171
00:21:39,430 --> 00:21:48,820
But yeah, it's driven by my ID with being in this location, watching that particular type of news from that particular source.

172
00:21:52,300 --> 00:21:58,240
So that's one thing I wanted to emphasize today, is each time we go through a project,

173
00:21:59,050 --> 00:22:01,750
let's I'm going to try and keep remembering, but please bring it up if I don't.

174
00:22:02,530 --> 00:22:06,609
What forms of communication channels have been used which can or should be used?

175
00:22:06,610 --> 00:22:10,450
Which shouldn't be used? Honestly, this is one of the things that public health.

176
00:22:13,820 --> 00:22:18,230
It's right about 70 or 80% of the time, but only about 70, 80% of the time.

177
00:22:18,620 --> 00:22:24,770
There's a decent amount of public health communication where that info is pretty decent and the channel selection is lousy.

178
00:22:25,880 --> 00:22:30,380
So pay attention to this one because it's an easy thing to fix if you really think about it.

179
00:22:30,530 --> 00:22:41,480
Why do you think that happens? Mismatch between people for design, designing, communication and the audience and related to that habit.

180
00:22:42,650 --> 00:22:50,010
If you're used to always dumping information in a certain channel part of it, we always publish stuff here on our website.

181
00:22:50,030 --> 00:22:57,380
We print a report every month we like. You, tend to just use the same channels that you're comfortable with.

182
00:23:00,020 --> 00:23:07,810
Where it breaks down in crises is that you don't realize that it's not actually a good fit for the audiences you need to reach in the timeframe.

183
00:23:07,880 --> 00:23:11,420
Consider. So that's where I think it breaks down the bond.

184
00:23:12,290 --> 00:23:21,020
That's one thing. That's one background thing for today. The other, which we'll allude to at the end of the day, when we when we have our rate cut.

185
00:23:22,100 --> 00:23:26,680
I think one of the best things about this reading is the fact that it breaks down these

186
00:23:26,720 --> 00:23:31,340
situations into the idea that there's going to be high versus low public interest.

187
00:23:32,150 --> 00:23:40,790
And high versus low. And all four combinations are super interesting and different.

188
00:23:41,630 --> 00:23:49,220
And so any time we're talking about a a risk today and the rest of this crisis action, let's have that conversation.

189
00:23:49,220 --> 00:23:52,940
Is this high or low interest? Is it high or low impact?

190
00:23:52,940 --> 00:24:07,750
And how does that change what we do? So for those, though, I want to ask the question just to sort of set the hour frame for thinking about this.

191
00:24:08,350 --> 00:24:15,670
If you think about all the public health risk communications that happened out there, all the medical risk communications.

192
00:24:18,540 --> 00:24:28,530
Are we spending most of our time and money and effort communicating about things that have high impact or bad things that have interest?

193
00:24:31,850 --> 00:24:41,180
Public health. How well calibrated is our time and money?

194
00:24:41,200 --> 00:24:46,120
Expenditures to either interest or compete.

195
00:24:46,900 --> 00:24:50,200
What do we spend a lot of time talking about? What do we not spend a lot of time talking about?

196
00:24:54,460 --> 00:25:00,980
To take a simple example just to get this conversation going. What does Pink stand for?

197
00:25:03,260 --> 00:25:10,040
Cancer. Breast cancer. How much effort is spent around breast cancer risk?

198
00:25:11,640 --> 00:25:15,060
How does that apply to high interest?

199
00:25:16,480 --> 00:25:25,210
How does that align to the magnitude of impact of breast cancer as compared to all of the other health things that we face as a society?

200
00:25:25,790 --> 00:25:31,900
I'm not saying it's low impact. Clearly, there is a large burden, disease burden of breast cancer.

201
00:25:32,830 --> 00:25:35,770
But certainly if we think about compared to other types of cancer,

202
00:25:35,770 --> 00:25:40,420
there is a disproportionate amount of interest in breast cancer as compared to many other types of cancer.

203
00:25:42,640 --> 00:25:45,370
That's the conversation we need to be having about all of these things.

204
00:25:45,910 --> 00:25:53,110
How are we aligned in how much we talk about it, how much we spend on it, etc., versus the magnitude of impact?

205
00:25:53,110 --> 00:25:56,720
And why is that? All right.

206
00:25:56,730 --> 00:26:05,490
So the first one I wanted to throw out just to get this conversation started, Emily, you were talking about, if I remember right.

207
00:26:06,390 --> 00:26:10,610
Romaine lettuce. Yes. And so this leads to the channel idea.

208
00:26:10,620 --> 00:26:18,240
So that's why I wanted to start there. So a couple of years ago, there was a big there was a.

209
00:26:19,810 --> 00:26:22,420
Bacterial something in romaine lettuce.

210
00:26:22,750 --> 00:26:28,750
And my family and I, we found out about it on the local news and we knew about it and we didn't buy any romaine lettuce.

211
00:26:29,350 --> 00:26:39,879
A couple days later in the mail, we got a letter from my grandmother who had cut out an article from the newspaper about the romaine

212
00:26:39,880 --> 00:26:47,080
lettuce recall and a lovely little note that says Don't eat romaine lettuce and it's still in our fridge.

213
00:26:48,480 --> 00:26:59,110
Honey, because I already know about it, but I, I guess it had a big impact on her, the paper articles that she had to mail it to us.

214
00:27:00,640 --> 00:27:06,610
So I love the story to start because it captures this idea that different audiences use different channels.

215
00:27:07,090 --> 00:27:15,580
Like How have you heard about it? Who's media? Is news media an appropriate channel for a food recall like romaine lettuce?

216
00:27:16,000 --> 00:27:23,920
Absolute fast dissemination. News media is going to recognize that it's a societal level thing, so it has broad interest.

217
00:27:25,570 --> 00:27:30,550
You want it to be going out quickly. So pushing it out to as many different channels as possible makes a lot of sense.

218
00:27:31,390 --> 00:27:35,379
Great. And is it something where action is urgent?

219
00:27:35,380 --> 00:27:40,000
And so the fact that the news media is going to sort of blow it up is actually probably a good thing.

220
00:27:40,000 --> 00:27:45,860
It's kind of it's going to do a lot of the work for us. Right? But so one question is,

221
00:27:46,490 --> 00:27:56,840
is this is was the your grandmother's first exposure to the news through the articles she read or did she get exposed to it anywhere else?

222
00:27:56,840 --> 00:27:58,790
You may not know the answer to it, but this is the question.

223
00:27:59,450 --> 00:28:05,120
I if the answer is your grandmother would never have gotten stuff from like electronic news media,

224
00:28:05,630 --> 00:28:10,640
then you better make sure that there is some letter or some print thing because she's just

225
00:28:10,640 --> 00:28:15,620
not going to get the message unless you also included in that slower communication chatter.

226
00:28:17,200 --> 00:28:23,910
So that's an interesting piece. And clearly that was a channel that she placed great weight on.

227
00:28:23,920 --> 00:28:32,200
So she wanted to share that format with you because she felt like that is, you know, here's the evidence that this is an important thing.

228
00:28:34,960 --> 00:28:39,250
This cuts both ways. Let's imagine this is reversed.

229
00:28:40,120 --> 00:28:46,870
And you were telling your grandmother about the posting on social media that you'd seen about the romaine lettuce.

230
00:28:47,440 --> 00:28:52,769
Would that have had any impact? Maybe.

231
00:28:52,770 --> 00:28:57,480
Maybe not. But the question we have to ask ourselves is.

232
00:28:58,710 --> 00:29:03,970
How will. Dissemination reach or not reach the client.

233
00:29:03,990 --> 00:29:11,500
If it's the case that, hey, I saw this really good posting on on Facebook about romaine lettuce and why we should eat

234
00:29:11,500 --> 00:29:17,830
it and where there's a recall and somebody has no trust in social media as a channel,

235
00:29:18,370 --> 00:29:23,110
you're not going to get anywhere. But.

236
00:29:24,210 --> 00:29:28,500
And here's where I'm going to flip this around. If that posting instead.

237
00:29:30,210 --> 00:29:40,560
Bribes even to a Food and Drug Administration Web site that somebody might have greater trust in than maybe they won't trust the posting,

238
00:29:40,920 --> 00:29:43,710
but they will trust the thing that that posting is driving you towards.

239
00:29:46,330 --> 00:29:53,320
So the channel selection is a combination of things like all of these things might or might not be relevant in a given context.

240
00:29:54,640 --> 00:30:01,270
I love that story because it's a perfect example of a channel mattering in terms of how you're disseminating this type of information.

241
00:30:05,860 --> 00:30:15,640
The next one I want to touch upon is your story about your father and diet soda.

242
00:30:16,680 --> 00:30:22,360
Yeah. I was talking about how my family, which is a bunch of people,

243
00:30:22,500 --> 00:30:29,720
are in general very cautious when there are risks of just like food poisoning at a restaurant

244
00:30:29,730 --> 00:30:35,240
and making sure not to go to any restaurants in the general area for like three weeks,

245
00:30:35,250 --> 00:30:44,760
even knowing that we never went to that one even before this happened, and probably an overreaction at the same time.

246
00:30:44,970 --> 00:30:51,840
My dad has been drinking for like 40 years despite having heard many times.

247
00:30:51,950 --> 00:30:57,210
It's probably not a good idea, but at the same time it's the idea of, well,

248
00:30:57,780 --> 00:31:03,959
I think by the time that actually happens, by the time the impact occurs, for me, it won't be a big deal.

249
00:31:03,960 --> 00:31:13,590
They'll have figured out something to do and overall it's in the future I can kind of ignore it versus the idea of something immediately happening.

250
00:31:14,280 --> 00:31:19,590
In the long run, it's more significant to have this mystery.

251
00:31:22,620 --> 00:31:27,780
So there's two risks here. Let's run through the whole breakdown of each of them.

252
00:31:27,810 --> 00:31:31,920
You've got a food poisoning at a local restaurant scenario.

253
00:31:33,160 --> 00:31:41,709
And you've got a impact. Health impact of cumulative exposure of the chemicals that are.

254
00:31:41,710 --> 00:31:44,770
And the lack of sugar of sodas.

255
00:31:45,950 --> 00:31:49,180
So. Restaurant.

256
00:31:50,570 --> 00:32:00,090
High interest. Low interest. My interest I interests found it in the sense that there's a geographic boundary here.

257
00:32:00,100 --> 00:32:06,399
Like I don't care about the food poisoning in, you know, downtown Detroit.

258
00:32:06,400 --> 00:32:16,030
I haven't been to Detroit, Detroit in a long time. So geography matters, but within a local space, a much more high interest.

259
00:32:17,740 --> 00:32:23,440
But that's important when we think about channels, because that means like Detroit News doesn't care about necessarily the Ann Arbor Restaurant.

260
00:32:24,520 --> 00:32:32,020
And so we may or may not have access to a news agency that would care about this locally.

261
00:32:32,470 --> 00:32:36,700
Let's imagine we're talking about an arbor. You don't have a Ann Arbor TV station.

262
00:32:36,710 --> 00:32:43,330
What do we have? But we do have a Ann Arbor radio. So we could certainly have a have a localized radio focused.

263
00:32:45,220 --> 00:32:49,240
You have online news media, and that's about it in terms of local.

264
00:32:49,870 --> 00:32:53,800
So the choices might be different here.

265
00:32:54,370 --> 00:33:00,270
Certainly would be different, say, in a rural community than there would be in a major city like Detroit or.

266
00:33:03,820 --> 00:33:09,729
Isn't it also kind of a present bias issue of like going to the restaurant to be in the now where

267
00:33:09,730 --> 00:33:14,370
it's like probably drinking one diet sodas is not going to have much of an effect in the now,

268
00:33:14,380 --> 00:33:18,700
but like over a long period of time, I would frame it.

269
00:33:20,260 --> 00:33:23,260
Yes, but there's also another dimension that's overlap with that.

270
00:33:23,680 --> 00:33:27,370
So you're framing it as a now versus later? Yeah, I'm framing it.

271
00:33:27,370 --> 00:33:39,319
I want to also frame it as a. Probability risk versus an accumulation risk, the chance that if you go to a restaurant today that you will get sick,

272
00:33:39,320 --> 00:33:46,010
even if there is a restaurant that has a food bar and the outcome is very small, but it's a random thing.

273
00:33:48,010 --> 00:33:54,399
The chance that one diet soda will have a transformative impact is probably very small,

274
00:33:54,400 --> 00:34:00,430
but the chance that diet soda might have an incremental impact. Is not so small like it is.

275
00:34:00,440 --> 00:34:03,560
You are absorbing that chemical, you are potentially being affected by it.

276
00:34:04,040 --> 00:34:08,570
So if we want to think about, for example, in the booklet, the salt.

277
00:34:10,310 --> 00:34:17,700
Salt is like diet soda. But it's not that one shaker is worth its salt is going to instantaneously transform something.

278
00:34:18,030 --> 00:34:33,360
We're talking about a cumulative exposure problem. Whereas risks of plane crashing is a probabilistically it happens.

279
00:34:33,370 --> 00:34:37,180
It's rare, but if it happens to you, it happens to you kind of thing.

280
00:34:37,270 --> 00:34:44,380
And that's that's another distinction that is an important one as they think about interest like people can be.

281
00:34:46,850 --> 00:34:51,200
Interested or not interested because of how likely it is an interested horse is

282
00:34:51,200 --> 00:34:56,420
not interested based upon their perception of how how relevant this is truly.

283
00:34:58,950 --> 00:35:04,769
And one of the things that I was also talking about is the idea of my mom and I in general.

284
00:35:04,770 --> 00:35:09,810
I would argue my father does. I've been trying to convince him as long as I've been alive, essentially, that he should stop.

285
00:35:10,260 --> 00:35:13,590
So it's what is going to actually change his behavior, if you will,

286
00:35:13,620 --> 00:35:20,250
from his family members, which is his nurse as well, which did not have any impact.

287
00:35:21,740 --> 00:35:28,220
So thank you for raising that, because I want to snap us back to something we read very early on in this course.

288
00:35:29,180 --> 00:35:33,740
Remember when you read that short article, this chapter from a book on Google's.

289
00:35:35,740 --> 00:35:39,310
We drew the distinction between changing beliefs, changing behavior.

290
00:35:41,270 --> 00:35:42,620
And Oracle said something.

291
00:35:42,620 --> 00:35:51,140
If your goal is to change behavior, not only is this communication not necessarily the best way to do it, it may not be an effective way to do it.

292
00:35:52,570 --> 00:35:57,580
This is an example of a situation in which it is not obvious that talking about

293
00:35:57,580 --> 00:36:02,830
the risks of diet soda is an effective way to potentially change behavior.

294
00:36:04,730 --> 00:36:14,120
And if that's the case, because the causes of the behavior are habit, enjoyment, other factors that have nothing to do with risk,

295
00:36:14,960 --> 00:36:21,440
lots of risks that we intentionally accept because we want them for other things.

296
00:36:22,470 --> 00:36:25,950
Then drawing more information about this is risky. This is risky.

297
00:36:26,160 --> 00:36:34,320
This is risky. Isn't going to change anything. Yet another dimension to this, though, because the risks of drinking diet soda are kind of unknown.

298
00:36:35,520 --> 00:36:40,560
So, yeah, and like some people would call that fear, like, irrational.

299
00:36:40,950 --> 00:36:44,549
Like people who are flying planes. Yeah, it's like, calm down.

300
00:36:44,550 --> 00:36:47,670
It's okay. Tickets, annex, whatever. You know?

301
00:36:47,670 --> 00:36:50,610
So how is it any different? Well, so, first of all,

302
00:36:50,610 --> 00:36:57,120
let's acknowledge that there's a huge range of stuff that was in the reading for today that isn't in the food safety space, etc.

303
00:36:57,690 --> 00:37:01,340
Where. We know that the stuff exists.

304
00:37:01,790 --> 00:37:08,520
We don't know whether it matters. And that the uncertainty, the crisis nature of this is not because it's time urgent,

305
00:37:09,000 --> 00:37:16,020
but it comes from the lack of knowledge about whether this thing whether it's genetic modification,

306
00:37:16,020 --> 00:37:22,800
whether it's diet sodas, whether it's, you know, cumulative exposure to bisphenol A, whatever.

307
00:37:23,040 --> 00:37:28,500
We don't know how much it matters. And that's the crisis element of is the uncertainty component.

308
00:37:29,780 --> 00:37:35,880
But it's usually brought on by something. Well, what do you mean by that?

309
00:37:36,360 --> 00:37:40,060
Like with the Ireland example, there's like some sort of chemical that.

310
00:37:40,080 --> 00:37:45,480
Right. Hmm. And then they, like, got rid of all of their or.

311
00:37:47,220 --> 00:37:56,220
I can't remember what precipitated it though. Well, so what the reason why causing is you're making an assumption here that there is an event,

312
00:37:56,940 --> 00:38:02,489
but there are many risks that if exist within society where there is no precipitating event,

313
00:38:02,490 --> 00:38:09,450
where there is some sort of very slow questioning awareness of, hey, does this matter?

314
00:38:10,800 --> 00:38:20,380
Salt actually falls pretty well into that pattern. Like we talk more now in the last 20 years or so about salt intake.

315
00:38:20,400 --> 00:38:23,400
But, you know, previously nobody thought about that.

316
00:38:23,820 --> 00:38:26,100
And there was sort of an accumulation of, well, wait a second,

317
00:38:26,820 --> 00:38:32,100
people who seem to be consuming lots of salt seem to be having worse cardiovascular outcomes, what's going on here?

318
00:38:32,100 --> 00:38:36,870
And then eventually we accumulated a sense that this is a risk factor.

319
00:38:38,190 --> 00:38:44,430
But, uh, well, let's actually talk about that sort of separate.

320
00:38:47,190 --> 00:38:53,490
One of the artificial sweeteners that has traditionally been used in sodas.

321
00:38:54,390 --> 00:39:04,140
I was growing up. Rice first growing up, Saffron was basically the only sweetener used in diet sodas.

322
00:39:05,650 --> 00:39:09,280
And then aspartame became available.

323
00:39:10,380 --> 00:39:15,480
And there was a stretch of time in which basically the news media was saccharin is going to kill you.

324
00:39:19,110 --> 00:39:22,590
And everybody switched off of it pretty much.

325
00:39:23,340 --> 00:39:28,540
So my father in law. For whatever reason.

326
00:39:28,540 --> 00:39:30,430
I don't know whether it's something about the taste.

327
00:39:31,750 --> 00:39:40,020
Held on to saccharin for use in his coffee rather than equal or other kinds of sweeteners because he hated that, whatever.

328
00:39:40,810 --> 00:39:44,500
But I remember sort of thinking, why are you doing this? This is going to be really bad for you.

329
00:39:45,160 --> 00:39:52,970
Fast forward 15, 25 years or so worth of science, whatever fears of saccharin has been basically blown up,

330
00:39:53,000 --> 00:39:56,650
it's not at all clear that saccharin has that much impact on people's health.

331
00:39:57,460 --> 00:40:02,290
So this is a case in which we have literally a societal change in behavior based

332
00:40:02,290 --> 00:40:07,870
upon a risk which on further investigation proved to be not much of anything.

333
00:40:08,040 --> 00:40:11,050
Now we've switched over and we're unsure about. Correct.

334
00:40:12,310 --> 00:40:17,770
And in fact, I think I've talked about the idea of a regrettable substitution.

335
00:40:18,310 --> 00:40:21,670
I talked about this. Oh, okay. So.

336
00:40:22,800 --> 00:40:31,980
This is relevant for this. Alex did a paper on people's attitudes related to bisphenol A.

337
00:40:34,110 --> 00:40:42,710
And. What we did was we set up a scenario in which people were buying tomatoes.

338
00:40:42,770 --> 00:40:55,860
So one of the places in which this all exists is in camp vegetables because it's used to make the seals more stable so that the can doesn't break,

339
00:40:56,070 --> 00:41:02,560
which obviously has actually really important things about preventing things like botulism and other things from growing up.

340
00:41:03,690 --> 00:41:10,310
But it means that there's some amount of this always it reaches into especially liquid like tomatoes.

341
00:41:11,520 --> 00:41:15,870
So if you eat lots of canned tomatoes or lots of can soup and the cans have this

342
00:41:15,870 --> 00:41:18,510
funnel and they'll be you will get some degree of exposure to this phenolic.

343
00:41:20,430 --> 00:41:25,710
So we came up with a scenario in which there was a news story about potential risk for bisphenol A.

344
00:41:27,150 --> 00:41:30,240
And I said, Well, here's a kid and that's bisphenol A free.

345
00:41:31,340 --> 00:41:35,170
Do you want? How much would you be willing to pay for it?

346
00:41:36,280 --> 00:41:42,640
And then we flipped it and said, okay, so here's a can with other chemical, which we.

347
00:41:43,450 --> 00:41:46,900
One of the alternatives to bisphenol A, but not the one that most people were talking about.

348
00:41:47,140 --> 00:41:55,360
I honestly don't remember what it was used for this study. And he said, Oh, but you can also get this chemical free thing which has bisphenol A.

349
00:41:55,600 --> 00:41:56,470
Would you want it?

350
00:41:58,550 --> 00:42:03,390
And what we showed is that people were willing to pay more to get the thing that was free of the thing that we had just warned them about,

351
00:42:03,390 --> 00:42:04,800
regardless of what the thing was.

352
00:42:06,890 --> 00:42:13,010
But it isn't actually that people are afraid of bisphenol A, it's that when you tell them a story of, Hey, this might be bad for you.

353
00:42:13,370 --> 00:42:21,720
They want things without that. And you can totally distort what it is people are avoiding versus not.

354
00:42:22,980 --> 00:42:32,390
Like how you set it up. So are these sugar free sodas or products?

355
00:42:32,690 --> 00:42:36,350
Good for you or bad for you? I can get you wanting them.

356
00:42:36,360 --> 00:42:39,940
I can get you not wanting them, by the way, in which I set this up for me.

357
00:42:40,800 --> 00:42:44,580
Rice, which is also its own form of crisis communication.

358
00:42:44,580 --> 00:42:48,150
Like how are you setting up? What is the thing that is dangerous?

359
00:42:49,880 --> 00:43:00,680
But the term regrettable substitution is the idea that we will often trade the thing that we know might be bad.

360
00:43:01,680 --> 00:43:03,930
For the things that we don't know anything about.

361
00:43:05,890 --> 00:43:11,560
And it's not unheard of for the thing that we don't know anything about to be worse than the things that we left.

362
00:43:14,890 --> 00:43:25,330
So in the food space. Think about the way in which fat free food items are often created.

363
00:43:26,830 --> 00:43:29,920
You get rid of fat and you throw more sugar in.

364
00:43:30,930 --> 00:43:39,079
Low and behold, they're not necessarily any more healthy for you, and they might be worse for you because the reformulation adds other things.

365
00:43:39,080 --> 00:43:45,270
That's not that. This is an example of the regrettable substitution which you can see in consumer products.

366
00:43:45,570 --> 00:43:49,620
You can see dietary choices. A lot of things have that characteristic.

367
00:43:53,760 --> 00:43:59,500
So yeah, that sort of example we can attack on many levels because you know, at this point.

368
00:44:00,670 --> 00:44:05,920
Honestly, I think I'd rather take a saccharin drink than an aspartame drink in many contexts.

369
00:44:06,010 --> 00:44:08,500
And that was not where I was 20 years ago.

370
00:44:14,210 --> 00:44:20,210
I noticed, by the way, how that one has played out, that one has played out in news media and social media for the most part.

371
00:44:22,460 --> 00:44:31,960
There's not been a crisis moment when all of a sudden there was a town hall meetings or lots of I mean, there's little bits and pieces.

372
00:44:31,970 --> 00:44:38,120
It's a slow accumulation of information as opposed to sort of the big crisis push that you might have with,

373
00:44:38,690 --> 00:44:44,270
you know, say, Ebola outbreak or a food poisoning incident or something like that.

374
00:44:47,100 --> 00:44:50,280
All right. So.

375
00:44:52,100 --> 00:44:55,520
Next example, I want to bring out actually what we're talking about.

376
00:44:57,870 --> 00:44:59,970
Yeah. Let's go there, Kayla.

377
00:45:00,960 --> 00:45:10,700
We're talking about a local example that mirrors many of the patterns that we saw in the emails and the reading, which was about PFA.

378
00:45:11,460 --> 00:45:16,050
Yeah. So I'm not like super, I guess like knowledgeable about it.

379
00:45:16,050 --> 00:45:22,260
Just like a case study used that and some of like my educational things for my residency.

380
00:45:22,260 --> 00:45:27,239
But basically talking about like in Michigan that I talked to somebody who was working at the state

381
00:45:27,240 --> 00:45:35,310
health department and there was a local community like very agricultural and farming community,

382
00:45:35,610 --> 00:45:44,970
and they had done testing of the land and the meat of these cows that they were selling for, like for consumption.

383
00:45:45,240 --> 00:45:47,810
And they found that there were high levels of farms.

384
00:45:48,270 --> 00:45:55,139
And basically, just like talking about like what the communications from the state were is like very complicated,

385
00:45:55,140 --> 00:46:02,250
having to like talk to those farmers about like now they have to like shut down their whole production.

386
00:46:02,550 --> 00:46:10,500
And then also like the way that the P that was getting into the cows was through the land by eating like the grass.

387
00:46:10,500 --> 00:46:17,730
And so then like all the people in the neighboring communities were very concerned about heath levels and like their exposures,

388
00:46:18,420 --> 00:46:22,200
even though that they weren't using their lands for like agricultural purposes or consumption.

389
00:46:22,200 --> 00:46:29,280
So there's not really like a true risk to them. And then also like the uncertainty of feedback from like what the actual risk exposure is.

390
00:46:29,700 --> 00:46:37,859
Um, so it just led to a lot of like really complex communications in the community and like everybody was like really requesting

391
00:46:37,860 --> 00:46:44,850
feedback testing even though there wasn't any like good indication of like what that would benefit them in that specific situation.

392
00:46:45,650 --> 00:46:51,400
It helps with the psychological. Well, yes, really there is a there is a benefit, like there's a lot of uncertainty.

393
00:46:51,540 --> 00:46:56,860
So I want to unpack this one because as you say, there's multiple audiences, multiple questions, multiple purposes.

394
00:46:57,480 --> 00:47:02,250
So who let's think about the audiences in this community.

395
00:47:02,250 --> 00:47:12,180
It's an agricultural community. There is a discovery of CSA that's in the cows that you are growing farming for consumption.

396
00:47:14,100 --> 00:47:24,990
So I guess what the farmers this is a nightmare scenario for them, like their product, their livelihood is being completely affected by this.

397
00:47:25,440 --> 00:47:33,420
So as bad as it is, this is one of those bad news first kind of moments like don't hide that.

398
00:47:34,470 --> 00:47:37,560
You're going to have to be blunt about just how bad this is right up front,

399
00:47:37,560 --> 00:47:44,970
because anything that gets worse over time is going to completely disrupt any trust they have in you as a communicator.

400
00:47:46,860 --> 00:47:52,970
Obviously there is a urgency like if it's a question of nobody can sell any

401
00:47:52,980 --> 00:47:56,360
cattle until we test it type of thing that that needs to be put in place that.

402
00:47:58,560 --> 00:48:10,740
To use a terrible example of this just because it popped in my mind that Jif Peanut Butter recall a couple of months ago.

403
00:48:12,420 --> 00:48:16,000
I remember getting news about that on the news media.

404
00:48:18,020 --> 00:48:21,740
And what grocery shopping like 24 hours later.

405
00:48:22,460 --> 00:48:26,360
And my grocery store still had all the jif peanut butter on the shelf.

406
00:48:27,140 --> 00:48:32,959
And I went to the desk and said, Do you know that you still have the peanut butter on the shelf?

407
00:48:32,960 --> 00:48:36,670
And that recalled. And they were like, No, and thank you.

408
00:48:36,680 --> 00:48:45,829
And they went off and started making it off the shelf right then, because that's that was a failure of the communication lines that somehow I had

409
00:48:45,830 --> 00:48:49,610
gotten that information before they had when they needed to take immediate action.

410
00:48:52,310 --> 00:49:00,620
So we've got the farmers. We've got who else ask for other critical audiences in that context?

411
00:49:03,760 --> 00:49:09,940
This isn't that complicated because only three or four I can come up with that. My consumers and consumers of the meat.

412
00:49:10,750 --> 00:49:15,370
Right. So we have not identified a food product that is contaminated.

413
00:49:16,000 --> 00:49:19,150
We want them to not eat it. You want them to throw it away, etc.

414
00:49:19,600 --> 00:49:26,260
How are you going to do that? How do we disseminate food recalls like that?

415
00:49:29,690 --> 00:49:36,409
You trace the supply chain? I don't know about you guys, but I go to Trader Joe's and there is a thing on the checkout sign that says,

416
00:49:36,410 --> 00:49:42,170
your product has been discontinued, please don't eat it, return it to us for a full refund type of stuff.

417
00:49:42,190 --> 00:49:45,889
Like to the extent you can, you figure out where it is.

418
00:49:45,890 --> 00:49:51,230
So when you hear product recalls for your X states, it was disseminated through these particular stores.

419
00:49:51,620 --> 00:49:59,510
Under this brand, you provide information so that people can know, does this apply to me or not?

420
00:50:00,260 --> 00:50:08,180
Because simply saying beef happens, PSA has in it is a way overgeneralization of the actual problem.

421
00:50:11,380 --> 00:50:14,440
All right. Well, what are their audiences that we need for this one?

422
00:50:18,010 --> 00:50:23,310
Yeah. The surrounding community. Yeah. So now notice that we're stepping away from the beef.

423
00:50:23,590 --> 00:50:27,549
The surrounding community is not actually freaked out about the community is freaked

424
00:50:27,550 --> 00:50:34,030
out about the fear and the belief that this is a signal that they might be at risk.

425
00:50:36,220 --> 00:50:40,750
So we have a couple critical features here. One is geography.

426
00:50:41,580 --> 00:50:44,950
How about this, a localized thing like the restaurant?

427
00:50:45,340 --> 00:50:50,890
How much of this is a global thing that affects larger communities and.

428
00:50:52,390 --> 00:50:54,610
Part of this is a mental model's problem.

429
00:50:56,520 --> 00:51:05,790
So what you said, which was really important, is the pathway was the cows eating like the grass in the ground, etc.

430
00:51:06,360 --> 00:51:11,370
It's not fair. So one of the.

431
00:51:12,060 --> 00:51:16,170
The more that we flesh that out, first of all, there may be people who don't know that they're like,

432
00:51:16,170 --> 00:51:19,980
what am I going to be exposed to it just because I live here, too?

433
00:51:20,940 --> 00:51:24,000
The more they learn. Is it the water? Is it the ground?

434
00:51:25,140 --> 00:51:31,700
Is my garden okay? Are my kids safe because my kids are going to be putting them out.

435
00:51:33,970 --> 00:51:42,990
This is all mental models conversation that and if we think about channels it's going to be very high interest.

436
00:51:43,000 --> 00:51:47,650
But notice that our goal isn't necessarily to say, hey, there's a risk here.

437
00:51:48,160 --> 00:51:56,380
Our goal is potentially to change those medical models, how people know who is at risk and who is not, what should we do and what should we not do?

438
00:51:58,330 --> 00:52:01,990
Those are the parallels here to the what do we know? What do we not know?

439
00:52:04,800 --> 00:52:10,730
Resolving uncertainty. The critical piece here, nobody should be.

440
00:52:11,730 --> 00:52:18,570
It's not everybody gets to leave town. It's who and what and when and why.

441
00:52:27,100 --> 00:52:32,820
And there is. So then there's these sort of generalized people.

442
00:52:33,350 --> 00:52:37,340
And then you've got one other thing, which was the sort of testing piece.

443
00:52:38,960 --> 00:52:45,140
So should there be testing? Who should be tested.

444
00:52:45,760 --> 00:52:51,470
Like, if we think about how this unfolded in the context of Flint on the water.

445
00:52:52,310 --> 00:52:56,690
There was a first wave of basically assume your water is not good.

446
00:52:57,680 --> 00:53:06,110
Well, I had to wait to test. We're just you know, the initial message is assume they danger now, respond to bottled water filters,

447
00:53:06,110 --> 00:53:11,820
etc., which evolved over time into more of a testing driven question of,

448
00:53:12,440 --> 00:53:12,720
you know,

449
00:53:12,740 --> 00:53:19,460
let's find out what your situation is and you can make different choices based upon how much of that already is or is not in your water supply, etc.

450
00:53:20,620 --> 00:53:24,010
So there would be a similar kind of crisis dynamic in this context.

451
00:53:25,060 --> 00:53:32,230
What would be the sort of the general advice to everybody versus how do we help people make decisions moving forward about their degree of exposure?

452
00:53:34,630 --> 00:53:40,000
Notice that I just took that one piece and unpacked it into like four or five sets of communications,

453
00:53:40,000 --> 00:53:45,430
each of which would have multiple channels, each of which has a different audience and each of which has a different goal.

454
00:53:50,450 --> 00:53:54,200
And that was not just simply me regurgitating everything I know.

455
00:53:55,570 --> 00:54:02,020
Because if my goal is don't eat the beef, I don't need to be talking about how the beef contaminated.

456
00:54:03,040 --> 00:54:10,820
That's irrelevant. One of the dangers for your next assignment.

457
00:54:11,740 --> 00:54:18,910
I only foreshadow this suspect to be writing a speech is basically some initial communication about a crisis situation.

458
00:54:19,720 --> 00:54:27,250
One of the dangers that people tend to run into is that they drop into health, education, vote it, regurgitate everything they know about the risk.

459
00:54:28,510 --> 00:54:39,330
Don't do it. You have a very specific goal and purpose and audience for communication in this context.

460
00:54:40,170 --> 00:54:44,790
What do they feel is more important than what you have?

461
00:54:47,980 --> 00:54:53,350
And then again, what they need is more important than what you have.

462
00:54:58,130 --> 00:55:01,730
So put yourself in your audience.

463
00:55:01,730 --> 00:55:08,180
You choose, figure out who your audience is. Think about their needs in that moment.

464
00:55:13,920 --> 00:55:18,209
This, by the way, is a broadly applicable coverage point about communication in general.

465
00:55:18,210 --> 00:55:23,880
But it's super important in a crisis context and.

466
00:55:25,240 --> 00:55:29,110
And honestly, this is one of those places where health communication breaks down the most.

467
00:55:30,120 --> 00:55:38,700
Because we are experts, we know a lot that's difficult for us to put the brakes on what we know.

468
00:55:39,030 --> 00:55:49,050
We feel like we have to regurgitate everything. Whereas ultimately our purpose is not actually to convey everything that we know.

469
00:55:50,030 --> 00:55:58,920
It's not a class essay like what you do in school, where your goal is to convince the teacher that you know as much as you know,

470
00:56:00,060 --> 00:56:05,040
when you're communicating for a professional purpose, your goal is to meet your audience's needs.

471
00:56:06,570 --> 00:56:12,180
And even if all you communicate is one thing, if that's all they need, then you are succeeding in your goal as a communicator.

472
00:56:26,380 --> 00:56:30,870
I mean, before I lose this track of high impact.

473
00:56:30,870 --> 00:56:36,510
Low impact pafs. I want to say that.

474
00:56:38,420 --> 00:56:42,600
Well, let's say you're wrong. I'd say let's unpack them. It's really hard to get rid of.

475
00:56:43,290 --> 00:56:49,780
It's harmful. So it's really hard to get rid of is true.

476
00:56:50,140 --> 00:56:54,170
Absolutely. It's really harmful is how we want to.

477
00:56:54,200 --> 00:57:00,340
We know the army creates that much.

478
00:57:00,820 --> 00:57:02,229
So there's this uncertainty,

479
00:57:02,230 --> 00:57:09,190
peace about the actual level of public health in that we're certainly spending some serious amount of time on it for not inappropriate reasons.

480
00:57:11,540 --> 00:57:16,610
But this is a space in which at least are some questions about what the actual full impact is.

481
00:57:17,150 --> 00:57:24,910
When you talk about impact as it is, it is a public health impact, but is it only health or like impact as well?

482
00:57:25,130 --> 00:57:26,300
Yeah, so that's a great question.

483
00:57:26,510 --> 00:57:35,840
Obviously, this overlaps like anything that has high interest evokes lots of emotions and those emotions have psychological impact.

484
00:57:38,070 --> 00:57:47,100
The way the reading talks about it is really terms of their actual physical health implications, both at an individual level and as a societal level.

485
00:57:47,110 --> 00:57:58,200
And that's important because things like salt have relatively small magnitudes of risk impact at the individual level as massive impacts the societal.

486
00:57:59,580 --> 00:58:06,000
Everybody be having their health risk of cardiovascular disease increased by a very small amount.

487
00:58:06,330 --> 00:58:09,990
Multiply it by 400 million people equals a very large impact,

488
00:58:11,610 --> 00:58:16,890
whereas the food poisoning is very localized and much more serious for the people who are affected.

489
00:58:18,010 --> 00:58:19,940
So both of those types of impact matters.

490
00:58:21,760 --> 00:58:29,020
I want to separate the psychological side for the moment simply because it's much more associated with the question of interest,

491
00:58:29,710 --> 00:58:33,850
like the worry anxiety side almost guarantees you.

492
00:58:33,850 --> 00:58:38,440
Anything that's going to be high interest is going to evoke some degree of anxiety, of concern.

493
00:58:38,650 --> 00:58:45,190
And so those are. But just give DFS.

494
00:58:46,630 --> 00:58:51,540
High interest. And again, on track, multiple audiences here.

495
00:58:53,430 --> 00:58:59,340
So you're shaking your head? No. Why not? I don't think I'd ever heard of it before this conversation or when we read about it.

496
00:59:00,390 --> 00:59:06,660
Really? I don't think so. I mean, how many of you had heard it passed before we started the conversation?

497
00:59:07,600 --> 00:59:17,620
But not all, but many. And we're in a public health school here like we are not exactly the representative sampling of the population in general.

498
00:59:18,610 --> 00:59:24,980
I have heard of it in part because it is essentially the water contaminant du jour in this state.

499
00:59:25,000 --> 00:59:28,630
That's what we talk about most. But.

500
00:59:30,140 --> 00:59:35,420
Many people don't pay any attention to it at a national level, at a state level.

501
00:59:36,230 --> 00:59:43,940
On the other hand, if your committee community is one of those who for whom it is identified in your state water system,

502
00:59:44,720 --> 00:59:49,730
or since it is often linked to use of firefighting chemicals,

503
00:59:49,730 --> 00:59:55,910
particularly on military bases, if you're at a military base or other spaces where there's known to be potential exposure.

504
00:59:56,510 --> 01:00:00,600
Interest rate goes way up. Because now it's not an abstract thing.

505
01:00:00,600 --> 01:00:06,300
It's a local. We don't talk.

506
01:00:06,320 --> 01:00:11,240
Most of the world doesn't talk about one for dioxane either. But in Ann Arbor, talk about it a little bit more.

507
01:00:13,670 --> 01:00:15,940
So, again, that localization matters here.

508
01:00:16,070 --> 01:00:21,740
When I think about think about interest, I'm not going to get national news paying attention to it necessarily.

509
01:00:21,890 --> 01:00:29,860
Although as it's turned out, PBS is such a broadly disseminated tablet problem that we are seeing a lot of national interest in it.

510
01:00:29,870 --> 01:00:38,000
So this was pre-COVID, but the last time I traveled down to Atlanta to give a talk at CDC,

511
01:00:38,540 --> 01:00:40,970
one of the things that they particularly wanted to talk about was house,

512
01:00:42,500 --> 01:00:46,520
because it had it was popping up in so many different places around the country.

513
01:00:49,490 --> 01:00:52,630
Or a few more examples.

514
01:00:53,650 --> 01:00:58,820
Lisa. You were talking about pasteurized cider.

515
01:00:59,840 --> 01:01:07,040
So you have brought some unpasteurized apple cider from a local cider mill.

516
01:01:07,670 --> 01:01:17,420
And he told me, just a gigolo, that I liked it so much that I ended up drinking the entire gallon in about two and a half days.

517
01:01:18,350 --> 01:01:21,140
And definitely I got food poisoning from it.

518
01:01:22,160 --> 01:01:27,500
But on the label, it would have it just said unpasteurized apple cider and like the name of the cider mill.

519
01:01:27,770 --> 01:01:35,560
But it didn't tell you or it doesn't tell you the risk of drinking unpasteurized and it can be contaminated with salmonella.

520
01:01:36,080 --> 01:01:39,980
Because I know my dad didn't really educate numerous either.

521
01:01:40,020 --> 01:01:45,170
He was just like, just drink a little bit at a time. And which I just have to interrupt with and say.

522
01:01:45,680 --> 01:01:53,540
And how much do we think that only drinking a little bit would have actually moderated your risk of exposure if it was contaminated,

523
01:01:53,540 --> 01:01:57,200
which obviously it was. So.

524
01:01:58,170 --> 01:02:05,440
Unpasteurized food is another one of these great risk communication questions that pops up.

525
01:02:05,460 --> 01:02:08,160
So you had unpasteurized cider.

526
01:02:08,190 --> 01:02:16,590
There have been multiple incidents in Michigan in the last few years related to people getting in trouble for selling unpasteurized dairy products.

527
01:02:17,620 --> 01:02:22,480
Milk, cheeses, etc. Direct from the farm. And.

528
01:02:23,590 --> 01:02:26,780
And so Andrew is like shaking your head.

529
01:02:26,800 --> 01:02:31,030
We go and there are other people who are like, How dare you not allow me to eat this stuff?

530
01:02:33,630 --> 01:02:36,720
I see them in the looks like they exist and everything in between.

531
01:02:37,230 --> 01:02:47,910
So let's unpack this. So their product, you do not know that it's contaminated, not a romaine lettuce situation.

532
01:02:47,910 --> 01:02:55,739
Like we don't know that there is a contamination, but we also know that we have not taken steps to prevent that contamination.

533
01:02:55,740 --> 01:03:02,690
So there is a potential risk. Were the audiences.

534
01:03:04,660 --> 01:03:07,690
One audience is consumers like you.

535
01:03:08,730 --> 01:03:14,280
You wanted to know. The label didn't really say telling you that there might be risk associated with that.

536
01:03:15,360 --> 01:03:20,760
Your father didn't really convey to you from a mental bottle standpoint, anything that would help you to manage that risk.

537
01:03:21,570 --> 01:03:26,720
So that's one type of space. Not that's not a news media type thing.

538
01:03:26,750 --> 01:03:30,710
That might be a labeling thing. That might be an educational type of thing.

539
01:03:33,230 --> 01:03:36,930
Now, we fast forward and we have, you know.

540
01:03:36,950 --> 01:03:40,130
Okay. So you got sick. Now what happens?

541
01:03:41,490 --> 01:03:53,220
Who else needs to be contacted? Not like other people who bought cider that produced it as well.

542
01:03:53,280 --> 01:03:59,610
The mills that produced it like. So this isn't just a, you know, chase it down to people who drank it, but what does the mill need to do?

543
01:04:00,870 --> 01:04:11,100
And there's multiple layers there, ranging from. The bill needs to disseminate information that this risk exists versus the bill needs to shut down.

544
01:04:13,730 --> 01:04:18,560
Depending upon what the legal situation is and whether or not we think that that contamination is continuing, etc.

545
01:04:20,840 --> 01:04:27,350
A parallel one who was writing about this one, this is where I read this goes down.

546
01:04:28,490 --> 01:04:33,620
Oh, Amy, you were talking about the farm.

547
01:04:33,770 --> 01:04:41,630
You're here. And in fact, in some significant trouble because of how they were, where they were growing their stuff.

548
01:04:43,460 --> 01:04:49,370
I was talking about how I guess it was like a month ago, and one of my classes was like,

549
01:04:49,370 --> 01:04:53,480
oh, just see, you know, like produce around here has been contaminated with human waste.

550
01:04:54,020 --> 01:05:01,429
And that was the first time I had heard of it. And I'm using I talked a lot about how like that was the only time I'd heard of it,

551
01:05:01,430 --> 01:05:05,720
even though I was a consumer of like those like locations in Ann Arbor.

552
01:05:06,620 --> 01:05:11,370
And I will admit, I'm not, like, well connected in social media.

553
01:05:11,420 --> 01:05:17,660
I know there was some stuff there, but still, like through all those different channels, like I don't know what they use, but it didn't come to me.

554
01:05:17,900 --> 01:05:25,879
So I know some about this. I won't claim to have followed this story perfectly well, but this is another great example of a localized crisis context.

555
01:05:25,880 --> 01:05:31,310
It would, in the sense, relate to food dissemination. So notice what you said.

556
01:05:32,740 --> 01:05:36,280
Some produce from around here is good to have. Do you know what farm?

557
01:05:38,320 --> 01:05:45,320
You know, it's. Do you know anything else to help you narrow down what was contaminated or not?

558
01:05:46,540 --> 01:05:49,820
The only thing I saw was the list of locations that sold that project.

559
01:05:50,360 --> 01:05:53,600
So unpack the problems with this.

560
01:05:54,290 --> 01:05:59,599
Like, ideally, we should know. Are we talking about cucumbers?

561
01:05:59,600 --> 01:06:03,380
Are we talking about squash? Are we talking about lettuce? What are we talking about?

562
01:06:04,190 --> 01:06:07,760
Ideally, we should know which particular farms because often.

563
01:06:08,330 --> 01:06:16,729
Oh, but certainly the the supermarkets or stands for selling this know where they got the stuff from and be able to draw

564
01:06:16,730 --> 01:06:21,650
a distinction between is this coming from a farm where it was contaminated versus another farm where it's not?

565
01:06:24,550 --> 01:06:31,420
Deeper into this is the mental models question, which is what is the actual contamination here?

566
01:06:31,750 --> 01:06:36,590
And is there actually serious risk associated with it? Yeah, sorry.

567
01:06:36,640 --> 01:06:42,310
That's just my question because like I was under this like is it like true contamination or is it like that's what they're using as fertilizer?

568
01:06:42,310 --> 01:06:46,150
Because I was under the understanding that like there's that that's actually

569
01:06:46,150 --> 01:06:51,690
really common agricultural practices to take sewage water to fertilizer crops.

570
01:06:51,700 --> 01:06:55,150
Yeah. So I do not know, non-organic.

571
01:06:56,740 --> 01:07:06,400
Right. Something I do not know the exact detail of my understanding, which I know is imperfect,

572
01:07:07,030 --> 01:07:12,759
was that there was a piece of lab where there was some exposure.

573
01:07:12,760 --> 01:07:16,380
And I don't know whether this was because it was buried or, you know, sewage water or whatever.

574
01:07:17,480 --> 01:07:19,640
And then at a later point in time,

575
01:07:20,390 --> 01:07:32,060
the plants were planted in that space and had would have had indirect exposure to whatever might have been in that human waste content.

576
01:07:33,210 --> 01:07:36,690
It was not. Somebody went around and sprayed urine on the product.

577
01:07:37,590 --> 01:07:41,040
We're not talking about that type of direct exposure.

578
01:07:41,040 --> 01:07:46,279
We're talking about something much more indirect. But again, what you're asking is the right question.

579
01:07:46,280 --> 01:07:51,440
What is the what is the actual pathway of contamination that has been uncovered?

580
01:07:51,950 --> 01:07:56,780
And how much do we think that that actually represents a real risk versus just simply disgust reaction?

581
01:07:57,900 --> 01:08:05,729
Not that it discussed reaction is irrelevant, but if our role as communicators is to help calibrate people to what should they be concerned about?

582
01:08:05,730 --> 01:08:08,070
What should they be reacting to and what shouldn't they?

583
01:08:09,700 --> 01:08:20,050
Even if legally this was illegal, we may or may not think that there's a lot of health impact associated with it and vice versa.

584
01:08:20,350 --> 01:08:28,060
It was legal to sell that unpasteurized cider, but we might think that there is some risk associated with it that we want to be communicating about.

585
01:08:28,690 --> 01:08:35,080
Actually, separating the legal from the magnitude of health impact is also an important piece here.

586
01:08:36,870 --> 01:08:44,460
But both of these are great examples. I remember when that hit and I actually happened to have bought some of the affected product.

587
01:08:44,910 --> 01:08:49,860
I knew what that it was affected product and had cooked it and eating it like two days early.

588
01:08:52,920 --> 01:09:05,819
And, and I remember sort of sitting and thinking. Yeah, I don't really want to know that, but I did cook it and I like the ads.

589
01:09:05,820 --> 01:09:10,920
If there is anything really here that is a danger to me is essentially microscopic.

590
01:09:10,920 --> 01:09:18,690
So I'm not going to stress about this, but it's one of those things you file away and say, Yeah, well, that's just like raising a point.

591
01:09:18,690 --> 01:09:23,730
Like a lot of the things we would talk about. I would like use about recalling we don't talk about like what to do if you already eat.

592
01:09:25,080 --> 01:09:31,610
Yeah. Well. So if you think about it, what should we be doing in that moment?

593
01:09:31,630 --> 01:09:35,110
So you have an audience. They know they are at risk.

594
01:09:37,240 --> 01:09:45,100
What is our goal as communicate? Well, I would think that one of our primary goals is what should this person be doing or not doing?

595
01:09:45,100 --> 01:09:55,330
And the answer is usually going to be monitoring. This might be what could happen if you experience this type of symptom or this type of symptom.

596
01:09:55,870 --> 01:10:01,720
Don't wait. Go seek treatment because we think that it might well be this.

597
01:10:04,080 --> 01:10:08,010
What we usually try to do is to get people from both.

598
01:10:09,880 --> 01:10:14,250
Well, Congress. We neither want people to freak out, Jordan.

599
01:10:14,250 --> 01:10:20,640
We want them to be apathetic. We want them to be in that middle space. How do you do that?

600
01:10:20,660 --> 01:10:29,990
You provide clarity of what needs to be done. So if I age.

601
01:10:32,520 --> 01:10:36,570
The latest example. I had a salad three days ago. I had romaine lettuce in it.

602
01:10:36,990 --> 01:10:44,610
What am I supposed to do? I can't on the salad, but I can pay attention to my symptoms.

603
01:10:45,210 --> 01:10:50,160
If we go to a more permanent product, I can't undo the cookies.

604
01:10:50,160 --> 01:10:51,600
I just hate with the flour.

605
01:10:52,020 --> 01:10:57,780
I can go look at the flour bag and see is it one of the recalled products and decide whether I'm gonna throw out the rest of the flour.

606
01:11:00,660 --> 01:11:12,059
Now I'll share a story. Three years ago, I went to a meeting of the Food and Drug Administration's Risk Communication Advisory Committee.

607
01:11:12,060 --> 01:11:15,480
And, yes, the Food Drug Administration has a risk communication advisory committee.

608
01:11:15,810 --> 01:11:23,070
I'm the. And one of the people on the committee was somebody who was really focused on food recalls.

609
01:11:26,580 --> 01:11:31,900
And I remember this guy talking about. Things like agriculture.

610
01:11:34,660 --> 01:11:41,670
And the danger. People would look at the record and say, Oh, that's not a big problem.

611
01:11:41,680 --> 01:11:47,400
I'm just going to cook banks really well. What's the problem with that?

612
01:11:52,420 --> 01:11:56,709
Even if you cook the egg really well, you've just handled it with your hands.

613
01:11:56,710 --> 01:12:02,410
That's contaminated with salmonella. And unless you are really careful, you're going to cross contaminate with all kinds of other things.

614
01:12:03,800 --> 01:12:07,490
So you talk a lot about the food recalls.

615
01:12:08,420 --> 01:12:12,050
Messaging is often overbroad, contextual.

616
01:12:13,460 --> 01:12:17,750
So it's like, I don't want you thinking about how much risk is in these eggs.

617
01:12:17,760 --> 01:12:27,620
I want you just throw the damn things out and don't think like they minimize the cognition that are being brought up by the communications.

618
01:12:28,280 --> 01:12:31,790
They simply say, Go throw it out, throw it out right now. Don't eat this.

619
01:12:31,790 --> 01:12:39,420
Don't touch. Even though. If the eggs were cooked well and you wash your hands, etc., you might be able to manage that.

620
01:12:40,140 --> 01:12:50,530
No, not going to play that game. Okay.

621
01:12:50,530 --> 01:12:58,670
I got the side or what? I got that one. Let me ask this.

622
01:12:59,650 --> 01:13:05,140
Before you break up, is there any one of the examples that the book talked about that really surprised you?

623
01:13:06,290 --> 01:13:10,190
Goats. The goat. What? What about it? It was sad.

624
01:13:10,310 --> 01:13:14,580
It was sad. And. And we.

625
01:13:17,480 --> 01:13:21,020
I think we sometimes have those situations.

626
01:13:21,370 --> 01:13:28,340
I know that was a case of animals, but we already were talking about, you know, you know, disposing of a whole bunch of cows that had been drawn.

627
01:13:29,270 --> 01:13:32,790
Situations in which people have to throw out their entire crops because of contaminations.

628
01:13:34,700 --> 01:13:37,850
The ones that really bother me are not ones like that.

629
01:13:38,870 --> 01:13:49,430
It's when the messaging is so poor that people basically throw out products that didn't need to be thrown out.

630
01:13:50,460 --> 01:13:59,460
So I remember with H1N1, which, if you think back, was often referred to as swine flu.

631
01:14:01,170 --> 01:14:04,260
Globally, there was culling of pork crops.

632
01:14:05,640 --> 01:14:11,780
Out of concern. It was spreading the. And there was not any science really to back that up.

633
01:14:12,470 --> 01:14:21,340
But it was not. So that an overreaction is also something that we worry a lot about in crisis situations where because of the high interest,

634
01:14:21,340 --> 01:14:29,060
because of the high emotions. People are like, I have to do something so they do something, even if it's not necessarily a good something.

635
01:14:30,680 --> 01:14:35,030
All right. So we got we're going to keep coming back to these kinds of themes over and over again.

636
01:14:35,030 --> 01:14:43,170
Food's just such a great space to talk about it and. For our question of the day, I want you to think about the easy ones.

637
01:14:43,260 --> 01:14:49,079
Are the low interest, low impact like those are you know, we chip away at it.

638
01:14:49,080 --> 01:14:53,610
We try to get people to pay attention. It not that big of a deal, but high interest,

639
01:14:53,610 --> 01:14:59,610
high impact ones are also not that big of a deal because they're everybody's talked about and everybody is interested in them.

640
01:15:00,510 --> 01:15:03,810
We're interested in them. The public's interested in we talk about it and stuff happens.

641
01:15:04,590 --> 01:15:09,120
But look at these ones on the opposite diagonal. So think about.

642
01:15:09,730 --> 01:15:16,280
So I come up with some examples from the readings or otherwise that really feel like high impact,

643
01:15:16,280 --> 01:15:19,310
low interest stuff that we all pay more attention to that we don't.

644
01:15:20,280 --> 01:15:24,810
Or low impact, high interest stuff that we pay way too much attention to.

645
01:15:25,890 --> 01:15:31,710
And then think about, well, okay, what are we trying to do in that situation? But what are what should our goals be in those situations?

646
01:15:32,850 --> 01:15:40,650
And just talk through that for a while. Among shallow groups that both to get the examples out but also to really wrestle with.

647
01:15:42,540 --> 01:15:45,660
Why are we talking to you in those situations and what are we trying to accomplish?

648
01:15:46,610 --> 01:15:49,170
So sometimes the answer is going to be to get you to not freak out.

649
01:15:49,950 --> 01:15:53,220
Sometimes the answer is going to be to get you to think about something you don't want to think about.

650
01:15:54,930 --> 01:16:17,940
So take a few minutes. Let's talk about that and then I'll pull it back to right before you kind of like don't know specifically.

651
01:16:18,840 --> 01:16:55,120
I read here in New York directly we have a long way away because there is no such thing as it was amazing.

652
01:16:59,910 --> 01:17:07,389
I mean, I guess they work as sculpture, but yes, it's a very complex issue.

653
01:17:07,390 --> 01:17:14,830
But at the same time, yes, they do have this meeting.

654
01:17:16,010 --> 01:17:30,040
And I know there's got to be I mean, maybe it's a good thing, but it was hard.

655
01:17:30,060 --> 01:17:36,720
I don't know. I guess they're there all by yourself.

656
01:17:39,510 --> 01:17:53,250
I don't keep talking about stuff like that.

657
01:17:55,590 --> 01:18:10,190
I've seen other stuff like that.

658
01:18:10,290 --> 01:18:15,960
So yeah, you know, you've got to leave this one right here.

659
01:18:15,990 --> 01:18:47,520
N.A., N.A., N.A., N.A., N.A., N.A., N.A., N.A., N.A., N.A., N.A., N.A., N.A., N.A., N.A., N.A., N.A., N.A., N.A.

660
01:18:50,100 --> 01:19:15,530
That's like I think obviously they're very important, but not necessarily going on the plane crash even.

661
01:19:15,540 --> 01:19:30,730
I know I'm hopeful that moment right now and I am greatly so it that you know where people die per year from that.

662
01:19:32,400 --> 01:19:44,790
Yes. Well, you know, that's one of the great example of an action movie to clear my head.

663
01:19:44,830 --> 01:19:57,480
So I put in the effort because she's, like, interested in, you know.

664
01:20:00,760 --> 01:20:05,050
Roosevelt. Which do you hear about on the news?

665
01:20:05,090 --> 01:20:18,550
It is what it is. I'm sure I never knew what I would be signing up for today.

666
01:20:21,370 --> 01:20:30,580
Oh, it is such a lovely place. Food is such an interesting domain when we think about risk because we are all have experience with it.

667
01:20:31,420 --> 01:20:36,170
Like this isn't just a cognitive thing. We have experience with food caused by daily life.

668
01:20:36,730 --> 01:20:43,270
So there's lots of good examples of thinking about how individuals would react to crisis communications related to food,

669
01:20:43,840 --> 01:20:53,290
how we react when there's a restaurant that has a sign that they have a contamination product that makes us sick, etc. So pay attention to those.

670
01:20:54,670 --> 01:20:57,380
More Tuesday, you will read this.

671
01:20:57,390 --> 01:21:04,900
There's a short article about COVID that's sort of just probably a long but I think really, really important article.

672
01:21:05,470 --> 01:21:08,680
Stanton about dilemmas in crisis communication.

673
01:21:10,720 --> 01:21:19,240
Unpack that one. There's going to be a lot of it in particular, unpack how much you sort of nod your head and say,

674
01:21:19,240 --> 01:21:22,750
Yeah, yeah, versus you go, that I could never do that.

675
01:21:24,270 --> 01:21:27,840
Some of the things that that article recommends are going to scare you.

676
01:21:28,350 --> 01:21:33,060
I mean, to use that word intentionally, they're going to scare you. It's going to seem like, wow, you can't be serious.

677
01:21:33,660 --> 01:21:37,620
He's serious. That article was written intentionally to be provocative.

678
01:21:38,910 --> 01:21:41,250
Feel free to come to class on Tuesday.

679
01:21:41,730 --> 01:21:48,120
Not necessarily always agreeing with it, but let's pay attention to each of the dimensions that he's talking about so that we can talk through this.

680
01:21:48,600 --> 01:21:53,280
All right. I'll see you on Tuesday. Okay.

681
01:21:54,640 --> 01:21:58,710
So I think that.

682
01:22:04,040 --> 01:22:14,690
I don't really understand how that works. Or is it like all I have come to understand is how to ask you what you're really going to do if you can't?

683
01:22:15,060 --> 01:22:23,960
That's like my fear of doing something just for a moment,

684
01:22:23,970 --> 01:22:34,260
or at least a moment where it would be like the fire smells like it's going to be there, like a nurse.

685
01:22:34,260 --> 01:22:49,970
And I have a life for ten years old and it's just not stable and I feel terrible.

686
01:22:51,180 --> 01:22:55,110
Yeah, right. I mean, like I said, not bad. Yeah.

687
01:22:55,140 --> 01:22:58,410
Oh, yeah. Going downstairs to be smart. Yeah.

688
01:22:59,400 --> 01:23:04,440
Open stuff from the fridge. And then, like, there is a literal probably more in there.

689
01:23:05,310 --> 01:23:08,820
And I think it's something like how you see inside that is.

690
01:23:10,290 --> 01:23:13,470
Yeah. That is not. Nobody does that. Yeah.

691
01:23:13,780 --> 01:23:17,850
I think. Yeah. And that's the sort of thing that I'm trying to sell you more.

692
01:23:18,180 --> 01:23:21,470
Yeah. Don't understand all that. Businesses that are Asian.

693
01:23:21,570 --> 01:23:25,980
I think that can be very different. Oh, that's awesome.

694
01:23:26,010 --> 01:23:31,830
Even something like when I am baking and then I suppose yes,

695
01:23:32,130 --> 01:23:51,090
sometimes it's so bad that there is that have these inform and just any places you see, we're still fighting this war for at least three years.

696
01:23:51,200 --> 01:24:02,160
Okay. There is no prerequisite. I don't for it on the website, but when you put it into your backpack, it's listed in backpack.

697
01:24:02,640 --> 01:24:06,020
Oh, okay. Please, I'm serious.

698
01:24:06,330 --> 01:24:11,700
Send an email to both me and Jackie detailing exactly where you see it, because that should not be there.

699
01:24:13,500 --> 01:24:18,450
Simply does not have to have never really had a prerequisite that says.

700
01:24:20,580 --> 01:24:24,780
And it certainly doesn't now that we have made it one of the.

701
01:24:27,030 --> 01:24:31,160
Options for fulfillment in the near. Sticky.

702
01:24:31,850 --> 01:24:35,410
As much as I love teaching this because this is what I do in my professional life.

703
01:24:35,680 --> 01:24:40,850
Sticky is fun. Yeah. Okay.

704
01:24:42,870 --> 01:24:50,110
You are all good. Okay. Hello.

705
01:24:51,220 --> 01:24:58,170
You look tired or something? Yeah. I know, but I a always.

