1
00:01:59,630 --> 00:02:04,820
All right. Good morning, everybody. Good morning.

2
00:02:06,620 --> 00:02:10,160
How are people's weekends? Also.

3
00:02:11,490 --> 00:02:16,820
Oh, wait. Did you say too short? I hurt if you didn't.

4
00:02:16,850 --> 00:02:19,970
You should have. I always feel the same way.

5
00:02:21,210 --> 00:02:24,290
And I spent all of Saturday working, so.

6
00:02:25,900 --> 00:02:29,860
And definitely felt like it was too short. All right.

7
00:02:30,460 --> 00:02:34,210
So. But welcome back to real life.

8
00:02:34,840 --> 00:02:46,310
Too bad life can't be the weekend. Today we are going to be talking about stage two.

9
00:02:46,340 --> 00:02:53,899
So moving on from engaging stakeholders and I realize that I did not put any review slides in here.

10
00:02:53,900 --> 00:03:00,070
So. I'll just say refresh yourself.

11
00:03:02,090 --> 00:03:11,170
Okay. I have to do it this time. I usually throw a couple in there, but we'll be talking about this stage.

12
00:03:12,040 --> 00:03:17,610
And when I say I go back and forth between stage and steps, it's the same thing.

13
00:03:17,620 --> 00:03:26,800
I promise you. We'll be talking about part of it this week, but then next week we're going get into evaluation questions.

14
00:03:28,240 --> 00:03:35,230
So this kind of part of the class will take a bit longer than a week.

15
00:03:38,370 --> 00:03:43,470
Jeff, a quick announcements if you haven't got it in today already.

16
00:03:43,800 --> 00:03:51,480
The email stakeholder assignment is due by 11:59 p.m.

17
00:03:52,080 --> 00:03:55,650
So and it shouldn't take you that long.

18
00:03:55,660 --> 00:03:59,820
Just keep in mind that what you're doing is responding to.

19
00:04:01,750 --> 00:04:09,700
To a stakeholder investor party. And really, you're you see a problem.

20
00:04:10,790 --> 00:04:16,850
So you should be able to identify a problem and some reasons for that problem that the client identify.

21
00:04:17,360 --> 00:04:28,820
And you can respond with a solution with some reasons why that solution would make sense and address the problems that the client has shared with you.

22
00:04:30,710 --> 00:04:37,400
So other than that, it doesn't need to be like a sighted formal text.

23
00:04:37,790 --> 00:04:47,059
It just needs to be email. But the idea of the email is how can we talk to our partners in a way that provides some

24
00:04:47,060 --> 00:04:52,670
room for capacity building and learning while maintaining the relationship with them?

25
00:04:53,570 --> 00:05:00,200
I realized when I put it to the side, okay, let's see if that that feels.

26
00:05:00,410 --> 00:05:05,120
Does that how it sounds a little more consistent? That's what I figure, because I can hear it in my ear.

27
00:05:06,650 --> 00:05:12,770
Yeah. So that is the email assignment. And then so the next thing coming up is the quiz.

28
00:05:14,360 --> 00:05:18,200
If you haven't had a chance to I know there's some new students.

29
00:05:18,530 --> 00:05:23,299
If you haven't had a chance to meet up with your group even through email,

30
00:05:23,300 --> 00:05:30,260
I just encourage you to do that because those assignments will, number one, start coming quickly.

31
00:05:30,260 --> 00:05:36,260
But two, you can work as you go, so you don't.

32
00:05:39,220 --> 00:05:42,520
Is that? That's a phone, right? I'm not just making that up. I'm not.

33
00:05:42,610 --> 00:05:51,040
I'm not about the trip. I'm just like, wait, what is that? I mean, I remember I'm like, that term our ringer off my playing sleep sounds.

34
00:05:51,640 --> 00:05:54,760
We make sure. Yeah, okay. I'm very.

35
00:05:54,940 --> 00:06:00,339
I'm sleepy today. Like, maybe I was playing rain sounds this morning because I want to go back to bed.

36
00:06:00,340 --> 00:06:04,239
I guess so.

37
00:06:04,240 --> 00:06:06,610
Yeah. So I encourage you to meet with your groups.

38
00:06:07,390 --> 00:06:17,620
You can work as you go, and there's no rule that says you have to turn in the assignment on the very last day, the final assignment, I mean, so.

39
00:06:18,790 --> 00:06:19,269
You know,

40
00:06:19,270 --> 00:06:27,510
to the extent that you can take advantage of it and it helps you on your finals that you actually have to come to and you're able to get home earlier,

41
00:06:27,520 --> 00:06:30,840
just keep that amount. All right. No pressure.

42
00:06:30,880 --> 00:06:39,150
Just. I manage a lot of projects myself, so I'm like and a half feels like if I can get it out the way, getting out the way.

43
00:06:40,500 --> 00:06:45,180
So like I mentioned today, we're going to be talking about describing the program.

44
00:06:48,100 --> 00:06:57,040
And what's the goal of this step? So when we look at the evaluation plan and the evaluation process,

45
00:06:57,850 --> 00:07:08,860
the plan being the project that you'll be doing for the course and what you would do as a program evaluator, the goal of this step in this section.

46
00:07:09,800 --> 00:07:11,450
Is really the clarify.

47
00:07:11,450 --> 00:07:27,290
All the components and the intended outcomes of the program are policy being evaluated, and obviously you can't model or discuss unintended outcomes.

48
00:07:28,790 --> 00:07:35,450
But you know, just as a side note, sometimes when we were doing this work, we find unintended outcomes as well.

49
00:07:35,840 --> 00:07:43,910
But in this section, what you will be doing is clarifying what you can anticipate or what you have.

50
00:07:46,140 --> 00:07:51,340
Observed if. It's the case that you're doing an evaluation.

51
00:07:52,410 --> 00:07:59,110
Closer to the end of a project? Yes. Say.

52
00:08:01,150 --> 00:08:04,960
Program. One we often want to sneak in and out.

53
00:08:06,520 --> 00:08:11,900
We would, but you just wouldn't know them at the time. Yeah, yeah, yeah.

54
00:08:11,920 --> 00:08:17,020
So I think. Yeah, I threw that in there just to say that.

55
00:08:19,200 --> 00:08:23,480
When you're doing an evaluation. You.

56
00:08:25,670 --> 00:08:30,440
Should be open to potential outcomes that you didn't anticipate.

57
00:08:32,050 --> 00:08:39,160
And sometimes those outcomes are very interesting and more interesting maybe than the ones that you did anticipate.

58
00:08:40,120 --> 00:08:45,290
Thank you for clarifying that. Why is this step important?

59
00:08:45,920 --> 00:08:56,510
So that we can ensure that the evaluation team is operating from the same frame of reference about the program and not just the evaluation team,

60
00:08:56,510 --> 00:08:59,540
all the partners that you are also working with.

61
00:09:00,980 --> 00:09:10,970
This process helps to come to that same frame of reference, and then it's also helpful, though helpful to help focus the evaluation questions.

62
00:09:15,940 --> 00:09:21,950
So when you're writing when you're writing the assignment, so, you know,

63
00:09:21,970 --> 00:09:30,350
when you're writing up in the evaluation plan, they are excluding the actual diagram of a logic model.

64
00:09:30,370 --> 00:09:34,540
There's seven components. Of that section.

65
00:09:36,040 --> 00:09:40,000
Needs assessed but addressed by the program. Expected outcomes.

66
00:09:40,390 --> 00:09:45,970
Activities. Outputs. Resources. Stage of development and context.

67
00:09:47,260 --> 00:09:50,920
Two. Three. Four. Five. We will talk about on Thursday.

68
00:09:51,250 --> 00:09:56,320
So today what we're talking about is one the needs.

69
00:09:57,460 --> 00:10:01,960
And that is a step that's probably familiar to a lot of you.

70
00:10:02,640 --> 00:10:08,680
Defining the public health problem that the program or policy aims to address.

71
00:10:11,620 --> 00:10:14,980
Six. We'll talk about the stage of development.

72
00:10:15,550 --> 00:10:18,850
Is the program or policy just getting started?

73
00:10:19,510 --> 00:10:26,200
Is it in the implementation stage or has it been underway for a significant period of time?

74
00:10:27,150 --> 00:10:30,180
That's the core question driving that component.

75
00:10:31,320 --> 00:10:40,650
And then context. What factors and trends in the larger environment may influence the program's success or failure?

76
00:10:50,470 --> 00:10:58,480
So let's start with defining problems. So when we are defining a problem.

77
00:11:01,130 --> 00:11:10,610
And this likely seems familiar to you all. What you're writing is a description of the problem or opportunity that the program itself addresses.

78
00:11:11,420 --> 00:11:15,170
So, for example, we're defining the focal population.

79
00:11:15,560 --> 00:11:18,860
Who is this program actually focusing on?

80
00:11:20,900 --> 00:11:27,170
And that can even account for potential subgroups within the population.

81
00:11:27,590 --> 00:11:30,980
So say you're working with public health students.

82
00:11:32,160 --> 00:11:39,600
Now we know in this room that there are also subgroups. There's the harbors, the HB H e students.

83
00:11:40,200 --> 00:11:44,820
We've got effort, epidemiology, students, environmental health.

84
00:11:45,270 --> 00:11:52,530
We have social work students who are not public health students, but we love them all the same.

85
00:11:53,790 --> 00:12:00,700
So there's different subgroups within that idea, that bubble of public health.

86
00:12:02,460 --> 00:12:09,310
We also talk about the nature of the problem. So is it a stable problem or is it dynamic?

87
00:12:09,330 --> 00:12:15,570
And what I mean by that question is we can look at different dimensions of that.

88
00:12:17,280 --> 00:12:23,420
Our, for instance, prevalence rates are rising, decreasing.

89
00:12:24,750 --> 00:12:37,710
Have we learned about new take it, for example, new variants that affect the magnitude of disease in the given person.

90
00:12:39,170 --> 00:12:47,780
So we're also thinking about the nature of the problem, and then we're thinking about the scope of the problem.

91
00:12:48,290 --> 00:12:59,780
So who's affected by and to what extent? And again, that's we're thinking about the subgroups and discussing subgroups also comes into play because.

92
00:13:02,970 --> 00:13:07,330
I was going to make a joke, but I'm not going to make a joke. See?

93
00:13:07,370 --> 00:13:20,580
I'm tired. No joke for today. Thinking about, you know, disparities within group in addition to compare to other groups.

94
00:13:21,030 --> 00:13:34,320
For example, one, when we think about racial disparities, one thing that we often see is a given, a given racial ethnic group compare to whites.

95
00:13:35,820 --> 00:13:41,040
But that doesn't that isn't necessarily the only standard that we want to use.

96
00:13:41,040 --> 00:13:48,510
We may want to look within a group and identify disparities among subgroups.

97
00:13:49,950 --> 00:14:00,900
For example, and it's helpful to I kind of go back and forth on how that discussed this aspect of it.

98
00:14:02,310 --> 00:14:13,980
You do want to consider like a mini literature review, but you only really need to include that what's necessary to inform your evaluation activities.

99
00:14:15,420 --> 00:14:19,590
So this isn't your, you know, your comprehensive literature review.

100
00:14:19,890 --> 00:14:22,140
You're, you know, multiple pages.

101
00:14:22,410 --> 00:14:31,590
It's really pulling out some data and some information that helps contextualize why a program might have the design that it does.

102
00:14:34,210 --> 00:14:41,500
Yeah. I often see when, you know, because I generally give this type of assignment when I teach this class,

103
00:14:43,150 --> 00:14:49,090
people like that love to go the town on this section and I love it.

104
00:14:50,020 --> 00:14:58,990
Because I like to learn. But if you're thinking, Oh, man, I just wrote this five page intro on this says Only a page and a half.

105
00:14:59,470 --> 00:15:07,840
What do I do? Which I have already encountered in the class I'm teaching at night because we've already passed this section.

106
00:15:09,640 --> 00:15:19,740
Think about it this way. You really. Does this help the reader or the team understand why the program exists?

107
00:15:22,330 --> 00:15:31,990
So that might help kind of narrow your scope in terms of the literature that you need to bring into the into the the problem statement.

108
00:15:37,810 --> 00:15:44,230
And ultimately what you're thinking about, too, is what's visible.

109
00:15:44,920 --> 00:15:48,729
Because in order, especially because in the evaluation,

110
00:15:48,730 --> 00:15:57,490
we're not just identifying gaps in literature or knowledge where we're creating products that are.

111
00:15:58,760 --> 00:16:02,540
Very closely connected to some type of social action.

112
00:16:03,560 --> 00:16:13,910
So your. Problem statement is really about how can we make the scope of this problem more visible?

113
00:16:15,630 --> 00:16:22,260
I shared this very lovely, complicated diagram before.

114
00:16:23,040 --> 00:16:27,270
And what it's really saying is that.

115
00:16:28,550 --> 00:16:36,570
You know, take us in public health. We have. You know, tried and true methods of defining what the problem is.

116
00:16:36,870 --> 00:16:42,810
And we tend to focus in on what's in read, write the magnitude, the scale or enormity of the problem.

117
00:16:43,860 --> 00:16:52,020
And so that what we generally will do is pretty consistent in terms of how we say a problem is a problem.

118
00:16:54,750 --> 00:17:01,080
So, you know, thinking about what I'm about to write in the red. Generally, professionally speaking.

119
00:17:02,640 --> 00:17:08,160
What's acceptable around here is pretty standard, you know, pretty consistent, again,

120
00:17:08,160 --> 00:17:14,100
because we use systematic methods to say what's a problem versus not a problem.

121
00:17:14,610 --> 00:17:26,300
And then in turn, we also. We'll be pretty consistent about what is a problem and what's not a problem.

122
00:17:27,620 --> 00:17:33,530
And then there might be some gray area, right? I mean, we in, you know, methods might change.

123
00:17:36,700 --> 00:17:39,760
Maybe our understanding of an issue might change.

124
00:17:40,390 --> 00:17:47,410
But what we also have to remember is that socially speaking, this changes.

125
00:17:47,530 --> 00:17:50,740
So what may be a problem today?

126
00:17:51,850 --> 00:17:57,370
May not be a problem tomorrow. I mean, we kind of starts we're seeing it right now with COVID, right?

127
00:17:57,790 --> 00:18:01,360
Where in in 2020, man.

128
00:18:01,510 --> 00:18:07,240
COVID was like right here and now it's kind of in this gray area, you know?

129
00:18:07,360 --> 00:18:11,770
You know, some of your wear masks, some of you are not I'm not wearing a mask.

130
00:18:12,590 --> 00:18:19,940
I mean, you know, I didn't even have my phone ready to show to the responsible blue person at the door today because I'm like, they don't care.

131
00:18:20,780 --> 00:18:28,730
I'm let me call out my phone. You know, that's that's this line and action.

132
00:18:29,570 --> 00:18:35,299
And we have to remember that because how people will generally,

133
00:18:35,300 --> 00:18:42,320
just in regular life define problems are, you know, the visibility of a problem is different.

134
00:18:43,040 --> 00:18:48,260
Can I see the problem? Is it near me? Am I thinking about it every day?

135
00:18:49,460 --> 00:18:59,020
So when we are thinking about this for evaluation, it's helpful to know not just this and this is what's going to show up in that like a,

136
00:18:59,090 --> 00:19:08,040
you know, mini literature review this part right here. But we also need to think about and consider this as context, this line here.

137
00:19:16,410 --> 00:19:23,660
Oh, and you know, just a mention because again. Proximity, intimacy, awareness.

138
00:19:23,670 --> 00:19:27,600
These are the lenses through which our partners.

139
00:19:28,720 --> 00:19:32,320
Will I, especially community members.

140
00:19:33,130 --> 00:19:37,000
That's the lens through which they're going to look at our data.

141
00:19:42,560 --> 00:19:49,340
And that kind of segways us into defining context because we also want to understand, you know,

142
00:19:49,340 --> 00:20:01,760
part of it is but do what's been a problem and what do people see as a problem within the context of this evaluation process.

143
00:20:02,990 --> 00:20:07,670
So when we're starting to think about context, we're also thinking about.

144
00:20:10,030 --> 00:20:17,109
Historical, structural, political, social, community,

145
00:20:17,110 --> 00:20:24,700
interpersonal and individual factors that shape the problem and will be important for us to consider in evaluation.

146
00:20:25,420 --> 00:20:29,980
And so, again, think about last week we talked about stakeholder analysis,

147
00:20:31,360 --> 00:20:36,850
who's in a position of power, who's in a position of influence and who's interested.

148
00:20:37,390 --> 00:20:43,660
And part of identifying that is understanding the context in which we're working now.

149
00:20:46,560 --> 00:20:50,940
And so when we take time to understand context,

150
00:20:51,900 --> 00:20:59,190
it really does allow us as evaluators to account for the key contextual factors in the evaluation, design and conclusions.

151
00:20:59,940 --> 00:21:03,480
So if we know, for example, that there is.

152
00:21:05,740 --> 00:21:10,660
You know, some political will that would discourage.

153
00:21:11,820 --> 00:21:15,150
Comprehensive sex education in a given district.

154
00:21:17,010 --> 00:21:25,220
That's going to have an impact on the success or challenges of a given comprehensive sex education program.

155
00:21:28,210 --> 00:21:33,610
And again, pointing to merit, worth and significance that's going to look different and.

156
00:21:35,250 --> 00:21:41,160
A a very conservative community versus somewhere like Ann Arbor.

157
00:21:46,740 --> 00:21:52,880
When we are defining context, we also want to think about the program.

158
00:21:53,220 --> 00:21:59,340
So so far we talked about the problem. What's the context of the problem?

159
00:21:59,700 --> 00:22:04,710
Why does the problem exist? What are some of the structural factors?

160
00:22:04,740 --> 00:22:10,410
What are some of the social factors? Well, there are some of the individual factors that we need to consider.

161
00:22:11,130 --> 00:22:14,850
But we also want to do the same thing for the program.

162
00:22:17,470 --> 00:22:22,670
And I should say that from. Like a pragmatic perspective.

163
00:22:23,490 --> 00:22:30,320
Well, you know, in other words, when you're doing this assignment, this doesn't mean, oh, another like three pages.

164
00:22:31,010 --> 00:22:41,930
You know, they're just solely dedicated to context. But it does it does mean lifting up some of the most important factors.

165
00:22:43,580 --> 00:22:46,760
And so it's helpful to kind of think through that process.

166
00:22:47,850 --> 00:22:55,100
What's likely what are you seeing making the most the biggest impact on the program and on the problem?

167
00:22:56,570 --> 00:23:00,560
So just keep that that was also kind of a pragmatic suggestion.

168
00:23:00,830 --> 00:23:04,160
Don't feel like you need to write again, a big lit review,

169
00:23:04,730 --> 00:23:09,620
but you just want to lift up some of those key contextual factors that you think are important.

170
00:23:12,320 --> 00:23:16,910
But back to the slide. We're talking about the program again.

171
00:23:16,910 --> 00:23:23,840
We're talking about historical, structural, political, social, etcetera that influence the program.

172
00:23:25,070 --> 00:23:36,649
So, for example, you may be doing a program that is a health peer education program and two different agencies.

173
00:23:36,650 --> 00:23:41,540
One may have a long reputation for doing this work.

174
00:23:42,680 --> 00:23:50,930
Maybe they've been around for like 20 years and they've been running peer education programs since that model was ever created.

175
00:23:51,320 --> 00:23:56,900
And then you might have a new one that is kind of the new kid on the block.

176
00:23:59,180 --> 00:24:06,020
Sorry. I'm. I'm old enough that New Kids on the BLOCK was actually like what we all listen to now.

177
00:24:06,440 --> 00:24:09,650
Okay. If you don't know who and the kids on the block is, I'm just gonna be quiet.

178
00:24:12,750 --> 00:24:14,250
Had just told you how old I am.

179
00:24:16,450 --> 00:24:27,520
And so in the same way, when we account for these factors in the evaluation plan and in this description of the program,

180
00:24:27,790 --> 00:24:31,360
it really does allow us to account for key contextual factors.

181
00:24:33,220 --> 00:24:39,580
So I think, you know, again, taking the example of a program.

182
00:24:41,520 --> 00:24:45,030
That is. You know, in an agency.

183
00:24:46,820 --> 00:24:52,770
What's the agency's? What's the agency's context?

184
00:24:53,910 --> 00:24:59,070
Are they seen? Are they? Do they have the capacity to be able to do this work effectively?

185
00:25:01,110 --> 00:25:04,710
Do they have the resources to be able to do it efficiently?

186
00:25:05,680 --> 00:25:11,140
Or is this a new thing for them? And if it is a new thing.

187
00:25:12,480 --> 00:25:15,380
Is this a mission? You know, is there mission creep here?

188
00:25:15,390 --> 00:25:25,650
Is there some scope creep where they kind of moving outside of their typical expertize or area of service?

189
00:25:26,970 --> 00:25:33,990
That's one you see a lot where, you know, the organization says, oh, let's chase the money, let's find the money.

190
00:25:34,680 --> 00:25:40,230
So, okay, you know, these particular problems are getting more funding than others.

191
00:25:40,380 --> 00:25:46,680
So or it's we're probably the best ones to do it because, you know, we've been working here for so long.

192
00:25:46,680 --> 00:25:51,630
We know we have to solve all problems in a given geographic location.

193
00:25:54,270 --> 00:26:01,090
And then also issues of equity. You know, is is.

194
00:26:02,570 --> 00:26:07,580
A given agency known for doing this work with an equity lens?

195
00:26:07,940 --> 00:26:13,580
Or are they serving a population that has to this point, not been served well?

196
00:26:14,750 --> 00:26:18,110
So these are some things that you want to think about at the agency level.

197
00:26:19,300 --> 00:26:28,150
Thinking about community level, what are the needs in the community and how does this program fit within that?

198
00:26:28,720 --> 00:26:37,090
And that doesn't mean that a program has to fit the the the biggest needs in the community in order to be successful.

199
00:26:37,780 --> 00:26:39,730
But it should at least account for them.

200
00:26:41,290 --> 00:26:53,650
If you have, for example, a like well, I spent last week writing a brief about workforce development and four in Detroit.

201
00:26:54,400 --> 00:26:58,330
If you're going to do workforce development, which means you got to go to work,

202
00:26:59,650 --> 00:27:05,560
are you accounting for one of the biggest barriers to work in Detroit, which is transportation?

203
00:27:06,460 --> 00:27:10,480
Transportation system is very unstable.

204
00:27:11,710 --> 00:27:19,360
So as an evaluator, I'm going to be attentive to that because at some point something's about the pop off where

205
00:27:19,510 --> 00:27:23,620
you're just not the program is going to struggle if they don't account for transportation.

206
00:27:25,330 --> 00:27:32,470
And they know the people that they're working with will struggle to meet their goals because transportation.

207
00:27:33,040 --> 00:27:38,650
So that's an example of something you want to consider as you're starting the process.

208
00:27:39,650 --> 00:27:43,160
And then finally, social policy forces.

209
00:27:45,470 --> 00:27:48,970
Workforce development. Another good example is not necessary.

210
00:27:48,980 --> 00:27:52,670
I think it's public health, but it's not traditionally thought about as public health.

211
00:27:53,390 --> 00:27:59,870
But there are lots of forces that operate to make workforce development challenging.

212
00:28:00,440 --> 00:28:06,800
What's, you know, what's considered a good job or what, you know, where's their pay equity?

213
00:28:07,400 --> 00:28:11,120
How are people being prepared for given jobs?

214
00:28:13,070 --> 00:28:18,170
And so if people haven't, for example, received adequate.

215
00:28:19,990 --> 00:28:26,110
Secondary education to take on some of the work available in the given geographic area.

216
00:28:26,830 --> 00:28:30,610
Then a workforce development program would have to account for that.

217
00:28:31,270 --> 00:28:40,240
That example makes sense, like they're not going to be successful if they are coming on solid secondary education.

218
00:28:40,900 --> 00:28:47,910
And as a evaluator, I've got to ask. Okay. When we're talking about this group of participants.

219
00:28:48,920 --> 00:28:56,600
Do they have the basic? Are the basic needs they need to be successful, fulfilled.

220
00:28:56,930 --> 00:29:04,370
Because if that's not already fulfilled in most cases, then I'm going to have problems saying that program is going to have problems.

221
00:29:04,370 --> 00:29:09,170
And so I'm going to need to understand why is the program having problems?

222
00:29:09,890 --> 00:29:16,370
Because participants were lacking something that the program was not providing.

223
00:29:17,810 --> 00:29:23,630
And the reason why they don't have the participants don't have it is because of these social forces.

224
00:29:27,110 --> 00:29:32,750
So again. Lifting up some of those key factors is helpful.

225
00:29:34,000 --> 00:29:40,360
Especially when you get to conclusions. And so as you I mean, and then it's not just a one time learning as well.

226
00:29:41,230 --> 00:29:46,620
Yes. You'll write up a plan. But that plan in some ways is a living document.

227
00:29:46,630 --> 00:29:51,070
It can be modified and changed as learning continues.

228
00:29:57,880 --> 00:30:07,360
The next section, if you will, is that our component is population, so defining population.

229
00:30:08,200 --> 00:30:12,340
You also want to think about the board. You want to think about the boundaries of your population.

230
00:30:12,490 --> 00:30:16,380
So there's geographic boundaries. There's identity.

231
00:30:16,390 --> 00:30:22,030
Social identity boundaries. Who is your population?

232
00:30:25,200 --> 00:30:31,080
And it's helpful that and the reason why you're going to you need to define those boundaries.

233
00:30:32,160 --> 00:30:38,190
Because. Is because. What was that about to say?

234
00:30:39,720 --> 00:30:49,060
I lost my train of thought. You know, I'm also trying to figure out how to say this.

235
00:30:52,890 --> 00:30:58,500
If you keep a population too broad, it's hard to understand.

236
00:30:59,890 --> 00:31:04,930
The context is hard to understand the problem.

237
00:31:07,270 --> 00:31:13,900
You want to be able to have your population be narrow enough that you can adequately assess.

238
00:31:14,950 --> 00:31:18,940
Whether in that the program components match the population.

239
00:31:23,130 --> 00:31:33,840
And it can be, you know, because I've seen some programs and people define a population that can be like strictly geographic, for example.

240
00:31:34,170 --> 00:31:40,740
But then you kind of have to think about, okay, what are the program components that match this population?

241
00:31:42,420 --> 00:31:48,480
And so if you're too broad, it just it's just really difficult to think about things that they have in common.

242
00:31:48,840 --> 00:31:51,840
I mean, again, think about this room in public health.

243
00:31:51,840 --> 00:31:57,060
We have a particular perspective on what a problem is.

244
00:31:57,390 --> 00:32:07,800
We focus on health. We generally have, you know, ideas about what it means to either now eat nutritious foods.

245
00:32:09,360 --> 00:32:18,420
Those things kind of make us into a community that and that has have that those share characteristics that.

246
00:32:19,360 --> 00:32:24,160
As an evaluator, I need to understand in order to successfully evaluate a program.

247
00:32:27,130 --> 00:32:31,870
You also want to think wisely about how you define the population.

248
00:32:32,350 --> 00:32:35,620
In order to illustrate the scope of your population.

249
00:32:36,190 --> 00:32:41,530
Again, so thinking about your program samples, your program sample.

250
00:32:41,920 --> 00:32:46,030
Most programs don't intervene with everybody in a given population.

251
00:32:46,840 --> 00:32:56,270
So why are you picking this particular sample? To focus the program and then pass the evaluation on.

252
00:32:57,490 --> 00:33:02,270
Sorry, I didn't catch. I agree with that.

253
00:33:02,270 --> 00:33:05,980
So sorry. You the evaluator for the program and what do you do with.

254
00:33:09,470 --> 00:33:12,530
Okay. I was hoping we're not I'll say the disagreement part.

255
00:33:12,530 --> 00:33:18,049
So the question is, I don't know. I'm bullying him.

256
00:33:18,050 --> 00:33:24,560
I don't know. So the question was how? Who sets the boundaries for a pop?

257
00:33:24,560 --> 00:33:31,070
Ah, for a population. The client you're working with or the evaluator.

258
00:33:31,070 --> 00:33:38,480
And what do you do if there's a disagreement? The client really should be defined in the population.

259
00:33:40,070 --> 00:33:46,070
And I'm glad you asked the question, because I realize even as I'm up there, get thrown off because I'm talking about this.

260
00:33:46,460 --> 00:33:54,170
I also do program design, so I'm talking as if I'm actually designing the program and that's what you'll be doing, which is really not the case.

261
00:33:54,530 --> 00:33:58,700
You're learning from a client what they have.

262
00:33:59,840 --> 00:34:03,740
What they have done. But what I found in practice is that.

263
00:34:04,770 --> 00:34:11,250
That's not always the case. So, you know, maybe a population is really broad.

264
00:34:12,560 --> 00:34:18,470
Or maybe it's kind of not fleshed out like we're going to help the kids in Ann Arbor.

265
00:34:18,950 --> 00:34:23,180
All kids. Is there age group like?

266
00:34:23,420 --> 00:34:31,040
So you end up working in a kind of a capacity building role to kind of help.

267
00:34:31,080 --> 00:34:41,140
Okay. Can. Let's kind of walk together through this process when there's disagreements, especially.

268
00:34:42,150 --> 00:34:46,860
If you're especially if you're not working with the client to do the defining.

269
00:34:50,060 --> 00:34:54,830
What the client in this case, what the client says goes because they've designed the program.

270
00:34:56,480 --> 00:35:05,630
But it is a little tricky because I have come in with clients where they have a a program and they can even be running.

271
00:35:05,990 --> 00:35:09,600
But then when I ask, okay, well, who is this program targeted to?

272
00:35:12,100 --> 00:35:15,820
That that that that's what I get sometimes.

273
00:35:16,180 --> 00:35:22,750
And so I'm working with them to try to kind of help them flesh out what it is that they are doing.

274
00:35:26,160 --> 00:35:33,430
But rarely do I say you're wrong. And you know, I can't say it from an outside perspective.

275
00:35:34,000 --> 00:35:39,850
You know, you say that you want to serve Ann Arbor kids, but I see Ypsi kids, I see Cam kids,

276
00:35:39,850 --> 00:35:49,390
I see smiling kids, I see Dundee kids or and and that's because there's been some kind of disconnect or creep.

277
00:35:50,340 --> 00:35:54,330
So I can be helpful in helping them identify that as well.

278
00:35:56,030 --> 00:35:59,210
Is it possible or common to do an evaluation of.

279
00:35:59,750 --> 00:36:07,200
Subset. So if. You did see a bunch of different tests that they wanted to evaluate.

280
00:36:08,240 --> 00:36:11,690
The program's assessed on a subset of participants.

281
00:36:13,970 --> 00:36:18,980
It can't. Yeah. So the question is, is it common to you say comma and put that word in?

282
00:36:18,980 --> 00:36:27,290
It is a common to do an evaluation just with the subs with a subset of program participants.

283
00:36:28,560 --> 00:36:31,860
I don't know if it's common, but it is has been done.

284
00:36:33,390 --> 00:36:42,520
And honestly, you do see this where. Where I have participated in that.

285
00:36:42,880 --> 00:36:49,120
It's been related to the health care system where there's like there's a standard of care.

286
00:36:49,360 --> 00:36:53,530
And there the the clients are trying to find out.

287
00:36:55,600 --> 00:37:02,110
Are we serving this subset of our population or our audience?

288
00:37:03,340 --> 00:37:08,590
Well, often it's like, okay, are we serving our.

289
00:37:10,370 --> 00:37:21,090
You know, are we serving our. Clients of color are we're serving LGBTQ clients well.

290
00:37:22,230 --> 00:37:24,780
So typically when I see that,

291
00:37:24,780 --> 00:37:35,580
it's really about are we addressing the factors that might be creating disparate access or disparate our disparate care for this group?

292
00:37:39,660 --> 00:37:46,770
Does that help and does that answer a question? Right.

293
00:37:50,150 --> 00:37:56,090
And so the third bullet point and clue markers of social identity and this intersection.

294
00:37:57,170 --> 00:38:01,250
So are there subpopulation disparities? So we were just talking about that.

295
00:38:01,820 --> 00:38:05,090
Are there potential barriers for successful implementation?

296
00:38:05,750 --> 00:38:11,420
Might be community level, cultural, level, social, structural.

297
00:38:12,170 --> 00:38:18,440
Again, think about that. Transportation, that's a potential barrier.

298
00:38:18,980 --> 00:38:26,120
So if I'm doing a regional initiative, so I'm looking at Wayne McComb in Oakland County,

299
00:38:26,120 --> 00:38:31,010
which we're in Washtenaw, but most of the people in Michigan live in those three counties.

300
00:38:32,480 --> 00:38:35,450
And I'm not considering the fact that.

301
00:38:37,150 --> 00:38:46,299
A high percentage of African-Americans live in a city with horrible transportation and their historical antecedents to that,

302
00:38:46,300 --> 00:38:54,280
which include city municipalities in the other counties blocking transportation, access.

303
00:38:54,820 --> 00:39:02,380
And the jobs are in those areas. I can't account for all of that because I'm going to be hard pressed.

304
00:39:04,180 --> 00:39:10,630
You know, that program is going to be hard pressed to be successful if they don't account for those barriers.

305
00:39:12,550 --> 00:39:16,420
And this and this is part of where, you know, again, just you know.

306
00:39:17,550 --> 00:39:32,220
Making a little detour. This is probably where the Cree lands comes into play a lot in the effort to take the time to understand the context because.

307
00:39:33,580 --> 00:39:40,000
Ultimately what we're not trying to say a program is successful or not, you know, a good program versus a bad program.

308
00:39:40,690 --> 00:39:43,809
To us, it's about, okay, what? What's working?

309
00:39:43,810 --> 00:39:51,740
What's not working? And so that's the kind of back to the the main, you know, main discussion.

310
00:39:53,590 --> 00:39:55,420
That's why we want to think about barriers.

311
00:39:56,780 --> 00:40:06,829
And then also as an evaluator, if I'm thinking about markers of social identity and intersections, it helps me in relationship to context.

312
00:40:06,830 --> 00:40:15,950
Think about who's missing. You're serving Ann Arbor youth, but where are youth who live on?

313
00:40:17,970 --> 00:40:22,050
The North Side. You know, you're located on the west side of Ann Arbor.

314
00:40:22,590 --> 00:40:29,130
What about youth who live on the north side? You know, I say that I was trying to think of my geography.

315
00:40:29,610 --> 00:40:33,660
No, actually, that's the south side, I think. Yes, it is south.

316
00:40:33,780 --> 00:40:37,550
Sorry. South is where?

317
00:40:38,570 --> 00:40:44,570
In Ann Arbor there. Multiple public housing neighborhoods.

318
00:40:45,440 --> 00:40:50,600
So that's a contextual factor. And so I'm going to ask a client.

319
00:40:50,750 --> 00:40:57,710
Okay. Your programs on the West Side, but you're missing a lot of youth who would benefit from this program.

320
00:40:58,840 --> 00:41:06,340
So there's kind of a suggestion for improvement. Any questions?

321
00:41:10,750 --> 00:41:14,620
So lots of things to consider. It's helpful, though. Keep all this written down, you can see.

322
00:41:17,490 --> 00:41:29,510
The next thing we'll talk about is stage program has stage had or program stage has implications for evaluation, example, fidelity and adaptation.

323
00:41:30,890 --> 00:41:34,400
I like this language better than just saying fidelity.

324
00:41:34,670 --> 00:41:39,260
Fidelity. To me, speaks to that.

325
00:41:39,260 --> 00:41:46,610
There's only one way to run a program and that we shouldn't account for change that we see as we're implementing.

326
00:41:47,180 --> 00:41:56,360
Whereas fidelity and adaptation allows and assumes that there will be change, there will be ways that a program will adapt to change.

327
00:41:59,150 --> 00:42:03,770
Program stage also has important implications for engagement.

328
00:42:05,090 --> 00:42:12,230
If a program is new, for example. Is that other LA?

329
00:42:16,250 --> 00:42:20,260
Okay. No, father. Okay. I'll keep going.

330
00:42:23,400 --> 00:42:32,010
Have input implications for engagement. So you may be working with a wet program clients or program staff.

331
00:42:33,550 --> 00:42:38,140
What is it? Okay, I'm just. I'm going to have to work by. I'm going to ignore it.

332
00:42:38,620 --> 00:42:47,979
Like it as well. Make sure we're not needing to run out has implications for engagement also

333
00:42:47,980 --> 00:42:52,450
has implications for evaluation questions as we'll talk more about next week.

334
00:42:53,980 --> 00:42:59,290
You know if if a program is new where we're asking a question like.

335
00:43:00,260 --> 00:43:02,600
Who's not being accounted for?

336
00:43:03,830 --> 00:43:17,450
Is this program the right program for this group that you've chosen to focus on, whereas a mature program may be asking questions about replication?

337
00:43:19,850 --> 00:43:23,680
There are no, like, hard and fast rules about defining stage.

338
00:43:23,690 --> 00:43:34,460
Like, there's no like a program must have ran for six months in order to be new or or ran for six months to be considered.

339
00:43:35,810 --> 00:43:52,440
Phil tested. It really it's about kind of getting to know the program and also following the guidance of your partners, especially program staff.

340
00:43:53,800 --> 00:43:59,970
I also figure in the midst of the there's the sound to mention that there's really three stages.

341
00:43:59,970 --> 00:44:04,500
You only need to worry about planning, and that's your new programs.

342
00:44:05,810 --> 00:44:17,270
Implementation stage, which means that they're in the process of doing a program, implementing a program, and in some ways it's already feel tested.

343
00:44:17,270 --> 00:44:20,600
So they probably already encounter some problems.

344
00:44:20,960 --> 00:44:26,300
And I mean that like social problems. I mean, like actual just tangible problems like.

345
00:44:27,920 --> 00:44:31,220
Operational problems. And then.

346
00:44:32,880 --> 00:44:37,710
Effects, which is about mature. What effects are we able to see?

347
00:44:38,070 --> 00:44:42,570
We're finally at a stage where we can see some outcomes emerging.

348
00:44:45,800 --> 00:44:53,780
There's also a connection to program stage and purpose as well as program evaluation type.

349
00:44:54,920 --> 00:45:00,950
So if some program is early in program development, so they're at that planning stage,

350
00:45:02,810 --> 00:45:08,480
you're going to want to look more at needs assessment or also formative evaluation,

351
00:45:09,110 --> 00:45:14,420
because really what that program needs is to it needs to understand.

352
00:45:15,350 --> 00:45:19,190
Is the program addressing a specific and relevant need?

353
00:45:20,030 --> 00:45:26,880
So are they addressing a need that actually exist? During program implementation.

354
00:45:26,900 --> 00:45:35,450
So again, thinking about that implementation stage where they've already kind of gone out and tested some things out in the field.

355
00:45:37,460 --> 00:45:45,050
One type of evaluation that is definitely appropriate is process evaluation.

356
00:45:46,310 --> 00:45:54,110
For example, are the program resources adequate? Is the program has is it being implemented well?

357
00:45:55,670 --> 00:46:02,149
So, for example, in our program staff or other invested parties,

358
00:46:02,150 --> 00:46:10,130
are they accounting for changes in the field or as problems arise, are they able to address those?

359
00:46:11,360 --> 00:46:16,940
And then is the program reaching its focal population or target population?

360
00:46:19,170 --> 00:46:23,040
Depending on how far the program is being implemented.

361
00:46:23,880 --> 00:46:29,910
And it is at the point where you or it will get to the point where you might see some effects.

362
00:46:31,260 --> 00:46:37,440
That's an appropriate time to bring in some of the types of evaluation.

363
00:46:37,440 --> 00:46:42,480
So we'll talk about outcome evaluation in the class and not impact evaluation.

364
00:46:44,010 --> 00:46:50,250
Kind of a question driving those is, is the program effective in creating positive outcomes?

365
00:46:52,920 --> 00:46:58,860
I'm wondering, I'm going to test something to see if I can stop the buzzing from stopping.

366
00:47:02,170 --> 00:47:05,950
No, that didn't work. I thought maybe if I turned on the mixer, it would work.

367
00:47:08,310 --> 00:47:13,920
I thought maybe it was conflicting. So after a program is implemented,

368
00:47:14,550 --> 00:47:25,230
or if you're near the end of kind of a program's first iteration outcome evaluation and efficiency evaluation are appropriate types of evaluation.

369
00:47:27,330 --> 00:47:33,150
Efficiency evaluation, a question that drives that is, is the program cost effective?

370
00:47:35,010 --> 00:47:39,480
So stage is helpful in picking design as well as picking type.

371
00:47:44,920 --> 00:47:51,460
Oh, and the disclaimer I like to always give the disclaimer that doesn't mean that you only have to do this.

372
00:47:51,760 --> 00:48:00,580
There might be a program that's already been implemented and wants to think about replication, so they might want to actually do a needs assessment.

373
00:48:02,390 --> 00:48:07,910
In order to think about, okay, what needs is this program addressing?

374
00:48:08,900 --> 00:48:14,300
So that I can think about where's the best places to replicate this this program?

375
00:48:17,890 --> 00:48:27,910
So you're also going to be called on to in this evaluation plan in general to identify the purpose or use of the evaluation.

376
00:48:28,840 --> 00:48:36,340
So what are some potential uses? We can help others understand the program and its results.

377
00:48:38,830 --> 00:48:45,580
We can help improve a program measure whether the program made a difference in people's lives.

378
00:48:46,270 --> 00:48:51,990
So, you know, tangible outcomes, even in tangible outcomes.

379
00:48:52,000 --> 00:48:57,250
I mean, we talked at some point, you know, just brought that example of hope.

380
00:48:57,880 --> 00:49:04,750
Hope is intangible and are something that's difficult to measure.

381
00:49:05,590 --> 00:49:16,180
Another one that is increasing giving, increasing visibility, racial healing, that's kind of a really complex.

382
00:49:18,460 --> 00:49:20,140
Construct to measure.

383
00:49:21,490 --> 00:49:32,920
But when you do, for example, a qualitative interview, you can you can actually identify some of those intangible things people will talk about.

384
00:49:32,920 --> 00:49:43,300
This was a healing space, for example. So making a difference is not just in terms of this scientific idea of.

385
00:49:45,640 --> 00:49:54,810
I didn't, you know, identifying and measuring a construct the intangible differences that can also be accounted for or measured.

386
00:49:56,740 --> 00:50:04,450
Determine if a program is worth the cost. So a program may be effective, but not cost effective.

387
00:50:06,160 --> 00:50:19,030
Yeah. Earlier I mentioned a cost evaluation I did of a caregiver support program and that in that case, it was cost effective.

388
00:50:19,330 --> 00:50:22,420
The program cost is saved.

389
00:50:23,530 --> 00:50:26,800
If a pro if the program was successful.

390
00:50:27,850 --> 00:50:35,950
For a caregiver. It saved the state approximately $80,000 a year.

391
00:50:36,550 --> 00:50:40,180
Because then the state didn't have to pay $90,000.

392
00:50:41,010 --> 00:50:45,830
For. For nursing home care.

393
00:50:47,450 --> 00:50:52,790
So in that case, it'll only cost $10,000 to operate that program.

394
00:50:53,810 --> 00:50:58,520
But what if it actually costs $100,000 per person to operate that program?

395
00:50:58,790 --> 00:51:08,480
That's a little different story. So sometimes clients also just want to know, is this something that I can justify paying for?

396
00:51:10,400 --> 00:51:16,580
And all my social work friends are probably also thinking it's always worth paying for.

397
00:51:16,850 --> 00:51:20,660
And I do have and to the extent agree with you.

398
00:51:21,140 --> 00:51:26,960
But unfortunately, capitalism does not bode capitalism.

399
00:51:27,260 --> 00:51:34,540
Somebody has got to pay for it. Sometimes that gets into a long discussion.

400
00:51:34,560 --> 00:51:38,030
When I teach, this is social work. Down with the cost.

401
00:51:38,870 --> 00:51:44,490
I know I can't concentrate this buzzing sound, though.

402
00:51:44,510 --> 00:51:51,000
I've never. You think it's a projector?

403
00:51:54,770 --> 00:51:58,770
Yeah. Well, keep going. I'm sorry if it's. But if it's bothering you, feel free to leave.

404
00:51:58,790 --> 00:52:02,540
Everybody gets up and leaves. Answer questions.

405
00:52:02,700 --> 00:52:07,520
So another purpose. Answer questions posed by funders and influential community members.

406
00:52:08,150 --> 00:52:11,990
I should probably just put this one at the top. This one's always there.

407
00:52:12,650 --> 00:52:20,990
I don't think I've ever done maybe I've done one evaluation that does not answer questions posed by funders and influential community members.

408
00:52:21,590 --> 00:52:27,050
So just keep that in mind. It's always there. Meet administrative requirements.

409
00:52:27,080 --> 00:52:33,690
That's probably number two. Assess the extent to which a program is being implemented as planned.

410
00:52:34,320 --> 00:52:39,660
Provide implement our information for the development of the initiative or its replication.

411
00:52:40,080 --> 00:52:43,830
Again, thinking about a like a later stage program,

412
00:52:45,750 --> 00:52:54,450
once replication or earlier stage wants to develop it and then assess alternative approaches to addressing a health problem.

413
00:52:58,400 --> 00:53:02,000
I apologize for going back, but I think this is also important.

414
00:53:04,160 --> 00:53:07,730
Again, thinking about stage when I said there's no hard and fast rules.

415
00:53:11,300 --> 00:53:17,330
I strongly encourage you not to use years operating as a proxy for stage.

416
00:53:18,170 --> 00:53:21,950
I've been evaluating a program for.

417
00:53:24,450 --> 00:53:28,230
Like three years and I was still probably putting it in planning.

418
00:53:29,420 --> 00:53:34,160
So time is not a good it's not an automatically good proxy.

419
00:53:35,370 --> 00:53:49,890
Just want to point that out. And you know, just a reminder, that type of evaluation type also has some purpose.

420
00:53:50,220 --> 00:53:53,790
Purpose is automatically embedded in it.

421
00:53:54,540 --> 00:54:03,960
A process evaluation is generally going to have a purpose of improving a program by identifying areas for improvement.

422
00:54:05,010 --> 00:54:15,870
It's going to assess the extent to which a program is being implemented as planned, and then also thinking about ways that it was adapted.

423
00:54:16,590 --> 00:54:26,610
And then a process evaluation is generally also going to help you determine how outcomes were achieved.

424
00:54:28,400 --> 00:54:34,670
Whereas an outcome evaluation generally when you're applying that type,

425
00:54:35,180 --> 00:54:43,640
it's so that you can determine whether the program made a difference and to help decide if a program is worth continuing.

426
00:54:44,680 --> 00:54:47,530
And that's why they don't they generally tend to work together.

427
00:54:50,210 --> 00:54:58,370
Because it help, you know, in order to be able to understand the outcomes and why they emerged the way they did.

428
00:54:58,370 --> 00:55:05,299
You need to have the process in order to care about the process of a program.

429
00:55:05,300 --> 00:55:10,580
You need to care about the outcomes. So those will generally kind of sit together.

430
00:55:15,960 --> 00:55:23,190
When you're thinking about purpose, it also and you're just describing it in this step.

431
00:55:23,550 --> 00:55:27,750
You want to think about how will the different parties use the evaluation results.

432
00:55:29,610 --> 00:55:36,600
How those results are used will often tie closely to who will use the evaluation results.

433
00:55:37,620 --> 00:55:49,980
Program staff. They are often thinking about, How do I implement this program next time or hopefully next time if we get funding.

434
00:55:51,660 --> 00:55:56,060
Program administrators are thinking a little broader.

435
00:55:56,070 --> 00:56:03,880
They might be thinking about how do we. Create the argument for continued funding.

436
00:56:05,260 --> 00:56:09,820
They're assessing, does it fit within our current mission?

437
00:56:12,800 --> 00:56:26,420
Or strategic priorities. If there are policymakers who are commissioning an evaluation, they often want to know, is the program worth the cost?

438
00:56:27,680 --> 00:56:32,990
Is making a broader community impact on my constituents?

439
00:56:34,880 --> 00:56:38,140
So who? Wants the results.

440
00:56:39,460 --> 00:56:45,280
It's helpful. You know, if you have those interested parties and remember,

441
00:56:45,280 --> 00:56:51,640
think about that power and the interest group we talked about last week for those who are interested.

442
00:56:53,010 --> 00:57:03,250
And also intend to use the results. It behooves you to ask them Why do you want these results so that you can account for it in the design of

443
00:57:05,250 --> 00:57:11,790
each party is also likely to have a different perspective on what they want to learn from that evaluation.

444
00:57:11,790 --> 00:57:15,330
And that's just similar to the the last bullet point.

445
00:57:17,860 --> 00:57:23,950
With the difference that people are just attentive to different things in terms of learning.

446
00:57:24,880 --> 00:57:32,950
Again, a policymaker is thinking about the program in the context of that person's given.

447
00:57:36,770 --> 00:57:43,129
Legislature, legislative area or program staff will be attentive to.

448
00:57:43,130 --> 00:57:49,020
What can I learn from the beneficiaries of the program or the program participants?

449
00:57:49,040 --> 00:57:52,879
What can I learn from them that will help me serve them better?

450
00:57:52,880 --> 00:57:59,060
So they might just be thinking about or not just, but they might be thinking about the way they practice their craft.

451
00:58:01,970 --> 00:58:08,870
So those are examples of different perspectives. And so that learning aspect can also help inform your purpose.

452
00:58:10,790 --> 00:58:16,070
You and your vested parties will probably be making decisions based on the results of the evaluation.

453
00:58:16,580 --> 00:58:21,650
So another thing that you need to consider is what decisions will be made.

454
00:58:22,340 --> 00:58:26,570
So, for example, is this at the end of this evaluation?

455
00:58:26,810 --> 00:58:33,110
Are we going to make a decision about the longevity of a program or the sustainability of a program?

456
00:58:33,710 --> 00:58:42,650
Are we talking about replication especially or not especially, but increasingly in this?

457
00:58:43,920 --> 00:58:56,459
World where a lot of nonprofits are having to look to monetization and think about how can they actually generate revenue replication,

458
00:58:56,460 --> 00:59:02,550
program models, program curricula. Those are becoming increasingly common.

459
00:59:02,560 --> 00:59:09,870
So sometimes a client wants you to come on and evaluate for the specific purpose of writing

460
00:59:09,870 --> 00:59:15,420
curricula that they could then monetize in some way and generate revenue for the agency.

461
00:59:17,580 --> 00:59:28,830
So thinking about and so that would give you some pretty, you know, specific questions about what are the essential components of this program.

462
00:59:29,400 --> 00:59:38,100
What did you do that you would have to do again for it to be part of the program versus something that you don't have to do again?

463
00:59:40,200 --> 00:59:45,359
So those are things that factor into a purpose.

464
00:59:45,360 --> 00:59:51,120
And then in turn, they they filter down into program questions or evaluation questions.

465
00:59:54,950 --> 00:59:59,310
Then finally. Who's going to conduct this evaluation?

466
01:00:02,270 --> 01:00:13,610
So. Essentially there are kind of two classifications of evaluator and the internal one and then external one.

467
01:00:14,300 --> 01:00:22,100
Internal evaluators work within the organization and they leave evaluations only for that organization.

468
01:00:25,420 --> 01:00:28,690
That's a big nonprofit that's here that you would actually see.

469
01:00:31,010 --> 01:00:34,290
Huh? I can't think of anything in Washington. United Way.

470
01:00:34,320 --> 01:00:38,780
No, no. YMCA. YMCA. I'm going to go with that. Oh, wait.

471
01:00:38,790 --> 01:00:44,020
Did somebody have idea? I heard something. Well, I worry about it.

472
01:00:44,350 --> 01:00:48,309
I thought of what I was like. I can think of big agencies.

473
01:00:48,310 --> 01:00:52,630
Not here. I was gonna say Starfish Family Services, but that's in Wayne County.

474
01:00:54,700 --> 01:01:02,010
Let's say the YMCA. They have internal evaluators, I guarantee you, because the size,

475
01:01:02,400 --> 01:01:07,770
if it's an organization that's really huge, they're likely going to have an internal evaluator.

476
01:01:08,190 --> 01:01:14,940
That person might be called the data specialist. That person might be called the learning and evaluation director.

477
01:01:15,660 --> 01:01:21,660
All kinds of titles. But ultimately they are doing evaluations specifically for the organization.

478
01:01:22,560 --> 01:01:25,620
And then in contrast, you have external evaluators.

479
01:01:26,430 --> 01:01:35,460
That's someone outside the organization who's not associated with the program and has hired to lead the evaluation.

480
01:01:36,270 --> 01:01:39,360
I see a typo that should actually be program.

481
01:01:48,770 --> 01:01:57,500
And there are certain advantages and disadvantages. Sometimes huge agencies like the YMCA, like Starfish Family Services, like.

482
01:01:59,490 --> 01:02:03,870
Health systems, they they will still hire external evaluators.

483
01:02:04,320 --> 01:02:08,640
And this is why. So some advantages.

484
01:02:08,910 --> 01:02:14,040
An internal evaluator is going to have better rapport with participants and stakeholders.

485
01:02:14,790 --> 01:02:18,540
They're going to have more knowledge about the program and its context.

486
01:02:19,020 --> 01:02:25,490
So that's definitely a benefit. You know, I just started off so many things about context that you could learn.

487
01:02:25,980 --> 01:02:32,430
You know, that you're always learning that as an internal evaluator for this specific, you know, for an agency.

488
01:02:32,440 --> 01:02:40,260
So it helps increase increased sensitivity to the meaning of findings and evaluation needs.

489
01:02:40,860 --> 01:02:48,840
I'm an internal evaluator is more cognizant of where the agency is or organization is.

490
01:02:50,580 --> 01:02:57,360
They are more sensitive to how many staff are actually contributing to a program's operations.

491
01:02:57,900 --> 01:03:07,560
So those are examples of increased sensitivity. They also know, you know better the capacity of staff to participate.

492
01:03:08,490 --> 01:03:16,530
So some of the challenges that an external evaluator like me faces where staff are like, Yeah, I'm super excited about this program evaluation.

493
01:03:16,950 --> 01:03:24,270
I'm going to be at every meeting. We're going to meet every week and we're going to plan and data collect and we're going to fall in love.

494
01:03:24,840 --> 01:03:30,990
And then a month later they leave you, you're emailing them, then that they go to you.

495
01:03:31,470 --> 01:03:39,570
Yeah. But an internal evaluator is less likely to have that happen to them because they know where that person sits in the building.

496
01:03:42,300 --> 01:03:45,900
They also know how to find them on Microsoft teams, etcetera.

497
01:03:47,880 --> 01:03:52,820
And then there's just like more of a realistic appraisal of obstacles to the evaluation design.

498
01:03:52,830 --> 01:03:58,559
They better understand how a program is operating so they know, okay,

499
01:03:58,560 --> 01:04:06,570
it's really not realistic to do that data collection in July because everyone goes on vacation in July or,

500
01:04:07,170 --> 01:04:14,760
you know, every it's not it's better to do it in September because the programs have concluded and there's kind of an open period.

501
01:04:14,760 --> 01:04:22,280
So they know those kind of operational, pragmatic things and they also know access to things like a comparison group.

502
01:04:22,290 --> 01:04:27,900
So when we get to talking about design, we'll talk about control groups, comparison groups.

503
01:04:28,410 --> 01:04:33,840
They know if there is a good compare, they're more likely to know about comparison groups.

504
01:04:34,200 --> 01:04:44,190
And then part of part of the reason why I like to work locally is because it allows me to account for some of the things that internal evaluators,

505
01:04:46,200 --> 01:04:52,950
you know, they have an advantage on. But a disadvantage is that there's a potential for decrease objectivity.

506
01:04:53,550 --> 01:04:59,010
You're ever really hard pressed as an evaluator to write up as an internal

507
01:04:59,010 --> 01:05:03,390
evaluator to write up a report that says this program is not worth the cost.

508
01:05:04,770 --> 01:05:08,490
Because you might be putting your friend Susan out of a job.

509
01:05:11,070 --> 01:05:15,540
And that's just you know, again, with I've said this over and over again,

510
01:05:15,540 --> 01:05:23,460
we're talking about real programs, real implications, possible lack of research, expertize.

511
01:05:28,410 --> 01:05:35,790
And this isn't just on the part of the internal evaluator and it's actually not speaking so much to the internal evaluator.

512
01:05:38,600 --> 01:05:42,080
But sometimes it is because you know, the.

513
01:05:42,950 --> 01:05:53,690
The first time I ever did evaluation, I got the job because I was an AmeriCorps worker who went to the University of Michigan and took a stats class.

514
01:05:54,940 --> 01:06:02,230
Yeah. You're the evaluator. Oh, what's that? I don't even know what you're talking about, but I'll do it because I'm an AmeriCorps worker.

515
01:06:02,680 --> 01:06:10,060
That's how I got my first evaluation job. And so that possible lack of research expertize definitely came into play.

516
01:06:12,100 --> 01:06:21,790
It's time consuming for staff. Internal evaluators often serve or where multiple heads and so.

517
01:06:23,920 --> 01:06:30,969
They may not have time for a really complicated design because not only are they, you know,

518
01:06:30,970 --> 01:06:39,550
been not only have they been charged with evaluation, they've been charged with managing all the data collection that goes on.

519
01:06:39,940 --> 01:06:44,410
If you've ever worked at a social service agency, you know, there's always some kind of.

520
01:06:46,910 --> 01:06:50,160
Intake. That's going on.

521
01:06:51,790 --> 01:07:02,770
There's always some data to be entered somewhere in the agency, and often the person who's doing the evaluation is also wearing that hat as well.

522
01:07:04,390 --> 01:07:10,660
So those are some advantages and disadvantages of an internal evaluator, an external evaluator.

523
01:07:12,290 --> 01:07:15,710
Sometimes, you know, time savings for staff.

524
01:07:18,720 --> 01:07:25,970
Now when we you know, we don't get benefits if we're working as an external evaluator, we I mean, we get benefits elsewhere.

525
01:07:25,980 --> 01:07:31,470
So an agency doesn't have to pay us for health insurance, for example,

526
01:07:32,910 --> 01:07:39,120
generally strong expertize and research methods and evaluation planning, because that is our only hat.

527
01:07:40,860 --> 01:07:48,420
And then objectivity in quotes. So we're a little distant, you know, we're not close friends with Susan.

528
01:07:48,870 --> 01:07:53,040
So we we it's a little easier for us to.

529
01:07:54,760 --> 01:08:02,380
Put that away and say, okay, I have to make an ethically sound assessment of this program.

530
01:08:03,760 --> 01:08:07,270
But we also, you know, have our biases as well.

531
01:08:10,440 --> 01:08:13,950
What disadvantages? We're expensive.

532
01:08:16,110 --> 01:08:19,560
So yes, we don't get health insurance and things like that.

533
01:08:21,360 --> 01:08:28,050
But otherwise we are expensive. Decreased trust with participants and stakeholders is a big one.

534
01:08:28,060 --> 01:08:31,800
We have to earn our reputation and relationship.

535
01:08:32,400 --> 01:08:42,060
Whereas an internal evaluator might already have been coming to different events and may be more visible to participants,

536
01:08:43,080 --> 01:08:45,960
and there's still the potential for us to have our own agenda.

537
01:08:46,410 --> 01:08:57,390
And then I've mentioned we you know, we often do have our own agendas, but how do we manage that and how do we mitigate those potential biases?

538
01:08:59,900 --> 01:09:11,090
You know, we we don't have the added burden of trying to mitigate biases for our coworkers, for example, or for our love for the agency.

539
01:09:13,240 --> 01:09:20,230
Sometimes. So before I go to the last slide, any questions about.

540
01:09:21,340 --> 01:09:27,820
What we talked about. Yes. What do you.

541
01:09:47,880 --> 01:09:52,590
Yeah. So the question the question comment is, you know,

542
01:09:52,590 --> 01:10:02,040
another disadvantage for being an external evaluator is that there's additional scrutiny on you questioning why you're there.

543
01:10:02,970 --> 01:10:07,980
Yes, we get that all the time, especially if we don't come with.

544
01:10:10,290 --> 01:10:13,230
Some previous relationship or connection.

545
01:10:15,550 --> 01:10:24,070
So if I'm, you know, like, say, if I move to San Francisco where I don't really have any relationships, you know,

546
01:10:24,070 --> 01:10:31,209
I don't have any I don't have any people to be in our organizations of already partner with to be able to come in and say,

547
01:10:31,210 --> 01:10:36,580
yeah, you can trust her because I worked with her and she didn't screw us over.

548
01:10:37,690 --> 01:10:43,870
Um, you know, the, the picture of the evaluator is still sometimes of.

549
01:10:44,840 --> 01:10:49,020
How many people say office space? Are you the only one?

550
01:10:49,050 --> 01:10:52,110
Oh, come on. Okay, a few more. You lie. I know you. I see.

551
01:10:52,110 --> 01:10:55,989
Office space. You are lying to me. Making me look crazy up here.

552
01:10:55,990 --> 01:11:00,340
I brought up new kids on the block. You all know what I'm talking about anyway.

553
01:11:03,090 --> 01:11:13,210
Office space. This is a movie. Person comes in and basically that person is coming in to eliminate like a bunch of people's jobs.

554
01:11:13,510 --> 01:11:19,659
So, like, everybody's treating this guy like a jerk, like or really nice, except for one person who's like, I don't care.

555
01:11:19,660 --> 01:11:28,410
You get rid of me. People think about this as the person who's coming in to get rid of a program or to get rid of somebody his job.

556
01:11:28,770 --> 01:11:39,780
And so we have to break down that barrier like, you know, by building trust, building confidence, trust that we are looking out for the program.

557
01:11:40,530 --> 01:11:46,349
And that's a fine line because you also don't want to make that line so fuzzy that

558
01:11:46,350 --> 01:11:51,210
people or your clients are thinking you can't be objective enough to tell the truth.

559
01:11:52,940 --> 01:11:58,910
So it's a it's a fine line. It is a disadvantage, but it's one that with stakeholder engagement, you can balance.

560
01:12:01,210 --> 01:12:05,950
And then sometimes people still don't like you. I don't know. It is what it is.

561
01:12:05,950 --> 01:12:10,590
And I understand because of the political nature. Any other questions?

562
01:12:15,130 --> 01:12:24,460
All right. So Thursday, we're going to talk about theories of change and logic models, which has to be the most.

563
01:12:24,880 --> 01:12:28,540
Best part. Favorite part that students love.

564
01:12:31,030 --> 01:12:34,360
I'm going to talk about both theories of change and logic models.

565
01:12:34,720 --> 01:12:38,410
And so I just want to prime you because they are two different things.

566
01:12:38,800 --> 01:12:45,040
These things get interchange so much. It took me years to even realize it was a difference.

567
01:12:45,820 --> 01:12:54,670
There is. And so I just kind of want to set the stage for you that what we're going to talk about are both conceptual and operational models.

568
01:12:55,120 --> 01:13:04,480
Theories of change are conceptual. How they believe change will occur, whether the mechanisms and the constructs and logic models are operational.

569
01:13:05,200 --> 01:13:11,200
What are the how do we operationalize this change that we hope to see into a program?

570
01:13:11,650 --> 01:13:17,709
So I just want I just want to kind of set that in your brain and prime you to think about the difference

571
01:13:17,710 --> 01:13:23,500
between or to think about what does it mean for something to be conceptual versus operational?

572
01:13:23,890 --> 01:13:31,180
And then on Thursday, we'll talk about it. And hopefully it'll be clear in all of our heads, including me,

573
01:13:31,660 --> 01:13:38,680
what the difference is between the theory of change and the logic model and why they fit together hand-in-glove.

574
01:13:40,090 --> 01:13:41,830
All right. That's all I got for you today.

575
01:13:44,550 --> 01:13:51,540
This will be the last time I do office hours in this in this at this desk ever since I finally got around to reserving a room.

576
01:13:51,540 --> 01:13:56,820
So I'll tell you what it is next week. But if you got questions today, welcome to this desk.

