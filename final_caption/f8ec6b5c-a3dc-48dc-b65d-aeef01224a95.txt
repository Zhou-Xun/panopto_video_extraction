1
00:00:02,490 --> 00:00:08,530
Yeah. It was like a second thing, right?

2
00:00:08,820 --> 00:00:22,660
Yeah. I started studying for the test, you know what I'm saying?

3
00:00:25,860 --> 00:00:29,190
Oh, yeah, I.

4
00:00:29,820 --> 00:00:35,310
I basically did the opposite on the right hand.

5
00:00:35,800 --> 00:00:45,600
Try to set up my study guide. Definitely a good study guide should be anywhere near as strongly one as I was the last one.

6
00:00:45,600 --> 00:00:55,320
Which is funny because I didn't feel very confident at this point that I needed coming here, hearing if you have the equation,

7
00:00:55,330 --> 00:00:59,570
it's like pretty straightforward, which I feel like it is also true for the rest of the Imperial.

8
00:00:59,580 --> 00:01:01,620
But at the same time, like, you know,

9
00:01:01,620 --> 00:01:11,380
he's going to ask a conceptual question if they're really trying to like what is actually what is that going to be like?

10
00:01:11,400 --> 00:01:22,680
Explain what it actually I mean, there's just there's like one question is like saying, well, that would be a great question.

11
00:01:22,710 --> 00:01:33,030
And I do remember that one, of course, was something was like, um, not going to like, you're not a nova, but I think so.

12
00:01:33,460 --> 00:01:40,970
Okay. Yeah. Yeah. And it was like, I'm not sure I'll look it up, I will let you know.

13
00:01:41,430 --> 00:02:04,070
But it was like, if you find a way to get together and figure out what can we do with the question about somebody who's able to ask

14
00:02:04,080 --> 00:02:17,740
it last time that I would certainly like to try to do might actually take it as a crisis or doesn't bother you.

15
00:02:18,830 --> 00:02:21,940
But I'm like, we are ready to work on that.

16
00:02:22,200 --> 00:02:27,930
I know. Like I just don't know that I'm going to be trying to take it personally.

17
00:02:28,070 --> 00:02:40,229
But the whole time, you know, I was like maybe nine, nine, nine, nine, 15, give yourself a ten.

18
00:02:40,230 --> 00:02:51,540
Because the only thing that I had, the idea that was the word I was like,

19
00:02:51,630 --> 00:03:02,970
not going to wake up for something like that is I don't want to think about, Oh, oh, how did they do that?

20
00:03:06,530 --> 00:03:14,850
But I think it's just like he's also not still crises.

21
00:03:17,250 --> 00:03:24,510
I just have to go here.

22
00:03:24,510 --> 00:03:42,780
Just kidding. Yeah, it was pretty exciting and it's like a lot of different people are like.

23
00:03:47,970 --> 00:04:09,270
That's something that I certainly knew from the outset, but it always comes from the emails.

24
00:04:12,120 --> 00:04:17,500
So are you considering that?

25
00:04:17,610 --> 00:04:58,720
But I really think we heard from you the model one one and 11 Commission, which is good in terms of the things.

26
00:04:58,740 --> 00:05:01,850
That's the one part of my life. Make it look straight. Like it was more like.

27
00:05:04,810 --> 00:05:08,950
You know, just like. What is that?

28
00:05:09,560 --> 00:05:13,670
There was a part of that. Yeah.

29
00:05:13,700 --> 00:05:28,190
Like, it's a different problem, but I think it's like, okay, yeah.

30
00:05:28,430 --> 00:05:35,240
I'm going to be someplace just sitting there.

31
00:05:35,340 --> 00:05:40,910
Like, when it was like, Oh, that's interesting.

32
00:05:41,510 --> 00:06:05,659
We're like, Excuse me for points, but right now I think maybe, you know, I, I really think like that might be something like,

33
00:06:05,660 --> 00:06:21,200
no, I don't know if we were saying no because I don't really want to do it.

34
00:06:22,680 --> 00:06:31,190
I'm not high drama. So, you know.

35
00:06:31,220 --> 00:06:47,600
So that was right that started thanks everybody for that and your decision and stuff in.

36
00:06:47,600 --> 00:06:55,429
I am spending most of my week working on the house and no, I don't have an I voted sticker on me yet,

37
00:06:55,430 --> 00:06:58,249
but that's because my absentee ballot went in three weeks ago.

38
00:06:58,250 --> 00:07:06,950
So the stickers like I encourage you, if you have not already voted to please make sure to find.

39
00:07:10,120 --> 00:07:23,049
Today. Obviously, there's a shift in this course. We're basically stepping away from those vacations and the model and talking

40
00:07:23,050 --> 00:07:31,780
about something which is disturbingly real and has been for the last few years,

41
00:07:31,780 --> 00:07:45,070
which is crisis communications. The story of this is in the materials that you sent for today comes out of the history of.

42
00:07:45,960 --> 00:07:56,730
September 11th, 2001. Actually, more than that, out of the history of the anthrax examinations that occurred in 2002 and.

43
00:07:58,090 --> 00:08:03,280
The public health infrastructure in the United States, particularly with the anthrax,

44
00:08:04,570 --> 00:08:12,340
kind of woke up to the fact that the main problem that they were facing was not magnitude of physical risks to the population,

45
00:08:12,340 --> 00:08:14,110
but magnitude of emotional risk,

46
00:08:14,920 --> 00:08:24,249
communication risk that it was that they needed principles and guidelines that were not just at the highest levels of government,

47
00:08:24,250 --> 00:08:35,200
but that could be managed at a national and a state and local level to have conversations, to provide guidelines for communication about crises.

48
00:08:35,470 --> 00:08:38,170
Now let's define a crisis.

49
00:08:38,740 --> 00:08:50,200
Critical pieces of crises, from what we were talking about today, basically boil down to situations that have enormous uncertainty,

50
00:08:52,810 --> 00:09:04,720
situations that have emotions associated with it, and where there is at least perception or a belief of a chance of really bad things happening.

51
00:09:06,760 --> 00:09:09,660
That doesn't mean that those things need to be likely.

52
00:09:09,670 --> 00:09:17,890
Like there are plenty of crisis communications about things which are extremely rare or unlikely events.

53
00:09:19,690 --> 00:09:24,070
Four things which are unlikely to have a substantial impact on people you might think about.

54
00:09:26,470 --> 00:09:33,730
Global exposure is where the concentration is very low, so it's extremely unlikely that there'll be any substantial public health effect.

55
00:09:34,300 --> 00:09:38,530
But it still happened and so it has some uncertainty. How much is this going to affect people?

56
00:09:38,890 --> 00:09:41,500
There's emotion. What do you mean? I'm being contaminated.

57
00:09:42,100 --> 00:09:50,950
And there's at least the fear that that chemical might be causing some harm, even if biologically we don't think that that's likely to occur.

58
00:09:51,700 --> 00:09:57,520
Those are the core elements here. And notice that this just doesn't necessarily have to be about public health.

59
00:09:58,240 --> 00:10:08,530
We're going to talk about it in this context. But. Crises include things like the leader of your organization just got hit by a bus.

60
00:10:10,150 --> 00:10:14,770
What's going to happen? We're in a crisis mode.

61
00:10:17,770 --> 00:10:23,500
Seriously? I mean, like, if you were trying to communicate to employees of Twitter this is crisis communication.

62
00:10:28,090 --> 00:10:32,780
It can be about organizational crises. It can be about money crises.

63
00:10:32,970 --> 00:10:40,570
It's, you know, the. But this actually happened at the current time, or at least I'm not thinking of excessive interest,

64
00:10:40,570 --> 00:10:46,840
but the yeah, our organization didn't get renewed for our grant is a crisis communication situation.

65
00:10:49,690 --> 00:10:56,020
So I'm giving you this background because this is one of the days where I really hope.

66
00:10:57,230 --> 00:11:07,220
You may remember this stuff five or ten years from now, some time in your life, you will be in the center of a crisis.

67
00:11:07,990 --> 00:11:13,090
It's going to happen. I don't know when. I don't know how it will happen.

68
00:11:14,200 --> 00:11:20,380
And when it happens, you're going to find I'm going to spend some time over the course of the next week or so talking about.

69
00:11:20,890 --> 00:11:26,980
You're going to find that the advice I'm going to give you today is going to feel difficult.

70
00:11:27,970 --> 00:11:35,740
And the people around you in the organization that you are in are not going to feel comfortable with following these rules.

71
00:11:38,640 --> 00:11:54,330
The history of crisis communication shows that what people tend to snap to is caution is not disclosing things and is holding on to sort of like,

72
00:11:54,330 --> 00:11:58,530
Oh, we have to be professional or we're going to talk about that next week.

73
00:11:59,770 --> 00:12:04,250
All of which. Ends up actually making things worse.

74
00:12:06,470 --> 00:12:12,890
And so I got the today is the intro they get to read the stuff from the CDC,

75
00:12:12,890 --> 00:12:19,490
developed an original curriculum for crisis emergency risk communication in the mid 2000s after the anthrax scare.

76
00:12:20,210 --> 00:12:27,290
They did the right thing like they got the experts on the time to consult with them.

77
00:12:27,290 --> 00:12:30,440
Like I know the people who help them would be good at this stuff.

78
00:12:31,190 --> 00:12:34,280
And the first version of this was like amazingly good.

79
00:12:34,730 --> 00:12:44,209
They just what you read was the update that they did in 2017 or 18 or so, which quite honestly has gotten a little bit bloated.

80
00:12:44,210 --> 00:12:50,510
I'm going to try to cut through some of the extra stuff in there to what I think of as the most critical pieces.

81
00:12:54,110 --> 00:12:58,220
What we're going to talk about over the course of the next couple of weeks is really.

82
00:12:59,720 --> 00:13:04,040
How do you see this playing out? When? When does it happen? When is it not happening?

83
00:13:06,020 --> 00:13:11,360
You're going to go a week from today, but a week from Thursday.

84
00:13:11,750 --> 00:13:21,530
I mean, you've got a bunch of speeches. Some of them are really good looking that we can, for example,

85
00:13:21,530 --> 00:13:33,410
compare and contrast how the CDC speeches were at the beginning of COVID versus when they were in 2009, when H1N1 influenza was the crisis du jour.

86
00:13:34,310 --> 00:13:37,640
And they were different. And we can unpack that and talk about it.

87
00:13:40,580 --> 00:13:46,240
As I was saying to one person, obviously, we're living this and we're having these conversations in the middle of COVID.

88
00:13:46,250 --> 00:13:50,210
I'm not going to exclude COVID, but I want us to be broader as much as we can.

89
00:13:50,540 --> 00:13:54,290
We will come back to COVID and try to put all the pieces together.

90
00:13:54,500 --> 00:13:58,490
The very last class of the course. It makes for a nice wrap up theme,

91
00:14:00,680 --> 00:14:06,230
but do try and think more broadly than just COVID because this type of stuff didn't come up in a lot of different situations.

92
00:14:08,660 --> 00:14:10,470
So one last piece of setting the stage.

93
00:14:10,490 --> 00:14:17,330
Your next assignment, which of course, should be given the scheduling means it's only two weeks away, is to wait.

94
00:14:17,540 --> 00:14:21,800
It's only a ten point assignment is to write a short speech.

95
00:14:22,190 --> 00:14:30,649
A crisis speech is a scenario. If it's over the assignment itself, it's basically imagined.

96
00:14:30,650 --> 00:14:38,300
You're a local public health official and you need to give the initial press briefing in a new crisis situation.

97
00:14:39,620 --> 00:14:45,050
What are you going to do? What are you going to say? I would give you examples.

98
00:14:45,290 --> 00:14:49,240
We're talking about principles today. Talk about examples of.

99
00:14:50,330 --> 00:14:55,020
It's pretty straightforward. I'm not asking you to be crazy.

100
00:14:55,040 --> 00:14:56,720
I don't need you to do lots of research,

101
00:14:56,960 --> 00:15:04,040
but I am going to be looking to see that you embody the principles that we're talking about today and over the course of the next week in that speech,

102
00:15:04,040 --> 00:15:09,590
that's the goal of that. I'll give you the practice to work on. So.

103
00:15:12,850 --> 00:15:19,480
I'll leave it in the musings today, but I'm going to do a little bit more sort of directive describing of the concept than I usually do,

104
00:15:19,540 --> 00:15:25,450
because I want to make sure you get these key ideas. The first one.

105
00:15:26,860 --> 00:15:31,690
And literally, if you remember nothing else from today, remember this one?

106
00:15:35,220 --> 00:15:43,860
Before. It used to be crises were measured in days.

107
00:15:44,760 --> 00:15:46,890
Right now, crises are measured in minutes.

108
00:15:48,150 --> 00:15:56,790
If something happens on this campus, most of us are going to be getting a text within minutes of that event.

109
00:15:57,420 --> 00:16:03,490
And that is the first point of contact of the crisis communication, the moment when the person,

110
00:16:03,870 --> 00:16:11,130
the audience learns that there is an event, that there is a crisis, that there is something that wasn't true for them before.

111
00:16:14,750 --> 00:16:20,320
The key point here is. As much as possible.

112
00:16:21,360 --> 00:16:24,610
You will want to be the one disclosing that information.

113
00:16:25,730 --> 00:16:32,890
For two reasons. One, if you disclose it.

114
00:16:34,340 --> 00:16:42,790
You get to start to control how much people disclose. Information is or is not provided, the tone, the context, etc.

115
00:16:44,300 --> 00:16:47,320
You are not the person or the organization that discloses it.

116
00:16:47,330 --> 00:16:56,730
You've seen that. Ability that power, that control, so that whoever, whoever sets the conversations set the agenda.

117
00:16:58,710 --> 00:17:04,980
The other piece is this. And this is sort of the main theme of a lot of crisis communication.

118
00:17:07,390 --> 00:17:15,580
Learning from the official source after you have learned something from somebody else increases trust.

119
00:17:17,350 --> 00:17:21,010
Why? They told me before they obviously knew this.

120
00:17:21,530 --> 00:17:31,670
What kept them from telling me this and is that trust is part of the problem in the context of crisis.

121
00:17:34,380 --> 00:17:40,090
So. One of the core principles is.

122
00:17:41,660 --> 00:17:53,000
As much as possible. The first advantage of being first is if you are if you can live, you can think about this differently.

123
00:17:53,000 --> 00:17:57,350
Like we talk about the University of Michigan, like talk about your government.

124
00:17:57,350 --> 00:18:01,640
We can talk about a county health department or a smaller organization.

125
00:18:03,020 --> 00:18:07,820
If you become part of the conversation, then people look to you.

126
00:18:08,960 --> 00:18:18,050
You said, I am a source of information come to me, which again gives you the ability to help shape how that plays out.

127
00:18:22,550 --> 00:18:26,660
If you don't, then people go wherever they're going to go and the hence are subject to all of the

128
00:18:26,660 --> 00:18:31,340
challenges that we have in a information environment in which you can Google anything.

129
00:18:31,340 --> 00:18:35,990
And that Twitter and whoever happens to be there with a cell phone could be the source of information.

130
00:18:36,320 --> 00:18:39,920
Not that that's there is a value to that. I want to minimize that.

131
00:18:39,920 --> 00:18:49,729
But but this idea of being first is really critical. And the other piece related to that, here are three sentences.

132
00:18:49,730 --> 00:18:52,970
I hope you'll remember that. But I want to highlight the second one.

133
00:18:54,920 --> 00:18:58,250
The faster you tell somebody the bad news, the better.

134
00:19:02,750 --> 00:19:07,250
There is this tendency to. We can't tell them that we don't.

135
00:19:07,250 --> 00:19:11,210
Actually, it's going to be too hard for them and it can be too scary for them, etc.

136
00:19:12,500 --> 00:19:21,379
Whether this is disclosing COVID to kids in schools, whether this is telling someone that they've been diagnosed with cancer,

137
00:19:21,380 --> 00:19:31,040
whether that's telling a community that their water supply is contaminated, whether this is where the country is and that there has been.

138
00:19:32,240 --> 00:19:35,960
You know, a food poisoning incident. And we don't know where it is.

139
00:19:41,260 --> 00:19:46,150
After you get the bad news out, the better. Okay.

140
00:19:46,580 --> 00:19:56,590
There's two reasons for this. One. If I know that something's going on,

141
00:19:56,830 --> 00:20:02,930
let's let's use the food contamination example and we'll talk about food next class a lot because there's a space documented with that because people.

142
00:20:04,720 --> 00:20:09,190
I might think that everything is contaminated. I might think that all vegetables are contaminated.

143
00:20:09,430 --> 00:20:12,130
I might think that I just ate a salad that's going to kill me.

144
00:20:14,170 --> 00:20:19,420
If the fact of the matter is that it's only romaine lettuce and it's only a lettuce that

145
00:20:19,420 --> 00:20:22,660
was grown in a particular part of the country and sold in these particular states.

146
00:20:25,260 --> 00:20:28,739
That narrows the scope. It provides concreteness.

147
00:20:28,740 --> 00:20:33,030
It provides more certainty. I get to know should I be really worried or not?

148
00:20:33,390 --> 00:20:41,430
Even if I am somebody who has just eat the salad or romaine lettuce, that was you know, that is the potential contaminate.

149
00:20:41,430 --> 00:20:48,550
But it's actually easier for us to deal with knowing the bad thing than the uncertainty of not knowing.

150
00:20:52,070 --> 00:20:58,920
And so by getting the bad news out, you switch this from a less certain situation to a more certain situation,

151
00:20:59,010 --> 00:21:06,620
maybe a more certain good, or might be for certain bad, but it's more certain we have a much easier time handling that process.

152
00:21:09,870 --> 00:21:13,250
All their piece is. And this is this is counterintuitive.

153
00:21:15,020 --> 00:21:20,660
If you get the bad news out first, everything else you're going to say will make it better.

154
00:21:27,510 --> 00:21:31,410
Then everything you're doing is you're communicating is you're trying to help people through this.

155
00:21:31,770 --> 00:21:36,090
You're not holding onto some bad news piece that they're going to have to, you know, find out later.

156
00:21:36,420 --> 00:21:42,300
You got it already out. Now your job is to help. And that's a really powerful thing.

157
00:21:43,650 --> 00:21:47,650
So. To start with examples, Sydney.

158
00:21:49,410 --> 00:21:54,150
You're talking and you're musing about, if I remember it, a bomb threat that happened to a school?

159
00:21:54,990 --> 00:21:59,399
Yeah. At my high school. Yeah. So tell us about it. Yeah.

160
00:21:59,400 --> 00:22:07,350
So since, like, junior year and we were just at school, like Norman kind of throughout the morning, there was this rumor that started going around.

161
00:22:07,500 --> 00:22:14,370
I heard from people that, like a certain student has, like, brought a problem to school, was gonna like, set it off like later in the day.

162
00:22:14,370 --> 00:22:19,600
And so, you know, like, that's pretty terrifying and sort of thing.

163
00:22:19,770 --> 00:22:26,790
This rumor kept going around and it was really like the topic of discussion like in our classes and we were like doing a lot of work necessarily.

164
00:22:26,820 --> 00:22:34,350
Um, a lot of uncertainty, a lot of times, like visibly upset and worried and scared and then kind of the police like see the police

165
00:22:34,350 --> 00:22:39,810
involved like from afar and like see the cars and then someone's like you're like investigating.

166
00:22:40,980 --> 00:22:47,340
And so like in the afternoon, my friends and I, we just decided like the school I don't like heard anything official from,

167
00:22:47,600 --> 00:22:51,780
from teachers or like anyone in the district, which is kind of like scared.

168
00:22:51,780 --> 00:23:01,499
So we left and then they did end up sending like an email later to like the whole school district that the threat was investigated by police.

169
00:23:01,500 --> 00:23:04,680
They looked into it, didn't find a bomb.

170
00:23:04,680 --> 00:23:08,400
And I like taking care of matter is basically like following up with the student.

171
00:23:09,090 --> 00:23:14,819
There's a lot of like outrage kind of in the following days, you know, from parents and people in the community.

172
00:23:14,820 --> 00:23:21,630
But yeah, so let's unpack this scenario, which is a nice prototype of a crisis situation.

173
00:23:22,530 --> 00:23:27,719
You start there's some signal, some knowledge that something has happened.

174
00:23:27,720 --> 00:23:32,550
So that's the rumors that are starting to circulate that there is a threat.

175
00:23:34,160 --> 00:23:39,200
There's lots of uncertainties. True. Is it not true? Obviously this would be highly concerning if it is true.

176
00:23:40,970 --> 00:23:44,840
The beef first principle says the crisis is already happening.

177
00:23:45,170 --> 00:23:52,030
Whether or not there is a bomb is not the point. The community is already being affected by this.

178
00:23:52,300 --> 00:24:02,450
So communication is necessary. So the concern in that moment and I guarantee you this is what somebody at that school administration was saying,

179
00:24:02,870 --> 00:24:07,400
somebody would say, yeah, we don't know whether this is true. So we can't tell people because they might panic.

180
00:24:09,520 --> 00:24:13,570
Notice that not saying something still led you to leave school.

181
00:24:16,390 --> 00:24:22,630
Take actions which obviously may or may not have been actually safer in the given situation.

182
00:24:23,970 --> 00:24:27,180
Because sitting there wondering, what should we do?

183
00:24:27,690 --> 00:24:35,850
Is it extremely emotionally difficult thing? So people have a natural tendency when they're struck with a crisis situation to do something.

184
00:24:36,180 --> 00:24:40,860
If you don't tell them what the something is to do or not do it, they're going to come up with something on their own.

185
00:24:46,360 --> 00:24:47,350
What would I have hoped?

186
00:24:47,920 --> 00:24:55,120
I would have hoped that literally within 5 minutes of the moment that anybody in the school administration found out about any of the rumors.

187
00:24:55,960 --> 00:24:58,180
Something was said to the whole school.

188
00:24:59,200 --> 00:25:07,600
Even if all that what was said was you're hearing rumors that there might be some kind of threat to the school.

189
00:25:07,990 --> 00:25:12,250
We are aware of this. We are trying to prepare and we're trying to be looking into it, etc.

190
00:25:13,480 --> 00:25:19,060
Please keep in touch with us if you hear anything more notes what that does.

191
00:25:20,590 --> 00:25:28,360
Now we know that this thing exists and that the people who are communicating, the organization, the leadership is aware of it.

192
00:25:30,960 --> 00:25:38,220
They're telling you they're going to do something. Not that they necessarily know how to prevent it, but they're attempting to respond to it.

193
00:25:41,210 --> 00:25:44,820
And three, they have oriented you. Here is what you can do. You will orient.

194
00:25:44,840 --> 00:25:53,380
You act to us. We will keep providing further information. All of that is helping to resolve the uncertainty of that moment.

195
00:25:54,320 --> 00:25:58,990
US notice that didn't require the leadership to actually know what was true or not.

196
00:26:00,490 --> 00:26:04,030
Because the role of crisis communication is not.

197
00:26:06,190 --> 00:26:09,400
To convey the truth about what's happening in the world.

198
00:26:10,380 --> 00:26:14,510
You may not know that, but you usually don't know. All of a crisis.

199
00:26:14,510 --> 00:26:20,540
Communication is to convey the truth of what is known and what is not known in a given moment.

200
00:26:22,340 --> 00:26:28,040
What is true is we know there are rumors and we don't know whether any of this is true.

201
00:26:28,520 --> 00:26:41,190
That is what must be communicated. The other thing I want to highlight from this is that is the communication that did happen.

202
00:26:42,600 --> 00:26:48,120
You meant the end of the day. Who was that communication actually designed for?

203
00:26:50,350 --> 00:26:52,210
The parents. Right.

204
00:26:52,960 --> 00:27:01,750
That was a communication to the parent because presumably in their minds, the parents were unaware of anything until they sent that email.

205
00:27:02,050 --> 00:27:07,810
And what's the flaw in that? What is the odds in today's environment where everybody has a cell phone that no

206
00:27:07,810 --> 00:27:11,620
parents were aware of what was going on in that school up until that point in time?

207
00:27:11,830 --> 00:27:18,780
Zero zero. So there's a failure of understanding that there is a separate audience,

208
00:27:18,780 --> 00:27:24,480
i.e. the parent who also is now freaking out and trying to figure out should they be pulling their kids out,

209
00:27:24,490 --> 00:27:31,560
etc. and they need communications to be first.

210
00:27:32,610 --> 00:27:42,600
All of this stuff gets better the faster you engage in the conversation, the faster you engage in that scenario with the students, the faster.

211
00:27:43,920 --> 00:27:47,790
You can orient them to whatever it is you want them to be doing or not doing.

212
00:27:48,840 --> 00:27:51,059
The faster you tell the parents that something is going on,

213
00:27:51,060 --> 00:27:55,980
the faster they orient you and stop calling their kids and say you need to run for whatever.

214
00:27:59,980 --> 00:28:07,060
Every organization you will work with will function. And frankly, it will.

215
00:28:07,180 --> 00:28:15,250
You'll find yourself on. There's this tendency of like, I don't know where to say I can't go.

216
00:28:16,320 --> 00:28:23,540
And I see this having been there. But it is probably the most important thing I'm going to say today.

217
00:28:23,750 --> 00:28:38,650
Being first. Even if all you have to say is I don't know, which is related to the second point.

218
00:28:40,480 --> 00:28:45,280
So the second thing I have up there would be. Right. What do I mean by that?

219
00:28:46,720 --> 00:28:55,960
What I mean by that, as you read to some degree, but I want to reinforce is you need to be true to your situation in the moment.

220
00:28:57,100 --> 00:29:00,249
It is not necessarily the case that you need to know everything about the

221
00:29:00,250 --> 00:29:07,060
truth and the world is totally okay in a crisis to say this is what is known.

222
00:29:07,720 --> 00:29:19,480
Even if all what you know is I heard reports of X the last time I remember you already see Michigan's emergency alert system being triggered.

223
00:29:21,070 --> 00:29:27,460
What the alert was was basically reports of possible gunshots in the diag.

224
00:29:32,230 --> 00:29:35,290
It turned out it was balloons popping, but that didn't matter.

225
00:29:37,740 --> 00:29:40,800
What mattered was there was something circulating.

226
00:29:41,070 --> 00:29:50,230
It came out. They said what it was they had heard and they said what it was they were doing and he'd be able to investigate, etc., etc., etc.

227
00:29:51,340 --> 00:29:57,370
And that framing of the problem enabled me and others to make choices like,

228
00:29:57,370 --> 00:30:02,110
okay, I'm not going to the dialog right now, let's just avoid that or whatever.

229
00:30:03,530 --> 00:30:11,000
Failing to do that. Rumors were already starting to circulate. And that's where the real danger is, is the rumors and the fear in The Observer.

230
00:30:15,740 --> 00:30:19,640
Three pieces. What do you know? What do you not know?

231
00:30:19,700 --> 00:30:25,100
What are you going to do? All those things start with you.

232
00:30:25,640 --> 00:30:29,480
What do you know? What are you. What do you not know?

233
00:30:29,510 --> 00:30:33,800
What are you going to do? This is not what is true in the world.

234
00:30:34,430 --> 00:30:38,480
This is not. How will this be performed? You may not have the answers to those.

235
00:30:40,130 --> 00:30:43,460
Your responsibility as a communicator is to convey what you know.

236
00:30:43,880 --> 00:30:48,540
What you do not know. What you are going to do. Your organization is going to do.

237
00:30:48,560 --> 00:30:57,230
Exactly. Emily.

238
00:30:58,730 --> 00:31:03,490
She? You were talking in your musings about this whole incident.

239
00:31:04,470 --> 00:31:15,270
Yeah. Okay. So in 2018, decent ordered text alert that a ballistic missile is heading towards Hawaii and in the message and said this is not true.

240
00:31:16,110 --> 00:31:23,220
And I remember like there was no official communication after that text message was sent for like another 4 minutes.

241
00:31:23,230 --> 00:31:28,020
So there were people that were like, what are we supposed to do? Because it was like one of those Amber Alerts.

242
00:31:28,800 --> 00:31:34,650
And I had periods where like, I just went back to sleep because there's like, nothing you could do if it was coming.

243
00:31:34,650 --> 00:31:41,400
And I had other people who like, because we don't really have bomb shelters or that I'm aware of that are underground.

244
00:31:42,090 --> 00:31:44,910
So I know some people that like went into the drainage sewers.

245
00:31:45,570 --> 00:31:52,260
And so just like that difference in like what they did after and then how like once the government did respond to it,

246
00:31:52,260 --> 00:31:59,130
like there was a lot of backlash because it took them so long to figure out how could someone mess up to that protocol?

247
00:31:59,490 --> 00:32:03,690
Yep. So notice that there's outrage over the error.

248
00:32:04,200 --> 00:32:10,050
So anytime you get errors, you've got a crisis, whether it's a hospital error, whether it's a government error, etc.

249
00:32:11,640 --> 00:32:18,030
Speed is key. So had they responded within 5 minutes, there would have been outrage at the fact that it occurred.

250
00:32:19,680 --> 00:32:24,600
The magnitude of the outrage would be different because it would have the uncertainty,

251
00:32:24,600 --> 00:32:32,730
the fear it said it would have been resolved a whole lot faster if that experience of uncertainty and fear, which is so aversive to us.

252
00:32:34,720 --> 00:32:46,710
The thing I want to. Highlights here is, I guess is the reason they didn't respond for a while is that they weren't sure how it had happened.

253
00:32:48,150 --> 00:32:52,910
Whereas the right response was. This is an error.

254
00:32:52,920 --> 00:33:01,370
We don't know how this happened. We're going to find out. We'll have to know that you don't have to.

255
00:33:01,520 --> 00:33:05,390
They simply have to know it's wrong before they can start to step in. That's it.

256
00:33:05,930 --> 00:33:14,420
Everything else can follow. Waiting until you figure out, oh wait, this is an error, etc. creates that uncertainty.

257
00:33:14,690 --> 00:33:30,070
He creates that outrage. So there's a lot of various health stuff going on right now that has outside covered that has components of this.

258
00:33:34,530 --> 00:33:43,210
Amy. Dry shampoo. Yeah, a great example right now of a public health crisis situation.

259
00:33:44,080 --> 00:33:49,659
Yeah, I feel like I've been seeing it everywhere about how there's all these recalls of dry shampoo because

260
00:33:49,660 --> 00:33:55,240
of the increased benzene and communication about how that can lead to increased risk of cancer.

261
00:33:56,410 --> 00:34:00,700
So, I mean, the oil. How many of you have heard anything about dry shampoo?

262
00:34:02,330 --> 00:34:05,620
Half, three quarters that I've noticed. This is step one.

263
00:34:06,400 --> 00:34:12,100
Like, if there is a risk and we are public health authorities and we want to minimize risk,

264
00:34:12,610 --> 00:34:17,470
we have to make sure that the maximum number of people get exposed to this information as quickly as possible.

265
00:34:18,800 --> 00:34:22,660
So. To some degree that is happening. To some degree it isn't.

266
00:34:22,660 --> 00:34:26,420
But that's one question here. You know, how is this being disseminated?

267
00:34:26,440 --> 00:34:29,530
How do we make sure that people know about it, too?

268
00:34:30,250 --> 00:34:36,130
You already sort of reframed this as, okay, so that there's benzene in this and there's some degree of exposure.

269
00:34:38,240 --> 00:34:45,440
I will be honest. I have heard the messages around dry shampoo circulating.

270
00:34:45,800 --> 00:34:51,800
None of the messages that I had gotten until this point in time had actually set the mechanism or what the particular chemical was.

271
00:34:51,800 --> 00:34:54,980
I'd only heard, you know, recalls of dry shampoo.

272
00:34:55,250 --> 00:35:03,290
Health threats don't use dry shampoo, etc. mean the actual message piece as opposed to the underlying what is the source of the risk?

273
00:35:05,780 --> 00:35:12,550
Which honestly is okay. Because the first and more important thing for me is.

274
00:35:14,480 --> 00:35:17,900
Am I right? Is there anything that I need to do?

275
00:35:18,960 --> 00:35:25,380
I don't use dry shampoo. So I was like, CheckBox, I don't actually need to worry about this, but I know someone who has.

276
00:35:25,920 --> 00:35:29,910
And so my mental frame went, Okay, do they know about this?

277
00:35:30,300 --> 00:35:36,060
Is it like I need to be a conduit of information to them to make sure that they are putting themselves at risk?

278
00:35:37,770 --> 00:35:47,840
The details. May or may not be that critical for me, except I want to highlight one critical caveat here.

279
00:35:51,710 --> 00:35:55,040
This is a case in which the science is already established.

280
00:35:56,290 --> 00:35:59,740
There are formal recalls of these products.

281
00:36:00,810 --> 00:36:09,090
This is a different situation than if somebody on Twitter had posted, Hey, Trisha poos have benzene in them, don't use them.

282
00:36:09,480 --> 00:36:13,080
And there was no background signs and there was no official recalls that are like that.

283
00:36:13,350 --> 00:36:21,260
That's also a crisis communication context. But there's a lot more uncertainty about the question of what the right answer is.

284
00:36:21,510 --> 00:36:25,850
And here there's not that much uncertainty. The right answer is don't use these products.

285
00:36:25,850 --> 00:36:33,260
They're being officially recalled, etc. What else struck you about what you've seen about those communications?

286
00:36:36,080 --> 00:36:42,180
Have they seemed helpful? Have they invoked fear? I don't know if they've been helpful.

287
00:36:42,600 --> 00:36:50,879
I guess this probably isn't what you're asking, but what I've seen as interesting is it's almost become a way for companies to compete or it's like,

288
00:36:50,880 --> 00:36:54,940
Oh, well, we're free and we don't use benzene any. We need to worry about it.

289
00:36:54,960 --> 00:37:01,680
Oh, yeah. So that's like I've seen more of those messages than the ones from the companies that are being recalled.

290
00:37:05,690 --> 00:37:09,620
So we're going to scan the room for a second.

291
00:37:10,900 --> 00:37:17,120
You've got a plastic water bottle there. You want to bet it has a BPA free?

292
00:37:18,280 --> 00:37:21,970
You want to bet it has a BPA free sticker on the bottom,

293
00:37:21,980 --> 00:37:27,580
something marked on it that says no BPA here, but it came as part of a like a composite thing.

294
00:37:27,580 --> 00:37:32,290
So I'm sure it was there. This is another one of these historical things.

295
00:37:32,290 --> 00:37:40,060
But there was a whole push in I have ten years ago around this funnel or otherwise known as PPA.

296
00:37:41,310 --> 00:37:46,410
Which is a plasticizer the agent used in creation of lots of plastics to keep

297
00:37:46,410 --> 00:37:53,040
it from being too brittle and breaking and was commonly used in automobiles.

298
00:37:55,300 --> 00:38:05,830
And when that story broke, we saw the same kind of pattern in which manufacturers very quickly became I saw well, I saw tons of ads about BPA free.

299
00:38:05,840 --> 00:38:07,120
You can you can get a water bottle.

300
00:38:07,120 --> 00:38:19,850
You know, no BPA, including that label being slapped on glass water bottles, which don't actually have to hold water bottles and problems like that.

301
00:38:20,470 --> 00:38:27,670
It was used as a marketing ploy because why are we surprised?

302
00:38:28,000 --> 00:38:34,840
Like, it's it's a way for them to discriminate their product from these other products, which are now have the the taint.

303
00:38:35,710 --> 00:38:42,520
These are bad for you. These are not okay. In this particular case, you know, we don't recall the products.

304
00:38:42,520 --> 00:38:45,220
This is like you shouldn't be using the recall product.

305
00:38:45,730 --> 00:38:53,560
There's plenty of other situations that are also this kind of situation where maybe there's some risk, maybe there isn't.

306
00:38:54,280 --> 00:38:57,849
We haven't gotten to the point of a recall like there was never, at least to my knowledge,

307
00:38:57,850 --> 00:39:03,970
there was never actually a formal recall of plastic bottles of plastic.

308
00:39:04,890 --> 00:39:08,040
Water bottles for people. It's just the market changed.

309
00:39:08,310 --> 00:39:13,410
So nobody would nobody would put them out. The only thing that I think was ever actually recalled was baby bottles.

310
00:39:16,440 --> 00:39:24,720
And the recall for baby bottles was really driven by not necessarily clarity about the level of risk, but clarity about the level of dosage.

311
00:39:25,190 --> 00:39:33,750
In a sense, babies are getting a lot of liquids through bottles that are warmed, which releases more of the chemical.

312
00:39:34,230 --> 00:39:41,730
And of course, they're small. So the dose per weight ratios are way higher than anything an adult, whatever age.

313
00:39:43,180 --> 00:39:47,610
But yeah, that's a good example of a crisis communication. And notice there's several layers to it, right?

314
00:39:47,630 --> 00:39:56,700
There's the crisis communication of the company, which unfortunately is basically, okay, our product sucks, you've got to give it back to us, etc.

315
00:39:58,580 --> 00:40:02,130
There's the crisis communication of public health agencies. Like what do you say about this?

316
00:40:02,150 --> 00:40:09,620
What is the action step you want people to do? Throw out your dry shampoo, you know, use other products, kinds of things.

317
00:40:12,460 --> 00:40:18,300
Etc. So there's multiple audiences you need to be thinking about. Another example.

318
00:40:18,840 --> 00:40:24,080
Yeah, I didn't write about this. I'm just not thinking, like, cause I thought.

319
00:40:24,090 --> 00:40:27,510
Oh, yes, I did write about this. I know you did.

320
00:40:28,090 --> 00:40:31,110
Well, but. But but, uh.

321
00:40:31,470 --> 00:40:36,510
Firestone tires got recalled about five or six years ago. There was a huge victim, Takata airbags.

322
00:40:36,630 --> 00:40:43,170
Remember that? The reason that blew up so bad for Takata was they didn't.

323
00:40:43,170 --> 00:40:48,540
They kept saying, no, there is the problem. No, there isn't a problem. No, there isn't a problem until they couldn't say that anymore.

324
00:40:51,560 --> 00:40:58,610
If they had come out with the B first and taken ownership of it, their company might well have survived.

325
00:40:59,000 --> 00:41:04,190
But instead, they were like, No, no, no, no, no, no, no, I guess not. And I killed them.

326
00:41:05,060 --> 00:41:10,770
By the way, there is the the I. And I can't remember whether I assignments to you or not.

327
00:41:13,910 --> 00:41:18,350
I will save it for later. There is a great example which I can bring up in the next class.

328
00:41:18,350 --> 00:41:28,400
If I haven't. If I don't decide a tale of a situation in which a company had a product kind of recall situation and pulled it back.

329
00:41:29,820 --> 00:41:37,290
Basically played the game perfectly. And then didn't suffer as a result because they were first, because they said what they knew,

330
00:41:37,290 --> 00:41:43,980
etc. and that maintained trust in the company even as the trust in the individual product was reduced.

331
00:41:46,740 --> 00:41:50,610
And by the way, just to extend this.

332
00:41:52,530 --> 00:41:57,630
Notice how all of this applies if let's say.

333
00:41:59,220 --> 00:42:00,780
Use a real world example.

334
00:42:01,650 --> 00:42:12,910
The U.S. Preventive Services Task Force says, Oh, wait, we're no longer going to recommend that average risk women start having mammograms at age 40.

335
00:42:12,930 --> 00:42:19,800
We're going to say you don't need to start until age 50 and you can have a shared decision with your provider in the intervening ten years.

336
00:42:21,160 --> 00:42:25,720
There are a lot of women who are feeling a lot of uncertainty about whether that was okay.

337
00:42:26,080 --> 00:42:32,560
A lot of emotion about whether that was okay. And a lot of need for clarity about how they were going to navigate this new situation.

338
00:42:34,270 --> 00:42:40,849
That was a crisis situation to. So anytime guidelines change, it's like a product.

339
00:42:40,850 --> 00:42:49,430
Recall that the product here is cancer screening. Q What about RSS feed?

340
00:42:49,450 --> 00:42:53,440
Right. So that's another one of these examples of stuff that's circulating right now.

341
00:42:54,280 --> 00:42:57,910
So share a little bit about what made you talk about that one.

342
00:42:58,780 --> 00:43:06,110
Let me talk about because I work with like small potatoes and then look randomly into like just that.

343
00:43:06,940 --> 00:43:13,950
And then we saw the information about where I saw the information about R&B and then like, oh, my supervisor was like all your.

344
00:43:15,940 --> 00:43:19,770
So it was almost like a I honestly didn't hear.

345
00:43:19,780 --> 00:43:25,299
But I'd be like, like, I know it's like about my radar or working around that.

346
00:43:25,300 --> 00:43:32,770
It was almost like it would circulate in their, like their environment very so that it's almost as if they were going to it in.

347
00:43:34,120 --> 00:43:39,970
So what I've seen in terms of RSV and I don't always remember what RSV stands for.

348
00:43:42,700 --> 00:43:47,680
Yeah, it's a respiratory something virus and I always never mispronounce it, right.

349
00:43:48,590 --> 00:43:58,409
Yeah. But what I've seen a lot in the public media right now is the the dual dual pandemic,

350
00:43:58,410 --> 00:44:06,149
triple pandemic fear for this winter kind of messages like it's going to be COVID and it's going to be a flu and it's going to be RSV,

351
00:44:06,150 --> 00:44:09,180
and we're going to get overloaded type messages.

352
00:44:11,480 --> 00:44:21,740
That's intelligent form of crisis. I notice in many ways that that really is a message at its heart for the health care system,

353
00:44:22,190 --> 00:44:29,400
for healthcare workers in emergency departments literally are like, yeah, this is could be really bad for us kind of situations.

354
00:44:29,430 --> 00:44:37,730
Yeah, I've seen Dearborn have little sticker earworm Public Health established this April.

355
00:44:39,020 --> 00:44:45,180
They released a statement on Instagram about it and then advocated for people to attend their food clinics.

356
00:44:47,300 --> 00:44:50,320
So that's another audience. Absolutely.

357
00:44:50,330 --> 00:44:57,950
So notice a key question here is and this is the start of the conversation, we're going to continue over the next couple of weeks in a crisis.

358
00:44:57,950 --> 00:45:00,080
You don't have one audience, you have many audiences.

359
00:45:00,980 --> 00:45:07,340
So there is the public who you want to get vaccinated and we can't at the moment vaccinate for RSV.

360
00:45:07,350 --> 00:45:12,229
So what's what is the action step we're offering people where I say, hey,

361
00:45:12,230 --> 00:45:18,530
go get vaccinated for flu because the last thing you want is to get flu and RSV and we can reduce the burden on the health care system.

362
00:45:18,890 --> 00:45:27,370
Same thing with co vaccinations. For parents of young children.

363
00:45:29,250 --> 00:45:36,600
Part of this is an awareness message in the sense of most kids who are prior to COVID,

364
00:45:36,600 --> 00:45:43,200
prior to when everybody's isolating and wearing masks, etc. Most young kids got RSV within the first two years of life.

365
00:45:43,740 --> 00:45:50,790
We now have a backlog because kids who were one and two over the last two years didn't necessarily get exposed to it.

366
00:45:50,790 --> 00:45:56,880
And now we're getting more people getting exposed. As kids are back in daycare or in schools, etc.

367
00:45:58,930 --> 00:46:02,170
Notice, by the way, what I'm doing right here. This is a mental model's communication.

368
00:46:02,200 --> 00:46:10,630
Why are we having this wave of our speed? No, it's not a new virus, but we're explaining how the history is leading to this moment in time.

369
00:46:12,390 --> 00:46:18,070
That's reducing the uncertainty to. But that's another kind of crisis.

370
00:46:18,070 --> 00:46:23,110
Like in your context, it's like, Oh, this is an explanation for why we're seeing so many kids getting out.

371
00:46:24,160 --> 00:46:27,250
In another context how to get people to get vaccinated.

372
00:46:27,580 --> 00:46:34,809
In other contexts, this is the warning to the pediatric E.R. over there to say, hey, be warned if this goes bad,

373
00:46:34,810 --> 00:46:40,389
you could get a lot of people, a lot of kids showing up with some combination of respiratory viruses.

374
00:46:40,390 --> 00:46:49,100
Let's anticipate this. So.

375
00:46:50,440 --> 00:46:56,050
Sarah. Hey.

376
00:46:58,300 --> 00:47:05,510
Um. You're talking about your experience with the ICP X Circus?

377
00:47:06,110 --> 00:47:17,570
Oh, yes. Yeah. So basically, I worked as a COVID outbreak investigator and I did an extreme, as I say, a stance for incident command structure.

378
00:47:18,560 --> 00:47:23,900
And it's basically a structure that explains on how they're responding to a big response,

379
00:47:23,900 --> 00:47:29,300
how different organizations will partner with each other without overstepping each other's.

380
00:47:31,000 --> 00:47:36,910
Leadership. Yeah. And right when I finished that training,

381
00:47:37,120 --> 00:47:47,020
the CDC failed to follow ICS because CDC sent out a public release on the guidance change without informing public health officials within a day.

382
00:47:47,410 --> 00:47:54,190
The morning after the public release came, I was slammed with a bunch of information from the public asking a bunch of

383
00:47:54,190 --> 00:47:58,540
questions I wasn't prepared to answer because I didn't know what the guidance was.

384
00:48:00,100 --> 00:48:08,590
And we could've asked the CDC because they had to go through a whole new meaning, and it was a delay of information.

385
00:48:09,100 --> 00:48:13,150
And that just caused a lot of confusion with the public and with public health officials.

386
00:48:13,960 --> 00:48:23,060
So. Let's think about this example. Was the right choice for the CDC not to have released the guidance in the first place?

387
00:48:26,330 --> 00:48:30,800
So that's that's one way you solve this problem is they don't even present that information in the first place.

388
00:48:32,100 --> 00:48:35,940
That's the hold back. That's the not the first kind of mindset.

389
00:48:37,300 --> 00:48:46,360
If you take the B first idea here and the principle underneath that incident command structure, the idea here is massive dissemination.

390
00:48:47,050 --> 00:48:49,990
At the moment you are disseminating your guidance.

391
00:48:49,990 --> 00:48:57,240
You must also be disseminating information to you, or at least beforehand, so that you know that it exists.

392
00:48:57,250 --> 00:48:58,900
You know what your responses are.

393
00:48:59,140 --> 00:49:05,770
You have available to you what you need to deal with your local community and the questions that you're going to get.

394
00:49:07,080 --> 00:49:14,970
And in a crisis situation, you may not have the chance to, you know, pre establish information downstream,

395
00:49:16,050 --> 00:49:22,290
which you can do is be broad and make sure that if you know what everybody knows.

396
00:49:23,660 --> 00:49:37,330
I give you a very concrete example of this. Continuous with COVID of the example I'm going to use actually dates previously to the 2009 H1N1 epidemic,

397
00:49:40,570 --> 00:49:50,650
which was that when that broke, University of Michigan created a website for H1N1 information.

398
00:49:57,590 --> 00:50:02,090
Why would it make sense for the University of Michigan to have a website that is

399
00:50:02,090 --> 00:50:07,610
basically simply repeating information that the CDC is disseminated like nothing?

400
00:50:07,640 --> 00:50:12,590
There was nothing new. I think this was not I mean, there was local context.

401
00:50:12,590 --> 00:50:16,150
Like there was stuff about sort of like what is the University of Michigan doing? Where can you find stuff?

402
00:50:16,160 --> 00:50:19,399
That kind of stuff. But there was no new science information on this website.

403
00:50:19,400 --> 00:50:26,480
It was purely repeating information that the public health officials at the state and national levels had already published.

404
00:50:26,870 --> 00:50:32,199
Why did you do that? Yeah, I imagine for probably parents and students.

405
00:50:32,200 --> 00:50:35,550
But also, I mean, I'm trying to think what the Internet was like in the early 2000.

406
00:50:36,040 --> 00:50:36,669
But I mean,

407
00:50:36,670 --> 00:50:43,090
it's probably better to have more official pages because there's always a lot of unofficial channels of information that might not be as accurate.

408
00:50:43,450 --> 00:50:51,040
Okay, so notice that there's not a danger. Like, you'd better keep the U of M page up to be accurate and constantly up to date,

409
00:50:51,040 --> 00:50:54,700
because otherwise it becomes one of those sources of information, misinformation.

410
00:50:55,270 --> 00:50:57,760
So there's some responsibility if you're going to go down this pathway.

411
00:50:59,880 --> 00:51:04,800
And part of it is, as you say, like there are audiences here, like the students may not know where to go for the CDC,

412
00:51:04,800 --> 00:51:08,650
but they may be able to find the relevant information for you about this.

413
00:51:08,850 --> 00:51:12,090
Or they can refer to stuff, they can point to their parents, etc.

414
00:51:12,640 --> 00:51:14,900
But yeah, I was just going to say also,

415
00:51:14,910 --> 00:51:23,060
people oftentimes are more likely to trust organizations they have some sort of data with or even if it's something that they can feel connected to.

416
00:51:23,160 --> 00:51:31,590
So when you look at organizations that have state or local chapters, so many, frequently they will have the exact same resources available.

417
00:51:31,800 --> 00:51:36,520
But it's like, Oh, that's the Michigan chapter. Right. That's what I'm a part of.

418
00:51:37,300 --> 00:51:37,920
Yeah. Yeah.

419
00:51:38,130 --> 00:51:44,650
It's just a repetition of the message to make sure it gets across most people as possible, but also that it acts like a verification step for people.

420
00:51:44,800 --> 00:51:50,590
Yeah, because like it. I mean, part of a one hour reading was talking to like making sure the information is for the people.

421
00:51:50,590 --> 00:51:56,800
Don't trust the information. They're not going to act. And notice a key piece of this is a conduit of information.

422
00:51:56,830 --> 00:52:02,470
Like the average person may or may not have much of a mental association.

423
00:52:02,860 --> 00:52:08,560
And I'm trying to recall pre-COVID, because we've talked about the CDC so much with COVID that everybody has an opinion now.

424
00:52:08,800 --> 00:52:12,310
But most of the time, most people don't actually think about this easy.

425
00:52:13,370 --> 00:52:18,380
They don't actually think about where should I go? If there is an epidemic, where should I go for public health information?

426
00:52:19,070 --> 00:52:22,220
So they go to the places that they know for other things.

427
00:52:25,750 --> 00:52:30,450
Which is why. This this is the best way I've heard this described was.

428
00:52:33,800 --> 00:52:44,860
We all of us here in the. We are the best available source of information to most of our friends and family about public health.

429
00:52:46,960 --> 00:52:55,150
They will turn to us because we are here. And.

430
00:52:56,270 --> 00:53:00,190
That doesn't mean we have to be experts, but we have that reputation,

431
00:53:00,240 --> 00:53:08,210
that authority that comes from being at the University of Michigan in public health associated with these kinds of questions.

432
00:53:11,440 --> 00:53:16,100
That's true of the environmental health worker at the hospital, too.

433
00:53:19,550 --> 00:53:24,320
All that person may be doing is changing bed linens, but to their family and friends,

434
00:53:24,680 --> 00:53:30,650
they are the source of health information because they work at Michigan Medicine in the hospital.

435
00:53:30,860 --> 00:53:38,550
They must know what the right thing to do is. So the model here is it doesn't matter who you are, it doesn't matter what your job is.

436
00:53:39,030 --> 00:53:47,609
Every single person needs access to the best available information because every single person might be that point of contact with their friends,

437
00:53:47,610 --> 00:53:51,300
their family, their house of worship, whatever.

438
00:53:53,380 --> 00:53:56,770
The power of, oh, wait, you work in public health, you study public health,

439
00:53:57,040 --> 00:54:01,450
you are at the University of Michigan, etc. It's part of what we carry with us.

440
00:54:02,350 --> 00:54:06,280
And so the response was, okay, we need to own that.

441
00:54:06,430 --> 00:54:10,600
We need to have our site that is up to date, doesn't have to be new, it doesn't have to be created.

442
00:54:10,600 --> 00:54:15,580
It just has to be first. It has to be right. It has to be there because we are credible.

443
00:54:17,370 --> 00:54:24,510
That's point three. The incredible credibility here does not necessarily come from being an expert on a particular thing.

444
00:54:25,500 --> 00:54:32,310
Comes from owning what you know and using your knowledge to find the most relevant information.

445
00:54:34,520 --> 00:54:41,300
And you are credible in some ways. Now we have to talk about how did credibility play out in the context.

446
00:54:43,620 --> 00:54:48,460
Oh. Where do I want to go for that one? Yeah.

447
00:54:48,690 --> 00:54:52,900
Let's go there. Cindy, you're talking about empathy.

448
00:54:54,470 --> 00:55:01,130
And in particular how certain actors seem much more empathetic than others when we were talking about it.

449
00:55:02,240 --> 00:55:09,709
Yeah. So I was talking about the 2020 election and I had heard I heard this like on a podcast.

450
00:55:09,710 --> 00:55:15,650
But some people are speculating that one of the reasons that there's a lot of factors,

451
00:55:15,650 --> 00:55:22,010
but possibly one of the reasons that President Biden was successful in the 2012 election was because he was a very empathetic speaker.

452
00:55:22,640 --> 00:55:26,840
And that gave people like comfort and credibility that they needed in that time,

453
00:55:26,840 --> 00:55:32,030
because at the time it was like probably the height of the panic around college uncertainty.

454
00:55:32,330 --> 00:55:37,459
And he had a reputation of being like really empathetic and the speeches like that and it kind

455
00:55:37,460 --> 00:55:43,010
of Miami him seem more credible as a leader when he was empathetic and what people were scared.

456
00:55:44,870 --> 00:55:49,250
So empathy. What do we mean when we talk about empathy in this kind of context?

457
00:55:53,150 --> 00:55:56,440
We think about what you care. Okay.

458
00:55:56,450 --> 00:56:04,520
So how is that expressed? I really care that you are good at all.

459
00:56:05,650 --> 00:56:10,180
Like acknowledging fear. Yeah. So acknowledging fear on pieces.

460
00:56:10,210 --> 00:56:14,430
What else? Like reflecting their own feelings? Yeah.

461
00:56:15,070 --> 00:56:18,590
The language they use, like the US. Our.

462
00:56:18,870 --> 00:56:27,840
Okay. So notice a common piece here. In a crisis communicator leader.

463
00:56:30,050 --> 00:56:33,270
It's usually part of the crisis as well.

464
00:56:33,290 --> 00:56:38,660
They are not outside of it. They are as affected by it has been.

465
00:56:40,050 --> 00:56:47,120
But I don't think. I was outside of COVID.

466
00:56:47,330 --> 00:56:52,110
I was inside the public eye who was personally affected by it. Yes.

467
00:56:52,160 --> 00:56:58,190
Have to use a better example. A difficult example or perhaps a more poignant example.

468
00:56:59,000 --> 00:57:03,140
Think about the responses of leaders to past shooting events.

469
00:57:05,750 --> 00:57:09,860
Think about the ones that seem to like a better Trump.

470
00:57:09,980 --> 00:57:12,890
Get it. Get how you are feeling in that moment.

471
00:57:13,810 --> 00:57:22,660
They tend to be ones in which you can tell that that person who is speaking is themselves emotionally affected by what has just occurred.

472
00:57:24,820 --> 00:57:29,480
That's empathy. That's that's saying I feel what you feel is genuine.

473
00:57:29,500 --> 00:57:33,620
It is not saying, I know it is really difficult for us to face this kind of stuff.

474
00:57:33,640 --> 00:57:37,180
Like the words I'm saying.

475
00:57:37,360 --> 00:57:43,800
I know that there are feelings. It's the expression of that personal notice.

476
00:57:44,800 --> 00:57:49,930
This is not what most people think of as being a leader.

477
00:57:53,650 --> 00:57:57,760
This is vulnerable. This is emotional. And yet.

478
00:57:59,280 --> 00:58:08,680
We will think back. When you see a leader being human and you protect that idea.

479
00:58:09,690 --> 00:58:13,320
Sweet being human because they are part of the crisis.

480
00:58:14,920 --> 00:58:23,980
Then. That builds on trust, because I could see that you were right in whatever way that makes sense.

481
00:58:24,250 --> 00:58:29,350
And when do we not trust leaders? When it seems like they are completely distant from our reality?

482
00:58:32,200 --> 00:58:38,200
Think about the the presidents visiting disaster sites kind of tours.

483
00:58:38,650 --> 00:58:46,240
Those are really tricky things because sometimes they can come across like, I really cared about what's going on and sometimes it looks like,

484
00:58:46,240 --> 00:58:50,530
hey, I want a photo op so that I can then go back to where I am and that that's awful.

485
00:58:50,530 --> 00:58:53,710
From a crisis communications standpoint, it's worse than not going.

486
00:58:57,330 --> 00:59:00,090
Have another example that's a little bit more fun than the 2010 election.

487
00:59:00,090 --> 00:59:05,729
So Iowa, like senators up for reelection and there was like a debate and they like someone asked like the two people,

488
00:59:05,730 --> 00:59:08,580
like what's the current price for corn or something like that,

489
00:59:08,580 --> 00:59:13,200
which is really important to people of Iowa and like the incumbent senator, like, could not answer.

490
00:59:13,200 --> 00:59:17,120
And like I like the way through the answer and the person like running against them, like you,

491
00:59:17,130 --> 00:59:21,360
they answer like right away and you were talking after it's like that shows like who's more in

492
00:59:21,360 --> 00:59:25,649
touch to the people that makes them feel more in touch with you're not connected with the prices.

493
00:59:25,650 --> 00:59:30,000
You don't know what people are going. Well, I have my own personal story for this and this will so date me.

494
00:59:30,000 --> 00:59:33,810
I feel embarrassed if I give you the story, but I will tell it anyway because it's a perfect example.

495
00:59:34,670 --> 00:59:39,740
When I was in college, I went to a small college that was rather technologically.

496
00:59:40,680 --> 00:59:45,720
Behind and I will not take this exactly just to leave it a little bit of as

497
00:59:48,060 --> 00:59:54,890
but this was pre cell phone and there were no cell phones in the dorm rooms.

498
00:59:55,260 --> 01:00:02,999
I mean, there were no landlines in this in the dorm rooms. There was one phone, four hall, and it sucked.

499
01:00:03,000 --> 01:00:09,800
If your room happened to be right next to the fault, which I've had for one semester, that was really bad.

500
01:00:11,460 --> 01:00:19,320
But. This was a big deal on campus like we had been advocating for years, like we got to get phones in the room.

501
01:00:19,370 --> 01:00:20,510
Hi, this is Rick Santorum.

502
01:00:21,290 --> 01:00:29,840
There was a presidential search while I was in I was in college and undergrad and one of the candidates was an internal candidate.

503
01:00:31,370 --> 01:00:38,060
And that candidate got asked about phones in the room and had no idea that it was an issue.

504
01:00:38,360 --> 01:00:41,150
And the whole student body was like, are you kidding me?

505
01:00:43,640 --> 01:00:48,530
Because it felt like they were so out of touch with reality that that was the thing that was important.

506
01:00:52,710 --> 01:01:06,750
I have to share probably the moment that I most drew upon the stuff we're talking about today, because of the fact that today is Election Day,

507
01:01:08,100 --> 01:01:16,829
because the day that snaps to my mind in November of 2016, I was teaching this class on Monday,

508
01:01:16,830 --> 01:01:25,170
Wednesdays, not Tuesday, Thursday, which means that at 8:30 a.m. on Wednesday morning after Election Day,

509
01:01:25,770 --> 01:01:33,990
I had to walk into this room and confront the students who had just seen what had unfolded that night before in terms of the election.

510
01:01:38,190 --> 01:01:42,360
And I basically said from the beginning that that's okay. This is a crisis.

511
01:01:42,370 --> 01:01:46,050
Mark, whatever your political persuasion.

512
01:01:46,710 --> 01:01:50,390
This is a crisis moment. This is a moment of great uncertainty.

513
01:01:50,430 --> 01:01:53,630
This is a moment of great fear. This is a moment of change.

514
01:01:54,500 --> 01:01:58,670
This is a moment of emotion. And.

515
01:02:02,190 --> 01:02:12,780
We talked about it. And we've spent most of the class essentially unpacking crisis communication through the lived experience of that moment.

516
01:02:14,790 --> 01:02:19,020
I will never forget that day. I was scared as [INAUDIBLE] that I was going to screw something up.

517
01:02:19,410 --> 01:02:26,480
But I knew I had to say something. Because the reality of that moment was that we weren't going to do anything else on that day.

518
01:02:28,100 --> 01:02:32,540
That was the thing that needed to be talked about. That was the risks that were on everybody's mind.

519
01:02:34,480 --> 01:02:40,660
And I remember. Okay, so here's what we know and here's what we don't.

520
01:02:43,660 --> 01:02:51,290
And just. Putting that situation out so that we could own the uncertainty and the emotion of the moment.

521
01:02:53,180 --> 01:02:59,060
And given that it's Election Day, that seems salient. I can't I can't avoid bringing that connection back.

522
01:02:59,510 --> 01:03:09,709
Yeah. Yeah. Just to contrast that, I remember having like a biology lab that Wednesday morning and people like walking into lab visibly upset.

523
01:03:09,710 --> 01:03:15,650
And weirdly in my jeans I was really upset about it and like scolded them.

524
01:03:15,650 --> 01:03:20,690
And obviously we have like a good relationship with her and because she was just so like

525
01:03:20,690 --> 01:03:23,940
dissonant it from the way people were just like actually feeling in the classroom.

526
01:03:24,380 --> 01:03:31,160
It like fractured the relationship with that instructor for the rest of the day because they were outside as opposed to inside.

527
01:03:33,190 --> 01:03:39,190
And and again, I want to try to be really clear about the distinction here.

528
01:03:40,240 --> 01:03:43,750
It's not that I had to know what was going to happen.

529
01:03:44,170 --> 01:03:47,710
It's not that I had to agree with.

530
01:03:49,250 --> 01:03:52,520
Whether people were happy or not happy or whatever.

531
01:03:53,270 --> 01:03:55,250
That wasn't the issue. I had to in the moment.

532
01:03:55,610 --> 01:04:04,730
I had the knowledge that that the community, the space was one of uncertainty, it was one of emotion, etc., and that that was the reality.

533
01:04:05,390 --> 01:04:11,540
And when you have somebody who's just like, well, yeah, well, this isn't a big deal now, it's like, how can this not better?

534
01:04:14,660 --> 01:04:20,270
Yeah. Can you talk about the Trump administration's response to COVID at the very beginning?

535
01:04:22,760 --> 01:04:31,490
Yes. So I will. Let's talk about what was talked about a lot on the last class when we pull everything together around COVID.

536
01:04:33,320 --> 01:04:36,110
I will certainly say right from the start that.

537
01:04:37,650 --> 01:04:49,500
Knowing what the CDC had in terms of guidelines and watching most of the communications from the national administration at that point in time,

538
01:04:50,160 --> 01:04:56,400
specifically not follow most of those guidelines was a exceedingly frustrating experience.

539
01:04:57,980 --> 01:05:05,010
They were not. First we unpacked and there was the whole, you know, don't wear masks.

540
01:05:05,030 --> 01:05:10,430
Oh, wait, yes, wear masks. Since that's a classic example of they don't do that.

541
01:05:11,240 --> 01:05:19,340
And it's like I remember in February hearing Trump administration people, pundits on MSNBC.

542
01:05:19,940 --> 01:05:25,040
I'm thinking of the one that has like the stocks that are the CNBC.

543
01:05:25,100 --> 01:05:28,459
CNBC Yeah, exactly. It's like, oh, don't worry about it. Don't worry about it. It's fine.

544
01:05:28,460 --> 01:05:32,950
It's fine. And that's like, that was one of my first. Memories of Cope.

545
01:05:32,950 --> 01:05:36,730
It was hearing them. They were first, but they were trying to downplay it.

546
01:05:37,030 --> 01:05:42,520
Well, and so another key thing here is never say and again, the things you'll see in the next readings over the course next week.

547
01:05:42,940 --> 01:05:52,360
Never say something that can turn out to be absolutely false. You can acknowledge uncertainty all you want,

548
01:05:52,960 --> 01:06:00,760
but we're going to foreshadow we're really hopeful this isn't going to be that long and

549
01:06:00,780 --> 01:06:04,600
we're whirlpool's going to blow over is a very different statement from don't worry.

550
01:06:09,580 --> 01:06:15,280
You know, the the the timetables of this is all going to be over by X type language.

551
01:06:16,150 --> 01:06:19,300
We didn't know that. There's no way you could have known that.

552
01:06:19,450 --> 01:06:25,510
And the problem is actually not that they're wrong. It's that they pretended that they could be right.

553
01:06:28,430 --> 01:06:33,920
At the core problem, there is the belief that I have so much confidence that I can say this is what's going to happen.

554
01:06:34,010 --> 01:06:42,080
You don't know that. And when you then express that false confidence and overconfidence, that's what breaks the trust.

555
01:06:43,520 --> 01:06:46,910
Whereas, you know, not that I am.

556
01:06:48,000 --> 01:06:53,430
The be all and end all of crisis communication. But you had one set right at the beginning in February.

557
01:06:53,970 --> 01:07:00,270
Wow. There's this new thing. We don't know that much about it. But what we do know about viruses are unpredictable.

558
01:07:00,810 --> 01:07:05,580
Sometimes they spread really fast. Sometimes they don't. Really difficult to know how this one is going to play out.

559
01:07:06,180 --> 01:07:08,669
We're hopeful it might be resolved relatively quickly.

560
01:07:08,670 --> 01:07:12,360
Sometimes these things do, but we've got to take it seriously because these things can be really good.

561
01:07:12,360 --> 01:07:16,380
That would have been a very different framing.

562
01:07:18,220 --> 01:07:22,990
I notice I didn't say anything that couldn't have been said at that point in time.

563
01:07:25,630 --> 01:07:29,890
That was just general background knowledge about how viruses are and how complicated they are.

564
01:07:29,960 --> 01:07:37,020
That's about it. Like I remember hearing that message of like, don't worry, everything's going to be fine.

565
01:07:37,030 --> 01:07:39,570
And I was like, Oh, everything is totally not fine. Fine.

566
01:07:40,030 --> 01:07:44,620
I mean, I don't remember ever having discussions with people about like when those things were coming out.

567
01:07:44,650 --> 01:07:49,270
I was like, okay, so are the when are we going to be done with this pool?

568
01:07:49,270 --> 01:07:55,810
Is this going to be a six months, a year or two years? We have conversations with my family about, okay, so how long do you think this is going to be?

569
01:07:56,050 --> 01:08:01,270
Nobody was short. Like it was all sort of like, well, obviously, this is going to be more complicated than I think it is.

570
01:08:02,050 --> 01:08:07,750
And the core piece of this account is not the truth. It's the question of confidence.

571
01:08:08,990 --> 01:08:15,890
A lack of credibility that comes from that degree of confidence in a situation where it's totally transparently not clear.

572
01:08:16,330 --> 01:08:25,140
Not certain, etc. All other things I want to hit.

573
01:08:25,380 --> 01:08:31,470
Oh, Carolyn, you're talking about some flooding in Ypsi, if I remember correctly.

574
01:08:31,650 --> 01:08:36,750
Yeah, because of a horrible rainstorm last, like, June or July.

575
01:08:36,750 --> 01:08:40,190
And yeah, it did actually hit a lot of Southeast Michigan.

576
01:08:40,500 --> 01:08:50,639
Ypsi But I lived in that city at the time, and I remember coming home like the night of the rainstorm and we're like, Damn, it's raining hard.

577
01:08:50,640 --> 01:08:55,560
Like, okay, whatever. You know, you just go inside the next morning.

578
01:08:55,560 --> 01:09:02,270
Like, the streets were just totally flooded and people were like going around storm drains, like cleaning out their hands.

579
01:09:02,280 --> 01:09:09,710
Like people were just throwing stuff out of their basements and like, basements ruined, and there's tons of belongings on the sidewalk and.

580
01:09:12,610 --> 01:09:17,740
In terms of like messaging we received. I don't remember any messaging at all.

581
01:09:18,310 --> 01:09:22,180
Nothing from the county, nothing from the city.

582
01:09:23,200 --> 01:09:31,090
So luckily we weren't hit as bad as a lot of people, but that was super frustrating because it was kind of like, is this a crisis?

583
01:09:31,730 --> 01:09:35,650
Like, are we going through a crisis? And what's going to be done about this?

584
01:09:35,650 --> 01:09:41,740
Like, this doesn't look good. Like it looks like people are losing a lot of money, right?

585
01:09:41,980 --> 01:09:50,200
When you drive around and then I start seeing pictures of like Detroit and how much it's like how hard they got hit and all their belongings.

586
01:09:50,200 --> 01:09:53,590
And finally we were like, contacted by FEMA.

587
01:09:53,830 --> 01:09:58,180
Yeah. They were like, I love this form. Like, if you had some damage and maybe you will get some money.

588
01:09:58,180 --> 01:10:02,770
And that was it, really. And it was it was really frustrating.

589
01:10:02,770 --> 01:10:05,919
We never received anything from the city.

590
01:10:05,920 --> 01:10:11,020
And then just thinking about the connections between like cities around here, like Ann Arbor and Ypsi,

591
01:10:11,020 --> 01:10:17,590
like they totally could have coordinated because Interior does a lot of stormwater management and I don't know, was just frustrating.

592
01:10:17,800 --> 01:10:22,540
So I want to unpack a couple things. One is there's the frustration about food.

593
01:10:22,540 --> 01:10:28,990
There have been more response on an on an objective level, like more coordination, more, you know, clean up, etc.

594
01:10:30,190 --> 01:10:35,230
I want to put that stuff aside because that's, that's actual like policy is not actually doing what they need to do.

595
01:10:35,260 --> 01:10:40,120
Kinds of problems. We just speak to the communication piece here, the pain.

596
01:10:40,600 --> 01:10:48,200
And we use that word intentionally for what I'm hearing in your voice. Is grounded in that disconnect between.

597
01:10:49,680 --> 01:10:55,020
A sense of life as being a problem and a sense of communication, not acknowledging that reality.

598
01:10:56,700 --> 01:11:02,730
So there's this again, this going back to the if you're in a crisis, your reality is in that crisis.

599
01:11:03,850 --> 01:11:09,580
And if that crisis is not acknowledged, then you're not acknowledging my reality.

600
01:11:09,610 --> 01:11:12,790
How should I trust you if you're not acknowledging what I am experiencing?

601
01:11:13,210 --> 01:11:16,620
So we keep coming back to that theme over and over. All right.

602
01:11:16,690 --> 01:11:21,660
In the interest of time, because I do want us to spend a few moments talking about this question.

603
01:11:21,670 --> 01:11:25,930
I want to highlight a couple of things that I put over here. One.

604
01:11:25,930 --> 01:11:29,650
And we've talked about this before. People don't panic.

605
01:11:32,380 --> 01:11:39,040
For the most part. I mean, I think that we have the awful experiences that we've seen, for example, in South Korea.

606
01:11:40,010 --> 01:11:46,770
We are we really did have true panic causing, you know, stampedes and deaths of the result of.

607
01:11:48,530 --> 01:11:52,010
The vast, vast majority of things do not look like that.

608
01:11:53,390 --> 01:11:54,380
They look like.

609
01:11:56,380 --> 01:12:03,790
Situations that are uncertain, situations that have lots of emotion, that's about maybe going and doing something that isn't the right thing,

610
01:12:04,360 --> 01:12:11,140
that may promote fear and apathy, but they don't provoke that sort of absolute panic.

611
01:12:12,390 --> 01:12:18,360
Why am I raising this? Because what you will hear over and over again from medical professionals,

612
01:12:18,360 --> 01:12:21,810
from public health professionals, is, oh, we can't tell you that because they might panic.

613
01:12:22,380 --> 01:12:27,930
And whenever you hear that, I want you to remember most people in most situations don't panic.

614
01:12:29,190 --> 01:12:31,270
That's not a justification for not communicating.

615
01:12:32,820 --> 01:12:39,299
None of the things I put up here, which is, I think, a really nice way to capture a lot of what this course is about,

616
01:12:39,300 --> 01:12:49,980
is there's a difference between telling people you should do X and helping people to this come to the conclusion that doing X is a good idea.

617
01:12:52,260 --> 01:12:58,170
Rather this is the difference between, say, everybody needs to get vaccinated for COVID and saying.

618
01:12:59,270 --> 01:13:03,410
That scene is going to help you stay out of the hospital if you get infected.

619
01:13:03,560 --> 01:13:09,590
It might even help keep the virus from circulating a lot less, and that'll help everybody protect the ones you love,

620
01:13:09,830 --> 01:13:15,860
etc. That's why getting vaccinated is a good thing, as opposed to just telling people This is what you should do.

621
01:13:17,530 --> 01:13:25,960
And when you empower people to make their own decisions in that way, you don't have to be so complete.

622
01:13:26,440 --> 01:13:31,690
You don't have to sort of say, I have to give you every last piece of knowledge you need about this crisis.

623
01:13:32,980 --> 01:13:35,230
You can help people to draw the same conclusions.

624
01:13:35,670 --> 01:13:42,220
They're going to follow up and be relatively rational people and navigate their environment and do appropriate things.

625
01:13:46,110 --> 01:13:49,210
The last thing I want to say before we go to this is.

626
01:13:58,220 --> 01:14:05,300
I think the hard part about this is. I'm acting like this is all under your control.

627
01:14:08,400 --> 01:14:11,810
Mostly situations. Lots of people.

628
01:14:12,740 --> 01:14:23,670
Hierarchies, etc. So to use an example, one of the things that happens on this campus when there is an event that affects the campus,

629
01:14:25,140 --> 01:14:30,810
is that there almost always come some message from the highest levels of the university leadership.

630
01:14:33,910 --> 01:14:37,900
It's also the case that the dean's office wants to respond to that.

631
01:14:39,080 --> 01:14:43,980
Whatever this event is. But organizationally, the dean's office can't act first.

632
01:14:46,390 --> 01:14:51,219
And so the speed with which the dean's office responds is a function of how fast

633
01:14:51,220 --> 01:14:56,830
the president's office responds because the winterization structure is set up.

634
01:14:57,640 --> 01:15:07,090
That's a problem in a crisis. But it's the way the university works for a variety of reasons, some of which are good and some of which are less good.

635
01:15:08,350 --> 01:15:17,680
That kind of thing pops up a lot where the constraints of the organization push back against how you or I might try to do stuff.

636
01:15:20,970 --> 01:15:25,800
So that's my lead into today's question, which I want you to think about for the last 5 minutes or so.

637
01:15:27,120 --> 01:15:34,800
What are the barriers? And there are many barriers. What are the barriers that most of you think about being first in crisis?

638
01:15:36,160 --> 01:15:39,970
What are the things that you think are going to make it hard in those moments?

639
01:15:41,060 --> 01:15:44,720
To be the first one out there to say what needs to be said as quickly as possible.

640
01:15:45,530 --> 01:15:49,370
Just let's name them all. We'll come back to this over the course of the next three days, three,

641
01:15:49,520 --> 01:15:53,570
three classes as we keep talking about this stuff and this is sort of driving the pump up.

642
01:15:54,200 --> 01:15:57,430
I'm not just saying this is what we ought to do, but why is it hard? Okay.

643
01:15:58,100 --> 01:16:01,370
Take a few minutes and your neighbors talk through that question.

644
01:16:01,370 --> 01:16:09,210
What's the barrier being? I mean, competing against a lot of people.

645
01:16:10,550 --> 01:16:22,580
It is I mean, I think about the why. I think if I ever wanted to send out an email, I mean, if I'm going to write 646 and I mean,

646
01:16:22,580 --> 01:16:31,190
like a lot of organizations I like to call their boss, like not only do you like that, but you want to say you are right.

647
01:16:31,190 --> 01:16:32,090
It's all their stuff.

648
01:16:32,270 --> 01:16:52,400
So they have to make it seem like you calculate how you can make something so wrong and finds out that alert are going to be harder, you know?

649
01:16:52,630 --> 01:16:58,430
Right. Yeah, exactly. Yeah.

650
01:16:59,730 --> 01:17:04,430
Yeah. You want to know what's going to happen, for example?

651
01:17:12,980 --> 01:17:23,000
Well, if you're bit immersed in that, you're like, we're working on it.

652
01:17:23,560 --> 01:17:49,860
Like, I guess that's all people want to know that when you get on someone like, Oh, I got it right.

653
01:17:49,970 --> 01:18:09,650
So it's just like he's always trying to come up with the right number of people expect will think they're smart people like

654
01:18:09,690 --> 01:18:35,100
remember that at least we need to make it very clear that it was I don't think anything happening on Twitter and Google+ converts.

655
01:18:39,770 --> 01:18:55,090
So yeah, I would like to be able to find it.

656
01:18:55,780 --> 01:18:59,229
And I got out of a big organization, put like a folder.

657
01:18:59,230 --> 01:19:03,910
There was so much trust in the way that we didn't do our job.

658
01:19:06,700 --> 01:19:20,330
I would ask about what they're going to do at the U.S. That's what I just think about how much organizations are built continuously,

659
01:19:22,430 --> 01:19:31,240
even in a crisis like that. So the question, okay, I feel like there's nothing.

660
01:19:31,300 --> 01:19:48,040
I was like, I don't know anything about and I do not believe the things that are happening.

661
01:19:48,090 --> 01:19:51,740
Yeah, I don't think that's probably student government.

662
01:19:54,080 --> 01:20:05,450
I mean, do you feel like you're like.

663
01:20:05,680 --> 01:20:10,670
I just like wrapped up in her job. She thought it was like socialism.

664
01:20:11,180 --> 01:20:20,730
And I was like, don't think that anyone to do, you know, integrity.

665
01:20:20,780 --> 01:20:39,110
So emotional distress people that I know, I have to find out who are these people.

666
01:20:41,780 --> 01:20:47,590
He's like, I don't know what you were doing. I mean, I think anything.

667
01:20:49,080 --> 01:21:02,780
I don't like asking, you know, and as simple as that, I they doing a crowd that is ridiculously optimistic.

668
01:21:05,600 --> 01:21:09,420
So it doesn't seem like you should wrap up.

669
01:21:09,680 --> 01:21:15,320
It's time to read a book for next class.

670
01:21:15,800 --> 01:21:25,820
But it is a relatively thick single document, which is a document from the European Food Safety Commission on Crisis Communications and Food.

671
01:21:26,210 --> 01:21:28,730
It's a really nice reference document, which is why I give you the whole thing.

672
01:21:30,860 --> 01:21:34,670
We're going to talk about some of the dilemmas we're starting to talk about today.

673
01:21:36,290 --> 01:21:44,880
But please keep writing examples of situations where there's been crisis communications that have worked be gas prices.

674
01:21:46,360 --> 01:21:51,590
I hope you understand what I'm saying.

675
01:21:57,870 --> 01:22:07,740
I think you have. Last night, I spent like all you in there.

676
01:22:08,820 --> 01:22:12,920
You got it.

677
01:22:13,280 --> 01:22:17,870
Where are you going? What am I supposed to be?

678
01:22:17,870 --> 01:22:25,060
Really nice. Oh, my goodness.

679
01:22:26,120 --> 01:22:37,550
I like to think of how important something like a life driving pattern.

680
01:22:37,610 --> 01:22:47,510
I've had people say I'm totally stressed that what you're saying is nasty.

681
01:22:49,550 --> 01:22:53,420
Well, I'm not afraid to travel. I know.

682
01:22:53,780 --> 01:23:21,270
I was like that for something like this. There's limitations on how much I was going to give, etc. I decided that it was two things one I didn't want.

683
01:23:23,300 --> 01:23:26,900
I guess a window into motivation. To.

684
01:23:28,060 --> 01:23:34,690
What do you remember about the interactions you and I have had in class or before class, etc.?

685
01:23:35,470 --> 01:23:42,340
Do you want to remind us to make it a little easier to speak to?

686
01:23:42,400 --> 01:23:48,780
I think that I can speak to that. And obviously the details of where and when and how.

687
01:23:49,350 --> 01:23:52,740
Yeah. Okay, I'll give you all that a.s.a.p.

688
01:23:53,520 --> 01:24:00,840
Thank you. Sure. Hello. So one thing I was thinking about was like a barrier that I kind of want to ask about because.

689
01:24:01,980 --> 01:24:05,700
Yeah, I mean, like, I feel like we'll probably cover this, but like, in terms of,

690
01:24:05,700 --> 01:24:15,779
like when we're doing consulting for like climate change and just like things that are more distant in terms of,

691
01:24:15,780 --> 01:24:20,489
oh, like these effects will show up and it is something that we need to be like worried about.

692
01:24:20,490 --> 01:24:27,780
And then also just like public fatigue of being aware of like this, you know, like the repercussions.

693
01:24:28,230 --> 01:24:35,850
Okay. Um, so part of what you're highlighting is there are things which we might want people to treat like a crisis.

694
01:24:35,850 --> 01:24:46,080
That they don't treat like a crisis. Yeah, exactly. Climate change, cardiovascular diseases, long term things.

695
01:24:46,310 --> 01:24:51,450
They they aren't crises, but they don't meet the definition that I'm talking about,

696
01:24:51,480 --> 01:24:57,750
the sense of they may have a lot of uncertainty, but they may not have that kind of emotion of.

