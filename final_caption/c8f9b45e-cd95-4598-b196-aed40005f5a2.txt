1
00:00:05,430 --> 00:00:06,089
Michael Akira Lee Hayashi: I think i'm going to get.

2
00:00:07,830 --> 00:00:12,450
Michael Akira Lee Hayashi: folks can filter in as you come back from lunch we'll get a few minutes so.

3
00:00:13,650 --> 00:00:19,710
Michael Akira Lee Hayashi: This afternoon i'm going to be covering decision in game theory which kind of broadly fall under the umbrella of.

4
00:00:20,250 --> 00:00:24,960
Michael Akira Lee Hayashi: models and mathematical models to try to capture different aspects of human behavior or.

5
00:00:25,170 --> 00:00:31,350
Michael Akira Lee Hayashi: A ways to kind of quantify aspects of disease burden and certain amount of health economics.

6
00:00:31,770 --> 00:00:44,070
Michael Akira Lee Hayashi: Before we start that I did want to see if you have any questions or anything from the morning session marissa covered parameter estimation and methods associated with that so i'm happy to talk about anything that happened there.

7
00:00:45,810 --> 00:00:52,530
Michael Akira Lee Hayashi: So we can start there and then, if there isn't a whole lot, then we can move on pretty quickly to our our main attraction.

8
00:00:54,060 --> 00:01:06,390
Adriana Perez: um my question for you guys so in all of these some alternatives so there can be Jewish spoke up just about many possibilities to get beat and this.

9
00:01:06,780 --> 00:01:21,330
Adriana Perez: morning we talked about different options sensitivity analysis and all of that, on a science wondering if, in reality, basically, what we would do in real life is to try.

10
00:01:22,200 --> 00:01:40,110
Adriana Perez: For something grow on mentors and they need to be that doesn't conversion we go to the next methods or how is a process works for any of those clouds a sensitivity analysis, you can give a like a big picture of what would be the plan.

11
00:01:41,400 --> 00:01:47,520
Adriana Perez: Down give me a better understanding of the old picture, overall I would appreciate that Thank you.

12
00:01:48,060 --> 00:01:56,940
Michael Akira Lee Hayashi: yeah so the methodology one chooses to do parameter estimation will sometimes depend a little bit on the model that you're trying to do parameter estimation for so.

13
00:01:57,210 --> 00:02:09,330
Michael Akira Lee Hayashi: A lot of the methods marissa covered we're focused on parameter estimation for deterministic odd models, although she did also cover methods for stochastic muscle models like Beijing methods and Markov chain Monte Carlo and things like that.

14
00:02:10,440 --> 00:02:18,420
Michael Akira Lee Hayashi: i'll kind of focus on O D methods, because it's a little easier to lay out kind of a flow of ways, you might try to fit the model there.

15
00:02:19,140 --> 00:02:21,960
Michael Akira Lee Hayashi: So, usually, when you have an odd model.

16
00:02:22,860 --> 00:02:34,920
Michael Akira Lee Hayashi: You have the model, and you know that you have some pre existing data source that you want to fit it to in a lot of cases if you're doing like an infectious disease model, this is going to be something like a prevalence curve an incidence curve something like that.

17
00:02:36,180 --> 00:02:39,000
Michael Akira Lee Hayashi: And typically That means that.

18
00:02:40,020 --> 00:02:51,390
Michael Akira Lee Hayashi: What you want to do is fit some particular output of your model to that date, you want to use the simulated prevalence curve from the model and use that as your thing to fit to the data.

19
00:02:52,380 --> 00:03:06,630
Michael Akira Lee Hayashi: And so often for odd models, the first place you'll start as some kind of least squares style numerical optimization or team so you'll write a little objective function that essentially calculates the some score they're.

20
00:03:07,470 --> 00:03:21,300
Michael Akira Lee Hayashi: Comparing your model to the data you'll put that thing into a numerical optimization routine something like I don't know the Meldrum need routine is pretty common for for a starting place, though there's others and then.

21
00:03:22,200 --> 00:03:31,410
Michael Akira Lee Hayashi: And then, like you mentioned you'll see what comes out and see if those results, a yield a good fit from a quantitative and qualitative perspective so you'll see if.

22
00:03:32,340 --> 00:03:45,120
Michael Akira Lee Hayashi: Your best fit model actually produces a trajectory that matches the data pretty well if it does, then you might do a little bit of extra interrogation, to make sure that you don't have an identifier ability problem and that.

23
00:03:46,290 --> 00:03:53,490
Michael Akira Lee Hayashi: The best fit parameter set that you've got is reasonably unique and if that works, then you're usually pretty good to go from there.

24
00:03:54,600 --> 00:04:05,790
Michael Akira Lee Hayashi: If anything doesn't work and then you have those prior steps that's usually where you'll start to branch into using other types of methods so if you do have an identify ability problem, for example, and you.

25
00:04:06,120 --> 00:04:11,070
Michael Akira Lee Hayashi: can't uniquely estimate the value of all of your parameters what you will usually do is.

26
00:04:11,340 --> 00:04:17,880
Michael Akira Lee Hayashi: Maybe try restricting yourself to estimating a subset of your parameters only or doing some sampling approaches or things like that.

27
00:04:18,090 --> 00:04:28,860
Michael Akira Lee Hayashi: To try to dig yourself out of your identify ability problem while still using sort of the fundamental like least squares numerical optimization framework to fit your model if that fails.

28
00:04:29,280 --> 00:04:43,470
Michael Akira Lee Hayashi: Then you start to dig into other methods like maybe maybe the Elder meat optimization method just isn't doing it for you, and so you want to try something like a simulated annealing method or a genetic algorithm or something more complicated.

29
00:04:44,580 --> 00:04:48,510
Michael Akira Lee Hayashi: To see if that'll get you out of the particular hole that you might have gotten into with.

30
00:04:48,840 --> 00:04:58,230
Michael Akira Lee Hayashi: Your regular numerical optimization algorithms, so in that case there's usually someplace that you'll start from often based on your particular training or.

31
00:04:58,710 --> 00:05:06,090
Michael Akira Lee Hayashi: What your lab tends to use like if your lab likes to start with say simulated annealing is your optimization or team that's usually where you'll start.

32
00:05:06,300 --> 00:05:13,320
Michael Akira Lee Hayashi: A lot of the fundamentals are kind of the same you still need to make a an objective function and then that has to and then.

33
00:05:13,980 --> 00:05:27,240
Michael Akira Lee Hayashi: That has to get fed into your optimization routine you get some putative best fit out of that, and then you work with that and see and then you perform diagnostics like sensitivity analysis and things like that to try to get a feel for whether you've arrived at a good fit.

34
00:05:29,400 --> 00:05:29,850
Michael Akira Lee Hayashi: So.

35
00:05:31,860 --> 00:05:39,840
Michael Akira Lee Hayashi: It where you start again often depends on your training, like, for me, I will usually use a least square style thing is my objective function.

36
00:05:40,260 --> 00:05:56,430
Michael Akira Lee Hayashi: And then try some kind of numerical optimization routine like the melter meet algorithm which is usually the default for most optimization packages see if my fits our qualitatively and quantitatively good is the actual some of squared error for that fit relatively low.

37
00:05:57,720 --> 00:06:07,830
Michael Akira Lee Hayashi: Does it qualitatively match then i'll go on to some of my other quantitative diagnostics, like a sensitivity analysis to see if I am likely to have an identify ability problem, or if.

38
00:06:08,580 --> 00:06:17,310
Michael Akira Lee Hayashi: Maybe i've only found a local minimum, and I should try to find a better global optimization or a better global best fit.

39
00:06:19,020 --> 00:06:32,190
Michael Akira Lee Hayashi: So that's that's often the approach that i'll take, particularly for odd models, to be honest, I don't I don't fit a lot of stochastic models, but it when I do it's usually some form of.

40
00:06:32,850 --> 00:06:42,480
Michael Akira Lee Hayashi: Markov chain Monte Carlo approach, just because stochastic model and you need to you need to simulate multiple runs which tends to mean you need a Monte Carlo style approach.

41
00:06:43,500 --> 00:06:43,860
Michael Akira Lee Hayashi: But.

42
00:06:45,360 --> 00:06:49,620
Michael Akira Lee Hayashi: Maybe to bring it back to core components you basically need to determine.

43
00:06:51,390 --> 00:07:00,510
Michael Akira Lee Hayashi: Three things for yourself one is what objective function you're going to use to determine the quality of fit between your model and your data.

44
00:07:01,290 --> 00:07:11,430
Michael Akira Lee Hayashi: How are you going, are you going to use some square there are you going to use like plus on residuals what is most appropriate to the model and data that you're using and that usually do in consultation with.

45
00:07:11,760 --> 00:07:18,840
Michael Akira Lee Hayashi: Maybe a statistician maybe another mathematical model or your group to try to figure out like what would be an appropriate error model for the data.

46
00:07:20,280 --> 00:07:27,750
Michael Akira Lee Hayashi: Then you pick an optimization routine usually you start with whatever reasonable default your optimization package provides.

47
00:07:28,200 --> 00:07:39,030
Michael Akira Lee Hayashi: Like i've said I like an elder mean it's pretty good it's relatively fast, then you do a sort of a first diagnostic step, where you look at the qualitative and quantitative.

48
00:07:39,960 --> 00:07:50,670
Michael Akira Lee Hayashi: fit, then you move on to your additional sort of quantitative diagnostics, where you do your sensitivity analysis and things like that does that sort of get it what you're asking.

49
00:07:59,580 --> 00:08:01,020
Adriana Perez: Yes, correct Thank you.

50
00:08:01,620 --> 00:08:02,430
Michael Akira Lee Hayashi: Okay cool.

51
00:08:02,820 --> 00:08:06,180
Michael Akira Lee Hayashi: Any other questions about about model fitting or parameter estimation.

52
00:08:09,630 --> 00:08:16,020
Kevin Chin-Wei Tracy: yeah I had a question about how the negative log likelihood was calculated in the in the lab.

53
00:08:17,040 --> 00:08:17,370
Michael Akira Lee Hayashi: yeah.

54
00:08:18,240 --> 00:08:35,190
Kevin Chin-Wei Tracy: So in um they use the Poseidon maximum likelihood to try to get the bottle and so what I noticed just looking at googling how the log likelihood for episode looks like it's there's a factorial term i'm in episode.

55
00:08:36,300 --> 00:08:54,300
Kevin Chin-Wei Tracy: In the log white person distribution, and so I don't see that term appearing in the lab and in the way that we're it's a calculated likelihood and so i'm just wondering, this is that part of like the shortened version that she was trying to calculate or was it.

56
00:08:57,630 --> 00:09:02,610
Kevin Chin-Wei Tracy: Or would that I guess factorial term effect how that log likelihood would.

57
00:09:03,960 --> 00:09:06,420
Kevin Chin-Wei Tracy: calculated and generate parameter estimates.

58
00:09:07,500 --> 00:09:10,830
Michael Akira Lee Hayashi: So i'm going to have to do a little bit of digging to make sure that I am.

59
00:09:12,900 --> 00:09:18,180
Michael Akira Lee Hayashi: But i'm not going to spew nonsense, when I try to describe this um let's see so.

60
00:09:22,500 --> 00:09:31,200
Kevin Chin-Wei Tracy: So yeah if you go to her to the github that she posted and then under the our folder there's the solutions for the lab.

61
00:09:32,640 --> 00:09:35,100
Kevin Chin-Wei Tracy: And then, if you look at line 60 of.

62
00:09:37,080 --> 00:09:43,200
Kevin Chin-Wei Tracy: Her solution of the pram estimation, I say our document or our file.

63
00:09:45,720 --> 00:09:47,850
Kevin Chin-Wei Tracy: or sorry line 65 I should say.

64
00:09:50,760 --> 00:09:52,740
Michael Akira Lee Hayashi: So premise automation so they are.

65
00:09:54,120 --> 00:09:55,260
Michael Akira Lee Hayashi: Our files.

66
00:09:58,590 --> 00:09:59,220
Michael Akira Lee Hayashi: profile like.

67
00:10:02,640 --> 00:10:07,020
Michael Akira Lee Hayashi: Oh let's see, so we have yeah so the log likelihood function written here.

68
00:10:08,700 --> 00:10:12,660
Kevin Chin-Wei Tracy: So yeah I think that's some why turn, so the, why is the data.

69
00:10:12,780 --> 00:10:19,260
Kevin Chin-Wei Tracy: i'm shinta why term have a fact, or should it be why factorial as opposed to just some some why.

70
00:10:21,900 --> 00:10:22,680
Michael Akira Lee Hayashi: i'm.

71
00:10:25,710 --> 00:10:35,460
Michael Akira Lee Hayashi: The summation is likely, a consequence of taking a log likelihood So if you if you take the log of a product, you get the some of the log of the thing.

72
00:10:36,090 --> 00:10:45,180
Michael Akira Lee Hayashi: So this is likely, why you have this particular form where you've got the some of the thing minus the some of the some of a thing times the log of a thing.

73
00:10:47,460 --> 00:10:48,840
Michael Akira Lee Hayashi: So the.

74
00:10:49,860 --> 00:10:55,770
Michael Akira Lee Hayashi: If you were just calculating the likelihood of this thing you'd have product terms between.

75
00:10:57,810 --> 00:11:13,140
Michael Akira Lee Hayashi: Between your data and your model output, I believe, again I don't remember exactly off the top of my head what the form of this thing is, it is also entirely possible to me that the factorial term cancels out between one or more terms in that equation because.

76
00:11:15,780 --> 00:11:26,310
Michael Akira Lee Hayashi: Because you're using some common terms between like your some of the some of your output and some of your data times the log your output so.

77
00:11:26,790 --> 00:11:29,190
Kevin Chin-Wei Tracy: um, I guess, can I share my screen will think or.

78
00:11:31,110 --> 00:11:39,990
Michael Akira Lee Hayashi: What do you make sure that it's there we go maple because I also don't remember off the top of my head the exact equation for like the light for a plus on likelihood of a particular thing.

79
00:11:41,730 --> 00:11:42,690
Kevin Chin-Wei Tracy: what's created my sharing.

80
00:11:49,860 --> 00:11:50,850
Kevin Chin-Wei Tracy: Okay um.

81
00:11:54,420 --> 00:11:58,650
Kevin Chin-Wei Tracy: So this is the person, this is the likelihood for a plus on distribution.

82
00:11:59,190 --> 00:11:59,550
Michael Akira Lee Hayashi: Right.

83
00:12:00,240 --> 00:12:09,960
Kevin Chin-Wei Tracy: And so, this is, I think the term that she was trying to Code into our, and so this is the concept term I think she said, you could ignore.

84
00:12:11,220 --> 00:12:17,820
Kevin Chin-Wei Tracy: um but then you have the sum over the data times the likelihood of the parameter honest, this.

85
00:12:19,500 --> 00:12:24,810
Kevin Chin-Wei Tracy: And so I think this is the term i'm confused by and I guess where did this factorial go.

86
00:12:47,160 --> 00:12:56,580
Michael Akira Lee Hayashi: let's let me walk back through the actual derivation here it's not remind me what i'm doing, because my recollection of this is the person likelihood function is more or less derived from.

87
00:12:57,330 --> 00:13:07,200
Michael Akira Lee Hayashi: Some of the some of the dairy on plus on distributions regarding the probability of a certain number of observations which which does have a factorial term in the denominator.

88
00:13:08,910 --> 00:13:12,420
Kevin Chin-Wei Tracy: yeah so that's right here, so this is the PMs salon.

89
00:13:14,250 --> 00:13:21,540
Kevin Chin-Wei Tracy: um and then, then they just multiply a bunch of the bunch of it together, and this is.

90
00:13:23,100 --> 00:13:25,890
Kevin Chin-Wei Tracy: The likelihood right here, and then they just take the log of that.

91
00:13:40,230 --> 00:13:44,040
Michael Akira Lee Hayashi: Where let's see what's the notation here for data so.

92
00:13:46,620 --> 00:13:49,560
Michael Akira Lee Hayashi: Data here is given to be the notation for the.

93
00:13:51,810 --> 00:13:56,550
Michael Akira Lee Hayashi: model parameters and I think it's a little.

94
00:13:57,120 --> 00:13:59,400
Kevin Chin-Wei Tracy: That data is model parameters X is the data.

95
00:13:59,460 --> 00:14:00,090
So.

96
00:14:15,990 --> 00:14:18,660
Kevin Chin-Wei Tracy: So yeah basically with the sun, why I think.

97
00:14:21,780 --> 00:14:23,340
Michael Akira Lee Hayashi: All right, um.

98
00:14:27,750 --> 00:14:41,880
Michael Akira Lee Hayashi: let's see and so and simplified equation, we have someone in mind some data times the log y and some data times the log why term is the more or less the second term in that equation so then.

99
00:15:00,960 --> 00:15:04,050
Michael Akira Lee Hayashi: There are, there are two possibilities in my mind without like.

100
00:15:05,970 --> 00:15:14,490
Michael Akira Lee Hayashi: kind of forcing myself to step through this thing and derive it one is that the factorial term in the last term here.

101
00:15:14,850 --> 00:15:27,870
Michael Akira Lee Hayashi: simplifies out to something that cancels nicely once you take the log that product term because that turns into a some of a log of a thing term The other possibility is that this log of.

102
00:15:29,040 --> 00:15:35,100
Michael Akira Lee Hayashi: And, and the thing that I actually find more likely looking at this, is that this law of the product of X factorial.

103
00:15:36,210 --> 00:15:43,350
Michael Akira Lee Hayashi: This term is the same, regardless of your model, regardless of your parameters so that's invariant to feta so.

104
00:15:44,910 --> 00:15:57,600
Michael Akira Lee Hayashi: So that means that if you're comparing two model fits you kind of don't care about the value of that last term because it's going to be the same between them, so it contributes no additional information, this is also why, in the.

105
00:15:57,960 --> 00:16:06,330
Michael Akira Lee Hayashi: In that last equation on this post where where the thing you do is you sell for maximum likelihood by differentiate getting with.

106
00:16:06,810 --> 00:16:16,890
Michael Akira Lee Hayashi: That with respect to data set things equal to zero, and do the first order condition that term disappears, because that term has no data in it, so it doesn't change, regardless of what your.

107
00:16:17,790 --> 00:16:30,960
Michael Akira Lee Hayashi: model is, which means that we can ignore it for the purpose of comparing the quality of fit between different parameters of the model, even though it's still there in the likelihood it just has no bearing on the fit.

108
00:16:35,430 --> 00:16:37,560
Michael Akira Lee Hayashi: Thinking through that is actually the answer, it is.

109
00:16:38,880 --> 00:16:46,470
Michael Akira Lee Hayashi: It has no data in it, so it doesn't matter essentially or it goes away once you once you differentiate with respect to data.

110
00:16:47,490 --> 00:16:53,700
Michael Akira Lee Hayashi: which is exactly what you're doing when you're performing log likelihood comparisons like when you're comparing one model fit to another.

111
00:16:55,140 --> 00:17:03,120
Michael Akira Lee Hayashi: While the absolute value of that of the log likelihood calculated for a given model parameter ization does matter.

112
00:17:03,810 --> 00:17:10,980
Michael Akira Lee Hayashi: What really matters is the difference between likelihoods calculated for one parameter ization of the model and another one.

113
00:17:11,280 --> 00:17:22,170
Michael Akira Lee Hayashi: And if you were to do that comparison between two different parameters Asians the model well the the factorial term sticking out the end, since that doesn't change with with regard to data.

114
00:17:22,650 --> 00:17:33,600
Michael Akira Lee Hayashi: Then it just kind of cancels out between those and doesn't really tell you anything additionally about whether one of those fits or another is that whether one contributes a.

115
00:17:35,310 --> 00:17:40,410
Michael Akira Lee Hayashi: Bigger log likelihood or a smaller negative likelihood blog likely.

116
00:17:45,660 --> 00:17:47,940
Kevin Chin-Wei Tracy: So the about happened to this and data term.

117
00:17:49,410 --> 00:18:04,740
Michael Akira Lee Hayashi: The term here, this is what this particular post is using to describe the I think the the that like some why term at the beginning of versus negative log like a good thing, I believe, because, looking at this, you have that.

118
00:18:05,910 --> 00:18:09,480
Michael Akira Lee Hayashi: You have to like log natural log data time some of.

119
00:18:11,160 --> 00:18:28,620
Michael Akira Lee Hayashi: Some of the data thing, so I think theta is taken to be a variable representing like the the sum of the model result in some sense the some of the the model trajectory so some of why.

120
00:18:29,790 --> 00:18:30,450
Michael Akira Lee Hayashi: give or take.

121
00:18:32,040 --> 00:18:38,160
Michael Akira Lee Hayashi: or or or maybe just the entire trajectory why it's not 100% clear to me from the notation used in this post.

122
00:18:39,450 --> 00:18:46,320
Michael Akira Lee Hayashi: But that would be my guess here that that and data term is more or less your.

123
00:18:48,030 --> 00:18:50,910
Michael Akira Lee Hayashi: Your summary of the model trajectory.

124
00:18:55,200 --> 00:18:58,800
Kevin Chin-Wei Tracy: Okay um i'll think about a little bit more I don't want to take up too much time.

125
00:18:59,340 --> 00:19:07,410
Michael Akira Lee Hayashi: yeah I can I can also spend a little bit of time like digging through the derivation for myself to find a notation that I find a little bit cleaner but.

126
00:19:07,740 --> 00:19:17,010
Michael Akira Lee Hayashi: I think I think essentially the the core of it is that a the factorial term cancels out when compared between two parameters Asians, or rather.

127
00:19:17,730 --> 00:19:29,400
Michael Akira Lee Hayashi: Is in variance between two different parameters Asians, and then the rest of it is more or less just a deviation type measure like How far is the.

128
00:19:30,540 --> 00:19:33,780
Michael Akira Lee Hayashi: Data from the model that's most of core of it.

129
00:19:37,530 --> 00:19:47,490
Michael Akira Lee Hayashi: The person like using the persona likelihood is a little bit newer to our research group it came about because one of our one of our statisticians pointed out that it is probably a better data model because.

130
00:19:49,350 --> 00:20:01,800
Michael Akira Lee Hayashi: We tend to assume that the data occurs by some variety for some process or else, like our model wouldn't make a whole lot of sense, so I haven't really sat down and thoroughly derived it for myself.

131
00:20:03,060 --> 00:20:03,570
This point.

132
00:20:09,120 --> 00:20:10,080
Michael Akira Lee Hayashi: Any other questions.

133
00:20:26,370 --> 00:20:34,230
Michael Akira Lee Hayashi: Alright well let's take a look at decision in game theory today so we're going to switch over to my lecture notes here.

134
00:20:38,250 --> 00:20:45,390
Michael Akira Lee Hayashi: For a little bit of context actually did my undergrad in political science and and a lot of what I focused on was was formal modeling of.

135
00:20:47,490 --> 00:20:54,600
Michael Akira Lee Hayashi: Of for for political science, which focused on social choice theory game theory decision theory and so.

136
00:20:56,460 --> 00:20:58,440
Michael Akira Lee Hayashi: When I moved into epidemiology.

137
00:21:00,360 --> 00:21:08,220
Michael Akira Lee Hayashi: More or less kept the interest in those particular mathematical modeling methods and looked for ways to apply them into into modeling for.

138
00:21:08,700 --> 00:21:18,300
Michael Akira Lee Hayashi: For public health and epidemiology, so a lot of this is sort of based in sort of interest in that theory and and sort of a broader interest in health policy and health economics so.

139
00:21:20,010 --> 00:21:24,750
Michael Akira Lee Hayashi: A lot of the a lot of the goal here and a lot of the motivation really is that.

140
00:21:26,940 --> 00:21:32,400
Michael Akira Lee Hayashi: Human behavior is weird and annoying and difficult to predict and frankly I wish it weren't.

141
00:21:32,700 --> 00:21:37,380
Michael Akira Lee Hayashi: But that's the world we live in, so the best we can do is try to come up with with.

142
00:21:37,620 --> 00:21:48,150
Michael Akira Lee Hayashi: ways to model, the behavior of humans in some kind of coherent framework so that we're not just kind of flying blind when we're trying to figure out why people.

143
00:21:48,420 --> 00:21:53,250
Michael Akira Lee Hayashi: behave the way that they do, and especially why people behave the way that they do in health relevant contexts.

144
00:21:53,520 --> 00:22:09,030
Michael Akira Lee Hayashi: Why is it that people react to disease outbreaks in certain ways, why do some people aggressively opposed vaccines, where others are really aggressively supportive of vaccines, why is it that most people kind of don't care and then go in whenever whenever their doctor tells them to.

145
00:22:10,170 --> 00:22:10,530
Michael Akira Lee Hayashi: and

146
00:22:11,640 --> 00:22:13,050
Michael Akira Lee Hayashi: And kind of to follow on.

147
00:22:14,100 --> 00:22:25,230
Michael Akira Lee Hayashi: What can we What can we learn about human behavior from trying to model it from a formal perspective, like what do we learn about the way that people organize their preferences about the.

148
00:22:26,010 --> 00:22:35,580
Michael Akira Lee Hayashi: The the priorities that they have in particular priorities that often focus on things like balances between economics and health or.

149
00:22:36,720 --> 00:22:39,000
Michael Akira Lee Hayashi: or reactions to particular policies.

150
00:22:40,380 --> 00:22:52,950
Michael Akira Lee Hayashi: So we there's there's there's tons of ways that we could potentially try to model human behavior um and and there's certainly plenty of theories in psychology social social psychology and sociology.

151
00:22:53,340 --> 00:23:03,360
Michael Akira Lee Hayashi: One of the one of the problems with with those domains, from my perspective is that those theories are not formal their their words and they described kind of.

152
00:23:04,560 --> 00:23:14,130
Michael Akira Lee Hayashi: varying degrees of logical theoretical constructs for how people behave but there's not really any math behind them, and that makes them awfully hard to implement in a computer or.

153
00:23:14,820 --> 00:23:30,030
Michael Akira Lee Hayashi: or, put another way it's awfully hard to integrate those theories explicitly with other kinds of models, we might want to make like disease transmission models or health outcome models because well again there isn't any formal operational ization behind so.

154
00:23:31,260 --> 00:23:40,110
Michael Akira Lee Hayashi: People have people have tried to grapple with this question of making a programmatic or mathematical or formal model of human behavior for a really long time.

155
00:23:40,530 --> 00:23:47,280
Michael Akira Lee Hayashi: stretching back to Pascal and for newly developing things like expected value and utility theory to try to explain.

156
00:23:47,760 --> 00:24:02,520
Michael Akira Lee Hayashi: Why, people are driven to do certain things, this goes back even further and people were making kind of informal but sort of naturalistic explanations of human behavior before this things like trying to trying to explain why people have certain drives to do certain things.

157
00:24:03,960 --> 00:24:05,250
Michael Akira Lee Hayashi: Where these things come from.

158
00:24:06,660 --> 00:24:21,450
Michael Akira Lee Hayashi: A lot of what I think of as modern economic theory for for models of human behavior really kick starts in kind of the early 20th century with fun Norman Morgenstern and john Nash, developing things like axiomatic choice theory.

159
00:24:21,960 --> 00:24:36,120
Michael Akira Lee Hayashi: expect developing unexpected utility theory to develop decision theory and later game theory, so a lot of this actual domain is a fairly recent development from a scientific perspective we.

160
00:24:37,200 --> 00:24:47,250
Michael Akira Lee Hayashi: We haven't really been modeling human behavior formally like this for quite as long as we've been sort of trying to quantify different aspects of human tribes and behavior.

161
00:24:49,320 --> 00:25:00,720
Michael Akira Lee Hayashi: The framework that we're going to use is is really the axiomatic choice framework or the decision theoretic framework and what we focus on are dividing human behavior into actions outcomes and preferences.

162
00:25:01,620 --> 00:25:15,180
Michael Akira Lee Hayashi: So a lot of this kind of cues close to the language of set theory and that we're thinking about discrete sets of things with certain axiomatic properties that enable us to make a particular logical deduction about their their.

163
00:25:15,840 --> 00:25:22,110
Michael Akira Lee Hayashi: Their interactions and the result, the pursuits the behavior that that you actually get when you when you solve this thing out.

164
00:25:24,150 --> 00:25:24,600
Michael Akira Lee Hayashi: So.

165
00:25:25,650 --> 00:25:33,390
Michael Akira Lee Hayashi: When I say actions or alternatives What I mean is the set of things that an individual can do in the context of a particular decision.

166
00:25:33,690 --> 00:25:43,470
Michael Akira Lee Hayashi: So this isn't necessarily the set of literally all the things that I could do ever, this is just the set of things that I could do when faced with a specific decision problem so, for example.

167
00:25:43,980 --> 00:25:49,680
Michael Akira Lee Hayashi: We might we might define incision problem where the things I can do, or play video games clean or grapes.

168
00:25:51,300 --> 00:26:08,190
Michael Akira Lee Hayashi: The next thing we need is a set of outcomes which basically tells us what happens when I when I perform each action, so what we might say, is if I play video games I get entertainment if I clean I improved my hygiene and if I grade I get worked.

169
00:26:09,870 --> 00:26:19,980
Michael Akira Lee Hayashi: And then, finally, we need to define preferences, which is an ordered set or an ordering that specifies how an individual ranks the outcomes available and note that.

170
00:26:20,160 --> 00:26:21,150
Michael Akira Lee Hayashi: it's important that.

171
00:26:21,270 --> 00:26:34,410
Michael Akira Lee Hayashi: This is a ranking over outcomes and not necessarily directly actions for reasons that we'll discuss a little bit later sometimes actions map 1212 outcomes sometimes they don't and so by making our preference order.

172
00:26:34,890 --> 00:26:43,530
Michael Akira Lee Hayashi: rank things over outcomes we kind of get around that so one potential preference order might be that I prefer entertainment over hygiene overwork.

173
00:26:44,070 --> 00:26:51,270
Michael Akira Lee Hayashi: And that might we might think that that preference order should imply what i'm actually going to do when I make a choice.

174
00:26:52,020 --> 00:26:57,600
Michael Akira Lee Hayashi: This kind of bendy greater than sign or bendy character, whatever you want to call it.

175
00:26:57,840 --> 00:27:09,360
Michael Akira Lee Hayashi: This indicates a preference So if you see this What I mean is this is preferred tips, and in particular I would call this a strict preference symbol, so this means that I prefer entertainment.

176
00:27:09,840 --> 00:27:18,510
Michael Akira Lee Hayashi: Over hygiene, where, if there are a bar under it like a greater than or equal to sign this would mean that I think entertainment is equally as good as hygiene or more.

177
00:27:21,870 --> 00:27:29,550
Michael Akira Lee Hayashi: So, right now, this still sounds like it's just a bunch of forms and then while it does does come from set theory and a lot of ways we haven't yet.

178
00:27:30,660 --> 00:27:35,910
Michael Akira Lee Hayashi: made our model entirely rigorous to start to do that.

179
00:27:36,510 --> 00:27:49,380
Michael Akira Lee Hayashi: We need to start placing restrictions on our on our model contracts so for one we probably don't want to allow literally any preference order that any person could ever come up with, and so.

180
00:27:50,280 --> 00:27:55,230
Michael Akira Lee Hayashi: Decision theory specifically restricts preference orders to those that we're going to say are rational.

181
00:27:56,640 --> 00:28:07,410
Michael Akira Lee Hayashi: And this isn't, this is not the same as rationality and kind of a colloquial sense if I say someone's acting rationally usually I mean that they're behaving in a way that I find logical and sensible but well.

182
00:28:08,190 --> 00:28:18,720
Michael Akira Lee Hayashi: I might have said that in the past past me would have said that current me would now use that exclusively describe what I call economic rationale which is that a person who is economically rational.

183
00:28:19,800 --> 00:28:29,010
Michael Akira Lee Hayashi: Has preference orders that are complete and transitive, this means that that preference or must satisfy a pair of formal accents which we'll see in a moment.

184
00:28:30,210 --> 00:28:37,860
Michael Akira Lee Hayashi: So the axiom of completeness, states that for any pair of outcomes in the set of outcomes available to an actor and a decision problem.

185
00:28:38,310 --> 00:28:53,760
Michael Akira Lee Hayashi: It must be the case that one is preferred to the other, and it could be a week preference, but what this means in in our notation is that for every outcome a&b in our set of outcomes, it must be the case that either as weekly preferred to be or bi weekly preferred to a.

186
00:28:54,930 --> 00:29:01,920
Michael Akira Lee Hayashi: This means that we can never have a circumstance, where a person refuses to rank two outcomes.

187
00:29:04,560 --> 00:29:20,190
Michael Akira Lee Hayashi: It could be the case that you say two things are equally as good as each other, I don't care which one which one I like better they're they're both the same, but what you cannot do is refuse to answer so if I say, do you like burgers better than hotdogs.

188
00:29:21,450 --> 00:29:25,620
Michael Akira Lee Hayashi: Decision theory decision theories axiom of completeness means that.

189
00:29:26,700 --> 00:29:32,550
Michael Akira Lee Hayashi: You cannot actually have zero preference, you could say, well, I don't care they're both.

190
00:29:32,880 --> 00:29:43,980
Michael Akira Lee Hayashi: Fine right what I would take that to mean is, these are literally equally as good as each other, which means that both burgers or weekly prefer to hotdogs and hotdogs or weekly preferred burgers that's fine that's actually.

191
00:29:44,340 --> 00:29:49,890
Michael Akira Lee Hayashi: This is fine, you can be ambivalent you just cannot refuse to rank two alternatives.

192
00:29:51,750 --> 00:30:01,110
Michael Akira Lee Hayashi: The actual of transitive it is slightly more complicated, this one suggests that or this one requires that if we take any three outcomes in our set of outcomes and call them a B and see.

193
00:30:01,530 --> 00:30:16,770
Michael Akira Lee Hayashi: If it is the case that a is preferred to be and to be is preferred to see, then it must be the case that as prefer to see so formally we use our notation if as weekly preferred to B and b's weekly preferred to see this implies that a is weekly prefer to see.

194
00:30:19,290 --> 00:30:30,270
Michael Akira Lee Hayashi: Why is this important well more or less what trends Nativity, is trying to eliminate our cycles in preference so we'll say more about this in a moment.

195
00:30:31,680 --> 00:30:35,130
Michael Akira Lee Hayashi: So the the idea here is that.

196
00:30:36,900 --> 00:30:48,210
Michael Akira Lee Hayashi: You can have a problem if we have three alternatives A, B and C and we use we use I don't know arrows to describe your preferences, and I say I like a better than be I like the better than see and I like see better than a.

197
00:30:49,590 --> 00:30:59,370
Michael Akira Lee Hayashi: list is awkward Unfortunately, this is a complete preference order I have specified a preference between every pair of alternatives in this in this set but.

198
00:31:00,600 --> 00:31:06,960
Michael Akira Lee Hayashi: there's a cycle, so if I want to say which thing is best.

199
00:31:09,210 --> 00:31:14,790
Michael Akira Lee Hayashi: I don't know because is a best well as better than be but see is better than a.

200
00:31:15,900 --> 00:31:25,650
Michael Akira Lee Hayashi: Is the best well he's better than see but then a is better than see so an intransitive preference order and, in particular, one which admits a cycle like this.

201
00:31:26,520 --> 00:31:32,760
Michael Akira Lee Hayashi: Is gonna make it pretty hard for us to make any reasonable prediction about what a person is going to choose, out of a decision theoretic problem.

202
00:31:34,500 --> 00:31:48,540
Michael Akira Lee Hayashi: So, by forcing preference orders to be transitive we preclude the possibility of cycles, by forcing a preference order to be complete, we preclude the possibility of refusing to choose, because this would be equally awkward if we had something like this.

203
00:31:50,250 --> 00:31:53,220
Michael Akira Lee Hayashi: And we just don't know what the relationship between.

204
00:31:53,250 --> 00:31:58,230
Michael Akira Lee Hayashi: A and C is once again we couldn't tell what the best alternative is or what the most.

205
00:31:58,230 --> 00:31:59,280
Adriana Perez: preferred alternative.

206
00:31:59,490 --> 00:32:15,780
Michael Akira Lee Hayashi: For this person is because we have an incomplete preference order, this one would also be potentially be intransitive because a preferred to be the preferred to see does not necessarily imply a preferred see because there is no preference defined here yeah question.

207
00:32:16,860 --> 00:32:38,010
Adriana Perez: Do you mean like it you don't ask for the ranking, but you are just asking each one individually, like in real life, because I mean i'm thinking like in parkinson's disease, you have to have by body olds that they could that could be the outcome any any of those five is.

208
00:32:39,630 --> 00:32:57,690
Adriana Perez: Big criteria for noticing that the Jersey packing some production example, but then the position will rank okay out of the five which ones, they have, I guess, I mean you'll be confused when the sensitivity will be applicable in real life, given that.

209
00:32:59,880 --> 00:33:09,390
Adriana Perez: You can request the ranking and they do have the order of preference on a very confused, why would the wing when these be an issue.

210
00:33:10,650 --> 00:33:11,490
Adriana Perez: in real life.

211
00:33:12,030 --> 00:33:23,910
Michael Akira Lee Hayashi: yeah so um so the axiomatic framework for decision theory tends to tends to be a thing that you need to keep in mind if you're trying to do any kind of study of of well.

212
00:33:25,350 --> 00:33:29,370
Michael Akira Lee Hayashi: behavior broadly, but especially studies that try to establish.

213
00:33:30,630 --> 00:33:31,680
Michael Akira Lee Hayashi: What sorts of.

214
00:33:33,180 --> 00:33:44,070
Michael Akira Lee Hayashi: Well i'm trying to say this without using the word decision and it it's very far because usually usually these are behavioral economic studies of like What do people actually pick under real world circumstances so you might do a study that's like.

215
00:33:45,000 --> 00:33:51,060
Michael Akira Lee Hayashi: Do consumers how sensitive our consumers to prices, for example, will people buy.

216
00:33:51,570 --> 00:34:03,930
Michael Akira Lee Hayashi: Any equivalent product that is cheaper than another product always and what that's trying to do is trying to establish the preference order of people over those products is their preference order sort of.

217
00:34:04,830 --> 00:34:13,740
Michael Akira Lee Hayashi: Does it rank products by their cost If so, then that cost preference order should satisfy completeness and transitive it.

218
00:34:14,070 --> 00:34:20,190
Michael Akira Lee Hayashi: And when you're designing your survey to ask people questions about what do you like what things do you like, better than the other thing.

219
00:34:20,400 --> 00:34:30,060
Michael Akira Lee Hayashi: You have to make sure that you design your survey in a way that it's not possible for a person to give you an answer that violates either transitive it or completeness like if I asked a person.

220
00:34:30,810 --> 00:34:36,960
Michael Akira Lee Hayashi: If I were doing consumer research, for example, and I wanted to know what foods, people like the most if I asked someone.

221
00:34:38,130 --> 00:34:47,910
Michael Akira Lee Hayashi: Do you tell me between apples and pears, which one you like better between pears and oranges, which one you like better and between oranges and apples which one you like better.

222
00:34:49,020 --> 00:34:56,070
Michael Akira Lee Hayashi: In asking those questions I might have admitted the possibility for the person to give me a response which is in transit, they might tell me.

223
00:34:56,220 --> 00:35:05,310
Michael Akira Lee Hayashi: I like apples better than pears pears, better than oranges, but I like oranges, better than apples and they've given me an answer, which creates a cyclic preference, which means that.

224
00:35:05,520 --> 00:35:17,400
Michael Akira Lee Hayashi: i'm left scratching my head about what I think they will actually buy if I if if they go into the grocery store and buy one of those fruits, so when I designed my study, then I have to try to make sure that.

225
00:35:18,570 --> 00:35:28,140
Michael Akira Lee Hayashi: That if, for example, they say, I like oranges, better than apples, I might do a follow up question to clarify well, but you said that you like apples better than Paris Paris better than oranges.

226
00:35:29,310 --> 00:35:37,320
Michael Akira Lee Hayashi: wouldn't you prefer apples to oranges, or something like that i'd have to ask questions to try to remove that intransitive it from the answer that a person gave me.

227
00:35:37,560 --> 00:35:49,350
Michael Akira Lee Hayashi: In the same way that if i'm serving people so again for like consumer behavior or what have you or or if we're talking about say medical decision making what treatments does a doctor prefer to give a patient under different circumstances.

228
00:35:49,680 --> 00:35:56,070
Michael Akira Lee Hayashi: If i'm asking them comparative questions like would you prefer, would you prefer to prescribe painkillers or steroids.

229
00:35:56,880 --> 00:36:03,600
Michael Akira Lee Hayashi: They can't refuse to answer, because if they did they would give me an incomplete preference ordering over those alternatives so.

230
00:36:03,810 --> 00:36:10,110
Michael Akira Lee Hayashi: By by understanding that I need completeness and trans Nativity to form a rational preference order, it can.

231
00:36:10,440 --> 00:36:24,810
Michael Akira Lee Hayashi: It can make it so that when I go to survey people for their actual behaviors or to try to establish what their actual empirical preferences are I don't wind up with data that leads me into a problem because the answers are incomplete or intransitive.

232
00:36:27,990 --> 00:36:29,070
Adriana Perez: yeah Thank you.

233
00:36:32,520 --> 00:36:38,190
Michael Akira Lee Hayashi: So all of this is to say that, between completeness and trans activity were able to guarantee that a person.

234
00:36:38,940 --> 00:36:50,910
Michael Akira Lee Hayashi: identifies a best alternative out of their available options or put a different way if we assume that an agent is a rational actor, who, who has preference orders that satisfy completing some sensitivity, then.

235
00:36:51,510 --> 00:36:54,900
Michael Akira Lee Hayashi: The consequence of this, the logical deducted consequence is that.

236
00:36:55,530 --> 00:37:03,390
Michael Akira Lee Hayashi: They must be able to identify the best alternative out if they're available options, they can make a ranking and there is a top thing that rank.

237
00:37:03,750 --> 00:37:13,230
Michael Akira Lee Hayashi: So, to reiterate a rational actor in the economic sense is assumed to pick the most preferred alternative out of their out of their list of options available.

238
00:37:13,560 --> 00:37:21,300
Michael Akira Lee Hayashi: So if we think about the example I gave of what I might want to do if I tell you that my preferences are entertainment over hygiene overwork.

239
00:37:22,200 --> 00:37:32,490
Michael Akira Lee Hayashi: If you told me well, I think you're going to play video games, then that should be consistent with my preference order, assuming that I am a rational actor in this context.

240
00:37:34,800 --> 00:37:39,690
Michael Akira Lee Hayashi: No, no, there are ways that we think people might actually deviate from economic rationality.

241
00:37:39,960 --> 00:37:47,490
Michael Akira Lee Hayashi: But this is actually a fairly tricky question to answer because there's two ways that a person can seemingly deviate from economic rationality.

242
00:37:47,730 --> 00:37:53,700
Michael Akira Lee Hayashi: One is that they are actually an irrational actor and they make a preference order which satisfies these properties, but then.

243
00:37:53,910 --> 00:38:01,590
Michael Akira Lee Hayashi: They don't pick the thing at the top of that preference right they tell you I like apples better than pears pears, better than oranges and apples better than oranges.

244
00:38:02,010 --> 00:38:04,980
Michael Akira Lee Hayashi: And I should think that person is going to buy apples.

245
00:38:05,760 --> 00:38:13,680
Michael Akira Lee Hayashi: But then they repeatedly go to the store and buy oranges and i'm left scratching my head thinking what happened, why are they buying oranges when.

246
00:38:14,010 --> 00:38:22,110
Michael Akira Lee Hayashi: I established that their preference orders should suggest that they buy apples, maybe, maybe they are acting in an economically rational way.

247
00:38:23,010 --> 00:38:27,990
Michael Akira Lee Hayashi: On the other hand, maybe i've done a poor job of capturing what actually.

248
00:38:28,350 --> 00:38:37,170
Michael Akira Lee Hayashi: describes their preferences, maybe there is some other factor which is influencing their decision that I did not include when I was trying to serve their preferences, maybe it's not that.

249
00:38:37,470 --> 00:38:50,250
Michael Akira Lee Hayashi: Maybe it's that there's some modifying factor, like the cost of fruit that changes, a person's preferences so maybe it's that if they cost the same a person likes apples better than pairs better than oranges, but.

250
00:38:50,820 --> 00:38:59,100
Michael Akira Lee Hayashi: If apples are more expensive if apples, are the most expensive thing then a person for first oranges, so it could be the case that.

251
00:38:59,520 --> 00:39:07,980
Michael Akira Lee Hayashi: it's merely that I did a bad job of serving what a person's preferences are, and this is a really thorny problem because it's hard to distinguish from.

252
00:39:08,130 --> 00:39:15,480
Michael Akira Lee Hayashi: Is a person actually acting irrationally from did I just do a bad job of establishing what their preference order is did I miss something.

253
00:39:15,810 --> 00:39:28,650
Michael Akira Lee Hayashi: So we often have to kind of interrogate our economic models to say, does the preference order does the utility function, or whatever we've implemented to describe what a person prefers does this actually capture.

254
00:39:29,160 --> 00:39:33,150
Michael Akira Lee Hayashi: The features that a person uses to try to calculate what they actually do.

255
00:39:36,300 --> 00:39:51,390
Michael Akira Lee Hayashi: So this gets us to how do we actually start to quantify things about why a person makes a given decision, how do we start to quantify what goes into a preference, one of the ways that we can do this goes back to the idea of expected utility theory unexpected value.

256
00:39:52,500 --> 00:39:54,330
Michael Akira Lee Hayashi: We could define a utility function.

257
00:39:55,500 --> 00:40:11,460
Michael Akira Lee Hayashi: To give us a mathematical expression of that preference order so what we're doing here is, if we have some set of alternative specs again, in this case we are going to assume the outcomes map one to one to the alternatives again that's that's not always the case, but it's fine for now.

258
00:40:12,810 --> 00:40:19,860
Michael Akira Lee Hayashi: And then some preference order P, which ranks those alternatives those alternatives could also just be the outcomes that might be simpler.

259
00:40:21,180 --> 00:40:28,950
Michael Akira Lee Hayashi: Then we're going to say a function which we're going to call you which maps the alternatives X onto the real number domain.

260
00:40:29,280 --> 00:40:47,220
Michael Akira Lee Hayashi: represents the preference or P if, and only if, for any pair of alternatives X, Y in our set of alternatives, it is the case that if the utility value, you get from X is less than or equal to the utility value, you get from why, but it must be the case that, why is weekly prefer to X so.

261
00:40:48,270 --> 00:40:58,320
Michael Akira Lee Hayashi: Higher utility shouldn't be more preferred right if I get three from apples and to from oranges, then I should also say that I for apples to oranges.

262
00:40:59,070 --> 00:41:14,670
Michael Akira Lee Hayashi: If I say, generally speaking, if I say that I get to from apples and to from oranges, then I like apples and oranges equally i'm ambivalent or I weekly prefer apples to oranges and I also we prefer oranges to apples, which creates the ambivalence relation.

263
00:41:15,840 --> 00:41:30,630
Michael Akira Lee Hayashi: So this now is a way for us to start to quantify quantitatively operationalize this notion of preference if I just say I like apples better than oranges apples better than Paris better than oranges, this is fine, but maybe we want to.

264
00:41:31,350 --> 00:41:39,150
Michael Akira Lee Hayashi: Maybe we want to know a little bit more of why or maybe we want this maybe we want to examine a preference domain that it's a little more inherently quantitative like money, for example.

265
00:41:39,510 --> 00:41:55,260
Michael Akira Lee Hayashi: Of a utility function on money might just be the utility I get for any amount of money is equal to the amount of money which is equivalent to saying that I prefer more money to less money always right, so if my utility function if this is dollars.

266
00:41:56,370 --> 00:41:58,650
Michael Akira Lee Hayashi: And this is the utility of dollars.

267
00:41:59,820 --> 00:42:03,570
Michael Akira Lee Hayashi: If this utility function is just linear increasing this means that.

268
00:42:04,770 --> 00:42:11,190
Michael Akira Lee Hayashi: More money is bad, I prefer more money to less money, no matter what, if I had a utility function that looked like this.

269
00:42:14,460 --> 00:42:25,680
Michael Akira Lee Hayashi: Well someone's going to take me for a ride at some point and take a bunch of my money, because what this means is that I like more money up to a certain point, and then I start liking less money more than more money.

270
00:42:27,600 --> 00:42:37,560
Michael Akira Lee Hayashi: So this should imply that there's some particular amount of money that I consider optimal and any amount of money that's not that amount of money is less good for me.

271
00:42:39,510 --> 00:42:47,880
Michael Akira Lee Hayashi: And, and if you're a charity you've been you want to find people like this, because you want to find where they're willing to reduce their amount of money.

272
00:42:49,890 --> 00:42:56,520
Michael Akira Lee Hayashi: This applies in other domains beyond the monetary to the, the question of how you develop utility function is primarily down to.

273
00:42:57,240 --> 00:43:10,860
Michael Akira Lee Hayashi: how you think you can quantifiably represent why a person likes what they look so this could be something like making discrete binary mappings of different qualities of a thing, so the example that I like to use these days is.

274
00:43:13,050 --> 00:43:25,380
Michael Akira Lee Hayashi: A I have a fairly strong preference order over the bananas, that I buy at the grocery store and the reason for this is that there are roughly three kinds three or four kinds of bananas, that you can walk there's the regular cavendish banana, which is the like.

275
00:43:26,730 --> 00:43:35,070
Michael Akira Lee Hayashi: The standard banana there's two kinds of small bananas typically and then some stores carry planting bacon starch.

276
00:43:36,930 --> 00:43:45,690
Michael Akira Lee Hayashi: I like a very particular kind of small banana better than every other kind of banana, and so my preference order over bananas tends to look something like Monsanto bananas.

277
00:43:46,200 --> 00:43:52,680
Michael Akira Lee Hayashi: cavendish bananas, whatever the weird little baby bananas that i've started seeing are that are fairly dismal lot and then plantains.

278
00:43:53,220 --> 00:44:11,130
Michael Akira Lee Hayashi: So if we wanted to make a utility function for how I ranked bananas, you might try to ask me questions like well, what are the characteristics about bananas, that you like, which things about bananas lead you to life in particular banana and, I might say I like I like shelf life.

279
00:44:12,150 --> 00:44:13,620
Michael Akira Lee Hayashi: shelf life is important to me.

280
00:44:14,730 --> 00:44:23,910
Michael Akira Lee Hayashi: The starkness of the banana I do not like, so I don't like it starts you banana I don't like a banana that over ripens and becomes mushy too fast.

281
00:44:24,810 --> 00:44:36,720
Michael Akira Lee Hayashi: So if you were to assign a value to each of those things if you were to say let's do a yes, no binary variable to represent whether a banana has a short shelf life for a long shelf life for it goes neely.

282
00:44:37,260 --> 00:44:41,760
Michael Akira Lee Hayashi: doesn't banana have a high degree of starting us or a low degree of starch enos and.

283
00:44:44,970 --> 00:44:49,650
Michael Akira Lee Hayashi: what's the other one starting this meal enos those two I like about bananas.

284
00:44:53,250 --> 00:45:02,910
Michael Akira Lee Hayashi: Well we'll say acidity unbalanced I like a more tarp banana no less arpanet So if you took those categories assign each type of banana 01 value for each category.

285
00:45:03,480 --> 00:45:13,620
Michael Akira Lee Hayashi: You might come up with a cavendish banana goes well, let me do this so cavendish on sauna and planting, for example, so let's do.

286
00:45:14,730 --> 00:45:19,500
Michael Akira Lee Hayashi: A shelf life acidity and.

287
00:45:21,570 --> 00:45:22,050
Michael Akira Lee Hayashi: and

288
00:45:23,430 --> 00:45:24,390
Michael Akira Lee Hayashi: starches.

289
00:45:25,560 --> 00:45:31,230
Michael Akira Lee Hayashi: So a plantation is very starchy, it also has a fairly long shelf life and it's not terribly acidic.

290
00:45:33,330 --> 00:45:43,050
Michael Akira Lee Hayashi: Where a common just be banana has a very short shelf life it's not terribly starchy but it's not terribly acidic and on santa's banana has good shelf life and.

291
00:45:43,800 --> 00:45:53,370
Michael Akira Lee Hayashi: Decent acidity and is also not terribly starch, so if we looked at each of these qualities and so that my utility function is the sum of.

292
00:45:54,630 --> 00:46:00,630
Michael Akira Lee Hayashi: The utility function for a banana or over X is equal to the sum of.

293
00:46:03,570 --> 00:46:11,490
Michael Akira Lee Hayashi: Well shelf life plus acidity plus starch enos then we'd find that this particular small banana.

294
00:46:11,910 --> 00:46:19,470
Michael Akira Lee Hayashi: gives me the highest utility value and therefore should be the most preferred banana, so this is me that m is preferred to P is preferred to see.

295
00:46:20,250 --> 00:46:29,040
Michael Akira Lee Hayashi: And, in principle, this should govern which banana actually buy when I go to the grocery store if we did a good job of establishing a utility function that describes.

296
00:46:29,790 --> 00:46:40,170
Michael Akira Lee Hayashi: How I tend to prefer bananas one over the other, and you can do this exercise for pretty much any product over what you have to make a decision, why do you buy one brand of soup over and other brands.

297
00:46:41,880 --> 00:46:53,250
Michael Akira Lee Hayashi: Do you like filtered water over non filtered water and, if so, why so what we're doing and constructing utility function and to a larger extent what we're doing by trying to model human behavior using decision theory.

298
00:46:53,520 --> 00:46:58,020
Michael Akira Lee Hayashi: Is we're trying to explain, for ourselves why people choose the things that they do.

299
00:46:58,260 --> 00:47:06,180
Michael Akira Lee Hayashi: by breaking down what matters to a person, so this is where we get into the mechanistic model and component, to a certain extent from kind of a psychological perspective of.

300
00:47:06,570 --> 00:47:13,830
Michael Akira Lee Hayashi: What matters to a person about the decisions that they make, so that if we can understand what matters to a different person.

301
00:47:14,040 --> 00:47:22,260
Michael Akira Lee Hayashi: Well, maybe we can predict why they do what they do when they're faced with a particular decision problem that we care about even if it's something more important than banana shopping.

302
00:47:22,650 --> 00:47:30,390
Michael Akira Lee Hayashi: Although banana shopping does matter to banana sellers i'll tell you that and consumer research is awfully important, so this also plays into things like.

303
00:47:30,600 --> 00:47:41,130
Michael Akira Lee Hayashi: How do companies try to understand why people buy their product over a competitor's product, how do they get an understanding of whether people are going to buy a new product that they're going to release and on the flip side.

304
00:47:41,850 --> 00:47:47,760
Michael Akira Lee Hayashi: If we're in a domain where we're trying to understand why some products that might be bad for people's health keep selling.

305
00:47:48,090 --> 00:47:52,140
Michael Akira Lee Hayashi: Well, we better have some understanding of why does the consumers, keep buying that product.

306
00:47:52,410 --> 00:48:02,310
Michael Akira Lee Hayashi: Why do people continue to buy certain types of cigarettes Why do people continue to buy certain types of E cigarettes or Why do people continue to buy alcohol, for example.

307
00:48:02,670 --> 00:48:09,870
Michael Akira Lee Hayashi: If we don't have if we don't try to establish an understanding for the mechanisms of that behavior then we're often left scratching our heads.

308
00:48:10,170 --> 00:48:20,850
Michael Akira Lee Hayashi: When it comes down to trying to modify those behaviors or trying to lay down policies that change the market landscape in an attempt to modify those behaviors that are causing negative health outcomes.

309
00:48:21,540 --> 00:48:30,450
Michael Akira Lee Hayashi: Similarly, if we want to know why people aren't getting vaccinated, we need to understand what drives a person to get vaccinated or not in the first place.

310
00:48:33,000 --> 00:48:41,700
Michael Akira Lee Hayashi: So if we're working from a utility function, how do we actually determine what a person is going to do what's our solution method for a decision theoretical well.

311
00:48:42,510 --> 00:48:55,410
Michael Akira Lee Hayashi: We know that a rational actor by assumption will always choose the most preferred alternative, we know that the most the most preferred alternative in a decision theoretic model is equivalent to the one that yield the highest utility belt, therefore.

312
00:48:56,760 --> 00:49:05,730
Michael Akira Lee Hayashi: If we solve for the argument that maximizes the utility function, where the argument in this case is the alternative that a person is faced with their decision problem then.

313
00:49:06,210 --> 00:49:12,840
Michael Akira Lee Hayashi: that's our game we've solved, we have solved for what a person should do in our particular decision theoretic problem.

314
00:49:13,320 --> 00:49:25,320
Michael Akira Lee Hayashi: Usually usually we do tend to work from utility functions, instead of discrete preference orders, because the utility function does give us the capacity to build in operational ization of different aspects that influence a person's preference.

315
00:49:28,140 --> 00:49:29,850
Michael Akira Lee Hayashi: How do we do this well.

316
00:49:31,170 --> 00:49:35,880
Michael Akira Lee Hayashi: If we've gotten lucky, and we have a utility function that is differentiable and single peaked.

317
00:49:37,170 --> 00:49:37,560
Michael Akira Lee Hayashi: Then.

318
00:49:38,940 --> 00:49:48,630
Michael Akira Lee Hayashi: We can use our first order condition to sell for the Max wherein we take the first derivative of the utility function set at equal to zero and solve for X so.

319
00:49:50,370 --> 00:49:51,960
Michael Akira Lee Hayashi: What this is going to look like is.

320
00:49:53,070 --> 00:49:55,470
Michael Akira Lee Hayashi: Suppose our utility function looks like this.

321
00:49:57,600 --> 00:50:07,470
Michael Akira Lee Hayashi: What we want is this right, and fortunately this function happens to be differential and there's only one peak in that function so.

322
00:50:08,070 --> 00:50:14,970
Michael Akira Lee Hayashi: So there's only one point in this function, where the derivative of this function equals zero that's going to look, if we look at D you.

323
00:50:15,630 --> 00:50:30,660
Michael Akira Lee Hayashi: dx this is going to look like well this function is kind of increasing, and then it starts to decrease the next hit zero, and then it starts to decrease and so here, this is where do you equals zero.

324
00:50:32,130 --> 00:50:35,910
Michael Akira Lee Hayashi: And this corresponds to this value of X question.

325
00:50:38,400 --> 00:50:51,390
Adriana Perez: Yes, do dance do PDT fun Shannon is always created for the individual that you're thinking or I mean, I cannot think right now and that isn't.

326
00:50:51,840 --> 00:51:05,160
Adriana Perez: utilities from different perspective it goes for me like a you take a sample from people, and it could be like CEOs Ray and they want a different up anything function that you can use for me.

327
00:51:06,060 --> 00:51:18,630
Adriana Perez: or his students before putting a different example, but then he's always from the perspective of the people who select the preferences, or are there other type of utilities for.

328
00:51:19,650 --> 00:51:21,960
Adriana Perez: Different crane groups or the friend.

329
00:51:23,280 --> 00:51:24,840
Adriana Perez: know the individual something.

330
00:51:26,010 --> 00:51:30,840
Michael Akira Lee Hayashi: that's a good question usually I tend to think of utility functions as being defined around.

331
00:51:31,350 --> 00:51:32,340
Michael Akira Lee Hayashi: A kind of.

332
00:51:32,670 --> 00:51:34,110
Michael Akira Lee Hayashi: type of person.

333
00:51:35,310 --> 00:51:40,980
Michael Akira Lee Hayashi: For whom that utility function is reasonably sensible, so we might think that.

334
00:51:43,890 --> 00:51:52,050
Michael Akira Lee Hayashi: So CEOs versus employees, for example, are likely to have different utility functions with respect to I don't know.

335
00:51:55,380 --> 00:52:03,660
Michael Akira Lee Hayashi: revenue of the company like a CEO is utility function over revenue, the company might just be strictly increasing all they care about is more revenue more revenue more revenue.

336
00:52:04,140 --> 00:52:15,420
Michael Akira Lee Hayashi: and employees utility function over revenue of the company might look more like this, where they're like I want the company to do well, but I just don't care if the company's making maximum money as long as I keep my job so.

337
00:52:17,040 --> 00:52:28,470
Michael Akira Lee Hayashi: What what we usually do when we're defining a decision theoretic problem and when we're creating the utility functions for people undergoing that decision problem is will usually sit down and think about like.

338
00:52:29,580 --> 00:52:40,110
Michael Akira Lee Hayashi: What types of people are likely to have this sort of utility function what types of people and I trying to model for what am I trying to model only employees, am I trying to model employees and the C suite.

339
00:52:40,680 --> 00:52:53,790
Michael Akira Lee Hayashi: And if that's true, then I probably need to design a different utility function for those those C suite members versus the regular rank and file employees in the same way that if i'm designing utility functions over.

340
00:52:55,920 --> 00:53:03,960
Michael Akira Lee Hayashi: To use an example from some of my own work suppose I wanted to sign a utility function that describes how a person evaluates the performance of a water filter.

341
00:53:05,400 --> 00:53:08,100
Michael Akira Lee Hayashi: Fortunately, water filters have a property that.

342
00:53:09,180 --> 00:53:20,580
Michael Akira Lee Hayashi: That is fairly easy to operationalize they have their filtration efficacy, which is usually defined in log removal rate, the amount of stuff that you get out of the water after you put it through that filter.

343
00:53:21,210 --> 00:53:27,060
Michael Akira Lee Hayashi: If our modeling someone in a developed country like the US i'd probably suppose that that person.

344
00:53:27,540 --> 00:53:33,150
Michael Akira Lee Hayashi: Has a utility function it's just increasing in efficacy of the filter we just want the best filter.

345
00:53:33,570 --> 00:53:37,170
Michael Akira Lee Hayashi: right we don't we don't care what the other factors are in that filter.

346
00:53:37,500 --> 00:53:45,810
Michael Akira Lee Hayashi: However, if i'm modeling someone in a developing country that has fewer resources available and maybe you know less less free time and things like that.

347
00:53:46,140 --> 00:53:56,790
Michael Akira Lee Hayashi: Maybe it's the case that what they want is a filter that is good enough, but isn't so efficacious that it starts to get inconvenient or inefficient, or that it breaks frequently so.

348
00:53:57,180 --> 00:54:03,690
Michael Akira Lee Hayashi: filters that have like a filter with finer pores in it that can filter out more stuff in the water is both more susceptible to clogging.

349
00:54:04,170 --> 00:54:10,500
Michael Akira Lee Hayashi: And also flows slower, so you have to wait longer for the water to flow through it now if i'm.

350
00:54:11,310 --> 00:54:25,380
Michael Akira Lee Hayashi: If i'm very wealthy and I have a if I have a bunch of hired people to filter my water for me I don't care how long that water has to go through, and I don't care how often I have to replace the filter I just throw money at the problem, and I want a better filter.

351
00:54:26,310 --> 00:54:35,760
Michael Akira Lee Hayashi: If I do have to care about how fast water flows through the filter and and how often I might have to replace that filter there by forcing me to buy a new one.

352
00:54:36,420 --> 00:54:46,890
Michael Akira Lee Hayashi: Then i'm going to have different preferences and therefore a different utility function over the efficacy of that filter so that would be another example of a case where we might think that people in certain.

353
00:54:47,190 --> 00:54:54,540
Michael Akira Lee Hayashi: economic context or certain socio economic strata may have different shapes of their utility function over a given domain.

354
00:54:54,810 --> 00:55:04,500
Michael Akira Lee Hayashi: So this can be this can be something that you make as individualized as trying to tailor utility function to a specific person I certainly do this if i'm trying to think about.

355
00:55:05,010 --> 00:55:09,240
Michael Akira Lee Hayashi: How a given person that i'm interacting with is going to respond to particular things like.

356
00:55:09,540 --> 00:55:17,340
Michael Akira Lee Hayashi: I will try to form a decision theoretic model of a person overstay their food preferences, because this is important if I want to try to get lunch with that person.

357
00:55:17,790 --> 00:55:30,930
Michael Akira Lee Hayashi: And that utility function is going to be tailored to that specific person, where in other contexts, maybe I will make a utility function that's tailored to a group or a class of people because that's what I want to try to model in that context.

358
00:55:37,260 --> 00:55:38,280
Adriana Perez: Okay, thank you.

359
00:55:39,990 --> 00:55:42,960
Michael Akira Lee Hayashi: One of the things about decision in game theory is frameworks that that they.

360
00:55:42,960 --> 00:55:55,350
Michael Akira Lee Hayashi: are very flexible you as a model, or have a lot of leeway over how you build things like the utility functions, so a lot of what it comes down to is how well you've done your due diligence on.

361
00:55:55,560 --> 00:56:05,010
Michael Akira Lee Hayashi: The individuals or groups that you're trying to model, such that you have reasonable confidence that you're including factors about those groups that influenced their actual decisions.

362
00:56:07,140 --> 00:56:08,850
Michael Akira Lee Hayashi: or individuals, as the case may be.

363
00:56:10,920 --> 00:56:22,890
Michael Akira Lee Hayashi: So there are sometimes cases where you get a utility function that isn't differentiable or single peaked and in that case solving for maximum utility gets a lot nastier and you have to use other solution techniques, but.

364
00:56:23,460 --> 00:56:33,780
Michael Akira Lee Hayashi: Often we try to explicitly select our utility functions such that they are differentiable and single, this is why so often you'll see utility functions that are.

365
00:56:34,020 --> 00:56:47,760
Michael Akira Lee Hayashi: Maybe a quadratic function or a negative absolute value function, because these are just these are really nice to to optimize like there's a nice closed form solution to the optimum of these things and it's very easy to find and.

366
00:56:48,390 --> 00:56:55,350
Michael Akira Lee Hayashi: If we can, if we have a reasonable justification for this shape of utility function reflecting a person's preferences, then.

367
00:56:56,190 --> 00:57:00,450
Michael Akira Lee Hayashi: We definitely want to try to use one of those things because they're really easy to solve.

368
00:57:00,960 --> 00:57:10,290
Michael Akira Lee Hayashi: A lot of a lot of mathematical modeling is trying to pick functions for things that are easy to work with, as opposed to hard and sometimes This can lead us into trouble where.

369
00:57:10,800 --> 00:57:18,510
Michael Akira Lee Hayashi: Our function is easy to solve, but so simple that it does a bad job of representing the thing that we're trying to model and that can get us into a little bit of trouble.

370
00:57:22,470 --> 00:57:27,180
Michael Akira Lee Hayashi: So when we actually go to build a utility function we've kind of preempted this discussion a bit.

371
00:57:27,510 --> 00:57:35,220
Michael Akira Lee Hayashi: there's a lot that goes into building utility function, because a lot of the design of the decision or game theoretic model is at the discretion of the model.

372
00:57:35,550 --> 00:57:44,850
Michael Akira Lee Hayashi: While there is often there there, there are domains, where there is kind of established theory like if we're talking about monetary preferences or things like that well.

373
00:57:45,240 --> 00:57:56,550
Michael Akira Lee Hayashi: economists who spent a lot of time thinking about how people's preferences over money book, and so there might be a utility function that's already ready to go out there, but if there isn't what do we have to balance well.

374
00:57:57,990 --> 00:58:07,590
Michael Akira Lee Hayashi: there's a little bit of art and science here, so a utility function should qualitatively reflect the preference order that they're that they're trying to represent, so if we have a continuous domain.

375
00:58:08,010 --> 00:58:19,770
Michael Akira Lee Hayashi: Over alternatives and and we have a preference or or we have a utility function that looks like this, we want to keep in mind that what this means is that a person has some thing that they think is best and.

376
00:58:20,250 --> 00:58:28,800
Michael Akira Lee Hayashi: Anything that's not that thing they like less than their ideal thing, where, if you had a utility function it looked a little more like this, this is more of a case where.

377
00:58:29,430 --> 00:58:39,600
Michael Akira Lee Hayashi: They like more and more and more of a thing and then at some point, they have enough and they're okay with getting more but they don't actively seek it they don't care so much this could be.

378
00:58:40,710 --> 00:58:41,280
Michael Akira Lee Hayashi: So.

379
00:58:43,080 --> 00:58:50,160
Michael Akira Lee Hayashi: To a certain extent this is somewhere in the neighborhood of my preferences over salary and compensation for a job.

380
00:58:52,110 --> 00:58:57,030
Michael Akira Lee Hayashi: While I generally would like to receive more pay for my job than less.

381
00:58:57,330 --> 00:59:05,640
Michael Akira Lee Hayashi: There is some point where I receive enough compensation that i'm comfortable and i'm not going to aggressively seek out a different job that gives me a higher salary.

382
00:59:05,880 --> 00:59:11,580
Michael Akira Lee Hayashi: purely to get that higher salary because i've received a salary which enables me to live in a reasonably comfortable way.

383
00:59:12,210 --> 00:59:22,680
Michael Akira Lee Hayashi: Now other people might have different preferences other people might have a more monotonic Lee increasing or more strictly increasing preference order over salary compensation, such that they will continue to seek jobs.

384
00:59:22,890 --> 00:59:26,910
Michael Akira Lee Hayashi: To give them more and more and more and more and more money, and then you wind up with people like you on musk.

385
00:59:29,220 --> 00:59:29,760
Michael Akira Lee Hayashi: So.

386
00:59:31,590 --> 00:59:36,120
Michael Akira Lee Hayashi: A qualitative representation of how a person ranks their alternatives is important.

387
00:59:37,290 --> 00:59:46,920
Michael Akira Lee Hayashi: And and alongside this, we want to think about what do the alternatives actually represent, is it something continuous like money is it something discrete like types of bananas.

388
00:59:48,240 --> 00:59:53,670
Michael Akira Lee Hayashi: Sometimes, the question of whether we're looking at a monetary versus a non monetary alternative matters a lot because.

389
00:59:53,880 --> 01:00:01,770
Michael Akira Lee Hayashi: The way that people think about money might differ from the way that they think about other sort of continuous value types of preferences like.

390
01:00:02,520 --> 01:00:14,190
Michael Akira Lee Hayashi: Like amount of time spent doing something would be a continuous value thing, but maybe preferences order preferences over the amount of time you spent doing activities doesn't look like preferences over money because.

391
01:00:15,090 --> 01:00:19,530
Michael Akira Lee Hayashi: Well there's a finite amount of time I have in my life or in a given day and maybe.

392
01:00:20,580 --> 01:00:32,340
Michael Akira Lee Hayashi: Maybe there is some optimal amount of time, I want to spend on an activity, even if I really like that activity and while I could spend more time on it that time is taking away from time I could spend on other activities, I look.

393
01:00:33,210 --> 01:00:46,650
Michael Akira Lee Hayashi: There are, as I mentioned some functional forum some specific equations that are nice because they're easy to solve for like a negative quadratic equation something like negative X squared right, this is this is great because.

394
01:00:47,790 --> 01:00:55,260
Michael Akira Lee Hayashi: This this is single peak to or the negative absolute value function these things have convenient maximum or minimum.

395
01:00:56,460 --> 01:01:02,880
Michael Akira Lee Hayashi: That we can solve for and we don't even have to do a whole lot of work to solve for them they're just really, really easy where.

396
01:01:03,480 --> 01:01:14,040
Michael Akira Lee Hayashi: The more terms you throw into a function, the more complicated the functional form, the harder it gets to optimize and that sort of maximize and so that ends up being one of our balances as well.

397
01:01:19,500 --> 01:01:21,390
Michael Akira Lee Hayashi: So here is a.

398
01:01:23,100 --> 01:01:29,340
Michael Akira Lee Hayashi: here's an example of a simple decision theoretic model with a utility function tacked on to it this, I believe, is um.

399
01:01:30,690 --> 01:01:41,280
Michael Akira Lee Hayashi: This is called the hotel and downs model of political preference, which is kind of one of those classic toy models of of political preferences in the legislative body, so.

400
01:01:42,300 --> 01:01:44,850
Michael Akira Lee Hayashi: it's often convenient to think about people.

401
01:01:46,620 --> 01:01:58,170
Michael Akira Lee Hayashi: In America as sitting on one side or another, have a liberal conservative spectrum or conservative, liberal spectrum, however, you want to order the things left right probably makes sense, so liberal conservative time later anyway.

402
01:01:59,880 --> 01:02:02,970
Michael Akira Lee Hayashi: And we can assume that members of Congress behave similar.

403
01:02:04,590 --> 01:02:09,240
Michael Akira Lee Hayashi: Will suppose that this spectrum is represented by the the closed interval 01.

404
01:02:10,560 --> 01:02:21,990
Michael Akira Lee Hayashi: And each Member of Congress has some ideal position along that spectrum, which is to say some degree of liberal or conservative ness that they think is best.

405
01:02:24,210 --> 01:02:35,880
Michael Akira Lee Hayashi: we're also going to assume that any newly proposed piece of legislation, any bill that hits the the House floor can also be placed on that spectrum somewhere, so it has a degree of liberal or conservative nets.

406
01:02:37,920 --> 01:02:55,950
Michael Akira Lee Hayashi: If a representative votes for the bill, then this is the utility value that they receive from for voting for that bill, if this is a negative quadratic utility function so basically are saying is look at the distance between a members ideal point and the bill.

407
01:02:57,660 --> 01:03:07,350
Michael Akira Lee Hayashi: Take the square of that and then take the negative of that so we end up with a preference order that is of this shape right where the peak is that X hat.

408
01:03:08,730 --> 01:03:13,080
Michael Akira Lee Hayashi: and any bill to the Left or Right of this ideal point is less good.

409
01:03:15,600 --> 01:03:21,390
Michael Akira Lee Hayashi: So if we if we treat a lawmaker preferences this way.

410
01:03:22,920 --> 01:03:32,160
Michael Akira Lee Hayashi: Do we think that this is going to have any consequences in terms of what kinds of bills can actually get passed in a you know larger body like if we had.

411
01:03:32,940 --> 01:03:44,460
Michael Akira Lee Hayashi: If we think about Congress acting in this way is there kind of a region in the political spectrum, where we tend to think that bills are going to fall that actually get passed, but actually get voted for by a majority.

412
01:04:12,480 --> 01:04:21,060
Michael Akira Lee Hayashi: Let me do a little illustration here so here's here's our spectrum, from zero to one suppose we have a bill that gets proposed over here, this is going to be X.

413
01:04:22,470 --> 01:04:34,560
Michael Akira Lee Hayashi: And suppose we have a very small Congress, because we've decided that we will still allow dueling as a way of resolving political disputes which frankly I think we should, that would be that would be hilarious.

414
01:04:36,450 --> 01:04:40,410
Michael Akira Lee Hayashi: And this is X had one X hat to.

415
01:04:41,610 --> 01:04:48,330
Michael Akira Lee Hayashi: X hat three and the preferences of each oh that's interesting that's a small.

416
01:04:50,220 --> 01:04:54,150
Michael Akira Lee Hayashi: let's fix this Oh, this is going to ruin everything gradually there we go.

417
01:04:56,370 --> 01:04:58,830
Michael Akira Lee Hayashi: The preferences of each member look kinda like this.

418
01:05:04,680 --> 01:05:07,170
Michael Akira Lee Hayashi: what's all let's suppose that there is.

419
01:05:10,380 --> 01:05:21,330
Michael Akira Lee Hayashi: Another bill that's over here so there's two alternatives for for a bill that could be passed which of these two is actually going to get passed by the legislature X one X two.

420
01:05:25,740 --> 01:05:30,240
Michael Akira Lee Hayashi: assume assuming majority vote, and no weird stuff like super majorities or filibuster.

421
01:05:33,600 --> 01:05:40,350
Caroline Godfrey: Maybe neither I don't think either of them falls into like more than one of the three people's preferences.

422
01:05:41,790 --> 01:05:46,290
Caroline Godfrey: Like if that if that curve underneath kind of shows the range at which that.

423
01:05:48,630 --> 01:05:55,770
Michael Akira Lee Hayashi: Will suppose that these kind of continue on indefinitely down and they just like they do cover the full range here, but I just didn't have room to.

424
01:05:55,770 --> 01:06:06,720
Michael Akira Lee Hayashi: draw them so maybe neither is a as a potential solution, maybe, maybe these both get voted down um any other thoughts any other things that might happen.

425
01:06:10,230 --> 01:06:14,100
Nicolle Krebs: Did you say that if it's to the right is less preferred.

426
01:06:14,970 --> 01:06:23,880
Michael Akira Lee Hayashi: Well, so the utility functions are given by these curves so that means that a bill that's either to the left or the right of a Members ideal point is.

427
01:06:24,480 --> 01:06:34,740
Michael Akira Lee Hayashi: less good by some amount and it doesn't matter whether it's more left or more right, like any distance in either direction is less good than being on that middle point.

428
01:06:38,490 --> 01:06:43,650
Kevin Chin-Wei Tracy: Would it be the bill that minimizes the tissue of X function, or all the numbers.

429
01:06:46,980 --> 01:06:51,690
Michael Akira Lee Hayashi: um that would be true, yes, we could, if we yeah so if we if we.

430
01:06:53,190 --> 01:06:58,200
Michael Akira Lee Hayashi: found something that minimize the utility function for every member of maximized it.

431
01:06:58,800 --> 01:07:03,720
Kevin Chin-Wei Tracy: Well, for the for the body as a whole, I guess, I mean it's not possible unless it fair.

432
01:07:05,430 --> 01:07:13,200
Michael Akira Lee Hayashi: yeah so we can kind of we can walk through the logic of how this how this maximization might look so let's look at bill one, for example.

433
01:07:13,530 --> 01:07:28,080
Michael Akira Lee Hayashi: who likes bill one well it's okay for person one it's kind of less okay for person to end it's really bad for person three based on just based on the sheer distance to those people right this versus this versus this.

434
01:07:29,430 --> 01:07:32,700
Michael Akira Lee Hayashi: bill to is kind of okay for person to.

435
01:07:34,410 --> 01:07:37,350
Michael Akira Lee Hayashi: kind of not okay for person three and.

436
01:07:38,910 --> 01:07:50,280
Michael Akira Lee Hayashi: kinda kind of not okay for person one, so this is bill to is maybe a little bit better for everybody, then bill one because there's slightly less total distance um.

437
01:07:53,490 --> 01:07:54,090
Michael Akira Lee Hayashi: What if we.

438
01:07:54,150 --> 01:07:54,570
Caroline Godfrey: What afford.

439
01:07:54,780 --> 01:08:11,220
Caroline Godfrey: The end of the day, like bill to is maybe a little bit better for everybody, on average, however, just like the way that voting works like you only need the majority so it's it's like it doesn't actually matter how bad bill one is for person three.

440
01:08:12,270 --> 01:08:18,210
Caroline Godfrey: If it's going to get passed by one into like it only matters what the slightly over 50% think of it.

441
01:08:19,140 --> 01:08:19,290
Caroline Godfrey: Like.

442
01:08:19,470 --> 01:08:21,390
Caroline Godfrey: A 50% that's close enough to the bill.

443
01:08:22,110 --> 01:08:34,110
Michael Akira Lee Hayashi: yeah so if we can get any two of these three people we're going to get a bill that passes, essentially, so if we can so one one observation is that if we can put a bill somewhere in here, that means that.

444
01:08:34,560 --> 01:08:42,810
Michael Akira Lee Hayashi: These two people or any two people will vote for it over any other bill, then we can guarantee that that one will pass, because we have majority.

445
01:08:43,770 --> 01:08:56,190
Michael Akira Lee Hayashi: In particular, there is a result, out of this model that if we make that special bill be the median voters preference if we stick our bill right here, this one.

446
01:08:57,930 --> 01:09:13,230
Michael Akira Lee Hayashi: Is the solution to our voting problem because, if we look at any other bill to the left or right of that one, it will be preferred by slightly fewer people and cannot gain a majority This is known as the median voter theorem where.

447
01:09:14,550 --> 01:09:30,690
Michael Akira Lee Hayashi: If you assume single peaked preferences over bills in a legislative body, the votes by majority, then, whoever the median voter is in that body has an enormous amount of power over the bills that get passed, if you believe this kind of general model.

448
01:09:32,220 --> 01:09:39,450
Michael Akira Lee Hayashi: Because they are in some sense closest to a full majority in either direction.

449
01:09:40,830 --> 01:09:50,400
Michael Akira Lee Hayashi: And so bills to the Left will will fail to garner their vote relative to one sitting here, which includes them and everyone to the right.

450
01:09:50,820 --> 01:10:01,140
Michael Akira Lee Hayashi: Where a vote to the right or a bill to the right will fail to garner their vote compared to this one here or one over here, which would, which would gain them and everyone to the left.

451
01:10:02,130 --> 01:10:12,480
Michael Akira Lee Hayashi: This is often used as an explanation for why people like Joe manchin interested in Sydney might have so much power in the Senate, right now, because the Senate is very evenly split.

452
01:10:12,750 --> 01:10:20,880
Michael Akira Lee Hayashi: between democrats and Republicans, and so it takes very few votes to swing a particular bill, one way or another, and.

453
01:10:21,150 --> 01:10:33,900
Michael Akira Lee Hayashi: mansion in cinema happened to be relatively close to the effective median of those bodies or that would be the explanation that we would tend to propose, in addition to the fact that the filibuster rule means it's harder to pass a bill in general, because the.

454
01:10:34,530 --> 01:10:36,990
Michael Akira Lee Hayashi: The threshold for a super majorities higher.

455
01:10:37,740 --> 01:10:52,350
Michael Akira Lee Hayashi: fairly sharp degrees of ideological polarization and things like that, but this is an example of being able to use a fairly simple decision theoretic model to try to gain some insight into why a real political body might be behaving in the way that it is.

456
01:10:55,500 --> 01:10:56,880
Michael Akira Lee Hayashi: Questions or thoughts.

457
01:11:14,820 --> 01:11:21,720
Michael Akira Lee Hayashi: One thing that I think is worth considering is, this is a very simple model of people's political preferences.

458
01:11:24,420 --> 01:11:32,700
Michael Akira Lee Hayashi: Do we think that it is simple enough or are we missing things that might actually contributes political behavior that.

459
01:11:33,480 --> 01:11:45,480
Michael Akira Lee Hayashi: We didn't we didn't think about when we built this model we didn't include in our utility function, because all we cared about was the liberal or conservative miss of a particular bill on the table and the liberal or conservative miss of a particular legislator.

460
01:11:46,440 --> 01:11:54,450
Michael Akira Lee Hayashi: Do we think that's reasonable do we think that there's more to it than that do we think they're things that seem like they might be more to it, but are.

461
01:11:54,840 --> 01:12:08,340
Michael Akira Lee Hayashi: You know more complication than complexity lobbying yeah so um so it may not be that individual Members preferences on a bill are entirely governed by the liberal or conservative miss or maybe.

462
01:12:08,730 --> 01:12:17,340
Michael Akira Lee Hayashi: Maybe it's the degree to which that was due to the preferences of some other entity as opposed to the ideal point of the Member themselves, maybe it's that.

463
01:12:17,730 --> 01:12:34,920
Michael Akira Lee Hayashi: This person has their own ideological preference, but one of their big donors has a preference somewhere else, and so they vote differently on things within that that that lobbyists domain than they would on other things, current events affecting the bill so.

464
01:12:36,150 --> 01:12:42,450
Michael Akira Lee Hayashi: Something like a rally around the flag effect in the event of a war might substantially to yeah like covert or a war exactly.

465
01:12:42,960 --> 01:12:53,760
Michael Akira Lee Hayashi: Those might substantially change change people's perspectives on a particular issue like people are our legislators tend to get way more hawkish if we get attacked, for example.

466
01:12:55,590 --> 01:13:13,020
Michael Akira Lee Hayashi: What this might also suggest is that maybe people don't have one liberal conservative preference that's monolithic maybe they have slightly different ones, depending on the domain and maybe that is influenced by things like current events or lobbying or all sorts of other factors.

467
01:13:14,070 --> 01:13:18,900
Michael Akira Lee Hayashi: who's in power, right now, who has the Presidency what's going on in Europe.

468
01:13:20,850 --> 01:13:22,740
Michael Akira Lee Hayashi: how's our economy doing, for example.

469
01:13:23,790 --> 01:13:25,710
Michael Akira Lee Hayashi: Those might influence a members.

470
01:13:26,820 --> 01:13:37,110
Michael Akira Lee Hayashi: position on on issues in different domains, you might have some some members of Congress who are very liberal in one domain and very conservative and another one.

471
01:13:39,240 --> 01:13:46,830
Michael Akira Lee Hayashi: If we were to compare American legislators to say European ones German ones, for example, we might find also that.

472
01:13:49,980 --> 01:13:56,550
Michael Akira Lee Hayashi: That our Members are very, very conservative on a lot of issues, relative to say, Members of the European.

473
01:13:57,630 --> 01:14:04,410
Michael Akira Lee Hayashi: Parliament or some legislative body like that and that might change our view of how of what kinds of bills get passed as well.

474
01:14:05,130 --> 01:14:15,000
Michael Akira Lee Hayashi: Are there other things that we might think we'd have to consider if we're trying to build a model of legislative behavior we've got lobbying we've got current events.

475
01:14:25,650 --> 01:14:27,840
Nicolle Krebs: What about like resources like money.

476
01:14:30,090 --> 01:14:33,900
Michael Akira Lee Hayashi: yeah i'm like their campaign war chest can be a thing.

477
01:14:35,610 --> 01:14:37,860
Michael Akira Lee Hayashi: How many lobbyists contribute to them.

478
01:14:41,760 --> 01:14:43,140
Michael Akira Lee Hayashi: Other features.

479
01:14:55,110 --> 01:15:11,580
Michael Akira Lee Hayashi: A person's background and experiences yeah if a person came from a particular like if a person came from a place that had a big steel industry, maybe they're going to be more sympathetic to any bill that is supportive of steel manufacturers than someone who didn't come from that place.

480
01:15:14,670 --> 01:15:24,570
Michael Akira Lee Hayashi: Joe Biden famously loves Amtrak because he rode the train to work every day for a lot of his working life and that influences what policies tend to come out.

481
01:15:27,480 --> 01:15:32,940
Michael Akira Lee Hayashi: somebody comes from an oil rich area might have a strong preference for fossil fuels over renewable energy.

482
01:15:35,460 --> 01:15:39,840
Michael Akira Lee Hayashi: or vice versa, if you come from a place that relies a lot on renewable energy you're gonna have a different take.

483
01:15:44,220 --> 01:15:48,150
Michael Akira Lee Hayashi: I think, at the end of the day, there's there's a lot that can go in here things like.

484
01:15:49,470 --> 01:16:02,160
Michael Akira Lee Hayashi: Are they going to be up for reelection students do they tend to have a fairly safe seat do they have do they live in a competitive district or a competitive state some of those things can also influence, of course, where a person sits on a given policy we might also think that.

485
01:16:02,520 --> 01:16:11,760
Michael Akira Lee Hayashi: Like general liberal conservative and this is not the greatest description of a person's policy preferences, maybe we think that we have the kind of two dimensional spectrum of like.

486
01:16:12,960 --> 01:16:19,950
Michael Akira Lee Hayashi: Economic and social a liberal conservative ness where you have sort of authoritarianism versus.

487
01:16:21,240 --> 01:16:22,950
Michael Akira Lee Hayashi: I forget what the other side of that is.

488
01:16:24,360 --> 01:16:28,020
Michael Akira Lee Hayashi: Radicalism on on the social scale and.

489
01:16:30,120 --> 01:16:34,590
Michael Akira Lee Hayashi: laissez faire versus heavy regulation, on the other, one I might be mixing things up.

490
01:16:35,250 --> 01:16:47,400
Michael Akira Lee Hayashi: But, but essentially a economic or social set of axes where people can fall somewhere in a two dimensional grid and maybe that does a better job of explaining certain policies than a merely one dimensional view.

491
01:16:48,930 --> 01:16:50,160
Michael Akira Lee Hayashi: But all this is to say that.

492
01:16:51,630 --> 01:17:08,610
Michael Akira Lee Hayashi: Even when we start from a simple model for one sometimes we can get some interesting inferences out of the simple model for to it often quickly becomes apparent that the simple model doesn't take into account behavioral factors that are likely to influence someone's decision and sometimes.

493
01:17:10,590 --> 01:17:17,220
Michael Akira Lee Hayashi: Sometimes there'll be those maybe more or less influential in determining whether we've done a good job of modeling a particular decision problem.

494
01:17:19,740 --> 01:17:29,250
Michael Akira Lee Hayashi: one type of one type of sort of behavioral quantification that we might find particularly interesting is the question of quantifying and modeling health outcomes and behaviors.

495
01:17:30,330 --> 01:17:41,880
Michael Akira Lee Hayashi: As as public health actors, we are often we might think of ourselves as preferring improvements in health outcomes in some ways, so when we think about what we like in terms of health policy.

496
01:17:42,390 --> 01:17:57,060
Michael Akira Lee Hayashi: I would wager that for the majority of us, we want to see health policies that we think an expectation, are going to reduce the burden of disease that's going to reduce the magnitude of suffering and death from from disease, to the extent that it is preventable.

497
01:17:59,490 --> 01:18:12,660
Michael Akira Lee Hayashi: And that's all well and good qualitatively, but if we want to try to model ourselves as a as a formal actor, we probably need to do some degree of operationalize of health outcomes themselves, how do we say that.

498
01:18:13,170 --> 01:18:29,790
Michael Akira Lee Hayashi: Reducing deaths by childhood deaths due to diarrhea is good, we could we could look at the number of reductions of cases, but we can we see it, a lot of circumstances that quantifying the value of health outcomes is not straightforward.

499
01:18:30,870 --> 01:18:44,400
Michael Akira Lee Hayashi: let's say let's say code, for example, can we think of issues in using different sorts of health statistics around and coven to describe the burden of disease or the badness of the pandemic at any point, and to communicate those.

500
01:18:54,990 --> 01:18:57,630
Caroline Godfrey: Like cases versus hospitalizations versus death.

501
01:18:58,800 --> 01:19:08,400
Michael Akira Lee Hayashi: yeah cases versus hospitalizations versus debts, a little bit more about that what what features of each measure might lead to different conclusions about different things, or different decision making.

502
01:19:09,360 --> 01:19:11,370
Caroline Godfrey: I mean cases.

503
01:19:12,390 --> 01:19:15,750
Caroline Godfrey: For example, recently there's been.

504
01:19:17,310 --> 01:19:26,820
Caroline Godfrey: A number of peaks in just sheer case numbers, however, as recent strains have been less severe and a larger percentage of the population has been vaccinated.

505
01:19:28,410 --> 01:19:37,230
Caroline Godfrey: The deaths and hospitalizations haven't peaked to the same extent that they have in previous waves, so if you are going just based off of cases.

506
01:19:37,980 --> 01:19:51,090
Caroline Godfrey: You might put the whole country on lockdown again, but if you're going more based off of hospitalizations and deaths, you know things seem more mild and you might keep things a little bit looser in terms of regulations.

507
01:19:52,020 --> 01:19:52,440
Michael Akira Lee Hayashi: yeah.

508
01:19:52,710 --> 01:19:54,390
Michael Akira Lee Hayashi: yeah exactly and that has.

509
01:19:54,480 --> 01:20:01,590
Michael Akira Lee Hayashi: that's that's that's fairly strongly influenced a lot of the recent shifts and decision making and and there's.

510
01:20:02,610 --> 01:20:10,290
Michael Akira Lee Hayashi: That particular debate is perpetually interesting to me there's there's even more in there, because the way that we.

511
01:20:12,330 --> 01:20:25,590
Michael Akira Lee Hayashi: The way that we assess cases hospitalizations and deaths is also somewhat consequential we use hospitalizations and death, so, as you say, as measures of severity of disease, because those are capturing the worst possible outcomes for people but.

512
01:20:28,020 --> 01:20:40,770
Michael Akira Lee Hayashi: Those those things have specific definitions for a person to be hospitalized they need to have an awfully severe case, these days, particularly as sort of the average severity and the treatment modalities have improved for.

513
01:20:41,070 --> 01:20:52,950
Michael Akira Lee Hayashi: For the newer strains and just kind of reflecting are increasing experienced with disease fewer people are dying, overall, because our treatment modalities have improved, in addition to changes in the path of biology of the of the virus itself.

514
01:20:54,030 --> 01:21:02,070
Michael Akira Lee Hayashi: Similarly, fewer people are being hospitalized some of this is likely, a reduction severity of symptoms, some of it is a greater degree of acceptance of living with with.

515
01:21:02,400 --> 01:21:12,000
Michael Akira Lee Hayashi: Disease, some of it is sort of understanding which sorts of presentations are more or less likely to actually endanger person's life so much that they need to go to the hospital.

516
01:21:14,610 --> 01:21:15,060
Michael Akira Lee Hayashi: and

517
01:21:17,940 --> 01:21:18,630
Michael Akira Lee Hayashi: And so.

518
01:21:19,770 --> 01:21:28,590
Michael Akira Lee Hayashi: There are there aspects of the burden of disease that may not be captured by any of those like if we have a lot of cases and not a lot of hospitalizations.

519
01:21:29,010 --> 01:21:39,030
Michael Akira Lee Hayashi: Is the pandemic in a severe face well when we say severe for code we basically mean does it put people in the hospital, as opposed to how miserable does it make them when they get sick and how long do they get sick for.

520
01:21:39,360 --> 01:21:51,630
Michael Akira Lee Hayashi: A person who's out of work for about a week because they're stuck in bed may not be hospitalized, but this is still a fairly large hit to their certainly to their income potentially probably third quality of life as as.

521
01:21:52,740 --> 01:21:57,630
Michael Akira Lee Hayashi: kavita notes, quality of life is is a consideration here.

522
01:22:00,270 --> 01:22:03,720
Michael Akira Lee Hayashi: There can be proud, like like some of the some of the problems here, it could be.

523
01:22:04,020 --> 01:22:16,530
Michael Akira Lee Hayashi: You you lose working hours, if you get sick, even if you're not hospitalized so there could be a fairly substantial economic cost to a given case, even if that case isn't showing up in the hospital or even if that person isn't dying.

524
01:22:17,460 --> 01:22:22,080
Michael Akira Lee Hayashi: There might be changes in quality of life that are positive, as, as you know, like like.

525
01:22:23,070 --> 01:22:33,930
Michael Akira Lee Hayashi: Improving improved working conditions that enable better flexibility and better work life balance, things like that less transit time less money spent on gas so there's there's those sorts of balances as well.

526
01:22:34,410 --> 01:22:47,160
Michael Akira Lee Hayashi: And so, if we're trying to make a decision on how aggressively are we going to institute policies or how aggressively are we going to change policies it's important both to consider what kinds of markers we have out there for.

527
01:22:47,790 --> 01:22:54,240
Michael Akira Lee Hayashi: for making a decision, do we focus on cases hospitalizations deaths, but also what some of the limitations of those markers are.

528
01:22:54,600 --> 01:22:59,970
Michael Akira Lee Hayashi: hospitalizations and deaths are almost certainly indicating severity, but only the worst kind of severity.

529
01:23:00,270 --> 01:23:08,400
Michael Akira Lee Hayashi: and none of these markers are necessarily doing a great job of capturing things like say an economic burden of disease or quality of life burden of disease.

530
01:23:08,790 --> 01:23:12,840
Michael Akira Lee Hayashi: That we might also care about maybe we don't want people to be miserable as much as we can.

531
01:23:13,140 --> 01:23:21,090
Michael Akira Lee Hayashi: Or maybe we're willing to let people be miserable for a certain amount of weeks after getting the disease, as long as we reverting the worst case outcomes.

532
01:23:21,270 --> 01:23:32,640
Michael Akira Lee Hayashi: And where you fall in this tends to determine that tends to be determined by what your perspective is on the goal of public health has an enterprise and the resources available to accomplish those goals.

533
01:23:36,240 --> 01:23:39,720
Michael Akira Lee Hayashi: So i'm going to i'll get more into this once we come back from the break but.

534
01:23:40,770 --> 01:23:54,900
Michael Akira Lee Hayashi: To kind of TEE up what we're going to talk about moving forward i'd encourage you to think about things like when we are going when we sit down to quantify health what are some features of quantifying burden of disease that we think we should care about and.

535
01:23:56,940 --> 01:24:09,990
Michael Akira Lee Hayashi: What are what What should our priorities be when we're trying to make health policy decisions to nominally reduce the burden of disease, so you might think about things like quality of life, economic burden.

536
01:24:11,190 --> 01:24:13,770
Michael Akira Lee Hayashi: Mortality just straight up deaths.

537
01:24:15,990 --> 01:24:23,670
Michael Akira Lee Hayashi: And anything that might contribute their sort of knock on socio political effects if you if you.

538
01:24:25,440 --> 01:24:35,970
Michael Akira Lee Hayashi: I would encourage you to think about some of these things, while we're on break and then, when we come back we'll spend a little bit of time discussing we'll talk about a couple of quantification methods and we'll take a look at the.

539
01:24:37,020 --> 01:24:48,660
Michael Akira Lee Hayashi: global burden of disease study, which is one study that attempts to do quite a lot of quantification of of health states and burden of disease to it's a fascinating thing that's really interesting data.

540
01:24:51,120 --> 01:25:13,980
Michael Akira Lee Hayashi: So I could start talking about something else, but I literally have a minute, so if anyone has a quick question before we break them happy to take that otherwise we can take a 15 minute break and we will resume at 315.

541
01:25:24,810 --> 01:25:27,870
Michael Akira Lee Hayashi: Alright well they're being done let's take a quick break and I will see you shortly.

542
01:25:39,750 --> 01:25:40,440
Michael Akira Lee Hayashi: drawn back.

543
01:25:43,500 --> 01:25:47,640
Michael Akira Lee Hayashi: i'm gonna start my screen share real quick and before we'd spend more time talking about.

544
01:25:49,140 --> 01:25:54,450
Michael Akira Lee Hayashi: Specific measures of health outcomes, I did want to start off with a little bit of a discussion of.

545
01:25:55,350 --> 01:26:10,530
Michael Akira Lee Hayashi: What kinds of things we think we, we should be measuring when we try to quantify health outcomes are and especially when we try to quantify health outcomes to be used for health policy decision maker what sorts of all sorts of factors should we be caring about.

546
01:26:20,370 --> 01:26:22,110
Nicolle Krebs: Like cost effectiveness.

547
01:26:22,650 --> 01:26:25,560
Michael Akira Lee Hayashi: cost effectiveness yeah so nothing's free.

548
01:26:28,380 --> 01:26:34,170
Michael Akira Lee Hayashi: For the moment, i'm going to i'm going to put cost but and also effects best, because these are.

549
01:26:38,970 --> 01:26:41,580
Michael Akira Lee Hayashi: These are often measured together but but are distinct.

550
01:26:41,580 --> 01:26:51,270
Michael Akira Lee Hayashi: constructs so we care about how well an intervention or policy works, how much disease it it diverts but also how expensive it is.

551
01:26:57,780 --> 01:26:58,620
Michael Akira Lee Hayashi: Other features.

552
01:27:02,820 --> 01:27:10,710
Michael Akira Lee Hayashi: Use of local resources that's a good one, yes, and that can that can sometimes speak to practicality, is it something that works well in a.

553
01:27:12,120 --> 01:27:13,950
Michael Akira Lee Hayashi: in a particular area so.

554
01:27:21,990 --> 01:27:23,640
Michael Akira Lee Hayashi: Resources others.

555
01:27:48,690 --> 01:27:56,040
Michael Akira Lee Hayashi: Efficient or optimized usage of existing systems yeah so that sometimes comes along with what can come along with either of these things right.

556
01:27:57,750 --> 01:28:03,750
Michael Akira Lee Hayashi: Are we are we able to exploit things that already exist in order to do something a little bit better.

557
01:28:17,730 --> 01:28:20,460
Nicolle Krebs: Would you model like accessibility or support.

558
01:28:21,300 --> 01:28:25,560
Michael Akira Lee Hayashi: yeah acceptable I didn't support are hugely important so those would definitely be.

559
01:28:28,410 --> 01:28:30,990
Michael Akira Lee Hayashi: going to misspell accessibility, because I don't know how to spell this word.

560
01:28:33,210 --> 01:28:34,320
Michael Akira Lee Hayashi: or support.

561
01:28:37,170 --> 01:28:45,780
Michael Akira Lee Hayashi: yeah policies seldom X in a vacuum and intervention seldom acts in a vacuum and many of them require actual compliance to work so.

562
01:28:46,920 --> 01:28:57,000
Michael Akira Lee Hayashi: Any effective but unacceptable intervention is not going to do so well or an efficient efficacious but not acceptable intervention nation sick.

563
01:28:58,920 --> 01:29:00,810
Michael Akira Lee Hayashi: When Adam here actually so efficacy.

564
01:29:04,740 --> 01:29:10,020
Michael Akira Lee Hayashi: is somewhat distinct from effectiveness, what is the difference between the efficacy and effectiveness.

565
01:29:25,800 --> 01:29:31,680
Michael Akira Lee Hayashi: We often see these terms used sometimes colloquially interchangeably, but they are not quite the same thing.

566
01:29:39,450 --> 01:29:44,280
Michael Akira Lee Hayashi: start with efficacy, what does that usually refer to in a health intervention sense.

567
01:29:48,390 --> 01:29:53,520
Adriana Perez: It man um is better than placebo, for example.

568
01:29:54,750 --> 01:29:58,050
Michael Akira Lee Hayashi: If a treatment or intervention works there's a little more to it.

569
01:29:58,560 --> 01:30:06,990
Michael Akira Lee Hayashi: there's it's if a treatment or intervention works somewhere in a in a in a controlled conditions so efficacy is kind of the optimal.

570
01:30:10,950 --> 01:30:23,070
Michael Akira Lee Hayashi: Impact of the thing evaluation of the population level or the real environment that would be effective so effectiveness is how well something performs when you take it out of the trial out of the clinic.

571
01:30:23,340 --> 01:30:36,210
Michael Akira Lee Hayashi: And and into the real world, so we may have interventions which are very efficacious but not very effective because maybe they're poorly acceptable or maybe they're too expensive for an area to implement sensibly, or maybe.

572
01:30:37,440 --> 01:30:41,280
Michael Akira Lee Hayashi: Maybe that region doesn't have the Labor to be able to implement that intervention.

573
01:30:42,540 --> 01:30:51,750
Michael Akira Lee Hayashi: So when we think about when we think about how good intervention is, we often have to think about both its efficacy and it's likely effectiveness.

574
01:30:58,230 --> 01:31:09,150
Michael Akira Lee Hayashi: What about things about measuring the disease burden itself, like, I can say disease burden till the cows come home, but what does that mean, or what should that mean like what should we care about in order to measure burden disease.

575
01:31:12,750 --> 01:31:16,440
Michael Akira Lee Hayashi: Mortality so death yeah if if something kills a lot of people that's bad.

576
01:31:21,990 --> 01:31:23,190
Michael Akira Lee Hayashi: that's often part of burden of.

577
01:31:23,190 --> 01:31:23,760
disease.

578
01:31:27,240 --> 01:31:28,320
Nicolle Krebs: Like fears love.

579
01:31:29,790 --> 01:31:33,120
Michael Akira Lee Hayashi: Life years last which, which is kind of in the.

580
01:31:34,560 --> 01:31:36,870
Michael Akira Lee Hayashi: I guess that's sort of a full morbidity.

581
01:31:40,560 --> 01:31:42,780
Michael Akira Lee Hayashi: This is kind of getting in the or.

582
01:31:49,470 --> 01:31:59,520
Michael Akira Lee Hayashi: Well, actually, I will I will put this to you when if we care about measuring life years last why, why is that an important thing to quantify.

583
01:32:08,370 --> 01:32:19,290
Caroline Godfrey: I mean, from an economic standpoint that's loss of productivity of those individuals during those years if you're taking out the just human basic desire to live forever.

584
01:32:20,520 --> 01:32:25,470
Michael Akira Lee Hayashi: yeah well and both of those are actually important right like you do get lost productivity and that's not so good.

585
01:32:26,610 --> 01:32:41,370
Michael Akira Lee Hayashi: And maybe we should think that people should be able to live a long time healthily and so if we treat if we treat kind of the good world it has, as our comparison point then life years last from that is not so.

586
01:32:41,370 --> 01:32:52,830
Michael Akira Lee Hayashi: Good so like our considerations here don't necessarily have to be only sort of cold economic ones like we can we can probably should care about things like how miserable or people.

587
01:32:53,760 --> 01:32:59,370
Michael Akira Lee Hayashi: Disability for a very similar reason you probably don't want people to be alive, but miserable for a long time.

588
01:33:02,670 --> 01:33:04,710
Michael Akira Lee Hayashi: In addition to the economic costs.

589
01:33:11,130 --> 01:33:15,450
Michael Akira Lee Hayashi: Both of these together, I mean disability is in.

590
01:33:16,740 --> 01:33:23,010
Michael Akira Lee Hayashi: I think in kind of the quantitative framework oftentimes to be a catch all for like all the different ways that disease makes you less.

591
01:33:24,630 --> 01:33:32,190
Michael Akira Lee Hayashi: Less functional then an optimal baseline more or less is, I think the the rough way to think about that one.

592
01:33:38,400 --> 01:33:45,000
Michael Akira Lee Hayashi: I might propose that we can also think about costs, so we often think about cost from kind of a societal or implement your perspective, like.

593
01:33:46,050 --> 01:33:56,220
Michael Akira Lee Hayashi: How much money, are you costing your employer, if you get sick or how much money, are you costing society if you get sick or how much money do we have to spend on an intervention.

594
01:33:56,490 --> 01:34:07,740
Michael Akira Lee Hayashi: As a say state public health agency or as a federal public health agency, but we can also think about cost from the individual perspective of the person facing a.

595
01:34:09,180 --> 01:34:14,340
Michael Akira Lee Hayashi: facing a health problem to we might care about, for example, that person's lost productivity.

596
01:34:14,760 --> 01:34:30,240
Michael Akira Lee Hayashi: Both impacts their employer, but themselves because that's their income and some people may be more or less able to bear different degrees of loss of income so even the economic considerations, we might extend down to the individual level in order to.

597
01:34:30,750 --> 01:34:32,910
Michael Akira Lee Hayashi: In order to have a broader perspective on.

598
01:34:33,780 --> 01:34:45,300
Michael Akira Lee Hayashi: What do we care about and and we will see sometimes that, depending on the measure that we use we've created like we've come up with a bunch of different things that we should care about sometimes depending on the way that you measure it or.

599
01:34:45,720 --> 01:34:51,780
Michael Akira Lee Hayashi: Who you measure it for you may come to a different conclusion over what decision is optimal so.

600
01:34:52,650 --> 01:35:11,370
Michael Akira Lee Hayashi: An example of clothes that we make see you again in the lecture notes, because I might use something like if they're talking about something else is suppose we think about the cost of a of an illness as being purely a societal cost so lost productivity, if we do that, then let's take.

601
01:35:14,850 --> 01:35:31,740
Michael Akira Lee Hayashi: let's take infectious diseases acquired through daycare so kids in daycare get sick all the time i'm sure anyone here with kids has encountered that delightful phenomenon and and those kids then get their parents sick and and that causes a whole cycle of misery i'm sure.

602
01:35:33,240 --> 01:35:34,020
Michael Akira Lee Hayashi: So.

603
01:35:35,100 --> 01:35:39,780
Michael Akira Lee Hayashi: So, then, that that's that's disease burden at multiple levels, so the.

604
01:35:41,250 --> 01:35:50,130
Michael Akira Lee Hayashi: there's there's certain disease burden incurred on the daycare because you might get an outbreak in the daycare and then you have staff out and you have kids out and your enrollment goes down and that's not so good.

605
01:35:51,660 --> 01:36:01,800
Michael Akira Lee Hayashi: there's economic burden at the level of the families parents might have to miss work to come up with other care arrangements, they might have to lean on other family members things like that there's all kinds of.

606
01:36:02,070 --> 01:36:07,980
Michael Akira Lee Hayashi: stuff there, I mean there's the societal burden of disease, because lost productivity.

607
01:36:08,970 --> 01:36:15,030
Michael Akira Lee Hayashi: And, depending on what we focus on, we might come to different conclusions about where we should perform interventions one particularly kind of.

608
01:36:15,270 --> 01:36:28,290
Michael Akira Lee Hayashi: perverse conclusion that we might come to is suppose we measure the burden of disease from a societal perspective as lost wages, which is very, very common in in monetizing disease outcomes, if we do that.

609
01:36:29,340 --> 01:36:33,330
Michael Akira Lee Hayashi: Who should we, who should we target in order to.

610
01:36:34,500 --> 01:36:39,000
Michael Akira Lee Hayashi: mitigate the highest degree of lost wages what kinds of people.

611
01:36:41,670 --> 01:36:45,870
Michael Akira Lee Hayashi: make this more pointed what economic strata, would we think we should target.

612
01:36:50,280 --> 01:36:54,300
Caroline Godfrey: it's just lost wages, you should be protecting the people who make a ton of money.

613
01:36:54,960 --> 01:36:56,250
Michael Akira Lee Hayashi: yeah yeah.

614
01:36:56,460 --> 01:36:59,040
Michael Akira Lee Hayashi: And that's that's rather awkward right, because we would probably.

615
01:36:59,250 --> 01:37:05,670
Michael Akira Lee Hayashi: We might think that they are okay on that already because they have a ton of money and have better access to healthcare and things like that, but.

616
01:37:06,360 --> 01:37:08,550
Michael Akira Lee Hayashi: But this is, this is a case where.

617
01:37:09,000 --> 01:37:22,950
Michael Akira Lee Hayashi: Our if we pick a particular measure of burden of disease and we follow the rational out through kind of a decision problem of well where should we put our resources in order to mitigate in order to optimize our intervention to our.

618
01:37:23,820 --> 01:37:30,300
Michael Akira Lee Hayashi: Burden metric then we wind up this wacky conclusion that we should probably make sure that billionaires never get sick.

619
01:37:32,580 --> 01:37:39,690
Michael Akira Lee Hayashi: And, and maybe that's uncomfortable I don't think I would find that entirely supportable argument to make from public health perspective but.

620
01:37:39,960 --> 01:37:50,790
Michael Akira Lee Hayashi: But it is the the conclusion of that particular metric so this means that we do have to be somewhat careful when we're making burden of disease style decision arguments.

621
01:37:51,900 --> 01:37:56,430
Michael Akira Lee Hayashi: What we're measuring and and how we think about the implications of that.

622
01:37:57,720 --> 01:38:08,340
Michael Akira Lee Hayashi: So i'm gonna i'm gonna move back for a bit this was good and i'm glad we're we're coming up with all sorts of interesting things about how to quantify burden of disease, because it is a large topic.

623
01:38:10,050 --> 01:38:20,130
Michael Akira Lee Hayashi: So let's talk about one particular framework for the moment to kind of bring things back in so one very common measure of a burden of disease is the disability adjusted life your dally.

624
01:38:21,330 --> 01:38:24,570
Michael Akira Lee Hayashi: And the idea here is to try to come up with a measure, essentially for.

625
01:38:26,280 --> 01:38:27,060
Michael Akira Lee Hayashi: How.

626
01:38:28,740 --> 01:38:35,520
Michael Akira Lee Hayashi: This is more or less the measure of suppose we think a person should live a reasonable pleasant healthy life for a certain amount of time.

627
01:38:36,030 --> 01:38:49,440
Michael Akira Lee Hayashi: anytime that person gets sick or has an adverse health outcome, they are not achieving that potential and the the amount to which they do not achieve that potential is sort of the badness of that health outcome.

628
01:38:50,490 --> 01:38:55,380
Michael Akira Lee Hayashi: So a Deli then represents one healthy life you're lost and then.

629
01:38:55,860 --> 01:39:01,200
Michael Akira Lee Hayashi: With a little bit of abuse of notation, but I have never found a good way to get around that which which exists in the literature.

630
01:39:01,500 --> 01:39:13,470
Michael Akira Lee Hayashi: The sum of delis in a population among all the individuals can be can be calculated as the total number of life years last plus the number of years, lost effectively due to disability so.

631
01:39:13,860 --> 01:39:27,030
Michael Akira Lee Hayashi: How many years earlier people dying relative to when we think they should be dying plus how many effective years of their life are they losing to being miserable in one form or another.

632
01:39:28,200 --> 01:39:45,930
Michael Akira Lee Hayashi: So years of life loss, then, is just the number of absolute deaths due to disease times the average remaining life expectancy at the age of death due to disease, so if you expect to live to 80 and you die at 60, then you contribute 20 years of life last.

633
01:39:48,060 --> 01:39:58,320
Michael Akira Lee Hayashi: This, this is a little wacky because the the expected age comes from life tables calculated for different populations, so I think it is possible and I haven't interrogated this.

634
01:39:58,710 --> 01:40:09,210
Michael Akira Lee Hayashi: A whole ton I think it's actually possible these life tables kind of bias years of life lost in in in a negative way if you're looking at a population who an expectation doesn't live very long, to begin with.

635
01:40:09,840 --> 01:40:17,160
Michael Akira Lee Hayashi: Because presumably of of the prevalence of adverse health outcomes in that population, so I do not know the degree to which.

636
01:40:18,030 --> 01:40:25,860
Michael Akira Lee Hayashi: delhi's account for for this kind of phenomenon and if anyone does i'd be really interested to hear about this this came up in another one of my classes, too.

637
01:40:26,100 --> 01:40:33,930
Michael Akira Lee Hayashi: And I didn't have a good answer them and, unfortunately, I still don't know so if anyone knows how life tables do or do not account for kind of.

638
01:40:35,580 --> 01:40:36,060
Michael Akira Lee Hayashi: The.

639
01:40:37,140 --> 01:40:39,750
Michael Akira Lee Hayashi: extrinsic variance in.

640
01:40:40,890 --> 01:40:45,600
Michael Akira Lee Hayashi: Well, actually potentially endogenous variants in lifespan I would love to hear.

641
01:40:51,300 --> 01:40:54,300
Michael Akira Lee Hayashi: Like it seems to me that there's potentially a chicken or egg problem here.

642
01:40:57,420 --> 01:41:06,030
Michael Akira Lee Hayashi: At any rate, years of years of life loss to do due to disability is kind of a similar thing, the idea is that for a given person if they.

643
01:41:06,630 --> 01:41:24,990
Michael Akira Lee Hayashi: undergo certain health conditions suppose I get cholera, then there is a table somewhere that the global burden of disease study has calculated that says on, on balance, how close to being dead is is having cholera and that that factor is essentially.

644
01:41:26,370 --> 01:41:39,810
Michael Akira Lee Hayashi: How much my time spent with that health condition contributes to my dollies So if I have a really serious health condition that that like if I if I get I don't know fully paralyzed then.

645
01:41:40,470 --> 01:41:53,370
Michael Akira Lee Hayashi: paralyzed my brain is already trying to talk about parallel ization if I if I get paralyzed completely then presumably this is pretty close to being dead from the for the purpose of disability waves and so each year that i'm paralyzed.

646
01:41:54,750 --> 01:42:06,480
Michael Akira Lee Hayashi: contributes close to a year of life loss to to my doubts, so what we're trying to do is take into account both the severity and the incidence of disease so.

647
01:42:06,780 --> 01:42:19,350
Michael Akira Lee Hayashi: Even a disease that's not stupendously severe might contribute decent dollies because it's really widespread so coven probably, it is a disease that has a relatively high dally because, even if it's.

648
01:42:19,980 --> 01:42:35,670
Michael Akira Lee Hayashi: Disability waiting and an actual mortality is on the lower end higher earlier on lower now there's just so much of it, the incidence is so incredibly high that we add up a bunch of things here so we're trying to capture both aspects.

649
01:42:38,220 --> 01:42:51,390
Michael Akira Lee Hayashi: This link is a little bit out of date, but if you look on canvas have posted links to the 2019 version of the global burden of disease study i'm going to take a bit of time for us to look at it, because this is a really fascinating thing it's a it's a.

650
01:42:54,090 --> 01:43:01,470
Michael Akira Lee Hayashi: it's just an awfully cool study that I forget what hmm he stands for Institute for some.

651
01:43:02,220 --> 01:43:10,200
Michael Akira Lee Hayashi: classically they haven't put their Institute for Health metrics and evaluation at the University of Washington, so they conduct this study every few years.

652
01:43:10,470 --> 01:43:27,150
Michael Akira Lee Hayashi: Essentially, to update those disability weights that give us the try to get a sense for how bad our specific health conditions and how much do they contribute to dollies for any given thing there's these there's also they publish this cool visualization.

653
01:43:28,260 --> 01:43:28,530
Michael Akira Lee Hayashi: Of.

654
01:43:29,820 --> 01:43:33,660
Michael Akira Lee Hayashi: Of what things globally contribute the most to.

655
01:43:35,430 --> 01:43:52,110
Michael Akira Lee Hayashi: To burden of disease worldwide so worldwide so heart disease and stroke neonatal diseases diarrhea still up there if we looked at, we looked at younger ages i'd wager diarrhea is yeah neonatal diarrhea malaria gentle.

656
01:43:55,320 --> 01:44:05,880
Michael Akira Lee Hayashi: This is finally I could I could spend a long time, exploring this thing because you can look at you can look at all sorts of types of causes, you can look at what sorts of things are particularly high in different places of the world.

657
01:44:06,930 --> 01:44:11,190
Michael Akira Lee Hayashi: This link is on canvas and i'd strongly recommend you look at it, because it is just fascinating.

658
01:44:12,570 --> 01:44:18,540
Michael Akira Lee Hayashi: False when people die from falling guess you know this this probably has an interesting waiting because.

659
01:44:19,230 --> 01:44:31,860
Michael Akira Lee Hayashi: Like i'd wager that most false are fairly non severe and some are really severe and that's contributing there I bet this one's actually quite interesting on it like location adjusted folks i'd like to know who has the most from Finland.

660
01:44:34,380 --> 01:44:35,370
Michael Akira Lee Hayashi: really bad for the elderly.

661
01:44:36,360 --> 01:44:38,370
Caroline Godfrey: sinners who fall and die.

662
01:44:38,850 --> 01:44:40,710
Caroline Godfrey: old people on blood thinners who fall and die.

663
01:44:41,190 --> 01:44:42,420
Caroline Godfrey: Yes, it is.

664
01:44:42,930 --> 01:44:44,160
Michael Akira Lee Hayashi: yeah that.

665
01:44:44,910 --> 01:44:58,110
Michael Akira Lee Hayashi: Apparently, of which there are a lot of movement, Finland is what we can take away from this, which is interesting, I suppose the Nordic countries actually pretty high life expectancy, so we might expect to see things that afflict the elderly, a little bit more there.

666
01:44:59,520 --> 01:45:03,960
Michael Akira Lee Hayashi: Maybe there's a lot of people falling off of the glaciers, and things up there, too, I don't know that's.

667
01:45:05,730 --> 01:45:09,420
Michael Akira Lee Hayashi: I if someone wants to tell me why Finland has been commonly high rate of fall.

668
01:45:10,740 --> 01:45:12,030
Michael Akira Lee Hayashi: fall delis i'd love to know.

669
01:45:14,010 --> 01:45:23,700
Michael Akira Lee Hayashi: More over if you want to see the actual data files, like the tables, you can download these on i've also posted the link to the to the downloads page for this.

670
01:45:23,970 --> 01:45:31,950
Michael Akira Lee Hayashi: And this doesn't just have the big dally table for all the things this also has a huge number of other estimates like air pollution exposure.

671
01:45:33,480 --> 01:45:37,530
Michael Akira Lee Hayashi: Well i've got fatal police violence, it unfortunately pressing one.

672
01:45:39,120 --> 01:45:43,980
Michael Akira Lee Hayashi: we've got some like smoking related behaviors there are some other categories that I thought were quite interesting.

673
01:45:44,610 --> 01:45:54,180
Michael Akira Lee Hayashi: There are also the LIFE tables so life expectancy and healthy life expectancy me to download one of these, and we can take a look at it, because i'd wager this is going to be quite interesting.

674
01:45:56,340 --> 01:46:01,290
Michael Akira Lee Hayashi: Where did I put it, life expectancy and healthy life expectancy reference tables probably what we want.

675
01:46:02,310 --> 01:46:04,560
Michael Akira Lee Hayashi: we're gonna see if this loads and any kind of sensible format.

676
01:46:09,840 --> 01:46:10,890
Michael Akira Lee Hayashi: Oh okay.

677
01:46:14,190 --> 01:46:21,210
Michael Akira Lee Hayashi: I suppose this answers my question about this city or complexity of this apparently this things that people live to about 88.

678
01:46:22,410 --> 01:46:35,880
Michael Akira Lee Hayashi: seems long for a human like that seems like like very specific countries but maybe maybe what this is is sort of a an optimistic, life expectancy like we think people should live this long as opposed to.

679
01:46:36,300 --> 01:46:43,080
Michael Akira Lee Hayashi: characterizing life expectancy for different areas which might get around the the potential issue, I was concerned with previously.

680
01:46:45,000 --> 01:46:54,630
Michael Akira Lee Hayashi: notice that this life table does also include a certain amount of like it accounts for a certain degree of survivorship effects so like.

681
01:46:55,710 --> 01:47:05,910
Michael Akira Lee Hayashi: If you notice that people who are 8590 and 95 still have what we might consider to be a surprising number of years left in them and i'd wager that this is because if you make it to 85.

682
01:47:06,120 --> 01:47:16,830
Michael Akira Lee Hayashi: Then you're probably pretty healthy and so you're reasonably likely then to continue living as opposed to like if you're zero then you're just kind of going off of regular newborn people.

683
01:47:17,430 --> 01:47:32,250
Michael Akira Lee Hayashi: Similarly, like 95 year olds if you've managed to make it 90 to 95 you're probably doing pretty OK so that's kind of an interesting feature of these estimates going to also pull up the big actual.

684
01:47:33,990 --> 01:47:50,190
Michael Akira Lee Hayashi: The global burden of disease tables, because it can be helpful to see or the disability adjusted weights table, I found it earlier here, it is because this one is also phenomenal as a reference.

685
01:47:51,480 --> 01:47:58,770
Michael Akira Lee Hayashi: If you if you want to do a study of your own that tries to quantify burden of disease forgiven things suppose you want to do a transmission modeling study, for example.

686
01:47:59,040 --> 01:48:16,110
Michael Akira Lee Hayashi: And then you want to estimate the burden of disease from infections in that model Well, this is a great reference for that you can go and look for whatever disease you're looking for HIV these in some cases are cicala or co infections tuberculosis.

687
01:48:17,250 --> 01:48:18,330
Michael Akira Lee Hayashi: Early HIV.

688
01:48:20,010 --> 01:48:33,240
Michael Akira Lee Hayashi: There is almost everything under the sun in here it's just delightfully thorough moderate hearing loss with ringing due to meningitis, like you, can you can get really specific stuff out of here apparently that's not considered to be terribly bad.

689
01:48:36,750 --> 01:48:41,730
Michael Akira Lee Hayashi: Although some of the bigger ones can, and you can see, the scale of some of these things so like like that.

690
01:48:42,390 --> 01:48:53,850
Michael Akira Lee Hayashi: mild hearing loss due to meningitis, not very bad where i'd wager like some of the HIV sequel involving tuberculosis or really bad drug susceptible tuberculosis without India with HIV.

691
01:48:55,020 --> 01:48:57,240
Michael Akira Lee Hayashi: pretty bad so a higher disability weight.

692
01:48:59,670 --> 01:48:59,970
Michael Akira Lee Hayashi: That.

693
01:49:01,290 --> 01:49:12,750
Michael Akira Lee Hayashi: likely has a fairly high fatality rate to stage five chronic kidney disease very severe, generally speaking, these weights go from zero to one where one is dead and zero is fine.

694
01:49:13,740 --> 01:49:21,480
Michael Akira Lee Hayashi: So that's more or less how to read these things, but I strongly recommend keeping this kind of in your back pocket as a resource, because it can.

695
01:49:22,020 --> 01:49:29,670
Michael Akira Lee Hayashi: It can give a really interesting perspective to a transmission modeling study or any kind of infectious disease study really to go from just.

696
01:49:29,970 --> 01:49:41,700
Michael Akira Lee Hayashi: Well i've modeled the number of cases that we should expect to and here's the expected burden of disease for these simulated cases and sometimes that gives your work a little bit of extra shine that can differentiate it from.

697
01:49:42,030 --> 01:49:53,070
Michael Akira Lee Hayashi: other kinds of modeling exercises this kind of stuff I think is also fairly common in chronic disease work like I i'd wager that our tobacco folks and other sort of chronic disease related folks are familiar with a lot of these things.

698
01:49:53,640 --> 01:50:04,290
Michael Akira Lee Hayashi: I think it's To be honest, it was a little newer to me as an infectious disease person, because I come from a little bit more of a line of just focusing on incidents and prevalence more cases bad.

699
01:50:05,970 --> 01:50:15,180
Michael Akira Lee Hayashi: So, again i'd strongly encourage you to explore this stuff just because it's incredibly fascinating and and a good resource to have in your back pocket.

700
01:50:17,730 --> 01:50:20,970
Michael Akira Lee Hayashi: Any other thoughts or questions on the subject of.

701
01:50:22,800 --> 01:50:26,940
Michael Akira Lee Hayashi: Well dollies and some of the particular burden of disease stuff that we've seen up to now.

702
01:50:45,000 --> 01:50:53,700
Michael Akira Lee Hayashi: Alright um let's start looking at a couple of other aspects of of disease burden analysis and a little bit of cost effectiveness so.

703
01:50:54,180 --> 01:51:12,210
Michael Akira Lee Hayashi: We might we might also want to come at the kind of the health impact framework from the other side, so instead of thinking of how much does it disease take away from you, maybe we want to think about this in terms of how much does an intervention give you.

704
01:51:13,710 --> 01:51:17,940
Michael Akira Lee Hayashi: So another metric we could use as a quality or quality adjusted life here.

705
01:51:18,510 --> 01:51:32,190
Michael Akira Lee Hayashi: Where we're basically doing an opposite doubt right if we think that on average you're going to die due to disease at age 40 because I don't know you live in England in the year 10 hundred, and you know there's playing everywhere.

706
01:51:33,510 --> 01:51:38,760
Michael Akira Lee Hayashi: If there were some intervention like if there were antibiotics available, how many years of life with that fight.

707
01:51:40,320 --> 01:51:52,140
Michael Akira Lee Hayashi: And, and we can calculate qualities and more or less than analogous way to a daily right you sum up the number of life years gained do you do an intervention and then do that across your population of interest or studied population of interest.

708
01:51:56,490 --> 01:52:07,950
Michael Akira Lee Hayashi: Often these sorts of metrics dahlias qualities, what have you are used to perform cost effectiveness analysis which we've which we have talked a little bit about the idea of being.

709
01:52:09,360 --> 01:52:15,480
Michael Akira Lee Hayashi: setters pair of US we'd really like a good intervention, one that substantially reduce the burden of disease but.

710
01:52:16,260 --> 01:52:28,290
Michael Akira Lee Hayashi: The reality is that interventions cost money and the extra reality is that in the United States, these days, the the office of management and budget has a really tight stranglehold over.

711
01:52:29,310 --> 01:52:39,030
Michael Akira Lee Hayashi: over health intervention policy and tends to demand cost effectiveness analysis in a lot of circumstances or or it is, it is a component of a lot of.

712
01:52:40,260 --> 01:52:48,480
Michael Akira Lee Hayashi: A lot of policy making these days I can't remember if it's still like a hyper explicit, but in the.

713
01:52:49,530 --> 01:52:59,040
Michael Akira Lee Hayashi: In the Bush to Presidency the omb started to roll out changes to their guidelines, such that proposed federal regulation made by executive agencies.

714
01:52:59,430 --> 01:53:09,900
Michael Akira Lee Hayashi: had to provide some kind of cost impact analysis and, subsequently, I believe the omb is walk that back a little bit to say cost impact cost benefit analysis.

715
01:53:10,530 --> 01:53:21,570
Michael Akira Lee Hayashi: should be part of the analysis of the impact of a regulation, but does not have to be the only one, but in practice I believe the omb does still fairly heavily weighted.

716
01:53:21,780 --> 01:53:28,770
Michael Akira Lee Hayashi: I think we might have someone from ttp here if anyone if anyone knows for sure what the current state of wrangling with omb is i'd also love to hear that.

717
01:53:31,470 --> 01:53:35,130
Michael Akira Lee Hayashi: I like administrative politics, so I never get tired of hearing about that.

718
01:53:42,030 --> 01:53:43,860
Michael Akira Lee Hayashi: But the other side of it is that.

719
01:53:46,560 --> 01:53:47,460
Michael Akira Lee Hayashi: It is often.

720
01:53:48,570 --> 01:53:54,960
Michael Akira Lee Hayashi: It often is part of your justification for an intervention to be like hey it doesn't only work it's also cost effective so.

721
01:53:55,320 --> 01:54:05,160
Michael Akira Lee Hayashi: You can kind of like if you're trying to sell your intervention to a policymaker that has limited resources or the past to do a lot of budgetary considerations, then being able to demonstrate that.

722
01:54:05,430 --> 01:54:24,150
Michael Akira Lee Hayashi: you're spending money efficiently is often part of making your case whether you know whether we think that's ideal or not, as a separate question, but that is that's that's what we've got so one measure of of cost effectiveness is the incremental cost effectiveness ratio or a Sir.

723
01:54:25,530 --> 01:54:31,500
Michael Akira Lee Hayashi: And all we're doing here is we're taking the cost of our intervention compared to the cost of our baseline scenario or control group.

724
01:54:32,070 --> 01:54:40,080
Michael Akira Lee Hayashi: And then dividing that by the difference in qualities between the intervention and control group, the reason we're using qualities here is that.

725
01:54:40,920 --> 01:54:49,140
Michael Akira Lee Hayashi: Provided your intervention works, you should get a positive difference so quality is for the intervention should be bigger than qualities under the baseline case.

726
01:54:51,480 --> 01:55:00,090
Michael Akira Lee Hayashi: You could use you could come up with a measure using using galleys where you kind of switch these things you probably do like dollies under the baseline case minus valleys under the.

727
01:55:00,450 --> 01:55:03,000
Michael Akira Lee Hayashi: Intervention case or something of that sort, to try to.

728
01:55:03,960 --> 01:55:18,930
Michael Akira Lee Hayashi: Try to reframe this around disease burden diverted I don't think it makes an enormous difference unless, for whatever reason, your estimation of qualities and valleys for particular health problem are done in substantially different ways, which could have.

729
01:55:23,460 --> 01:55:32,400
Michael Akira Lee Hayashi: One thing to keep in mind about ISIS and ratio measures in general is that there are measures that are kind of multiple roads to Rome measures so.

730
01:55:32,910 --> 01:55:41,550
Michael Akira Lee Hayashi: In order to get a big Iser, which is what we are sorry, in order to get a small leiser, which is what we want there's a couple ways we could do that.

731
01:55:43,020 --> 01:55:49,080
Michael Akira Lee Hayashi: If you had a really expensive and extremely effective intervention that would be good.

732
01:55:50,100 --> 01:55:55,890
Michael Akira Lee Hayashi: But that could also be considered equally as good as a really, really cheap and hardly effective intervention.

733
01:55:56,610 --> 01:56:12,210
Michael Akira Lee Hayashi: So, like more or less any combination of the numerator and denominator that yields the same ice or is going to be seen as equally good from the perspective of ice and so when we evaluate cost effectiveness We may want to be a hair careful about like.

734
01:56:13,440 --> 01:56:16,410
Michael Akira Lee Hayashi: If someone tells me oh i've got this incredibly efficient intervention.

735
01:56:18,150 --> 01:56:20,190
Michael Akira Lee Hayashi: It costs pennies and does almost nothing.

736
01:56:20,610 --> 01:56:30,810
Michael Akira Lee Hayashi: Do I care about that well probably not because the absolute health benefit is miniscule, on the other hand it doesn't do anything bad and it is very cheap so maybe somethings better than nothing.

737
01:56:31,140 --> 01:56:40,920
Michael Akira Lee Hayashi: But it is worth keeping in mind that there is not one single class of intervention success case that will yield a good eyesight.

738
01:56:43,800 --> 01:56:54,930
Michael Akira Lee Hayashi: And again, this goes for pretty much any ratio measure if you're using a ratio measure to estimate burden of disease any particular outcome in a study or conducting you want to be a little bit careful and you interpret it to make sure that.

739
01:56:55,410 --> 01:57:01,920
Michael Akira Lee Hayashi: You haven't gotten a good value with an awkward combination of numerator and denominator, because that absolutely can happen.

740
01:57:05,310 --> 01:57:05,790
Michael Akira Lee Hayashi: So.

741
01:57:07,380 --> 01:57:09,060
Michael Akira Lee Hayashi: i'll pause at this point and.

742
01:57:10,500 --> 01:57:14,940
Michael Akira Lee Hayashi: Now that we've seen a couple of quantitative ways to measure disease burden.

743
01:57:15,210 --> 01:57:24,660
Michael Akira Lee Hayashi: What do we think about that, what do we think about using a kind of like disability adjusted life you're a dahlia equality framework or a cost effectiveness framework in order to make.

744
01:57:24,900 --> 01:57:37,650
Michael Akira Lee Hayashi: Health policy decisions, what are good uses of that and bad ones, or what are what are ways that we might worry about in or what are the things we might worry about when we're trying to do that process.

745
01:57:48,600 --> 01:57:59,820
Nicolle Krebs: You may want to wear as like the qualities of the delis are like equally distributed across the whole population, and not just like one subgroup benefiting versus another.

746
01:58:01,290 --> 01:58:08,190
Michael Akira Lee Hayashi: yeah that's a really good point um delis callie's ice there's a lot of these things if you're calculating the population level.

747
01:58:09,540 --> 01:58:11,460
Michael Akira Lee Hayashi: They don't care about who things are happening to.

748
01:58:13,230 --> 01:58:13,740
Michael Akira Lee Hayashi: and

749
01:58:14,820 --> 01:58:25,170
Michael Akira Lee Hayashi: And again, because of the nature of arithmetic more or less if you had a really, really big impact in a small part of the population, you might still get an apparently good looking.

750
01:58:26,550 --> 01:58:38,940
Michael Akira Lee Hayashi: disease burden result or intervention success results, just because big number is bigger than small number right or big number times small number is is is still a decent sized number right and that's the thing.

751
01:58:40,200 --> 01:58:50,190
Michael Akira Lee Hayashi: yeah minority populations and really, really small but highly impacted by certain diseases yeah the other, the other side of this works to where maybe it's good that.

752
01:58:50,700 --> 01:58:59,100
Michael Akira Lee Hayashi: A very small portion of the population does a whole ton better because the alternative cases they do a whole lot worse so.

753
01:58:59,940 --> 01:59:09,750
Michael Akira Lee Hayashi: So yeah in all of this, we want to be thinking carefully about who is getting the benefit of the intervention and are they the people that we want to be targeting for the benefit of the intervention it's the.

754
01:59:10,890 --> 01:59:17,070
Michael Akira Lee Hayashi: it's the billionaire daycare problem again in some sense like do billionaires need the most sanitary daycares in the entire world.

755
01:59:18,180 --> 01:59:27,480
Michael Akira Lee Hayashi: Maybe but but maybe that's not the population that we're actually trying to target and maybe that's not the population that suffers the worst outcomes of disease.

756
01:59:28,920 --> 01:59:42,780
Michael Akira Lee Hayashi: So that certainly is a factor and that often leads us to doing things like stratification to make sure that we're adjusting our our results by kind of the amount that we worry about a population, it can it leads to measures like.

757
01:59:44,160 --> 01:59:51,210
Michael Akira Lee Hayashi: Like the CDC calculates the thing called the social vulnerability index for different localities and this major tries to quantify.

758
01:59:51,540 --> 02:00:03,150
Michael Akira Lee Hayashi: How disproportionately likely is a given area to suffer adverse health events on the basis of more or less associated demographic profile compared to other regions in its domain so like in Michigan.

759
02:00:05,880 --> 02:00:20,400
Michael Akira Lee Hayashi: Each county and each census tract has a social vulnerability index associated with it, that gives an indication of like what's the combination of like educational attainment access to health care income.

760
02:00:21,450 --> 02:00:39,360
Michael Akira Lee Hayashi: Unemployment all sorts of other things, to give an idea for how vulnerable or people in those localities to particular health problems if you had to hazard a guess where in Michigan if you if you're a michigander do you think we would likely see high social vulnerability.

761
02:00:42,630 --> 02:00:45,120
Michael Akira Lee Hayashi: This is not a trick question in any way, unfortunately.

762
02:01:10,950 --> 02:01:26,490
Michael Akira Lee Hayashi: what's the first place that come to my comes to mind if we think of like economic problems in Detroit or health problems in Detroit or in Michigan I can't even do this without giving it away it's Detroit it is Detroit and flint and and a lot of those surrounding areas and then specifically.

763
02:01:27,930 --> 02:01:29,850
Michael Akira Lee Hayashi: Detroit city like flint.

764
02:01:31,260 --> 02:01:42,510
Michael Akira Lee Hayashi: For for reasons that I think are not terribly surprising from any kind of like historical and demographic perspective but, but that is to say also that measures like social vulnerability will capture factors factors like that, like the fact that.

765
02:01:44,190 --> 02:02:02,790
Michael Akira Lee Hayashi: Detroit has an uncommon we like it's big for one it has a really large poor unemployed homeless population if you can come up with socio demographic factors that are that are a problem for health outcomes Detroit probably has a lot of them.

766
02:02:04,260 --> 02:02:13,470
Michael Akira Lee Hayashi: And so you see that collection of things included in calculations of social vulnerability X and so things like that can be used to try to get toward this notion of things like like.

767
02:02:14,460 --> 02:02:23,610
Michael Akira Lee Hayashi: Like local differences geography local differences in those actual health outcomes to try to adjust our answers, so that we don't just say like this.

768
02:02:24,210 --> 02:02:35,430
Michael Akira Lee Hayashi: This place is off over here and inexplicably bad, but we're not going to worry about substance because because kind of bulk population averaging can lead us to do that and that's not so great.

769
02:02:37,860 --> 02:02:40,290
Michael Akira Lee Hayashi: And sometimes even like the relative.

770
02:02:41,430 --> 02:02:49,320
Michael Akira Lee Hayashi: The relative vulnerability of a particular location or a particular population compared to other ones nearby it can matter as well.

771
02:02:50,490 --> 02:02:56,100
Michael Akira Lee Hayashi: So so yeah we've we've brought up a lot of sort of like distributional.

772
02:02:56,490 --> 02:03:07,710
Michael Akira Lee Hayashi: problems that could arise if we if we use burden of disease measures in kind of a naive population wide way and I think it's i'm glad that we're thinking about these sorts of things because he's come up a whole ton.

773
02:03:11,490 --> 02:03:24,990
Michael Akira Lee Hayashi: Fortunately, Detroit has a well Detroit for a while had also one of the lowest covert vaccination rates in the state which was equally bad and you also tend to see things like code vaccination falling along them.

774
02:03:26,730 --> 02:03:40,680
Michael Akira Lee Hayashi: fairly fairly traditional socio demographic geographic lines like poor neighborhoods in Chicago had low vaccination rates things like that phenomenally black neighborhoods tended to have still tend to have fairly poor vaccination rates.

775
02:03:41,880 --> 02:03:48,000
Michael Akira Lee Hayashi: So you get a lot of you can see visually a lot of the influence of those those health disparities, when you.

776
02:03:49,590 --> 02:03:51,300
Michael Akira Lee Hayashi: When you take a more local view.

777
02:03:54,660 --> 02:03:57,570
Michael Akira Lee Hayashi: um any other any other stray thoughts about.

778
02:03:58,680 --> 02:04:13,290
Michael Akira Lee Hayashi: Conducting studies that use things like burden of disease as metrics or or again to kind of bring this into the decision theory framework if we want to think like people trying to make health decisions or trying to model health decisions.

779
02:04:15,300 --> 02:04:30,450
Michael Akira Lee Hayashi: How do we, how can we come at it from kind of burden of disease frameworks, or how can we use those to inform things like the utility functions, we build or the the choices available to policymakers or or the choices we might advocate policymakers make.

780
02:04:56,010 --> 02:04:59,760
Michael Akira Lee Hayashi: I know it's mid afternoon everyone's tired in a going to be on my like.

781
02:05:02,220 --> 02:05:06,990
Michael Akira Lee Hayashi: Subsequent cup of coffee after after this so I can stay awake for the evening.

782
02:05:09,360 --> 02:05:17,100
Michael Akira Lee Hayashi: Well, all um I will suggest that one of the things that's actually quite important here is to think about.

783
02:05:18,390 --> 02:05:25,140
Michael Akira Lee Hayashi: What the audience that you're what audiences in different domains care about so if you're trying to influence a.

784
02:05:25,770 --> 02:05:37,200
Michael Akira Lee Hayashi: Health policy maker, to make a particular choice to implement a particular intervention that that maybe you think works really well it's important to think about what they consider to be important.

785
02:05:38,130 --> 02:05:41,400
Michael Akira Lee Hayashi: So if we're talking about like the CDC or a local health department.

786
02:05:42,390 --> 02:05:52,020
Michael Akira Lee Hayashi: Understanding their priorities are important because that can help you tailor what metrics you use in order to make your arguments, so this, this is also part of.

787
02:05:52,620 --> 02:06:04,560
Michael Akira Lee Hayashi: I tend to think that decision theory as a as a topic to kind of bring this back around there is useful for a few things one is just as a modeling exercise to understand how different actors make their choices and how we.

788
02:06:05,010 --> 02:06:14,430
Michael Akira Lee Hayashi: How we arrive at health policy choices or or behavioral choices in the population that lead to health consequences, the other is this kind of Meta cognitive thing of.

789
02:06:15,930 --> 02:06:29,100
Michael Akira Lee Hayashi: Trying to understand the audiences, with whom you may find yourself working so if you're trying to convince a policymaker you're not going to do it by showing them metrics that they don't care about if you're trying to convince.

790
02:06:29,940 --> 02:06:34,920
Michael Akira Lee Hayashi: A business to do something, then you probably want to show them a metric that.

791
02:06:36,600 --> 02:06:39,720
Michael Akira Lee Hayashi: That gets it their bottom line, are they saving money.

792
02:06:41,100 --> 02:06:53,370
Michael Akira Lee Hayashi: Where if you're talking to a Community advocate, then you want to be giving the metrics that indicate how the intervention will reduce the burden of disease for their Community right so.

793
02:06:54,750 --> 02:07:08,820
Michael Akira Lee Hayashi: We can we can use some of the decision theoretic framework, coupled with ideas of how to quantify different health outcomes to be able to tailor our health, communication and our presentation of of results or presentation of.

794
02:07:10,260 --> 02:07:26,130
Michael Akira Lee Hayashi: Our of our of advocacy, to the extent that we do that, to audiences in ways that will make them more likely to resonate a corporation, is a very different beast from a local health department and they they think about their incentive structure very differently.

795
02:07:29,220 --> 02:07:40,890
Michael Akira Lee Hayashi: I think I think it's often it's often fairly tempting in public health to think about adversarial actors as working in kind of mysterious ways like Why would.

796
02:07:41,610 --> 02:07:52,290
Michael Akira Lee Hayashi: Why would a company do something that so manifestly bad for people, or why, why would someone act in ways that so clearly contrary to their to the preservation of their health and.

797
02:07:53,400 --> 02:07:56,400
Michael Akira Lee Hayashi: To a certain extent, I think that perspective can sometimes be.

798
02:07:57,510 --> 02:07:59,700
Michael Akira Lee Hayashi: stymieing or unhelpful because.

799
02:08:01,410 --> 02:08:08,070
Michael Akira Lee Hayashi: If we assume that there is a reason that people make their decisions, and we can analyze the decision making calculus that underlies that.

800
02:08:08,430 --> 02:08:18,330
Michael Akira Lee Hayashi: We can figure out if there are levers to pull to try to gain traction on that, knowing that businesses tend to be profit motivated means that if we want to get them to do something.

801
02:08:18,750 --> 02:08:26,190
Michael Akira Lee Hayashi: we'd better be prepared to convince them that their bottom line will be positively impacted by the thing that we want them to do under some timescale.

802
02:08:27,540 --> 02:08:27,930
Michael Akira Lee Hayashi: and

803
02:08:29,100 --> 02:08:45,960
Michael Akira Lee Hayashi: And we got to a certain extent, sometimes we have to accept the particular game that an actor is playing because there's no sense, trying to convince an actor using you know, using things that they don't care about that don't play into their utility function at all.

804
02:08:51,270 --> 02:08:53,550
Michael Akira Lee Hayashi: To come back then to a little bit more of the formal framework.

805
02:08:54,150 --> 02:09:03,240
Michael Akira Lee Hayashi: It turns out that we don't know what happens when we make choices and and often we have to act under uncertainty almost always, in fact, when I go to the grocery store I don't know what bananas they're going to have.

806
02:09:03,660 --> 02:09:11,580
Michael Akira Lee Hayashi: I hope that they're going to have the weird small bananas, that I like but they might not and I still go to the grocery store with the expectation of buying bananas.

807
02:09:12,750 --> 02:09:25,200
Michael Akira Lee Hayashi: What this What this means, and the decision theoretic framework is that problem I noted earlier, where an action might not map uniquely to a single outcome, so if I go to the grocery store to buy bananas, does that mean that I will always buy.

808
02:09:25,620 --> 02:09:31,950
Michael Akira Lee Hayashi: That one particular type of small banana know it might mean that I buy one of the number of types of bananas at the store.

809
02:09:33,210 --> 02:09:40,560
Michael Akira Lee Hayashi: So how do we deal with that in the decision theoretic framework well fortunately a in a fairly straightforward way.

810
02:09:41,700 --> 02:09:43,110
Michael Akira Lee Hayashi: let's suppose that.

811
02:09:44,220 --> 02:09:58,800
Michael Akira Lee Hayashi: We have a we have a model where choices can map to multiple types of outcomes we're just going to say that there's some set are of possible results that map to every choice that a person could make that for every X there's some set are of possible results.

812
02:10:00,840 --> 02:10:11,790
Michael Akira Lee Hayashi: And let's suppose also that there's some probability distribution over the results in the set of possible results that tells us the chance of getting one of those results, based on our choice so.

813
02:10:12,210 --> 02:10:26,100
Michael Akira Lee Hayashi: If my choices go to the grocery store to buy bananas there's some probability that I will buy the bananas, I want the the Madonna bananas, a cavendish banana plantation or maybe there's a chance they'll make a mistake and buy the small bananas, that I don't.

814
02:10:28,020 --> 02:10:37,020
Michael Akira Lee Hayashi: Then we can still work from the utility framework, because we can calculate the expected utility have that choice, where the expected utility is just.

815
02:10:37,590 --> 02:10:50,640
Michael Akira Lee Hayashi: The sum of multiplying the probability of a given outcome with the utility of that outcome so from before, if I remember right, we had the small bananas, the capitalist bananas and the.

816
02:10:51,090 --> 02:11:01,920
Michael Akira Lee Hayashi: plantations plan teams were to cavendish for one month Sana bananas are three so if there was a 10% chance of getting months on a bananas.

817
02:11:03,600 --> 02:11:10,290
Michael Akira Lee Hayashi: 80% chance of getting a cavendish banana and a 10% chance of getting a plantation when I go to the grocery store.

818
02:11:10,800 --> 02:11:24,900
Michael Akira Lee Hayashi: Then, my expected utility for this choice for the choice of going to the grocery store is point one times three plus point eight times one plus point one times two is the expected utility.

819
02:11:25,980 --> 02:11:45,720
Michael Akira Lee Hayashi: of going to the grocery store, which is going to be point three plus point eight plus point two, or about well exactly equal to 1.3 so 1.3 now is my expected utility of going to the grocery store I think if I calculate this right.

820
02:11:48,240 --> 02:11:51,360
Michael Akira Lee Hayashi: Possible I did my math wrong about that I would not entirely surprise me.

821
02:11:54,780 --> 02:12:01,470
Michael Akira Lee Hayashi: So what this means is that we can still we can still use the decision theoretic framework to.

822
02:12:03,630 --> 02:12:20,820
Michael Akira Lee Hayashi: To try to model what people do, even if the outcome of those choices are uncertain, even if your intervention has some probability of working like maybe it's got a maybe it's got a 30% probability of of preventing disease and a.

823
02:12:21,840 --> 02:12:32,370
Michael Akira Lee Hayashi: At 70% probability of not well there's still you can calculate the expected utility of that intervention, nevertheless, to a certain extent, you can like this can be helpful if you're trying to evaluate.

824
02:12:34,170 --> 02:12:43,380
Michael Akira Lee Hayashi: costs and benefits of vaccination, so this almost certainly underlies decisions about whether or not to broadly distribute the monkey pox vaccines.

825
02:12:44,010 --> 02:12:55,950
Michael Akira Lee Hayashi: So, so now that we've got a little outbreak of monkey pox rolling around there are there's the smallpox vaccine which is reasonably efficacious against monkeypox I believe there's a monkey pox specific vaccine.

826
02:12:58,530 --> 02:13:04,080
Michael Akira Lee Hayashi: However, both of these vaccines have somewhat more severe side effects so.

827
02:13:05,130 --> 02:13:16,170
Michael Akira Lee Hayashi: When when the CDC and FDA or can't well I think it's just the CDC right now, when the CDC is contemplating whether to recommend more general distribution of smallpox and monkeypox vaccines.

828
02:13:16,500 --> 02:13:21,540
Michael Akira Lee Hayashi: What they're doing essentially is weighing the costs and benefits of.

829
02:13:22,440 --> 02:13:30,000
Michael Akira Lee Hayashi: On the one hand, the preventative advocacy of the monkey pox vaccine the likelihood that people will actually become infected in general.

830
02:13:30,480 --> 02:13:41,250
Michael Akira Lee Hayashi: As well as the costs to people who receive the be monkeypox vaccine and, of course, the cost of storage and distribution, and all of that stuff like the operational costs.

831
02:13:43,620 --> 02:13:55,080
Michael Akira Lee Hayashi: So there there's a decision being made, knowing that the monkeypox vaccines will not absolutely go to people that absolutely need them there's some chance that people who need them will get them.

832
02:13:55,350 --> 02:14:01,860
Michael Akira Lee Hayashi: And they will not absolutely work there's some chance that a person who takes a monkey pox vaccine will actually.

833
02:14:02,640 --> 02:14:16,320
Michael Akira Lee Hayashi: not get infected if they're exposed and so that uncertainty can be modeled probabilistic Lee in order to give an overall estimate of the value that we think there is to either distributing or not, the monkey pox vaccine.

834
02:14:17,940 --> 02:14:26,070
Michael Akira Lee Hayashi: same thing with like the Tuberculosis Vaccine in the country like that it's not a regular one, but you do often get it when you travel because they're the cost benefit favors like.

835
02:14:27,150 --> 02:14:30,060
Michael Akira Lee Hayashi: Your risk is higher, when you travel, therefore.

836
02:14:31,200 --> 02:14:35,190
Michael Akira Lee Hayashi: We should think that the value of the vaccine is more worthwhile.

837
02:14:36,240 --> 02:14:40,680
Michael Akira Lee Hayashi: The, this is actually the case with a few other vaccines like that too.

838
02:14:42,270 --> 02:14:44,430
Michael Akira Lee Hayashi: I mean some like rabies are only administered.

839
02:14:45,450 --> 02:14:55,080
Michael Akira Lee Hayashi: Under particularly hybrid scenarios or is post exposure prophylaxis they're fairly they're fairly elaborate vaccine sequences and they're frankly quite unpleasant to get so.

840
02:14:55,500 --> 02:15:04,770
Michael Akira Lee Hayashi: What a random person who didn't get a bachelor apartment just go out and get a rabies vaccination probably not because balance the probability means that they wouldn't need it.

841
02:15:05,970 --> 02:15:08,910
Michael Akira Lee Hayashi: And they don't want to have a hard time sitting down for about a week.

842
02:15:12,570 --> 02:15:13,740
Michael Akira Lee Hayashi: While we're on the subject.

843
02:15:14,130 --> 02:15:17,310
Adriana Perez: Then I ask a quick question sorry denigrates exam but.

844
02:15:19,440 --> 02:15:25,620
Adriana Perez: One question that I have been burning is all of these is assuming that they.

845
02:15:26,880 --> 02:15:29,010
Adriana Perez: They intervention works.

846
02:15:29,100 --> 02:15:30,120
Adriana Perez: And then.

847
02:15:30,210 --> 02:15:36,150
Adriana Perez: Eve, they I mean I mean it could be that he works, but it could be that he doesn't work right.

848
02:15:36,690 --> 02:15:44,970
Adriana Perez: yeah So how do you try to incorporate of these concerns on concepts without.

849
02:15:47,100 --> 02:16:01,680
Adriana Perez: finishing the trial, for example, how do you sell to someone else to support for this type of work if you don't have certainty, the intervention works or not I mean you hope that it works, but if it is not.

850
02:16:04,140 --> 02:16:11,640
Adriana Perez: If he doesn't prove that it works, then, how do you sell all of this because I am struggling with that portion.

851
02:16:12,360 --> 02:16:20,340
Michael Akira Lee Hayashi: that's a good question yeah, and this is a, this is a fundamentally hard thing it's as i'm sure you've i'm sure you have an experience with.

852
02:16:22,020 --> 02:16:29,250
Michael Akira Lee Hayashi: Part of it is you, you can come at this from a number of different angles, one is that one of the beauties of modeling is that you can.

853
02:16:29,460 --> 02:16:37,770
Michael Akira Lee Hayashi: You can create any scenario that you want you could you can model, a scenario where the intervention does work, you can model, a scenario where the intervention doesn't work.

854
02:16:38,130 --> 02:16:43,530
Michael Akira Lee Hayashi: And you can look at what the what the expected cost benefit is under those scenarios, so if I say.

855
02:16:43,890 --> 02:16:52,620
Michael Akira Lee Hayashi: let's suppose I spend all this money and the intervention does work well here's the cost effectiveness in that scenario it's bad, but here it is, and I can quantify it.

856
02:16:53,010 --> 02:17:00,900
Michael Akira Lee Hayashi: let's suppose the intervention does work I can calculate the cost effectiveness in the hypothetical that it does and look at how good, that is, and then.

857
02:17:01,560 --> 02:17:14,490
Michael Akira Lee Hayashi: Maybe I have some inkling from early stage trials or preliminary work of whether there's a signal of whether one of those things is more likely or not, maybe there's preliminary efficacy results that might suggest that there's some probability that.

858
02:17:15,540 --> 02:17:19,290
Michael Akira Lee Hayashi: We will have a success full intervention or drug or whatever.

859
02:17:20,400 --> 02:17:23,820
Michael Akira Lee Hayashi: And you can use that to kind of form a prior on.

860
02:17:24,330 --> 02:17:38,010
Michael Akira Lee Hayashi: Well suppose that the chance of success what's the expected cost benefit given, given that preliminary chance of success, you can also do things like sensitivity analysis to say suppose i'm wrong suppose suppose.

861
02:17:38,910 --> 02:17:48,810
Michael Akira Lee Hayashi: The intervention works better than I think it does, based on the preliminary results, how much better, is that the cost effectiveness look they're suppose it's worse, how does the cost effectiveness look under that circumstance, but.

862
02:17:49,740 --> 02:17:54,600
Michael Akira Lee Hayashi: At the end of the day, some of this is kind of peering into a crystal ball and my favorite example of.

863
02:17:55,620 --> 02:18:10,080
Michael Akira Lee Hayashi: An example of this is, this is the problem that pharmaceutical companies undergo when they're trying to decide whether they want to invest money in the development of a new drug drug developments profoundly expensive and most of the time, it fails so.

864
02:18:11,130 --> 02:18:20,520
Michael Akira Lee Hayashi: As as as i'm sure you're aware most time most times, the thing goes in for trial it doesn't work right and you've committed all these resources to something that didn't work but.

865
02:18:21,270 --> 02:18:33,420
Michael Akira Lee Hayashi: The decision calculus underlying letting that go in the first place, usually has something to do with the fact that if it does the returns are astronomical whoever whoever hits on the first.

866
02:18:33,840 --> 02:18:43,860
Michael Akira Lee Hayashi: properly effective alzheimers drug is going to make a pile of money and they're going to make a pile of money for the rest of their and their their descendants lives so.

867
02:18:44,070 --> 02:18:49,680
Michael Akira Lee Hayashi: Sometimes the way the resolution to this problem of I don't know if this is going to work is the question of.

868
02:18:50,040 --> 02:19:00,090
Michael Akira Lee Hayashi: How good are the potential returns relative to the cost, so the only reason that drug companies keep funding trials, is that, when one does work they make so much money.

869
02:19:00,330 --> 02:19:10,380
Michael Akira Lee Hayashi: That it offsets the costs of all those failures, the massive numbers of failures and so similar logic often applies in and other health domains to like.

870
02:19:10,830 --> 02:19:14,550
Michael Akira Lee Hayashi: Why do we, why do we throw a bunch of money at cancer prevention, because.

871
02:19:15,240 --> 02:19:30,360
Michael Akira Lee Hayashi: If if we can come up with effective treatments, we have such a huge health impact that it makes the failures worthwhile so often, I think the way to present this is the question of just how good would it be if this succeeded.

872
02:19:31,170 --> 02:19:38,490
Michael Akira Lee Hayashi: there's going to yes and to be realistic about the chance of failure yeah there's likely to be a lot of failure yeah this isn't going to work but.

873
02:19:39,420 --> 02:19:50,100
Michael Akira Lee Hayashi: When it does, then then that's that's where sort of the gambling on the return happens Similarly, I think, like the scenario analysis can tell you something about.

874
02:19:50,580 --> 02:19:59,610
Michael Akira Lee Hayashi: How much tolerance, you have for risk in that particular say say you're trying to decide if you want to fund the trial and in a research group or something like that.

875
02:20:00,090 --> 02:20:04,770
Michael Akira Lee Hayashi: Being able to be presented with good scenario analysis can give you a sense for well.

876
02:20:05,340 --> 02:20:14,250
Michael Akira Lee Hayashi: In this space over here there's like a 60% chance that the thing fails kind of mildly and we're out a little bit we learn something it's not a total wash.

877
02:20:14,670 --> 02:20:21,210
Michael Akira Lee Hayashi: there's like a 10% chance it fails catastrophic Lee and we've wasted a huge amount of resources and time and then.

878
02:20:21,750 --> 02:20:29,610
Michael Akira Lee Hayashi: Maybe there's there's a 30% remaining chat or 20% remaining chance that it succeeds, a little bit a 10% chance that it succeeds well.

879
02:20:30,090 --> 02:20:46,710
Michael Akira Lee Hayashi: And that kind of scenario breakdown and probability breakdown can give you a feel for what is my tolerance for risk in this circumstance, do I think it's okay that there's like a 50% chance of catastrophic failure, for example, but some of, but a lot of this does come down to.

880
02:20:48,060 --> 02:20:59,520
Michael Akira Lee Hayashi: Decision calls on the part of whoever is conducting the study to figure out the range of scenarios they wanted to envision and how realistic they think those are what the chance of those they think is so.

881
02:21:00,450 --> 02:21:09,150
Michael Akira Lee Hayashi: Again long story short there's not a fantastically clear way to get around this problem, but I think the more we try to quantify and examine scenarios.

882
02:21:09,630 --> 02:21:24,930
Michael Akira Lee Hayashi: Then the better we'll get it kind of understanding what the what the total space of outcomes can be or what the tolerance for risk could be or what sort of the the expected cost benefit looks like across our spectrum of outcomes.

883
02:21:26,580 --> 02:21:27,240
Adriana Perez: But then.

884
02:21:28,290 --> 02:21:31,290
Adriana Perez: It will not get funded until I do the.

885
02:21:31,800 --> 02:21:35,430
Adriana Perez: simulator and i'll be proof, so I did all the work and.

886
02:21:35,730 --> 02:21:37,890
Adriana Perez: You may not be successful anyway.

887
02:21:38,850 --> 02:21:39,780
Michael Akira Lee Hayashi: yeah that's.

888
02:21:39,870 --> 02:21:40,440
Adriana Perez: and

889
02:21:41,400 --> 02:21:42,090
Michael Akira Lee Hayashi: And that is.

890
02:21:42,120 --> 02:21:49,560
Michael Akira Lee Hayashi: That is unfortunately a feature of a lot of what we do right, like you, you hope that works.

891
02:21:50,760 --> 02:21:59,370
Michael Akira Lee Hayashi: It might not you hope that someone's going to like what you're doing it might not to a certain extent, this is the calculus of throwing grant applications at the NIH right, unlike.

892
02:21:59,670 --> 02:22:06,210
Michael Akira Lee Hayashi: Any given grant application takes me a whole ton of time and stress and i'm probably not going to get it, but the one that does is going to get me tender.

893
02:22:06,810 --> 02:22:14,130
Michael Akira Lee Hayashi: and fast, that is, the calculus and and is it gambling, yes, it is absolutely gamble you're gambling on a low probability event.

894
02:22:14,760 --> 02:22:24,780
Michael Akira Lee Hayashi: In order to attain a very, very large reward and that's that's that's what drives a lot of this there there's there's a certain amount of risk tolerance underlying that so.

895
02:22:25,080 --> 02:22:34,680
Michael Akira Lee Hayashi: I think I think that's maybe the slightly dismal answer there that sometimes the the, how do we deal with that sort of monumental uncertainty is.

896
02:22:35,370 --> 02:22:49,980
Michael Akira Lee Hayashi: Well what's the carrot what's what's the potential light at the end of the tunnel like if we do get something that works and that's promising and that gets us NIH funding and narrow one level we're set for a really good amount of time that's great and so.

897
02:22:51,120 --> 02:22:55,620
Michael Akira Lee Hayashi: yeah I wish I had a nicer more optimistic cancer, but.

898
02:22:56,790 --> 02:23:01,650
Michael Akira Lee Hayashi: Having been on the end of a lot of failed grant applications, maybe i'm in a slightly pessimistic mood on that front.

899
02:23:04,800 --> 02:23:07,890
Michael Akira Lee Hayashi: That being said, to I think one thing to keep in mind is that.

900
02:23:11,310 --> 02:23:23,850
Michael Akira Lee Hayashi: Failure in the sense of like failure in a particular decision theoretic problem failure in the in the in the quest for a particular successful intervention does not necessarily mean uniform failure.

901
02:23:24,150 --> 02:23:36,360
Michael Akira Lee Hayashi: and often when we're thinking about decisions like do I fund a trial for something or do I fund a study or do I try to do, I try to put together all of the material to get myself funded for thing.

902
02:23:37,200 --> 02:23:42,630
Michael Akira Lee Hayashi: Sometimes, what happens along the way, is that you get a little bit of positive externality out of the process where it's like well.

903
02:23:43,050 --> 02:23:51,270
Michael Akira Lee Hayashi: I didn't get the thing that I wanted, but I did get this other thing like maybe I got a connection to a collaborator that got me funded on a separate thing or maybe I.

904
02:23:51,600 --> 02:23:58,380
Michael Akira Lee Hayashi: ended up getting funded on a separate mechanism or maybe I was able to publish some papers that got me some advancement in a different way or that.

905
02:23:58,590 --> 02:24:07,110
Michael Akira Lee Hayashi: Maybe I learned about a different mechanism through the process that ended up being useful later on, so I think another thing to keep in mind is that while we tend to measure.

906
02:24:07,860 --> 02:24:15,540
Michael Akira Lee Hayashi: and quantify specific outcomes of decision theoretic processes it's often worth considering that some of these processes fundamentally.

907
02:24:15,960 --> 02:24:20,640
Michael Akira Lee Hayashi: enable and include different kinds of externalities as byproducts of them.

908
02:24:20,940 --> 02:24:31,350
Michael Akira Lee Hayashi: And this is often like often we think about negative externalities bad things that happened by accident, but that is to say that there are also positive externality that can come along with some of these processes to.

909
02:24:33,750 --> 02:24:36,360
Michael Akira Lee Hayashi: So as to not be completely dismal about the situation.

910
02:24:42,150 --> 02:24:54,090
Michael Akira Lee Hayashi: Which which recently dovetails with the with my slide on risk tolerance here, so the reality is to that different people tend to express different degrees of risk tolerance, I am.

911
02:24:54,870 --> 02:25:01,290
Michael Akira Lee Hayashi: Well, because because i'm an academic researcher, I clearly am somewhat risk tolerant of the fact that.

912
02:25:01,590 --> 02:25:11,700
Michael Akira Lee Hayashi: I have a very low chance of success for any given grant application and I keep doing them and they keep you know I keep throwing papers at publisher's knowing that some of them are going to get rejected.

913
02:25:12,030 --> 02:25:24,360
Michael Akira Lee Hayashi: And that expresses something about my degree of willingness to willingness to undertake uncertainty in the decisions that I make so a classic example of degrees of risk tolerance is the following question.

914
02:25:24,810 --> 02:25:35,760
Michael Akira Lee Hayashi: suppose I offer you $5,000 or I say i'll flip the coin, if it comes up heads i'll give you $10,000 if it comes up tails you get nothing.

915
02:25:37,170 --> 02:25:37,740
Michael Akira Lee Hayashi: What do you do.

916
02:25:38,940 --> 02:25:42,450
Michael Akira Lee Hayashi: Well, let me put this in class who would take the $5,000 who would take the coins.

917
02:26:00,300 --> 02:26:01,110
Michael Akira Lee Hayashi: See to for.

918
02:26:05,670 --> 02:26:18,840
Michael Akira Lee Hayashi: It occurs to me that i'm asking students and and broadly academics and we may have a different sort of utility function with regard to money, given the way that our field is compensated Oh, here we go we've got a coin flipper okay.

919
02:26:27,330 --> 02:26:36,240
Michael Akira Lee Hayashi: And this this to where you all fall on this might also speak to questions of your own economic situation as we've seen in a lot of the decision theoretic problems where.

920
02:26:36,690 --> 02:26:43,650
Michael Akira Lee Hayashi: Your your utility your risk tolerance things like that often depend on your particular circumstances with regards to the decision problem so.

921
02:26:44,880 --> 02:26:54,390
Michael Akira Lee Hayashi: lot a lot of 5000s and okay if i'm being honest, I take the 5000 certainty to because i'd rather I could I could use that money that would be nice.

922
02:26:55,590 --> 02:26:55,980
Michael Akira Lee Hayashi: So.

923
02:26:57,660 --> 02:27:05,460
Michael Akira Lee Hayashi: what's interesting about this particular problem is that, from a statistical perspective, these outcomes are no different right like the expected value.

924
02:27:05,880 --> 02:27:17,280
Michael Akira Lee Hayashi: of both of these processes is $5,000 it's just that in one of these sometimes some people get nothing right so, so this is one of those weird phenomena where like.

925
02:27:17,820 --> 02:27:26,940
Michael Akira Lee Hayashi: The average might do a poor job of characterizing like what happens at the individual level when the process manifests but.

926
02:27:28,110 --> 02:27:37,080
Michael Akira Lee Hayashi: What we can do is save from this process that someone is risk averse if they prefer the certain outcome, so if your utility from that $5,000.

927
02:27:37,320 --> 02:27:42,480
Michael Akira Lee Hayashi: is bigger than or equal to the utility you get from the coin flip and the way that this manifests in kind of.

928
02:27:42,690 --> 02:27:49,590
Michael Akira Lee Hayashi: Preference surveying is all of you who said $5,000 i'm going to trust that you told me your real preference that you'd actually just take the money with certainty.

929
02:27:49,950 --> 02:28:01,410
Michael Akira Lee Hayashi: And for the one of you who would take the coin flip that would be potentially a risk seeking behavior or risk a fine behavior where the you the the expected utility of.

930
02:28:02,010 --> 02:28:16,650
Michael Akira Lee Hayashi: This coin flip is bigger than the utility of the certain to certain outcomes and, of course, a person can be risk neutral to where you just don't care either thing is fine and maybe sometimes you take the coin flip and sometimes you take the $5,000.

931
02:28:18,360 --> 02:28:27,030
Michael Akira Lee Hayashi: But the concept of risk tolerance can be really important in modeling decision processes as well, knowing perhaps that many of us are risk averse over questions of money.

932
02:28:27,960 --> 02:28:38,610
Michael Akira Lee Hayashi: That likely is going to tell us something about how we might behave in financial or consumer spaces and maybe it even tells us something about how we're likely to behave in.

933
02:28:41,250 --> 02:28:44,340
Michael Akira Lee Hayashi: sort of healthy economic cases as well.

934
02:28:47,610 --> 02:28:48,450
Michael Akira Lee Hayashi: Another one.

935
02:28:49,830 --> 02:28:51,930
Michael Akira Lee Hayashi: Another similar kind of thing could be.

936
02:28:55,350 --> 02:28:59,430
Michael Akira Lee Hayashi: Like i'm trying i'm trying to think of a more health related thing.

937
02:29:07,800 --> 02:29:11,370
Michael Akira Lee Hayashi: Thank you fact seems are often the classic risk seeking versus risk tolerant thing.

938
02:29:13,860 --> 02:29:21,090
Michael Akira Lee Hayashi: Particularly if it has side effects or treatments with side effects so like you might see questions of risk tolerance arise in them.

939
02:29:23,280 --> 02:29:26,670
Michael Akira Lee Hayashi: In cancer treatment, especially geriatric cancer treatments.

940
02:29:28,740 --> 02:29:29,340
Michael Akira Lee Hayashi: So.

941
02:29:31,350 --> 02:29:33,150
Michael Akira Lee Hayashi: You might run into a case where.

942
02:29:34,290 --> 02:29:43,560
Michael Akira Lee Hayashi: there's some chance that a treatment will work i'll, be it with side effects there's some chance it won't and the person will live with side effects anyway and.

943
02:29:44,160 --> 02:29:52,260
Michael Akira Lee Hayashi: You might find that the degree of risk seeking this for a person potentially undergoing that treatment may change as they age if i'm if i'm 95.

944
02:29:52,770 --> 02:30:02,250
Michael Akira Lee Hayashi: And I developed colon cancer and someone's like well, we could we could we could treat that aggressively we could give you chemo and radiation and potentially remove some of your colon.

945
02:30:03,510 --> 02:30:12,330
Michael Akira Lee Hayashi: i'd be like no i'm 95 How much longer do I have anyway i'm like i'm pretty like well the LIFE table says something like little have about five more years but.

946
02:30:12,540 --> 02:30:20,490
Michael Akira Lee Hayashi: In expectation that's probably pretty close to the amount of time, the cancer would kill me anyway, so do I really want to undergo the costs of that.

947
02:30:20,700 --> 02:30:27,570
Michael Akira Lee Hayashi: treatment on the uncertain basis of it even working, knowing that i'm going to have to live with those consequences, where.

948
02:30:27,840 --> 02:30:35,010
Michael Akira Lee Hayashi: If I got colon cancer now Would I be more willing to undergo aggressive treatment sure, because I think i've got years of my life left to live.

949
02:30:35,490 --> 02:30:40,020
Michael Akira Lee Hayashi: And i'd rather not die in 10 years from colon cancer, for example.

950
02:30:41,010 --> 02:30:55,800
Michael Akira Lee Hayashi: So we may find that risk tolerance to different topical domains changes for people in different circumstances changes over the life course especially for things like cost benefits of treatments and disease and things like that.

951
02:31:01,650 --> 02:31:04,710
Michael Akira Lee Hayashi: I think this is probably the most certain.

952
02:31:06,030 --> 02:31:10,350
Michael Akira Lee Hayashi: choices that i've seen in a class a little bit so that's actually quite interesting I I wouldn't.

953
02:31:12,090 --> 02:31:20,040
Michael Akira Lee Hayashi: I suppose we're also in kind of awkward economic times we've got massive inflation and quite a lot of instability, so I wonder that he reached which this influences things.

954
02:31:22,500 --> 02:31:31,950
Michael Akira Lee Hayashi: So we've seen a lot of ways to kind of think about a simple decision problem right where you were you were just considering a single decision do I go to the grocery store to buy bananas.

955
02:31:32,610 --> 02:31:46,770
Michael Akira Lee Hayashi: that's a one off it's really easy to model I come up with a utility function that represents my preferences over bananas and maybe my preferences overstayed home and then bob's your uncle we can we can make a little model and predict whether i'm going to go to the grocery store today.

956
02:31:48,210 --> 02:31:54,300
Michael Akira Lee Hayashi: What if we want to do something more elaborate What if we want to express a chain of decisions or a sequence of decisions.

957
02:31:55,470 --> 02:31:59,910
Michael Akira Lee Hayashi: Even a sequence of decisions under uncertainty, where we don't know.

958
02:32:00,480 --> 02:32:02,520
Michael Akira Lee Hayashi: What the outcome could be for a given to us.

959
02:32:02,880 --> 02:32:16,710
Michael Akira Lee Hayashi: We can use a particular structure called a decision tree which which may well be familiar to a number of you, I suspect, I suspect, tobacco folks will probably seen this because it's often come and kind of the health policy space so to take a bit of a formal step back.

960
02:32:18,690 --> 02:32:30,750
Michael Akira Lee Hayashi: A decision tree is strictly speaking a mathematical logic called a graph and for our purposes i'll call it a tree, because the tree is a special kind of graph that's composed of nodes in the edges so.

961
02:32:32,220 --> 02:32:32,850
Michael Akira Lee Hayashi: here's a node.

962
02:32:33,870 --> 02:32:36,090
Michael Akira Lee Hayashi: here's another node and there's an edge between.

963
02:32:38,310 --> 02:32:49,080
Michael Akira Lee Hayashi: A parent node is going to be said to be a node connected by edges to other notes, so this one here is a parent, and I should have adopted gender neutral terminology for this and.

964
02:32:50,100 --> 02:32:53,310
Michael Akira Lee Hayashi: Adapting myself to the times and sometimes I miss it.

965
02:32:54,870 --> 02:32:56,460
Michael Akira Lee Hayashi: These are child notes.

966
02:32:58,710 --> 02:33:10,380
Michael Akira Lee Hayashi: which are connected to parents, the way we can think about this is there are three types of notes and the decision tree there's a root node, which is a node that has no parents, so this here would be a route.

967
02:33:11,460 --> 02:33:18,900
Michael Akira Lee Hayashi: and internal node would be a know that has both parents and children, so this one, here is an internal note going to label this route.

968
02:33:19,470 --> 02:33:30,960
Michael Akira Lee Hayashi: This is an internal because it's parents is this note up here and Scott children terminal notes are nodes with no children, so this one here is terminal this one here is terminal and this one here is terminal.

969
02:33:32,430 --> 02:33:46,050
Michael Akira Lee Hayashi: The types of nodes make it our our kind of useful for us right because the root node is the first decision in the tree, this is where you start the internal nodes are part of the sequence of decisions and the terminal nodes basically or outcomes of your decision process.

970
02:33:48,810 --> 02:34:02,760
Michael Akira Lee Hayashi: i'll note that it is of course possible to make a decision tree where there's some chance that you go from one parent node to a given child and this isn't certain right but there's a probability you go from here to here and a probability that you go from here to here.

971
02:34:07,230 --> 02:34:10,710
Michael Akira Lee Hayashi: here's a slightly nicer graph, this is a root node at the very top.

972
02:34:12,090 --> 02:34:17,250
Michael Akira Lee Hayashi: I know these are called trees, but they are growing upside down so if you want to think about it like a tree flip it upside down.

973
02:34:17,880 --> 02:34:28,260
Michael Akira Lee Hayashi: The root node is where you start there's an internal note, with whose parent is the roots and which has three children and the root also has one child, which is a terminal note.

974
02:34:31,110 --> 02:34:48,090
Michael Akira Lee Hayashi: So this sort of structure is is is the kind of thing that if you're a pharmaceutical company, you will probably actually make one of these things in order to figure out if you think you're going to invest in the development of a new product.

975
02:34:48,990 --> 02:34:53,220
Michael Akira Lee Hayashi: And essentially what the terminal notes will represent is the different places that.

976
02:34:53,670 --> 02:35:06,090
Michael Akira Lee Hayashi: You could wind up like abject failure partial success that gives you some return on investment spectacular success, where you make unlimited money for the rest of your existence and the internal decisions, the internal nodes are often things like.

977
02:35:07,980 --> 02:35:18,150
Michael Akira Lee Hayashi: How long do I continue development for like a year, do I continue to fund development, a year on after that do I continue to fund development do I hire staff, do I.

978
02:35:18,510 --> 02:35:26,910
Michael Akira Lee Hayashi: Do I try to approach, an academic partner all those might form decision nodes in this process, which your your operations research people.

979
02:35:27,540 --> 02:35:36,870
Michael Akira Lee Hayashi: have estimated influence the chance of success or failure of your thing, and this, of course, will be reevaluated as you're going if you find that a first stage thing fails.

980
02:35:37,230 --> 02:35:43,320
Michael Akira Lee Hayashi: Well, your operations research folks are going to re re analyze their decision tree to be like okay.

981
02:35:43,980 --> 02:35:54,450
Michael Akira Lee Hayashi: that the first stage failed, which means I need to change, I need to update my prior on whether I think subsequent stages are going to fail that's probably going to reduce the chance that things are going to work down the line.

982
02:35:55,260 --> 02:36:05,610
Michael Akira Lee Hayashi: And then the project manager or their Director or someone like that might be like okay looking at these new estimates I no longer think it's worth continuing development, so you might cut your losses at that point.

983
02:36:10,860 --> 02:36:23,940
Michael Akira Lee Hayashi: So the way to interpret the decision tree as as as we've kind of alluded to, is more or less to draw paths from the root node down to every terminal note because each of these defines a sequence of decisions that you could make.

984
02:36:25,470 --> 02:36:34,200
Michael Akira Lee Hayashi: As I mentioned the terminal notes, then, are the outcomes of the decision process, and when we calculate utility for a decision tree.

985
02:36:34,890 --> 02:36:44,580
Michael Akira Lee Hayashi: We calculate utility basically for the terminal notes, where the utility of a terminal node is basically the sum of costs and benefits accrued in the path from the root node to that terminal.

986
02:36:46,440 --> 02:36:47,850
Michael Akira Lee Hayashi: So if I.

987
02:36:48,960 --> 02:36:50,580
Michael Akira Lee Hayashi: If I am trying to decide.

988
02:36:51,690 --> 02:36:54,690
Michael Akira Lee Hayashi: If i'm trying to decide whether to continue a project for another year.

989
02:36:56,670 --> 02:37:03,690
Michael Akira Lee Hayashi: That decision is going to incur a certain cost that's i'm going to spend money on on personnel and equipment and supplies.

990
02:37:04,440 --> 02:37:12,690
Michael Akira Lee Hayashi: And there's going to be some chance of a benefit that spending on personal equipment supplies and expectation might yield me I don't know two papers in the conference talk.

991
02:37:14,280 --> 02:37:17,880
Michael Akira Lee Hayashi: But there might be some probability that it does and so.

992
02:37:19,770 --> 02:37:25,350
Michael Akira Lee Hayashi: If I want to analyze the whole situation I might be like okay i'm going to look three years down the line down my tree.

993
02:37:25,890 --> 02:37:31,020
Michael Akira Lee Hayashi: One of the outcomes, is that I published six papers 123 conferences and did pretty well for myself.

994
02:37:31,620 --> 02:37:47,310
Michael Akira Lee Hayashi: And that gives me some value, one of the outcomes was I published two papers went to two conferences and that was Okay, and another outcome is that I published no papers, so I then want to look at the the path through the tree that got me in each of those and try to determine.

995
02:37:48,360 --> 02:37:53,100
Michael Akira Lee Hayashi: What decisions will he'll be the best expect to benefit, given that.

996
02:37:55,680 --> 02:37:59,580
Michael Akira Lee Hayashi: And then, of course, if the results of the decision is subject to uncertainty, then.

997
02:38:00,720 --> 02:38:06,000
Michael Akira Lee Hayashi: When you're when you're walking yourself through the tree you more or less treat.

998
02:38:07,020 --> 02:38:13,770
Michael Akira Lee Hayashi: The note that you arrive at from one subject uncertainty, so if these two things branch with some desert uncertainty.

999
02:38:15,660 --> 02:38:24,930
Michael Akira Lee Hayashi: Then there's some probability that I wind up at be in some probability that I wind up at sea, and I have to include that in the expected utility that I calculate later down the tree.

1000
02:38:26,700 --> 02:38:34,680
Michael Akira Lee Hayashi: So the values that these outcomes reflect the some or the expectation of the costs and benefits accrued.

1001
02:38:35,730 --> 02:38:43,050
Michael Akira Lee Hayashi: down every every every branch of this path, or data sorry down down this path, every edge of the path.

1002
02:38:44,940 --> 02:38:47,040
Michael Akira Lee Hayashi: Questions or comments or thoughts.

1003
02:39:03,870 --> 02:39:11,850
Michael Akira Lee Hayashi: So let's let's take a moment, since we've got we've got about a half hour left i'm trying to decide whether I want to start introducing game theory at this point, or if I want to.

1004
02:39:12,210 --> 02:39:27,390
Michael Akira Lee Hayashi: take a step back to do a bit more of a practical exercise I think let's um let's do an exercise in making a decision theoretic model so someone proposed for me, a decision process that we want to try to mom it could be a health one it doesn't have to be it could be something else.

1005
02:39:39,450 --> 02:39:41,280
Nicolle Krebs: Whether or not to take a vaccine.

1006
02:39:42,330 --> 02:39:44,700
Michael Akira Lee Hayashi: All right, let's model let's model vaccination.

1007
02:39:45,900 --> 02:39:48,390
Michael Akira Lee Hayashi: So i'm going to.

1008
02:39:49,920 --> 02:39:57,360
Michael Akira Lee Hayashi: want to really quickly create a little Google spreadsheet and I will share that shortly.

1009
02:39:58,740 --> 02:40:01,290
Michael Akira Lee Hayashi: syrup this class and might have a folder.

1010
02:40:01,290 --> 02:40:03,510
Michael Akira Lee Hayashi: prepared well I do that's Nice.

1011
02:40:05,160 --> 02:40:12,030
Michael Akira Lee Hayashi: mercy even made a folder for stuff that's good i'm going to make a spreadsheet to model of vaccinations session.

1012
02:40:25,740 --> 02:40:28,230
Michael Akira Lee Hayashi: Let me make sure that link sharing is enabled.

1013
02:40:36,540 --> 02:40:40,770
Michael Akira Lee Hayashi: I want to put this thing in chat there's literally nothing in it, but hopefully you can access the spreadsheet.

1014
02:40:45,000 --> 02:40:45,450
Michael Akira Lee Hayashi: So.

1015
02:40:47,640 --> 02:40:52,950
Michael Akira Lee Hayashi: Do you want to be, do you want to look at is there a particular kind of vaccination decision, we want to look at.

1016
02:41:00,120 --> 02:41:05,700
Michael Akira Lee Hayashi: If not, I have a proposition for one that might be relevant to folks in the present time.

1017
02:41:07,140 --> 02:41:08,400
Nicolle Krebs: Okay that's fine.

1018
02:41:10,380 --> 02:41:12,180
Michael Akira Lee Hayashi: let's look at the problem of.

1019
02:41:13,800 --> 02:41:23,370
Michael Akira Lee Hayashi: This is going to be a fairly small decision problem, to start with um let's look at the question of whether we whether we want to get a booster.

1020
02:41:23,820 --> 02:41:34,980
Michael Akira Lee Hayashi: Now, or wait or not at all a second booster particularly assuming that that we've had our first boosters or if you've just had your primary series whether to get a booster I don't.

1021
02:41:38,250 --> 02:41:46,620
Michael Akira Lee Hayashi: pull this out and screen share the spreadsheets that we can kind of lay out our recent so i'm just going to write down my problem so.

1022
02:41:50,340 --> 02:41:52,500
Michael Akira Lee Hayashi: let's look at our alternatives first so.

1023
02:41:56,370 --> 02:41:57,330
Michael Akira Lee Hayashi: We can have.

1024
02:42:01,530 --> 02:42:02,370
Michael Akira Lee Hayashi: booster now.

1025
02:42:03,510 --> 02:42:04,110
Michael Akira Lee Hayashi: or later.

1026
02:42:05,250 --> 02:42:05,820
Michael Akira Lee Hayashi: No boost.

1027
02:42:08,610 --> 02:42:11,340
Michael Akira Lee Hayashi: For Kofi perhaps some surprisingly.

1028
02:42:15,120 --> 02:42:15,570
Michael Akira Lee Hayashi: So.

1029
02:42:16,890 --> 02:42:25,350
Michael Akira Lee Hayashi: What are some things, what is the outcome that we care about from this decision, like what what's The thing that happens at the end of this whole thing that.

1030
02:42:26,610 --> 02:42:29,340
Michael Akira Lee Hayashi: That potentially costs us to care about this.

1031
02:42:33,480 --> 02:42:34,710
Nicolle Krebs: prevent infection.

1032
02:42:35,760 --> 02:42:41,010
Michael Akira Lee Hayashi: yeah we really want to engage with this question because we want to know if we're going to become infected.

1033
02:42:44,520 --> 02:42:46,950
Michael Akira Lee Hayashi: we'll start here, so the outcome is infected.

1034
02:42:49,260 --> 02:42:49,740
Michael Akira Lee Hayashi: In fact.

1035
02:42:50,910 --> 02:42:55,380
Michael Akira Lee Hayashi: After some time price, and we can we can be a little bit fuzzy about what that looks like.

1036
02:43:00,030 --> 02:43:13,470
Michael Akira Lee Hayashi: Okay, so these are alternatives, these are our outcomes notice that we have fewer outcomes than we have alternatives, this is okay because presumably these alternatives are going to map to these outcomes in different ways, so.

1037
02:43:15,840 --> 02:43:20,730
Michael Akira Lee Hayashi: First of all, is this a decision problem with with uncertainty.

1038
02:43:32,520 --> 02:43:40,230
Michael Akira Lee Hayashi: Is there something that we don't know for sure, on the basis of the decision we're making here like do we know whether our decision will map to an outcome or not.

1039
02:43:43,380 --> 02:43:44,370
Michael Akira Lee Hayashi: Or what outcome or nothing.

1040
02:43:49,530 --> 02:43:53,760
Nicolle Krebs: I don't think we could say for certain because you have the breakthrough infections.

1041
02:43:54,420 --> 02:44:08,760
Michael Akira Lee Hayashi: yeah, so this is, this is a problem with uncertainty, even if you get boosted under either circumstances, you could become infected and we don't know stuff like how much transmission there's going to be somewhere down the line, and in fact.

1042
02:44:09,840 --> 02:44:18,300
Michael Akira Lee Hayashi: If we were doing this as a formal exercise for paper, for example, we probably actually want to specify a time horizon for when we become infected, so why don't I.

1043
02:44:18,960 --> 02:44:25,530
Michael Akira Lee Hayashi: Why don't I make that a little more specific, so that we have some concrete is to work for what, if I say that the outcome is infected.

1044
02:44:30,030 --> 02:44:30,720
Michael Akira Lee Hayashi: By.

1045
02:44:33,300 --> 02:44:43,920
Michael Akira Lee Hayashi: end of the year, not infected by and to give ourselves essentially a six month time price or so so booster now would mean like you got a second booster.

1046
02:44:44,700 --> 02:44:54,300
Michael Akira Lee Hayashi: Like Well now, I know it's not technically available it's really not hard to go gun booster later would be suppose you wait for the fall, so this is.

1047
02:44:55,950 --> 02:44:57,360
Michael Akira Lee Hayashi: September, October so.

1048
02:44:58,920 --> 02:45:00,720
Michael Akira Lee Hayashi: No booster just means you don't get a booster.

1049
02:45:02,520 --> 02:45:03,180
Michael Akira Lee Hayashi: So.

1050
02:45:04,470 --> 02:45:12,120
Michael Akira Lee Hayashi: So now, what do we need to start breaking down what we, what do we need to think about in order to figure out how to model this problem.

1051
02:45:13,410 --> 02:45:16,020
Michael Akira Lee Hayashi: we've got actions you've got outcomes what don't we have yet.

1052
02:45:30,870 --> 02:45:31,800
Nicolle Krebs: preferences.

1053
02:45:32,850 --> 02:45:38,580
Michael Akira Lee Hayashi: preferences yeah costs things like that what we what we wanted to so.

1054
02:45:42,240 --> 02:45:45,630
Michael Akira Lee Hayashi: let's think a little bit about what goes into the preferences for this problem.

1055
02:45:48,420 --> 02:45:51,570
Michael Akira Lee Hayashi: Things like availability of vaccine cost.

1056
02:45:52,740 --> 02:46:02,850
Michael Akira Lee Hayashi: Are there other things that that go into essentially the value that we get or the the utility that we get for any of our given decisions.

1057
02:46:06,420 --> 02:46:15,990
Michael Akira Lee Hayashi: So let's let's put this in kind of a cost benefit framework these this is often a way of expressing or building utility function, so that we can determine preferences, if I.

1058
02:46:17,460 --> 02:46:18,690
Michael Akira Lee Hayashi: If I do this so.

1059
02:46:23,130 --> 02:46:25,170
Michael Akira Lee Hayashi: Now i'm going to go down the line.

1060
02:46:34,020 --> 02:46:38,550
Michael Akira Lee Hayashi: And we're going to do, costs are going to do benefits.

1061
02:46:45,690 --> 02:46:54,000
Michael Akira Lee Hayashi: So let's start here if if you are to get a booster now or as soon as practically possible what would be a cost of doing so.

1062
02:47:00,330 --> 02:47:01,140
Adriana Perez: and go next.

1063
02:47:02,940 --> 02:47:04,950
Michael Akira Lee Hayashi: yeah there's there's a bit of an out of pocket so.

1064
02:47:05,940 --> 02:47:06,990
Michael Akira Lee Hayashi: You might have the.

1065
02:47:11,010 --> 02:47:11,490
Michael Akira Lee Hayashi: Okay.

1066
02:47:14,370 --> 02:47:23,970
Michael Akira Lee Hayashi: The costs also can be they don't necessarily have to be explicitly monetary they could be like time spent or side effects.

1067
02:47:27,120 --> 02:47:27,600
Michael Akira Lee Hayashi: Well, at.

1068
02:47:29,190 --> 02:47:32,670
Michael Akira Lee Hayashi: Times it's not much, but but one does have to do.

1069
02:47:34,530 --> 02:47:35,250
Michael Akira Lee Hayashi: Any other.

1070
02:47:40,740 --> 02:47:41,400
Any other pretend.

1071
02:47:42,690 --> 02:47:47,400
Adriana Perez: i'm work hours without pain big time.

1072
02:47:47,460 --> 02:47:53,550
Michael Akira Lee Hayashi: yeah yeah so so factoring into time are things like having to take time off from work lost productivity.

1073
02:47:55,860 --> 02:47:57,210
Michael Akira Lee Hayashi: That sort of stuff.

1074
02:48:10,050 --> 02:48:10,980
Michael Akira Lee Hayashi: Of the likelihood.

1075
02:48:13,320 --> 02:48:17,310
Michael Akira Lee Hayashi: There, there could also be some operational ones like like who is administering it.

1076
02:48:19,290 --> 02:48:26,460
Michael Akira Lee Hayashi: Whether you kind of fundamentally think this is a good idea or not, what are some benefits of getting a booster in the short term.

1077
02:48:31,860 --> 02:48:45,810
Michael Akira Lee Hayashi: i'll explain a little bit more of why i'm thinking short term long term after that peace of mind, which is a real thing that that is like we should be considering things like that, like the fact that maybe I won't be as stressed, if I get a booster now.

1078
02:48:48,330 --> 02:49:01,440
Michael Akira Lee Hayashi: we'll talk about how to operationalize these things shortly as we're working through this and some of them I may or may not keep because they're easier harder to operationalize but but it's it's good to cast a wide net when we're thinking about these things.

1079
02:49:11,070 --> 02:49:12,480
Michael Akira Lee Hayashi: Other it could be mandates yep.

1080
02:49:15,990 --> 02:49:23,730
Michael Akira Lee Hayashi: And of course we'd be remiss if we didn't know, one of the major purposes, which is reduced chance of infection.

1081
02:49:24,900 --> 02:49:27,150
Michael Akira Lee Hayashi: Which which which impacts, many of these things.

1082
02:49:34,620 --> 02:49:36,960
Michael Akira Lee Hayashi: So let's leave it there, for the moment, why.

1083
02:49:38,100 --> 02:49:49,800
Michael Akira Lee Hayashi: Why might I be thinking about a booster later what what is the function of including this in our decision theoretic process like what might change between now and later now in the fall, for example.

1084
02:49:58,830 --> 02:50:07,380
Nicolle Krebs: People might think that there's going to be more infection in the fall, or they might be more susceptible because they're inside more.

1085
02:50:08,580 --> 02:50:10,260
Michael Akira Lee Hayashi: yeah there could be changes in.

1086
02:50:17,070 --> 02:50:18,420
Michael Akira Lee Hayashi: Disease dynamics.

1087
02:50:25,140 --> 02:50:27,840
Michael Akira Lee Hayashi: yeah your your timing on your vaccine series.

1088
02:50:31,320 --> 02:50:32,160
Michael Akira Lee Hayashi: That could be a thing.

1089
02:50:37,500 --> 02:50:46,020
Michael Akira Lee Hayashi: For the rest of want to get a booster right for new variant this this could very much be a thing that you want to try to time your booster to match those changes in disease dynamics.

1090
02:50:46,650 --> 02:50:56,430
Michael Akira Lee Hayashi: Maybe I think that we're in a quiet period, and I want to tie my booster the best match when we're going to be an exciting one waiting on a bio available for a new booster that's why I personally am waiting.

1091
02:51:02,490 --> 02:51:15,630
Michael Akira Lee Hayashi: Waiting for more research or evidence related to the benefits of the booster yeah so we still have fairly preliminary data on how well they actually work at preventing infection and a lot of the preliminary data is kind of suggesting that immune like.

1092
02:51:16,950 --> 02:51:33,150
Michael Akira Lee Hayashi: The first pass immunity, the neutralizing antibody one wayne's pretty fast from the boosters, though, whereas the kind of regular adaptive immunity sticks around for a good bit even from the earlier boosters or even from the vaccines last year.

1093
02:51:42,780 --> 02:51:52,170
Michael Akira Lee Hayashi: And, to a certain extent, a lot of this stuff kind of tells us what the costs and benefits of not getting a booster all are right, if you don't get a booster then you're at increased risk.

1094
02:51:53,370 --> 02:51:54,150
Michael Akira Lee Hayashi: of infection.

1095
02:51:55,680 --> 02:51:58,650
Michael Akira Lee Hayashi: But you're not inconvenienced.

1096
02:52:04,740 --> 02:52:17,340
Michael Akira Lee Hayashi: If people around you're vaccinated you wouldn't be in a rush to get a booster now yeah so there's this problem very quickly actually turns into a game theory problem for that specific reason that vaccination is not an isolated behavior and it does.

1097
02:52:17,820 --> 02:52:27,990
Michael Akira Lee Hayashi: strongly depend on interactions with other people, and that we probably won't get to it today, I think i'm going to take more of tomorrow to talk some more about game theory stuff because we haven't quite gotten there.

1098
02:52:29,040 --> 02:52:32,730
Michael Akira Lee Hayashi: But that is a thing that a lot of behaviors do interact with other people.

1099
02:52:34,110 --> 02:52:51,030
Michael Akira Lee Hayashi: So let's start here, we have some cost me have some benefits for each of our potential decisions, so the trouble now is to try to start writing utility function style equations to represent the balance of costs and benefits between our different alternatives so.

1100
02:52:52,980 --> 02:52:53,760
Michael Akira Lee Hayashi: If I.

1101
02:52:55,680 --> 02:52:59,760
Michael Akira Lee Hayashi: If I get a booster now, then what we might think, is that my.

1102
02:53:02,010 --> 02:53:06,660
Michael Akira Lee Hayashi: My kind of expected utility over that is.

1103
02:53:09,180 --> 02:53:13,470
Michael Akira Lee Hayashi: Sorry, I should be a little careful about my term here, this is i'm going to say, this is a health.

1104
02:53:14,100 --> 02:53:27,960
Michael Akira Lee Hayashi: outcome because for a decision theoretic purpose, what we really care about is what choice I actually made, what we need to figure out the preferences over those like we probably know whether I do or do not want to get infected by the end of the year that's not that's not as health.

1105
02:53:29,580 --> 02:53:33,540
Michael Akira Lee Hayashi: So um so if we wanted to think about utility.

1106
02:53:35,640 --> 02:53:38,130
Michael Akira Lee Hayashi: Then, maybe we want something that looks like.

1107
02:53:40,650 --> 02:53:41,610
Michael Akira Lee Hayashi: there's a.

1108
02:53:44,940 --> 02:53:47,040
Michael Akira Lee Hayashi: we're going to say that there's some costs term.

1109
02:53:48,060 --> 02:53:58,530
Michael Akira Lee Hayashi: to reflect potentially a some of these costs, however, we choose to operationalize and i'm leaving this deliberately fuzzy because we can break this down as we make things more elaborate.

1110
02:54:00,000 --> 02:54:03,060
Michael Akira Lee Hayashi: So there might be a we'll call this a.

1111
02:54:08,220 --> 02:54:16,260
Michael Akira Lee Hayashi: an inconvenience cost there might be a side effect cost but there's also a.

1112
02:54:19,980 --> 02:54:20,250
Michael Akira Lee Hayashi: A.

1113
02:54:21,750 --> 02:54:23,220
Michael Akira Lee Hayashi: what's it called a protect.

1114
02:54:26,970 --> 02:54:31,680
Michael Akira Lee Hayashi: A protected benefit right, so this is proportional to the chance that.

1115
02:54:33,600 --> 02:54:42,090
Michael Akira Lee Hayashi: That that you don't get infected, given that you're exposed, this is, this is a somewhat complex thing to calculate so while while i'm being a little bit fluffy about this.

1116
02:54:43,320 --> 02:54:43,950
Michael Akira Lee Hayashi: we'll get into it.

1117
02:54:45,750 --> 02:54:46,170
Michael Akira Lee Hayashi: Now.

1118
02:54:47,310 --> 02:54:52,260
Michael Akira Lee Hayashi: Really, for the most part, these things kind of.

1119
02:54:55,080 --> 02:55:02,340
Michael Akira Lee Hayashi: Maybe and heck maybe want to maybe maybe we want to peace of mind sure i'll put it, because it's kind of an interesting thing to.

1120
02:55:03,150 --> 02:55:11,130
Michael Akira Lee Hayashi: Like people do care about stuff like that, like i'm an anxious person and I like to deal with stuff quickly I don't like to wait, if I can help it.

1121
02:55:12,090 --> 02:55:26,910
Michael Akira Lee Hayashi: And that does actually influence my decisions in the enormous amount right, so the interesting thing is that this utility function more or less works for each of the alternatives what distinguishes them is the value of the components of this thing right so.

1122
02:55:29,430 --> 02:55:33,900
Michael Akira Lee Hayashi: So when we're thinking about this kind of qualitatively what we might think, is that.

1123
02:55:35,910 --> 02:55:40,740
Michael Akira Lee Hayashi: let's let's take a look at each of the terms here so i'm.

1124
02:55:51,690 --> 02:55:59,190
Michael Akira Lee Hayashi: So if I get a booster now I suffer some amount of inconvenience, so this happens, I do.

1125
02:56:00,720 --> 02:56:01,950
Michael Akira Lee Hayashi: say yes.

1126
02:56:03,060 --> 02:56:13,170
Michael Akira Lee Hayashi: or won't call it a one will be binary about this for now I will get side effects if we're talking about, for the moment i'll talk about myself I do get side effects from the thing.

1127
02:56:14,790 --> 02:56:23,190
Michael Akira Lee Hayashi: we'll talk about this a bit and I get peace of mind if I get a booster later I still suffer inconvenience, although it's slightly future discounted, which is the thing.

1128
02:56:23,550 --> 02:56:31,080
Michael Akira Lee Hayashi: I will almost certainly get side effects and I get less peace of mind, because i'm worried about getting infected in the interim.

1129
02:56:31,410 --> 02:56:45,600
Michael Akira Lee Hayashi: If I have no boosters then i'm not out any time or money I don't have side effects, but I get no peace of mind, the protective effect is where modeling vaccination decisions get really interesting because, as we saw there's a bunch of stuff that plays into this.

1130
02:56:47,010 --> 02:56:58,170
Michael Akira Lee Hayashi: For for the record i'm kind of rolling some things together so like mandates side effects last mandate lost productivity copay those i'm kind of lumping into sort of the notion of inconvenience and peace of mind.

1131
02:56:59,460 --> 02:57:03,510
Michael Akira Lee Hayashi: The words you choose or mostly in order for those are salesmanship.

1132
02:57:04,530 --> 02:57:04,860
Michael Akira Lee Hayashi: But.

1133
02:57:06,960 --> 02:57:11,370
Michael Akira Lee Hayashi: You know they're they're neither here nor there the protective effects is where things get rather interesting so.

1134
02:57:12,990 --> 02:57:20,340
Michael Akira Lee Hayashi: If I get a booster now how relatively good do I think the protective effect of that booster will be for the rest of the year.

1135
02:57:20,580 --> 02:57:27,510
Michael Akira Lee Hayashi: With the understanding that probably means that I won't be able to get another booster until very nearly the end of the year, at which point it won't matter.

1136
02:57:28,170 --> 02:57:36,810
Michael Akira Lee Hayashi: Or do we think that that strongly reduces my chance of infection over the rest of the year kind of moderately lightly, not much at all.

1137
02:57:48,420 --> 02:57:52,710
Michael Akira Lee Hayashi: When we move this over in preparation for what i'm starting to what i'm thinking about here.

1138
02:58:00,300 --> 02:58:01,470
Michael Akira Lee Hayashi: let's break this down and.

1139
02:58:07,710 --> 02:58:20,460
Michael Akira Lee Hayashi: When I say long term i'm so short term will say within the next few months long term is from there on to the rest of the year, so the short term risk for booster now that's probably fairly low right.

1140
02:58:22,500 --> 02:58:28,920
Michael Akira Lee Hayashi: So, for the moment i'm literally just going to say low and we will come back to quantifying that.

1141
02:58:29,580 --> 02:58:40,230
Michael Akira Lee Hayashi: But the long term risk of a booster now I might actually think is kind of fight because read infections are pretty prominent right now and breakthrough infections with with boosters are pretty prominent after a certain amount of lag time.

1142
02:58:43,200 --> 02:58:45,630
Michael Akira Lee Hayashi: Where the short term risk for a booster later.

1143
02:58:46,890 --> 02:59:02,130
Michael Akira Lee Hayashi: Given the current covert situation I might think it's kind of medium and the long term risk then is low because i'm gambling on some of this stuff that that we might see a biovail enter a multi veil of vaccine booster come fall.

1144
02:59:03,750 --> 02:59:13,590
Michael Akira Lee Hayashi: Where if I don't get a booster my short term risk is high or really medium because it's whatever my non booster risk is and my long term risk is high.

1145
02:59:16,440 --> 02:59:17,820
Michael Akira Lee Hayashi: How would we quantify.

1146
02:59:19,560 --> 02:59:26,340
Michael Akira Lee Hayashi: what's a way that we could watch the way that we could use stuff that we've used in our class to try to quantify either of these things.

1147
02:59:45,480 --> 02:59:47,970
Michael Akira Lee Hayashi: we're thinking here of the risk of infection given different.

1148
02:59:47,970 --> 02:59:50,310
Michael Akira Lee Hayashi: kinds of vaccination in particular.

1149
02:59:53,520 --> 02:59:54,840
Nicolle Krebs: We like probability.

1150
02:59:56,070 --> 03:00:09,210
Michael Akira Lee Hayashi: yeah we could assign a probability of them, in particular, if we really wanted to, we could actually design a little disease transmission model to simulate potential risk under different vaccination scenarios, so I could make a little model if I wanted to that was like.

1151
03:00:10,980 --> 03:00:12,120
Michael Akira Lee Hayashi: suppose I.

1152
03:00:12,420 --> 03:00:16,440
Michael Akira Lee Hayashi: suppose I think i'm going to have X number of contacts between now and whenever I get my.

1153
03:00:16,620 --> 03:00:25,890
Michael Akira Lee Hayashi: booster and I can take the the prevalence of infectious contacts from state of current disease prevalence.

1154
03:00:26,280 --> 03:00:31,650
Michael Akira Lee Hayashi: What do I think my risk is going to be from that I could do that I could make a transmission model that explicitly models.

1155
03:00:31,860 --> 03:00:43,800
Michael Akira Lee Hayashi: Be transmission dynamics from now through the rest of the year, to give myself a feel for what the prevalence is going to be over that time horizon such that I can try to estimate what the actual risk probability is from that.

1156
03:00:44,790 --> 03:00:59,130
Michael Akira Lee Hayashi: And in fact if I was if I was doing this as a real project I probably would that is probably, in fact, what I would do I would make a transmission model that estimates my like three months risk versus my six month risk under different vaccination decisions.

1157
03:01:05,970 --> 03:01:06,390
Michael Akira Lee Hayashi: And then.

1158
03:01:07,650 --> 03:01:09,030
Michael Akira Lee Hayashi: So i'm going to hand wave that.

1159
03:01:11,670 --> 03:01:19,200
Michael Akira Lee Hayashi: i'm going to suppose that if I don't get vaccinated my long term risk of infection is almost certain pretty much because.

1160
03:01:19,560 --> 03:01:31,590
Michael Akira Lee Hayashi: The current variants are Comically infectious and as anti social, as I am every so often I do go to the grocery store to buy bananas so it's possible they'll get infected that way so let's suppose, this is just one.

1161
03:01:35,280 --> 03:01:47,550
Michael Akira Lee Hayashi: let's suppose that if I do a booster now that my long term risk is fairly high, but not absolutely certain so we'll call it 8% again this is very hand wavy because I don't have time right now to make an actual model.

1162
03:01:48,750 --> 03:02:04,830
Michael Akira Lee Hayashi: The short term risk of infection if I got a booster now i'm going to call it about 20% which is like I kinda kinda eyeballing but the vaccine efficacy right now is about 80% from a booster me, maybe not terribly on point.

1163
03:02:07,800 --> 03:02:18,030
Michael Akira Lee Hayashi: And I might do something like suppose there's 10% long term risk from a booster later because I am gambling on the fact that booster being good and I don't know, maybe a.

1164
03:02:20,310 --> 03:02:34,200
Michael Akira Lee Hayashi: Maybe a 60% short term risk for breakthroughs, or what have you, and this would also be a 60% chance, so, while these numbers are slightly fake we can kind of see how we're building up a way to evaluate.

1165
03:02:37,230 --> 03:02:40,140
Michael Akira Lee Hayashi: The utility of different choices, so I might do something like.

1166
03:02:44,880 --> 03:02:59,700
Michael Akira Lee Hayashi: I could do a utility function that's like this that literally is just the sum over these separate components and if I did, that what we find is that who actually, this is a these are minuses aren't they because these are cost terms.

1167
03:03:02,580 --> 03:03:06,150
Michael Akira Lee Hayashi: I was thinking, but some of these looks suspiciously high so oops.

1168
03:03:13,290 --> 03:03:15,030
Michael Akira Lee Hayashi: So here we go oh.

1169
03:03:16,110 --> 03:03:18,480
Michael Akira Lee Hayashi: wow okay doing good at typing.

1170
03:03:24,090 --> 03:03:29,700
Michael Akira Lee Hayashi: OK, so now, if I do this naive thing and just sum up the components of my utility function.

1171
03:03:30,810 --> 03:03:37,530
Michael Akira Lee Hayashi: What would you what would you say the decision theoretic model would predict that I do, what does this model compel me to what choice does it compelled me to take.

1172
03:03:42,960 --> 03:03:43,740
Nicolle Krebs: Mr now.

1173
03:03:44,430 --> 03:03:46,110
Michael Akira Lee Hayashi: yeah this would suggest that I should.

1174
03:03:46,710 --> 03:03:47,970
Michael Akira Lee Hayashi: Go get my booster right now.

1175
03:03:49,500 --> 03:03:52,980
Michael Akira Lee Hayashi: By a fairly tight margin, but but, nevertheless, this is still the maximum.

1176
03:03:54,180 --> 03:03:57,990
Michael Akira Lee Hayashi: Having seen this result and having seen sort of what I put into it.

1177
03:03:59,130 --> 03:04:05,610
Michael Akira Lee Hayashi: What do we think about that Is this reasonable did I are these reasonable values for things are they scaled reasonably.

1178
03:04:11,430 --> 03:04:18,120
Michael Akira Lee Hayashi: I could, I could make this a little more on the nose and say that I am not going to get a booster now, and I am actually waiting until later.

1179
03:04:21,270 --> 03:04:30,480
Michael Akira Lee Hayashi: And what would that suggest about our modeling exercise if you know that my actual behavior does not conform to the thing that we thought we should get out of the decision theoretical.

1180
03:04:36,270 --> 03:04:38,280
Nicolle Krebs: Then why not, accounting for something.

1181
03:04:39,780 --> 03:04:47,160
Michael Akira Lee Hayashi: yeah we're we're not accounting for something maybe we're waiting some factor to highly in one scenario or another in one action or another.

1182
03:04:53,040 --> 03:05:00,390
Michael Akira Lee Hayashi: yeah maybe maybe we're focusing on the wrong component of risk maybe by equally waiting the component of risk where we're not.

1183
03:05:02,160 --> 03:05:04,110
Michael Akira Lee Hayashi: we're not adequately capturing.

1184
03:05:05,580 --> 03:05:07,740
Michael Akira Lee Hayashi: what's actually driving my decision like.

1185
03:05:09,120 --> 03:05:21,900
Michael Akira Lee Hayashi: Maybe, maybe, what is the case is that I care a lot about reducing my long term risk, and so we should wait this factor, a little more so if we did something like that let's let's let's do that in fact.

1186
03:05:27,120 --> 03:05:31,650
Michael Akira Lee Hayashi: Well, actually, you know what i'll just i'm not even going to make a new column we're going to multiply this by two.

1187
03:05:32,880 --> 03:05:37,620
Michael Akira Lee Hayashi: let's suppose that the long term risk is twice as important to me as the short term risk.

1188
03:05:39,000 --> 03:05:41,970
Michael Akira Lee Hayashi: So I really don't want to get sick around the holidays, for example.

1189
03:05:51,360 --> 03:06:01,380
Michael Akira Lee Hayashi: Sorry scaling changes are predicted outcome right, we can see that the decision theoretic processes are fairly sensitive to the things that go into their utility functions, because now.

1190
03:06:01,710 --> 03:06:09,210
Michael Akira Lee Hayashi: Having up waited the long term risk by a factor of two now we get the solution that I will get my booster later.

1191
03:06:12,810 --> 03:06:20,970
Michael Akira Lee Hayashi: there's a phenomenon related to the balance of short term versus long term reward that you often see in economics type things is that do do folks know about that one.

1192
03:06:22,080 --> 03:06:25,710
Michael Akira Lee Hayashi: It is essentially the opposite of the way that i'm thinking about my vaccination thing.

1193
03:06:29,850 --> 03:06:42,630
Michael Akira Lee Hayashi: there's a thing called future discounting, which is often used in health economics and behavioral research, which suggests that we undervalue outcomes that take place farther in the future, relative to ones that take place closer to now.

1194
03:06:43,050 --> 03:06:43,320
So.

1195
03:06:45,390 --> 03:06:46,230
Michael Akira Lee Hayashi: If I.

1196
03:06:46,590 --> 03:06:55,710
Michael Akira Lee Hayashi: Applied future discounting what that might actually mean is that I value this long term risk less than I value the short term, and that would also change my decision.

1197
03:06:56,280 --> 03:07:03,240
Michael Akira Lee Hayashi: It just so happened that in this case we figured out that I actually do value the long term risk more highly.

1198
03:07:03,870 --> 03:07:08,190
Michael Akira Lee Hayashi: Another thing that could be the case is that maybe I, maybe even if I do future discount.

1199
03:07:08,760 --> 03:07:17,670
Michael Akira Lee Hayashi: Maybe it's that I have a different evaluation of short versus long term risk under different disease snares maybe I think that, even if I get a booster now my short term risk is.

1200
03:07:18,240 --> 03:07:32,880
Michael Akira Lee Hayashi: You know, still decent if I don't get a booster now you know that's there, but I think my long term risk is even smaller, because I think that later booster is going to be tailored to the variants that are coming out and so that's going to mean that the breakthrough chances even lower.

1201
03:07:33,960 --> 03:07:39,090
Michael Akira Lee Hayashi: And in this case we didn't change a whole lot but you know we.

1202
03:07:41,190 --> 03:07:48,390
Michael Akira Lee Hayashi: So, for one, there are some changes to the utility function that the model is largely invariant to so from a sensitivity perspective.

1203
03:07:48,870 --> 03:07:56,940
Michael Akira Lee Hayashi: We just didn't change my my preferences enough to actually change the outcome, and we might have had to up or down way things are up or down scale other things.

1204
03:07:57,120 --> 03:08:05,580
Michael Akira Lee Hayashi: But what This also means, to a certain extent, is that we can kind of see a parameter estimation type thing emerging here, where, if you knew what I did.

1205
03:08:06,720 --> 03:08:23,250
Michael Akira Lee Hayashi: And you built your model with with different utility values for things you could potentially try to fit some of these like cost parameters in the model to the actual decision that I made to try to get an idea of how much do I relatively value different aspects of this problem.

1206
03:08:24,570 --> 03:08:33,240
Michael Akira Lee Hayashi: And that's where we start to take some of the decision and game theoretic stuff out of the realms of purely theoretical exercise into like suppose I don't want these to just be fluff.

1207
03:08:33,780 --> 03:08:42,870
Michael Akira Lee Hayashi: Maybe I want to try to estimate relative values for them well I could, because we know what I did, and if we were to survey people and decision problems we know what they do.

1208
03:08:43,350 --> 03:08:50,160
Michael Akira Lee Hayashi: And so you can perform a sort of parameter estimation exercise to fit some of the components of the utility function.

1209
03:08:50,490 --> 03:09:06,240
Michael Akira Lee Hayashi: To the decision that people made to try to try essentially to uncover what's called revealed preferences, which is the concept that while I might not tell you accurately what I want you can infer from what I actually do you can infer.

1210
03:09:07,320 --> 03:09:15,030
Michael Akira Lee Hayashi: My preferences over things from my behaviors right So if you know that I actually took a booster later and you're pretty sure that.

1211
03:09:15,420 --> 03:09:26,580
Michael Akira Lee Hayashi: I view the inconvenience and side effects of boosters and of boosters in different timings about the same, then you should think that the thing that my outcome is telling you.

1212
03:09:27,690 --> 03:09:32,040
Michael Akira Lee Hayashi: Oh yeah if you have to go no worries I will i'm wrapping up here in just a moment.

1213
03:09:32,820 --> 03:09:38,820
Michael Akira Lee Hayashi: Then what my what my actual empirical decision was telling you gives you some information.

1214
03:09:39,210 --> 03:09:48,210
Michael Akira Lee Hayashi: about the relative value that I placed on other components of the utility function, and this can be really powerful and trying to analyze the behavior of people or organizations.

1215
03:09:48,630 --> 03:10:04,440
Michael Akira Lee Hayashi: So i'll leave us there tomorrow morning relax i'm going to pick up with with our game theory stuff and then move into agent based models, but i'm happy to stick around if anyone has a question or anything like that, and if not, then I will see you all bright and early tomorrow morning.

1216
03:10:16,140 --> 03:10:18,180
Michael Akira Lee Hayashi: Alright, thanks everyone bye.

