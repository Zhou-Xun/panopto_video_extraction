1
00:00:16,680 --> 00:00:25,480
One that can be used for your. Yeah.

2
00:00:26,010 --> 00:00:48,670
Have the files stored somewhere or. Yeah.

3
00:00:57,110 --> 00:01:34,170
I will do later. What I can do is just.

4
00:01:34,200 --> 00:01:39,810
Just get up. Just close it. I already post this.

5
00:01:40,050 --> 00:01:47,500
Oh, in the. We're.

6
00:02:14,030 --> 00:02:17,660
Okay. Eight. The Google ship.

7
00:02:19,240 --> 00:02:22,299
Make up for it off the teams and set up your teams.

8
00:02:22,300 --> 00:02:31,870
Then we're going to start to look at data and also like make a plan for your practice or something like that.

9
00:02:33,520 --> 00:02:41,980
So if you haven't done all that, please, you know, just talk to your peers and try to make up whatever team and,

10
00:02:42,130 --> 00:02:46,150
you know, convince someone to join your team or something like that.

11
00:02:46,180 --> 00:02:56,210
So anyway, here's the plan that Leo is going to talk about some of the lengths from which we will go into

12
00:02:56,740 --> 00:03:04,270
capturing the data and we are going to analyze the data captured on those database sites.

13
00:03:04,990 --> 00:03:07,990
And we'll continue this mathematical modeling and.

14
00:03:09,910 --> 00:03:13,300
Become part of the lecture. Look out. Please go ahead.

15
00:03:14,620 --> 00:03:19,810
Hello, everyone, and welcome to the second year The History of the Civil Rights by Dr. Song.

16
00:03:20,530 --> 00:03:27,940
I have been working on this project like two years ago and I also have taken this course my last year.

17
00:03:28,120 --> 00:03:33,100
So I'm going to introduce some data resources for this course.

18
00:03:33,460 --> 00:03:42,400
And yes, I took this quarter last year, so I'm pretty sure this data is like the most up to date data.

19
00:03:42,400 --> 00:03:48,610
But if you have other data resources, please share with your classmates.

20
00:03:49,390 --> 00:03:55,120
And if you have any questions, please to free to stop me.

21
00:03:55,360 --> 00:04:02,410
If you have any follow up question after the class, you can contact me through this email address.

22
00:04:03,460 --> 00:04:08,950
So I'm going to firstly, I'm going to introduce some data resources.

23
00:04:09,550 --> 00:04:18,220
The first one is a CDC data website, which is the most proposed and most reliable data resources.

24
00:04:18,940 --> 00:04:34,700
So. So the first thing I provide some are a website that you camp we're answering for or COVID 19 related datasets on the CDC data website.

25
00:04:35,090 --> 00:04:40,790
So it includes like more than 100 datasets in this website.

26
00:04:42,770 --> 00:04:51,530
And I ornelas a few of those. So the first one, the case surveillance data.

27
00:04:57,100 --> 00:05:08,340
It is a database that updated monthly is the most detailed data that I ever funds, and so it's actually individual level data.

28
00:05:08,350 --> 00:05:13,990
So each role will be in the individuals confirmed COVID 19 cases.

29
00:05:14,410 --> 00:05:19,510
So this is has the most the most details.

30
00:05:19,720 --> 00:05:28,330
So the data is actually like with very large size and some data are not public available.

31
00:05:28,930 --> 00:05:36,850
So actually is I believe it should be more than ten gigabytes if your bank.

32
00:05:37,810 --> 00:05:42,440
But it is maybe far more than a tag buys.

33
00:05:43,210 --> 00:05:47,460
So since I haven't thought, I didn't download this dataset before.

34
00:05:47,470 --> 00:05:50,470
So yeah. So it actually can handle things.

35
00:05:50,980 --> 00:05:54,430
So yeah. Yeah, yeah. So yep.

36
00:05:54,430 --> 00:06:04,990
So after provides through. If you cannot do it, you can specify the time window over which you want to download data and split them to subset.

37
00:06:05,020 --> 00:06:09,520
Right? For example, year of 2020 and 2021.

38
00:06:11,190 --> 00:06:20,159
Or you split this entire data into several batches by like the times that you think it

39
00:06:20,160 --> 00:06:26,340
will create a reasonable dataset and offer you get the data and read into our that.

40
00:06:26,340 --> 00:06:36,440
You can extract some variables, you know, somehow relevant and combined summaries, some statistic, right, and combine the raw data together.

41
00:06:36,670 --> 00:06:45,630
So supplies on the way to deal these disputed I bet attempting by adults think is hugely of difficulty for hard to handle.

42
00:06:46,570 --> 00:06:53,490
Yeah. Well, actually it includes like three datasets in this data.

43
00:06:53,490 --> 00:07:09,120
So the first two with fewer were rivals available and the first one with the most data elements are like, you need to request for access to this data.

44
00:07:11,160 --> 00:07:18,990
Like for each dataset, it will provide some brief introduction of this dataset,

45
00:07:19,650 --> 00:07:32,910
including like how frequently this dataset will be updated and it will provide used data dictionary and approve previous tables for this dataset.

46
00:07:33,240 --> 00:07:43,830
So in this dataset, each row is of patients who confirmed COVID 19 are probable or probable cases.

47
00:07:44,250 --> 00:07:51,350
So it will provide informations about is there sex, race and ethnicity?

48
00:07:51,360 --> 00:08:00,180
Yeah. And it will also provide informations about whether they are death because of COVID 19.

49
00:08:02,370 --> 00:08:10,860
So this dataset is the like the most detailed things that we have and we're come to the reality.

50
00:08:11,010 --> 00:08:16,530
You can see a lot of work, see data. Is that you?

51
00:08:16,890 --> 00:08:26,200
Yeah, I have it. But anyway, I think that we want access to restricted data with some permission from the.

52
00:08:26,740 --> 00:08:33,150
The owner of the data. You need to think ahead because this approval process may take some time to complete.

53
00:08:33,660 --> 00:08:42,310
You cannot get the data right away. For example, if you have a plan to analyze something like the first homework asks you to think about write s,

54
00:08:42,510 --> 00:08:46,200
what problems grow to problems you really want to investigate.

55
00:08:46,200 --> 00:08:57,480
But if the your your hypothesis were objective, your analysis requires some data that cannot be accessed, you know, available publicly,

56
00:08:57,870 --> 00:09:05,760
then then you need to really think about how you plan, how to really get the permission to access the restricted data for your project.

57
00:09:06,300 --> 00:09:17,130
So data cleaning takes time, so download the data as soon as possible so you can start to learn how to clean data and build up some pipeline.

58
00:09:20,740 --> 00:09:26,920
Or to use, you know, of some of the of the functions or volumes that you.

59
00:09:28,380 --> 00:09:32,640
Analyze the data that will really speed up your album.

60
00:09:33,000 --> 00:09:41,610
There are novels that are out, so you can see a lot of recent data that you can now derive and put your whatever stats software to do.

61
00:09:41,610 --> 00:09:53,420
You have to do with the data coming in. Oh, if you think like the individual level data is not necessary for analysis.

62
00:09:53,630 --> 00:09:59,060
This website also provides you with a like state level or country level data.

63
00:09:59,450 --> 00:10:07,370
So you also have like more summaries, statistics for sex, less stratified by sex or age group.

64
00:10:07,850 --> 00:10:24,140
So this is an example. So in this dataset, we no longer have individual level data, but we have the, the is the, is the state.

65
00:10:27,970 --> 00:10:37,240
Oh, it's like the country level data, so it will provide you less data stratified by sex age group.

66
00:10:38,790 --> 00:10:41,620
It is updated every week.

67
00:10:43,120 --> 00:10:54,820
So there are like many kinds of like summaries that they'd has for COVID 19 deaths or confirmed cases and just watch on those websites.

68
00:10:55,090 --> 00:11:01,030
So you can also ring it and search for what you exactly need.

69
00:11:01,630 --> 00:11:08,120
And this COVID 19 vaccinations data is also provided by the CDC website,

70
00:11:08,560 --> 00:11:16,600
and it provides detailed state level information of vaccinations in terms of vaccine brands, Pfizer.

71
00:11:16,600 --> 00:11:22,150
But there are not gender and so on age groups and those compliance.

72
00:11:25,360 --> 00:11:28,569
Full vaccination data. There's no subject level data. Yeah.

73
00:11:28,570 --> 00:11:31,850
So it only provides state level data. Okay.

74
00:11:32,350 --> 00:11:39,730
So maybe that individual level of vaccination is regarded as a personal privacy medical.

75
00:11:45,170 --> 00:11:50,070
They level? County only. State level. Yeah. Yeah.

76
00:11:50,300 --> 00:12:01,760
Okay. And so despite the CDC website, we also have another data resources from Johns Hopkins University.

77
00:12:02,060 --> 00:12:05,780
So this dataset is updated every hour, every date.

78
00:12:06,260 --> 00:12:14,810
It provides a clean country level summary data of confirmed cases, thefts as well as state level Western nations data.

79
00:12:15,350 --> 00:12:20,390
So this this dataset is actually very well structured.

80
00:12:20,960 --> 00:12:25,160
You can directly download it from the link provided here.

81
00:12:25,580 --> 00:12:30,050
So you can see that there is a different level of resolution, for example, here.

82
00:12:31,580 --> 00:12:38,300
So you have vaccination data only on a state level, so you also have other information at the personal level.

83
00:12:38,990 --> 00:12:47,209
So you have a lot of personal level. I mean, this is probably a little bit at the data of high resolution and personal mobile,

84
00:12:47,210 --> 00:12:54,470
but you have something at the state level or county level, you know.

85
00:12:58,010 --> 00:13:09,040
So. This. So, you know, you can think of all that the data is giving you a lot of.

86
00:13:11,690 --> 00:13:17,300
Right here. And then, you know, essentially, you know, you.

87
00:13:18,510 --> 00:13:23,610
It's a different level of resolution. But Dana, let's talk yourself.

88
00:13:23,790 --> 00:13:30,629
This is a newer network. I'm very, very detailed resolution to another level.

89
00:13:30,630 --> 00:13:38,760
And this this kind of level could be some of the summer statistics of the aggregation, of the information of the individual.

90
00:13:38,770 --> 00:13:42,390
This is a neural network, right?

91
00:13:42,990 --> 00:13:56,350
Well, of course, that you know, you and I were that. Publicly available and some of their of the architecture.

92
00:13:56,710 --> 00:14:00,090
If you want to predict something at the very end you keep.

93
00:14:06,830 --> 00:14:10,010
But I just I mean, just had done this as well.

94
00:14:10,010 --> 00:14:13,850
I say this kind of resolution, I say is this is really just a new network.

95
00:14:15,310 --> 00:14:20,930
So so what? A revival, of course, is the way it is.

96
00:14:20,960 --> 00:14:29,270
How this, uh, this sort of data structure at different resolution level can be connected.

97
00:14:29,930 --> 00:14:36,380
This can be going from very individual level information to county level.

98
00:14:37,900 --> 00:14:45,760
So. So there is kind of this hierarchical structure and then this information is naturally organized.

99
00:14:46,850 --> 00:14:54,860
Oh, yeah. So. Or you can borrow from this some of the existing software.

100
00:14:58,600 --> 00:15:08,729
One thing I want to mention for this dataset is that actually this oh, this resource center didn't like produce their own data.

101
00:15:08,730 --> 00:15:12,640
They just that is just data from other websites like CDC.

102
00:15:13,110 --> 00:15:16,260
So although they claim that they update it every day,

103
00:15:16,470 --> 00:15:27,540
but if the original data resources like CDC only update their data like weekly so they cannot make it actually updated everyday for this website.

104
00:15:27,750 --> 00:15:45,330
So the data will appears like 000 for a zero new increases for life from sun to sun to Friday's and I'll I'll run out of breath in Saturday.

105
00:15:45,600 --> 00:15:49,770
That doesn't mean that there is actually no cases in the weekdays,

106
00:15:49,950 --> 00:15:56,760
but only the data are the origin though they have resources only update that they data like weekly.

107
00:15:57,630 --> 00:16:03,810
So in this case, if you want to analyze like the weekly trend is totally fine.

108
00:16:03,810 --> 00:16:08,969
You just use this data. But if you want to analyze like the daily trend,

109
00:16:08,970 --> 00:16:18,450
you need to like look into the data and claim that they have first to see if they have like really the daily new

110
00:16:18,690 --> 00:16:34,020
if in fact cases data and the link I highlighted this actually requires the data sources for this JHU data.

111
00:16:34,410 --> 00:16:42,780
So actually it provides like state dashboard for I think for every states in the United States.

112
00:16:43,380 --> 00:16:49,800
So I think this might be a very useful resource sources for you to search for data.

113
00:16:51,720 --> 00:16:59,459
And if all this data cannot satisfy your needs, you can look into the state level data.

114
00:16:59,460 --> 00:17:05,700
So in each state in the United States, they have their online health department.

115
00:17:05,970 --> 00:17:10,320
So they also report some COVID 19 related data.

116
00:17:10,740 --> 00:17:19,740
So I guess two examples here. The first one is the Michigan data and the second one is the Texas data for a second.

117
00:17:19,740 --> 00:17:30,660
One is the reason why I list the Texas data is that when our groups in the last year in this course are tied to apply the ACA,

118
00:17:30,660 --> 00:17:41,760
our models to to to our project, we find that we found that we cannot find recovery data from like most states.

119
00:17:41,760 --> 00:17:51,270
But in Texas the Texas states actually and we find some recovery data so we can we can then fit our science model.

120
00:17:51,540 --> 00:18:03,810
So yeah, so if you want like extra data, you might look into the state level website to search for more data.

121
00:18:05,550 --> 00:18:17,220
And since the statute, this data that is the OH is the is the most useful one or we use this dataset most.

122
00:18:17,580 --> 00:18:22,020
So I have included some data description for this dataset.

123
00:18:22,800 --> 00:18:26,640
So maybe it's too small to show.

124
00:18:26,640 --> 00:18:37,140
But actually the, the data of confirmed cases and test cases and vaccination data have very similar structure.

125
00:18:37,530 --> 00:18:42,450
So perhaps I could just open one with.

126
00:18:42,870 --> 00:18:50,540
Yeah. So this one. Yeah.

127
00:18:50,580 --> 00:18:59,100
Might be easier to see. So actually each row here is state.

128
00:19:00,690 --> 00:19:11,430
So since is the state level data. So it will provide the FIPS code for each state and it will provide the latitude longitude of the state,

129
00:19:11,880 --> 00:19:17,340
the population of the states and the columns are through the population state.

130
00:19:18,180 --> 00:19:27,810
Population column is the number of people getting vaccines is a cumulative number.

131
00:19:29,010 --> 00:19:32,310
So each column is that day.

132
00:19:33,570 --> 00:19:41,520
So this dataset is start from 2020, December the 14th until today.

133
00:19:41,940 --> 00:19:49,230
So we can see actually see a trend from 2020 December two to now.

134
00:19:49,710 --> 00:19:58,740
So this is the basic structure of this data dataset and for for confirmed cases.

135
00:19:58,740 --> 00:20:09,120
This is country level. So instead of having FIPS codes for each state, it's now having FIPS code for each country.

136
00:20:09,450 --> 00:20:16,320
So each row is a is for a county now in this dataset.

137
00:20:19,900 --> 00:20:30,010
Just like ideas come to you. So when you link data, you need to really use this unique sort of ID to link data from different sources.

138
00:20:31,030 --> 00:20:39,910
Yeah. And this two data set like for confirmed cases and death cases are started from a January 21, 2020.

139
00:20:40,720 --> 00:20:55,330
And this one is far later versus the last seen hasn't like the like developed since like this December 14th 2020.

140
00:20:56,110 --> 00:21:03,100
And for the data of recovery cases, we actually no longer have this data.

141
00:21:03,110 --> 00:21:11,470
So considering the fact that most people don't report their recovery and CDC tends to not collect and report such data.

142
00:21:11,770 --> 00:21:13,299
So we no longer have this data.

143
00:21:13,300 --> 00:21:23,620
But if you really need a recovered data, I just suggest to go to the State Health Department website and check is availability.

144
00:21:25,120 --> 00:21:28,650
Yeah. So, yeah, that's it for my.

145
00:21:28,660 --> 00:21:32,830
Sure. And any questions? Yeah.

146
00:21:33,260 --> 00:21:42,350
You have to really go into the deep end and click on the links and really explore and see what information is available.

147
00:21:42,620 --> 00:21:52,520
I mean, in comparison to the data we had before this year, I mean, the CDC upgrade the sort of system to provide the individual level data,

148
00:21:52,850 --> 00:22:00,470
for example, you know, for this kind of infectious disease mode, the fact that some population is elderly people.

149
00:22:00,680 --> 00:22:05,330
So sometimes you really want to see well, even, you know.

150
00:22:09,770 --> 00:22:20,860
But the. We tend to be more likely to be infected or have a higher mortality or something like that.

151
00:22:21,490 --> 00:22:29,630
And also, we know that. Disproportionately higher for their risk of.

152
00:22:31,440 --> 00:22:42,540
But. So so we could look at the data and at the visual level, maybe to now look at the data for the entire country.

153
00:22:42,550 --> 00:22:48,500
You want to focus on Michigan first. That's the place we've probably got a bit more of.

154
00:22:49,640 --> 00:22:53,170
Of demographics and also the situation in the state.

155
00:22:53,570 --> 00:23:01,520
So before you want to do a very ambitious project, maybe you can focus some individual level data industry.

156
00:23:01,940 --> 00:23:06,760
I think that this site will be much smaller. Oh.

157
00:23:07,170 --> 00:23:14,050
Now, maybe we can use a room to watch them and come to you right where we need.

158
00:23:17,890 --> 00:23:25,290
The. To to to see that you do provide individual level data.

159
00:23:27,210 --> 00:23:42,790
Of data set to be given. Okay.

160
00:24:01,130 --> 00:24:05,030
But. No.

161
00:24:06,030 --> 00:24:13,080
The issue here is how we're going to, you know, analyze data to learn something about the.

162
00:24:15,810 --> 00:24:21,000
And that mix of infection and answer some important questions.

163
00:24:32,870 --> 00:24:40,279
So what I plan to do is really construct this kind of dynamic model where I would have

164
00:24:40,280 --> 00:24:45,680
this mathematical modeling structure and then have the statistical model on structure.

165
00:24:45,950 --> 00:24:52,889
And I also want to incorporate the temporal dynamics and the spatial dynamics on

166
00:24:52,890 --> 00:24:58,520
the top so that we have a model that can really crunch the data that you just see.

167
00:24:59,030 --> 00:25:04,610
Of course, there are some issues in data quality that we need to deal with, but overall,

168
00:25:04,910 --> 00:25:15,380
this is kind of a model that we're going to build up over time to help us to understand the stories of the disease.

169
00:25:16,100 --> 00:25:25,550
So I talk about at this simplest sort of as our models, the sensible infected and the cover model.

170
00:25:26,060 --> 00:25:32,570
And this model is built up on three ordinary differential equations.

171
00:25:33,350 --> 00:25:44,209
And I also talk about that the using the probability better than using the absolute number of the cases,

172
00:25:44,210 --> 00:25:55,140
because this probability will help you to sort of deal with the the change in the population size for one dataset.

173
00:25:55,760 --> 00:26:05,680
Lili I mentioned that each state has this number of number of the population that you can use to justify your do.

174
00:26:09,360 --> 00:26:17,810
Okay. So. Well, that's the first model for the company that I would build up.

175
00:26:17,820 --> 00:26:33,870
So you have one compartment that will, you know, take some a new sort of volume of water or volume of you factor individuals into this compartment.

176
00:26:34,410 --> 00:26:42,880
And this I comparable will lose some volume of in fact, the individual to the outer compartment.

177
00:26:42,930 --> 00:26:48,040
So this is a dynamic process, something computing, something going out.

178
00:26:48,060 --> 00:27:01,020
Right. So this minus means something going out. So some individual in the apartment will move out to the outer compartment.

179
00:27:01,020 --> 00:27:15,540
In this rate, gamma and our explained that gamma is the actually the the rate that is linked to the the time someone stay on this compartment.

180
00:27:15,980 --> 00:27:28,020
Oh, okay. So, wow. Gamma is it's that I'm so looking at this first compartment of susceptible individuals, the s compound, the one to begin with.

181
00:27:29,220 --> 00:27:35,670
And this is the subpopulation that the scope of individuals and risk.

182
00:27:35,790 --> 00:27:43,840
Right. Just because here we shown that recovered people were never back to be at risk again.

183
00:27:43,860 --> 00:27:50,940
So that you are constantly. So this compartment consider losing individuals and moving out.

184
00:27:51,060 --> 00:27:55,170
Right. So there is no return. There's always moving out.

185
00:27:55,180 --> 00:28:06,000
So that's why you have minus of the this this dynamic model, the model, the speed of individuals moving out from s compartment.

186
00:28:06,270 --> 00:28:14,400
Okay. And likewise, the for the our compartment, because that's the observing compartment.

187
00:28:15,360 --> 00:28:19,829
People would. They'd come to the compartment, they'd never move out.

188
00:28:19,830 --> 00:28:28,770
So this is the place. Okay. QUESTION So now overall that you added.

189
00:28:30,300 --> 00:28:33,540
Well, this should be equal to zero.

190
00:28:33,870 --> 00:28:36,930
Okay, so the gravity of this should be zero.

191
00:28:36,960 --> 00:28:38,940
Why? Because the total.

192
00:28:39,600 --> 00:28:49,940
So if you randomly sample individual from population, this person is either in the apartment or in the compartment or to our compartment.

193
00:28:50,000 --> 00:28:53,250
Right. So it is not exclusively that.

194
00:28:53,520 --> 00:29:06,270
But if you take a derivative with respect to t, basically you're looking at the the speed of chance or rate of change and the constant becomes zero.

195
00:29:06,420 --> 00:29:15,040
So that's exactly you can see that the the probability, okay, the sum of these three probability would be one.

196
00:29:15,060 --> 00:29:24,430
If you look at the sort of the. The percentage of population of each compartment.

197
00:29:25,150 --> 00:29:31,330
And if you want to use absolute number of of course the sum of this will be equal to total population capital.

198
00:29:31,330 --> 00:29:35,190
N But if you want to work on the probability,

199
00:29:35,200 --> 00:29:46,140
which way I'd like to do then basically then this sum of three probabilities equal to one and the derivative of you to see,

200
00:29:46,630 --> 00:29:54,520
well, this is a balance that you have to sort of enforce in constructing of this system.

201
00:29:54,730 --> 00:30:03,520
So in other words, that this free process, this free sort of these dynamics are not orthogonal,

202
00:30:03,520 --> 00:30:08,950
that they are inter connect to each other through this constraint.

203
00:30:09,070 --> 00:30:14,860
Right? So you have to make sure that this constraint is satisfied because if you randomly sample

204
00:30:14,860 --> 00:30:21,850
individual population dispersing person either in compartment s or in compromise or okay,

205
00:30:22,150 --> 00:30:30,130
so this theta s t base, it tells you what's the chance this person randomly sample, that would be compartment s, so on, so forth.

206
00:30:30,430 --> 00:30:38,260
Okay. So they said that this can be also look at, you know,

207
00:30:40,030 --> 00:30:47,530
this respect to comes in that case that you would have this so towards fixed and

208
00:30:48,220 --> 00:30:52,570
in the literature notation on the cards under the constraint of this equal to

209
00:30:52,570 --> 00:31:00,380
the total population are used extensively so but you might view that as our

210
00:31:00,400 --> 00:31:07,270
model based on probability are magically normalized by time and population size.

211
00:31:07,800 --> 00:31:12,040
And this is more appealing to me when you do modeling.

212
00:31:15,620 --> 00:31:21,469
So the reproduction number or basic production number does something we really want to figure out.

213
00:31:21,470 --> 00:31:26,960
And the beginning, the outbreak of the disease, that's the ratio of beta of gamma.

214
00:31:27,140 --> 00:31:31,790
Of course, the paid on the gala will change over time.

215
00:31:31,850 --> 00:31:32,040
Right.

216
00:31:32,090 --> 00:31:45,620
So because of some of the interventions coming and gamma right, people may start to take medication so they won't stay shorter in the infectious beds.

217
00:31:45,980 --> 00:31:50,270
Well, if there's no medicate, if there's no treatment, right.

218
00:31:50,660 --> 00:31:55,010
Like Pax avoid, then people may need the ten days to recover.

219
00:31:55,340 --> 00:31:59,240
Right now you have medication like Paxil or as such.

220
00:31:59,810 --> 00:32:08,450
The the the duration people stay in the eye compartment will be shorter because people can recover fast, faster.

221
00:32:08,460 --> 00:32:14,840
So it's gonna be a function of medication or some other treatment.

222
00:32:14,930 --> 00:32:18,299
Right. And data is also the transmission rate.

223
00:32:18,300 --> 00:32:23,080
The rate. So how you value individual can in fact most people.

224
00:32:23,690 --> 00:32:32,600
So this can be reduced to when people start to wear face masks or people get vaccinated or people use social distancing, whatever.

225
00:32:32,990 --> 00:32:37,810
Something going out and to intervene. This whole dynamics that beta will change.

226
00:32:38,150 --> 00:32:47,209
So when people look out that the basic reproduction number that really looking at the very beginning outbreak of the disease where people have very,

227
00:32:47,210 --> 00:32:55,730
very little of awareness of what's going on and the people have no idea of to to intervene where to treat.

228
00:32:56,660 --> 00:33:00,170
Okay. So so that's the number, of course.

229
00:33:00,170 --> 00:33:06,880
Very important. We need to figure it out and. And so.

230
00:33:10,640 --> 00:33:17,120
Basically the a look at that the property of this.

231
00:33:17,120 --> 00:33:30,170
Right. So when we have this are zero bigger than one and you know, or our school hours is more than one,

232
00:33:30,440 --> 00:33:34,730
then we have basically different sort of dynamics of the process.

233
00:33:36,040 --> 00:33:43,660
So we can study that, how this R0 will affect this outbreak of the disease.

234
00:33:51,180 --> 00:33:57,900
It's our model because astute interpretation. Okay so so if we back to the.

235
00:34:03,290 --> 00:34:06,400
Which notation I use. Okay.

236
00:34:06,410 --> 00:34:18,350
I used to. Right.

237
00:34:19,000 --> 00:34:24,360
I think I have the equation somewhere. Right.

238
00:34:24,670 --> 00:34:39,580
This one. The first differentiating question that we've been playing to over the past.

239
00:34:51,470 --> 00:34:54,950
They are dynamics full of compartments.

240
00:34:55,070 --> 00:35:04,560
Okay. So now if we look at first sort of a period of time, like what, month or so after outbreak?

241
00:35:04,640 --> 00:35:14,120
Right. So that in this case, the number of the susceptible individual will be roughly equal to.

242
00:35:16,000 --> 00:35:17,590
Or not at all exact.

243
00:35:17,950 --> 00:35:25,660
Some people are very a handful of individual or beginning in fact in the very beginning, but now the very, very crazily large number.

244
00:35:26,020 --> 00:35:29,520
So there are roughly equal the same at the very beginning of.

245
00:35:30,400 --> 00:35:34,690
So in this case, then this essay will become two one.

246
00:35:34,690 --> 00:35:42,270
So you basically approximately. Come on.

247
00:35:42,720 --> 00:35:47,320
It's because of her very close and very game.

248
00:35:47,770 --> 00:35:55,660
All right. Well, now you can factorization also fail to come up over 80.

249
00:35:59,000 --> 00:36:05,149
So that, you know. So so what is the R0?

250
00:36:05,150 --> 00:36:08,570
R0 is the the ratio of theta.

251
00:36:09,170 --> 00:36:13,940
So if you factor eyes six comma.

252
00:36:16,530 --> 00:36:22,250
Right. And this if you if you factor eyes gamma out of this equation, then this.

253
00:36:24,030 --> 00:36:30,580
Our zero. What you get here is essentially that this dynamics.

254
00:36:31,660 --> 00:36:41,210
Right, is very, very similar to the r zero minus one and the common times I.

255
00:36:44,240 --> 00:36:52,580
Well, you can say that if this if this it, you will decreasing this this to it.

256
00:36:55,020 --> 00:36:59,600
First of all, the gravity of the function is negative, then this will be a decrease in function, right?

257
00:37:00,240 --> 00:37:03,240
Or if this is positive that you have increase in function.

258
00:37:03,250 --> 00:37:11,230
So this sign of this, the sign of this is its period determined by if our zero is bigger than one will see.

259
00:37:11,250 --> 00:37:20,370
More on what? Which is not good.

260
00:37:20,490 --> 00:37:28,500
Right. So the larger of our zero, we get our one, then you have more severe, faster increase of the dynamics.

261
00:37:28,560 --> 00:37:41,280
Right. And so you can see that the derivative of t tea is function to your immediate notice that this our it is what is a split.

262
00:37:43,130 --> 00:37:48,740
So you have this. This whole thing determines the rate of exponential function.

263
00:37:49,430 --> 00:37:50,180
And then.

264
00:37:50,190 --> 00:38:05,090
All right, so that this bigger than zero of one or more than the one rate determines that what this the process, this dynamics will look like.

265
00:38:05,210 --> 00:38:16,040
Okay. So that's the very important thing to for for epidemiologists to follow CDC to really figure out when you have this outbreak,

266
00:38:16,220 --> 00:38:20,210
how how much different from one in which way.

267
00:38:22,040 --> 00:38:29,950
But. The disease evolves over time.

268
00:38:30,040 --> 00:38:37,360
Our zero is no longer a be a good quality tool to monitor or to estimate the process.

269
00:38:37,780 --> 00:38:42,370
So what we're trying to do here is we look at effective reproduction number.

270
00:38:42,530 --> 00:38:49,240
Okay. So this is the definition of the effective reproduction number.

271
00:38:49,570 --> 00:38:52,810
Right. So essentially, is this R zero.

272
00:38:53,650 --> 00:38:57,640
Okay. Factor by the the change of this ratio.

273
00:38:57,880 --> 00:39:05,440
Okay. How many people are still in the proportion of people in the s compartment?

274
00:39:05,470 --> 00:39:17,170
So R0 is the basic reproduction number or this basic reproduction number will be factored by actually percentage of people who are at risk.

275
00:39:17,620 --> 00:39:24,250
If this is zero, then the R0 wouldn't be much and it doesn't matter anymore.

276
00:39:24,520 --> 00:39:37,390
But if this is very large, that means you have a very different situation, more sort of a concerning situation.

277
00:39:37,570 --> 00:39:44,950
Right. So so that you need to really is number in this way.

278
00:39:45,950 --> 00:39:52,570
So what you're trying to this is definition, actually.

279
00:39:52,960 --> 00:39:58,810
So basically definition is saying that expected number of newly infected individuals who are virus directly from

280
00:39:58,840 --> 00:40:09,340
continuous individual at the time t o and very beginning we see that because of the NTR roughly the sense of this,

281
00:40:09,340 --> 00:40:14,320
in fact, the reproduction number and the basic reproduction number will be approximately the same.

282
00:40:17,110 --> 00:40:26,590
And our tea is a constant, reflecting its intrinsic degree of contagions of disease itself.

283
00:40:27,100 --> 00:40:31,239
But effective reproductive number describes the progression of the infection.

284
00:40:31,240 --> 00:40:43,150
Disease in the population is a time. So this if in fact if the reproduction number is a number as a function of time, it changes over time.

285
00:40:43,390 --> 00:40:54,540
Yeah. So, so basically it gives you the sort of the of the picture of the progression of the infection disease is.

286
00:40:55,880 --> 00:41:02,180
Every time. And we can see that if they.

287
00:41:04,610 --> 00:41:09,340
Uh, the size of this would be, uh.

288
00:41:13,640 --> 00:41:22,730
I this. Just.

289
00:41:25,920 --> 00:41:34,370
Zero is now read. I mean, let me just rewrite this whole thing.

290
00:41:41,520 --> 00:41:44,750
So I have up.

291
00:41:49,400 --> 00:41:55,160
I. Over and.

292
00:42:01,730 --> 00:42:18,430
I'm a. So if I have this one of a factor in number two.

293
00:42:18,430 --> 00:42:22,930
Fine. And this way. So if I divide it by.

294
00:42:27,160 --> 00:42:35,860
And then this will be my r0 s2 over and will be my of the fraction from top to bottom here.

295
00:42:36,610 --> 00:42:41,560
So then this whole thing will be my r.

296
00:42:45,220 --> 00:42:48,550
Right. And I.

297
00:42:53,160 --> 00:42:59,460
Well now I get exact equality here, which is my rs you see my.

298
00:43:05,360 --> 00:43:09,950
So I would have. So the purposely I have the approximation.

299
00:43:10,610 --> 00:43:14,540
The submission is under this condition. But actually.

300
00:43:15,780 --> 00:43:28,320
Just relaxing number is generalization of my are zero arguments before and allow the to factor this 1 to 2 to change over time.

301
00:43:28,880 --> 00:43:37,970
Allow this to tend to be variable. And I have the same interpretation of this sign.

302
00:43:37,970 --> 00:43:49,460
This bigger than our small one basically tells me the story of the defection, what's going on here according to the acceleration deceleration.

303
00:43:49,550 --> 00:43:58,940
Right. So that will be a good sort of variable to follow over the course of this function.

304
00:43:59,120 --> 00:44:11,090
So the RTT, you can see that the effective reproduction number is very natural concept to be involved in this sort of interpretation.

305
00:44:11,450 --> 00:44:22,490
And to generalize or in the r zero sort of expanding your argument about the direction of this dynamics, because in actual reality,

306
00:44:22,850 --> 00:44:32,210
the direction of the dynamics very important is really the disease of being content to disease is out of control.

307
00:44:32,720 --> 00:44:37,740
It's really saying that, you know, whether or not this is more than one or bigger one,

308
00:44:37,820 --> 00:44:43,190
if this is the are you to use more of what the disease is under control?

309
00:44:43,610 --> 00:44:53,420
The process is decreasing number of in vaccine, number of confirmed cases, or in fact, the cases are decreasing.

310
00:44:53,890 --> 00:45:01,990
This is our is bigger than one day. You still have this sort of situation that dynamics out of control.

311
00:45:02,000 --> 00:45:03,890
So so you need to do something more.

312
00:45:06,790 --> 00:45:15,760
So just looking at the example of the effective reproduction number, which is something very interesting, like people want to figure out in practice.

313
00:45:16,450 --> 00:45:22,060
Okay, so that supposed to the basic reproduction number is 2.5,

314
00:45:22,360 --> 00:45:32,020
meaning that every infected person were infectious person would on average in fact 2.5 people in population.

315
00:45:32,830 --> 00:45:39,040
Our t becomes smaller one and so here here is the other one I just calculated.

316
00:45:39,040 --> 00:45:47,140
Right? So the one that I, I have this example you remember that right here.

317
00:45:47,500 --> 00:46:01,390
So I simulate this from this super model where I have this, the end is 100, as is the one I simulate from from this equation.

318
00:46:01,690 --> 00:46:12,880
It's our equation. I produce this curve so that you can see that the s over and would be simply calculate this is a decrease in function.

319
00:46:13,540 --> 00:46:23,470
And then if there you use this formula our tr0 times the same as a still in.

320
00:46:24,870 --> 00:46:27,060
Which is basically a percentage, right.

321
00:46:27,510 --> 00:46:37,940
So that you can see that this curve is very, very similar to my stick curve, except that now the Y axis is no longer like 0 to 100.

322
00:46:37,950 --> 00:46:47,070
Now this one would be, you know, maximized and 2.5, which is the basic reproduction number.

323
00:46:47,640 --> 00:46:58,320
Right. So so this this reproduction number is upper bounded by R zero because this steel is always smaller, equal to one.

324
00:46:58,650 --> 00:47:09,060
Okay. So that's clear enough. So at the very beginning, your reproduction number is 2.5, which is the basic reproduction number.

325
00:47:09,630 --> 00:47:15,850
But over the time and this reproduction number decrease and then you look at the

326
00:47:16,010 --> 00:47:24,749
the time at which that is r e t this is my r e t becomes smaller becomes smaller,

327
00:47:24,750 --> 00:47:29,880
number one. This is very, very important turning point of the process.

328
00:47:30,300 --> 00:47:36,390
When this process cross the line, one becomes more than one.

329
00:47:36,390 --> 00:47:39,900
That means the disease is going what decreasing.

330
00:47:39,930 --> 00:47:46,649
That's really reflect on the this plot you can see that and the 19 period is not

331
00:47:46,650 --> 00:47:53,520
exactly 20 at the time 19 this number are in fact the disease is decreasing.

332
00:47:54,360 --> 00:48:01,810
Okay. So that this can be also seen in this plot.

333
00:48:01,830 --> 00:48:11,090
That's the plot where you estimate this factor of reproduction number and find this what?

334
00:48:12,340 --> 00:48:15,670
This are eat what you call do once more.

335
00:48:15,940 --> 00:48:21,250
This is a very, very critical controlling point for this dynamics.

336
00:48:21,520 --> 00:48:31,270
If you can make this curve to be small on one and a certain time, then you'll see the light at the end of the tunnel.

337
00:48:31,330 --> 00:48:39,360
So basically so your process can continue, but you know that everything's under control and you can open the stores.

338
00:48:39,370 --> 00:48:46,810
You would like people to go back to school. Everything. This is a very critical point for people to really judge how we're going to do.

339
00:48:47,350 --> 00:48:55,120
Right. So this this is the point that we really want to study in practice and to monitor that.

340
00:48:56,620 --> 00:49:05,589
So another interesting part here is we only work on the first order relative to understand the dynamics.

341
00:49:05,590 --> 00:49:10,180
But if you work on the second order drugs, they ask you to work on the second order.

342
00:49:10,510 --> 00:49:14,470
This will be related to answer a ratio with deceleration, right?

343
00:49:15,100 --> 00:49:23,200
So you have this distance of travel and also we have speed of your car that you drive.

344
00:49:23,440 --> 00:49:35,290
But also during the sort of the driving, you can add more gas to how the acceleration or deceleration, for example, like over the past three years.

345
00:49:35,290 --> 00:49:45,520
Right. When a new variant comes out, we don't have the right protection like vaccination is no manufacturer designed to,

346
00:49:46,360 --> 00:49:51,040
you know, have the antibody for for that particular like variant.

347
00:49:51,400 --> 00:49:58,450
And you can see that at the very beginning of that, you can see the acceleration number of, in fact, cases.

348
00:49:58,870 --> 00:50:08,799
So so for the public health surveillance point of view, when suddenly you see a fast increase of number of confirmed cases,

349
00:50:08,800 --> 00:50:13,120
you will immediately notice that, oh, maybe there's new variant company, right?

350
00:50:13,420 --> 00:50:21,070
So, so you work out the dynamics, not only and the itself, which is not what we're trying to do.

351
00:50:21,370 --> 00:50:27,520
And the whole SRM, although we're looking at, is build out the first derivative of this system.

352
00:50:27,880 --> 00:50:33,490
Basically our interest in modeling the speed of change or incremental of the situation,

353
00:50:34,360 --> 00:50:41,679
but more a sort of also we are interested in modeling the acceleration of deceleration of process.

354
00:50:41,680 --> 00:50:51,730
And then you can see that that was certainly that gave you some ideas how the derivatives will be possible monitored

355
00:50:51,780 --> 00:51:02,680
and provide some additional information to understand that the the well how to see the evolution of the infection.

356
00:51:02,950 --> 00:51:09,340
So why you were called a derivative. Well, some people want to, you know,

357
00:51:10,660 --> 00:51:17,799
estimate this a of reproduction number using some kind of non primitive function

358
00:51:17,800 --> 00:51:25,270
where the the it itself is kind of functional parameter we like to model.

359
00:51:25,900 --> 00:51:41,880
And so, you know, this smoothing spline smoothing supply is the method that people propose in number of measures statistic to estimate a sort of time

360
00:51:42,160 --> 00:51:56,170
parameter for a functional parameter and if you want to use grease robust small since fly in the policy only standard of we know.

361
00:51:56,860 --> 00:52:10,680
Let me put it simply that the we know process then the prior of the we know process is really related to the second work derivative of this number,

362
00:52:10,720 --> 00:52:16,720
much functional. There is a interest from that statistic point of view.

363
00:52:17,020 --> 00:52:24,850
If you want to estimate the the production of you're using some non premature smoothing supply approach,

364
00:52:26,440 --> 00:52:34,780
then you can work work out the second derivative of that functional so that you can sort of use

365
00:52:34,780 --> 00:52:40,540
those reasonable approach to estimate the effective reproduction number number metrically.

366
00:52:42,070 --> 00:52:48,070
But anyway, this is clinically meaningful to monitor in population.

367
00:52:48,220 --> 00:52:54,490
Technically, if you want to do this number measure estimation second order derivative will be involved.

368
00:52:54,750 --> 00:52:56,860
Okay. Okay.

369
00:52:56,860 --> 00:53:08,380
So let me just before we go to all of the sort of the mathematical details, let me just begin with some discussion of the assumptions for our model.

370
00:53:08,560 --> 00:53:11,800
So we are aware of the sort of limitations or.

371
00:53:12,050 --> 00:53:18,440
Were some weaknesses of this small I mean, this small that has was proposed 100 years ago or so.

372
00:53:18,890 --> 00:53:26,660
And there is a very basic model of to to you know, to start in facilities is an early time.

373
00:53:26,660 --> 00:53:32,930
But so clearly there are multiple limitations and we have to really know the

374
00:53:32,930 --> 00:53:38,930
assumptions to understand under which situations we can really use this model.

375
00:53:41,080 --> 00:53:49,090
Okay. So so the basic assumption says that if someone says population involve,

376
00:53:49,090 --> 00:53:56,140
the infection is closed with no additional leakage of individual, namely the size of population figures.

377
00:53:57,100 --> 00:54:07,150
Okay. So this is clear assumption that you have to, you know, sort of aware of this.

378
00:54:08,190 --> 00:54:14,600
So so there's no addition sort of to the population we're leakage of.

379
00:54:15,490 --> 00:54:18,640
So we have kind of a closed door system. Okay.

380
00:54:19,360 --> 00:54:27,280
So this assumption may be satisfied by a epidemic that is rapid and short lived during

381
00:54:27,280 --> 00:54:33,160
which disease evolution is not affected or is minimal factor by vital changes.

382
00:54:33,850 --> 00:54:44,350
For example, natural births or deaths, you know, so those can change the population size and migration, immigration and mitigation.

383
00:54:44,350 --> 00:54:51,879
That would certainly change the population. I mean, for a short period time, you would think that this kind of change is very minimal.

384
00:54:51,880 --> 00:54:57,370
So that with no effect on your population under investigation, that's the first option.

385
00:54:58,540 --> 00:55:07,719
The second assumption for this is our model. Individuals in the population meet each other randomly in that those probably probability,

386
00:55:07,720 --> 00:55:16,110
in degree of interaction with one another remain constant over time, regardless of geographic and demographic factor.

387
00:55:16,120 --> 00:55:23,050
So certainly this is very strong assumption of homogeneity for a strong dynamic system that's

388
00:55:23,110 --> 00:55:30,309
covered by the same transmission and recovery parameter based on the common practice.

389
00:55:30,310 --> 00:55:37,000
Of course, this homogeneity, something can be easily violated, like people live in the same dorm or,

390
00:55:37,480 --> 00:55:44,860
you know, we, we have class in the same classroom or people go to shopping in the same email store.

391
00:55:45,040 --> 00:55:49,180
I mean, so, so so this is, you know.

392
00:55:49,960 --> 00:55:50,860
Yes, yes.

393
00:55:51,070 --> 00:55:59,070
To some extent people meet randomly, but to some other extent, people do not need to random people will have party together on Friday easily.

394
00:55:59,080 --> 00:56:09,430
Right. So they go for you know, you run into your last murder, you know, suddenly you just go to dinner together.

395
00:56:10,020 --> 00:56:14,409
I mean I mean, it's a 100% randomness.

396
00:56:14,410 --> 00:56:20,080
It certainly is not very realistic. But we're talking about mathematical model.

397
00:56:20,080 --> 00:56:31,960
And this is the assumption that we have to put on the S.R. model in order to really do some sort of mathematical analysis or statistical analysis.

398
00:56:32,560 --> 00:56:43,870
So there there is quite a sort of amount of interest in practice how we're going to model histories and that these are genius dynamics.

399
00:56:45,500 --> 00:56:56,810
And this is really active research area in the literature and in fact, is of course, it's hard to track personal behaviors.

400
00:56:56,870 --> 00:57:03,810
Right. So but there are some surrogate surrogate variables you might use, for example.

401
00:57:07,250 --> 00:57:22,220
Some of these and I read the one paper that's quite interesting where they look at the percentage of people voting for Trump versus Biden.

402
00:57:22,730 --> 00:57:33,170
I mean, certainly, you know, that there's two things are not really related, but this attitudes towards one person,

403
00:57:33,170 --> 00:57:42,200
the candidate versus another as a surrogate variable to really reflect like how likely they'll wear a

404
00:57:42,200 --> 00:57:52,530
face mask and how likely they're accept the vaccination or rather the conspiracy of the vaccination.

405
00:57:52,580 --> 00:58:03,229
So there are some variables. I mean, we're talking population, some variables that are not do not directly measure what you want,

406
00:58:03,230 --> 00:58:13,130
but some variables are indirectly reflect something you want to capture in there in terms of its originality in the population.

407
00:58:13,400 --> 00:58:17,510
You can use those surrogate variables in that modeling.

408
00:58:17,540 --> 00:58:26,900
So some people are doing that and not talking about a time temple and special sort of Christian genealogy.

409
00:58:27,200 --> 00:58:32,720
We can pull out other variables and and so, so on and so forth.

410
00:58:33,080 --> 00:58:39,950
Okay. So that people are trying to relax the constant beta into beta t like, you know,

411
00:58:39,950 --> 00:58:48,710
the transmission rate to be time dependent and the recover rate gamma to be time dependent.

412
00:58:49,190 --> 00:58:54,579
Now this becomes a functional parameter, right? Is so you can think about it.

413
00:58:54,580 --> 00:58:58,159
The data is actually a function over time.

414
00:58:58,160 --> 00:59:03,860
So this is become a non parametric a problem estimation problem.

415
00:59:04,490 --> 00:59:18,380
So so you you know, this is very natural way to deal with situation novelty of of infectious dynamics by relaxing constant beta gamma.

416
00:59:19,990 --> 00:59:29,500
Specialty. You can add another argument here, not only time dependent, but also spatially dependent,

417
00:59:29,680 --> 00:59:33,940
you know, so so this will become a two dimensional, functional, right?

418
00:59:33,940 --> 00:59:39,850
So you can add some kind of complexity your like and.

419
00:59:40,480 --> 00:59:43,600
Well, can we deal with that complexity? Yes.

420
00:59:43,780 --> 00:59:51,700
I mean, to some extent, statistic has to drop a lot of two boxes in the atrophy like brain imaging.

421
00:59:52,270 --> 01:00:01,390
And so, you know, the the air pollution and the other like spatial temporal modeling and so on.

422
01:00:02,020 --> 01:00:10,900
And some of this excess in two boxes are maybe up to here to solve this problem, which never thought would be a big deal.

423
01:00:11,650 --> 01:00:20,469
But now we're in this sort of era of the pandemic that we need to really want to have more invested is the method to solve it,

424
01:00:20,470 --> 01:00:25,830
the problem to understand better what's going on so that we can bring in some of the

425
01:00:25,830 --> 01:00:30,880
of the methods never divert order that is the problem so modeling into this view.

426
01:00:33,440 --> 01:00:48,110
So the way you do this kind of mall and this becomes very, very difficult to probably fool apply to mathematicians and epidemiologists because,

427
01:00:48,500 --> 01:00:57,500
you know, if you think about the data, it's time bearing. And so they apply mathematicians, but they always do calibration.

428
01:00:58,010 --> 01:01:04,330
They sort of try like try their luck in some way.

429
01:01:04,340 --> 01:01:15,500
Like, for example, let's say there are like 1 million different types of beta t and see which one is the right one to feed them all dynamics.

430
01:01:15,860 --> 01:01:22,800
So basically. So here is my theory to solve.

431
01:01:23,680 --> 01:01:26,950
So here's my data. So this is observed.

432
01:01:28,200 --> 01:01:32,500
I see. I t observe. Oh, you can plot that.

433
01:01:32,710 --> 01:01:37,500
So from like zero to. Okay.

434
01:01:37,860 --> 01:01:41,350
So you plot this this absurd number of confirmed cases, you know?

435
01:01:42,490 --> 01:01:52,370
Now you'll have to siamo. You believe that this process is generated by bye.

436
01:01:52,400 --> 01:01:56,920
Buy, buy. This is our model. This is our generative model of that generate.

437
01:01:58,180 --> 01:02:03,690
But now the question here is what is to be the T. The big.

438
01:02:05,580 --> 01:02:08,970
I came to the asylum all of you work to get this.

439
01:02:09,330 --> 01:02:12,660
So format applied mass mediations. The of.

440
01:02:13,980 --> 01:02:15,810
Why it's a different type of candidate.

441
01:02:16,770 --> 01:02:26,820
There is some kind of ability and try and all this to kind of recency all this core problem gives the you know the you match some.

442
01:02:27,820 --> 01:02:33,820
A whole different way. We create a likelihood function, object, function.

443
01:02:34,540 --> 01:02:42,150
So we create object function. Lost function of your goodness.

444
01:02:42,760 --> 01:02:50,210
We don't try and. They supply a fixed number of candidates.

445
01:02:50,570 --> 01:02:54,560
We said that the beta team will be just functioning in this space.

446
01:02:54,800 --> 01:02:59,240
We don't go and advise on basis functions, right?

447
01:02:59,270 --> 01:03:04,610
So we just say here is the space or function from which we are going to pick up the optimal one.

448
01:03:04,700 --> 01:03:09,710
We don't want no fixed number of candidates to 12.

449
01:03:10,310 --> 01:03:14,630
We have to say full capability leasing a space or functional space.

450
01:03:20,810 --> 01:03:25,370
Whatever about your function. Feel confident that you're trying to optimize.

451
01:03:29,230 --> 01:03:33,850
Over all the possibilities in this. I just.

452
01:03:34,820 --> 01:03:40,490
Optimal solution. So we have a like different ways to solve the problem.

453
01:03:40,700 --> 01:03:43,760
Right. So. So that's why.

454
01:03:43,790 --> 01:03:47,659
Because the different ways we solve the problem, we have different toolboxes.

455
01:03:47,660 --> 01:03:51,340
For example, we could use posterior, right?

456
01:03:51,350 --> 01:03:59,810
So now some applied mathematicians start to use some seed posterior mode or something because the posterior molar is a,

457
01:04:01,070 --> 01:04:06,590
uh, the optimal solution that achieves the minimal base risk.

458
01:04:07,730 --> 01:04:13,760
Posterior posterior mode is the optimal solution that achieves the minimal base risk.

459
01:04:13,880 --> 01:04:20,150
Right? So that we can calculate the posterior mode because that's opposite of, you know,

460
01:04:20,180 --> 01:04:27,259
optimal solution according to this base risk so that we can use simulation method to

461
01:04:27,260 --> 01:04:33,200
maximize it to find that solution rather than trying different candidate in this solution.

462
01:04:33,290 --> 01:04:38,210
So we have different ways of doing optimization.

463
01:04:38,750 --> 01:04:50,389
So that's why statisticians are more whole see a modern were more sort of cutting edge way of solving

464
01:04:50,390 --> 01:04:57,200
the problem because we're having board toolboxes available for us to solve the difficult problem.

465
01:04:57,900 --> 01:05:01,160
Okay. So assumption three.

466
01:05:10,570 --> 01:05:12,460
So this is also very strong stuff.

467
01:05:12,790 --> 01:05:23,140
So one susceptible individual can only develop immunity or self immunization with antibody against virus through infection.

468
01:05:24,040 --> 01:05:32,660
So there is no involvement in vaccination, this induced antibody by the vaccine?

469
01:05:33,250 --> 01:05:44,740
No. So. So this is. So this ceremonial law, the natural infection is self immune immunization through infection.

470
01:05:44,970 --> 01:05:56,170
Okay. So the eye compartment is only except of the compartment and there is no other state to which at risk individual would move next.

471
01:05:56,890 --> 01:06:10,670
Once recovered from infection, one becomes immune to the virus to the remainder of study period and return to the susceptible situation state.

472
01:06:10,690 --> 01:06:17,830
Okay. So this is like basically saying that the outer compartment is absorbing compartment.

473
01:06:18,160 --> 01:06:23,560
There is no return for a individual who recovered from which is now reality.

474
01:06:23,680 --> 01:06:26,730
This is not true for the core.

475
01:06:27,070 --> 01:06:30,520
There. It's.

476
01:06:33,550 --> 01:06:43,150
So in fact, there's a rigorous definition of recovery to use in smart from a small flowchart.

477
01:06:43,180 --> 01:06:48,480
This implies there's no connection from the art compartment to this compartment.

478
01:06:48,490 --> 01:06:52,990
Namely, the compartment is terminal state of infection dynamics.

479
01:06:54,210 --> 01:07:08,730
So yeah. So basically that the each individual has to go through this sort of multi-stage situation that you one individual has to move from se to I,

480
01:07:08,730 --> 01:07:17,730
that I to r. Okay? There's no way that one can move from S to to r directly back to s.

481
01:07:19,020 --> 01:07:28,020
So the, uh, the validation of the assumption of the copy pad is, you know,

482
01:07:29,400 --> 01:07:35,549
the reality of this option is problematic due to the fact that such a can be repeated.

483
01:07:35,550 --> 01:07:40,320
In fact, it um, so in the whole year 19 literature,

484
01:07:40,320 --> 01:07:49,200
this condition is assumed for certain short period of time over which antibody titers are high enough for protection from the infection.

485
01:07:49,200 --> 01:08:00,610
So and current. The literature says that someone infected by Omen Club usually you have very high antibody titers for three months, right?

486
01:08:00,630 --> 01:08:05,040
So that's the empirical sort of data people.

487
01:08:06,180 --> 01:08:12,780
So basically people have this strong self immunity for three months after you got infected.

488
01:08:13,800 --> 01:08:24,120
So that's something for assumption three, something for infection has zero later appeared in that one becomes infectious once exposed.

489
01:08:24,450 --> 01:08:33,689
This is very also unrealistic assumption where did this re compound model?

490
01:08:33,690 --> 01:08:46,320
There is no incubation period so you move from S to high and so basically in that assigned model, infected is equivalent to infectious.

491
01:08:46,680 --> 01:08:49,709
So that's not actually reality.

492
01:08:49,710 --> 01:09:03,240
Right? So so that there say certainly very sort of important extension in this context that can relax this assumption

493
01:09:03,960 --> 01:09:12,330
to have certain days of latent period so that that basically leads to something called a SETI model.

494
01:09:12,900 --> 01:09:17,760
So as SETI model, you add one additional compartment.

495
01:09:18,870 --> 01:09:28,860
This exposure of that, that's really not a very popular model, very popular extension in the study of infectious disease.

496
01:09:30,150 --> 01:09:38,430
So like many fashion disease, the COVID 19 has a report average incubation period between 4 to 7 days,

497
01:09:38,430 --> 01:09:42,270
which adds some additional complicity in pneumonia fashion.

498
01:09:42,330 --> 01:09:45,970
Is that. Complicity is the.

499
01:09:46,270 --> 01:09:49,720
You don't have data for that. You don't. William monitors.

500
01:09:50,460 --> 01:10:02,410
Of the population about the infection really that when people have symptoms right up your typically typically you are

501
01:10:02,410 --> 01:10:10,060
able to capture an individual with symptoms because when people have symptoms either go to clinic for medical treatment,

502
01:10:10,120 --> 01:10:17,620
where they go to clinic for where some testing center test to confirm whether or not they got the virus infection.

503
01:10:18,220 --> 01:10:23,530
So when they have this early period, the late in pure, they do don't have a symptom.

504
01:10:23,530 --> 01:10:25,000
They feel like a normal person.

505
01:10:25,960 --> 01:10:36,190
They don't have intention or anything that that can drive them to basically go somewhere to see doctors or do some tests.

506
01:10:36,610 --> 01:10:44,040
So you're not able to capture that data. That's very difficult to estimate this sort of exposure period.

507
01:10:44,050 --> 01:10:58,180
But when someone got sick and come to the see doctors and then people can ask when, when, when you feel that your, your, your, your, your, your,

508
01:10:58,240 --> 01:11:00,700
your first day of occurrence, of your symptom,

509
01:11:01,240 --> 01:11:09,370
then a lot of data coming here is from this survey rather than having a some kind of rigorous test taken.

510
01:11:12,220 --> 01:11:15,610
So that's the the difficulty of capturing that data.

511
01:11:15,910 --> 01:11:26,290
So even though you people the e-comm part of the into the model and the parameter moving from SE to is not a very easily I think.

512
01:11:27,430 --> 01:11:36,129
So the there is a technical issue and people talking about some technical difficulty of estimating

513
01:11:36,130 --> 01:11:44,170
that parameter of moving from s to you assumption five because estimate has constant transmission,

514
01:11:44,170 --> 01:11:52,630
the recover parameter are gonna the underlying fashion is to to be evolve in the fully neutral, you know,

515
01:11:53,920 --> 01:12:04,780
mitigation efforts by external interventions like public policy of social distance factor medication or fast testing key for diagnosis.

516
01:12:05,290 --> 01:12:12,790
So there are a lot of things that are happening to come and start to intervene the disease.

517
01:12:13,030 --> 01:12:22,790
So for example, beta can be different when you know there's a fast testing kit for diagnosis.

518
01:12:22,840 --> 01:12:30,969
When people have this testing kit and home that they test positive, then they start to stay in a home right to they isolated.

519
01:12:30,970 --> 01:12:37,510
And so if if then this curve if that person will not have zero testing,

520
01:12:37,510 --> 01:12:47,740
in fact 2.5 or four people because they're in isolated situation, the beta won't decrease when when you have testing kit available.

521
01:12:48,590 --> 01:12:53,900
Of self testing. So so those interventions basically would change the dynamics.

522
01:12:53,960 --> 01:13:03,920
Right. So the the biggest restriction of the are for COVID 19 pandemic.

523
01:13:05,330 --> 01:13:19,310
So the the there are a lot of these control measures imposed by, you know, government across the world.

524
01:13:19,790 --> 01:13:32,240
I mean, you know, that China has very a very rigorous blockage and sort of the the pharmaceutical pharmacological control measure that.

525
01:13:32,780 --> 01:13:41,090
And there are different ways to to do this intervention and to impose the control measures across different countries.

526
01:13:41,510 --> 01:13:46,670
So you can see that the beta and gamma would be different across different countries.

527
01:13:47,960 --> 01:13:55,400
And so people are trying to find different ways to relax this and to see how we're

528
01:13:55,400 --> 01:14:02,450
going to evaluate the effectiveness of the the control measure when it's imposed to,

529
01:14:02,990 --> 01:14:05,120
you know, reduce and mitigate to deal.

530
01:14:10,250 --> 01:14:19,340
Or not or something something sexist, that population size is large enough to have enough number of incidents, including number of infections,

531
01:14:19,340 --> 01:14:28,010
number of deaths and number of recovered cases, so that on our model parameters can be stable to estimate this high precision.

532
01:14:28,550 --> 01:14:34,490
I think this is a important thing that we need to keep in mind.

533
01:14:34,970 --> 01:14:40,520
You know, it's for the model specification by our hand.

534
01:14:40,520 --> 01:14:48,739
What data quality would allow us to really get something meaningful of this,

535
01:14:48,740 --> 01:14:58,010
somewhat contradicted to the need of estimate basically reproduction number R0 and early stage of pandemic outbreak with limited data available.

536
01:14:58,250 --> 01:15:05,780
So I would imagine that idea that so when people have this limited dataset available,

537
01:15:05,780 --> 01:15:18,080
people are trying to find some priors that can be somehow relevant or useful to improve the estimation accuracy.

538
01:15:18,980 --> 01:15:26,570
For example, you can use source data to help you to estimate the sum of transmission rate and recovery

539
01:15:26,570 --> 01:15:33,630
rate for COVID 19 because they are in the same family of the coronavirus as infection.

540
01:15:34,340 --> 01:15:39,830
So because on very early stage, you don't have enough data for you to do very accurate estimate,

541
01:15:40,070 --> 01:15:51,620
having some good prior sort of information prior that you can borrow to help you to impose that, that would be really helpful.

542
01:15:54,380 --> 01:16:04,110
So because this mechanistic model like SRM will ultimately be used for risk prediction, A will train.

543
01:16:04,110 --> 01:16:12,260
The model with reliable data is necessary to not only produce accurate prediction, but also to actually assess the prediction uncertainty.

544
01:16:12,910 --> 01:16:15,170
Well, this is actually the prediction.

545
01:16:15,230 --> 01:16:25,370
Uncertainty is something when we sort of coming to this field, people are always doing this sort of pointed prediction.

546
01:16:25,850 --> 01:16:33,110
But it is a statistic. We know that the confidence interval is more useful than single point estimation.

547
01:16:33,290 --> 01:16:39,470
So how do you build up a prediction interval rather than a, you know, single prediction value?

548
01:16:40,640 --> 01:16:44,060
It's something like very interesting problem to look at.

549
01:16:46,060 --> 01:16:57,400
So going through the two properties, I said, okay, so the size of a compartment state, you know, is a.

550
01:17:00,950 --> 01:17:04,550
Which is treated at a continuous value of the variable in the literature.

551
01:17:04,880 --> 01:17:10,910
Okay. So, so there is no problem because you know that there is a property that.

552
01:17:16,100 --> 01:17:24,979
So if you had some random variable in my mind that follows that plus some random variable from some random integer that a random variable.

553
01:17:24,980 --> 01:17:31,590
Right. Just the meaning of trust when you is going to infinity.

554
01:17:35,040 --> 01:17:42,980
Convert your distribution. And essentially Missouri to prove this.

555
01:17:43,120 --> 01:17:51,840
This is why falls council dissolution of his and mucosal affinity though why will converts to normal distribution.

556
01:17:52,260 --> 01:17:56,640
So this is a mathematical B, so how do we interpret this?

557
01:17:56,650 --> 01:18:01,770
The basically says that if you have integer value data that's very big,

558
01:18:02,130 --> 01:18:09,360
you can simply just press a routine in search of value as a continuous variable like normal distribution.

559
01:18:09,360 --> 01:18:19,230
And that's that's fine. But the problem here is that when you have that the early stage where you look at only the first couple of weeks,

560
01:18:19,590 --> 01:18:33,660
right where you want to really figure out are zero there your eye and are to a very small point the milk the meal is not very much you.

561
01:18:35,080 --> 01:18:43,600
In this case that some people argue that, well, you you you you use normal distribution to do that.

562
01:18:43,600 --> 01:18:50,200
It's little bit inaccurate. Too much approximate approximation error involved in this.

563
01:18:50,830 --> 01:18:56,070
Oh. Feeding into Tivoli because.

564
01:19:03,960 --> 01:19:09,330
Just. You can Google if you can.

565
01:19:09,780 --> 01:19:17,530
You have. So.

566
01:19:21,860 --> 01:19:28,490
So they I don't have time to prove this we can prove is this is proved by the correct theories function.

567
01:19:28,790 --> 01:19:34,400
This is a very famous proof to use the correct first function to prove some thought humanity.

568
01:19:35,900 --> 01:19:39,530
Anyway, I don't want this, but this is fact. So.

569
01:19:39,530 --> 01:19:43,520
So. So the.

570
01:19:44,390 --> 01:19:48,050
What do we usually do here to overcome this?

571
01:19:48,200 --> 01:20:01,970
You know, use the proportions. Okay. That's some advantages, particularly when you work on the data on one stage of that.

572
01:20:06,230 --> 01:20:16,460
Okay. This is good point. So Somalia is supposed to be a dynamics over time and continues over time.

573
01:20:17,270 --> 01:20:21,050
Okay. So although your surveillance state,

574
01:20:21,060 --> 01:20:31,580
our captured database is a weekly basis and you as lawyer just introduced today that you basically said this, it only updated data.

575
01:20:31,910 --> 01:20:45,500
Your database is a weekly basis, but the actually this underlying process is a an underlying dynamics is dynamics continuous over time.

576
01:20:45,980 --> 01:20:49,550
Every single process, the dynamics changes.

577
01:20:49,640 --> 01:20:57,680
Okay. So the but, you know, people trying to scrutinize this dynamics on a daily basis.

578
01:20:58,670 --> 01:21:07,460
So knowing this discrepancy is important because later on, we'll see how we're how our data will be used here.

579
01:21:09,410 --> 01:21:14,910
So the SRM, Somalia is deterministic, does not contain any probabilistic components.

580
01:21:14,930 --> 01:21:18,300
This is a system of differential equations.

581
01:21:18,320 --> 01:21:21,800
It has no stochastic ability is just dynamics.

582
01:21:21,860 --> 01:21:29,570
So basically, we need to be careful to to understand the difference between dynamics and stochastic.

583
01:21:30,110 --> 01:21:46,100
Okay. So the so when we want to do this statistic analysis, these are these sort of the custody that really is issue.

584
01:21:46,130 --> 01:21:52,890
That's why we want to extend that the SRM model to have some additional sampling error

585
01:21:53,150 --> 01:21:58,820
sampling uncertainty so that that we can apply statistical method to analyze the data.

586
01:21:59,180 --> 01:22:04,670
So we can also, you know, deal with uncertainty and red arrows.

587
01:22:08,120 --> 01:22:15,230
So yeah, we talk about some of the modern continuity of the party and i.t.

588
01:22:15,890 --> 01:22:20,540
And talk about of some of the important turning points.

589
01:22:21,230 --> 01:22:25,340
And those are things that we're interested in estimation.

590
01:22:25,650 --> 01:22:38,910
Okay. Doesn't have time to finish all these sighs and yeah, maybe come back next week to finish up the remaining properties.

591
01:22:40,510 --> 01:22:40,700
Okay.

