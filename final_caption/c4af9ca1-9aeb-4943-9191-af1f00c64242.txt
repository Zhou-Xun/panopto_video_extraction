1
00:00:00,420 --> 00:00:04,740
So I am looking for Joey.

2
00:00:04,980 --> 00:00:12,900
Last night I actually uploaded a new model and found this inside on the folder.

3
00:00:13,140 --> 00:00:26,060
So in this module here, I've been updating the world and written about this little group of about.

4
00:00:26,070 --> 00:00:31,530
Well, we added three slides, so I don't to what they are about, about the past.

5
00:00:32,190 --> 00:00:37,700
So let's just write more of these licenses.

6
00:00:38,550 --> 00:00:45,380
It is not how it is. Three. So yesterday we added this bridge lies in the real world.

7
00:00:47,100 --> 00:00:53,160
That will be okay. But anyways, so we can I think maybe it's better if we start from.

8
00:00:54,270 --> 00:01:02,460
Yeah, if we start from here, we, we actually went over this but I think before the exam we do not have to know too much things,

9
00:01:02,520 --> 00:01:04,329
too many things to talk about before,

10
00:01:04,330 --> 00:01:16,370
about the exam so we can slow down another bit to make sure that we, we understand how to carry out a sequence of multimedia crashing.

11
00:01:16,380 --> 00:01:21,270
So let's let's start from here. This is how we went over this.

12
00:01:21,270 --> 00:01:23,910
But I think it's important for us to look at this again.

13
00:01:25,140 --> 00:01:44,550
So as we mentioned in the in the Mongolian reference, I'm only marginally interactive, so let's see who was aware.

14
00:01:44,580 --> 00:01:48,150
This is the virus that we assumed about virus, the capsule.

15
00:01:48,690 --> 00:01:55,229
Everyone ever follows that you can be assumed one number two times on time.

16
00:01:55,230 --> 00:02:01,610
One is assuming that it follows. Let's write in Matrix now.

17
00:02:01,650 --> 00:02:06,450
One is assuming normality was normal with this virus.

18
00:02:06,900 --> 00:02:10,260
But. But in either case, the Cinema Square is unknown.

19
00:02:10,320 --> 00:02:16,170
The virus is unknown. So in order to make an inference, we have to estimate the sequence we're using.

20
00:02:16,170 --> 00:02:24,810
The data we collect as measure of this Sigma Square is very similar to simple linear regression.

21
00:02:25,050 --> 00:02:35,640
So these see the error sum of square, which is defined as the inner part of the residuals or capsule,

22
00:02:35,640 --> 00:02:45,990
have small sums from have divided by adjusted by its you are afraid or divided by your freedom and you are free down here the square of siac.

23
00:02:45,990 --> 00:02:56,850
That's yeah. Minus cheat. The reason that we have this to you now is because here if she is, here she is the number of normal patents.

24
00:02:58,320 --> 00:03:02,340
So we have beta zero theta one beta two of the beta minus one.

25
00:03:02,910 --> 00:03:06,809
So that's why here we have this view of the government where you are.

26
00:03:06,810 --> 00:03:13,050
FREELAND And then the variance,

27
00:03:13,230 --> 00:03:19,860
the estimate of the variance of beta hat and recall that beta ference of beta hat is

28
00:03:19,860 --> 00:03:26,400
given by Sigma Square Times X transpose time x immersed and that's what we calculated.

29
00:03:27,150 --> 00:03:36,520
So this is the variance of beta half. But of course the see my square here is unknown and it needs to be estimated if it was we plant this,

30
00:03:36,590 --> 00:03:45,120
see my hat into this expression we get the the estimate of the variance of beta hat.

31
00:03:45,300 --> 00:03:52,530
So that's why we put a hat over here. And this kind of means that Beatrice is also has major we are estimating the

32
00:03:52,550 --> 00:03:59,310
variance replacing this sigma squared by this see my square sigma has squared.

33
00:04:01,230 --> 00:04:05,600
I see. You see, my house square is given by as I see people based on the work, you know.

34
00:04:06,290 --> 00:04:09,319
So now if you look at this expression here, everything is not right.

35
00:04:09,320 --> 00:04:13,670
You can capture this from the video. You see what had a square Coca-Cola for a million acts.

36
00:04:13,670 --> 00:04:17,300
That is on Netflix. Of course, this is just given by our data.

37
00:04:18,530 --> 00:04:24,560
So this is how we estimate this variance of various and beta hat.

38
00:04:26,210 --> 00:04:30,710
And as we mentioned, so this is a P by P matrix.

39
00:04:30,960 --> 00:04:40,250
So the variance in the estimate of variance a bit I have this is a P by P matrix is divide your matrix.

40
00:04:41,120 --> 00:04:53,990
So that is diagonal elements. These are the estimate of greater rate of zero had variance estimate of beta one simply than zero.

41
00:04:54,900 --> 00:05:03,470
And then there is the estimate of variance of paid out p minus one, paid a P minus one hat.

42
00:05:03,830 --> 00:05:13,520
And these are the bag of elements. So each one corresponds to as long as the variance of the corresponding beta and then the of that going to happen.

43
00:05:14,090 --> 00:05:23,000
Let's say if we look at of it, it's diagonal elements. Then here is going to be the comparison between the data I had and the beta j hat.

44
00:05:24,150 --> 00:05:32,820
This is the i j element of this matrix.

45
00:05:44,040 --> 00:05:50,250
Right that's what this various Colbert's mission this.

46
00:05:54,740 --> 00:06:05,040
Any questions about this? Okay.

47
00:06:05,430 --> 00:06:09,960
And once we gather the various covariance matrix, then we can carry it out.

48
00:06:10,290 --> 00:06:15,809
How will this testing we can test similar to similar calibration here?

49
00:06:15,810 --> 00:06:23,050
We are also in for multiple linear regression. Right? So last time this actually is a way to equal rate.

50
00:06:23,160 --> 00:06:26,430
As a wedge, we regress weight on age.

51
00:06:28,200 --> 00:06:34,200
Weight is equal to zero plus beta one h plus beta treatments that it tight.

52
00:06:38,880 --> 00:06:43,270
Right. This is a michael linear regression that has two covariates.

53
00:06:44,950 --> 00:06:52,059
Now for multiple linear regression. Oftentimes we are interested in testing whether a specific beta is equal to zero.

54
00:06:52,060 --> 00:06:59,740
Let's say we are interested in the effect. The effect on weight not adjusting for height does not.

55
00:07:00,250 --> 00:07:05,650
And we are interested in testing whether this beta zero are beta one is equal to zero or not.

56
00:07:06,190 --> 00:07:13,450
You feel y is equal to zero when is by age? After adjusting for height age, it has no effect on weight.

57
00:07:13,930 --> 00:07:21,490
But if you're beta why is not equal to zero? That means adjusted for height age still has a in fact some effect on all weight.

58
00:07:22,000 --> 00:07:27,630
So beta also we're interested in testing of particular whether a particular beta case equal to zero or not.

59
00:07:28,360 --> 00:07:32,740
And this old business are not, but this is where it has to be better than is equal to zero against.

60
00:07:33,280 --> 00:07:41,649
What can you do zero against beta without a test for any of this for any of

61
00:07:41,650 --> 00:07:47,650
these betas now we can construct has the statistic exactly the same as before.

62
00:07:48,280 --> 00:07:56,620
So the pass the statistic is the estimated beta patch minus as we mentioned last time.

63
00:07:56,620 --> 00:08:00,729
So minus the the value specified under null hypothesis.

64
00:08:00,730 --> 00:08:09,880
But now there has a whether zero or not. So -0 is is equal and then divided by the standard error.

65
00:08:09,910 --> 00:08:17,809
This is the center error and this is actually this various patch beta.

66
00:08:17,810 --> 00:08:22,910
Okay, have this is assuming that you have a corresponding operator, for example,

67
00:08:23,230 --> 00:08:29,560
if there has been a one is equal to zero or not and that's the corresponding this the second element.

68
00:08:33,160 --> 00:08:44,110
So that's what this virus is. Viruses as it is, and the corresponding dynamo element from the various components matrix.

69
00:08:44,650 --> 00:08:52,550
And if we take a square root of it, we get the center out of this T statistic, because under normal policies,

70
00:08:52,630 --> 00:08:57,190
assuming this is true, then it follows tedious fusion with this particular freedom.

71
00:08:58,420 --> 00:09:06,549
And based on this, now we are able to test whether this is equal to zero or not and to the following.

72
00:09:06,550 --> 00:09:17,170
While these this realize there they are just these are the facts that you find on the statement that this was following this volunteer's decision.

73
00:09:17,590 --> 00:09:23,160
But for now, I mean, we want have some facts. We we we have not shown them yet.

74
00:09:23,170 --> 00:09:27,220
So they will be shown later. Now, for now, let's just take this as a fact.

75
00:09:27,460 --> 00:09:32,630
So this statistic, historicity follows t exclusion under the novelist.

76
00:09:33,490 --> 00:09:42,550
Now, in this case that we can follow exactly the same procedure as before, the symbolic expression to to not to test this hypothesis.

77
00:09:42,860 --> 00:09:46,990
Now we can look at, for example, the look you have. And so.

78
00:09:48,390 --> 00:09:53,700
We know that he does fusion as a business, tedious fusion living among his people of freedom.

79
00:09:56,100 --> 00:10:08,679
And then let's say that he is. Now I am going to well, in this case I'm going to put it in here.

80
00:10:08,680 --> 00:10:16,450
So previously we say, oh, what, what? While if he's here that but but but actually he could be here and he could be both positive and negative.

81
00:10:17,290 --> 00:10:23,559
So so let's consider it because here in this case, I say we've got a negative teeth cavity, we got a negative value.

82
00:10:23,560 --> 00:10:32,170
Let's say he's already here and observed that out of bounds and then the p value would be

83
00:10:33,310 --> 00:10:40,390
the area to the left of this observed he and also to the right of that if you t right.

84
00:10:40,420 --> 00:10:46,450
So he's 1997 and also the average for this tell.

85
00:10:48,170 --> 00:10:54,830
At least good health. These are the planets. And so in this case, the p value is equal to the probability that.

86
00:10:56,320 --> 00:11:04,450
Is that probably a natural attitude fusion with A-minus PD or freed up larger than the absolute

87
00:11:04,450 --> 00:11:10,929
value of T because these tools are due to tedious scrutiny to assign it under the lab,

88
00:11:10,930 --> 00:11:14,290
whether it is on or not realizes this. This is the p value.

89
00:11:17,610 --> 00:11:19,780
That is the probably the obvious to health.

90
00:11:21,700 --> 00:11:32,940
And then after you get to the P-value, you can compare it to 2.05 and say, right, if you are if you want to keep your cough, I never had a .05 level.

91
00:11:33,240 --> 00:11:36,540
So then compared to Apollo, it's less than 25.

92
00:11:36,810 --> 00:11:44,610
Then you will reject this null hypothesis and that by concluding that the conclusion would be that, okay,

93
00:11:44,610 --> 00:11:51,570
so the data provides strong evidence, significant evidence showing that a beta one is not able to zero repeated.

94
00:11:51,580 --> 00:11:55,050
Why is significantly different from zero that that's that implies.

95
00:11:56,280 --> 00:12:06,420
But if p value is larger than political five what it means is that the data does not provide significant evidence against anomalies.

96
00:12:07,050 --> 00:12:11,520
So beta k is not significantly different.

97
00:12:13,050 --> 00:12:25,000
So these are the conclusions depending on whether she's out of this mess that we're looking on more than 1.5 and this is what we're got,

98
00:12:25,020 --> 00:12:28,020
at least not if you want to construct a confidence interval.

99
00:12:28,440 --> 00:12:35,310
Now the covenant interval in this case would be theta k hat.

100
00:12:35,340 --> 00:12:47,580
This is our estimated value, right? Plus minus five minus the center error of beta had a k.

101
00:12:48,850 --> 00:12:58,630
Times. This isn't how.

102
00:12:59,840 --> 00:13:11,079
Of. Continuous fusion I because we are looking at this business to sort of accommodate what we are using the .975 this percent

103
00:13:11,080 --> 00:13:24,700
how to use fusion so this is the 95% this is making this clear so this is the 95% confidence interval for for band for.

104
00:13:30,010 --> 00:13:39,330
You're concerned this confidence interval based on this. These are based on the standard error and with the prison panel, that was crucial.

105
00:13:39,660 --> 00:13:46,200
Okay. And then you can look at this confidence interval to see whether it covers zero or not,

106
00:13:46,320 --> 00:13:52,559
whether and zero falls inside or if zero does not fall inside the interval.

107
00:13:52,560 --> 00:13:59,010
If zero is outside to be beta, beta K is.

108
00:14:00,220 --> 00:14:04,930
Significantly different from zero because of the combination of the does not cover zero.

109
00:14:05,320 --> 00:14:09,730
So it's still the case from zero.

110
00:14:09,910 --> 00:14:17,050
But if the zero false inside of this common, you know better means better case not being to do from zero.

111
00:14:18,460 --> 00:14:30,190
So these are how this is how we make Carolina have all this housing based on the piece that to do with multiple unit pressure.

112
00:14:34,870 --> 00:14:48,500
And. Okay.

113
00:14:54,420 --> 00:14:57,570
Okay. So any questions about this?

114
00:15:04,140 --> 00:15:04,440
Okay.

115
00:15:06,750 --> 00:15:17,670
And then the interpretation is, in the end is whether the cave variant of the cave Coolgardie doesn't mean it has to be the case equal to or not.

116
00:15:17,670 --> 00:15:27,330
Right. So whether it's covariate is associated with the outcome, adjusting for it, controlling for all the other categories included in the model.

117
00:15:27,340 --> 00:15:36,930
So this is very important for linear regression where we look at a particular covariate and the effect is always after controlling,

118
00:15:36,930 --> 00:15:42,440
after adjusting for all the other. So this, this lists, this part of the settlement is very important.

119
00:15:42,720 --> 00:15:52,230
So without saying this, if if if you if you ignore this, then the state, then people might buy the thing.

120
00:15:52,230 --> 00:15:58,370
Actually, you are simply feeding on a simple regression model because you are doing the same, adjusting for anything.

121
00:15:58,380 --> 00:16:02,730
Right. So in order to make it clear we have the same existing,

122
00:16:02,730 --> 00:16:09,570
we're controlling for the uninvolved areas in the model or holding all of the other communities constant.

123
00:16:14,060 --> 00:16:18,440
Okay so that's the t this go to Pete has been Peter's vision.

124
00:16:21,500 --> 00:16:29,660
And then we are able to now for a simple linear regression, we talk about both T test and F test.

125
00:16:31,530 --> 00:16:40,020
And back then we saw that the kid has an outcast. They are they are they are equivalent in testing to hypothesis.

126
00:16:40,200 --> 00:16:41,940
If you go back to the slides, you will see that.

127
00:16:42,360 --> 00:16:50,220
So kid had, whether you use tap for testing to subdue hypotheses by their use to test or out test, you will get the same exact same conclusion.

128
00:16:50,640 --> 00:16:56,280
But we also mentioned that the cheat has to can test one sided hypotheses and

129
00:16:56,280 --> 00:17:01,440
test and was only for it was only an idea for multiple linear regression.

130
00:17:01,470 --> 00:17:05,270
We will see that the kid has an outcast. They become different.

131
00:17:05,940 --> 00:17:15,090
They do. They test different things. Now, let's take a look at what our past is and what the differences between what has been asked.

132
00:17:17,010 --> 00:17:24,900
So again, here, well, in order to introduce our test, we need to talk about we need to decompose some of the squares.

133
00:17:26,100 --> 00:17:29,969
This is very similar to multiple symbol linear regression.

134
00:17:29,970 --> 00:17:35,400
We call that a simple linear regression. We want pure mean no matter whether we are looking on a symbol or model.

135
00:17:36,330 --> 00:17:43,290
So the total sum elsewhere, this is total sum of squares and this is sum of squares, y minus y bar.

136
00:17:43,710 --> 00:17:52,110
This is total sample squares. No matter whether similar to the world over here, this is always defined in the same way.

137
00:17:52,590 --> 00:17:59,560
All small squares and total sample squares can be decomposed into regressions, almost squares in error.

138
00:17:59,580 --> 00:18:08,909
Some squares. This is simply by subtracting y I have and I can actually back what I had again separation of squares.

139
00:18:08,910 --> 00:18:14,090
So if you combine those two and those two and then separating the square to the edge,

140
00:18:14,550 --> 00:18:24,120
if you combine a certain term for internal will cancel and then in the end you have it and it is equal to this plus this.

141
00:18:24,900 --> 00:18:31,560
And in the first part, this is why I minus the predicted, what does it mean?

142
00:18:31,770 --> 00:18:39,450
That's why I had. And then the sum of squares that's called an error sum of squares, because it look has look, look,

143
00:18:39,450 --> 00:18:46,679
looks at how far away your predict what the predicted Y based on the model how far that is from your

144
00:18:46,680 --> 00:18:56,159
truly observed true observed Y so so that this is actually error and this is predicted by our model.

145
00:18:56,160 --> 00:19:01,440
This is as we observed that I can do this to best.

146
00:19:02,460 --> 00:19:09,510
So this is the horizontal square. And again, this is the this is the so-called regression, some square SSR regression sample square.

147
00:19:09,750 --> 00:19:19,770
So if you look at looks at how far away your predictive value is from the model, but that's not a content any covariance.

148
00:19:20,190 --> 00:19:25,799
So basically one bar. So this is a regression solution and this is just algebra.

149
00:19:25,800 --> 00:19:33,930
So you can if you are interested, you can, you can just fill out your fill in the gaps, the steps we we all needed.

150
00:19:34,140 --> 00:19:41,490
You can check this out. So the total sum of squares is equal to the error sum of squares plus regression sum of squares.

151
00:19:42,600 --> 00:19:53,360
This, this is just some algebra. And we can interpret this SSR as the variation.

152
00:19:54,020 --> 00:19:58,009
This says Why is the total variation? Why the total variation?

153
00:19:58,010 --> 00:20:02,870
Why the SSR is the variation that can be explained by your regression model.

154
00:20:02,990 --> 00:20:09,290
So you build a regression model and you are trying to use the model to explain why.

155
00:20:09,670 --> 00:20:15,720
So you are trying to use, for example, age and height to explain people's weight, right?

156
00:20:15,770 --> 00:20:20,540
So you see different people. We have different weights. So we are trying to use people's age and height.

157
00:20:20,540 --> 00:20:29,059
Please put on weight and then ask us are these the variation in the in that you are in

158
00:20:29,060 --> 00:20:34,730
the weight in the response interval weight that can be explained by a regression model.

159
00:20:34,730 --> 00:20:39,950
So your model can explain part of the variation, but I cannot explain everything.

160
00:20:39,950 --> 00:20:45,560
Right. So, so what the part of that I cannot explain cannot be explained by a regression model that is,

161
00:20:45,680 --> 00:20:49,070
as I see, this is a residual variation not explained by the model.

162
00:20:51,920 --> 00:20:55,750
So this so this is just a, you know,

163
00:20:56,450 --> 00:21:03,920
to decompose the total variation into the part of that can be explained about the model in the part that cannot be explained about the model.

164
00:21:07,430 --> 00:21:12,740
This is exactly the same as similarly, there is no difference here.

165
00:21:15,620 --> 00:21:18,680
But now the effort has. Now is.

166
00:21:20,150 --> 00:21:24,330
Is. Okay.

167
00:21:24,330 --> 00:21:28,680
So it's not different from similarly mutilation, but but that is different from t test.

168
00:21:28,920 --> 00:21:32,910
So recall that the key past. Let me make this very clear.

169
00:21:54,950 --> 00:22:01,160
So testing individual running coalitions. And this is done by using a key test.

170
00:22:01,970 --> 00:22:05,270
So by calculating key statistic in beta, okay.

171
00:22:06,260 --> 00:22:11,510
And divided by various particles divided by center in a row.

172
00:22:16,180 --> 00:22:21,010
This is this. Follow. T-minus cheating. Do not let us.

173
00:22:23,560 --> 00:22:29,080
And sorry. So I may get a super clearance of that.

174
00:22:48,240 --> 00:22:56,250
In a way it has that individual Reagan coalition. That means testing whether this particular any particular bit hay is equal to zero or not.

175
00:22:56,880 --> 00:23:00,620
And so here I only would rule down the null hypothesis.

176
00:23:00,630 --> 00:23:05,430
I didn't write down the alternative because you can test against whether Berocca

177
00:23:05,430 --> 00:23:09,150
is not able to zero for longer than zero will be again smaller than zero.

178
00:23:09,480 --> 00:23:14,610
So you can the alternative can alternative hypothesis because it is fine in different ways.

179
00:23:14,610 --> 00:23:20,550
But not what this is, is always that Peter can't keep from zero. Now for testing this individual bit.

180
00:23:20,560 --> 00:23:23,940
Okay, well this individual bit. Okay. Is equal to zero or not.

181
00:23:24,660 --> 00:23:36,000
That's T test. So the T test is used for that purpose for individual whatever sized for this individual rubric these.

182
00:23:39,130 --> 00:23:42,940
But we have a test, a test, a deeper thing.

183
00:23:42,940 --> 00:23:48,550
So it actually tests whether all the coefficients there are equal to zero or not.

184
00:23:49,600 --> 00:23:59,920
So we call that a model regression. So if you model regression we have, this is not a good practice.

185
00:24:27,100 --> 00:24:35,860
This is what Moneyball regression. And so we have we have a molecule a cobra's exon or we have multiple betas.

186
00:24:37,660 --> 00:24:46,330
And if past is that it is a test to test whether all the collisions are simultaneous and equal to zero.

187
00:24:47,290 --> 00:25:01,209
So the the logic or rationale behind those is that we are as we're trying to test whether this whole thing is related to one,

188
00:25:01,210 --> 00:25:05,140
because this is how this fits on your model, your space on this model.

189
00:25:05,170 --> 00:25:09,640
You are seeing that. You are thinking about where you are believing that,

190
00:25:11,410 --> 00:25:19,390
or at least you are assuming that these X are somehow they are associated with this one or they may be associated with this one.

191
00:25:19,480 --> 00:25:24,690
And that's the reason why you see this at such a moment. You're seeing that some of these acts, they are there.

192
00:25:25,030 --> 00:25:29,020
We have we have in on what they are associated with.

193
00:25:32,200 --> 00:25:39,010
And that past is as we has them, whether indeed any of these is associated with that, with this one.

194
00:25:40,480 --> 00:25:46,660
So in other words, the not of this is is that none of the covariates explain that relation one.

195
00:25:47,410 --> 00:25:57,400
So in other words, none of these covariates, you included, really has any association, has any meaning or association with one.

196
00:25:58,570 --> 00:26:10,750
So that's what the F test is, testing versus H one, the alternative, but at least at least one covariate, excluding variation one.

197
00:26:15,640 --> 00:26:19,540
So that in terms of the regression coefficients, the F test.

198
00:26:29,170 --> 00:26:35,480
The nub of this is. Is that. Beta one is equal to zero.

199
00:26:39,260 --> 00:26:47,090
So all these beta beta y is equal to. Beta to is equal to a few minus one is equal to zero.

200
00:26:47,930 --> 00:26:51,290
So it's testing. All these betas are equal to zero.

201
00:26:51,530 --> 00:26:54,830
Here are well here. Notice that there is no intercept.

202
00:26:54,890 --> 00:26:56,900
So we are not really increasing the intercept.

203
00:26:57,320 --> 00:27:04,550
So we're parsing whether for these beta collisions, for this different covariance, for different x, whether they are equal to zero.

204
00:27:05,030 --> 00:27:10,880
And this this null hypothesis does not include beta zero, doesn't care about the intercept.

205
00:27:13,090 --> 00:27:21,080
So its past and whether the Beatles or these only Steve or Clarence, whether they are equal to zero,

206
00:27:21,180 --> 00:27:25,840
all of them are equal to zero versus, you know, versus the alternative.

207
00:27:29,210 --> 00:27:40,990
Versus the alternative that. At least one of the one witness who.

208
00:27:43,520 --> 00:27:48,080
Even if he one is not. It's not easy.

209
00:27:56,150 --> 00:28:05,770
But if we look at what this hypothetical novelist and her publicist means, so we are actually testing whether the model used space flight.

210
00:28:05,830 --> 00:28:11,530
This is the motto of spaceflight and using this x gizmos whether the mother is flying.

211
00:28:14,970 --> 00:28:20,040
Why does that? I can't explain sort of some association.

212
00:28:20,800 --> 00:28:26,250
Well, whether whether the motive is based, that whether this park has has any association with one.

213
00:28:26,310 --> 00:28:31,880
So that's what we have so that no one believes us, that there is no association.

214
00:28:31,890 --> 00:28:38,400
So the model you specify basically has no power at all, has no association with that,

215
00:28:38,400 --> 00:28:45,840
with a response like but I've heard you assess that at least one meter is not equal to zero without at least I mean,

216
00:28:46,380 --> 00:28:50,400
some, some part of your models actually is associated with the line.

217
00:28:50,880 --> 00:28:51,900
And can you explain one?

218
00:28:52,230 --> 00:29:02,520
So this is the testing the overall you can think of this as testing the overall performance of the model and overall goodness of the model.

219
00:29:02,790 --> 00:29:16,130
Like whether this component you specify here, whether that's that's has has has any has any power or has any association with the response one.

220
00:29:17,250 --> 00:29:21,240
So that's what the test is now for.

221
00:29:21,480 --> 00:29:24,710
This is the answer. The difference between is she has an impasse, right?

222
00:29:24,720 --> 00:29:31,110
So she has that for a single coefficient capacity, whether particular been AKC were there or not.

223
00:29:31,620 --> 00:29:37,070
But our test thus testing whether all these feeder case, you know, simultaneous is equal to zero.

224
00:29:37,080 --> 00:29:42,720
Right. Now, of course, for simple linear regression, if you recall simple linear regression.

225
00:29:47,180 --> 00:30:01,940
Now a special case is somebody near. The simple, intuitive why I relate a zero speed on one side.

226
00:30:01,940 --> 00:30:06,860
Plus I was like someone in no rush. Now for a simple linear version, of course.

227
00:30:07,690 --> 00:30:12,920
Now, if you'd has is testing whether beta one is equal to zero or not.

228
00:30:15,080 --> 00:30:19,380
Yeah. And test is also testing whether in a one is equal to zero.

229
00:30:19,650 --> 00:30:29,480
All right. So in this case now because we only have one three, I'm sorry to beat up on, but but only one covariate only.

230
00:30:29,900 --> 00:30:42,990
So in this case, she passed and our test was.

231
00:30:43,220 --> 00:30:49,750
All right. Let's get about. So in this case, for testing.

232
00:30:52,750 --> 00:31:01,870
This novel as it was versus alternative that's based on one not able to do it because

233
00:31:01,870 --> 00:31:06,520
we only have one beta one for pursuing this null hypothesis so we can apply.

234
00:31:10,730 --> 00:31:15,670
False that he'd asked. And at that.

235
00:31:20,290 --> 00:31:24,230
Right in this case. That's that's why we sat about in this case testing this.

236
00:31:25,010 --> 00:31:29,930
Now, how about this versus this alternative? Each one of you has an impasse.

237
00:31:29,930 --> 00:31:32,600
They are equivalent. You can apply either one.

238
00:31:32,630 --> 00:31:39,140
You will get exactly the same conclusion that the best for somebody or a rational person that's for testing.

239
00:31:39,390 --> 00:31:45,799
You know, when you only have a single X single covariate in the model now for model regeneration,

240
00:31:45,800 --> 00:31:51,110
when you have multiple valence, now you has an ad, it has to be different.

241
00:32:00,370 --> 00:32:14,850
Okay. Any questions? She has not passed. Oh.

242
00:32:15,370 --> 00:32:23,430
Oh. And another thing I want to point out is that now here we see that we can apply bolted has an outcast

243
00:32:23,760 --> 00:32:31,320
that's actually for posting this to have a lesson against this alternative against a two sided alternative.

244
00:32:33,010 --> 00:32:39,940
Because F as we measure F is the square of t f, but if we if we take a square of T run the variable,

245
00:32:39,940 --> 00:32:44,050
we get an F for the variable, look the numerator, the growth rate of equal to one.

246
00:32:45,460 --> 00:32:54,460
But if you change this alternative to a one sided, let's say you're testing whether beta one is equal to zero versus beta one is larger than zero.

247
00:32:55,740 --> 00:33:01,799
In that case you will need to use a sheet, has antacids and has to work long work.

248
00:33:01,800 --> 00:33:05,820
In that case, antacids is always for a two sided hypothesis.

249
00:33:19,240 --> 00:33:23,050
And that's not for Av-Test.

250
00:33:25,280 --> 00:33:32,409
In Russia, Russian, Ukraine, on the roof of the plane, you will get so close to the table.

251
00:33:32,410 --> 00:33:37,190
We have seen this table for a symbol in Russia. Now, let's take a look at this table again for a moment.

252
00:33:38,690 --> 00:33:41,900
But people's character is exactly the same as similar in Uruguay.

253
00:33:42,860 --> 00:33:52,760
Exactly the same. Part of what will change are the freedoms for four, four different all squares.

254
00:33:52,790 --> 00:33:58,370
Now, let's take a look at this. Now, let's let's try to fill out a smaller this table.

255
00:33:59,060 --> 00:34:03,080
So we have total sum of what? This column here. This is the sum of squares.

256
00:34:03,920 --> 00:34:07,069
And we have as we mentioned, we have total sum of squares, areas almost.

257
00:34:07,070 --> 00:34:14,570
We are involved in most of the right side. Yes. So the total sum of squares, that's that's absolutely right.

258
00:34:14,990 --> 00:34:20,810
So what if you want one book?

259
00:34:22,520 --> 00:34:34,009
This is the Pluto's office with. Maybe I'll just write it because I don't want to take up the space from the second column.

260
00:34:34,010 --> 00:34:40,180
So this is. This is total sample squares.

261
00:34:40,750 --> 00:34:54,550
And then there are some old squares, as I see that's equal to one minus white square, and that's ever some of the squares.

262
00:34:58,570 --> 00:35:03,760
And then we have the model sample square that's done as is are not Osama's squares.

263
00:35:18,090 --> 00:35:26,990
That's the most on the squares. And then we have the associated with our freedoms for this, for example, squares.

264
00:35:30,810 --> 00:35:34,520
Two four kudos almost where I thought you were three that we still get minus one.

265
00:35:38,240 --> 00:35:52,750
Is two imams, one. The reason is that, you know, we are using again, we are using the data to estimate this way bar so we lose one degree of freedom.

266
00:35:53,170 --> 00:35:59,440
So that's why we have fewer freedom is and minus one now for errors almost square is the degree of freedom is a lot of people.

267
00:36:01,540 --> 00:36:11,450
And let's it. The reason is that we are using now when we estimate this white hat we are putting in our model, we have she beat us.

268
00:36:11,750 --> 00:36:17,560
So we need to estimate I know how to win is that is that you work for them means that amount

269
00:36:17,570 --> 00:36:21,470
as chief and then the model you are freedom that's just difference between those two.

270
00:36:21,740 --> 00:36:31,250
So that's she minus one. So this is t minus what you were afraid of the models on the squares.

271
00:36:32,090 --> 00:36:38,510
And then this and this. This is the mean sum of a mere sum of squares.

272
00:36:39,110 --> 00:36:39,650
I'm sorry.

273
00:36:40,250 --> 00:36:49,310
This means squares are some sort of new square, and then the mean square is simply the corresponding sum of square divided by we are due our freedom.

274
00:36:49,760 --> 00:36:58,160
So here, for example, for models of square root for regression, that's.

275
00:37:00,510 --> 00:37:11,670
And as are equal to Festivus. Kahn. If I had to minus one, the history of freedom and then amnesty is equal to siac divided by history.

276
00:37:12,420 --> 00:37:16,740
Come on the cheap and give up then.

277
00:37:17,370 --> 00:37:26,160
And as total say y is equal to as s y divided by its d more freedom and minus one.

278
00:37:30,490 --> 00:37:36,670
Okay. So this is what we called the mean of the square.

279
00:37:37,600 --> 00:37:42,980
And then what this means where this column we are able to calculate an F statistic.

280
00:37:43,450 --> 00:37:52,570
But that statistic is actually calculated as m s r divided by M and as E.

281
00:37:54,170 --> 00:37:59,900
MSR did not do that. I must see. So it's actually you guys over here.

282
00:38:00,740 --> 00:38:10,730
This is the F statistic because MSR is SSR divided by Pima as one reason and ML sees as is the amount of m on this feeling of freedom.

283
00:38:11,060 --> 00:38:14,420
So that is how s statistic is calculated.

284
00:38:16,990 --> 00:38:23,090
If you look at it, well, it is interpretation.

285
00:38:23,320 --> 00:38:29,410
It's just compare the sum of squares from the model to assign a square of.

286
00:38:30,280 --> 00:38:34,120
But of course, adjusting for each small square by their own bigger freedom.

287
00:38:35,170 --> 00:38:40,720
So you compare this to and then, of course, if your model is very good, you have it.

288
00:38:40,900 --> 00:38:48,280
If you have a very good model, then this part should be fairly large compared to the error or the model

289
00:38:48,280 --> 00:38:55,680
somewhat square should be very large to compare to the error somewhat squares. Then you have a friend, you have a fairly large s not hosting f them.

290
00:38:56,770 --> 00:38:58,780
But if your model is is poor,

291
00:38:58,780 --> 00:39:06,550
you build a few poor model by poor auto would mean that your model does not really explain the variation what promote them.

292
00:39:07,300 --> 00:39:17,020
And then the model somewhat squares compared to Arizona squares is going to be very small because you do not explain the liberation wide enough.

293
00:39:17,320 --> 00:39:22,750
So the whole the variation, what we're model variation, what we actually go to the error sample squares.

294
00:39:23,020 --> 00:39:26,230
So in that case that F value will be small.

295
00:39:26,530 --> 00:39:36,700
You have a very small then so so large F value indicates that you have a good model and small F value indicates that your model is poor.

296
00:39:37,090 --> 00:39:45,120
Right. But how large is large? And I would like how do we summarize the result and we summarize results by this P value?

297
00:39:45,340 --> 00:39:49,090
P value is actually the probability that the F.

298
00:39:51,330 --> 00:39:57,059
The F decision in this case with P minus one and minus PD one.

299
00:39:57,060 --> 00:40:05,970
Freedom is larger than observed after ballistic SM under monopolists.

300
00:40:06,360 --> 00:40:11,700
This is why the p value is so what it amuses.

301
00:40:11,820 --> 00:40:17,820
While graphically you recall a few dos during orgasm and this was without this fusion has had such.

302
00:40:19,020 --> 00:40:29,589
This is what our news fusion looks like. Of then suppose that in your F you observe f so it is to hear another F not at

303
00:40:29,590 --> 00:40:34,330
least get a business the F disposable and p minus one and implies P or freedom.

304
00:40:36,160 --> 00:40:41,200
And another p value is as to the error to the right of this observed f.

305
00:40:44,490 --> 00:40:55,920
And so then. A large p value like our large value means that your f the f value, the observed value is kind of small.

306
00:40:56,100 --> 00:41:00,960
So if your f is small than ed for this f is is large.

307
00:41:01,680 --> 00:41:11,430
And so if you have a small, if you have a larger p value, then these are a small F that you fail to reject the novels.

308
00:41:11,460 --> 00:41:15,780
It's not a lot. This is that all these measures are equal to zero.

309
00:41:16,320 --> 00:41:20,240
This is not worth the other words. You have a poor model.

310
00:41:20,550 --> 00:41:24,180
So because all of those should be equal to zero a business model.

311
00:41:24,750 --> 00:41:30,120
But. But none of this better is is not zero so then means honored.

312
00:41:30,120 --> 00:41:39,060
I have it is it's not what this is sense value model if you are considering simpler model so if you have a large p value,

313
00:41:39,090 --> 00:41:44,280
if you have a small F small house then hosting that means you have a large.

314
00:41:44,280 --> 00:41:47,960
If you have it, then you fail to reject or not have a business.

315
00:41:48,960 --> 00:41:58,890
And so so that's actually not means the data has evidence showing that the problem is is not against the models.

316
00:41:59,640 --> 00:42:09,360
So here I'm not sure whether, you know, we have I hope that this logic behind this is is clear.

317
00:42:09,360 --> 00:42:11,500
So here I am.

318
00:42:11,700 --> 00:42:25,250
I cannot write everything down, but I try to explain that the logic behind the not how how our test works and so on, if we have a small F,

319
00:42:25,260 --> 00:42:35,730
that small absolute holistic value means this model for regression error regarding sample square is small compared to errors on the square.

320
00:42:36,120 --> 00:42:38,580
So that means your regression model is a poor model.

321
00:42:39,480 --> 00:42:47,190
And in the end, if this is one, if this is small, then you have a large area to the right of this afternoon that means a large p value.

322
00:42:48,300 --> 00:42:52,140
When p value is large, we will not reject liabilities.

323
00:42:53,220 --> 00:43:03,540
That means that if we do not a region of losses, that means indeed your model does not have much power in explaining about regime one.

324
00:43:04,140 --> 00:43:07,740
So that's what happens when the cap statistic is very small.

325
00:43:08,580 --> 00:43:10,830
But what F is very large?

326
00:43:11,700 --> 00:43:22,350
What F is very large that it means the sum of squares from the model is large compared to the sum of square of s in that case.

327
00:43:22,980 --> 00:43:30,240
Now if F is large, then anywhere to F is small to the right of F that's small.

328
00:43:30,450 --> 00:43:34,140
So you have a small p value, a small p value.

329
00:43:35,340 --> 00:43:38,940
If you have a small p value that you will reject this nonsense.

330
00:43:41,010 --> 00:43:43,440
Smart people willing to the it does not exist.

331
00:43:43,920 --> 00:43:52,590
But that means well, your motto is not so bad because at least if you are this novelist, then that means at least some beta.

332
00:43:53,040 --> 00:44:01,299
It's not beta nine zero. And so then that means you're doing all these things and it's okay.

333
00:44:01,300 --> 00:44:08,730
Life is not too bad moment. And whether the p value is large or not large enough or not, that's to .05.

334
00:44:08,940 --> 00:44:13,910
Compare your p value 2.5 and then decide whether to generalize.

335
00:44:15,900 --> 00:44:19,170
So this is how we apply the F test.

336
00:44:20,400 --> 00:44:29,190
So you can see that how we summarize our data in the end by the absolute hosting and eventually by this P value.

337
00:44:29,610 --> 00:44:41,820
But all of course in our data we have this in rules like, you know, like P columns, people as one positive response and also the P and covariance.

338
00:44:42,180 --> 00:44:44,730
So we have an M by P matrix and that's our data.

339
00:44:45,630 --> 00:44:51,540
And then by calculating the model regarding ensemble squares, there is almost gross total sum of squares.

340
00:44:52,080 --> 00:45:01,559
And then in the end we summarize the data by this absolute usdc is just original and then it's a single so about absolute host and

341
00:45:01,560 --> 00:45:09,990
eventually we summarize the data by this she out again it's just a single number and then based on that single number that a summary.

342
00:45:10,530 --> 00:45:13,920
Now the P value summarizes all the evidence in the data.

343
00:45:14,340 --> 00:45:23,090
Well, that's against a lot of other things or not. So then we make our conclusions based on those final summaries plus.

344
00:45:29,320 --> 00:45:40,690
Any questions about this? Okay.

345
00:45:41,500 --> 00:45:45,900
So that's. All arms passed.

346
00:45:49,470 --> 00:45:53,970
And okay, so then the next target is actually the coalition of determination.

347
00:45:53,970 --> 00:45:59,370
This is our where Andrew went over this slide with these three slides about out of our past.

348
00:45:59,580 --> 00:46:08,130
This is the new slides we added. And then this slide to the our square coalition of the Determined Determination.

349
00:46:08,340 --> 00:46:12,810
We actually remember this slide in our last lecture, but let's go over this again.

350
00:46:14,820 --> 00:46:23,640
So we just date of decomposition of some squares by as as y is equal to SSR plus SC and one.

351
00:46:23,970 --> 00:46:34,080
Very easy, quick, quick and easy way to measure how well our model is like overall, how well our model is, how good our model is.

352
00:46:34,290 --> 00:46:39,450
That's by looking out of the square. Then by comparing the regression sample square, it's full of total samples here.

353
00:46:39,840 --> 00:46:43,440
This is that's a similar to the idea of F statistic.

354
00:46:43,710 --> 00:46:50,280
If you look have an absolute s, it allows you to compare the the model of sum of square to the error somewhat square.

355
00:46:51,330 --> 00:46:58,320
But after adjusting for the corresponding to our freedom after improvement of your freedom here in our square,

356
00:46:58,590 --> 00:47:04,170
it just directly look at the result in a sample square compared to nine total sample square.

357
00:47:06,310 --> 00:47:15,870
And then, of course, that. Intuitively larger the is almost where is the battery the model is because the larger the our square

358
00:47:15,870 --> 00:47:22,980
is and that means that the higher proportion of the variation why that's got explained by the model.

359
00:47:25,790 --> 00:47:29,990
So our square then is actually the total percent,

360
00:47:30,170 --> 00:47:39,590
total proportion of variation in Y that it can be explained by your regression model or by older people variance of about all the covariates.

361
00:47:40,820 --> 00:47:49,580
Then of course one minus R squared. That's the proportion of variation that cannot be explained by rationale.

362
00:47:50,420 --> 00:47:59,730
And as we mentioned, this R squared typically is between zero and one is typically strictly between zero and three and between zero.

363
00:48:00,320 --> 00:48:10,650
So it is equal to zero or one only in some hypothetical scenarios, mathematically in some mathematical scenario as well.

364
00:48:11,210 --> 00:48:15,020
Zero one But in reality, our square is always between zero and one.

365
00:48:16,400 --> 00:48:21,080
The larger the R square is neutrality. It is in case, the better the model is.

366
00:48:22,910 --> 00:48:26,720
Um. Okay, so that's what our square is.

367
00:48:29,310 --> 00:48:37,370
Okay, I think we will take a ten minute break, and then after we come back to New York City, we'll finish the all about our square.

368
00:48:37,370 --> 00:48:46,440
We'll look at one example and that will why we have a very small symbol because I emphasize today.

369
00:48:47,150 --> 00:48:53,005
Okay, what about buffers? Let's take a look at.

370
00:49:00,919 --> 00:49:10,339
The our square, as we mentioned, the our square is of is a quantity that qualifies the variation,

371
00:49:10,339 --> 00:49:15,409
the proportional variation in Y that it can be explained by a regression model.

372
00:49:15,829 --> 00:49:23,009
So intuitively, the higher the R square is, the better the model explained more affordable variation.

373
00:49:24,649 --> 00:49:29,749
However, for multiple linear regression, we have to be careful when we make such an interpretation.

374
00:49:31,039 --> 00:49:44,569
The reason is that the reason is that the as I see, the sums of aerosol squares in will always decrease when you add more variables into the model.

375
00:49:44,989 --> 00:49:50,449
It doesn't matter whether the variables are indeed truly associated with the Y.

376
00:49:50,479 --> 00:49:58,279
So for example, I'll give you guys one extreme example. So in the dataset, usually there is one column called i-D, right?

377
00:49:58,279 --> 00:50:03,529
So we have different individuals. And of course, for the individuals you have ideal for for this idea.

378
00:50:03,559 --> 00:50:07,569
Could it be, you know, for example, for you an idea or it could be just a, you know,

379
00:50:08,209 --> 00:50:15,109
artificially created like number like one, two, three, 400, 100, for example, if you have a similar size equal to 100.

380
00:50:15,409 --> 00:50:20,539
So we have this idea. And the this idea typically is created a complete random.

381
00:50:20,659 --> 00:50:27,859
It has nothing to do with your response. For example, if your response is weight is people's weight, then this idea has nothing to do with weight.

382
00:50:27,889 --> 00:50:36,139
I mean, it's just really not relevant to assign numbers. However, when you fit regression model, if you are interested, you can check this yourself.

383
00:50:36,589 --> 00:50:41,059
If you fit a regression model, if you throw this idea into the model,

384
00:50:41,839 --> 00:50:48,739
you will see that r squared increase increases, although that idea has nothing to do with the response rate.

385
00:50:49,849 --> 00:50:54,649
So if an argument increases, that means the error somehow squares decreases.

386
00:50:55,009 --> 00:51:00,918
So errors almost queries, it always decreases as long as you throw more reasonable people on the ground.

387
00:51:00,919 --> 00:51:10,609
No matter whether those scenarios are indeed indeed related to the Y and similar to the as as are the random sample square.

388
00:51:10,609 --> 00:51:16,429
Always increase. Always increases if you throw more more variables into the model.

389
00:51:16,519 --> 00:51:20,749
Well, matter whether those variables are really related to your response or not.

390
00:51:21,799 --> 00:51:27,019
This is my business as well based on mathematical fact because of the production.

391
00:51:28,159 --> 00:51:33,499
But let's not get into the details. So but in essence y the total error.

392
00:51:33,529 --> 00:51:36,228
Some squares of course is always the same result.

393
00:51:36,229 --> 00:51:44,599
Once you are given the data, the total sum of squares, that's always the same because total sum of squares that's calculated, right.

394
00:51:44,839 --> 00:51:52,969
The total sum of squares by this guy over here or as was your response, y is less than or data is given.

395
00:51:53,359 --> 00:51:58,429
Now the total sum square is fixed is a small change. It doesn't matter which model think true.

396
00:52:00,739 --> 00:52:10,459
So in this case now what it means is that, okay, so tourism is where it is always based, where you throw a little bit more variables into the model.

397
00:52:10,869 --> 00:52:18,078
You are always going to see SSR increases and as I see decreases, that means well, so more variables into the model.

398
00:52:18,079 --> 00:52:26,629
We will always see an increasing R-squared. And even if your model, your the comparative, you are including in the model human,

399
00:52:26,659 --> 00:52:35,149
the cougar has nothing to do with your response one but this is of course undesirable because then by looking at our square itself,

400
00:52:35,899 --> 00:52:45,589
while we do not have a really good way of distinguishing which model is better because it will always prefer the Model S and it has more variables,

401
00:52:45,589 --> 00:52:49,159
more variants. Merkel enters this to higher R-squared.

402
00:52:51,319 --> 00:52:58,849
So in this sense that the s the R Square is actually not a good tool to compare models

403
00:53:00,229 --> 00:53:05,509
because it will always prefer it always prefer the model that has more covariance.

404
00:53:06,829 --> 00:53:13,729
So for example, if you if you are model weight, you use age and height to model weight.

405
00:53:14,209 --> 00:53:19,638
So you build two models. One model has age and height, the other model has age.

406
00:53:19,639 --> 00:53:26,699
In addition to age and height, you also throw ideas and people's idea in the model and you will see that the second model,

407
00:53:26,749 --> 00:53:31,489
the model that has IB in it, has a higher R-squared compared to the model without it.

408
00:53:31,909 --> 00:53:35,459
But if we know that idea has nothing to do with the response.

409
00:53:36,259 --> 00:53:51,109
And so R-squared, this is not a really good tool to distinguish models, but we do have a picture of okay, so this is also important.

410
00:53:51,109 --> 00:53:52,188
This point is also important.

411
00:53:52,189 --> 00:54:02,269
So as the number of queries increases, if you have we have more comparisons tomorrow model likely that the more variables we have,

412
00:54:02,839 --> 00:54:09,679
the higher the likelihood that we are actually feeding the noise rather than the real signal.

413
00:54:09,979 --> 00:54:15,099
So as we mentioned. Is that history is what we do tomorrow.

414
00:54:16,049 --> 00:54:19,169
We are actually using our model to approximate the truth.

415
00:54:19,709 --> 00:54:24,139
We never know the true underlying biological because a lot of these things have been canceled.

416
00:54:24,149 --> 00:54:27,239
That's something that is never known to us the truth.

417
00:54:27,269 --> 00:54:32,729
We never know the real truth. However, we use our motto to approximate the truth.

418
00:54:33,389 --> 00:54:41,729
So no matter whether it's linear regression modeling your original work later you will learn other advanced models.

419
00:54:43,079 --> 00:54:47,369
First of all, these models, we are using them to approximate the ideal truth.

420
00:54:48,419 --> 00:54:56,909
Now, if you throw too many variables into the model, then you run the risk range or the risk that you're on overfitting for data.

421
00:54:57,419 --> 00:55:03,359
So in other words, your data always has random noise, because if you collect one device that you collect,

422
00:55:03,359 --> 00:55:06,869
not only does this to various people different results.

423
00:55:07,109 --> 00:55:10,479
That's because we have noisy.

424
00:55:11,099 --> 00:55:11,969
There is randomness.

425
00:55:12,919 --> 00:55:21,389
But if you throw too many variables in the model, then you are running the risk of your modeling noise rather than modeling the truth online.

426
00:55:23,009 --> 00:55:28,379
So that's why, on one hand, we do want to include all the important measurements.

427
00:55:28,769 --> 00:55:35,158
On the other hand, we do not want to include too many of them because because some if you include

428
00:55:35,159 --> 00:55:39,209
if you start to include irrelevant variables and because of your modeling,

429
00:55:39,209 --> 00:55:44,019
you are starting to multiply the noise in advance.

430
00:55:45,059 --> 00:55:48,089
So is because of this pattern,

431
00:55:48,089 --> 00:56:00,299
we introduce that another quantity that's called a drastic R squared adjusted R square is our square adjusted by the corresponding to our freedom.

432
00:56:03,079 --> 00:56:13,399
So R-squared is defined by one minus as I see divided by as as y adjusted rs where is what minus?

433
00:56:14,239 --> 00:56:19,969
And as I see divided by, it's only worth reading and as as y divided by is due our freedom.

434
00:56:25,309 --> 00:56:33,979
So this addresses our square then does not have the drawback we just mentioned for our square anymore.

435
00:56:35,029 --> 00:56:40,459
We can look out this quite a lot, but there is a quite a good way of looking at this.

436
00:56:40,939 --> 00:56:45,889
So now let's consider the definition. This is how I address the R squared as defined, right?

437
00:56:46,639 --> 00:56:54,259
And to the now because the ss y is always fixed, it's all about it does not depend on which model you are looking at.

438
00:56:54,499 --> 00:56:59,179
The total sum of squares that's always fixed of course. Then minus one is always fixed.

439
00:56:59,899 --> 00:57:07,699
So to look at how the adjusted r squared, how it varies depending on the number of variables in the model.

440
00:57:08,179 --> 00:57:14,059
Now we just let's just look at them as I see the column, as I see it divided by its graph.

441
00:57:16,639 --> 00:57:28,169
So of. So if I'm if you already have a really good model,

442
00:57:28,629 --> 00:57:37,839
if let's say you have already included all the relevant variables in the model, you already have the perfect model.

443
00:57:37,839 --> 00:57:46,839
That's it. And then if you add one more covariate into the model that the coverage you're adding now has nothing to do with any other response y.

444
00:57:47,049 --> 00:57:57,969
So you're adding just another variable into the model then the essence, because you have already have the true model, then the I.

445
00:57:59,379 --> 00:58:05,959
After adding this irrelevant variable, I see you may be reduced by only a month,

446
00:58:05,979 --> 00:58:10,089
but only by a tiny bit because you have already built a very good model.

447
00:58:11,049 --> 00:58:17,119
So have error or squares. By adding one additional irrelevant variable.

448
00:58:17,659 --> 00:58:25,249
While you may still reduce the SLC but only reduce it by a private, you are not able to have a very large design.

449
00:58:28,569 --> 00:58:35,079
However, if you add more variables that your team will increase.

450
00:58:36,619 --> 00:58:41,899
So in other words, if you to have a very good model, you're gonna have a good model.

451
00:58:42,529 --> 00:58:51,709
Then when you add more covariates, as I see you will not reduce by much, but maybe by a tiny bit, but not by much.

452
00:58:52,519 --> 00:58:58,339
However, by increasing the number p by increasing by adding more variables,

453
00:58:58,579 --> 00:59:05,629
you're increasing the number of people and that means you're increasing while you're decreasing this this guy decreases.

454
00:59:05,989 --> 00:59:10,369
And then because this up here is the ratio. So this whole thing will increase.

455
00:59:13,339 --> 00:59:18,439
And this whole thing increased and this whole thing increased.

456
00:59:19,129 --> 00:59:24,979
Now, when this increase increased, and then what?

457
00:59:24,979 --> 00:59:28,459
Because there is a minus. So this ah, spirit will decrease.

458
00:59:30,739 --> 00:59:31,759
So in other words.

459
00:59:33,559 --> 00:59:41,779
So in other words, now, if you look at the address, our square, if you look at the square, then if you are to have a very good model,

460
00:59:43,039 --> 00:59:52,039
then by adding more variables into the model, you are going to make this address our square smaller rather than increasing it.

461
00:59:53,759 --> 00:59:57,569
Smuggling resumed because the adjustment of the degree of freedom.

462
00:59:59,099 --> 01:00:06,089
So this is the difference because addresses are square in our square. So if you look at our square, you add a more variables.

463
01:00:06,539 --> 01:00:16,469
You will always increase the value of our square. But if our adjusted our square because because is right on top by the bigger freedom.

464
01:00:16,889 --> 01:00:24,689
So adding more variables does not always leads to increased our adjustment.

465
01:00:25,529 --> 01:00:33,479
So you may have a reduced hours. You might you may have actually have a decrease our square if you add more variables.

466
01:00:34,409 --> 01:00:44,729
So this is sort of you can think of this as your your you put up penalty of adding more calories into the model.

467
01:00:45,419 --> 01:00:52,379
And you do not want to include two elements. Those are two that Americans this is this is intuitive.

468
01:00:52,439 --> 01:01:00,749
This makes sense because let's say you are a data center. You have 30, 50 covariance, you have a response Y, you have 50 X.

469
01:01:01,259 --> 01:01:05,009
Of course we do not a you are we do not want to throw all this 50 X into the model.

470
01:01:05,849 --> 01:01:12,179
That's that's not us. That's not a good strategy. So we have to be careful in lot of variables to be included in the model.

471
01:01:12,869 --> 01:01:23,009
And but if you throw all 50 variables in the model, your definition of a larger square compared to the model has only 30 covariance of.

472
01:01:23,529 --> 01:01:27,089
But but a throw in alphabetical areas in the model is not a good idea.

473
01:01:27,119 --> 01:01:34,859
So in that case, we can compare the model that that has 30 comparison to the class using just our square.

474
01:01:35,339 --> 01:01:41,939
So our does in our square as we put a penalty on the number of words in the volume.

475
01:01:42,059 --> 01:01:51,329
So it does not allow you to to include too many variables into the model because you are running into the risk of overfitting the data,

476
01:01:51,359 --> 01:01:57,119
your model of you are starting to model the noise rather than modeling the true signal.

477
01:01:58,709 --> 01:02:02,609
So this is not the rationale behind adjusting our square.

478
01:02:04,589 --> 01:02:12,808
So in theory. Now in theory, the model that with the largest R square adjusted R squared, so now we, we just take the model.

479
01:02:12,809 --> 01:02:18,029
If we model compare different models, then we just pick the model that has the largest address in R squared.

480
01:02:18,629 --> 01:02:22,129
So in theory, the model with a large designer doesn't R-squared.

481
01:02:22,529 --> 01:02:27,119
It has only the crack, the variables and a no noise variables.

482
01:02:28,559 --> 01:02:35,219
No. So that in terms of comparing two models.

483
01:02:35,489 --> 01:02:44,939
And so we have different variables, different covariates that we would pick the one that has the larger adjusted R squared low than R squared itself.

484
01:02:45,939 --> 01:02:51,489
Yes, because it's no longer the same as the original R-squared value we adjusted.

485
01:02:51,819 --> 01:02:55,029
How does our interpretation of that change? Yes.

486
01:02:55,569 --> 01:02:58,429
You mean the interpretation, right? Yeah, definitely. This is a good point.

487
01:02:58,449 --> 01:03:04,809
So the interpretation of adjusted R-squared now is definitely different from the original R-squared,

488
01:03:05,079 --> 01:03:10,779
a real loss where it has a very simple interpretation, the proportion of the way that it was explained by our model.

489
01:03:11,319 --> 01:03:16,479
But adjusted R-squared loses that interpretation because of the arsenal of your freedom.

490
01:03:17,169 --> 01:03:24,459
So it no longer has that a simple interpretation of this, as with the price we pay, right?

491
01:03:24,459 --> 01:03:27,219
So we do not have that simple interpretation anymore.

492
01:03:27,459 --> 01:03:38,229
However, and this one, because the adjustment to be greater naturally gives us a better way of distinguishing to model which model is better?

493
01:03:43,659 --> 01:03:54,609
Okay. Any other questions? Okay.

494
01:03:55,119 --> 01:03:58,209
And then let's take a look at one example.

495
01:04:00,399 --> 01:04:09,029
This using ironic. Ah, I saw the guest list the Beatles had used by this example I had just uploaded under our library folders.

496
01:04:09,039 --> 01:04:11,769
We were interested. We had a clear idea of how to resolve.

497
01:04:12,879 --> 01:04:21,999
This is a study to examine the relationship between body weight and weight and age and height.

498
01:04:22,959 --> 01:04:38,489
So this is the model. Is equal to zero plus beta one plus rain until it comes from.

499
01:04:41,659 --> 01:04:47,969
And this is the model we are building and we have a small size single to solve some.

500
01:04:52,109 --> 01:04:57,809
Okay. And then while the first moto we are building actually this is this is a symbol,

501
01:04:58,139 --> 01:05:13,229
you know, this is just a wage who 32018 for this model with only the page has appointed.

502
01:05:14,099 --> 01:05:17,849
So this is the output from the model.

503
01:05:18,799 --> 01:05:23,339
And so we have seen this out of all of our output from previous lectures.

504
01:05:23,339 --> 01:05:27,119
So this part, this is the residual table.

505
01:05:27,719 --> 01:05:34,109
Now we have 12 individuals. So by feeding after feeding the model, the residuals, these are the ABS mass.

506
01:05:34,349 --> 01:05:39,959
So equal is what I want to know. Exactly. That's what these residuals are.

507
01:05:41,579 --> 01:05:44,909
Here we have 12 individual, so we have 12 residuals.

508
01:05:45,299 --> 01:05:50,849
And just to keep a summary that has been for this residuals and it gives you the minimal residual first quarter,

509
01:05:50,849 --> 01:05:56,129
median third quarter, third quarter and the maximum interest.

510
01:05:57,209 --> 01:06:02,539
So the total we have far leverage. And then we have the coefficients table.

511
01:06:02,659 --> 01:06:09,569
These table is well, this table is super important because it tells us what the estimated values are.

512
01:06:09,589 --> 01:06:12,769
So these this is this value is beta.

513
01:06:13,009 --> 01:06:25,219
This is beta zero. And this is where one helped in the second recall of this is the standard error of the beta zero hat.

514
01:06:25,969 --> 01:06:38,559
And this is the center of the. And then we have the key that was called this Keystone Don't stick.

515
01:06:38,919 --> 01:06:42,068
This is where a zero has divided by the center.

516
01:06:42,069 --> 01:06:49,029
Never been a zero. And this is a one that divided by seven over one had.

517
01:06:56,579 --> 01:07:07,499
And then these are the products. These are the XI values, the P values, the probability, the larger event, the key statistic.

518
01:07:07,979 --> 01:07:11,519
This is calculated as murder. So that's the definition of P value.

519
01:07:12,269 --> 01:07:15,869
As for example, let's focus on this one because this is for a fact.

520
01:07:15,899 --> 01:07:24,519
So let's focus on this one. So this one is forecasting is forecasting certain anomalies and theta beta one.

521
01:07:26,129 --> 01:07:31,569
Beta one is equal to zero versus beta one is not equal to zero.

522
01:07:37,359 --> 01:07:41,229
So the table was covered in table key test and P-value.

523
01:07:41,589 --> 01:07:44,979
This is by default. This is for a two sided test.

524
01:07:45,849 --> 01:07:55,029
If you want to test against a one sided alternative, then you'll have to do it by manual, by buying, by help yourself.

525
01:07:55,419 --> 01:07:58,389
Or you can write our code and do it.

526
01:07:58,659 --> 01:08:07,309
But by default, this dispute out of this is our two sided test as to whether better wines even do zero or is not able to do.

527
01:08:10,669 --> 01:08:14,509
And then the degree of freedom here, the t statistic.

528
01:08:15,229 --> 01:08:21,489
Okay, so the t statistic it it follows t this fusion with the amnesty people.

529
01:08:21,499 --> 01:08:28,249
Freedom, amnesty or freedom. So in this case is equal to two because we have been a zero beta one.

530
01:08:28,579 --> 01:08:34,099
So I'm on the to the word freedom, which is t the ten you are freedom.

531
01:08:35,669 --> 01:08:50,939
You can see total sample size is top and then this p value this pinata found equal to its probability that this.

532
01:08:53,829 --> 01:09:00,798
Tito's Virgin run America larger than or equal to this observed this observed planet.

533
01:09:00,799 --> 01:09:04,149
Right. So observed this pretty much so here.

534
01:09:04,149 --> 01:09:07,689
I mean, this course, we are not super rigorous in our notation.

535
01:09:10,009 --> 01:09:13,399
I mean, sexual tools, things will become a lot more rigorous.

536
01:09:14,269 --> 01:09:22,249
But here, I mean, in the lecture hall, sometimes we use this capital T $20 to see the calculated value of the statistic,

537
01:09:23,329 --> 01:09:27,859
which is not the best notation, but that's what a lecture slides used.

538
01:09:27,859 --> 01:09:35,389
So I would just of just follow the lecture slides. So this is the p value that underlie well, this is the T test fusion.

539
01:09:37,339 --> 01:09:41,209
The T rather variable has to be roughly larger than the observed.

540
01:09:41,599 --> 01:09:45,679
This is the absolute value, larger than the absolute value of this guy.

541
01:09:47,519 --> 01:09:58,659
So if you look at the graphical event, if you look at maybe all of the cases graphically, then this is the tedious version with the ten work veto.

542
01:09:59,669 --> 01:10:03,889
So let's say that your observed value is not.

543
01:10:03,899 --> 01:10:21,239
This is done. This is not. Sorry.

544
01:10:21,359 --> 01:10:39,459
This. And to say, okay, so this is this I guess this is just an occupation.

545
01:10:39,459 --> 01:10:47,469
So what it means is actually is it's two sided, so.

546
01:10:57,229 --> 01:11:00,429
So it's a little bit tricky. So let me just write it in this way.

547
01:11:00,439 --> 01:11:13,759
Okay. So it is larger than absolute value of T or less than 19 absolute value of T.

548
01:11:13,969 --> 01:11:19,878
So, so here I'm just trying to make it clear that it is actually not forecasting true sorry to

549
01:11:19,879 --> 01:11:24,499
have all this is is as the p value is is the two tails is probably the obvious to house.

550
01:11:34,459 --> 01:11:39,409
Yeah. Okay. Because we are casting against this two sided alternative.

551
01:11:39,769 --> 01:11:43,308
So the p value here is actually the the message.

552
01:11:43,309 --> 01:11:46,369
This is the absolute value of T, right?

553
01:11:46,699 --> 01:11:51,409
So then the P value is actually the tail probability on both on both counts.

554
01:11:51,919 --> 01:12:00,709
So that's the t p value. So in this case, we see that the P value is .034.

555
01:12:01,529 --> 01:12:07,969
Well, this is a very small P value compared to 2.05 is a very small p value.

556
01:12:08,809 --> 01:12:12,579
So what it means is that you will reject this normalizes.

557
01:12:13,579 --> 01:12:20,889
We have this model is. Meaning what? Meaning that age.

558
01:12:20,899 --> 01:12:27,549
The effect of age is significantly different from zero. So that's.

559
01:12:29,239 --> 01:12:34,429
The coveted table. And then you have some other studies sitting down at the bottom.

560
01:12:34,429 --> 01:12:40,489
So you have a residual center area. As we mentioned, this is actually square root of an AC.

561
01:12:42,139 --> 01:12:49,309
And this is the corresponding to your freedom. Your freedom of of assessment of of assessment.

562
01:12:50,059 --> 01:12:57,139
And so in this case is minus two and minus two, which is equal to ten, ten of freedom.

563
01:12:59,599 --> 01:13:05,449
And then you have you are square and also you have the address, our square.

564
01:13:05,459 --> 01:13:12,279
Now we are able to address it our square and our square.

565
01:13:12,289 --> 01:13:19,039
Again, the interpretation of our square is that of 59% of the variation in Y is explained by this regression model.

566
01:13:20,399 --> 01:13:25,489
But address in our square the four or five five that does not have have that interpretation anymore.

567
01:13:26,369 --> 01:13:30,209
But that's what this addresses R Square this after adjusting for the degree of freedom.

568
01:13:32,629 --> 01:13:43,239
And then we have the F statistic. Our statistic and our statistic has one the work law it follows.

569
01:13:44,589 --> 01:13:53,269
So now distribution with one one the growth rate in the numerator and then you work for them in the denominator altogether.

570
01:13:53,289 --> 01:13:57,309
You can check this episode as to because there's a simple linear regression model.

571
01:13:57,669 --> 01:14:06,429
So is exactly equal to is equal to three the square of 3.814.

572
01:14:07,359 --> 01:14:16,399
That's actually. That's just not okay for the team.

573
01:14:16,459 --> 01:14:19,879
For the team. That hostess was excellent.

574
01:14:20,119 --> 01:14:26,748
It's just a squirrel that. And again, the key that if you look at the P value,

575
01:14:26,749 --> 01:14:34,459
the P value is exactly the same as the p value based on the tested it based on two asked 30 exactly the same.

576
01:14:35,539 --> 01:14:41,839
So while they are exactly the same, because here we have simple interaction, so forth that he has an app test,

577
01:14:42,259 --> 01:14:59,629
you ask the ability this is also testing it's zero beta one zero beta one not in the testing but c not the visits as the test.

578
01:15:00,739 --> 01:15:03,979
And so that's why in the end we have exactly the same product.

579
01:15:04,219 --> 01:15:14,389
So we will get exactly the same conclusion. Any questions about this outcome?

580
01:15:22,149 --> 01:15:29,949
And then now we are able to construct a common to the senior roles, especially especially for age, right?

581
01:15:30,159 --> 01:15:34,729
That's what we are interested in. So this one gives you that 95% confidence interval.

582
01:15:35,359 --> 01:15:41,379
So so this is the age of the constructed 95% confidence interval for for beta one.

583
01:15:42,279 --> 01:15:50,379
For beta one. That's beta one hatch plus minus center error beta one times t minus two.

584
01:15:50,439 --> 01:15:54,939
You are free to. 95 5%.

585
01:15:55,999 --> 01:15:59,669
And if you calculate this, you will get out of this combination.

586
01:16:01,159 --> 01:16:05,749
And this is direct indirect output from from our. But it is calculated in this way.

587
01:16:11,559 --> 01:16:17,799
And we can see that in this combination or what does not include zero zero is outside of this confidence interval,

588
01:16:18,729 --> 01:16:22,689
which means that the beta one is significantly different from zero.

589
01:16:24,349 --> 01:16:32,099
And the same conclusion, the same conclusion as the conclusion that you draw based on based on what should have

590
01:16:32,419 --> 01:16:40,549
four aspects are based on P-value zero does not include zero meaning that you know what,

591
01:16:40,819 --> 01:16:47,639
I'm going to do my policy. So now the interpretation.

592
01:16:48,659 --> 01:16:51,819
No interpretation of the of the results here.

593
01:16:51,839 --> 01:16:55,559
There are several things we need to pay attention to. And this is particularly important.

594
01:16:57,029 --> 01:17:00,899
Yes. That especially for the first bar exam.

595
01:17:01,089 --> 01:17:04,269
In exam, you will you will not.

596
01:17:04,709 --> 01:17:11,259
We will ask you guys to give give interpretation of the of the results so they never defer to the interpretation.

597
01:17:11,279 --> 01:17:22,469
There are certain things that we should pay attention to, like the units of X and Y and also the direction of of the change in X and Y.

598
01:17:23,939 --> 01:17:32,909
And also recall that the fact of X all Y that's that's for all that that's the effect on the average Y on a mean one,

599
01:17:32,939 --> 01:17:40,899
on the media response, because our model is actually Spanish and Y is equal to.

600
01:17:47,679 --> 01:17:56,209
And this is what our motto is. So once you change this X, you will see not the trending in in the response is beta one.

601
01:17:56,209 --> 01:17:59,899
But that's the change for the average Y for not for the media response.

602
01:18:00,619 --> 01:18:11,139
It's also here and this is also very important. So and also our our effect the beta one that's estimated effect.

603
01:18:11,269 --> 01:18:16,399
And that's not a true true beta. What our estimate is that it has no the exact parameter one.

604
01:18:17,479 --> 01:18:21,109
And also we need to pay attention to the magnitude.

605
01:18:21,949 --> 01:18:28,429
So and that's that's when we interpret the results some things that we need to pay attention to.

606
01:18:29,599 --> 01:18:36,669
So for example, let's. So.

607
01:18:36,909 --> 01:18:42,369
And then another thing when you go through is. In our state.

608
01:18:42,369 --> 01:18:48,069
When you are proficient in our statement, as some of you asked this question during our summer for us,

609
01:18:48,099 --> 01:18:53,979
whether you should provide 95% accommodation or you value your information.

610
01:18:55,899 --> 01:19:00,099
The answer is actually, especially if you are writing paper.

611
01:19:00,149 --> 01:19:06,249
That was a resounding yes. So in our interpretation, you should provide a 95% confidence interval.

612
01:19:06,699 --> 01:19:09,789
Or if you haven't, you probably do not need to provide both.

613
01:19:10,179 --> 01:19:12,849
But I definitely want to provide at least one of these.

614
01:19:15,429 --> 01:19:23,499
So because because these two like covered are for people, really, it indicates whether you are in fact, a significant difference.

615
01:19:23,509 --> 01:19:28,209
This indicates the significance of the evidence, your data.

616
01:19:29,469 --> 01:19:33,969
So let's take a look at this example.

617
01:19:33,999 --> 01:19:38,259
So in this example, a fact as median, in fact, is 3.6,

618
01:19:38,259 --> 01:19:47,229
but hasn't made a better life 3.64 P-value is best and 95% confidence interval, which is calculated is given by this.

619
01:19:47,699 --> 01:19:55,089
Okay, so with all these results that we are able to obtain from our output, let's see how to interpret this result.

620
01:19:56,649 --> 01:20:05,109
So in this case, now we estimating that, okay, so this means that while this is estimated about right, this is not a true truth.

621
01:20:05,319 --> 01:20:07,719
We don't know what the truth is when we are estimating it.

622
01:20:08,259 --> 01:20:14,829
So we estimated that the amount children ages 6 to 12, that's actually a given by the example.

623
01:20:15,879 --> 01:20:20,799
So in this particular example, we are looking at children aged between six and 12.

624
01:20:21,609 --> 01:20:32,019
So fewer men, we estimate that among children aged between six and 12, you know, one year higher in age.

625
01:20:32,469 --> 01:20:35,909
And this is our X, we include our Xs age, right?

626
01:20:36,159 --> 01:20:43,029
So for one year hiring age, now it's significantly associated.

627
01:20:43,029 --> 01:20:49,388
While this significant this was part of the statement come from looking at the P values less than

628
01:20:49,389 --> 01:20:56,619
.05 so significant or it comes from this comment in senior year companies or does not cover do so.

629
01:20:57,189 --> 01:21:03,909
So that to me is the better one is a different from zero so significantly associated.

630
01:21:05,399 --> 01:21:12,849
With this much. With this might change because beta one is the start of beta.

631
01:21:12,849 --> 01:21:17,769
What happened has been model business. So with this large unit,

632
01:21:17,769 --> 01:21:26,049
this is our unit rise or power like the weight is matter empowering you no uniform response with 3.64 pass

633
01:21:26,709 --> 01:21:39,969
increase or higher rate on average on average or the mean or average which become 3.6 for a pound higher.

634
01:21:42,159 --> 01:21:50,769
And then you can provide the p value for confidence interval inside of this parentheses primarily reported this evidence inside the

635
01:21:50,769 --> 01:22:01,569
parentheses because this indicates like the numerical quantitative evidence how strong evidence is you are do we do not need to include both.

636
01:22:02,049 --> 01:22:08,669
So typically people I guess would include p value, but sometimes you also use zero.

637
01:22:09,039 --> 01:22:18,589
You do not have to provide both. So this is actually a formal like a formal statement that you would make in your life.

638
01:22:18,639 --> 01:22:22,119
When you write a report, when you write a paper, we try to publish something.

639
01:22:22,599 --> 01:22:27,689
So this is on the formal interpretation that you would provide, of course.

640
01:22:27,729 --> 01:22:37,529
I mean, when I got know in a verbal conversation, sometimes, you know, sometimes we we do not like sometimes we are not this formal.

641
01:22:38,229 --> 01:22:41,799
Sometimes we make some some sounds.

642
01:22:42,189 --> 01:22:48,579
So, for example, in our verbal conversation, sometimes we do not provide exactly what the p value and the number of comments,

643
01:22:48,869 --> 01:22:57,009
you know, those are, but like informal writing when like in exam or in, in that we write a report, we write a paper.

644
01:22:58,809 --> 01:23:03,119
This should be a formal statement of occasion.

645
01:23:03,309 --> 01:23:09,899
The result. Okay.

646
01:23:09,899 --> 01:23:19,949
So any questions about this? Yes. On why the confidence interval between the zero service and what is the confidence interval?

647
01:23:20,549 --> 01:23:23,559
Oh, okay. So yeah, that's a good question.

648
01:23:23,579 --> 01:23:29,789
So let's say now I'm making out by example. So let's say now instead of this confidence interval, we got our problems here.

649
01:23:29,789 --> 01:23:34,949
Well, let's say from 97 to 8 making a negative.

650
01:23:36,029 --> 01:23:39,509
So in this case, because they include zero and copper zero.

651
01:23:40,319 --> 01:23:54,569
So in the case that the individual women we estimate about about children aged 6 to 12, why your higher age is low, but there are different ways.

652
01:23:54,869 --> 01:24:06,959
So y you're 881 you're hiring age let's say is associated with this much higher wage on average.

653
01:24:08,129 --> 01:24:19,469
What this is what you've got to say, but this is not a significant but this is not not a significant an event.

654
01:24:19,499 --> 01:24:28,199
You could have put apprentices here and give the confidence in our right or left for looking out for you not.

655
01:24:30,809 --> 01:24:38,779
On that. So in this kind of sea way to expose or not launch, this is not a single event, although,

656
01:24:38,779 --> 01:24:44,329
I mean, the estimated value is 3.64, but this is not a significant event from.

657
01:24:55,109 --> 01:24:58,609
So any other questions?

658
01:25:13,049 --> 01:25:22,469
Okay. Um, yeah, that's. That's what the interpretation would be if you have a company to serve on that covers the commerce you in that case,

659
01:25:22,469 --> 01:25:25,799
the p value would definitely be larger than 105. Right.

660
01:25:31,129 --> 01:25:40,099
Okay. So that's. And then our square is equal to. That's right. So this means that age explained 59% of the variation in the weight the response.

661
01:25:43,039 --> 01:25:50,749
Okay. So that's the the simple linear regression model.

662
01:25:51,049 --> 01:25:55,849
And then well here this is a another similar to international.

663
01:25:55,899 --> 01:26:02,069
In this case, it only includes ways. That's right.

664
01:26:02,239 --> 01:26:11,419
All right. Read the proof previous not only include weight, but only school age, and this model only includes height.

665
01:26:13,279 --> 01:26:19,549
In a bottle and a you have the same. If you look at this table here, it's exactly the same structure as before.

666
01:26:20,419 --> 01:26:25,449
But now it's just added. Now this, this covariate included, that becomes height.

667
01:26:26,149 --> 01:26:30,889
So h and again we see that in this p value is less than five.

668
01:26:31,039 --> 01:26:40,189
The five weights that is h of lesser known is higher, has a significant association with which.

669
01:26:44,089 --> 01:26:49,579
Okay, so and of course we are also able to obtain a confidence interval for height.

670
01:26:53,989 --> 01:26:56,989
And now we have let's do either jump into the interpretation.

671
01:26:58,069 --> 01:27:10,849
So in this case, now the estimated value is 1.7 and P value is driven by this and 95% confidence in our physical values.

672
01:27:11,209 --> 01:27:16,489
Again, we see that P value is very small, less than 25 and a confidence interval.

673
01:27:16,579 --> 01:27:23,719
It does not cover zero, which means that indeed there is a significant association between height and weight.

674
01:27:24,859 --> 01:27:30,889
So again, the. The. This is the interpretation.

675
01:27:30,899 --> 01:27:33,599
Now, the interpretation is expressed in slightly different ways.

676
01:27:33,599 --> 01:27:42,119
So you can see that while we do have different ways of of of making in interpretation, different ways of writing, but essentially this is the same.

677
01:27:42,509 --> 01:27:51,539
So a man, children aged 6 to 12, you know, if we compare it to children who differ in Hyde by one inch.

678
01:27:53,069 --> 01:27:57,319
We've learned how to buy one each. That's that's one difference.

679
01:27:57,319 --> 01:28:01,978
The x axis height is our our X.

680
01:28:01,979 --> 01:28:12,019
So for two children who differ by five in height by one inch by one unit, then the taller one has an estimated mean weight.

681
01:28:12,719 --> 01:28:22,859
A new weighted average average response. New weight has an estimated new weight.

682
01:28:22,949 --> 01:28:31,769
That is 1.7, but is estimated they are, what, 1.07 higher, significantly higher compared for that.

683
01:28:33,959 --> 01:28:40,469
Compare those individuals? Well, this is comparing, you know, the taller individual, one inch taller individuals.

684
01:28:42,389 --> 01:28:46,468
So, again, if you look at if you compare this interpretation to the previous interpretation,

685
01:28:46,469 --> 01:28:50,789
you will see that this two interpretation provided exactly the same information.

686
01:28:50,789 --> 01:28:57,389
They're stating in slightly different ways, different different orders in providing all this information,

687
01:28:57,789 --> 01:29:01,889
but this to interpretation, to provide exactly the same information.

688
01:29:05,989 --> 01:29:11,299
And again, you you can provide either the company scenario or the p value or both.

689
01:29:11,659 --> 01:29:16,069
But most of people I would just provide one, but you can definitely provide both.

690
01:29:18,649 --> 01:29:23,959
So that's done on information in this case.

691
01:29:26,579 --> 01:29:37,888
Any questions? So when you make this an operation, I think it's better actually to, you know,

692
01:29:37,889 --> 01:29:44,009
to keep this cures in mind and keep this cure as it might and then just use,

693
01:29:44,009 --> 01:29:48,559
you know, use the example here as templates just filled in that, you know,

694
01:29:49,499 --> 01:29:55,709
after you got your rays out of the field in the numbers and then you have the interpretation cracking,

695
01:29:57,779 --> 01:30:01,138
if you were as are the things that we need to pay attention to,

696
01:30:01,139 --> 01:30:08,549
what we try to make the most rigorous interpretation and then we have the unadjusted r R-squared.

697
01:30:08,879 --> 01:30:13,589
But that's the the example with height.

698
01:30:13,949 --> 01:30:17,609
Now this is the model that has both age.

699
01:30:27,079 --> 01:30:35,839
At a height in the morning. So this is a part of a linear regression as to covariance and the output.

700
01:30:36,139 --> 01:30:40,039
The tables are the structure wise. They are exactly the same as before.

701
01:30:40,519 --> 01:30:48,318
So you still have the residual table with usual table and we still have the conversion table.

702
01:30:48,319 --> 01:30:55,878
But now the coefficients here we have, we have the beta zero hash, we have beta one hat, we have beta.

703
01:30:55,879 --> 01:31:05,299
True. And we have estimated the value for for all these betas resulting from age and height.

704
01:31:06,419 --> 01:31:14,249
And also we have the Castlevania standard areas on a series of beta zero has been a standard arrow beta to have.

705
01:31:16,999 --> 01:31:26,009
And also we have the corresponding T values. The statistic testing whether each of these data is equal to zero.

706
01:31:29,429 --> 01:31:36,508
And so, for example, this this is the key value. I'm not going to write this down because because of the time time constraints.

707
01:31:36,509 --> 01:31:40,219
So and also this is exactly the same as before.

708
01:31:40,229 --> 01:31:43,649
So, for example, this this point is up to six, eight.

709
01:31:44,489 --> 01:31:50,849
This is the value of the key statistic for testing whether failure to murder

710
01:31:50,879 --> 01:31:54,469
and failure corresponding to find when the beta two is equal to zero or not.

711
01:31:55,089 --> 01:31:59,789
That's not what this is. It's better to is equal to zero. Alternative is not being true.

712
01:31:59,789 --> 01:32:04,809
Is not equal to. And then we have the corresponding.

713
01:32:07,369 --> 01:32:11,609
She it okay.

714
01:32:11,619 --> 01:32:15,819
And then we have that now that you freedom.

715
01:32:15,939 --> 01:32:18,098
You got to see that you are freedom for some of us.

716
01:32:18,099 --> 01:32:25,389
Wherever someone squares him through from 10 to 9 or this is, you know, minus P, now we have 3 p.m. on a three.

717
01:32:25,599 --> 01:32:31,639
That is 12 minus three. That is. That is how this nine in a like to represent.

718
01:32:34,819 --> 01:32:40,579
Okay. And then the average statistic, brothers and sisters has a f.

719
01:32:40,579 --> 01:32:44,119
This vision was to do more freedom and not be more freedom.

720
01:32:45,649 --> 01:32:50,269
And this is also different from before the because now we have a multiple linear regression

721
01:32:50,269 --> 01:33:00,019
model and this F statistic and the F distribution that is actually from the another table,

722
01:33:00,409 --> 01:33:08,959
we have about 50. So we have these are the corresponding to our freedom what we calculate about a CAF statistic.

723
01:33:11,579 --> 01:33:20,719
So that's that's how FS that has these calculated and how the degree of freedom is is determined.

724
01:33:24,089 --> 01:33:33,209
And this is the problem. You can see that now this p value, now this p value is different from either one of these two values here.

725
01:33:35,959 --> 01:33:39,148
Like this is because now this f statistic.

726
01:33:39,149 --> 01:33:42,899
This is testing. This is testing.

727
01:33:44,039 --> 01:33:49,589
Beta one is equal to beta two is equal to zero versus h one.

728
01:33:50,399 --> 01:33:55,109
Beta one not equal to zero for the two not able to do so.

729
01:33:55,109 --> 01:33:59,849
At least one beta is not equal to zero. So this test is different from what you asked,

730
01:34:01,889 --> 01:34:09,699
but he asked is still has to whether it comes from the corresponding beta zero zero individual beta came out the best you can do.

731
01:34:10,049 --> 01:34:17,399
But now this impasse is testing whether, you know, one is equal to being true and whether both are equal to zero simultaneously.

732
01:34:19,109 --> 01:34:26,639
So that's why you see that of a pinnacle here. This this is not related to any of these two problems based on the of.

733
01:34:34,199 --> 01:34:41,889
And then based on the results, we are able to construct a 95% confidence interval for beta one kind of for PTSD.

734
01:34:43,499 --> 01:34:46,589
And this is still the same confidence interval as before.

735
01:34:46,589 --> 01:34:50,699
I mean, the same the same way of constructing this confidence interval as before.

736
01:34:53,309 --> 01:34:57,779
And then let's take a look at the interpretation. No.

737
01:34:58,169 --> 01:35:02,429
Again, I just dropped a job into an vacation because we have only 4 minutes left.

738
01:35:03,089 --> 01:35:14,879
So of the let's see, for example, let's let's look at the ages and age is in families.

739
01:35:15,129 --> 01:35:18,329
This is as medium value. This is portable five, seven.

740
01:35:18,899 --> 01:35:23,849
And now we see that 95% confidence interval. You know, does it include zero?

741
01:35:25,179 --> 01:35:30,599
It does equal to zero. And also P is five, which means that it was 2.05.

742
01:35:31,139 --> 01:35:35,909
This estimate that in fact it's a fact is not a significant difference from zero anymore.

743
01:35:36,569 --> 01:35:40,789
Right. So now that's what that is not it's going to be different from now.

744
01:35:40,799 --> 01:35:44,069
That's okay. So we can interpret the result as this.

745
01:35:44,999 --> 01:35:48,029
So we estimate in that, you know,

746
01:35:48,029 --> 01:35:54,209
above as children y you're higher in age and that's that's for one unit higher

747
01:35:54,659 --> 01:36:00,919
X and X we're looking at Y you're higher age is no significant money now

748
01:36:00,989 --> 01:36:06,659
is not significantly associated with that one over this is estimated based on

749
01:36:06,659 --> 01:36:13,259
what we know is equivalent associated with a 2.05 higher which on average.

750
01:36:15,699 --> 01:36:20,989
Yeah. So here we need to point out this.

751
01:36:21,039 --> 01:36:28,059
This association is not significant, and then you can provide the p value for the confidence interval.

752
01:36:28,929 --> 01:36:35,949
And then in the end, you have to make it very clear that this is adjusting for height because this is malleable linear regression model.

753
01:36:37,119 --> 01:36:43,859
And this is in fact is as after adjusting for height after including height in the closet,

754
01:36:46,839 --> 01:36:51,789
this is the interpretation of the fact and a similar if for for height.

755
01:36:52,539 --> 01:36:57,938
Similarly, for height you can see that the relation is along with children.

756
01:36:57,939 --> 01:37:05,079
Comparing this to true children differ in height about what unit the taller individual has estimated the mean weight.

757
01:37:05,589 --> 01:37:13,799
Why is this much count significant the higher adjusting for H and then you can provide a confidence interval if you had.

758
01:37:16,689 --> 01:37:21,789
You can see that again, there's two interpretations by Indonesian for age in the region for height.

759
01:37:22,239 --> 01:37:27,519
They are written in slightly different ways, but they provide exactly the same amount of information.

760
01:37:28,459 --> 01:37:36,009
You can you can, of course, change the order, the exact language, your your birth regime, a statement by John.

761
01:37:37,269 --> 01:37:44,019
But you should convey that you should have the same of content or the same information.

762
01:37:44,229 --> 01:37:48,569
The same information. Okay.

763
01:37:48,649 --> 01:37:55,469
This this is not the. Okay.

764
01:37:55,489 --> 01:38:02,029
Let's. Very quickly, I can compare the prime harassment from similar eruptions, a lot of linear regression models.

765
01:38:02,299 --> 01:38:05,599
So for simple linear regression, we will only have edge in the model.

766
01:38:05,659 --> 01:38:16,759
This is the estimate of edge. But if we look at the artifact, when we include both age in height, we see that any effect will become smaller.

767
01:38:18,409 --> 01:38:24,199
And similarly for height, we see that the height if had also become smaller.

768
01:38:24,209 --> 01:38:28,339
When we look out of the draw anamorphic model, the linear regression model.

769
01:38:29,179 --> 01:38:32,419
This is actually not uncommon in practice.

770
01:38:32,899 --> 01:38:39,469
So when you look at a modern life, we have a single linear regression model, in fact, maybe higher than magnitude of maybe, maybe higher.

771
01:38:39,889 --> 01:38:45,409
But when you put both variables into the model, that magnitude becomes smaller.

772
01:38:45,769 --> 01:38:51,079
The reason is that, as with both age and height, if they are related to weight.

773
01:38:52,069 --> 01:38:55,579
So until then, we could have both in the models.

774
01:38:56,009 --> 01:39:02,869
Actually, if you look at their joint effect on a weight,

775
01:39:03,439 --> 01:39:16,129
that part part of the effect of age here in the simultaneous regression model that that okay got explained by height weight and whole time.

776
01:39:16,939 --> 01:39:20,209
So that's why you see this decrease in magnitude. Okay.

777
01:39:21,739 --> 01:39:25,519
So this is not a common interest in mind.

778
01:39:26,149 --> 01:39:31,459
So this is as was summarized, summarized in this time slot location.

779
01:39:31,969 --> 01:39:43,559
So we see that a crude analysis age was significantly associated with weight, but after adjusting for height, the association was the longest.

780
01:39:45,019 --> 01:39:55,219
And this is also not uncommon because of because both age and height we are associated with the weight.

781
01:39:56,869 --> 01:40:04,759
Now, if you look at each single sort of covariate associated about what we throw both into the model, not now become less significant.

782
01:40:04,999 --> 01:40:10,519
Not that significant simply because the weight because we have weight in the model as well.

783
01:40:10,669 --> 01:40:17,599
Both actually have both have effects on a weight.

784
01:40:17,629 --> 01:40:23,129
So that is the effect of age on weight in a similar linear regression model.

785
01:40:23,809 --> 01:40:30,729
In fact, part of the effect going explained by balance height, in fact, one, we can do a hybrid model.

786
01:40:31,369 --> 01:40:33,649
So this is one important observation.

787
01:40:34,429 --> 01:40:44,929
Another one is that the majority of estimates for both height and weight become smaller by smaller magnitude than the unprocessed weights.

788
01:40:45,289 --> 01:40:50,028
This is another model which is actually quite a combination when you compare simple

789
01:40:50,029 --> 01:40:56,599
linear regression model estimates to model the impression models mix of okay,

790
01:40:56,609 --> 01:41:07,609
that's the final value. Just on the sense that you can get all the results by writing our code of results instead of writing your own article,

791
01:41:08,619 --> 01:41:15,949
by applying the formula, rather than by drivers feeding the model using order, and you will get exactly the same results.

792
01:41:16,289 --> 01:41:24,109
That's the following slides that. So we can. That's, that's not super important not as important as comparative interpretation.

793
01:41:24,979 --> 01:41:29,629
Okay. So we are 2 minutes over. I apologize for that. So we will have it here today.

794
01:41:30,079 --> 01:41:34,309
And then, of course, Tuesday we will. Big announcement on Tuesday.

795
01:41:34,519 --> 01:41:40,609
We'll have a review session and we will session will be held in the auditorium in as few as 20 total.

796
01:41:40,609 --> 01:41:48,299
But whose actions we will talk about? We will stand together as well as the exact exam will also be allowed to do so.

797
01:41:48,849 --> 01:41:49,459
One single.

