1
00:00:00,870 --> 00:00:10,610
You know, actually in the U.K., I got York is one of the lucky ones doing most of the most arduous work.

2
00:00:10,620 --> 00:00:13,800
And yeah, this is an interesting survey.

3
00:00:18,930 --> 00:00:28,410
It's something that we don't do too much because there really aren't any any U.S. studies looking at it.

4
00:00:30,180 --> 00:00:34,020
So it's it's relatively new. Yeah. Especially while these work out.

5
00:00:34,380 --> 00:00:38,280
Yeah. You find ways to not do this in your sleep.

6
00:00:39,840 --> 00:00:49,490
Well, good morning, everyone. Good to see you all. Today we're talking about equity and the big picture in cost effectiveness analysis.

7
00:00:49,500 --> 00:00:56,069
It's very much focused on efficiency. And the way I think about it is it would cost to reconcile this.

8
00:00:56,070 --> 00:00:59,430
We're analyzing costs and aggregate health outcomes,

9
00:00:59,430 --> 00:01:09,750
quality adjusted life years and looking at any trade offs between the two as we're evaluating companies and it's an input to a decision.

10
00:01:09,840 --> 00:01:16,829
So a decision maker might want to look at a cost effective analysis to help them make decisions about whether they'd like to do policies,

11
00:01:16,830 --> 00:01:27,390
ABCD or E of course, efficiency and raw kind of costs and quality adjusted life years are not the only thing that policymakers care about.

12
00:01:27,840 --> 00:01:34,319
Clearly, equity is important, and today we'll talk about equity and how we might think about that and really,

13
00:01:34,320 --> 00:01:42,840
I guess how in the videos you've been watching and a lot of things I'll present today are how cost effectiveness researchers might think about equity.

14
00:01:42,930 --> 00:01:47,579
This is a relatively new area for cost effectiveness.

15
00:01:47,580 --> 00:01:53,490
Researchers to be looking at ways, of course, people care about equity for a long time.

16
00:01:54,030 --> 00:02:01,019
And but with that said, these kind of more formal methods for quantifying equity are are relatively new,

17
00:02:01,020 --> 00:02:03,839
at least in the world of health policy and cost effectiveness.

18
00:02:03,840 --> 00:02:09,030
Analysis of everything I'm talking about say the you're watching none of these things are

19
00:02:09,120 --> 00:02:16,830
the end all be all written in stone and is an authoritative way of evaluating equity.

20
00:02:18,450 --> 00:02:22,830
So please speak your mind here and then let me know your thoughts about some of this.

21
00:02:22,940 --> 00:02:27,300
This is all relatively new. I'm going to present to you the way some of these researchers think about this.

22
00:02:27,570 --> 00:02:32,340
They're not necessarily the right answers, but we'll we'll kind of walk through it here.

23
00:02:32,820 --> 00:02:36,120
So the first thing I want to talk about are a kind of equity efficiency tradeoffs.

24
00:02:36,120 --> 00:02:44,280
And then we'll talk about one of the methods that is gaining a lot of popularity called distributional cost effectiveness analysis.

25
00:02:46,670 --> 00:02:50,840
So we think about equity efficiency trade offs.

26
00:02:51,200 --> 00:02:59,930
One of the things that you, most of you or some of you actually say did was this this survey here.

27
00:03:02,160 --> 00:03:08,960
Here we know of a survey on Qualtrics and it was listed.

28
00:03:09,260 --> 00:03:13,489
It was ungraded. So many of you maybe decided you didn't need to do this, which is fine.

29
00:03:13,490 --> 00:03:14,630
You didn't need to do it.

30
00:03:15,260 --> 00:03:26,570
But it was a survey asking you about about thinking about efficiency and equity and your thoughts, I should say most of the students here, you know,

31
00:03:26,690 --> 00:03:34,430
did say that, you know, government should redistribute income, which is slightly different from what we're talking about here about health.

32
00:03:34,760 --> 00:03:38,240
And then most people did say they were kind of on the political left.

33
00:03:41,060 --> 00:03:46,520
And most people said they do support reducing health inequality between rich and poor.

34
00:03:48,200 --> 00:03:53,060
And then many people did think that reducing inequality was was very important.

35
00:03:54,610 --> 00:04:02,090
And then but in this I mean, I should say, you know, cost effectiveness, researchers were very interested in quantifying,

36
00:04:02,540 --> 00:04:07,519
as you as you may have noticed in this class, quantifying things very precisely as possible.

37
00:04:07,520 --> 00:04:11,329
So quantifying precisely how many dollars are being spent on intervention,

38
00:04:11,330 --> 00:04:16,760
a person intervention, be precisely quantifying how many quality adjusted health, I should say,

39
00:04:17,030 --> 00:04:21,919
and and doing that oftentimes with this measure of a quality adjusted life year

40
00:04:21,920 --> 00:04:25,950
where we're saying quality of life with this specific health state is a .67.

41
00:04:25,950 --> 00:04:34,159
In this health state, it's a .82. And this I'll say 2.97, you know, for very precisely quantifying that the health of things.

42
00:04:34,160 --> 00:04:39,290
And so naturally when the researchers who do this kind of work are thinking about equity,

43
00:04:39,290 --> 00:04:42,980
they want to precisely quantify how do you think about equity?

44
00:04:44,210 --> 00:04:54,980
And so in this survey, some of the things you looked at here were some trade offs and maybe I'll zoom in on this.

45
00:04:55,070 --> 00:05:03,020
So not everyone I think did this here today. So I just want to recap the types of questions that are being asked here.

46
00:05:03,440 --> 00:05:15,230
And I will say this is based off of a survey done in the U.K. to try to really precisely quantified preferences or feelings about equity.

47
00:05:16,370 --> 00:05:21,830
It does in some way conflate a couple of other things. They talk about the richest fifth and the poorest fifth,

48
00:05:22,370 --> 00:05:29,810
although sometimes researchers will think about this in terms of that, the healthiest fifth and the least healthy fifth.

49
00:05:30,560 --> 00:05:34,910
So here they're kind of providing two different concepts about wealth and and health here.

50
00:05:35,240 --> 00:05:40,700
But in this example here we have and maybe it's on to unfair to do that.

51
00:05:40,700 --> 00:05:46,110
I mean, there are clearly are very strong correlations between wealth and health, but it's not necessarily the same thing personally.

52
00:05:47,180 --> 00:05:52,010
So here we can see two different potential programs here, program and program B,

53
00:05:53,690 --> 00:06:02,330
and the sense here is that there are some sort of baseline health here or and and these are life years.

54
00:06:03,410 --> 00:06:06,440
And you can also think about quality adjusted life years lived per person.

55
00:06:06,670 --> 00:06:08,930
I think what this is pointing is just life expectancy.

56
00:06:09,500 --> 00:06:19,760
So people in this example, people in the richest fifth of the population would live to be 74 on average, and people the poorest have lived to be 62.

57
00:06:20,330 --> 00:06:25,969
And then we're thinking about interventions that would extend the life in both of those populations.

58
00:06:25,970 --> 00:06:30,560
And so we see the little green bars as an extension of life expectancy.

59
00:06:30,560 --> 00:06:34,310
We can also take on as quality of just life expectancy in these two populations.

60
00:06:34,970 --> 00:06:40,400
And the idea here is we have two hypothetical programs, program A, program B,

61
00:06:42,080 --> 00:06:49,610
and they can add additional years of life to these two different populations.

62
00:06:50,210 --> 00:06:58,760
So with program A, we're adding seven years of life to the richest fifth three years of life to the poorest fifth program.

63
00:06:58,760 --> 00:07:03,950
B We had three years of life to the richest and eight years of life to the poorest.

64
00:07:06,500 --> 00:07:09,770
Many questions about this hypothetical scenario. Yes.

65
00:07:10,820 --> 00:07:15,729
So. So I know this example.

66
00:07:15,730 --> 00:07:23,200
And the study came from the U.K., which obviously has a much more rigid class system than in the US.

67
00:07:24,220 --> 00:07:34,810
So I'm curious if there's like in the U.K., do they is it standard to use like measures of class as opposed to help and these kinds of analysis?

68
00:07:36,190 --> 00:07:42,220
So just this study and like this is the example. Yeah, I don't I actually don't know the answer to that.

69
00:07:42,580 --> 00:07:47,290
It might be the case, but I'm not sure. And this is the example here, actually,

70
00:07:47,290 --> 00:07:50,379
Holly German and Scott Greer might be able to better answer that since they're

71
00:07:50,380 --> 00:07:54,910
much more knowledgeable about all the details of what's going on in the U.K.

72
00:07:56,680 --> 00:07:57,510
That would surprise me.

73
00:07:57,520 --> 00:08:02,950
Not that maybe there are some things that I will say, you know, we should be aware the U.K. is different from the United States.

74
00:08:03,010 --> 00:08:05,560
I mean, there are many similarities, but there are many differences.

75
00:08:07,540 --> 00:08:13,840
And one of the distribution of cost effective analysis, I believe you you looked at today.

76
00:08:19,400 --> 00:08:34,809
You're. Alex There is an example in the UK that uses this and when they think about equity they,

77
00:08:34,810 --> 00:08:39,220
they think about income, but they actually know the income of individuals.

78
00:08:39,610 --> 00:08:44,510
So they looked at income based on your neighborhood.

79
00:08:44,560 --> 00:08:48,550
But of course, you know, neighborhoods are quite crowded with income there as here.

80
00:08:49,930 --> 00:08:53,530
And when they thought of racial differences, maybe I'll have you guys guess.

81
00:08:53,800 --> 00:08:56,830
How do they how do they think about kind of racial differences in the U.K.?

82
00:09:00,040 --> 00:09:03,849
I mean, they only measured it by people from the Indian city in this example,

83
00:09:03,850 --> 00:09:09,190
from India, from the Indian subcontinent, as opposed to like other ethnic.

84
00:09:10,060 --> 00:09:14,230
I mean, here in the United States, when we think about race variables, we say we say black,

85
00:09:14,230 --> 00:09:18,970
we say Native American, maybe Hawaiian Pacific Islander or maybe Asian.

86
00:09:19,690 --> 00:09:23,320
But when we say Asian, we just say Asian as this giant kind of category.

87
00:09:24,430 --> 00:09:31,299
Whereas in the head and Hispanic ethnicity, that's how Americans think about race.

88
00:09:31,300 --> 00:09:33,160
But in the UK, when they think about it,

89
00:09:33,490 --> 00:09:41,230
it's do you live in a neighborhood with one of the highest quintiles of people living or originate from the Indian subcontinent?

90
00:09:41,830 --> 00:09:49,900
So, you know, it's very different way that they think about race in the U.K. than we do here in the United States anyway.

91
00:09:50,080 --> 00:09:56,350
There are a lot of differences between how the U.K. does things and the way we think do things here and think about things here as well.

92
00:09:56,870 --> 00:09:59,380
With that said, I think this is still kind of an interesting,

93
00:09:59,800 --> 00:10:10,240
useful example to think about equity and how we how policymakers might want to think about equity.

94
00:10:10,250 --> 00:10:16,120
And I think there are some interesting questions here, theoretical questions and moral questions about, you know,

95
00:10:17,050 --> 00:10:21,850
who should be making these decisions about equity and should policymakers just use their own preferences

96
00:10:21,850 --> 00:10:26,320
or should they survey the population and try to figure out what the population preferences are for,

97
00:10:26,620 --> 00:10:32,590
for equity as well? Interesting questions here.

98
00:10:33,490 --> 00:10:42,520
Anyway, so here we have programing and program B and this the researchers and kind of ask these hypo of functions and you who answered this

99
00:10:42,520 --> 00:10:52,460
question were asked questions here about program versus program B and it looks like everyone in this class preferred program.

100
00:10:52,480 --> 00:10:54,970
B, why might someone prefer program b?

101
00:10:58,480 --> 00:11:04,410
The answer is yes because it supports the Portsmouth, because it supports the poorest fifth over the richest people.

102
00:11:05,040 --> 00:11:13,020
Yeah. So here that the poorest fifth you are gaining more quality at just over five years here than impregnate so

103
00:11:13,200 --> 00:11:19,499
they're gaining more and so you are supporting a population and disadvantage in kind of two dimensions.

104
00:11:19,500 --> 00:11:24,270
One, their wealth they're the poorest fifth and also they start off with the lowest baseline based on health.

105
00:11:24,270 --> 00:11:30,450
So so you're you're you're giving an advantage to this disadvantaged population.

106
00:11:31,470 --> 00:11:38,520
You're reducing the gap. So here in this example, they highlight the total gain, but also the gap.

107
00:11:38,520 --> 00:11:45,479
So the gap is the kind of final gap between life expectancy in the two groups and someone you could also argue.

108
00:11:45,480 --> 00:11:48,170
Also, Program B has the biggest total gain here.

109
00:11:48,180 --> 00:11:56,480
Two of these populations are the total gain of like here's an entire population in this example is highest program B.

110
00:11:58,490 --> 00:12:05,210
Okay. So everyone in this class felt that program B was the best when they had any questions.

111
00:12:08,370 --> 00:12:13,760
And so that was the first question. That one, I think, is a relatively easy question.

112
00:12:15,170 --> 00:12:19,370
Sorry. The next question is a little bit trickier here, a little more challenging.

113
00:12:20,450 --> 00:12:23,750
Here we have the.

114
00:12:26,580 --> 00:12:33,780
And these questions, I guess, get progressively more difficult, I think as now here in this example here.

115
00:12:35,790 --> 00:12:41,970
Program and program B have the same game ten life years games or both.

116
00:12:45,150 --> 00:12:47,640
Ten total gain in both these options here.

117
00:12:48,330 --> 00:12:59,220
But many of you chose program B over program A again, I think because of the answer given earlier here, it's advantaging you know what?

118
00:12:59,460 --> 00:13:05,010
Why is this? Sorry.

119
00:13:05,280 --> 00:13:39,470
That is not up to date. That.

120
00:13:50,470 --> 00:13:58,460
Here we go. Yeah, this is correct. Here. I did it. So we had 40 people respond as of at least last night.

121
00:13:58,470 --> 00:14:02,490
A few more of you maybe. Or some this morning. But anyway, most people chose program B.

122
00:14:03,860 --> 00:14:08,090
One person said we're going to be A and B are equally good in this example.

123
00:14:09,260 --> 00:14:18,740
Then the next question is very similar. Basically, as these questions go along here, b began to mean is reduced the bridges.

124
00:14:19,010 --> 00:14:24,290
Basically the only thing changes in program B as these questions evolve and the resistance

125
00:14:24,290 --> 00:14:30,589
always get plus three and the poorest fifth get the plus seven off and plus eight,

126
00:14:30,590 --> 00:14:37,250
then goes ten plus seven plus six plus five. So this kind of green bars is shrinking as these questions go along here.

127
00:14:37,670 --> 00:14:41,670
So now. With this one here.

128
00:14:42,720 --> 00:14:48,540
One person said the programs are equally good recipes recipe program b here with the gain of five.

129
00:14:48,960 --> 00:14:54,380
One person said Program A is better. Another person said Program a fear equally good.

130
00:14:54,390 --> 00:14:58,410
But most of the class said program B was best here.

131
00:14:58,410 --> 00:15:08,490
When we get to plus three plus for this program B, more people said program was best, but still a large majority said program B was best.

132
00:15:10,140 --> 00:15:22,230
Now here, when it gets two plus three plus three, now it's more 5050 saying program as best person, program B and then here when program eight.

133
00:15:24,260 --> 00:15:31,559
Gives. Plus three, the poorest fifth in program B only gives plus two to the poorest.

134
00:15:31,560 --> 00:15:39,540
And most people said Program A, although three people did say Program B was better than better than him.

135
00:15:40,110 --> 00:15:48,000
And that's the last question. So a few things I want to highlight here, I guess, is there is there's quite a bit of a variety of opinions.

136
00:15:48,230 --> 00:15:53,969
There's no kind of right or wrong answer here. These are just, you know, personal preferences here, but there's quite a bit of variation.

137
00:15:53,970 --> 00:16:01,200
So, again, one person thought that at this point for him and B, were equally equal to each other.

138
00:16:02,190 --> 00:16:10,110
And then for this one, there were still, you know, 25% of the population of the population in this class said that program B was better than that.

139
00:16:10,110 --> 00:16:17,010
So there's some variation in preferences or feelings about kind of efficiency and efficiency, equity tradeoffs.

140
00:16:18,120 --> 00:16:21,210
Any questions so far about this, this kind of hypothetical question?

141
00:16:26,860 --> 00:16:32,409
Yeah. So I was like, when I did the survey, I was like, Eh, gallantry.

142
00:16:32,410 --> 00:16:38,260
And number three was the person who would like take a lot of efficiency trade offs to increase equity.

143
00:16:39,550 --> 00:16:49,629
And my main reason for that is that like the research that I read and like my moral beliefs is that like inequality like hurts everyone,

144
00:16:49,630 --> 00:16:52,870
like rich and poor alike, but obviously especially the poor.

145
00:16:53,770 --> 00:16:55,930
And I'm wondering if there's a way that.

146
00:16:56,960 --> 00:17:06,290
These kinds of analysis can capture that that like that that inequity by like health and wealth is damaging to help overall.

147
00:17:06,590 --> 00:17:12,860
Like everyone is damaged by that. So that's that's a good good point.

148
00:17:13,100 --> 00:17:16,010
And this these kind of theoretical questions,

149
00:17:16,070 --> 00:17:22,190
they assume that everything else is that outside of this and this is the only thing that you're you're looking at.

150
00:17:22,190 --> 00:17:26,839
But clearly, I guess you're thinking about some things outside of this that that yes,

151
00:17:26,840 --> 00:17:31,910
in this example, the richest fifth only get three additional years of life expectancy.

152
00:17:31,940 --> 00:17:39,589
So they're losing out on four additional years of life expectancy. But somehow their life is better here and here because of reduced inequality.

153
00:17:39,590 --> 00:17:41,960
I mean, that's kind of what you're getting at, right? Yeah. Yeah.

154
00:17:43,070 --> 00:17:47,810
And then even here, even though the poorest, if they lose out on a year of life expectancy,

155
00:17:48,110 --> 00:17:51,520
their lives are better here than here because there's a lower gap.

156
00:17:51,530 --> 00:17:56,000
Is that what you're saying? Yeah. Yeah. And that's something that what I mean.

157
00:17:56,060 --> 00:18:04,340
I think so that's that's part of your thinking here. It's not necessarily explicit, but I mean, I think that's I mean, that is part of your, I guess,

158
00:18:04,340 --> 00:18:13,999
preferences and your belief that that that this reduce the gap actually improves kind of quality of life for both groups.

159
00:18:14,000 --> 00:18:15,650
I think that's what you're seeing right now.

160
00:18:17,180 --> 00:18:25,750
I guess I have a question when you're like top working with policymakers or something, how often is equity in cost effectiveness action up?

161
00:18:26,630 --> 00:18:33,709
Because I feel like. I mean, in the US I feel like the righteous people are running our country and so they wouldn't

162
00:18:33,710 --> 00:18:39,320
want to use program aid because it increases the richness of people's life expectancy.

163
00:18:39,350 --> 00:18:44,900
Maybe I'm a pessimist, but I just feel like that's probably wouldn't even be thought of.

164
00:18:47,060 --> 00:18:49,760
So, I mean, you're bringing up some interesting questions, I guess.

165
00:18:52,310 --> 00:18:58,459
Maybe the fact that this is a new phenomenon that people are even trying to quantify this in the last five or

166
00:18:58,460 --> 00:19:03,650
ten years suggests that maybe it hasn't been important enough for people to try to kind of quantify equity.

167
00:19:04,730 --> 00:19:11,510
With that said, people are trying to do this. So I think there is growing interest certainly from academics, but I think also from policymakers.

168
00:19:13,550 --> 00:19:19,910
And so I think there is a growing interest in equity.

169
00:19:20,450 --> 00:19:28,460
You're right, though, there are a lot of kind of powerful forces that that have a lot of influence in our government.

170
00:19:28,910 --> 00:19:33,590
And, you know. Yeah, that that kind of richer you are, the more influence you probably have.

171
00:19:33,590 --> 00:19:39,170
And so you can advocate for for yourself better with you if you have more resources.

172
00:19:39,620 --> 00:19:48,469
And so, you know, with that said, I think there are plenty of really wealthy people who do care about equity and and do want to see that.

173
00:19:48,470 --> 00:19:55,790
You constantly hear about philanthropists giving away a lot of money to to help underprivileged populations.

174
00:19:56,060 --> 00:19:58,190
So I think there is there is an interest in them.

175
00:19:58,190 --> 00:20:06,980
And as we look at our our class here, you know, only only one person here said that these were equivalent,

176
00:20:07,130 --> 00:20:13,730
that basically you kind of think about pure efficiency. By the way, no one said program pay is better than B now.

177
00:20:13,730 --> 00:20:18,230
Maybe maybe there's some kind of social stigma or something like that of of admitting to that or something like that in the classroom.

178
00:20:19,160 --> 00:20:26,360
Hopefully, this is anonymous. I didn't try to identify any particular people here, but no one said, Hey, hey is better than be in this classroom.

179
00:20:27,890 --> 00:20:33,980
But of course, people in the classroom are not, you know, president of the United States or speaker of the House or anything like that.

180
00:20:35,620 --> 00:20:43,250
And, you know, one's in the US Senate here, so, you know, maybe your preferences are different than those kind of enacting policy.

181
00:20:43,490 --> 00:20:46,850
But you know, no one here said that A is better than B, no one.

182
00:20:46,850 --> 00:20:51,110
No one actually was explicitly kind of pro rich in this in this example here.

183
00:20:53,510 --> 00:21:02,270
And many, many people, you know, would trade away a lot of efficiency for equity in this classroom, at least.

184
00:21:04,460 --> 00:21:09,650
Yes. In fact, let me just kind of we'll get to this literally.

185
00:21:10,430 --> 00:21:16,040
But but so I think people people certainly do have preferences for equity,

186
00:21:16,700 --> 00:21:21,710
whether or not it's the it's the, you know, policymakers kind of at the top of that that do care about it.

187
00:21:22,250 --> 00:21:25,550
I think there's growing interest in that. And and I think you'll you'll see that.

188
00:21:26,960 --> 00:21:34,820
But actually, I will say, I don't know of any U.S. politicians who have done a survey like this or have read the results of a survey like this.

189
00:21:35,480 --> 00:21:42,350
This was based on a study in the UK. There are no as far as I know, you know, U.S. studies that, you know,

190
00:21:42,410 --> 00:21:50,060
try to precisely evaluate Americans thoughts about different suburbs and equity in a health setting,

191
00:21:51,320 --> 00:21:54,980
how you can ask these kind of similar questions about income distribution.

192
00:21:55,250 --> 00:22:00,230
And there have been some in the U.K. and the U.S. on income distribution, but not for health.

193
00:22:01,640 --> 00:22:11,600
Yeah. And I will say the I mean, my perception is that in the U.S., when we think about equity, we don't think about it precisely in this way.

194
00:22:11,930 --> 00:22:13,430
I'm not saying this is the best way to think about it,

195
00:22:13,430 --> 00:22:21,350
but people oftentimes will identify populations that they see as disadvantage and they'll try to advocate for that population.

196
00:22:21,620 --> 00:22:30,030
But they they won't have a a precise kind of goal in terms of, well, I need to achieve kind of this level of equity,

197
00:22:30,040 --> 00:22:32,960
or maybe I'm willing to trade off this level of efficiency for equity.

198
00:22:33,350 --> 00:22:41,480
So I'll just say, well, I worked with an advocate in in the San Francisco area who was very concerned about hepatitis B,

199
00:22:41,720 --> 00:22:48,260
and that was a disease that that affected Asians or more often than other populations.

200
00:22:48,260 --> 00:22:52,760
So they advocated for they created this Asian liver center that that tried to reduce that

201
00:22:52,760 --> 00:22:57,470
disparity and make people aware of their hepatitis B and treat give or treat for hepatitis B.

202
00:22:57,680 --> 00:23:00,890
But, I mean, that was very much focused on that particular population.

203
00:23:01,940 --> 00:23:06,589
And I don't think there was any any thought about efficiency, equity tradeoffs or something like that.

204
00:23:06,590 --> 00:23:12,590
I mean, there are people who advocate for women in children's health or African-American health or Native American health,

205
00:23:13,880 --> 00:23:19,640
health and Hispanic and Latino communities with the with the goal, I think, of reducing disparities.

206
00:23:19,640 --> 00:23:30,140
But I don't think anyone has, you know, thought precisely about, you know, what are, you know, what, what is our end goal here?

207
00:23:30,140 --> 00:23:36,500
And is there an efficiency equity tradeoff? Does that answer your question?

208
00:23:36,610 --> 00:23:45,130
Yeah. You know, by the way, I don't know if actually quantifying these things in this way is is very helpful.

209
00:23:46,300 --> 00:23:49,410
But I want to present this to you because this is how people are thinking about.

210
00:23:52,500 --> 00:24:01,140
You can tell me if you think it's helpful or not to. So kind of.

211
00:24:01,380 --> 00:24:07,530
So anyway, this is this is a survey to kind of think about efficiency, equity tradeoffs in a in a more precise way.

212
00:24:09,500 --> 00:24:16,100
And. The way someone who would be thinking about distributional cost effectiveness

213
00:24:16,100 --> 00:24:20,540
analysis would think about these things in terms of kind of two dimensions here.

214
00:24:23,120 --> 00:24:27,799
Thinking about something being more cost effective or less cost effective because you could think

215
00:24:27,800 --> 00:24:36,490
about now this is transforming our previous two dimensional cost factors plane into one dimension.

216
00:24:36,500 --> 00:24:40,100
So saying something is more cost effective or less cost effective,

217
00:24:40,640 --> 00:24:47,090
but then adding a new dimension here of equity and saying something has more equity or less equity.

218
00:24:49,550 --> 00:24:55,340
And yeah, I was at a meeting called the Society for Medical Decision Making a week ago.

219
00:24:55,640 --> 00:25:01,969
And you know this there were a bunch of people who were trying to researchers generally kind of academics,

220
00:25:01,970 --> 00:25:06,680
but thinking about how do we incorporate equity or how should we be thinking about equity?

221
00:25:07,010 --> 00:25:14,330
And again, in the US there's very, very, very little quantification of these trade for efficiency and equity.

222
00:25:15,050 --> 00:25:19,459
But I think even just thinking about things in terms of this plane are are useful.

223
00:25:19,460 --> 00:25:25,040
So we think about, you know, if you were up in this region, this is our big checkmark.

224
00:25:25,040 --> 00:25:28,910
Yes. We like things that are more cost effective and increase equity.

225
00:25:29,450 --> 00:25:31,370
But there are some interesting questions here about, well,

226
00:25:31,370 --> 00:25:36,559
what if you have something here where it is more cost effective but it hurts equity or similarly

227
00:25:36,560 --> 00:25:40,310
down to this quadrant here where we might have something that's not so cost effective,

228
00:25:40,310 --> 00:25:46,880
but it increases equity. And this is where these kind of trade offs come into play in these kind of quadrants.

229
00:25:48,690 --> 00:25:52,400
So maybe actually you don't need to worry about equity if you're if you're up in this part.

230
00:25:52,660 --> 00:25:56,850
You got something that's, let's say, really cost effective.

231
00:25:56,850 --> 00:26:00,360
And it helps homeless drug addicts, you know, get better lives.

232
00:26:00,500 --> 00:26:04,229
Like, I think they might be really might have really bad outcomes.

233
00:26:04,230 --> 00:26:08,880
And you're using the really cost effective way to improve their health outcomes. But maybe that's a win win.

234
00:26:09,030 --> 00:26:15,900
But again, there are some times here where you might be in one of these programs here where we're asking kind of more difficult questions.

235
00:26:19,640 --> 00:26:28,790
So again, this this concept of distribution of cost effectiveness analyzes is is a new approach that's gaining popularity.

236
00:26:29,360 --> 00:26:34,100
And what it does is it looks at the distribution of health benefits and opportunity costs.

237
00:26:35,120 --> 00:26:41,060
So not only what's and everything we learned about so far in this class just talks about what are the total qualities gained.

238
00:26:42,020 --> 00:26:46,040
But it doesn't look at who gains the qualities, for example.

239
00:26:46,520 --> 00:26:49,910
So it's examining the distribution of those health benefits, opportunity costs.

240
00:26:50,510 --> 00:26:54,530
And then again, if there are trade offs. So we think we're in one of these quadrants here.

241
00:26:56,910 --> 00:27:00,120
Then look at the equity constraints and waiting.

242
00:27:00,930 --> 00:27:08,130
And, you know, one way to think about this is your objective is some sort of weighted function of efficiency versus equity.

243
00:27:12,080 --> 00:27:13,580
So there are a lot of different steps here.

244
00:27:14,450 --> 00:27:21,320
The first is to identify the policy, Robert Robb and subgroups and I mentioned this kind of earlier here when we talk about the U.K.

245
00:27:21,680 --> 00:27:27,860
When the U.K. thinks of policy relevant subgroups, they think about they would think about for colon cancer screening.

246
00:27:27,860 --> 00:27:40,429
They're thinking about men versus women. They were thinking about people who live in areas with high elevations from the Indian subcontinent ancestry.

247
00:27:40,430 --> 00:27:48,890
They're thinking about income. So they have a different sense of what their policy relevant subgroups are for that particular problem.

248
00:27:49,400 --> 00:27:53,220
But in the U.S., we might have different ways of thinking about cultural subgroups.

249
00:27:54,530 --> 00:28:03,530
And number two is construct a baseline distribution of health. And so we think about this here, too, is it might be the blue bars here, 74 and 62.

250
00:28:03,540 --> 00:28:10,390
What is our baseline distribution of health? And then if I need to post.

251
00:28:11,940 --> 00:28:18,600
Intervention distributions. And so that's kind of the bars, the green bars on top, the total, you know, distribution of health.

252
00:28:19,530 --> 00:28:27,150
After you do your intervention, then comparing the poster interventions using that equity impact point.

253
00:28:28,740 --> 00:28:38,740
So he. Actually for you guys here.

254
00:28:41,240 --> 00:28:44,840
So this first example here, let me zoom in on this.

255
00:28:47,950 --> 00:28:52,810
Where will we put interventions and be on the equity impacts plan?

256
00:28:52,840 --> 00:28:56,770
We had to roughly put them on equity impact plan.

257
00:28:58,420 --> 00:29:02,080
So which one has more? Which one is more efficient? Assuming they have the same cost.

258
00:29:02,410 --> 00:29:12,120
In which one is more equitable? So how do they relate to each other in terms of efficiency and equity?

259
00:29:12,740 --> 00:29:25,390
Use the whiteboard. So it's an intervention is here.

260
00:29:25,630 --> 00:29:31,840
So where is B in relation to AA in terms of efficiency and equity when we've got this example?

261
00:29:40,050 --> 00:29:44,460
More efficient and it like promotes equity more so it would be higher and more to the right.

262
00:29:45,220 --> 00:29:50,090
Yeah. So in this case, B is, is more efficient. The way I think about efficiency is the total gain here.

263
00:29:51,150 --> 00:29:56,160
So if for the same price you're gaining more by features or quality, just the by features would be.

264
00:29:56,550 --> 00:29:59,550
So it's more efficient and then it's also for equitable.

265
00:29:59,550 --> 00:30:03,090
That gap is is smaller here.

266
00:30:03,840 --> 00:30:06,569
So program B would be more equitable as well.

267
00:30:06,570 --> 00:30:16,920
So it's kind of moving along, you know, both dimensions here, increasing the total gain and also improving equity.

268
00:30:19,650 --> 00:30:26,010
So that might be how we would put that on the equity impact plan. But then let's say we've got intervention five or something here.

269
00:30:27,750 --> 00:30:36,010
So now. If we're comparing A versus B here, you zoom in against and see this.

270
00:30:39,240 --> 00:30:47,730
Now where does B sit relative to? Efficiency on Mars, Edwards.

271
00:30:49,450 --> 00:30:53,170
Key to the efficiency and equity.

272
00:30:54,630 --> 00:31:01,830
So let's. Why do you say less efficiency? Because the total game is seven, which is faster times.

273
00:31:02,100 --> 00:31:07,799
Yeah. So you're not gaining as total as many life years. So what would you consider is less efficient?

274
00:31:07,800 --> 00:31:11,190
And you also say it is less equitable. You have a gap.

275
00:31:11,220 --> 00:31:14,940
Oh, no, it's it's more equitable.

276
00:31:15,030 --> 00:31:18,809
So it has a lower down. So here. Yeah, in this example here, be with me.

277
00:31:18,810 --> 00:31:23,370
Over here we have less efficiency, less turn and total years of life gain.

278
00:31:23,730 --> 00:31:27,270
But more equitable in that.

279
00:31:27,270 --> 00:31:30,750
That the difference between those two populations is. Is small.

280
00:31:36,230 --> 00:31:46,100
So that's and so for example, then if you were thinking about if you were facing this question here of A versus B and A games,

281
00:31:46,100 --> 00:31:49,790
ten years B games, 11 years A has a gap of 16 years.

282
00:31:49,790 --> 00:32:00,470
B has gap of seven years here. Here, in that first example, this blue the first example is is better than am on both those dimensions.

283
00:32:00,740 --> 00:32:06,620
And so we wouldn't worry about the trade offs. We say, okay, B is better in terms of efficiency and equity.

284
00:32:07,010 --> 00:32:11,150
However, if you were facing problem five here instead.

285
00:32:14,050 --> 00:32:19,750
Now there is a. Now here is down here comparatively and you are facing a trade off.

286
00:32:19,750 --> 00:32:26,170
And so then it might be important to understand how do people feel about those tradeoffs between efficiency and.

287
00:32:28,430 --> 00:32:32,630
So that's that's the thinking behind step four here.

288
00:32:33,080 --> 00:32:37,310
If if they're first of all, you know,

289
00:32:37,340 --> 00:32:43,340
put those on the health equity impact plan and then if there are some trade offs, then you want to think about that.

290
00:32:43,340 --> 00:32:49,459
And the approach in this distributional cost effective analysis is to use a social welfare function,

291
00:32:49,460 --> 00:32:59,000
and the social welfare function is fed in by that aversion to inequality that one would assess by asking these types of questions.

292
00:33:03,800 --> 00:33:08,420
And then the last step here is conduct, sensitivity, analysis, performance, social welfare function, etc., all the evasion.

293
00:33:09,260 --> 00:33:13,520
And I guess I'll say, you know, as we see we saw in this class and your answers here,

294
00:33:14,450 --> 00:33:21,890
there is quite a bit of variation in terms of what individuals had said their preferences are for efficiency versus equity.

295
00:33:28,370 --> 00:33:31,610
So in the tutorial you get a question.

296
00:33:31,820 --> 00:33:37,490
Yeah, sorry for that. Like plotting the programs on the plane.

297
00:33:37,910 --> 00:33:44,340
Do you always put like, I guess like the equivalent of program or whatever it is, like the status quo.

298
00:33:44,360 --> 00:33:53,750
Like you always put that at the intersection of the, of the axes or like would you start out with like eight MP being in different places?

299
00:33:54,080 --> 00:33:59,480
Like, I guess I'm just curious like if we're supposed to do this homework, like how would we go about plotting?

300
00:33:59,900 --> 00:34:06,300
Yeah, I mean, in this case, I mean, I think the key thing is to understand how does a relate to to be.

301
00:34:07,430 --> 00:34:19,430
And so and actually I mean technically in this example here any one of these here, I suppose you could also think about none of the above.

302
00:34:19,760 --> 00:34:26,600
So none of the above you only get 74 and 62 or you could do a or you could do B.

303
00:34:26,690 --> 00:34:31,429
So it kind of depends on, you know, none of the above.

304
00:34:31,430 --> 00:34:37,610
And then let's say a. Actually they probably integrate increases.

305
00:34:38,150 --> 00:34:42,320
Sorry, they would be over here. Maybe it increases inequality.

306
00:34:42,320 --> 00:34:47,510
The gap was 12 years. Now here the gap gets to 16 years.

307
00:34:47,960 --> 00:34:55,470
So a would be. This is efficiency.

308
00:34:56,010 --> 00:35:00,210
I'm just going to say it and let's assume it's efficient because is actually a cost to that.

309
00:35:00,570 --> 00:35:10,620
And then equity is here and so we'd be more efficient, but but also increase in quality with A and then program B.

310
00:35:11,220 --> 00:35:15,930
The gap is nine years, so that's less than it was here.

311
00:35:15,930 --> 00:35:21,240
So A B would be over here. So it's it's more equitable compared to none.

312
00:35:22,290 --> 00:35:26,519
And you actually, in this case, the gap is the gain is nine years.

313
00:35:26,520 --> 00:35:34,530
So it's less efficient, right? So it's less efficient than a but more equitable than non more equitable than a.

314
00:35:35,340 --> 00:35:38,700
Yeah. Now where you put the origin is kind of irrelevant.

315
00:35:40,500 --> 00:35:46,050
What's important is how do these three or two or whatever sit relative to each other?

316
00:35:49,580 --> 00:35:56,290
It's a good question. Other questions? Yeah.

317
00:35:56,290 --> 00:36:02,230
I think again. Where are you for the origin? Less. Less important. What? What is important is how do these things sit relative to each other?

318
00:36:03,010 --> 00:36:10,540
And because you're making a decision between. Let's see. Well, in this case, it's just A versus B, and you're not told that that not as an option.

319
00:36:11,980 --> 00:36:17,770
And so you really do want to think about, okay, versus B, how much efficiency am I giving up, but how much equity in my gaining?

320
00:36:18,400 --> 00:36:30,719
I think both those tradeoffs. Anyway.

321
00:36:30,720 --> 00:36:38,310
So this last step, though, here is to conduct sensitivity analysis on the form and the level or extent of inequality version.

322
00:36:38,610 --> 00:36:40,890
Again, because there is quite a distribution in that.

323
00:36:41,130 --> 00:36:51,060
And, and in the tutorial example, I think you read for today, this is an example of that distribution of health here.

324
00:36:51,150 --> 00:36:55,229
Now, this is slightly different. This is not wealth here on the x axis.

325
00:36:55,230 --> 00:37:02,389
It's least healthy to most healthy. And there are some people who might be really wealthy, might be unhealthy.

326
00:37:02,390 --> 00:37:11,030
Some people who are not as wealthy might be more more healthy. But what they did was they simulated all these, you know, 50 or something,

327
00:37:11,030 --> 00:37:17,750
different populations and for each population, calculated, quality, adjusted life expectancy.

328
00:37:18,260 --> 00:37:24,950
And so that's the 20% of the population with the lowest quality adjusted life expectancy would be here in this bar.

329
00:37:25,310 --> 00:37:29,990
And the 20% with the highest quality is the life expectancy over here in this upper bar.

330
00:37:31,730 --> 00:37:34,850
And that's is how they thought about that distribution of health.

331
00:37:34,850 --> 00:37:40,339
So they broke up the population into small sub segments and then calculated the

332
00:37:40,340 --> 00:37:45,710
quantities of life expectancy to be gained or to be lived by in each of the populations.

333
00:37:45,920 --> 00:37:49,160
And so this is how they built that distribution of health.

334
00:37:51,260 --> 00:37:54,649
Let me see back. So any thoughts on this? I mean, is it is it reasonable?

335
00:37:54,650 --> 00:37:58,760
Is it good to to produce these distributions of health?

336
00:37:59,690 --> 00:38:09,229
Is it useful or not useful help? I wonder if this distribution of health like as opposed to doing it by income masks,

337
00:38:09,230 --> 00:38:15,709
things like the healthy immigrant fact and like the Latino or Hispanic paradox, which I hate that term,

338
00:38:15,710 --> 00:38:21,740
but like basically that like some people who might be very low income and disadvantaged in some ways,

339
00:38:21,740 --> 00:38:29,090
like get marked as healthy and they might still benefit from like different kinds of health interventions as well.

340
00:38:30,260 --> 00:38:39,229
So, so doing this certainly would so it would it would, you know, I mean, now this is this is an example from the U.K. So it's going to have that.

341
00:38:39,230 --> 00:38:46,670
But in the U.S., it might so it would say, look, people of Hispanic ethnicity in general, when you look at it statistically,

342
00:38:46,970 --> 00:38:51,740
they they have a longer life expectancy, but yet they might be disadvantaged in other ways.

343
00:38:51,950 --> 00:38:57,890
And I think it I mean, it certainly might be disparities in terms of income, for example.

344
00:38:58,340 --> 00:39:04,410
And now I think it introduces interesting policy questions about what is the appropriate policy response,

345
00:39:04,520 --> 00:39:11,500
the policy response to do a health intervention, or should or should the policy response be to do some sort of income intervention?

346
00:39:11,510 --> 00:39:15,360
If the problem is income inequality, maybe that should be addressed with income.

347
00:39:15,380 --> 00:39:17,450
Of course, these things are tied together.

348
00:39:18,410 --> 00:39:23,120
But yeah, I mean, you could and actually, if you how many people think that women's health should be prioritized?

349
00:39:24,800 --> 00:39:29,610
People. Now, women have a longer life expectancy than men. Maybe. Should we have men's health departments, right?

350
00:39:30,610 --> 00:39:37,270
I mean, so men, if we were measured in terms of life expectancy, even the quality of life expectancy would be lower than women.

351
00:39:37,340 --> 00:39:41,969
Right. And so so, you know, men in general have lower life expectancy.

352
00:39:41,970 --> 00:39:48,450
Right. And so if you measure it that way, you might say, hey, let's we should do interventions for men's health.

353
00:39:48,720 --> 00:39:53,670
Right. Because they're disadvantaged. Well, of course, men have advantages in many other ways.

354
00:39:56,760 --> 00:40:04,319
Like a lot of this is like also time dependent. So I think we're seeing that as like woman into the workforce and like the environment changes.

355
00:40:04,320 --> 00:40:07,530
Obviously, our life expectancy is decreasing right now as well.

356
00:40:07,920 --> 00:40:10,740
And so I think my main problem with this is just like how.

357
00:40:11,820 --> 00:40:19,400
Limited how it doesn't take into account like the history over a long period of time of the different fluctuations and demographic changes.

358
00:40:19,410 --> 00:40:22,760
So yeah, that's one issue with us.

359
00:40:23,530 --> 00:40:30,420
But it's so so no. Tell me more about your thoughts about changing changing patterns over time.

360
00:40:31,050 --> 00:40:36,860
Right. Well, like immigrants.

361
00:40:36,920 --> 00:40:43,819
Like the Latino, for example. Like just that pattern has changed from, like, the early 1900s to now.

362
00:40:43,820 --> 00:40:49,520
And whether that's like through what jobs are taking off whenever they come in, because like in the 1900s,

363
00:40:49,520 --> 00:40:53,749
we see through various different sources that they were often coming in for like farm work.

364
00:40:53,750 --> 00:40:58,250
And a lot of Latinos still come in to do farm work, but now they're also doing like other jobs as well.

365
00:40:58,780 --> 00:41:03,350
And we see that. And so then it obviously impacts their overall health.

366
00:41:03,800 --> 00:41:11,930
But this like one snapshot of the distribution of health doesn't necessarily take that into account and that change.

367
00:41:11,930 --> 00:41:16,459
And that's only for like one section of a growing part of our population,

368
00:41:16,460 --> 00:41:22,460
which is like Latinos are growing and expected to make up a greater percentage of the US population.

369
00:41:22,790 --> 00:41:31,160
But yeah, I don't know. I think this is just like so one sided comes at the issue from one direction.

370
00:41:31,520 --> 00:41:34,909
So what certainly does come at that issue from one direction?

371
00:41:34,910 --> 00:41:38,840
Right. It's trying to quantify what do we think that distribution of health is?

372
00:41:38,840 --> 00:41:41,959
And you're right, it's it's based on kind of historical patterns.

373
00:41:41,960 --> 00:41:50,030
So if there is a population group that historically maybe had a healthier lifestyle, what their how their lifestyle is changing.

374
00:41:50,450 --> 00:41:59,329
And so and so this is this modeling or whatever would be based on historical patterns of it could be diet and exercise,

375
00:41:59,330 --> 00:42:04,460
it could be smoking patterns, all kinds of other things that that are evolving over time.

376
00:42:06,620 --> 00:42:10,909
And so, yeah, that's something that is embedded in these in these analyzes or models.

377
00:42:10,910 --> 00:42:11,150
Yeah.

378
00:42:11,930 --> 00:42:21,140
Just going back to your example about like men's health, like to me that raises like a really interesting question because like male life expectancy,

379
00:42:21,320 --> 00:42:28,550
a lot of it has to do with like choices, you know, like risky behaviors, lifestyle choices and like violence, things like that.

380
00:42:28,970 --> 00:42:30,350
And I'm curious sort of like.

381
00:42:31,780 --> 00:42:42,490
Is there an attempt to try and like model out sort of like self inflicted like quality loss versus like just quality loss period.

382
00:42:42,790 --> 00:42:45,820
You know, I'm not aware of that. No.

383
00:42:46,990 --> 00:42:49,030
Yeah. And that's that's an interesting question. I mean. Yeah.

384
00:42:49,030 --> 00:42:57,370
To what to what extent should we should we say this is, you know, personal responsibility for for what you've got and then other times, you know.

385
00:42:57,730 --> 00:43:00,490
Yeah, that's an interesting question. And people talk about that right now,

386
00:43:01,240 --> 00:43:05,889
certainly with coronavirus and maybe wearing masks and getting vaccines and like, hey, those people didn't get that.

387
00:43:05,890 --> 00:43:07,270
Some people will say, hey,

388
00:43:07,270 --> 00:43:13,809
those people who didn't get vaccines shouldn't shouldn't we shouldn't we should lock up our hospitals and not let them come there if they if they get,

389
00:43:13,810 --> 00:43:20,020
you know, bad coronavirus infections, because they they didn't take the personal responsibility to get the vaccine, for example.

390
00:43:20,020 --> 00:43:25,060
I mean, there are some people who say that I'm not advocating for that. There are people who do say that kind of thing.

391
00:43:25,720 --> 00:43:34,390
But I will say, you know, 30 years ago, people would also say, hey, those days who got infected with HIV, they didn't take personal responsibility.

392
00:43:34,390 --> 00:43:39,430
And maybe we should just throw them on an island somewhere in the middle of the ocean and forget about them, too.

393
00:43:39,600 --> 00:43:42,940
So, you know, there's this idea of personal accountability.

394
00:43:42,940 --> 00:43:48,220
I mean, I think we want to do things to encourage people to engage in good, healthy behaviors.

395
00:43:49,210 --> 00:43:52,690
But we have to be careful, too, about the kind of personal responsibility here as well, you know.

396
00:43:58,580 --> 00:44:03,830
But anyway, you bring up this this topic here of equity, I think, brings up a lot of really interesting,

397
00:44:03,830 --> 00:44:08,720
thorny questions about how do we think about equity if we want to quantify it.

398
00:44:09,200 --> 00:44:15,710
And I'm not saying we have to, but if we want to quantify, there are very difficult questions about how do we quantify equity?

399
00:44:15,860 --> 00:44:16,670
Was there a question?

400
00:44:19,710 --> 00:44:26,770
You know, and this is one way that researchers have thought about doing that is to again, these are researchers who kind of like me,

401
00:44:26,950 --> 00:44:32,229
you know, build out of mathematical models of disease and say, hey, this is something we can model, right?

402
00:44:32,230 --> 00:44:35,680
We can try to simulate what are the outcome.

403
00:44:35,680 --> 00:44:39,040
We can, you know, break up population growth, hydration group subgroups.

404
00:44:39,340 --> 00:44:43,500
We know some basics of the demographics about life expectancy and willing,

405
00:44:43,510 --> 00:44:50,140
in this case, this example, willingness to to do stool samples for colon cancer, etc.

406
00:44:50,470 --> 00:44:58,870
And because of that, we know we think we know who is least healthy and most healthy and what the life expectancy is likely to be.

407
00:44:59,260 --> 00:45:03,340
And maybe we can send a targeted intervention to, you know,

408
00:45:03,700 --> 00:45:09,520
certain population groups that will then raise up the life expectancy of that least healthy population.

409
00:45:11,940 --> 00:45:13,929
Then they kind of want to quantify that.

410
00:45:13,930 --> 00:45:19,930
So they will take your health distribution age, which is, you know, maybe under some sort of status quo policy.

411
00:45:20,170 --> 00:45:26,540
Health industry should be with a maybe a different policy guide,

412
00:45:26,680 --> 00:45:35,770
the total agreed quality adjusted life years plug them into a social welfare function which includes the inequality aversion, those preferences there.

413
00:45:36,790 --> 00:45:47,370
How could an equally distributed equivalent of A and B and then choose the one with the maximum equally distributed equivalent example.

414
00:45:47,500 --> 00:45:53,950
So in this very high level hypothetical example here, health distribution a well, actually, I'll have you guys tell me.

415
00:45:54,070 --> 00:45:57,700
So what are your thoughts about health distribution and B in this example?

416
00:46:02,500 --> 00:46:05,680
I mean, this one is not quite as simple as some of the other examples.

417
00:46:05,920 --> 00:46:11,650
Here it shows all quintiles and it's not just a difference between the most and least deprived.

418
00:46:12,010 --> 00:46:19,510
They're actually while Quintiles two or three are the same in both, one quintiles four and five and one are slightly different.

419
00:46:20,440 --> 00:46:34,640
Did you ever. You're stretching. So what do you think here in this very hypothetical example about health distribution, a health issue should be here.

420
00:46:36,920 --> 00:46:40,280
Seems more equitable and seems more equitable.

421
00:46:40,460 --> 00:46:44,060
Yeah. The the distribution isn't quite as steep. There isn't.

422
00:46:44,360 --> 00:46:50,810
We look at the most deprived versus least deprived here. This difference here is smaller than this difference here.

423
00:46:52,010 --> 00:46:55,580
So we'd say we'd probably say Hey is more equitable.

424
00:46:57,170 --> 00:47:00,829
But in terms of efficiency here, in this example, the average is 70 qualities.

425
00:47:00,830 --> 00:47:08,990
And in this example, it's 71 quality. So we here in this hypothetical example, just reason B is more efficient but less equitable.

426
00:47:11,240 --> 00:47:20,270
And the idea behind distributional cost effective slices is then we try to plug that idea in to this social welfare function.

427
00:47:20,270 --> 00:47:20,630
The social,

428
00:47:20,900 --> 00:47:31,160
social welfare function is informed by the answers to those hypothetical questions that we saw earlier spending on kind of where you switch here.

429
00:47:33,230 --> 00:47:39,590
You might have different preferences for A versus B, depending on your your willingness to trade off efficiency versus equity.

430
00:47:40,670 --> 00:47:43,820
So some people might say A is better off.

431
00:47:44,450 --> 00:47:48,499
Some people might say B is better depending on their preferences for efficiency versus equity.

432
00:47:48,500 --> 00:47:55,430
And in fact, in this example, the person who said A and B are equally good in this answer here,

433
00:47:55,880 --> 00:48:03,500
that that person is really just most concerned about the health gain and is really focused on efficiency.

434
00:48:03,740 --> 00:48:10,220
So that person would would prefer program B with the highest quality probably.

435
00:48:11,270 --> 00:48:17,299
And, and then the three people who said Program B is better than per me.

436
00:48:17,300 --> 00:48:26,780
In fact, some other view was that B is better than A here would likely say in this case that A is better would be this one is more equitable.

437
00:48:26,780 --> 00:48:30,590
One is better than the one that is less equitable but a little more efficient.

438
00:48:33,600 --> 00:48:40,020
And again, what this social welfare function can do. I mean, if you if you believe in that kind of Atkins an index that we'll talk about in a minute.

439
00:48:40,740 --> 00:48:43,950
What it does is it creates this equally distributed equivalent.

440
00:48:43,950 --> 00:48:48,780
So says, yes, this policy has inequality in it.

441
00:48:49,290 --> 00:48:51,389
What would be the equally distributed equivalent?

442
00:48:51,390 --> 00:48:59,160
And maybe they would consider this distribution equivalent to one where everyone lives 64 years of life or something like that,

443
00:48:59,250 --> 00:49:05,280
let's say equally distributed equivalent. What if this what if this was, you know,

444
00:49:05,460 --> 00:49:11,620
equal across all and then there's equally distribute equivalent for this one and and

445
00:49:11,730 --> 00:49:17,130
then you just pick the one that has the better equally distributed equivalent value.

446
00:49:19,040 --> 00:49:22,519
So what that happens in the next session, which we'll talk with in a minute,

447
00:49:22,520 --> 00:49:31,760
is it takes the answers to these questions and has a formula for basically turning this unequal distribution into an equally distributed equivalent.

448
00:49:32,240 --> 00:49:40,700
And then you just pick the one that you like the best in terms of equally distributed quantity so that it has this function here,

449
00:49:40,700 --> 00:49:52,300
this Atkinson index, and this is the equally distributed equivalent, and that is equal to that eight year health and it's the health of each.

450
00:49:52,640 --> 00:49:59,420
So there are different subgroups, single population in these all of these most examples are between five quintiles,

451
00:50:00,080 --> 00:50:06,860
but you could have 100 groups or whatever it is. So you've got a bunch of different groups and you look at the health of that individual group,

452
00:50:08,000 --> 00:50:14,360
but then apply this kind of weighting factor here that in this case to the power of one minus epsilon.

453
00:50:15,440 --> 00:50:23,150
Now, how many of you know you're epsilon? So this is kind of an obtuse mathematical concept here.

454
00:50:24,590 --> 00:50:29,870
So what we can do here is think about your response to those seven questions here.

455
00:50:30,260 --> 00:50:36,500
So we have the response to question one, two, three, four, five, six, seven.

456
00:50:37,310 --> 00:50:51,469
So if you said hey to all of them, you'd be basically indifferent between a73 and a33, 8.5 and so forth.

457
00:50:51,470 --> 00:50:55,640
Going down the list here, if you said be all the time and we had some people who did that, you know,

458
00:50:55,640 --> 00:51:01,820
roughly we're saying that that a seven gain of seven and three is equivalent to a gain of three and one and a half.

459
00:51:04,370 --> 00:51:11,330
And so these were the names that were given to all of those different answers here.

460
00:51:12,530 --> 00:51:16,849
Again, don't don't feel like you you hate equality or stuff like that.

461
00:51:16,850 --> 00:51:21,260
If you weren't utilitarian and don't feel like you hate efficiency, if you weren't,

462
00:51:21,620 --> 00:51:25,460
you don't care where health, if you weren't a health maximizer or something like that. These are names that they gave to these.

463
00:51:26,630 --> 00:51:29,900
With that said, I think this is really interesting here.

464
00:51:30,140 --> 00:51:35,390
This was England, which many of us might think of as a as a pretty egalitarian society.

465
00:51:35,390 --> 00:51:39,050
And and and there were more egalitarians than pro rich here.

466
00:51:39,380 --> 00:51:45,470
But I think what's really interesting to me is there were 15% of the population that gave pro rich answers,

467
00:51:46,550 --> 00:51:51,950
and a little less than 30% of the population gave egalitarian kind of answers.

468
00:51:52,340 --> 00:51:58,580
And then the other 60% or whatever gave weighted priority and answers.

469
00:51:59,060 --> 00:52:07,190
And also, you know, the cost effectiveness framework assumes that your health maximizer, that was only 5% of the population.

470
00:52:07,820 --> 00:52:09,379
So I think, you know, a few things here.

471
00:52:09,380 --> 00:52:17,690
One, you know, pure health maximization maybe isn't the right answer for all policymakers or at least all cities in the UK.

472
00:52:17,720 --> 00:52:23,120
They weren't they didn't think that was their their preferred answer here.

473
00:52:24,170 --> 00:52:31,130
Maybe surprisingly to me, a significant, noticeable fraction of the population gave this these pro rich answers.

474
00:52:32,720 --> 00:52:41,570
And so that was that was interesting to me. And and then a lot of people gave that egalitarian answer.

475
00:52:41,570 --> 00:52:49,250
So there's a to me anyway, there's a wide set of preferences and distribution of preferences here about equity.

476
00:52:49,490 --> 00:52:54,170
So some people, you know, 20% of the population said, I don't really care about equity.

477
00:52:55,130 --> 00:53:01,660
And then, you know, 30% said equity is basically the only thing I care about, you know,

478
00:53:01,820 --> 00:53:09,410
only but you know, the egalitarian is is very much in, you know, focused on reducing that inequality.

479
00:53:10,910 --> 00:53:15,560
And then so anyway, there's there's quite a bit of distribution here in terms of preferences.

480
00:53:17,150 --> 00:53:19,280
I think that that might make it challenging though,

481
00:53:19,280 --> 00:53:24,760
if you are a policymaker to incorporate equity because you know, you're damned if you do and damned if you don't.

482
00:53:24,780 --> 00:53:29,120
I mean, if you if you say I'm going to go for the equitable policy, you're going to have 25% with you.

483
00:53:29,420 --> 00:53:32,300
If you say, I'm going to concession policy, you're going to have more, you know,

484
00:53:32,660 --> 00:53:36,709
so you're never I mean, maybe that's just politics in general, but in policymaking.

485
00:53:36,710 --> 00:53:41,240
But that's a challenge. Yes. Explain what the maximum means.

486
00:53:41,360 --> 00:53:44,179
I understand what a health maximizer is, but yeah,

487
00:53:44,180 --> 00:53:55,310
so maximal says my my my decision making logic is I want to do whatever it is to maximize the health of the least well-off population.

488
00:53:55,820 --> 00:54:00,740
So if you said these are equally good here, in this example, you would be maximum.

489
00:54:03,860 --> 00:54:07,040
So you say, well, here the poorest fifth gets plus three.

490
00:54:07,040 --> 00:54:09,980
Here the poorest fifth gets plus three. These are equivalent to me.

491
00:54:10,880 --> 00:54:15,740
There's nothing else matters is I just want to do whatever I can to maximize the health of the poorest fifth.

492
00:54:16,040 --> 00:54:23,909
And so if you answered. It's up to me to answer B to this are not maximum because you said I'm willing to trade off health.

493
00:54:23,910 --> 00:54:29,400
I'm willing to take a year of life expectancy off the poorest path in order to improve equality.

494
00:54:30,810 --> 00:54:33,840
So so this this actually this, you know,

495
00:54:34,230 --> 00:54:40,800
B hurts the poorest fifth in terms of their life expectancy might help in other ways, but it hurts their health.

496
00:54:42,270 --> 00:54:49,140
Their life expectancy years per person. It would just be instead of a right they have fewer years of life would be than.

497
00:54:49,800 --> 00:55:02,370
So this is if you chose being of a here that's that's not maximizing health proportions at least in terms of this measure of, you know, years of life.

498
00:55:02,370 --> 00:55:07,180
The person. So that's.

499
00:55:12,760 --> 00:55:18,760
So the Max men again would say that the second to last one is equivalent.

500
00:55:19,110 --> 00:55:23,920
They say, well, three years, three years. All I care about is maximizing the health of that least our population.

501
00:55:24,910 --> 00:55:29,440
But if they said if they said B is better.

502
00:55:32,370 --> 00:55:34,740
If you said be is better here.

503
00:55:38,970 --> 00:55:46,600
B is better here that you do have a preference for some sort of preference for equality over over just caring about the poorest,

504
00:55:46,600 --> 00:55:55,390
then you should be instead of out here. And so then that would push you into what they call the priority or egalitarian group.

505
00:55:55,840 --> 00:56:11,600
Yeah. So these are the those the U.K. And to my knowledge, this is the only study in the world that that has looked at healthy quality.

506
00:56:11,990 --> 00:56:15,440
So people have done kind of similar studies looking at income inequality,

507
00:56:15,800 --> 00:56:21,850
but this is the only one I'm aware of that looks at kind of health inequality here.

508
00:56:21,920 --> 00:56:26,060
Here are our preferences from our class. So I tried to turn that same graph into.

509
00:56:27,260 --> 00:56:32,040
These are the answers as of last night. There are a few other students who did it this morning and have your data.

510
00:56:32,060 --> 00:56:35,510
Sorry about that. But so we had one health maximizer.

511
00:56:36,500 --> 00:56:43,340
A lot of prior trends and about half egalitarian in our in our class as of now.

512
00:56:45,260 --> 00:56:49,640
This is, of course, a very small sample size. But this is kind of what does this come from?

513
00:56:50,000 --> 00:56:50,750
It should be six, ten.

514
00:56:57,350 --> 00:57:10,250
One other thing you can do here is, at least from this particular example, is try to convert this into what's called the implied weight.

515
00:57:11,390 --> 00:57:21,050
So it's basically how how valuable is the health of the the poorest fifth relative to the richest fifth in this example.

516
00:57:22,700 --> 00:57:27,799
So here we have various kind of Atkinson Summers.

517
00:57:27,800 --> 00:57:33,470
So if you remember where you were in terms of protection or egalitarian or health, maximize or whatever,

518
00:57:33,830 --> 00:57:40,370
you can calculate what your Atkinson's Epsilon is an easy one here is that Atkinson's Epsilon of zero?

519
00:57:40,610 --> 00:57:44,740
If you're the health maximizer, so you kind of don't give any weight to the party.

520
00:57:45,320 --> 00:57:51,380
And actually, that maxim in you basically has an infinite Atkinson's Epsilon.

521
00:57:51,860 --> 00:57:57,920
So the the health of that the poorest fifth is infinitely valuable compared to the richest fifth.

522
00:57:59,030 --> 00:58:02,060
You also there's there's a name here for the outrage. We'll get to that in a minute.

523
00:58:03,830 --> 00:58:08,870
But then the implied weight here is again saying if you're a pro, which one?

524
00:58:08,870 --> 00:58:13,670
If you said a all the way, baby, all I care what is a it's always the best.

525
00:58:14,450 --> 00:58:22,070
The implied weight is roughly that the poorest fifth their their health is worth about 70% of the health of a rich person.

526
00:58:22,310 --> 00:58:28,310
It's a little hard to say precisely where to find way is if you said always, but if you said Health Maximizer,

527
00:58:28,310 --> 00:58:32,750
then you're saying, well, a gain of a life year to the poorest and the richest is is equivalent.

528
00:58:33,380 --> 00:58:38,450
So that's pretty straightforward. But then some of these priority areas, let's say priority and five,

529
00:58:38,960 --> 00:58:50,840
it's saying that the a year of life gained in the richest fifth would be equivalent to a gain of two and a half years of life in in the poorest fifth.

530
00:58:54,810 --> 00:59:00,340
And then again, it's still similarly maxim in they say, I don't I don't care what happens to the richest man.

531
00:59:00,360 --> 00:59:03,389
All I care about is maximizing the health gain.

532
00:59:03,390 --> 00:59:09,600
And of course, that's infinitely valuable compared to the richest men. So that's another way of thinking about this.

533
00:59:10,260 --> 00:59:12,170
In these types of examples is, you know,

534
00:59:12,240 --> 00:59:20,430
at what point is the tradeoff here between the 30 years of life gain to the rich death versus the years left to the poorest?

535
00:59:23,500 --> 00:59:36,110
Any questions with this? So in that in that example you read about the colon cancer example here,

536
00:59:36,110 --> 00:59:41,150
there's kind of a universal reminder reminding everyone to get colon cancer screenings and they have a targeted reminder,

537
00:59:41,450 --> 00:59:49,400
targeted populations that they thought were worse off. And they kind of mapped this out.

538
00:59:50,660 --> 00:59:55,430
And it you know, I thought they found some kind of interesting things here.

539
00:59:56,810 --> 01:00:01,230
If you were a health maximizer, you would prefer this universal program.

540
01:00:01,230 --> 01:00:03,710
Just send everyone reminders to get colon cancer screening.

541
01:00:05,030 --> 01:00:19,009
But if you were really in favor of equity and so you'd have this Atkinson's attacks off to the right, you prefer the targeted reminders.

542
01:00:19,010 --> 01:00:23,270
So these were reminders sent to various combinations and the kind of extra enhanced,

543
01:00:23,450 --> 01:00:26,150
enhanced encouragement for them to get their colon cancer screenings.

544
01:00:27,110 --> 01:00:35,749
And if we look back at the U.K. example here, weighted priority and you know, the median preference here is rated priority and seven,

545
01:00:35,750 --> 01:00:45,500
I think, in the U.K. And so if we looked at rate of weighted priority, priority seven, they have an Atkinson index of ten or so.

546
01:00:47,300 --> 01:00:55,340
And so ten or 11. And so in the U.K., they said, hey, well, we think the median U.K. response is about ten or 11.

547
01:00:55,730 --> 01:01:05,120
And so they'd be on this line here. What that means is that here's the difference between universal versus targeted.

548
01:01:05,360 --> 01:01:09,140
And so if it's if this line is positive, that means universal is better.

549
01:01:09,890 --> 01:01:16,070
If the line is negative as it is here. But the point is negative, that means the targeted is better.

550
01:01:16,640 --> 01:01:21,350
And so this is kind of a sensitivity analysis on that inequality aversion.

551
01:01:22,010 --> 01:01:29,540
So if you are that health maximizer and you don't care what inequality or equity you do just say, hey, universal is best.

552
01:01:29,990 --> 01:01:38,210
But as you have more and more aversion to inequality, as that Atkinson index increases here, you would be more and more.

553
01:01:39,020 --> 01:01:45,770
And actually if your epsilon increase exceeds 7.4, then you would switch to preferring the targeted reminders.

554
01:01:45,770 --> 01:01:53,149
And this was the kind of average for the U.K. So they use this approach to try to get an understanding of what

555
01:01:53,150 --> 01:01:59,660
are some of the trade offs between a universal reminder and one that's more targeted on more vulnerable,

556
01:01:59,960 --> 01:02:01,280
disadvantaged population groups.

557
01:02:01,610 --> 01:02:13,970
And they kind of figured that based on U.K. preferences, that this prime this targeted intervention might be preferred.

558
01:02:14,150 --> 01:02:23,180
Although I will say, you know, the cut off here is that an epsilon of 7.4 and an Epsilon 7.4 is weighted for a material six,

559
01:02:23,450 --> 01:02:27,889
which is this group right here. So it's not too far from the median.

560
01:02:27,890 --> 01:02:32,840
I mean, and it's not clear quite the way that you should use the median preferences or anything like that.

561
01:02:32,840 --> 01:02:36,319
It is not necessarily a right or wrong answer here for that.

562
01:02:36,320 --> 01:02:41,630
But yeah, any questions about things?

563
01:02:47,670 --> 01:02:52,820
So kind of what's going on with the distributional cost effectiveness analyzes.

564
01:02:52,830 --> 01:03:01,300
It's just kind of a big picture here too is trying to not not just quantify total cost and total politics with your different pockets,

565
01:03:01,320 --> 01:03:02,550
with your different policies.

566
01:03:03,000 --> 01:03:12,720
But look at the distribution of what those total cost inequalities will be among different subgroups of the population and of creating these.

567
01:03:15,130 --> 01:03:22,750
Distributions A and B, and then what they do is they take the answers to those questions,

568
01:03:23,260 --> 01:03:29,650
feed them into a formula here and try to figure out which one would you prefer based on those preferences.

569
01:03:30,610 --> 01:03:38,560
In this case, they said yes, the targeted, targeted intervention maybe gives us slightly fewer qualities,

570
01:03:39,280 --> 01:03:43,060
but we think that's because of the equity benefits that probably would be preferred in.

571
01:03:48,440 --> 01:03:54,650
Any questions on this? There's a lot kind of going on here with this this approach.

572
01:03:55,580 --> 01:03:58,909
Maybe some final questions here. You know, what does equity mean to you?

573
01:03:58,910 --> 01:04:03,830
How should how should we evaluate, if at all, how should we evaluate equity?

574
01:04:05,590 --> 01:04:08,890
Is there a is there an appropriate quantitative way where equity if not,

575
01:04:09,130 --> 01:04:15,460
how should we think about equity or and and think about equity when we're kind of thinking about health policy?

576
01:04:18,250 --> 01:04:21,680
And allocating resources to policy responsibly versus policy.

577
01:04:25,360 --> 01:04:33,090
Sort of question. But I thought you kind of alluded to this at the beginning, but how kind of popular,

578
01:04:33,360 --> 01:04:39,180
mainstream and accepted are kind of these methods that we've been going through today?

579
01:04:39,730 --> 01:04:43,620
So you talk about today is very much not the mainstream.

580
01:04:43,650 --> 01:04:50,100
It's new. There certainly are a lot of people interested in it, but it's certainly not the standard, I would say,

581
01:04:50,100 --> 01:04:56,580
of all of the approaches to look at equity and quantify equity distribution or cost effectiveness analysis is probably the most popular.

582
01:04:57,000 --> 01:05:00,060
But even then, if you looked at, you know,

583
01:05:00,300 --> 01:05:04,770
how many of my World Economy Journal articles are published on cost effectiveness

584
01:05:04,770 --> 01:05:08,249
analyzes and how many are published and distributional cost effectiveness analyzes?

585
01:05:08,250 --> 01:05:18,479
It's probably, you know, 2% or something like that. Now there's growing interest in it, but it is not the kind of standard when the you know,

586
01:05:18,480 --> 01:05:24,840
when Blue Cross is evaluating some new drug, they're not asking for a distributional cost of resources.

587
01:05:24,840 --> 01:05:30,870
They might ask for a cost for resources, but not a distribution of cost. So a lot of this is and this is why I'm asking you guys,

588
01:05:30,870 --> 01:05:38,310
a lot of this is kind of new and there's a lot of theory that suggests, hey, you know, people do have preferences for equity.

589
01:05:38,490 --> 01:05:39,720
Maybe we should try to incorporate them.

590
01:05:39,930 --> 01:05:48,500
But these approaches are not necessarily set in stone and necessarily the right answer to how should we be thinking about equity now?

591
01:05:49,350 --> 01:05:53,190
So because it's like how disjointed the US health care system is,

592
01:05:53,190 --> 01:05:59,490
I wonder like how feasible is it to do this kind of thing where it's like maybe Medicare could do it?

593
01:05:59,820 --> 01:06:01,740
And this is you're right, this is difficult.

594
01:06:01,740 --> 01:06:08,790
And and in some ways, you know, putting money into Medicaid maybe would increase equity because presumably that's a disadvantage.

595
01:06:08,790 --> 01:06:12,720
Population are actually putting money into Medicare.

596
01:06:13,260 --> 01:06:20,249
It's, I guess, debatable, but whether that is improving equity or not, you know,

597
01:06:20,250 --> 01:06:25,440
clearly people who are older have many more health conditions that need more health attention.

598
01:06:26,010 --> 01:06:32,840
But then again, someone who is age 85 is already kind of beyond the mean life expectancy in the

599
01:06:32,850 --> 01:06:36,180
US and maybe we should invest money in people who haven't made it there yet.

600
01:06:37,080 --> 01:06:39,170
So there are some interesting kind of equity questions.

601
01:06:39,180 --> 01:06:47,219
Yes, I know that there's like a theory that the media is like the best health care system the states do.

602
01:06:47,220 --> 01:06:52,870
They do stuff like this on a regular basis. Do we have a lot of I'm not aware of the VA looking into that.

603
01:06:52,890 --> 01:06:59,110
You're right, though. I mean. Well, the VA treats a really interesting population, which might you know,

604
01:06:59,130 --> 01:07:04,680
there are many I will say there are many disadvantaged people in the U.S. There are people who are advantaged as well.

605
01:07:05,460 --> 01:07:10,530
There's a lot of debate about, you know, I work with people in the VA and they think that they're the greatest.

606
01:07:10,530 --> 01:07:16,530
But there are a lot of other people who actually think they're terrible. So I don't know necessarily know the right answer there to that.

607
01:07:17,190 --> 01:07:20,190
Yeah. And I will say, my you know, my bias is having worked with those people,

608
01:07:20,190 --> 01:07:24,569
I think they're intentioned and they're doing great things, but I don't know all the details of it.

609
01:07:24,570 --> 01:07:27,900
Maybe there's some scary things about that.

610
01:07:27,990 --> 01:07:32,250
Again, I'm biased because I've worked with those people and I think they're first of all and so forth.

611
01:07:32,250 --> 01:07:34,530
And so I'm probably inclined to believe that it's a good system.

612
01:07:36,040 --> 01:07:40,859
And I will say they do some really great things in terms of analyzing the data of their many members,

613
01:07:40,860 --> 01:07:44,880
and they really try hard to do great things for them. Yeah, but yeah.

614
01:07:45,150 --> 01:07:51,270
Speaking of investing in Medicaid, but you could say investing in the VA is a good thing and that that helps really,

615
01:07:52,770 --> 01:07:58,500
you know, disadvantaged populations that have had a lot of health issues and challenges and.

616
01:08:02,040 --> 01:08:05,070
Does that answer your question? Yeah.

617
01:08:06,780 --> 01:08:13,120
Is there another question? Well, so how should we be thinking about equity?

618
01:08:13,150 --> 01:08:18,879
I mean, if you're if you how should Joe Biden be thinking about equity?

619
01:08:18,880 --> 01:08:23,260
How should how. HARRIS Or think about equity when they're.

620
01:08:23,980 --> 01:08:27,100
How should Nancy Pelosi, Mitch McConnell, how should they be thinking about equity,

621
01:08:27,190 --> 01:08:31,360
if at all, when they're thinking about advocating for health emergency?

622
01:08:31,360 --> 01:08:38,740
How should Gail Wilensky be thinking about how should Blue Cross Blue Shield be thinking about equity?

623
01:08:51,060 --> 01:08:57,960
It. Clearly you guys care what equity. Many of you said that at least I read along with applications when you find to come into the company,

624
01:08:57,970 --> 01:09:01,710
you said it was important to expanding the services. That was important to me.

625
01:09:04,170 --> 01:09:13,380
Yeah, I think I think what is most likely for Blue Cross Blue Shield or any insurance company is for them to think about equity in a way that,

626
01:09:14,250 --> 01:09:16,710
especially when it comes to policy making,

627
01:09:17,460 --> 01:09:24,180
thinking about equity in a way that will, one, save them the most money as an insurance company, but also helping most people in the same time.

628
01:09:24,630 --> 01:09:31,790
And so looking at like not only what is the most equitable, I think it's very likely that they'll be like,

629
01:09:31,800 --> 01:09:36,110
what is the most cost effective in conjunction with actually profitable?

630
01:09:36,120 --> 01:09:40,080
Because if we can help this population and then that will save us money in the long term,

631
01:09:40,440 --> 01:09:47,190
I feel like that is both politically feasible and also like insurance companies could get behind,

632
01:09:47,190 --> 01:09:58,710
not in even like maybe even like a lobbying way to like help push push policies that will help support them because it'll save them money.

633
01:09:58,980 --> 01:10:04,200
Yes, I agree. I think I think a lot of people are looking for things in this Win-Win Quadrant here that are,

634
01:10:04,200 --> 01:10:07,800
you know, cost effective, maybe saving money and also improving equity.

635
01:10:08,160 --> 01:10:13,889
So if there's you know, they're really excited about an intervention that can take, you know, you know,

636
01:10:13,890 --> 01:10:19,980
someone who's got a lot of chronic conditions, give them a cheap intervention that helps improve their life.

637
01:10:19,980 --> 01:10:25,640
And also, you know, maybe they would have been really expensive. And that's a, you know, maybe just a population.

638
01:10:26,030 --> 01:10:32,309
Yeah, yeah. They're looking for ways there. And there are there are kind of things like the political optics of it as well.

639
01:10:32,310 --> 01:10:36,900
And so, you know, if you're Blue Cross Blue Shield, you want to be seen as helping the community.

640
01:10:37,230 --> 01:10:44,370
And actually, if you work and many of you might go work for Blue Cross Blue Shield or you are alumni work from the abortion shield.

641
01:10:44,550 --> 01:10:46,850
I would argue that they actually do care about that.

642
01:10:47,310 --> 01:10:51,720
You know, designated populations, they're not just doing it for for, you know, political visibility.

643
01:10:53,100 --> 01:10:56,520
And so that's something to think about, is who are your we are stakeholders.

644
01:10:56,520 --> 01:11:00,089
They might be politicians, they might be the community, they might be your employees.

645
01:11:00,090 --> 01:11:07,110
And so you want to I think they do have an interest in, you know, improving equity in addition to efficiency,

646
01:11:07,470 --> 01:11:15,330
but, you know, is probably based on, you know, what are the kind of, if you will, local political or concerns.

647
01:11:15,330 --> 01:11:21,600
So in Detroit, the concerns about equity are very different than in Upper Peninsula of Michigan or in the UK.

648
01:11:21,810 --> 01:11:30,890
So from that example, so that the interest in equity and how we think about equity is going to be shaped by the operations and situations.

649
01:11:32,890 --> 01:11:40,930
Yes, we've prioritized the interventions like more cost effectiveness and more equitable.

650
01:11:41,290 --> 01:11:47,199
So that means that intervention seems to be less equitable and less affordable.

651
01:11:47,200 --> 01:11:52,480
Would not pay for. Yeah.

652
01:11:52,490 --> 01:11:55,910
Presumably we don't like interventions in this law. Is that what you're saying?

653
01:11:56,330 --> 01:11:59,710
Yeah. So it's a yes or no question the like.

654
01:12:00,170 --> 01:12:04,880
But how come? Like, can we like we can, like distribution.

655
01:12:05,210 --> 01:12:09,380
Like, not even to invest in different intervention, but not saying, okay,

656
01:12:09,380 --> 01:12:20,000
we only like pay for this one because it is more cost effectiveness and more equitable for like so, you know, 2 to 1 that being not affordable.

657
01:12:20,720 --> 01:12:26,030
Yeah. Well, so we clearly like interventions here in the circle.

658
01:12:27,020 --> 01:12:32,690
We don't like things with the X, but I would say, you know, there might be some here that we we do like.

659
01:12:32,690 --> 01:12:36,500
So maybe there are some out of here that we we do like, you know,

660
01:12:36,680 --> 01:12:40,579
maybe we're willing to do some things that are they give us a lot of equity but maybe

661
01:12:40,580 --> 01:12:43,340
aren't so cost effective and maybe willing to a few things here are the really

662
01:12:43,340 --> 01:12:47,660
cost effective but harm equity a little bit and you know if you do enough of these

663
01:12:47,900 --> 01:12:52,760
you know this plus this might give you something you know if you might you know,

664
01:12:53,540 --> 01:13:00,230
net you know if you're if you're kind of far enough, you know, in this zone or in this zone here,

665
01:13:00,440 --> 01:13:04,190
you know, maybe it doesn't harm equity that much, but it really increases efficiency.

666
01:13:04,190 --> 01:13:08,479
And then the next thing you know, hurts efficiency a little bit, really increases equity.

667
01:13:08,480 --> 01:13:13,580
Maybe if you do things like that, you're going to net net kind of get both of these things.

668
01:13:13,580 --> 01:13:26,250
You're like. Is that what you're getting at or is that like for me, those question would be like giving up the people on the left side, you know?

669
01:13:28,630 --> 01:13:33,010
What do you mean? We're giving up on the left outside because we don't want to.

670
01:13:33,640 --> 01:13:42,910
We didn't. To invest more money for maybe like the more equitable and also cost effectiveness advice.

671
01:13:42,910 --> 01:13:47,620
But I know like some population thing my life always to be that downstream.

672
01:13:49,510 --> 01:13:54,950
When you say downstream, what do you mean? Like, okay, we talked to you after the class.

673
01:13:55,070 --> 01:14:10,570
Okay. I mean I mean, certainly they're like here, you know, here in this example, foreign aid is of less efficient and less equitable.

674
01:14:10,570 --> 01:14:15,580
Would be. But, you know, so this this rich is missing out.

675
01:14:15,580 --> 01:14:22,360
Is that what you're getting out of that maybe there maybe in that, you know, in that case, they would be kind of in this lower left,

676
01:14:22,360 --> 01:14:29,260
that policy would be in a lot of that has portrayed here less equity in the less cost effective of in that case that the richest fifth are losing out.

677
01:14:29,890 --> 01:14:36,650
That's potentially that's is not maybe what you can answer and pretty cost.

678
01:14:39,300 --> 01:14:48,600
Other. Yeah. So I know like the FDA and Medicare like generally can't they're not allowed to think about cost effectiveness.

679
01:14:49,290 --> 01:14:55,950
But I'm curious if there's like a push to like force them to think about equity even if they're not allowed to think about fast.

680
01:14:56,430 --> 01:14:59,669
Mhm. So that's, that's interesting.

681
01:14:59,670 --> 01:15:07,320
I haven't seen a big push for, for FDA or or Medicare to, to think about equity.

682
01:15:07,560 --> 01:15:14,460
I mean, I think clearly Medicaid does have was kind of designed to improve health equity.

683
01:15:15,810 --> 01:15:18,990
But yeah, I haven't seen much of a push for that within Medicare.

684
01:15:19,530 --> 01:15:24,359
And there probably are some things that I'm missing out on about let's try to do

685
01:15:24,360 --> 01:15:27,870
more colon cancer screenings or breast cancer screenings in this population. In that population.

686
01:15:29,730 --> 01:15:30,330
Yeah, but I mean.

687
01:15:32,570 --> 01:15:42,290
Know, I haven't seen too much of a push for that or from FDA and any the FDA is really concerned about, you know, safety and efficacy.

688
01:15:42,310 --> 01:15:49,780
And so if they think something is not helpful or has, you know, safety harms, they're not going to approve it.

689
01:15:52,480 --> 01:16:03,309
So those are some some challenges. Well, why don't I finish off here with a just brief introduction to the homework?

690
01:16:03,310 --> 01:16:08,020
Because I think you had a question about, you know, is this going to be how we're going to think about these things in the homework?

691
01:16:08,020 --> 01:16:12,850
So I think it'd be good to take a look at that.

692
01:16:14,890 --> 01:16:23,160
And so this is similar to the previous ones you've done here. There's a Google sheet, a template and a homework assignment here.

693
01:16:29,680 --> 01:16:34,870
So in this example here, there are several questions here.

694
01:16:36,940 --> 01:16:40,810
And so the first question is about distribution or cost effectiveness analysis.

695
01:16:41,140 --> 01:16:46,930
You're kind of working through an example and you're given here are two interventions

696
01:16:46,930 --> 01:16:54,070
intervention A and B with a certain cost for each and overall qualities for each.

697
01:16:54,730 --> 01:17:02,380
And then the distribution of those that quality, just the life expectancy in the house, which I was one, two or three, four or five.

698
01:17:03,400 --> 01:17:12,370
She? And then why should one a is say, ignoring equity concerns if you're willing to pay $100,000 for quality?

699
01:17:12,670 --> 01:17:17,049
Which intervention would you prefer? That's kind of a standard cost effective analysis.

700
01:17:17,050 --> 01:17:21,160
And that example, you just kind of ignore all the stuff in these last five columns.

701
01:17:23,110 --> 01:17:28,880
Question one B, though, is how would you describe A and B in terms of equity?

702
01:17:29,590 --> 01:17:32,860
And does one appear more or less equitable than the other?

703
01:17:33,040 --> 01:17:40,750
Why is that? Question one C Is it if you were to put these on the cost of equity plane, how would intervention be related to intervention?

704
01:17:40,900 --> 01:17:44,920
So we wouldn't have to actually have to draw it. Or if you do, you can just take B versus AA.

705
01:17:45,550 --> 01:17:49,870
You don't have to, you know, precisely identify the axes. Why should they able the axes?

706
01:17:49,870 --> 01:17:54,510
This one is equity and this one's efficiency. We do have to say this one is 7.2 and 6.9 or whatever.

707
01:17:54,640 --> 01:18:02,410
We have to have units on the axes for question one C And then the maybe the most challenging part here is.

708
01:18:04,660 --> 01:18:12,460
Question one D here. This this is the formula for equity, sorry, the equally distributed equivalent.

709
01:18:14,380 --> 01:18:23,500
And I want you to calculate this for A and B using Epsilon value five.

710
01:18:25,060 --> 01:18:30,709
And so recall that what this is doing is it summing up over different groups.

711
01:18:30,710 --> 01:18:41,500
And here we have five groups that health in this case the quality adjusted life expectancy for that quintile.

712
01:18:43,750 --> 01:18:50,560
So you sum up that health tied to the power one minus epsilon in five here,

713
01:18:51,550 --> 01:18:58,030
you sum up all those things for the five groups and take the average or one over to divide by five basically.

714
01:18:58,780 --> 01:19:03,010
And then you take that whole thing to the power of one over one minus epsilon.

715
01:19:03,430 --> 01:19:08,860
So you're going to calculate this funky value that's going to be equally distributed equivalent.

716
01:19:10,090 --> 01:19:13,990
So which is interesting here. Here's the overall 77 and 79.

717
01:19:14,230 --> 01:19:17,740
That was the average, but the equally determined equivalent is going to be a different number.

718
01:19:17,740 --> 01:19:25,540
That is, it is presumably equivalent to this distribution of health here and, you know, one, three, five.

719
01:19:25,540 --> 01:19:28,770
So once you kind of actually work through that and calculate that.

720
01:19:28,780 --> 01:19:33,280
Yes. So in this situation, you just the epsilon and the sample size, it just happens to be the same.

721
01:19:35,110 --> 01:19:38,530
Yes, that's true. Yeah. Yeah. The epsilon.

722
01:19:38,800 --> 01:19:44,380
Yeah. If you want to you can pick. Yeah. Could you six etc. just make sure it's a different figure.

723
01:19:45,940 --> 01:19:50,830
And so you say that and then question two is more qualitative.

724
01:19:52,210 --> 01:19:58,810
So it's assuming our well that we imagine there's a new medication developed to treat sickle cell disease.

