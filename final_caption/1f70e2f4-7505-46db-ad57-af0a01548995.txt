1
00:00:01,410 --> 00:00:14,340
Late Saturday night, they were going to be like, Hey, I assume you don't have a life.

2
00:00:14,430 --> 00:00:21,570
We had to be done. It's like the probability is that it's going to be a force.

3
00:00:21,690 --> 00:00:37,800
Oh, my God. If I you know, my brother is like one of those great national parks from California, that's always going to be really tough, I guess.

4
00:00:37,990 --> 00:00:46,800
So my very handsome survivor made 24 hours.

5
00:00:48,270 --> 00:01:07,240
Really? And I make you think, oh, yeah, it's like, you know, he's very much for having me.

6
00:01:09,540 --> 00:01:13,780
Oh, yeah. I don't like that.

7
00:01:15,860 --> 00:01:22,709
Yeah, actually, I'm like, Oh, yeah, it's like that.

8
00:01:22,710 --> 00:01:39,400
Like, yeah, we're looking for another shot.

9
00:01:39,750 --> 00:01:50,070
I think your credit is actually going to go on forever that, you know,

10
00:01:55,360 --> 00:02:16,000
you might as well be the only thing you like because I you know, we have to say, I don't know, maybe it is.

11
00:02:19,260 --> 00:02:27,380
Yeah. Oh, I get it. Yeah, I gave him candy.

12
00:02:28,310 --> 00:02:32,390
Like, it would be like, you know. Yeah, I would like.

13
00:02:32,690 --> 00:02:42,960
And I just kept you, like, the guy really, like, knocking on doors?

14
00:02:43,170 --> 00:02:49,620
No. Well, he lives on the West Coast.

15
00:02:49,620 --> 00:02:53,670
It's true. I saw the pictures. Let's get started.

16
00:02:56,460 --> 00:03:01,740
A change is that instead of your homework, three being due on Tuesday.

17
00:03:01,740 --> 00:03:06,330
It's now due on Thursday. So move the date from the fourth to the sixth.

18
00:03:06,750 --> 00:03:14,969
You can all thank one of your classmates for that and everything should be set up.

19
00:03:14,970 --> 00:03:17,040
So those all change. If you have any problems, let me know.

20
00:03:17,040 --> 00:03:27,330
But it should be fine and then we'll post the answers to that homework because I don't know if it'll be created in time for you to see the site.

21
00:03:27,420 --> 00:03:31,620
Just study from it. But we'll post the answers, at least on that day after class.

22
00:03:31,620 --> 00:03:37,170
So you can study from the answer. Any questions before we get started?

23
00:03:38,340 --> 00:03:43,410
Before I get started, yes. I hope you started recording. I didn't start recording.

24
00:03:43,800 --> 00:03:47,820
So I'll make sure you and all the class. Oh, so I actually.

25
00:03:47,820 --> 00:03:52,320
So they're doing this pilot of recording the classes where I don't do anything.

26
00:03:52,320 --> 00:03:56,400
They're just recording it. So that's why it looks like I'm not doing anything. But it should be recording.

27
00:03:57,510 --> 00:04:04,290
That's how it has been happening, right? There's some like automatic Panopto pilot occurring in this.

28
00:04:04,650 --> 00:04:12,300
Yes, it's doing it right now in this classroom. All right.

29
00:04:16,260 --> 00:04:26,850
Okay. So we were talking on Tuesday about phase two designs in particular, sort of standard designs.

30
00:04:26,850 --> 00:04:31,589
And when I say standard, I mean one of our non-randomized designs.

31
00:04:31,590 --> 00:04:35,940
And so we were talking about this two stage design.

32
00:04:35,940 --> 00:04:42,030
So we went from like a one arm, just put everybody on it and see what happens to well,

33
00:04:42,030 --> 00:04:47,459
we could probably figure out that this isn't going to work earlier. So if we can, let's make that decision.

34
00:04:47,460 --> 00:04:55,920
And so Keagan had formalize this idea by saying let's enroll a cohort and in particular he said, let's enroll seven.

35
00:04:55,920 --> 00:04:59,580
And then they are, he said 14. And then we changed it to seven.

36
00:04:59,660 --> 00:05:05,600
Later on and said, if we see any responses, let's go into the second stage and get the rest of the patients.

37
00:05:05,930 --> 00:05:12,919
But if we see zero responses, let's stop then, because this is not going we're not going to feel good about this treatment.

38
00:05:12,920 --> 00:05:19,760
We're not going to move on. So we might as well not expose our patients to it or take up the resources for this trial.

39
00:05:21,320 --> 00:05:30,290
So we were talking about the genes design and then we saw that like he's kind of rigid, right?

40
00:05:30,290 --> 00:05:34,160
It's either that you have seven or 14, you see any move on.

41
00:05:34,400 --> 00:05:39,229
It's not very flexible. And so it would be nice instead to say, you know,

42
00:05:39,230 --> 00:05:45,889
can we figure out other numbers that we could have in that first stage in terms of the total cohort and the

43
00:05:45,890 --> 00:05:52,220
number of responses that we see to make these decisions that satisfy still are type one and Type two error.

44
00:05:52,580 --> 00:05:58,070
And that could help us potentially have higher power or stop more often or whatever we need.

45
00:05:58,940 --> 00:06:10,249
And so we ended by saying that Richard Simon formalize this process to find the the these

46
00:06:10,250 --> 00:06:16,969
measures that we need for a two stage phase two setting to satisfy type one error and power.

47
00:06:16,970 --> 00:06:23,720
And so these measures are one the number of responses required in the first stage to move on, and one,

48
00:06:23,720 --> 00:06:30,140
the number of total individuals required in that first stage that we see if we have our own responses.

49
00:06:30,140 --> 00:06:36,770
And then our is that total response rate for the full trial out of that total and patients.

50
00:06:38,750 --> 00:06:45,860
And Simon said, you know, there's lots of different criteria we could use to figure out what this set of numbers should be,

51
00:06:45,860 --> 00:06:54,440
are one and one are an end. And in fact, there is not just one set that is going to satisfy a specific criteria.

52
00:06:55,220 --> 00:07:01,760
And so he said, well, I think these two criteria are perhaps the ones that we should be going for.

53
00:07:02,060 --> 00:07:07,790
And so he developed these two designs, the Minimax and the optimal design in particular.

54
00:07:07,790 --> 00:07:16,250
That said, you know, here are two ways that we can define these values and they have different, different goals.

55
00:07:16,760 --> 00:07:22,550
So what we want to think about is that our total sample size N for this phase two,

56
00:07:22,580 --> 00:07:27,680
two stage phase two trials, right, is made up of the number of individuals in the first stage.

57
00:07:28,100 --> 00:07:34,310
And if we have less than those little R one responses, that would be the total number of people in our trial.

58
00:07:34,340 --> 00:07:41,090
Right? So we'd stop then, plus the total number of individuals in the full two stages of the trial.

59
00:07:41,090 --> 00:07:50,120
And we move on to that. We get that n if we don't stop after the first stage and we have more than R1 responses

60
00:07:50,900 --> 00:07:54,950
so we can calculate the average number of individuals enrolled in our trial.

61
00:07:54,950 --> 00:08:00,349
Right? It's just N1 times the probability that we stopped under the null plus the total.

62
00:08:00,350 --> 00:08:03,920
And given that we didn't stop under the null hypothesis.

63
00:08:04,310 --> 00:08:05,209
And so he said,

64
00:08:05,210 --> 00:08:15,290
let's set up this one type of trial that's called the optimal two stage design that's going to try to minimize this expected number of individuals.

65
00:08:15,710 --> 00:08:22,310
So we're trying to minimize this average number of individuals enrolled on the stage to trial given.

66
00:08:23,500 --> 00:08:26,710
The type of error that we specify and our power.

67
00:08:28,720 --> 00:08:34,180
And specifically this is minimizing the number of subjects enrolled when the trials shouldn't have been run.

68
00:08:34,690 --> 00:08:41,110
So what you're going to see is that this optimal two stage design, right, that N1 is going to be small.

69
00:08:41,440 --> 00:08:45,700
We're trying to minimize that N1. That's when the trial shouldn't be run.

70
00:08:45,830 --> 00:08:50,210
Right. You'd only enroll the N1 people. Okay.

71
00:08:50,230 --> 00:08:51,670
Then he said alternatively,

72
00:08:51,940 --> 00:08:57,590
maybe we don't want to just minimize the number of individuals if the trial shouldn't have been wrong, shouldn't have been run.

73
00:08:57,610 --> 00:09:01,780
We just want to completely minimize the number of individuals on this trial, even if it was run.

74
00:09:02,230 --> 00:09:08,600
So in that case, we can set up the Minimax design, which says, I don't want to just minimize that N1.

75
00:09:08,620 --> 00:09:17,979
I want to minimize the actual end. Okay. So he said, let's choose R1, N1, R9 given alpha and minus beta to minimize that total.

76
00:09:17,980 --> 00:09:27,280
And the minimax design usually has the same maximum sample size as the smallest single stage design.

77
00:09:27,280 --> 00:09:31,660
Meaning we just enroll everybody on that one arm, right, and look at the data at the end.

78
00:09:32,980 --> 00:09:38,820
But because there is that potential for early termination, there's a smaller expected sample size, right?

79
00:09:38,830 --> 00:09:44,770
Because some of the times we might actually end early. We can have a smaller expected sample size under the null.

80
00:09:46,810 --> 00:09:55,630
So we can run these Simon two stage designs in R by using this library clean fun and

81
00:09:55,870 --> 00:10:03,160
specifically the function page to Simon is the phase two Simon design function where we put in.

82
00:10:03,970 --> 00:10:13,230
Again, this is kind of funny, I guess somewhat funny notation, but PUE is the expected proportion of response, right?

83
00:10:13,240 --> 00:10:22,720
Or of the outcome under the null. And then a is the expected probability of response under the alternative or what we want to see.

84
00:10:22,740 --> 00:10:33,629
Right. To go forward with this treatment EP one is that type one error and EP two is the type two error, right?

85
00:10:33,630 --> 00:10:41,820
So we're putting in that we want to see a difference from 20% to 35% in terms of response rate for this new treatment,

86
00:10:42,270 --> 00:10:44,819
we are pay with 5% type one error.

87
00:10:44,820 --> 00:10:55,830
And remember in a state in a Simon two stage designer jeans design, this is a one sided type two type one error and a 80% power.

88
00:10:57,450 --> 00:11:00,750
And so if we run this, I think I have our up.

89
00:11:06,250 --> 00:11:14,010
Yeah. Right.

90
00:11:14,050 --> 00:11:20,110
So if I run this, I get. This output or the output that I have on the slide.

91
00:11:22,620 --> 00:11:26,110
That just tells us the inputs that we had. Right.

92
00:11:26,130 --> 00:11:33,210
And make sure that that's actually what we wanted. So the use stands for unacceptable response rate and a stands for alternative.

93
00:11:34,140 --> 00:11:39,840
And then we have the error rates. And so we see that it gives us the optimal design and the minimax design.

94
00:11:39,840 --> 00:11:44,250
So the optimal design says, first, enroll 22 participants.

95
00:11:45,030 --> 00:11:49,100
If you see more than five responses, then move to the second stage.

96
00:11:49,110 --> 00:11:59,430
If you see five or less responses, then you stop the trial and then in total have 72 total patients on this phase two trial.

97
00:11:59,640 --> 00:12:05,220
And if you see more than 19 responses, then it's successful and you'd want to move forward into phase three.

98
00:12:07,060 --> 00:12:14,170
The Minimax design right it instead of having so that optimal design has the lowest N1 it's 22.

99
00:12:14,500 --> 00:12:17,770
The Minimax design has a higher N1 but a lower end.

100
00:12:18,250 --> 00:12:24,670
So the Minimax design says now you need a C 31 patients in that first stage cohort.

101
00:12:24,970 --> 00:12:33,040
And if you see greater than six responses, then you should go on to continue to enroll until you get to 53 patients.

102
00:12:33,370 --> 00:12:42,580
And if at the end of that trial you see more than 15 responses, then you can declare that this looks successful and you can go on into phase three.

103
00:12:43,820 --> 00:12:47,090
And so you'll see here that it's then giving us this.

104
00:12:47,450 --> 00:12:50,970
So here this is our set of numbers that we're interested in, right?

105
00:12:50,990 --> 00:12:54,980
Are one and one Arden and then np0.

106
00:12:55,340 --> 00:12:59,330
That's the expected total sample size of the trial under the null.

107
00:12:59,750 --> 00:13:11,180
Right. So this is that given that the trial is going to end sometimes if it's truly the probability of success is truly 20%, then we end quite often.

108
00:13:11,180 --> 00:13:15,500
And so instead of having a sample size of 72, right, we have a sample size of 35.

109
00:13:15,800 --> 00:13:20,960
And in fact, this is the probability of early term early termination.

110
00:13:21,280 --> 00:13:23,840
All right. So that's the probability of early stopping.

111
00:13:24,080 --> 00:13:32,780
And so it says that you're actually stopping after phase after that stage 170, almost 73, a little bit more than 73% of the time.

112
00:13:33,670 --> 00:13:40,010
Right. So in this case, you're more likely to stop if it's really true.

113
00:13:40,460 --> 00:13:44,390
Truly not a useful treatment if that response rate is closer to 20%.

114
00:13:44,960 --> 00:13:54,800
The minimax design. Right. The expected sample size is actually higher because you're not stopping as often under the null.

115
00:13:55,310 --> 00:14:02,660
Right. So you're only stopping 57% of the time after that first stage if the true response rate is 20%.

116
00:14:02,960 --> 00:14:05,960
So you can see the tradeoffs here. Right. There is lots of different tradeoffs.

117
00:14:05,960 --> 00:14:09,470
How big is the first cohort? How big is the total sample size?

118
00:14:09,710 --> 00:14:12,140
How often are you stopping? Right.

119
00:14:12,140 --> 00:14:18,469
So there's lots of tradeoffs here that you'd want to think about and you'd make a decision based on your disease setting,

120
00:14:18,470 --> 00:14:25,490
based on the rate of accrual, based on resources, etc.

121
00:14:28,340 --> 00:14:41,299
Okay. So if you remember yesterday, we also had created this two stage operating characteristic function where we could play with Gwynn's design,

122
00:14:41,300 --> 00:14:46,370
or we could see other operating characteristics and we can actually use this.

123
00:14:46,640 --> 00:14:57,740
And to check the Clinton fund, the page to Simon, the page to Simon function, we'll get the same results if we kind of put in the information.

124
00:14:57,740 --> 00:15:07,010
So if we take the R, R, one and one, R and end what's right with the null and alternative,

125
00:15:07,010 --> 00:15:13,010
we'll see that we get the similar probabilities of stopping early and the average enrolled.

126
00:15:14,660 --> 00:15:24,290
So we did a good job writing our function. Okay, now notice though that I can choose some different R one and one r an n, right?

127
00:15:24,290 --> 00:15:35,270
So this isn't quite the minimax or the optimal 520 to 631 Right now I'm choosing 627 and 1658 somewhere in between there.

128
00:15:35,690 --> 00:15:40,430
Right. But I could just choose those and now I can see what the operating characteristics are.

129
00:15:40,820 --> 00:15:47,629
And if I do that, then I see that I under the null I would terminate 71% of the time and I have

130
00:15:47,630 --> 00:15:53,030
an average number of roles of 36 that's really similar to the optimal design,

131
00:15:53,420 --> 00:16:03,200
right? I'm almost adding early, almost as much. And I have this very similar expected number of individuals in my trial under the alternative.

132
00:16:03,200 --> 00:16:12,439
Right. I almost I only end early about 12% of the time and I have an average enrolled of 55.

133
00:16:12,440 --> 00:16:16,640
Right. It's very close to the total and because I'm not ending very early.

134
00:16:16,970 --> 00:16:22,940
So this is another design that I could use, right, that has relatively good operating characteristics.

135
00:16:22,940 --> 00:16:26,480
It's almost optimal, but not quite.

136
00:16:27,050 --> 00:16:30,530
And in my case, this is called an unmissable two stage design.

137
00:16:30,890 --> 00:16:34,700
Right. So Simon said there isn't one unique answer.

138
00:16:34,760 --> 00:16:41,930
Right. There's there's all these different possibilities that we can have that satisfy our type one and type two error.

139
00:16:41,930 --> 00:16:44,240
And they're just minimizing different things.

140
00:16:44,750 --> 00:16:53,690
And so we can set up this cost function that depends on the total number of individuals that's N and the expected number

141
00:16:53,690 --> 00:17:04,489
of individuals if it's truly not successful like our and one right or that's actually not quite N1 but related to N1.

142
00:17:04,490 --> 00:17:07,730
Right. And we can figure out, well, which, which how much do we want to wait?

143
00:17:07,760 --> 00:17:16,010
Do we care about really minimizing the total sample size or do we care about minimizing that expected number if we're if we're wrong,

144
00:17:16,070 --> 00:17:21,049
if the treatment isn't good and so we can decide to as anything we want, right?

145
00:17:21,050 --> 00:17:26,720
We could set this up and now we can figure out our R1, N1, R and end and use that.

146
00:17:26,720 --> 00:17:33,440
And that can be an admissible design. It's going to be somewhere in between the minimax and the optimal design.

147
00:17:35,030 --> 00:17:41,330
In fact, if we consider those costs function right, what's the optimal design?

148
00:17:41,470 --> 00:17:44,720
What is Q for the optimal design?

149
00:17:46,620 --> 00:17:53,610
Remember that the optimal design, if we go back, minimizes the number of subjects enrolled when the trial should not have been run.

150
00:17:54,960 --> 00:18:07,540
So if you look at this, what's Q for the optimal design? Yeah.

151
00:18:07,780 --> 00:18:10,889
Okay, great. Is it that easy? Yes, it's zero.

152
00:18:10,890 --> 00:18:16,950
Right? If we put zero here, this goes away. Or minimizing the expected number of individuals when the trial should have been run.

153
00:18:17,220 --> 00:18:21,730
And so what does that mean? The minimax is what's Q for the minimax? One.

154
00:18:21,790 --> 00:18:25,290
Right. And so we're trying to weaken.

155
00:18:25,300 --> 00:18:29,410
Those are the opposite ends. Right? You could be zero. It could be one or it could be any weight in between.

156
00:18:29,890 --> 00:18:32,950
And so any way in between is minimax.

157
00:18:33,250 --> 00:18:36,430
I mean, this is admissible, right? Any way in between is admissible.

158
00:18:36,680 --> 00:18:40,210
And on on the other ends are the minimax and the optimal design.

159
00:18:42,540 --> 00:18:46,200
I have is one of your readings, this Jong article, I believed.

160
00:18:46,470 --> 00:18:50,070
Who outlines these admissible designs and sets us up?

161
00:18:50,370 --> 00:18:56,970
That's kind of amazing, right? So if we go back to the Garland design, this came out in 1961.

162
00:18:58,260 --> 00:19:02,400
Simon has his paper.

163
00:19:03,530 --> 00:19:09,110
In 1989, like 30 some years later, right?

164
00:19:09,380 --> 00:19:12,830
Or 20 some years. Almost 30 years later. And then.

165
00:19:14,660 --> 00:19:23,690
Almost. Not quite. 28, right? 15 years later, John says, Oh, hey, we could actually be in between, as you would think, if you look at this in a row.

166
00:19:23,690 --> 00:19:28,740
Right. Looking at in this class, it's like, well. This is obvious, right?

167
00:19:28,800 --> 00:19:30,720
Like that should have been done a lot faster.

168
00:19:31,020 --> 00:19:35,820
But it took that long for people to think about these things and to rate this theory and to get it going.

169
00:19:36,120 --> 00:19:44,250
Right. And so I. I just always want to remind you that things seem a lot easier in retrospect.

170
00:19:44,370 --> 00:19:48,390
Right. And when you're actually working through it, it takes a long time.

171
00:19:48,750 --> 00:19:56,870
And if any of you are thinking about going to the PhD, do not like do not think it's this thing that is unattainable, right?

172
00:19:56,880 --> 00:19:59,970
That's baby steps. It's going forward. It takes a long time.

173
00:20:00,870 --> 00:20:05,699
So I just don't want you to get scared that all of this happened overnight.

174
00:20:05,700 --> 00:20:12,510
Right? This took decades to get to this very simple minimizing this cost function.

175
00:20:12,810 --> 00:20:14,850
Right, with cure between zero and one.

176
00:20:17,790 --> 00:20:24,899
And also shows you how I think a lot of people think, oh, clinical trials, you just have A versus B, that's super easy, right?

177
00:20:24,900 --> 00:20:30,240
It's just parallel design, A versus B, there's actually a lot of room for improvement in clinical trials.

178
00:20:30,240 --> 00:20:36,389
Right. And it sometimes takes a long time because people aren't unfortunately, too many people are thinking, oh, there's no room for approval.

179
00:20:36,390 --> 00:20:39,840
I should do A versus B, right? But you can do a lot of other things.

180
00:20:39,840 --> 00:20:44,820
And so there's a lot of open questions and a lot of room for Biostatistician to work on these things.

181
00:20:45,600 --> 00:20:52,169
And so I think it's a very interesting area that unfortunately others think, oh, just just say versus B, just give me a sample size.

182
00:20:52,170 --> 00:20:56,730
Right? There's a lot more. Okay. So here is this scene.

183
00:20:57,090 --> 00:21:00,749
Oh, no, this is now a different package. Page two mold.

184
00:21:00,750 --> 00:21:05,130
So it can do it. They can do optimal minimax admissible.

185
00:21:05,370 --> 00:21:10,559
And also it gives this like max power phase two output.

186
00:21:10,560 --> 00:21:17,730
It doesn't actually put it in in a text output, but it will show you a key for Max Power on the plot.

187
00:21:18,120 --> 00:21:25,559
So you can install this package, you can run it. This says that we have a binding design so that our outcome is is binary, right?

188
00:21:25,560 --> 00:21:32,220
We have this response rate and then we can say what we're interested in or we can just leave that out and it'll show us output for everything.

189
00:21:32,880 --> 00:21:39,090
And so here we're saying we have 20% versus 35%, 5% type one error, 80% power.

190
00:21:39,360 --> 00:21:44,729
We want to see the plot because it's kind of interesting. And then it says, all right, well, here's your options.

191
00:21:44,730 --> 00:21:55,200
You got the optimal where we're going to minimize this N1, although actually you can see here that there's an admissible where that's even smaller.

192
00:21:55,530 --> 00:21:59,250
We've got the minimax where we're going to minimize this total end.

193
00:21:59,640 --> 00:22:02,790
Right. And we can find lots of different admissible designs in between.

194
00:22:03,450 --> 00:22:09,089
And so it shows you this plot where it says, okay, here's the Minimax design, here's one admissible design,

195
00:22:09,090 --> 00:22:15,540
here's another admissible design, here's our optimal design, and here's a max power design.

196
00:22:16,050 --> 00:22:19,320
And you can see, right, we, we specify the type one error in the power.

197
00:22:19,320 --> 00:22:22,440
So this should all be around 5% and 80%. Yeah.

198
00:22:22,860 --> 00:22:27,450
So you can pick a bunch of different cues for an admissible design.

199
00:22:27,450 --> 00:22:32,370
Yes. So how do you know which queue they're picking there and does it actually matter in practice?

200
00:22:33,630 --> 00:22:36,830
Um. Let me see if we can.

201
00:22:37,810 --> 00:22:41,230
I don't think we know who is picking, but I just want to see if in the outs.

202
00:22:41,680 --> 00:22:49,640
But we can tell. No, we can't tell here.

203
00:22:51,410 --> 00:22:55,460
Maybe if we read the material a little bit closer, we could tell.

204
00:22:55,820 --> 00:22:59,540
But, you know, that could be it could be any cue.

205
00:22:59,720 --> 00:23:00,110
Right.

206
00:23:00,110 --> 00:23:07,730
And it does matter in some sense in terms of like you might have you and the clinician might have an idea of what you're really trying to minimize.

207
00:23:07,970 --> 00:23:15,100
Like, do do you want to go more toward making sure that the first cohort is small and you stop early?

208
00:23:15,110 --> 00:23:19,879
Or do you want to go more toward making sure you're not going to miss it?

209
00:23:19,880 --> 00:23:23,930
Right. Getting everybody and then making that decision.

210
00:23:24,380 --> 00:23:30,380
So it's kind of a a discussion with the clinician.

211
00:23:30,410 --> 00:23:37,160
I will say that. So I'll show you an example today of inadmissible design that was run by a statistician here, not me.

212
00:23:37,170 --> 00:23:41,690
It was by Phil Boonstra, but I usually only in practice.

213
00:23:41,690 --> 00:23:49,310
I usually just use the minimax or the optimal. Excuse me.

214
00:23:49,340 --> 00:23:55,130
Yeah. So, for the minimum of smoothies, now, you're a minimized the lab rat.

215
00:23:55,490 --> 00:23:58,850
Yeah, but why? Yeah, this one actually has a smaller one. Yeah.

216
00:23:59,870 --> 00:24:09,990
We check the output? Did that actually happen? Yeah, it did. I feel like that shouldn't have been possible, but it must be there.

217
00:24:10,030 --> 00:24:18,960
Very, very close. You can tell. I would have thought that the second one would have been the optimal.

218
00:24:19,680 --> 00:24:22,709
The expected value one is higher though maybe.

219
00:24:22,710 --> 00:24:28,210
That's right. Yeah. Like this is slightly higher because you're stopping slightly less I think, right?

220
00:24:28,230 --> 00:24:36,780
Yeah. You're stopping a little bit less. And in this one, I think essentially it's saying that.

221
00:24:38,030 --> 00:24:42,120
There. I guess there are. Ways in which you could.

222
00:24:42,870 --> 00:24:46,210
How can you get more than a way to one? I don't know. I don't know that answer.

223
00:24:46,230 --> 00:24:53,970
I don't know. It is important, for example, to show because I don't know why I did that, but usually the optimal should have the lowest N1.

224
00:24:54,750 --> 00:24:57,600
But I guess there are other options where you could have a lower N1,

225
00:24:58,860 --> 00:25:06,060
but you're going to pay the price of not being not stopping as much and having a slightly higher expected value there.

226
00:25:10,490 --> 00:25:16,370
So what's wrong with the two stage design? It seems like a seems like a benefit.

227
00:25:16,700 --> 00:25:22,100
There's an improvement over just having one stage because you can stop early if it doesn't look like it's going well.

228
00:25:22,130 --> 00:25:28,940
Right. And it seems like an improvement over Ian's design because it's more flexible and you can decide what you want to minimize.

229
00:25:29,390 --> 00:25:33,980
However, the problem is the timing. So in phase two designs.

230
00:25:34,250 --> 00:25:38,630
Right. Remember, we're still interested in safety, but now we're collecting efficacy data.

231
00:25:39,140 --> 00:25:45,020
And the problem is that just like a lot of safety endpoints, efficacy isn't often instantaneous.

232
00:25:45,410 --> 00:25:49,920
And so it usually takes a little bit of time to see that there is a response, right?

233
00:25:49,940 --> 00:25:55,999
It's not often it's not like maybe if we're looking at headache and we're testing like aspirin, right?

234
00:25:56,000 --> 00:26:02,000
We could see that within hours. But usually it's like we're giving some sort of chemotherapy and we're seeing if the tumor has shrunk.

235
00:26:02,510 --> 00:26:10,190
And so that takes months. And so the problem with this two stage is that we get to the N1 and now we have

236
00:26:10,190 --> 00:26:15,200
to wait all the months for everybody to see to be able to view their outcome.

237
00:26:15,590 --> 00:26:21,020
And that means that we'd have to put the trial on pause. And so there might be patients that really want to get into this trial.

238
00:26:21,350 --> 00:26:24,860
Right. But we won't let them because we don't actually know if we can open it up or not.

239
00:26:25,370 --> 00:26:31,519
And so there is a slight logistical issue with this in terms of it's difficult to make

240
00:26:31,520 --> 00:26:35,720
sure that we hit that number that them are waiting for the entire time and then,

241
00:26:36,410 --> 00:26:40,730
you know, making patients wait and then eventually opening it back up.

242
00:26:41,390 --> 00:26:44,360
It can just be a little awkward for people,

243
00:26:44,780 --> 00:26:50,630
especially for those who are working on contributing to the studies like, oh, sorry, no, oh, no, opening back up.

244
00:26:52,430 --> 00:27:03,680
And so this is kind of the main reason why people would not do this trial is because if it takes a long time or a longer time to see the response,

245
00:27:03,980 --> 00:27:06,710
they're not as interested in this pause session.

246
00:27:10,550 --> 00:27:20,540
So in general, we'll talk more about phase two trials today and Thursday and maybe Tuesday, maybe not.

247
00:27:20,540 --> 00:27:25,130
I don't remember. But phase two drug trials in general are what we call futility trials.

248
00:27:25,610 --> 00:27:28,790
So that means that we're willing to stop them because it's not working.

249
00:27:29,120 --> 00:27:33,800
Right. We don't usually ever stop phase two trials early because it's looking great.

250
00:27:34,130 --> 00:27:38,570
We actually want to just continue to get that data at phase two because the sample size is still small,

251
00:27:38,570 --> 00:27:41,780
and if it's doing well, we might as well give it to the patients, right?

252
00:27:41,780 --> 00:27:47,990
It's going to benefit them. And so we only generally ever stop phase two early if it's not looking good.

253
00:27:49,490 --> 00:27:55,069
Remember, our goal of phase two is to take all those treatments that are both worthwhile and not

254
00:27:55,070 --> 00:27:59,330
worthwhile and try to cut out some of those not worthwhile treatments when we move forward.

255
00:28:03,950 --> 00:28:07,009
There's nothing really special about having two stages, right?

256
00:28:07,010 --> 00:28:10,339
So that you have one stage and then you can stop and move on. You can have more stages.

257
00:28:10,340 --> 00:28:11,030
It's just, again,

258
00:28:11,030 --> 00:28:19,189
that logistical issue of like waiting for everybody and making that decision makes it a little bit more difficult to implement in practice.

259
00:28:19,190 --> 00:28:22,580
And so therefore, two stages is what we generally stick to.

260
00:28:28,350 --> 00:28:32,370
There's also this issue that we'll talk about next, which is that.

261
00:28:33,460 --> 00:28:39,820
The trial conduct, whether how many people you've accrued and what you're looking at,

262
00:28:39,820 --> 00:28:42,930
and then how you analyze the data at the end, it can actually differ a little bit.

263
00:28:42,940 --> 00:28:46,940
So if we have a two stage design, we need to consider that in our analysis.

264
00:28:46,960 --> 00:28:51,670
However, some people at the end might just say, Oh, we had our out of end responses,

265
00:28:51,670 --> 00:28:56,440
so let's just take that we don't have who cares about R1 and N1, right?

266
00:28:56,590 --> 00:29:02,640
But that can actually be a problem. And so you can see, right, that our inference is really going to depend on the design.

267
00:29:02,650 --> 00:29:11,500
So for example, if we have this minimax design with, we'll just keep going at 20%, 35%, 5% type one error, 80% power.

268
00:29:12,130 --> 00:29:15,580
We could choose this set of R1. N1 are an N.

269
00:29:16,120 --> 00:29:21,669
And so that would say that we could we would successfully conclude that this trial looks good.

270
00:29:21,670 --> 00:29:26,140
This treatment should go on if we have 16 or more responders at the end of the trial.

271
00:29:27,400 --> 00:29:30,790
So say we have 16 or so we're interested in.

272
00:29:31,150 --> 00:29:34,250
So what's the probability that we get? I don't know.

273
00:29:34,300 --> 00:29:37,540
I said 17. Here's 17.

274
00:29:37,540 --> 00:29:41,290
It could have been 16, but 17 are more responders.

275
00:29:41,290 --> 00:29:44,290
Given that we actually went to that second stage.

276
00:29:44,290 --> 00:29:47,830
Right. This was this was successful in the first stage. We go to the second stage.

277
00:29:48,220 --> 00:29:54,070
What's our p value? What we have to take into account that we looked right, that we actually went into that second stage.

278
00:29:54,640 --> 00:30:00,430
And so we're taking that to an into account here and this calculation.

279
00:30:00,790 --> 00:30:03,069
So this is a calculation of our P value.

280
00:30:03,070 --> 00:30:15,520
So the probability that the number of responses minus the first number of responses in the first stage is greater than the 16 minus some x.

281
00:30:15,520 --> 00:30:23,470
Right? We're going to put an X, we're going to let that vary to get from 7 to 31 to get the P value given under the null.

282
00:30:23,590 --> 00:30:23,919
Right.

283
00:30:23,920 --> 00:30:32,680
And so what's the probability that we actually got to that second stage or we finish the trial as a probability of having seven or more successes?

284
00:30:34,890 --> 00:30:37,350
At least in the first stage. Okay.

285
00:30:37,350 --> 00:30:44,760
So here, if we actually implement this, right, we'll see that the P-value from the two stage trial is just under 5%.

286
00:30:44,880 --> 00:30:50,450
Right. It's just saying that with this type of error, we actually get a significant finding.

287
00:30:50,460 --> 00:30:59,550
We would move on. However, if we said that we had 16 responses, the same kind of interest.

288
00:30:59,550 --> 00:31:02,690
Right? But we just did a one stage design. Right.

289
00:31:02,700 --> 00:31:09,660
We have a different calculation for that P value, and our P value is actually just over 5%.

290
00:31:10,110 --> 00:31:17,160
And so if you're super strict about that 5% p value, right in the one stage design, you say this isn't significant.

291
00:31:17,490 --> 00:31:20,820
And in the two stage design, you say this is significant, let's move forward.

292
00:31:21,120 --> 00:31:24,330
This is a little funny, right? Like we have the exact same data.

293
00:31:25,830 --> 00:31:30,809
And so you can see that there is this this differentiation between the counting for

294
00:31:30,810 --> 00:31:35,070
the design and not accounting for the design in the analysis or in the inference.

295
00:31:36,030 --> 00:31:43,800
Here's another example. This is like the classic example that if you look up the likelihood principle on Wikipedia, they give some version of this.

296
00:31:44,760 --> 00:31:52,710
So now assume there are two different designs and we're testing again for this probability response equal to 20% or not.

297
00:31:53,250 --> 00:32:00,030
And so assume that the one design says, well, let's enroll 25 patients and ah,

298
00:32:00,180 --> 00:32:06,020
ah, we assume that our outcome is binomial and we observe eight responses.

299
00:32:06,030 --> 00:32:09,630
So this is like a one stage we see eight out of 25, right?

300
00:32:09,720 --> 00:32:15,600
Are P values really quite simple to calculate and we get that it's 0.109.

301
00:32:17,290 --> 00:32:21,040
Now I see we have this different design and it says, well,

302
00:32:21,040 --> 00:32:30,819
enroll patients up until you have 17 non-responders and then see how many responders you have right in this case are the number of responders

303
00:32:30,820 --> 00:32:38,560
is actually negative binomial right the way that we're enrolling to see nonresponders as opposed to just enrolling 25 and seeing responders.

304
00:32:39,100 --> 00:32:42,790
So here assume now again we have eight responses.

305
00:32:43,690 --> 00:32:48,370
Then we can calculate our p value and we get 0.0892.

306
00:32:49,530 --> 00:32:53,370
So again, we have the same data basically, right?

307
00:32:53,400 --> 00:32:58,530
We have the same number of responses, eight responses, but we have these very different P values.

308
00:32:58,920 --> 00:33:05,610
And it's because in one way we assumed that the data was binomial and the other assumed it was negative binomial.

309
00:33:06,470 --> 00:33:14,830
And again, if we were using like the 10% threshold for significance, we would say, oh, well, it was if this outcome is binomial,

310
00:33:14,840 --> 00:33:19,850
we see we don't see significance, but if it was a negative binomial, this is a significant finding.

311
00:33:21,030 --> 00:33:25,710
So some funny things here are happening, right? It depends on the design.

312
00:33:26,400 --> 00:33:30,690
Depends on what you assume that distribution for that outcome is.

313
00:33:31,230 --> 00:33:36,570
And we can find very disparate results. And so this actually is a violation of the likelihood principle.

314
00:33:37,260 --> 00:33:40,680
So the likelihood principle says that all you need to know is the likelihood.

315
00:33:40,950 --> 00:33:45,480
And if you are the likelihood, you get the same thing. But that's not true, right?

316
00:33:45,810 --> 00:33:49,530
We just saw that. Actually, you need to know more. You need to know the design.

317
00:33:50,310 --> 00:33:53,430
And you should be analyzing the data based on the design.

318
00:33:54,670 --> 00:34:01,290
And so kind of interesting that we can see just in clinical trials this violation of this likelihood principle.

319
00:34:07,330 --> 00:34:12,170
And so it's very important for you to always be thinking about what is the analysis?

320
00:34:12,170 --> 00:34:15,410
And the analysis always depends on the design. Okay.

321
00:34:15,740 --> 00:34:25,430
And so in any clinical trial, you need to know the outcome and you need to know your design, and then you can write your analytic plan.

322
00:34:26,000 --> 00:34:32,030
But you can't write that analytic plan without knowing the design. Okay, let's try some questions.

323
00:34:33,950 --> 00:34:40,430
So how many values of PN the actual sample size can a two stage design actually have?

324
00:34:40,460 --> 00:35:26,320
Assuming that all rules are followed? Precisely. I like the wording on this is a little confusing, but just try this.

325
00:35:29,620 --> 00:35:46,630
Let's get 15. Well, okay, we have no idea.

326
00:35:48,460 --> 00:35:53,560
All right. So in a two C's design, most of you think that enrollment could stop at any point in the trial.

327
00:35:53,950 --> 00:36:04,700
That is false. Why do you think that? We specify a R1 and one R and right.

328
00:36:06,230 --> 00:36:13,340
After say that say that we have R1 and one hour and in they're like 517.

329
00:36:16,790 --> 00:36:21,810
Ten and 50. I don't know. Right. We could stop it.

330
00:36:22,080 --> 00:36:25,110
27. No. Okay.

331
00:36:25,110 --> 00:36:30,630
So the answer. Think about it again.

332
00:36:35,990 --> 00:36:43,210
There we go. Okay. Sure. Okay.

333
00:36:44,150 --> 00:36:48,960
Yeah. Great. So I think it's a little bit confusing.

334
00:36:49,160 --> 00:36:55,450
What is the word? Actual is used too much, right? In reality, there's only one sample size of your stops earlier.

335
00:36:55,460 --> 00:36:59,690
It doesn't, right? But it either stops early on or it continues to end.

336
00:36:59,690 --> 00:37:03,420
So there are two possible sample sizes that could occur.

337
00:37:03,440 --> 00:37:08,120
Right. It's either N1 or it's and we can't stop at anything.

338
00:37:08,570 --> 00:37:12,160
But it's either that we stop after the first cohort or we go to the end and we see then.

339
00:37:12,200 --> 00:37:19,250
So there's like one true sample size, but we won't know until the end of the trial if it's N1 or N.

340
00:37:23,360 --> 00:37:27,210
Okay. How about this one?

341
00:37:27,230 --> 00:37:32,720
So try to take this concept right and then apply this area to it.

342
00:37:32,750 --> 00:37:37,610
So if you're studying a rare disease in which patient accrual is slow because there's

343
00:37:37,610 --> 00:37:42,680
not a lot of patients with the minimax or the optimal design make more sense.

344
00:38:03,950 --> 00:38:08,010
You have to remind yourself, right? What does the minimax one do? What does that minimize?

345
00:38:09,820 --> 00:38:13,480
Total. The total in an optimal one minimizes.

346
00:38:14,440 --> 00:38:18,450
Yeah. And one or the expected number if it's not going well.

347
00:38:18,460 --> 00:38:23,910
Right. So what do you think. See. So.

348
00:38:24,210 --> 00:38:30,710
Oh. Huh. Like some crazy switching all of a sudden for us.

349
00:38:30,730 --> 00:38:35,920
Just many more responses. All right. So it's kind of like, who knows, I guess, right?

350
00:38:35,940 --> 00:38:39,480
So let's look at an example. I think that's the easiest way to do it.

351
00:38:39,930 --> 00:38:43,709
All right. So whenever you have a question, always just like this is what I do.

352
00:38:43,710 --> 00:38:47,700
If I have no idea. Go to R and try it something out, right?

353
00:38:47,730 --> 00:38:52,170
Try simulations or try whatever and see what makes sense intuitively to you.

354
00:38:52,170 --> 00:38:55,110
Play around with it so that that's how I think you answer this question,

355
00:38:55,470 --> 00:38:58,710
which obviously you can't do on a test because I'm not letting you have R but.

356
00:38:58,980 --> 00:39:02,520
Right. This will help you build that that intuition.

357
00:39:02,880 --> 00:39:08,880
Okay. So assume now that we have under the null 10% response rate and we want to see 30% or better,

358
00:39:09,240 --> 00:39:13,260
we have a type one error of 1% and a type two error of 10%.

359
00:39:13,260 --> 00:39:22,520
So a power of 90%. So under the optimal design and one is 12 and N is 35, right?

360
00:39:22,530 --> 00:39:29,909
So we're minimizing this and and one minimax design is so the optimal is in actually minimizing

361
00:39:29,910 --> 00:39:34,760
in one it's minimizing the expected number of individuals if it's truly not successful.

362
00:39:34,770 --> 00:39:35,790
Right. That's a little bit different.

363
00:39:35,790 --> 00:39:44,549
So that's why I think that admissible one because I was smaller and one because I was minimizing the E of DN, not the N1 exactly.

364
00:39:44,550 --> 00:39:51,420
But they're usually very similar. But so the minimax design here has a bigger N1 and 16, but a smaller end.

365
00:39:52,530 --> 00:39:56,190
All right. And the expected sample size is basically equal.

366
00:39:57,240 --> 00:40:07,860
Right we're we're stopping early more in the optimal design but because the minimax total and a smaller we have basically the same expected number.

367
00:40:09,040 --> 00:40:19,220
So in this case, we really just need to think about time and accrual and the amount of people possible to enroll versus the amount that we need.

368
00:40:19,240 --> 00:40:22,899
So in rare diseases, it's very, very difficult to enroll individuals.

369
00:40:22,900 --> 00:40:27,370
So rare diseases are ones that affects less than 200,000 individuals in America.

370
00:40:27,700 --> 00:40:30,879
And it's really hard to get these individuals to be on trial.

371
00:40:30,880 --> 00:40:33,370
It's really hard to get anybody to be on trials right now.

372
00:40:33,370 --> 00:40:38,890
Adding in that, we have a very small sample, people who have this disease that we want to have on a trial.

373
00:40:40,690 --> 00:40:44,140
And so because of that, right accrual is likely to be slow.

374
00:40:44,710 --> 00:40:53,680
And so we likely, even though it would be great to make a decision early, given the fact that our expected sample size is about the same,

375
00:40:54,010 --> 00:40:58,060
we really just want to minimize the total number of individuals on the trial.

376
00:40:58,420 --> 00:41:05,889
So in this sense, I would say that we would want a minimax design, which I think most of you chose.

377
00:41:05,890 --> 00:41:11,050
But that's right. You really want to go and look at the numbers because I could see how you could argue either way.

378
00:41:11,080 --> 00:41:18,130
Right. Well, you really want to make you really want to stop early with a small number of patients, given the optimal, if you can, however,

379
00:41:18,670 --> 00:41:26,620
given like this kind of set up right where you're expecting about the same regardless, you probably just want to minimize the total number of people.

380
00:41:27,280 --> 00:41:33,969
Yeah. So those numbers change depending on what the parameters that you specify like yeah, for sure they do change.

381
00:41:33,970 --> 00:41:40,150
But I think generally for rare diseases, the usually you want to go in a max.

382
00:41:41,710 --> 00:41:49,590
Yeah. Yeah. Like if he's afraid of P not and P one an alpha beta change, then your R one and one R and are going to change.

383
00:41:49,860 --> 00:41:54,060
And therefore the D is expected are going to change.

384
00:41:54,420 --> 00:42:00,090
But you're still most likely going to want to lower the total number.

385
00:42:02,030 --> 00:42:14,030
Okay. Any questions? So let's move on to today's, which is if we get to a little bit of new stuff at the end.

386
00:42:14,030 --> 00:42:19,330
But generally, I want to show you a couple of examples. So we're going to review two examples.

387
00:42:19,340 --> 00:42:23,510
The first one is like what not to do? And the second one is, this is good.

388
00:42:23,660 --> 00:42:28,840
This is a good one. And then I want to tell you a little bit about Bayesian phase two designs.

389
00:42:28,970 --> 00:42:37,250
So in phase one, we took those baby steps from like algorithmic to hybrid to Bayesian design, model based designs.

390
00:42:37,520 --> 00:42:41,000
And phase two, we say there's a really simple one arm.

391
00:42:41,280 --> 00:42:49,480
There's a relatively simple two stage, one arm. Then we're going to say, Oh, well, you can have one arm, but do Bayesian in the Bayesian framework.

392
00:42:49,490 --> 00:42:51,770
And then we'll say, Oh, but you would also randomize.

393
00:42:51,830 --> 00:42:55,760
So that's sort of the progression of the Phase two designs, and there are more that exist out there.

394
00:42:56,140 --> 00:43:02,930
Like there are more Phase one designs that exist out there. But this is sort of a general giving you a general feeling of what exists.

395
00:43:04,010 --> 00:43:06,710
Okay, so we're discussing these two papers they were given.

396
00:43:06,980 --> 00:43:11,300
The first one that I'm saying is, a, what not to do is actually in the New England Journal of Medicine.

397
00:43:12,170 --> 00:43:17,389
And then the second line was a good example is in this American Journal of Hematology.

398
00:43:17,390 --> 00:43:20,750
And you can see the first author is Feldman Shroff, who's a professor here.

399
00:43:22,310 --> 00:43:25,490
So this first one is in acquired aplastic anemia.

400
00:43:26,180 --> 00:43:31,960
It was investigator initiated, which means that it wasn't run by the pharmaceutical company.

401
00:43:31,970 --> 00:43:36,980
It was a clinician investigator at the academic hospital who said, I want to run this trial.

402
00:43:38,510 --> 00:43:44,600
So a single are actually is not single arm, but there's no randomization historically controlled.

403
00:43:44,600 --> 00:43:51,230
Right. Meaning that we don't have like a placebo arm. It's we're going to assume that we know what the response rate would be without this treatment.

404
00:43:51,800 --> 00:43:59,270
And this was actually a phase one two study. So they started with some kind of figuring out a dose and then moving into phase two.

405
00:44:00,110 --> 00:44:07,700
So they had a figuring out the dose by saying, we're actually going to look at three cohorts of different dosing schedules.

406
00:44:07,700 --> 00:44:11,270
So it's not the amount of the treatment so much.

407
00:44:11,510 --> 00:44:15,979
It's not like the amount given at one time. It's a cumulative difference.

408
00:44:15,980 --> 00:44:19,820
So it was dosing schedules of like when they're giving the dose or how long they're giving the dose.

409
00:44:21,250 --> 00:44:26,409
So all the cohorts are getting this one treatment cyclosporine and then there are

410
00:44:26,410 --> 00:44:31,870
these three cohorts where they're this is the this e drug is the drug of interest.

411
00:44:32,230 --> 00:44:36,400
And so they said, well, what if this cohort gets it from day 14 to 6 months?

412
00:44:36,760 --> 00:44:40,510
What what if this cohort gets it shorter just for day 14 at three months?

413
00:44:40,930 --> 00:44:44,590
Or what did this cohort actually gets it all the way from the beginning to six months.

414
00:44:44,600 --> 00:44:50,140
So you can see right there different cumulative amounts of the drug, but they're all getting like the same amount.

415
00:44:50,500 --> 00:44:57,250
If you look at it at just one time when they're getting the drug, it's small, but they're getting it for over different periods of time.

416
00:44:59,530 --> 00:45:05,499
And so they're looking at both three month response and six month response and assess hematologic response.

417
00:45:05,500 --> 00:45:11,320
So they're looking at a change in blood levels. Right. That's their short term outcome.

418
00:45:12,220 --> 00:45:19,630
So it's this six month hematologic response that there is their primary endpoint.

419
00:45:20,020 --> 00:45:25,510
And so it's defined by achieving certain levels and these and this in blood counts.

420
00:45:26,260 --> 00:45:35,200
And then they're also so in phase two, we have a primary efficacy, end point, some binary usually response and we have some primary safety end point.

421
00:45:35,590 --> 00:45:39,010
And so here there are safety endpoint was a safety profile.

422
00:45:39,010 --> 00:45:46,540
And six months after the initiation of treatment, they actually didn't really specifically specify these endpoints.

423
00:45:46,540 --> 00:45:53,469
Well, this problem one with this paper and they had no power for this, which we don't actually often have power for a safety endpoint,

424
00:45:53,470 --> 00:46:00,130
but we do want have specific goals of what we're trying to see and or what would cause us to say this is unsafe.

425
00:46:01,600 --> 00:46:01,929
Okay.

426
00:46:01,930 --> 00:46:10,120
So their original protocol, which by the way, if you publish in like the New England Journal of Medicine or The Lancet or one of these really high,

427
00:46:11,800 --> 00:46:12,940
high level journals,

428
00:46:12,940 --> 00:46:22,090
they require you to either attach as an appendix or provide the clinicaltrials.gov information which has your original protocol description.

429
00:46:22,610 --> 00:46:24,940
Right. We're trying to keep investigators honest.

430
00:46:25,330 --> 00:46:32,080
And so they said that they had a Simon to stage minimax design where they had if without this treatment,

431
00:46:32,080 --> 00:46:39,130
there was 10% response and they wanted to see a 30% response or better 5% type one error and 80% power.

432
00:46:39,670 --> 00:46:43,570
And so their total sample size was 25.

433
00:46:43,930 --> 00:46:48,040
You can see that we can actually match what they've done.

434
00:46:48,460 --> 00:46:56,290
Right? So given this, we can run our clinic for an hour to Simon function and we could see.

435
00:46:56,290 --> 00:47:04,030
All right, so they chose this design where they need to see one more than one response out of the first 15 in the first cohort

436
00:47:04,450 --> 00:47:10,390
and more than five responses out of the total 25 And so it's unlikely that this trial is going to stop early,

437
00:47:10,630 --> 00:47:14,320
right, 55% of the time.

438
00:47:15,100 --> 00:47:18,490
And so we have an expected sample size of about 20.

439
00:47:20,200 --> 00:47:25,080
All right. So they start running the trial and then they go, oh, well, some people are dropping out.

440
00:47:25,420 --> 00:47:34,239
So now we need to amend the protocol and say, well, some people are are not evaluable,

441
00:47:34,240 --> 00:47:41,860
so they might be having issues with the cancer or whatever something is happening and we can't actually test the six month endpoint.

442
00:47:41,860 --> 00:47:48,850
And so now they're saying actually let's accrue 31 patients to make sure that we have 25 who are valuable.

443
00:47:49,600 --> 00:48:01,659
And so now they're saying, well, if we actually have 31 patients, right, this would be like the new new design that they have,

444
00:48:01,660 --> 00:48:06,580
although I don't really think the design changes because they're really still just trying to count on the 25.

445
00:48:06,580 --> 00:48:09,700
Right. But you can try to figure out what's going on here.

446
00:48:10,540 --> 00:48:17,590
Okay. And then they also actually originally just plan this for for the phase two part for one cohort.

447
00:48:18,040 --> 00:48:21,939
But then they said, oh, let's just do the phase two across all the cohorts, right?

448
00:48:21,940 --> 00:48:26,620
So now we'll try to get 31 patients across all three of these dosing schedules.

449
00:48:27,130 --> 00:48:32,470
So if you remember one thing about clinical trials, you should always specify what you're doing upfront.

450
00:48:32,680 --> 00:48:36,370
Now that doesn't mean that you can't have changes like protocol. Amendments are common.

451
00:48:36,910 --> 00:48:41,680
However, it shouldn't be vastly changing your trial most of the time.

452
00:48:41,680 --> 00:48:46,960
So this is a little bit worrisome that they didn't think about these things ahead of time.

453
00:48:47,890 --> 00:48:49,450
But whatever they're adding amendments,

454
00:48:50,050 --> 00:48:56,140
they're adding on these cohorts and they're trying to figure out probably what happened is that didn't start with those three cohorts.

455
00:48:56,140 --> 00:49:03,549
It started with the other the other dosing levels. And then they said, Oh, these aren't quite producing enough responses.

456
00:49:03,550 --> 00:49:06,879
Let's try doing the treatment more. Right?

457
00:49:06,880 --> 00:49:10,030
And so like this is the problem that they're like looking at the data,

458
00:49:10,030 --> 00:49:14,200
then they're adding these cohorts and that's not very they should have been doing okay.

459
00:49:14,200 --> 00:49:20,530
So even though this is a New England Journal of Medicine, you need to always be critical about what you're reading and how they're presenting it.

460
00:49:21,280 --> 00:49:25,780
So here's the table that comes at their table two.

461
00:49:25,780 --> 00:49:31,450
So all the response information, so you can see they have information on cohort one, cohort two and cohort three.

462
00:49:31,450 --> 00:49:39,939
So those are those three different dosing schedules. They tell us how many people have overall response, a partial response or a complete response.

463
00:49:39,940 --> 00:49:43,480
So what their their main outcome is complete response.

464
00:49:43,600 --> 00:49:50,590
Partial response usually means that like they did, they didn't get worse.

465
00:49:50,890 --> 00:49:56,170
Usually it's more related to like stable disease than actually doing better.

466
00:49:56,170 --> 00:50:00,340
And so that's why it's not often a primary endpoint or sometimes it's not counted as one

467
00:50:00,340 --> 00:50:05,860
because it's not usually that helpful in terms of how they're ultimately going to do.

468
00:50:06,820 --> 00:50:11,350
Okay. So what we're interested in is this primary outcome at six months.

469
00:50:11,440 --> 00:50:15,850
So you can see on cohort one, it was ten out of 30.

470
00:50:16,720 --> 00:50:25,330
Somehow they actually evaluated everybody. It was eight out of 31 on the second cohort and then 18 out of 31 on the third cohort.

471
00:50:26,110 --> 00:50:31,599
So you can see. Right, that likely because cause one and two it's at oh, we're not given the drug enough, let's try it longer.

472
00:50:31,600 --> 00:50:39,070
And then they did get better response in the third cohort. Now if you actually take a discerning eye to this table, there are several issues.

473
00:50:39,220 --> 00:50:49,750
So again, this is like unfortunately a lack of rigor on the authors part and then a lack of rigor in the the reviewers and the editors part.

474
00:50:49,750 --> 00:50:55,990
So, for example, if we look up here, this is the confidence interval for the response rate.

475
00:50:56,110 --> 00:51:00,970
The response rate point estimate is 33%. The confidence interval upper bound ends at 31.

476
00:51:01,060 --> 00:51:05,170
Like that's not that's not possible. Right. So that was bad. That's a bad typo there.

477
00:51:05,170 --> 00:51:10,540
We'll give them the benefit of the doubt. Some bad typo. Okay. Now, here, this is just like egregious.

478
00:51:10,540 --> 00:51:19,300
Somebody is not a statistician. So now they're saying, oh, this response rate is 94% and the content zero go interval goes from 84 to 1, two, three.

479
00:51:19,750 --> 00:51:25,930
Well, sure, when you calculate it goes one of three, but nobody can have a 100, but you can have a 103% response rate.

480
00:51:25,930 --> 00:51:30,009
Right. So somebody should have been like, Hey, dummy, that's 100% right.

481
00:51:30,010 --> 00:51:36,760
Somebody should have caught that somewhere. And then this last thing over here is this p values testing the null hypothesis

482
00:51:36,760 --> 00:51:40,150
that the rate of complete response at six months would be 30% or greater.

483
00:51:40,270 --> 00:51:44,680
No, no, that's the alternative, right? The null hypothesis was 10%.

484
00:51:45,190 --> 00:51:52,090
So again, there's just like a lot of of dumb mistakes, which when you start seeing these add up, you get worried.

485
00:51:52,390 --> 00:51:59,320
And so someone should have caught this the New England Journal of Medicine at some point because I don't know.

486
00:51:59,350 --> 00:52:04,410
I'm not I personally don't think this is probably worthy of publication in New England Journal most.

487
00:52:07,660 --> 00:52:09,880
There are more problems, though. There are more problems.

488
00:52:10,750 --> 00:52:21,520
So so now they say, oh, and our analysis is that we're going to analyze the response probabilities for each cohort using binomial distributions,

489
00:52:21,520 --> 00:52:24,639
which generally means like using the exact binomial distribution.

490
00:52:24,640 --> 00:52:28,340
Right. We can calculate these p values and do these hypothesis tests.

491
00:52:28,360 --> 00:52:32,050
Okay. Okay, great. So let me try to let me try to match that.

492
00:52:32,200 --> 00:52:38,470
Okay. So I'm gonna use my package by now. For example, for cohort one, they got ten out of 30.

493
00:52:38,830 --> 00:52:42,610
So now I'm going to calculate the response rate and the interval.

494
00:52:43,390 --> 00:52:47,720
All right. And there they're like gazillions of ways to calculate binary intervals, right?

495
00:52:47,740 --> 00:52:52,420
We can pretend they're normal. We can do all these different types of of approximations.

496
00:52:53,290 --> 00:52:56,889
And so you can see here that if I have ten out of 30, right.

497
00:52:56,890 --> 00:53:04,660
I have a 33% response rate like that that we agree on and now are lower in our upper confidence interval.

498
00:53:04,780 --> 00:53:13,690
Right. It goes from at at lows or at least 17% to at most 53%.

499
00:53:14,260 --> 00:53:18,590
Okay. What did they get? 15. Like where what where does that come from?

500
00:53:18,610 --> 00:53:23,170
Right. We don't have anything that low. At least they're erring on the side of.

501
00:53:24,240 --> 00:53:31,860
More variants, right? But I don't know how if we do anything, any type of binomial distribution, right.

502
00:53:32,130 --> 00:53:37,140
We don't get 15 here and then we'll give them the benefit of the doubt that the 31 should have been a 51.

503
00:53:37,140 --> 00:53:42,840
So I guess I can match their upper in some way, but like that, that lower, I guess here is the lowest 16.

504
00:53:42,900 --> 00:53:45,630
Right. I can't I can't get that. So what did they do?

505
00:53:46,110 --> 00:53:54,270
Well, if I do some sleuthing right, I could say, oh, maybe they used a T test on this binary outcome.

506
00:53:55,140 --> 00:54:01,170
And in fact, they did. Yeah, right. So that was that that gets me 15 to 51%.

507
00:54:01,800 --> 00:54:12,630
And so they write that they're using binomial distributions, but then somehow they're using a T test, they do the same thing for all the cohorts.

508
00:54:13,050 --> 00:54:18,780
So if we look at cohort two, right, we got eight right here, eight out of 31.

509
00:54:21,120 --> 00:54:35,990
And so. If I try to put that in any, any type of binomial confidence interval, I get, you know, maybe 10% to 43% and they somehow got.

510
00:54:39,500 --> 00:54:46,340
Or is it 9% to 42? So again, that lower level is not possible via the binomial distribution.

511
00:54:46,350 --> 00:54:50,260
They're actually again using the T test. I don't know why.

512
00:54:50,270 --> 00:54:57,580
Right. They said that they didn't say they were doing that and then they I don't think in this table or no.

513
00:54:57,590 --> 00:55:07,330
Yeah. In this table they give us some p values. So remember the P value should depend on the design and all of these designs are two stage designs.

514
00:55:07,340 --> 00:55:15,380
So they should be accounting for the fact that they have a two stage design, not just that they have like eight out of 31 responses, but yes.

515
00:55:16,420 --> 00:55:20,530
If I calculate the p value.

516
00:55:22,390 --> 00:55:25,810
Then I get this point.

517
00:55:25,810 --> 00:55:29,470
0571. Right. They get .06.

518
00:55:30,340 --> 00:55:37,540
Oops. Um, but that's just accounting for eight out of ten.

519
00:55:37,750 --> 00:55:43,750
I mean, eight out of 31 responses, not accounting for the fact that they had a two stage design.

520
00:55:44,530 --> 00:55:48,939
So their P value is incorrect. They also all.

521
00:55:48,940 --> 00:55:54,010
Simon Two stage designs are all generally two. Stage phase two designs have a one sided P value.

522
00:55:54,220 --> 00:55:56,140
They report all two sided P values.

523
00:55:56,740 --> 00:56:03,420
And so there's just like inconsistency after inconsistency after inconsistency for this trial, which is quite unfortunate.

524
00:56:03,430 --> 00:56:03,730
Right?

525
00:56:03,840 --> 00:56:11,470
Like, actually, if we consider the fact that they had a two stage design and it's a one sided P value, we get a P value, a highly significant P value.

526
00:56:11,530 --> 00:56:15,100
Right. They would have had a totally different conclusion than what they had.

527
00:56:15,310 --> 00:56:17,290
We actually have a highly significant p value.

528
00:56:17,770 --> 00:56:27,250
So I don't know if the statistician wasn't actually involved in this paper or if they are just not skilled.

529
00:56:27,460 --> 00:56:30,640
I don't know what happened, but this paper is not a good paper.

530
00:56:31,600 --> 00:56:36,360
And so it's unfortunate. Well, like some of it's unavoidable, right? Maybe we do make amendments and trials.

531
00:56:36,370 --> 00:56:43,180
However, the amount of amendments, the amount of changes plus the amount of incorrect results is just very concerning.

532
00:56:44,350 --> 00:56:47,950
Does it mean that this trial is bad? I mean, I think the analysis was bad.

533
00:56:48,160 --> 00:56:53,560
However, it looks like they weren't.

534
00:56:53,920 --> 00:56:55,450
It looks like it was a safe drug.

535
00:56:56,020 --> 00:57:05,290
And ultimately, I think that they were able to move forward with this drug, with that cohort three dosing schedule, and it was effective.

536
00:57:05,620 --> 00:57:08,770
So ultimately, right, I think good things came out of this trial.

537
00:57:08,800 --> 00:57:14,200
However, it would have been better if this trial was a bit more rigorous and the results shown have been done well.

538
00:57:14,530 --> 00:57:20,530
So I'm not saying it's like a wrong trial or it shouldn't been run necessarily, because I think ultimately it benefited patients.

539
00:57:20,560 --> 00:57:26,290
However, I think we probably could have done this in a better way and obviously presented the results much better.

540
00:57:29,240 --> 00:57:39,920
Okay. So here's an example of something that was well specified mostly and done well and actually ended after the first homework.

541
00:57:40,400 --> 00:57:47,360
So this is a phase two study in patients with relapsed or refractory cutaneous.

542
00:57:47,360 --> 00:57:51,220
And those I don't know what that is. Some some blood disorder, I think.

543
00:57:53,540 --> 00:58:01,880
And oh, this had already been approved for multiple myeloma, but I think they were testing it in this new this new hematologic cancer.

544
00:58:04,070 --> 00:58:08,630
So the primary endpoint is the best response in six months.

545
00:58:10,850 --> 00:58:17,360
And they posited that the best objective response rate was 30% and they were looking.

546
00:58:17,360 --> 00:58:22,880
So that's without this treatment, right? There's a 30% response and they wanted to see a much better response, like 60% or more.

547
00:58:23,240 --> 00:58:26,990
And they had 5% type one error and 90% power.

548
00:58:29,060 --> 00:58:35,690
So if we put this information in, this tumult, right, we could consider optimal or minimax or some admissible design.

549
00:58:36,260 --> 00:58:45,680
And we can see here that the first cohort is anywhere from 10 to 18 and the total sample size is anywhere from 23 to 28.

550
00:58:47,200 --> 00:58:54,099
So they decided to go with this admissible design where it's kind of in between.

551
00:58:54,100 --> 00:59:03,280
Right. Like it's not it's not requiring so many participants in the first stage or stopping as much of it's ineffective,

552
00:59:04,240 --> 00:59:08,590
but it has slightly less participants than the optimal design.

553
00:59:09,820 --> 00:59:14,580
And so, for example, if I put this in, this is the output. It says here is an admissible design, right?

554
00:59:14,590 --> 00:59:23,770
25 total patients. Here's the optimal design, 28 patients, and this is this max power and this is the mini max design up here.

555
00:59:27,200 --> 00:59:30,469
So they actually so they were going with this one.

556
00:59:30,470 --> 00:59:36,920
So they wanted 11 patients in the first stage because of the logistics and the practicality of like accruing patients,

557
00:59:36,920 --> 00:59:38,840
they actually ended up with 12 patients.

558
00:59:38,850 --> 00:59:45,950
So probably what happened is they didn't realize after the 11th patient and four on the same day, somehow two patients were enrolled.

559
00:59:46,340 --> 00:59:49,940
Right. So they so they said, oh, we've got to start the trial. We actually have 12.

560
00:59:49,940 --> 00:59:54,319
Let's look at the data. And then when they when they stopped and looked at the data,

561
00:59:54,320 --> 01:00:03,050
they actually had two patients who ended up withdrawing from the study before they could assess that response.

562
01:00:03,410 --> 01:00:09,380
And so then they had to open to back the study to enroll one more patient to get to that 11.

563
01:00:09,770 --> 01:00:14,720
Right. So they actually had 13 but they're looking through looking at the 11 evaluable patients.

564
01:00:18,890 --> 01:00:23,930
So this is what I think we call this is somewhat of a waterfall plot.

565
01:00:23,930 --> 01:00:27,979
And so it's showing you each individual enrolled in the trial.

566
01:00:27,980 --> 01:00:35,510
So this is all 13 patients enrolled, but the two who went through, we just don't have a lot of information on.

567
01:00:36,380 --> 01:00:39,980
And so you can see what happened. So obviously we're not identifying the patients.

568
01:00:39,980 --> 01:00:44,150
Right. These are just random subject IDs.

569
01:00:44,750 --> 01:00:52,670
And instead of putting it in from like who came in first to last, this is an order of how long they were on a study.

570
01:00:53,150 --> 01:01:01,700
And so you can see, right, that it goes from this person was on from not even one month to somebody has been on for 14 months.

571
01:01:02,750 --> 01:01:11,990
And as soon as somebody progresses, right. So this project means progresses that means that they're not going to get the right like this.

572
01:01:12,170 --> 01:01:16,100
This treatment isn't useful. They're not no longer on our trial. They've reached our end point.

573
01:01:16,100 --> 01:01:21,650
And so that's why they we stop following them. And this person, this Damien's withdrawn.

574
01:01:21,800 --> 01:01:26,420
So this person. Right. Stayed in for like a month and then withdrew from our study.

575
01:01:27,080 --> 01:01:32,719
And then this dark spot means that the patient has stable disease.

576
01:01:32,720 --> 01:01:37,820
So the disease isn't growing or getting worse, but it's not getting better.

577
01:01:38,390 --> 01:01:42,800
And then the gray means partial response.

578
01:01:43,190 --> 01:01:49,429
So that might mean that they're doing slightly better, but not hitting the benchmarks for actual complete response.

579
01:01:49,430 --> 01:01:59,290
And so then this. The dark lighter gray means that they have a complete response such that they've cleared the disease from from their blood.

580
01:01:59,890 --> 01:02:07,000
And so you can see that out of these patients, only one of them had a complete response by six months.

581
01:02:07,360 --> 01:02:12,970
So they were supposed to, in this admissible design, find three out of 11.

582
01:02:13,180 --> 01:02:17,970
Right. They actually have 12 evaluable patients and only one response.

583
01:02:17,980 --> 01:02:21,670
And so this had to stop at the end of the first cohort.

584
01:02:25,910 --> 01:02:29,240
So these examples show you that Simon like designs.

585
01:02:29,480 --> 01:02:34,129
Well, they don't. They show you two examples. But I'll let you know that if you go further in the literature.

586
01:02:34,130 --> 01:02:41,180
SIMON Two stage designs are very popular in oncology and AIDS research for Phase two designs.

587
01:02:41,570 --> 01:02:46,760
So if you look up either cancer studies or AIDS studies in phase two, you'll often see.

588
01:02:46,760 --> 01:02:52,680
Simon Two stage designs. They're useful starting point, but they don't have to be the be all, end all.

589
01:02:52,700 --> 01:03:01,459
You could also consider other optimality criteria and think about some other admissible designs and or either randomized or Bayesian designs,

590
01:03:01,460 --> 01:03:04,480
which we'll talk about next. All right.

591
01:03:04,490 --> 01:03:11,720
So let's see, because we're going to talk about Bayesian designs, which requires prior information.

592
01:03:12,230 --> 01:03:18,500
A lot of people forget that frequentist studies also have some prior information we just don't quantify.

593
01:03:18,520 --> 01:03:25,669
And so for assignment two, stage design, how much prior information are we implicitly claiming we have about the null probability of

594
01:03:25,670 --> 01:03:30,830
response or that probability response given the standard of care without our treatment?

595
01:03:58,680 --> 01:04:01,739
So most of you think a great deal that is true, right?

596
01:04:01,740 --> 01:04:08,680
We're implicitly saying that we know that we know the historical control rate or we know that no response.

597
01:04:08,700 --> 01:04:12,750
Right. We're not collecting data on it. We're not saying it varies.

598
01:04:13,080 --> 01:04:20,100
We're saying that the normal response is 10% or 20% and then we're saying how much better our experimental arm is.

599
01:04:20,440 --> 01:04:28,280
And so we're actually placing a great deal of prior information on this uninteresting response rate.

600
01:04:29,580 --> 01:04:35,610
So it's just something to remember when people one argument against Bayesian design is that it

601
01:04:35,610 --> 01:04:42,200
has this subjective prior information that you're putting weight on some prior information.

602
01:04:42,210 --> 01:04:47,730
However, you usually have some weight to put on prior information and frequentist statistics as well.

603
01:04:47,730 --> 01:04:55,050
We just don't quantify it the same way or talk about it. So you always want to think about these assumptions regardless of the framework.

604
01:04:55,410 --> 01:05:00,120
I'm not pro Bayesian or pro frequentist or anti Beijing or anti frequencies.

605
01:05:00,120 --> 01:05:05,460
I'm just like, whatever makes the most sense for the setting at hand, right?

606
01:05:05,470 --> 01:05:10,680
You want to think about the setting and think about what these options are and then apply the best thing.

607
01:05:12,450 --> 01:05:19,950
Okay, so patience is a six. We've already talked a little bit about this, but just a reminder that and frequentist statistics,

608
01:05:19,950 --> 01:05:27,810
what you primarily learn is that our population parameters of interest are fixed and unknown,

609
01:05:28,260 --> 01:05:32,610
whereas invasion statistics, they're actually random, right? Like, who knows the population.

610
01:05:32,610 --> 01:05:35,769
And actually, it's probably going to change based on different things, right?

611
01:05:35,770 --> 01:05:40,590
And so that's the Bayesian framework. The frequentist framework says, well,

612
01:05:41,280 --> 01:05:46,409
we can have this likelihood based point estimation and we're going to use hypothesis

613
01:05:46,410 --> 01:05:50,399
testing and we're going to focus on our results usually in terms of P values,

614
01:05:50,400 --> 01:05:53,430
and that reflects the probability of our data given the design.

615
01:05:53,640 --> 01:05:58,260
Bless you and frequencies statistics rate is based on this repeatability.

616
01:05:58,260 --> 01:06:03,060
What if you did this 100 times? How many times would you get the same thing or something more extreme?

617
01:06:03,540 --> 01:06:09,059
Right invasion statistics where we have our prior and we have our likelihood

618
01:06:09,060 --> 01:06:12,870
what we use observed and from that we get our posterior distribution of our

619
01:06:12,870 --> 01:06:20,760
population parameter and we generally can ignore the data generating mechanism

620
01:06:21,480 --> 01:06:27,390
because we are interested in this combination of the prior plus what we observe.

621
01:06:28,920 --> 01:06:34,770
So in the Bayesian design, we can allow stopping early whenever we want.

622
01:06:34,800 --> 01:06:39,300
So in the two stages I and you have N1 or N in the Bayesian design,

623
01:06:39,300 --> 01:06:45,540
you can have any N and you can decide to stop because you're going to create these rules that are based on probabilities.

624
01:06:45,840 --> 01:06:54,270
So you're going to say, well, once the probability that the response rate looks is not going to be higher than this thing is is high, right?

625
01:06:54,270 --> 01:06:58,830
Then I should stop. Or what's the probability that the response rate is?

626
01:07:00,510 --> 01:07:04,979
Maybe I didn't say that right is higher than something is very low.

627
01:07:04,980 --> 01:07:09,540
Right. Then I want to stop. If I if it looks like it's not going to happen, then I should stop early.

628
01:07:10,440 --> 01:07:16,140
The problem why these aren't why Bayesian designs aren't used often is because they're computationally intensive.

629
01:07:16,440 --> 01:07:21,269
They require more analysis because we can make decisions after every patient, right?

630
01:07:21,270 --> 01:07:28,290
Just like we saw with the CRM. And because that in most programs, statisticians are taught in a frequentist framework.

631
01:07:28,620 --> 01:07:32,130
And so learning Bayesian statistics takes a lot of extra steps.

632
01:07:32,970 --> 01:07:43,080
And so there are not as many well trained Bayesian statisticians to be doing this as there are frequentist statisticians also in small sample sizes,

633
01:07:43,080 --> 01:07:47,309
like in the serum and or phase two prior to prior information.

634
01:07:47,310 --> 01:07:50,549
Right? Your prior distributions can have more effect on the outcome.

635
01:07:50,550 --> 01:07:54,360
And so you really need to take that into consideration and make sure you're making good choices.

636
01:07:55,800 --> 01:07:59,100
Okay. So let's consider the likelihood of our Phase two data, right?

637
01:07:59,100 --> 01:08:05,280
We have this binary outcome, you respond or not. And so we just have this binary likelihood, right?

638
01:08:05,280 --> 01:08:10,290
This gamma is our is our parameter of interest.

639
01:08:10,740 --> 01:08:19,140
Right? And this how many responses you have is this arc and then K is how many patients you have.

640
01:08:19,680 --> 01:08:24,899
So we're interested in how many responses we have out of the total K patients thus far.

641
01:08:24,900 --> 01:08:28,440
And we're trying to figure out like the dose response rates.

642
01:08:28,440 --> 01:08:31,829
Right. And so what do we want to use for this price of gamma?

643
01:08:31,830 --> 01:08:35,309
This is the prior distribution of our parameter of interest.

644
01:08:35,310 --> 01:08:42,120
That's how we're specifying it. Pi, sub, gamma, that's what is the prior distribution of this parameter of interest.

645
01:08:43,050 --> 01:08:54,210
And so just like in the serum, when we had that DLT or not, we, if we have a binary outcome of interest, then we usually put a beta prior on that.

646
01:08:55,960 --> 01:09:06,880
On that parameter because the data distribution, when combined with the binomial likelihood, provides us again a beta likelihood.

647
01:09:06,880 --> 01:09:11,020
And so it's easy to interpret and to get information from.

648
01:09:11,800 --> 01:09:15,760
So our density of a beta distribution is as such.

649
01:09:16,060 --> 01:09:22,090
And what's nice about this and what we're going to use, as we saw with the CRM, is that the mean of a beta distribution.

650
01:09:22,090 --> 01:09:31,300
So indeed, beta distribution has two parameters A one or what we call hyper parameters A1 in A2 and the mean is A1 over A1 plus a two.

651
01:09:31,750 --> 01:09:35,320
And the variance is a such that's not quite as interesting.

652
01:09:36,160 --> 01:09:38,920
But this is a nice place.

653
01:09:38,920 --> 01:09:48,150
The A1 over A1 plus A2 allows us to figure out these values because whatever we believe the probability of responses ahead of time, right?

654
01:09:48,160 --> 01:09:56,500
We can use that. So we think it's 30%. Well, then we want to set up the beta distribution so that A1 over A1 plus two equals 30%.

655
01:09:56,620 --> 01:10:04,360
Right. And then if you remember that A1 plus A2 is like this effective sample size or the amount of weight we put on this prior.

656
01:10:04,780 --> 01:10:10,660
And so if we are planning to enroll 50 patients into our trial,

657
01:10:10,900 --> 01:10:17,050
we might want A1 plus A2 to be somewhere between like zero one and five patients worth of information.

658
01:10:17,120 --> 01:10:27,849
Right. We don't want it to overtake the data and so we can set up the algebra to say A1 plus two equals five and A1 over A1 plus two equals 0.3.

659
01:10:27,850 --> 01:10:33,969
And then we can solve for A1 and A2. Okay.

660
01:10:33,970 --> 01:10:41,400
So that's just what I said is that A1 plus A2 is this representing the historical patient's worth of data?

661
01:10:41,410 --> 01:10:45,489
So in the in the two stage.

662
01:10:45,490 --> 01:10:53,110
SIMON Two stage design, right? We say that historical pinot is like 20% and we're basically giving it a bunch of people's worth of data.

663
01:10:53,110 --> 01:10:55,780
We're saying that's what it is, right? Invasion design.

664
01:10:56,170 --> 01:11:01,180
We can decide how many people's worth of data we're giving that guess of that historical control.

665
01:11:01,630 --> 01:11:05,260
And like I said, usually it's somewhere between actually I think I have a summary.

666
01:11:08,910 --> 01:11:12,270
Usually it's Oh, no, I didn't put it there. Usually it's somewhere in between.

667
01:11:12,270 --> 01:11:15,899
Like it's a it depends, but like zero and five or six or whatever.

668
01:11:15,900 --> 01:11:23,520
It depends on the sample size. Right. But we want, we want this weight not to be too much so that our data actually talks to us.

669
01:11:25,920 --> 01:11:30,840
So now we can incorporate once we have that prior right in the beta prior plus

670
01:11:30,840 --> 01:11:36,120
the binomial distribution gives us another beta distribution as seen down here.

671
01:11:36,510 --> 01:11:45,299
And so now we can actually see that our response rate is a is distributed beta with these two parameters,

672
01:11:45,300 --> 01:11:52,980
a one plus the number of responders and a two plus the number of total patients seen so far, minus the number of responders.

673
01:11:54,510 --> 01:12:03,180
So this is just to give you some idea of like the amount of weight replacing on an on this on the with the prior distribution.

674
01:12:03,180 --> 01:12:10,649
So for example, all right, this beta one two distribution, all of these beta distributions have the same expected value, right?

675
01:12:10,650 --> 01:12:13,860
The same mean about one over three.

676
01:12:13,860 --> 01:12:19,710
Right, one third. So all these black lines are the same for all the A1 plus a twos are different.

677
01:12:19,740 --> 01:12:26,820
So this is small, this is three. So it's a very flat, almost uniform distribution around one third.

678
01:12:26,910 --> 01:12:30,450
Right. It's a little bit more weight toward down here.

679
01:12:30,450 --> 01:12:35,339
But because this tail goes out longer than a very flat distribution.

680
01:12:35,340 --> 01:12:41,850
So this says that while I think the mean is one third, I don't know, it could be anything from 0 to 1.

681
01:12:42,300 --> 01:12:47,760
Right. And I think it's probably more likely around here, but it really could take any of these.

682
01:12:48,180 --> 01:12:53,480
Now, the more the more weight I put in these. So now A1 plus two is six, right?

683
01:12:53,490 --> 01:13:00,570
My distribution is starting to take a little bit of a different look and it's saying, hey, actually, I don't think it's over here.

684
01:13:00,780 --> 01:13:08,129
Right? Like this tail got much smaller and the amount of mass over here got much larger and saying, Oh, you know what?

685
01:13:08,130 --> 01:13:11,790
I actually think it's probably more over here, but still not very strong.

686
01:13:12,210 --> 01:13:14,730
So that you see here that if I actually go to A1,

687
01:13:14,730 --> 01:13:22,049
plus A2 is 45 like 45 patients worth of data have a much more normally distributed curve right around

688
01:13:22,050 --> 01:13:29,070
that mean and it's saying I have a lot of weight on the fact that I think that this probability is 33%.

689
01:13:29,580 --> 01:13:38,780
Right. So I'm essentially taking my prior information and saying I strongly believe that the probability of response is 33% and the data can shift it.

690
01:13:38,790 --> 01:13:44,750
However, you're going to need to give me a lot of data because I have such a strong belief, like 45 patients worth of data, right?

691
01:13:45,000 --> 01:13:51,480
Imagine if we just observe ten people, it's not going to change us because we already have 45 patients worth of data essentially in this prior.

692
01:13:52,320 --> 01:14:01,440
So this is giving you some intuition about that the weight of this prior around the mean because the more

693
01:14:01,440 --> 01:14:07,380
and more a one plus two is the more and more we're getting that nice bell curve around our average.

694
01:14:11,100 --> 01:14:18,720
Okay. So the one arm vision, phase two design is going to say that we're not going to have a specific time.

695
01:14:18,900 --> 01:14:25,920
It's not a specific stage at which we stop. It's that we set up this rule, and as we accrue patients,

696
01:14:25,920 --> 01:14:34,140
we can calculate this probability that our response rate is greater than our uninteresting response rate plus on Delta.

697
01:14:34,170 --> 01:14:38,549
Right. We want to be better than that, given the number of responses we've reviewed so far.

698
01:14:38,550 --> 01:14:44,220
And if that probability is, we're going to compare that to some thresholds.

699
01:14:44,220 --> 01:14:46,450
And then based on that, we could stuff, right?

700
01:14:46,470 --> 01:14:52,770
And so usually we have a pi l as a threshold and phase two, we generally have these futility thresholds.

701
01:14:52,920 --> 01:14:56,670
However, you could potentially say that you can stop for efficacy as well.

702
01:14:57,450 --> 01:15:05,940
So you could say that, well, if this is so high, right, that it's like definite that I'm seeing a really good response rate, I can stop early.

703
01:15:06,030 --> 01:15:16,200
Like I said, we usually don't do that except for in the case where there is a really big need for getting this treatment to market fixed.

704
01:15:16,620 --> 01:15:23,370
Right. So if we want to get this treatment out to patients because there is no other option that we might stop early for efficacy,

705
01:15:23,370 --> 01:15:30,749
so we can go to phase three and get it up faster. Otherwise, usually we there are if there are other good treatment options,

706
01:15:30,750 --> 01:15:39,520
we usually want to get more data and look at some more like do different correlative studies to make sure that we're hitting the target or what,

707
01:15:39,570 --> 01:15:44,820
you know, it's really safe, etc. Okay.

708
01:15:44,820 --> 01:15:49,140
So we're trying to figure out this posterior probability that the response rate

709
01:15:49,170 --> 01:15:54,510
gamma exceeds some historical control rate by at least some delta amounts.

710
01:15:54,780 --> 01:15:57,850
And so this I give you this reading Mithal and Simon paper.

711
01:15:57,870 --> 01:16:01,110
So right. Simon is the same Simon from Simon to stage design.

712
01:16:01,590 --> 01:16:04,770
And he said, oh, this is great, right? I made that in 1989.

713
01:16:04,920 --> 01:16:09,820
But now in 1984, I work with my Bayesian colleague Peter Thall, who's done it and he,

714
01:16:09,840 --> 01:16:14,549
Anderson, and is giving a talk both in 803 and in our seminar in December.

715
01:16:14,550 --> 01:16:20,010
So you might want to check that out. He's a character. He is really interesting.

716
01:16:20,010 --> 01:16:25,140
So like, I would suggest that you don't miss that seminar. At least he is a funny, funny guy.

717
01:16:26,730 --> 01:16:33,270
So they got together and they said, Well, we can make this better. Let's use the Bayesian framework and say we can stop any time we wanted, right?

718
01:16:33,270 --> 01:16:37,800
Like let's not just have N1. And so that's what they did. So they, they came together and they said,

719
01:16:37,950 --> 01:16:46,050
so let's specify this criteria and give people some ideas about what the priors should be and what these pi ls in these pi use should be.

720
01:16:47,310 --> 01:16:55,320
And so we can see again that right this this prior this data prior on our response rate parameter,

721
01:16:55,320 --> 01:16:58,330
this A1 plus A2 is going to be very important, right?

722
01:16:58,410 --> 01:17:02,400
Because it's telling us how much we believe that probability of responses.

723
01:17:03,300 --> 01:17:08,100
And so for example, example of A1 plus A2 is five, right.

724
01:17:09,630 --> 01:17:15,180
And so and this is a the mean is 10% right is a ten you're expecting a 10%

725
01:17:15,180 --> 01:17:20,400
response rate and you're putting like five people worth of data on it on that.

726
01:17:20,610 --> 01:17:28,729
And then you actually observe. Up and then or right.

727
01:17:28,730 --> 01:17:35,320
So say it's 6.5 or 4.5 versus like oh no.

728
01:17:35,330 --> 01:17:40,730
So then so if you actually. Okay, so sorry, this is the prior probability point 5 a.m. 4.5.

729
01:17:41,060 --> 01:17:44,690
So that's 10% mean and weight of five right now.

730
01:17:44,690 --> 01:17:49,280
So you actually run the trial and after ten patients you see nine responses, right?

731
01:17:49,280 --> 01:17:52,460
That's the observed data. You have a 90% observed response rate.

732
01:17:52,820 --> 01:17:57,799
Now you combine, right? You combine the prior and the observed data into the posterior.

733
01:17:57,800 --> 01:18:03,260
And because it's a binomial and a beta, you can just calculate that easily so that our response rate,

734
01:18:03,260 --> 01:18:08,570
the posterior distribution is beta with the parameters 9.5 and five plus five,

735
01:18:09,140 --> 01:18:13,940
we can calculate the probability that our response rate is greater than or equal to point three.

736
01:18:13,970 --> 01:18:18,530
Remember, we came in with a guess of it's 10%. You see that it's 90%.

737
01:18:18,530 --> 01:18:28,370
We put these things together and in this case it says, well, there's 69% probability that you're that this true response rate is greater than 0.3.

738
01:18:28,730 --> 01:18:30,709
Right. We had some way on our prior.

739
01:18:30,710 --> 01:18:38,210
That's why it's not like if we just saw 90% in the frequencies rolled, we'd be like, oh my gosh, this is really definitely much higher, right?

740
01:18:38,210 --> 01:18:42,260
That probability would be very high. That is higher than 30%.

741
01:18:42,920 --> 01:18:46,430
But because we came in with a 10%, guess it's tempered, right?

742
01:18:46,850 --> 01:18:53,389
But imagine if we actually had the 10% guess with a much higher weight, five and 45.

743
01:18:53,390 --> 01:19:00,200
Right. That's like 50 people were at the data. And now we have these ten people's worth of data that we combine with the 50.

744
01:19:00,650 --> 01:19:05,690
And now our probability that our response rate is greater than point three is only 11%.

745
01:19:06,350 --> 01:19:13,130
Why? Because we have 50 data, 50 people worth of data on 10% and only ten on 90%.

746
01:19:13,580 --> 01:19:15,860
And because we have so much weight on that 10%,

747
01:19:15,860 --> 01:19:22,730
this probability that we have some greater probably some greater response rate, greater than 30% is actually super low.

748
01:19:23,330 --> 01:19:29,000
Right. So you can see that the prior is very important. That A1 plus 82 is very important here.

749
01:19:29,270 --> 01:19:37,219
We want the data to talk, right? We want the data to tell us however it's useful if we give it some guidance or what we believe.

750
01:19:37,220 --> 01:19:41,500
But we don't want our power to overtake the data. Okay.

751
01:19:41,500 --> 01:19:51,970
So we'll stop here and we'll finish this talk on vision trials on Tuesday and then we'll move into the randomized trials.

752
01:19:53,170 --> 01:19:59,200
Reminder, if you weren't here in the beginning, your homework is now next Thursday, not next Tuesday.

753
01:20:00,280 --> 01:20:06,290
I'll see you. Yeah, I know that.

754
01:20:06,480 --> 01:20:10,890
Literally. My father's a psychologist.

755
01:20:11,610 --> 01:20:18,000
I know that. Oh, yeah.

756
01:20:21,000 --> 01:20:28,700
And I said, Where is that? He says he wants to make sure to.

757
01:20:29,140 --> 01:20:35,570
To you? Yeah. Yeah. And then, like, here's a little more.

758
01:20:36,720 --> 01:20:57,660
Yeah, yeah, yeah. It's just I know it sounds like for you thing, I think that maybe he needs to be understood so that something like normal.

759
01:21:04,050 --> 01:21:18,090
Yeah. I said, you know something that really kind of life that I think of it this morning and I was like,

760
01:21:18,090 --> 01:21:32,500
yeah, it's probably going to be going to the movie partners and stuff.

761
01:21:33,190 --> 01:21:43,970
So how did you meet real people in your life?

762
01:21:43,990 --> 01:21:47,490
And I was working my friend, and he was like, Yeah, I'm buying your house.

763
01:21:47,490 --> 01:21:52,240
And I was like, Oh my gosh, it's exciting. It's such a great accomplishment. And I said, Where is it?

764
01:21:52,530 --> 01:21:56,160
Well, he said, Hang on, I'll just needs a little update.

765
01:22:01,230 --> 01:22:02,400
That is the word.

766
01:22:02,400 --> 01:22:31,060
I'm a little I think he really liked the way he could playing sports, you know, in cycling this evening, I think he might like just on Saturday live.

767
01:22:31,230 --> 01:22:35,540
So I'm having a lot of trouble walking the streets.

