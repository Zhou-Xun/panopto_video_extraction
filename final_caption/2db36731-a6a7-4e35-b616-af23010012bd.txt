1
00:00:01,050 --> 00:00:20,980
All right. Okay.

2
00:00:24,260 --> 00:00:30,580
Cool. And when we started to recognize the names.

3
00:00:33,250 --> 00:00:39,970
Okay. Thank you. Okay. So just a little bit of logistics before we dove into material.

4
00:00:41,710 --> 00:00:47,050
So the next two set of class notes, starting with class notes, eight and nine.

5
00:00:47,050 --> 00:00:52,150
So the ones that are up for this week and next week two are mediation,

6
00:00:52,150 --> 00:00:56,410
direct and indirect effects that'll that'll kind of cover the material through the midterm.

7
00:00:58,510 --> 00:01:02,410
It's also, frankly, I think, the basic set of sort of paradigms for causal inference.

8
00:01:02,980 --> 00:01:08,020
So it sort of gets us to sort of the basic level of what we needed, I think, covered in this in this class.

9
00:01:09,580 --> 00:01:15,549
I think I'll probably do one more homework after the midterm that will will cover some of this material.

10
00:01:15,550 --> 00:01:23,950
So you'll be able to kind of get a chance to to look at that and then and then focus on on final reports.

11
00:01:25,750 --> 00:01:32,409
The since there's only been seven of us, we might sort of map 699 even a little more closely and have people give a little

12
00:01:32,410 --> 00:01:36,819
sort of preliminary thoughts on what they're talking about at some point. Take a class for that.

13
00:01:36,820 --> 00:01:41,110
But but we'll see what the idea is and how popular that might be.

14
00:01:41,110 --> 00:01:48,340
It'll also give you a chance to get some feedback right as you move forward, not only from me, but from from your rest of the class.

15
00:01:51,040 --> 00:02:00,000
Okay. And I guess the last thing, as I said, I think next class Wednesday, we'll take a little bit of time for the sort of instrumental variable idea.

16
00:02:01,170 --> 00:02:06,969
This my first time I taught this class I think was kind of fun and again, not mandatory.

17
00:02:06,970 --> 00:02:11,500
But but if at least some of you have some things to take some time for that.

18
00:02:11,530 --> 00:02:17,650
So. Okay. Any questions before we dove in?

19
00:02:21,740 --> 00:02:34,040
Okay. So just to kind of finish up on moving back to the instrumental variable particular this overlap.

20
00:02:40,900 --> 00:02:49,060
Between the instrumental overall approach and the HD effect players or the player average causal effect.

21
00:02:52,180 --> 00:03:01,150
So I think we started on this last week, but I'll I'll sort of just rehash some of it to get people's head back in their head and finish up.

22
00:03:03,640 --> 00:03:13,870
So this intent to treat effect in compliance using this principal verification approach matches this instrumental variable estimate.

23
00:03:13,870 --> 00:03:23,770
Or when there is a single binary instrument and a single binary intermediate variable so that the following assumption and the findings are met.

24
00:03:23,830 --> 00:03:32,830
The super is sort of independence from other treatment assignments and the fact that the observed outcome

25
00:03:33,250 --> 00:03:38,780
under a given treatment is equivalent to the potential outcome under the treatment arm randomization.

26
00:03:38,860 --> 00:03:42,460
Right. So our treatment is randomized exclusion restriction.

27
00:03:43,570 --> 00:03:50,350
So that means that there's only going to be a causal effect in compliance with

28
00:03:50,350 --> 00:03:56,229
this intent to treat effect in or in potentially modifiers if you allow for it.

29
00:03:56,230 --> 00:04:04,390
Because this to treat effect in always takers and never takers is zero and only goes through the.

30
00:04:14,280 --> 00:04:19,530
The entire effective treatment is only in having taken the treatment and tenacity.

31
00:04:19,530 --> 00:04:23,400
So no to fires. So you should turn that around.

32
00:04:24,600 --> 00:04:42,180
So. Okay. So. So our definition of two stage these squares can be written as the covariance between the outcome and the treatment.

33
00:04:42,630 --> 00:04:51,360
Just observed outcome, observed treatment and the covariance divided by the covariance between the instrument and the treatment.

34
00:04:52,470 --> 00:04:57,480
And so for the treatments, binary, right from the definition of covariance we can write,

35
00:04:57,480 --> 00:05:04,260
covariance is the expected value of the product of Y and Z, minus the expected value of Y and expected value T, right?

36
00:05:04,620 --> 00:05:12,300
So if these are independent, then this expects the expectation of the product is the product of the expectations of the covariance zero.

37
00:05:13,140 --> 00:05:18,240
So otherwise these two are not equal to each other.

38
00:05:19,320 --> 00:05:29,370
So the well totally true but, but when, when this went independent towards the zero.

39
00:05:30,120 --> 00:05:37,170
So then if we're going to have a well we can rewrite the.

40
00:05:43,920 --> 00:05:50,620
Right. And brings peace here. All right.

41
00:05:50,640 --> 00:05:57,690
So in 00001100, then this quantity is going to be zero.

42
00:05:58,560 --> 00:06:03,440
Since the expected value of y times zero six, y times zero, of course, would be zero.

43
00:06:04,260 --> 00:06:06,959
So basically this expectation,

44
00:06:06,960 --> 00:06:19,080
the expected value of of Y and Z can be written as the expected value of Y given equal to one times probabilities equals one.

45
00:06:19,120 --> 00:06:24,540
Right, because if it if Z is zero, then then this quantity zero.

46
00:06:24,540 --> 00:06:27,630
So right when they exist in Z is one.

47
00:06:28,830 --> 00:06:36,570
And for this part, we're just going to expand out the expectation of Y using conditional expectations.

48
00:06:37,290 --> 00:06:43,349
So the marginal expectation of Y is the expectation of Y and z equals one times probabilities equals

49
00:06:43,350 --> 00:06:48,690
one plus the expected value of Y and equals zero times of probability is equal to zero or one one.

50
00:06:48,690 --> 00:06:52,679
It's a probability z it was one, right? So that's just definitions.

51
00:06:52,680 --> 00:06:55,680
And then of course expectation of Z is just the probabilities equals one.

52
00:06:56,050 --> 00:07:02,730
Again for SUSY is binary. So you ready.

53
00:07:02,730 --> 00:07:05,760
Okay. On that these steps.

54
00:07:08,310 --> 00:07:27,560
So we can then factor out. Probability of.

55
00:07:31,880 --> 00:07:37,220
Why giving as equals to one factor this piece here. And then we have the product of this and this.

56
00:07:38,150 --> 00:07:45,950
And so that goes down to that that there then we just have this piece left over, which is basically this times.

57
00:07:45,950 --> 00:07:58,930
This is this. Right. So and of course, we can rewrite this is probably Z times one minus the probability Z was one which the same piece here.

58
00:07:58,940 --> 00:08:03,410
So we can factor all this out. So we get down to this part here.

59
00:08:04,130 --> 00:08:10,010
So basically these. Until of the communities.

60
00:08:10,010 --> 00:08:17,680
The variances, he claims, is conditional expectation. Okay.

61
00:08:19,330 --> 00:08:23,710
And then we can play exactly the same game replacing X with Y.

62
00:08:25,660 --> 00:08:29,740
I'm sorry, replacing y with x. So they give us this piece there.

63
00:08:30,640 --> 00:08:35,770
So you can see when we take the ratio, we get this nice cancelation.

64
00:08:40,100 --> 00:08:44,419
Now further, we have these assumptions. I think we also went through this.

65
00:08:44,420 --> 00:08:49,310
So this is suit for this one authenticity. This is the exclusion restriction.

66
00:08:51,480 --> 00:08:58,940
So. Rewriting.

67
00:09:05,900 --> 00:09:17,120
This margin of error, this conditional probability of y giving equals to one, then so we can replace under under suit five.

68
00:09:17,120 --> 00:09:21,140
We can replace this observed expectation with the potential outcome.

69
00:09:22,400 --> 00:09:26,719
And then we're just going to replace the fact that the compliance classes

70
00:09:26,720 --> 00:09:33,080
consist of compliance always takers and ever takers so we can rewrite the C of

71
00:09:33,080 --> 00:09:38,479
Y given the equals one is here y one and then we just condition on compliance

72
00:09:38,480 --> 00:09:43,370
class and multiply by that probability sort of total probability approach.

73
00:09:43,820 --> 00:09:48,890
Okay. So then can play the same game four as equals zero.

74
00:09:50,030 --> 00:10:00,320
The key factor factor being here now that we can replace the potential outcome of y under control with the potential outcome of winner or treatment.

75
00:10:01,250 --> 00:10:04,460
Right. That's assuming this exclusion restriction, right?

76
00:10:04,700 --> 00:10:08,660
Only for the only for the always takers and then ever takers.

77
00:10:10,130 --> 00:10:15,290
So. Right.

78
00:10:15,290 --> 00:10:34,230
And so then we can. We can then go to the denominator piece and again, we could have the approach where assuming x is is binary here.

79
00:10:34,770 --> 00:10:37,620
So it's expectation is just the probability that's equal to one,

80
00:10:40,650 --> 00:10:53,430
but the probability that the compliance behavior that people comply or the yes, that the treatment taken behavior, let's say.

81
00:10:54,540 --> 00:10:57,779
So the probability that they take treatment, given their assigned treatment,

82
00:10:57,780 --> 00:11:02,010
means if that's observed, then they're either a comply or an always taker.

83
00:11:03,420 --> 00:11:07,350
And so we as equals zero, right?

84
00:11:07,350 --> 00:11:14,760
We get down here if they're observed to take the treatment when they're not assigned to it, that means they have to be an always take home.

85
00:11:15,270 --> 00:11:21,210
So the nice thing is then we subtract this from this. We pulled out the observed probability of being a compliance.

86
00:11:23,610 --> 00:11:30,030
And similarly, when you subtract this from this, we can cancel these pieces here.

87
00:11:32,270 --> 00:11:35,980
Right. Because I want him to survive this one. Right.

88
00:11:36,030 --> 00:11:41,420
We don't assume that this is the same as that would be taking away the treatment, the fact that we're trying to estimate.

89
00:11:42,890 --> 00:11:48,500
So that just leaves us with the marginal probabilities of compliance.

90
00:11:49,800 --> 00:11:58,940
Right. We just cancel those. And now then we're just looking at the expected value of the difference between potential outcomes among the compliance.

91
00:11:58,940 --> 00:12:06,680
And that's the case. So our instrumental variable estimator of the causal effect is equal to the ITC effect on compliance.

92
00:12:10,970 --> 00:12:14,850
So. Questions on the math.

93
00:12:27,380 --> 00:12:31,430
Okay. So but conceptual here, conceptual stuff made quite a lot here.

94
00:12:32,210 --> 00:12:36,950
So the basic idea is this assumption that the.

95
00:12:39,830 --> 00:12:47,930
Residual from aggressing treatment on the control is independent of.

96
00:12:50,060 --> 00:12:54,440
The compliance, the the the treatment taken variable, if you will,

97
00:12:54,440 --> 00:13:06,770
for the compliance behavior bureau encodes two of the principal stratification assumptions essentially that the assignment of of of Z is ignored.

98
00:13:07,010 --> 00:13:11,540
Right. So you basically got this independence between our.

99
00:13:16,600 --> 00:13:22,720
Or mediator or or which is sorry or a mediator is the treatment assigned itself.

100
00:13:23,110 --> 00:13:24,940
So that definitely holds.

101
00:13:25,810 --> 00:13:36,010
And then the effect of Y Z on Y is entirely through X, because in a moment we're going to try to codify this a little bit differently.

102
00:13:36,010 --> 00:13:40,959
But this idea of the exclusion restriction that the only way that treatment affects the outcome is

103
00:13:40,960 --> 00:13:51,040
through the treatment taken is is basically encoded in this this assumption of of no coherence between.

104
00:13:54,510 --> 00:14:07,860
Episode. So. So furthermore, this kind of tenacity implies a kind of a constant relation to X and Z.

105
00:14:07,860 --> 00:14:10,260
There sort of no interactions, right?

106
00:14:11,100 --> 00:14:18,509
So this idea that you don't have this this interaction term and we're going to actually relax again in the next the next set,

107
00:14:18,510 --> 00:14:22,440
we're going to have more general approaches of so-called mediation we're going to consider.

108
00:14:24,570 --> 00:14:31,860
So this principle stratification and I know it can be sort of we just kind of extend in instrumental variable approaches,

109
00:14:32,280 --> 00:14:35,810
at least in the binary intermediate variable or instrumental variable section,

110
00:14:36,540 --> 00:14:40,700
since the exclusion restriction assumption of monitors can be relaxed, right?

111
00:14:41,070 --> 00:14:46,920
You don't have to keep those. But retaining the causal inference interpretation of the average treatment affects these good players.

112
00:14:47,340 --> 00:14:52,230
So it's kind of a more it's a generalization of this instrumental variable effect or the to switch these squares as beta.

113
00:14:53,310 --> 00:14:58,590
So which is kind of one of the main points, the stratification.

114
00:15:01,320 --> 00:15:05,910
So okay. So we can try to link those two together a little bit.

115
00:15:09,590 --> 00:15:18,320
All right. So we've gone through randomization stratification.

116
00:15:18,420 --> 00:15:29,319
Stratification approaches which are kind of in some ways a special case of principal stratification, although they they certainly aren't.

117
00:15:29,320 --> 00:15:35,680
The whole story, I should add, just to finish up that it's sort of deeper than what I've covered here.

118
00:15:36,590 --> 00:15:40,810
I know we probably featured the one or two credit class on instrumental variables by themselves.

119
00:15:43,450 --> 00:15:44,310
So, you know,

120
00:15:44,500 --> 00:15:54,190
we've we've only looked at the sort of normally distributed or at least continuous type measures that we can assume symmetrically distributed.

121
00:15:54,190 --> 00:16:01,150
So we haven't talked about more generalized linear models. There are sensitivity analyzes for these failures of that indoctrinating assumptions.

122
00:16:01,900 --> 00:16:12,400
We talked a little bit about that, but there are ways to to assess that and without having to make assumptions or making assumptions,

123
00:16:12,400 --> 00:16:17,229
but in ways that you sort of stabilize that and take that as a new approach and sort of see

124
00:16:17,230 --> 00:16:22,810
what happens to your results and then enhancing the strength of multiple weak instruments.

125
00:16:23,650 --> 00:16:27,190
Can we see putting in multiple models can help with that, but there are some other approaches.

126
00:16:27,850 --> 00:16:37,840
So some of this works inside of potential outcomes frameworks and was outside of it, but yet it is kind of another set of approaches.

127
00:16:41,390 --> 00:16:54,220
Okay. So let's move on to.

128
00:16:57,940 --> 00:17:06,190
Mediation, direct and indirect effects. So you're background here in this sort of class notes,

129
00:17:07,390 --> 00:17:15,700
we're going to start out with a definition which again sort of precedes potential outcomes paradigm, the so-called Bernie Kenney method.

130
00:17:17,140 --> 00:17:25,570
We're then going to move into an assessment of mediation and the potential outcomes approach and which are typically term,

131
00:17:25,570 --> 00:17:33,940
direct and indirect effects and somewhat akin to what we just talked about with instrumental variables and principal stratification.

132
00:17:33,940 --> 00:17:42,160
You can see that these sort of Bearden Kenny approaches correspond to a sort of a special case of this more broader mediation idea

133
00:17:42,690 --> 00:17:49,810
that they imply a bunch of assumptions that aren't necessarily really obvious in the sort of regression based development of it.

134
00:17:52,570 --> 00:18:02,320
So and then we'll talk about some measures of mediation under these potential outcome, direct and indirect effect approaches.

135
00:18:02,320 --> 00:18:09,950
And finally, finish up with an example. We're not going to get to all of this today, but part way down.

136
00:18:13,060 --> 00:18:21,300
Okay. So. So the concept of mediation is is critical to causal inference.

137
00:18:22,830 --> 00:18:32,309
It's kind of a that the natural next question that arises after determining that a treatment or exposure causes that outcome as to ask

138
00:18:32,310 --> 00:18:41,130
how it causes that outcome and the fact or event that links that exposure to the outcome through a causal pathway is termed a mediator.

139
00:18:42,390 --> 00:18:53,340
So the sort of non mathematical or sort of lay definition, I guess transmission by an immediate mechanism or agency.

140
00:18:54,360 --> 00:18:58,709
So some specific examples to go back to a kind of silly moon and tides example.

141
00:18:58,710 --> 00:19:01,860
Gravity would be the mediator there between the moon and earth tides.

142
00:19:04,200 --> 00:19:15,750
Something more serious example. If we look at, you know, the well-established pathways between smoking and lung cancer, risk, tar,

143
00:19:15,810 --> 00:19:22,020
formaldehyde are not the only carcinogens, but they are important carcinogens that mediate part of that effect.

144
00:19:23,450 --> 00:19:31,109
Right. So you can think about of the how of of smoking that causes lung cancer through

145
00:19:31,110 --> 00:19:37,530
this is through the inhalation and processing of tar formaldehyde in the body.

146
00:19:38,430 --> 00:19:45,090
And you can sort of break that down further. Right tar from how to tar formaldehyde cause this will they enter cells damage DNA.

147
00:19:45,720 --> 00:19:51,750
It's part of the sort of chain of events from in relation to the cigaret smoke to the formation of the cancerous tumors.

148
00:19:52,690 --> 00:19:56,210
So and of course there are other carcinogens.

149
00:19:56,220 --> 00:20:02,430
It's not the only ones cigaret so they sort of have these idea of multiple mediators, multiple pathways, which we'll get into.

150
00:20:06,420 --> 00:20:16,730
So without sort of requiring a fully mechanistic definition here, we can define mediation as just take turns that uses physical models.

151
00:20:17,460 --> 00:20:27,000
And we're generally going to try to use the letter M to do a potential mediator variable to kind of keep our notation consistent.

152
00:20:28,710 --> 00:20:36,480
And as I mentioned before, that's barely any work, actually, I think is one of the single most cited papers and statistics.

153
00:20:36,480 --> 00:20:41,580
I think it has over 100,000 citations now, dates from, I think 86,

154
00:20:42,660 --> 00:20:45,930
although the potential outcome stuff didn't really get in the way until the nineties.

155
00:20:47,400 --> 00:20:54,420
So okay. It's actually, I guess not only in statistics, it's actually when the most cited papers in all of science.

156
00:20:55,080 --> 00:21:06,090
So, okay, so this idea of defining mediation was done in a regression context and in particular are considered fitting two models,

157
00:21:07,470 --> 00:21:15,840
one relating the mediator linearly to a treatment or exposure call in the usual way,

158
00:21:16,470 --> 00:21:23,990
and then another model relating the outcome to a combination to it, to a regression model,

159
00:21:24,000 --> 00:21:29,280
a jointly model based on the treatment exposure and the mediator itself.

160
00:21:30,840 --> 00:21:41,700
So the direct effect was given by beta one in this model and the indirect effect was given by the product of alpha and Beta two.

161
00:21:42,480 --> 00:21:49,050
So we're going to try to define direct and indirect effect a little more precisely in a bid to basically.

162
00:21:53,840 --> 00:21:59,630
The idea of the direct effect is the direct effect of treatment that we're not not through the mediator.

163
00:22:00,650 --> 00:22:05,299
So that's going to be a little confusing because you're sort of thinking about we're concerned about mediation.

164
00:22:05,300 --> 00:22:08,840
So it's the direct effect, the effect of the mediator. It's not the opposite of that.

165
00:22:09,650 --> 00:22:15,980
So it's sort of the thing that where the treatment kind of directly affects the outcome, not through this other pathway.

166
00:22:17,270 --> 00:22:22,250
And the indirect effect is actually the effect through the pathway of interest.

167
00:22:23,120 --> 00:22:29,060
So it's it's very hard to get that. At least it was for me to get that in my head when I was first thinking about this.

168
00:22:29,930 --> 00:22:36,980
So, so kind of logically, you can see, right, if you're sort of conditioning or holding the mediator constant,

169
00:22:37,520 --> 00:22:41,450
you might think that beta one is a sensible estimate for that direct effect.

170
00:22:41,810 --> 00:22:46,160
Right? So mediator doesn't change. There's still some effect on the outcome.

171
00:22:46,760 --> 00:22:51,440
That's got to be the effect. It's not called through the media like constant.

172
00:22:52,610 --> 00:22:58,310
The indirect effects may be somewhat less clear as a product of the two, but.

173
00:23:15,990 --> 00:23:23,350
Another huge way I can say for some of this fear itself is very void.

174
00:23:27,660 --> 00:23:33,750
So the idea of these pictures is you're kind of trying to show graphically there's some improvement.

175
00:23:35,190 --> 00:23:39,060
There's some impacts. Mediator.

176
00:23:39,870 --> 00:23:47,640
Okay, so this is this whole thing with the cigaret information of the car and formaldehyde in the body.

177
00:23:48,690 --> 00:23:59,090
This is the cancer cell. So, you know, there would be some effect of cigaret development of cancer that doesn't involve formation of know.

178
00:23:59,220 --> 00:24:04,840
And so that's kind of the idea and kind of right.

179
00:24:04,840 --> 00:24:15,920
The. The kill efficiency is something which is so.

180
00:24:22,110 --> 00:24:33,950
And. So again we're not really potential outcomes world here yet.

181
00:24:35,330 --> 00:24:39,710
So we're going to write this in terms of future data.

182
00:24:43,960 --> 00:24:54,330
Emphasize here that. So right.

183
00:24:54,380 --> 00:25:07,250
So we would we're going to hold in constant here and then I finish my day and then we're going to take another expectation respect to him.

184
00:25:09,320 --> 00:25:15,870
The idea there. So you do that, right?

185
00:25:15,920 --> 00:25:21,460
We used to have our. This model here.

186
00:25:22,240 --> 00:25:28,020
Not staying away has been you and.

187
00:25:34,260 --> 00:25:42,270
So now we go through and we take the tape and we get a truly random.

188
00:25:42,270 --> 00:25:53,160
So still conditional. So you get the Internet atmosphere no one wants it to.

189
00:25:54,990 --> 00:26:00,830
And what's. It's just going to be to replace it with an expectation.

190
00:26:30,700 --> 00:26:42,730
So right now, this is my. Assumptions about not having a patient zero their term.

191
00:26:46,030 --> 00:26:50,980
So now I'm going to kind of collect together my terms and do and don't involve a.

192
00:27:07,390 --> 00:27:10,790
I need to be drafted right over here.

193
00:27:10,790 --> 00:27:17,200
And that would be the one plus one day to be.

194
00:27:18,750 --> 00:27:24,910
So. Decomposed here.

195
00:27:55,040 --> 00:28:00,650
And so it's of decomposes into a piece that involves this direct effect.

196
00:28:04,460 --> 00:28:08,690
And then a part involves this directly, this indirect effects.

197
00:28:12,480 --> 00:28:24,890
To the right person. And so I various.

198
00:28:32,550 --> 00:28:37,250
I just have some constant. And then this.

199
00:28:50,140 --> 00:29:05,600
The direct and indirect effects. That's a basic testament, just a very.

200
00:29:19,340 --> 00:29:23,240
We think there is one thing going on here. We don't have any interaction.

201
00:29:23,470 --> 00:29:26,580
Right. This assumes basically you're in an accident.

202
00:29:46,460 --> 00:29:55,460
The other critical issue is that because we measure em after a, we can't really assign causal interpretations here.

203
00:29:57,350 --> 00:30:02,180
So while we are trying to get some idea of the effect of the issue.

204
00:30:03,180 --> 00:30:04,650
And frankly, it's more.

205
00:30:09,490 --> 00:30:15,970
We aren't really thinking in terms of potential outcomes, like what would happen to the new leader under treatment under a control.

206
00:30:17,740 --> 00:30:24,900
So. That's the next step.

207
00:30:26,160 --> 00:30:29,580
And so I'm taking a lot of this out of the band, real text.

208
00:30:29,580 --> 00:30:34,740
So we kind of switch textbooks up here and I'm going to use their notation.

209
00:30:35,940 --> 00:30:43,500
So this idea basically expands, tries to expand the concept of what do we mean by mediation?

210
00:30:44,070 --> 00:30:49,260
If we allow both the mediator and the outcome to have potential outcomes under treatment.

211
00:30:51,750 --> 00:30:55,860
So and particularly for the outcome now,

212
00:30:56,880 --> 00:31:07,170
we can sort of think about what happens to this outcome if we separately manipulate the mediator and the exposure treatment.

213
00:31:08,400 --> 00:31:16,290
So we now have sort of added an extra dimension to the potential outcome setting.

214
00:31:18,630 --> 00:31:21,360
I guess here I'm going to switch because I'm sort of switching textbooks.

215
00:31:21,360 --> 00:31:25,350
I'm going to switch to the band on notation, which uses the subscripts with an imprint disease.

216
00:31:26,130 --> 00:31:27,570
In some ways, it seems clear to me.

217
00:31:30,480 --> 00:31:37,560
So so this is obviously a big step forward, or at least a different direction from the approach that we've sort of taken before,

218
00:31:39,720 --> 00:31:42,810
in part because we know we're sort of trying to get at this this idea that need here.

219
00:31:43,890 --> 00:31:51,210
So and of course, we're going to retain the notation that allows the mediator to take the set of potential values and are different treatments.

220
00:31:52,500 --> 00:32:02,110
Right. So we can still think of what would happen to our levels of formaldehyde in individual had they not been smoking versus had the smoking.

221
00:32:04,790 --> 00:32:12,170
So now you can quickly start to see that once we allow for this.

222
00:32:13,100 --> 00:32:18,180
This gets interesting. Right.

223
00:32:18,190 --> 00:32:24,580
So there's a couple. A couple ideas here, this idea of a sort of separate manipulation.

224
00:32:26,410 --> 00:32:31,780
So I want to write this down and let the blank space we write.

225
00:32:31,780 --> 00:33:10,770
But. It's the cigaret.

226
00:33:17,670 --> 00:33:25,410
The. You know, you could imagine.

227
00:33:30,770 --> 00:33:38,760
Other sources could.

228
00:33:48,800 --> 00:34:11,630
Manipulated. Ha. Other than Cigarets and Cigarets.

229
00:34:22,180 --> 00:34:34,360
Other sources of air pollution from Cigarets and other environments are very difficult for independent.

230
00:34:37,430 --> 00:34:43,410
You know, maybe. Some smokers.

231
00:34:48,460 --> 00:34:56,850
He least the theory kind of been employed in the past and.

232
00:34:59,280 --> 00:35:28,620
And different social networks. Different modes of parking outside.

233
00:35:29,250 --> 00:35:37,559
So it's all kind of counterfactual here, sort of explain what would happen if they were able to somehow have an individual have

234
00:35:37,560 --> 00:35:42,110
and continue to smoke but have lower levels and even zero levels of formaldehyde.

235
00:35:43,260 --> 00:35:57,450
If I had said it's not smoking and I sort of increased or decreased decreases. So it's sort of compliance example.

236
00:36:06,030 --> 00:36:16,960
Right. So you're. You know, the previous two sectors having 4 to 6 claims against.

237
00:36:22,640 --> 00:36:30,540
Well with our media, it's great to sort of think about the example of, you know, noncompliance,

238
00:36:31,890 --> 00:36:37,740
where you just may not take treatment at their side or treatment from that side.

239
00:36:38,610 --> 00:36:47,510
What's the mediator there? Exposure is the treatment assignment.

240
00:36:48,540 --> 00:36:53,010
To the viewers. All right, but.

241
00:36:57,640 --> 00:37:03,220
Of compliance. Quite frankly, my attitude.

242
00:37:14,460 --> 00:37:19,540
So. So this 1000 players.

243
00:37:26,280 --> 00:37:33,780
We could force. Someone.

244
00:37:36,300 --> 00:37:43,090
And take in the treatment. We're not.

245
00:37:52,700 --> 00:37:53,900
Regardless of treatment assignment.

246
00:38:09,510 --> 00:38:16,469
So, you know, we're kind of okay conceptually, but, you know, in practice, you know, different side effects and so forth.

247
00:38:16,470 --> 00:38:25,860
Like in the extreme case, the side effects that like, you know, for some pretty side effects, there's no meaningful outcome.

248
00:38:26,280 --> 00:38:31,260
So if you work for someone on the treatment.

249
00:38:34,330 --> 00:38:45,100
Independent insider. So the sort of principles are usually said, let's first verify individuals based on their behavior.

250
00:38:45,760 --> 00:38:47,169
This sort of mediation approach says,

251
00:38:47,170 --> 00:38:58,360
let's imagine that we can take everybody and get them to take the treatment or not and then have the treatment assigned or not independently.

252
00:38:58,510 --> 00:39:04,130
And then consider that potential outcomes and use that to define our.

253
00:39:07,250 --> 00:39:14,630
So. All right.

254
00:39:14,840 --> 00:39:16,610
You know about this, Karl? Effects of interest.

255
00:39:23,380 --> 00:39:30,090
What are they going to be and what are sort of three, three big ones that we're going to we're going to focus on here, at least to start with?

256
00:39:31,410 --> 00:39:43,950
The first one is the controlled, direct effect, so that the natural direct effect in the natural indirect effect and I'm using the term eight,

257
00:39:43,960 --> 00:39:46,380
they start to refer to two different treatment levels.

258
00:39:47,280 --> 00:39:56,370
But if you want to think of a as one treatment in a star zero control, then maybe we can sort of becomes a little easier to talk about these.

259
00:39:58,920 --> 00:40:02,640
So what's then someone saying words with this controlled direct effect is.

260
00:40:09,770 --> 00:40:15,050
What are we doing here? So look at these subscripts fixing the and variance in this.

261
00:40:15,680 --> 00:40:16,580
Right, exactly.

262
00:40:17,390 --> 00:40:23,780
Sort of holding or the treatment effect of the treatment holding the median value at some level them which is why it's sort of indexed by M.

263
00:40:24,140 --> 00:40:27,530
Right, because you can have them as continuous.

264
00:40:27,530 --> 00:40:32,390
You could have sort of infinite number of these. If it was binary, then you could have two, right?

265
00:40:32,660 --> 00:40:40,010
You have the effect of the treatment holding the mediator at some little outcome one and then some of the outcome zero.

266
00:40:41,030 --> 00:40:45,050
What about that so-called natural indirect effect?

267
00:40:47,250 --> 00:40:59,770
It's. You know, it's just a little different how we're actually thinking about potential outcomes for the mediators.

268
00:41:22,940 --> 00:41:26,360
Yeah. What I want to try to say this same words.

269
00:41:40,370 --> 00:41:43,990
Is this subscription? You're right.

270
00:41:44,470 --> 00:41:49,190
Okay, so this is the mediator. What? What. What does may start me.

271
00:41:51,710 --> 00:41:58,810
So mediate starts control. Like under like this in like a prison.

272
00:41:59,520 --> 00:42:04,310
Right. So.

273
00:42:06,980 --> 00:42:14,540
This is obviously a treatment effect, but controlling for a 1 to 1 with the media controlling the contributor is.

274
00:42:19,200 --> 00:42:25,320
I don't know. I can't explain this. They start the eve and they start right.

275
00:42:25,710 --> 00:42:36,270
Well, this is all right. So basically if we go back to the cigaret example, right, so you can think about this as if we were whole,

276
00:42:36,270 --> 00:42:41,610
the formaldehyde and tar levels at the level they would be in an individual where they're not

277
00:42:41,610 --> 00:42:48,170
smoking but have these folks and not smoke comparing what would happen to smoke and not smoking.

278
00:42:49,080 --> 00:42:58,170
So there's some sort of like magical thing in there maybe that somehow blocks their of formaldehyde levels from increasing.

279
00:42:58,680 --> 00:43:03,780
This is all very this is all conceptual here. So if you would sort of keep those formaldehyde levels constant,

280
00:43:04,380 --> 00:43:11,370
what's the what's the what's going to have effect on the outcome of of of the on the treatment side?

281
00:43:11,970 --> 00:43:17,010
So it's the direct effect idea, right? Because you're holding the mediator constant, right?

282
00:43:17,550 --> 00:43:21,030
So but you're holding it constant at the level. Would it be under control.

283
00:43:22,860 --> 00:43:30,450
So whatever, whatever sort of individual level they would have them.

284
00:43:30,960 --> 00:43:35,250
So it's rather than holding it at a fixed value would potentially allow it to vary.

285
00:43:35,490 --> 00:43:43,140
But at that B across, let's say across individuals but at the level individual would had had, they'd be under a control.

286
00:43:46,490 --> 00:43:50,570
So it was in individuals held at that level. They vary across individuals.

287
00:43:52,550 --> 00:44:19,180
So what about the natural indirect effect? See if we're looking at the different formaldehyde levels, for example, under the treatment.

288
00:44:20,650 --> 00:44:29,290
Yes, exactly right. So basically, what would happen to an individual if they kept them in treatments or kept under smoking, let's say?

289
00:44:30,610 --> 00:44:36,850
But we were able to take the formaldehyde levels from what they would be normally under smoking to what they would have been had they not smoked.

290
00:44:39,080 --> 00:44:46,760
Right. So that's the idea of the mediation. Right. But change changing here is the formaldehyde level, not the smoking behavior.

291
00:44:47,690 --> 00:44:54,890
What's changing here? And here are the smoking behaviors, not the formaldehyde level.

292
00:44:56,180 --> 00:45:08,060
Keep it, for example. Theoretically, how would you know what the main factors are?

293
00:45:08,760 --> 00:45:15,780
That's where the assumptions come in. And this is this is maybe the one of the most important things is that sort of this work that

294
00:45:15,780 --> 00:45:21,780
Vandewalle and Robyn's and a lot of these these folks did was to take the Bear and Kenny idea and say,

295
00:45:21,780 --> 00:45:28,319
look, you're making a lot of critical assumptions here. So in order for this to be treated as a real cod,

296
00:45:28,320 --> 00:45:33,930
as a real kind of in the sort of the way that we want to define causality, and this is what they are.

297
00:45:35,130 --> 00:45:42,090
And I guess just to do a spoiler alert, we're going to condition on a lot of stuff to try and make it a little more reasonable and

298
00:45:42,090 --> 00:45:46,650
then average out over those over those Xs to get these sort of more marginal effects.

299
00:45:48,480 --> 00:45:51,780
So. Right.

300
00:45:55,540 --> 00:46:01,639
And he's going to let that sit here for a second. Because this is super important.

301
00:46:01,640 --> 00:46:05,480
We're going to be talking about these for the next couple of weeks and even after that.

302
00:46:11,730 --> 00:46:24,310
That was a really good question. Whether other. Okay sort point to is it's, you know, it's good just to sort of dig into this a little bit.

303
00:46:25,510 --> 00:46:38,770
All right. So as you we're sort of it would seem that in order to identify these direct and indirect effects, we have to make some assumptions.

304
00:46:39,520 --> 00:46:42,820
So the control direct effect is.

305
00:46:45,470 --> 00:46:50,780
Maybe a little fewer assumptions, in part because we're kind of fixing him here.

306
00:46:51,470 --> 00:46:56,450
Coming in basically assumes that this outcome exposure relationship's on confounded.

307
00:46:57,410 --> 00:47:00,440
Right. So when you think about this sort of expanded potential outcome,

308
00:47:00,440 --> 00:47:08,420
which depends both on A and possibly said independently that it's completely independent of the exposure or treatment

309
00:47:11,000 --> 00:47:19,040
and furthermore within within a an exposure treatment group that this potential outcome is independent of the mediator.

310
00:47:21,250 --> 00:47:30,290
So so if we have a clinical trial, we can make this assumption pretty easily.

311
00:47:31,130 --> 00:47:38,600
But even in a clinical trial, this assumption is not guaranteed. So typically we end up having a conditional covariance.

312
00:47:39,500 --> 00:47:44,690
And if we have an observed situation like we're observing our assignment, then we have to do it from the first part as well.

313
00:47:46,040 --> 00:47:51,080
So and even this, of course, may be heroic in some cases, but hopefully it's sort of better than if we don't.

314
00:47:52,100 --> 00:47:57,110
They're met more closely than if we don't we don't condition. So.

315
00:47:59,550 --> 00:48:12,410
Okay. So if we define these traditional covariates, right?

316
00:48:12,500 --> 00:48:21,650
So this traditional direct effect is this difference in expectations holding sort of covariance at a constant value.

317
00:48:23,300 --> 00:48:30,890
Then we can use the observed sample means or predictive values in a regression to compute these controlled direct effects.

318
00:48:32,420 --> 00:48:40,610
So in particular, we can go from our potential outcomes to our observed outcomes where we're just

319
00:48:40,610 --> 00:48:51,740
conditioned on our observed treatment and are there of control groups holding M constant.

320
00:48:53,480 --> 00:48:58,660
So a famous categorical you might look at this is actually just observe means otherwise you might have some kind of regression estimator.

321
00:49:02,160 --> 00:49:07,040
So how does this work? Right.

322
00:49:07,060 --> 00:49:09,629
So the first part is right. It tastes linear.

323
00:49:09,630 --> 00:49:14,790
So we can just reiterate this difference and the expectation differences, the difference of the expectations.

324
00:49:16,170 --> 00:49:26,880
So then for the second part, we're assuming conditional and X that we can use that as independent of X,

325
00:49:27,720 --> 00:49:31,230
so both unconditionally conditional expectations of each other.

326
00:49:32,730 --> 00:49:45,480
And once we've made that leap, then if we have mediator outcome conditional on exposure independence, then we can drop the amount, right?

327
00:49:46,560 --> 00:49:53,670
Things are independent. Whether you conditional on them or not has no effect on the expected value.

328
00:49:57,450 --> 00:50:09,060
And then the last line is just consistency, which is kind of equivalent to suit fur, but more in this direct and indirect effect setting.

329
00:50:11,550 --> 00:50:25,590
So basically says what you've observed when for the potential outcomes at a given level of A&M corresponds to to that I'm sorry,

330
00:50:25,590 --> 00:50:30,000
which you've observed at a given millennium corresponds to potential outcomes at that level of A&M.

331
00:50:42,910 --> 00:50:49,210
So pretty straightforward, right? You know, these these two assumptions here.

332
00:50:52,490 --> 00:50:59,650
And they come into play. Which appeared to hear.

333
00:51:06,530 --> 00:51:11,690
Okay. So you can see, right, we were a regression model for this regression model for this,

334
00:51:12,710 --> 00:51:19,070
that taking the difference will allow us to get at this this control direct effect.

335
00:51:22,840 --> 00:51:29,800
So the natural direct national indirect effects can be identified from the survey in under a couple of additional assumptions.

336
00:51:32,190 --> 00:51:34,800
It is perhaps a little harder sometimes to conceptualize.

337
00:51:37,830 --> 00:51:42,120
The first is there's no measured in measure confounding of exposure, mediate or relationship.

338
00:51:43,170 --> 00:51:50,960
So basically means that. Again in a randomized assignment kind of makes sense.

339
00:51:51,890 --> 00:51:58,790
But just like we had the potential outcomes for the we're just defining visual outcomes for treatment control for the outcome.

340
00:51:59,930 --> 00:52:05,720
We're independent of a randomization so the mediators can be quite everything's independent

341
00:52:07,130 --> 00:52:14,840
and then suddenly there's sort of no confounder between M and Y that's affected by exposure,

342
00:52:16,010 --> 00:52:26,419
right? So that essentially this potential outcome for for Y is going to be independent of the mediator at a different value of the,

343
00:52:26,420 --> 00:52:32,060
of the of the treatment than the potential outcome under the potential.

344
00:52:34,920 --> 00:52:40,740
Okay. So again, typically have a conditional covariance here.

345
00:52:46,820 --> 00:52:51,350
So under those four assumptions, now we can estimate these natural, direct and indirect effects.

346
00:52:54,230 --> 00:53:05,090
So. So essentially we can go from our difference of potential outcomes to a difference in

347
00:53:06,710 --> 00:53:17,000
observed values averaged over the distribution of the media at the control value.

348
00:53:18,590 --> 00:53:25,880
And then down here, we sort of look at the for the direct it for the indirect effect.

349
00:53:26,690 --> 00:53:40,220
We consider the expectation at a given level of AM, but now averaged over the effect of the treatment on the mediator value itself.

350
00:53:41,000 --> 00:53:44,940
Again, always conditional x. So.

351
00:53:47,510 --> 00:53:55,760
So how does this work? Well, it's sort of just an extended version of what we did before and a little different direction.

352
00:53:55,800 --> 00:54:03,950
We, first of all, start off with sort of like total, total probability, right.

353
00:54:04,760 --> 00:54:14,270
That we can think of the marginal distribution of a may store as the conditional distribution at a

354
00:54:14,270 --> 00:54:23,990
given value of of m averaged over that that value of always of course conditional marks as well.

355
00:54:25,980 --> 00:54:40,250
So. So if we have the the two assumptions that we just made in the previous previous slide, we can jump from here down to here.

356
00:54:41,390 --> 00:54:45,380
Sense of it was a definitive May store.

357
00:54:46,070 --> 00:54:49,100
Then you can add or drop. So we're going to drop here.

358
00:54:50,240 --> 00:54:58,040
And if May is independent of a then we can add a here, whatever you want.

359
00:54:58,820 --> 00:55:05,180
So restart. So then the next two lines just come out of the previous thing.

360
00:55:05,660 --> 00:55:10,550
Right. We can just continue to condition on a and then when I'm given a.

361
00:55:14,880 --> 00:55:18,900
Right for this expectation here. We just bring that down through.

362
00:55:20,580 --> 00:55:27,989
So now we've set our expected value of potential outcomes at the observed values of A&M.

363
00:55:27,990 --> 00:55:34,530
So we can just replace those with the observed values of our outcome in kind of the same game here.

364
00:55:35,150 --> 00:55:40,230
Right. We're thinking about what's the value of the mediator at the control level.

365
00:55:41,310 --> 00:55:47,320
So that's it's going to be observed value here. So that gives us that part.

366
00:55:49,390 --> 00:55:53,530
So we get a similar derivation when we play, say, with a star.

367
00:55:55,480 --> 00:56:01,280
So then we look to do the difference. This this stays constant.

368
00:56:01,370 --> 00:56:05,000
Both of those pieces. Right.

369
00:56:07,880 --> 00:56:13,400
And so the difference is the expected value of Y, whether we consider it at a or a star.

370
00:56:13,760 --> 00:56:17,600
Give me a fixed media level. So.

371
00:56:19,470 --> 00:56:27,840
There are natural indirect effects in. It's exactly, exactly what we stated before.

372
00:56:29,820 --> 00:56:40,530
And and I can go through very similar derivations to get sort of may it y sub in a

373
00:56:40,530 --> 00:56:52,110
story when y a m of a so I end up essentially with the same pieces I did before,

374
00:56:53,520 --> 00:56:59,910
except now I'm replacing a star with a on this conditional part here.

375
00:57:01,410 --> 00:57:01,860
So.

376
00:57:09,940 --> 00:57:20,830
So again, I can consider the difference here as this expectation now weighted by the difference in the probabilities of being at some level little.

377
00:57:25,410 --> 00:57:36,440
Given treatment and control. Okay.

378
00:57:36,670 --> 00:57:44,440
So I'm going to try to link this back to the bear and Kenny analysis allowing for an interaction term here and covariance.

379
00:57:54,200 --> 00:57:57,710
So to a little bit of algebra here.

380
00:58:48,700 --> 00:58:54,920
So our definition. With back.

381
00:59:02,380 --> 00:59:08,330
So. We don't have a pier.

382
00:59:10,580 --> 00:59:16,840
Just. That sort of controlled direct effect.

383
00:59:19,020 --> 00:59:33,229
Was. So once we had converted this into observer data and I'm just using it I can write

384
00:59:33,230 --> 00:59:40,120
media equals a big difference in this field I'm just going to use it smaller is to.

385
00:59:41,460 --> 00:59:49,080
Condition is. So holding him the next concert.

386
00:59:50,670 --> 00:59:56,820
I'm sorry. Pulling down the next concert. Intimidating. Start to different specifications.

387
00:59:59,720 --> 01:00:08,180
So. All right.

388
01:00:08,180 --> 01:00:13,030
So what's this bearing under this linear model going to be?

389
01:00:21,080 --> 01:00:31,700
Read that author. It's a new part.

390
01:00:37,160 --> 01:00:43,660
This is.

391
01:00:52,040 --> 01:00:58,070
So I'm going to subtract off from I think the savings at least are.

392
01:01:12,300 --> 01:01:23,540
Right. So basically. And I'm left with.

393
01:01:25,910 --> 01:01:31,580
Either one. 83.

394
01:01:33,600 --> 01:01:40,410
And I'm saying that as a star, that's just a serious matter one.

395
01:01:55,410 --> 01:02:02,630
So the natural, direct effect. So basically.

396
01:02:08,690 --> 01:02:12,200
My weighted average conditioning.

397
01:02:12,200 --> 01:02:29,180
A little difference in treatments and then weighted by the probability.

398
01:02:36,270 --> 01:02:49,080
If you're actually out there, go to the media given the right control. All right.

399
01:02:49,110 --> 01:02:53,310
So kind of worked out this part up here right already.

400
01:02:56,050 --> 01:03:33,180
I described that as. I'm just quiet here so I can take this a little further.

401
01:03:33,270 --> 01:03:40,910
So I can write this as. Nine.

402
01:04:03,460 --> 01:04:32,050
No. But.

403
01:04:44,210 --> 01:04:58,930
This. Okay.

404
01:04:58,930 --> 01:05:05,710
So. It's essential to consider the fact that we bring that out.

405
01:05:08,300 --> 01:05:14,960
So some of this over and what's that going to be? I'm a dancer.

406
01:05:15,930 --> 01:05:24,310
One. Right. It's just, you know, it's the definition of probability.

407
01:05:25,070 --> 01:05:31,560
So. So this just becomes.

408
01:05:34,660 --> 01:05:42,280
One a star depending on impact that out.

409
01:05:44,750 --> 01:05:48,120
And so was this summation.

410
01:05:48,170 --> 01:05:54,080
30. It's expensive inflation rate getting.

411
01:06:15,120 --> 01:06:18,690
Right. So I can I can factor out.

412
01:06:21,700 --> 01:06:28,450
He was a star and then gave it to one that's been free.

413
01:06:30,100 --> 01:06:36,910
And now it's this expectation of him. See.

414
01:06:46,340 --> 01:06:51,470
She wrote that. Okay.

415
01:06:51,570 --> 01:07:02,850
So for a linear model here, I'm going to use Alpha one who's out for a start, and then after finishing the Covariance.

416
01:07:05,080 --> 01:07:21,790
This. If you start to see something else different, right?

417
01:07:21,790 --> 01:07:31,600
So as as if we don't have an interaction that is free of zero, then it's getting back to our old Barry Kennedy stuff.

418
01:07:32,740 --> 01:07:42,340
Right. So. Due to zero data one consequences store here.

419
01:07:42,500 --> 01:07:51,830
So whether you control or natural direct in fact in the absence of these interactions, then we have fairly simple.

420
01:07:52,070 --> 01:07:57,140
But in order to get this, we have all these other assumptions running around.

421
01:07:59,270 --> 01:08:06,530
So that's the I think the critical insight here is that in order to be able to use the prediction model,

422
01:08:06,530 --> 01:08:14,720
you're implicitly getting a bunch of assumptions about independence in this counterfactual settings if you want to find deviation and maybe just.

423
01:08:27,610 --> 01:08:31,890
So. For the thing.

424
01:08:31,920 --> 01:08:41,920
Name of the natural indirect effect. But.

425
01:09:13,450 --> 01:09:28,180
So that's probably why a treatment given amino acids and fixed values is the difference to the difference in the treatment and control effects of.

426
01:10:06,520 --> 01:10:14,389
It's. All right.

427
01:10:14,390 --> 01:10:20,550
So I can write this out as. Zero.

428
01:10:25,340 --> 01:10:29,370
It was. You want and.

429
01:11:11,890 --> 01:11:41,630
You're. Times. So the same kind of game we played down here, we're going to play down play over here.

430
01:11:41,900 --> 01:11:53,780
Right. So these are the zeros, but the one A's, they're all kind of going to zero because they're taking summations.

431
01:11:54,140 --> 01:11:58,990
You know, they're just over these quantities. Well, this is just going to go to one of the one.

432
01:12:00,420 --> 01:12:07,640
So sorry. What happened was that some of the equations would be up there.

433
01:12:20,180 --> 01:12:34,799
Right. So it's a square summation summing over all the events. All right.

434
01:12:34,800 --> 01:12:38,310
So that is it is zero times zero, right?

435
01:12:40,760 --> 01:12:45,170
They don't want a hero.

436
01:12:47,270 --> 01:13:01,880
Now for the better too. I have this expected value of m a x minus the expected value of them star x.

437
01:13:13,940 --> 01:13:39,820
And the same thing here. So again,

438
01:13:41,830 --> 01:13:49,360
some over and then in terms of any given impacts of the expected values and I think index the same thing and

439
01:13:49,390 --> 01:14:00,310
think about yeah you can experience these things add up to each of these at one so the difference is zero.

440
01:14:00,460 --> 01:14:24,990
So these go away. So.

441
01:14:40,230 --> 01:14:43,890
All right. So when you signed over here.

442
01:14:54,820 --> 01:15:09,790
All right. So this is a nine plus one, a2x minus two star.

443
01:15:13,440 --> 01:15:21,700
And so you're going to have left here cancelations instead out for one.

444
01:15:27,140 --> 01:15:34,900
So plugging that gap in up here. Get into.

445
01:15:36,260 --> 01:15:39,340
I for 1 a.m. I say star?

446
01:15:42,360 --> 01:15:45,940
Was. Three.

447
01:15:47,150 --> 01:15:51,290
A four way system.

448
01:15:54,710 --> 01:16:05,840
So again, without interaction, you can see the indirect effect here now boils down to the bear in any peace with it.

449
01:16:08,440 --> 01:16:16,820
At least we were defining this natural, indirect effect. Holding things constant.

450
01:16:20,700 --> 01:16:26,130
Holding the tribute concert and then flipping the meteor. Okay.

451
01:16:26,490 --> 01:16:30,270
Just to be clear. So essentially.

452
01:16:31,850 --> 01:16:36,840
I guess another way to think about this. Clear.

453
01:16:38,060 --> 01:16:43,130
All right. It's better to put some potential for action right here.

454
01:16:52,060 --> 01:17:01,940
Here. So again, very keen out of that idea.

455
01:17:02,070 --> 01:17:12,960
Just there's a lot of assumptions here, including the overarching social interaction between the media treatment and exposure and.

456
01:17:14,880 --> 01:17:18,270
The custom wanted to put the updated.

457
01:17:28,040 --> 01:17:33,770
Okay. So it's a very natural starting place.

458
01:17:34,970 --> 01:17:39,740
Questions. And so it's going to take a little while,

459
01:17:39,740 --> 01:17:48,110
I think in sort of a different way of thinking about this sort of added dimension to this idea that Central comes then and now.

460
01:17:48,110 --> 01:17:55,280
We've got a bunch of assumptions that try to lead us from the underlying counterfactual

461
01:17:55,280 --> 01:17:59,270
models we want to estimate to what we actually can estimate with observed data.

462
01:18:00,710 --> 01:18:13,610
And the next steps will be kind of move out of the linear model context a little bit, sort of binary versus versus linear, both mediator and outcome.

463
01:18:14,390 --> 01:18:19,160
And then at the sensitivity analysis. Right, we've made a lot of assumptions here that don't always hold.

464
01:18:19,160 --> 01:18:23,390
Exactly. Are there things we can do to test that or think out of the system?

465
01:18:24,110 --> 01:18:29,390
You know, we make certain assumptions about what maybe a failure, what's going to happen to our results.

466
01:18:30,800 --> 01:18:36,840
So and typically, how badly do they have to fail to kind of eliminate causal effects, for example?

467
01:18:38,270 --> 01:18:47,750
Okay. So I see you. I have we have this afternoon the updated homeworks due tonight and you get your new homework.

468
01:18:48,200 --> 01:18:52,220
So what's going on? Sorry. Busy time, dear.

