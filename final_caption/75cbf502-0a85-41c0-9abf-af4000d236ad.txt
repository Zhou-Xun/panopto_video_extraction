1
00:00:02,490 --> 00:00:12,600
Thank you for the reminder. All right. Back to it. So is there their relative to relative to all in-person learning?

2
00:00:12,810 --> 00:00:17,940
People in hybrid classrooms were reporting a little bit higher levels of loneliness was a significantly different.

3
00:00:21,110 --> 00:00:24,480
Yes. So this is our standard error and this is our T value.

4
00:00:24,490 --> 00:00:30,280
P value is our confidence interval. How about for people all online?

5
00:00:35,610 --> 00:00:38,639
We think his real life question, folks, this is a year to see.

6
00:00:38,640 --> 00:00:45,190
This day is year old. There's a bunch of college students, about 115,000 were people relative.

7
00:00:45,390 --> 00:00:48,630
Were people in online classes lonelier than people in offer in-person classes?

8
00:00:49,620 --> 00:00:53,249
Yeah. Tell me something, Deborah, for me. I mean, walking by the hallway.

9
00:00:53,250 --> 00:00:58,709
What would you tell? Grace.

10
00:00:58,710 --> 00:01:01,710
You know what I felt?

11
00:01:02,220 --> 00:01:07,800
I don't know. All right. Who can help? Is it to all in person?

12
00:01:07,950 --> 00:01:11,130
I like you wrote that song in person.

13
00:01:11,220 --> 00:01:15,420
Mm hmm. All of my students.

14
00:01:19,080 --> 00:01:22,990
Four point. Sure.

15
00:01:25,760 --> 00:01:29,530
I guess we're increased, but I guess they're among the best.

16
00:01:34,180 --> 00:01:44,350
Well, a unit change here we're talking about going from in-person to online is still about a point one change in our awareness.

17
00:01:44,350 --> 00:01:48,010
That'll come. Right. And also, what else are you saying here? And this is big.

18
00:01:48,040 --> 00:01:51,669
This is why I think this particular analysis that my colleague over at Boston University,

19
00:01:51,670 --> 00:01:57,370
she's an MPH program, just like many of you and Sharon's analysis.

20
00:01:59,140 --> 00:02:02,920
What's the what's the what's the only caveat for both of these statements?

21
00:02:02,920 --> 00:02:09,310
Yes, that's how we interpret the coefficient is significantly different. So I love that.

22
00:02:09,510 --> 00:02:14,590
I love that because I think that's what makes this particular analysis really, really powerful.

23
00:02:14,650 --> 00:02:20,500
Right. So even after we control for your level of warning and what kind of institution you go to and how old you are,

24
00:02:20,500 --> 00:02:26,889
how many years you've been in school, your demographic characteristics after all of that are our predictor variable.

25
00:02:26,890 --> 00:02:31,810
Here. The class format is explaining some variability and reporting loneliness.

26
00:02:32,320 --> 00:02:41,760
Yeah, right. This format. Is it fair to say that hybrid because it has a higher speed estimate and that it's also seen signal.

27
00:02:43,590 --> 00:02:52,810
Lower all. Is it fair to compare the two online versus hybrid or the different?

28
00:02:53,690 --> 00:02:57,350
Yes. Testing. See that? Would you?

29
00:02:59,270 --> 00:03:06,350
What if I think I'm an idiot? So there's your question whether we can compare like this to this.

30
00:03:06,440 --> 00:03:17,780
Yeah. A lot of folks think that what I'm going to do for us is standardize what is standardizing a regression model.

31
00:03:17,780 --> 00:03:24,079
Do I forget standard deviation style?

32
00:03:24,080 --> 00:03:27,290
I need a little bit more than that. I tell you to do it.

33
00:03:27,290 --> 00:03:30,740
You did it. You did it for the midterm, I bet. How come you did it? What did you do?

34
00:03:30,770 --> 00:03:35,460
What's going on behind the scenes? I mean, I want to compare them.

35
00:03:38,790 --> 00:03:44,350
I think the same scale. Yeah. So if it's if you're if you use the element of your standardizing regression equation,

36
00:03:44,590 --> 00:03:49,149
we are taking each one of these variables, every single one we're creating,

37
00:03:49,150 --> 00:03:56,050
we're calculating z-score for those variables, even if it is a factor variable, we're also taking the Oracle variable, creating a Z score.

38
00:03:56,170 --> 00:04:01,540
We're plugging in all of those standardized variables into the analysis outcome, all the predictors.

39
00:04:01,810 --> 00:04:08,049
And based on that, we can then make a little bit more of a direct comparison between some of these coefficients, your, your question,

40
00:04:08,050 --> 00:04:11,950
our size and maybe just a teeny bit different because we don't have to worry quite

41
00:04:11,950 --> 00:04:17,380
so much about the the scaling of these two values because they're the same.

42
00:04:17,590 --> 00:04:20,860
It would be more of a concern with something like age, which we all remember now.

43
00:04:20,860 --> 00:04:24,159
We multiply by anything from 18 to we have a go learning.

44
00:04:24,160 --> 00:04:27,490
So that could be 40, right. And that's what's going to be multiplied by here.

45
00:04:27,760 --> 00:04:36,010
Those are some of the things that we have to worry about. Yeah. Um, now, just looking at this, what are we running here?

46
00:04:42,160 --> 00:04:45,520
Multivariate regression, linear regression. Right. Here's the trick.

47
00:04:46,300 --> 00:04:51,970
Now, I'm going to ask you to interpret this. This is actually we took that one win this outcome, and we set a standard threshold.

48
00:04:52,150 --> 00:04:56,350
We dichotomous it zero one. What's changed now about your interpretation?

49
00:04:59,300 --> 00:05:05,300
No, I don't use that word. The six value it is now either a01 or if you're above like a three, I think.

50
00:05:06,560 --> 00:05:09,480
Since 1984. We have probably.

51
00:05:11,570 --> 00:05:21,050
There's a probability and probability of saying, yes, you're lonely or not where we were earlier, but from Think of the Sun.

52
00:05:21,410 --> 00:05:24,560
No. Zero one. Oh, I'm sorry.

53
00:05:24,570 --> 00:05:28,730
That's just a profession. Yeah, this is a logistic regression output, actually.

54
00:05:29,120 --> 00:05:32,300
So these are. What are these?

55
00:05:35,580 --> 00:05:41,540
They're not original units either. And they are as well.

56
00:05:41,580 --> 00:05:47,840
Not for a lot of reasons. There are no kids running around yet again. What are the odds?

57
00:05:47,910 --> 00:05:55,860
Right. So that's actually what we're dealing with here now. You would never know what is the exact same gun that looks the exact same.

58
00:05:56,610 --> 00:05:59,639
Right. And we can interpret it the same way. We have negative values here.

59
00:05:59,640 --> 00:06:06,180
We have positive values here. It said the same exact way that we would think about this is a negative association, positive associations, etc.

60
00:06:06,510 --> 00:06:06,770
Right.

61
00:06:06,780 --> 00:06:16,560
So being very clear about the kinds of analysis that we're running, it's also a good check to make sure that when you have a dichotomous outcome,

62
00:06:16,710 --> 00:06:20,640
we are interpreting this like we would a logistic regression, right?

63
00:06:20,640 --> 00:06:23,600
So we're not going to use our own data here. Right?

64
00:06:23,680 --> 00:06:27,660
We're going to use we're going to exponentially each one of these coefficients to look at the odds ratios.

65
00:06:27,990 --> 00:06:31,080
That's how we're going to make some decisions about whether or not these things matter.

66
00:06:32,300 --> 00:06:40,209
We'll know that when our confidence intervals are are exponential and we're not looking to see whether or not they've contained the value zero.

67
00:06:40,210 --> 00:06:44,640
We're going to see that they contain the value one way, right?

68
00:06:45,030 --> 00:06:50,670
So small things that when we move into the general in your model space, we want to be mindful of.

69
00:06:50,940 --> 00:06:54,630
I think this analysis is kind of fun to say. It maps on to our prediction.

70
00:06:55,170 --> 00:07:01,260
We did run another analysis that looks at the interaction between belonging and in class format,

71
00:07:01,470 --> 00:07:06,680
and what we find is that belonging makes the difference or the yeah,

72
00:07:06,750 --> 00:07:15,239
I guess the difference between online and in-person classroom, it mitigates that effect on moments.

73
00:07:15,240 --> 00:07:19,100
So all of a sudden, if you have a lot of belongingness in your life, this is not right.

74
00:07:19,110 --> 00:07:23,849
I mean, this is probably not allowing anybody but with a lot of belongingness in your life, right?

75
00:07:23,850 --> 00:07:27,750
So really feeling like you are part of the institution. You have people who care about you.

76
00:07:28,380 --> 00:07:33,180
Being online relative to being in person isn't quite such a big deal.

77
00:07:33,210 --> 00:07:37,230
It's it mitigate some of that effect, I'm sorry to tell you.

78
00:07:37,310 --> 00:07:43,650
It's just I guess I question what skills that you use to measure belonging.

79
00:07:44,160 --> 00:07:47,760
One is I think it's like a three item measure.

80
00:07:48,450 --> 00:07:55,980
Um. Ooh.

81
00:07:56,060 --> 00:07:59,840
International. There it is.

82
00:08:04,010 --> 00:08:10,450
Four items arrested. Now, here's what's fun about this.

83
00:08:11,230 --> 00:08:14,500
Everybody put this this nice blogging skill.

84
00:08:14,560 --> 00:08:19,240
You feel okay with it? It's got a citation and everything. This is just my colleague.

85
00:08:19,840 --> 00:08:23,649
She wrote this paper three years ago. They took one of those items from one scale.

86
00:08:23,650 --> 00:08:27,370
They took the other three from a different scale and created this new belonging measure.

87
00:08:28,210 --> 00:08:32,950
So what we do? We check the reliability. She ran a factor analysis.

88
00:08:34,420 --> 00:08:38,760
It is unit dimensional. It does seem to function well, at least to back in 2018.

89
00:08:38,770 --> 00:08:47,380
So we'll do it again for this for the sample as well. But this, you know, there's not 15, 20 years of evidence to support the scale.

90
00:08:47,980 --> 00:08:52,710
No. Your job would be to take a look at this. And on a face, you know, your face validity here.

91
00:08:52,720 --> 00:08:57,220
Does this seem like we're talking about belonging or here? Are you picking up something different?

92
00:08:57,550 --> 00:09:02,379
Would you critique this particular. I'm not saying do it now, but those are some of the questions.

93
00:09:02,380 --> 00:09:07,000
If you're bringing that kind of curiosity, if you're bringing that critical eye that you could ask about,

94
00:09:07,360 --> 00:09:18,220
even analysis know that's coming from a published article from a large, say, a large dataset that's been around for a long time or a large study.

95
00:09:18,850 --> 00:09:28,750
But that's what we did. Did you start out with like more variables in the scale and then kind of it down to dozens of stuff?

96
00:09:30,490 --> 00:09:34,540
I'd have to ask her about the genesis. It was so there there were two.

97
00:09:34,870 --> 00:09:40,480
One was based on connectedness and one was, I think, literally titled either belonging or something like that.

98
00:09:41,380 --> 00:09:48,580
And then from there, I think part of it was the connectedness item that she wanted to bring in to make that four items.

99
00:09:49,510 --> 00:09:56,499
And I forget exactly why you can look at the citation and kind of dig through their decision around that creation.

100
00:09:56,500 --> 00:10:02,620
But that was the first time that those four items had been paired together, and they did a little bit more of the psychometric work.

101
00:10:02,890 --> 00:10:08,290
I'm cheating because this is a brief report just saying, hey, look, they did this and it's kind of fair.

102
00:10:08,290 --> 00:10:13,059
It's kind of not you would be well within reason to say, well, Justin's just because they did it once.

103
00:10:13,060 --> 00:10:17,500
And what data there was similar to yours collected three years ago? Does that mean that it works here too?

104
00:10:17,770 --> 00:10:23,350
So I would fully expect that somebody would say, Well, what's your reliability once you run that alpha for me real quick, it takes 2 seconds.

105
00:10:24,130 --> 00:10:35,610
Know, I say that I'll do that. Other questions.

106
00:10:36,840 --> 00:10:41,910
Who's this? The fun stuff for what we do where they are.

107
00:10:43,110 --> 00:10:53,130
So just because folks sometimes seem interested in kind of how I approach this stuff, I finalize all my analysis before we start writing.

108
00:10:53,610 --> 00:10:57,360
The reason being, if you start writing, even the theory part, all that kind of stuff,

109
00:10:58,080 --> 00:11:01,490
and then your analysis shift, your variables shift, all that kind of stuff,

110
00:11:01,500 --> 00:11:05,700
you're going back and it's really hard to edit parts of your writing,

111
00:11:06,420 --> 00:11:11,459
whereas to kind of start from a clean slate when you already know where you're going to end up, it's a little different in theory.

112
00:11:11,460 --> 00:11:14,520
You probably should write all the intro first nature hypotheses, blah, blah, blah, blah.

113
00:11:14,730 --> 00:11:18,900
But I have my question again. The analysis we find,

114
00:11:18,900 --> 00:11:23,459
where we find the analysis that we're comfortable with and we go backwards and

115
00:11:23,460 --> 00:11:28,140
then we can kind of write up the methods and the results and archive stuff. This is the interaction table.

116
00:11:28,380 --> 00:11:37,200
It's a little trickier because we do have that categorical variable that's not in the conditional manifests, but there's the interaction term.

117
00:11:37,920 --> 00:11:44,310
So you've got to think a little bit harder about what these mean when we have multiple levels, right?

118
00:11:44,610 --> 00:11:50,280
So that's the significant interaction for the online relative to the in-person stuff.

119
00:11:52,020 --> 00:11:59,909
I don't need you to know this right off the cuff here, but I want you not to be intimidated by it so that you can look at it again and say,

120
00:11:59,910 --> 00:12:06,090
All right, this does kind of map on to what I'm expecting. I by the approach that you've used here,

121
00:12:06,330 --> 00:12:14,580
I think that the way that you've interpreted this interaction term makes sense to me because it does happen where people will make mistakes.

122
00:12:14,610 --> 00:12:17,880
Either they weren't trained properly, they make a mistake or whatever.

123
00:12:18,120 --> 00:12:23,609
And we want to be mindful of helping to get the right messages and science out there,

124
00:12:23,610 --> 00:12:28,500
especially if I'm going to recommend to my 150 participating schools and colleges.

125
00:12:28,770 --> 00:12:31,770
You ought to be careful about your online courses. Right?

126
00:12:31,770 --> 00:12:33,599
This school still has a lot of online courses.

127
00:12:33,600 --> 00:12:38,880
Should I go to the boys and say, hey, you really want to consider what this might be doing for the mental health of your spouse,

128
00:12:39,080 --> 00:12:43,260
your student population, or in this case,

129
00:12:43,260 --> 00:12:48,360
this has a clear intervention potential, if you can say, all right, if you're going to do the online stuff,

130
00:12:48,570 --> 00:12:53,230
make sure for our online program that you have some sort of connectedness part of what you're doing.

131
00:12:53,610 --> 00:12:58,139
Do the little socials that nobody wants to go to, but you kind of do. And it's kind of fun when you go, right?

132
00:12:58,140 --> 00:13:01,620
What are some of those ways that you can make people feel like they're part of community?

133
00:13:01,890 --> 00:13:07,020
And yeah, again, maybe not earth shattering, but now it's data informed and so that's what we do.

134
00:13:07,140 --> 00:13:14,760
Anyways, I just want you to look at the, the, the, the coefficients here see in real life and I think this might be state output.

135
00:13:17,300 --> 00:13:24,230
I can't remember. She did this in our number, we go back and forth. But even if it is state output, it's the same information.

136
00:13:24,590 --> 00:13:28,630
I'm missing some of the values and missing the R squares.

137
00:13:28,820 --> 00:13:34,490
And that's another one that if you start to look and you're like, when the words are square, what does this what what exactly are you explaining?

138
00:13:34,760 --> 00:13:37,850
Does this really matter in weeks? Maybe like 2% of the variability in loneliness?

139
00:13:38,090 --> 00:13:43,670
And if that's the case, my little online statement kind of doesn't hold a lot of water, but it's like 40%.

140
00:13:43,880 --> 00:13:48,500
It's like, boom. Oh, yeah. It's good stuff. It's good stuff. We'll see if we can get out there.

141
00:13:49,370 --> 00:13:52,530
Oh, that's me. All right.

142
00:13:55,760 --> 00:13:59,540
Sure. Why do I run to all or in a step model modeling, logistic regression.

143
00:13:59,660 --> 00:14:04,940
This is so easy to generate a come what it is it for me?

144
00:14:10,760 --> 00:14:17,270
Recall, the question is sex initiation rate by age or over 1415?

145
00:14:17,810 --> 00:14:19,490
Where to use a whole bunch of variables to predict it?

146
00:14:19,490 --> 00:14:25,870
But before we use a lot of variables, we're running this baseline model because it's the worst possible.

147
00:14:26,360 --> 00:14:29,360
Yeah, this is our our worst guess, right?

148
00:14:29,360 --> 00:14:33,769
We're just going to assume if it's over 50% probability, everybody's initiated.

149
00:14:33,770 --> 00:14:40,670
If it's under 50% probability, the proportion of people who actually stay in the sample, it's we're going to say everybody, nobody in this year.

150
00:14:41,000 --> 00:14:48,410
Right. That's our worst possible. We're just going to take the proportion, the literal proportion of people who said yes or no to this item.

151
00:14:48,680 --> 00:14:54,830
If I use my my loneliness example, I take the number of people who are lonely and divided by the total number of people.

152
00:14:55,250 --> 00:14:59,899
If that's over 50%, I say everybody, well, if it's less than 50%, I say nobody.

153
00:14:59,900 --> 00:15:03,230
Well, that is a terrible way to guess or to predict.

154
00:15:03,740 --> 00:15:09,170
Right. But it gives us an idea of what the absolute worst way we could predict.

155
00:15:10,220 --> 00:15:15,920
And then anything else that we do on top of this is going to be compared to this baseline that kind of gives us

156
00:15:15,920 --> 00:15:22,330
the logic of our model explaining additional variability because the our square thing is not going to be true.

157
00:15:22,640 --> 00:15:31,850
It's not going to be as straightforward in logistic regression and for some regression, all that kind of stuff, we lose that comfortable.

158
00:15:32,030 --> 00:15:37,100
This is the proportion of a variability explained statistic that we've had all semester long.

159
00:15:37,610 --> 00:15:42,290
All right. And this is just showing you how we could take that very baseline estimate.

160
00:15:42,470 --> 00:15:47,630
It starts as a logit. We can work backwards to a probability because that's all we're really talking about here.

161
00:15:48,410 --> 00:15:52,880
And the probability in this case was about 0.62.

162
00:15:53,210 --> 00:15:56,330
So about 62% of the folks had initiated.

163
00:15:56,570 --> 00:16:01,340
And lo and behold, that's just a proportion of the sample. Okay, that's all this is going.

164
00:16:02,480 --> 00:16:06,320
So run this model. I think it's so it's always kind of helpful as a starting place.

165
00:16:06,680 --> 00:16:10,879
It kind of helps to make sure that your data are are what you're expecting.

166
00:16:10,880 --> 00:16:15,110
So we have 850 people in our sample, but only 820 in this analysis.

167
00:16:15,470 --> 00:16:18,530
So we can find that information somewhere.

168
00:16:18,530 --> 00:16:23,010
Whereas in. There. Sure.

169
00:16:23,670 --> 00:16:26,790
Why is it 819? Oh, this is what I mean now.

170
00:16:33,070 --> 00:16:37,190
Give me a hint. 320 people of missing data from 30 people.

171
00:16:37,190 --> 00:16:43,809
But how come this is an 820? You do lose a degree for him.

172
00:16:43,810 --> 00:16:47,780
But how come? Now?

173
00:16:50,150 --> 00:16:57,710
In some ways, yeah. It's because you estimate something, you're estimating a parameter more of these you have,

174
00:16:57,920 --> 00:17:06,739
the more of these you lose all that doesn't matter so much when you're in 20, but it does matter when you have 110 or 60 or whatever.

175
00:17:06,740 --> 00:17:15,950
Folks are often the older. All right. And we should take a look at this model mostly review here, but logics, how do we interpret logics?

176
00:17:15,950 --> 00:17:22,640
What is a negative logic versus the positive logic? Yes, you do.

177
00:17:22,850 --> 00:17:26,030
Oh, I don't know.

178
00:17:26,090 --> 00:17:31,430
Do we think this is a positive association or a negative association in itself?

179
00:17:31,440 --> 00:17:36,769
I it just like your linear regression coefficients. No difference when we're in that logic framework.

180
00:17:36,770 --> 00:17:44,299
That's what's nice about and one of the reasons why you often see this data presented this way, anything that's positive is a positive association.

181
00:17:44,300 --> 00:17:51,650
Anything that's negative is a negative association. Where it starts to change is when we take when we start to look at those odds ratios.

182
00:17:52,350 --> 00:17:56,179
All right. So we can interpret these in many of the same ways, except for now,

183
00:17:56,180 --> 00:18:10,010
a unit change in age is associated with about a 0.62 predicted change and the probable or the log of the odds of sex initiation.

184
00:18:10,250 --> 00:18:17,600
That's that's the bad part about loads for this kind of output because nobody wants to say a unit change in the log or the odds.

185
00:18:17,600 --> 00:18:21,200
Right. Or a 0.6 to 5 change in the long the odds.

186
00:18:21,200 --> 00:18:25,160
It just doesn't it doesn't have a lot of interpretability for your average person,

187
00:18:26,180 --> 00:18:36,680
but older students more likely to initiate sex that does have a pretty interpretable and that's that is a pretty accessible statement.

188
00:18:42,380 --> 00:18:47,870
I mean, I was more or less likely to initiate sex in the sample relative to females.

189
00:18:48,920 --> 00:18:52,090
Females are a. How do you know?

190
00:19:01,190 --> 00:19:08,510
Somebody said, How do you know? Because they asked me. Yeah, it's about questions.

191
00:19:10,400 --> 00:19:19,280
Yeah, I'm just curious. You're saying that because females direct from female to male, you're giving your life.

192
00:19:19,370 --> 00:19:24,620
What are the odds are increasing so the probability is higher that you're going to say yes to that particular question.

193
00:19:25,430 --> 00:19:28,520
It's never a guarantee. Right. This is still a prediction model.

194
00:19:28,730 --> 00:19:32,809
We're trying to figure out for each person, they plug in their values. They tell you what their sex is.

195
00:19:32,810 --> 00:19:34,670
They tell you what the race is. They tell you how there are.

196
00:19:35,030 --> 00:19:45,080
We put that into our regression equation and we try to predict whether or not they they are likely to initiate sex by age 1450, whatever can.

197
00:19:45,860 --> 00:19:50,060
Right. It's a prediction model. Then we're going to compare that to what they actually said.

198
00:19:51,230 --> 00:19:55,220
That's what our model is trying to do. This is still regression.

199
00:19:55,400 --> 00:19:59,750
This is still taking a sample and trying to extrapolate to a population.

200
00:20:00,530 --> 00:20:03,860
We think that if this model fits the data well,

201
00:20:04,040 --> 00:20:11,330
I can ask anybody who more or less fits that sample plug their values in here and get a good indication of whether or not they've initiated sex.

202
00:20:12,080 --> 00:20:15,050
That's what this is all about. So it's not that different.

203
00:20:15,320 --> 00:20:22,100
It's just the jargon becomes a little bit different than if they were just well aware when we were in the general minimum program.

204
00:20:22,520 --> 00:20:32,040
Anybody remember why we have to do this? You know, I meant to do that.

205
00:20:41,160 --> 00:20:44,930
Row two here. There are three parts to the general linear model. What's the first part?

206
00:20:47,930 --> 00:20:54,170
Or the second or third part. I was going to say that the outcome variable is yes or no.

207
00:20:54,380 --> 00:20:57,470
Yes. The sampling distribution of or outcome variable. Absolutely.

208
00:20:57,470 --> 00:21:01,660
Which incidentally, is the answer that to your question. What's the second part now?

209
00:21:02,330 --> 00:21:09,950
What is the link to that is how we are able to change it.

210
00:21:12,440 --> 00:21:16,400
Something that we do it. It's not good.

211
00:21:17,900 --> 00:21:24,230
Yeah, there is. There is. Yeah, we take that we're variable, it's got two levels and we're using a wave function to work.

212
00:21:29,330 --> 00:21:40,010
We're transforming that variable into so into a new variable that has a range of values that will fit our third part structural model,

213
00:21:40,010 --> 00:21:45,410
which is where we relate our outcome variable to some combination of linear predictors.

214
00:21:46,520 --> 00:21:52,140
Those are the three parts of the general linear model, the sampling model, what is our outcome variable?

215
00:21:52,160 --> 00:21:55,630
And like second part is the length function we're going to take that sampling,

216
00:21:55,640 --> 00:22:00,140
that sample or that outcome variable look like something that we can plug into a linear regression.

217
00:22:00,440 --> 00:22:05,269
And the third part is actually that linear regression. It's this equation right here, right?

218
00:22:05,270 --> 00:22:07,610
What are the predictors that we think relate to our outcome variable?

219
00:22:07,850 --> 00:22:16,070
Katie This family is the r our opportunity to identify what kind of outcome variable we're dealing with.

220
00:22:16,400 --> 00:22:20,540
Binomial is what we can use when we have a two level outcome, a dichotomous outcome.

221
00:22:20,840 --> 00:22:27,530
And then there is a we're using the default here, but it's in that parentheses is where we specify that link function.

222
00:22:27,860 --> 00:22:32,870
How are we going to date a variable that only has two lobes and violates all those assumptions of linear

223
00:22:32,870 --> 00:22:38,030
regression that you know and love and turn it into something that we can plug into an equation like this.

224
00:22:38,870 --> 00:22:45,060
We use a logic link. It takes the the log of the odds and ends up getting us to something like this.

225
00:22:45,710 --> 00:22:51,380
So it's the structural model just the same as the regression model because.

226
00:22:51,380 --> 00:22:57,260
Yes. And just one more time.

227
00:22:57,830 --> 00:23:04,700
We are doing the same thing when we run a normal linear regression.

228
00:23:05,420 --> 00:23:13,880
The only difference here is that our our sampling or sampling model or similar sampling distribution is a normal distribution.

229
00:23:14,840 --> 00:23:19,790
Our link function is what's called an identity length because we don't change it.

230
00:23:20,240 --> 00:23:25,190
It's already where we needed to be. So we've been running GLM all semester.

231
00:23:25,550 --> 00:23:32,270
Just a very special case of the globe where alpha variable is normal and just normal.

232
00:23:32,270 --> 00:23:35,320
Distributing continuous. I like that.

233
00:23:35,740 --> 00:23:40,750
Yeah. So I don't know. Yes or no?

234
00:23:41,020 --> 00:23:47,980
Yeah. Yeah, because. Because this question is whether or not in my lifetime I've had sex or not.

235
00:23:49,000 --> 00:23:51,190
We can operationalize as a01.

236
00:23:51,640 --> 00:23:58,070
What's interesting is I showed you an example here where we took a variable that ranges from 1 to 6 and could be 1.51.25.

237
00:23:58,250 --> 00:24:02,260
It's a mean variable. I could have run that model as a linear regression model.

238
00:24:02,710 --> 00:24:09,280
I would have changed this to just a Gaussian or whatever they call basically normal right or just left alone,

239
00:24:09,290 --> 00:24:11,800
because the default is going to be let's run normal linear regression.

240
00:24:12,040 --> 00:24:19,690
I can run that equation with my predictor variables or I chose to take those six levels and create a cutoff score.

241
00:24:20,140 --> 00:24:29,020
What do you say if I'm saying I should or should not? I just did. Based on some degree with that cutoff score, I now have a01 variable.

242
00:24:29,230 --> 00:24:33,940
I think this is relevant in clinical, clinical, clinical context because often it's present, not present.

243
00:24:33,940 --> 00:24:37,389
That's more important than the degree of present ness. Right.

244
00:24:37,390 --> 00:24:47,920
So you can take variables that might have some level are are benign, are depression variable indicator and it ranges technically from 1 to 27,

245
00:24:48,220 --> 00:24:55,570
but we have thresholds at ten and 18 to indicate moderate versus severe levels of depression as a pseudo clinical measure.

246
00:24:55,930 --> 00:25:01,239
Right. So we can take scores depending on how we want to disseminate this information and think about the

247
00:25:01,240 --> 00:25:06,130
information and change and operationalize them in different ways to fit different kinds of models.

248
00:25:06,670 --> 00:25:12,220
I do this a lot with count variables because even though they range from in theory, zero to positive infinity,

249
00:25:12,640 --> 00:25:17,600
a lot of times I'm dealing with counts like number of firearm crimes within a given month.

250
00:25:18,100 --> 00:25:22,360
They're very, very small. So it's really did it happen in your block or did it not happen in your block?

251
00:25:22,630 --> 00:25:26,410
So that's more of a dichotomous question then how many times did it happen in your block?

252
00:25:26,680 --> 00:25:30,470
Because nobody really says more than two. I'm not going to.

253
00:25:36,580 --> 00:25:40,030
It's hardly anybody in my dress up for Halloween or for your holiday stuff.

254
00:25:40,230 --> 00:25:44,330
I still pick from it. I'm colorblind, but that's fine. Or what was you?

255
00:25:45,580 --> 00:25:48,910
I was Misty Long, one of the trainers. Okay.

256
00:25:49,430 --> 00:25:53,340
And my Pokémon were running around. Sure.

257
00:25:53,560 --> 00:26:00,730
Trying to trick. I was trying to catch the ball, and I was walking behind my daughter.

258
00:26:00,880 --> 00:26:03,070
And again, you do the Minecraft stuff.

259
00:26:05,580 --> 00:26:15,160
I of think it's all like boxes like Lego World, like Lego video game type of world and even all the store bought ones, which we kind of do.

260
00:26:16,000 --> 00:26:19,120
They're cool, they don't have frills and all that kind of stuff. I could never reproduce them.

261
00:26:19,300 --> 00:26:27,129
Sometimes it's those homemade ones that are just really cool. And this is Mom to kind of show me how she did it, which is like the whole box.

262
00:26:27,130 --> 00:26:29,950
So they have about a foot and a half taller than they normally would be.

263
00:26:29,950 --> 00:26:35,859
This is like ten and you just kind of walking around like a endearment, I guess is what it looked exactly like.

264
00:26:35,860 --> 00:26:38,870
The video game. I that was pretty cool. Yeah.

265
00:26:39,460 --> 00:26:57,040
Um. Question box. In theory when you're doing the coding and since we've been doing essentially geography but.

266
00:26:57,870 --> 00:27:04,109
All of us respect that. But can you run, Glenn?

267
00:27:04,110 --> 00:27:09,130
But just with like. You wouldn't have to do anything.

268
00:27:09,150 --> 00:27:14,430
Actually, I think so. The default you'd want to check there and the help menu.

269
00:27:14,670 --> 00:27:18,840
But if you didn't put this year, this would default to assuming that this is a continuous variable.

270
00:27:19,170 --> 00:27:21,620
Aloha. It's nice when we don't get that errors.

271
00:27:21,840 --> 00:27:26,850
You got to be careful because even though this is a01, if you didn't tell this was binomial is going to say,

272
00:27:26,850 --> 00:27:30,960
let me just go ahead and run a linear regression analysis and it's just going to assume that there was.

273
00:27:31,230 --> 00:27:34,260
This could have ranged from anywhere positive to negative infinity.

274
00:27:34,500 --> 00:27:39,810
And you just have a whole bunch of zero ones. And we've run the analysis that way, which would be a mistake.

275
00:27:40,200 --> 00:27:46,890
The coefficients would be wrong right there, but the violations would be there, the assumptions would be violated.

276
00:27:47,130 --> 00:27:53,070
So that has implications for the coefficients, the standard errors, and then certainly the associated tests.

277
00:27:53,700 --> 00:27:59,550
So you got to be a little bit mindful of that and you're looking for kind of the kind of output that you would expect.

278
00:28:01,350 --> 00:28:05,130
You run this model. Are you getting deviance? Are you getting R squared?

279
00:28:05,520 --> 00:28:10,020
There's an F test down here. It's a good indication that you did not run the appropriate model.

280
00:28:10,640 --> 00:28:14,190
Right. So be mindful of things as you're running his analysis.

281
00:28:14,670 --> 00:28:22,080
Ever go to the meetings as they were run? Shows the money.

282
00:28:22,740 --> 00:28:26,350
It is a handsome measure, but I'll take this.

283
00:28:26,700 --> 00:28:29,700
It's. So now we are dealing with Lord likelihood.

284
00:28:29,820 --> 00:28:33,360
Or the likelihood because we don't have a measure of our square.

285
00:28:34,200 --> 00:28:41,100
So the way that we can test models is to look at minus two times the the log of the likelihood.

286
00:28:41,340 --> 00:28:46,680
Likelihood is just kind of a fit indicate indicator and we can see how that changes from model to model.

287
00:28:47,010 --> 00:28:51,120
So it's going to be akin to our ANOVA test of nested models.

288
00:28:51,480 --> 00:28:52,320
That's how we're going to use it.

289
00:28:52,560 --> 00:28:59,880
And we have a likelihood and B instead of R squared, because with this kind of model, it's a different form of estimation.

290
00:29:00,300 --> 00:29:04,650
We're using kind of rote guessing rather than kind of a calculus solution.

291
00:29:06,390 --> 00:29:11,820
After we ran just that initial model logics we talked about, nobody really knows where Logit is, so why do it?

292
00:29:12,360 --> 00:29:21,030
Instead we can x exponential each one of those coefficients on the left hand side here to odds ratios, which changes our interpretation.

293
00:29:21,510 --> 00:29:29,910
Like something more like this. Still, more often than not, I'm talking about whether or not this is a positive or negative association.

294
00:29:30,270 --> 00:29:33,210
So even if you don't want to memorize language like this,

295
00:29:34,260 --> 00:29:39,780
to be able to say that older students were more likely to initiate, their male students were more likely to initiate.

296
00:29:40,020 --> 00:29:47,220
Chances are that's going to be just fine. Am I doing here?

297
00:29:50,330 --> 00:29:53,959
Oh, just confidence equals confidence intervals where the word,

298
00:29:53,960 --> 00:30:00,470
the magic value that we want to avoid should be to the right of or to the left of the right.

299
00:30:00,890 --> 00:30:07,010
That's 011. That's crazy. Wow. So we're looking for values that are that do not contain one.

300
00:30:07,250 --> 00:30:14,239
Don't be fooled by the little double zero here. I don't know why they need to have it redundant here, but this one means over one, right?

301
00:30:14,240 --> 00:30:19,760
So this one does contain the value one not significant of confidence intervals.

302
00:30:19,760 --> 00:30:24,160
Always nice because they give you a range of point estimates rather than just a single on the same story.

303
00:30:25,880 --> 00:30:31,580
All right. We did this last week, but we got this we got this value from that baseline.

304
00:30:31,580 --> 00:30:35,240
Worst possible guess for convenience. It's always right here.

305
00:30:36,170 --> 00:30:39,710
So no matter what we throw in here, no matter what we throw in in this equation,

306
00:30:40,040 --> 00:30:45,620
if we don't change the outcome variable, this will always stay the same, which is fine,

307
00:30:45,890 --> 00:30:52,610
except for eventually we're going to we're not going to be quite so interested in testing our new model relative to the baseline model,

308
00:30:52,970 --> 00:30:57,890
because if this model already fits better than this one and we start adding more variables,

309
00:30:58,370 --> 00:31:01,580
we don't need to test whether it still fits better than our worst guess.

310
00:31:01,880 --> 00:31:07,670
We're going to be interested in testing our alternative model to now a revised model or something like that.

311
00:31:08,000 --> 00:31:13,670
But anyhow, the nice thing about these deviant statistics is we can they're distributed as a chi square

312
00:31:13,670 --> 00:31:19,850
value so we can take the difference between our worst possible guess and our new model Y.

313
00:31:19,850 --> 00:31:27,860
We lose four degrees of freedom before we have for any coefficients, I hope.

314
00:31:29,690 --> 00:31:36,319
One, two, three, four. So four degrees of freedom.

315
00:31:36,320 --> 00:31:43,940
This is all contained within the output, conveniently enough. So if you forget which way this model goes, it's the big one minus the small one.

316
00:31:44,420 --> 00:31:49,790
This should never be a new model. Should never be high at the very, very worst.

317
00:31:49,790 --> 00:31:55,879
In the exact same. If it's higher somehow, then there was a mistake out of the sample change.

318
00:31:55,880 --> 00:32:00,980
Which can happen, right? You have fewer people because people won't respond to a question that you just added in the analysis.

319
00:32:01,250 --> 00:32:05,450
Something like that can make things up. But by and large, this will never be higher.

320
00:32:05,720 --> 00:32:11,510
This will never be higher. That's just where it is.

321
00:32:11,630 --> 00:32:17,840
QUESTION And I'm going fast. We talked a little bit about this on Thursday, but I think it's worth repeating here.

322
00:32:20,680 --> 00:32:23,730
You're going to have to do it this Thursday.

323
00:32:28,620 --> 00:32:31,830
Now, look, you've midterms done. We're in. We still got class left.

324
00:32:32,480 --> 00:32:41,420
Yeah, but I'm just trying to think for the moment, I'm saying this for you.

325
00:32:41,880 --> 00:32:57,420
I didn't think you were there. I heard you're so not the idea that we we will do a logistic regression kind of workshop ish on Thursday.

326
00:32:57,420 --> 00:33:00,690
And if folks want to play around maybe a different sort of model rather than logistic regression,

327
00:33:00,690 --> 00:33:04,680
you can do that to whatever you feel is maybe the most relevant to the stuff, the stuff that you want to do.

328
00:33:05,790 --> 00:33:12,570
So I don't know why, but I don't know of a super easy way to do just to run an allergy test.

329
00:33:12,780 --> 00:33:17,730
There should be one easy for me to say. Somebody should go one of these things because it's not.

330
00:33:18,570 --> 00:33:21,090
I wouldn't think it's all that problematic.

331
00:33:21,090 --> 00:33:26,760
Like you could have a function that would just give me your your model values and plug them in and you can kind of do this.

332
00:33:26,780 --> 00:33:33,060
But so within each model object, there is a variable called deviance.

333
00:33:34,290 --> 00:33:38,910
Right. It's kind of it's fit. Everyone will have the null deviance.

334
00:33:39,990 --> 00:33:46,140
Right. That's that ten 95.5. And then there's going to be the new one for your alternative model.

335
00:33:46,560 --> 00:33:53,010
Now that very first model, the null deviance and deviance, were the exact same in this second model.

336
00:33:53,160 --> 00:34:00,809
Model one we had the we we had have change the deviance we could have use m one is null deviance.

337
00:34:00,810 --> 00:34:04,830
But I don't know. I just. I guess either one would have worked.

338
00:34:06,060 --> 00:34:14,010
Same thing with degrees of freedom. It's always going to contain the null, which just means no predictors and the the alternative models one.

339
00:34:14,330 --> 00:34:17,760
Okay. So that's the only thing you really have to remember what I would suggest.

340
00:34:17,970 --> 00:34:27,390
Save this chunk of code and you're just substituting in, you know, one and two or well or zero and two and two and then three and three if you want.

341
00:34:27,390 --> 00:34:36,600
But the difference will be eventually we're going to be interested in having like one versus two and one versus two.

342
00:34:36,960 --> 00:34:39,480
So this is just that first test against the null.

343
00:34:39,870 --> 00:34:45,750
But we will we'll eventually want to be comparing nested models that already have additional predictors in there.

344
00:34:46,500 --> 00:34:55,740
We can use the chi square. I'm sorry, the chi square function which is just going to ask for what's the but chi squared difference here,

345
00:34:55,770 --> 00:35:00,989
which is going to be subtracted, taking the deviance from the deviance as well as the degrees of freedom for the degrees of freedom.

346
00:35:00,990 --> 00:35:07,110
So it's taking this value in this value, we're just having the computer calculate it for us.

347
00:35:07,110 --> 00:35:15,780
But we could have plugged those in directly if we wanted to. You could have put 74.5 and four in here and gotten the same kind of answer.

348
00:35:16,710 --> 00:35:21,060
And then when we just run these these objects, we're going to return.

349
00:35:21,390 --> 00:35:25,560
What's the difference? What's the difference? And then what is my chi square value?

350
00:35:26,370 --> 00:35:35,700
The null hypothesis is that the models were the same and that that change in deviance is not worth the change in degrees of freedom.

351
00:35:36,420 --> 00:35:43,500
So if this value is really, really small and this value is one or two, this will be not significant, right?

352
00:35:44,010 --> 00:35:47,730
The bigger this value, the better the fit of your alternative model.

353
00:35:47,970 --> 00:35:54,330
But one more time, the bigger this value, the better the fit have your alternative model.

354
00:35:55,650 --> 00:36:00,390
And that's always relative to the degrees or the cost of adding new variants.

355
00:36:01,980 --> 00:36:05,400
What does that mean? Which is one. Yeah,

356
00:36:05,760 --> 00:36:09,569
this is just the change in deviance or the difference in that evenness or

357
00:36:09,570 --> 00:36:15,510
differences in the minus two times the log likelihood difference in model faithful.

358
00:36:22,000 --> 00:36:30,170
Questions. Right.

359
00:36:30,680 --> 00:36:38,930
So now we are going to add one more variable. This will be the last example before I turn it over to you wanting to figure out, let's see here.

360
00:36:39,320 --> 00:36:44,860
My colleague Mark does a lot of work on resiliency and the idea is that there are positive things in the environment.

361
00:36:44,870 --> 00:36:47,240
In my there are a couple of different ways that he contextualizes it.

362
00:36:47,390 --> 00:36:51,770
But one is a compensatory model, basically, where you have positive and negative things in your environment.

363
00:36:52,010 --> 00:36:58,339
They kind of cancel each other out. So entering in a protective factor for a risk behavior.

364
00:36:58,340 --> 00:37:09,020
So we think of sex initiation as a risk behavior. Could we consider something that might counteract or of moving in the opposite direction, basically?

365
00:37:09,770 --> 00:37:14,360
So we're using involvement in organized activities, which is way of one.

366
00:37:14,360 --> 00:37:21,110
H one. We can just take a quick peek to see what this looks like ahead of the people responding.

367
00:37:21,560 --> 00:37:25,010
445 said yes. 375 said no.

368
00:37:25,190 --> 00:37:31,100
So about almost 3/5 of the sample are saying, yes, they're involved in these activities.

369
00:37:32,040 --> 00:37:37,010
This folks, this is a kind of as a contingency did more, frequency did more.

370
00:37:37,280 --> 00:37:41,890
This is a good idea to do when you're running any sort of discrete data analysis.

371
00:37:41,900 --> 00:37:45,860
So anything where you have zero ones or accountable outcomes or something like that,

372
00:37:46,130 --> 00:37:50,990
this is more or less your correlation table that you're trying to kind of think through.

373
00:37:51,350 --> 00:37:54,650
It's about as interpretable as a correlation table as well in the sense that,

374
00:37:55,010 --> 00:37:59,630
you know, you're trying to eyeball whether all of the people who say, yes.

375
00:38:00,310 --> 00:38:11,170
Know which one is which. It's. These must be or this must be initiation or this must be initiation.

376
00:38:11,170 --> 00:38:16,030
This must be organized activities. All right.

377
00:38:16,030 --> 00:38:20,890
So of the people who say, yes, I'm involved in organized activities,

378
00:38:21,250 --> 00:38:25,360
does that kind of proportion different, saying that they participate, initiated sex?

379
00:38:25,600 --> 00:38:28,750
Does that what difference does that to 75 to 170?

380
00:38:29,020 --> 00:38:33,280
What different than the 232 to 143. Hard to do in your head.

381
00:38:33,880 --> 00:38:38,140
It gives you a sense, though, perhaps, of kind of what the data are supposed to look like.

382
00:38:38,950 --> 00:38:42,790
So if you actually ran your analysis and you got something that was very different from this,

383
00:38:43,810 --> 00:38:48,580
might be just another way to kind of check what you're what you're saying. All right.

384
00:38:48,970 --> 00:38:56,500
So plug it in there. And if you didn't see major differences, make this as broad because it wasn't significant.

385
00:38:56,500 --> 00:39:00,760
But if you want to interpret this formulas, how would you interpret that?

386
00:39:09,170 --> 00:39:12,410
Relative to not participating in them in whatever activities.

387
00:39:20,590 --> 00:39:32,230
Relative to people who didn't participate in the activities. People who did had a negative light continue to lower.

388
00:39:33,430 --> 00:39:42,690
Lower. Every second injection that works.

389
00:39:43,230 --> 00:39:49,290
Very, very small, controlling for everything else involved. And this was not significant.

390
00:39:50,580 --> 00:39:53,940
So association in the expected direction.

391
00:39:54,120 --> 00:39:57,330
Yes. Um, but not significant.

392
00:40:02,930 --> 00:40:06,830
No, it's down here, right? It's still safe to say no.

393
00:40:07,550 --> 00:40:12,140
But now our deviants with a new variable, we should see one fewer degrees of freedom.

394
00:40:12,860 --> 00:40:16,639
Right? Because we are estimating in your parameter this value.

395
00:40:16,640 --> 00:40:21,890
Interestingly enough, it's probably not changing all that much relative to the second model.

396
00:40:21,890 --> 00:40:29,600
We were in model one. The reason being is that this is not explaining much variability and whether or not people are

397
00:40:29,600 --> 00:40:35,210
initiating sex right as a predictor is a little and it just doesn't have a lot of utility for us.

398
00:40:36,850 --> 00:40:41,900
Yeah, it still goes in the direction that we wanted it to, but it's not significant.

399
00:40:42,470 --> 00:40:44,630
It's kind of a question that had a limited to two.

400
00:40:44,960 --> 00:40:51,680
But you still say that there is some sort of a situation in some sort of relationship, but it's not like what people think.

401
00:40:52,460 --> 00:41:04,840
Important question. What would you say to the valid questions?

402
00:41:05,990 --> 00:41:09,050
Theoretically, it's moving in the right direction. Can we say anything about it?

403
00:41:11,420 --> 00:41:16,219
Her says, No way, because this stuff is statistically significant.

404
00:41:16,220 --> 00:41:21,320
So we know that, like there's a chance that that's actually true.

405
00:41:21,320 --> 00:41:26,560
The situation is low. That's kind of the rationale.

406
00:41:26,600 --> 00:41:31,790
And so people in Brazil. Right. Like, if the pivot is .06, they'll say it's trending.

407
00:41:32,150 --> 00:41:37,630
Right? Right. So, I mean, we we could we use these thresholds for a reason, right?

408
00:41:37,650 --> 00:41:40,969
We have ideas about what we would accept in terms of air.

409
00:41:40,970 --> 00:41:44,900
And what we want to do is not make a conclusion that we're rejecting or null hypothesis.

410
00:41:45,200 --> 00:41:49,489
And again, our null hypothesis was that there is no association between involvement in

411
00:41:49,490 --> 00:41:52,940
activities and our outcome variables controlling for everything else in the model.

412
00:41:53,900 --> 00:41:56,000
Our test is telling us that no,

413
00:41:56,000 --> 00:42:02,389
the overwhelming amount of evidence suggests that we should retain a null hypothesis and that any difference that this value

414
00:42:02,390 --> 00:42:10,070
is from zero is probably due to chance and not really because there is an underlying association between this variable,

415
00:42:10,730 --> 00:42:17,719
but this variable is just a cut off. Yes. No. So that could be predictions of participation beyond that aren't being explored.

416
00:42:17,720 --> 00:42:24,950
So if you've got a significant numbers, could you potentially look at participation at least once a week for sure?

417
00:42:25,670 --> 00:42:28,850
Yeah, if you get significance, then, yeah, absolutely.

418
00:42:28,850 --> 00:42:33,770
So and that's more of a measurement question. We chose to make this a dichotomous variable.

419
00:42:33,770 --> 00:42:37,849
I can't remember if it is actually the same thing in this in the data, but if we asked instead,

420
00:42:37,850 --> 00:42:42,620
how many hours of participation do you after school do you do in a week?

421
00:42:42,950 --> 00:42:51,410
And we saw that they range anywhere from 0 to 25. Maybe it's at levels of ten or higher that people will start to have some sort of protective effect.

422
00:42:51,710 --> 00:42:57,530
Right. That changes the question a little bit. I think the general gist of the question or the spirit of the question is the same.

423
00:42:57,770 --> 00:43:07,160
So you can think about doing something different that way. What I would suggest avoiding, though, is changing this variable a half dozen times,

424
00:43:07,430 --> 00:43:10,960
pointing in your analysis until you gets one that actually works out right.

425
00:43:10,970 --> 00:43:14,000
If it's only between I mean, unless you had fear, I mean,

426
00:43:14,000 --> 00:43:18,780
some reason why there should be a particular level which it sounds like you could maybe think about,

427
00:43:18,800 --> 00:43:21,860
like if it's really aged 10 hours a week, you have time for anything.

428
00:43:21,860 --> 00:43:25,219
I mean, it's something I don't know and that's why we think that matters.

429
00:43:25,220 --> 00:43:31,160
Or if there's a level of involvement that makes for better social relations, I don't know, whatever your theory is,

430
00:43:31,370 --> 00:43:35,210
and then you could justify it by just random changes or, you know,

431
00:43:35,240 --> 00:43:39,890
pseudo random changes to your the way that you're constructing the variable, not best practice.

432
00:43:44,750 --> 00:43:49,570
Just like before we can take a look at our coefficients, our odds ratios.

433
00:43:49,790 --> 00:43:58,310
We're not surprised that this variable that wasn't significant I this decimal place goes over it goes from point one or 2.7 all the way to 1.3.

434
00:43:58,580 --> 00:44:01,729
It contains the interval one. We reject that null hypothesis.

435
00:44:01,730 --> 00:44:06,170
Yes. So if it's above one, it's okay but it just doesn't.

436
00:44:06,320 --> 00:44:11,810
Yeah. What if I mean, what does it mean if it's above one? That's the association between the Creator and the outcome.

437
00:44:14,000 --> 00:44:18,830
You know. Then one of two things.

438
00:44:19,400 --> 00:44:24,560
Well, so let's see if you can generalize this. One is Anderson's message here.

439
00:44:25,160 --> 00:44:30,680
This was points. There's two common logics. We take the exponential nations 1.6.

440
00:44:31,620 --> 00:44:35,600
One is a positive log. Odds are a positive odds ratio, something over one.

441
00:44:37,350 --> 00:44:47,730
I arrived. I know it's something below on anything 0 to 2.99 and whatever is going to be a negative association, one is not.

442
00:44:54,120 --> 00:45:02,220
Aha. So here's what a changed notice now that I'm using the deviance, the null deviance for the deviance from model one,

443
00:45:02,610 --> 00:45:06,860
because that is the last model that we have, which is the demographic variables. And using the deviance.

444
00:45:06,870 --> 00:45:11,310
Now, from model to our newest model, we're doing the same thing with the degrees of freedom.

445
00:45:11,580 --> 00:45:16,440
We're plugging them literally back into the exact same equation. We get the same sort of output.

446
00:45:17,550 --> 00:45:23,160
This time there's not a significant difference between our Model one and model two.

447
00:45:23,520 --> 00:45:30,720
They fit the exact same. The addition of the predictor did not see it as substantively improve our model fit,

448
00:45:31,170 --> 00:45:38,070
which means we would probably defer back to or default back to our more our simpler model.

449
00:45:39,160 --> 00:45:46,979
Right. All things being equal, we want a simpler model that's just kind of standard practice in reality.

450
00:45:46,980 --> 00:45:52,500
If I were writing this up, I'd probably include my focal predictor and just have to acknowledge that it didn't

451
00:45:52,500 --> 00:45:56,220
really add any sort of prediction relative to model hedges demographic variables,

452
00:45:56,550 --> 00:45:59,850
because I want people to see this value that it didn't work.

453
00:46:00,300 --> 00:46:03,960
I'm now just going to go back and report the demographic model and say, I never read this model.

454
00:46:06,610 --> 00:46:13,170
Question. What's the first? Likelihood ratio test.

455
00:46:18,310 --> 00:46:22,540
But all this information is contained in here. Right. So you can get, you know, deviancy, deviance.

456
00:46:22,820 --> 00:46:28,690
This is kind of a model fit that we're we're building up towards. Right. We've worked from something that's very simple.

457
00:46:29,110 --> 00:46:32,889
Just a proportion basically is a predictor to something that's a lot more complex.

458
00:46:32,890 --> 00:46:36,370
We have demographic variables and we have our involvement variable.

459
00:46:36,370 --> 00:46:43,179
It didn't do us any good. And that's the way that we're kind of it's which is a little bit more stringent.

460
00:46:43,180 --> 00:46:45,390
I'd be curious if anybody's trying to do fall line.

461
00:46:45,640 --> 00:46:50,560
You know, if we just for any involvement variable by itself maybe that might be a better fit than normal.

462
00:46:51,250 --> 00:46:56,230
I don't know. We have to try and. All right.

463
00:46:57,670 --> 00:47:05,890
Of course. Any questions about this? He feel like he could do this ish, maybe with a little practice.

464
00:47:06,550 --> 00:47:12,670
Awesome. Lonzo we're going to, um, so some problems with logistic regression.

465
00:47:13,570 --> 00:47:18,190
We do have the same kind of assumptions that we dealt with earlier this semester,

466
00:47:18,820 --> 00:47:25,330
but I do want to call your attention to these two incomplete, separate, incomplete information and complete separation.

467
00:47:25,510 --> 00:47:31,390
What this is ultimately going to deal with is the statistical test, because their standard errors are going to be kind of all over the place.

468
00:47:31,880 --> 00:47:39,550
Um, incomplete suffer incomplete information. This is a tricky one because it's almost entirely to do with your sample size.

469
00:47:39,940 --> 00:47:46,720
So as you start to break down by different levels, if you're going to include those variables into your analysis, you can have empty cells.

470
00:47:47,110 --> 00:47:55,510
So that contingency table that I showed you that had both sex initiation and involvement, we had values in all four of those cells.

471
00:47:55,630 --> 00:48:05,620
Right now, imagine a multifaceted cell that had or a multidimensional set of contingency table or frequency table that had seven different variables,

472
00:48:05,860 --> 00:48:09,550
all of the different levels and all the different possible values.

473
00:48:09,940 --> 00:48:15,340
That's when you can run into work with problems from around and incomplete information.

474
00:48:15,670 --> 00:48:22,420
So if you didn't have any females in your sample and you tried to use that sex variable, then it's not going to work, right?

475
00:48:22,900 --> 00:48:27,460
Similarly, if you didn't have those specific combinations of people.

476
00:48:27,790 --> 00:48:31,060
So really what you're trying to find is just variability in your sample.

477
00:48:31,300 --> 00:48:34,450
This is not a big surprise. It's what we need for most of our analysis.

478
00:48:34,720 --> 00:48:40,030
But in logistic regression, you can occasionally get a model that just doesn't want it,

479
00:48:40,030 --> 00:48:43,299
can't estimate because there's just empty information and doesn't know how to

480
00:48:43,300 --> 00:48:47,020
deal with an empty cell that's a little bit different from linear regression.

481
00:48:47,020 --> 00:48:55,480
Yeah. Q Is this something that you would, I guess, use cases for or.

482
00:48:57,210 --> 00:49:06,180
It's easier. It's not necessarily complete there because everybody might have said that, you know, we're we're all female or all male.

483
00:49:06,630 --> 00:49:10,950
So it's not that the information is incorrect. It's just we don't have variability in information.

484
00:49:11,560 --> 00:49:17,310
And so you want to try to recruit more people to represent ourselves or your collection.

485
00:49:18,240 --> 00:49:24,840
We do this, unfortunately, a lot with racial demographics or ethnicities that are less represented in most of the data we collect,

486
00:49:25,200 --> 00:49:28,140
I mean, of collapsing across and creating some other category.

487
00:49:29,100 --> 00:49:38,910
So that might be one way to restrict or you know, you could exclude those folks from the sample, but that's not great practice either.

488
00:49:40,110 --> 00:49:46,770
Um, so it's a tricky one and that's a good example I see here.

489
00:49:47,100 --> 00:49:48,479
And the demographics is a big one.

490
00:49:48,480 --> 00:49:56,760
But then the more like an age variable that has tons and tons of levels that you're going to include it as like a, like true 14, 15, 16, 17 buckets.

491
00:49:57,030 --> 00:50:02,670
Sometimes that can be a problem in come buckets if you don't have people represented as earnings on the scale.

492
00:50:04,140 --> 00:50:08,670
So most of your ideas are trying to recruit more people, or you're playing around with how you're defining the variables.

493
00:50:09,820 --> 00:50:21,960
Complete separation is is also similar to low variability in the sense that you have a variable that's just kind of a perfect predictor.

494
00:50:23,760 --> 00:50:25,080
I'm trying to think of a good way to.

495
00:50:25,980 --> 00:50:32,160
So if you had a training variable and an intervention variable and that training variable is basically the same thing as your intervention variable,

496
00:50:32,160 --> 00:50:40,100
everybody who said the age of training was also part of your intervention condition, for example, you might have or the sorry,

497
00:50:40,430 --> 00:50:44,370
the intervention variable it's predicting like satisfaction with training or something like that.

498
00:50:44,370 --> 00:50:50,760
And everybody who was part of the intervention got the training and nobody who didn't receive the intervention got the training.

499
00:50:51,030 --> 00:50:54,180
That would be a perfect predictor of some of the training outcomes.

500
00:50:54,450 --> 00:50:57,660
Right. Because if you're an intervention, you have something in common on the training.

501
00:50:57,960 --> 00:51:01,020
And there are a few different examples that I can think of.

502
00:51:01,380 --> 00:51:08,880
Maybe that would be basically a perfect correlation, and that's also similar to linear regression.

503
00:51:08,880 --> 00:51:12,750
If you ever have a variable that perfectly predicts the outcome variable, your model doesn't run.

504
00:51:14,040 --> 00:51:18,700
It's the same kind of situation. Watch.

505
00:51:19,450 --> 00:51:32,340
All right. We didn't cover some of these other types of general linear model approaches.

506
00:51:32,850 --> 00:51:35,399
I do have a lot of videos for all of them as well as examples,

507
00:51:35,400 --> 00:51:41,010
and we can spend some time there for the rest of the day or on Thursday talking through if you want to see what some of these other ways,

508
00:51:41,550 --> 00:51:46,860
logistic regression and multi normal regression, multinational regression is, is just a categorical outcome.

509
00:51:47,250 --> 00:51:55,139
These are count outcomes. Negative binomial is just a count kind of outcome when you have a lot of zeros really to turn to.

510
00:51:55,140 --> 00:51:59,280
No. Or I mean, I guess to utilize this kind of information,

511
00:52:00,600 --> 00:52:08,670
you're just trying to recognize what is my outcome variable look like and then you're mapping that on to the appropriate analysis.

512
00:52:09,780 --> 00:52:14,849
I wish I had a better mnemonic than just kind of memorizing, but if it's a01, it's logistic.

513
00:52:14,850 --> 00:52:19,080
If it's a category is multi normal. If it's a count, it's probably Poisson.

514
00:52:19,710 --> 00:52:23,970
As you get more and more into this, there might be some nuance that you're going to try to incorporate.

515
00:52:24,210 --> 00:52:28,980
For example, it's a count, but there's a lot of zeros that are going to be happening, firing stuff.

516
00:52:29,550 --> 00:52:34,440
You're going to see a lot of these things zero inflated plus on fire and stuff because there's a lot of zeros.

517
00:52:34,830 --> 00:52:37,530
So they're going to be little things like that that you have to remember.

518
00:52:37,950 --> 00:52:45,330
The great part about all of this is it follows a similar logic in terms of it's a unit change in the predictor,

519
00:52:45,600 --> 00:52:48,510
it's related to some sort of change in our outcome variable.

520
00:52:49,350 --> 00:52:56,339
Most of these transformations are going to use something very similar to the logistic regression analysis.

521
00:52:56,340 --> 00:53:00,390
The mirror is going to use a logit transformation or something very similar to it.

522
00:53:00,750 --> 00:53:04,440
So we're going to be dealing with logit and odds ratios.

523
00:53:05,100 --> 00:53:12,210
And then it's just a little bit of interpretive interpretation of changes for how we talk about the coefficients.

524
00:53:12,630 --> 00:53:13,620
So that's the good news.

525
00:53:17,070 --> 00:53:25,800
Memorizing this is if you want to, but I think I have, you know, it's also just having to have a table in your back pocket that you can write to.

526
00:53:27,270 --> 00:53:33,870
And if you can recognize the outcome, you can use most of these default sampling models.

527
00:53:34,230 --> 00:53:40,410
You don't even have to worry about all the the parameters here.

528
00:53:41,280 --> 00:53:48,200
But then you see the, the, the links that are typically used for a variable that follows one of these outcomes.

529
00:53:51,370 --> 00:53:55,460
Yeah. We're currently just interesting regression.

530
00:53:57,800 --> 00:54:02,360
Yeah. Yeah, but vanilla is just a special case of the binomial model.

531
00:54:02,660 --> 00:54:08,149
So it's when we have one trial, it's just going to be zero one binomial zero also all zero one trials.

532
00:54:08,150 --> 00:54:11,930
But we have successive ones, independent success trials, right?

533
00:54:12,260 --> 00:54:18,860
So depending on how you want to think about your outcome variable, it's going to follow some sampling distribution.

534
00:54:19,550 --> 00:54:27,440
We have some associated parameter and this is the mean, this is the per proportion, this is the count or the rate, but this is kind of a bigger one.

535
00:54:27,440 --> 00:54:32,300
What kind of transformation are you going to use? Logit agent log human of logit.

536
00:54:32,570 --> 00:54:35,780
So human of logit loaded are almost identical. That's nice.

537
00:54:35,870 --> 00:54:39,830
It's helpful. Log is just taking that out of the logarithm of the rate.

538
00:54:40,190 --> 00:54:47,389
So this looks really complex in practice.

539
00:54:47,390 --> 00:54:53,540
It's not so bad because you can usually default to the defaults and the interpretation

540
00:54:53,540 --> 00:54:57,130
is going to be a lot of what we did for logistic regression this week.

541
00:54:57,560 --> 00:55:01,190
So I encourage you, if you know that you have like a current outcome that you're interested in,

542
00:55:01,520 --> 00:55:05,089
take a peek at my video, but kind of comes through the same thing with the multi nominal outcomes,

543
00:55:05,090 --> 00:55:07,160
or we can cover an example on Thursday or something,

544
00:55:08,660 --> 00:55:16,100
but multi nominal outcomes are basically just how using a couple of different logistic regressions within one broader analysis.

545
00:55:16,400 --> 00:55:20,600
So if you have three levels, you're going to have two separate logistic regression analysis,

546
00:55:20,840 --> 00:55:24,770
one for level two versus one, the other one for level three versus one.

547
00:55:25,130 --> 00:55:30,830
Yeah, for level two kind of does the same thing. So count outcomes.

548
00:55:31,130 --> 00:55:41,000
You're still going to be thinking about how to take a rate and convert it to basically log odds and exponentially to guitar's ratios.

549
00:55:41,330 --> 00:55:45,980
So it's still all pretty similar with just your occasional but annoying.

550
00:55:46,310 --> 00:55:52,690
You know how to tweak that. We have to be mindful for which church.

551
00:55:54,620 --> 00:55:59,120
Questions about this. I'm actually going to keep an eye on this, even though it looks really fancy.

552
00:55:59,870 --> 00:56:02,870
I'm going to ask for how folks are feeling about this.

553
00:56:06,430 --> 00:56:11,380
Really. Continuous variable dichotomy.

554
00:56:12,250 --> 00:56:17,500
Count category. Continuous dichotomy.

555
00:56:17,740 --> 00:56:21,040
Count. Category. That's all you need to remember.

556
00:56:22,630 --> 00:56:27,130
And that can be a true continuous dichotomy counter category.

557
00:56:27,430 --> 00:56:32,680
Or it can be an artificial one to reconstruct loneliness because that's going to,

558
00:56:33,040 --> 00:56:39,700
you know, be, you know, 127 It can be a continuous variable, it can be a binary.

559
00:56:39,820 --> 00:56:46,900
You're above or below some threshold, it can be a count. How many of these do you see as two of the nine in a given two weeks?

560
00:56:47,350 --> 00:56:50,820
It can be a category. We can category maybe a little tougher.

561
00:56:51,190 --> 00:56:56,620
And I can think of a category because there is some form of like there.

562
00:56:59,390 --> 00:57:08,930
Yeah. Very efficiently concerned. How do you make the decision which.

563
00:57:14,560 --> 00:57:22,630
Combination, I think a theory and you can look at the data, what it kind of shows you what people have said before.

564
00:57:23,140 --> 00:57:30,250
Talk to your practitioners. You know, what is the outcome that's most interesting and does it make sense?

565
00:57:30,700 --> 00:57:39,370
So does somebody who has an 18 relative to a ten on the page do nine major versus moderate depression or more severe versus moderate depression?

566
00:57:39,700 --> 00:57:44,090
Is that qualitatively different for folks who say, I feel this way?

567
00:57:44,110 --> 00:57:49,270
What more than a couple of times across these nine items to get up to 18?

568
00:57:49,660 --> 00:57:56,379
Does that feel different than I've just endorsed one or two of these nine items and that's how I got to ten.

569
00:57:56,380 --> 00:57:59,620
Something like that. Right. Who are you going to talk to?

570
00:57:59,800 --> 00:58:03,850
You can talk to people who work in mental spaces. You can talk to physicians, surgeons.

571
00:58:03,950 --> 00:58:08,170
You're interactive, as you said earlier.

572
00:58:08,210 --> 00:58:12,470
But it is a combination of what you're doing in your own space are going to

573
00:58:12,520 --> 00:58:15,610
and what you can learn from other people who are working in similar spaces.

574
00:58:16,330 --> 00:58:22,240
But again, no one's really going to know how you're making these decisions.

575
00:58:22,540 --> 00:58:30,580
So I think you're just trying to explain the process that you follow and why this makes sense for your data and for your analysis.

576
00:58:31,570 --> 00:58:34,899
And I wouldn't say because I know linear regression better than logistic regression.

577
00:58:34,900 --> 00:58:41,950
That's why I ran on. That's why I kept a continuous. Now, that is one thing I'll just add.

578
00:58:42,310 --> 00:58:47,400
There's lots of lots of help out there with this. This is the second most popular.

579
00:58:47,410 --> 00:58:55,240
So you're going to find a fair amount of resources for this. A little bit less here and probably the least when we get into accounts and stuff.

580
00:58:55,630 --> 00:59:00,200
It just it's difficult to do. The one that I don't have on here on a horror category.

581
00:59:00,220 --> 00:59:05,050
So this is probably the least where it can cause a panic. But this is like your lecture style.

582
00:59:05,230 --> 00:59:10,420
Instead of treating it as a 1 to 5 continuous, you were thinking about one which is less than two,

583
00:59:10,690 --> 00:59:17,020
which is less than three, but they are discrete categories, and so you have to estimate multiple thresholds.

584
00:59:17,740 --> 00:59:18,850
There are a couple of assumptions.

585
00:59:18,850 --> 00:59:23,430
I do have a video on this that folks are looking at that's the most complex and there are only three sources available for.

586
00:59:31,520 --> 00:59:33,620
We think if we do this.

587
00:59:47,900 --> 00:59:57,140
I think you can and I think you're going to do great and we're going to do this on Thursday, so the day will be entirely yours.

588
00:59:57,200 --> 01:00:00,890
I will be prowling around asking anybody or answering any questions, if you will.

589
01:00:01,640 --> 01:00:08,510
But basically it's going to start with rerunning models one and two from today at the very least.

590
01:00:08,510 --> 01:00:12,320
And then you can take this model and try something different.

591
01:00:13,070 --> 01:00:16,430
And this is where you get a chance to play around with any of the data that you want.

592
01:00:17,930 --> 01:00:22,910
You can create a self-acceptance or school engagement scale if you want and however you want to think about it,

593
01:00:24,260 --> 01:00:29,750
if you haven't had enough fun with social support and you want to construct a parent support or a friend's support variable,

594
01:00:30,140 --> 01:00:33,710
just, you know, off the top of my head, maybe you can include any analysis.

595
01:00:37,460 --> 01:00:41,450
That's right. All right.

596
01:00:41,450 --> 01:00:53,960
That's all for me. Any questions? Okay.

597
01:00:54,190 --> 01:01:01,559
That's what they hear. All right.

598
01:01:01,560 --> 01:01:07,020
Well, thank you, everyone. I hope you have a great rest your days and start to reach.

599
01:01:14,920 --> 01:01:30,350
I just. Does anybody here have data where you do use logistic regression?

600
01:01:30,500 --> 01:01:35,270
So curiosity that it's socialist versus.

601
01:01:36,480 --> 01:01:42,620
All right. Whether it's present or not for others alone or with the help.

602
01:01:43,160 --> 01:01:53,630
Okay. Yeah. Well, actually, so I was using one item for such a support scale because, I mean, if you weigh that, it it's not the definition.

603
01:01:54,440 --> 01:02:04,220
Okay. Yes. There's no scope for it. So I'm supposed to be running a factor analysis, find these groups of who like that.

604
01:02:04,760 --> 01:02:08,900
So that's now I know how to do it. Yeah, I literally know how to do it.

605
01:02:10,070 --> 01:02:13,670
So I might play around with that a little. Are some.

