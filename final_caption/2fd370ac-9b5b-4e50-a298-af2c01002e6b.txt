1
00:00:01,710 --> 00:00:05,580
Christine. And she wrote that letter.

2
00:00:06,450 --> 00:00:12,000
Oh, I think should I turn off the 621 afternoon?

3
00:00:13,710 --> 00:00:21,090
Picked up her phone and walked through the circle.

4
00:00:25,350 --> 00:00:32,160
Okay. I'm so glad to be here.

5
00:00:33,840 --> 00:00:40,740
I just wanted to mention I'm going to be available Monday. I know it's a it's a break day, but I will be have my usual office hours.

6
00:00:41,070 --> 00:00:47,130
So if you have things you want to ask about before the exam, I'll be around to know.

7
00:00:50,400 --> 00:01:02,160
And, yeah, because that's all I want to say about that. But move on to previewing the problem sets from from Homer, too.

8
00:01:04,920 --> 00:01:10,290
So, look, I spend too much time here because generally folks got got things pretty well.

9
00:01:12,240 --> 00:01:15,790
The first question was basically trying to come up with an overall measure of balance.

10
00:01:15,880 --> 00:01:23,520
You sort of done off me to be done or focused on the sort of variable variable, but sometimes it's nice to have an overall measure.

11
00:01:24,180 --> 00:01:33,210
And we as we saw, there are certainly a few variables that are that are not well balanced and that shows up when we do the multivariate version here.

12
00:01:34,140 --> 00:01:39,150
So so we just needed to keep that, that statistic.

13
00:01:39,150 --> 00:01:48,450
That's the sort of Z type statistic. So any quick I think this was virtually always correct.

14
00:01:48,840 --> 00:02:00,090
Any questions on this? The problem to basically kind of redid what we did in the class notes,

15
00:02:00,090 --> 00:02:06,780
but with a more reduced model propensity score is basically just using age, airbag deployment and age.

16
00:02:06,780 --> 00:02:17,190
But airbag deployment, those were things that were most imbalanced by by use of, of, of car seats booster seats versus seatbelts.

17
00:02:19,590 --> 00:02:25,620
So to murder with an estimated that was maybe slightly stronger than we saw we did the sort of more complete balance,

18
00:02:25,650 --> 00:02:36,300
which maybe isn't shocking since it's sort of less, less complete focus on balancing, less, uh, smaller set of covariates.

19
00:02:37,140 --> 00:02:44,130
Um, and so the model for that, again, most people got this right through a few issues.

20
00:02:45,150 --> 00:02:52,560
I did ask you to use age as a, as a categorical variable.

21
00:02:53,490 --> 00:02:57,330
So putting it in here with the interactions, somebody noticed this interaction was pretty,

22
00:02:57,780 --> 00:03:03,090
pretty hard to estimate because there's basically nobody who is sort of in this in this group.

23
00:03:03,780 --> 00:03:08,160
So it was it was it was hard to pick up that interaction. I think you kind of build that around.

24
00:03:08,310 --> 00:03:12,390
Minus nine was fitting the logistic regression.

25
00:03:13,530 --> 00:03:18,720
But in any events you you could go ahead and get the fitted values.

26
00:03:19,500 --> 00:03:25,440
So we want to wait by the inverse of the probability of what they actually were observed to be in.

27
00:03:25,440 --> 00:03:31,799
So if they were in the booster seat, the propensity to be in the booster seat and if they were in the seatbelt, the propensity to be in the seatbelt,

28
00:03:31,800 --> 00:03:41,550
which is one minus for the booster seat, some of you went ahead and did sort of work this out sort of by hand using the formulas that I but I gave.

29
00:03:41,550 --> 00:03:45,990
But as I did know, you can also use the the survey package.

30
00:03:46,230 --> 00:03:52,140
So you just need to tell it what variables you're going to use and what's the weight variable.

31
00:03:53,310 --> 00:04:00,270
And then if you put this in with booster seat as a as a01 variable, that is the estimate of the difference in the means.

32
00:04:01,230 --> 00:04:07,200
So kind of an ANOVA here, very simple ANOVA and you get the result of shown here.

33
00:04:13,260 --> 00:04:24,750
So jump in if you have questions. So then going on and doing a match analysis now matching on age shape.

34
00:04:25,320 --> 00:04:30,180
So you could create this continuous and airbag deployment and using a gritty algorithm.

35
00:04:30,180 --> 00:04:40,530
So basically doing the treatment effect on the treated and I actually the code I have here uses a bootstrap me to use the analytical results.

36
00:04:40,530 --> 00:04:49,770
That's fine. I could see that the bootstrap is somewhat different, a little bit wider, sort of a little bit more toward the negative side.

37
00:04:52,350 --> 00:04:55,590
So again, pretty straightforward.

38
00:04:56,970 --> 00:05:03,180
You can use the code that I provided and I guess I'm just showing the the bootstrap

39
00:05:03,180 --> 00:05:10,260
version here within the sort of original point estimate just uses the original data.

40
00:05:11,280 --> 00:05:17,310
So you want to compute this variance covariance matrix,

41
00:05:18,450 --> 00:05:30,510
then compute this mahalanobis distance to determine how close the treated observation is with each of the control observations.

42
00:05:33,380 --> 00:05:39,500
And we then go ahead and pick the one that's the closest.

43
00:05:40,700 --> 00:05:45,559
And there was an original I'm sorry, there was an original story up here based on the propensity score and the idea being that you want to

44
00:05:45,560 --> 00:05:53,990
sort of if you sort of grabbed the hardest ones to match off the bat and leave the easier ones for later.

45
00:05:55,100 --> 00:06:03,500
So okay. So that again, I think most people were finding that the few little issues here and there.

46
00:06:08,970 --> 00:06:12,030
And finally, I just asked you to look at this issue of overlap.

47
00:06:12,690 --> 00:06:20,310
And they say looking at this propensity score measure, that that looks at the difference in the log of propensity scores.

48
00:06:21,090 --> 00:06:24,180
And as long as you can find at least one observation,

49
00:06:24,180 --> 00:06:31,380
that's where that difference in the log is less than some threshold, some say .01 here specifically.

50
00:06:31,950 --> 00:06:41,969
Then we can consider that observation as being Mashable or we're not requiring too much extrapolation to use.

51
00:06:41,970 --> 00:06:47,850
And so we find that, you know, this is maybe slightly more generous than we did on the previous ones,

52
00:06:47,850 --> 00:06:57,200
although we've taking all these approaches, basically we had plenty of overlaps on the control side was fine.

53
00:06:57,210 --> 00:07:02,750
It was sort of the the booster seat kids were sometimes harder to find because they were sort of less common,

54
00:07:02,780 --> 00:07:07,200
unsurprisingly, although even their 90% seemed to be reasonable.

55
00:07:09,000 --> 00:07:15,450
Okay. So the last part for the simulation study, this is maybe where there were some issues.

56
00:07:17,580 --> 00:07:28,230
So basically the idea here is that we have some method for generating some confounded confounders and.

57
00:07:33,200 --> 00:07:40,910
Treatments and then an outcome that is confounded by because it's not part of the prediction for this.

58
00:07:43,250 --> 00:07:45,620
So I should say a little bit,

59
00:07:45,620 --> 00:07:50,299
some of you were probably the way I set this up was probably a little confusing because in some sense I generated the treatment first,

60
00:07:50,300 --> 00:07:54,260
which is which is conceptually not what we're how we're thinking about a confounder.

61
00:07:54,920 --> 00:08:00,220
So I wanted to just. Favorite methods on.

62
00:08:03,610 --> 00:08:07,910
Whose work sort of note that you can kind of do this either way.

63
00:08:07,920 --> 00:08:14,030
So I also point out that the principle actually is is correct here.

64
00:08:15,050 --> 00:08:20,770
So. I would do it as.

65
00:08:37,200 --> 00:08:43,920
So we can compute the probability of the treatment assignment given the confounders.

66
00:08:48,170 --> 00:08:52,720
All right. A little baseball.

67
00:09:14,920 --> 00:09:18,870
So basically it's.

68
00:09:22,710 --> 00:09:27,930
Of the vacancy. And just be very poorly received in any kinds of trouble today.

69
00:09:28,710 --> 00:09:42,080
And so they nominated. So we think like the one C.I. Right?

70
00:09:42,160 --> 00:09:46,230
So that's going to be the standard normal distribution, right?

71
00:09:46,240 --> 00:09:49,790
So. CO2 in air.

72
00:09:50,030 --> 00:09:56,300
So there's one that's just going to be minus one for the meat.

73
00:09:56,480 --> 00:10:02,510
All right. So the big one off, I bet, is centered at zero deviation zero.

74
00:10:05,440 --> 00:10:16,900
I mean 30 years was one too many so. And then this is one half are probably that one half have.

75
00:10:21,810 --> 00:10:37,810
And then. The nominator I have probably see eye for an apples one that WCI zeroes is going to be extremely important.

76
00:10:41,280 --> 00:10:44,550
So I. And that's not what happened.

77
00:10:51,060 --> 00:10:56,430
Okay on that. So.

78
00:11:03,780 --> 00:11:14,030
And then basically that would seem to sort of switch the denominator and the other component of the numerator.

79
00:11:32,340 --> 00:11:36,500
At least one House law canceled right at the start of the.

80
00:11:38,730 --> 00:11:47,100
Denominator. So basically it's just this, you know, this PDF will stand alone.

81
00:11:48,660 --> 00:11:51,900
So if I think about the logic here.

82
00:11:57,070 --> 00:12:00,610
Right. So, I mean, I guess conceptually, the first thing you think of is.

83
00:12:03,660 --> 00:12:13,670
But the speculation is that we're going to generate some controversy from this mixture of models and band aid.

84
00:12:13,670 --> 00:12:17,150
Is that the same with these probabilities?

85
00:12:18,350 --> 00:12:21,770
And then why I take some of the value given by.

86
00:12:24,610 --> 00:12:31,950
So the looks going to get better in terms of the way the mechanism can be thought about working?

87
00:12:31,960 --> 00:12:37,690
The way I described it, this is sort of trying to generate this association through your name,

88
00:12:37,690 --> 00:12:41,800
but you can also think back mechanistically, which is quite bad for corporate.

89
00:12:46,250 --> 00:12:56,240
So furthermore I think the longer this. All right, so that's just the wall.

90
00:13:05,890 --> 00:13:09,650
When I started, since I was just a pioneering.

91
00:13:15,080 --> 00:13:33,730
This is a long. Okay.

92
00:13:34,030 --> 00:13:38,190
So we're going to move on to.

93
00:13:40,510 --> 00:13:47,110
So the more a lot of this just going to be a lot of this.

94
00:13:52,080 --> 00:14:42,030
One of. Right.

95
00:14:42,270 --> 00:14:46,649
So my denominators basically are going to be the same here.

96
00:14:46,650 --> 00:14:51,780
So they cancel. And so I'm just left with.

97
00:15:27,520 --> 00:15:32,320
Okay. All right.

98
00:15:32,330 --> 00:16:01,320
So. So basically it's right out this pdf now.

99
00:16:30,880 --> 00:16:35,020
So I just put in the PDF The Normal Distribution.

100
00:16:37,980 --> 00:16:46,930
You just need a normal. So, you know, this was like this is some level of the log cancel.

101
00:16:48,100 --> 00:16:55,230
I just didn't want to take that function here. So that gives me this rule.

102
00:16:55,510 --> 00:17:01,450
Where to? All times.

103
00:17:03,000 --> 00:17:26,220
I scared him to. Started out competitive, so positive.

104
00:17:27,530 --> 00:17:37,500
So basically everything with this guy minus one half or one half us.

105
00:17:39,960 --> 00:17:49,630
So. I think my model.

106
00:17:56,170 --> 00:18:04,990
So so you can see this sort of linear logistic model makes sense actually as correctly specified,

107
00:18:05,740 --> 00:18:10,120
although that wasn't really obvious when I wrote here. So.

108
00:18:13,880 --> 00:18:18,950
Okay. So whether we generate it this way, you could also think about it this way.

109
00:18:19,280 --> 00:18:26,520
From this mixture of normals, this probability of the I equals one is then generated from this logistic model that's linear and C.

110
00:18:28,760 --> 00:18:36,430
Okay. And that's true for both of these.

111
00:18:38,720 --> 00:18:45,940
So, okay, so first question, what's the super population center, this data generating mechanism?

112
00:18:46,690 --> 00:18:50,860
Well, the important thing to remember here is that we're we're looking at differences within an individual.

113
00:18:52,720 --> 00:18:57,560
It's probably a type of. Go away.

114
00:18:58,240 --> 00:19:02,160
And so canceled. I'm left with the differences.

115
00:19:02,170 --> 00:19:08,170
And if you think about error terms here. Right, these are zero. So the ace is one.

116
00:19:10,150 --> 00:19:20,740
So then I ask you to generate the bias using the unadjusted estimate or taking the difference to observe means then using a regression estimate.

117
00:19:20,890 --> 00:19:29,800
So basically fitting this model here and comparing the coefficient associated with I and then

118
00:19:31,300 --> 00:19:36,550
the weighted estimate are using these inverse probability weights in reverse score weights.

119
00:19:37,570 --> 00:19:41,680
So and then I ask you to compute the bias and Ruby's Square.

120
00:19:42,880 --> 00:19:50,050
So most people got this right. There were a few things that went off the rails, but the unadjusted one is is biased.

121
00:19:50,950 --> 00:19:54,790
The adjusted estimators are unbiased.

122
00:19:56,230 --> 00:20:04,750
The regression estimate is a little more efficient than the weighted estimate, although it's not a huge difference.

123
00:20:08,170 --> 00:20:12,610
And then kept the same generating model for the assignment,

124
00:20:12,610 --> 00:20:24,010
but then basically specified the model by having bi be linear with respect to the exponential of C with respect to C itself.

125
00:20:25,180 --> 00:20:29,170
So however, whatever function of C you're looking at here, things are going to cancel.

126
00:20:29,680 --> 00:20:34,630
So our s hasn't changed, but our.

127
00:20:39,020 --> 00:20:45,620
When we go and fit using the linear model, the regression estimate or now has a pretty substantial amount of bias.

128
00:20:47,570 --> 00:20:52,640
Now, in theory, the inverse probability weighted estimate should be unbiased, but that's really only true asymptotically.

129
00:20:53,300 --> 00:20:57,830
So our sample size here is not small, but it's not huge either, right?

130
00:20:58,440 --> 00:21:05,450
We have. Yeah, it's only ten episodes of 200.

131
00:21:06,080 --> 00:21:13,190
So if you play around and generate a larger sample size, you would probably start to see this behave a little bit better.

132
00:21:15,920 --> 00:21:26,300
So I then ask you to sort of note why this regression estimator didn't work as well.

133
00:21:27,440 --> 00:21:32,990
Under two is under one like most people. The idea here that basically you've got a specified model.

134
00:21:33,650 --> 00:21:40,100
So the little trick we have and the regression estimate doesn't work because we don't have the betas estimated correctly.

135
00:21:40,640 --> 00:21:48,650
And since we don't have a randomized assignment, we we end up with with with a biased estimate of that effect.

136
00:21:51,440 --> 00:21:58,040
And then why does the when it's why is the intercept square a larger under three than two?

137
00:21:58,190 --> 00:22:01,310
It's actually actually continued to actually be a little bit larger here.

138
00:22:01,400 --> 00:22:06,350
So in some sense, if you think about RBC as the standard, maybe the regression is still working better.

139
00:22:06,950 --> 00:22:11,460
Basically, it's sort of struggling because it just doesn't have.

140
00:22:11,810 --> 00:22:16,730
If I could have, I suppose you can also play around and look at things like overlap and so forth.

141
00:22:16,730 --> 00:22:20,330
You might see some issues here, but but it's sort of doing its best.

142
00:22:20,330 --> 00:22:24,890
But there are a few. If you also looked at the specific output,

143
00:22:25,730 --> 00:22:30,799
there are a handful of observations that are a handful of simulated datasets where the estimation of inverse

144
00:22:30,800 --> 00:22:40,459
probability is really terrible because there are some outlying observations that that have extreme values.

145
00:22:40,460 --> 00:22:43,700
And so we wait them, it really goes off the rails.

146
00:22:44,060 --> 00:22:48,290
So even with the stabilized estimate,

147
00:22:49,520 --> 00:22:56,720
that's a bit of a misnomer sometimes because it is technically stabilized relative to the uncivilized estimate or base.

148
00:22:56,990 --> 00:23:03,890
It's really all that stable. So so we're kind of trading off this robust estimation of causal effects for increased variance.

149
00:23:05,090 --> 00:23:11,960
So the way you think about it is that the here are a significant part of the ruby squares really due to bias.

150
00:23:12,120 --> 00:23:21,230
Right. These are on the same scale. So whereas most of the figure is just due to variability if compare here again.

151
00:23:22,460 --> 00:23:26,180
Variability is basically the pull that's causing the square.

152
00:23:27,590 --> 00:23:38,860
So okay, the questions on that one, I think it's good to get a little bit of experience of simulations.

153
00:23:38,870 --> 00:23:42,490
Also, just in general, they're really useful things to be able to do.

154
00:23:42,500 --> 00:23:44,930
I think no matter what you end up doing for your career out of here,

155
00:23:44,930 --> 00:23:50,120
if you're working in statistics because you're trying different things and you sort of wondering, is this working?

156
00:23:51,410 --> 00:23:55,070
So being able to construct a sensible simulation and test, it is important.

157
00:23:55,350 --> 00:24:01,940
So. Okay. Entertain at home or to.

158
00:24:05,320 --> 00:24:10,300
Not move on. Okay.

159
00:24:11,650 --> 00:24:14,320
So we were looking at this idea of sensitivity,

160
00:24:14,320 --> 00:24:23,320
analyzes this sort of thought that there are sort of potential unmeasured confounders that we might want to that we might want to explore.

161
00:24:25,240 --> 00:24:37,750
Since we we worry for nonrandomized settings, our treatments themselves may suffer from unobserved, confounding, right.

162
00:24:37,750 --> 00:24:43,210
If we have randomization. The great thing about that is that it controls for both observed unobserved confounders.

163
00:24:44,080 --> 00:24:53,590
So if we don't have that, then we might want to think, well, how bad unobserved confounding would have to be to eliminate the effects we're

164
00:24:53,590 --> 00:24:59,290
seeing or perhaps to to sort of illuminate potential masking can go both ways.

165
00:25:00,850 --> 00:25:08,409
And then for the mediation effects as we'll get into a little bit today, we even when things are randomized,

166
00:25:08,410 --> 00:25:14,020
we still can't necessarily assume the mediators and the outcomes are randomized.

167
00:25:14,560 --> 00:25:19,420
So we basically will rely more heavily on coverage for that.

168
00:25:20,080 --> 00:25:24,640
And and this idea of potential unobserved covariance can play the same role here.

169
00:25:26,230 --> 00:25:45,940
Okay. So we've worked out kind of a similar model for how we work at the model for the for the continuous outcome and continuous confounder.

170
00:25:46,220 --> 00:25:51,310
And then in the to the to treatment arm.

171
00:25:51,550 --> 00:26:04,030
So, so, so we can work out something similar for treatment effects on the odd scale when

172
00:26:04,030 --> 00:26:08,830
we have binary outcomes and if we assume that unobserved confounders is binary.

173
00:26:10,090 --> 00:26:16,990
So this now sort of move to this multiplicative scale and again we're going to assume no interaction between the observed cofounder and the treatment.

174
00:26:20,290 --> 00:26:29,170
So we don't have to do that. But to get this somewhat more manageable construction for bias, we're going to need to.

175
00:26:30,640 --> 00:26:34,330
So basically our bias here is going to sort of come in the two forms, right?

176
00:26:34,330 --> 00:26:47,800
The sort of two arms. So this gamma is this measure of our adjusted probability of the of the outcome on a given treatment arm,

177
00:26:50,830 --> 00:27:02,080
how much that's impacted by the unobserved confounders. Right. So basically, if X contains all of you, then these probabilities are equal.

178
00:27:02,620 --> 00:27:07,960
Or conversely, if they if basically whatever the unobserved confounding is, he's very minor.

179
00:27:08,080 --> 00:27:12,580
So this gamma is close to one, then this component here is going to be very close to zero.

180
00:27:14,230 --> 00:27:20,799
And then the other piece we have to worry about is the association between the confounder and the treatment assignment.

181
00:27:20,800 --> 00:27:27,670
So right again, always conditioning on covariates X and that's what we're putting in here.

182
00:27:28,030 --> 00:27:32,179
So again, these are quantities are all going to have to be these are sensitivity analysis.

183
00:27:32,180 --> 00:27:39,370
So you're basically going to be making these up. We're seeing what is the impact under different assumptions about these quantities.

184
00:27:42,670 --> 00:27:51,730
And and then we can sort of get an overall measure if we want to average over the X that we can do from observed data,

185
00:27:53,140 --> 00:27:58,780
but essentially plug it in whatever observed values are of X and taking the lead across the sample.

186
00:27:59,860 --> 00:28:04,030
Or if we want to model these in some ways and B access low dimensional more closely as well.

187
00:28:05,590 --> 00:28:17,950
But okay, so show that it's basically the same game that we did before, but now we're in a multiplicative step.

188
00:28:19,390 --> 00:28:31,709
Wonder what if I. You guys have have the sheets there.

189
00:28:31,710 --> 00:28:38,040
So suppose I just close this down, lift this up and write on this board with more room.

190
00:28:38,040 --> 00:28:43,520
Would that be better? I think so. Okay.

191
00:28:55,450 --> 00:29:36,580
Right. So. So we got an unbiased estimate of the multiplicative scale, but we never quite.

192
00:29:36,880 --> 00:29:50,530
So basically we would say that we have some estimation of the expected value, why we're going to be a probability of rank one.

193
00:29:56,020 --> 00:30:09,130
And we sort of get that probability given treatment, an X and control and x and that should be equal to our potential outcome.

194
00:30:11,260 --> 00:30:30,880
Condition covariance. So in that case is this multiplicative bias.

195
00:30:35,250 --> 00:30:48,230
I'm just going to write this out because it's going to come useful. And I'm writing this out in terms of the observed and potential outcomes.

196
00:31:08,070 --> 00:31:50,510
This. And so this bias, multiplicative bias equal to one is equivalent to unbiased biases.

197
00:31:52,100 --> 00:31:59,030
Right. And sort of saying you take whatever your estimate is, you multiply it by one, you get the same thing back.

198
00:31:59,480 --> 00:32:02,270
Generally take your estimate and multiply it by your bias.

199
00:32:02,840 --> 00:32:10,520
And that is or take your estimate of divided by your bias and that should be done biased estimate.

200
00:32:11,150 --> 00:32:19,100
So just like in the case of the additive, so when you sort of have this term, you subtract off here, you had a term you would divide with.

201
00:32:20,210 --> 00:32:24,080
Of course, if you divide by one, then you get the same thing back.

202
00:32:24,080 --> 00:32:31,140
So I'm biased, okay. So right.

203
00:32:31,160 --> 00:32:34,190
So that's if I sort of figured this is my.

204
00:32:44,270 --> 00:32:47,780
More generally now where I do allow for bias sort of general case.

205
00:33:03,410 --> 00:33:12,770
So now I'm going to allow for this unobserved offender.

206
00:33:25,530 --> 00:33:30,450
And basically just taking this piece here now and I'm going to write it out.

207
00:33:34,080 --> 00:33:34,319
Right.

208
00:33:34,320 --> 00:33:45,360
So this if you think this is marginal and this is now the conditional given some value, you are going to average that over the distribution of you.

209
00:33:45,810 --> 00:33:55,620
Again, always conditional on an X. I'm going to do that for all four of these things here to the observer counterfactual.

210
00:34:33,300 --> 00:34:38,280
So these are good to see those on board. First time I wrote this down, it was all on an iPad.

211
00:34:42,720 --> 00:34:46,070
It's okay.

212
00:35:06,250 --> 00:35:15,210
Okay. So now. So look, right down here in this part of the world.

213
00:35:19,910 --> 00:35:38,280
So I'm just going to rewrite this. Some of this doesn't change.

214
00:35:39,600 --> 00:35:43,860
What I'm going to do here is I'm going to move from my counterfactual to my observed.

215
00:36:13,470 --> 00:36:18,870
And I do apologize. I know it. Sometimes I'm left handed, so I tend to stand in front of what I'm writing.

216
00:36:20,160 --> 00:36:24,750
It's very difficult for me to completely avoid that and be able to write something like that myself.

217
00:36:36,950 --> 00:36:43,910
So it seems basically I'm going from here from this counterfactual to now observed and why and I do that.

218
00:36:54,340 --> 00:36:58,750
But everything I include. You couldn't do it up here.

219
00:37:03,640 --> 00:37:07,219
That's right. This is following all of our usual assumptions.

220
00:37:07,220 --> 00:37:12,320
And the reason it works is because now we're assuming we can. When we conditioned on you, we've got all the confounders.

221
00:37:13,430 --> 00:37:27,620
So. Instead of just call this usual assumptions about conditional independence.

222
00:37:37,100 --> 00:37:55,210
Confounders. Right?

223
00:37:56,690 --> 00:38:06,990
I mean, you're making up the shoes, so why not go for it? This is just everything you need to sell.

224
00:38:08,030 --> 00:38:11,930
So, you know, that's kind of the key conceptual piece here.

225
00:38:13,550 --> 00:38:18,320
Okay, so that's on the board.

226
00:38:21,000 --> 00:38:53,370
Furthermore. So. I mean, if we sort of fix you a new prime.

227
00:38:57,320 --> 00:39:00,440
And you have the same game.

228
00:39:01,880 --> 00:39:05,990
We had the other thing, but now it's on the multiplicative scale.

229
00:39:07,160 --> 00:39:29,000
So basically I just factor this out now because it doesn't vary now in summation over you just goes to one a distribution.

230
00:39:40,140 --> 00:39:44,140
So. Basically.

231
00:39:44,140 --> 00:39:48,730
Now I can put it in the zero before and I can put it in as a multiplier one.

232
00:39:48,730 --> 00:40:34,070
So I can just write this as. So the first part of the same numerator and denominator here.

233
00:40:35,240 --> 00:40:39,380
But basically I'm averaging over from the conditions on here.

234
00:40:40,090 --> 00:40:44,780
And so it doesn't here. It just depends.

235
00:40:52,010 --> 00:40:57,890
Now, here's the same thing. I just replace with a star.

236
00:42:00,810 --> 00:42:18,600
So. So we assume this idea there's no interaction between unobserved confounders you and treatment.

237
00:42:18,610 --> 00:42:23,310
EG So this is by assumption.

238
00:42:32,920 --> 00:42:38,829
So you could not make that assumption to work directly with this building

239
00:42:38,830 --> 00:42:44,980
block because now you're going to have to figure out what is it interactions. So this is what I do for a little bit.

240
00:42:55,720 --> 00:43:12,880
We were also use binary. So basically this ratio is going to be the same in both a star.

241
00:43:35,090 --> 00:43:38,150
So we're going to call this. Yeah.

242
00:45:41,560 --> 00:45:55,080
Okay. So you're. Right.

243
00:45:55,140 --> 00:46:00,190
So when you I guess we're going to say you prime equals zero here.

244
00:46:00,210 --> 00:46:15,060
Right. So basically when you prime equals one, when you equals one, this ratio is going to be this gamma here.

245
00:46:15,990 --> 00:46:20,700
And when you equals zero, right, these things are going to equal each other.

246
00:46:22,080 --> 00:46:27,990
And this is where you primarily zero. So what's true here as well?

247
00:46:29,970 --> 00:46:37,980
So that basically leaves us with gamma when you as one and just times this probability equals one

248
00:46:37,980 --> 00:46:44,550
giving it an X and just the probability equals zero to an index since this just close to one.

249
00:46:47,270 --> 00:46:56,790
And that's true throughout all these four components. So I'm pretty clear on that.

250
00:47:04,590 --> 00:47:09,210
So because this is not conditional on a, these guys are equal.

251
00:47:12,090 --> 00:47:25,220
So they just canceled. And there's a little bit of how do you better how do you break?

252
00:47:41,210 --> 00:47:53,930
Right. So I just think that for you to just look at one line for that kind of gets this part here, this part here.

253
00:47:54,350 --> 00:48:03,630
So I think this is just a little clearer because it kind of emphasizes the fact that we began as one bias, zero, and the one game is not one.

254
00:48:04,350 --> 00:48:12,180
The strength of that bias is a function of. Of how confounding is with you.

255
00:48:12,450 --> 00:48:31,270
With you. Okay.

256
00:48:32,360 --> 00:48:35,630
Okay, so very similar.

257
00:48:35,640 --> 00:48:41,120
We just looked at what the additive one is now instead of subtracting, multiplying, dividing.

258
00:48:42,230 --> 00:48:46,510
So does that make sense?

259
00:48:46,520 --> 00:48:54,050
Questions might be different. Yes. Your major comment about one game is one.

260
00:48:54,680 --> 00:48:58,069
I forgot the condition after that. Well, we get this one right.

261
00:48:58,070 --> 00:49:08,540
It's basically saying that it's kind of a confounder that this this this ratio of the other bias is basically the same.

262
00:49:08,960 --> 00:49:12,470
Mm hmm. And again, as one than this. This is zero. And this is zero.

263
00:49:13,250 --> 00:49:16,800
So this term goes away.

264
00:49:16,830 --> 00:49:29,370
You go ahead. Okay. So this is essentially if we think about the very simple picture here of.

265
00:49:37,200 --> 00:49:49,990
You're finished. Right.

266
00:49:50,140 --> 00:50:15,120
So. This is the same as gamma ray and this is the p have you given a x and you're using a star, right?

267
00:50:15,900 --> 00:50:19,080
So this is one that goes away. This is one that goes away.

268
00:50:22,690 --> 00:50:28,720
One of those will be enough to pick the fights down to two zero on the multiplicative scale one.

269
00:50:30,100 --> 00:50:34,030
But that will take the bias down to one, which a lot of people feel more biased.

270
00:50:47,540 --> 00:50:52,250
And so you can start to think about what reasonable values might be here for this.

271
00:50:53,840 --> 00:50:57,470
Or conversely, you can since you.

272
00:51:01,640 --> 00:51:12,500
Does your estimate of the effect you could say how take the reciprocal of that and say how big the beta gamma or it is?

273
00:51:13,700 --> 00:51:24,710
I don't know if you want to call Delta. How big do those those components have to be to sort of illuminate the effect we're seeing?

274
00:51:27,740 --> 00:51:35,840
Or you could look at it at the lower upper end interval and use that as a sort of measure of how far,

275
00:51:36,110 --> 00:51:40,249
how much confounding would have to exist for us to no longer have a statistically

276
00:51:40,250 --> 00:51:45,440
significant outcome if indeed be able to start with or if not really a way around.

277
00:51:45,450 --> 00:51:50,270
You could say I don't have the statistical significant result, but maybe there's masking going on.

278
00:51:51,350 --> 00:51:58,790
So how big with this confounding would the sun certainly have to be to sort of hide a difference?

279
00:52:00,080 --> 00:52:03,709
So it doesn't always have to be about getting getting to one.

280
00:52:03,710 --> 00:52:10,240
It could be, but getting away from one. All right.

281
00:52:44,840 --> 00:52:48,550
All right. So, you know, it's a lot to write down.

282
00:52:49,350 --> 00:52:54,090
I could have obviously put this on a slide or thought you might actually.

283
00:52:56,950 --> 00:53:00,990
Fall into a coma. We're trying to focus on the slides.

284
00:53:01,030 --> 00:53:06,640
I thought that would not be good. When you've done.

285
00:53:07,910 --> 00:53:15,310
Hopefully it's associated with more. All right.

286
00:53:15,490 --> 00:53:19,060
So it's a back and forth a little bit.

287
00:53:23,340 --> 00:53:52,650
Yeah. So again, I mentioned this before, but just to draw a little picture, the same issue of of measuring confounding.

288
00:53:54,090 --> 00:53:57,570
Of having a measured confounding between the mediator and the outcome. Right.

289
00:53:57,720 --> 00:54:02,100
Right. Can occur. And this is a small picture.

290
00:54:02,110 --> 00:54:07,200
So this just right here. Right. So now we've got instead of just.

291
00:54:07,200 --> 00:54:18,920
Hey, y, man x. So we could have.

292
00:54:22,260 --> 00:54:29,400
So this unmeasured confounding that goes on here. And you know in a randomized trial.

293
00:54:36,120 --> 00:54:51,970
Right. So basically. That takes care of these lines, but we can still have this piece here.

294
00:54:59,920 --> 00:55:12,399
Yeah. So. All right.

295
00:55:12,400 --> 00:55:18,660
So now we can come up with. Sensitivity analysis.

296
00:55:19,620 --> 00:55:23,310
And I'm going to start with control direct effects, because it's kind of the easiest one to work with.

297
00:55:25,800 --> 00:55:36,060
So let's assume now I've got these use in here and now we've got once we include the X and the you,

298
00:55:37,110 --> 00:55:40,860
we've controlled for all the residual confounding, right?

299
00:55:40,860 --> 00:55:45,330
So that given x and you broken this.

300
00:55:49,740 --> 00:55:58,170
We've broken this conditional and a and that that you and I are are connected to Max.

301
00:55:59,310 --> 00:56:03,490
So sorry. I this, this, this, this.

302
00:56:07,000 --> 00:56:14,080
And again, we're going to kind of assume this. There's no interaction between the observed mediator and the treatment conditional on both M and X now.

303
00:56:14,170 --> 00:56:22,750
Right. So before we only conditional next. And again, to make it a little simpler, we're going to assume you as binary and y is linear.

304
00:56:23,170 --> 00:56:27,790
So we just have some zero one out variable that's out there that sort of grabs the

305
00:56:27,790 --> 00:56:35,080
rest of this unobserved confounding and that y is linear and am x giving you.

306
00:56:36,580 --> 00:56:46,630
In that case, the bias for this control direct effect is again this sort of delta gamma product or gamma of measures, this part here.

307
00:56:48,250 --> 00:56:55,420
Right. So it's the expected value given a M and X and Y in terms of how it changes

308
00:56:55,420 --> 00:57:05,650
when Y goes from 1 to 0 and then Delta works on on on the randomization piece.

309
00:57:05,860 --> 00:57:14,620
Right. So the assumes that you've got some probability of being of you being one varies depending on what treatment you're in,

310
00:57:14,620 --> 00:57:20,500
even what you condition on accident. So once you have those down that you can get the bias.

311
00:57:21,790 --> 00:57:31,419
So I think we have just about enough time to go through this and we're going to many more of these.

312
00:57:31,420 --> 00:57:38,110
I'm sort of debating about getting to them, but I did want to show this.

313
00:57:39,370 --> 00:57:44,470
And again, I'm going to play the same game here for you so often.

314
00:57:46,660 --> 00:57:58,520
So. Right.

315
00:58:02,150 --> 00:58:11,420
So you can see if you've been reading text. I am kind of going pretty heavily from like a wheelbarrow, but hopefully then there's a lot in there.

316
00:58:11,540 --> 00:58:16,840
So I'm just trying to grab the highlights too.

317
00:58:17,000 --> 00:58:38,000
Buried in the weeds. So we're back to this scale again.

318
00:58:40,640 --> 00:58:42,860
And this is the bias and the control direct effect.

319
00:58:43,970 --> 00:58:51,260
And we're always going to condition on the access again once we have this weekend out over the X if we like.

320
00:58:57,120 --> 00:59:04,020
So and from that data, I can compute these these expectations.

321
00:59:06,520 --> 00:59:14,280
Right. So this would be my control direct effect.

322
00:59:14,580 --> 00:59:19,860
All right. I'm going to assume my mediator stays constant and I'm going to change.

323
00:59:26,800 --> 00:59:41,470
Because there's an implicit hand here as well that should change the treatment condition x.

324
00:59:42,860 --> 00:59:47,960
So that's what I get from my observed data.

325
00:59:48,830 --> 00:59:54,680
But of course, what I'm really interested in trying to target is the expected value in these potential outcomes.

326
00:59:58,430 --> 01:00:07,720
S So you're sort of taking this to a potential outcome.

327
01:00:07,730 --> 01:00:10,940
It's a function both of a given value of the mediator and a given value of the treatment.

328
01:00:11,750 --> 01:00:21,030
Your constant thinking is. All right.

329
01:00:22,500 --> 01:00:29,040
Whereas look at this from the definition of a controlled, direct effect with biases, a difference between.

330
01:00:33,280 --> 01:00:38,260
Our cause of effect in terms of potential outcomes, in our estimation, from the data.

331
01:00:41,750 --> 01:00:45,940
Okay. So guess what? It's the same game.

332
01:00:47,560 --> 01:00:54,370
We have this you we're going to write out the conditional P's here.

333
01:01:42,850 --> 01:01:50,930
Again. Since you covers everything, I can convert from identical outcomes to my observed data.

334
01:02:09,180 --> 01:02:15,480
And I'm conditioning on a through here. So it's I'm subtracting the positive.

335
01:02:58,770 --> 01:03:12,250
So. Right.

336
01:04:01,880 --> 01:04:08,140
So I'm collecting this common factors of the conditional expectation of why

337
01:04:08,150 --> 01:04:17,300
given an X and you and he started an X and you find these probabilities of you.

338
01:04:25,920 --> 01:04:29,819
Either a restarting or just finish.

339
01:04:29,820 --> 01:04:33,020
You might start next week as conditioning starts.

340
01:04:35,760 --> 01:04:39,830
All right. So let's see. And.

341
01:04:42,900 --> 01:04:49,260
You're a. So.

342
01:04:52,420 --> 01:04:57,630
All right, so we pull these together to get this. We pull these together to get that.

343
01:05:10,800 --> 01:05:14,580
And I'm going to play the same game again. That.

344
01:05:29,740 --> 01:05:32,920
I have this term that fixes you if you start.

345
01:06:01,110 --> 01:06:33,280
The fact that the South. And so he's just become one and they cancel the whole thing.

346
01:06:33,280 --> 01:06:42,760
Zero. So bringing this over here.

347
01:07:14,640 --> 01:07:21,480
If we get, you know, zero here in that summation.

348
01:07:31,550 --> 01:08:08,640
I guess it has to be. All right.

349
01:08:08,640 --> 01:08:39,720
So it's the same thing now, just with a star. But it's this kind of emotional form, so.

350
01:08:45,900 --> 01:09:06,470
If you use binary. And then we can just write this summation out now.

351
01:09:17,720 --> 01:09:20,810
Know, some of this stuff goes to zero.

352
01:09:36,110 --> 01:09:41,240
You know. So you private zero.

353
01:09:41,420 --> 01:10:48,820
You. So basically when you have zero.

354
01:11:04,030 --> 01:11:13,030
So when you is zero, which is going to be. And so, I mean, over lunch I had when you was and when you were zero.

355
01:11:13,480 --> 01:11:16,630
So when you was one. Right. I get this here.

356
01:11:19,780 --> 01:11:24,290
What about when you had 000?

357
01:11:24,310 --> 01:11:31,930
Right. Is you is you prime central here? And so these cancel these cancel only have the situation.

358
01:11:33,600 --> 01:11:38,620
The only non-zero components are when you as one so.

359
01:11:50,710 --> 01:13:04,020
So this. Right.

360
01:13:04,030 --> 01:13:07,050
So this quandary is the same. So I can essentially factor that out.

361
01:13:08,620 --> 01:14:00,700
We new star. Oh.

362
01:14:02,480 --> 01:14:06,800
So. But we're assuming this by assumption.

363
01:14:07,610 --> 01:14:12,470
Right. There's no interaction with a. So these values actually are going to be the same.

364
01:14:13,040 --> 01:14:19,190
So we factor that happen again. And and then we have this part left here.

365
01:14:34,090 --> 01:14:39,220
And you see that plus here somewhere.

366
01:14:45,690 --> 01:14:51,260
And then I end up with. You know.

367
01:15:12,990 --> 01:15:19,290
So. But you can write that.

368
01:15:32,740 --> 01:15:38,110
Because. What about this?

369
01:15:40,070 --> 01:15:48,040
These two quantities are going to be equal. Because if.

370
01:15:54,860 --> 01:15:58,580
Because I'm assuming this is you sort of contain everything that I need.

371
01:16:06,840 --> 01:16:15,800
Condition X. Right. So basically you is going to be independent of A, right?

372
01:16:15,840 --> 01:16:20,700
If you go back, you don't have it up here, but you will independent of age in the next.

373
01:16:30,560 --> 01:16:34,970
So I'm just going to be left with this part here. Yes.

374
01:16:38,160 --> 01:16:50,389
Yes. Oh.

375
01:16:50,390 --> 01:16:59,160
Sorry. Okay.

376
01:17:00,170 --> 01:17:03,740
Okay. All right.

377
01:17:03,750 --> 01:17:07,310
So it was a little ugly. And if you think about it.

378
01:17:13,540 --> 01:17:20,090
So right after all this came to get this over here, you know,

379
01:17:20,170 --> 01:17:29,290
you get sort of this factor to think of the scammer as representing the unmeasured association

380
01:17:30,280 --> 01:17:42,700
between why are you and this delta is the unmeasured association between a and you.

381
01:17:44,590 --> 01:17:48,950
So and it's all conditional on them. Right.

382
01:17:49,000 --> 01:18:01,060
So that's one reason why the easiest development so this bias and this conditional direct effect basically is the same derivation we did for that,

383
01:18:02,110 --> 01:18:07,900
for the overall treatment effect. We just had a kind of condition in the whole way through.

384
01:18:08,770 --> 01:18:14,800
A couple of things. We've like set you prime equal to zero, and then after that, the expectations.

385
01:18:15,130 --> 01:18:18,310
Can you explain that trick just a little bit more?

386
01:18:18,460 --> 01:18:30,020
Right. So we want to think about ultimately what we want to think about distinctions here, right.

387
01:18:30,110 --> 01:18:34,420
When when you changes. Right. That's how we get the effect of you.

388
01:18:35,500 --> 01:18:41,650
So so we want to look at this at this difference.

389
01:18:42,940 --> 01:18:49,509
But, of course, when we're doing the summation over here, so it's a bit of a trick because we some out over you, this whole thing just goes to zero.

390
01:18:49,510 --> 01:18:58,930
But when you're looking at conditional differences, it doesn't. So we can drop it within the sum, but then we go ahead and do these conditional parts.

391
01:18:59,050 --> 01:19:03,310
We end up with zero pieces. Okay?

392
01:19:03,310 --> 01:19:07,810
So and that's how we get the films that we're in should be this way.

393
01:19:08,370 --> 01:19:21,950
Yeah. So I look at the slides and there is one assumption that B of you get an X is equal to give you even a third of it.

394
01:19:21,970 --> 01:19:25,530
So yeah.

395
01:19:25,840 --> 01:19:30,250
So that is, that allows us to get.

396
01:19:40,160 --> 01:20:05,750
See. And.

397
01:20:20,600 --> 01:20:28,350
Mediator in a treatment condition. It was what I've written that would make Delta zero.

398
01:20:28,410 --> 01:21:09,950
That's not correct. So what are we doing wrong here? Yeah, I.

399
01:21:24,640 --> 01:21:44,580
Information. And frankly, I think this maybe we should be saying that the effect of you,

400
01:21:44,910 --> 01:21:55,350
the difference between you and course you probably have you would want to be able to zero once you condition on M an x doesn't vary across a.

401
01:21:56,850 --> 01:22:15,040
So I think there may be an error. 30. Right.

402
01:22:15,040 --> 01:22:21,340
So this is the assumption and I was trying to I did some mathematically I may have made a pattern error.

403
01:22:22,510 --> 01:22:25,630
So maybe let's ignore that for the minute.

404
01:22:26,810 --> 01:22:30,990
Puerto Ricans this we can't see the screen.

405
01:22:31,300 --> 01:22:48,590
Right. So that part there.

406
01:22:50,350 --> 01:22:51,280
I don't think that's correct.

407
01:22:58,880 --> 01:23:06,020
This is all part of the part of the assumptions that we needed to do to get the estimation of the variation, in fact, from the observed data.

408
01:23:06,080 --> 01:23:14,690
Right. These are all these things just that you as needed to be added on to X to get back to our.

409
01:23:17,860 --> 01:23:21,140
Because some white people.

410
01:23:25,480 --> 01:23:56,270
I know we're over time here. So we had all these assumptions before.

411
01:23:58,530 --> 01:24:02,760
So it's exactly the same thing we're doing here. We're just plugging in.

412
01:24:02,940 --> 01:24:15,090
We now have to condition on well, we if you don't have randomized assignment, you would have to condition on X here as well.

413
01:24:16,650 --> 01:24:22,379
So now we're going to condition on X and you sort of assumptions are made to make you compute

414
01:24:22,380 --> 01:24:31,530
the bias the way we did so averaging out over this this unmeasured confounder association.

415
01:24:31,530 --> 01:25:04,489
So we're going to specify the advance. Maybe write this.

416
01:25:04,490 --> 01:25:09,020
I have a little clearer link to these. Okay.

417
01:25:10,020 --> 01:25:14,880
So in order to time any last quick questions, we wanted to.

418
01:25:16,770 --> 01:25:23,160
Right? Not. I will have office hours tomorrow, Wendy, and we'll have the exam Wednesday.

419
01:25:24,960 --> 01:25:28,290
Meantime, have a good break, buddy. Break.

420
01:25:30,300 --> 01:25:36,740
Taking a break. Break. It's been two days and we come today.

