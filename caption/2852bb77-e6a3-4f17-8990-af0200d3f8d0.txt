1
00:00:05,830 --> 00:00:23,180
I. Yeah, yeah, yeah, yeah, yeah.

2
00:00:27,610 --> 00:00:38,630
You. Hey.

3
00:00:38,990 --> 00:00:48,470
Good morning. Today's the day many of you have been waiting for us in a few weeks ago.

4
00:00:49,610 --> 00:00:58,489
Not because it's Halloween only, but because today we will start addressing confounding,

5
00:00:58,490 --> 00:01:06,470
which is the most dreadful issue to infer causation from correlation.

6
00:01:06,980 --> 00:01:17,140
Very scary indeed. So I'm glad that you're here also because it's you know, it's it can be it will be dense.

7
00:01:17,150 --> 00:01:22,230
But so you are able to interrupt them as squishes.

8
00:01:23,350 --> 00:01:33,739
Um, so to go back to where we were and where we are headed, so we've done information bias, right?

9
00:01:33,740 --> 00:01:41,600
We had two sessions and today you have the lab and this is what we are doing today and for the next few sessions.

10
00:01:45,140 --> 00:01:52,760
So we will go through really a review of many of the issues we have discussed,

11
00:01:52,940 --> 00:01:57,620
especially during the causal inference sessions at the beginning of the course.

12
00:01:58,040 --> 00:02:05,840
But then we will introduce new concepts and work through them, such as independent predictors of outcome.

13
00:02:06,720 --> 00:02:12,740
Go back to opposing causal questions in observational studies and counterfactuals,

14
00:02:12,740 --> 00:02:22,310
and then we will discuss specific items and confounding the definition, the structure, and begin to illustrate the treatment of confounding.

15
00:02:23,610 --> 00:02:34,430
Um, and at the end we will use that to identify ways to treat confounding in observational studies.

16
00:02:34,790 --> 00:02:38,239
I will also well, I hope I'll have the time. If not, we'll do it next time.

17
00:02:38,240 --> 00:02:41,930
It's very important. I want to.

18
00:02:45,720 --> 00:02:53,760
Point out some differences between confounding and effect modification, because that's something that's confusing.

19
00:02:54,930 --> 00:02:57,750
All right. So let me do the brief review.

20
00:02:58,140 --> 00:03:07,980
You may remember in an ideal randomized experiment, the investigators assigned a level of exposure to each person using a random method.

21
00:03:08,640 --> 00:03:15,540
If the exposure has two levels, everybody has a 50% chance of getting one treatment or the other,

22
00:03:17,130 --> 00:03:22,530
and everybody should have the same probability of being assigned to each treatment if it is done.

23
00:03:23,880 --> 00:03:27,840
As we say, unconditionally on any characteristics.

24
00:03:28,050 --> 00:03:36,180
So if you just take the whole population that may be potential participants and assign them randomly, everybody should have the same chance.

25
00:03:37,530 --> 00:03:44,940
Also recall that there are some important characteristics of a randomized experiment for it to be ideal.

26
00:03:46,080 --> 00:03:54,630
There must not be loss to follow up. There must be full compliance or adherence with the assigned exposure or treatment.

27
00:03:55,500 --> 00:03:59,070
The exposure has to be well-defined and have only one version.

28
00:03:59,670 --> 00:04:05,999
So if you are trying a pill that of, you know, medication,

29
00:04:06,000 --> 00:04:18,000
it has to have every single pill has to have the same composition and the same potency and be identical to each other.

30
00:04:18,000 --> 00:04:25,319
And you should be there and there should be masking, which is that nobody knows what everybody's getting.

31
00:04:25,320 --> 00:04:33,990
And that's to do away with those subjective or objective biases that might occur when somebody knows that they are receiving an active trade.

32
00:04:35,490 --> 00:04:43,560
So there should be a blending of the identity of the receiver.

33
00:04:45,150 --> 00:04:53,940
Now, we also discussed that in an ideal randomized experiment, exposure groups are exchangeable with each other.

34
00:04:54,360 --> 00:04:58,140
With respect to any measured or unmeasured characteristics.

35
00:04:58,860 --> 00:05:10,079
And because of that, we can say that in an ideal randomized experiment, the association we observed has a causal interpretation.

36
00:05:10,080 --> 00:05:21,830
So association is causation. Okay, but what does randomization exactly do to produce exchange ability between exposure groups?

37
00:05:21,840 --> 00:05:32,670
And we touched on this in the randomized trials session, but I'm happy to remind you here of what happens.

38
00:05:33,060 --> 00:05:43,710
So what randomization does is it removes any aros from any measure to measure levels that might be incoming into the exposure rate.

39
00:05:43,980 --> 00:05:48,330
So this is the typical DAG representing a randomized trial.

40
00:05:48,810 --> 00:05:55,260
Randomization removes any potential arrows from L or all other variables into a.

41
00:05:56,370 --> 00:06:03,110
Okay. Now. Those other variables.

42
00:06:07,370 --> 00:06:13,700
We need to have. A special characteristic.

43
00:06:13,720 --> 00:06:20,230
Those other variables need to be independent predictors of the outcome.

44
00:06:20,440 --> 00:06:25,110
In this case, L is a cause of doubt.

45
00:06:25,630 --> 00:06:36,910
Right. So basically what randomization does is to remove errors from potential independent predictors of outcome into the exposure.

46
00:06:40,880 --> 00:06:46,700
All independent predictors of outcome other than the exposure will be evenly distributed between treatment acts.

47
00:06:49,130 --> 00:06:54,200
And let's go back to that favorite example on marijuana, smoking and Alzheimer's.

48
00:06:54,530 --> 00:07:10,740
Let me ask you, what could be independent predictors of outcome in real life from your knowledge of, you know, aging, epidemiology or Alzheimer's?

49
00:07:10,760 --> 00:07:14,590
What are independent predictors of Alzheimer's?

50
00:07:14,600 --> 00:07:17,690
In other words, whether variables that might cause insight.

51
00:07:19,630 --> 00:07:23,200
Is family history of Alzheimer's.

52
00:07:23,470 --> 00:07:26,780
Great. Excellent. Yes. And age.

53
00:07:26,940 --> 00:07:32,649
Yeah. Obviously, you know, ice age progresses. There is a high stress possibly.

54
00:07:32,650 --> 00:07:37,420
Yeah. But it's. Yeah. Head trauma.

55
00:07:37,450 --> 00:07:43,020
Yeah. Okay, that's a great one. Sex.

56
00:07:43,200 --> 00:07:47,040
Female sex? Possibly. Yes. Lifestyle.

57
00:07:47,620 --> 00:07:52,470
How about from your favorite exposures? Nutritional exposures.

58
00:07:52,590 --> 00:08:03,020
Which ones? For data it might be some specific issues that I before people so that could

59
00:08:03,020 --> 00:08:06,710
have something to do with anything that has been has been calling to push.

60
00:08:08,630 --> 00:08:13,580
All right. So I guess you get the concept of of what an independent predictor of outcome is, right?

61
00:08:13,880 --> 00:08:22,040
Yeah, certainly so. And they have some of some of them here and several of them actually you touched on.

62
00:08:25,190 --> 00:08:32,870
So let's keep this in mind for the rest of the example here.

63
00:08:33,590 --> 00:08:44,900
Suppose we could conduct a randomized explain experiment of marijuana smoking with two equal sized groups and before randomization,

64
00:08:46,220 --> 00:08:54,200
we learned that 45% of potential participants in our experiment had a history of head trauma,

65
00:08:54,200 --> 00:08:57,740
which you identified as one of those potential predictors of hope.

66
00:08:58,340 --> 00:09:10,400
So I have a question for you. After randomizing them, what percentage of those assigned to marijuana smoking would have had a hip drop?

67
00:09:10,410 --> 00:09:13,710
And for that, we can do a poll here.

68
00:09:14,580 --> 00:09:18,120
So why don't you go ahead and try to pull.

69
00:10:08,310 --> 00:10:13,110
Let's see. We hit 50 and then. Oh, well, more than 50.

70
00:10:13,300 --> 00:10:23,910
Great. This. Okay.

71
00:10:25,080 --> 00:10:29,000
So. Uh hmm.

72
00:10:30,870 --> 00:10:35,050
It doesn't say who. Oh, you did?

73
00:10:48,400 --> 00:10:52,710
Oh, I see. Yeah, this is the. For that.

74
00:10:52,720 --> 00:10:57,310
I always forget. Uh huh. Uh huh.

75
00:10:57,460 --> 00:11:02,010
Yes. Somewhere here. Yes. Yes. Yes. Okay.

76
00:11:04,470 --> 00:11:07,530
Yes. So? Most of them.

77
00:11:07,950 --> 00:11:10,950
Most of you got the right answer.

78
00:11:11,250 --> 00:11:14,660
45%, right? 40.

79
00:11:14,790 --> 00:11:21,510
Yeah, it does. It does. So if if you got 100 potential participants.

80
00:11:21,720 --> 00:11:29,040
Potential participants, and of those 100, you find out that 45 have had a head trauma.

81
00:11:29,990 --> 00:11:34,740
Right. Or maybe let's do this.

82
00:11:35,490 --> 00:11:38,850
So suppose you have 200 potential participants. Right.

83
00:11:40,020 --> 00:11:46,110
And of those potential participants before randomizing them, 90 have either had trouble.

84
00:11:47,260 --> 00:11:56,440
That's 45% rate of 200. Then you randomize them 100 go into the treatment.

85
00:11:56,710 --> 00:12:00,250
Active treatment exposed the other 100.

86
00:12:00,250 --> 00:12:07,900
Going to no active team. Among those in active treatment, how many would have had a head trauma?

87
00:12:07,930 --> 00:12:11,730
What do you expect? 45.

88
00:12:12,460 --> 00:12:16,720
So 45% right now.

89
00:12:16,730 --> 00:12:26,780
22.5%. Cannot be because that's only half of those that you expect to be equally distributed between treatment.

90
00:12:28,330 --> 00:12:32,040
Right. Okay. And then.

91
00:12:32,050 --> 00:12:41,390
Well, this this is a bit of a almost rhetorical question now, but how about those are saying to normal if one is close to 45%.

92
00:12:41,520 --> 00:12:50,270
Right. So you may be wondering, okay, so we have something that actually causes Alzheimer's,

93
00:12:50,270 --> 00:12:55,850
which is now evenly distributed in both the exposed and unexposed because of randomization.

94
00:12:56,330 --> 00:12:59,990
What happens with the independent effect of head trauma?

95
00:13:00,980 --> 00:13:04,040
In my ideal randomized experiment.

96
00:13:05,900 --> 00:13:13,550
So it cancels out because exactly the same proportion of people have it in each group.

97
00:13:14,000 --> 00:13:17,330
You won't be able to see that effect, right?

98
00:13:21,170 --> 00:13:25,399
But we also discussed that we have a problem because not all exposures can be

99
00:13:25,400 --> 00:13:29,150
randomly assigned by the investigator because of ethical or practical reasons.

100
00:13:29,660 --> 00:13:37,459
And as alleges, we have to rely a lot on observational studies, which is we cannot manipulate the exposure.

101
00:13:37,460 --> 00:13:42,380
We can only observe exposure, status and follow people for the potential outcomes.

102
00:13:44,760 --> 00:13:50,880
So in the case of our example, a randomized experiment is not possible to do it.

103
00:13:51,060 --> 00:13:56,070
You know, I guarantee that nobody could do such an experiment.

104
00:13:57,840 --> 00:14:04,740
So what can we then do? Well, let's conduct an observational study that's sort of good as it gets.

105
00:14:05,190 --> 00:14:14,040
So identify a group of people, all of whom are exposed to marijuana, you know, by themselves, their ambitions, but not by not by the investigators.

106
00:14:14,670 --> 00:14:19,260
And then we followed them for, say, 30 years and measure the risk of Alzheimer's.

107
00:14:20,460 --> 00:14:25,860
And then for comparison, we identify a group of people, all of whom are unexposed to marijuana as well.

108
00:14:26,850 --> 00:14:33,150
Let's say Seventh Day Adventists and measure the risk of Alzheimer's in 30 years.

109
00:14:34,080 --> 00:14:40,080
So let's say I actually did this study and I brought you the data.

110
00:14:41,100 --> 00:14:50,370
So this is the, you know, snapshot of my data file I have here on the left hand side, the marijuana smokers.

111
00:14:50,880 --> 00:14:56,070
So this is an arbitrary ID number for every person in my study.

112
00:14:56,070 --> 00:15:02,910
And A, which is the exposure takes a value of one by convention to indicate that they are exposed.

113
00:15:03,030 --> 00:15:04,740
Yes, marijuana smoke.

114
00:15:05,940 --> 00:15:13,500
Then some of them will have a value of one on weight, which is the outcome, which means these people actually got Alzheimer's, right.

115
00:15:14,040 --> 00:15:18,120
There is to have a zero on viable light did not get Alzheimer's.

116
00:15:18,450 --> 00:15:23,790
Okay. And then on the right hand side, they have the data for the Seventh Day Adventists.

117
00:15:23,790 --> 00:15:27,330
And, you know, the structure of the data is is pretty much the same.

118
00:15:28,380 --> 00:15:33,130
So. What's the prevalence of exposure?

119
00:15:34,900 --> 00:15:40,810
In other words, what proportion of my 40 participants are exposed?

120
00:15:47,620 --> 00:15:57,160
50%, right? Because they have 20 people with a equals one out of 42 probability of a or a equals one.

121
00:15:57,190 --> 00:16:01,600
This is kind of abbreviated notation or lazy notation.

122
00:16:02,740 --> 00:16:07,870
So if if I or Mitt equals one, you have to assume that that's what I mean.

123
00:16:08,080 --> 00:16:11,080
I mean, I don't mean me, me, myself.

124
00:16:11,440 --> 00:16:23,920
But, you know, the people who invented this notation and the probability of outcome would be, well, everybody with the value of y equals one, right?

125
00:16:24,490 --> 00:16:28,900
Divided by everybody in the population. Those would be the marginal probabilities of exposure, explosion, outcome.

126
00:16:29,380 --> 00:16:38,850
And if you count people with a value of one Y, or if you just have faith in me, you would see that there is ten people out of 40.

127
00:16:38,920 --> 00:16:49,059
That's 25%. All right. So if we wanted to estimate the magnitude of this association,

128
00:16:49,060 --> 00:17:00,940
we could estimate the risk of Alzheimer's among the exposed that's going to be eight people with Y equals one divided by a total of 20 exposed.

129
00:17:01,360 --> 00:17:05,440
That's point four. And we can do the same among the unexposed.

130
00:17:05,470 --> 00:17:11,020
That is two people with Alzheimer's in the unexposed. Out of 20 this point one.

131
00:17:12,670 --> 00:17:18,190
And because we said you know the close cohort with all the conditions to estimate risk we could estimate

132
00:17:18,190 --> 00:17:26,230
the cumulative incidence rate right as the ratio of these two figures and it is a risk ratio of four.

133
00:17:27,400 --> 00:17:32,980
So it's a positive association between marijuana, smoking and Alzheimer's in this example.

134
00:17:34,420 --> 00:17:38,310
But this begs a causal question, right?

135
00:17:38,320 --> 00:17:44,230
So does this have a causal interpretation? Technically, how would we posed the causal question?

136
00:17:45,190 --> 00:17:51,549
But you may recall that the way to pose it is to think back of the counterfactual.

137
00:17:51,550 --> 00:17:58,750
It's been right. For example, had the marijuana smokers been unexposed to marijuana, smoking, everything else being equal,

138
00:17:59,260 --> 00:18:04,870
what their risk of Alzheimer's be the same as that of the Seventh Day Adventists?

139
00:18:05,050 --> 00:18:12,310
So in other words, this is the notational way of a controversial question.

140
00:18:12,790 --> 00:18:26,920
This means the conditional probability of the outcome when you pass these people to be unexposed, even though in real life they were exposed,

141
00:18:27,310 --> 00:18:36,160
is that equal to the same conditional probability, under the same exposure limit by the among the people who in real life were unexposed?

142
00:18:36,610 --> 00:18:44,290
Right. So notation aside, because I know, you know, he's not the most popular item of my course.

143
00:18:45,520 --> 00:18:52,690
We could also just say, are the marijuana smokers exchangeable with the Seventh Day Adventists?

144
00:18:53,530 --> 00:18:58,660
And was what does that mean? Well, that means everything else being equal.

145
00:18:59,410 --> 00:19:03,520
Aha. Here comes the practical implication.

146
00:19:03,790 --> 00:19:09,550
Everything else being equal is the distribution of independent predictors of outcome.

147
00:19:10,510 --> 00:19:18,880
Or that one is of course likely to be the same between marijuana smokers and non marijuana smoking Seventh Day Adventists.

148
00:19:19,360 --> 00:19:27,280
Right. So you have to bring back what you retrieved as independent predictors of outcome from your knowledge,

149
00:19:28,150 --> 00:19:32,950
let's say these ones that, you know, some of you said and I also add here,

150
00:19:34,390 --> 00:19:43,420
is it likely that among people who are exposed themselves to marijuana and among people who are Seventh Day Adventists,

151
00:19:43,420 --> 00:19:47,140
the distribution of these factors be the same. No.

152
00:19:47,170 --> 00:19:54,850
Okay, Nicole, give us an example from this list of which ones do you think may be more likely in one group or the other?

153
00:20:11,580 --> 00:20:22,580
Excellent. Okay. We heard that. So basically, the Seventh Day Adventists have a different risk pattern in that they have a they don't smoke.

154
00:20:22,590 --> 00:20:29,970
They have higher intake of fruits and vegetables and more physical activity, etc.

155
00:20:30,750 --> 00:20:41,400
No alcohol. Great. So let's focus on on one one of these, which is the history of head trauma.

156
00:20:42,860 --> 00:20:52,370
Um, so let's see if this one factor is also an equally distributed between exposed and unexposed.

157
00:20:53,120 --> 00:20:59,870
So I actually got you later on that because that's the way to, you know, check it out in your data.

158
00:21:00,000 --> 00:21:07,370
So I have a third column here for Revival that I have called L to represent.

159
00:21:07,910 --> 00:21:11,750
Having had a head trauma or not, I need to. The cartoon is very binary.

160
00:21:12,020 --> 00:21:15,169
One means yes. You still have head trauma. Zero means no.

161
00:21:15,170 --> 00:21:22,590
No history of head trauma. Right? So you have it for everyone in the data set.

162
00:21:23,250 --> 00:21:33,240
And in order to figure out whether head trauma is equally distributed between exposed and unexposed, what do you propose that we do?

163
00:21:51,210 --> 00:21:55,500
Is head trauma equally distributed between exposed and unexposed?

164
00:21:55,590 --> 00:22:03,000
How do we find out? Or odds ratio.

165
00:22:03,990 --> 00:22:11,280
Sorry, I'm having a bit of chest pain here. No.

166
00:22:13,950 --> 00:22:18,360
I try to always say yes to you, but in this case, I have to say no.

167
00:22:18,900 --> 00:22:24,060
But why don't you try again? We can calculate something, but.

168
00:22:29,780 --> 00:22:37,720
Any help. Yeah.

169
00:22:37,870 --> 00:22:44,360
We can get conditional probabilities. Of what? Of drama.

170
00:22:44,510 --> 00:22:56,030
My levels of exposure. Excellent. So this would correspond to examining the prevalence or probability of head trauma.

171
00:22:56,060 --> 00:23:00,410
Again, conditional exposure levels here among the exposed.

172
00:23:00,440 --> 00:23:07,969
So among this group of exposed people, we have seen as a result, 14 people who have either head trauma out of 20.

173
00:23:07,970 --> 00:23:11,630
That's point seven. And in the unexposed we have had.

174
00:23:14,510 --> 00:23:17,839
For people with a value of L equals one out of 20.

175
00:23:17,840 --> 00:23:28,970
That's point to is the history of head trauma an independent predictor of outcome equally equally distributed between exposed and unexposed.

176
00:23:31,010 --> 00:23:35,390
Unexposed and unexposed. Exchangeable with respect to history of head trauma.

177
00:23:35,960 --> 00:23:48,680
No. A good. So in observational studies, we cannot expect that independent predictors of the outcome will be the same between exposure groups.

178
00:23:49,460 --> 00:24:02,090
We cannot write. In other words, independent predictors of outcome may be statistically associated with exposure, as we just showed for head trauma.

179
00:24:03,050 --> 00:24:05,300
So was a problem with independent predictors?

180
00:24:05,330 --> 00:24:16,850
Well, the problem is that that association could be problematic because the independent predictors could cause the exposure.

181
00:24:19,780 --> 00:24:24,490
Let's say a head trauma could induce behavioral changes that lead to marijuana smoking.

182
00:24:24,610 --> 00:24:33,250
Right. And if that's the case, look at what happens with the dead l head trauma causes the exposure.

183
00:24:34,240 --> 00:24:39,140
And if this is the case, we now have a backdoor and open backdoor path from a into what?

184
00:24:40,060 --> 00:24:43,030
So the estimation of the size of this arrow,

185
00:24:43,030 --> 00:24:49,480
which is the magnitude of the Association of Alien White that ignores this backdoor path, will not have a causal interpretation.

186
00:24:50,110 --> 00:24:55,780
Right. But there is another possibility, which is that there could be another factor,

187
00:24:55,900 --> 00:25:01,030
known or unknown, that causes both the independent predictor and the exposure.

188
00:25:02,770 --> 00:25:10,809
Let's say living in a violent and safe neighborhood leads to both head dramas and marijuana smoking because,

189
00:25:10,810 --> 00:25:17,110
you know, some social being alleges and I agree. So if that were the case, this would be a that representation.

190
00:25:17,200 --> 00:25:21,580
This would be you would represent living in a violent and safe neighborhood.

191
00:25:22,030 --> 00:25:26,300
And it causes both head trauma and marijuana smoking.

192
00:25:26,320 --> 00:25:31,180
And the end result is pretty much the same. Right? There is a backdoor path from a into what?

193
00:25:33,820 --> 00:25:38,740
So the exposure groups will not be exchangeable with respect to head trauma history.

194
00:25:39,250 --> 00:25:48,440
And the association that we saw, the association between marijuana smoking and assignment could not be completely causal.

195
00:25:48,460 --> 00:25:55,540
It could be due because there is an overrepresentation of people with head trauma among the marijuana smokers.

196
00:25:57,250 --> 00:25:57,520
Right.

197
00:25:58,720 --> 00:26:10,450
So the independent effect of head trauma is sort of making the marijuana smokers more at higher risk than they really are just from smoking marijuana.

198
00:26:12,070 --> 00:26:22,260
Yeah. And this example leads us to the definition of confounding.

199
00:26:23,250 --> 00:26:30,870
So confounding is a non-coercive association or a lack of association that arises from lack of exchange of.

200
00:26:34,590 --> 00:26:40,290
A lack of exchange ability arises when the exposure and the outcome share a common cause,

201
00:26:41,490 --> 00:26:46,380
which is a predictor, an independent predictor of the outcome or its cause.

202
00:26:48,850 --> 00:26:54,790
If that's the case, exposure and outcome are statistically associated through an open adoption.

203
00:26:56,380 --> 00:27:00,540
Okay. So what to do?

204
00:27:02,070 --> 00:27:06,390
Well, we can actually close the border path.

205
00:27:09,150 --> 00:27:17,210
And account for the difference in the distribution of independent predictors of outcome between exposure outcomes.

206
00:27:22,280 --> 00:27:31,010
How do we do that? Well, we could estimate the effect of marijuana smoking on Alzheimer's condition,

207
00:27:31,580 --> 00:27:38,600
on head trauma history, because the groups may be exchangeable within levels of head trauma history.

208
00:27:39,560 --> 00:27:45,020
And in practice, we do that by stratifying, stratify.

209
00:27:45,950 --> 00:27:51,290
So what we are going to be doing is to estimate the association between marijuana,

210
00:27:51,290 --> 00:27:59,540
smoking and Alzheimer's separately for people without and with a history of head trauma stratify.

211
00:28:02,250 --> 00:28:08,340
So let's go back to my data. Page here.

212
00:28:10,220 --> 00:28:18,780
And let's first. Estimate the association of Marijuana Smoking with Alzheimer's among people

213
00:28:18,780 --> 00:28:23,280
without head trauma or condition alone not having a history of head trauma.

214
00:28:25,630 --> 00:28:32,350
Those would be these people. Why? Because they have a value of zero on L, which is history of head trauma.

215
00:28:32,590 --> 00:28:39,270
No head trauma. Okay. So among the exposed, we didn't have a head trauma.

216
00:28:39,280 --> 00:28:42,700
We have one case of Alzheimer's out of six.

217
00:28:43,270 --> 00:28:44,380
That's point 17.

218
00:28:45,430 --> 00:28:56,319
Among the unexposed who did not have a head trauma, we have one case of Alzheimer's among 16, which are these people enclosed in this red box.

219
00:28:56,320 --> 00:29:07,660
And that's .063. We can estimate the cumulative incidence ratio in that group and it is 2.7, meaning this number divided by this number.

220
00:29:08,170 --> 00:29:13,840
That's 2.7. Okay. So we have one stratum.

221
00:29:14,380 --> 00:29:20,290
We have the cumulative incidence ratio in this stratum of people without the head trauma equals zero.

222
00:29:22,420 --> 00:29:25,960
What's next? Well, we have to do it among people with a history of head trauma.

223
00:29:26,050 --> 00:29:33,600
Right. So that would be these people who have a value of one on variable.

224
00:29:34,630 --> 00:29:43,000
How do we do that? Among people among the exposed who also have a history of head trauma, there were seven cases of Alzheimer's.

225
00:29:43,330 --> 00:29:49,870
This out of 14, which are all people enclosed in this orange box.

226
00:29:49,900 --> 00:29:59,850
So that's half point five. And among the unexposed who did have a history of head trauma, which are four people,

227
00:29:59,860 --> 00:30:04,150
there was one case of Alzheimer's out of four, and that's point 25.

228
00:30:04,930 --> 00:30:15,220
They can see this regime, that stratum is to right point five divided by 2.25, and we have it for the stratum of head equals one.

229
00:30:21,410 --> 00:30:29,130
Now. How do we know there is confounding here by head trauma?

230
00:30:30,030 --> 00:30:34,170
Well, medically, we have to make a comparison.

231
00:30:35,370 --> 00:30:49,500
We have to compare the stratum with specific estimates of association is case 2.7 and two with the overall and stratified SD which is for.

232
00:30:52,020 --> 00:30:55,470
If they differ there is confounding.

233
00:30:56,940 --> 00:31:01,820
Do they differ here? So how do they compare?

234
00:31:01,910 --> 00:31:09,470
Is the stratified association stronger or weaker than the overall and stratified association?

235
00:31:17,110 --> 00:31:25,110
We could we could thank you because we could, you know, do on 2.7 or closer to one.

236
00:31:25,120 --> 00:31:37,240
No association than four is, which means the confounding or lack of exchange ability by head trauma is making us see.

237
00:31:38,360 --> 00:31:51,230
A stronger association than there really is. But we if we account for the history of head trauma, we see that real association, which is.

238
00:31:52,550 --> 00:31:55,640
Actually less than that. Since that night.

239
00:31:57,290 --> 00:32:01,430
Have you gone through regression in bio stats?

240
00:32:02,420 --> 00:32:07,130
Not yet. Okay. And then I will keep respectfully quiet to avoid confusion.

241
00:32:09,810 --> 00:32:15,230
So this is what I just said. My specifics here differ from overall honest debate here.

242
00:32:16,580 --> 00:32:20,340
Okay, now, what's the structure of confounding meaning?

243
00:32:20,590 --> 00:32:27,930
Whenever you say, structure or I say or others, structure, structure means that structure is structure.

244
00:32:27,950 --> 00:32:36,030
I mean, that's how can you represent confounding using that sort of what can you see in that with respect to confine?

245
00:32:36,090 --> 00:32:42,930
So there are basically three types of potential ways to represent confounding with that.

246
00:32:42,940 --> 00:32:49,379
And they are from your reading the important thing the definition the key is that there is

247
00:32:49,380 --> 00:32:56,550
confounding if there are open boundary patterns from exposure mean to outcome recall a backdoor.

248
00:32:56,640 --> 00:33:03,420
An open path is a path that doesn't have a collider and it's undirected, right?

249
00:33:05,060 --> 00:33:13,610
So in this example, again, from your readings, the outcome is death, a is cardiac surgery, the exposure and L is the severity of heart disease.

250
00:33:14,330 --> 00:33:23,840
So people who have severe heart disease are more likely to undergo heart surgery to fix the problem, but they are also more likely to die.

251
00:33:24,590 --> 00:33:31,520
Right. So the severity of heart disease is an independent predictor of outcome that happens to cause the exposure.

252
00:33:32,630 --> 00:33:39,140
The second example actually, A, you can illustrate what we have been going through.

253
00:33:40,130 --> 00:33:46,880
Let's say life can be Alzheimer's, disease, AIDS, marijuana, smoking an L is a history of head trauma.

254
00:33:46,880 --> 00:33:56,660
You is living in an unsafe and violent neighborhood which causes both head trauma and marijuana smoking.

255
00:33:58,610 --> 00:34:02,270
And in this other structure, why could be stroke?

256
00:34:02,870 --> 00:34:09,290
A could be aspirin intake. And l could be a heart disease.

257
00:34:10,190 --> 00:34:16,110
Now there is an unmeasured variable that causes atherosclerosis, that causes heart disease on the one hand,

258
00:34:16,110 --> 00:34:27,200
and certainly causes stroke, and then l causes aspirin, heart disease because it's aspirin intake.

259
00:34:27,200 --> 00:34:30,890
But aspirin intake can actually cause one type of stroke.

260
00:34:31,430 --> 00:34:37,000
Right. There's. Yeah, yeah, yeah.

261
00:34:37,680 --> 00:34:42,180
You have to validate me here because I don't remember any of them, huh?

262
00:34:42,510 --> 00:34:47,400
So I'm glad that you are here. I think it can cause hemorrhagic stroke, right?

263
00:34:51,680 --> 00:34:59,300
The doctor said that you have to believe now in this particular that what the independent predictor of outcome.

264
00:35:01,130 --> 00:35:09,870
This structure. Is l the independent predictor of outcome.

265
00:35:12,890 --> 00:35:17,570
I mean, this outcome is an indirect effect, but really,

266
00:35:17,780 --> 00:35:24,190
you is going to be the independent predictor of outcome here, which is associated or causes the exposure through L.

267
00:35:24,680 --> 00:35:35,330
Right. But again, the important thing is, is that you'll be able to identify the open backdoor path from a do you mean into what?

268
00:35:36,860 --> 00:35:42,820
All right. Any questions on this so far? Isn't.

269
00:35:51,470 --> 00:35:57,870
Okay. Okay, great. That's actually the last couple of lines.

270
00:35:58,240 --> 00:36:04,270
So if we can wait, I'll be very happy to entertain that.

271
00:36:05,000 --> 00:36:08,380
This is very interesting. And actually, this is new.

272
00:36:08,890 --> 00:36:15,460
New, you know, after 11 years, they realize that they should clarify.

273
00:36:15,610 --> 00:36:18,820
So today is the day is your lucky day.

274
00:36:19,300 --> 00:36:22,720
Yeah. This is my Halloween treat, perhaps.

275
00:36:22,750 --> 00:36:33,520
All right. Now we are going to get into how to close back parts, meaning how to deal with phone.

276
00:36:34,270 --> 00:36:41,830
And to do that, I have to review with you and also advance your knowledge on some that suit.

277
00:36:42,700 --> 00:36:49,810
All right. Okay. You ready? When you have this stretch, you have a common cause.

278
00:36:50,050 --> 00:37:01,720
You of two variables L and A. Now, you may recall from the next class that I told you in dogs, there are never double headed arrows.

279
00:37:02,950 --> 00:37:09,070
You remember that? I hope you do. Well, that's still true, but it's a bit of a fib.

280
00:37:09,370 --> 00:37:19,270
But let's forgive them because there is a notation situation in which you can actually have double digit errors.

281
00:37:19,600 --> 00:37:22,030
That is just the notation situation. And again,

282
00:37:22,870 --> 00:37:30,370
I would like things and the brain that will forgive me if I see it's a bit lazy notation because basically the

283
00:37:30,370 --> 00:37:36,399
double headed arrow doesn't mean that one variable causes the other on the other causes the one and vice versa.

284
00:37:36,400 --> 00:37:41,020
No, no, no. It doesn't mean reciprocal causation, it just means this.

285
00:37:41,800 --> 00:37:46,150
So again, this is just the notation is spatial notation case for this situation.

286
00:37:47,410 --> 00:37:55,570
That means L and A are associated because they are consequences of a common cause.

287
00:37:56,680 --> 00:38:02,480
That's all. Okay. The second item is that.

288
00:38:04,440 --> 00:38:06,120
Conditioning on a variable,

289
00:38:06,300 --> 00:38:13,890
let's say when you stratify by levels of a variable can be represented in a that by enclosing that variable in a box like this.

290
00:38:14,940 --> 00:38:24,959
So if you find a dag where there is a box around the variable, that means that variable has been conditioned on meaning is attractive.

291
00:38:24,960 --> 00:38:45,490
The values are stratified. Okay. Now conditioning on a common course or it's descending closes the open path where the common cause lacks meaning.

292
00:38:45,490 --> 00:38:52,090
It blocks the association flow. So in this particular case, we have a common cause, which is l right.

293
00:38:52,120 --> 00:38:55,180
It causes both why the outcome and the expulsion.

294
00:38:56,110 --> 00:39:07,750
So if we condition an L, if we place a box around L, we have closed or blocked the backdoor path from A into what?

295
00:39:10,050 --> 00:39:16,800
In other words, this would be the representation of we of what we just did with the marijuana,

296
00:39:16,800 --> 00:39:22,170
smoking and Alzheimer's example when we stratified by levels of L, right.

297
00:39:23,580 --> 00:39:28,690
This is what we did. We closed that bag and puff and then they submit specific estimates.

298
00:39:28,690 --> 00:39:35,130
And actually they're true that the true association between a and like the causal at least taking care of it.

299
00:39:35,400 --> 00:39:40,800
Right. So this is how you represent conditioning and closing about.

300
00:39:41,580 --> 00:39:56,450
Now. Conditioning on a collider or its this end then opens the path that the collider was closed so it can be very treacherous.

301
00:39:57,730 --> 00:40:04,210
In this case. Is there a collider on this? That was the collider.

302
00:40:05,530 --> 00:40:18,700
Z So if you happen to condition on Z in this case, let's say a descendant of the outcome, you are going to open a path, non causal path from a into Y.

303
00:40:20,990 --> 00:40:30,620
Yes. That's the awful truth. So this is why you have to be very mindful of of the relations of your rivals,

304
00:40:30,620 --> 00:40:36,680
because if you have a collided and you happen to just years, if you are modeling and you are just throwing everything to your model.

305
00:40:37,550 --> 00:40:44,180
If you do this, you are going to get the wrong answer. Any questions on that?

306
00:40:45,800 --> 00:41:07,120
Yes. Precisely.

307
00:41:07,570 --> 00:41:10,000
So to recap, the panel said so.

308
00:41:10,210 --> 00:41:22,810
In this first example, a, B for conditioning A is statistically associated with why there is an association not causal, but association.

309
00:41:23,350 --> 00:41:30,730
If I conditional l I do away with that association so l is no longer statistically associated with.

310
00:41:31,780 --> 00:41:44,200
On the second example in this one that A is not statistically associated with Y is not white because they are only connected through a collider.

311
00:41:44,380 --> 00:41:50,440
And as you recall, when there is a collider, the path is closed and there is no statistical association.

312
00:41:51,340 --> 00:42:01,950
If I condition on Z the collected, I open up the path and I create a statistical association which by the way is non custom.

313
00:42:05,100 --> 00:42:12,379
Okay. Right. No, you know, treatment of confinement.

314
00:42:12,380 --> 00:42:16,700
So again, from a design point of view, we go back to what we have been saying.

315
00:42:17,240 --> 00:42:21,620
Basically two ways to treat confinement, the randomization.

316
00:42:21,980 --> 00:42:30,620
And this is the mechanism to remove all the errors in coming into exposure from independent predictors of outcome.

317
00:42:30,890 --> 00:42:34,760
The result is exchange, ability, use, unconditional or margin.

318
00:42:37,340 --> 00:42:44,090
Then in observational studies we need to condition because there is no randomization.

319
00:42:44,810 --> 00:42:53,270
So the mechanism instead of removing the arrows is going to be blocking by their pass at the level of data analysis.

320
00:42:53,720 --> 00:43:04,090
Right. And the result is exchange ability by within levels of the conditioned on variable use case.

321
00:43:04,090 --> 00:43:07,660
L In other words, we have conditional exchange ability,

322
00:43:08,290 --> 00:43:16,420
so we hope that within levels of L that is exchange ability by any other potential predictors of.

323
00:43:16,690 --> 00:43:22,429
Oh, right. So obviously some implications.

324
00:43:22,430 --> 00:43:32,030
Again, this a bit of a review. We can with randomization, we can estimate causal effects from associations with old assumptions.

325
00:43:32,270 --> 00:43:35,389
We don't even need real cost and knowledge, which is kind of surprising.

326
00:43:35,390 --> 00:43:45,280
But whereas with conditioning, we are required to have a lot of prior knowledge to be able to know which are the backdoor

327
00:43:45,290 --> 00:43:50,210
paths that are open and let's say which data do we need to collect on which variables.

328
00:43:50,930 --> 00:43:54,860
If we are designing a study or if we are analyzing a study which variables,

329
00:43:54,860 --> 00:44:03,950
we have to condition them to be able to close all the parts and get sort of the purest causal effect that we can write.

330
00:44:06,460 --> 00:44:20,320
Now here is a definition of confounder, and there is a bit of, of, of, um, controversy in the field as to whether confounder really is, um.

331
00:44:20,860 --> 00:44:28,990
So the definition of confounding is pretty clear, you know, association or lack of associations that arises from role exchange ability.

332
00:44:29,470 --> 00:44:33,550
But the definition of a confounder, it's much less clear.

333
00:44:34,420 --> 00:44:39,910
And as they said, since I don't really like semantic discussions,

334
00:44:40,210 --> 00:44:47,950
I offer you the least compromising definition of a confounder, which is any variable that can be used to block an open.

335
00:44:50,820 --> 00:44:55,050
If you condition a variable that blocks about the path, that viable is a concern.

336
00:44:57,420 --> 00:45:03,080
I mean, that nobody can tell you. No, no, no. At least this low.

337
00:45:03,550 --> 00:45:09,600
No. All right. Now the fun part.

338
00:45:10,140 --> 00:45:14,520
How do we use that to identify which variables to conditional?

339
00:45:15,510 --> 00:45:24,030
Meaning to close all backdoor parts and obtain that sort of neat and pure causal effect of an explosion or no.

340
00:45:26,070 --> 00:45:30,930
So of course you need to have all possible because the knowledge and you probably have

341
00:45:30,930 --> 00:45:36,870
already drawn your that or if you are given the dagger already drawn it say you know,

342
00:45:37,080 --> 00:45:41,740
oh wow, this is what you have to do.

343
00:45:41,760 --> 00:45:49,850
It's a checklist. First of all, remove all arrows departing from the exposure to other variables.

344
00:45:51,650 --> 00:46:03,309
Sometimes. The exposure may have an effect on the outcome that is indirect is through immediate and you want to ignore that.

345
00:46:03,310 --> 00:46:08,590
But because of that, we will see later on. So to do that, to ignore that.

346
00:46:08,590 --> 00:46:16,950
But you are better off by erasing any arrows you find that are departing the exposure, right?

347
00:46:17,250 --> 00:46:21,450
That is the first. The second is that.

348
00:46:22,670 --> 00:46:29,660
Identify the arrows pointing to the exposure and follow the paths back.

349
00:46:30,840 --> 00:46:39,020
To the outcome, but only do so for open meaning where there are no collectors.

350
00:46:41,720 --> 00:46:56,810
And finally, when you have identify all those pets, then you can look at the back and see conditioning on which variables would close all the pets.

351
00:47:00,110 --> 00:47:04,459
That's called the minimum set of conditioning.

352
00:47:04,460 --> 00:47:11,350
That's right. So let's let's try this with a real example.

353
00:47:11,350 --> 00:47:19,150
This is a nice deck. So here the this is a that from the field of kinesiology.

354
00:47:19,840 --> 00:47:33,010
You know, the exposure these warmup exercises before a game and the outcome is having an injury during that game.

355
00:47:33,820 --> 00:47:43,629
Right. So some kinesiology did some prior causal knowledge research and decided from the very

356
00:47:43,630 --> 00:47:49,990
best that they had in terms of evidence that this was how the causal system worked.

357
00:47:53,170 --> 00:47:56,830
So your mission should you decide to accept it.

358
00:47:57,870 --> 00:48:09,169
Is. To identify the minimum set of variables in this that you would need to condition on in order to

359
00:48:09,170 --> 00:48:18,500
close all the burger parts there may be from warmup exercises the exposure into the alt right.

360
00:48:19,640 --> 00:48:26,180
So. We can go through the checklist for this exercise.

361
00:48:26,190 --> 00:48:32,010
So recall the first stage is to remove all arrows departing the exposure.

362
00:48:32,550 --> 00:48:37,150
Are there any arrows departing the exposure? Yes.

363
00:48:37,300 --> 00:48:42,970
There is this arrow. This is the explosion destroys the putting the explosion into into a game proprioception.

364
00:48:42,970 --> 00:48:48,280
So they're going to remove and it's just it's just a safety measure.

365
00:48:49,430 --> 00:48:59,659
Okay. And now we focus on the exposure and we identify all arrows pointing to it and we are going to

366
00:48:59,660 --> 00:49:07,690
follow each one of those arrows to any potential backdoor paths that will lead us to the outcome.

367
00:49:08,810 --> 00:49:12,379
Right. So let's say let's focus on these.

368
00:49:12,380 --> 00:49:17,810
There are two arrows pointing to the exposure. Let's focus on this one to the left first.

369
00:49:20,330 --> 00:49:27,049
And here you can have a backdoor path that goes through the motivation.

370
00:49:27,050 --> 00:49:34,940
Right then, coach. Right. Fitness level, neuromuscular fatigue, an injury.

371
00:49:35,840 --> 00:49:41,000
That's one bugaboo. Do you agree? Okay, then I'm going to market.

372
00:49:43,800 --> 00:49:52,290
There is more. You could go all the way through coach again, neuromuscular fatigue.

373
00:49:52,290 --> 00:49:57,780
But instead of going straight to injury, you could go through intra again proprioception and then injury, right?

374
00:49:58,260 --> 00:50:08,790
That's a different of. Now they are using this this arrow, this the second one.

375
00:50:09,330 --> 00:50:17,250
There are also a number of potential bugaboos. There is one through pregame perception to fitness level, to genetics, to connective tissue.

376
00:50:17,250 --> 00:50:21,340
So that is a weakness, an injury. Right.

377
00:50:25,230 --> 00:50:29,940
And there is another one, you know, that would go all the way through connective tissue disorder,

378
00:50:29,940 --> 00:50:34,170
but doesn't necessarily need to go straight, but could go through neuromuscular fatigue and injury.

379
00:50:34,590 --> 00:50:46,299
Right. And there could be another one that may skip altogether.

380
00:50:46,300 --> 00:50:51,370
Connective tissue sorted by go from genetics straight in through neuromuscular fatigue and injury.

381
00:50:51,850 --> 00:51:05,220
Right. There are yet there is yet another one that would go through again, proprioception, fitness level, neuromuscular fatigue and injury rate.

382
00:51:06,830 --> 00:51:15,049
And yeah, there is one. You can go use the same path up to neuromuscular fatigue, but then go through it again.

383
00:51:15,050 --> 00:51:18,650
Proprioception and in you. Okay.

384
00:51:20,300 --> 00:51:23,390
Are there any other bad parts that I may have missed?

385
00:51:35,170 --> 00:51:44,220
Is this highlands a yes or no for? Is Andrea.

386
00:51:47,410 --> 00:51:53,800
Yes. Exactly. So, you know, you got me.

387
00:51:53,980 --> 00:52:02,910
It was a bit of a tricky question to see if somebody perhaps would show me a path that went regulated.

388
00:52:03,130 --> 00:52:13,209
So. But Andrea saved you all. So those are all the all somehow go through regulator and they are not opened back there.

389
00:52:13,210 --> 00:52:17,290
But because the collider is closing. Right. Like, for example.

390
00:52:17,920 --> 00:52:24,700
How about this? Well, my bet is I see motivation, coach, fitness level genetics at where fitness level is regulated.

391
00:52:25,360 --> 00:52:28,750
So there is not an open back there. You should not make it.

392
00:52:30,310 --> 00:52:33,520
Is that clear? All right.

393
00:52:34,210 --> 00:52:39,150
So here are they all, you know, all their splendor, all the bag, their.

394
00:52:39,640 --> 00:52:44,740
And then the question for you is.

395
00:52:46,400 --> 00:52:55,880
Which variables could you condition on to close all these parts?

396
00:52:57,160 --> 00:53:01,960
And the fewer the variables that you identified, the bit, the study will be more efficient.

397
00:53:04,030 --> 00:53:12,430
There can be more than one possible set of variables to close all the up so that that's all right.

398
00:53:27,860 --> 00:53:37,010
I know that's a matter. Usually you you want to select pads, that you want to select variables that are actually measurable,

399
00:53:37,190 --> 00:53:46,340
for example, that are measurable well, with relatively little measurement error.

400
00:53:47,900 --> 00:53:52,700
But again, for the sake of this exercise, you can just. Come on.

401
00:53:52,940 --> 00:53:56,340
Fitness level. Aha.

402
00:53:56,390 --> 00:54:02,740
Fitness level. Everybody with fitness level.

403
00:54:03,310 --> 00:54:07,440
No. You're shaking your head. Yes. Into it.

404
00:54:09,030 --> 00:54:15,630
It's a glider. Mm. It's a glider on at least one path and possibly on others.

405
00:54:15,660 --> 00:54:25,380
Look this. And in fact, also on this. So if you condition and fitness level, you would open a non coastal path like this one.

406
00:54:28,160 --> 00:54:42,070
So he's not a good candidate. Okay.

407
00:54:42,190 --> 00:54:49,710
Give me. Yeah. One of you. Regain proprioception?

408
00:54:50,580 --> 00:54:55,800
Would it do the trick by itself? So I agree it's not a collider, so that that's really great.

409
00:54:56,520 --> 00:55:00,450
And then it would close all the parts basically, right.

410
00:55:00,600 --> 00:55:04,950
Going through it so that that's a really great way but may not be enough.

411
00:55:06,630 --> 00:55:13,530
We don't coach a ha we didn't practice this is.

412
00:55:15,650 --> 00:55:27,410
So if you do a condition on these two variables, you would actually close all the background parts and they would not be colliders.

413
00:55:28,910 --> 00:55:32,899
You could also do instead of coach, for example, the motivation.

414
00:55:32,900 --> 00:55:37,290
Right. Could you. Yeah.

415
00:55:39,960 --> 00:55:43,080
Okay. So a few pointers on this.

416
00:55:43,080 --> 00:55:46,470
It is not necessarily conditioned condition on all variables on a path.

417
00:55:47,070 --> 00:55:52,260
The path can be closed by conditioning on only a few and that is called the minimal set.

418
00:55:52,910 --> 00:55:57,990
And as I mentioned before, there can be more than one minimum set made up of different violence.

419
00:56:02,590 --> 00:56:09,100
The key is that the variables conditioned on must not be colliders on any path from exposure to welcome,

420
00:56:09,670 --> 00:56:15,340
because conditioning on colliders opens a path and creates a non causal statistical association.

421
00:56:15,850 --> 00:56:22,780
Right. Also, this is some sort of fine print.

422
00:56:23,440 --> 00:56:31,090
Fine print. Therefore, the variables conditioned on must not be the sentence of the exposure.

423
00:56:31,990 --> 00:56:40,820
Because. They could be intermediate violence and conditioning on intermediate variables might also.

424
00:56:42,150 --> 00:56:49,290
We have had. Conditioning on intermediate variables is.

425
00:56:50,740 --> 00:56:54,010
And resulting in bias, which is called over at jasmine bias.

426
00:56:54,010 --> 00:56:57,220
And we will go through it in a couple of weeks.

427
00:56:58,450 --> 00:57:05,070
All right. Now get a few exercises on on some that structures here.

428
00:57:05,100 --> 00:57:13,620
And the question is it's a on we on this that which whose variable should be conditioned on.

429
00:57:15,870 --> 00:57:19,980
To estimate the causal effect of a on weight.

430
00:57:21,210 --> 00:57:27,030
So I brought a poll so perhaps, you know, go ahead and write out.

431
00:57:28,590 --> 00:57:57,090
Should have something. It might be helpful if I give you back the right to see.

432
00:58:10,080 --> 00:58:14,469
Okay. So let's see when we hit.

433
00:58:14,470 --> 00:58:20,310
Maybe. For the OC.

434
00:58:26,830 --> 00:58:31,120
Okay. You ready? If you're looking.

435
00:58:34,610 --> 00:58:37,800
All right. So how do.

436
00:58:40,160 --> 00:58:45,260
Okay. Now it's easy. Yeah. Yeah, that's funny.

437
00:58:46,430 --> 00:58:49,009
Yeah. So no one is the correct answer.

438
00:58:49,010 --> 00:59:06,920
And, um, well, I guess some of you, um, thought that you could or should, uh, a condition on you one or you two, but why should you not?

439
00:59:09,160 --> 00:59:15,300
Now you can rethink. He's a close pal.

440
00:59:15,750 --> 00:59:20,490
They don't actually know about their pets. That was another filthy, tricky question.

441
00:59:21,780 --> 00:59:25,350
You know, there is no open backdoor path from A to why?

442
00:59:25,380 --> 00:59:30,060
Because the only path other than the directed path is actually close by equally.

443
00:59:30,930 --> 00:59:41,120
So you don't have to adjust for nothing. And on top of that, I guess, you know, in that syntax, oftentimes you is used.

444
00:59:41,120 --> 00:59:47,750
I mean, you don't have to know these, but use is used to represent variables that are unmeasured or unmeasurable.

445
00:59:48,770 --> 00:59:52,700
So, you know, it's going to be impossible to condition and something cannot match.

446
00:59:52,730 --> 00:59:56,060
Okay, good. How about this?

447
00:59:58,340 --> 01:00:04,340
For which variables would you condition on to estimate the effect of a on y?

448
01:00:05,540 --> 01:00:09,500
I'm just going to hear your thoughts because I don't have a.

449
01:00:10,930 --> 01:00:14,960
Okay. Stephen, you are. You're on a roll here. You still close?

450
01:00:15,130 --> 01:00:19,950
Yeah. You see a and y you're only connected through a close button.

451
01:00:19,990 --> 01:00:23,170
And it's close because it is a globe. How about these?

452
01:00:23,200 --> 01:00:29,120
Are these changes? Everything. Or it.

453
01:00:32,400 --> 01:00:39,720
Why do you have to condition on in order to estimate that direct effect during without confinement?

454
01:00:44,060 --> 01:00:48,200
Well, you can really not condition on the exposure that's illegal.

455
01:00:54,200 --> 01:01:00,890
And me give you a hint. Yeah.

456
01:01:01,250 --> 01:01:05,420
Yeah, you can you can estimate it directly because the other part is still closed.

457
01:01:06,110 --> 01:01:11,000
So you don't have the condition and nothing. How about this?

458
01:01:12,300 --> 01:01:19,080
How? What do you have to condition on to estimate?

459
01:01:21,350 --> 01:01:35,320
The effect of a one way. You.

460
01:01:35,620 --> 01:01:39,220
Me? Yeah. You should condition on you.

461
01:01:39,700 --> 01:01:45,190
Right, because there is a backdoor path from A to I that goes through you.

462
01:01:45,970 --> 01:01:58,900
Open back. Now, if you recall what I told you earlier, that sometimes you is used to represent variables that are not measured.

463
01:01:59,770 --> 01:02:11,130
So let's say if that was the case here, but you have a proxy descendant of you, you could condition on that proxy, this and that.

464
01:02:12,070 --> 01:02:22,690
And that should, if not fully, at least contribute to closing that bag because in general conditioning on proxy this and then

465
01:02:22,750 --> 01:02:28,780
of a variable that's the same as if you were conditioned on conditioning on the violence.

466
01:02:29,710 --> 01:02:34,660
I mean, quantitatively depends on how strong the association is between the violent and proxy.

467
01:02:35,410 --> 01:02:39,310
But that's that's that's that's the case.

468
01:02:39,490 --> 01:02:50,830
That's what you should do. Right. And I'm going to go really quickly through this, because this is really to sort of nitty gritty and not that,

469
01:02:51,010 --> 01:02:54,740
but there are conditions for causal inference in observational studies.

470
01:02:54,760 --> 01:03:00,610
So recall the values for exposure need to correspond to well-defined interventions.

471
01:03:00,610 --> 01:03:03,490
And we had talked about this before. We.

472
01:03:05,420 --> 01:03:13,780
Gave the example of BMI body mass index, which is an ill defined intervention because you can get there through many, many ways.

473
01:03:13,780 --> 01:03:20,809
So it can mean a number of things for different people. You need conditional exchange ability.

474
01:03:20,810 --> 01:03:25,160
That means that when you condition by levels of an L variable,

475
01:03:25,550 --> 01:03:32,600
you have to assume that there is no lack of exchange ability by other variables within levels of that level.

476
01:03:33,740 --> 01:03:39,260
That's called conditional exchange. And finally, there has to be positivity.

477
01:03:39,260 --> 01:03:50,479
And I guess to try to put this as simple as possible, you need to have enough data, especially with respect to exposure status.

478
01:03:50,480 --> 01:03:53,120
That means if you are going to condition.

479
01:03:57,140 --> 01:04:07,310
By levels of an L variable, the probability of exposure within levels of the L variable must always be greater than zero.

480
01:04:08,480 --> 01:04:15,830
So in that in our one in smoking example, you may recall the probability of.

481
01:04:18,850 --> 01:04:24,280
Exposure by levels of l was in one level point seven and in the other 2.2 or something like that.

482
01:04:24,910 --> 01:04:34,330
It could have never been zero. If it was zero, you would have lack of positivity and that would violate one of the conditions to go.

483
01:04:36,460 --> 01:04:42,670
All right. Now to Lindsay's question and where they feel they really should be addressing,

484
01:04:43,600 --> 01:04:51,010
what are the differences between confounding and effect modification so we can describe the differences at the number of levels.

485
01:04:51,340 --> 01:04:53,710
The first one is structure.

486
01:04:55,630 --> 01:05:03,790
So I will have the items on confounding on the left hand side and for comparison, the items of effect modification, the right hand side.

487
01:05:05,050 --> 01:05:11,950
This is the typical representation of confounding in that structure, right?

488
01:05:13,000 --> 01:05:20,920
So if A is the exposure and what is the outcome, they are connected through a backdoor path that's going far.

489
01:05:22,620 --> 01:05:30,420
This is a bias in the sense that it will give us the wrong answer if we do not account for these open border.

490
01:05:32,720 --> 01:05:34,370
With a family ification.

491
01:05:34,370 --> 01:05:46,310
And again, a disclaimer the representation of effect modification with tax is imperfect, is imperfect, but this is so far the best attempt.

492
01:05:46,880 --> 01:05:49,940
And for for the sake of this is enough is good enough.

493
01:05:52,980 --> 01:05:59,160
In effect, modification, there is no bias. Now, let me ask you, what is the difference between these two tracks?

494
01:06:00,900 --> 01:06:06,090
Why can I say that here there is bias and here there is not a bias.

495
01:06:08,910 --> 01:06:14,490
I may have highlighted the difference using a certain color.

496
01:06:28,670 --> 01:06:34,880
Exactly. Exactly in confounding. You need to have a common cause of the exposure and the outcome.

497
01:06:35,660 --> 01:06:41,360
So this arrow must be there. This is why it's a bias, in effect, modification.

498
01:06:41,390 --> 01:06:45,440
You do not have that by that that arrow anyway.

499
01:06:45,680 --> 01:06:50,600
And in this case, I am really. So that's the first key difference, this structure.

500
01:06:50,810 --> 01:06:57,850
Okay. The second difference is how do you evaluate and this is very important because it

501
01:06:57,850 --> 01:07:04,209
has consequences on the result you might get recall when you evaluate confounding,

502
01:07:04,210 --> 01:07:09,490
you have to compare associations of age and weight within levels of confounder.

503
01:07:09,670 --> 01:07:18,910
L In other words, you have to estimate stratum specific associations of a weight and you compare

504
01:07:19,120 --> 01:07:24,640
those that misperceive associations with the overall and stratified association.

505
01:07:25,540 --> 01:07:30,000
And I think I gave you a slide for that because.

506
01:07:31,960 --> 01:07:38,430
When you compare in the example of marijuana smoking the two for two and 2.7 strategies,

507
01:07:38,440 --> 01:07:47,470
specific associations in each of L0 and l one against four which was the and certified as the way to evaluate consumption.

508
01:07:51,490 --> 01:07:58,870
To evaluate effect modification. You compared the associations of eight unlike within levels of the modifier.

509
01:07:58,900 --> 01:08:03,850
Let's say in this case e. With each other.

510
01:08:04,930 --> 01:08:16,830
With each other. Meaning you would compare the estimate of the association between NY among people with a equals zero,

511
01:08:17,100 --> 01:08:19,150
with the estimate of association between and white,

512
01:08:19,230 --> 01:08:30,570
among people with a equal equals one right, not with the overall estimate that that comparison is irrelevant in the case of effect modification.

513
01:08:30,870 --> 01:08:36,900
You just have to focus on the stratum specific estimates and how do they differ from each other.

514
01:08:37,470 --> 01:08:40,020
So that's a second difference, right?

515
01:08:43,060 --> 01:08:50,860
Now with respect to the numerical results that you are typically you will typically get with confounding the stratum.

516
01:08:50,860 --> 01:08:57,700
Specific associations of a young white would differ from the overall stratified association,

517
01:08:58,600 --> 01:09:05,560
but usually in the same direction, meaning recollect in the example of marijuana and Alzheimer's.

518
01:09:06,760 --> 01:09:13,149
The the overall was for right and the stratified were two and 2.7.

519
01:09:13,150 --> 01:09:18,700
So both both were less weaker than the stratified.

520
01:09:21,020 --> 01:09:31,250
In effect, nullification the stratum. Expressive associations of and weight differ from each other, from each other.

521
01:09:32,490 --> 01:09:41,120
Right. Now this has a consequence that again, well, you don't need to feel obliged to understand.

522
01:09:41,120 --> 01:09:49,370
But I also could not leave out because you may come back to this after you see, let's say, immigration or.

523
01:09:53,980 --> 01:10:04,639
But in. Confounding the overall and stratified estimate is usually not numerically,

524
01:10:04,640 --> 01:10:14,660
not in between the values of the state specific estimates and once again a good example on my one and then same.

525
01:10:16,660 --> 01:10:21,310
Four, which is then stratified, is not in between two and 2.7.

526
01:10:22,810 --> 01:10:28,650
That's confirmed. In effect, modification.

527
01:10:28,650 --> 01:10:36,400
The overall and stratified estimate is usually in between the stratum specific estimates.

528
01:10:38,750 --> 01:10:51,470
So if the overall one is, let's say four and you have in one stratum one of six and in the other one of two, that's effectively.

529
01:10:53,060 --> 01:10:56,390
Mosley. So I'm stratify this in between.

530
01:10:59,070 --> 01:11:06,479
Now the consequence of that and again, this is what I said. I mean, you don't feel obliged to judge, to understand this immediately.

531
01:11:06,480 --> 01:11:16,049
But if you are to take for confounding, if you were to summarize the stratum specific estimates into one and you can do that,

532
01:11:16,050 --> 01:11:20,250
you can combine them by actually we would be doing that.

533
01:11:20,460 --> 01:11:30,150
You can combine combine them by taking the weighted average weighted by the size of each stratum that weighted average.

534
01:11:31,580 --> 01:11:35,420
We may not be equal to the stratify.

535
01:11:37,240 --> 01:11:42,720
As the. So back to the marijuana and Alzheimer's example.

536
01:11:45,120 --> 01:11:51,120
If I were to take the weighted average of the two in zero and the 2.7 in L one,

537
01:11:51,750 --> 01:12:02,010
I might get I should get something between 2.3 or so, but that 2.3, that summary weighted average is not equal to four.

538
01:12:03,730 --> 01:12:07,980
Of be. Right. But guess what?

539
01:12:08,010 --> 01:12:09,240
In effect, modification.

540
01:12:09,780 --> 01:12:20,130
If I take the weighted average of the settlement specific estimates and recombine them, it should not be different from the under stratified.

541
01:12:28,840 --> 01:12:32,300
Interesting, huh? So is it clear now?

542
01:12:33,350 --> 01:12:40,850
Okay. It's very important, guys. Really. It's very important because, you know, sometimes and I don't like that,

543
01:12:40,850 --> 01:12:45,589
but students are accused of not knowing the difference of confounding and effect modification.

544
01:12:45,590 --> 01:12:48,740
And they say, no, this is this is nonsense. They know.

545
01:12:51,070 --> 01:13:05,510
So. Right. Now here is his summary of the situation, because I guess perhaps bad news, possibly confusing news is that they can actually coexist.

546
01:13:08,460 --> 01:13:12,180
And I guess that was probably your original question, right?

547
01:13:13,260 --> 01:13:22,860
And here is some sort of a very, I guess, uh, you know, raw, uh, summary of potential situations.

548
01:13:23,070 --> 01:13:27,510
So let's say the strategy is specific.

549
01:13:27,510 --> 01:13:31,770
Estimates do not differ from each other or from the anesthetic fight.

550
01:13:33,210 --> 01:13:38,240
And here is the examples of a hypothetical study of the effect of age and weight.

551
01:13:40,620 --> 01:13:44,880
I'm going to be using the cumulative incidence ratio because, by the way,

552
01:13:45,690 --> 01:13:55,560
this theory only works with certain measures such as the probability based measures or continuous measures that are normally distributed.

553
01:13:57,120 --> 01:14:02,460
It does not work with the odds ratio and other measures.

554
01:14:02,820 --> 01:14:06,690
This is one of the reasons I dislike so much the odds ratio.

555
01:14:07,630 --> 01:14:15,130
Because using the odds ratio can actually hamper your ability of a plane as relatively simple a set of rules like this.

556
01:14:16,820 --> 01:14:23,510
And the problem is the mathematical property of the odds ratio, which is called not collapsible, but you don't need.

557
01:14:25,260 --> 01:14:28,290
Now. Whatever, depending on your path.

558
01:14:29,390 --> 01:14:38,950
It, Robin. But so in this example, the risk ratio is too stratified.

559
01:14:39,190 --> 01:14:45,100
And if you stratify by levels of, say, l, you know, an independent potentially in the belt greater.

560
01:14:45,640 --> 01:14:51,040
Turns out they are the same in both. So they don't differ with each other and they don't differ within the stratified.

561
01:14:51,350 --> 01:14:56,530
Therefore, is there confounding? No y because they don't differ from the new study.

562
01:14:56,530 --> 01:15:01,330
Biased is in effect measure modification, I guess in the multiplicative scale?

563
01:15:01,450 --> 01:15:05,770
No, because they don't differ from each other. Okay.

564
01:15:07,300 --> 01:15:10,450
How about some specific estimates do not differ from each other,

565
01:15:10,450 --> 01:15:19,060
but differ from an stratified example and a stratified is two and the stratified at each one.

566
01:15:20,550 --> 01:15:23,580
Is there confounding? Yes.

567
01:15:23,760 --> 01:15:27,389
Why? Because they differ from the uncertified user effect.

568
01:15:27,390 --> 01:15:30,440
Measure modification on this scale. No. Why?

569
01:15:30,480 --> 01:15:33,870
Because they are disabled compared with each other. Now.

570
01:15:35,360 --> 01:15:39,350
Specific estimates differ from each other, but any stratified estimate is in between.

571
01:15:39,710 --> 01:15:48,350
So let's say you have a series of two and you have a CAGR of 02.5 on one and one of 0.4.

572
01:15:48,560 --> 01:15:52,940
They're confounding, possibly not, because this measure is what we call collapse.

573
01:15:53,450 --> 01:15:57,560
Is it effect measure modification? Yes, because they differ from each other.

574
01:15:58,340 --> 01:16:02,160
I mean, they also differ, I guess, from the overall study by destiny.

575
01:16:02,210 --> 01:16:05,420
But this is in between these two numbers.

576
01:16:06,680 --> 01:16:13,690
So that's telling you is really effect modification. But I wouldn't confirm the effect is completely different in the two step.

577
01:16:15,750 --> 01:16:19,700
The final situation is if suddenly specific estimates differ from each other.

578
01:16:20,450 --> 01:16:30,820
But the understood divide this time is not in between. Let's say you're at an stratified is two and the stratified in one level is 1.8.

579
01:16:30,830 --> 01:16:34,880
In another level is 1.2. Is there confounding?

580
01:16:36,710 --> 01:16:42,260
Yes. Because this differs from this. Right. Stratum specific differ from the instead of it.

581
01:16:42,530 --> 01:16:46,010
Is that affect measure modification? Yes. Because these differ from each other.

582
01:16:49,170 --> 01:16:53,120
You. Any questions?

583
01:17:04,090 --> 01:17:08,930
Up. Okay. So here is your progress report.

584
01:17:09,620 --> 01:17:13,580
You should be able to describe why randomization results in exchange ability.

585
01:17:13,610 --> 01:17:27,470
Why is that? Come on.

586
01:17:27,500 --> 01:17:31,520
We want to go home. Or at least have lunch. Why?

587
01:17:31,700 --> 01:17:36,020
Randomization results in exchange ability. Okay.

588
01:17:40,140 --> 01:17:45,240
Well, but this is structurally way. Structurally.

589
01:17:45,240 --> 01:17:48,500
That's what the mechanism is there.

590
01:17:49,440 --> 01:17:54,910
Okay. Zuck. Right. It removes the arrow from the.

591
01:17:55,740 --> 01:17:59,460
Independent predictor of outcome two. Yes. To the exclusion.

592
01:18:00,510 --> 01:18:03,780
And all of them. Known or unknown. Measure or omission.

593
01:18:06,070 --> 01:18:11,260
Identify the cause of non exchange ability between exposure groups in observational studies.

594
01:18:15,820 --> 01:18:20,770
But they differ in the distribution of potential independent predictors of vote.

595
01:18:22,490 --> 01:18:27,140
Stay the council question using counterfactuals in an observational study so.

596
01:18:28,160 --> 01:18:32,510
Go back to the example on Seventh Day Adventists and marijuana smokers.

597
01:18:32,870 --> 01:18:37,250
But if you can actually change the exposure of the actually observed exposure.

598
01:18:37,490 --> 01:18:40,760
Okay. Define confounding.

599
01:18:41,540 --> 01:18:58,660
What's confounding? Excellent.

600
01:18:59,110 --> 01:19:02,770
Fantastic. Recognize the instructional component using that?

601
01:19:02,980 --> 01:19:06,490
You must have a common cause of exposure to know.

602
01:19:07,760 --> 01:19:14,100
But. Identify a minimum set of variables to condition underestimate the causal effect on exposure.

603
01:19:14,100 --> 01:19:17,489
So is the exercise we need are complicated that recall.

604
01:19:17,490 --> 01:19:21,190
You should not. Conditioned on colliders.

605
01:19:22,270 --> 01:19:26,320
Describe three conditions for causal inference. Two conditional observational studies.

606
01:19:27,040 --> 01:19:30,540
Okay. Yeah. It's there, you know.

607
01:19:30,660 --> 01:19:34,270
Uh hmm. Well-defined interventions.

608
01:19:36,160 --> 01:19:43,270
Conditionality, ability and positivity, and then explain differences between confounding and effect modification.

609
01:19:43,450 --> 01:19:47,830
So recall structurally one is bias, the other is not bias.

610
01:19:48,340 --> 01:19:51,460
How do you evaluate it when you compare some specific?

611
01:19:52,720 --> 01:19:57,310
Estimates against and certified settlements specific between themselves.

