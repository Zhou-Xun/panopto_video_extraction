1
00:00:01,260 --> 00:00:06,280
Okay. You guys take it away.

2
00:00:09,240 --> 00:00:18,000
So our article was about cancer screenings and the cost of that and what is fully covered under the ACA and what is not.

3
00:00:18,690 --> 00:00:26,370
So there's actually a doctor named Dr. Mark Frederick, and he's the director of the Center for Value Based Insurance Design here at the U of M.

4
00:00:27,030 --> 00:00:35,609
So while the ACA was being written up, he actually wanted to include something that said to include screenings underneath, like what?

5
00:00:35,610 --> 00:00:39,000
Insurance covered and specifically underneath, like Medicaid and Medicare.

6
00:00:39,240 --> 00:00:43,980
So he wanted to make sure that all screenings for cancer were covered underneath that.

7
00:00:44,820 --> 00:00:48,870
And so he's been working with other, like, insurance companies to make sure that's happening.

8
00:00:49,380 --> 00:00:55,860
And that made over 100 preventable care services free. And usually, like before, that could cost up to $600 just for that initial screening.

9
00:00:56,100 --> 00:01:00,900
So he was saving a lot of people money. By 2016, he noticed that his plane wasn't working Super Bowl.

10
00:01:01,110 --> 00:01:05,670
So what insurance companies were actually doing is covering the initial part of the cancer screening.

11
00:01:05,680 --> 00:01:10,170
So like the initial testing, which is usually sometimes very inexpensive, like it could reach up to $600.

12
00:01:10,440 --> 00:01:17,550
But for other types of cancer, like colorectal cancer, colorectal cancer, it was very inexpensive because you could just do an at home test.

13
00:01:17,880 --> 00:01:25,560
So over time, they covered that part, but they didn't cover the second screening, I guess, because in order to actually be diagnosed with cancer,

14
00:01:25,710 --> 00:01:28,650
you do have to have like the follow up visit and the doctors will usually run more tests.

15
00:01:28,920 --> 00:01:33,600
And so although the first part was covered, the second part wasn't really covered. And that's where more costs came from.

16
00:01:33,870 --> 00:01:38,340
And so this really had a big emotional toll because, you know, once you find out that you could potentially have cancer,

17
00:01:38,520 --> 00:01:45,719
a lot of people may find that very stressful and not knowing and having to figure out how to make up the money to pay for all those extra testing.

18
00:01:45,720 --> 00:01:51,180
And the follow up doctor's appointments is also like added stress, which is just not good if you are even sick.

19
00:01:52,590 --> 00:01:59,579
And so over time, he's been working with other insurance companies and also other advocates to tackle the different types

20
00:01:59,580 --> 00:02:05,220
of cancer screenings and then the different legislator legislature legislations throughout the states.

21
00:02:13,880 --> 00:02:23,330
Okay. Yeah. So since this legislation has gone into effect, um, they've tried to advocate obviously for more coverage and more states.

22
00:02:24,320 --> 00:02:28,310
So like the most successful they've had isn't colorectal cancer.

23
00:02:28,730 --> 00:02:39,770
Um, so an epidemiologist at Kaiser Permanente, um, basically advocated, um, specifically the state of Oregon, um, and started to move there.

24
00:02:40,400 --> 00:02:46,160
So now private insurance insurers cover, um, follow up care.

25
00:02:46,550 --> 00:02:50,970
Um, Medicare is too common and they find that this.

26
00:02:53,960 --> 00:02:59,300
So in the same vein, $0.10, Susan anti-Communism, Bob, too.

27
00:02:59,510 --> 00:03:03,470
But they're advocating for breast cancer coverage now.

28
00:03:03,950 --> 00:03:14,390
So ten states currently cover it and there's legislation pending to do things like Florida, Georgia and Iowa as well.

29
00:03:15,650 --> 00:03:25,400
At the same time, there is kind of this new law that in Texas, like a district court judge,

30
00:03:25,400 --> 00:03:33,950
ruled that this part of the ACA does not require insurers to fully cover these cancer screenings and that that's constitutional.

31
00:03:34,940 --> 00:03:38,930
So, yeah, there's obviously a lot of challenges still remaining with this.

32
00:03:41,210 --> 00:03:52,610
Yeah. So. And I think Morgan was the first state to really start this movement of free screenings

33
00:03:52,610 --> 00:03:58,130
just beyond that first screening and some other states have been following.

34
00:03:59,390 --> 00:04:07,160
But mostly where we chose this article is because we thought was interesting that there was a University of Michigan advocate, Dr. Mark Springer.

35
00:04:07,790 --> 00:04:14,359
And we're also just interested in the fact of, like the fundamentals of health care services really,

36
00:04:14,360 --> 00:04:19,160
is that like coverage and cost and like what is the policy doing to help with that?

37
00:04:20,330 --> 00:04:32,209
But then also finding out that like it doesn't fully cover like all the screenings in general and like we've seen people and have experienced.

38
00:04:32,210 --> 00:04:38,960
I've never seen how medical expenses can be such a burden through patients or like for patients.

39
00:04:38,960 --> 00:04:43,250
And they talked about that emotional burden of like finding out kids who might have cancer and then like

40
00:04:43,580 --> 00:04:48,800
having to not pay for housing or having to pay for food just because medical expenses can be so much.

41
00:04:49,730 --> 00:04:56,719
And then we're thinking about to like we learned in our other policy class about the new surprises, acting like learning.

42
00:04:56,720 --> 00:05:04,280
How effective is it really when the incentive is more on the patient side of things versus like the providers and the payers.

43
00:05:05,900 --> 00:05:11,140
So we were just like thinking about also like what's next beyond the ACA?

44
00:05:11,150 --> 00:05:18,860
It seems like that's like the one policy framework that has really moved health care forward and it comes to cost of care and covering that.

45
00:05:18,860 --> 00:05:25,040
And then we're thinking about to like what comes next in terms of like, okay,

46
00:05:25,040 --> 00:05:29,150
you get free screenings, but what portion of care and treatment is really covered?

47
00:05:30,140 --> 00:05:37,500
If you were to be diagnosed with cancer. Any questions?

48
00:05:41,770 --> 00:05:43,780
So when they say that the follow up is not covered.

49
00:05:44,230 --> 00:05:49,719
So, for example, breast cancer, you'll get your initial mammogram and sometimes it's inconclusive or it's a maybe.

50
00:05:49,720 --> 00:05:54,550
And then when you go back, you called back for the second part of the biopsy that's not covered, is that what you're saying?

51
00:05:55,500 --> 00:05:59,290
That is so common, too. It's so scary and upsetting.

52
00:05:59,290 --> 00:06:01,209
Like I you know, I'm in my forties,

53
00:06:01,210 --> 00:06:07,210
so I have my friends and I are just starting to go through this and there are definitely people who get called back like every time.

54
00:06:07,390 --> 00:06:14,260
So my one friend has calcifications in her breast tissue, which is like pretty normal, especially, I think for women who have breast fed.

55
00:06:14,830 --> 00:06:20,760
I mean, it's not normal, normal because it shows up on a mammogram, but it's not a it's not going to cause cancer.

56
00:06:20,780 --> 00:06:24,249
Right. It's not that. But it's you know, it's these bright spots.

57
00:06:24,250 --> 00:06:29,620
And so they always call her back and she always gets really upset because she had friends who have breast cancer.

58
00:06:29,620 --> 00:06:35,259
And, you know, it brings her out every single time and she has to call and get another appointment.

59
00:06:35,260 --> 00:06:40,719
And it takes like the first time this happened to her, it was during the pandemic,

60
00:06:40,720 --> 00:06:48,370
and they wanted her to wait two months to come back for her second mammogram. She's like I said, like, please, please help me get it before that.

61
00:06:48,370 --> 00:06:51,309
And they they did. They managed to get her in. But yeah.

62
00:06:51,310 --> 00:06:55,660
And the biopsy is very expensive because that's like a, you know, outpatient surgical procedure.

63
00:06:55,660 --> 00:06:58,810
So, yes, these are problems for sure.

64
00:06:59,110 --> 00:07:04,540
They I think they're also might make just like the initial screenings that were free also like not free anymore

65
00:07:04,540 --> 00:07:10,420
depending on the court ruling because technically it's like unconstitutional since in that's in Texas.

66
00:07:10,770 --> 00:07:17,530
Andre, Texas, yeah. Yeah. Because the U.S. Preventative Service Task team has not.

67
00:07:17,650 --> 00:07:21,620
But the president. So yeah. Yeah.

68
00:07:22,610 --> 00:07:31,410
Good times. I mean, it has to be that's kind of the point of screening programs, is that they are cost effective because it's way more.

69
00:07:32,750 --> 00:07:38,930
It's you're doing it to a lot of people, but it's way cheaper than treating a bunch of people for cancer.

70
00:07:38,960 --> 00:07:46,560
Right. So I really like how they just view public health in the US to where it's like a lot of it is around like

71
00:07:46,580 --> 00:07:53,180
preventative care and no one seems to like really all of them really care to put funding into that.

72
00:07:53,890 --> 00:08:02,020
Yeah. And we all are a little disillusioned with public health after the whole Kobe thing.

73
00:08:02,030 --> 00:08:05,330
Yeah. Okay. Good job, guys.

74
00:08:10,820 --> 00:08:17,880
Okay. So today we're continuing our discussion on study design.

75
00:08:22,440 --> 00:08:25,979
So we had gone over this whole selection bias issue last time.

76
00:08:25,980 --> 00:08:33,390
Right. So remember we were you're saying that selection bias and generalizability are not the same thing.

77
00:08:33,400 --> 00:08:40,020
So if you use, for example, everybody's I think we've gone through the questions last time, but just to kind of go over this,

78
00:08:40,020 --> 00:08:46,440
remember selection bias is where when the where you choose people for your study gives you the wrong answer in those people.

79
00:08:46,500 --> 00:08:53,729
Right. So it's not like a lot of cancer cohorts which are overwhelmingly white.

80
00:08:53,730 --> 00:08:58,950
For example, you're you may very well be getting the right answer for white people in your cohort.

81
00:08:58,950 --> 00:09:06,310
It may be not generalizable to people of other racial groups, but that doesn't mean you're getting the wrong answer in your study population.

82
00:09:06,330 --> 00:09:09,630
Right. So it is not a selection bias, it's a generalizability problem.

83
00:09:10,230 --> 00:09:13,380
Whereas in the man article that we talked about last time,

84
00:09:14,640 --> 00:09:28,650
the way that they selected their controls from other patients of GI doctors made it so that the exposed but without disease.

85
00:09:28,650 --> 00:09:35,610
So these are the controls, right? The exposure was very low in these people because they were very unlikely to drink coffee or they may

86
00:09:35,610 --> 00:09:40,709
have stopped drinking coffee because of whatever stomach or digestive ailment sent them to the GI doc.

87
00:09:40,710 --> 00:09:48,840
Right. Which made it look like coffee was increasing the risk of pancreatic cancer when you did the math for that for the odds ratio.

88
00:09:49,500 --> 00:09:58,440
So that's one of the ways if you're a math B person or if you like these two by two tables to think about whether it is selection,

89
00:09:58,440 --> 00:10:04,979
bias or generalizability is if it changes one cell in your two by two table.

90
00:10:04,980 --> 00:10:09,330
So these are the cells, ABCD, the orange or what we call the marginals, right?

91
00:10:09,750 --> 00:10:15,840
If it changes one cell in your table, you have a potential selection bias problem.

92
00:10:17,070 --> 00:10:20,160
And that's what we saw with McMann. Right. It changed only the B cell.

93
00:10:21,150 --> 00:10:30,270
It was both exposed. It was it was different by exposure and your disease status if it only changes one, if it only changes the marginal.

94
00:10:30,570 --> 00:10:37,170
So if you end up with too many people, you end up with more people who drink coffee than the average population of the U.S.

95
00:10:37,320 --> 00:10:42,690
In your study, you can still get the right answer between exposure disease, right?

96
00:10:42,690 --> 00:10:50,459
So if it were only like there were just more coffee drinkers in our study than would be expected from a random sample,

97
00:10:50,460 --> 00:10:57,420
you might have a generalizability problem. Okay, so if it affects a marginal, it might be a generalizability problem.

98
00:10:57,420 --> 00:11:01,590
If it affects a single cell, you may very well have a selection bias problem.

99
00:11:03,060 --> 00:11:06,940
So that makes sense. There's a way to think about it.

100
00:11:09,530 --> 00:11:17,670
Okay. So last time we talked about ecologic studies, case control studies, and now we're going to talk about cohort studies.

101
00:11:17,690 --> 00:11:22,160
And remember, we're kind of moving up that pyramid of evidence in terms of like least biased.

102
00:11:22,370 --> 00:11:25,670
Right, the least possibility for bias. All right.

103
00:11:25,820 --> 00:11:32,990
So in cohort studies, you're following a study population. Over time, you are recruiting people who do not have your disease.

104
00:11:33,080 --> 00:11:38,150
You're recruiting healthy people and you are following them over time to see who gets disease.

105
00:11:39,080 --> 00:11:44,389
Okay. The incidence of disease in the exposed people is compared with the incidence in the non exposed people.

106
00:11:44,390 --> 00:11:48,460
So you're assessing exposure at baseline when they do not have the disease.

107
00:11:48,470 --> 00:11:53,540
Right, then people aren't. You can select people.

108
00:11:53,540 --> 00:11:57,140
So remember in the case control study, you're selecting people based on whether or not they have the disease,

109
00:11:57,650 --> 00:12:01,400
you're picking people with the disease and some people without the disease to compare to each other.

110
00:12:01,940 --> 00:12:05,300
You can do the same thing in a cohort study with exposure.

111
00:12:05,600 --> 00:12:10,550
You can pick exposed people and unexposed people to compare them to.

112
00:12:11,330 --> 00:12:15,320
You might choose to do that if you were really interested in a very rare exposure.

113
00:12:16,670 --> 00:12:24,770
I have very infrequently seen this done in cancer cohorts in almost in every cancer cohort I can think of in that I know of.

114
00:12:25,520 --> 00:12:29,839
They picked some population of people like in Nurses Health Study and in the health professional study.

115
00:12:29,840 --> 00:12:36,680
They take nurses and health professionals and then they ask them about a lot of different exposures and followed them over time for cancer outcomes.

116
00:12:37,880 --> 00:12:47,120
Right. Multiethnic cohort in California and Hawaii, they picked people based on race, ethnicity, just so that they got a good mix of race ethnicity.

117
00:12:47,870 --> 00:12:54,050
But it wasn't really based on any particular exposure and it asked about a lot of different exposures and then followed them over time.

118
00:12:54,530 --> 00:13:00,500
Right. So a lot of times it's geographic. In the case of the American Cancer Society cohort study,

119
00:13:00,950 --> 00:13:09,229
they originally got people who volunteered for us to get their friends and family to enroll, and this was kind of their original cohort of people.

120
00:13:09,230 --> 00:13:11,990
And then they asked about lots of exposures evolved over time.

121
00:13:12,800 --> 00:13:17,360
Where I have seen this exposure thing done is occasionally in like occupational studies.

122
00:13:19,220 --> 00:13:22,459
If they wanted to study air pollution exposure in railway workers, right?

123
00:13:22,460 --> 00:13:27,980
And so they got a bunch of railway workers. They picked some who had particular jobs that expose them to pollution.

124
00:13:27,980 --> 00:13:34,140
And then they picked like office worker people who weren't exposed, for example, to compare them to and then followed them for a lot of diseases.

125
00:13:34,490 --> 00:13:39,050
So using that exposure status selection is less common.

126
00:13:39,650 --> 00:13:47,870
If you do that, you can introduce some of the same issues that you have with selection bias when you're choosing controls for a case control study.

127
00:13:47,870 --> 00:13:52,310
Right? It can be kind of some of those same issues can create that. Does that make sense?

128
00:13:53,390 --> 00:14:01,610
But that is sort of an aside because most cancer cohorts, this is a cancer, you know, cancer epidemiological or cancer public type of cancer class.

129
00:14:02,450 --> 00:14:13,040
Most cancer cohorts that I'm aware of do not select that way. So again, allocation to the study subject is not under control of investigators.

130
00:14:13,040 --> 00:14:17,960
So this is not a randomized controlled trial. People are picking what they do. You're just asking them what what they are exposed to.

131
00:14:19,400 --> 00:14:25,160
So this is kind of a picture of that. You have your study population from which you select your cohort.

132
00:14:26,300 --> 00:14:32,900
You're assessing whether they're taking, in this case, oral contraceptives, and then you are finding out whether they have breast cancer later.

133
00:14:34,850 --> 00:14:40,159
Okay. So the advantage is here. Your exposure is measured before disease onset.

134
00:14:40,160 --> 00:14:47,809
So at baseline, when you're assessing exposure, you nobody has your disease because you impact non disease people, right?

135
00:14:47,810 --> 00:14:50,629
So if you were asking people about their exposures,

136
00:14:50,630 --> 00:14:55,880
they should not be answering differently based on whether they're going to get cancer or not because they would have to have a first of all,

137
00:14:57,200 --> 00:14:59,120
to know if they were going to get cancer or not. Right.

138
00:15:02,120 --> 00:15:08,540
The one thing we do worry about in cancer studies that I alluded to a little bit before is if you take a lot of times we'll take blood

139
00:15:08,540 --> 00:15:14,870
samples from people at baseline or some kind of biological sample from people at baseline when they say they don't have disease.

140
00:15:16,160 --> 00:15:21,229
And then maybe six months later they get diagnosed, well, they probably actually have the cancer.

141
00:15:21,230 --> 00:15:27,469
When you took their blood, they just didn't know. Right. This is kind of that cancer is one of those things that has a long latency period.

142
00:15:27,470 --> 00:15:33,740
And we don't always know. Right. When people have it, especially with some cancers we don't know about early, early disease.

143
00:15:33,740 --> 00:15:34,010
Right.

144
00:15:34,670 --> 00:15:42,979
So you could imagine that there are some biologic changes or things going on that are being caused by the cancer rather than the other way around.

145
00:15:42,980 --> 00:15:50,990
And so sometimes we institute a bit of a lag period in our analysis and we'll only look at cases that happened two years after baseline or something,

146
00:15:50,990 --> 00:15:54,200
particularly for like biologic specimen analysis. Right?

147
00:15:55,640 --> 00:16:03,020
That makes sense. But in theory, you've got non disease people, you're asking them all this stuff and then they go on to get disease.

148
00:16:03,020 --> 00:16:10,370
But again, special consideration for cancer. And sometimes we institute that lag because people might have disease and not know it.

149
00:16:11,090 --> 00:16:15,200
Right. You have to be thoughtful about whether that might matter for the exposure that you're interested in.

150
00:16:16,120 --> 00:16:22,510
Okay. So if you select an exposure, like I mentioned, you can look at four exposures, right?

151
00:16:24,310 --> 00:16:26,650
And you can look at multiple diseases and multiple exposures.

152
00:16:26,650 --> 00:16:30,970
When people spend the money to put together one of these cohort studies, it is expansive.

153
00:16:32,290 --> 00:16:36,129
Like we just got the grants, let's go to my parents and we're doing it on a shoestring.

154
00:16:36,130 --> 00:16:42,070
Let me tell you, we did not put together the Cadillac of budgets and it's like a $13 million grant.

155
00:16:43,880 --> 00:16:49,070
So this is not chump change if you're going to spend the effort and the time and the money to put one of these together,

156
00:16:49,070 --> 00:16:53,690
you're going to ask about everything you can, all exposure.

157
00:16:53,690 --> 00:16:56,810
As you can imagine, you're going to try to build as much into that as you can.

158
00:16:57,530 --> 00:17:01,280
We are mostly interested in cancer, but we are certainly going to assess other things, right?

159
00:17:01,520 --> 00:17:07,639
Our cardiovascular disease colleagues will be able to look at cardiovascular diseases like diabetes, you know, prior to any chronic disease.

160
00:17:07,640 --> 00:17:11,570
You can think that we're going to try to be able to look at this.

161
00:17:11,960 --> 00:17:13,880
Right. So you don't put all of these things together, be like,

162
00:17:13,880 --> 00:17:19,080
I'm looking at this one exposure of this one disease and I'm spending $13 million to do just that, right?

163
00:17:19,100 --> 00:17:20,239
I mean, if you're doing this,

164
00:17:20,240 --> 00:17:26,930
you're going to try to do it right and get as much as you can and make this a really useful tool for a lot of different things.

165
00:17:29,360 --> 00:17:32,450
Okay. So limitations, like I said, these are expensive, right?

166
00:17:33,380 --> 00:17:37,550
These are huge undertakings. They go on for a long, long time.

167
00:17:37,550 --> 00:17:47,600
So if things change over time, like changes in exposure or diagnostic criteria for your disease or something, it can really kind of mess things up.

168
00:17:47,830 --> 00:17:57,980
Right. We talked about some diseases that have had changes in diagnostic criteria over time like dementia or autism, for example.

169
00:17:58,010 --> 00:18:01,040
Autism spectrum disorder has changed quite dramatically over time.

170
00:18:01,400 --> 00:18:10,760
Right. So if you had a cohort study that spanned from like the early eighties until now and you were looking at autism diagnosis,

171
00:18:11,960 --> 00:18:16,850
it might be quite different over time. Right. Exposures can change, too.

172
00:18:17,300 --> 00:18:20,840
Right. And the way we classify exposures can change.

173
00:18:21,290 --> 00:18:24,769
So you just have to be thoughtful about that because these things go on for so long.

174
00:18:24,770 --> 00:18:31,310
I mean, the exposure status example that I think we talked briefly about earlier was like oral contraceptives.

175
00:18:31,490 --> 00:18:40,900
Right. The women who are getting cancer now, when they took oral contraceptives, it was a completely different pill than what we're taking today.

176
00:18:41,000 --> 00:18:47,370
Right. So those things can change. The average life.

177
00:18:49,460 --> 00:18:51,680
You know, people keep on going as long as they can.

178
00:18:51,710 --> 00:18:59,810
I think we have started to for example, the ABC study is a cohort that I worked with when I was in my post-doc.

179
00:18:59,810 --> 00:19:07,670
It's an NCI cohort of almost 30,000 men from Finland and they were all smokers because it was meant to study lung cancer.

180
00:19:07,820 --> 00:19:12,290
So they wanted to enrich for people who were going to get lung cancer. So they're starting to have enough.

181
00:19:12,290 --> 00:19:19,420
And it was started in the early eighties. There suddenly have enough of those men die that it's not worth following that.

182
00:19:20,120 --> 00:19:27,409
So it's set. I mean, if you have a successful cohort, you're going to try to follow these people until they're done or until enough of them have died,

183
00:19:27,410 --> 00:19:30,740
that it doesn't really make sense to put the resources continuing to follow them.

184
00:19:31,820 --> 00:19:36,799
Does that make sense? So that was a lot of the cool kids were clipboards.

185
00:19:36,800 --> 00:19:40,520
The final words were started in, let's just say mid eighties.

186
00:19:40,730 --> 00:19:44,510
Let's say 85. That's what, almost 40 years?

187
00:19:46,260 --> 00:19:50,220
Yeah. I mean, you're going to follow him as long as you can. You're not going to give up on it if you can, okay?

188
00:19:50,820 --> 00:19:56,910
Because even if you can't send out more questionnaires to ask or collect more samples or do any more, you know,

189
00:19:56,910 --> 00:20:03,180
if you don't have money for that, you're at least going to find scrounge up the money to live with like the national Democrats on Capitol.

190
00:20:03,600 --> 00:20:08,940
Right. Just to find out if they're going to cancer and to find out who the guy is, then he can still use all the data collected.

191
00:20:09,600 --> 00:20:14,340
Right. And you know what happens to that? Yeah.

192
00:20:19,760 --> 00:20:26,420
Okay. This is kind of a theoretical concern that the ascertainment of the outcome can be influenced by knowledge of exposure status.

193
00:20:27,740 --> 00:20:35,690
This would require that the investigator who is really interested in the exposure and one exposure in

194
00:20:35,690 --> 00:20:41,630
particular was also assessing the outcome and if they knew the exposure status before they went and did that.

195
00:20:42,680 --> 00:20:50,749
In my experience, this is very unlikely to happen in a cohort study because you're assessing multiple exposures and the people who are assessing

196
00:20:50,750 --> 00:20:59,730
the outcomes are usually like staff who are medical record review experts or staff who are doing a lot of like data linkage.

197
00:20:59,750 --> 00:21:03,530
They're not really like the peers who are coming up with the research questions.

198
00:21:04,250 --> 00:21:06,590
So, I mean, I think in theory that can happen.

199
00:21:07,370 --> 00:21:15,440
But in practice, in a big cancer cohort where you're studying so many different things and your study team is so big, it's probably not a real issue.

200
00:21:16,280 --> 00:21:20,620
Does that make sense? Okay. Now,

201
00:21:20,620 --> 00:21:23,799
I told you that these are better for selection bias because you're getting your cohort

202
00:21:23,800 --> 00:21:27,680
following over time where you can you're not like picking controls to go with it.

203
00:21:27,700 --> 00:21:33,070
So in a case control study, the big nasty part for selection bias is how you pick your controls.

204
00:21:34,090 --> 00:21:39,400
Picking controls that came from the same source population as the cases is very tricky.

205
00:21:40,840 --> 00:21:46,420
You don't really have that problem in cohort studies, but where you can get selection bias is if you have a lot of loss to follow up.

206
00:21:47,080 --> 00:21:52,780
If you are losing people and you're not finding out what happened to them with respect to their cancer or their death,

207
00:21:53,080 --> 00:21:58,660
and they're just falling out of your study and you don't know what happened, if that is different by exposure.

208
00:22:00,250 --> 00:22:03,340
So if you're exposed, people are much more likely to be lost.

209
00:22:03,790 --> 00:22:06,990
You can have a real selection bias problem. Right.

210
00:22:07,770 --> 00:22:14,909
So. You really want to maximize follow up in your cohort study the all the cohort

211
00:22:14,910 --> 00:22:17,520
studies that I've been mentioning to you in all of their methods sections,

212
00:22:17,520 --> 00:22:21,600
they all say we have 95 or better percent complete follow up because they pay

213
00:22:22,620 --> 00:22:26,900
people whose entire job it is to follow their cohort members and not themselves.

214
00:22:29,470 --> 00:22:34,220
Right. They'll send in their big follow up questionnaire.

215
00:22:34,790 --> 00:22:38,449
If they don't answer, they send it again. And if they don't answer it, they'll send them a short one.

216
00:22:38,450 --> 00:22:42,060
That's like, just tell us if you have cancer, which is very important.

217
00:22:43,130 --> 00:22:48,110
And if they don't answer that, they'll call them on the phone. And if they don't answer the phone again, right.

218
00:22:48,530 --> 00:22:53,299
Like they will bug the crap out of these people until they at least just find out.

219
00:22:53,300 --> 00:22:57,440
Have you had cancer since we sent you this last questionnaire? Because that's the key.

220
00:22:57,440 --> 00:23:00,890
That's the key that you need to know, are you alive and have you had cancer?

221
00:23:02,600 --> 00:23:09,589
So those are kind of the things. Okay. You can also have changes in study staffing that can affect how the data is collected.

222
00:23:09,590 --> 00:23:13,400
Right. You're not probably not going to have the same staff people on a study for 40 years.

223
00:23:13,430 --> 00:23:20,809
Right. Um, the volume of data and biological specimens that you're collecting and these, I mean, keep in mind when we're talking about cancer cohorts,

224
00:23:20,810 --> 00:23:29,240
I didn't really make this point earlier, but you need at least tens of thousands of participants to have a study that is powered to study cancer.

225
00:23:31,550 --> 00:23:37,730
If not hundreds of thousands of BTC is one of the smallest tax records I know of.

226
00:23:37,730 --> 00:23:42,559
It is 30,000 people, health professionals. It's like 57,000 nurses.

227
00:23:42,560 --> 00:23:47,440
It's like 75,000 women. I mean, these are big states, right?

228
00:23:47,450 --> 00:23:54,229
And so if you imagine we used to now things are more electronic.

229
00:23:54,230 --> 00:24:00,050
When I was working at the American Cancer Society in 2000, 2005, there was a room.

230
00:24:01,070 --> 00:24:07,340
It was about the size of this room. There was nothing but those shelves that like, have you ever been in the library stacks?

231
00:24:07,340 --> 00:24:11,630
And they've got their shelves that she can like turn the things and they move all medical records

232
00:24:12,590 --> 00:24:16,210
where people had said that they got cancer and they had requested their medical records.

233
00:24:16,220 --> 00:24:20,770
It was paper medical records and it had like a big lock on the door and you couldn't go in and but you had access,

234
00:24:20,790 --> 00:24:26,990
all the stuff, whole room in the building for nothing but medical records for the records, biological specimens.

235
00:24:27,980 --> 00:24:32,720
Who you want to get three vials of blood on 50,000 people.

236
00:24:34,040 --> 00:24:38,359
That's a lot of freezers that are have a generator to you,

237
00:24:38,360 --> 00:24:44,179
but you better actually just pay a freezer farm because they've got backup generators and they can make sure that they're keeping track of everything.

238
00:24:44,180 --> 00:24:50,149
Because if you spent all that time and money collecting it, you don't want a power outage to make it all absolutely useless.

239
00:24:50,150 --> 00:24:53,180
Right. But you're paying for those freezers.

240
00:24:54,380 --> 00:24:59,420
You're paying for the freezers. They're paying to store the samples and got to have a big room somewhere to put the freezers out.

241
00:24:59,990 --> 00:25:06,230
Like, that's not trivial. Right. And if you're going to store these things, I mean, you going to be storing in 40 years, right?

242
00:25:07,040 --> 00:25:10,490
That's a long time to to keep a freezer farm up and running.

243
00:25:12,590 --> 00:25:17,719
So it sounds like like a trivial piece. We're just going to put these specimens in the freezer.

244
00:25:17,720 --> 00:25:26,300
Right. But maintaining freezer space for 40 years is not trivial, actually, in terms of money or effort.

245
00:25:28,700 --> 00:25:36,050
All right. So how many of you have seen this kind of picture before where we're showing, like, person time and exposure and events?

246
00:25:37,920 --> 00:25:43,790
Okay, so imagine we've got ten people in our cohort, we have a little bitty cohort and our outcome of interest is brain cancer.

247
00:25:45,020 --> 00:25:50,420
And we've got some people shown in red who were exposed to x rays and some people trying to blue who were unexposed.

248
00:25:51,230 --> 00:25:56,150
And then we follow them over time. So person one was enrolled and one year later they got brain cancer.

249
00:25:57,170 --> 00:25:59,120
Person two got brain cancer after four years.

250
00:25:59,840 --> 00:26:04,490
Person three Never got brain cancer at our five year follow up, which is how much follow up we currently have.

251
00:26:05,270 --> 00:26:07,730
Okay. And you can do that for all of these things.

252
00:26:08,840 --> 00:26:17,650
So then the way we measure things in a cohort study, we have person time, we actually have time to event data is what we call it.

253
00:26:17,660 --> 00:26:23,120
And that's very powerful because you can actually find out if you have more information, right?

254
00:26:23,150 --> 00:26:26,810
You don't just know if something happened, you know, when it happened, you know how quickly it happened.

255
00:26:26,900 --> 00:26:28,730
So there is that element as well.

256
00:26:29,630 --> 00:26:37,280
And so what we do is we look at the rate ratio, the incidence rate ratio, instead of just risk, we can actually look at the rate.

257
00:26:37,370 --> 00:26:42,889
Right. So what you do is you count up the number of exposed cases and the total amount of exposed person

258
00:26:42,890 --> 00:26:48,950
time and divide that by the number of unexposed cases divided by the unexposed person time.

259
00:26:49,130 --> 00:27:02,110
So in this case, you would have 1 to 3 exposed cases and one, five, ten, 12, 17 total person years that were exposed.

260
00:27:02,110 --> 00:27:04,450
Does that make sense? That's the number of years.

261
00:27:04,450 --> 00:27:10,100
So this person could be one person or this person for age would add them all up for your denominator.

262
00:27:12,590 --> 00:27:19,920
I'm not going to ask you to calculate that. But for those of you who like math, that's that is how you do it for cohort studies.

263
00:27:19,940 --> 00:27:26,809
So when modeling strategies, strategies are used in cohort studies, you will see people use Cox proportional hazards models generally,

264
00:27:26,810 --> 00:27:30,740
and you will see the measure of association that is reported as hazard ratio.

265
00:27:32,030 --> 00:27:37,670
You can interpret this exactly the same way as an author ratio is with any ratio measure of association.

266
00:27:38,150 --> 00:27:44,600
The null value is one greater than one means the exposed or increased risk of less than one user at decreased risk.

267
00:27:45,650 --> 00:27:54,710
Just know that when you see a hazard ratio, they have to have time to event data to create, had to have person time data to do this model.

268
00:27:55,460 --> 00:27:59,330
So if you see a hazard ratio reported, you got a prospective cohort study, right?

269
00:28:03,250 --> 00:28:06,069
And if you take, you know, a bio stats class,

270
00:28:06,070 --> 00:28:10,299
you'll learn all the ways that this is actually different than an incidence rate ratio, different than an odds ratio.

271
00:28:10,300 --> 00:28:16,690
But for the purposes of this class, when you're reading the papers and trying to kind of understand what they're saying about your cancer,

272
00:28:16,690 --> 00:28:20,140
for example, just know that you can kind of read them and interpret them all the same way.

273
00:28:20,200 --> 00:28:24,100
Yeah. All right.

274
00:28:24,820 --> 00:28:28,120
I've mentioned this example before, the nurses health study.

275
00:28:28,150 --> 00:28:37,450
I lied about how many it was, though I was mistaken. It was established in 1976 and they have 121,700 nurses that they have recruited, age 30 to 55.

276
00:28:37,990 --> 00:28:49,060
As of 2000, only 6% were lost. To follow up, that is a lot of work by a lot of people to not lose more than 6% over 25 years.

277
00:28:49,840 --> 00:28:53,050
Wait 24 years. I do the math, right? Yes, I did.

278
00:28:54,490 --> 00:29:00,490
All right. And they have lots of information on all kinds of exposures, including past and current smoking habits, medical history and diet.

279
00:29:00,880 --> 00:29:06,190
Kind of the brothers study, too. This is the health professionals follow up study, which was established in 1986.

280
00:29:06,880 --> 00:29:12,530
They have 51,529 men aged 40 to 75 and enrollment again, only 6% lost.

281
00:29:12,530 --> 00:29:18,050
To follow up as of 2002. They have lots of detailed information on all kinds of the same sorts of.

282
00:29:20,830 --> 00:29:27,130
This is you guys know about and i. Reporter This is a fun way to spy on your professors.

283
00:29:28,860 --> 00:29:36,420
You can go to an H reporter and you can type in people's names and you can see the grants that they've gotten and how much they were for.

284
00:29:38,070 --> 00:29:41,230
And it's all because it's public information. It's your your tax dollars. Right.

285
00:29:41,250 --> 00:29:45,900
Are paying for these. So. So if it's a federally funded NIH grant, they tell you how much it was worth.

286
00:29:46,560 --> 00:29:55,800
This is what will it. He is the pi of a bunch of these cohorts at Harvard.

287
00:29:56,940 --> 00:30:00,959
So this was the title of cancer epidemiology cohort of male health professionals.

288
00:30:00,960 --> 00:30:09,690
So this is for two years of funding, but the beginning date was 25 years of funding 2012, and the end date is 2017.

289
00:30:09,690 --> 00:30:17,490
So this is five years of funding to follow an existing cohort for five years and the direct costs are over $2 billion.

290
00:30:18,960 --> 00:30:24,390
That's to pay the people who look up the medical records and call the people when they don't respond.

291
00:30:24,870 --> 00:30:29,100
And to pay the people who manage the databases and to pay for the freezer farm for all the samples.

292
00:30:30,060 --> 00:30:35,280
Right. This is those 51,000 men that they recruited in 1987.

293
00:30:35,670 --> 00:30:41,520
Following them for five more years costs over $2 million. These are not sheep enterprises.

294
00:30:43,090 --> 00:30:46,600
Right. Okay.

295
00:30:47,530 --> 00:30:53,710
So when you assess things and measure things in a cohort study, you want to make sure that you're doing appropriate and accurate measurements, right?

296
00:30:55,030 --> 00:31:02,050
You might do you know, you might try to find things from more objective sources if you can.

297
00:31:02,080 --> 00:31:06,700
Right. So you might try to get people's medical records rather than follow up interviewing them.

298
00:31:07,630 --> 00:31:10,570
Now, not everything is recorded super well in the medical record.

299
00:31:10,930 --> 00:31:16,480
Some things you might get much better information about if you interview people for some of the questions.

300
00:31:17,590 --> 00:31:23,620
Do you guys think of anything like that where you think you might get better data from a questionnaire that you designed than from the medical record?

301
00:31:34,950 --> 00:31:39,159
Yeah. You're doing the qualitative. Yeah.

302
00:31:39,160 --> 00:31:48,060
So, like, for example, what are you thinking about asking? If you're inquiring about somebody experience with.

303
00:31:48,900 --> 00:31:52,220
The health care system. Yeah, for sure. That's not going to be in the medical record at all.

304
00:31:52,230 --> 00:31:55,370
Right? Yeah.

305
00:31:55,770 --> 00:32:00,450
Like, unrelated to cancer, but, like, mental health thing for sure.

306
00:32:00,480 --> 00:32:06,150
Mental health for sure. One thing related to cancer that I always think about is.

307
00:32:08,350 --> 00:32:13,750
Smoking when they ask about what you get from the medical record is are you currently smoking yes or no?

308
00:32:14,800 --> 00:32:18,820
Which is not. When we do our smoking, I'm sure you're going to find out that that's like smoking about right.

309
00:32:19,270 --> 00:32:22,749
You want to know what age did you start? On average, how many cigarets per day did you smoke?

310
00:32:22,750 --> 00:32:26,530
Did you smoke menthol cigarets or just plain cigarets? Did you smoke?

311
00:32:26,890 --> 00:32:30,070
Um, you know, did you quit and then start again?

312
00:32:30,250 --> 00:32:32,590
Like kind of what's your lifetime history of smoking, right?

313
00:32:32,860 --> 00:32:38,290
And then a lot of people like their doctor, like my colleagues who study smoking related cancers,

314
00:32:38,290 --> 00:32:41,530
tell me, oh my, all my patients quit in the parking lot and then they start, get them, they leave.

315
00:32:42,940 --> 00:32:48,429
So they're a little bit a little jaded about the smoking responses that they get.

316
00:32:48,430 --> 00:32:51,219
So, you know, you may not be getting accurate information, number one.

317
00:32:51,220 --> 00:32:56,860
And number two, you may you're certainly not even if they're not telling lies or, you know,

318
00:32:57,040 --> 00:33:02,169
stretching the truth about their smoking, currently, you're not getting a thorough history.

319
00:33:02,170 --> 00:33:05,979
Right. So there's all kinds of stuff like that. Right. And some stuff is great in the medical record.

320
00:33:05,980 --> 00:33:12,309
Right. But that's not one of them. So you have to be thoughtful about the best way to collect your your information.

321
00:33:12,310 --> 00:33:18,580
And the best way is always. These sources that people think are more objective, right?

322
00:33:19,270 --> 00:33:23,590
Interviewing is sometimes the best way. Questionnaires are sometimes the best way.

323
00:33:24,520 --> 00:33:29,880
All right. We talked about some of this already.

324
00:33:30,240 --> 00:33:36,060
All right. So we talked about how you're selection bias is usually minimized.

325
00:33:36,330 --> 00:33:43,410
Right. In cohort studies. You can introduce it if you're doing the selecting on exposure status thing.

326
00:33:43,890 --> 00:33:48,030
Right. That has the same pitfalls as selecting a disease status for a case control study.

327
00:33:48,030 --> 00:33:54,960
But if you're doing kind of the more regular case, the more kind of regular cohort approach selection bias at the beginning, not a problem.

328
00:33:55,290 --> 00:33:57,629
What you really want to do is minimize your loss of follow up,

329
00:33:57,630 --> 00:34:02,040
because if that is differential by exposure in disease status, you have a problem potentially, right?

330
00:34:02,640 --> 00:34:04,830
And you're not going to know if it's differential or you're just going to know

331
00:34:04,830 --> 00:34:08,040
that you've lost like 60% of your people and you probably have a problem.

332
00:34:10,980 --> 00:34:20,910
Information bias can still be a problem, right? This is one that isn't really minimized by doing a cohort study,

333
00:34:20,910 --> 00:34:27,930
except you're probably not going to have recall bias or differential information bias.

334
00:34:28,020 --> 00:34:33,360
Right. Because people when they're giving you the information, they don't know about their case status yet because of that.

335
00:34:34,500 --> 00:34:38,069
So it's very difficult to imagine a way in which people would report something

336
00:34:38,070 --> 00:34:41,070
differently based on whether some day they're going to become a cancer case or not.

337
00:34:41,100 --> 00:34:47,880
Right. So if you're collecting the data before they ever become a case, any information bias is very likely to be non differential.

338
00:34:49,410 --> 00:34:52,860
So you can predict that it will bias toward the null. Right.

339
00:34:52,980 --> 00:34:58,650
And generalizability, of course, is always a problem and it is a huge problem in cancer and cancer cohort studies.

340
00:34:58,650 --> 00:35:02,760
Right. Most of the cancer cohorts that are mature at this point and on which we have most of

341
00:35:02,760 --> 00:35:07,800
our published data were begun in the eighties and nineties and are largely white,

342
00:35:08,040 --> 00:35:12,960
for example. So that is clearly a generalizability problem.

343
00:35:13,560 --> 00:35:17,090
The multiethnic cohort is a counterexample.

344
00:35:17,190 --> 00:35:24,540
They were recruited equal numbers of white, black, Asian, possibly Hispanic.

345
00:35:24,540 --> 00:35:32,819
But I think one black Asian were there three groups of most interest and maybe Hispanic?

346
00:35:32,820 --> 00:35:38,430
Two, never mind at least white, black, Asian. So they made an effort to get this multiethnic group.

347
00:35:40,020 --> 00:35:43,709
And then the Southern Committee cohort study was begun in the early 2000.

348
00:35:43,710 --> 00:35:47,610
So that is starting to develop cases and have more people in it.

349
00:35:48,210 --> 00:35:54,660
That was they tried very hard to get largely a big black population in that in that group.

350
00:35:56,610 --> 00:36:01,230
The new X cohort cancer prevention study three that they can just put together,

351
00:36:01,260 --> 00:36:08,579
that's like 300,000 and some people in it, they are making a big effort to try to get more a more diverse cohort.

352
00:36:08,580 --> 00:36:13,950
And so they have a larger proportion of black people. And like I said, in my cares, we are recruiting.

353
00:36:14,250 --> 00:36:19,090
Hopefully the plan is to recruit equal numbers of white, black, Hispanic and Middle Eastern, North African.

354
00:36:23,470 --> 00:36:28,970
Okay. So that is cohort studies.

355
00:36:29,660 --> 00:36:35,960
And now we arrive at the tippy top of the evidence pyramid, the randomized controlled trial.

356
00:36:37,850 --> 00:36:45,350
Everybody thinks these are the best answer, right. So trials are interventions that are designed and applied to improve the health of populations.

357
00:36:45,500 --> 00:36:49,160
Investigators are responsible for allocating subjects to the different study groups.

358
00:36:49,220 --> 00:36:52,610
So essentially you can think of a randomized controlled trial as a cohort,

359
00:36:53,480 --> 00:36:57,890
but rather than people choosing their own exposure, you are assigning them to the exposure.

360
00:36:59,260 --> 00:37:05,200
All right. The follow up period, there is a follow up period that will be instituted to evaluate the outcomes of the intervention.

361
00:37:05,200 --> 00:37:10,330
And what you want to do is understand disease status and the effectiveness of the interventions.

362
00:37:10,520 --> 00:37:13,670
Okay. I'm going to ignore that.

363
00:37:14,060 --> 00:37:20,000
So you are randomly allocating your subjects to exposure so there cannot be any selection bias.

364
00:37:21,400 --> 00:37:27,700
Right. The way your people are selected into the study, by definition cannot have anything to do with exposure status.

365
00:37:29,230 --> 00:37:33,490
You are breaking that association because you are assigning it randomly.

366
00:37:34,000 --> 00:37:39,520
So there cannot be any selection bias because you are randomly allocating people to exposure.

367
00:37:40,690 --> 00:37:44,320
You are breaking any. Remember a confounding triangle.

368
00:37:46,740 --> 00:37:50,660
I pick through the dirty towels again, Donna. Okay.

369
00:37:50,660 --> 00:37:58,010
Remember that confounding triangle we've got? You're interested in accessing assessing the relationship between exposure and disease,

370
00:37:58,010 --> 00:38:03,700
but you might give the wrong answer if your exposure is associated with this third factor conceptual confounder.

371
00:38:04,250 --> 00:38:07,700
You are breaking this association.

372
00:38:09,170 --> 00:38:14,720
You cannot have any association between exposure and something else because you are randomly assigning the exposure.

373
00:38:16,070 --> 00:38:23,750
So you won't have confounding. And if you are double blinding, you can't have measurement bias.

374
00:38:23,930 --> 00:38:25,729
You could have a bad measurement,

375
00:38:25,730 --> 00:38:31,940
but you can't have it being related to exposure disease status if you're people are blinded who are doing the measurements right.

376
00:38:34,700 --> 00:38:39,049
That makes sense. You guys know double lining is single.

377
00:38:39,050 --> 00:38:44,959
Blinding is where the participants don't know what they're getting. They don't know if they've gotten the introduction or the placebo.

378
00:38:44,960 --> 00:38:51,650
Right. Double blinding is where the investigators also do not know.

379
00:38:51,740 --> 00:38:59,180
Right. So that when they are assessing the outcome, they can't know what the exposure is and therefore they can't be accidentally or on purpose.

380
00:39:00,610 --> 00:39:03,940
Changing the way that they assess outcome based on whether people were exposed or not.

381
00:39:06,960 --> 00:39:12,180
Okay. And you can study multiple outcomes. You can also study multiple exposures in a trial.

382
00:39:12,780 --> 00:39:22,020
If you study an exposure, so say you have a big group of people you're I don't know, randomizing them to say it's a cancer Cambridge trial.

383
00:39:22,350 --> 00:39:28,830
Randomizing them to a vitamin B, vitamin E. Right. And you want to see if people who get the vitamin E are less likely to get cancer.

384
00:39:29,610 --> 00:39:32,590
What if I want to study? But we collected all these other things at baseline.

385
00:39:32,740 --> 00:39:37,559
We collected their their exercise habits, we collected BMI, we collected their smoking.

386
00:39:37,560 --> 00:39:41,700
So what if I want to look at smoking and cancer in these people? Can I do that?

387
00:39:44,760 --> 00:39:48,390
What kind of study is it? Is that a trial?

388
00:39:53,280 --> 00:39:57,419
So we've assessed smoking status before they ever have cancer because we got cancer free people,

389
00:39:57,420 --> 00:40:02,150
we allocated them to our vitamin and were following them over time for cancer outcomes.

390
00:40:02,160 --> 00:40:07,590
Now instead of looking at the vitamin which we allocate, I'm looking at smoking, which is something they chose for themselves.

391
00:40:08,700 --> 00:40:15,990
So we had an exposure that was assessed in healthy people that we're looking at over time, but I didn't allocate them to a picture of themselves.

392
00:40:16,020 --> 00:40:19,110
What study design is that as a cohort?

393
00:40:19,410 --> 00:40:26,520
Absolutely. Randomized controlled trials are cohorts for any exposure that is not from randomized exposure.

394
00:40:29,970 --> 00:40:36,780
Yeah. All right.

395
00:40:37,980 --> 00:40:41,010
These are super expensive, particularly if they're large.

396
00:40:41,520 --> 00:40:45,690
If they are cancer incidence related, they're going to be enormous.

397
00:40:46,050 --> 00:40:51,780
Now, cancer outcomes, a lot of trials in the cancer world are in patients.

398
00:40:51,790 --> 00:40:55,110
Right? Like you have a group of patients and you're looking at a treatment.

399
00:40:55,770 --> 00:40:59,520
You're randomizing them to a treatment or not or some new treatment versus the old treatment.

400
00:40:59,530 --> 00:41:03,900
Right. You need far fewer patients for that because your outcome.

401
00:41:04,050 --> 00:41:13,040
What is your outcome in those trials? What is the thing you're looking at?

402
00:41:13,050 --> 00:41:16,080
They all have cancer. What's the outcome? What is the effect?

403
00:41:18,770 --> 00:41:24,390
If you're trying to prevent your treatment. Sure.

404
00:41:24,410 --> 00:41:31,730
Death or maybe progression or, you know, you want to have them at that more time until they got something like that.

405
00:41:31,770 --> 00:41:38,340
So that is not rare. Death in cancer patients, particularly in some cancers, is not there.

406
00:41:38,360 --> 00:41:42,530
Right. So you don't need as many people as you do if you're going to recruit a group of

407
00:41:42,530 --> 00:41:46,310
healthy people and you want to look at incidence of cancer in healthy people.

408
00:41:46,880 --> 00:41:54,050
You need a huge study because it is rare if you want to look at death or outcomes in cancer patients.

409
00:41:54,530 --> 00:41:58,100
You can have far fewer people. Right? So those trials are smaller.

410
00:41:59,900 --> 00:42:05,140
Okay. You can have ethical problems, right? You can't randomize people to things you hypothesize might be harmful.

411
00:42:05,150 --> 00:42:09,740
So observational studies will always have a place in cancer epidemiology.

412
00:42:11,680 --> 00:42:18,610
The other issue that comes up is not treating the control group. So it used to be when you did a trial, you would do your drug versus placebo.

413
00:42:19,450 --> 00:42:23,409
You actually cannot ethically do that if there is an existing treatment.

414
00:42:23,410 --> 00:42:30,820
And for most cancers, there is something, right. So what you're doing is you're comparing your new treatment to the standard of care, right?

415
00:42:31,450 --> 00:42:37,280
And so it makes it harder to see differences, right? Because your new treatment may only be a small amount better.

416
00:42:38,530 --> 00:42:42,040
So you might need a bigger study to be powered to see that smaller difference.

417
00:42:42,040 --> 00:42:52,360
But you can randomize people to nothing if something isn't. It might be really difficult to ensure compliance and avoid contamination.

418
00:42:52,540 --> 00:42:57,640
So here is everybody's favorite example of this in the cancer world. How many people have heard of the placebo study?

419
00:42:57,730 --> 00:43:05,470
Anybody? Placebo stands for prostate one colorectal and ovarian cancer screening trial.

420
00:43:05,710 --> 00:43:10,030
Okay. So this was looking at screening tests for these four different cancers.

421
00:43:10,480 --> 00:43:23,530
So they actually randomized people to get the screening from the study yearly or at whatever intervals, appropriate versus standard of care.

422
00:43:24,610 --> 00:43:27,400
Because you can't tell them to do nothing if something exists. Right.

423
00:43:28,660 --> 00:43:37,480
So for the people who also started in 1982 and one of the tests that were at the test that they were looking at for the P for prostate was PSA.

424
00:43:38,380 --> 00:43:46,850
Anybody remember offhand when PSA became available? So they started doing so like, okay,

425
00:43:46,850 --> 00:43:52,910
we're going to randomize these men in our study to either get PSA every year from us or to get whatever their doctor recommends for them,

426
00:43:53,420 --> 00:43:56,880
which at the time had been just digital rectal exam, right?

427
00:43:56,930 --> 00:44:05,910
Just feeling the prostate with the finger through through the rectum. And then very quickly, PSA really took off in the population.

428
00:44:06,770 --> 00:44:10,969
So for the most part, for most of the partial follow up period,

429
00:44:10,970 --> 00:44:18,110
what they ended up doing was comparing men who were getting PSA from the PSA go to men who were getting PSA from their doctor.

430
00:44:19,490 --> 00:44:25,970
I'll tell you spoiler for the ending. They found no difference between the men that they randomized to screening of the men.

431
00:44:26,090 --> 00:44:31,070
They did not. And I think in you know, after years of study,

432
00:44:31,160 --> 00:44:35,870
everyone has decided that this is much less because PSA does nothing to prevent

433
00:44:35,870 --> 00:44:39,410
prostate cancer death and much more because they were comparing apples to apples.

434
00:44:40,580 --> 00:44:42,710
They were comparing men giving PSA to make any PSA.

435
00:44:43,730 --> 00:44:49,430
And it turns out that giving PSA from the placebo trial is not any different than getting it from your doctor at the doctor's office.

436
00:44:49,430 --> 00:44:50,640
But it's the same, right?

437
00:44:51,170 --> 00:44:57,710
So European trials where they didn't have so much contamination because they didn't begin doing population based PSA screening.

438
00:44:59,230 --> 00:45:05,880
See a big difference. Or some some significant difference between people, men randomized to get the PSA test, and many did.

439
00:45:07,560 --> 00:45:12,530
So they spent a ton of money and a ton of time to compare two groups.

440
00:45:12,540 --> 00:45:16,230
They were getting the exact same thing to each other and find nothing, which is very frustrating.

441
00:45:19,740 --> 00:45:26,980
So the kind of bias that this caused obviously is toward the not right. Because you are you have information bias essentially is what has happened.

442
00:45:27,000 --> 00:45:31,139
Right. You assign people to be yes screening, no screening.

443
00:45:31,140 --> 00:45:34,760
And instead what happened is you have. Yes, screening also. Yes, screening.

444
00:45:34,780 --> 00:45:43,740
Right. And because that is not different by outcome, you have non differential misclassification and bias toward the norm.

445
00:45:44,790 --> 00:45:49,610
Does that make sense to everybody? Okay.

446
00:45:50,240 --> 00:45:54,680
So there's also difficulty in recruiting certain certain certain ethnic groups.

447
00:45:55,400 --> 00:46:02,480
Most large trials are predominantly or exclusively white, and there is a huge push to try to get particularly more black participants in trials.

448
00:46:03,800 --> 00:46:08,690
I think it's clear that we have a longstanding difficulty recruiting black populations

449
00:46:08,690 --> 00:46:13,300
and some research studies for really valid and obvious reasons of mistrust.

450
00:46:13,490 --> 00:46:19,910
Right. So you guys have all taken kind of beers that you've all covered, for example, the study, right?

451
00:46:20,760 --> 00:46:29,510
Right. If that happened to people who looked like me and someone came in and was like, Hey, I have this government funded study, I want to enroll you.

452
00:46:29,510 --> 00:46:33,020
And I'd be like, No, thank you, actually. Hard pass, right?

453
00:46:33,740 --> 00:46:38,420
So totally makes sense. So we're working really hard to try to build trust with those communities again

454
00:46:38,810 --> 00:46:42,680
and to get more diverse populations into our studies and into our trials.

455
00:46:43,220 --> 00:46:49,549
Trials in particular can be tough because what kinds of hospitals do these big treatment trials,

456
00:46:49,550 --> 00:46:54,530
for example, is that your average neighborhood hospital?

457
00:46:56,180 --> 00:47:06,200
No, we're talking tertiary care centers like Michigan has some we have quite a few, but nothing compared to like Memorial Sloan Kettering or.

458
00:47:09,430 --> 00:47:12,790
And the innocent in Texas. Right. They do tons of these treatment trials.

459
00:47:14,110 --> 00:47:17,740
But if you want to go be treated on a trial, you have to be able to go there.

460
00:47:18,550 --> 00:47:21,820
Right. You have to be able to travel to M.D. Anderson.

461
00:47:21,820 --> 00:47:25,180
And most of the people who are able to do that are fairly well off. Right.

462
00:47:26,320 --> 00:47:32,020
So you end up with this higher group and of course, that intersects with race and ethnicity in this in this country.

463
00:47:32,210 --> 00:47:40,060
Right. And so that is part of the reason why we end up with some of these trials being having difficulty recruiting racial and ethnic minorities.

464
00:47:41,320 --> 00:47:42,760
Now, they are doing a lot of work.

465
00:47:42,760 --> 00:47:50,620
They've done a lot of work to make these kind of trial networks that include community hospitals so that they can recruit patients

466
00:47:50,620 --> 00:47:57,720
from some of these other places and institute their their protocols and other treatment protocols in these other hospitals.

467
00:47:57,790 --> 00:47:59,880
So if they can get a more diverse group of people. Right.

468
00:48:00,490 --> 00:48:05,200
So that is definitely something that is ongoing and that people are really working to try to address.

469
00:48:05,560 --> 00:48:10,870
But historically, that's kind of two of the big reasons why it has been difficult to recruit people.

470
00:48:12,390 --> 00:48:15,480
I mean, and sometimes you also have to come back, like usually you're coming back a lot.

471
00:48:15,480 --> 00:48:18,360
If you're being treated for cancer, you're coming back a lot and you wait to be treated.

472
00:48:18,360 --> 00:48:23,160
But sometimes you have to come back even more if you're enrolled in a study, and so it can be burdensome.

473
00:48:25,170 --> 00:48:30,420
Although one of the professors I got to, Johns Hopkins, ended up being the head of the cancer center there.

474
00:48:31,050 --> 00:48:33,629
And he always said, if you're if you need to be treated for cancer,

475
00:48:33,630 --> 00:48:38,880
you want to be in a trial because you know you're getting the best care no matter what, if you're on the protocol or not on the protocol,

476
00:48:38,880 --> 00:48:40,470
because if you're not on the protocol,

477
00:48:41,220 --> 00:48:48,870
there's a lot of scrutiny about whether you're providing the people not in the treatment group with the best standard, current standard of care.

478
00:48:48,870 --> 00:48:53,070
Right? So either way, you're kind of getting the best. But you can get.

479
00:48:56,690 --> 00:49:00,680
All right. Here's an example of a trial that I think went a bit awry.

480
00:49:02,730 --> 00:49:03,450
Provide a trial.

481
00:49:04,200 --> 00:49:10,620
So I've done a fair bit of work on vitamin D, and this the price of this rejoined Manson in July, appearing at Harvard Medical School.

482
00:49:10,740 --> 00:49:14,640
Smart, very smart, very capable, great epidemiologists.

483
00:49:15,510 --> 00:49:22,260
So they are recruiting or were recruiting has done now 20,000 women and men to look at all.

484
00:49:22,260 --> 00:49:30,120
And the outcomes they were powered for were all cardiovascular disease and all cancer with two separate outcomes, CVD and cancer.

485
00:49:32,070 --> 00:49:36,990
This already should concern you because I told you that cancer is not.

486
00:49:36,990 --> 00:49:40,620
What disease do you think it is appropriate to put together?

487
00:49:41,880 --> 00:49:46,020
Breast cancer. Colon cancer, lung cancer, pancreatic cancer, ovarian cancer and material cancer.

488
00:49:46,020 --> 00:49:51,000
And look at all of those things together as one outcome in relation to vitamin D.

489
00:49:54,080 --> 00:49:58,790
Right? Ideally, no. Trouble is, you have to recruit a lot more than 20,000.

490
00:49:59,240 --> 00:50:02,660
Now, this is men and women, assuming they're getting about half and half.

491
00:50:03,380 --> 00:50:05,840
You've only got 10,000 women to study breast cancer.

492
00:50:07,790 --> 00:50:13,010
You only get 10,000 men to study prostate cancer, so you have even fewer people to study the sex specific cancers.

493
00:50:14,730 --> 00:50:22,709
Okay. So they gave these people a combination of vitamin D 20 I use per day plus omega omega three versus placebo.

494
00:50:22,710 --> 00:50:27,690
And they did this in a two by two factorial design. Do you guys know what that is? It means there's four groups.

495
00:50:28,890 --> 00:50:36,960
There's placebo. Placebo plus vitamin D, placebo plus.

496
00:50:38,040 --> 00:50:41,070
Omega three and then vitamin D and omega three.

497
00:50:41,760 --> 00:50:46,979
Okay. And so what you can do with this is you can it's it's kind of a powerful design.

498
00:50:46,980 --> 00:50:54,709
You can capture groups. So like you can put these two together versus these two to look at vitamins or omega three versus No.

499
00:50:54,710 --> 00:51:02,400
Omega three. Right. And you can collapse. These two versus these two to look at vitamin D versus no vitamin D.

500
00:51:03,480 --> 00:51:09,720
And you can look at whether both together is more powerful than if you work with health workers separately.

501
00:51:11,760 --> 00:51:13,740
All right. And the supplement of these people for five years.

502
00:51:14,940 --> 00:51:21,930
However, please note, vital participants are allowed to take up to 800 days per day of vitamin D and study supplements should they choose to do so.

503
00:51:22,650 --> 00:51:26,790
Together with intake from food, which averages 200 to 300 times per day.

504
00:51:27,510 --> 00:51:30,930
Most participants can opt to consume at least 1000 items per day vitamin D on their own.

505
00:51:36,140 --> 00:51:39,750
I'm having shades of polka.

506
00:51:41,840 --> 00:51:49,069
Having positive flashbacks, right? Because you're not going to be comparing vitamin D, you're not going to be comparing people taking 2000.

507
00:51:49,070 --> 00:51:50,660
I use a vitamin E to people taking that.

508
00:51:52,220 --> 00:52:06,260
You're going to be maybe comparing a mix of people taking anywhere from 2000 to maybe 3000 to people taking maybe 200 to like 1000.

509
00:52:07,090 --> 00:52:12,510
Right. So that's not exactly yes and no.

510
00:52:14,120 --> 00:52:17,920
Right. Plus, you have all of this in here. Then you've got sun.

511
00:52:18,730 --> 00:52:23,230
Right. So if somebody is going if somebody in this group spends all day at the tanning booth,

512
00:52:23,230 --> 00:52:28,810
they're going to have really high vitamin D levels that are not reflected in their intake because sun exposure.

513
00:52:29,500 --> 00:52:34,880
Your skin makes vitamin D in response to sun exposure. Okay.

514
00:52:34,890 --> 00:52:45,980
So this is this is messy. And they found no association because they had all of this misclassification essentially right now, they didn't put this.

515
00:52:45,980 --> 00:52:51,920
The IAB made them do this. This trial is not going to be approved with a true placebo.

516
00:52:52,250 --> 00:52:56,630
We're telling the people that they couldn't take something that's on their own because everybody thinks vitamin D is good for everything.

517
00:52:57,410 --> 00:52:59,620
And an RV wouldn't let them tell people they couldn't take a supplement.

518
00:53:04,010 --> 00:53:07,640
They also don't have enough cases of individual cancers to look at them separately.

519
00:53:09,290 --> 00:53:14,840
So this is this is the problem, right? So when people tell you that trials are the best evidence,

520
00:53:15,050 --> 00:53:22,070
what you could do if you were not in my class and therefore learning how to do all of these things is you can say,

521
00:53:22,070 --> 00:53:27,979
well, the final trial was power to look at cancer and they found nothing with vitamin D.

522
00:53:27,980 --> 00:53:32,360
So we're done, right? Vitamin D does do anything for cancer. Put it to bed.

523
00:53:32,570 --> 00:53:37,040
It's the best evidence. Tippy top of the pyramid. We did a trial and we found nothing.

524
00:53:38,660 --> 00:53:46,040
But what they are studying is not vitamin D, high vitamin D status compared to low vitamin D status.

525
00:53:46,580 --> 00:53:56,389
Right. So they're getting the best answer, the most unbiased answer for the question that their study is asking,

526
00:53:56,390 --> 00:54:01,280
which is maybe not the question we really want the answer to that makes sense.

527
00:54:02,690 --> 00:54:06,679
Might also be the other problem with a lot of these cancer trials,

528
00:54:06,680 --> 00:54:12,830
particularly for like chemoprevention or prevention trials where you're looking at incidence of cancer, five years might not be long enough.

529
00:54:13,250 --> 00:54:20,540
Right. Or I don't remember exactly how old these people are, but maybe you are giving it at the right moment in their life.

530
00:54:20,540 --> 00:54:23,750
Maybe they need it during adolescence to prevent breast cancer.

531
00:54:24,650 --> 00:54:30,530
Maybe they need it in pregnancy. I don't know. Do you know what I mean? Like there's all of these different windows when it could be more effective.

532
00:54:30,530 --> 00:54:34,100
Maybe you gave it at the wrong time or for not long enough.

533
00:54:36,680 --> 00:54:48,500
Okay. Large scale studies. So this is kind of like when we do like multiple multicenter studies or you do pooled studies,

534
00:54:49,730 --> 00:54:59,000
so you might do this if you have a low prevalence of exposure. Honestly, when we do this in cancer studies, it's often because we have very few cases.

535
00:54:59,000 --> 00:55:02,270
So when people have done a lot of pooling of cohorts and cancer studies,

536
00:55:02,270 --> 00:55:07,249
for example, it's because usually they're doing it for the rare cancers first. Like ovarian cancer,

537
00:55:07,250 --> 00:55:11,840
there's a big ovarian cancer consortium where they put together a bunch of different studies with

538
00:55:11,840 --> 00:55:17,059
ovarian cancers so that they can get big numbers of this rare cancer that in an individual cohort,

539
00:55:17,060 --> 00:55:23,959
even a big one, you're going to have not that many. Right. So we've done this for ovarian of pancreatic and honestly, all cancers at this point.

540
00:55:23,960 --> 00:55:27,530
But it kind of started from that place of like you've got a really rare cancer that we need.

541
00:55:28,040 --> 00:55:32,120
We need more people to be able to look at these things and we need to pool our resources.

542
00:55:33,530 --> 00:55:38,189
Okay. So. There's kind of different ways of doing this.

543
00:55:38,190 --> 00:55:46,220
You can do a meta analysis, a pooled analysis or multicenter studies. I'm going to kind of like from easiest to hardest to sort of a meta analysis.

544
00:55:47,060 --> 00:55:52,520
Okay. Most of the meta analysis is essentially a formal combination of published results.

545
00:55:52,580 --> 00:55:58,670
So all these different cancer cohorts have published their fair paper looking at vitamin D and ovarian cancer.

546
00:55:59,000 --> 00:56:07,219
And what you do is you kind of go in, pull all the papers, and you get their odds ratio or their hazard ratio or whatever measure of association.

547
00:56:07,220 --> 00:56:12,770
And you essentially just do math, kind of average them together. You get like a weighted average of all their findings.

548
00:56:14,240 --> 00:56:17,780
Pooled analysis is where do you then go? Actually, I think we can do better.

549
00:56:17,960 --> 00:56:24,920
I'm going to call up all the people from all of these different studies, and I'm going to ask if they'll share their data with me.

550
00:56:25,430 --> 00:56:29,210
And I'm going to get the raw data from all these people, and then I'm going to analyze it together.

551
00:56:30,710 --> 00:56:33,790
Multicenter studies is where you're like, Actually, this isn't working for me.

552
00:56:33,800 --> 00:56:39,380
We're just going to start from scratch and start a giant study where we have multiple different centers that are all doing it the exact same way.

553
00:56:39,410 --> 00:56:43,520
We're going to collect data from a lot of different places at once.

554
00:56:45,150 --> 00:56:51,510
Okay. So like I said, this is this horrible combination of results from independently conducted and report studies.

555
00:56:51,810 --> 00:56:54,570
You're kind of assuming that these studies are comparable to each other.

556
00:56:55,410 --> 00:56:58,740
You're assuming that it's appropriate to just sort of mathematically combine them.

557
00:57:00,240 --> 00:57:04,229
So you're going to identify all these different studies, you're going to extract the effect estimates,

558
00:57:04,230 --> 00:57:09,460
calculate that combined effect, and then interpret it and things that we are really interested in here.

559
00:57:09,740 --> 00:57:16,560
Is there bias or heterogeneity? So heterogeneity is evidence that the studies don't belong to the same population.

560
00:57:17,580 --> 00:57:20,640
So you can have lots of different sources. Right.

561
00:57:21,390 --> 00:57:24,360
Effect modifiers. And I'm going to show you an example of this in a minute.

562
00:57:26,340 --> 00:57:32,610
You can have studies that have different like there's a true difference on some third factor,

563
00:57:32,610 --> 00:57:39,059
not the exposure or outcome between these studies and that the relationship between the explosion output is actually different.

564
00:57:39,060 --> 00:57:42,320
But is there. Okay.

565
00:57:44,410 --> 00:57:45,190
Study design.

566
00:57:47,050 --> 00:57:52,630
So maybe you have a mix of like case control and comfort study and you're actually getting different answers from those two different study designs,

567
00:57:53,230 --> 00:57:57,010
which would indicate that there is some bias in one of the study designs.

568
00:57:57,250 --> 00:58:02,160
Right. Or are the studies just a very, very different quality?

569
00:58:02,200 --> 00:58:07,700
Like, maybe some of them are adjusting for a lot of confounders and others aren't. Maybe some of them measured things very carefully.

570
00:58:07,710 --> 00:58:12,980
Others didn't, right? So if heterogeneity is president, you don't rule.

571
00:58:13,280 --> 00:58:20,749
You have to look at them separately. So the other source of bias that is possible in a meta analysis is publication bias,

572
00:58:20,750 --> 00:58:29,570
which is the preferential reporting and publication of positive results. This is not people lying and hiding their low results, honestly.

573
00:58:29,990 --> 00:58:34,760
A lot of times people a lot of times students think that this is intentional and it's not.

574
00:58:35,480 --> 00:58:40,310
It is incredibly difficult sometimes to get a null paper published because it's not interesting.

575
00:58:41,710 --> 00:58:48,640
Right. If you have a paper where you kind of find nothing and you say, Well, we looked at this thing and we found nothing.

576
00:58:49,270 --> 00:58:55,150
A lot of journals won't publish it just because the editor will send it back and say, Sorry, this is a fine, a priority for us.

577
00:58:56,650 --> 00:59:00,129
So I've had studies like that and I do think it's important to publish them

578
00:59:00,130 --> 00:59:03,850
for this kind of reason where you need null and positive results out there.

579
00:59:05,230 --> 00:59:08,980
It has taken me seven tries, seven different journals to get a paper published sometimes.

580
00:59:10,270 --> 00:59:14,169
There are some journals that have specific known results in brief sections where you can just submit an article.

581
00:59:14,170 --> 00:59:21,700
It's like, Hey, we did this briefly. We didn't find anything. So that's helpful because and that's partly in response to this kind of issue,

582
00:59:21,700 --> 00:59:27,609
but it's just difficult to get and if I have three other papers that I know are going to get published in a high

583
00:59:27,610 --> 00:59:33,790
impact journal because they have positive results and I'm prioritizing my time and I'm going up for tenure,

584
00:59:34,090 --> 00:59:37,989
which ones am I going to spend my time on? Am I going to go for seven journals for No.

585
00:59:37,990 --> 00:59:42,940
One and end up in like a very low journal?

586
00:59:44,140 --> 00:59:47,950
Or am I going to prioritize my time to get the things out there that I know we're going to look really good?

587
00:59:52,660 --> 00:59:55,150
So it's not that people are being sneaky.

588
00:59:56,350 --> 01:00:06,250
It's kind of a a byproduct of the system and how we're rewarded for doing research as investigators and also,

589
01:00:06,850 --> 01:00:11,170
you know, having limited time and prioritizing which things we're going to try to get out there.

590
01:00:11,440 --> 01:00:15,440
So this can this can be an issue. Okay.

591
01:00:16,250 --> 01:00:19,460
So you really need to adjust address sources of heterogeneity and bias.

592
01:00:19,670 --> 01:00:24,080
You need to apply proper statistical methods. So make friends with a statistician if you're not Matthew yourself.

593
01:00:25,190 --> 01:00:30,300
And interpretation should be driven by biological rather than statistical considerations.

594
01:00:30,350 --> 01:00:34,700
So here's an example of a meta analysis where they actually really did have important

595
01:00:34,700 --> 01:00:39,590
heterogeneity and heterogeneity with by the age of the participants in the studies.

596
01:00:41,080 --> 01:00:44,110
So they were looking at vitamin D levels and risk of breast cancer.

597
01:00:44,110 --> 01:00:47,320
And what they found is they actually had a very different result.

598
01:00:48,280 --> 01:00:53,230
While a somewhat different result, these are all pretty minor associations,

599
01:00:54,070 --> 01:00:59,709
but they actually found a different result in pre-menopausal breast cancer cases compared to post-menopausal breast cancer cases.

600
01:00:59,710 --> 01:01:04,150
And so they show them separately. So in the pre-menopausal cases, they really found nothing.

601
01:01:05,290 --> 01:01:13,450
The overall relative risk is .99, and you can see that the confidence interval spans one and they see this modest like

602
01:01:13,690 --> 01:01:18,270
decreased risk with higher vitamin D in the postmenopausal breast cancer cases.

603
01:01:18,280 --> 01:01:24,370
That's barely statistically. So if they found heterogeneity by something that kind of made sense.

604
01:01:26,290 --> 01:01:32,540
And then they showed the results separate. All right.

605
01:01:32,540 --> 01:01:36,680
How about pooled analysis where you combine raw data from independently conducted studies?

606
01:01:37,580 --> 01:01:40,980
So this is an improvement, right? It gives you increased flexibility in the use of the data.

607
01:01:41,000 --> 01:01:44,750
You can create comparable categories of exposure, outcome and confounders.

608
01:01:44,750 --> 01:01:48,050
So let's look at this really quick. If you look at this,

609
01:01:49,610 --> 01:01:56,179
they actually were able to do this in this in this in this meta analysis per five milligrams per mil increase in 25 hydroxy vitamin D.

610
01:01:56,180 --> 01:02:00,079
But a lot of times you are stuck with whatever category.

611
01:02:00,080 --> 01:02:11,989
When you're doing a meta analysis, you have say study one looked at quartiles, okay, so you have quartile four versus quartile one.

612
01:02:11,990 --> 01:02:14,990
You have an odds ratio for their fourth quartile versus their fourth quartile.

613
01:02:15,170 --> 01:02:20,900
Okay. This study was done in Florida, so their fourth quartile is people with vitamin D greater than 75.

614
01:02:21,320 --> 01:02:27,470
Okay. Then you have another study that published also quartiles great quartile four versus quartile one.

615
01:02:27,980 --> 01:02:34,790
But this study was conducted in Finland. So there quartile four is people who had greater than 40 because they live way

616
01:02:34,790 --> 01:02:38,180
up at higher latitudes and high vitamin D in that population isn't that high.

617
01:02:39,320 --> 01:02:43,790
All right. And then we had another pot, another study that did clinical categories.

618
01:02:43,790 --> 01:02:50,690
Right. So they just looked at greater then that's a lesson sign, sorry, greater than or equal to 50.

619
01:02:51,260 --> 01:02:51,530
Right.

620
01:02:52,070 --> 01:02:59,000
So we looked at high versus low and you're going to combine all of these estimates, the high versus low, the high versus low, the high versus low.

621
01:02:59,000 --> 01:03:05,330
And the kind of finding apples and oranges here. If you if you do a pooled analysis.

622
01:03:07,800 --> 01:03:11,970
You can actually create. You get the raw data so you can create the same categories in all of these.

623
01:03:11,970 --> 01:03:18,690
Right. Great. In this maybe this this study might have adjusted for age and race.

624
01:03:19,140 --> 01:03:24,210
This study adjusted for age, race, education, BMI, oral contraceptive use.

625
01:03:24,840 --> 01:03:31,780
This study didn't have any of that. They just adjusted for age. This may include physical activity, but this one didn't.

626
01:03:31,930 --> 01:03:41,170
So you have you're stuck with whatever they decided to adjust for in terms of confounders and the categories that they use could be very different.

627
01:03:41,890 --> 01:03:46,030
Right. So you can create your own categories of confounders.

628
01:03:46,840 --> 01:03:51,940
Right. That's nice. And you can use the same statistical methods everywhere.

629
01:03:52,360 --> 01:03:59,889
Right. One thing that's usually you can do in pooled analysis is that you can't always do in meta analyzes and stratified analysis.

630
01:03:59,890 --> 01:04:04,870
Right? So if you want to look in subgroups like say you want to look at white and black women separately,

631
01:04:04,870 --> 01:04:12,639
but you don't have enough women to do that in each individual study. They might not have presented those results in the individual studies for you

632
01:04:12,640 --> 01:04:16,090
to look at in a meta analysis because they didn't have enough people to do it.

633
01:04:16,090 --> 01:04:19,240
But if you get the pooled data, you suddenly have to do that.

634
01:04:19,960 --> 01:04:23,680
Right. So that is a big approach to pool analysis.

635
01:04:25,280 --> 01:04:28,430
All right. So you got to request the data from investigators.

636
01:04:29,540 --> 01:04:33,360
There's some possibility that some people will participate and others will choose not to.

637
01:04:33,380 --> 01:04:39,090
I will say that in cancer, this is. Normal, right?

638
01:04:39,090 --> 01:04:45,270
We just do this. And you want to be part of a consortium like if your study is invited, you want to be in it.

639
01:04:45,840 --> 01:04:54,250
If your study hasn't been invited, you are trying to get it right because it is it is a big it's it's important.

640
01:04:54,660 --> 01:04:58,620
It's part of being like kind of in the group that in the community of researchers.

641
01:04:58,620 --> 01:05:00,510
And so people will definitely do that.

642
01:05:00,540 --> 01:05:06,540
Now sometimes there is a little bit of like who we really want to get our individual paper out before the pool paper comes out.

643
01:05:06,540 --> 01:05:11,559
Because if your data is in a pool paper, you can't then go publish just your data, right?

644
01:05:11,560 --> 01:05:13,830
That's already out there as part of the pool paper.

645
01:05:14,580 --> 01:05:20,729
So sometimes there will be a little bit of like niggling about timing and people will rush to get their own paper out first and that kind of thing.

646
01:05:20,730 --> 01:05:24,060
But generally everybody wants to be okay.

647
01:05:25,560 --> 01:05:30,750
Then you have to do all the data quality control, the editing and harmonization and pooling.

648
01:05:33,060 --> 01:05:41,400
And this is an example of a project that just got I started this as a postdoc in 2013 and it got published last week.

649
01:05:44,080 --> 01:05:47,470
I can't tell you how glad I am. Have you seen my plate?

650
01:05:47,980 --> 01:05:51,790
These these things are huge undertaking. I mean, that's a little extreme.

651
01:05:51,790 --> 01:05:55,840
This one took a long time for various reasons, but these things are not fixed.

652
01:05:57,860 --> 01:06:01,180
They are the bane acts of studies. They are not fast.

653
01:06:01,930 --> 01:06:10,149
All right. So these were all the different studies we had. So we ended up with a total of about 12,000 cases of 14,000 controls.

654
01:06:10,150 --> 01:06:13,390
You can see there is no individual study that comes anywhere near that number.

655
01:06:13,630 --> 01:06:20,740
Right. So this is huge and this is more or less what we found.

656
01:06:21,430 --> 01:06:24,970
We were able to do IOM points. What do you guys think?

657
01:06:26,260 --> 01:06:29,990
Vitamin D and breast cancer. Yes. This is our represented.

658
01:06:30,020 --> 01:06:35,530
Right. Because this is what they say is replete. 50 to 70 nanograms per mil of vitamin D is replete.

659
01:06:35,530 --> 01:06:41,620
These are blood levels, not intake, very high levels of blood levels.

660
01:06:41,950 --> 01:06:47,610
And this is their risk of breast cancer. Should we all be taking vitamin D, ladies?

661
01:06:51,300 --> 01:06:56,260
Are you impressed? Are you wowed? Think you've found the answer.

662
01:07:00,210 --> 01:07:03,630
We have a. Which is important, right?

663
01:07:03,640 --> 01:07:07,800
Because if you do a very good study and this is also part of why it's taken for us

664
01:07:07,810 --> 01:07:11,050
now to get the damn thing published is because we didn't really find anything.

665
01:07:11,890 --> 01:07:14,560
Which I think is a very important public health message.

666
01:07:14,920 --> 01:07:20,560
Like everybody stop pretending like vitamin D is this panacea for all kinds of cancer and actually does nothing for breast cancer.

667
01:07:21,880 --> 01:07:29,460
No, it may do something for survival in patients. But for incidents or.

668
01:07:31,110 --> 01:07:35,189
But I will tell you that this is a huge undertaking.

669
01:07:35,190 --> 01:07:38,969
So this is a picture of our spreadsheet. These are all the different.

670
01:07:38,970 --> 01:07:40,830
These are shorthand for all the different cohorts.

671
01:07:42,150 --> 01:07:47,070
And this is the physical activity measure that they had and kind of whether it was a numeric or character variable.

672
01:07:49,980 --> 01:07:59,070
So in the Mac they had total metabolic equivalence of physical activity and physical total vigorous hours,

673
01:07:59,220 --> 01:08:04,470
total moderate hours, and like how many years they'd been doing it in 83.

674
01:08:04,470 --> 01:08:10,440
And they had leisure time, physical activity only, and occupational separately, not just total.

675
01:08:12,240 --> 01:08:17,670
And they had that as minutes or hours too, to again, they only have leisure.

676
01:08:17,670 --> 01:08:23,909
So they didn't ask about occupational. They only had leisure time. Just what day? Here.

677
01:08:23,910 --> 01:08:29,559
This is the epic cohort. They have leisure time. That's. Hear about the PSA.

678
01:08:29,560 --> 01:08:36,730
I was real fun. They just had hours of vigorous activity as a low, medium high.

679
01:08:37,720 --> 01:08:41,140
We had, like a check box for, like, less than this many hours.

680
01:08:41,140 --> 01:08:44,680
This man needed as many members spent a year or more. And you just check the box.

681
01:08:45,670 --> 01:08:48,459
So, like, all these other ones were calculating metabolic equivalents,

682
01:08:48,460 --> 01:08:54,250
which you get by asking about particular activities and how long they were doing them for each day.

683
01:08:54,260 --> 01:08:58,930
And that gives you like the number of metabolic equivalents per week that kind of integrates time and.

684
01:09:00,970 --> 01:09:13,540
Intensity. So. We had to decide how to create creative has got to be variable and harmonize that we could you know create in all these studies,

685
01:09:16,300 --> 01:09:22,540
you know, how many how many conference calls that was so many how many got and what we ended up having to do.

686
01:09:22,660 --> 01:09:26,469
What ends up happening is you'd end up dumbing your data down to the lowest common denominator.

687
01:09:26,470 --> 01:09:30,070
So our lowest common denominator here was this three category variable from possible.

688
01:09:31,000 --> 01:09:37,840
And so what we did is we created for these these studies have a very nice continuous, very well collected physical activity variable.

689
01:09:37,840 --> 01:09:44,560
We created Tertiles. So we had a 1 to 3 variable and that's how we adjusted for physical activity because that was the way we can harmonize it.

690
01:09:46,030 --> 01:09:49,480
It's a pain in the butt. Sounds like such a great idea.

691
01:09:50,020 --> 01:09:56,110
It is. It's really important to do. It is a giant pain in the butt to do pooled analysis.

692
01:09:57,970 --> 01:09:59,260
All right. You got to get cooperation.

693
01:09:59,260 --> 01:10:04,239
Investigators, you have to identify the relatives, relevant studies you might be dealing with participation bias,

694
01:10:04,240 --> 01:10:07,630
although in the cancer world, again, not a huge problem lately.

695
01:10:09,250 --> 01:10:13,720
And then you got to make the data comparable, which is a giant pain in the butt, as I just showed you.

696
01:10:15,280 --> 01:10:18,399
Okay. Multicenter studies.

697
01:10:18,400 --> 01:10:24,340
These are sort of the Cadillac version. You got to design and conduct a study according to a common protocol in multiple different places.

698
01:10:25,060 --> 01:10:29,680
This means you have increased comparability of data, so everyone's collecting data the same way theory, right?

699
01:10:30,190 --> 01:10:36,640
You don't have this harmonization issue and then you do the analysis together and coordinate a report of the results.

700
01:10:37,840 --> 01:10:43,710
But this is huge, right? This is huge. If you thought that pooled analysis was a pain in the butt.

701
01:10:43,720 --> 01:10:47,170
Oh, my God. Try doing this right. You have to identify your collaborators.

702
01:10:47,170 --> 01:10:52,030
You have to prepare this common protocol. You have to coordinate the conduct of the study.

703
01:10:52,030 --> 01:10:54,400
You have to coordinate the data analysis and coordinate the report.

704
01:10:54,880 --> 01:11:03,790
If you're going to try to do this, like ideally you might be wanting to do this in like different not just different places in the U.S.,

705
01:11:03,790 --> 01:11:06,490
but maybe ideally you'd be doing it in international settings, right?

706
01:11:07,210 --> 01:11:13,180
Well, think about trying to get some sort of common like, for example, dietary questionnaire for different international settings.

707
01:11:16,400 --> 01:11:21,020
Can't do it. Right. You can't give a U.S. food frequency questionnaire to people in China.

708
01:11:21,470 --> 01:11:26,330
That's stupid. Doesn't make any sense. You're not going to get the right data right.

709
01:11:26,330 --> 01:11:31,100
And so that's a you know, the comparability of exposure circumstances might be quite different.

710
01:11:31,310 --> 01:11:36,860
Right. And so collecting, you might not be able to collect the data in the same way because the exposures might be completely different.

711
01:11:37,220 --> 01:11:40,280
Diet is a very kind of intuitive example of that.

712
01:11:41,540 --> 01:11:45,610
But even smoking, like in Mexico, for example, they have in in other parts of the world.

713
01:11:45,620 --> 01:11:49,399
I just know Mexico off the top of my head because there's a Ph.D. student who's studying this,

714
01:11:49,400 --> 01:11:53,330
and he was in my class last year and I saw his proposal.

715
01:11:54,260 --> 01:11:58,489
But they actually sell like individual cigarets they don't just sell them in packs,

716
01:11:58,490 --> 01:12:05,990
they sell individual ones and they sell these flavored cigarets which are which are banned here but are not banned in all places.

717
01:12:05,990 --> 01:12:09,920
And people, you know, people think that this encourages younger people to smoke and that kind of thing.

718
01:12:09,920 --> 01:12:14,560
But they like cucumber flavored and strawberry flavored. And I mean, they're made by Marlboro.

719
01:12:14,570 --> 01:12:16,040
It's just like we don't have those here.

720
01:12:16,040 --> 01:12:21,770
So if you wanted to do a smoking questionnaire in an international setting, it has to be different in different places, right?

721
01:12:22,460 --> 01:12:28,160
You would have to ask about individuals. You can't ask about packets per day because they're not buying a pack.

722
01:12:28,160 --> 01:12:32,870
They're buying these individual cigarets. And you have to ask about these flavored cigarets, which you wouldn't ask about here.

723
01:12:32,870 --> 01:12:37,910
So it can be very tricky, right? You want to get comparable outcome data,

724
01:12:38,300 --> 01:12:43,640
you've got lots of logistical issues and you might have heterogeneous results that you actually can't put together.

725
01:12:45,120 --> 01:12:49,290
So you really want to involve these low income countries in multicenter studies or pooled studies?

726
01:12:49,350 --> 01:12:53,790
You're going to get a wider range of exposures because their exposure is going to be very different.

727
01:12:53,790 --> 01:12:56,550
And that's cool, but it can be a challenge.

728
01:12:57,270 --> 01:13:01,469
You know, you really want these this evidence from study populations that it provides an opportunity for training.

729
01:13:01,470 --> 01:13:04,860
But there's a lot of, you know, difficulties as well.

730
01:13:06,390 --> 01:13:12,900
So this is just sort of a table that summarizes what we just talked about in terms of the

731
01:13:12,900 --> 01:13:17,430
pros and cons of these three strategies for using doing kind of these multicenter studies.

732
01:13:18,060 --> 01:13:23,880
So in conclusion, you know, in general, we think that a few large studies are better than lots of small studies.

733
01:13:25,350 --> 01:13:29,909
Multicenter studies are in some ways the best option, but they're difficult to do.

734
01:13:29,910 --> 01:13:32,879
Right. And so the best option in some cases is, you know,

735
01:13:32,880 --> 01:13:39,780
you guys learn about what the best option is in your classes in terms of what provides the least biased answer to the question.

736
01:13:40,290 --> 01:13:43,620
But there's also like, can you do it in a reasonable amount of time?

737
01:13:44,670 --> 01:13:51,270
And the answer might be no, right? So the best option might be one of these studies that's kind of lower down on the pyramid,

738
01:13:51,270 --> 01:13:57,380
but provides you the opportunity to get some answers more quickly. And that's a balance, right?

739
01:13:57,390 --> 01:14:01,920
Like you want to get the best data you can, but you also want to get the data in a reasonable amount of time.

740
01:14:01,920 --> 01:14:08,819
And so finding that balance between what we're willing to give up in order to do it a little bit more quickly and cheaply, it's hard, right?

741
01:14:08,820 --> 01:14:10,950
That's a judgment call and it's not easy to do.

742
01:14:12,480 --> 01:14:18,660
Pooled analysis is perhaps an efficient compromise, although it took how many years, nine years you favor out.

743
01:14:18,660 --> 01:14:24,370
I don't know how efficient it was in my particular case, but. All right.

744
01:14:24,370 --> 01:14:31,120
And this is kind of a a little summary of the kinds of bias that we talked about

745
01:14:31,690 --> 01:14:36,759
and where what study designs minimize or maximize these potential biases.

746
01:14:36,760 --> 01:14:42,460
Right. All right.

747
01:14:44,020 --> 01:14:48,520
So if you loved that, you might want to be an epidemiologist. Any questions?

748
01:14:53,080 --> 01:14:57,490
All right, before you run away. What are we doing?

749
01:14:58,300 --> 01:15:09,370
Let's see. Where are we at? So you have quiz three, right?

750
01:15:10,540 --> 01:15:16,419
That is due in a week. We're going to do our cancer prevention overview and then we're going to have our exam review.

751
01:15:16,420 --> 01:15:18,820
And the first exam is on October 13th.

752
01:15:19,570 --> 01:15:24,520
If anybody has accommodations and they haven't already spoken to me about scheduling something and what you need,

753
01:15:24,520 --> 01:15:33,730
let me know kind of knowledge so we can get that going. Do we have a news article presentation next time?

754
01:15:39,550 --> 01:15:47,620
Well, let's double check. No, we don't.

755
01:15:47,710 --> 01:15:51,890
Okay. No news articles this time. You guys are right. All right.

756
01:15:51,910 --> 01:15:56,230
And then you have your final project outline due also in a week.

757
01:15:57,350 --> 01:16:00,430
Okay. Yes. But you expect to study 19 months.

758
01:16:01,630 --> 01:16:07,600
I believe it's fair. Yeah.

759
01:16:08,890 --> 01:16:13,480
Can you guys get to that? Can someone who's got the computer open try? Yeah, it's open.

760
01:16:13,780 --> 01:16:16,840
Okay, so it's there on the review date. Okay.

761
01:16:18,280 --> 01:16:21,400
Anything else? Who's got the sign in? If you need the sign in sheet.

762
01:16:21,430 --> 01:16:24,840
It's up here. Don't forget.

763
01:16:26,460 --> 01:16:27,330
Have a great day, guys.

