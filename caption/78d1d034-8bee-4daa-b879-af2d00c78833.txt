1
00:00:01,800 --> 00:00:09,990
So we will finish module F and then we will start talking about the extra sum of

2
00:00:10,000 --> 00:00:20,880
first principle and partial and sequential testing in multi-billionaire regression.

3
00:00:21,180 --> 00:00:29,700
So if you recall, we.

4
00:00:29,880 --> 00:00:34,350
So basically let's just do a quick review of where we are.

5
00:00:35,340 --> 00:00:50,850
We essentially wrote the sum of squares as quadratic forms and using the this theorem one,

6
00:00:52,410 --> 00:01:04,910
we have established the distributions of s this y ss are an s s e, okay.

7
00:01:05,250 --> 00:01:19,200
So we, we have established that these are by squared random variables with the appropriate degrees of freedom.

8
00:01:19,890 --> 00:01:34,230
And we have also established that under the null that s r has a central chi squared distribution.

9
00:01:34,860 --> 00:01:41,430
Correct. And under the null hypothesis.

10
00:01:42,120 --> 00:01:51,540
And also we have convinced you that under the linearity assumption of the line.

11
00:01:52,260 --> 00:01:55,050
So in other words, if the model is correctly specified,

12
00:01:55,470 --> 00:02:04,050
then since he also has a central chi square distribution or in other words, the non central pattern, but there is zero.

13
00:02:04,630 --> 00:02:13,950
Okay. So basically bottom line is we have established the distributions of SSR and SSP.

14
00:02:15,600 --> 00:02:27,270
Now remember, what is the context? The context is that we are trying to construct the F test and the F is a ratio of two

15
00:02:27,270 --> 00:02:34,890
independently distributed by squares divided by their corresponding degrees of freedom.

16
00:02:35,280 --> 00:02:40,350
So we have established the that is assigned is the C r squared.

17
00:02:40,710 --> 00:02:51,150
So what is left to be sure that it sets out of necessity independent if again true that SSR and SC are independent.

18
00:02:51,540 --> 00:02:59,880
Then we get one star or we can take the ratio of appropriately c this is our necessity.

19
00:03:00,690 --> 00:03:09,959
And for that we do that. So let's now prove that SSR and SC are independent.

20
00:03:09,960 --> 00:03:14,730
So first again, just to remind you, what is SSR?

21
00:03:14,730 --> 00:03:34,610
We wrote it as y transpose E and y when we are the matrix is h minus the matrix of ones divided by n and SSP is y transpose e y very.

22
00:03:34,950 --> 00:03:41,909
The matrix is the identity matrix minus the projection matrix, the hat matrix.

23
00:03:41,910 --> 00:03:46,170
So let's write those down again.

24
00:03:46,380 --> 00:03:50,160
So society's okay, so it's missing the transpose.

25
00:03:54,590 --> 00:04:06,230
So this is why drones, both E, R, Y and c is y, transpose e y.

26
00:04:07,100 --> 00:04:11,569
And now we have to show that. So starting is to see an independent.

27
00:04:11,570 --> 00:04:18,650
So in order to show that is deciding is a C are independent, we are going to use theorem two.

28
00:04:19,190 --> 00:04:23,420
So let's go back and look at theorem to what is clear and to a solid.

29
00:04:23,690 --> 00:04:31,009
Theorem three. What does Theorem three say that if it is an interesting matrix of constants and I is an

30
00:04:31,010 --> 00:04:35,329
interest one multivariate normal random vector would mean new and variance for begins

31
00:04:35,330 --> 00:04:44,780
matrix sigma squared I then and b is another n cross n matrix then the quadratic forms

32
00:04:45,080 --> 00:04:50,870
y transpose the y and y transpose b why both the quadratic forms are independent.

33
00:04:51,230 --> 00:05:01,760
If E times b is zero for this theorem, we are not going to use this theorem to show the independence of SSR and SS e.

34
00:05:03,290 --> 00:05:15,140
Okay, so let's now go back and use this theorem to prove that this audience is independent.

35
00:05:15,830 --> 00:05:19,550
So what do we have?

36
00:05:19,880 --> 00:05:24,950
A society's a y transpose, DIY, SCC, y transpose evi.

37
00:05:25,340 --> 00:05:31,760
So we need to show that the product e r game C is the matrix of zeros.

38
00:05:33,710 --> 00:05:49,790
Good. Okay, so let's do that. So now what is e r e r is, if you recall, e r is a h minus the matrix of once divided by N.

39
00:05:50,690 --> 00:05:55,550
That's what gives rise to the quadratic form for SSR.

40
00:05:55,880 --> 00:06:03,020
And what is E e is the matrix associated with the quadratic form for this?

41
00:06:03,020 --> 00:06:08,540
E And that is the identity minus the hat matrix.

42
00:06:08,810 --> 00:06:13,730
So, you know, these are these are basically what we have established, correct?

43
00:06:14,720 --> 00:06:24,320
E r times. E this product we have to know for sure is equal to zero.

44
00:06:26,120 --> 00:06:40,729
So let's see. So again, just the first step is from here to here is the basic expansion H minus the matrix of once divided by enzyme.

45
00:06:40,730 --> 00:06:50,600
So identity matrix minus the second term is H minus one, the one matrix divided by N times H.

46
00:06:52,460 --> 00:07:04,130
So once again now from here to here, the first term stays as it is, because both multiplying by the identity matrix just keeps that matrix.

47
00:07:04,820 --> 00:07:15,620
And then the second term is basically eight squared minus and the matrix of once times eight divided by N.

48
00:07:16,310 --> 00:07:21,260
So this is this is the term that we have to work with.

49
00:07:22,490 --> 00:07:34,880
Okay. So now working with that, what do I know? I know that eight is it important so I can just replace eight square with H?

50
00:07:35,720 --> 00:07:43,750
Correct. And what about the interest then made picks up once again.

51
00:07:43,830 --> 00:08:02,590
So this is the matrix of once I can write it as the product of a column vector of 1111 with the rule vector of one.

52
00:08:03,850 --> 00:08:14,770
Or in other words, I can write it as the column vector, one of dimension, and plus one multiplied by the rule vector of one of dimension.

53
00:08:14,770 --> 00:08:18,770
One crossing. Yes.

54
00:08:19,760 --> 00:08:26,960
And that's what I did. Yes. Multiplied by age divided by Midland.

55
00:08:28,040 --> 00:08:33,370
So. All good. So that's this stuff.

56
00:08:33,610 --> 00:08:39,310
So now from here to here, once again, the first one stays as it is, minus eight.

57
00:08:39,790 --> 00:08:45,850
And now what happens to what happens to this part here?

58
00:08:48,870 --> 00:09:03,780
So we also know that it is symmetric. So eight Johns pose is equal to each and it is a projection matrix.

59
00:09:05,460 --> 00:09:14,630
Correct. So what is one? Canada.

60
00:09:14,720 --> 00:09:35,810
It does. Yeah.

61
00:09:35,850 --> 00:09:42,510
Maybe I did like this. The new vector of plants.

62
00:09:43,710 --> 00:09:55,380
I did does the transport of the column vector of once and h transport is equal to H because it is symmetric.

63
00:09:55,980 --> 00:10:00,630
So if that's the case, then what is this fact?

64
00:10:12,570 --> 00:10:13,500
Who wants to tell me?

65
00:10:27,000 --> 00:10:41,700
So they made it because each one in plus one transpose of the whole thing because a b trans transport of the whole thing is be transported transpose.

66
00:10:42,660 --> 00:10:48,120
Yes. Okay. And H is a projection matrix.

67
00:10:59,350 --> 00:11:05,680
So it spans the column suffix unto itself.

68
00:11:06,430 --> 00:11:09,940
So what is eight times the column per hour?

69
00:11:10,030 --> 00:11:19,629
Once your exam middle names problem this is equal to one column vector.

70
00:11:19,630 --> 00:11:25,209
One transpose of that whole thing is basically the rule.

71
00:11:25,210 --> 00:11:33,190
But one plus and I kind of did it along with it would directly even argue.

72
00:11:35,430 --> 00:11:42,390
Okay. So all I did is then I just replaced this product.

73
00:11:43,020 --> 00:11:51,930
One, the low vector of one multiplied by H matrix is basically the new vector one.

74
00:11:53,340 --> 00:12:00,450
So I have this. And now what is the product.

75
00:12:02,460 --> 00:12:08,940
What, what is the product of the column. Vector of one with the little bit of one it stuck me picks up once.

76
00:12:10,680 --> 00:12:14,249
Okay? Yeah. Oops. Here is a typo.

77
00:12:14,250 --> 00:12:18,010
This is not the identity matrix. This is the matrix of one scanning.

78
00:12:18,010 --> 00:12:23,090
Please correct that. Okay.

79
00:12:23,900 --> 00:12:34,610
So I have h minus one, the matrix of ones divided by N minus the same term, which is equal to zero.

80
00:12:40,740 --> 00:12:45,540
Okay, everyone, I kind of did it really slowly.

81
00:12:45,540 --> 00:12:52,810
Gently. So now I know that it's not on and says See an independent.

82
00:12:57,160 --> 00:13:12,520
I'm done. So now let's put all of these things together and get to the final step of the proof of the distribution for the FTC.

83
00:13:13,060 --> 00:13:18,820
So to consider the FTC for the model there,

84
00:13:19,270 --> 00:13:24,940
the null hypothesis is that none of the poverty aids explain the variation in white

85
00:13:26,500 --> 00:13:31,690
versus the alternative that at least one coordinate explains the variation in white.

86
00:13:32,860 --> 00:13:46,450
So if I put it in the context of regression parameters, basically my null hypothesis is based on beta two, beta three who make up minus one.

87
00:13:47,380 --> 00:13:54,640
All of them are equal to zero. So all regression.

88
00:14:00,480 --> 00:14:06,990
Well, if I should be specific acquisitions at that.

89
00:14:11,700 --> 00:14:22,390
All the public idiots. Equal to zero.

90
00:14:25,150 --> 00:14:44,290
Simultaneous. Okay.

91
00:14:45,760 --> 00:14:51,310
Not here. The intercept bay does not is not included.

92
00:14:53,020 --> 00:14:59,649
Everybody remember that the normal model is the model with only the intercept.

93
00:14:59,650 --> 00:15:04,960
Beta not so. Beta not is part of the nine models here.

94
00:15:04,970 --> 00:15:09,970
The null hypothesis is basically turning all the other vehicles.

95
00:15:10,330 --> 00:15:14,710
We go on beta to beta three up B to B minus one equal to zero.

96
00:15:15,880 --> 00:15:24,310
So that's to point out beta naught is not included here.

97
00:15:31,470 --> 00:15:34,500
So for this hypothesis, what have been shown so far,

98
00:15:34,500 --> 00:15:39,410
we have shown that this is why over three months where as a chi square distribution within

99
00:15:39,420 --> 00:15:46,469
minus one degrees of freedom and non centrality parameter lambda y given by expected

100
00:15:46,470 --> 00:15:55,520
value of y transpose the identity matrix minus the matrix of ones divided by n multiplied

101
00:15:55,530 --> 00:16:03,360
force multiplied by expected value of y and the whole p divided by sigma squared.

102
00:16:03,660 --> 00:16:07,610
So it's a function of the big does. Okay.

103
00:16:09,720 --> 00:16:19,980
We have also shown that under the null and this is important under the null hypothesis is this r over

104
00:16:19,980 --> 00:16:27,660
sigma squared has a central fly squared distribution with degrees of freedom equal to p minus one.

105
00:16:28,170 --> 00:16:43,590
We have shown on slide 19 that under the null hypothesis ss r heads up chi square

106
00:16:43,590 --> 00:16:50,100
distribution with degrees of freedom p minus one and non central city parameter lambda r,

107
00:16:50,100 --> 00:16:57,060
which is zero under the null hypothesis. Okay, so that's SSI.

108
00:16:57,090 --> 00:17:05,940
What about SS e? We have also shown that if you see you will see my square has a nice square distribution with degrees

109
00:17:05,940 --> 00:17:14,759
of freedom in minus P and the non centrally D parameter is zero if the linearity assumption holds,

110
00:17:14,760 --> 00:17:21,540
if the models correctly specify under the line model, as I'm sure it says,

111
00:17:21,540 --> 00:17:27,720
C over sigma squared has a central square distribution with degrees of freedom and minus P.

112
00:17:28,500 --> 00:17:34,020
And just now we showed that it's inside an associate independent.

113
00:17:34,590 --> 00:17:40,810
Just now we showed that. So voila, we are.

114
00:17:40,900 --> 00:17:51,790
We are kind of done. Now, what do we do is we take the ratio of this to centrally distributed random variable SSR,

115
00:17:51,790 --> 00:17:58,090
NSC, appropriately scaled by their corresponding degrees of freedom.

116
00:17:59,140 --> 00:18:03,580
And we take the ratio of this two. And because they're independent, though,

117
00:18:03,580 --> 00:18:14,020
they sure have an error distribution with degrees of freedom B minus one and minus B under the null hypothesis H naught.

118
00:18:16,420 --> 00:18:32,049
So again, putting this in the known context, if is the MSR robbery, MSI, MSR, SSR divided by Sigma Square and you know,

119
00:18:32,050 --> 00:18:42,520
kind of just the standardized by degrees of freedom, B minus one and in the bottom in the denominator, what we have is a silver sigma squared.

120
00:18:42,520 --> 00:18:49,720
That random variable divided by N minus B and SSR, NSC are independent.

121
00:18:50,200 --> 00:19:01,150
So under the null hypothesis, under H, not this husky, it has an F distribution with degrees of freedom B minus one and then minus B.

122
00:19:02,680 --> 00:19:10,850
Okay. So. They are well known and what they will be bringing back again.

123
00:19:10,850 --> 00:19:16,700
So the regression somewhat squares is what I saw in the MLA multiple linear regression.

124
00:19:16,700 --> 00:19:22,580
The error sum of squares is see the total sum of persons.

125
00:19:22,590 --> 00:19:30,380
This is why we just showed based on, you know,

126
00:19:31,940 --> 00:19:43,850
our groups that SS are the degrees of freedom associated with the society and it's a C are B minus one and N minus B so here we have B minus one,

127
00:19:44,090 --> 00:19:48,770
in minus B and in minus one.

128
00:19:49,400 --> 00:20:01,130
What is this? Why the sum of it's this are plus cc is this y and then the m is like the mean squares are just the s.

129
00:20:01,160 --> 00:20:05,480
This are the sum of 12 divided by the corresponding degrees of freedom.

130
00:20:06,020 --> 00:20:17,900
And the f statistic is the mass R or by MSE, which is an F distribution with degrees of freedom B minus one.

131
00:20:18,240 --> 00:20:22,080
Minus three under the null hypothesis.

132
00:20:25,520 --> 00:20:34,969
So once we calculate the value of this are what A.C., which is going to be a guy who develop the best statistic,

133
00:20:34,970 --> 00:20:42,290
a single number we calibrated against an error distribution would be minus one and then minus B, and we obtain the.

134
00:20:44,540 --> 00:20:57,619
Yeah. So that's the context of the F test in multiple linear regression.

135
00:20:57,620 --> 00:21:13,700
And this completes the proof of of the F statistic as to why that ratio of necessary is to see appropriately state even distribution.

136
00:21:14,510 --> 00:21:28,130
Okay. So now we have one other piece that we have to prove and that relates to that D test in multiple linear regression.

137
00:21:29,030 --> 00:21:41,510
So if you recall, the T test for a single covariate in the MLA model is basically constructed by

138
00:21:41,930 --> 00:21:48,180
taking the ratio of the point estimate divided by the standard of the estimate.

139
00:21:48,200 --> 00:21:55,550
So because we had divided by standard in a speed that we had and we know or do we know that,

140
00:21:56,090 --> 00:22:01,210
how do we like, you know, what is the form of the distribution?

141
00:22:01,220 --> 00:22:10,800
It's a normalized zero one divided by the square root of what spread appropriately skewed by the use of three.

142
00:22:12,940 --> 00:22:26,410
Okay. So now in order to show that in multiple linear regression beta they had divided by the end of it, in a beta they had has a distribution.

143
00:22:27,070 --> 00:22:32,800
What do we need to show? We need to show that beta has the latest estimate.

144
00:22:36,260 --> 00:22:42,110
Estimate there is independent of Sigma has read.

145
00:22:43,700 --> 00:22:47,359
So let's show that and then we'll put this into into context.

146
00:22:47,360 --> 00:22:53,450
So next what we are going to show is the independence of beta hat and Sigma Hat Square.

147
00:22:54,260 --> 00:22:57,340
So first let me remind you, what is beta here?

148
00:22:59,840 --> 00:23:10,400
We have had these extra for the inverse example of why this is the Euler's estimate and what is sigma squared.

149
00:23:10,760 --> 00:23:22,940
Sigma head squared is s e over in minus p or the MSE mean squared in A and B, we know how to write a C in matrix notation.

150
00:23:23,300 --> 00:23:26,930
It's y transpose y you know the transport of.

151
00:23:33,530 --> 00:23:38,890
So why transpose 80 by divided by in minus B?

152
00:23:40,640 --> 00:23:46,640
Okay. So we need to show the independence of these two quantities.

153
00:23:47,390 --> 00:23:55,960
What is what how did we sort of define this y down for the y violate the form.

154
00:23:56,100 --> 00:24:01,730
This is a quadratic form. It's a quadratic form in Y.

155
00:24:02,480 --> 00:24:06,170
What about the form of the heart?

156
00:24:06,680 --> 00:24:12,200
It stands for the X inverse examples. Why? It's a linear combination of the whys.

157
00:24:12,260 --> 00:24:16,250
Right. So it's a linear function of y.

158
00:24:19,030 --> 00:24:25,450
So now we are trying to establish the independence for linear function with the

159
00:24:25,450 --> 00:24:35,290
quadratic function of Y and we are going to make use of this theorem here.

160
00:24:36,910 --> 00:24:45,879
So this is theorem two. Again, let a built in cross and matrix of constants ys and plus one multivariate normal random vector

161
00:24:45,880 --> 00:24:53,470
with mean new and medians properties matrix sigma split i y transpose e by the quadratic form.

162
00:24:53,920 --> 00:25:08,590
And now if we have a matrix B of dimension B cross and then y transpose E by and B by the quadratic form and the linear form of y are independent.

163
00:25:08,590 --> 00:25:26,290
If B times A is equal to zero, please make a note of the of the matrix broader like the the product e times b here will not be defined.

164
00:25:29,220 --> 00:25:33,040
Yes. If I did eight times.

165
00:25:33,070 --> 00:25:35,680
B this matrix product will not be defined.

166
00:25:37,030 --> 00:25:49,770
This multiplication will not be defined because of the dimension of B, so that the theorem is are to understand,

167
00:25:50,200 --> 00:25:55,090
make sure that you have the correct sort of understanding of this theorem.

168
00:25:55,480 --> 00:26:03,879
It's the matrix associated with the linear form multiplied by the mean streaks associated with the quadratic form.

169
00:26:03,880 --> 00:26:11,200
That product is equal to zero. Okay, so we are going to make use of this theorem here.

170
00:26:16,460 --> 00:26:27,830
Theorem two. So let's go back and use this term in the context of beat to happen Sigma Square.

171
00:26:29,780 --> 00:26:38,060
So now in order to show that Peter had and Sigma had split and are independent, then what do we need to show?

172
00:26:38,660 --> 00:26:45,680
The Matrix associated with the linear form is x transpose, x inverse x transpose.

173
00:26:46,280 --> 00:26:53,710
This is a p cross and matrix multiplied by the matrix associated with the quadratic form, which is a D.

174
00:26:53,930 --> 00:27:00,050
This is an interesting matrix. We have to show that the product of these two is equal to zero.

175
00:27:03,230 --> 00:27:09,970
Okay. So applying. Puram to.

176
00:27:13,850 --> 00:27:24,330
Off slide. What? Slide four.

177
00:27:30,900 --> 00:27:35,430
Okay. So now let's look at this product.

178
00:27:37,620 --> 00:27:43,590
So what is it strong for the x inverse x transpose 88.

179
00:27:43,920 --> 00:27:49,620
Remember is the identity matrix minus the production matrix h.

180
00:27:51,960 --> 00:28:06,330
So I just plug in 80 and now I have expandable vaccine versus extra spool times, the identity matrix minus the hat matrix.

181
00:28:08,100 --> 00:28:11,940
Once again, I know it is symmetric.

182
00:28:11,940 --> 00:28:24,090
I'd import them, but it is a production matrix. And in homework two you showed that I minus eight is also symmetric item 14.

183
00:28:30,220 --> 00:28:33,880
Okay. So what is x transpose ie minus eight?

184
00:28:35,890 --> 00:28:51,080
You can write this part as. External force I minus h transpose because I minus eight transpose is equal to I minus eight and

185
00:28:51,080 --> 00:29:04,580
applying the result on transposes you basically get I minus a ninth x transpose of the whole thing.

186
00:29:11,000 --> 00:29:17,420
Okay. And what is A-minus C?

187
00:29:20,550 --> 00:29:36,660
Times ex. The physical two x minus six eight is a projection matrix to produce columns of the x matrix unto itself.

188
00:29:36,930 --> 00:29:40,730
So I have x minus eight x is equal to it.

189
00:29:41,640 --> 00:29:47,940
So this is. Okay.

190
00:29:50,920 --> 00:30:05,860
So the product or the matrix associated with the linear form and the matrix associated with the quadratic form is zero.

191
00:30:08,200 --> 00:30:16,750
In other words, we have shown that Pizza Hut and Sidmouth Square are independent by applying the theorem to on Slide four.

192
00:30:18,230 --> 00:30:21,240
You get everybody convinced.

193
00:30:22,170 --> 00:30:30,290
So now let's get back to our proof of the distribution from the desk.

194
00:30:30,840 --> 00:30:35,110
So again, we call the tedious for a single bulb idiot.

195
00:30:35,940 --> 00:30:40,889
If I had called idiot 61x2 weeks, three weeks, b minus one.

196
00:30:40,890 --> 00:30:47,310
And now I'm interested in testing within the context of the multiple linear regression model.

197
00:30:47,520 --> 00:30:52,710
I'm interested in interested in testing for a single forwarded beta equal to zero.

198
00:30:52,830 --> 00:31:00,170
Yes. There's two solutions to the. Oh yea.

199
00:31:00,170 --> 00:31:03,430
Yea. Yea. Yea. I see quite a few diapers there.

200
00:31:03,440 --> 00:31:09,310
Thank you. Yes. It should be in my must be soap.

201
00:31:10,010 --> 00:31:17,090
So I am interested in testing for semen will be betas equal to zero.

202
00:31:17,450 --> 00:31:27,889
So what is the AP test? So it's because they have divided by the standard of pay that they have and I simply write

203
00:31:27,890 --> 00:31:37,240
it does because they had to divide it by the square root of sigma squared times e g d.

204
00:31:37,250 --> 00:31:45,680
Well what is ADHD? ADHD is the g element of the example, the x inverse matrix.

205
00:31:45,680 --> 00:31:53,959
Because remember we had shown in module E that variants of beta had or the

206
00:31:53,960 --> 00:31:59,060
estimated variance of beta had B sigma had squared times x transpose x inverse.

207
00:31:59,510 --> 00:32:08,400
We had shown this in module. So and what is the variance of the individual beta heads?

208
00:32:09,170 --> 00:32:13,400
They are in the die, but not all that matrix.

209
00:32:15,510 --> 00:32:29,340
Correct. So diagonal of that matrix means what's it sigma had where the hides the GDP element of that it stands for vaccine version six.

210
00:32:32,950 --> 00:32:37,540
Everybody with me. Do I need to write this down?

211
00:32:43,810 --> 00:32:54,610
Here is the variance covariance matrix of beta high and what is beta have beta had is beta one had better not had.

212
00:32:54,880 --> 00:33:01,870
The intercept is also included beta one had that the delta up to the P minus one had.

213
00:33:06,650 --> 00:33:15,350
Okay. So so basically what I have in the diagonals are the variety and stance.

214
00:33:17,420 --> 00:33:20,840
Okay, so. So now I can write better.

215
00:33:20,840 --> 00:33:27,200
They had divided by square root of sigma had squared times ADHD.

216
00:33:27,200 --> 00:33:32,240
But ADHD is the DVD element of the example mix inverse matrix.

217
00:33:32,780 --> 00:33:36,200
And what do I do now?

218
00:33:36,560 --> 00:33:46,520
Both in the numerator and denominator? I divide by square root of sigma squared ADHD, but sigma squared is the unknown error.

219
00:33:50,210 --> 00:34:05,760
Variants. I would know when I in the numerator I have a quantity like beta they had divided by the square root of Sigma Square ADHD.

220
00:34:05,790 --> 00:34:11,850
What is the distribution of this under the null hypothesis?

221
00:34:12,660 --> 00:34:19,860
This has a standard normal distribution because under the null hypothesis, beta is equal to zero.

222
00:34:22,110 --> 00:34:39,810
So beta they had had a normal distribution between zero and variants equal to the seed must with 90 digit.

223
00:34:39,900 --> 00:34:46,110
But now I'm kind of standardizing it by dividing it by the variance and that

224
00:34:46,110 --> 00:34:52,440
standardization gives rise to all normal zero on random variable on the numerator.

225
00:34:54,870 --> 00:35:01,170
What about the denominator? The denominator is what is sigma hat squared?

226
00:35:01,320 --> 00:35:11,490
Sigma hat squared is basically the SCC divided by n minus one another was the MSE.

227
00:35:12,480 --> 00:35:21,959
So I have is is c divided by in minus P and I have the leftover sigma squared from the bottom.

228
00:35:21,960 --> 00:35:26,940
The added is cancel out. Yes.

229
00:35:30,560 --> 00:35:40,460
So I have sigma squared. I have SCC over sigma squared divided by N minus b and square root of the whole thing in the denominator.

230
00:35:41,090 --> 00:35:49,760
So now again, you recognize the form of, of this quantity or the or how this ratio looks.

231
00:35:50,150 --> 00:35:59,720
So this ratio looks like the normal zero one under under the null hypothesis and the null hypothesis.

232
00:36:00,230 --> 00:36:14,630
This ratio looks like a normal zero one divided by the square root of a square root within minus three degrees of freedom divided by N minus P.

233
00:36:15,770 --> 00:36:26,000
Because I proved earlier that this equals sigma squared has a central square distribution with degrees of freedom n minus b.

234
00:36:28,820 --> 00:36:48,470
Correct. I have moved that s this e over Sigma Square has a central chi square distribution with degrees of freedom in minus P under l in line.

235
00:36:51,020 --> 00:36:56,720
And the assumption that the the linear the model is correctly specified.

236
00:36:58,400 --> 00:37:14,900
So this ratio looks like what it looks like a standard normal divided by the square root of what chi square standardized by degrees of freedom.

237
00:37:14,910 --> 00:37:18,560
So isn't this like the E?

238
00:37:21,700 --> 00:37:26,559
With degrees of freedom in minus B and please, you are right.

239
00:37:26,560 --> 00:37:30,040
Absolutely. This should be A minus B. Sorry about that typo.

240
00:37:32,840 --> 00:37:40,040
So I'm of the null hypothesis, the three who had the three distribution with n minus three degrees of freedom.

241
00:37:44,390 --> 00:37:51,460
And that's the proof of the distribution for the test in multiple linear.

242
00:37:54,380 --> 00:37:58,370
Okay. Questions?

243
00:38:02,770 --> 00:38:17,899
Moments. So this concludes module F and it's as when we started I said that module every day you really like the purity of hypothesis

244
00:38:17,900 --> 00:38:27,560
testing in multiple regression and it's it's it's basically all about will be the results that we have been referring to and.

245
00:38:28,430 --> 00:38:39,770
So. So now we began we can have our peace of mind that all true set of the and the results because

246
00:38:39,770 --> 00:38:45,980
everything that needs to be said that we can see we have now establish the problem solved.

247
00:38:46,490 --> 00:38:55,400
Why that the issue of them is not a body you see behaves like an MP why that is she will be

248
00:38:55,420 --> 00:39:04,250
done had divided by the standard that it up because we had the expected distribution and so on.

249
00:39:05,090 --> 00:39:15,380
So it's almost like we are close. We close the loop on on hypothesis testing in the linear regression setting for both the

250
00:39:15,860 --> 00:39:23,720
overall is best for regression and that s testing for C the audience in the end and offset.

251
00:39:25,890 --> 00:39:30,390
Okay. Questions. Comments.

252
00:39:34,960 --> 00:39:43,810
Okay. Then we will stop for a break and then it's 846.

253
00:39:43,810 --> 00:39:51,040
So please come back at 856 and we will start the new module.

254
00:40:04,967 --> 00:40:21,337
Okay, so now what we are going to talk about, so this is more g we still are in the market for linear regression hypothesis testing framework,

255
00:40:22,837 --> 00:40:31,927
but we are going to sort of introduce the concept of extra sample square,

256
00:40:32,017 --> 00:40:43,747
the nested models and the idea of partial and sequential testing in the context of multiple linear regression.

257
00:40:44,347 --> 00:40:50,707
So here is an outline. First, we'll talk about existence of squares principle.

258
00:40:51,757 --> 00:41:01,257
Then we are going to introduce a general affairs and a committed subset death.

259
00:41:02,977 --> 00:41:11,127
Somebody asked me about the whole we did subset test earlier, like I think a couple lectures back.

260
00:41:11,497 --> 00:41:16,297
Did you ask me about that? You did say yes. So here it is.

261
00:41:17,977 --> 00:41:26,646
So we are going to talk about the covariance upset first and I am just going to give a sort of example like for example,

262
00:41:26,647 --> 00:41:32,827
like your whole body, its our age, height, weight,

263
00:41:33,907 --> 00:41:42,277
gender and then some social demographic really social demographic variables like you know,

264
00:41:43,297 --> 00:41:47,316
education is done better, but at the end you want to test for a cluster.

265
00:41:47,317 --> 00:41:55,347
B So 31 prepares like income, education together the effects of income and education.

266
00:41:55,347 --> 00:42:02,227
And you want to test the effect of physiologic age, height, weight together.

267
00:42:03,097 --> 00:42:06,677
So that's what I refer to as school body. It's subsidies.

268
00:42:06,707 --> 00:42:14,467
So so far what you have seen is testing all the whole period simultaneously that are in the model,

269
00:42:14,977 --> 00:42:18,427
the test or testing a single school years at the time.

270
00:42:19,177 --> 00:42:27,317
So now I'm going to introduce to you also how to test for subsets of proteins that cluster

271
00:42:27,347 --> 00:42:36,967
something called idiots that are meaningful or interpretable from a biological point of view.

272
00:42:39,927 --> 00:42:43,797
And then we'll have some examples. Okay.

273
00:42:44,337 --> 00:42:54,777
So the last so what we ended module F with was the first where the null hypothesis is borderline equal to.

274
00:42:54,777 --> 00:42:59,066
We definitely want to make a P minus one equal to zero.

275
00:42:59,067 --> 00:43:07,257
So we are testing these. Simultaneously.

276
00:43:12,037 --> 00:43:20,347
And we should be in more duty if that was the alternative that at least one of them is nonzero.

277
00:43:21,067 --> 00:43:31,357
And in module F, we have once again to remind you we have established all of these results for the SS.

278
00:43:31,357 --> 00:43:32,377
Why is this Assad?

279
00:43:32,377 --> 00:43:43,387
Is this e you showed that each of them is a quadratic forming log and they have five square distributions with the appropriate degrees of freedom.

280
00:43:43,387 --> 00:43:47,166
And we also showed that under the null hypothesis,

281
00:43:47,167 --> 00:43:57,487
SSR and SS e are independent and they are independently distributed centers by square random variables.

282
00:43:57,607 --> 00:44:07,896
So we could construct the first as the ratio of MSR to MSE and under the non hypothesis of an F distribution

283
00:44:07,897 --> 00:44:14,807
would be the freedom p minus one and then minus the all would be just sort of wrapped up that module.

284
00:44:15,877 --> 00:44:27,427
Know this is how like conceptually we are going to think about the F tests in a slightly different way.

285
00:44:31,337 --> 00:44:37,547
It's nothing new, but it's kind of putting old wine in a new bottle, sort of.

286
00:44:39,317 --> 00:44:44,387
So here it is. Let me guide you through that thinking.

287
00:44:45,677 --> 00:44:56,326
So step one, think about creating the full model Y equal to Paternot plus beta 1x9 plus beta two x2

288
00:44:56,327 --> 00:45:06,617
ie da da da da da b minus one xp minus one i plus we have the random error epsilon I.

289
00:45:06,637 --> 00:45:13,247
So these are my coordinates and this is my random error.

290
00:45:20,067 --> 00:45:28,047
Media narratives, of course. The Intercept. Okay.

291
00:45:28,867 --> 00:45:40,767
Now think about step two as if you are fitting the name of the model non model.

292
00:45:43,327 --> 00:45:48,656
Another sort of general term for this novel model.

293
00:45:48,657 --> 00:45:55,257
The novel model is a is a special case of what we will refer to as the abused model.

294
00:45:55,347 --> 00:46:02,217
And you will see that when I talk about the youth model in comparison to the full movie,

295
00:46:02,227 --> 00:46:09,506
because everything like everything we need, like all that you have made sure that you are included in the, in the model.

296
00:46:09,507 --> 00:46:13,287
The reduced model has less barometers.

297
00:46:14,487 --> 00:46:20,307
So at least one less barometer, let's say at least one less for me.

298
00:46:20,967 --> 00:46:25,587
So that's what a reduced model means in comparison to a full model.

299
00:46:26,097 --> 00:46:34,767
The non model is a severely reduced model Y because it has not the all the obedience, all the excess.

300
00:46:35,367 --> 00:46:40,797
The only thing I have is data set to the non model is a special case of the reduced

301
00:46:40,797 --> 00:46:48,507
model and the non model we saw is basically y equal to not plus epsilon I.

302
00:46:49,617 --> 00:46:58,317
So it's just the intercept plus the random noise.

303
00:47:00,117 --> 00:47:13,137
Okay, now recall what is a sissy? A C by definition is the sum of squared of the observed minus the fitted values y minus y you had squared sample.

304
00:47:13,137 --> 00:47:16,736
Were I from one blend. Yes.

305
00:47:16,737 --> 00:47:19,947
That's, that's the it says E by definition.

306
00:47:21,447 --> 00:47:26,756
So let's now look at the non model and the full model for the non model only has

307
00:47:26,757 --> 00:47:39,027
to be done on what is the s this e for the non model and under the non-monogamy,

308
00:47:39,027 --> 00:47:46,197
what is your best guess of done better? Not what is the least worse estimate of better not it's wide but right.

309
00:47:46,587 --> 00:47:55,347
So I have a cc is summation y minus y you have now y you had this y bar.

310
00:47:56,067 --> 00:48:09,657
So summation y minus y bar squared this and we had seen this before because under the non model beta not had is y bar.

311
00:48:11,877 --> 00:48:26,547
So is this e under the non model is actually equal to ss y and what is that is this are for the non model it's zero because it's a E minus.

312
00:48:26,727 --> 00:48:34,646
It's so it says this Y minus C and it sees equal to s is Y for the non model.

313
00:48:34,647 --> 00:48:39,897
So that is decided zero. What?

314
00:48:39,967 --> 00:48:43,236
The Normandy. What about the full model?

315
00:48:43,237 --> 00:48:49,597
The full model? The SSD is by definition some Asian Y minus y.

316
00:48:50,077 --> 00:48:53,917
I had square. This is by definition.

317
00:49:00,517 --> 00:49:08,707
And what is it? CSR is CSR is basically is this Y minus it says E.

318
00:49:12,387 --> 00:49:15,837
Is this art? Is this why? My goodness.

319
00:49:15,867 --> 00:49:20,627
Is this the. For the full model.

320
00:49:21,107 --> 00:49:27,797
But what is is this why is this why is equal to the SS e for the null model?

321
00:49:28,367 --> 00:49:46,947
So I just plug that in. So what I have is the SSR for the full model is equal to the SNC under the Normandy minus the SNC for the full model.

322
00:49:50,477 --> 00:49:54,737
And this is greater than zero. Why?

323
00:49:54,797 --> 00:50:01,967
Because it's the sum of squares. Okay.

324
00:50:01,967 --> 00:50:11,217
So everybody with me so far. So now I stared at this expression for a pause for a while.

325
00:50:12,207 --> 00:50:18,507
What am I saying? What I'm saying is that the big if you stare at this expression.

326
00:50:30,627 --> 00:50:35,547
What I'm seeing is that the deep freeze in the SCC.

327
00:50:38,277 --> 00:50:48,057
Equals the increase in the SS are going from the novel model to the fully models.

328
00:50:52,307 --> 00:51:05,896
The more explicitly ss e from the non-GM model minus SSD from the full model is

329
00:51:05,897 --> 00:51:12,947
going to be equal to the s r from the full model minus the SSR from the null model.

330
00:51:20,537 --> 00:51:31,637
Yes, you can. You can. Basically, we just in the previous few steps we have, we showed it algebraically, but conceptually intuitive.

331
00:51:31,637 --> 00:51:39,497
You should make a whole lot of sense. What we are saying is that we do not want to do the full model.

332
00:51:40,037 --> 00:51:43,547
We are going to explain more of the variation.

333
00:51:45,467 --> 00:51:51,947
So that is this R is going to increase going from the non-mobile to the full market.

334
00:51:55,027 --> 00:52:09,547
And the amount of increase in the SSR is going to be equal to the amount exactly equal with the amount that is left unexplained.

335
00:52:12,767 --> 00:52:20,467
By the what is funding models and what what what is that lived on.

336
00:52:20,487 --> 00:52:35,087
Explain what it is that is. So the SCC now what is left unexplained by the non lobby is a see began what is left unexplained by the model S is e beta.

337
00:52:38,047 --> 00:52:42,186
And what is going to be left unexplained in the full model is, of course,

338
00:52:42,187 --> 00:52:51,816
going to be a smaller bar that smaller than what's left unexplained by an anomaly, because I'm expecting more of the variation with the obedience.

339
00:52:51,817 --> 00:53:05,227
And that and this decrease or the increase in assets are going from the non to the full model is going to be equal to the decrease in see.

340
00:53:07,817 --> 00:53:11,357
Going from the Full Monty finale.

341
00:53:11,837 --> 00:53:20,547
Yes. Question. Speak a little louder.

342
00:53:21,397 --> 00:54:01,707
Yes. I am not sure I understand your position, but then you repeat that.

343
00:54:50,537 --> 00:54:55,017
I see you were saying, like, why you you like okay.

344
00:54:55,347 --> 00:55:02,487
Yeah. I think what you're confusing is with the calculated value versus.

345
00:55:03,797 --> 00:55:07,727
The distribution, the purity and distribution.

346
00:55:10,127 --> 00:55:20,757
So let me draw for a moment to this is more of a general impression when you draw from the population and you move the population to the smaller.

347
00:55:24,017 --> 00:55:29,087
So you can you can draw from a normal 3 to 1.

348
00:55:30,137 --> 00:55:35,617
You can draw zero. But.

349
00:55:37,737 --> 00:55:48,797
The random variable has an underlying distribution of normal 3 to 1 Bitcoin activity values in the end of the life.

350
00:55:54,457 --> 00:56:00,157
Does that help? So it's it's kind of a realization from that distribution.

351
00:56:02,477 --> 00:56:12,507
What does it mean that that it is kind of like it has a because the whole more sensible.

352
00:56:16,767 --> 00:56:26,947
So. It's it's basically the calculated value.

353
00:56:34,887 --> 00:56:46,347
Just as it's made. May maybe the one thing that some think about that they could join from from our distribution, a single realization would be zero.

354
00:56:47,537 --> 00:56:51,737
But that doesn't mean the distribution of use has all the massive.

355
00:56:59,377 --> 00:57:04,446
Yeah. Because you're calibrating that when he gains distribution.

356
00:57:04,447 --> 00:57:13,207
And that's why we always need a reference distribution to be even more like what is what what does this statistic behave like?

357
00:57:24,377 --> 00:57:33,347
It's that's sort of like the other way and you'll see some and other thing that that can pop up here is it.

358
00:57:33,647 --> 00:57:39,557
And that's why I said it's it's a kind of a another way of looking at that.

359
00:57:39,557 --> 00:57:46,237
Nothing more. Make sense.

360
00:57:47,907 --> 00:57:53,257
Any other questions? Okay.

361
00:57:53,527 --> 00:57:59,887
So, so that's the decrease in SSP equals the increase in SSR.

362
00:58:00,577 --> 00:58:04,567
Now step three is let's go back to the exit testing.

363
00:58:04,777 --> 00:58:12,137
That reconstructed is that issue off MSR or what MSI saw on the new monitor?

364
00:58:12,157 --> 00:58:18,757
I have SSR from the full module divided by the degrees of freedom for the full model.

365
00:58:20,377 --> 00:58:30,277
And then in the denominator, I have the SSD from the full model divided by the degrees of freedom of SSD from the full model.

366
00:58:31,877 --> 00:58:34,567
I'm just going to write it a little differently.

367
00:58:34,687 --> 00:58:44,077
And once again, like, you know, sort of thinking about the, the, the Narmada in a different way, casting this in a different way.

368
00:58:46,627 --> 00:58:49,917
So on the numerator in the denominator, I keep it as it is.

369
00:58:49,927 --> 00:58:57,967
This is ESI for the full model divided by the degrees of freedom of sase and in the numerator.

370
00:58:57,967 --> 00:59:05,166
What do I have? I have SSR data minus SSR beta not this is a beta.

371
00:59:05,167 --> 00:59:08,767
Not like I said like in the non model is like zero.

372
00:59:09,457 --> 00:59:15,477
So I'm subtracting zero and then in the denominator I have degrees of freedom SSR

373
00:59:15,487 --> 00:59:22,417
beta minus degrees of freedom is this are becoming all the degrees of freedom

374
00:59:22,417 --> 00:59:30,816
is this are in the non model is also feel like if you think about the the and what

375
00:59:30,817 --> 00:59:37,927
they were like it's like now I have only one factor for PS one one minus one.

376
00:59:41,057 --> 00:59:51,406
Zero. So it's a it's a little kind of like a weird sort of, uh, formulation, but,

377
00:59:51,407 --> 00:59:56,867
um, and subtracting zero from both the top and the bottom of the numerator.

378
00:59:59,037 --> 01:00:02,156
Why did I do that? Because it is kind of like already.

379
01:00:02,157 --> 01:00:05,067
I'm like there is some confusion over it all.

380
01:00:05,307 --> 01:00:12,807
I mean, the reason why I'm doing that is I just want to see the numerator in some sort of a different life.

381
01:00:12,927 --> 01:00:20,787
And what is that different like? What I'm saying is that if you look at the numerator at this point for getting that,

382
01:00:20,787 --> 01:00:26,997
what I saw directed from the top and the bottom of the numerator are basically zeros.

383
01:00:28,497 --> 01:00:36,627
You can see that the if this compares the enter or that is this are whichever way you

384
01:00:36,627 --> 01:00:43,437
want to think about it between two more who's you doing the analogy and the full model.

385
01:00:46,737 --> 01:00:59,727
Intuitively if the error reduces the assessee reduces or in one question is this odd increases greatly

386
01:00:59,727 --> 01:01:08,007
due to the AP that only does due to adding more radius then it makes sense to use the larger model.

387
01:01:11,097 --> 01:01:29,907
If I if I keep the SSR increases law by adding it struck out on me despite adding extra obedience or conversely, if the SSP decreases along.

388
01:01:32,557 --> 01:01:38,166
The unexplained park included a long view, adding extra.

389
01:01:38,167 --> 01:01:48,156
Hopefully it's there. I would of course favor the larger lobby and there'll be this way of writing in step three,

390
01:01:48,157 --> 01:01:56,017
using the hours from the full model and the null model, the freedom of the full model in our model, just to convince you that look,

391
01:01:56,017 --> 01:02:08,197
I can write the if this as if I'm comparing between two models, that is what if I have sort of convinced you on that,

392
01:02:09,487 --> 01:02:15,187
then I'm happy because that's all I need to convince you that you can write this a fist.

393
01:02:15,547 --> 01:02:21,127
As if I'm comparing between the two models.

394
01:02:25,067 --> 01:02:29,597
And here comes sort of the extension of this concept.

395
01:02:31,007 --> 01:02:35,297
And this is a very important concept in multiple linear regression.

396
01:02:35,297 --> 01:02:38,627
It's called the extra sum of squares principle.

397
01:02:39,617 --> 01:02:42,617
What does the extra sum of first principles say?

398
01:02:44,117 --> 01:02:57,887
It says that s e for the null model, minus the C for the full model is refer to.

399
01:02:57,887 --> 01:03:03,947
It's either the difference in the secedes or the difference in the S is RS.

400
01:03:05,537 --> 01:03:15,887
Either way you look at it, this is referred to as an extra sum of squares and it can be viewed in either a few ways.

401
01:03:15,887 --> 01:03:23,086
It can be viewed as either the reduction in the C or the increase in the S.

402
01:03:23,087 --> 01:03:28,457
This are when one or more predicted variables are added to the model.

403
01:03:29,117 --> 01:03:37,427
We kind of started like or we introduced the concept of it's just somewhat squares by comparing two drastic models.

404
01:03:38,987 --> 01:03:46,227
At one end of the spectrum, we have the full model which has the humanly everything that you have measured and that we want to control for.

405
01:03:46,607 --> 01:03:50,957
And on the other end of the spectrum, we have not no obedience.

406
01:03:51,917 --> 01:04:00,017
So we introduce the concept of expression of squares through these two drastically different models.

407
01:04:00,407 --> 01:04:06,827
But the concept applies to any model that's in between,

408
01:04:08,177 --> 01:04:17,237
and the whole idea is to show that the F first can really be as complicated between the models.

409
01:04:19,087 --> 01:04:28,507
One larger than the other in terms of the number of barometer for the number of pull bets on the number of predictable animals that are in the market.

410
01:04:28,897 --> 01:04:31,987
So in a sense, when we add predicted to a model,

411
01:04:32,437 --> 01:04:39,667
we hope to explain some of the variability in the response by regression and thereby reduce some of the error.

412
01:04:40,027 --> 01:04:44,827
So when we add more and more variables in the model, as,

413
01:04:45,317 --> 01:04:54,307
as you saw that the system will increase or stay the same, its, you know, if it allows you to do that,

414
01:04:54,697 --> 01:05:03,006
but if it doesn't contribute to explaining any relation but it's just our you just like R-squared or I should

415
01:05:03,007 --> 01:05:09,337
say off the record behaves just I guess the thought as you add more people to the model that is the service,

416
01:05:10,087 --> 01:05:21,747
at least stay the same or will increase. You are going to explain at least the same amount of variation in one or more.

417
01:05:23,127 --> 01:05:24,987
And as a result, what will happen?

418
01:05:25,407 --> 01:05:34,377
The amount of variation that is left unexplained to at least see the same or will decrease as you add more centers in the model.

419
01:05:34,827 --> 01:05:43,317
And that's what the reduction in SC reflects.

420
01:05:43,887 --> 01:05:51,446
So an extra sum of squares quantifies how much variability be explained through the increase in SSR,

421
01:05:51,447 --> 01:05:57,057
or alternatively, how much l are really due to a reduction in SSP.

422
01:06:01,157 --> 01:06:12,827
Everybody with me. So do you see like, you know, it's kind of like no new concepts, but it's kind of old wine in a new bottle.

423
01:06:12,827 --> 01:06:23,597
I mean, then thinking a little differently. That's what is important for you to recognize.

424
01:06:23,627 --> 01:06:30,297
So here it is. Now more generally, defining the extra sample square.

425
01:06:30,307 --> 01:06:36,886
So let's say we have a model Y equal to now back into the matrix notation.

426
01:06:36,887 --> 01:06:51,227
Y equals x beta plus epsilon where y is in plus one x design matrix and cross p beat up out of the detected plus one and epsilon.

427
01:06:51,257 --> 01:07:03,227
Then the matter is in her F1 vector and let's say your challenger vector like your or your property in space is has

428
01:07:03,587 --> 01:07:20,547
the example of a gender IP income indication that what I'm doing is now I'm partitioning that whole radial space.

429
01:07:20,547 --> 01:07:32,326
People do x finally school so let's say cluster in gender height we have the X1 and x2

430
01:07:32,327 --> 01:07:42,087
is so incoming version because I'm going to with another kind of similar type of self,

431
01:07:42,297 --> 01:07:53,147
so few variables, IDs, gender, height, weight and kind of similar stuff like you need like something more the physiology.

432
01:07:54,527 --> 01:08:14,207
So I decide to partition the x design matrix into X1 and X2 and red x1 and correspondingly the beta got mean vector as between one and beta two.

433
01:08:15,497 --> 01:08:31,097
Where we go on is p one plus one and beta two is p two plus one and b1 plus B2 is equal to be the beta parameter vector is p.

434
01:08:31,097 --> 01:08:38,227
Both one. Yes. Yes.

435
01:08:38,237 --> 01:08:41,297
Okay, good. I was anticipating this question.

436
01:08:41,297 --> 01:08:46,027
Where is Peter Zito? But what am I? What am I going to do with Bedazzled?

437
01:08:46,697 --> 01:08:51,797
So by convention, bedazzled is always speaking as part of its one.

438
01:08:54,177 --> 01:09:02,577
Okay. So B2C, too, and we'll see this later in the conference because it was always taken as part of X one.

439
01:09:04,797 --> 01:09:08,767
So the extra sum of squares. So now do you understand what I mean?

440
01:09:08,787 --> 01:09:13,347
So let. Let me just write a little bit more. So let's say I had X is.

441
01:09:18,127 --> 01:09:30,877
It did. High the income education.

442
01:09:34,607 --> 01:09:40,577
So now the way I'm going to partition is I'm going to make like it's one.

443
01:09:44,897 --> 01:09:58,367
Is the passport, age, gender, height, weight, and it still is income and education.

444
01:10:00,527 --> 01:10:06,367
So then what is the dimension of between beta?

445
01:10:06,497 --> 01:10:09,047
One would be a for plus one vector,

446
01:10:10,607 --> 01:10:20,177
so a five plus one vector because it also includes the intercept and what is greater to better to be a to cross one vector.

447
01:10:21,287 --> 01:10:30,287
And in total I have how many parameters in the model in the linear model, seven, six plus one.

448
01:10:30,827 --> 01:10:36,047
So B is seven and I have partitioned B this five plus two.

449
01:10:37,757 --> 01:10:50,957
Okay. So the extra sum of squares due to beta two, I'm going to denote V does this is kind of the sum, you know, this notation,

450
01:10:51,527 --> 01:10:59,236
I'm going to denote it as s's sum of squares of beta two given beta one was

451
01:10:59,237 --> 01:11:04,337
already in the model and this would be the one in which the two are vectors.

452
01:11:05,627 --> 01:11:14,027
So it's written as SS beta two and then a bar vertical bar beta one.

453
01:11:15,527 --> 01:11:33,767
So this means that this is the quantity which captures the increase in the SSR attributable to adding X2 given that the X1 was already in the model.

454
01:11:34,067 --> 01:11:42,647
So if I want to say it in plain English, I'm saying that, okay, what is the increasing SSR attributable to adding income and Jen,

455
01:11:42,887 --> 01:11:52,067
income deficient in the model, given that I already had age, gender, height, weight in the body and also by convention.

456
01:11:52,497 --> 01:11:59,507
The dataset is also part of the the model with X1.

457
01:12:00,977 --> 01:12:08,507
But in terms of the decrease, so something like explain more of the variation in Y by adding income in in Russia.

458
01:12:10,787 --> 01:12:13,847
Well, already I have the gender hybrid in the model.

459
01:12:14,057 --> 01:12:18,287
That's what this extra sample squared will capture.

460
01:12:19,127 --> 01:12:28,307
So the S's that do given beta one I can write it does is this are from the model that

461
01:12:28,307 --> 01:12:36,137
has both middle on and beta two minus the SSR from the model with only beta one.

462
01:12:36,287 --> 01:12:40,367
And once again note that beta one beta two are all vectors here.

463
01:12:44,917 --> 01:12:53,917
Okay. In the previous slide, I convinced you that one way or another way of thinking about that expressed almost perfect.

464
01:12:54,447 --> 01:13:00,817
It's you can go either like the increase in SSR or the decrease in SSI.

465
01:13:01,327 --> 01:13:01,597
Right.

466
01:13:01,837 --> 01:13:13,237
So I can also write it as the difference off the SSI from the model with only B Belen minus the SS C from the model with both beta one and beta two.

467
01:13:21,587 --> 01:13:30,077
Okay. So now what is the degree of freedom associated with this extra sum of squares bit that you've given me tomorrow?

468
01:13:31,277 --> 01:13:38,477
It's the number of additional parametres that I have added in common and indication.

469
01:13:40,007 --> 01:13:49,967
So it's what? It's going to be great to be told the dimension of the external matrix.

470
01:13:52,207 --> 01:13:55,237
Or the number of columns in the extremely famous.

471
01:13:58,167 --> 01:14:03,027
How many extra perimeters have I added? So conceptually, think about it this way.

472
01:14:03,267 --> 01:14:14,427
Like by adding a B to its parameters, how much of the variation in y?

473
01:14:14,487 --> 01:14:22,417
I am additionally explaining on top of it gender height.

474
01:14:27,097 --> 01:14:37,307
For me and. Does it make it want to add, you know,

475
01:14:37,877 --> 01:14:44,596
these maybe whatever these may be that number is bad and it struck already thing struck

476
01:14:44,597 --> 01:14:51,767
out at me just in the model if I have only increased my my sister by a small amount.

477
01:14:53,777 --> 01:14:56,507
So how many extra are that number?

478
01:14:56,657 --> 01:15:07,807
What is that number and how small is small that I have to make a judgment call and I'm going to make that judgment call through this extra sum Oscar

479
01:15:07,817 --> 01:15:16,847
so that since it's this why is this is our process to see that in using this are due to X two would equal the big business is due to external.

480
01:15:19,007 --> 01:15:25,907
So that's the concept. Okay.

481
01:15:26,507 --> 01:15:33,707
Now, another important concept, the idea of partial and sequential sample squares for the full design matrix.

482
01:15:35,147 --> 01:15:38,297
I have the following the following at once.

483
01:15:38,297 --> 01:15:51,137
And now I, let's see, I have setup already, it's x1, x2, x2, x1 is like my age gender hybrid x2 is, as I said, income integration.

484
01:15:51,407 --> 01:16:00,797
And let's see, X3 is some kind of lifestyle factors like dietary intake, walking alcohol intake.

485
01:16:03,067 --> 01:16:10,777
So I am kind of trying to trying to understand the effect of this cluster of variables on the outcome.

486
01:16:11,557 --> 01:16:21,257
So I have x money to do X and correspondingly I position the barometer vector on the side of the full parameter vector data.

487
01:16:22,417 --> 01:16:26,887
If you can correspondingly partition, it does better not.

488
01:16:28,267 --> 01:16:30,996
We do the intercept beta one transpose,

489
01:16:30,997 --> 01:16:38,347
beta two transpose with a three transpose transpose up the whole thing because the beta vector is a foreign vector.

490
01:16:41,407 --> 01:17:00,137
So what is partial sum of squares for beta one for a delta like the partial squares is like the extra sample squares due to adding a gender height.

491
01:17:00,137 --> 01:17:14,677
Then we give in that e ga medication, alcohol, smoking, diabetes, all of those and everything else other than that plus there, but only in the model.

492
01:17:15,937 --> 01:17:22,417
So that it says beta one given beta not be that to be that C was already in the model.

493
01:17:22,687 --> 01:17:33,337
So note that beta not the intercept is all this kind of in the inverse of the starting line after that bar sign?

494
01:17:34,597 --> 01:17:45,187
What is the buckets of which would be w it's that is this it's just all squares up and attributable to greater give given beaten up

495
01:17:45,187 --> 01:17:55,477
between one reduction already in the them so excess on all squares attributable to income and education is given by the sum of squares.

496
01:17:55,837 --> 01:18:03,996
The increase in the regression sum of squares you were adding in common education when we already had it gender,

497
01:18:03,997 --> 01:18:08,227
height, weight, nutrition, smoking, alcohol in the model.

498
01:18:10,537 --> 01:18:20,757
And similarly the extra small squares for beta three would be given by SS beta three given beta not be the one beta two, but already in the model.

499
01:18:20,797 --> 01:18:28,047
So not that beta naught. Is always.

500
01:18:31,907 --> 01:18:35,737
After the Bard sign.

501
01:18:35,747 --> 01:18:46,907
Meaning what? That we assume that the starting model always has the beta now.

502
01:18:48,467 --> 01:18:56,477
So the partial sum of squares is somewhat squares like, you know, when we're looking at clusters of variables and you know,

503
01:18:57,647 --> 01:19:05,387
that's how they contribute to explaining the variation in Y given everything else was already getting the model.

504
01:19:07,127 --> 01:19:13,487
Now let's talk about a different kind of some of this sequence sequential, some of this.

505
01:19:17,147 --> 01:19:22,937
And here the order in which you enter the variables in the regression model becomes important.

506
01:19:25,837 --> 01:19:29,617
So the equations, the sequential sum of spiritual data,

507
01:19:29,617 --> 01:19:36,967
one is saying let's start from nothing from the non model and let's add age, gender, height, weight.

508
01:19:39,037 --> 01:19:48,816
So that's the sum of it's the sum of squares attributable to beat along or attributable to age,

509
01:19:48,817 --> 01:19:52,327
gender hatred given only weight and opposing the model.

510
01:19:54,217 --> 01:19:58,926
What about the sequential sample squares for me to do what this is saying?

511
01:19:58,927 --> 01:20:04,267
Okay, now I want to see that 800 was already in the model.

512
01:20:05,437 --> 01:20:10,807
Am I gaining? What am I gaining by adding income and education?

513
01:20:11,737 --> 01:20:18,877
So it's the extra sum of squares attributable to me that do even better now than beta one.

514
01:20:18,877 --> 01:20:29,617
Where in the model? Next for beta three four the lifestyle factors nutrition, alcohol, smoking and same.

515
01:20:31,117 --> 01:20:35,657
Do those variables contribute much or what?

516
01:20:35,677 --> 01:20:45,797
How much do they contribute in explaining the variation in why when I already have the social demographics and the physiologic variables in the model,

517
01:20:45,817 --> 01:20:52,567
so the sum of squares of beta three its just of squares due to bigotry given beta not be the one.

518
01:20:52,567 --> 01:20:59,257
Beta two was already in the model. So what is the four do you see?

519
01:20:59,257 --> 01:21:10,086
Like how the contextually these will these will firstly the partial some of groups and the sequential

520
01:21:10,087 --> 01:21:16,746
somewhat squares how they differ contextually and how they will give different quantities,

521
01:21:16,747 --> 01:21:31,717
different results when then the test is carried out using the factual sample squared for the sequential software and the other one,

522
01:21:31,717 --> 01:21:34,077
the guide one doing for the partial somewhat squares.

523
01:21:34,707 --> 01:21:46,236
It doesn't matter in which ordering in the variables, but in the sequential somewhat square definitely does matter in which order you enter.

524
01:21:46,237 --> 01:21:49,507
The variables do within the future demographics.

525
01:21:49,507 --> 01:21:55,027
First you put in the particular the previous first group of these the lifestyle

526
01:21:55,027 --> 01:22:03,577
factors first that definitely that order will determine how these change.

527
01:22:05,477 --> 01:22:10,187
Okay. So order is important here.

528
01:22:26,897 --> 01:22:30,437
Okay. Question.

529
01:22:43,717 --> 01:22:54,577
We want to. Speaking to.

530
01:23:06,547 --> 01:23:13,157
Yes. Yeah.

531
01:23:13,177 --> 01:23:15,837
So they it in even mind because we knew, you know,

532
01:23:15,957 --> 01:23:25,707
like all the regression models that we have been looking at so far, the disks, the effort, all that [INAUDIBLE].

533
01:23:27,117 --> 01:23:29,627
So we were looking at that statistically.

534
01:23:29,997 --> 01:23:38,187
Then when we see say adjusted, it means that each coefficient is that just before everything else in the model.

535
01:23:39,297 --> 01:23:47,577
So the tests put. So in going back to your question, in most applied situations, we will do partial this.

536
01:23:57,797 --> 01:24:06,017
Yeah. It's cool. Yeah, it uses the whole concept of blockchain investing, so it is adjusted for everything else in the modern.

537
01:24:14,947 --> 01:24:24,277
No, no. Remember, the statistics grade is equal to it holds exactly when all we seem to be getting back.

538
01:24:32,907 --> 01:24:50,187
City. Yeah, yeah, yeah, yeah.

539
01:24:50,197 --> 01:24:54,247
If just for that, for review that particular order.

540
01:24:54,317 --> 01:24:58,347
Yes, you're right. Yeah, but, but, but not the.

541
01:25:00,877 --> 01:25:06,417
50. To.

542
01:25:08,597 --> 01:25:14,237
It still is. It is that the concept is partially at this point everything else in the model.

543
01:25:14,627 --> 01:25:18,857
It's not that okay on top of it, gender.

544
01:25:19,007 --> 01:25:29,997
I think if you add income when there is also like education and other lifestyle factors,

545
01:25:30,617 --> 01:25:38,867
like if you carry on the place in a sequential way, then you can construct sequential access.

546
01:25:39,467 --> 01:25:46,327
But what I'm saying is that in a standard regression model, what you get are kind of the partial.

547
01:25:46,427 --> 01:25:50,597
And just for everything else in the model, there is no order that is.

548
01:25:53,137 --> 01:25:56,677
Involving everybody. Well, that makes sense.

549
01:25:58,327 --> 01:26:04,327
So typically you do a partial. Yes. Unless and in fact,

550
01:26:04,367 --> 01:26:17,807
there's a hallmark that's even more fun where we tell you to actually do it in a certain order and then you carry out the sequential tests.

551
01:26:18,917 --> 01:26:24,347
But then we tend to argue the positive side of the problem.

552
01:26:25,067 --> 01:26:31,167
Then we tell you to argue that in the applied setting, does it make sense to do it as a sequential,

553
01:26:31,167 --> 01:26:40,287
since there should be really had to be done as a function? There are some scenarios where you may want to do a sequential test,

554
01:26:40,287 --> 01:26:49,077
but typically the sort of what is reported are based on partial tests, but partial software.

555
01:26:51,107 --> 01:26:58,157
Okay. So that's the concept.

556
01:27:00,957 --> 01:27:05,996
Not once again a city under the null model is equal to SS.

557
01:27:05,997 --> 01:27:11,967
Why SS are under the NOL model in Plato we saw that.

558
01:27:12,387 --> 01:27:26,697
So just a little bit of three in algebra, the partial, the extra sum of squares of veto on given based on what was in the model.

559
01:27:27,957 --> 01:27:32,516
You can write it as the difference between the SSR from the model.

560
01:27:32,517 --> 01:27:38,217
With both, we cannot be the one minus the SSR with in the model with only beta.

561
01:27:38,217 --> 01:27:47,096
No, because this is zero. Right. So carry it forward.

562
01:27:47,097 --> 01:27:50,217
Now introduce me to do. It's an extra sum of words.

563
01:27:50,217 --> 01:27:56,727
We do better do given beta one maybe a little in the model by definition is the SSR.

564
01:27:57,657 --> 01:28:05,486
We better do better. One we cannot in the model minus the SSR, we beta one and beta are not in the model.

565
01:28:05,487 --> 01:28:11,127
So this is the part after the bar sign that's one model.

566
01:28:11,127 --> 01:28:14,367
And before the Mars sign is what you added struck.

567
01:28:15,387 --> 01:28:24,596
So the extra sum of squares are attributable to beta do given beta one beta are not,

568
01:28:24,597 --> 01:28:29,877
but already in the model in that is the difference in the SSR from the model.

569
01:28:29,877 --> 01:28:39,297
We better not be the one with the two and the SSR with only beta, not in between in the model.

570
01:28:41,397 --> 01:28:52,047
So if you can write by definition that all. So now you can write the SSR bring that negative SSR beta one beta, not to the left.

571
01:28:52,827 --> 01:29:06,287
So you can write it as SSR of bitterness. And beta one is equal to the extra sum of squares for beta one given beta not was in the model blood.

572
01:29:06,327 --> 01:29:13,557
We don't because it's this are for bitcoin to be zero so this one comes from here this flipping.

573
01:29:17,477 --> 01:29:21,017
And the quantities. And what about from here?

574
01:29:21,107 --> 01:29:27,467
From here to here? What you have is that it's this are for better, not better want better do.

575
01:29:27,467 --> 01:29:36,526
You can write it as it says extra sum of squares for better two, given beta one and better not in the model blah states the sum of squares.

576
01:29:36,527 --> 01:29:43,307
You can write it like as a chain extra sum of goods attributable to beta one

577
01:29:43,307 --> 01:29:49,907
given beta not in the model plus the it says are for better not with is zero.

578
01:29:53,327 --> 01:29:57,887
Okay. So I'm just sort of changing sides of these quantities.

579
01:30:00,047 --> 01:30:12,647
And what do I get? So can you can I keep on, you know, kind of add more variables, beat up three or more possibilities better 3 to 4 and so on.

580
01:30:13,307 --> 01:30:28,157
And you can apply the same sort of logic, same sort of principle to write the extra sum of squares like this, you know, kind of in a recursively.

581
01:30:28,937 --> 01:30:39,016
So extra sum of squares attributable to be better to beta one given beta are not in the model can be written as the extra sum of spurs

582
01:30:39,017 --> 01:30:49,037
due to beta two given beta wanted beta not in the model last thanks to some of squares of beta one given beta no this in the model.

583
01:30:49,097 --> 01:30:52,397
So you can kind of write this in a recursive fashion.

584
01:30:55,777 --> 01:31:09,057
Okay. Everybody see this once again, this is another place where you have to firstly get the concepts right, think about it,

585
01:31:09,057 --> 01:31:22,497
and then sit in a quiet corner after your 6 to 1 exam and convince yourself that we can write this in a record.

586
01:31:22,947 --> 01:31:26,247
So I think I'm going to end here.

587
01:31:30,027 --> 01:31:38,097
Stop here. And we will come back to nested models on Tuesday.

588
01:31:38,977 --> 01:31:45,817
Okay. Thank you. And good luck for the midterm this afternoon.

