1
00:00:31,040 --> 00:00:34,220
Okay. Let's get started. Good morning.

2
00:00:37,300 --> 00:00:51,670
So yeah. So it's been, it's been two month we says since we started this of course now we're well after the turning point, uh, halfway through.

3
00:00:52,240 --> 00:00:59,530
So, uh, but there are, you know, multiple things going on.

4
00:00:59,530 --> 00:01:06,940
So I just wanted to explain what the expectations are and.

5
00:01:10,000 --> 00:01:13,910
Yeah. And we're going to go through this multicolor integration.

6
00:01:14,840 --> 00:01:19,780
So. Just so.

7
00:01:19,780 --> 00:01:24,090
Let's see. So.

8
00:01:27,350 --> 00:01:34,280
So homework for us to do next week. So I gave one more week because we had one.

9
00:01:35,490 --> 00:01:43,140
One lecture escaped. And I think now we covered all the material, but previously some material wasn't covered.

10
00:01:44,540 --> 00:01:54,470
So and midterm project is out now it's a due is November 23rd.

11
00:01:56,220 --> 00:02:00,990
I encourage you to start earlier.

12
00:02:02,370 --> 00:02:07,920
So two weeks from the completing of the company, a of four might not be enough.

13
00:02:08,550 --> 00:02:23,010
So just to keep keep it in mind that you, you know, this is this midterm project is could it be a little more challenging than previous homeworks.

14
00:02:24,450 --> 00:02:30,200
So. So we don't midterm projects.

15
00:02:30,860 --> 00:02:39,640
You're going to see Colette Page and I basically you need to work with this this this concept of the story, this one.

16
00:02:41,720 --> 00:02:44,980
So you need to feel the specific part in the qualities.

17
00:02:45,010 --> 00:02:49,640
If you know what you're doing should be should be actually trickier than.

18
00:02:51,080 --> 00:02:54,780
How trickier than the typical homeowner problem there.

19
00:02:54,800 --> 00:03:00,470
There are a couple of differences from homo assignment for with.

20
00:03:02,450 --> 00:03:06,530
With a mid-term project. So mid-term project is basically like a take home exam.

21
00:03:06,940 --> 00:03:16,280
Okay. So even though I said it's a project in this year, I gave so previously a little bit,

22
00:03:16,280 --> 00:03:23,080
it wasn't that the project was a little bit open ended, but this this year I made it very clear the what the the expectation is because,

23
00:03:23,960 --> 00:03:34,250
you know, open ended questions ended up not being very useful in terms of diversity of the answers that students choose to do,

24
00:03:34,280 --> 00:03:44,150
whatever the easiest way to do. So I, uh, I just specify what exactly we want is more like a, like a exam.

25
00:03:44,810 --> 00:03:54,380
So you can, so you're never, you're never allowed to talk about midterm term project with anyone else.

26
00:03:54,840 --> 00:03:59,810
Okay, this one is not. You shouldn't discuss with anyone else.

27
00:04:00,230 --> 00:04:05,960
This is all this. This is on your own. So you need to solve this problem on your own.

28
00:04:06,350 --> 00:04:16,970
You can discuss with instructors if you need help, but unlike homo problems, we're not give exact.

29
00:04:18,180 --> 00:04:23,730
Uh, you know, help. Okay, so we're not provided we're not going to provide detailed help.

30
00:04:24,300 --> 00:04:28,530
We are going to provide what the problem is.

31
00:04:28,660 --> 00:04:36,810
Okay. So if you if you if you're so if your code has has some problem, if you are struggling with some issue,

32
00:04:37,170 --> 00:04:44,309
we can say, oh, your code, you know, your code seems like having a problem in numerical precision.

33
00:04:44,310 --> 00:04:47,670
For example, you need to deal with very small numbers very well.

34
00:04:47,940 --> 00:04:52,350
So that that could be a hint. But but that that's it. So we're not going to go into all this.

35
00:04:52,560 --> 00:04:57,390
You need to change this line to this and so on. We're not going to give that kind of detailed.

36
00:04:59,490 --> 00:05:07,740
Help so that the help from these trucks is in instructors will be provided but in a limited capacity.

37
00:05:08,550 --> 00:05:11,640
So yeah, those are what you should expect.

38
00:05:11,870 --> 00:05:17,909
Okay. So this is this would be more challenging than typical homework problems in a this

39
00:05:17,910 --> 00:05:25,860
is really trying to assess whether you can solve this problem of the yourself.

40
00:05:26,070 --> 00:05:29,550
So that's there's something you wanted to keep in mind.

41
00:05:30,330 --> 00:05:34,910
So. Let me just go through what the problem is.

42
00:05:34,970 --> 00:05:41,690
Lovely. You have a three problems. You may not understand everything now, but I'm going to.

43
00:05:44,270 --> 00:05:47,530
So a lot of a lot of parts you don't need to modify.

44
00:05:47,540 --> 00:05:50,850
So if you see there is a most of the cells that do that, modify the cell.

45
00:05:50,870 --> 00:05:56,120
That means that you should not you should not change this content on the part.

46
00:05:56,150 --> 00:06:03,100
You need to change the content is the part that that, you know, that has underlined.

47
00:06:03,320 --> 00:06:06,440
Let me show what what it is. But the problem is.

48
00:06:06,680 --> 00:06:16,370
Here is where we're dealing with this handwritten digit images, 28 by 28 pixel images.

49
00:06:18,050 --> 00:06:26,510
And the task is to use these images to to perform the classification or clustering.

50
00:06:26,510 --> 00:06:31,130
But you don't need to know what class classification or clustering is.

51
00:06:31,670 --> 00:06:37,130
You just need to follow a specific. So this is not a machine learning class.

52
00:06:37,340 --> 00:06:44,330
So we're not doing actually machine learning. We're actually trying to fit the numerical images to perform the numerical optimization.

53
00:06:45,050 --> 00:06:51,680
So first task is that is to binary classification of these these digits.

54
00:06:51,890 --> 00:06:57,950
So you're going to among these different digits, we're going to select two digits, zero and one,

55
00:06:57,950 --> 00:07:04,370
for example, and try to field a classifier that classifies between those two labels.

56
00:07:04,580 --> 00:07:15,660
Okay. So response variable is zero or one, for example, and the predictor variable is all the individual pixels.

57
00:07:15,680 --> 00:07:21,969
Okay. 784 pixels. So you have you have a 780 428 by 2020.

58
00:07:21,970 --> 00:07:35,720
8784. So. You have that 784 predictors and you're trying to perform the largest regression basically to try to perform zero in one classification.

59
00:07:35,720 --> 00:07:42,170
But because these are a lot of dimensions you need to do, some are penalized.

60
00:07:42,440 --> 00:07:46,190
And so we're going to do the logistic regression we're going to implement.

61
00:07:46,190 --> 00:07:49,880
So this is the regression you're going to implement. Okay.

62
00:07:50,540 --> 00:07:56,059
So but you're not allowed to use any external packages.

63
00:07:56,060 --> 00:07:58,190
You you need to implement your own.

64
00:07:58,670 --> 00:08:11,420
And the thing we're asking you to do is that we gave you that likely function like this and you need to just use the optimum function,

65
00:08:11,570 --> 00:08:17,690
make optimization that is a you built in R to actually perform this optimization.

66
00:08:17,720 --> 00:08:29,030
Okay. So what you need to do is basically find just to figure out how to use optimum function to do this fitting, numerical fitting.

67
00:08:29,240 --> 00:08:34,730
Okay. So that's so this is a numerical optimization problem.

68
00:08:35,330 --> 00:08:44,110
So that's the task one. A Okay. And and the different parties that you saw.

69
00:08:44,110 --> 00:08:51,110
Basically, if there's any underlying part, this is the underlying the parties, the part you need to fill your answer in.

70
00:08:51,260 --> 00:09:01,390
Okay. So you're not only required to implement the code, you need to explain your code here, too.

71
00:09:01,420 --> 00:09:12,060
So mathematical derivation, how to came up with a gradient here and how you how you actually use these functions to plug them in.

72
00:09:12,070 --> 00:09:17,229
So this is this is what my solution looks like in your code.

73
00:09:17,230 --> 00:09:25,000
So you just need to describe your embodiment conceptually so that that's what you need to, it doesn't have to be long.

74
00:09:25,000 --> 00:09:30,670
And actually just giving the short, showing your work briefly, you don't have to show every step.

75
00:09:31,150 --> 00:09:34,600
You just need to show your work briefly and.

76
00:09:35,440 --> 00:09:38,470
And, and. Yeah.

77
00:09:38,800 --> 00:09:43,000
And put in putting your code and this party's evaluation.

78
00:09:43,000 --> 00:09:48,850
You're not supposed to change this part. It's just, for example, in this case, if you run this,

79
00:09:49,360 --> 00:09:57,579
basically the classification works about 99.8% of time in, in, in the example code that I implement.

80
00:09:57,580 --> 00:10:01,120
So this is just a, you know, this is one possible answer.

81
00:10:01,240 --> 00:10:03,280
You don't have to get exactly the same answer.

82
00:10:03,550 --> 00:10:09,940
So this is also just this or the one one difference in terms of grading is that we are going to look at your code.

83
00:10:10,030 --> 00:10:13,030
We're going to do the do the grading manually.

84
00:10:13,030 --> 00:10:22,330
So the getting the result the right I mean, is important, but you don't have to get exactly the right result here based on the implementation.

85
00:10:23,710 --> 00:10:28,690
Your answers could be slightly different, less, slightly less accurate and so on.

86
00:10:28,690 --> 00:10:34,209
That's that's totally fine. In this case, my, my code took 2 seconds for your input to solve this problem.

87
00:10:34,210 --> 00:10:42,820
In this particular example, your code could take a little bit longer or a little bit faster, but lawfully,

88
00:10:42,820 --> 00:10:51,400
if your code is less than you know, you know about about the same speed or twice or twice slow, that's totally fine.

89
00:10:51,490 --> 00:10:55,240
If it's like ten times slow, you may not you may not get a full credit.

90
00:10:55,930 --> 00:11:04,360
Okay. And the accuracy wise, it's a if it's a reasonably accurate, since accuracy is similar,

91
00:11:06,010 --> 00:11:09,340
you're going to get you're going to be eligible to get a full credit.

92
00:11:09,760 --> 00:11:16,930
Okay. And yeah, so. And in the tests.

93
00:11:17,150 --> 00:11:21,110
Oh I should have said Tesco won't be I. This is my mistake.

94
00:11:21,110 --> 00:11:28,310
I'll change this. Tesco on B is so extended to the multi digit classification.

95
00:11:28,520 --> 00:11:36,110
Okay so if you do this multiple multi digit classification, this is how the likelihood looks like.

96
00:11:36,500 --> 00:11:46,940
So it should be pretty much straightforward. Four is a is a it's a pretty similar but here the the the tricky part is the

97
00:11:46,940 --> 00:11:56,630
the the parameter you need to estimate B okay is the is a matrix not a vector.

98
00:11:56,870 --> 00:12:02,689
Okay? But the ultimate function takes the takes a vector as a inputs.

99
00:12:02,690 --> 00:12:08,120
So you need to just change the change the shape of these simple parameter to fit into the function.

100
00:12:08,120 --> 00:12:13,549
So you need to tweak a little bit to, to utilize the optimum function.

101
00:12:13,550 --> 00:12:18,590
So that slight, slight modification is needed compared to the previous ones.

102
00:12:19,040 --> 00:12:23,600
And you can see otherwise it's a pretty much the same.

103
00:12:24,290 --> 00:12:30,260
And you can if you have any questions you can ask, you can ask in this case or zero in one in seven.

104
00:12:30,500 --> 00:12:39,940
I mean, accuracy is not as good as before, but you got some accuracy here and a Yeah, so, so this is one example, uh,

105
00:12:40,820 --> 00:12:49,520
result with the multi, multi class, uh, classification, but a principle should be pretty much the same within task one.

106
00:12:50,180 --> 00:12:54,049
You, you need to fill in this part whenever there's underlying you need to fill in.

107
00:12:54,050 --> 00:13:00,709
So test score one after running this, you're going to need to briefly report that what, what your finding was.

108
00:13:00,710 --> 00:13:04,580
And this part will, will take a small amount, a small amount of points.

109
00:13:04,580 --> 00:13:09,230
But if you need to fill this in, okay, so that's task one.

110
00:13:09,920 --> 00:13:15,250
Task two is the part. So you need to learn. Yeah. My revision to, to solve this we're going to learn.

111
00:13:15,260 --> 00:13:18,340
Yeah. Resume soon. So yeah.

112
00:13:18,400 --> 00:13:26,600
Yeah. So basically this is a clustering. So the first one classification, you take the labels and you take the, uh,

113
00:13:27,200 --> 00:13:34,830
the predictors in this case the images and to, to build a classification classifier in task to you.

114
00:13:35,480 --> 00:13:44,420
You are unaware of the label at all and you're trying to cluster these high dimensional the image data into different classes.

115
00:13:44,780 --> 00:13:49,400
And a year ago, this is a good way to accomplish it.

116
00:13:49,550 --> 00:13:57,709
So you need to basically implement the algorithm with this particular in a likely the model.

117
00:13:57,710 --> 00:14:05,270
So you need pretty much everything is a given. So I think you just need to come up with a particular algorithm and implement it.

118
00:14:05,900 --> 00:14:09,590
Most of the cases you need to deal with some numerical precision problems.

119
00:14:10,340 --> 00:14:14,450
So you might you might even you might have have to handle a very, very small value.

120
00:14:14,450 --> 00:14:19,549
And you need to try to think about how to deal with those values efficiently.

121
00:14:19,550 --> 00:14:24,380
And those are some tricky part you need to figure out yourself.

122
00:14:24,890 --> 00:14:30,440
Okay. And we are allowing also.

123
00:14:33,340 --> 00:14:37,600
Extra credit. A problem this is not meant to be overburden you.

124
00:14:37,620 --> 00:14:43,180
So this is really optional because task one it has to total 100 hundred points.

125
00:14:43,540 --> 00:14:48,249
The maximum points in Tesco three you can get is ten points, but you're probably not.

126
00:14:48,250 --> 00:14:52,210
So, you know, ten points is really the rare okay.

127
00:14:52,660 --> 00:15:02,620
And usually if you do some extra task, those will be will be worth about 2 to 3 points or five points depending on how hard those task were.

128
00:15:03,010 --> 00:15:11,559
But if you if you have additional bandwidth and if you wanted to improve upon from from what you have done,

129
00:15:11,560 --> 00:15:16,210
what is required, you can try some additional thing and.

130
00:15:18,020 --> 00:15:23,000
And, you know, explore the problem more for your improved understanding.

131
00:15:23,010 --> 00:15:27,810
So that's the intention of these extra credit problems. Okay.

132
00:15:28,430 --> 00:15:37,169
Uh, so. So that's the overview of the term project I know that you're working on the homework for,

133
00:15:37,170 --> 00:15:41,700
but I just wanted to give a background so that you can get started with this.

134
00:15:43,360 --> 00:15:46,760
Test. Test one at least the test two. You probably need to wait.

135
00:15:46,910 --> 00:15:54,930
Wait until the EMR region is covered. If you look at these both from exercise and homework.

136
00:15:55,420 --> 00:16:00,560
Yeah, you can use anything from lectures like the homework. You're not allowed to use any external packages you.

137
00:16:05,990 --> 00:16:09,150
Okay. So.

138
00:16:10,870 --> 00:16:16,179
Now let's jump onto the so we need to go through the Yemen question, which is a lecture 14 I think.

139
00:16:16,180 --> 00:16:20,499
So I can switch switch of the order if needed, if we're really behind.

140
00:16:20,500 --> 00:16:27,310
But I don't think we have to. So let's, let's I believe I can catch up with the Yemen within the next week.

141
00:16:28,120 --> 00:16:35,660
Okay. So. Monte Carlo integration.

142
00:16:35,840 --> 00:16:39,590
Okay. So that's. That's the part we need to cover.

143
00:16:39,590 --> 00:16:42,930
So. Today. So.

144
00:16:44,360 --> 00:16:48,280
Before going there. Any other question? Okay. Okay.

145
00:16:51,080 --> 00:16:55,530
So what they call integration. Okay. So. Uh.

146
00:16:57,190 --> 00:17:02,080
So let's think about the problem of integrating some function.

147
00:17:02,290 --> 00:17:08,710
Okay, then let's think about the problem of integrating some function from 0 to 1.

148
00:17:09,070 --> 00:17:15,400
How would integrating? Well, if you know how to do the whole thing analytically, you can do it.

149
00:17:16,090 --> 00:17:20,139
But what if? What if you cannot write?

150
00:17:20,140 --> 00:17:26,590
So why? What if the integration is not possible to do analytically?

151
00:17:26,590 --> 00:17:32,260
You can do numerical integration. In that case, what kind of algorithm can you do?

152
00:17:32,440 --> 00:17:44,680
Okay, so maybe you because integration is calculating the country in the region under the curve.

153
00:17:45,190 --> 00:17:52,290
One way to think about it is that, oh, I'm going to generate this uniform, uniform, this piece.

154
00:17:52,840 --> 00:17:59,380
So. The evenly spaced grid and you can calculate the regions.

155
00:17:59,560 --> 00:18:05,290
So that's one way to do it. But another way to do it is that you can.

156
00:18:05,440 --> 00:18:09,370
Oh, why don't me. Why don't I just generate.

157
00:18:11,380 --> 00:18:15,750
Uniformly should be value from 0 to 1 and take the average it.

158
00:18:16,810 --> 00:18:21,190
So that should be fairly similar to what you're doing here.

159
00:18:22,030 --> 00:18:28,509
And in this case, the taking average works because of just it's conveniently the width with some of these antibodies.

160
00:18:28,510 --> 00:18:34,450
One, but if you have different interval, you can just divide by the wages of this rectangle.

161
00:18:35,080 --> 00:18:38,140
So that's what that's what you can do.

162
00:18:38,170 --> 00:18:47,320
So I think this is a this is a pretty, pretty straightforward, you know, algorithm you can think about.

163
00:18:48,040 --> 00:18:52,839
We're going to go through the order of the mathematical details and so on.

164
00:18:52,840 --> 00:18:57,760
But the the listing in terms of the.

165
00:18:59,470 --> 00:19:07,510
In in terms of the method itself, I think it should be relatively easy to understand.

166
00:19:07,510 --> 00:19:17,470
So let's see if this works. Okay. So for example, if you try to compute this integral X squared from 0 to 1, what is the expected value?

167
00:19:18,670 --> 00:19:26,620
Well, what though? One is a one third x x cubic from 0 to 1, so it should be one third.

168
00:19:26,800 --> 00:19:36,040
If you integrate it analytically, it but let's say let's pretend I don't know how to integrate and analytically.

169
00:19:36,040 --> 00:19:44,859
So let's try to do integrate numerically. Okay, so this function is written in this way.

170
00:19:44,860 --> 00:19:51,190
So I am going to create simple m different numbers.

171
00:19:51,340 --> 00:19:55,960
Okay. So this is the number of random numbers I'm going to simulate.

172
00:19:56,860 --> 00:20:01,150
And uh, integration is a function F of X.

173
00:20:01,390 --> 00:20:07,470
Okay. And a simpler is the the.

174
00:20:07,570 --> 00:20:13,100
This the. The sampling function of this random variable.

175
00:20:13,230 --> 00:20:20,820
The in this case, the simpler simpler was uniform distribution here.

176
00:20:20,830 --> 00:20:26,040
So I'm going to going to use a uniform distribution in this particular example.

177
00:20:26,040 --> 00:20:30,540
So simpler is a uniform distribution integral and these X squared.

178
00:20:30,720 --> 00:20:34,470
Okay. And M is the different number of.

179
00:20:36,480 --> 00:20:43,850
It's a random sample. Okay. So. And in this case, basically, these parties are taking the mean.

180
00:20:43,860 --> 00:20:52,170
So why don't I just take them in? Okay. So obviously, this doesn't work for all cases, but this should work in the case, too.

181
00:20:52,530 --> 00:20:56,610
When you integrate from 0 to 1. So this is a special case.

182
00:20:57,480 --> 00:21:07,740
So I know the answer. And Spencer is sorry.

183
00:21:25,930 --> 00:21:29,450
Mm hmm. Sorry.

184
00:21:30,010 --> 00:21:37,070
Now I feel okay. Okay. So. So in this case.

185
00:21:38,790 --> 00:21:42,900
Uh, we use that. You know, the answer is a 0.3 one third.

186
00:21:43,530 --> 00:21:52,830
But if you use a 1010 random sample in this particular case, the answer is far, very far from what I hoped.

187
00:21:53,010 --> 00:21:58,770
If you try different ten numbers, this number changes a lot as you see.

188
00:21:59,340 --> 00:22:03,630
So this is a not very reliable way to do it.

189
00:22:03,960 --> 00:22:14,670
So you may be tempted to just do the grid based integration, which is fine, but we're trying to find a way to do the use the random numbers here.

190
00:22:15,330 --> 00:22:22,080
So if you use a thousand random numbers, this looks fairly close to 0.33.

191
00:22:22,080 --> 00:22:31,920
And it doesn't doesn't change much. So that this is good if you use 100,000, this value is even more accurate, in fact.

192
00:22:33,390 --> 00:22:40,740
Well, it does it does seem to be very, you know, very close to 0.333.

193
00:22:40,740 --> 00:22:44,130
So it has a precision of pretty, pretty.

194
00:22:45,850 --> 00:22:49,660
In a pretty stable precision in up to two.

195
00:22:50,940 --> 00:22:57,249
2 to 3 digits. Okay. So this method actually works.

196
00:22:57,250 --> 00:23:04,150
But we're going to try to understand more on this kind of integration throughout the lecture.

197
00:23:05,100 --> 00:23:14,760
Okay. So when we try to use these random numbers to perform the integration, what kind of properties do we need?

198
00:23:14,940 --> 00:23:24,030
Okay. So. So first property we want is the consistency.

199
00:23:24,040 --> 00:23:31,449
So if we use the more and more random variable we're going to where we're going to expect to

200
00:23:31,450 --> 00:23:40,450
see the value that that are after this numeric integration is converted to actual true value.

201
00:23:40,450 --> 00:23:46,060
So these are so well that so that's the test consistency.

202
00:23:46,150 --> 00:23:51,639
Okay. And second part is that, you know, you want this to be unbiased.

203
00:23:51,640 --> 00:23:59,170
So if it gives a bias, if it's always give a larger, larger value than what it should be, that's not ideal.

204
00:23:59,170 --> 00:24:03,160
So we want to minimize the bias in either direction.

205
00:24:04,000 --> 00:24:13,899
Similarly, we want to minimize the variance. So if we use the, you know, tenant on variable, that thousand random variable 100,000 random variable,

206
00:24:13,900 --> 00:24:21,160
we expect that there are some variation, but we want the variation is as small as possible.

207
00:24:21,310 --> 00:24:25,650
Okay. So how do we assess those things?

208
00:24:25,660 --> 00:24:30,450
So bias is basically expectation of these.

209
00:24:30,780 --> 00:24:43,740
Our estimate in this estimate in this case, where in these particular cases, if you wanted to calculate the expectation,

210
00:24:43,770 --> 00:24:52,530
this expectation can be just a can can be it can be represented by a combination of each of the components.

211
00:24:52,980 --> 00:25:01,340
Okay. So what matters is that what's the expectation of these actual F of f of u of I and f of u of I?

212
00:25:01,410 --> 00:25:14,220
If you calculate the expectation, if you think about this, uh, this is actually just, you know, this, this value itself is this value.

213
00:25:14,250 --> 00:25:19,290
Right? So this, this value itself is theta.

214
00:25:19,440 --> 00:25:27,120
So the expected expected value of theta head is exactly the same as data.

215
00:25:27,270 --> 00:25:30,420
Okay. How about the variants?

216
00:25:30,540 --> 00:25:34,200
Where variants of data had less is.

217
00:25:36,910 --> 00:25:41,709
Can be represented in this way. So because the expectation is theta.

218
00:25:41,710 --> 00:25:45,250
So you can represent this way and.

219
00:25:48,830 --> 00:25:55,780
So then you can represent these variances in this way.

220
00:25:55,790 --> 00:26:00,820
So this is this is this is just simply using the widget.

221
00:26:00,850 --> 00:26:05,180
The fact that the of x x bar.

222
00:26:06,640 --> 00:26:09,700
Here with this is Vegas, right?

223
00:26:10,570 --> 00:26:18,400
Uh. Is the same as the expectation in spirit and expectation of spirit.

224
00:26:18,670 --> 00:26:28,360
So we're just using this and, uh, you can represent, uh, represent these things in this way.

225
00:26:28,510 --> 00:26:34,720
Okay. So. So this.

226
00:26:36,630 --> 00:26:42,580
So they said this is the one. Yeah.

227
00:26:42,670 --> 00:26:52,260
So, so this is a way to calculate the variance and consistency because the expectation is theta that it is a consistent estimate.

228
00:26:52,390 --> 00:26:56,830
It is pretty. Straight forward to show that.

229
00:26:56,950 --> 00:27:00,530
So we show that the bias is this consistency.

230
00:27:00,550 --> 00:27:08,590
It is consistent. And we didn't prove that this is the minimum possible variance, but we are list of quantified how the variance looks like.

231
00:27:09,460 --> 00:27:15,670
Okay. So this is a this is one possible way to do the integration.

232
00:27:16,180 --> 00:27:20,140
Now, let's set it aside and let's think about other way to do it.

233
00:27:20,380 --> 00:27:31,810
Okay. So the next way to think about it, think about the integration is think about think of this problem as except to reject multi-color integration.

234
00:27:32,020 --> 00:27:47,930
Okay. So. So we're still talking about the very specific example where, you know, every every X and Y is just between zeros and ones.

235
00:27:48,050 --> 00:27:51,170
So so that we can think about the problem in easy way.

236
00:27:52,160 --> 00:28:03,150
So in the case, the algorithm is basically you can think about a define a rectangle from from the 020 0 to 1 one in.

237
00:28:03,200 --> 00:28:06,820
If you want it to be more general, you can specify different rectangle.

238
00:28:06,830 --> 00:28:10,760
But now just to, you know, think about is this problem.

239
00:28:11,960 --> 00:28:15,380
And let's say a chico h means hit.

240
00:28:15,380 --> 00:28:26,300
No, hit and miss. Miss. And and now, instead of sampling from the single dimensional point about we're going to sample from the two dimensional point.

241
00:28:26,570 --> 00:28:30,590
Okay. And you probably remember this in the accepted reject.

242
00:28:30,890 --> 00:28:35,960
Uh, the yeah. Except to reject, uh.

243
00:28:37,710 --> 00:28:43,230
The. Sampling problem in in the previous lecture.

244
00:28:43,680 --> 00:28:51,720
But the strategy here is that if Y is less than F of X, we increase the number of hits.

245
00:28:52,020 --> 00:28:55,580
If not, we increase the number of. Ms. Mrs. Okay.

246
00:28:56,160 --> 00:29:02,100
And repeat the step three and four with the specified number of times.

247
00:29:02,400 --> 00:29:08,310
And then our integration estimate here is.

248
00:29:11,290 --> 00:29:18,490
Yeah. Is the ratio between H and M so eight more eight divided by eight plus h plus n.

249
00:29:18,940 --> 00:29:22,410
So the proportion of H. So.

250
00:29:25,770 --> 00:29:37,320
So this only works in me when whenever the iPhone X is rated between zero and one and also doesn't have the value that is greater than one.

251
00:29:37,480 --> 00:29:40,710
But so this is a special case.

252
00:29:41,550 --> 00:29:46,170
But for example, a y equals y equals x squared.

253
00:29:47,010 --> 00:29:54,090
She can be calculate this way or y equals one minus x squared.

254
00:29:55,410 --> 00:30:04,080
Security like this. This is actually the horror of a circle so that that can be calculated.

255
00:30:04,740 --> 00:30:07,830
If this works. Right. So.

256
00:30:09,530 --> 00:30:14,120
So do you think these are going to work? So do you understand what this argument does?

257
00:30:16,290 --> 00:30:20,380
First. So let's say.

258
00:30:21,820 --> 00:30:25,360
Well, I mean, let's let let's let's talk about this.

259
00:30:25,720 --> 00:30:31,090
Oh, the we want to calculate this area basically like scared.

260
00:30:31,330 --> 00:30:35,500
Right. So then how do we calculate it?

261
00:30:36,220 --> 00:30:42,880
So the the strategy here is that I'm going to generate a lot of random plots here.

262
00:30:43,450 --> 00:30:51,940
Okay. And I'm going to calculate how much fraction of these these these dots are below this curve.

263
00:30:52,660 --> 00:30:59,710
And I'm going to call that from proportion as integration. That that works because the total area here is one.

264
00:31:00,190 --> 00:31:07,899
So if you if you're talking about different rectangle, we need to adjust the by the by the area of the rectangle.

265
00:31:07,900 --> 00:31:11,740
But otherwise these are we can actually should work.

266
00:31:12,070 --> 00:31:15,270
Right. But other.

267
00:31:15,390 --> 00:31:20,930
So the question is. So we now have a two day program in the first hour.

268
00:31:21,110 --> 00:31:33,980
So this is the exact registration. And the other way we did is that we just randomly sample one dimension of value and calculate the F of X, right.

269
00:31:34,670 --> 00:31:39,830
And take the average right. Which one do you think it's better?

270
00:31:41,710 --> 00:31:46,180
In terms of bias variance, consistency.

271
00:31:52,640 --> 00:31:59,330
So this is a method one we tried. Okay, now this method two is acceptable.

272
00:31:59,330 --> 00:32:05,930
Reject method. Okay. And this is, I think, the name name integration.

273
00:32:07,600 --> 00:32:11,410
So raise your hand if you think the method one will do better.

274
00:32:14,960 --> 00:32:19,700
Raise your hand if you think method two will do better. Okay.

275
00:32:19,850 --> 00:32:25,580
Well, we have a pretty good contenders. We have we have argument for those for both.

276
00:32:26,060 --> 00:32:32,100
Why do you think about that? So it so people who think they matter, the one you will do better.

277
00:32:32,120 --> 00:32:38,180
Why do you think so? Any arguments? Good arguments so that you can convince others.

278
00:32:40,190 --> 00:32:48,860
Yeah. It has a smaller variance so that I think that it's a smaller variance.

279
00:32:50,360 --> 00:33:01,390
Okay. What about what about this group? Okay.

280
00:33:04,280 --> 00:33:10,979
No volunteer. Well, I mean, this, except to reject the method is a lesson.

281
00:33:10,980 --> 00:33:14,730
Not naive. So it must be better, right? Okay. There was.

282
00:33:15,180 --> 00:33:21,570
There is, I guess, a lot of people's impression, I think.

283
00:33:22,410 --> 00:33:32,130
So let's see if that is the case. Okay. So we can assess the bias and variance in this way.

284
00:33:32,400 --> 00:33:37,530
Okay. So is it biased or not?

285
00:33:37,540 --> 00:33:46,680
So the way how you can calculate this, this. Because our estimate is basically 80 divided by 80 plus m h is.

286
00:33:48,260 --> 00:33:57,680
All we if we have all you and we a pair two pairs of undies where there are generate the randomly.

287
00:33:57,980 --> 00:34:08,600
Basically the the expectation of theta head is proportion of these of we un we pairs that

288
00:34:08,600 --> 00:34:16,339
is less than this area but so but these rest the proportion proportion of the region.

289
00:34:16,340 --> 00:34:22,840
So this is exactly. Now if you think about this individual problem probability, right.

290
00:34:23,610 --> 00:34:28,730
Uh, yeah, I have to.

291
00:34:29,030 --> 00:34:33,770
Sorry, this is wrong. I'm sorry about. Oh, so I'm sorry about this.

292
00:34:33,980 --> 00:34:38,150
This has to be probability, not the indicator, because it this is expectation.

293
00:34:38,160 --> 00:34:40,970
So I, I just realized this equation is wrong.

294
00:34:41,570 --> 00:34:52,729
So basically the, the key part is that this probabilities theta, the probability that we of we is less than f of you is is exactly this region.

295
00:34:52,730 --> 00:34:57,049
So this region is a critical theta. That's what we're trying to get.

296
00:34:57,050 --> 00:35:05,240
So because these probabilities theta and this is that because we are culprit expectation this this is a probability of indicator.

297
00:35:05,240 --> 00:35:09,500
So expectation of indicator which is the just probability of this happening.

298
00:35:09,980 --> 00:35:16,250
So this is theta, so then it's a B theta divide by B, so this should be theta.

299
00:35:16,340 --> 00:35:19,730
Okay, so bias. So that means that there is no bias.

300
00:35:20,030 --> 00:35:25,999
Okay, how about various? Okay, various might might be a little bit tricky to calculate,

301
00:35:26,000 --> 00:35:37,670
but actually it is actually simpler because you know that the probability that of V of AI is less than half of u of AI is theta.

302
00:35:37,730 --> 00:35:42,410
So you know this. No, no, these are for a fact.

303
00:35:42,650 --> 00:35:46,370
And we are just repeating the same thing be different amount of time.

304
00:35:46,370 --> 00:35:51,760
So theta high is one minus theta E by by B, okay.

305
00:35:51,800 --> 00:35:54,900
This is a binomial distribution variance. Okay.

306
00:35:55,460 --> 00:36:09,200
So because H follows h follows a binomial distribution, so p times so binomial distribution, billions of B times theta one minus theta.

307
00:36:09,200 --> 00:36:17,840
Right? So this, this is h right. But your so this is expectation of H right.

308
00:36:18,380 --> 00:36:25,010
But we're calculating the expectation of eight divided by B because this is total number of trial we're doing.

309
00:36:25,010 --> 00:36:32,000
So you just divide everything by B squared. So this will be this will give you this value.

310
00:36:32,210 --> 00:36:36,920
Okay. So. So this is a variance.

311
00:36:37,250 --> 00:36:45,800
And now let's look at this number and let's look at this number and let's think about which one is better.

312
00:36:45,950 --> 00:36:49,850
Okay. Okay. So. Okay. So.

313
00:36:52,230 --> 00:36:57,670
Fit variants if you look at the first one. So this is the acceptable reject method.

314
00:36:58,390 --> 00:37:03,000
The variance is this and that sigma squared zero.

315
00:37:03,010 --> 00:37:09,070
The variance is this part. Okay. So you can you can take the difference between them.

316
00:37:09,490 --> 00:37:15,400
Then you're going to you're going to have the status care party's gets canceled out.

317
00:37:15,730 --> 00:37:22,090
And what you have is this. Okay. So this part is.

318
00:37:24,310 --> 00:37:32,040
So. So this part is basically you can you can do so.

319
00:37:33,520 --> 00:37:46,050
I'm going to just write one more step to make sure that you can you can translate is being of theta minus expectation of f over you experience.

320
00:37:46,300 --> 00:37:50,120
Right. So this, this is what, what, what came out.

321
00:37:50,890 --> 00:37:57,530
And theta is also expectation of. Expectations of you, right?

322
00:37:57,720 --> 00:38:01,290
So you can replace this as expectation f of you.

323
00:38:02,100 --> 00:38:09,210
Then this becomes expectation of f of you, one minus F of you.

324
00:38:09,450 --> 00:38:13,020
Right. Okay. So you can, you can write that this way.

325
00:38:13,320 --> 00:38:17,100
Okay. Which is which is basically equivalent to this.

326
00:38:17,280 --> 00:38:20,820
Good. So, uh.

327
00:38:22,920 --> 00:38:26,560
So. Then.

328
00:38:26,800 --> 00:38:36,460
Then what we know is that in this particular set of example, we designed F of X to be always confined between zero zero and one.

329
00:38:37,030 --> 00:38:44,230
So this is positive and this is positive. So this has to be always equal or greater than zero.

330
00:38:45,070 --> 00:38:54,490
Okay. So which means that this a well, which means that these various is larger than these various.

331
00:38:54,670 --> 00:39:01,900
So even though accept reject method looks more sounds more advanced than naive method.

332
00:39:02,050 --> 00:39:13,200
Actually, nine method does better in this case. Okay. So, uh, so that's the, uh, the so different method here.

333
00:39:13,260 --> 00:39:18,540
Here, we just try to tell you the impulse to calculate the Monte Carlo integration.

334
00:39:18,870 --> 00:39:30,240
Both of them are valid way to calculate the integration, but and it uses exactly the same number of random random variable for random numbers.

335
00:39:30,750 --> 00:39:36,180
But if you compare the variance, one method has a similar variance than the other.

336
00:39:36,180 --> 00:39:44,580
So that is arguably better method than the other if there's nothing else that differentiate them.

337
00:39:44,720 --> 00:39:58,310
Okay. So this is Tony Temple and we're trying to figure out how do we then pick the good Monte Carlo integration method in different cases?

338
00:39:58,760 --> 00:40:12,570
Okay. So so that's that's state and we're now trying to figure out try to use a little bit different problem to make a more general case.

339
00:40:12,600 --> 00:40:16,559
Previously it was a toy you tempo. Everything is between zero and one.

340
00:40:16,560 --> 00:40:21,420
You cannot use this method for general problems. And now let's try to find the more general problem.

341
00:40:21,570 --> 00:40:26,880
Okay. So the problem we're going to try to calculate is this.

342
00:40:27,900 --> 00:40:31,650
So let's say you have normally this with random variable.

343
00:40:33,120 --> 00:40:39,870
X is normally this random variable. What I want is to calculate this expectation.

344
00:40:41,660 --> 00:40:52,280
Okay. So normally it is a random variable, but you are calculating exponential.

345
00:40:52,900 --> 00:41:06,700
Uh, x. So. So e to the exponential function of x but conditioned on the x is equal or greater than t.

346
00:41:07,120 --> 00:41:12,639
Okay. So. Maybe.

347
00:41:12,640 --> 00:41:15,940
Maybe you may ask why this is important. Okay.

348
00:41:16,360 --> 00:41:26,080
Well, first first thing I want you to make sure is that a lot of Monte Carlo integration problem is actually calculating expectation.

349
00:41:26,950 --> 00:41:31,090
So you have if you want to get working in any kind of area in statistics,

350
00:41:31,600 --> 00:41:41,080
a lot of cases you want to calculate the expectation expectation in the that that's by definition is represented as integration.

351
00:41:41,590 --> 00:41:47,080
So sometimes that that integration may be tricky to calculate analytically.

352
00:41:47,440 --> 00:41:51,310
In that case, you need to use the numerical method. And that's why we are learning this.

353
00:41:52,570 --> 00:42:04,600
And this particular particular form is actually used for form because if a lot of so this is the this is a form that I often use in the finance,

354
00:42:04,630 --> 00:42:13,810
finance or some economic so economist or some some financial finance people are using this,

355
00:42:14,260 --> 00:42:19,600
as I know, because I that's what I heard from the people who taught this.

356
00:42:19,720 --> 00:42:26,100
Okay. So. So these these cases that the decision money.

357
00:42:26,540 --> 00:42:35,040
Okay so is is kind of normally distributed when you take the law of the people it's the money that.

358
00:42:35,760 --> 00:42:42,150
So it the distribution of wealth is more close to the normal distribution than the normal distribution.

359
00:42:42,240 --> 00:42:48,180
Okay. So but sometimes you want to calculate the expectation like let's say what's the,

360
00:42:48,690 --> 00:42:55,410
what's the overall wealth of like top 1% or top 99% or, you know, people who had like a greater than.

361
00:42:56,610 --> 00:43:04,050
So what is the mean income of the people who has like, you know, seven digit salary or something or whatever?

362
00:43:04,100 --> 00:43:13,140
Okay. Then if you wanted to do it, you you if you wanted to make at some distributional assumption, this is a good way to do it,

363
00:43:13,860 --> 00:43:24,360
because you cannot represent the mean as a normal distribution because, you know, wealth is a low normal of this ratio.

364
00:43:24,360 --> 00:43:28,980
So. So this way is a actually practical, useful way to do it.

365
00:43:30,060 --> 00:43:39,180
And this particular way, actually, you don't need a numerical integration because if you know the CDF of the standard normal distribution,

366
00:43:39,600 --> 00:43:42,360
you can analytically calculate this value.

367
00:43:42,810 --> 00:43:51,450
That's why we chose this because it's it's kind of you can calculate it, but it is it is a it is tricky to calculate, right?

368
00:43:51,960 --> 00:43:57,840
So and most of a case you probably can calculate this, this kind of quantity,

369
00:43:57,840 --> 00:44:04,770
some expectation, less analytical leaders and not necessarily analytical solutions.

370
00:44:04,770 --> 00:44:10,380
So in that case, we need the numerical way to do it. So now with this example, we know what the true values are,

371
00:44:10,770 --> 00:44:19,260
and so we can assess how each different algorithm works and then that we're going to figure out how to do it numerically.

372
00:44:19,510 --> 00:44:26,660
Okay. So we're going to pretend that we don't know these closed form solution and we're going to use the Monte Carlo.

373
00:44:27,180 --> 00:44:33,560
Okay. So we're going to try four different methods.

374
00:44:33,650 --> 00:44:41,980
Okay. Sorry. The first method is accept or reject method, hit and miss method.

375
00:44:42,640 --> 00:44:48,160
Second one is the knife. Monte Carlo 39.

376
00:44:48,160 --> 00:44:51,970
Monte Carlo method. And third is that.

377
00:44:53,170 --> 00:45:01,120
Uh, 30. So first second is you're basically using uniform distribution to do the motorcar integration.

378
00:45:01,600 --> 00:45:08,420
There are two methods that we're going to use some non-uniform distribution where the actual actual sampling distribution.

379
00:45:08,530 --> 00:45:14,859
So that's the third method. Fourth method is that we're going to do something called the important sampling.

380
00:45:14,860 --> 00:45:23,050
How many people heard about the important simply? Just I just want you to know how many people used important, important sampling before it.

381
00:45:23,450 --> 00:45:26,560
Okay. So so some people who use it, but most people didn't.

382
00:45:26,600 --> 00:45:30,280
Okay. So that's what I was expecting. So that's good to know. Okay.

383
00:45:30,370 --> 00:45:34,290
So except reject the Monte Carlo method. I'm sorry.

384
00:45:34,630 --> 00:45:40,120
Let me just. But this.

385
00:45:40,280 --> 00:45:43,890
This mask somehow is too small for my face, I guess.

386
00:45:45,340 --> 00:45:49,180
Or by my glad my glass is not cooperating with me.

387
00:45:50,470 --> 00:45:57,250
Okay. So except that Monte Carlo method is a method that we will learn here.

388
00:45:57,250 --> 00:46:06,540
But previously we learned it in a very specific case where you have everything is a 0 to 1, right?

389
00:46:07,000 --> 00:46:12,640
So this is a more general description of accept or reject the Monte Carlo method.

390
00:46:12,980 --> 00:46:18,760
Okay. So you generate a random X and Y from uniform distribution.

391
00:46:19,030 --> 00:46:22,870
That means that you need to define some rectangular space.

392
00:46:23,020 --> 00:46:26,900
Okay. And you need to.

393
00:46:26,920 --> 00:46:34,690
So. So you have some width and height of these are these of this region.

394
00:46:35,060 --> 00:46:41,110
Okay. And you need to identify the point that y is less than four x like this.

395
00:46:41,320 --> 00:46:56,590
Okay. And, uh. So in our cases, we know that if because an F of X is we're trying to integrate this these values so we know this F of X is,

396
00:46:57,040 --> 00:47:04,630
you know, it has some maximum value here. So so we know that this has a this is a maximum value, actually.

397
00:47:04,930 --> 00:47:10,809
So square root of e divide by square root of two to pi is the maximum value.

398
00:47:10,810 --> 00:47:15,400
So we know that this has a maximum value so we can define a rectangle.

399
00:47:15,850 --> 00:47:19,960
Okay. And a culture that hit and miss.

400
00:47:19,980 --> 00:47:25,710
But actually, we can't define the rectangle in the horizontal axis because.

401
00:47:27,160 --> 00:47:34,420
We are calculating this value and this value is X is greater than T.

402
00:47:34,450 --> 00:47:38,440
Right. So it's it doesn't have upper amount.

403
00:47:38,590 --> 00:47:45,660
Right. So. So some sometimes if X is a unbounded uniform, distribution doesn't work.

404
00:47:45,870 --> 00:47:52,649
So how do we do it? Well. Well, if you can ignore extreme values, you can use a mistake that.

405
00:47:52,650 --> 00:48:00,010
Oh, I'm going to use some window with the very large w that is a hand-waving argument.

406
00:48:00,270 --> 00:48:05,310
And the way we took way to do it. But there's one way to still use this.

407
00:48:05,370 --> 00:48:09,200
Accept, reject, multi-color. So.

408
00:48:10,850 --> 00:48:15,800
So let's try this. Except reject the multicolor method here.

409
00:48:16,010 --> 00:48:31,190
Okay. So. So in this case, uh, actually, I, uh, where I skipped this part, I'm, I'm now confused.

410
00:48:31,220 --> 00:48:43,640
Okay. So I was supposed to cover this part to do the exit project one day kind of method to explain what this method does.

411
00:48:43,640 --> 00:48:46,700
But I apparently skip this and sorry about that.

412
00:48:47,120 --> 00:48:52,640
I believe that I was supposed to do this when I explaining when I was explaining it.

413
00:48:53,090 --> 00:48:57,140
So let me let me just try this, because it's just to accept reject multicolor method.

414
00:48:58,190 --> 00:49:03,620
So in this particular case, this is the this is the the quarter circle, right?

415
00:49:04,160 --> 00:49:08,360
So the integration value should be PI over four.

416
00:49:08,630 --> 00:49:12,320
Okay. So let's see what whether this works or not.

417
00:49:12,320 --> 00:49:17,450
The nice thing about this example is that we could have like a previous example of the accept,

418
00:49:17,450 --> 00:49:22,910
reject, multicolor, accept, reject random sampling method.

419
00:49:24,740 --> 00:49:31,810
You can visualize how this function looks like. So basically the same you you read from your sample from direct this rectangle.

420
00:49:31,820 --> 00:49:38,330
But we are counting only the part that are below this, this, this function.

421
00:49:39,620 --> 00:49:44,450
So then this method is basically I'm, I'm going to.

422
00:49:45,080 --> 00:49:49,580
So this particular method is simple because everything is a 0 to 1.

423
00:49:49,580 --> 00:49:54,400
So I'm sampling from a uniform random variable.

424
00:49:54,470 --> 00:50:03,620
And the method is very simple because you are just calculating the number of hits you buy by total number of the random sample.

425
00:50:03,630 --> 00:50:09,780
So this is a very convenient. And here what this has done is that.

426
00:50:12,430 --> 00:50:20,660
The average average that emcees the night Monte Carlo method I try I explain the very beginning and the air that emcee

427
00:50:21,350 --> 00:50:30,590
is the except the project the Monte Carlo method and a it's a a and a and sees an actual value pi over four good.

428
00:50:30,980 --> 00:50:35,360
So this is a true value and this is the estimate from one one method.

429
00:50:35,360 --> 00:50:42,379
The other method is that I use a ten simple 100 random sample and thousand random samples and so on.

430
00:50:42,380 --> 00:50:52,010
So that's how this code is designed. And as you see, you know, the value is which one do you think is doing better?

431
00:50:52,010 --> 00:50:52,370
Well,

432
00:50:52,670 --> 00:51:03,680
it's it's a hard to hard to see but it does it ah it does converge to the right value if you compare very at the very end we're using million samples.

433
00:51:04,070 --> 00:51:11,030
I average this first method does better than the second method in terms of being close to the the true value.

434
00:51:11,030 --> 00:51:15,620
And if you repeat the experiment the multiple times, you will realize that that's the most of the cases,

435
00:51:15,890 --> 00:51:23,240
because the variance of this method is smaller than this method, as we looked at in in our previous slide.

436
00:51:23,360 --> 00:51:31,159
Okay. So this is accept reject Monte Carlo method when when it's defined in just the zero one

437
00:51:31,160 --> 00:51:41,210
unit rectangle rectangle if it's not the if it's not the if rectangle is more general,

438
00:51:41,930 --> 00:51:47,500
you just need to sample from different space here the next x x max.

439
00:51:47,540 --> 00:51:58,000
You need to provide that value. Y value cannot be negative because it should usually represent some, some probability with this density.

440
00:51:58,010 --> 00:52:05,330
So I'm assuming that the minimum value of minimum value of Y's is zero and a maximum value is a y y max.

441
00:52:05,870 --> 00:52:17,569
So then you calculate the proportion that are that are accepted, but you now need to rescale them based on the region of your rectangle,

442
00:52:17,570 --> 00:52:21,680
just to multiply the region of the rectangle and that will be your integral, right?

443
00:52:22,520 --> 00:52:29,090
So that's that. And in this particular case, what?

444
00:52:29,240 --> 00:52:33,379
What am I doing here? So here it is.

445
00:52:33,380 --> 00:52:38,570
The Senate checking. This is just doing the Senate checking. So the norm is just the normal distribution.

446
00:52:38,570 --> 00:52:47,750
So I'm going to do the I'm going to integrate this normal distribution from -10 to 10.

447
00:52:48,530 --> 00:52:52,969
And I know that this normal distribution has the maximum value of 0.5.

448
00:52:52,970 --> 00:53:02,120
So my Y max is a 0.5. Then I should expect that because normal distribution -10 to 10 is large enough.

449
00:53:02,120 --> 00:53:05,180
It should is the integral should be very close to one.

450
00:53:05,480 --> 00:53:09,170
And I see that it in there is a yes.

451
00:53:09,440 --> 00:53:14,270
Yes, I do see some value that is very close to one.

452
00:53:15,530 --> 00:53:21,440
So that that's what I see. Sometimes this value could vary.

453
00:53:21,470 --> 00:53:28,070
Sometimes you can see a slightly larger value than one because the, you know, the it's a monte Carlo method.

454
00:53:28,070 --> 00:53:31,160
So you can give it.

455
00:53:31,370 --> 00:53:37,220
Yeah, it can give sometimes a value that is a greater than true value.

456
00:53:37,510 --> 00:53:43,520
Okay. So, so but what we want it to do is to calculate this value, right?

457
00:53:44,630 --> 00:53:48,140
This expectation when in, let's say T equals five.

458
00:53:48,590 --> 00:53:54,050
Okay. So then what we wanted to do is calculate the expectation.

459
00:53:55,760 --> 00:54:00,490
This. So this is normal distribution.

460
00:54:01,020 --> 00:54:04,320
But your your values this. But now.

461
00:54:04,890 --> 00:54:13,020
So this is a this is a typical file. But instead of just calculating this integral, we want to multiply it to the X here.

462
00:54:13,200 --> 00:54:19,140
Okay. And calculate it. Right. So this is the function we want it to integrate.

463
00:54:19,430 --> 00:54:30,830
Okay. And so the the way how this was designed is that if X is greater than T, then I'm going to have this value.

464
00:54:30,840 --> 00:54:36,090
Otherwise I'm going to have to have zero. Then this function is basically truncated function.

465
00:54:36,330 --> 00:54:41,780
Okay. TRUNCATE. So all the values are is a zero in the here.

466
00:54:41,790 --> 00:54:47,850
You just multiply it to the x to the to this density. So that's the target function we want it to integrate.

467
00:54:49,530 --> 00:54:53,610
And we already know what the true answer should be. So this is true answer.

468
00:54:54,270 --> 00:54:58,590
And we are going to use accept the reject method in two different ways.

469
00:54:59,130 --> 00:55:05,520
So what are these two different ways? First, we're going to try this range.

470
00:55:06,310 --> 00:55:15,430
Okay. For first, when we try to do the exact reject method, I'm going to give it like W in this case, minus ten.

471
00:55:15,450 --> 00:55:24,350
So one way to do it is that I'm going to use this all the all rectangle to.

472
00:55:26,810 --> 00:55:31,469
To do this multicolor sampling. The other way to do it is that.

473
00:55:31,470 --> 00:55:47,240
Oh. I'm going to use the rectangle from actually I'm going to use a small rectangle she to heat to w w is a very, very large, large value here.

474
00:55:47,460 --> 00:55:58,550
Good to hear. And also, when I do that, I can define the maximum because I don't know what the value should be exactly here.

475
00:55:58,730 --> 00:56:04,100
So this is the this should be y Max, because it is a decreasing function.

476
00:56:04,640 --> 00:56:12,230
So I'm giving. So basically the difference between this and these is that it's using the same Monte Carlo method,

477
00:56:12,230 --> 00:56:16,430
but one is using the larger rectangle than the other one.

478
00:56:16,550 --> 00:56:21,450
Okay. So you know what the impact will be.

479
00:56:21,600 --> 00:56:26,400
Let's see. Okay. So if you do this, this is what you get.

480
00:56:26,740 --> 00:56:37,390
Oh, interesting. So. We sampled 500,000 samples, 500,000 random samples.

481
00:56:38,830 --> 00:56:42,410
Uh. So.

482
00:56:44,740 --> 00:56:50,500
I'm just trying to figure it out. Okay. So 500,000 random samples and.

483
00:56:52,410 --> 00:56:56,400
And so this is this is what our values should be.

484
00:56:57,030 --> 00:57:03,850
The first method gave us zero. And the second method gave a second method gave a reasonable number.

485
00:57:04,330 --> 00:57:16,660
Why do you think that is the case here? So in this case, the rectangle is actually quite should be very poor actually.

486
00:57:17,050 --> 00:57:22,810
Right. Because the maximum value is a is a 0.5.

487
00:57:23,500 --> 00:57:28,000
And these these are values much smaller than it looks in this graph.

488
00:57:28,780 --> 00:57:36,819
Right. So if what we are trying to do is that we are trying to sample random random point

489
00:57:36,820 --> 00:57:43,840
from here and we are only consider them as a hit if they fall into this these range.

490
00:57:44,680 --> 00:57:47,620
So the probability over here is really small, actually.

491
00:57:48,910 --> 00:57:55,660
In this case because we defined the max here, you know, the probability of hit is still not one.

492
00:57:55,780 --> 00:58:00,220
So you only have this part, but the probability of a hit is much.

493
00:58:01,430 --> 00:58:07,020
Much, much more likely to hit here than than here from here.

494
00:58:07,040 --> 00:58:12,070
So that's why there's a differences. Let's try a couple of more cases.

495
00:58:12,080 --> 00:58:19,610
Sometimes you see that, you know, if you get lucky, there is some point here and it is giving a non-zero value.

496
00:58:20,330 --> 00:58:23,800
But, you know, it doesn't always does that.

497
00:58:23,810 --> 00:58:31,700
So almost all the time, the the first exit rejected what they call a method.

498
00:58:31,700 --> 00:58:40,550
Give it a really high variation. The second method gives a relatively close value to what we wanted to do.

499
00:58:40,700 --> 00:58:47,870
So the lesson here I wanted to convey is that they accept the rejected Monte Carlo method

500
00:58:47,870 --> 00:58:53,630
could vary a lot based on how you define the how tightly you define your rectangle.

501
00:58:54,490 --> 00:58:58,810
Okay. So.

502
00:58:59,590 --> 00:59:02,830
So that's the accept reject. Okay.

503
00:59:05,210 --> 00:59:09,650
Second method is a naive Monte Carlo integration.

504
00:59:09,770 --> 00:59:15,020
It's the same Monte Carlo integration integration we learned at the very beginning.

505
00:59:15,530 --> 00:59:19,970
But now we are. So we're sampling X axis.

506
00:59:20,270 --> 00:59:25,810
So. So it is acceptable to promote the kind of method we are sampling two dimensional value.

507
00:59:26,050 --> 00:59:32,740
In this case, we're just a simply one dimensional value and take the average value of F of x.

508
00:59:33,310 --> 00:59:44,740
But we're now multiplying the width of these rectangles, the width of these x range, because we are calculating the integral which is a region.

509
00:59:44,740 --> 00:59:48,400
So if we select from the wide range, we need to multiply the width.

510
00:59:48,620 --> 00:59:54,649
Okay. So. Basically these are what you mean.

511
00:59:54,650 --> 01:00:02,960
Basically sampling from sampling random variable variable from the x axis and we cultured F of X in just a.

512
01:00:04,700 --> 01:00:08,990
Calculate the average of these f. F of x across all the random value.

513
01:00:09,470 --> 01:00:12,800
So you can do it this way or this way to get by.

514
01:00:13,190 --> 01:00:14,480
But where do you sample from?

515
01:00:14,490 --> 01:00:25,180
Do you want the sample from minus W to W or do you sample from T to W so that depending on how you do it, it could be slightly different.

516
01:00:25,190 --> 01:00:34,760
So. So here. Here. My guess is that because this part when X is less than t useful is I would guess that

517
01:00:36,080 --> 01:00:42,020
value focusing on the region that that has a positive value would be even better.

518
01:00:42,030 --> 01:00:45,850
So that's what I would expect. Let's see if that is the case then.

519
01:00:47,000 --> 01:00:54,340
So. So this case is a very similar to the first version of the Monte Carlo integration.

520
01:00:54,730 --> 01:00:57,590
But now you have to mean an x x max here.

521
01:00:57,610 --> 01:01:09,910
So you are randomly sampling from from this range and calculate the mean of this function, but multiply by the width so that that's what it is.

522
01:01:10,240 --> 01:01:15,730
Okay. So now let's compare.

523
01:01:16,870 --> 01:01:24,700
The this one is this. This one is the second second version of these except reject the Monte Carlo method.

524
01:01:24,750 --> 01:01:35,440
We're going to use them to compare, but we're going to compare with the neighbor Monte Carlo method that has a range from minus W to W,

525
01:01:36,070 --> 01:01:46,060
and then I want a column method that has at2w. So if you compare between these three, two, four, three method,

526
01:01:46,420 --> 01:01:52,120
you can you can try multiple times and each of them are slightly different, give the slightly different answers.

527
01:01:52,960 --> 01:01:59,350
But the point here is that, you know, as you as you suspected,

528
01:02:00,430 --> 01:02:06,200
accept reject Monte Carlo method in most of the cases is not better than the naive Monte Carlo method.

529
01:02:07,090 --> 01:02:16,389
So that's one observation. The other observation is many of the cases nine Monte Carlo method one is worse

530
01:02:16,390 --> 01:02:21,160
than the Monte Carlo method two in terms of being close to the true answer.

531
01:02:21,160 --> 01:02:26,290
So that that is a probabilistic observation. You can see if you run into many different times.

532
01:02:27,300 --> 01:02:38,560
Okay. So that that makes sense because basically when you sample from the value of between between in this case, a -10 to 10.

533
01:02:38,890 --> 01:02:42,910
Okay. So then -10 to 5, you don't do anything.

534
01:02:43,170 --> 01:02:45,520
This is not doing anything. So that makes sense.

535
01:02:46,060 --> 01:02:57,280
But it's not as bad as the previous example here because in this previous example, you are sampling from two dimension, two dimensional space.

536
01:02:57,880 --> 01:03:06,610
So X-axis, you're you, you have a wasted space in the x axis, but you have a huge weighted space in the y axis too.

537
01:03:06,970 --> 01:03:17,320
So that that's that gives the key that gives a very poor efficiency of the first Monte Carlo except Monte Carlo method.

538
01:03:18,670 --> 01:03:21,880
But here. Oh.

539
01:03:23,010 --> 01:03:32,480
There is a no sampling from the Y axis, so we're wasting about two third of that well, three quarters of the space of this space, you know.

540
01:03:32,720 --> 01:03:39,580
So compared to here in here, you're wasting three quarters of the of the X axis, probably, but that's it.

541
01:03:39,590 --> 01:03:51,950
So it's still giving a reasonably close value because, you know, the wasted random variable is not as at as many as the previous except it.

542
01:03:54,420 --> 01:03:57,790
I don't know if that makes sense. Okay. So, um.

543
01:03:59,300 --> 01:04:04,500
So just a naive Monte Carlo method is just requires one dimensional random variable.

544
01:04:04,520 --> 01:04:09,410
So that that's what I wanted to say. So previous case is using.

545
01:04:10,280 --> 01:04:15,709
So compared to using this range and compared to using this range, this range is more precise.

546
01:04:15,710 --> 01:04:25,100
So it's better, but it's not a lot of loss. It's like four times loss which which is a large but not not as large as previous cases.

547
01:04:25,280 --> 01:04:28,520
Okay. Okay.

548
01:04:28,530 --> 01:04:40,140
So. Now the root of the problem, I'm kind of unsatisfied because I have to set this w right.

549
01:04:40,600 --> 01:04:44,980
This W ten. It's a very arbitrary value hand-waving. I don't I don't like this.

550
01:04:45,340 --> 01:04:51,280
Okay, so can we try something? You know, that does not require.

551
01:04:53,110 --> 01:04:59,620
Does not require, actually. Um, having rectangular regions.

552
01:04:59,650 --> 01:05:08,320
So can we, can we have a multiple integration method that does not have to specify some, some actual arbitrary band?

553
01:05:10,280 --> 01:05:17,790
So. So let's stand here.

554
01:05:20,320 --> 01:05:23,530
Here. Basically the. So these.

555
01:05:23,650 --> 01:05:29,139
This particular particular case is just a moving from important simply for moving

556
01:05:29,140 --> 01:05:35,410
from this Monte Carlo knife Monte Carlo method to the to the important sampling.

557
01:05:35,410 --> 01:05:38,950
So we're going to basically move to important sampling.

558
01:05:38,950 --> 01:05:42,720
And our argument is that important sampling should be the best.

559
01:05:42,730 --> 01:05:46,580
So just spoiler alert, but this is a Segway.

560
01:05:46,810 --> 01:05:55,090
Okay, so this is one way to do it. So well, let's to use the so let's use this.

561
01:05:57,650 --> 01:06:01,830
So instead of sampling from. Uniform random variable.

562
01:06:02,070 --> 01:06:05,150
Why don't we sample from normal distribution? Okay.

563
01:06:05,160 --> 01:06:08,340
So that's that's why what we are trying to do.

564
01:06:09,060 --> 01:06:12,270
So then this is the this is the PDF.

565
01:06:12,720 --> 01:06:22,020
Okay. And if we define the g of X as a E to the X and a truncated version of B to the x,

566
01:06:22,830 --> 01:06:28,530
then if you multiply this to the this F of x is basically our target function.

567
01:06:28,680 --> 01:06:31,920
Right. So then if you integrate them over,

568
01:06:32,040 --> 01:06:44,400
you can integrate from negative infinity to infinity and you can get a proper version of this expectation, which is the basic expectation of.

569
01:06:44,940 --> 01:06:50,190
So this is an expectation of G based on this.

570
01:06:50,820 --> 01:06:54,280
So. So basically.

571
01:07:00,580 --> 01:07:08,330
So basically we wanted to. Populated e to the ex times.

572
01:07:10,080 --> 01:07:13,799
These Peel pullbacks, which is normal, normal density.

573
01:07:13,800 --> 01:07:17,550
And we wanted to we wanted to integrate them.

574
01:07:17,790 --> 01:07:28,830
Right. So one way to do it is that we can consider these as a target function, but instead doing that, why don't we consider this target function?

575
01:07:29,220 --> 01:07:38,010
Okay. And in this case, so well, we need to we need to integrate one T to the infinity.

576
01:07:38,130 --> 01:07:49,740
Right. And so. But so instead, instead of saying that this did everything, I'm going to say.

577
01:07:49,950 --> 01:07:55,950
Well. Into the piece of x x.

578
01:07:56,260 --> 01:08:00,250
Okay. So if we sample x as a.

579
01:08:01,350 --> 01:08:05,670
If is sample x from these POV x which is normal distribution,

580
01:08:06,210 --> 01:08:14,430
then we just need to take the expectation of this is equivalent to calculating the integration of this, right?

581
01:08:14,730 --> 01:08:21,490
If we calculate from key to the infinity, but because this is speculation, we cannot do key to the infinity.

582
01:08:21,510 --> 01:08:29,370
If you wanted to go from the minus infinity, infinity, you just need the indicator from indicator function here so that you calculating

583
01:08:29,370 --> 01:08:34,230
the same thing as that's what that's what this is trying to trying to say.

584
01:08:34,260 --> 01:08:40,200
So you're just calculating the expectation of X, which is the E to the X,

585
01:08:42,060 --> 01:08:48,780
but multiply multiplying the rest of the part, including the sampling distribution.

586
01:08:50,440 --> 01:08:57,920
So. So that's that. Okay, so let's let's move into the actual code.

587
01:08:58,880 --> 01:09:03,650
So now we're not using the random, uh, uniform distribution.

588
01:09:03,650 --> 01:09:07,220
So here what we have is a, we have a simpler function here.

589
01:09:08,210 --> 01:09:11,960
Simpler function that doesn't have to be uniform distribution anymore.

590
01:09:13,280 --> 01:09:16,250
And that is function is a target function we need to integrate.

591
01:09:16,580 --> 01:09:24,470
So here the tricky part is that you need to modify your target function to get rid of this piece of x part.

592
01:09:25,070 --> 01:09:30,320
Okay. So, so your g of actually your target function.

593
01:09:30,320 --> 01:09:35,690
Now, it doesn't have the genome part here. You just have a piece of X here.

594
01:09:36,080 --> 01:09:40,220
The 14 on part is a part of the sampling distribution.

595
01:09:40,630 --> 01:09:43,700
Okay. So then.

596
01:09:44,890 --> 01:09:48,490
We know this. We have transferred. Now let's compare.

597
01:09:49,600 --> 01:09:55,870
These are golden in multiple fronts. So let's try this and see how this looks like.

598
01:09:56,080 --> 01:10:06,040
Okay. So we're sampling a thousand, 100,000, 10 million, and this is a hundred million random values.

599
01:10:06,880 --> 01:10:12,970
But as you see, so this takes a really long time. Okay. As you see, this is actually not very good.

600
01:10:14,290 --> 01:10:19,780
Okay. So why is this not very work?

601
01:10:20,290 --> 01:10:23,500
Why this part is not working very well? Why do you think so?

602
01:10:24,810 --> 01:10:30,570
So our procedure is that we sample from normal distribution and take this right.

603
01:10:32,190 --> 01:10:37,800
But what's wrong here? Why did why does this give us zero?

604
01:10:38,070 --> 01:10:39,090
That doesn't make sense.

605
01:10:39,510 --> 01:10:49,410
That means that no, none of the random descent, the value was actually a contributing disintegration, which in part is a waste of wasting part.

606
01:10:54,410 --> 01:10:59,580
This part is wasting wasted part. So t is five here.

607
01:10:59,680 --> 01:11:12,479
So in our example, so we're only taking the we're sampling from normal distribution, but we're only sampling on on only you.

608
01:11:12,480 --> 01:11:19,559
We are only using that sample, that random variable, only if that value is greater than five or greater than five.

609
01:11:19,560 --> 01:11:22,940
Right. So that's a very small fraction of your random variable.

610
01:11:23,080 --> 01:11:28,470
You're wasting all the other random bit of especially when when you're sampling from normal distribution,

611
01:11:29,070 --> 01:11:33,930
most of the value will have value within -5 to 5.

612
01:11:34,380 --> 01:11:45,330
So that's why. So that if you sample thousand sample, almost always there is no value that is greater than five and the 100,000 same.

613
01:11:45,870 --> 01:11:52,799
If you sample 10 million, probably some of them are located outside of the those regions.

614
01:11:52,800 --> 01:11:56,580
So some are some will contribute this calculation.

615
01:11:56,940 --> 01:12:00,300
So you have some value, but not as close as you would expect.

616
01:12:00,570 --> 01:12:04,590
If you use 100 million, maybe. But 100 million is a lot of value.

617
01:12:04,620 --> 01:12:08,240
This is actually worse than the.

618
01:12:08,460 --> 01:12:12,090
So conceptually it sounds good.

619
01:12:12,540 --> 01:12:19,530
But because of this truncation, in fact, this actually is worse than the just accept reject method.

620
01:12:19,910 --> 01:12:23,230
Okay. So it didn't work out very well. Okay.

621
01:12:25,910 --> 01:12:32,990
So that that gives us with whether we the last part of the Segway.

622
01:12:33,080 --> 01:12:42,300
Okay so. So the reason why this integration didn't work very well, because this is so much,

623
01:12:42,590 --> 01:12:50,150
you know, the probability that you have anything that actually are useful is really small.

624
01:12:50,160 --> 01:13:01,200
So you only use like one out of, you know, one out of 3 million random variables are actually used for the calculation.

625
01:13:02,750 --> 01:13:06,620
So can we do better? How do we do better?

626
01:13:06,680 --> 01:13:10,160
So I like the idea of the not having to have these bound.

627
01:13:10,610 --> 01:13:17,899
But can we generalize this? Well, this is actually generalizable with arbitrary distribution.

628
01:13:17,900 --> 01:13:20,030
So this is a called the important sampling.

629
01:13:21,080 --> 01:13:29,270
So this this may look very so I had a hard time to understand what this is doing when I try to understand this.

630
01:13:29,810 --> 01:13:39,830
But the the real part here is that basically you want to you want to sample from some this these so you can think about this.

631
01:13:39,830 --> 01:13:46,160
You want to integrate this. Right. But if it's a uniform distribution, just you can put the X.

632
01:13:47,280 --> 01:13:53,760
But if you are sampling from some other distribution, call the Q of X.

633
01:13:57,950 --> 01:14:05,750
So if you are simply from some other disparate Q of x, then so x.

634
01:14:06,290 --> 01:14:10,429
So this is what is because these are sampling this machine, you're sampling from x.

635
01:14:10,430 --> 01:14:15,170
Then when you come to the expectation, you need to multiply this, right?

636
01:14:15,920 --> 01:14:26,420
Okay. So the idea is that because you have to multiply, this lets you modify your target function to divide by your backs.

637
01:14:27,020 --> 01:14:39,620
Okay. Then you have. So then if you if you calculate the expectation of this, that is equivalent to calculate the integration of F of x.

638
01:14:40,300 --> 01:14:47,920
That's it. Okay. So that's so equation looks very complicated, but the part is that whatever you sample from,

639
01:14:47,930 --> 01:14:59,470
you just divide the divide by the PDF of that, that sampling distribution from this original target distribution.

640
01:14:59,480 --> 01:15:07,070
So if you wanted to integrate F of X, just divide by Q of over COVAX or whatever, whatever sampling distribution it is.

641
01:15:07,280 --> 01:15:15,620
So that's what it is. And this is a very close to the envelope function thing we learned from the previous lecture.

642
01:15:15,830 --> 01:15:24,230
So there is a connection, but I'm not going to go to the detail of this proof because this is very obvious, actually.

643
01:15:24,740 --> 01:15:30,850
But the part is that, you know, if you wanted to calculate the expectation of some distribution.

644
01:15:30,860 --> 01:15:35,210
Q you need to divide by queue to match the.

645
01:15:37,060 --> 01:15:40,960
Match was eventually being integrated to have events.

646
01:15:43,870 --> 01:15:52,220
So that's that. So if you have questions in this particular equation, again, as a question,

647
01:15:52,240 --> 01:16:00,520
but I think what I explained was the easiest way to understand the important simply instead of getting into actual detail of the function.

648
01:16:01,520 --> 01:16:07,009
Okay. So then then basically importers distribution has a to distribution.

649
01:16:07,010 --> 01:16:11,060
So I'll just just so that I can I can understand.

650
01:16:11,600 --> 01:16:18,680
So originally so f over x, you can you can you can represent f of x as a.

651
01:16:20,070 --> 01:16:28,290
You know, so f of X is a some some other distribution P of x, but p over X doesn't doesn't really matter here.

652
01:16:28,440 --> 01:16:32,640
Okay. So because of what matter is the cure of the envelope function.

653
01:16:32,790 --> 01:16:42,689
Okay. What you want? You want it to calculate so that F of x can be represented as a g g of x and poverty of x is.

654
01:16:42,690 --> 01:16:48,899
So if you want it to say, oh, I want you to calculate the expectation of this vision.

655
01:16:48,900 --> 01:16:54,600
P. Okay. And though this is what I wanted to take eop energy of.

656
01:16:54,600 --> 01:17:01,400
X. This is what I wanted to calculate originally. Then this means that let's say there's a uniform distribution.

657
01:17:01,410 --> 01:17:06,000
This is equivalent to saying that, well, this is not a good way.

658
01:17:06,000 --> 01:17:13,440
Does it represent. Okay, so this is basically g of X and p of x the of x, right?

659
01:17:14,010 --> 01:17:17,580
So this you can you can rewrite this that F of X again.

660
01:17:17,790 --> 01:17:27,150
So this is my target function then, but I don't know how to sample from p then this double sampling from P, a sample from Q.

661
01:17:27,390 --> 01:17:35,520
Okay. So then this will be F of x, q of x and Q of x times D over x.

662
01:17:36,360 --> 01:17:43,890
So this part is basically calculating the expectation of Q and a f of X by vacuum x.

663
01:17:44,160 --> 01:17:44,400
Okay.

664
01:17:45,060 --> 01:17:53,820
So just the when you cut the the key part is that when you when you want to calculate the expectation from some distribution you can sample from,

665
01:17:54,330 --> 01:18:02,430
just use some other sampling distribution to adjust the expectation and that that's that still works.

666
01:18:02,640 --> 01:18:08,690
Okay. So. So that's how this was working.

667
01:18:08,720 --> 01:18:16,270
So there is a simpler and p simpler. The simpler is the the sampling distribution of your function.

668
01:18:16,280 --> 01:18:24,770
So I am calculating some of this some some function F of from some sampling distribution in this case.

669
01:18:26,000 --> 01:18:33,860
And in this case, it could be uniform distribution if you don't I want I don't have I don't want to sample from anything.

670
01:18:33,860 --> 01:18:40,819
So I just want you to f of and as a my target function, if you have f of an F1 as your target function,

671
01:18:40,820 --> 01:18:46,280
you can just sample from your sample can be uniform distribution if you wanted to.

672
01:18:47,060 --> 01:18:51,190
So if so, f for where is actually here?

673
01:18:51,200 --> 01:18:54,290
The view of x okay and simpler can be pure.

674
01:18:54,590 --> 01:18:59,540
So whatever whatever x is. So you can make a uniform distribution, a normal distribution, whatever.

675
01:19:00,290 --> 01:19:04,759
And P simpler is the same is the distribution.

676
01:19:04,760 --> 01:19:14,790
Actually, you can easily sample from empty so well you can easily calculate the expectation from.

677
01:19:14,810 --> 01:19:16,940
So this is a secure X. Okay.

678
01:19:17,810 --> 01:19:34,670
So in this particular example, okay, let's say so I know this is very confusing, but I hope that I, uh, this example explains what, what the,

679
01:19:34,670 --> 01:19:36,020
this difference of different,

680
01:19:36,020 --> 01:19:47,240
the difference of different sample simply simpler and the p simpler functions so simple again simple as a p of x ps employees are q of x.

681
01:19:47,360 --> 01:19:58,100
Okay. And here first one is that I'm going to use as a simpler I'm sampling from uniform distribution from minus W to W.

682
01:19:58,430 --> 01:20:09,680
Okay. So, and I'm going to use, uh, also, uh, the uniform distribution, okay?

683
01:20:09,980 --> 01:20:18,220
So the same uniform distribution. So this is so in this case, it's just a, this is a uniform distribution basically, right?

684
01:20:18,230 --> 01:20:21,530
So this is a very this is just a normal normal.

685
01:20:21,530 --> 01:20:25,250
Just a nice Monte-Carlo integration, basically the same thing.

686
01:20:25,520 --> 01:20:31,459
Okay. Because there's no waiting happens. So this is this is the same thing.

687
01:20:31,460 --> 01:20:41,390
This is not even Monte Carlo method, but using the key to the W it's a more tighter distribution of tighter window of the this x axis.

688
01:20:42,530 --> 01:20:52,399
Okay this one is I'm going to use a exponential distribution, truncated exponential distribution.

689
01:20:52,400 --> 01:20:57,140
So I know that this function.

690
01:21:00,480 --> 01:21:09,800
This function I am trying to integrate integrate is the idea is beginning from.

691
01:21:10,010 --> 01:21:14,430
So have some value and that this this is what this function looks like.

692
01:21:14,430 --> 01:21:22,200
Right. So I'm going to just use the exponential distribution because I used in the previous lecture, it worked well.

693
01:21:22,780 --> 01:21:25,829
And so this is a truncated exponential distribution.

694
01:21:25,830 --> 01:21:37,140
So I'm generating the exponential, this random variable to add by T and that that basically have this density.

695
01:21:37,320 --> 01:21:46,590
Okay. And, and the next thing is that I'm going to use a normal distribution shifted by T okay.

696
01:21:46,590 --> 01:21:51,690
So my and below function also looks like it's not able to function anymore because you don't

697
01:21:52,170 --> 01:21:56,820
have the requirement that this has to be greater because you are scaling them differently.

698
01:21:57,930 --> 01:22:01,120
So so these are four different choices. Okay.

699
01:22:01,860 --> 01:22:06,360
Oh, I need to load this first and then let's use.

700
01:22:06,660 --> 01:22:11,460
Okay, if you use these four different methods, basically this is what.

701
01:22:13,570 --> 01:22:18,760
So we're using one with a thousand random variables and this is what the value looks like.

702
01:22:19,010 --> 01:22:28,880
Okay. So it's about. Oh. It's relatively close compared to the example we have done before.

703
01:22:30,410 --> 01:22:33,640
So. And, uh.

704
01:22:35,700 --> 01:22:39,630
I don't know. So this one is a this one is just a duplicate.

705
01:22:39,780 --> 01:22:46,050
I'm sorry. I'm sorry for the for the confusion, but this is just the same cell, so I'm going to delete it now.

706
01:22:46,260 --> 01:22:51,089
Okay. And the. Okay. So this is already 5052.

707
01:22:51,090 --> 01:22:56,340
We had 52. Sorry for going 2 minutes over, but I just wanted to explain this, put it simply in part.

708
01:22:57,750 --> 01:23:03,320
And we are going to we are going to go to the, the, the final evaluation in the next lecture.

709
01:23:03,330 --> 01:23:08,130
Sorry for going over in a will. We're going to see in the Wednesday.

