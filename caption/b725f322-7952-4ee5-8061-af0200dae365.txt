1
00:00:01,640 --> 00:00:07,160
All right. Good morning, everyone. Let's get started.

2
00:00:07,160 --> 00:00:11,690
We have a lot to cover today.

3
00:00:11,690 --> 00:00:25,700
Also very exciting stuff. And the topic is graphical representation of causation and association.

4
00:00:25,730 --> 00:00:32,630
In other words, we are going to go through a tool that's becoming mainstream in epidemiology.

5
00:00:35,060 --> 00:00:38,870
Use a graphical tool called Dags.

6
00:00:39,410 --> 00:00:42,890
The A-G also called causal diagrams.

7
00:00:43,490 --> 00:00:57,200
It is so mainstream now that many journalists are actually requiring these two authors to include these diagrams.

8
00:00:57,200 --> 00:01:07,940
When you submit your paper and chances are you may be also asked to draw these diagrams for you.

9
00:01:07,970 --> 00:01:12,860
A l is research or otherwise in your own area.

10
00:01:12,890 --> 00:01:16,100
So. And they are really helpful tools.

11
00:01:16,100 --> 00:01:23,090
I myself use them quite, quite a bit. I mean, of course they have limitations, but in general, they can be pretty helpful in your day to day practice.

12
00:01:24,020 --> 00:01:28,430
So this is what we will go through today.

13
00:01:28,610 --> 00:01:38,230
With respect to this, we will first describe the elements of direct it a sickly roughs, which is how they are spelled out.

14
00:01:38,240 --> 00:01:41,750
So they are called that's because of the initials of these three words.

15
00:01:44,870 --> 00:01:49,340
We will describe the types of causal effects that can be represented with that.

16
00:01:50,510 --> 00:01:57,530
And then because that can also represent non causal statistical associations,

17
00:01:57,530 --> 00:02:05,899
we will go about how to differentiate what's a causal association and what's just a

18
00:02:05,900 --> 00:02:12,170
statistical association that is not causal from a that how to do that there are some rules.

19
00:02:13,970 --> 00:02:22,190
Um, then we will link that to some of the notation we have been through.

20
00:02:22,730 --> 00:02:37,040
I know this is somewhat painful, but, um, but again, it's important to know that there is a close relationship between the two representations.

21
00:02:37,670 --> 00:02:48,260
And finally we will discuss in practice how do we interpret that and how do we draw that?

22
00:02:49,440 --> 00:03:04,620
Okay. A couple of words on history that were invented in the early 1990s by this gentleman, Professor Julius Baer.

23
00:03:04,650 --> 00:03:08,880
He was a professor of computer science, in fact, at UCLA.

24
00:03:09,720 --> 00:03:24,000
He was an epidemiologist. And they were adopted into epidemiology by Jamie Robins from Harvard and Greenland, also from UCLA.

25
00:03:24,690 --> 00:03:28,500
It'd be, you know, in the mid 1990s.

26
00:03:32,880 --> 00:03:36,840
He has actually he has worked a lot on on causality.

27
00:03:36,840 --> 00:03:42,090
That's actually something that computer scientists use on a daily basis.

28
00:03:42,750 --> 00:03:46,140
And he has a pretty good book for the general public.

29
00:03:46,500 --> 00:03:50,549
And, you know, also for us interested in causality.

30
00:03:50,550 --> 00:04:03,120
He's called The Book of why anybody about this book or ready is very good and he also has a couple of longer more technical books.

31
00:04:03,120 --> 00:04:07,830
I may have included them in your slides in case some of you may be interested.

32
00:04:10,370 --> 00:04:17,030
So a few general words about that are directed at graphs.

33
00:04:17,260 --> 00:04:25,190
They're also called causal diagrams. They are equivalent mathematically to the counterfactual approach to causal inference.

34
00:04:26,090 --> 00:04:30,400
They link statistical associations with causal structures.

35
00:04:30,410 --> 00:04:40,250
In other words, they can help us identify whether a statistical association as depicted is supposed to be caused or not.

36
00:04:41,420 --> 00:04:46,250
And obviously, they can represent both cause effects and statistical associations.

37
00:04:48,220 --> 00:04:59,110
What are the elements of Dex that have two elements letters and connectors?

38
00:05:01,060 --> 00:05:05,710
The letters are called nodes or vertices.

39
00:05:06,930 --> 00:05:10,100
And they simply represent variables.

40
00:05:11,320 --> 00:05:19,770
There are variable names. They the arose are called connectors again or edges.

41
00:05:25,970 --> 00:05:31,220
And we are going to see what they represent.

42
00:05:32,400 --> 00:05:37,520
So. Why?

43
00:05:37,820 --> 00:05:46,670
That's called direct. They are called director because the connectors are areas with just one head.

44
00:05:48,340 --> 00:05:52,640
You cannot find. Two headed arrows in a that.

45
00:05:55,360 --> 00:05:59,570
And these arrows represent the passage of time.

46
00:06:00,070 --> 00:06:11,860
They represent time flowing from their variable, from which they depart, from which they have dictated into the variable to which they point.

47
00:06:13,720 --> 00:06:23,060
So that's kind. The direction of the arrows is from the potential cause.

48
00:06:24,410 --> 00:06:30,260
So in this case, a variable is a potential cause to their potential effect.

49
00:06:30,290 --> 00:06:37,640
In this case, variable y y is a potential effect or a potential outcome from variable a.

50
00:06:41,270 --> 00:06:43,490
In this situation a.

51
00:06:44,700 --> 00:07:00,960
Can be called also an ancestor or parent from which the arrow departs and way is also called a descendant or child or the variable.

52
00:07:01,140 --> 00:07:18,060
Those are just synonyms. Okay. When there is just one arrow and there are just two variables connected through that arrow.

53
00:07:18,720 --> 00:07:21,870
Those two variables are called adjacent variables.

54
00:07:23,460 --> 00:07:33,920
So. In this case. This is a parent that's adjacent to this child or descendent, and they are again connected by a single arrow.

55
00:07:34,800 --> 00:07:46,680
They're also called neighbors. And this arrow between two adjacent variables represents a causal effect.

56
00:07:47,990 --> 00:07:57,020
A causal effect of the variable from which they are or the part on the variable into which the arrow points.

57
00:08:00,020 --> 00:08:10,190
So if you see again this representation in the context of it that you can tell a has a causal effect on what does what is telling.

58
00:08:12,950 --> 00:08:16,340
And a recedes in time. What?

59
00:08:22,200 --> 00:08:25,980
Now, this is a very important rule also of Dex.

60
00:08:26,910 --> 00:08:31,800
The absence of an arrow indicates no causal effect.

61
00:08:35,970 --> 00:08:42,990
Some people say actually the most important error there could be,

62
00:08:43,150 --> 00:08:50,940
that is the arrow that doesn't exist, because then for sure you can tell there is no causal effect.

63
00:08:52,480 --> 00:08:57,730
Between two variables. Okay. Here is an example.

64
00:08:59,830 --> 00:09:12,069
Is this an example? You know, from from a real study, a real life situation toward the end of the Second World War to the Nazis imposed a siege,

65
00:09:12,070 --> 00:09:17,860
a blockade in western Poland and caused widespread famine.

66
00:09:18,880 --> 00:09:29,370
So the caloric intake of people who are trapped, they are before the allied liberation dropped to very, very few calories.

67
00:09:30,640 --> 00:09:35,860
So people were starving. And that situation historically is called the Dutch famine.

68
00:09:36,520 --> 00:09:41,530
It's a manmade sort of experiment, terrible experiment.

69
00:09:42,490 --> 00:09:51,220
And investigators have been, you know, taking advantage of that situation to examine the effects of.

70
00:09:53,040 --> 00:10:05,880
Being pregnant during a situation of mass starvation on the development of the baby and in fact, on health outcomes throughout life after birth.

71
00:10:06,300 --> 00:10:16,020
Right. Okay. That's fantastic. So in this example, we have one variable in this case, famine in pregnancy being exposed.

72
00:10:17,710 --> 00:10:21,610
To famine, the Dutch famine when a woman was pregnant.

73
00:10:22,840 --> 00:10:26,560
And the outcome is this size of the baby. Right.

74
00:10:28,000 --> 00:10:40,150
So this that is representing a causal effect of being exposed to famine when the woman was pregnant and the size of the baby.

75
00:10:42,940 --> 00:10:48,910
These are adjacent variables. They are a represents a causal effect.

76
00:10:50,050 --> 00:10:57,970
Farming in pregnancy is the ancestor, the possible cause and newborn size is the this and then or the possible effect.

77
00:10:59,420 --> 00:11:05,590
And so this is why. That's our call dating now.

78
00:11:06,420 --> 00:11:18,180
Why are that's called a cyclic? They are called a cyclic because there cannot be cycles or feedback loops.

79
00:11:18,570 --> 00:11:28,980
In other words. And. Two variables cannot be connected back after they have been connected in one direction.

80
00:11:30,300 --> 00:11:36,120
So you can never find a structure like this that.

81
00:11:38,450 --> 00:11:44,540
The reason is that nothing can cause itself right.

82
00:11:45,050 --> 00:11:49,070
So I am giving you the skull with the bones.

83
00:11:49,430 --> 00:11:56,740
This is incorrect. If you find this representation in it, that that is wrong.

84
00:11:58,980 --> 00:12:05,670
But sometimes people say, well, but there are situations really in which, you know, one.

85
00:12:07,870 --> 00:12:14,079
Variable cost is another, and that other variable somehow still causes the first one.

86
00:12:14,080 --> 00:12:18,160
Again, for example, in thinking, psychology, sociology,

87
00:12:19,060 --> 00:12:26,620
there is a situation with the happiness of couples that the happiness of one member of a couple influences,

88
00:12:26,620 --> 00:12:33,300
the happiness of the other, and at the same time the happiness of the other, influences by the happiness of the person.

89
00:12:33,340 --> 00:12:38,170
So on the nutrition.

90
00:12:39,630 --> 00:12:47,190
Science field. There is another typical example, which is called the cycle of malnutrition and infection.

91
00:12:48,060 --> 00:12:58,020
And nutrition majors have heard of that. So like a baby is undernourished, the baby is more likely to get infections.

92
00:12:58,020 --> 00:13:03,360
And because of the infections, you know, the baby may not be able to eat or, you know,

93
00:13:03,990 --> 00:13:09,540
has low appetite and then might become more malnourished and so on and so forth.

94
00:13:12,240 --> 00:13:18,060
So, you know, those those situations exist, but they cannot be represented like this.

95
00:13:19,140 --> 00:13:27,960
There is one detail that. Helps representing those situations.

96
00:13:27,980 --> 00:13:31,160
I have heard that that example of undernutrition infection.

97
00:13:31,170 --> 00:13:35,110
So. Instead of doing this.

98
00:13:37,050 --> 00:13:41,250
What you would need to do is what anybody has an idea.

99
00:13:46,910 --> 00:13:52,580
Right. And what's the element that would distinguish the different stages?

100
00:13:55,220 --> 00:14:02,330
Time. Time. You have to give a specific timeframe for each of the variables.

101
00:14:03,170 --> 00:14:06,230
So you change that. Okay. We have to be specific.

102
00:14:06,620 --> 00:14:13,970
And then nutrition at age one year causes an infection at age one year and a half,

103
00:14:14,720 --> 00:14:19,580
an infection at age one yet to half causes undernutrition at age two.

104
00:14:20,780 --> 00:14:27,420
You have to take advantage that the arrows represent the passage of time, and then you can specify a time frame for each fight.

105
00:14:27,820 --> 00:14:33,750
Okay. All right. So that's what they are called a.

106
00:14:36,630 --> 00:14:41,190
What are the types of causal effects that can be represented with that?

107
00:14:41,400 --> 00:14:52,260
There are basically three types of causal effects. There are direct effects, indirect causal effects and total causal effects.

108
00:14:53,920 --> 00:14:59,320
We are going to go through each. Beginning with.

109
00:15:01,480 --> 00:15:13,300
So is this a mixed sample? And this is a direct effect because there is a single arrow connecting to at gas environments.

110
00:15:14,800 --> 00:15:18,280
Direct effects may also have an actual.

111
00:15:22,090 --> 00:15:27,700
Physiological meaning of directness in that is a good example.

112
00:15:27,810 --> 00:15:31,600
You know, you can think of the fact that.

113
00:15:33,720 --> 00:15:47,940
For a mom not to have enough calories or protein to eat during pregnancy means the baby will not have enough energy and protein and nutrients to grow.

114
00:15:49,860 --> 00:15:56,010
So physiologically, it's sort of a direct situation, right?

115
00:16:00,960 --> 00:16:07,440
Now there can also be indirect effects when you have.

116
00:16:10,420 --> 00:16:15,820
A situation like this. There are more than two arrows or connectors.

117
00:16:17,540 --> 00:16:22,130
We can't give proper names to. These variables.

118
00:16:22,280 --> 00:16:28,429
So these are the same example, a still famine in pregnancy placed in newborn size.

119
00:16:28,430 --> 00:16:31,430
But then there is something in between preterm birth.

120
00:16:35,370 --> 00:16:41,390
So a y are no longer adjacent, however.

121
00:16:42,570 --> 00:16:51,780
All arrows from a two way flow have to tell this case there is only two arrows.

122
00:16:51,780 --> 00:16:59,880
So there is just one head to take situation. But. You have to go from head to tail.

123
00:17:00,720 --> 00:17:06,210
And if that's the case, then you have an indirect causal effect.

124
00:17:07,350 --> 00:17:10,830
Again, not adjacent variables because there is more than one arrow,

125
00:17:11,250 --> 00:17:17,250
but all arrows connecting the exposure with the outcome flow had to take indirect causal effect.

126
00:17:18,450 --> 00:17:24,720
And again, in essence, that's the kind of set of ecological example here would be.

127
00:17:25,140 --> 00:17:32,400
Well, regardless of whether lack of a substrate.

128
00:17:33,830 --> 00:17:39,200
In terms of food leads to lack of substrate to growth for the baby.

129
00:17:39,860 --> 00:17:49,310
In this case, being exposed to very little food during pregnancy causes the woman to give birth earlier.

130
00:17:50,410 --> 00:18:01,140
Then it should. And because a baby is born earlier and each year it's smaller than it should be, it hasn't had enough.

131
00:18:02,260 --> 00:18:07,610
Time to grow in the right. Indirect cost of living.

132
00:18:11,710 --> 00:18:17,980
This variable a preterm birth is called an intermediate variable.

133
00:18:18,430 --> 00:18:24,240
An intermediate between. A and way between exposure and outcome.

134
00:18:25,600 --> 00:18:32,639
It can also be called a mediator. I is a mediator in the castle.

135
00:18:32,640 --> 00:18:42,810
But from a who I. And again, the interpretation of these that is that a has an indirect causal effect on weight.

136
00:18:43,350 --> 00:18:47,410
The effect of a young way is mediated through I.

137
00:18:49,610 --> 00:18:53,940
We? But wait.

138
00:18:55,560 --> 00:18:59,720
There can be more than one mediator on a given course.

139
00:18:59,880 --> 00:19:03,930
But. And this is an example.

140
00:19:07,490 --> 00:19:17,420
Famine in pregnancy could cause maternal infections because, you know, the immunity suffers when you don't eat properly.

141
00:19:17,750 --> 00:19:27,899
Learn. Having a maternal infection can cause preterm birth and being born before dates can cause the

142
00:19:27,900 --> 00:19:32,760
baby to be smaller than it should be because it hasn't had enough time to grow a new right.

143
00:19:37,060 --> 00:19:43,780
Why is there an indirect effect of a young white male and white are not adjacent.

144
00:19:44,170 --> 00:19:50,200
But all arrows connecting a young white fellow to date.

145
00:19:50,740 --> 00:19:57,670
You see, this one is hard to tell. And this one is hard to take. So that means there is an indirect causal effect.

146
00:20:03,290 --> 00:20:10,970
And we would say that the indirect causal effect of violence is mediated through M and I.

147
00:20:15,370 --> 00:20:20,290
But wait, there can be more than one indirect effect.

148
00:20:21,980 --> 00:20:27,690
The plot thickens. Yeah. How about this?

149
00:20:29,140 --> 00:20:32,980
On the one hand, we have this indirect effect because this great is true.

150
00:20:34,240 --> 00:20:40,420
But suffering from famine in pregnancy for sure is going to lead to stress.

151
00:20:42,270 --> 00:20:52,800
And guess what? Stress. And also affect the growth of the baby in utero because of cortisol and other hormones, etc.

152
00:20:55,040 --> 00:21:05,930
So we would say that A has two indirect causal effects on way one mediated through M and another mediated through S.

153
00:21:07,010 --> 00:21:14,000
SH. Yeah. I chose this to represent stress and anxiety is right because.

154
00:21:15,380 --> 00:21:19,620
For. Exact.

155
00:21:20,130 --> 00:21:23,970
They are separate but simultaneous. So it's.

156
00:21:26,820 --> 00:21:32,760
No. No, he's not. An intermediate variable is not the same as a confounded.

157
00:21:32,850 --> 00:21:36,500
Good question. Thank you. May I?

158
00:21:36,510 --> 00:21:42,240
As you do for this lecture, forget about the word confounding.

159
00:21:44,430 --> 00:21:48,960
Maybe I should not ask you that, but that mediator is not a confounder.

160
00:21:49,080 --> 00:21:55,500
I mean, there is one situation which might happen.

161
00:21:56,430 --> 00:22:01,440
It's called time varying, confounding, but it is is really beyond.

162
00:22:01,830 --> 00:22:07,260
So for now, let's say not noticing because a confounder is a variable that.

163
00:22:08,770 --> 00:22:15,210
Sort of. Yes, Mrs. things up.

164
00:22:16,820 --> 00:22:23,060
It misses causality, whereas a mediator is part of a causal.

165
00:22:37,380 --> 00:22:46,580
Can I ever have a situation in which I. Yes.

166
00:22:47,360 --> 00:22:54,470
Great question. Can I have a situation in which stress would cause preterm birth as well?

167
00:22:54,860 --> 00:23:04,310
The answer is yes. Yes. Is this just a representation of the biology if you have enough causal knowledge.

168
00:23:05,300 --> 00:23:08,840
To to substantiate that we justified that error.

169
00:23:08,930 --> 00:23:19,880
You can put it there, definitely. The important thing from a purely graphical point of view is that you never go back from Y to eight.

170
00:23:20,990 --> 00:23:25,650
Other than that, you can have all sorts of religions. Good questions.

171
00:23:26,190 --> 00:23:33,870
Okay. So. We have two indirect causal effects, right?

172
00:23:36,310 --> 00:23:43,030
And we could still also have a direct causal if they are not mutually exclusive.

173
00:23:44,670 --> 00:23:49,649
So in addition to those two indirect causal effects, still eating little,

174
00:23:49,650 --> 00:23:57,990
having little to eat may cause a baby to be small because there is not enough food or nutrients for the baby to grow.

175
00:23:58,770 --> 00:24:05,180
So there could still be a directive. There's some.

176
00:24:06,600 --> 00:24:15,750
Of all indirect effects. And the direct effect is called the total causal effect.

177
00:24:21,220 --> 00:24:30,040
Right. The total causal effect is the sum of all indirect effects and the direct effect.

178
00:24:32,710 --> 00:24:43,360
And by the way, in this course and in most of episodic research, people have been concerned with the total effects.

179
00:24:44,290 --> 00:24:50,080
Only relatively recently. So methods have been put forth to.

180
00:24:52,400 --> 00:24:58,110
Decompose. Effects into direct and indirect.

181
00:24:58,140 --> 00:25:02,370
But the important thing is that when you.

182
00:25:04,030 --> 00:25:09,070
Start your research, you need to know what effect are you trying to estimate?

183
00:25:11,010 --> 00:25:15,630
And often times it will be the totality and you have to keep true to that.

184
00:25:16,830 --> 00:25:21,930
Because there are a few things you may or may not do that.

185
00:25:23,870 --> 00:25:27,499
May get the effect you are trying to estimate.

186
00:25:27,500 --> 00:25:34,370
Actually be confused. Okay. Any questions so far?

187
00:25:34,390 --> 00:25:40,100
Other questions? We've been clear.

188
00:25:40,850 --> 00:25:44,240
So far, so good. Easy peasy.

189
00:25:44,570 --> 00:25:49,480
Yeah. So I was like, Hey.

190
00:25:55,230 --> 00:26:00,550
Would you also say that? Oh.

191
00:26:07,840 --> 00:26:19,870
Okay. So the question is could and also have a direct arrow into why the answer is it good.

192
00:26:20,200 --> 00:26:24,730
If. Real coastal knowledge tells you that's possible.

193
00:26:25,540 --> 00:26:32,510
However, when you see a dead. And I tell you this, that represents.

194
00:26:33,490 --> 00:26:37,660
Fully and completely the underlying control system.

195
00:26:38,230 --> 00:26:44,030
You cannot make more assumptions. So in this that as I have presented it to you.

196
00:26:45,300 --> 00:26:48,360
M does not have a direct effect. On what?

197
00:26:50,910 --> 00:26:55,050
Okay. Good. Any other questions?

198
00:26:59,470 --> 00:27:04,500
Go. Yes.

199
00:27:04,510 --> 00:27:10,300
If there is no direct causal effect, the total effect would be the sum of the indirect causal effects on.

200
00:27:15,100 --> 00:27:23,720
All right. Now we are going to start.

201
00:27:25,030 --> 00:27:31,270
Studying some rules that allow us to differentiate association from causation in a death.

202
00:27:32,650 --> 00:27:42,790
The first thing we need to do to accomplish that is to understand a concept, which is the concept of path.

203
00:27:44,540 --> 00:27:45,380
What's a pet?

204
00:27:47,100 --> 00:28:01,800
A path is any route drawn through connectors errors that link two variables, let's say a and way independent of the direction of the arrowheads.

205
00:28:01,980 --> 00:28:09,870
So a path is a very agnostic concept is simply following how two variables are connected.

206
00:28:11,000 --> 00:28:14,300
Regardless of the direction of the arrowheads.

207
00:28:18,410 --> 00:28:27,500
Now a study of the pets and a study of the directions of the arrowheads within a path will actually tell us.

208
00:28:29,710 --> 00:28:33,850
Where the two variables are statistically associated.

209
00:28:35,150 --> 00:28:40,490
And in addition, whether that statistical association is causal.

210
00:28:41,480 --> 00:28:47,970
Or not. Okay. So pets.

211
00:28:49,720 --> 00:28:57,700
Can be classified. According to two systems.

212
00:28:59,230 --> 00:29:05,090
The first system. Is according to the causation flaw.

213
00:29:07,750 --> 00:29:11,950
The second system is according to the association flow.

214
00:29:14,000 --> 00:29:19,410
Okay. Let's first study.

215
00:29:21,250 --> 00:29:26,890
The classification of pets according to the causation field.

216
00:29:29,130 --> 00:29:33,210
According to the causation flaw, pets can be of two types.

217
00:29:35,150 --> 00:29:39,630
They can be directed. Or Andrea.

218
00:29:41,810 --> 00:29:47,860
Meaning non-native oak. Let's look at direct impacts.

219
00:29:50,690 --> 00:29:56,660
This is an example from life course epidemiology. Exposure is birth weight a.

220
00:29:57,990 --> 00:30:01,680
Outcome is hypertension in adulthood.

221
00:30:03,390 --> 00:30:09,350
And there is an intermediate variable, which is. Obesity at age 20 years.

222
00:30:15,440 --> 00:30:24,870
The definition of a directed path. He's one in which all arrows connecting the exposure with the outcome.

223
00:30:26,000 --> 00:30:30,770
Flo had to take. In this case, we only have two rows.

224
00:30:30,770 --> 00:30:33,950
But they are here to take.

225
00:30:35,900 --> 00:30:38,930
The head is the point of the right head to take.

226
00:30:39,800 --> 00:30:47,710
So when all arrows from exposure to outcome from flow head to tail, the path is directed.

227
00:30:48,860 --> 00:30:54,700
Have a. To make a semantic parenthesis.

228
00:30:55,650 --> 00:31:06,300
And so with an apology, because the choice of words for these nomenclature has been done in a confusing way.

229
00:31:06,600 --> 00:31:11,040
I didn't do it. But we have to be sort of forward.

230
00:31:12,400 --> 00:31:17,230
Direct. It is not synonymous with direct effect.

231
00:31:18,160 --> 00:31:28,990
Which we already know. Elected, but he's not the same as a direct effect, even though they both have direct in their name.

232
00:31:29,440 --> 00:31:38,320
It's a very important distinction. This is a directed path, for example, but actually it does not represent a directive, is it?

233
00:31:39,430 --> 00:31:47,770
So I'm sorry that they gave the same name to two different concepts, but if you are aware of that, it should not lead to confusion.

234
00:31:48,120 --> 00:31:55,479
Right. So again, if you vision of a directed path ad nauseum is that these were in English all

235
00:31:55,480 --> 00:32:04,270
address connected and I think it's an flow head to take as opposed to direct it.

236
00:32:04,290 --> 00:32:08,470
But there are undirected parts or non directed parts.

237
00:32:09,620 --> 00:32:22,700
And will the definition by opposition direct it but is going to be a path connecting a runway on which not all areas flow.

238
00:32:23,000 --> 00:32:26,780
Today is really simple. Really simple.

239
00:32:28,970 --> 00:32:32,570
There are two main examples of undetected pats.

240
00:32:36,000 --> 00:32:43,400
This is the first one. So we have variable a exposure and we have variable way out.

241
00:32:46,360 --> 00:32:51,520
There is a path that connects a anway through variable help.

242
00:32:53,130 --> 00:33:00,510
Right. I could get. From 8 to 8 following these two connectors.

243
00:33:00,530 --> 00:33:10,850
Right. And they happened to go through every. Do the two arrows connecting a two way.

244
00:33:12,770 --> 00:33:21,090
No head to tail. No. You know, in fact, there is that tail to tail situation.

245
00:33:24,550 --> 00:33:27,960
Right. So these parties and their.

246
00:33:31,540 --> 00:33:37,840
When you have a path that's undirected because you have a tale to tell, a situation.

247
00:33:40,410 --> 00:33:47,610
You say that the two variables exposure are outcome connected through a back door.

248
00:33:49,490 --> 00:34:01,980
This is a backdoor path. We can't give proper names to these variables for for a real life example.

249
00:34:04,130 --> 00:34:09,500
A he's carrying matches, I guess, for a lighter.

250
00:34:12,380 --> 00:34:18,600
And why is lung cancer? Okay.

251
00:34:28,230 --> 00:34:33,910
Let's help. But could be a. Smoking.

252
00:34:35,930 --> 00:34:41,030
Smoking so ill is what's called a common cause.

253
00:34:42,020 --> 00:34:47,490
Like. You see, there is a direct effect of smoking on carrying matches.

254
00:34:47,640 --> 00:34:52,170
Right. And there is a direct effect of smoking on lung cancer.

255
00:34:57,030 --> 00:35:03,480
But a and we are only connected through a back door, but that goes through a common cause.

256
00:35:04,450 --> 00:35:13,340
In this case most. The second type of undirected parts is this.

257
00:35:14,300 --> 00:35:19,380
This is sometimes called an M structure. Because of how he looks.

258
00:35:19,740 --> 00:35:27,240
She looks like the letter M, right? So you have variable a exposure variable way outcome.

259
00:35:28,530 --> 00:35:33,750
Are they connected through iPads? Through a path agnostic.

260
00:35:35,230 --> 00:35:45,300
Are they connected? Yes. You know, you could go from a railway following these connectors, regardless of the direction of the arrowheads.

261
00:35:47,160 --> 00:35:50,950
Is this path directed? He's not.

262
00:35:51,760 --> 00:35:57,100
He's underrated for two reasons. One is they hate footed and they're underrated.

263
00:35:58,630 --> 00:36:08,380
The other is that. And the other one is that the arrows connecting a and way do not all flow.

264
00:36:08,560 --> 00:36:11,740
Had to take these first arrow.

265
00:36:12,250 --> 00:36:15,610
These first are you have a tale to tell situation.

266
00:36:15,820 --> 00:36:23,770
But then hey, what happens here? You have a head to head situation and then you have another tale to tell situation.

267
00:36:26,350 --> 00:36:30,520
If we give proper names to these variables. You know.

268
00:36:31,890 --> 00:36:35,940
The exposure could be low education of a person for another person.

269
00:36:36,210 --> 00:36:40,640
Right. The outcome could be diabetes of the same person.

270
00:36:43,840 --> 00:36:48,850
Variable you one, which let's say is unmeasured.

271
00:36:48,940 --> 00:36:58,570
In our study, we did not measure that. Is poverty during the childhood of the person who ended up with no education in adulthood.

272
00:37:01,070 --> 00:37:10,490
Variable C could be that this person's mother had diabetes and variable due to which perhaps we also

273
00:37:10,520 --> 00:37:20,810
didn't measure in this study is a gene that predisposes the mother of that person to diabetes.

274
00:37:23,500 --> 00:37:31,600
Okay. Now there is something special in this spot that.

275
00:37:34,390 --> 00:37:42,810
Is not on this back. Which is the head to head situation, right?

276
00:37:44,420 --> 00:37:49,940
When you have a head to head situation, the variable on which the two arrowheads.

277
00:37:52,730 --> 00:37:59,850
Point two has a proper name. That variable is called a collider.

278
00:38:02,420 --> 00:38:07,330
Where two arrowheads meet. That variable is called a line.

279
00:38:20,060 --> 00:38:24,410
So of the two types of pets.

280
00:38:26,430 --> 00:38:29,660
They reacted. Versus undetected.

281
00:38:30,880 --> 00:38:35,210
Which type? Represents a causal effect.

282
00:38:37,370 --> 00:38:46,110
They directed. The undirected ones do not represent a causal effect.

283
00:38:47,950 --> 00:38:53,200
So this part does not represent a causal effect of a and way, way.

284
00:38:54,100 --> 00:39:04,940
Because not all arrows flow to take. This path does not represent the causal effect of a way because not all arrows connecting them flow had to take.

285
00:39:13,210 --> 00:39:22,570
Now let's go through the classification of pets according to the Association Flow System Statistical Association.

286
00:39:25,930 --> 00:39:30,240
According to this system. To the association.

287
00:39:30,250 --> 00:39:33,450
Flow patterns can be of two types.

288
00:39:34,680 --> 00:39:37,830
They can be closed or they can be open.

289
00:39:43,010 --> 00:39:54,020
This is an example of a closed path, a synonym for closed, but is also blocked or inactive.

290
00:39:56,700 --> 00:40:01,890
What's the definition of a close? That is a very simple definition.

291
00:40:03,200 --> 00:40:11,180
A path between a and way is closed when there is a collider pony peering.

292
00:40:18,410 --> 00:40:21,500
So this part is closed because there is a polite.

293
00:40:26,980 --> 00:40:33,820
And well, guess what? As opposed to close bets, then there are open bets, right?

294
00:40:35,800 --> 00:40:40,360
So these two pads are open. Why are they open?

295
00:40:43,630 --> 00:40:49,110
Because they're inoculated. Very simple. Okay.

296
00:40:50,040 --> 00:40:54,110
So open bats are also cool and blocked.

297
00:41:01,220 --> 00:41:07,700
Now. On each of these pads.

298
00:41:11,650 --> 00:41:19,960
Or which of these pets closed or open represent a statistical association between A and what?

299
00:41:20,050 --> 00:41:25,670
In other words. If you actually conduct this study in a population.

300
00:41:27,140 --> 00:41:38,030
And measure those variables. On which scenario will you actually find a statistical association?

301
00:41:38,150 --> 00:41:44,240
In other words, on which scenario will you find a difference in the summary?

302
00:41:46,130 --> 00:41:51,520
Outcome measure between exposure groups in the open.

303
00:41:52,310 --> 00:41:57,020
The open. Which means.

304
00:42:00,960 --> 00:42:06,260
You have this. In the open.

305
00:42:06,260 --> 00:42:13,960
Perhaps you'll find an association. Your outcome variable is not going to be independent of your exposure.

306
00:42:13,970 --> 00:42:19,880
Right? So the summary measures of your outcome will differ between levels of your exposure.

307
00:42:20,690 --> 00:42:24,410
The close. But you should not find as an association.

308
00:42:26,520 --> 00:42:31,400
The summary outcome measures would be the same by exposure levels.

309
00:42:32,130 --> 00:42:44,010
So if you go and collect data on the low education level of people in the population and diabetes,

310
00:42:44,010 --> 00:42:53,460
the same people, you should not find a statistical association if these that represents the true.

311
00:42:58,590 --> 00:43:10,000
Okay. Now, if this that represents the truth and you go and collect data on these three variables, you should find an association.

312
00:43:11,620 --> 00:43:19,630
If this that represents the truth and you go and collect data on these variables, you should find an association between L and what?

313
00:43:22,380 --> 00:43:31,530
In fact, there is. You could do that. You will find that people who carry matches or people, you know, with lung cancer.

314
00:43:33,380 --> 00:43:39,980
The summary measure of lung cancer is higher. The probability is higher in people who carry matches than people who are not carrying.

315
00:43:42,260 --> 00:43:45,320
Or I like that. You know, I guess it's much the same.

316
00:43:46,840 --> 00:43:50,290
Unless the. Like to set things on fire.

317
00:43:51,290 --> 00:43:55,610
That's a different issue. Perhaps a problem. Okay.

318
00:43:56,450 --> 00:44:00,020
Any questions on this? All right.

319
00:44:00,740 --> 00:44:12,050
So now we can combine the two classification systems to figure out when a structure is telling us.

320
00:44:13,100 --> 00:44:20,750
Whether there is a statistical association and with it that says physical association may have a causal interpretation.

321
00:44:21,650 --> 00:44:29,300
Right. So I have this little summary with some notation.

322
00:44:32,320 --> 00:44:37,650
And the conclusion of. What's going on?

323
00:44:40,120 --> 00:44:43,180
So. This is the dog.

324
00:44:44,790 --> 00:44:53,040
Four different types of decks. And this is the cross classification of the two systems causation of line association flow.

325
00:44:53,340 --> 00:44:58,130
Right. So let's go through the first. Rob.

326
00:44:59,210 --> 00:45:04,940
So this is the simplest possible that between two adjacent variables.

327
00:45:05,660 --> 00:45:21,150
So. This part is directed because according to the causation flow, because all arrows flow ages when arrow the path is open.

328
00:45:21,300 --> 00:45:25,400
Why? Huh?

329
00:45:27,180 --> 00:45:38,040
No colliders. Right. This other part is also directed because the arrows flow head to tail and it's open because, you know.

330
00:45:38,050 --> 00:45:45,120
Collider Sorry, I don't want to be obnoxious, but it's just that, you know, it's really simple.

331
00:45:45,120 --> 00:45:49,320
There is no and repetition apparently works.

332
00:45:53,500 --> 00:45:56,500
So if a path is directed.

333
00:45:58,090 --> 00:46:05,530
And open. That means there is a statistical association and that statistical association has a causal interpretation.

334
00:46:07,000 --> 00:46:11,830
So here the association. This is the notation for the association.

335
00:46:12,070 --> 00:46:18,190
That is an association because in summary, measures of outcome differ between expression levels in the real world.

336
00:46:18,940 --> 00:46:23,169
And there is a causal effect because the marginal counterfactual summary measure.

337
00:46:23,170 --> 00:46:35,260
So it's no different, right? So there should be exchange ability and we have a causal effect of a, you know, the second path we have.

338
00:46:37,670 --> 00:46:41,990
Apart from eight to why that is underrated because.

339
00:46:43,410 --> 00:46:50,060
The arrows flow. Entertain not head to toe is open because.

340
00:46:52,640 --> 00:47:01,790
There's no colliders. So because there are no colliders, there is a statistical association.

341
00:47:03,360 --> 00:47:11,280
But it doesn't have a causal interpretation because the parties and the situation here is there is a common cause,

342
00:47:11,310 --> 00:47:16,560
there is a backdoor between a and one. So that's not cause.

343
00:47:16,560 --> 00:47:22,010
Why in this situation and why are only statistical associated?

344
00:47:22,020 --> 00:47:29,500
Because they are both consequences of error. The third path again is the structure.

345
00:47:30,190 --> 00:47:35,590
It is undirected because not all arrows connecting and way flow had to turn.

346
00:47:36,160 --> 00:47:41,300
And it is close because. Recirculating because it is closed.

347
00:47:42,020 --> 00:47:47,510
There is no statistical association. Can there be causation without statistical association?

348
00:47:49,410 --> 00:47:52,770
No way. So is another nice conclusion.

349
00:47:53,610 --> 00:47:58,230
Statistical association is a prerequisite for there to be causation.

350
00:48:00,150 --> 00:48:09,970
Right. And the situation here is that there is a cooling and there is a collider.

351
00:48:10,900 --> 00:48:15,850
There is no statistical association and therefore there is no causation.

352
00:48:16,970 --> 00:48:22,060
I think this last one is a very interesting example.

353
00:48:23,930 --> 00:48:30,820
So this path is open because. He's now colliding.

354
00:48:31,970 --> 00:48:42,380
Is undetected because if you are going from a to why the arrow is not law, you today is flowing tail to head.

355
00:48:45,290 --> 00:48:49,900
You always have to declare. Why is your departing variable?

356
00:48:49,920 --> 00:48:52,920
What's your exposure and where?

357
00:48:54,070 --> 00:49:02,070
We are going, which is by zero. And same with the one under.

358
00:49:03,510 --> 00:49:08,250
A and we are connected by. But going from a two way.

359
00:49:09,890 --> 00:49:13,340
The arrows are not flowing at the tail.

360
00:49:13,970 --> 00:49:19,050
They are flowing to hit. Is at these pats open.

361
00:49:20,950 --> 00:49:25,300
Yes, quite so. But they are undirected.

362
00:49:25,600 --> 00:49:31,090
Because once you declare, where are you going from to that is done flow to take.

363
00:49:33,180 --> 00:49:40,720
So there will be a statistical association, but it doesn't mean that there is a causal effect of a.

364
00:49:40,740 --> 00:49:43,890
On why is there a causal effect there.

365
00:49:46,840 --> 00:49:51,120
Of whether or not there is a causal effect or why only.

366
00:49:52,660 --> 00:49:57,070
And that paradox, if you will, actually has a proper name.

367
00:49:57,610 --> 00:50:01,210
It is called reverse causation bias.

368
00:50:02,590 --> 00:50:10,000
Reverse causation bias, and we will provide examples of these when we study because next we may.

369
00:50:12,850 --> 00:50:19,600
Okay. Any questions on that? I'm not.

370
00:50:22,990 --> 00:50:30,700
Yes. You know, uh.

371
00:50:34,660 --> 00:50:39,070
You know that salt intake causes high blood pressure, right?

372
00:50:39,190 --> 00:50:53,350
I mean, that's that's sort of well known. If if you go to University Hospital, let's say, and do a survey among people waiting in the waiting room on.

373
00:50:55,240 --> 00:50:58,600
Salt intake and hypertension.

374
00:51:01,050 --> 00:51:08,250
I bet you you will find that salt intake is lower in people who have hypertension.

375
00:51:09,640 --> 00:51:18,720
Even though you would expect that. Should be higher because salt intake causes excessive salt intake causes hypertension.

376
00:51:19,290 --> 00:51:26,080
Why is it lower? Why might you find lower salt intake among hypertensive?

377
00:51:32,070 --> 00:51:37,660
Right. They are in a low sodium light weight. Because they are hypertensive.

378
00:51:39,070 --> 00:51:44,320
So the outcome. Hypertension could lead to a change in exposure.

379
00:51:50,680 --> 00:51:57,630
Any other questions? Right.

380
00:51:58,560 --> 00:52:04,970
Now. There are some variables that that interesting to study and that are interesting for you to recognize,

381
00:52:05,660 --> 00:52:10,130
mostly because most of the time you want to leave them alone.

382
00:52:10,910 --> 00:52:18,770
When, for example, you are going to analyze data and I call them variables outside a causal path.

383
00:52:19,790 --> 00:52:26,750
So let's go back to this simplified example of how many pregnancy has the exposure and newborn size as the outcome.

384
00:52:28,070 --> 00:52:33,650
Right. There is an indirect effect from preterm birth and there is a direct effect.

385
00:52:34,270 --> 00:52:38,930
Right. So there could be.

386
00:52:40,660 --> 00:52:49,560
One descendant of exposure that is really otherwise not connected with the outcome.

387
00:52:50,600 --> 00:52:57,020
And we could give it a proper name in these in the context of this example, this could be the hunger sensation, you know.

388
00:52:57,440 --> 00:53:01,610
So being exposed to starvation, you know, makes you pretty hungry.

389
00:53:02,500 --> 00:53:08,500
Right. But he doesn't have, again, anything to do with it.

390
00:53:09,790 --> 00:53:22,840
He doesn't cause the outcome. When you have this situation, B can be called a proxy descendant of A a proxy the same.

391
00:53:24,480 --> 00:53:27,780
And these variables are sometimes helpful.

392
00:53:29,660 --> 00:53:33,890
When? You cannot directly measure.

393
00:53:35,370 --> 00:53:38,639
The exposure. Or the outcome.

394
00:53:38,640 --> 00:53:42,180
There can also be a proxy the descendants of the old.

395
00:53:44,400 --> 00:53:51,900
When that's the case, you could sort of take advantage of a variable that is a consequence of the

396
00:53:51,900 --> 00:53:58,890
exposure that is highly associated with the exposure and that is measurable.

397
00:54:00,100 --> 00:54:07,080
And this is, in fact, how some investigators have measured exposure to famine in pregnancy because, you know,

398
00:54:07,960 --> 00:54:20,620
there may not be records of of the actual number of calories that the mothers of the offspring that people are studying were eating back in 1945.

399
00:54:20,680 --> 00:54:30,280
Most of them are, in fact, already dead. So people go around asking, you know, how angry?

400
00:54:32,570 --> 00:54:35,840
Were people feeling? At the time.

401
00:54:37,620 --> 00:54:44,910
A proxy this. There are variables that.

402
00:54:46,050 --> 00:54:54,750
Cause they are welcome but again are not really connected otherwise with the exposure.

403
00:54:55,770 --> 00:54:58,470
One example here is the sex of the newborn.

404
00:54:59,010 --> 00:55:10,410
You know that because the genetic sex in general, baby boys tend to be a little larger than baby girls at the same week of gestation.

405
00:55:13,210 --> 00:55:16,660
So this is a cause of the outcome, but is an understanding of exposure.

406
00:55:17,590 --> 00:55:25,390
So in a way, it's outside this causal system. There could be brought to this end of the outcome.

407
00:55:26,570 --> 00:55:40,910
This is breastfeeding duration. Because, you know, maybe moms who have a smaller baby may be more prone to breastfeed the baby for longer or shorter,

408
00:55:40,910 --> 00:55:48,650
depending on, you know, the prevailing advice and seems to be sending up.

409
00:55:50,250 --> 00:55:55,110
And then there could be variables that are totally disconnected from anything else.

410
00:55:55,650 --> 00:55:58,890
An example is here. See cooking skills.

411
00:55:59,460 --> 00:56:03,400
You know, they. Everybody was.

412
00:56:04,330 --> 00:56:08,710
Exposed to famine. Some people, more or less, and others.

413
00:56:09,680 --> 00:56:12,940
Whether somebody could prepare a fancy meal didn't really matter.

414
00:56:15,220 --> 00:56:21,470
Okay. So see is a disconnected right now.

415
00:56:22,910 --> 00:56:25,910
How do we interpret associations with that?

416
00:56:30,660 --> 00:56:36,860
I'm going to give you a few hints. The idea is that when you see a dog.

417
00:56:38,310 --> 00:56:51,420
You should be able to tell which variables are statistically associated and which variables have a causal effect on which others are not.

418
00:56:51,940 --> 00:56:55,890
Okay. So I'm going to give you hints to to do that.

419
00:56:58,550 --> 00:57:10,440
First of all. A single dad typically depicts many associations between more than two life that can become really messy.

420
00:57:13,890 --> 00:57:19,680
Obviously there can be more than one exposure and one outcome in a single that.

421
00:57:21,420 --> 00:57:28,590
Therefore to analyze it, that the first thing you have to do is to.

422
00:57:30,090 --> 00:57:37,970
Clearly identify which exposure you are interested in and which outcome you are interested in.

423
00:57:39,410 --> 00:57:40,700
Forget about everything else.

424
00:57:43,170 --> 00:57:53,550
That are also like, I guess Netflix series in that, you know, a variable, the same variable could play many different roles in the same that.

425
00:57:57,240 --> 00:57:59,250
So that's why you have to.

426
00:58:02,030 --> 00:58:13,310
Clearly define your Bibles of interest and as a first step, identify one and only one exposure in relation to one and only one outcome.

427
00:58:29,320 --> 00:58:34,860
Okay. So the question is, will exposure and outcome always be able and why?

428
00:58:36,430 --> 00:58:38,880
And the answer is no. You.

429
00:58:38,960 --> 00:58:49,560
They cannot be labeled in any way, but you can still decide which one is your exposure of interest and which one is your outcome.

430
00:58:51,110 --> 00:59:01,899
And that's what you. Yeah, that's the first step. So as you have identified your exposure of interest and your outcome of interest or somebody like

431
00:59:01,900 --> 00:59:11,200
you or 600 professor has told you you have to focus on the patterns connecting the exposure,

432
00:59:11,500 --> 00:59:16,700
that exposure with that outcome and forget about every piece.

433
00:59:20,940 --> 00:59:30,900
Now step two is to write out each path that begins at the exposure and ends at the outcome one at a time.

434
00:59:32,250 --> 00:59:34,140
Preserving the detection of errors.

435
00:59:37,120 --> 00:59:44,740
And making sure that you include all the pets because there can be more than one path between a given exposure and given up.

436
00:59:46,600 --> 00:59:50,170
You cannot go over the same arrow twice.

437
00:59:53,240 --> 00:59:57,620
Now let let's put this into practice again with this debt.

438
00:59:58,070 --> 01:00:03,920
Suppose this is a drug that represents the true cause, that system.

439
01:00:04,160 --> 01:00:11,750
And then somebody asks you. Hmm. Is there a causal effect of newborn sex on preterm birth?

440
01:00:13,440 --> 01:00:16,860
So to go back to Rachel's question in this case.

441
01:00:17,990 --> 01:00:19,790
What's the exposure and what's the outcome?

442
01:00:25,500 --> 01:00:34,740
The exposure is newborn sex and it happens to be labeled the right and the outcome is preterm birth and it happens to be labeled high.

443
01:00:37,450 --> 01:00:41,020
So that's the first. It was the second step we call.

444
01:00:43,020 --> 01:00:48,120
Draw all the parts right out, all the parts that connect.

445
01:00:49,370 --> 01:00:53,240
The Wi-Fi, starting with the.

446
01:00:54,430 --> 01:01:01,030
And leading into. Right. So how many pets do we have?

447
01:01:01,570 --> 01:01:10,930
Let's see. There's the most obvious would be you start with the go through y and then that in high.

448
01:01:11,890 --> 01:01:15,850
Right so we can draw it this way.

449
01:01:16,510 --> 01:01:19,780
The as an arrow pointing in the Y, right.

450
01:01:20,890 --> 01:01:28,360
And the Y. Is receiving an arrow from a so you have preserved.

451
01:01:29,400 --> 01:01:32,670
The direction of the arrows in my writing.

452
01:01:32,670 --> 01:01:38,460
Out of this path is yet another path connecting them with a.

453
01:01:40,540 --> 01:01:46,600
It is actually you can go from day to day by going through y here.

454
01:01:47,050 --> 01:01:50,740
But then a. And then I.

455
01:01:52,260 --> 01:01:55,610
Right. So I have written that.

456
01:01:55,610 --> 01:02:01,010
But here like this then it's into y why receives an arrow from a.

457
01:02:02,350 --> 01:02:13,370
And a has an arrow into at. So we have completed the 2/1 steps to answer this question.

458
01:02:13,640 --> 01:02:17,410
There is a cause and effect of neurons. Say something. Now.

459
01:02:17,740 --> 01:02:25,490
Step three. Apply the rules of association flow to each path one at a time.

460
01:02:27,710 --> 01:02:34,340
So recall by the flow of associations that can be closed or open.

461
01:02:35,510 --> 01:02:38,720
They are closed when there is a colliding.

462
01:02:40,230 --> 01:02:45,480
Hoping otherwise. So the first question is, are there colliders on the path?

463
01:02:46,800 --> 01:02:53,970
If there are no colliders, the path is open and the exposure is statistically associated with the outcome.

464
01:02:55,090 --> 01:03:02,170
If there are colliders, the path is closed and the exposure is not statistically associated with the outcome.

465
01:03:03,280 --> 01:03:07,720
Explosion out. Come out in the pit. Okay, so let's do this with these two.

466
01:03:08,990 --> 01:03:13,460
Pets about the first one is regulated and above.

467
01:03:14,780 --> 01:03:21,380
Yes. Therefore, the park is closed. There is no association, no statistical association on this.

468
01:03:21,680 --> 01:03:28,360
How about the second one? Is the regulator? Yes. So the same thing is guided by this dosage, not association.

469
01:03:32,020 --> 01:03:38,380
Next step for applying the rules of causation flow to each part one at a time.

470
01:03:39,190 --> 01:03:46,780
Do all arrows flow head to tail from exposure? Blood flow as the question to apply the rules of causation.

471
01:03:48,190 --> 01:03:52,900
If the answer is no, the parties undirected and there is no causal effect.

472
01:03:53,650 --> 01:03:58,060
If the answer is yes, the path is directed and the exposure causes the.

473
01:03:59,200 --> 01:04:07,220
So let's do it for these two pets. Do all arrows flow head to tail on this path?

474
01:04:08,360 --> 01:04:13,280
No. That means the party's undirected. There is no causal effect.

475
01:04:13,670 --> 01:04:16,670
How about on this path to all arrows flow here today?

476
01:04:16,790 --> 01:04:21,440
Nope. So the same situation. Step five.

477
01:04:23,000 --> 01:04:26,870
Conclude. And this is the rule.

478
01:04:27,440 --> 01:04:36,260
Important rule to conclude. It only takes one open path for there to be statistical association.

479
01:04:37,550 --> 01:04:43,730
If that that fulfills a condition called faithfulness that you don't have to worry about.

480
01:04:45,350 --> 01:04:57,530
Are assuming faithfulness. And it only takes one directed path for there to be causation overall.

481
01:04:59,900 --> 01:05:04,120
All right. So let's conclude on this example.

482
01:05:08,860 --> 01:05:12,130
Because there is no association on either of these bats.

483
01:05:12,970 --> 01:05:21,070
There is no statistical association overall because there is no causation on either, but there is no causation overall.

484
01:05:21,700 --> 01:05:25,210
Is there a positive effect on newborn sex, on preterm birth? No.

485
01:05:26,200 --> 01:05:34,460
And you are done. You can add some notation here if you are feeling sort of fancy or.

486
01:05:37,550 --> 01:05:44,780
These would be the corresponding notation here. First practice right now because.

487
01:05:49,840 --> 01:05:53,260
Right? Well, in this case, yes, but, you know, I suppose. Yeah.

488
01:05:53,260 --> 01:06:00,339
I mean, you could with experience I bolded again immediately that but yeah we're just trying

489
01:06:00,340 --> 01:06:05,650
to follow systematically the steps because of the next examples that are coming up.

490
01:06:08,180 --> 01:06:11,430
Especially the last. All right, another question.

491
01:06:11,450 --> 01:06:15,109
That's preterm birth, cause, breastfeeding duration. What is preterm birth then?

492
01:06:15,110 --> 01:06:20,230
Birth rate invasion? First of all, define exposure.

493
01:06:20,250 --> 01:06:25,160
No exposure is.

494
01:06:26,140 --> 01:06:31,430
With The Pretenders. Outcome is breastfeeding duration.

495
01:06:32,240 --> 01:06:37,850
I think that the animation is messed up. I apologize. So let's go through the pets.

496
01:06:39,980 --> 01:06:47,120
The first birth that connects preterm birth with breastfeeding goes from A through and through Z.

497
01:06:48,050 --> 01:06:52,740
Okay, so I put it here and I preserve the Arrowhead directions.

498
01:06:53,540 --> 01:07:01,970
The second part is you can also connect preterm birth to respiration through A, then Y and then Z.

499
01:07:03,080 --> 01:07:10,740
Right? And I have preserved here the detection of the. Apply the rules of association.

500
01:07:10,780 --> 01:07:15,190
Next. Was the question you have to ask for each birth.

501
01:07:18,690 --> 01:07:21,960
How do you enjoy this game? Are there colliders on this path?

502
01:07:22,650 --> 01:07:26,160
No. So the path is open or close? Open.

503
01:07:26,370 --> 01:07:32,680
Is there a statistical association? Yes. Are there colliders on this other path?

504
01:07:33,850 --> 01:07:38,350
No. Is the path open? Yes. Is there a statistical association?

505
01:07:39,100 --> 01:07:45,210
Yes. Okay. Now applying the rules of causation was the question.

506
01:07:46,910 --> 01:07:50,330
Do all arrows flow head to tail on this path?

507
01:07:50,360 --> 01:07:54,200
Yes. Is there a causal effect? Yes.

508
01:07:55,410 --> 01:07:58,580
All arrows flow head to tail on this set? No.

509
01:07:59,000 --> 01:08:02,360
Is there a causal effect? No. Conclude.

510
01:08:06,060 --> 01:08:09,790
There is an association because there is an association on at least one part.

511
01:08:09,810 --> 01:08:15,980
So you say yes. There is causation because there is causation on at least one part, even though there is.

512
01:08:15,980 --> 01:08:19,790
And you know so that's. But then birth cause breastfeeding duration.

513
01:08:22,130 --> 01:08:29,010
It only takes one, but. Yes. Okay. Last example.

514
01:08:30,770 --> 01:08:36,080
That's hunger sensation cause preterm birth. First day of exposure.

515
01:08:39,040 --> 01:08:43,990
Hunger sensation. Viability Outcome. Preterm Birth.

516
01:08:44,350 --> 01:08:55,010
Eight. Pets. These connected to AI through A, B, A, and here is the original arrows.

517
01:08:56,150 --> 01:09:01,190
These are also connected to AI through a Y and AI.

518
01:09:02,030 --> 01:09:05,120
And here is the preserved direction of the arrowheads.

519
01:09:06,940 --> 01:09:11,530
Rules of association. Question. And if colliders.

520
01:09:12,220 --> 01:09:16,300
No. Is the path open that is artistically associated?

521
01:09:16,600 --> 01:09:27,280
Yes. Second, radical ideas. Are there any variables on which to arrowheads collide?

522
01:09:28,150 --> 01:09:31,540
Yeah. Quite right. So is this open?

523
01:09:32,840 --> 01:09:46,670
Yeah. These open no is an association no rules of causation to all arrowheads flow head to tail on these, but no is there a causation?

524
01:09:48,470 --> 01:09:53,990
Do all arrowheads flow head to tail and despite the causation so.

525
01:09:55,470 --> 01:10:00,630
Because it only takes one path for there to be a statistical association overall.

526
01:10:01,020 --> 01:10:05,820
Is there association? Yes. Is there causation?

527
01:10:06,630 --> 01:10:10,610
No. So does hunger sensation cause preterm birth?

528
01:10:11,120 --> 01:10:14,660
No. If you go collect data, will you find a statistical association?

529
01:10:15,860 --> 01:10:18,890
Yes. Does it have a causal interpretation? No.

530
01:10:19,370 --> 01:10:25,280
So this goes back to your original question. Right.

531
01:10:29,990 --> 01:10:36,560
Here is the notation if you. Now how do we describe association using?

532
01:10:36,940 --> 01:10:48,550
In other words, how do we draw decks? The most important thing you need to know is that to draw that you need prior knowledge.

533
01:10:48,560 --> 01:10:54,680
I think you were the person who brought this important concept up few lectures in.

534
01:10:55,650 --> 01:11:04,680
You need prior knowledge. You need some. Knowledge that is already, you know, believed to be close and to be able to draw that.

535
01:11:06,480 --> 01:11:12,030
From the literature. So I'm going to present you with scenarios of.

536
01:11:15,160 --> 01:11:25,040
Because knowledge. And your mission, should you decide to accept it, is to represent those scenarios only that.

537
01:11:28,090 --> 01:11:36,220
Data suggest that youth who engage in binge drinking are more likely to be diagnosed with depression than those who do not engage in binge drinking.

538
01:11:37,060 --> 01:11:40,510
So there is a positive association between binge drinking and depression.

539
01:11:41,500 --> 01:11:43,570
Does binge drinking cause depression?

540
01:11:44,720 --> 01:11:53,480
So we go to the literature and we find some prior knowledge that says there is a gene that predisposes some people,

541
01:11:53,780 --> 01:12:00,170
causes some people to both engage in binge drinking and to become depressed.

542
01:12:00,740 --> 01:12:06,620
So how do we represent this? We could start with the gene variable, let's say.

543
01:12:06,620 --> 01:12:10,310
Well, that causes binge drinking.

544
01:12:10,550 --> 01:12:16,070
Right on the one hand, but also causes people to become depressed.

545
01:12:16,860 --> 01:12:21,739
Variable what the outcome is a. Excuse me.

546
01:12:21,740 --> 01:12:26,690
The exposure is the outcome is why does binge drinking cause depression?

547
01:12:28,280 --> 01:12:33,740
Was there real question I have to ask? Do all the arrows flow here today?

548
01:12:34,610 --> 01:12:43,330
No. So if this that truly represents the underlying system, binge drinking does not cause depression.

549
01:12:43,900 --> 01:12:47,050
Are these statistical associated? Yes.

550
01:12:47,230 --> 01:12:51,630
But these open. There are no colliders. These. No.

551
01:12:51,990 --> 01:13:01,830
We also find or alternatively, we can also find that binge drinkers engage in binge drinking because they have addictive personality traits.

552
01:13:02,700 --> 01:13:09,180
In addition to alcohol, people with addictive traits use other addictive substances, including amphetamines, which may cause depression.

553
01:13:09,990 --> 01:13:12,000
How do you represent this bit of knowledge?

554
01:13:13,230 --> 01:13:20,090
We can start with the addictive traits, which in this case is a variable perhaps that cannot be measured in a study.

555
01:13:20,970 --> 01:13:26,310
The measurable. Or was it mission?

556
01:13:27,690 --> 01:13:33,440
But we know from this prompt that addictive traits cause people to engage in binge drinking.

557
01:13:33,510 --> 01:13:40,500
So there is a direct effect here, and it also cause people to use amphetamines.

558
01:13:41,630 --> 01:13:46,160
And it is also said that amphetamine use of amphetamines causes depression.

559
01:13:49,260 --> 01:13:54,030
If this is the truth from various analysts, does binge drinking cause depression?

560
01:13:56,030 --> 01:13:59,660
No. Are they statistically associated?

561
01:14:00,470 --> 01:14:03,800
Yes. Because they are connected through a backdoor path.

562
01:14:05,130 --> 01:14:15,220
Where there are no colliders. Yes.

563
01:14:16,070 --> 01:14:19,720
Can you say to the same person that the strangest.

564
01:14:20,290 --> 01:14:23,710
Leads to depression. Yes. Excellent.

565
01:14:24,970 --> 01:14:29,050
The question is, can you say that addictive traits cause depression?

566
01:14:29,740 --> 01:14:37,610
And the answer is a resounding yes, because they pass from addictive traits to depression is detected and open.

567
01:14:39,050 --> 01:14:44,730
Wonderful. Thank you. How about this other bit?

568
01:14:44,880 --> 01:14:53,300
People at the early stages of depression while still undiagnosed engaged in binge drinking to cope with their depressive symptoms.

569
01:14:54,270 --> 01:14:59,210
How do we represent these? It's a good one.

570
01:15:00,050 --> 01:15:05,720
So the president goes is binge drinking reverse causation?

571
01:15:07,430 --> 01:15:17,620
Okay. Right. You remember last week's example as Monday's maternal mortality is inversely associated with infant deaths?

572
01:15:17,980 --> 01:15:19,540
Is this a causal association?

573
01:15:20,230 --> 01:15:27,640
So we go to the literature and we find a higher education leads to both lower piety and to fewer infant deaths that represent that.

574
01:15:28,780 --> 01:15:32,470
So exposure, disparity, outcome is infant death.

575
01:15:33,220 --> 01:15:40,480
And what the prompt is telling us is that education courses, both on the one hand and on the other education courses,

576
01:15:40,750 --> 01:15:47,680
and that so if these that fully represented the underlying causal system, that's pretty cause infant death.

577
01:15:49,910 --> 01:15:54,770
Question? No. Despite it statistically associated with being funded.

578
01:15:55,760 --> 01:16:00,570
Yes. So in summary.

579
01:16:03,310 --> 01:16:10,300
To draw that. Assume the explanatory statements that somebody might give you represent prior

580
01:16:10,660 --> 01:16:15,010
knowledge and that the complete causal system is enclosed in those statements.

581
01:16:16,710 --> 01:16:21,090
Identify the possible cause and the possible effect explosion.

582
01:16:21,130 --> 01:16:27,040
I'll break down the statements if there is more than one for each statement.

583
01:16:27,060 --> 01:16:31,500
Identify all the variables and draw letters that represent each.

584
01:16:33,540 --> 01:16:36,750
Consider how the variables relate to each other in time.

585
01:16:37,260 --> 01:16:45,390
What happens before? What happens after? Because that will tell you the direction the arrowheads you point, right?

586
01:16:46,620 --> 01:16:54,090
Then draw the connectors between the variables according to the information given by the statements and the temporal sequence between them.

587
01:16:54,220 --> 01:16:59,600
Recall the arrows represent time. And then finally,

588
01:16:59,600 --> 01:17:06,709
this is just a sort of a technical bit when the problem says things like two variables are

589
01:17:06,710 --> 01:17:13,970
associated through something or because of something on for something which is unknown.

590
01:17:15,050 --> 01:17:26,030
That typically means they are. Common effects of something else, which sometimes may not be measured or measurable or known.

591
01:17:32,490 --> 01:17:36,870
We will have practice of of these at the lab and then at homework.

592
01:17:37,110 --> 01:17:43,730
But again, the lab should will be before the homework is due on a lag again they they like.

593
01:17:43,770 --> 01:17:54,450
So that was that helpful this week to have the lab before the homework was you know to summarize the uses of

594
01:17:54,450 --> 01:18:02,580
that that help us clearly define the causal research question what type of effect are we estimate total,

595
01:18:02,610 --> 01:18:10,510
direct or indirect? If you're conducting a study with existing data, many of you may actually do for you really.

596
01:18:11,520 --> 01:18:20,010
And these effects be identified with the variables you have available after you have done your iteration, search and prior knowledge and.

597
01:18:22,060 --> 01:18:31,840
If you're planning a new study with primary data collection, which variables do you need to measure it that can tell you that?

598
01:18:34,660 --> 01:18:39,790
And when analyzing data from a study, regardless of whether it's primary or secondary,

599
01:18:40,420 --> 01:18:46,479
how you should treat the variables that you have at hand to estimate the given causal effect,

600
01:18:46,480 --> 01:18:50,050
and we will do that more of that in the second part of the course.

601
01:18:53,070 --> 01:18:57,660
But obviously, you know, dogs are far from perfect and they have limitations.

602
01:18:58,080 --> 01:19:05,130
Limitations emanate from their non parametric nature.

603
01:19:05,400 --> 01:19:10,470
Well, what is that? That non parametric means there are no numbers attached to that.

604
01:19:11,520 --> 01:19:14,760
That's a big problem. That's a big problem.

605
01:19:16,110 --> 01:19:25,669
In other words, they are not really one viable. That means they cannot represent the scale of an association.

606
01:19:25,670 --> 01:19:28,760
And you recall that we evaluate an association.

607
01:19:28,760 --> 01:19:35,810
We always have two options an additive scale and negative scale only that you cannot tell which one is being used.

608
01:19:36,980 --> 01:19:43,680
To quantify the statistical associations. They cannot represent the magnitude of the association.

609
01:19:44,920 --> 01:19:50,050
You don't know if variables that are strongly associated or weakly associated.

610
01:19:51,090 --> 01:19:56,430
For me that they don't even represent the direction of the association.

611
01:19:57,490 --> 01:19:58,270
You don't know if.

