1
00:00:00,680 --> 00:00:05,640
Okay. Okay. So hi everyone. Welcome back to at 636.

2
00:00:06,660 --> 00:00:14,070
First thing I want to talk about before we get into sort of moving forward is scheduling and workload.

3
00:00:14,460 --> 00:00:19,110
I get the impression that an extra workday would probably be helpful in the near future,

4
00:00:20,310 --> 00:00:24,780
especially given that we didn't really have access to joined point last week.

5
00:00:25,700 --> 00:00:37,590
Um, and so my plan is tentatively speaking to a be a little bit flexible with the deadlines for lab four and five.

6
00:00:38,130 --> 00:00:49,140
I've given us the next two weeks a lot for already I'm working with as teachers I need to get this joint point six.

7
00:00:49,140 --> 00:00:54,360
Our joint is already working, but get the Cyr stack working.

8
00:00:54,840 --> 00:01:00,000
He was like, Oh, I logged in virtually and it was fine. It's like, Well, I walked in in person and it was not fine.

9
00:01:00,330 --> 00:01:07,260
So I'm not quite sure what, what the disconnect is there, but hopefully we'll get that figured out.

10
00:01:08,430 --> 00:01:11,670
We are still scheduled to be back in the computer lab on Monday.

11
00:01:12,330 --> 00:01:17,980
Um, and hopefully they'll be working then we are going to continue with joint point.

12
00:01:18,000 --> 00:01:29,280
One point is also available only for Windows computers and is on the is on and is it working.

13
00:01:29,880 --> 00:01:36,690
Was last I checked in on the computer lab computers so unfortunately I can't just like jump

14
00:01:36,690 --> 00:01:42,540
ahead to this because you still need your data for the concerns that it's from serious that um,

15
00:01:43,110 --> 00:01:51,810
which is why I'm hoping that and it will have at least see us start working on Monday so you can download the data.

16
00:01:51,930 --> 00:01:57,320
And when we're back here on Wednesday, we'll be able to just kind of look forward.

17
00:01:57,390 --> 00:02:04,970
Yes. So lab for this, your stat lab that's supposedly due on Monday right now is that I moved it.

18
00:02:05,250 --> 00:02:09,030
So I moved it to the 10th.

19
00:02:09,030 --> 00:02:12,450
I think that's October. I don't know, whatever it is on campus.

20
00:02:12,780 --> 00:02:15,450
And then that can be flexible with me too.

21
00:02:15,780 --> 00:02:21,210
I also know that Lab three ended up being kind of more work than I had originally thought it was going to be.

22
00:02:21,570 --> 00:02:25,590
So I just wanna make sure that we're talking about a reasonable pace here.

23
00:02:26,220 --> 00:02:34,380
Um, but given that probably don't have your serious data, we're just going to move forward learning about Joined Point today,

24
00:02:34,740 --> 00:02:40,800
then we'll take a little bit of a break to kind of recalibrate and then move on to HPC models after we've had that break.

25
00:02:41,490 --> 00:02:48,090
Okay. So today we're going to talk a little bit more about how to think about the cancer incidence and how to, how to moderate.

26
00:02:48,930 --> 00:02:55,770
Um, so before we have mostly been focusing on just visualizing cancer incidence and kind of looking at trends by eyes.

27
00:02:55,770 --> 00:03:00,030
So how do we do a little bit more quantitative analysis of these trends?

28
00:03:01,500 --> 00:03:14,130
So here's to, uh, cancer incidence curves for colorectal cancer for men and women to make sure I'm reporting to say, okay, I'm okay.

29
00:03:15,070 --> 00:03:20,660
Um. And we might want to ask the question.

30
00:03:20,660 --> 00:03:23,960
So are the trends for men and women different?

31
00:03:25,610 --> 00:03:29,060
How much is the incidence changing each year?

32
00:03:29,660 --> 00:03:33,340
It's sort of generally going up. When does the trend change?

33
00:03:33,350 --> 00:03:36,530
So do these kind of little ups?

34
00:03:37,280 --> 00:03:40,760
Are these just noise?

35
00:03:41,150 --> 00:03:48,500
Are they, like, real in some sense? And so so what's essentially a straight line on these plots?

36
00:03:48,800 --> 00:03:58,730
Where do we put different lines? Are these sort of Gibson bumps real trend changes or are they little blips due to data collection?

37
00:04:04,090 --> 00:04:11,410
So we might want to ask, how do you summarize trends in this could be in cancer incidence?

38
00:04:11,680 --> 00:04:16,210
Well, we could also be looking at deaths or other types of longitudinal data.

39
00:04:17,170 --> 00:04:22,990
So one thing you might say is, well, one, you just look at the averages over time.

40
00:04:23,410 --> 00:04:35,770
So what how how has like the average incidence between 1973 and 1983, how is that different from 83 to 93 example?

41
00:04:36,670 --> 00:04:44,890
Okay. And that's all well and good, but it's actually pretty subjective where you put those, um, you know,

42
00:04:45,670 --> 00:04:51,160
whether you're doing like two year, five year, ten year averages, are you starting at the beginning of the decade?

43
00:04:51,940 --> 00:04:54,880
And so these things can be pretty subject to manipulation,

44
00:04:55,090 --> 00:05:03,010
just kind of by changing where you put your employees and and what the length of the periods are.

45
00:05:04,030 --> 00:05:08,380
Okay. So then we might say, what are polynomial models?

46
00:05:08,740 --> 00:05:12,220
You know, in Excel we could just kind of like fifties, like crazy curves,

47
00:05:13,540 --> 00:05:21,400
like 10th degree polynomials and just like feel that the data are reasonably well and these can definitely produce a good fit,

48
00:05:22,000 --> 00:05:27,220
but they're tend to be really hard to describe because, you know, what does that even mean?

49
00:05:27,370 --> 00:05:32,680
That like the coefficient on the x to the fifth, you know, was 0.02.

50
00:05:33,280 --> 00:05:38,380
What is that? And how do you how do you explain that to someone when talking about cancer incidence trends?

51
00:05:39,250 --> 00:05:45,550
And so as an alternative, we're going to talk about doing models and doing point models,

52
00:05:46,660 --> 00:05:52,780
which all defined the second are nice because they're really useful for asking whether trends are changing.

53
00:05:52,810 --> 00:05:57,970
So at what point does the trend change from being one trend to another trend?

54
00:05:59,950 --> 00:06:05,019
We're also going to focus on these because this is what, you know, I'm not sure where all of you are going in your careers,

55
00:06:05,020 --> 00:06:14,440
but if any of you end up in a health organization like NCI or CDC or W.H.O., they use joint points in their work.

56
00:06:16,630 --> 00:06:20,680
One limitation, though, is that it's a simplification because, you know,

57
00:06:20,710 --> 00:06:28,630
cancer rates aren't changing at sort of constant rates that that change at certain points.

58
00:06:28,930 --> 00:06:36,010
But it's kind of a first step. So let's look at just an example of cancer incidence.

59
00:06:36,280 --> 00:06:43,590
This is all cancer, not generally something that we look at in terms of overall incidence, but it helps kind of prove a point here.

60
00:06:43,600 --> 00:06:48,160
So this is all cancer cases in men from 1975 to 2015.

61
00:06:49,270 --> 00:06:54,640
And you could say, okay, let me fit this polynomial model on top of it.

62
00:06:55,840 --> 00:07:01,420
It gets the sort of general shape, right? But like there's lots of places where it's not doing a very good job.

63
00:07:01,870 --> 00:07:06,250
You know, this kind of bump here, it's not getting all the way up.

64
00:07:06,700 --> 00:07:10,210
This is not very right. I'm not sure why it's doing that.

65
00:07:12,790 --> 00:07:17,919
A joint plant model, on the other hand, is just a series of line segments, essentially.

66
00:07:17,920 --> 00:07:22,060
So we're going to just be drawing straight lines over our data.

67
00:07:23,020 --> 00:07:33,310
It's a pretty simple, pretty simplified approach, but at least it is easy to understand and fairly easy to implement,

68
00:07:33,610 --> 00:07:38,020
although as we'll see, there are some interesting sort of challenges under the.

69
00:07:40,610 --> 00:07:45,139
So what is it like my model? And there is some of those terms.

70
00:07:45,140 --> 00:07:53,450
It's just a piecewise linear or piecewise linear model, so simple as that, even for linear regressions.

71
00:07:53,900 --> 00:07:58,520
But they are you can have multiple of them that change at certain points.

72
00:07:58,760 --> 00:08:03,440
And if these points of trend change, we call it joint and strain point model,

73
00:08:04,400 --> 00:08:09,590
I'm not sure that I think that's the best name, but that's what the standard as an industry.

74
00:08:09,890 --> 00:08:11,750
So that's what we call it.

75
00:08:12,110 --> 00:08:19,820
I generally prefer piecewise linear model, but I think it's more descriptive than doing quant, but just that that's what it is.

76
00:08:20,690 --> 00:08:28,910
So generally we like the number and locations of joint points to be determined by the data rather than determined by the user.

77
00:08:31,810 --> 00:08:40,700
And so this is we're sort of less subject to this specification and manipulation

78
00:08:40,730 --> 00:08:45,340
if you allow the data to kind of decide what the best driving model is.

79
00:08:46,510 --> 00:08:55,300
But we do have to constrain the sort of maximum minimum number of driving points for us for the model to sort of search through.

80
00:08:58,030 --> 00:09:12,210
All right. So let's look at an example here. So this is a piece was a linear model where we say we have this slope from 1969 to 1973.

81
00:09:12,960 --> 00:09:22,800
We have this different line segment from 1973 to 1991 and this different line segment from 1991 to 2000.

82
00:09:24,510 --> 00:09:34,290
And we can write the model as just three separate linear functions on a sort of piecewise on over time.

83
00:09:35,130 --> 00:09:44,370
And this is one way to write the model in a way that really emphasizes the piece wise, linear ness of what's going on.

84
00:09:45,930 --> 00:09:54,810
And at the joints, you'll notice that you're constrained so that the two pieces have to be equal to each other because this is a continuous model.

85
00:09:58,220 --> 00:10:04,700
So continuous improvements. That's only one way to specify a joint pain model.

86
00:10:05,720 --> 00:10:22,400
The other way is to specify it based on the initial intercept and a series of indicator functions that kind of add to the slope as you go over time.

87
00:10:22,760 --> 00:10:30,589
So you start with slope beta one. You get to 1973, you add slope delta one.

88
00:10:30,590 --> 00:10:40,430
So now, right, so beta two, then you add Delta two to get all the way to get to beta three.

89
00:10:42,560 --> 00:10:53,540
And so the indicators are nice because this works much better with our sort of standard regression framework of using like a model matrix.

90
00:10:53,900 --> 00:10:56,210
Like I'll show you in a moment.

91
00:10:56,270 --> 00:11:04,220
So the model is essentially exactly the same, or like there's a way to write it so that you get the same as that, that piecewise form.

92
00:11:04,610 --> 00:11:10,100
But this is the way we tend to work with. And then you can sort of start to think about, you know,

93
00:11:11,570 --> 00:11:18,060
in our standard sort of statistical framework, is Delta one significantly different than zero?

94
00:11:19,100 --> 00:11:23,990
If it is significantly different than zero, then you have a kind of a trend change.

95
00:11:25,070 --> 00:11:30,500
If Delta two is significantly different than zero, then this is a significant trend change.

96
00:11:35,730 --> 00:11:42,360
So the model matrix. So how many of you are familiar with model matrix in the context of regression?

97
00:11:43,950 --> 00:11:48,090
But was I matrix or is I matrix? Yeah. Okay. Just just one.

98
00:11:48,480 --> 00:11:59,220
So the high under the hood linear regression analysis of regression models is this idea of the model matrix.

99
00:11:59,640 --> 00:12:07,890
And that comes from thinking about the output Y as being a function of the product of a

100
00:12:07,890 --> 00:12:15,870
matrix X and some regression coefficients or effect coefficients to beta and some error.

101
00:12:17,550 --> 00:12:28,890
And so what we're always trying to find is these effects coefficients or betas that tell us how each row of the designed matrix,

102
00:12:29,460 --> 00:12:37,320
each, um, predictor essentially affects the output.

103
00:12:39,030 --> 00:12:48,089
And so one sort of classic result from statistical theory is that you can write through, um, least squares.

104
00:12:48,090 --> 00:12:55,620
This is the sort of the result of these squares. It's a projection on to the sort of the right space.

105
00:12:56,100 --> 00:13:02,250
Um, and we're not going to get into that in this class, but if you,

106
00:13:03,210 --> 00:13:09,360
there's sort of plenty of information out there on the Internet to to to sort of both.

107
00:13:09,720 --> 00:13:14,310
The point being, though, is that we're going to think about our model matrix.

108
00:13:15,300 --> 00:13:20,130
Typically, we have this rule ones when we ever read an intercept in the model.

109
00:13:20,640 --> 00:13:27,000
So that's just saying what better times one is added to get are wise.

110
00:13:27,450 --> 00:13:34,380
So it's just, it's a constant, uh, it's that the data zero or the B and X plus B.

111
00:13:36,750 --> 00:13:40,680
Because we have essence as a function of time.

112
00:13:40,680 --> 00:13:44,580
We have to include time as one of the recurring columns of our model matrix.

113
00:13:44,970 --> 00:13:53,730
That's the X and our Y equals an x plus b is the the independent variable.

114
00:13:55,890 --> 00:14:01,780
And then we're going to include these indicator functions that are zero.

115
00:14:02,700 --> 00:14:06,060
If they are less than.

116
00:14:07,020 --> 00:14:14,580
In this case, 1973. Then move up linearly. And this one is zero plus 1991, and we move up linearly.

117
00:14:16,020 --> 00:14:26,160
And so what we always what happens is to get y one, we take the first row at the model matrix, multiply it by our coefficients,

118
00:14:26,490 --> 00:14:31,860
and that gives us y one we then some error and the same for y two we take the second row,

119
00:14:32,250 --> 00:14:42,210
multiply it by the beta and deltas, plus an area that y two, so on and so forth.

120
00:14:43,330 --> 00:14:46,480
Okay. Generally speaking, we don't do this by hand.

121
00:14:46,750 --> 00:14:52,480
Right. We like the software to do it for us. I argue that it's helpful to know what's going on under the hood.

122
00:14:53,350 --> 00:14:57,760
But from our perspective, we don't need to sort of dove too much into the details.

123
00:14:58,840 --> 00:15:08,079
Having this regression framework is nice because we can get kind of standard statistical things that are statistical here being super technical,

124
00:15:08,080 --> 00:15:17,920
our statistical things are sustainable outcomes such as standard errors, confidence intervals,

125
00:15:18,370 --> 00:15:22,690
testing, whether your coefficients are statistically different from zero.

126
00:15:22,900 --> 00:15:34,380
So having that whole framework is very nice. One thing I mentioned is that your model can be linear or model there,

127
00:15:35,610 --> 00:15:41,430
and generally speaking well will tend to prefer log linear models for cancer incidence

128
00:15:42,630 --> 00:15:48,270
because we like to be able to characterize them by this annual percentage change.

129
00:15:49,140 --> 00:15:56,880
That's one way of characterizing the trend as a percent change in incidence as opposed to an absolute changed incidence.

130
00:15:57,180 --> 00:16:03,510
So you can think of this linear model as being the absolute change in the log in your model as being the relative change.

131
00:16:05,350 --> 00:16:10,100
Um, here, I just have a little bit of formula just so that you have it here.

132
00:16:10,920 --> 00:16:16,320
But if we think about our model as being the log of why this so that's a log in your model.

133
00:16:17,640 --> 00:16:27,900
And if I think about my change, I think about the rate and the next tier minus the rate in the current year and divide by the current year.

134
00:16:28,050 --> 00:16:31,080
So that's just the typical percent change formula.

135
00:16:31,710 --> 00:16:35,940
If I end up plugging all of this in and simplifying,

136
00:16:36,420 --> 00:16:44,070
it turns out that I have a fairly nice way of expressing the annual percent change as a function of that slope parameter.

137
00:16:46,670 --> 00:16:55,400
And when you go to present the results of a joint joint model, this is what people like to see annual percentage change.

138
00:16:55,670 --> 00:17:02,479
It's very, uh, descriptive and understandable.

139
00:17:02,480 --> 00:17:10,790
And so that's why this is sort of generally preferred, not that the slope of a linear model isn't also understandable,

140
00:17:10,790 --> 00:17:14,750
but this is pretty much this is the standard in most situations.

141
00:17:18,940 --> 00:17:27,190
Often we want to go a little bit farther than just the annual percent change and think about the average annual percent change.

142
00:17:27,490 --> 00:17:31,360
So that will help make the average annual percent change over fixed intervals.

143
00:17:32,050 --> 00:17:42,250
So what that means is that these joint points happen at kind of like upper places relative to what we normally present data.

144
00:17:42,520 --> 00:17:51,880
Right. We like to put you know, we have our sense of time as humans and we're like, this is 1970, 1975.

145
00:17:52,150 --> 00:17:56,790
And so we like to we have these like five year periods. We don't like to start in like 1973.

146
00:17:56,790 --> 00:18:03,800
You want to start 1970? You want to start in 1975. And so our joint points don't always agree with us.

147
00:18:04,240 --> 00:18:10,300
And so we'll probably do is pick this interval and say, what's the annual average percent change?

148
00:18:10,690 --> 00:18:21,610
Even though it crosses this join point. And so to do that, there's a pretty standard formula where basically you just wait.

149
00:18:22,450 --> 00:18:37,540
The length of time contributed to the interval. So in this case, you'd have three years, actually, 70, 71, 72, 73, three years, 72, 71,

150
00:18:37,540 --> 00:18:49,870
73 to 20, 23, three years in this interval and 73 to 74, 74 is 75 two and the next slope.

151
00:18:52,900 --> 00:19:02,670
So a weight appropriately with our the slope for each interval and just kind of and then appropriately.

152
00:19:03,430 --> 00:19:12,190
And so why I'm telling you this is that when you go to actually report trends in cancer incidence,

153
00:19:12,400 --> 00:19:15,190
this is what the National Cancer Institute wants to see.

154
00:19:16,180 --> 00:19:25,090
So they want to see both annual percent changes and joint points and these average annual percent changes.

155
00:19:25,570 --> 00:19:27,970
So they like they provide them and they like to see them.

156
00:19:28,240 --> 00:19:34,750
And so that's something that reviewers, if you want to publish a paper, often are going to be interested in seeing as well.

157
00:19:36,310 --> 00:19:44,440
Yeah, there's quite a difference between moving averages and a a piece.

158
00:19:46,210 --> 00:19:49,500
It's. I mean, it's part of big. Yeah.

159
00:19:49,510 --> 00:19:54,580
So. So a moving average would be a moving average of the incidents values themselves,

160
00:19:55,450 --> 00:20:05,050
whereas this is an average of the slopes of the models which are had already been calculated by your joint model.

161
00:20:07,640 --> 00:20:17,210
So this is really once you have a joint plant model, how do you describe it to stakeholders?

162
00:20:19,180 --> 00:20:23,040
Okay. So how do we actually go about doing the driving model?

163
00:20:23,250 --> 00:20:27,300
You might say piecewise linear regression. Super straightforward.

164
00:20:27,570 --> 00:20:31,380
Like why is why we even like talking about this? Just slap a model on that, right?

165
00:20:31,680 --> 00:20:37,350
It's actually a little bit more difficult than it looks if you want your joint points to be determined by the data.

166
00:20:38,430 --> 00:20:42,570
So the way that we think about this is first, we're going to set a maximum minimum number of joint points.

167
00:20:43,680 --> 00:20:47,550
You have to have you have to have fewer turning points than you have points in the data, of course.

168
00:20:47,850 --> 00:20:56,340
But even then, you're looking for a balance between sort of parsimony and being able to fit the data.

169
00:20:56,700 --> 00:21:00,060
We don't want to overfed all of the little extra bumps.

170
00:21:01,050 --> 00:21:06,750
So what's going to happen is that for all possible combinations of number and location of joint points,

171
00:21:07,500 --> 00:21:10,080
you fit the best fit model and assess goodness of fit.

172
00:21:10,480 --> 00:21:20,970
So the model is literally saying like, okay, what if there was a joint point in 1979 and 1987 and 1997, and it computes that.

173
00:21:21,570 --> 00:21:29,010
And then it's like, okay, that's the same thing. But now 1998. And then it computes that model and it does all of the different iterations.

174
00:21:30,210 --> 00:21:41,640
Fortunately, linear models are relatively computationally light so that this is even doable, but it still takes a while, generally speaking.

175
00:21:44,270 --> 00:21:47,720
Um. So you. So what?

176
00:21:47,730 --> 00:21:53,400
Regression is fast. So. So this is doable, despite the very large number of possible combinations.

177
00:21:53,660 --> 00:22:04,550
And so you can imagine that the longer your underlying timespan and the more joint points you want to include, the harder this is to do.

178
00:22:07,060 --> 00:22:10,230
Okay. So what does that look like?

179
00:22:10,560 --> 00:22:13,860
Easiest to see for a single drink.

180
00:22:14,640 --> 00:22:25,900
So somewhere between 1970 and I think it was like 2000, we're going to try a joint plant at every single location and see which one has the best of.

181
00:22:26,580 --> 00:22:35,970
So some of square errors here is going to be our cost function, very similar to the negative log likelihoods that we worked with in Lab three.

182
00:22:36,510 --> 00:22:44,730
Some of square error is actually very related to Gaussian or normal distributed negative log likelihood.

183
00:22:47,420 --> 00:22:50,880
With some caveats, but that's the general idea.

184
00:22:50,900 --> 00:22:56,200
It's a it's a measure of the fit of your model to the data.

185
00:22:57,670 --> 00:23:08,840
And so we check every single joint point and say the joint point that gives us the best fit by having two trends is a joint plan in 1991.

186
00:23:11,970 --> 00:23:25,890
And what does that look like? Looks like this one linear trend up to 1991 and another from 1981 to 2001.

187
00:23:26,520 --> 00:23:30,120
And you can see here that that is pretty reasonable.

188
00:23:30,120 --> 00:23:34,320
Right. You might also put another join point here, maybe.

189
00:23:34,560 --> 00:23:38,880
But for a single joint point, that pretty clearly makes sense.

190
00:23:41,520 --> 00:23:45,510
And you can do the same thing as you increase the number of three points.

191
00:23:46,530 --> 00:23:52,470
This is not the data from previous. This is the data for all incidences of cancer for men.

192
00:23:53,100 --> 00:23:56,460
So that that model lives beginning where we had a polynomial.

193
00:23:57,000 --> 00:24:00,690
So now we have okay, let's take a single track on here.

194
00:24:00,690 --> 00:24:08,760
Currently, it's not terribly but not super great and you can start to see which are the trends that are the most important.

195
00:24:09,180 --> 00:24:12,660
As we break things a little bit further and further down.

196
00:24:16,390 --> 00:24:24,610
And then the question becomes, at which point do these extra joint points constitute overfitting?

197
00:24:28,350 --> 00:24:33,110
Because strictly speaking, increasing the number of playing programs has to improve the fact.

198
00:24:35,950 --> 00:24:42,380
So. But when are you overfitting? How to determine a number of things.

199
00:24:43,120 --> 00:24:47,769
So the two general approaches the first and generally accepted one is the

200
00:24:47,770 --> 00:24:56,080
permutation test that I assigned as an optional reading is available on canvas.

201
00:24:56,950 --> 00:25:04,510
The general idea of the permutation test is to define a physical no and alternative hypothesis

202
00:25:05,050 --> 00:25:10,180
and the null hypothesis you have t0 join points and in the alternative you have K-1.

203
00:25:10,660 --> 00:25:16,690
And our goal is to make a statistical decision based on distribution.

204
00:25:17,200 --> 00:25:23,530
The best is history. Unfortunately, there is no known distribution of the test statistic.

205
00:25:23,590 --> 00:25:30,520
There's no sort of natural. It's not a Gaussian, it's not a Chi square distribution.

206
00:25:30,880 --> 00:25:36,070
It doesn't a it's not an ABS statistic. And so that makes this a little bit difficult.

207
00:25:37,480 --> 00:25:45,790
And so the idea that that behind this testing is to compute the residuals from the null model.

208
00:25:46,930 --> 00:25:55,660
And that's going to help us estimate that an empirical distribution of the test statistic under the null hypothesis.

209
00:25:56,440 --> 00:26:01,570
I think I have some figures to hopefully make that a little bit clearer.

210
00:26:02,500 --> 00:26:05,890
Then once we have this empirical estimate of the distribution,

211
00:26:06,280 --> 00:26:14,020
we can estimate the P value is the fraction of tested mistakes under the different permutations that are greater than the uncommitted.

212
00:26:15,190 --> 00:26:25,090
And so this is this permutation test method for selecting the number of joint points is generally preferred,

213
00:26:25,540 --> 00:26:30,010
preferred if you want a parsimonious model, which we generally do.

214
00:26:33,730 --> 00:26:39,910
The second approach, which you may be more familiar with, is the Bayesian information criterion.

215
00:26:40,840 --> 00:26:50,110
Bayesian information criterion is one of a class of information criterion or information criterion.

216
00:26:50,380 --> 00:26:56,170
The other most commonly used one is the okay information criterion.

217
00:26:57,100 --> 00:27:00,190
And generally speaking, you don't have to memorize the form or anything like that.

218
00:27:00,550 --> 00:27:09,040
But the idea is that we're we have to they have two pieces to this information criterion.

219
00:27:09,370 --> 00:27:14,170
One is a contribution that is going to penalize performance.

220
00:27:14,260 --> 00:27:18,340
So that's typically negative or negative like likelihood or cost function.

221
00:27:18,700 --> 00:27:22,720
So we want to be able to say we want to do a good job of fitting the model.

222
00:27:23,350 --> 00:27:32,530
The second is that we want to avoid overfitting. And so we're going to penalize the number of parameters in a in a smart way so that your, you know,

223
00:27:32,830 --> 00:27:39,310
one parameter is equivalent to one point of log likelihood or something along those lines.

224
00:27:39,820 --> 00:27:49,960
So again, the specifics here don't really matter. But the idea is that we are trying to balance fit with avoiding overfitting.

225
00:27:50,810 --> 00:27:54,549
Okay. Yes. Can you explain the issues?

226
00:27:54,550 --> 00:27:57,760
But we're finding data that comes to mind.

227
00:27:58,570 --> 00:28:06,320
Yeah. So the idea is that. We want.

228
00:28:06,650 --> 00:28:16,970
So you can imagine adding more and more joint points so that all of a sudden, like in each between every year, there's a different trend.

229
00:28:17,870 --> 00:28:24,650
And the question is, is that useful to describe a trend from between every single pair of years, for example?

230
00:28:25,550 --> 00:28:30,410
And the answer is, well, that's not really a trend because it's sort of like a single, a single point.

231
00:28:31,300 --> 00:28:34,340
Um, so that's kind of the one end of the extreme.

232
00:28:34,610 --> 00:28:38,850
And then you could say, like, okay, well, what defines a trend?

233
00:28:40,130 --> 00:28:45,890
Um, and there it's a little bit of.

234
00:28:50,090 --> 00:28:54,469
Overfitting tends to be one of these like I know when I see it type things and the

235
00:28:54,470 --> 00:29:00,380
information criteria are how we're trying to sort of quantify the idea of overfitting,

236
00:29:00,680 --> 00:29:06,740
but it's not there's not kind of like a clearly defined, correct way of describing overfitting.

237
00:29:07,070 --> 00:29:15,950
We want to look ultimately, what are we doing as people in public health or sort of health related fields?

238
00:29:16,370 --> 00:29:22,460
We want to be able to distill information from the data and tell it to people.

239
00:29:23,210 --> 00:29:27,260
And we want to do that in a simple, yet effective way.

240
00:29:27,800 --> 00:29:35,180
And so that's why we're avoiding so we're having this overfitting effect predictions later on.

241
00:29:35,480 --> 00:29:46,850
So. What I say about that?

242
00:29:46,860 --> 00:29:50,160
Does overfitting affect predictions?

243
00:29:50,580 --> 00:29:56,940
So in the case of like forecasting, let's say that we're forecasting here.

244
00:29:57,390 --> 00:30:07,860
And so you can say like what you predict for 2020, assuming a constant trend is going to be different for each of these models.

245
00:30:07,860 --> 00:30:15,510
Right. And the more and more you quote unquote, over fit, you can see that these last two points are actually fairly flat.

246
00:30:16,200 --> 00:30:23,730
And so there might come a point where you say, like, actually, I think it's just going to be flat here, as opposed to, you know,

247
00:30:23,760 --> 00:30:30,090
one of these other reasonable models like this one that's going to suggest that this trend is going to continue quite a bit farther.

248
00:30:30,720 --> 00:30:36,180
So from that perspective, this is certainly going to affect my projections.

249
00:30:37,400 --> 00:30:41,010
Um, when I think about overfitting and.

250
00:30:43,900 --> 00:30:49,810
And predictions more generally, it's better in the context of predicting cancer incidence.

251
00:30:50,170 --> 00:30:57,720
It's you're not going to go back and be like, Oh, what was cancer incidence in like the first three months of 1990?

252
00:30:57,850 --> 00:31:01,390
Like, it's not a question that's particularly useful to ask, right?

253
00:31:01,900 --> 00:31:11,920
And so kind of going back and kind of thinking about rather than describing the trends, you're trying to like pick specific values.

254
00:31:12,190 --> 00:31:26,070
This is not really in this context. Outside of this context, I can definitely imagine situations where overfitting something where where I mean,

255
00:31:26,740 --> 00:31:42,160
something like biomarker values are dependent on that variable and like how something like this severity of outcome is on the Y axis.

256
00:31:42,490 --> 00:31:49,150
And I can imagine a situation where you could be overfitting that depending on your data.

257
00:31:49,600 --> 00:31:53,950
And that matters for you when you're predicting outcomes for other people in the future.

258
00:31:57,010 --> 00:32:00,790
Does that answer your question in no one wanted way? Okay.

259
00:32:01,180 --> 00:32:07,390
Yeah. I can use when this idea of pre meeting the residual, the model and the permutation has.

260
00:32:07,480 --> 00:32:14,410
Yeah. If I may have a so understanding or model of the model of care key not talking

261
00:32:14,410 --> 00:32:17,950
points but what do you mean like for me commuting the resistance from it.

262
00:32:19,120 --> 00:32:27,250
Yes. So it's a thought that I put a figure in the slides that I looks like I did.

263
00:32:28,120 --> 00:32:42,670
So. So then we have our normal level with some number of checkpoints.

264
00:32:43,240 --> 00:32:46,240
And these are my residuals.

265
00:32:47,050 --> 00:32:57,700
Yeah. And what I'm going to do is somehow draw the stand with a different color.

266
00:32:59,140 --> 00:33:16,840
And I'm going to say what the data that like this residual now goes over here and this residual goes over here and this residual goes over here.

267
00:33:20,430 --> 00:33:26,770
So now I have permeated all of my residuals across the different years,

268
00:33:27,400 --> 00:33:37,330
and I'm going to say what is like the model I would have drawn under the permutation residuals?

269
00:33:37,900 --> 00:33:41,410
Okay. And how much better or worse is that?

270
00:33:41,560 --> 00:33:49,240
Yes. Okay. And you're competing with that replacement rate so that every every residual gets the same.

271
00:33:49,420 --> 00:33:51,370
Yeah, that's right. Every know.

272
00:33:52,840 --> 00:33:59,800
I'll admit that like this is also a little bit out of my comfort zone in terms of like standard statistical things to do.

273
00:34:00,580 --> 00:34:05,880
Um, so it's a little bit of, uh. I recommend reading the cam at all paper.

274
00:34:06,250 --> 00:34:09,250
They do a good job of talking through it. Um.

275
00:34:10,330 --> 00:34:21,129
It's, I guess a little bit out of my comfort zone, but it's kind of like an ingenious approach to thinking about what I like about it.

276
00:34:21,130 --> 00:34:28,050
In particular is that a lot of what we do in the statistics is that like we have, um.

277
00:34:29,800 --> 00:34:34,780
Like algorithms for how we approach things. Okay, we want to test this thing.

278
00:34:35,050 --> 00:34:38,620
We're going to assume that there's normality and then we apply this test to it.

279
00:34:39,280 --> 00:34:48,490
All of a sudden, what happens when you want to instantly test something for which there is not a clearly defined approach?

280
00:34:49,270 --> 00:34:56,700
Um, you know, often we'll do things like Delta Method to come up with new distributions.

281
00:34:57,220 --> 00:35:04,030
But in a case like this, you really need a kind of empirical distribution test to.

282
00:35:05,790 --> 00:35:08,730
So what this ends up looking like is that you're testing this day.

283
00:35:14,220 --> 00:35:25,020
You end up getting a like curve of some sort and you say, you know, this was the test statistic at the model.

284
00:35:25,440 --> 00:35:37,620
What fraction of my empirical guesses based on, you know, if if this red line was the true red line, then the residuals are exchangeable.

285
00:35:37,920 --> 00:35:41,760
That's the definition of of an outcome for a linear regression.

286
00:35:42,090 --> 00:35:45,120
Right. Hetero as good as doesn't.

287
00:35:48,710 --> 00:35:52,070
And so if that's true, then we can premiere all of them.

288
00:35:52,280 --> 00:35:57,740
And then we have true values of how other test? So.

289
00:35:59,220 --> 00:36:02,490
So you have this curve of possible coming off.

290
00:36:03,000 --> 00:36:15,150
Yeah. So in the new compared to the norm, you can test that to that distribution or sorry, the alternate test that was written.

291
00:36:16,430 --> 00:36:23,700
Right. So what is this? Where do there. And then.

292
00:36:28,980 --> 00:36:32,860
Uranium is supposed to be. Each day.

293
00:36:34,180 --> 00:36:41,910
And I say is each day with an, you know, 95 milliliters.

294
00:36:47,300 --> 00:36:57,440
Yeah. So, so publicly they did not really, really dove into the market before coming to pass so we could find out more about it.

295
00:36:57,900 --> 00:37:06,710
That's not just the most common application of joint points, but in cancers like analyzing cancer trends or what other applications says typically.

296
00:37:06,950 --> 00:37:16,040
So I generally see in the context of cancer because the people that developed the model are from the National Cancer Institute,

297
00:37:16,610 --> 00:37:20,090
but it is completely transferable.

298
00:37:20,540 --> 00:37:24,340
Any place that you want to do piecewise linear regression.

299
00:37:24,810 --> 00:37:34,110
Okay. Thank you. So here we go.

300
00:37:34,290 --> 00:37:37,830
So what happens when we put this? We do the trick.

301
00:37:38,160 --> 00:37:43,770
So, again, we've been talking about sort of technical under the hood type things.

302
00:37:44,970 --> 00:37:50,070
We're going to be we're going to be using a software to basically do all of that for us.

303
00:37:50,400 --> 00:37:53,160
I just want you to sort of have a sense of what's going on under the hood.

304
00:37:53,910 --> 00:38:02,370
Well, we're actually going to get is something spit out stuff like this where you have different joint points for individuals.

305
00:38:02,670 --> 00:38:06,600
You'll notice here that these are all kind of slightly curved.

306
00:38:07,770 --> 00:38:12,750
Right. So these don't look linear anymore. That's because this is a logo in our model.

307
00:38:13,590 --> 00:38:21,240
So now you have little exponentials instead of linear functions.

308
00:38:22,200 --> 00:38:27,800
And because they're exponential, we can now do that annual percent change.

309
00:38:27,810 --> 00:38:35,700
And so we have annual percent changes for each of the trend periods.

310
00:38:36,600 --> 00:38:41,220
And we can say, okay, she doesn't want it here in five.

311
00:38:41,580 --> 00:38:44,970
What is the annual average annual percentage change?

312
00:38:45,810 --> 00:38:56,460
So this is exactly the sort of thing that has to be looked for when analyzing incidents over time.

313
00:38:59,200 --> 00:39:02,680
Okay. Well, the other classroom was very impressed when I saw that.

314
00:39:06,110 --> 00:39:13,580
So this is just another example of some results that you would see in a paper or technical report.

315
00:39:14,270 --> 00:39:21,620
This is for invasive thyroid cancer. And so they're looking at all races, white and black.

316
00:39:22,910 --> 00:39:27,230
I know for a long time those are the only races that have data.

317
00:39:27,500 --> 00:39:35,600
More recently, they have started being much better about including data for Hispanic and Asian cancer patients.

318
00:39:36,620 --> 00:39:43,430
But those data starting like the mid 2000 I think um, maybe 2000.

319
00:39:44,000 --> 00:39:48,770
Okay. So you can see that we have that different joined point trends.

320
00:39:49,010 --> 00:39:54,770
It's a little bit awkward, but you can see that the different joint trends are different for each of the different groups.

321
00:39:55,670 --> 00:40:01,129
We can also guess that probably the white cancer patients are probably driving the

322
00:40:01,130 --> 00:40:06,410
overall all races because you see sort of a similarities in the joint points.

323
00:40:08,210 --> 00:40:17,180
And we have the annual percentage change which tells us the slope on the log scale for those periods.

324
00:40:18,020 --> 00:40:20,660
So you have these each join point trend information.

325
00:40:21,080 --> 00:40:30,680
It's just a table value of each of the information that's plotted here, the annual percentage changes and the points that your endpoint periods.

326
00:40:32,390 --> 00:40:37,130
One thing I did not mention here is that the stars represent statistical significance.

327
00:40:38,360 --> 00:40:44,930
And here's this for significance means non-zero. So zero would be a flat trend.

328
00:40:45,560 --> 00:40:50,480
This is very close to zero and you can notice that it is not the 0.2.

329
00:40:55,200 --> 00:41:07,170
Okay. And then because they lost their average annual percent changes, we have annual percent changes from 2006, 2010 and 2011 to 2015.

330
00:41:08,130 --> 00:41:17,880
I put on my hand, I'm not sure why they chose these sort of odd pieces, but maybe this is supposed to be 2000, 68,011.

331
00:41:17,880 --> 00:41:21,630
That would make more sense, but I'm not sure.

332
00:41:22,920 --> 00:41:26,760
Been in the event for a few years before.

333
00:41:27,720 --> 00:41:31,960
Yes. Would you be able to. Compare them.

334
00:41:33,400 --> 00:41:36,430
That's why. That's why we're doing this. Right. So.

335
00:41:37,450 --> 00:41:53,050
So it's awkward to try to be like, okay, well, white patients had average annual or had an annual percentage rate of 7.5% per year from 1975 to 77,

336
00:41:53,440 --> 00:42:01,750
whereas black cancer patients had that the annual percent change of 0.8% per year, 1975 to 1995.

337
00:42:02,070 --> 00:42:07,390
Like that's a super awkward thing to have on a table, right? Like it's you can't compare them in any meaningful way.

338
00:42:08,500 --> 00:42:20,380
And so you probably want to be thinking about on any given period what is the annual percent change, at least in the average over that period?

339
00:42:21,310 --> 00:42:29,740
And so that's just saying, like, okay, this weird thing happened here for men and didn't really happen for women.

340
00:42:30,250 --> 00:42:34,450
But we still kind of want to know where we were in 2000 versus 25.

341
00:42:35,080 --> 00:42:43,360
And so we would do that for both of them. And so really, for men, you're just kind of like, okay, well, it actually looks like this over that period.

342
00:42:46,480 --> 00:42:56,680
Okay. So on the one hand, you could probably do a lot of this by hand and are maybe not the kind of best Fed stuff,

343
00:42:57,370 --> 00:43:07,840
but I'm going to make a suffer through working with talking points, mostly because it's the standard software for doing this work.

344
00:43:08,980 --> 00:43:14,110
This is I checked it in the computer lab. It is available and it does appear to be working.

345
00:43:16,150 --> 00:43:25,000
To start you load information from the you download from series that if we go back to the lecture from last time,

346
00:43:25,300 --> 00:43:30,940
there were instructions on how to download your data for a joint session.

347
00:43:31,030 --> 00:43:37,600
So we'll revisit that connection of stuff that back in this lecture as well.

348
00:43:38,440 --> 00:43:46,059
Okay. Again, we're going to kind of go through the data and go through the overview and but again,

349
00:43:46,060 --> 00:43:50,770
sort of working with it in person is sort of can be the best.

350
00:43:51,100 --> 00:43:56,799
I think what we'll probably do is that I will just make some data available to for

351
00:43:56,800 --> 00:44:00,310
you to play with on Monday if you haven't had a chance to download your own data.

352
00:44:01,660 --> 00:44:08,620
Okay. So how does this work? So you're going to start with an input file that's just going to confirm the data and the variables.

353
00:44:08,950 --> 00:44:13,330
So in the data that I've imported here, I have race sex.

354
00:44:13,900 --> 00:44:15,160
This is for head and neck cancer.

355
00:44:15,160 --> 00:44:27,399
So I have had an x sub site, my year of diagnosis without the mean or without the interval, the age adjusted rates, the count of the population.

356
00:44:27,400 --> 00:44:38,310
So that's all the data that came from Seierstad. Not too much else that I really need to point out here.

357
00:44:38,550 --> 00:44:43,110
This is telling us what our independent variable as my year of diagnosis of that range.

358
00:44:44,730 --> 00:44:55,500
Here are the variables by which I'm going to be separating my, my, my data so I can maybe I can do it for both at the same time,

359
00:44:55,500 --> 00:44:58,469
and I can do it for me and I can do it for women and same for race.

360
00:44:58,470 --> 00:45:07,140
And for that sub sites and these other tabs, we can do things like set the minimum, maximum or joint points in the model selection method.

361
00:45:07,140 --> 00:45:11,010
So that's the permutation test versus the information criterion.

362
00:45:11,760 --> 00:45:14,280
And there's sort of other options that we're not going to get into.

363
00:45:14,280 --> 00:45:23,910
But that's if you sort of dove into this, you'll also notice that you have the choice of doing the linear model or the law model.

364
00:45:24,970 --> 00:45:32,370
Generally speaking, you want to pick one linear unless you have zeros in your data, meaning you have not very incident cancer.

365
00:45:33,570 --> 00:45:37,380
Because of course we cannot transform lot, transform zeros.

366
00:45:39,270 --> 00:45:43,770
Okay. Um, this is kind of useful.

367
00:45:44,670 --> 00:45:51,600
The exclude, uh, point, because these kind of take a long time to run.

368
00:45:52,110 --> 00:46:02,220
It's nice to be like, okay, well, the data had other race in it, but other race was just a small it's fairly it's not really interpretable.

369
00:46:03,030 --> 00:46:08,970
It's a mishmash of Asian and Native American, maybe Hispanic depending.

370
00:46:09,330 --> 00:46:13,170
Could be other things. It's not very interpretable. So what does it even mean to have a joint?

371
00:46:13,320 --> 00:46:23,250
Oh, let's just not include it in our models. And, um, maybe if the way you define your cancer, there's, like, substantive sites you don't include.

372
00:46:24,030 --> 00:46:29,220
So that's again, we're going to hit our lightning bolt execute.

373
00:46:29,610 --> 00:46:37,740
You can tell that this was designed by the same people that is that generally recommend not doing more than five joint points.

374
00:46:38,190 --> 00:46:47,030
Um, unless when you run it it already selects five and it looks like maybe anymore.

375
00:46:48,090 --> 00:46:55,380
It takes a really long time to do more than five, even five. Um, often you may get some errors.

376
00:46:56,160 --> 00:47:00,480
Um, that kind of need to be dealt with on a case by case basis.

377
00:47:00,810 --> 00:47:04,020
So you might get zeroed in on a cohort that's not an interest.

378
00:47:04,350 --> 00:47:14,850
So it might be like, okay, I have HPV related cancer and black women, and you might be like, okay, there's a lot of zeros.

379
00:47:14,860 --> 00:47:18,990
Do I care about the joint point on that specific group of people?

380
00:47:19,410 --> 00:47:22,800
Or do I want to sort of zoom out a little bit on my worries?

381
00:47:23,340 --> 00:47:26,850
So you might want to exclude certain groups.

382
00:47:27,720 --> 00:47:31,500
Um, or you have these zeros, but you really do care.

383
00:47:31,680 --> 00:47:36,600
You just, if you're interested, your cancer incidence isn't very high. So that's where you don't wanna transform.

384
00:47:40,150 --> 00:47:44,290
Okay. So then it's going to start running all these models.

385
00:47:46,480 --> 00:47:51,310
Generally speaking, I like to select.

386
00:47:51,700 --> 00:48:00,399
I think this is where I do exclude, if I recall correctly, and you're going to pick which variables to include.

387
00:48:00,400 --> 00:48:07,450
So you can see here. Um, I just picked white black and exclude and exclude other an unknown.

388
00:48:08,170 --> 00:48:13,570
I didn't do male and female together and I just picked one of my subsets that way.

389
00:48:14,050 --> 00:48:18,970
The cohorts I have are just white males and HPV related black males.

390
00:48:18,970 --> 00:48:22,060
Asian related white females. Issue related black people. Thank you for.

391
00:48:23,080 --> 00:48:27,850
It's kind of nice to do this, at least for the first step, just because it kind of takes a while and you want to get a hang of it.

392
00:48:28,210 --> 00:48:33,120
And so it's gonna start processing all these join point models on all of the different cohorts.

393
00:48:33,340 --> 00:48:38,170
And if you kind of take a little bit of a while to run, as you will find out.

394
00:48:40,420 --> 00:48:44,710
So but once it does run, it's going to spit all of these out here.

395
00:48:45,560 --> 00:48:54,730
Four of them have possibles are being excluded. But here for men and HPV related cancer, I think this is under white men.

396
00:48:55,330 --> 00:48:58,390
It's it checked all the different joint points and it says it likes to jump.

397
00:49:00,260 --> 00:49:04,760
And those dream points are here in 1995 and here in 2015.

398
00:49:07,480 --> 00:49:12,970
I can see that the annual percent change was point 76.

399
00:49:13,090 --> 00:49:16,540
Fairly small, but still significantly different than zero.

400
00:49:17,200 --> 00:49:23,140
So it's not flat in this first time range of 1975 to 1994 for 1995.

401
00:49:23,560 --> 00:49:27,820
Then it increases much faster at 4.24% per year.

402
00:49:28,180 --> 00:49:32,110
Again significant and then decreases at about 2%.

403
00:49:32,110 --> 00:49:36,790
But this 2% is not significant, probably just because it's a very short time period.

404
00:49:37,360 --> 00:49:43,100
Because it doesn't look like it's. Can be fairly significant.

405
00:49:45,160 --> 00:49:48,760
Okay. So that was that's the graph portion.

406
00:49:49,080 --> 00:49:57,400
If I look at the model estimates, this is a good place to go and just sort of see how things are happening.

407
00:49:57,760 --> 00:50:05,800
Let's say, for example, you want to plot your models on a nicer visualization and they have enjoyed point.

408
00:50:06,190 --> 00:50:10,120
Well, that's nice because now they have the two different parameter positions.

409
00:50:10,900 --> 00:50:18,760
This is the sort of general parameterization where you have just the the different segments that

410
00:50:18,760 --> 00:50:25,300
the intercepts and slopes or we can do the standard joint plan where we have the intercept,

411
00:50:25,600 --> 00:50:30,730
the slope and then those two deltas, the difference in slopes that get added over time,

412
00:50:31,870 --> 00:50:38,980
um, it's giving you the, the p values for everything that you need.

413
00:50:40,240 --> 00:50:48,010
So that information is there and this is where you're in information about the trends.

414
00:50:48,520 --> 00:51:00,010
So this is where you can say, here's my annual percent changes in the confidence intervals for those annual percent changes and the p values.

415
00:51:01,060 --> 00:51:05,260
So we could, we said, oh, that -1.9 wasn't statistically significant.

416
00:51:05,770 --> 00:51:09,009
What was the p value for that in case we need to report it here?

417
00:51:09,010 --> 00:51:22,340
2.51. Um. The average annual percent change over the full end point was 2.1% per year.

418
00:51:23,330 --> 00:51:31,600
I think in the lab, I'm going to ask you to calculate a couple by hand, but this at least tells you the overall.

419
00:51:35,580 --> 00:51:38,820
Then we might say, Well, how did we know it was to join points?

420
00:51:40,200 --> 00:51:46,530
This is where you can just double check that around 4500 permutations in that time for each of these.

421
00:51:47,850 --> 00:51:51,930
And I think probably if I move to the right, I'll see all the better.

422
00:51:52,290 --> 00:51:57,030
But it test is it's each test. It tells you what you want to like better.

423
00:51:57,900 --> 00:52:01,290
And it ended up with two joint points.

424
00:52:02,340 --> 00:52:13,209
So. I'm not really sure this order exactly, but it started with no none and tried five or five was better.

425
00:52:13,210 --> 00:52:19,090
So I moved up in the the hypothesis and so that it tried five.

426
00:52:19,960 --> 00:52:26,710
Well it still works once and I was going to try against for it still likes want to try three still likes one it's going to try to it likes to better.

427
00:52:29,880 --> 00:52:32,280
But as you can imagine, this takes a little bit of time to do.

428
00:52:33,210 --> 00:52:40,020
So now I ran my joint points for these four categories and we can see how different they are, right?

429
00:52:40,410 --> 00:52:46,710
They all look pretty different, despite the fact that they're all the same set of cancers,

430
00:52:47,070 --> 00:52:50,850
head and neck, cancer, HPV related sites, mostly in the oropharynx.

431
00:52:51,840 --> 00:52:56,490
And depending on here we have white male, black male, white female, black female.

432
00:52:58,080 --> 00:52:59,489
There's very different trends.

433
00:52:59,490 --> 00:53:10,350
And so if we had not looked at this sort of very specific intersection of race and sex or just like what's going on with HIV related cancers,

434
00:53:10,770 --> 00:53:16,350
well, we probably would then like, oh, they're going up, but really they're only going up for white men.

435
00:53:17,400 --> 00:53:23,850
You know, they're coming back up for white women, but for black men and black women have been decreasing over time.

436
00:53:24,330 --> 00:53:29,550
Um, also keep an eye on the scales here because they are different and we should be careful about that.

437
00:53:30,500 --> 00:53:43,410
Um, so I don't have any like one of the perhaps like slightly unsatisfying things about, um, cancer incidence data in general.

438
00:53:43,620 --> 00:53:47,880
Is that like, um, like, here are the trends. Cool.

439
00:53:48,090 --> 00:53:50,700
You know, like, what is it? What does any of it mean?

440
00:53:51,030 --> 00:54:00,719
Well, it's not it's not always easy to sort of point to be like, oh, yes, the epidemiology of HPV among like black women has been doing this.

441
00:54:00,720 --> 00:54:01,860
Therefore, this makes sense.

442
00:54:02,430 --> 00:54:09,390
So oftentimes we're just trying we're just kind of being descriptive and saying, like, this is what we're observing in the data.

443
00:54:10,080 --> 00:54:17,220
And how do you describe that nicely and in a way that that people can understand,

444
00:54:17,670 --> 00:54:26,879
as opposed to just like having like lots and lots of plots, lots of tables of things.

445
00:54:26,880 --> 00:54:30,750
So part of in addition to sort of learning the methods.

446
00:54:31,260 --> 00:54:34,480
My goal for you in this class is to learn some of the communication.

447
00:54:34,500 --> 00:54:37,500
So how do you do the summarizing of this work?

448
00:54:39,850 --> 00:54:48,250
Okay. So that is if you go ahead for today, any questions?

449
00:54:49,080 --> 00:54:56,410
My question is, yeah. So since you're like doing your test, you're doing like this iterative process testing.

450
00:54:56,770 --> 00:55:01,030
Yeah, permutation testing. Do you need a correction for like multiple testing?

451
00:55:01,960 --> 00:55:12,800
Kind of interesting. It's a good question.

452
00:55:13,480 --> 00:55:22,970
Here is the question. Since you're like doing so many like an iterative testing process to get the to determine the amount of

453
00:55:23,360 --> 00:55:30,140
joint points you want to use and statistics when you do like if you test something a bunch of times,

454
00:55:31,070 --> 00:55:36,200
you're just going to you're going to get it. Even if it's not significant, you're going and actually get a significant result.

455
00:55:37,340 --> 00:55:43,350
And I don't know if you heard this before, but there's something called like a functioning correction for like let's use

456
00:55:43,350 --> 00:55:46,610
similar scenarios when you do a bunch of comparisons or a bunch of tests.

457
00:55:47,240 --> 00:55:51,500
So just wondering something we go through over here. Yeah, so often.

458
00:55:51,500 --> 00:56:01,100
So like let's say that we're trying to understand the associations of head and neck cancer with a slew of risk factors.

459
00:56:01,580 --> 00:56:11,780
And we say like, I'm going to run my like odds ratio test, logistic regression against each of these risk factors.

460
00:56:12,290 --> 00:56:23,239
And in many cases in epidemiology, we wouldn't do a multiple testing just because this tends to be more of a hypothesis generating.

461
00:56:23,240 --> 00:56:27,950
And then I thought this is testing approach, but that's a little bit of an aside.

462
00:56:28,880 --> 00:56:36,860
But all we would say is that since I'm trying all of these different risk factors just by chance,

463
00:56:37,490 --> 00:56:41,660
so there is going to be a statistical significant association.

464
00:56:42,560 --> 00:56:48,590
And I want to be careful that I'm not saying like a ha P-value less than 0.05.

465
00:56:48,800 --> 00:56:56,040
That means that this is like causally related to the outcome that we really want to avoid that.

466
00:56:56,040 --> 00:57:05,360
And so correction like the Bonferroni correction says like, okay, you've done 50 tests your P values 0.05 anymore.

467
00:57:05,570 --> 00:57:11,360
It's whatever it is 0.01 so that we have a stricter.

468
00:57:14,760 --> 00:57:20,700
Like threshold for what we consider a service association.

469
00:57:22,290 --> 00:57:33,930
Okay. So now the question is, is this a similar situation where I need to worry about, um, uh, this sort of thing I'm going to.

470
00:57:34,350 --> 00:57:42,030
Without having deeply thought about this, I'm going to say no. And the reason is that all of those tests were concerned about multiple testing.

471
00:57:42,270 --> 00:57:46,470
Those are all independent. And you're testing different models.

472
00:57:47,160 --> 00:57:52,240
These are like nested or not.

473
00:57:53,010 --> 00:57:56,490
And even when they're not nested, they're related in in a way.

474
00:57:58,560 --> 00:58:13,920
So what would it even mean to to to possible testing or to put in could have put a, um, correction on that.

475
00:58:14,220 --> 00:58:24,030
What would happen is that it would the order in which you test them is going to matter is one potential problem.

476
00:58:25,410 --> 00:58:32,790
Although that's probably true already. Um, but I guess I just like from,

477
00:58:32,790 --> 00:58:48,900
from the perspective of we do have a correction for multiple testing to avoid incorrect or being too sure of our outcomes.

478
00:58:49,290 --> 00:58:58,920
It doesn't feel like it applies in this situation to me because it's not a matter of saying, okay, is it one joint point that is,

479
00:58:59,160 --> 00:59:06,150
you know, the two different points associated and it's no, it's which of these options is the best fitting one.

480
00:59:06,630 --> 00:59:11,460
And so from that perspective, you know, the goal is to really describe the data.

481
00:59:12,180 --> 00:59:18,810
And I think that yeah, I don't think we need multiple testing.

482
00:59:19,260 --> 00:59:24,030
That's a good question because that's something we should have in the back of our minds.

483
00:59:24,510 --> 00:59:31,410
Um, but I don't think it applies here. Um, so just to clarify, with the drawing points, we use it when we,

484
00:59:31,470 --> 00:59:37,460
we use it for modeling things where there's drastic change in trend is what you say.

485
00:59:38,240 --> 00:59:43,500
So. So they don't have models can be used for any longitudinal.

486
00:59:44,190 --> 00:59:50,430
Mm hmm. Um, joint points. We find joint points where you see changes in trend.

487
00:59:50,550 --> 00:59:59,790
Okay. Or, like, the goal is to decide where the trend changes happen by using data on the data itself.

488
01:00:00,390 --> 01:00:06,750
And so, um, cannot be used. Like I'm a little confused about because it just seems like the comments make

489
01:00:06,750 --> 01:00:10,260
it seem like a very drastic change in transient is like a new trend each time.

490
01:00:10,260 --> 01:00:18,059
So it cannot be useful for like predictive modeling or because how could like the previous check like

491
01:00:18,060 --> 01:00:22,440
trends like these like little chunk be useful when like how would we predict like another change,

492
01:00:22,440 --> 01:00:31,860
I guess. Right. So, um, we talked a little bit about this earlier with this question so we can imagine,

493
01:00:31,860 --> 01:00:36,780
like let's do a short term forecasting with each of these pieces.

494
01:00:37,320 --> 01:00:44,880
Um, these two are probably fairly straightforward and, you know, I will probably believe that it will continue to go along this line.

495
01:00:45,510 --> 01:00:57,120
But for right now, you know, like what, what, like what over which point do y is the interval that appropriate for doing my forecasting?

496
01:00:57,420 --> 01:01:02,970
It's if I did like this interval, the average annual percent change is still probably going to be, like, going up.

497
01:01:03,090 --> 01:01:12,330
Mm hmm. So the fact that we have this little downward trend, it probably does matter to have included the join point there for future prediction.

498
01:01:13,200 --> 01:01:18,900
Is it commonly used for future predictions or not? I would say that, um.

499
01:01:21,900 --> 01:01:27,060
I would say that this tends to be more of a descriptive methodology.

500
01:01:27,510 --> 01:01:34,049
I'm not going to say that it's not used for forecasting because I certainly think it's appropriate to say,

501
01:01:34,050 --> 01:01:38,670
like based on these models and this is actually I'm like, I should have put this in the lab.

502
01:01:38,910 --> 01:01:43,470
But based on these models, what will cancer incidence be in five years from now?

503
01:01:44,730 --> 01:01:52,139
Because that is so I'm talking myself into saying like, yes, that's a useful methodology,

504
01:01:52,140 --> 01:01:57,000
but it's not as much of like creating a predictive model that gets more or less descriptive statistics.

505
01:01:57,030 --> 01:02:02,370
Yes. And my last question is, just so there's a joint point software that we use.

506
01:02:02,460 --> 01:02:07,290
You mentioned something about being able to do it, like some of it and our other way to do this.

507
01:02:07,290 --> 01:02:10,350
And are you really do the software in order to execute it?

508
01:02:10,770 --> 01:02:20,130
Good question. I have not done my doctor my homework to know if there's an R package that will do this.

509
01:02:22,080 --> 01:02:33,809
I suspect not at the moment. So you're maybe you're checking right now so our can certainly run a general linear regression.

510
01:02:33,810 --> 01:02:40,350
And the tricky part is the permutation testing.

511
01:02:41,310 --> 01:02:51,390
I don't think that as far as I know, that there's not an R package that lets you do that, which is why we have the Joint Plan software.

512
01:02:53,990 --> 01:03:01,730
If I would. What I think is that like, say, like intermediate to advanced coder can probably put something together.

513
01:03:03,740 --> 01:03:13,580
But we're going to look at it, we're gonna use it to our point software in case any of you end up at NCI or Kaiser Permanente or whatever group.

514
01:03:13,580 --> 01:03:16,850
And they want to use troponin because it's standard software,

515
01:03:17,990 --> 01:03:25,160
because I think what you'll find is that a lot of analysts are trained to use the software rather than the method.

516
01:03:25,610 --> 01:03:32,030
Yeah. And so I think it's useful to know what the method is doing, but also be able to use the software that everyone uses.

517
01:03:32,780 --> 01:03:42,020
So that's kind of where I'm at right now. I'll be honest that like joint plans is not something that I find, like I use on a daily basis myself.

518
01:03:43,340 --> 01:03:49,190
But I think it's important to have because that it is used, you know,

519
01:03:50,090 --> 01:03:55,990
can you think of like another disease that it's, you know, commonly used in other cancer types of cancers?

520
01:03:56,810 --> 01:04:00,590
I, like I would say, any chronic disease. Okay. You'll see.

521
01:04:01,100 --> 01:04:06,680
Infectious disease. I doubt it. Um, unless it's something.

522
01:04:10,060 --> 01:04:13,389
Yeah. I doubt you see too much of this.

523
01:04:13,390 --> 01:04:25,990
An infectious disease, just cause it's much more at the transmission perspective kind of overrides the sense of of like, trends over time.

524
01:04:26,260 --> 01:04:28,690
This is sort of useful because it's a very independent perspective, right?

525
01:04:29,350 --> 01:04:34,060
Like every person that gets cancer is is not like infecting other people to getting cancer.

526
01:04:34,450 --> 01:04:48,810
So trends are trends more about behavior, lifestyle and like exposures as they become sort of more prevalent society.

527
01:04:48,820 --> 01:04:53,320
So different kinds of chemicals being used after 1980, you know, that kind of thing.

528
01:04:53,890 --> 01:04:59,710
I would definitely expect to see it for things like heart disease, for things like diabetes,

529
01:05:00,030 --> 01:05:10,599
that sort of I could even imagine it for like, uh, things like stroke falls, opioid deaths, all of these things.

530
01:05:10,600 --> 01:05:13,420
There's no reason you can use joint pain.

531
01:05:13,810 --> 01:05:21,580
I don't necessarily see that, um, in all those fields, although I'm not going to pretend that I read the literature for everything.

532
01:05:22,000 --> 01:05:30,209
Um, constantly. But. Um, this is, I think this is maybe one of these opportunities where you like,

533
01:05:30,210 --> 01:05:38,280
you get a job in something that's not cancer and you're like, Hey, I have this skill set that you are using but could be transferable.

534
01:05:38,310 --> 01:05:42,150
So this is one of the things about this class that I think is very transferable.

535
01:05:42,710 --> 01:05:49,250
Yeah, I'm sorry. I just have a lot of questions. But just like another thing of joint points, because, like, you have, like,

536
01:05:49,260 --> 01:05:52,589
these different trends and it's easier to do this in cancer just because of

537
01:05:52,590 --> 01:05:56,309
stuff like something could occur that could affect like society as a whole,

538
01:05:56,310 --> 01:05:59,760
that could change like that. Like our brain like or asymmetry.

539
01:06:00,150 --> 01:06:14,220
Yeah. So it's. It's interesting. Um, so, so again, the join point is giving us a bit of a false sense of security around this idea of trend change,

540
01:06:14,700 --> 01:06:22,080
because really it's a continuous change that's sort of decelerating, accelerating over time.

541
01:06:22,980 --> 01:06:26,850
Um, but people like linear things. They like to be able to draw lines on things.

542
01:06:26,850 --> 01:06:33,810
And so it's very nice to be able to be like, okay, here's the point. Whereas this is like really hard, like a smooth cup shape, right?

543
01:06:34,890 --> 01:06:38,610
It's just hard to describe that succinctly, quantitatively.

544
01:06:39,600 --> 01:06:41,819
And then from a cancers perspective, we might say, like, okay,

545
01:06:41,820 --> 01:06:55,050
what is going on that is impacting head and neck cancer rates for white females in some sort of event might be occurring that cause that change.

546
01:06:55,140 --> 01:06:59,430
Yeah I'm not sure like me that's maybe not the right word there.

547
01:06:59,430 --> 01:07:05,310
But you would say like this is what's happening in smoking, this is what's happening in HPV prevalence.

548
01:07:05,940 --> 01:07:12,570
And like, this is what's happening. And like Epstein-Barr virus, let's say, maybe that's related.

549
01:07:13,230 --> 01:07:25,620
And so we we might say that like these underlying trends at the population level, um, and,

550
01:07:25,620 --> 01:07:32,790
and also like keeping in mind, um, which population, the fact that cohorts are changing.

551
01:07:33,270 --> 01:07:38,420
So it's not necessarily that something is happening in whatever this is 1995,

552
01:07:39,240 --> 01:07:46,110
something could have happened back in 1950 such that that people were exposed then are the ones that are getting cancer now.

553
01:07:47,550 --> 01:07:53,580
And that's one of the tricky things about cancer that we're going to get into later in the semester,

554
01:07:53,850 --> 01:07:59,460
where we really take into account these time differences that are important.

555
01:08:00,600 --> 01:08:06,690
And this concept of age and cohort and calendar year is actually the subject of the next lecture,

556
01:08:07,110 --> 01:08:13,940
which I think we'll do not next week, but the week after, all these years before cancer.

557
01:08:16,520 --> 01:08:24,800
You know, I'm not sure what they did. They probably did some of this by hand and were just like, good enough.

558
01:08:25,350 --> 01:08:29,830
Like, I slapped a linear regression on this because it looked to me like, this is the point.

559
01:08:30,630 --> 01:08:36,830
Um, so, but this idea of the permutation test was around the year 2000.

560
01:08:36,980 --> 01:08:43,390
So we've had it for 20 years. Um, how long is driving around for people coming?

561
01:08:46,670 --> 01:08:58,830
Doesn't say. Someday I'll have like nice packages in order to do this, but for now, to no questions.

562
01:09:02,360 --> 01:09:05,749
No, it's not. Still about 10 minutes left.

563
01:09:05,750 --> 01:09:10,370
So happy to entertain questions about the labs.

564
01:09:12,410 --> 01:09:16,460
How are people doing on your access? Does anyone still waiting on your access?

565
01:09:20,770 --> 01:09:26,620
Okay. Then we will meet in the lab again next Monday.

566
01:09:26,740 --> 01:09:30,820
3615. Hopefully we'll have it figured out.

567
01:09:31,090 --> 01:09:36,130
So your staff are done. If not, we'll work on a joint point with some big data.

568
01:09:38,310 --> 01:09:38,540
But.

