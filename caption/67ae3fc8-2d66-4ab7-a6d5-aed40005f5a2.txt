1
00:00:07,230 --> 00:00:07,740
Michael Akira Lee Hayashi: i'm.

2
00:00:11,280 --> 00:00:21,060
Michael Akira Lee Hayashi: Talking a bit about Markov models in particular discrete time Markov models so i'm just going to very quickly jump to my final slide out of that deck because.

3
00:00:22,170 --> 00:00:30,780
Michael Akira Lee Hayashi: we've seen some of the structural foundation of the market model and we've talked a little bit about potential application so a couple others that i'm going to note are so.

4
00:00:31,710 --> 00:00:38,610
Michael Akira Lee Hayashi: Marco models are generally pretty good for doing things like generating a simulated cohort, especially in cases where you're.

5
00:00:39,660 --> 00:00:41,520
Michael Akira Lee Hayashi: you're modeling some phenomenon that.

6
00:00:42,690 --> 00:00:51,090
Michael Akira Lee Hayashi: Either that has kind of a discrete signal of whether it happens or not so smoking stage or disease status forgiven diseases things like that.

7
00:00:52,830 --> 00:01:01,440
Michael Akira Lee Hayashi: they've also been used for things like movement models so so migration things like that there's their models broadly are fairly flexible because.

8
00:01:02,100 --> 00:01:18,150
Michael Akira Lee Hayashi: What you define as a state is largely open to whatever you can well it's largely open to interpretation, because a state in the mark of model is just some discreet thing so whether that's a number of people or a particular.

9
00:01:19,170 --> 00:01:25,650
Michael Akira Lee Hayashi: Health state that a person's occupying both of those are perfectly acceptable within the market model framework it's just a question of.

10
00:01:26,040 --> 00:01:35,370
Michael Akira Lee Hayashi: Can you define a sensible structure for transitions between states and that system, however you've chosen to define the States, so it might be that if your system.

11
00:01:35,760 --> 00:01:49,710
Michael Akira Lee Hayashi: is defined in terms of numbers of people in a transition in that system is going to be, how do you move a person from one state to another, ie, how do you detriment one states population by one and increment another one by one.

12
00:01:51,600 --> 00:02:03,000
Michael Akira Lee Hayashi: Things like market predictions and other case where you can use Markov model will look up look go down things like that one of the kind of otter more interesting cases for market model is google's pagerank algorithm.

13
00:02:04,470 --> 00:02:15,390
Michael Akira Lee Hayashi: This is, this is actually the secret sauce that makes Google Google, this was this was the thing that that google's founders developed really to kick start the search engine and.

14
00:02:15,750 --> 00:02:30,990
Michael Akira Lee Hayashi: More or less this thing acts by treating the Internet as a Jason see matrix of a network and then trying to calculate the value of a the relevance of a site, based on the number of links to and from that site and so.

15
00:02:31,830 --> 00:02:36,960
Michael Akira Lee Hayashi: At the end of the day when Google is indexing search results it's really got.

16
00:02:37,320 --> 00:02:48,690
Michael Akira Lee Hayashi: Enormous server farms just crunching on matrix multiplication in order to solve their pagerank algorithm, and this is, this is a lot of both why Google is a search engine outperforms.

17
00:02:49,140 --> 00:03:03,030
Michael Akira Lee Hayashi: Its competitors in the early 2000s, and why search and google's activities are so compute intensive because, as we saw things like matrix multiplication they're fairly big operations and.

18
00:03:03,420 --> 00:03:18,810
Michael Akira Lee Hayashi: If you're doing that, on the scale of the Internet, even with even with massive supercomputers and a high degree of personalization, this is a big task and so it's it's kind of a clever application of some of this theory to recognize that you can think about.

19
00:03:20,340 --> 00:03:30,060
Michael Akira Lee Hayashi: You can think about the structure of web pages as a sort of dynamical system, and that means that it opens itself up to certain kinds of analysis that maybe wouldn't have been.

20
00:03:31,440 --> 00:03:47,730
Michael Akira Lee Hayashi: wouldn't have been recognized before that we'll talk more about like a smoking history generator and a bit before we move on and before we get to a little bit of coding I did want to spend a little bit of time talking about differences between statistical modeling and systems model.

21
00:03:49,350 --> 00:04:00,870
Michael Akira Lee Hayashi: And I think I think one of the ways that is probably most helpful to frame, it is really the difference between a mechanistic model and a non mechanistic model or phenomenal logical model is often called them so.

22
00:04:01,710 --> 00:04:15,930
Michael Akira Lee Hayashi: In complex systems in general, and when we when we do systems modeling usually are exercises to try and make a mess a mechanistic model of whatever system, we want to represent whether birds or traffic or disease transmission or anything really.

23
00:04:16,560 --> 00:04:24,300
Michael Akira Lee Hayashi: What that means is that what we care about the things that we're interested in operationalize and translating into math or computer logic are.

24
00:04:26,400 --> 00:04:35,130
Michael Akira Lee Hayashi: The the phenomenon that cause something to happen so one thing that's kind of worth keeping in mind about mechanistic models is that in some sense they're intrinsically causal.

25
00:04:35,490 --> 00:04:44,340
Michael Akira Lee Hayashi: If I design and si our model of disease transmission, then, if someone becomes infected by contact with another person well that.

26
00:04:44,970 --> 00:04:54,030
Michael Akira Lee Hayashi: That index case caused the transmission that there's no there's no doubt about where the cause happened in the same way that if we were to make.

27
00:04:54,510 --> 00:05:04,200
Michael Akira Lee Hayashi: A smoking history model, for example, and we code in logic to represent taxation policies or or advertising bands of product fans.

28
00:05:04,950 --> 00:05:15,540
Michael Akira Lee Hayashi: Well, when we see changes in smoking behavior population wide from our model from those simulations those changes are directly attributable in a causal way.

29
00:05:15,990 --> 00:05:23,310
Michael Akira Lee Hayashi: To the things that we programmed in that made either the smoking rate or the cessation rate or whatever go up or down it's not.

30
00:05:23,820 --> 00:05:35,220
Michael Akira Lee Hayashi: Quite the same in a statistical model where our exercise is to form associations between variables, so, as I mentioned before the break really the goal of a statistical model is you've got some data.

31
00:05:36,570 --> 00:05:44,670
Michael Akira Lee Hayashi: And you just want to make a mathematical function that does a good job of looking like that data, this is, this is really simple and in like a simple linear case but.

32
00:05:45,450 --> 00:05:50,820
Michael Akira Lee Hayashi: Exactly the same logic applies if you're looking at a really complex statistical model there's not.

33
00:05:51,270 --> 00:06:02,610
Michael Akira Lee Hayashi: there's not really any other magic under the hood there everything that goes into a statistical model, all of the variable transformations or all of the extra structure, like a like a mixed model or something like that.

34
00:06:03,120 --> 00:06:24,270
Michael Akira Lee Hayashi: All of that is really there to make sure that the predictive equation for the outcome of that of that data fits reasonably well none of it is intrinsically designed to tell you whether the covariance that you put in caused the outcome, and this is somewhat by design because well.

35
00:06:27,480 --> 00:06:38,370
Michael Akira Lee Hayashi: there's not you don't necessarily know going into a data analysis, whether whether here covariance are likely to cause the outcome, so you have to rely on a bunch of heuristics.

36
00:06:38,670 --> 00:06:53,160
Michael Akira Lee Hayashi: To try to get a feel for if I see a strong association between between variable and outcome is that likely to be causal, this is the whole point of all of the Dag junk and all of that stuff that epidemiologist love prejudice I shouldn't.

37
00:06:54,240 --> 00:06:56,400
Michael Akira Lee Hayashi: I shouldn't say that on the record, but there we go i've done it.

38
00:06:58,080 --> 00:07:03,660
Michael Akira Lee Hayashi: But the the point of all of that, and the point of designing statistical models around dogs and things like that.

39
00:07:04,110 --> 00:07:17,610
Michael Akira Lee Hayashi: is to try to make your life, a little bit easier when you're going to make causal inference out of your statistical analysis right, because if I throw a bunch of covariance into a statistical model, one way or another it's going to give me a good fit one of the.

40
00:07:18,300 --> 00:07:25,860
Michael Akira Lee Hayashi: One of the funny things about fitting models to data of any kind is really the the game that you're playing.

41
00:07:26,280 --> 00:07:38,490
Michael Akira Lee Hayashi: is just a game of degrees of freedom, so if you have enough variables, then you can produce a model which will reproduce almost any behavior out there, laying including some really weird data behavior.

42
00:07:39,480 --> 00:07:44,520
Michael Akira Lee Hayashi: And the question always is both in statistical models and mechanistic models.

43
00:07:45,390 --> 00:07:55,260
Michael Akira Lee Hayashi: How do I know I have a reasonable model, how do I know I didn't just kind of brute force it and get a model that fits the data, because I threw everything in the kitchen sink into my model, this is this is in some ways.

44
00:07:55,980 --> 00:08:06,720
Michael Akira Lee Hayashi: A more obvious problem and statistical models, because if you throw every covert you've gotten your data set and you're almost certainly going to get something that gets a reasonable P value and that you know that fits the data pretty well because.

45
00:08:07,020 --> 00:08:17,760
Michael Akira Lee Hayashi: You don't need all that much to fit your data generally like your data is going to go up sometimes down sometimes up some other times down some other times and that's really the only behavior that you need to explain it.

46
00:08:18,840 --> 00:08:19,260
Michael Akira Lee Hayashi: So.

47
00:08:20,490 --> 00:08:30,720
Michael Akira Lee Hayashi: The major difference, then between a mechanistic model and and like a statistical model is really that a mechanistic model is directly in the business of building in.

48
00:08:31,110 --> 00:08:38,550
Michael Akira Lee Hayashi: hypotheses about causal mechanisms in that system, so if I if I think that.

49
00:08:39,390 --> 00:08:48,960
Michael Akira Lee Hayashi: A taxation policy should causally reduce smoking initiation by I don't know changing the pricing structure which interacts with.

50
00:08:49,260 --> 00:08:57,660
Michael Akira Lee Hayashi: With the user preferences over costs and things like that such that some people get priced out of the market, some people turn to other devices things like that, then.

51
00:08:58,230 --> 00:09:13,890
Michael Akira Lee Hayashi: All of that stuff has to get explicitly represented in the model, one way or another, and this means again that when I get a simulation trajectory out of the model that says, increasing the I don't know, increasing the excise tax by 5% leads to a.

52
00:09:14,910 --> 00:09:28,110
Michael Akira Lee Hayashi: I don't know a 10% decrease in smoking initiation over a 10 year time horizon that that relationship is caused where if I do that from a statistical model analyzing a corpus of data that has.

53
00:09:28,800 --> 00:09:35,280
Michael Akira Lee Hayashi: The tax rates across different countries and smoking prevalence across different countries, the best I can say is.

54
00:09:36,180 --> 00:09:51,270
Michael Akira Lee Hayashi: A increase in tax rates is associated with a decrease in smoking initiation but no matter how much work I do, I can never say that relationship is causal I can have fairly good confidence in it, I can I can be pretty certain that that so but.

55
00:09:52,170 --> 00:10:04,830
Michael Akira Lee Hayashi: The nature of statistical models means that a causal statement just isn't ever fully possible where a causal statement, out of a mechanistic model is the caveat, of course, is that.

56
00:10:05,760 --> 00:10:14,610
Michael Akira Lee Hayashi: To a certain extent you do build your answer into your model if I say that in my model i'm going to assume that increase in taxes by.

57
00:10:15,270 --> 00:10:26,700
Michael Akira Lee Hayashi: 5% creates a two and a half percent price pass through to the consumer, so the consumer pays two and a half percent more when they buy a cigarette and consumers have certain kinds of preferences over.

58
00:10:28,290 --> 00:10:36,750
Michael Akira Lee Hayashi: Over costs of goods and certain budgets and things like that, and that means that at the end of the day, X number of people get priced out of the market well.

59
00:10:37,800 --> 00:10:50,100
Michael Akira Lee Hayashi: I built that into my model essentially as assumptions and if those assumptions are wrong or questionable then even though my answer is causal to the mechanisms that built into the model it's still not right because.

60
00:10:50,550 --> 00:10:58,740
Michael Akira Lee Hayashi: I made wrong assumptions about my model, so another kind of difference in framing between statistical and mechanistic models is that.

61
00:10:59,730 --> 00:11:09,120
Michael Akira Lee Hayashi: Statistical models often are presented as though they make fewer assumptions about the way our system works and they're often described slightly more as sort of.

62
00:11:12,510 --> 00:11:16,410
Michael Akira Lee Hayashi: mechanism agnostic methods in some sense or or methods that.

63
00:11:17,100 --> 00:11:24,180
Michael Akira Lee Hayashi: That don't claim to make as many strong assumptions about mechanism, which is not entirely true in itself, because the inferences we take from them.

64
00:11:24,450 --> 00:11:29,850
Michael Akira Lee Hayashi: Are tend to be interpreted in causal ways because of our assumptions about mechanism.

65
00:11:30,150 --> 00:11:43,260
Michael Akira Lee Hayashi: it's just that they don't ever explicitly implement them, so when a statistical model includes covariance for race, age and sex, which are pretty common because those things changed basically every health outcome known to man, then.

66
00:11:45,060 --> 00:11:59,130
Michael Akira Lee Hayashi: they're not doing it necessarily because we know, or we have a good reason to believe why those things change the outcome so much as that we know that they do and that's sufficient for a statistical model, knowing that.

67
00:12:00,270 --> 00:12:10,110
Michael Akira Lee Hayashi: An exposure or a covariance impacts, the outcome and an upper down way from other literature isn't is good enough reason to put that thing in your statistical model.

68
00:12:10,470 --> 00:12:23,880
Michael Akira Lee Hayashi: Where if you were if you're doing the same thing in a mechanistic model, the first question, I would ask you, is why what does this do what does this change, and that is really the fundamental question behind building a mechanistic model.

69
00:12:24,810 --> 00:12:30,450
Michael Akira Lee Hayashi: We hope that we put the right things in our model that if we want to fit the model to data, later on, that it'll do a decent job of it.

70
00:12:30,720 --> 00:12:38,190
Michael Akira Lee Hayashi: But we don't necessarily build it explicitly with the goal of fitting the data in some sense, partly because one of the.

71
00:12:38,910 --> 00:12:51,210
Michael Akira Lee Hayashi: One of the functions of mechanistic modeling is essentially to test counterfactual situations to test manifestations, the world, as we did not see it in our in our real life experience and so kind of kind of.

72
00:12:51,660 --> 00:13:02,010
Michael Akira Lee Hayashi: trivial as a consequence, that means that our model may generate things that the real world never did and we it's incumbent on us, then, to interrogate.

73
00:13:03,570 --> 00:13:14,040
Michael Akira Lee Hayashi: Are these alternate worlds that we made in our model are they plausible ones are mechanisms plausible on the basis of existing literature and on the basis of of things that we think about.

74
00:13:14,760 --> 00:13:30,270
Michael Akira Lee Hayashi: causal pathways or is it that the ultimate worlds that we generate our artifacts have some oversimplification in our model or some poor choice of assumption in building the model, the other side of this, I think, is that.

75
00:13:32,400 --> 00:13:32,940
Michael Akira Lee Hayashi: Different.

76
00:13:34,020 --> 00:13:39,870
Michael Akira Lee Hayashi: Different domains will use the word model differently, like if you talk to a statistician and you say i'm going to model this thing.

77
00:13:40,860 --> 00:13:50,340
Michael Akira Lee Hayashi: What they will think of immediately is some form of regression model some form of fitting a line to the data through transformations and torture of the data in order to make it fit that line.

78
00:13:51,660 --> 00:13:51,960
Michael Akira Lee Hayashi: If.

79
00:13:53,490 --> 00:13:58,950
Michael Akira Lee Hayashi: If you take nothing else away, let it be this which which I promise we'll help you in your statistics courses.

80
00:13:59,340 --> 00:14:04,800
Michael Akira Lee Hayashi: Every regression under the sun every single kinda will ever learn about it's just forcing a line through the day.

81
00:14:05,280 --> 00:14:15,000
Michael Akira Lee Hayashi: Some of them transform the data, some of them change the data points to be different shape door to be in different scales or things like that, or they introduced a bunch of other stuff but.

82
00:14:15,420 --> 00:14:21,900
Michael Akira Lee Hayashi: That is still at the end of the day, fitting a line through a sequence of points and that's really everything that's going on in a regression model so.

83
00:14:24,090 --> 00:14:28,620
Michael Akira Lee Hayashi: That is all of your apply statistics courses you're welcome and you don't need to take any more after this.

84
00:14:29,340 --> 00:14:38,250
Michael Akira Lee Hayashi: What what is helpful to know, though, is some of the kind of underlying philosophy of why these things are the way that they are and to a certain extent, why there are disciplinary differences between.

85
00:14:38,820 --> 00:14:46,410
Michael Akira Lee Hayashi: Statistical modeling and mechanistic model obviously one of the biggest caveats with mechanistic modeling is again garbage in garbage out.

86
00:14:47,220 --> 00:14:55,980
Michael Akira Lee Hayashi: it's it's still not very hard for me to build a mechanistic model that will reproduce features of realistic data, whether qualitatively or quantitative so.

87
00:14:56,880 --> 00:15:09,000
Michael Akira Lee Hayashi: The question always becomes Was this an accident or do I actually understand something about the system that i'm trying to model and that can be hard to say for a mechanistic model because your.

88
00:15:09,840 --> 00:15:19,530
Michael Akira Lee Hayashi: Your assumptions that you build in the mechanisms that you build in in large part, are based on your research background and intuitions about what you think should matter to assist if I.

89
00:15:20,400 --> 00:15:28,890
Michael Akira Lee Hayashi: If i'm going to try to model, a human's behavior in it in a given realm like their purchasing behavior, for example, which kinds of bananas, a person is going to buy at the store then.

90
00:15:30,360 --> 00:15:38,880
Michael Akira Lee Hayashi: The goodness of the exercise, for me, be the degree to which i'm going to do well at this exercise is heavily dependent on how well I understand.

91
00:15:39,090 --> 00:15:51,030
Michael Akira Lee Hayashi: What drives people to buy bananas, what is it about bananas, that people prefer, why do they, why do they express certain preferences over the bananas that they buy, what do those preferences look like and so.

92
00:15:51,960 --> 00:16:03,750
Michael Akira Lee Hayashi: That matters a lot in a statistical model you do still need to know very similar things like the fact that we throw race, age, sex into pretty much every regression we'd ever do isn't an accident it's because.

93
00:16:04,020 --> 00:16:19,020
Michael Akira Lee Hayashi: We know intuitively or otherwise, that those characteristics do impact, a lot of the things that change a person's health status they might expose a person to greater risk through one pathway another they might make it more likely that a person has.

94
00:16:20,430 --> 00:16:34,650
Michael Akira Lee Hayashi: I don't know has poor educational or income attainment and those things mean that they have for access to health care or nutrition or things like that, and those chains, to a certain extent, are why, when we build a Dag and we do things like that well when when people built Dag.

95
00:16:37,170 --> 00:16:41,580
Michael Akira Lee Hayashi: They put so much effort into that because a lot of this is trying to.

96
00:16:42,960 --> 00:16:58,170
Michael Akira Lee Hayashi: formalize the reasoning for why variables are going in the regression so that you're not just throwing stuff at the wall and seeing what sticks because we've realized that if you do that, you can make a line fit your data it's just not very useful to anyone so.

97
00:16:59,220 --> 00:16:59,700
Michael Akira Lee Hayashi: I think.

98
00:17:00,060 --> 00:17:05,280
Michael Akira Lee Hayashi: In a lot of ways, it primarily comes down to the question of mechanistic or not.

99
00:17:05,430 --> 00:17:15,840
Michael Akira Lee Hayashi: Which is not to say that you should not apply mechanistic thinking to statistical models you absolutely should and it's always worth thinking about why am I, putting covariance and am I doing it because everyone in the literature, does it.

100
00:17:16,020 --> 00:17:24,570
Michael Akira Lee Hayashi: Am I doing it because I think there's a good reason to actually include it from a causal perspective, am I doing it because my advisor told me to write these, these are all different.

101
00:17:25,170 --> 00:17:38,010
Michael Akira Lee Hayashi: forms of the same mechanistic question which traditional traditional presentations of statistics don't necessarily encourage to a very strong degree, but which is kind of fundamentally.

102
00:17:39,990 --> 00:17:50,580
Michael Akira Lee Hayashi: Something that you can't actually ignore in a statistical analysis, though it may not be explicitly represented or explicitly presented in that context.

103
00:17:52,080 --> 00:17:57,000
Michael Akira Lee Hayashi: And i'll pause for a bit or i'll shut up for a moment at least, in case there were questions or comments about any of that.

104
00:18:08,460 --> 00:18:08,850
groups.

105
00:18:26,130 --> 00:18:29,040
Michael Akira Lee Hayashi: And in some sense another way I put it, too, is that.

106
00:18:32,160 --> 00:18:33,240
Michael Akira Lee Hayashi: I tend to think of mechanistic.

107
00:18:33,240 --> 00:18:35,100
Michael Akira Lee Hayashi: models and systems models generally as.

108
00:18:35,100 --> 00:18:40,710
Michael Akira Lee Hayashi: Being exercises and testing whether the world works, the way that I think it so.

109
00:18:42,480 --> 00:18:51,450
Michael Akira Lee Hayashi: If I have some suspicion about how a disease is transmitted then i'll usually build a mechanistic model that includes a mechanism consistent with that suspicion.

110
00:18:51,840 --> 00:19:09,390
Michael Akira Lee Hayashi: And i'll see if the results look remotely like the data on incidence or prevalence for that disease or the or the data that indicates the way that that particular disease spreads and that's a way of testing my own assumptions about the way the world works in the particular domains.

111
00:19:10,740 --> 00:19:12,720
Michael Akira Lee Hayashi: That i'm interested in researching so.

112
00:19:13,740 --> 00:19:24,630
Michael Akira Lee Hayashi: Some what some of this can tell you also is things like well, a lot of diseases have multiple transmission mechanisms right things like colds flus all of the respiratory viruses.

113
00:19:26,730 --> 00:19:34,860
Michael Akira Lee Hayashi: they're spread by aerosol droplets mainly you get suspension of virus in them and really small water droplets.

114
00:19:35,640 --> 00:19:46,650
Michael Akira Lee Hayashi: That are exhaled or cough or sneeze out or whatever you also get some larger particle D positions like droplets spread, which is more or less a ballistic process where you breathe or cough or sneeze and you blast.

115
00:19:47,520 --> 00:20:01,110
Michael Akira Lee Hayashi: blast and number of droplets out and they'll kind of fallen the ballistic trajectory and some of those will get other people, you also have full night transmission, where some of that stuff sits on surfaces someone picks it up on their hands and rubs the rye, and now they've got a cold.

116
00:20:02,160 --> 00:20:02,580
Michael Akira Lee Hayashi: But.

117
00:20:03,600 --> 00:20:11,280
Michael Akira Lee Hayashi: there's a lot of active debate about which of those pathways are stronger or meaningful for particular diseases for flu, for example.

118
00:20:11,520 --> 00:20:20,760
Michael Akira Lee Hayashi: flu is primarily thought to be a respiratory disease and its primary thought primarily thought to be an airborne transmission disease, with some droplet transmission fairly minimal phone might transmission.

119
00:20:21,270 --> 00:20:29,580
Michael Akira Lee Hayashi: Well, that may not be true, there might actually be reasonably substantial phone my transmission of flew under certain contexts, but it's really hard for us to tell from the data right.

120
00:20:30,240 --> 00:20:42,570
Michael Akira Lee Hayashi: The data on its own doesn't say anything about for my transmission, so if we even if we tried to do a statistical analysis of where is the transmission coming from droplet format or rest or aerosol.

121
00:20:43,140 --> 00:20:52,110
Michael Akira Lee Hayashi: We just don't have the variables for that right like there aren't a whole lot of data sets that are going to tell us well this transmission event was a recipe was an aerosol one this one was a phone might one, and so on.

122
00:20:52,440 --> 00:20:58,020
Michael Akira Lee Hayashi: So sometimes we end up in situations where we want to evaluate some kind of hypothesis, but.

123
00:20:58,950 --> 00:21:05,520
Michael Akira Lee Hayashi: In cases like that we don't necessarily have the data available to directly test the hypothesis using statistical methods.

124
00:21:06,240 --> 00:21:15,210
Michael Akira Lee Hayashi: What we can do is build a transmission model that includes those three pathways that simulates transmission and then you can look to see.

125
00:21:15,480 --> 00:21:29,880
Michael Akira Lee Hayashi: Whether simulations involving one, two or three pathways match the data that we actually see in incidents or problems or whatever, and that can give you an idea of whether there's a signal in that data have multiple transmission pathways.

126
00:21:30,570 --> 00:21:35,190
Michael Akira Lee Hayashi: So you end up kind of smashing worlds together a little bit and that you're performing.

127
00:21:35,550 --> 00:21:45,840
Michael Akira Lee Hayashi: performing some degree of data driven modeling in fitting your model to data part of the reason that you're doing this is to try to understand something about the mechanism of that disease transmission to say, well, the.

128
00:21:46,920 --> 00:21:54,150
Michael Akira Lee Hayashi: The data looks kind of like this the model that has only respiratory transmission tends to look like this.

129
00:21:54,630 --> 00:22:02,670
Michael Akira Lee Hayashi: Have a model that has respiratory and fill my transmission tends to look pretty good and the model that has for my transmission only tends to look like this.

130
00:22:03,390 --> 00:22:11,040
Michael Akira Lee Hayashi: So from this, we would we would tend to conclude that well, we probably do need multiple mechanisms in our system or that there's reasonable evidence that.

131
00:22:11,340 --> 00:22:19,380
Michael Akira Lee Hayashi: There are multiple mechanisms in our system because models lacking those things just can't fit the data they don't have the effective degrees of freedom to do that.

132
00:22:20,280 --> 00:22:26,040
Michael Akira Lee Hayashi: This is not to say that there aren't other potential mechanisms that could explain that thing, but this is sort of the the.

133
00:22:26,550 --> 00:22:33,360
Michael Akira Lee Hayashi: Careful to step dance of interpreting your results do you say well it's definitely that there's evidence for for my marisol transmission.

134
00:22:33,930 --> 00:22:45,030
Michael Akira Lee Hayashi: No, but what you could say is at minimum there seems to be more evidence for that than one mechanism of transmission alone, and even if there are other things that could generate these same dynamics.

135
00:22:45,330 --> 00:22:54,300
Michael Akira Lee Hayashi: These seem plausible because we know that the disease can actually spread through these mechanisms so sometimes mechanistic modeling is also an exercise in.

136
00:22:55,230 --> 00:23:03,930
Michael Akira Lee Hayashi: Being able to use information from other sources beyond a single corpus of data to construct a model to test hypotheses about.

137
00:23:04,410 --> 00:23:15,930
Michael Akira Lee Hayashi: The the mechanistic functions of a particular system and to try to learn something about what those mechanisms might actually be the generate the macro level phenomenon that you're looking at at the back end.

138
00:23:27,060 --> 00:23:31,350
Michael Akira Lee Hayashi: Any thoughts or is reasonably reasonably good on that front.

139
00:23:34,530 --> 00:23:35,880
Michael Akira Lee Hayashi: or sleepy after lunch.

140
00:23:41,970 --> 00:23:45,720
Michael Akira Lee Hayashi: Let me go sleepy after lunch that's usually where i'm at.

141
00:23:49,290 --> 00:23:52,080
Michael Akira Lee Hayashi: All right, so let's take a step back to.

142
00:23:53,730 --> 00:24:00,720
Michael Akira Lee Hayashi: To our ma cough models some and what i'd like to do is an exercise that I put in the lab document which i'm going to.

143
00:24:02,220 --> 00:24:04,590
Michael Akira Lee Hayashi: wrap for a moment and screen share.

144
00:24:06,090 --> 00:24:06,510
Go.

145
00:24:08,970 --> 00:24:13,230
Michael Akira Lee Hayashi: And we're in we build a little Markov model of.

146
00:24:14,370 --> 00:24:29,370
Michael Akira Lee Hayashi: Smoking initiation and cessation it's going to be a very, very simple model and i'd rather stupid, one and a lot of ways, because it's going to miss a huge amount of actual mechanisms, but I think it's a you got to start somewhere and in a lot of ways I.

147
00:24:30,120 --> 00:24:45,300
Michael Akira Lee Hayashi: i'm a very personality driven model or I like to start with the very simplest smallest model I can possibly build for a given system so that I have a reasonable understanding of how that model works and how parts of that model interact with each other to generate results because.

148
00:24:46,350 --> 00:24:50,940
Michael Akira Lee Hayashi: One thing that might have occurred to you when i'm talking about statistical versus mechanistic models is.

149
00:24:51,180 --> 00:25:01,260
Michael Akira Lee Hayashi: hey it's pretty easy to throw stuff into a model to to add additional mechanisms be it's quite tempting to do that, because we know the real world is fairly complex, we know that there's a lot that plays into.

150
00:25:01,560 --> 00:25:07,200
Michael Akira Lee Hayashi: Why things happen, the way that they do, even for fairly simple problems so it's pretty tempting to be like well.

151
00:25:07,710 --> 00:25:12,060
Michael Akira Lee Hayashi: I know there's there's all this extra detail about the way the world works that.

152
00:25:12,420 --> 00:25:24,540
Michael Akira Lee Hayashi: My model isn't actually representing, and this is true of literally any model you're going to make, whether it is a conceptual model in your brain of whether you think your friends going to agree to get pizza with you for lunch to.

153
00:25:25,590 --> 00:25:38,040
Michael Akira Lee Hayashi: A mathematical model describing disease transmission or cancer incidence or mutation even to things like physical models all of those are making a bunch of simplifications, in order to.

154
00:25:39,270 --> 00:25:55,770
Michael Akira Lee Hayashi: In order to try to capture as much as possible about the system that they care about without without either putting so much detail into be intractable or leaving so much out that you no longer reasonably evoke the system that you're trying to model at all.

155
00:25:59,250 --> 00:26:08,040
Michael Akira Lee Hayashi: I because because I am someone that likes to build and paint physical models it's things this is often there's a lot of there's a lot of that trade off in that sort of thing.

156
00:26:08,280 --> 00:26:18,690
Michael Akira Lee Hayashi: A model of a boat is not that actual boat and if it were the actual boat it have X numbers of rivets and why numbers of funnels and engines and the things and whatever whatever it is that you put in boats.

157
00:26:20,400 --> 00:26:23,190
Michael Akira Lee Hayashi: But obviously that models not going to have all of those things right.

158
00:26:23,490 --> 00:26:30,840
Michael Akira Lee Hayashi: The goal, though, is for that model to have just enough stuff that when you look at it you're like oh that's this one particular boat.

159
00:26:31,080 --> 00:26:35,100
Michael Akira Lee Hayashi: understand that it is because it has enough features to evoke the boat that I know that it.

160
00:26:35,340 --> 00:26:45,780
Michael Akira Lee Hayashi: is trying to represent, and this is exactly what we're trying to do when we build mechanistic models of systems we don't want to throw literally all that detail and because we'd never analyze it.

161
00:26:46,800 --> 00:26:57,720
Michael Akira Lee Hayashi: But we also don't want so little detail that when you look at what the model does you're like this isn't remotely like what happens in the real world, this isn't even qualitatively close to the dynamics that we see in the real world.

162
00:26:58,710 --> 00:27:02,970
Michael Akira Lee Hayashi: So That being said, let's make a extremely simplified market model of.

163
00:27:04,260 --> 00:27:18,180
Michael Akira Lee Hayashi: Smoking initiation and cessation so what i've said here is i'm more or less pruned the smoking system down to its very simplest elements as far as I can tell, so we can make people be non smokers.

164
00:27:19,410 --> 00:27:21,120
Michael Akira Lee Hayashi: They could be current smokers.

165
00:27:22,680 --> 00:27:28,380
Michael Akira Lee Hayashi: or they could be former smokers, so we essentially have three states that people can occupy in a market model framework.

166
00:27:30,300 --> 00:27:36,090
Michael Akira Lee Hayashi: And let's well so so for one.

167
00:27:37,290 --> 00:27:43,230
Michael Akira Lee Hayashi: How do we think people transit through these states what kinds of ways can people go from one State to another.

168
00:27:47,130 --> 00:27:51,150
Caroline Godfrey: nonsmoker to current speaker current to former former to current.

169
00:27:53,160 --> 00:27:53,460
yeah.

170
00:27:54,480 --> 00:28:07,050
Michael Akira Lee Hayashi: yeah so so what we've done here is we've suggested that a nonsmoker in some senses is equivalent to a never smoker they've just not smoke cigarettes and as soon as they become a current smoker by by starting to smoke cigarettes.

171
00:28:07,500 --> 00:28:17,490
Michael Akira Lee Hayashi: They can't go back to being a nonsmoker However, if a person quits and becomes a former smoker we do keep track of that because they could relax and start smoking so we've.

172
00:28:18,390 --> 00:28:28,470
Michael Akira Lee Hayashi: we've built our system and defined some transitions between states in the system, which means that now our task is to turn this into a transition matrix for a markup.

173
00:28:29,010 --> 00:28:34,170
Michael Akira Lee Hayashi: So what's convenient about this that is fairly small, so we can we can write down quite a lot of what's going on here.

174
00:28:35,490 --> 00:28:36,210
Michael Akira Lee Hayashi: We have.

175
00:28:37,770 --> 00:28:41,640
Michael Akira Lee Hayashi: we're just going to define three states non current and former.

176
00:28:44,820 --> 00:28:51,960
Michael Akira Lee Hayashi: i'll note that, while this model is extremely simple it does actually form essentially theoretical foundation for quite a lot of smoking history models.

177
00:28:52,980 --> 00:28:57,330
Michael Akira Lee Hayashi: This this is more or less where these things come from various forms so.

178
00:28:58,560 --> 00:29:01,200
Michael Akira Lee Hayashi: A couple things to keep in mind about this transition matrix.

179
00:29:02,550 --> 00:29:08,610
Michael Akira Lee Hayashi: And about transition matrices in general, what do the diagonal elements represent these ones here.

180
00:29:11,820 --> 00:29:12,510
Caroline Godfrey: Staying in this.

181
00:29:14,580 --> 00:29:25,290
Michael Akira Lee Hayashi: yeah yeah, so this is this is your probability of staying in the same state where the off diagonal elements are all of the actual what we would think of as transition so going from never to current from never to former.

182
00:29:26,400 --> 00:29:38,070
Michael Akira Lee Hayashi: Now that does also mean that some of these states based on our our little diagram here can't actually be accessed from some of the others so.

183
00:29:38,790 --> 00:29:54,510
Michael Akira Lee Hayashi: um so, for example, I could not go directly from a never to a former smoker based on this diagram right because I have to pass through current smoker first so going to take those Apps they look suspiciously like zeros so we could do something like this, where.

184
00:29:55,530 --> 00:30:05,280
Michael Akira Lee Hayashi: This is a zero you can't ever go home again so you can't go from current to never and you also can't go from forward endeavor.

185
00:30:06,720 --> 00:30:15,150
Michael Akira Lee Hayashi: So we can kind of start blocking out our transition matrix by figuring out some elements that we know, have to be trivially zero.

186
00:30:15,360 --> 00:30:22,770
Michael Akira Lee Hayashi: And that simplifies a lot, because that means that all we have to figure out are the non zero elements of this transmission matrix so now we're basically left with.

187
00:30:23,160 --> 00:30:31,590
Michael Akira Lee Hayashi: A diagonal elements and one off diagonal element for each column in this transition matrix that's not too bad that's something that we can work with.

188
00:30:32,820 --> 00:30:43,260
Michael Akira Lee Hayashi: So now, the question is how do we actually set these values, how do we, how do we pick values for our trends our transition problems well.

189
00:30:43,620 --> 00:30:51,840
Michael Akira Lee Hayashi: Some of this is for now just going to be an exercise in making an assertion about about what values I think they should take based on what sounds halfway.

190
00:30:52,440 --> 00:31:01,560
Michael Akira Lee Hayashi: in real life, you probably wouldn't do that, except in your first pass, but you'd what you pretty quickly do is go digging through the literature, to look for, on average, what is the.

191
00:31:01,890 --> 00:31:18,720
Michael Akira Lee Hayashi: Age of initiation what is the average duration of smoking, what is the average time until relapse need go and dig all of this stuff stuff up and the literature, to try to put together, where you're going to find values for your transition probabilities here i've just inserted some stuff.

192
00:31:21,150 --> 00:31:29,340
Michael Akira Lee Hayashi: yeah so once we built this very simple model, we will want to have a talk about some of the things about this model but.

193
00:31:30,390 --> 00:31:38,670
Michael Akira Lee Hayashi: Maybe maybe it's not capturing but that the real world very definitely has like experimental users and things like that.

194
00:31:40,470 --> 00:31:50,550
Michael Akira Lee Hayashi: or hack a multi product world where where you have a more complicated situation where people could could try a different product that causes them to then start smoking regular cigarettes and so on.

195
00:31:52,530 --> 00:31:53,820
Michael Akira Lee Hayashi: But let's let's let's.

196
00:31:55,800 --> 00:32:03,720
Michael Akira Lee Hayashi: let's start simply first so let's suppose that on average people initiate smoking at about age 18 so here.

197
00:32:04,980 --> 00:32:14,490
Michael Akira Lee Hayashi: And that people on average smoke for about 10 years and that, on average, people relapse after about a year, and these probably aren't right for the most part.

198
00:32:16,050 --> 00:32:19,200
Michael Akira Lee Hayashi: So what we have here essentially our in our.

199
00:32:19,950 --> 00:32:27,960
Michael Akira Lee Hayashi: In terms of our previous terminology what we've been given our waiting times, these things are the amount of time before an event fires were that event is state change.

200
00:32:28,170 --> 00:32:34,050
Michael Akira Lee Hayashi: This one is the event, corresponding to initiation so it has a waiting time on average of 18 years.

201
00:32:34,650 --> 00:32:41,220
Michael Akira Lee Hayashi: Were quitting has a waiting time on average 10 years and relapse has a waiting time of one year, so now.

202
00:32:41,850 --> 00:32:57,480
Michael Akira Lee Hayashi: What do we need well waiting times are nice, but what we probably want our rates, fortunately, we know that rates and waiting times correspond nicely, in fact, if you take the inverse of a waiting time you get its corresponding exponentially distributed wait or rate and I can talk.

203
00:32:59,190 --> 00:33:07,320
Michael Akira Lee Hayashi: So if I want to know what the rate of initiation is it's going to be one over 18 and one over 18 years.

204
00:33:08,970 --> 00:33:15,840
Michael Akira Lee Hayashi: Similarly, the rate of quitting so initiation quitting is going to be one over 10.

205
00:33:17,760 --> 00:33:22,080
Michael Akira Lee Hayashi: Over 10 years and the rate of relapse is going to be one over one.

206
00:33:23,100 --> 00:33:23,340
Michael Akira Lee Hayashi: Year.

207
00:33:24,780 --> 00:33:26,340
Michael Akira Lee Hayashi: that's cool because.

208
00:33:28,830 --> 00:33:34,530
Michael Akira Lee Hayashi: We we are almost where we want now i'm going to do one other kind of little little.

209
00:33:35,580 --> 00:33:36,480
Michael Akira Lee Hayashi: Mathematical trick.

210
00:33:37,530 --> 00:33:39,270
Michael Akira Lee Hayashi: Let us assume that.

211
00:33:40,830 --> 00:33:42,150
Michael Akira Lee Hayashi: Fundamentally, so.

212
00:33:43,170 --> 00:33:51,960
Michael Akira Lee Hayashi: What we've got here a rates, but what we need for this transition matrix are probabilities those are not the same things and we cannot use them exactly interchange.

213
00:33:53,220 --> 00:33:57,510
Michael Akira Lee Hayashi: However, we could make some assumptions, for example, that.

214
00:33:58,620 --> 00:34:06,330
Michael Akira Lee Hayashi: Each of these trends transitions is governed by a pusan process, I told you they'd come back to haunt you and here, here they are.

215
00:34:07,590 --> 00:34:21,210
Michael Akira Lee Hayashi: If we do that what that means is that we can assume that these things, these rates are the rates of corresponding for some processes governing the transition between states so there's a persona process for.

216
00:34:21,720 --> 00:34:33,930
Michael Akira Lee Hayashi: initiation there's some process for quitting there's what's on process for relapse that means them for for reasons that you will have to trust me on that we can convert these rates into a probability.

217
00:34:34,920 --> 00:34:44,340
Michael Akira Lee Hayashi: Using this expression here, so one minus E to the negative Lambda T Wer T is the time step between.

218
00:34:44,790 --> 00:34:54,450
Michael Akira Lee Hayashi: evaluations of this system it's the time interval between before we check it because we're we're using a discrete time Markov model in this case, we do need to define a time interval so maybe we'll call it.

219
00:34:54,750 --> 00:35:01,860
Michael Akira Lee Hayashi: A yearly interval, for example, to make this simple on this, so what that means is that, if we want to calculate the probability of.

220
00:35:02,880 --> 00:35:16,470
Michael Akira Lee Hayashi: initiation for a given person within one year it'll one your time step we're going to do is that's going to be one minus E to the minus one over 18.

221
00:35:17,580 --> 00:35:18,870
Michael Akira Lee Hayashi: Then our tea in this case is one.

222
00:35:20,130 --> 00:35:31,680
Michael Akira Lee Hayashi: Time interval is one year and our clock of the model is easier, so this thing here gives us the probability and i'm going to make my calculator do this because I.

223
00:35:33,330 --> 00:35:34,560
Michael Akira Lee Hayashi: know how to do this in my head.

224
00:35:36,030 --> 00:35:36,720
Michael Akira Lee Hayashi: So.

225
00:35:38,370 --> 00:35:42,150
Michael Akira Lee Hayashi: Great teams about point of six so one minus.

226
00:35:44,160 --> 00:35:46,140
what's the point of six.

227
00:35:47,670 --> 00:35:48,870
Michael Akira Lee Hayashi: E to the.

228
00:35:53,160 --> 00:35:54,090
Michael Akira Lee Hayashi: six.

229
00:35:55,830 --> 00:36:03,330
Michael Akira Lee Hayashi: About point nine four and so total we end up with about a 6% probability for a year of.

230
00:36:04,770 --> 00:36:16,770
Michael Akira Lee Hayashi: Of initiation from our from our correspondence here and we can use this for each of these event rates to transform them into probability, so this is roughly equal 2.06.

231
00:36:18,090 --> 00:36:18,720
Michael Akira Lee Hayashi: Within a few.

232
00:36:19,770 --> 00:36:26,190
Michael Akira Lee Hayashi: Within questionable precision, but that's fine we'll we'll do a better when we actually calculate thing it's.

233
00:36:27,900 --> 00:36:36,510
Michael Akira Lee Hayashi: calculators getting drunk thing, so this is actually pretty much enough to specify the trends, the transition matrix for this system.

234
00:36:36,960 --> 00:36:46,530
Michael Akira Lee Hayashi: So let's switch over to our studio for a moment to start coding this thing, because now we need to start building the data structures to hold stuff about model.

235
00:36:49,020 --> 00:36:55,230
Michael Akira Lee Hayashi: So that and get back to wherever I put our studio somewhere here.

236
00:36:57,930 --> 00:36:59,280
Michael Akira Lee Hayashi: itself and background.

237
00:37:01,620 --> 00:37:06,000
Michael Akira Lee Hayashi: Okay, so i'm going to do i'm going to start a new script and i'm going to save my script so that.

238
00:37:08,280 --> 00:37:08,940
Michael Akira Lee Hayashi: I can.

239
00:37:10,320 --> 00:37:12,510
Michael Akira Lee Hayashi: work with it sensibly, this is going to be.

240
00:37:16,590 --> 00:37:17,100
Michael Akira Lee Hayashi: Free.

241
00:37:27,540 --> 00:37:41,610
Michael Akira Lee Hayashi: You might know the same rules tend to apply to me for file naming as for variable naming make them descriptive also don't put spaces in your file names it's easier to parse in the future, student resource, be consistent about your capitalization be consistent about your date.

242
00:37:43,110 --> 00:37:58,830
Michael Akira Lee Hayashi: Your your date tagging this sounds picky but I promise, it will help you later down the line, if you name all of your files in a consistent format, especially if you named data files in the consistent format, you can process them procedurally like if all of your data files are like.

243
00:38:00,240 --> 00:38:15,000
Michael Akira Lee Hayashi: Data name underscore your your your your dash month month dash de de it's really easy to write a loop that reads in all those files and parses the middle critically and then does something with them and save yourself an enormous amount of time and frustration so.

244
00:38:16,590 --> 00:38:22,200
Michael Akira Lee Hayashi: Naming hygiene is surprisingly helpful anyway, we need a few things here so.

245
00:38:24,210 --> 00:38:28,590
Michael Akira Lee Hayashi: let's let's start by kind of writing down what we know, so we have some.

246
00:38:29,670 --> 00:38:40,410
Michael Akira Lee Hayashi: We have some stuff we have some rates we're going to have initiation rate is going to be one over 18 we have a quick rate is going to be one of 10 and relapse.

247
00:38:41,550 --> 00:38:41,880
Michael Akira Lee Hayashi: rate.

248
00:38:44,430 --> 00:38:45,330
Michael Akira Lee Hayashi: So.

249
00:38:47,160 --> 00:38:54,960
Michael Akira Lee Hayashi: What we need now are some probabilities so we're going to want Internet problems equal to one minus.

250
00:38:57,090 --> 00:38:59,580
Michael Akira Lee Hayashi: argue exponential dsp.

251
00:39:03,030 --> 00:39:05,280
Michael Akira Lee Hayashi: I think it is i'm going to Google it just in case.

252
00:39:08,820 --> 00:39:29,580
Michael Akira Lee Hayashi: So what I want specifically is law is is he to the power, so I don't want to screw that up and it does look like it is X so that's good, so I want one minus what did I say it was one minus E to the negative Lambda T So when I say T interval is one are all say T step.

253
00:39:32,520 --> 00:39:33,150
Michael Akira Lee Hayashi: Is.

254
00:39:34,950 --> 00:39:38,190
Michael Akira Lee Hayashi: You xp minus unit rate.

255
00:39:39,720 --> 00:39:44,400
Michael Akira Lee Hayashi: So this should calculate the initiation probability same deal for quit prob.

256
00:39:50,130 --> 00:39:51,780
Michael Akira Lee Hayashi: And same deal for relapse.

257
00:39:58,980 --> 00:40:04,080
Michael Akira Lee Hayashi: So let's just run this thing for the moment and be thorough and print.

258
00:40:13,980 --> 00:40:14,370
Michael Akira Lee Hayashi: All those.

259
00:40:15,840 --> 00:40:19,980
Michael Akira Lee Hayashi: Okay So here we have things that look pretty okay for our.

260
00:40:21,090 --> 00:40:32,460
Michael Akira Lee Hayashi: The transition probabilities i'm kind of eyeballing whether these things look okay to me on the basis of I know the probability for relapse in a given year should be fairly high because the rate is one, and so it is.

261
00:40:33,840 --> 00:40:44,490
Michael Akira Lee Hayashi: I back of the envelope calculated the initiation probability, so I know this isn't the right neighborhood and the quote probability should be slightly higher than that so good we're basically that so now.

262
00:40:45,540 --> 00:40:53,190
Michael Akira Lee Hayashi: Now we need to put this stuff in and Jason see matrix so what I do here is start by.

263
00:40:54,690 --> 00:40:56,850
Michael Akira Lee Hayashi: Creating a thing.

264
00:41:01,080 --> 00:41:06,660
Michael Akira Lee Hayashi: I felt with zeros that's going to be three by three, so this is just going to be our starting transition matrix.

265
00:41:10,140 --> 00:41:17,610
Michael Akira Lee Hayashi: And do that there it is that's Nice, so now we just need to sort out which elements we need to.

266
00:41:19,470 --> 00:41:34,860
Michael Akira Lee Hayashi: need to fill in these are all probabilities for the off diagonal elements, because they represent changes as opposed to staying the same so let's fill those in So if I so first we're going to do the initiation which is never to current this is going to be.

267
00:41:37,830 --> 00:41:43,440
Michael Akira Lee Hayashi: An assign the second row of the first column and that's going to be in it prob.

268
00:41:44,790 --> 00:41:45,510
Michael Akira Lee Hayashi: And we're gonna.

269
00:41:48,090 --> 00:41:50,070
Michael Akira Lee Hayashi: have to do quitting which is.

270
00:41:51,930 --> 00:41:54,780
Michael Akira Lee Hayashi: column to to row three so that's.

271
00:41:56,940 --> 00:41:58,770
Michael Akira Lee Hayashi: A great next goes row column so.

272
00:42:00,030 --> 00:42:01,230
Michael Akira Lee Hayashi: Make sure that you keep those.

273
00:42:02,970 --> 00:42:03,510
Michael Akira Lee Hayashi: streets.

274
00:42:05,040 --> 00:42:16,860
Michael Akira Lee Hayashi: In your heads and, finally, the relapse one so transition matrix and this one is going to be column three road to or this.

275
00:42:19,980 --> 00:42:22,980
Michael Akira Lee Hayashi: And after all this is said and done, i'm now going to.

276
00:42:27,390 --> 00:42:35,130
Michael Akira Lee Hayashi: My thing to make sure that i've done it right so here, I can kind of double check myself.

277
00:42:37,620 --> 00:42:48,660
Michael Akira Lee Hayashi: This is the initiation which is never to current one to two that's right, this is quitting which is two to three, this is relapse which is three to two, so this looks OK.

278
00:42:49,320 --> 00:42:57,600
Michael Akira Lee Hayashi: We have zero here here, and here, which is fine, we don't need to do anything with that now, when you to calculate the diagonal elements so.

279
00:42:58,800 --> 00:43:04,020
Michael Akira Lee Hayashi: there's different ways we could do that we could, for example, do we can do this explicitly.

280
00:43:05,790 --> 00:43:06,630
Michael Akira Lee Hayashi: By doing.

281
00:43:10,170 --> 00:43:11,130
Michael Akira Lee Hayashi: Simple to.

282
00:43:13,020 --> 00:43:13,470
Michael Akira Lee Hayashi: This.

283
00:43:35,610 --> 00:43:39,120
Michael Akira Lee Hayashi: And we can do a little bit of arithmetic to make sure that these look right but they look right to me.

284
00:43:39,420 --> 00:43:51,270
Michael Akira Lee Hayashi: So here we formed our transition matrix, which is quite a lot of the actual market models that we wanted to build there's not a whole ton of code that goes into the market model itself, so there is sometimes more code involved in.

285
00:43:51,750 --> 00:43:55,620
Michael Akira Lee Hayashi: Well, doing stuff with the Markov model which, which will take a look at here.

286
00:43:56,640 --> 00:43:57,120
Michael Akira Lee Hayashi: So.

287
00:43:58,350 --> 00:44:02,610
Michael Akira Lee Hayashi: Right is could we have done this another way Well, yes.

288
00:44:05,370 --> 00:44:06,990
Michael Akira Lee Hayashi: We could, if we were.

289
00:44:08,790 --> 00:44:23,820
Michael Akira Lee Hayashi: We were feeling cutting we could explain the fact that our likes to think about vectors middle lot of operations in our are implicitly vectors this actually includes this one, the exponential function this This is equivalent to.

290
00:44:25,590 --> 00:44:28,320
Michael Akira Lee Hayashi: E to the X.

291
00:44:29,940 --> 00:44:40,710
Michael Akira Lee Hayashi: Interestingly, this function works, just as well, whether X is a singleton or whether it's a vector so this could actually look like X one X two X three and so on.

292
00:44:42,270 --> 00:44:48,180
Michael Akira Lee Hayashi: Why is this remotely helpful to us well, we did something like that so.

293
00:44:50,490 --> 00:44:54,780
Michael Akira Lee Hayashi: You can make a little vector that's going to make it done but it's fine.

294
00:44:58,200 --> 00:45:09,330
Michael Akira Lee Hayashi: notice that this has taken each each of these elements sequential fortunately it didn't do any kind of weird collapsing operation it just element wise exponential weighted each element.

295
00:45:10,470 --> 00:45:22,950
Michael Akira Lee Hayashi: Why is that helpful because I have three things essentially that I need to exponential the quit rate the relapse rates and the initiation So if I did something like this.

296
00:45:30,120 --> 00:45:33,300
Michael Akira Lee Hayashi: And then just kind of tact and negative on each of these.

297
00:45:34,710 --> 00:45:35,100
Michael Akira Lee Hayashi: This.

298
00:45:36,750 --> 00:45:37,350
way all.

299
00:45:42,960 --> 00:45:43,410
that's.

300
00:45:47,310 --> 00:45:54,720
Michael Akira Lee Hayashi: Why am I commenting lines, because I refuse to push the button so i'm going to continue running the entire So what does this look like Trent.

301
00:46:03,480 --> 00:46:06,360
Michael Akira Lee Hayashi: Sorry, I had to name my variable and assign it or this wouldn't work at all.

302
00:46:08,490 --> 00:46:14,610
Michael Akira Lee Hayashi: So this factor is just storing each of the rates as an element, so now, if I did something like.

303
00:46:22,290 --> 00:46:22,920
Michael Akira Lee Hayashi: What does this give.

304
00:46:24,690 --> 00:46:39,990
Michael Akira Lee Hayashi: me another record this has actually given me the the inverse of the probabilities of each of these things, this is actually pretty helpful right now I can use this almost directly so we'll keep this for the moment let's do.

305
00:46:42,690 --> 00:46:48,870
Michael Akira Lee Hayashi: Actually, this is going to be not event props for for reasons that will be kind of in the moment.

306
00:46:51,150 --> 00:46:53,340
Michael Akira Lee Hayashi: So event props then or just.

307
00:46:54,720 --> 00:46:55,800
Michael Akira Lee Hayashi: One minus not.

308
00:46:57,330 --> 00:47:03,750
Michael Akira Lee Hayashi: event process, why does this work because, again, our can vector eyes operation, so if I print event probs.

309
00:47:05,280 --> 00:47:10,470
Michael Akira Lee Hayashi: It gives me the vector holding all of the probabilities for each event.

310
00:47:12,480 --> 00:47:16,200
Michael Akira Lee Hayashi: And I could assign those out accordingly for use later.

311
00:47:17,640 --> 00:47:19,530
Michael Akira Lee Hayashi: The one of the first things i'm going to do with it.

312
00:47:20,850 --> 00:47:24,300
Michael Akira Lee Hayashi: is change the way i'm assigning stuff in the transmission just a little bit so.

313
00:47:33,960 --> 00:47:36,360
Michael Akira Lee Hayashi: Like that that's Nice.

314
00:47:38,250 --> 00:47:38,580
Michael Akira Lee Hayashi: and

315
00:47:39,600 --> 00:47:47,340
Michael Akira Lee Hayashi: i'm gonna do one extra bit of of sorcery here and do a matrix operation on the transition matrix.

316
00:47:52,320 --> 00:47:55,470
Michael Akira Lee Hayashi: And if this works and if i'm good at matrix sorcery today.

317
00:47:56,670 --> 00:48:00,480
Michael Akira Lee Hayashi: bring it exactly the same matrix in fewer lines which is kind of fun.

318
00:48:01,620 --> 00:48:08,130
Michael Akira Lee Hayashi: by exploiting some of ours intrinsic vector ization of mathematical operations so.

319
00:48:08,700 --> 00:48:19,320
Michael Akira Lee Hayashi: to walk through what i've done here I stuck all of my rates in a vector and also made them negative because I knew this is part of the calculation i'd have to do right like ultimately my calculation looks like one minus E to the.

320
00:48:20,460 --> 00:48:21,240
Michael Akira Lee Hayashi: Negative are.

321
00:48:23,010 --> 00:48:39,600
Michael Akira Lee Hayashi: This is what I want So if I wanted to take the exponent of all of my rates in a vector eyes format here i'm just using the exponent function, which is vector eyes, which will work sequentially on each element of this vector it returns this not event probs vector.

322
00:48:41,640 --> 00:48:54,600
Michael Akira Lee Hayashi: which holds well the probability of not the events and then, if I want the event probabilities themselves, I take one minus this so in some sense i'm literally doing a full vector ization of this operation here.

323
00:48:56,100 --> 00:49:03,180
Michael Akira Lee Hayashi: I could have probably done this directly right like I could have actually saved myself a step and done this.

324
00:49:05,580 --> 00:49:08,100
Michael Akira Lee Hayashi: And this actually will work exactly the same.

325
00:49:09,420 --> 00:49:22,350
Michael Akira Lee Hayashi: I chose not to because I noticed when I was calculating these things that this vector is actually useful to me right, I named this not event problem, because this vector contains the probability of the event not happening.

326
00:49:22,770 --> 00:49:31,560
Michael Akira Lee Hayashi: Another way of putting that is that, in this case happens to be the probability of staying in the same state just because we got lucky and then our model.

327
00:49:32,610 --> 00:49:41,610
Michael Akira Lee Hayashi: there's really only two things that can happen for any given state and there's some there's some transitions that are legal, so we made our lives, a lot easier here.

328
00:49:42,960 --> 00:49:50,160
Michael Akira Lee Hayashi: And then, when I went to assign stuff I assign the probabilities from this vector that I had here.

329
00:49:50,550 --> 00:50:04,680
Michael Akira Lee Hayashi: And I had to keep in mind that the first element correspondence initiation The second element for responded to quitting third element corresponds to relapse and what i'd probably do is something like here I would find a need to document things so i'd say.

330
00:50:08,010 --> 00:50:08,820
Michael Akira Lee Hayashi: like this.

331
00:50:18,570 --> 00:50:32,760
Michael Akira Lee Hayashi: Just to remind myself that when I see this I don't get confused later down what this is a is a our function which assigns values to the diagonal of a matrix, so this is kind of an odd one.

332
00:50:35,400 --> 00:50:40,620
Michael Akira Lee Hayashi: Because it serves two functions in a way that I don't i'm not entirely down with.

333
00:50:41,640 --> 00:50:53,400
Michael Akira Lee Hayashi: So the definition of the diag function is that it extracts or replaces the diagonal of a matrix or constructs the diagonal matrix so it's actually a triple threat but I don't ever really use this.

334
00:50:55,320 --> 00:50:57,960
Michael Akira Lee Hayashi: So what would happen if I called.

335
00:51:03,210 --> 00:51:21,630
Michael Akira Lee Hayashi: That thing just to print out is that it would return the elements on the Dag, however, if I assign something to the results here it then overwrite the diagonal of that matrix itself, this is really strange to me, and this is this is questionable design to me because.

336
00:51:22,800 --> 00:51:26,040
Michael Akira Lee Hayashi: What this means is that this function.

337
00:51:26,670 --> 00:51:32,940
Michael Akira Lee Hayashi: is implicitly returning a reference to the original matrix is diagonal component so.

338
00:51:33,150 --> 00:51:43,080
Michael Akira Lee Hayashi: there's a couple different ways that a program can return values, one is that it just returns that actual value like it just returns whatever was on that diagonal and if I reassign anything to it.

339
00:51:43,290 --> 00:51:52,380
Michael Akira Lee Hayashi: It overrides it another is that it can return a reference which is basically a thing that points to wherever that data structure lives in my computer memory that's like okay.

340
00:51:52,710 --> 00:52:04,500
Michael Akira Lee Hayashi: i'm going to be lazy and i'm just going to show you where this thing is, and you can manipulate it, however you'd like this diag function seems to be the latter it's it's a reference, so this is not returning a copy.

341
00:52:05,340 --> 00:52:22,830
Michael Akira Lee Hayashi: Of the transition matrix is diag what it's actually doing is pointing to where the diagonal of that transition matrix lives on my computer which enables me to overwrite it directly, instead of having to do something, what the the flow that would make more sense to me and then.

342
00:52:23,850 --> 00:52:28,500
Michael Akira Lee Hayashi: If borrower sensibly to design language what probably happened is something like this.

343
00:52:32,250 --> 00:52:33,510
Michael Akira Lee Hayashi: There there'd be some.

344
00:52:36,660 --> 00:52:38,190
Michael Akira Lee Hayashi: thing that's like diag.

345
00:52:43,200 --> 00:52:44,490
Michael Akira Lee Hayashi: Wait you know what actually I mean.

346
00:52:47,190 --> 00:52:54,420
Michael Akira Lee Hayashi: I would, I probably have written this or I would have preferred the function honestly I think what I probably would have been what I probably would have preferred something like.

347
00:53:03,870 --> 00:53:11,160
Michael Akira Lee Hayashi: Something it looks like this, this would be syntax that I would find more broadly comprehensible, because what it's what it's doing is it's telling me okay.

348
00:53:11,670 --> 00:53:15,870
Michael Akira Lee Hayashi: This function is going to replace the diagonal of this matrix with this.

349
00:53:16,140 --> 00:53:29,790
Michael Akira Lee Hayashi: Right and then it's going to save that to a variable, this is a little more conventional style of coding where this function requires you to to think a little bit about why is it even capable of doing this, which is sometimes a weird task for the programmer.

350
00:53:31,620 --> 00:53:41,340
Michael Akira Lee Hayashi: Because because language is like are and even Python or not always explicit about when they're giving you a reference to something versus a copy it's it's anyway that's that's the thing.

351
00:53:46,680 --> 00:53:53,610
Michael Akira Lee Hayashi: Is there a way in our that whole section cannot be read by our wall reading the codes Oh, I like like a block comments about.

352
00:53:55,200 --> 00:53:58,230
Michael Akira Lee Hayashi: The top of my head I don't honestly know, let me, let me do some googling.

353
00:54:03,360 --> 00:54:04,500
Michael Akira Lee Hayashi: know what there is not.

354
00:54:05,970 --> 00:54:06,360
Michael Akira Lee Hayashi: Knowing.

355
00:54:08,400 --> 00:54:21,150
Michael Akira Lee Hayashi: ya know there's not like if you're if you're a Python person, you probably made heavy use of this to block comments it's it's wonderful just turns off a section you're a matlab user also you probably blocked comment there.

356
00:54:22,230 --> 00:54:31,680
Michael Akira Lee Hayashi: We are not so lucky of our another failure design, so no Unfortunately, you do have to do a kind of cumbersome thing when you're commenting out sections in our code.

357
00:54:32,700 --> 00:54:40,680
Michael Akira Lee Hayashi: Some of what this doesn't well some of what this encourages which is bad practice is only running the lines that you want using the no no button.

358
00:54:42,750 --> 00:54:56,520
Michael Akira Lee Hayashi: But what this can also encourage is compartmentalizing your Code into functions, so that you, you just call a function that does a specific thing right like if I wanted to test two different versions of creating this thing what I might do is something like i'm.

359
00:55:08,550 --> 00:55:08,910
Michael Akira Lee Hayashi: done.

360
00:55:15,570 --> 00:55:25,500
Michael Akira Lee Hayashi: This and then crammed all of the relevant code inside these functions such that I can own I only have to use the one that I want to use at any given time.

361
00:55:28,320 --> 00:55:31,500
Michael Akira Lee Hayashi: This is probably the closest you'll come to properly encapsulating.

362
00:55:33,000 --> 00:55:42,120
Michael Akira Lee Hayashi: sections of our code otherwise be prepared for block commenting the Internet says that control shift see supposedly will.

363
00:55:42,960 --> 00:55:57,180
Michael Akira Lee Hayashi: will comment every line out individually receive that oh it's about it does that get used to, but then you still have to go to sleep when you're done it's faster at the start, at least so you know it's not literally The worst thing in the entire world.

364
00:55:59,190 --> 00:56:00,060
Michael Akira Lee Hayashi: it's just close.

365
00:56:02,460 --> 00:56:05,160
Michael Akira Lee Hayashi: So I can do a little bit more like this if I wanted to.

366
00:56:05,700 --> 00:56:14,550
Michael Akira Lee Hayashi: Now that i've got the stuff to be able to build my transition matrix maybe I do actually want to wrap that in a function, so that I can do it again and again and again with different rates.

367
00:56:14,820 --> 00:56:25,440
Michael Akira Lee Hayashi: So let's do this and i'm going to reorganize my code so it's cleaner and stick my function definitions at the top and everything that's not a function definition down at the bottom, this is going to take.

368
00:56:34,800 --> 00:56:38,010
Michael Akira Lee Hayashi: to notice that when I write our functions.

369
00:56:38,280 --> 00:56:47,040
Michael Akira Lee Hayashi: or when I write functions in general, if they're multi where things will often use an underscore to separate words if i'm naming variables in script code i'll use what's called camel case alternating capitals.

370
00:56:47,310 --> 00:56:58,560
Michael Akira Lee Hayashi: This also helps me keep straight in my brain what is a variable defined in the script versus what is a name for an argument within a function it's just an organizational trick to keep myself honest.

371
00:57:00,150 --> 00:57:05,580
Michael Akira Lee Hayashi: same deal here then do that and then just keep pushing itself down the line.

372
00:57:07,050 --> 00:57:11,490
Michael Akira Lee Hayashi: So am I going to put this in the explicit version.

373
00:57:13,590 --> 00:57:16,110
Michael Akira Lee Hayashi: Please rise my code here is fine.

374
00:57:18,300 --> 00:57:18,870
Michael Akira Lee Hayashi: This.

375
00:57:30,240 --> 00:57:42,960
Michael Akira Lee Hayashi: I might put this all the way at the top, because it's kind of a preliminary that everything else needs but I go back and forth on those sorts of things, and then I probably need this blob here actually X to do this thing.

376
00:57:46,440 --> 00:57:57,570
Michael Akira Lee Hayashi: And this would be the function to generate our thing explicitly for not out there and that out, and then for the vector is one very similar deal, so in this case i'm just going to do this.

377
00:58:01,650 --> 00:58:02,010
Michael Akira Lee Hayashi: and

378
00:58:03,360 --> 00:58:04,080
Michael Akira Lee Hayashi: This.

379
00:58:09,090 --> 00:58:10,320
Michael Akira Lee Hayashi: You have to give all kinda.

380
00:58:11,700 --> 00:58:12,990
Michael Akira Lee Hayashi: Well, we told you about this.

381
00:58:15,060 --> 00:58:16,260
Michael Akira Lee Hayashi: Sign my diagonal.

382
00:58:18,630 --> 00:58:19,380
Michael Akira Lee Hayashi: And then returned.

383
00:58:23,130 --> 00:58:28,320
Michael Akira Lee Hayashi: So now, I can get rid of this junk i'm going to keep this here and put it back in.

384
00:58:29,370 --> 00:58:31,740
Michael Akira Lee Hayashi: Here, because this version tends to need.

385
00:58:34,830 --> 00:58:40,920
Michael Akira Lee Hayashi: Yes, um let me, let me write one more line here and then.

386
00:58:48,930 --> 00:58:51,930
Michael Akira Lee Hayashi: And then I will paste code somewhere.

387
00:59:10,800 --> 00:59:12,570
Michael Akira Lee Hayashi: And that's do and then we're gonna print.

388
00:59:19,110 --> 00:59:26,130
Michael Akira Lee Hayashi: And then we're gonna run to confirm that these are exactly the same, unfortunately, they are so we seem to seem to have done okay.

389
00:59:26,880 --> 00:59:33,210
Morgan Caitlin Byrd: So, actually, you have a question in the chat of whether you could copy and paste the current Code that you have.

390
00:59:33,990 --> 00:59:37,200
Michael Akira Lee Hayashi: yeah i'm going to put this on canvas really quick.

391
00:59:38,160 --> 00:59:40,590
Michael Akira Lee Hayashi: So if I posted in chat it's going to be ugly.

392
00:59:44,490 --> 00:59:49,140
Michael Akira Lee Hayashi: So let me put this in the stochastic model section.

393
00:59:50,910 --> 00:59:57,180
Michael Akira Lee Hayashi: And we'll get to see how ugly it is when I paste it directly here that's going to be so special exercise.

394
01:00:02,040 --> 01:00:05,790
Michael Akira Lee Hayashi: Oh what's the best way to do this there's not one that's free.

395
01:00:15,660 --> 01:00:21,330
Michael Akira Lee Hayashi: i'm waffling about how to do this okay i'm gonna slap it in chat for the moment, and I will think of a better way to put it in.

396
01:00:22,950 --> 01:00:30,450
Michael Akira Lee Hayashi: I don't even know if will paste into chapters rather a lot of code and I think about a way to put it in canvas that will just do is.

397
01:00:37,620 --> 01:00:38,790
Michael Akira Lee Hayashi: What is the way to do this.

398
01:00:41,550 --> 01:00:45,900
Michael Akira Lee Hayashi: Well, when in doubt brute force i'm going to copy it onto the end of the.

399
01:00:48,000 --> 01:00:55,650
Michael Akira Lee Hayashi: Page so ourselves it's going to be it's going to be gross I think there's a way to quote stuff a little more sensibly in.

400
01:00:57,660 --> 01:01:07,020
Michael Akira Lee Hayashi: In canvas because it's basically using html not sure I feel like figuring out to it, although started now so we're a little bit committed.

401
01:01:08,190 --> 01:01:11,220
Michael Akira Lee Hayashi: For my code that there it is OK.

402
01:01:17,670 --> 01:01:18,090
Michael Akira Lee Hayashi: there.

403
01:01:19,170 --> 01:01:20,490
Michael Akira Lee Hayashi: that's not worst thing in the world.

404
01:01:25,770 --> 01:01:32,640
Michael Akira Lee Hayashi: Okay, so now that's up on them is pretty ugly okay that's good now it's up on the stochastic models page.

405
01:01:41,850 --> 01:01:45,360
Michael Akira Lee Hayashi: At least a format at the tabs so it could be worse, I guess.

406
01:01:49,200 --> 01:01:59,880
Michael Akira Lee Hayashi: Okay, so we got our matrix now and probably want to do stuff with it like like I don't know simulating the system or or calculating the.

407
01:02:01,200 --> 01:02:03,600
Michael Akira Lee Hayashi: stationary distribution or things like that.

408
01:02:04,680 --> 01:02:20,880
Michael Akira Lee Hayashi: One of the one of the more straightforward things that we probably want to do with the system like this is just simulate so this model can represent a way a State trajectory for a given person so let's write a function to simulate our model.

409
01:02:23,190 --> 01:02:24,300
Michael Akira Lee Hayashi: And i'll note that i'm.

410
01:02:26,040 --> 01:02:34,320
Michael Akira Lee Hayashi: A version of all of this stuff in final form is actually available on canvas I left it there, because I honestly don't care, if you look at it, ahead of time.

411
01:02:35,190 --> 01:02:44,250
Michael Akira Lee Hayashi: I just figured that like sometimes sometimes folks have found that like watching me talk through my coding can be helpful because it lays out the reasoning for why I wrote a thing in a particular way.

412
01:02:44,520 --> 01:02:51,210
Michael Akira Lee Hayashi: because sometimes that is a bit of a mystery So if you download the smoking history Markov model code that is actually a complete functional version of this thing.

413
01:02:53,220 --> 01:02:56,700
Michael Akira Lee Hayashi: Does it not around they break, something I might have broke something.

414
01:02:58,800 --> 01:03:05,730
Michael Akira Lee Hayashi: So well that's interesting actually I thought i'd tested that one it's always possible I broke something in the intervening time.

415
01:03:07,320 --> 01:03:09,990
Michael Akira Lee Hayashi: Let me, let me pull it up and possibly fix it.

416
01:03:13,710 --> 01:03:18,690
Michael Akira Lee Hayashi: So here's the template one just going to smack it open source and see what comes out the end.

417
01:03:21,780 --> 01:03:23,820
Michael Akira Lee Hayashi: Thinking varicose.

418
01:03:25,290 --> 01:03:25,950
Michael Akira Lee Hayashi: seems to work.

419
01:03:36,300 --> 01:03:40,800
Michael Akira Lee Hayashi: Do you mean the code that I just wrote doesn't run because that's also very plausible but I left something out.

420
01:03:43,050 --> 01:03:43,740
Michael Akira Lee Hayashi: Ah, OK.

421
01:03:46,620 --> 01:03:52,980
Michael Akira Lee Hayashi: that's interesting it worked for me just now, let me wipe my thing and see if it's a oh.

422
01:03:55,170 --> 01:03:55,710
Michael Akira Lee Hayashi: yeah that.

423
01:03:58,560 --> 01:04:02,520
Michael Akira Lee Hayashi: Oh, you know what I left some extra jumped in here.

424
01:04:04,680 --> 01:04:05,160
Michael Akira Lee Hayashi: that's good.

425
01:04:06,480 --> 01:04:08,460
Michael Akira Lee Hayashi: So what I need is this.

426
01:04:13,710 --> 01:04:26,010
Michael Akira Lee Hayashi: that's what I get for copy pasting too fast and you got to see in real time a problem with the the global environment stuff so that's nice there, let me put that on campus and fix that.

427
01:04:34,770 --> 01:04:43,470
Michael Akira Lee Hayashi: Fortunately, the version from last year does actually work properly, which is gratifying to me infidelity broke, one of my examples.

428
01:04:45,120 --> 01:04:45,570
So always.

429
01:04:47,550 --> 01:04:54,510
Michael Akira Lee Hayashi: that's always a risk all right, but we should that block code formatting it probably does I don't feel like let's try this one now, this should be better.

430
01:05:01,830 --> 01:05:06,690
Michael Akira Lee Hayashi: Let this be less than that, no matter how long you write code for you are never saved from your own books.

431
01:05:13,080 --> 01:05:19,140
Michael Akira Lee Hayashi: So you're giving that a go let's think a little bit about how to how to simulate this thing so we're going to write a new function.

432
01:05:20,670 --> 01:05:23,220
Michael Akira Lee Hayashi: And for now i'm not going to give it arguments just yet.

433
01:05:24,660 --> 01:05:34,800
Michael Akira Lee Hayashi: um let's suppose I want to simulate an individual person for 80 years close to close to an average American lifestyle give or take.

434
01:05:36,810 --> 01:05:40,260
Michael Akira Lee Hayashi: So, in order to do this, I basically need to.

435
01:05:41,580 --> 01:05:46,770
Michael Akira Lee Hayashi: do some form of iterative matrix vector multiplication in order to.

436
01:05:47,340 --> 01:06:00,000
Michael Akira Lee Hayashi: Take a take a person from a starting state, all the way to an ending state, and I want to keep track of what all of those States are going to be along the way, so that does tell me a little bit about what has to go into the function so, for example, I should probably know.

437
01:06:01,710 --> 01:06:05,310
Michael Akira Lee Hayashi: Start starting state or the initial state, I want to use kind of similar.

438
01:06:06,720 --> 01:06:07,380
Michael Akira Lee Hayashi: language.

439
01:06:08,400 --> 01:06:11,070
Michael Akira Lee Hayashi: I probably want to know how long this is going to run for.

440
01:06:14,310 --> 01:06:16,590
Michael Akira Lee Hayashi: And then i'm going to need my parameters.

441
01:06:21,060 --> 01:06:25,830
Michael Akira Lee Hayashi: i'm going to pass these explicitly for now, because I feel as though that is a reasonable way to do this.

442
01:06:27,090 --> 01:06:27,900
Michael Akira Lee Hayashi: So.

443
01:06:28,980 --> 01:06:40,860
Michael Akira Lee Hayashi: First, we need to construct our transition matrix i'm going to call this thing a following the notation from my notes, one of the few cases where i'm willing to use shorthand for notation is when I am.

444
01:06:41,250 --> 01:06:54,270
Michael Akira Lee Hayashi: or for variable names is when i'm relying on pre existing notation from other literature that's why i'm like an SDR model, for example, my variables are probably going to be called si and are there's going to be parameters like beta gamma Sigma whatever new new.

445
01:06:55,260 --> 01:07:05,370
Michael Akira Lee Hayashi: That tends to be the case where i'll deviate from my sort of verbose variable naming scheme because those that notation tends to be known in the field.

446
01:07:06,540 --> 01:07:08,580
Michael Akira Lee Hayashi: So here on a build my.

447
01:07:12,360 --> 01:07:16,530
Michael Akira Lee Hayashi: matrix and i'm going to give it my things.

448
01:07:18,720 --> 01:07:26,970
Michael Akira Lee Hayashi: i'm going to give it a fixed time step because, for now i'm going to assume that i'm working on a fixed time step of one and i'll be fine for now.

449
01:07:28,830 --> 01:07:29,340
Michael Akira Lee Hayashi: So.

450
01:07:30,480 --> 01:07:40,890
Michael Akira Lee Hayashi: What do we have to do to simulate the model, such that, for every time step, I get the actual state that a person occupied, not the state distribution, but the actual state.

451
01:08:20,490 --> 01:08:23,040
Michael Akira Lee Hayashi: So one one of the things that.

452
01:08:24,480 --> 01:08:32,790
Michael Akira Lee Hayashi: printing the matrix at each stage, so I don't necessarily actually need to see what the matrix looks like at every stage, because the transition matrix is never going to change.

453
01:08:33,360 --> 01:08:44,430
Michael Akira Lee Hayashi: What is going to change is the state distribution vector because that's that's The thing that actually gets manipulated by all the things that we do for a mark off so.

454
01:08:45,960 --> 01:08:51,150
Michael Akira Lee Hayashi: I probably should also initialize my state distribution vector.

455
01:08:52,170 --> 01:08:56,100
Michael Akira Lee Hayashi: So I could do something like I zero is equal to.

456
01:08:57,210 --> 01:09:00,750
Michael Akira Lee Hayashi: We need a vector of zeros which I can never remember how to do in our.

457
01:09:03,540 --> 01:09:04,170
Michael Akira Lee Hayashi: Google it.

458
01:09:10,530 --> 01:09:11,790
Michael Akira Lee Hayashi: A numerical REP.

459
01:09:13,290 --> 01:09:18,600
Michael Akira Lee Hayashi: can't remember which one I prefer I think i'm going to do a numeric i'm going to do rap because I think this is a little more explicit.

460
01:09:21,870 --> 01:09:23,010
Michael Akira Lee Hayashi: So what's this going to do.

461
01:09:25,410 --> 01:09:25,620
That.

462
01:09:26,700 --> 01:09:33,060
Michael Akira Lee Hayashi: wasn't terribly exciting let's suppose the person starts off as a nonsmoker, which means that Pfizer a one is equal to one.

463
01:09:36,690 --> 01:09:41,400
Michael Akira Lee Hayashi: And we're just going to do a little test to make sure that nothing went completely screwed so.

464
01:09:45,390 --> 01:09:51,420
Michael Akira Lee Hayashi: we're going to need initial state of ooh you know what actually we're gonna we're going to be clever about this initial state.

465
01:09:53,430 --> 01:09:57,600
Michael Akira Lee Hayashi: Air so that we can configure the initial state will see the initial state is one.

466
01:09:58,890 --> 01:10:00,930
Michael Akira Lee Hayashi: And i'm not gonna be sloppy.

467
01:10:03,660 --> 01:10:04,140
Michael Akira Lee Hayashi: that's better.

468
01:10:06,840 --> 01:10:10,680
Michael Akira Lee Hayashi: of tea steps know TIM we're not going to do anything with that just yet.

469
01:10:16,140 --> 01:10:18,540
Michael Akira Lee Hayashi: And let's let's see what this does.

470
01:10:19,680 --> 01:10:33,270
Michael Akira Lee Hayashi: Okay, so we got our initial state vector if I change the initial state to be two or three, we can see that it moves the one down this down the state vector so that's nice that's good that's that's basically what we want.

471
01:10:34,620 --> 01:10:47,190
Michael Akira Lee Hayashi: Now we get to the harder part, now we need the actual simulation so at each time step what I basically need to do is take this matrix multiply it by this vector and that's going to give me the state distribution vector for that timestamp.

472
01:10:48,840 --> 01:10:58,050
Michael Akira Lee Hayashi: And I calling global variables in the function know, and I will never call a global variable in any function I ever right because global variables are the worst.

473
01:10:59,130 --> 01:11:06,660
Michael Akira Lee Hayashi: I will only ever call local variables, to the to the function itself, unless I unless I deeply screw up my writing.

474
01:11:08,520 --> 01:11:12,390
Apostolos Alexandridis: I What I mean is i'm like if you go up to line three.

475
01:11:14,280 --> 01:11:18,720
Apostolos Alexandridis: you're calling in it rate but shouldn't you be calling in it underscore.

476
01:11:19,320 --> 01:11:20,100
Right now.

477
01:11:21,690 --> 01:11:21,990
Michael Akira Lee Hayashi: Yes.

478
01:11:22,830 --> 01:11:25,590
Apostolos Alexandridis: And, and I guess their case sensitive right.

479
01:11:26,220 --> 01:11:28,890
Michael Akira Lee Hayashi: They are the sensitive yes that's embarrassing.

480
01:11:29,310 --> 01:11:37,890
Apostolos Alexandridis: I think what's going on is it's it's not it's it's it's only working because it's it's taking what set globally right.

481
01:11:38,340 --> 01:11:39,000
Michael Akira Lee Hayashi: Yes, it is.

482
01:11:39,390 --> 01:11:40,830
Michael Akira Lee Hayashi: Yes, it is and.

483
01:11:42,240 --> 01:11:53,700
Michael Akira Lee Hayashi: And that is that is me being dumb about this like I said you don't ever escape bugs like that you don't ever escape typos like it literally will haunt me for the rest of my existence.

484
01:11:55,620 --> 01:11:57,990
Michael Akira Lee Hayashi: So i'll fix that again on canvas that's good.

485
01:12:02,160 --> 01:12:02,970
Michael Akira Lee Hayashi: I just can't.

486
01:12:04,320 --> 01:12:05,340
Michael Akira Lee Hayashi: do that today, apparently.

487
01:12:07,020 --> 01:12:11,940
Michael Akira Lee Hayashi: This is what I get for trying to to live code stuff and then change things, while i'm live coding.

488
01:12:19,230 --> 01:12:27,420
Michael Akira Lee Hayashi: Oh, this is also got a dumb little hanger on there that I did not require so let's try this maybe we'll get there, eventually, one day.

489
01:12:34,860 --> 01:12:36,510
Michael Akira Lee Hayashi: How about that that might be better.

490
01:12:37,650 --> 01:12:44,490
Michael Akira Lee Hayashi: I would try to cover for myself and be like Oh, this is a live debugging exercise, no, no, I just I just don't remember if you finish sometimes.

491
01:12:46,050 --> 01:12:48,360
Michael Akira Lee Hayashi: So this has some possibility of actually working.

492
01:12:49,530 --> 01:12:50,670
Michael Akira Lee Hayashi: If it doesn't let me know.

493
01:12:52,620 --> 01:13:03,420
Michael Akira Lee Hayashi: yeah normally I am extremely opposed to ever using global variables there super dangerous so if if it appears that my coach doesn't matter it's almost certainly the made a fairly haynes type.

494
01:13:04,920 --> 01:13:06,900
Michael Akira Lee Hayashi: So let's.

495
01:13:08,730 --> 01:13:18,930
Michael Akira Lee Hayashi: let's write our simulation so we know how many steps we need to take, which means that we can right kind of the outer bit I equal one to two steps.

496
01:13:20,070 --> 01:13:30,660
Michael Akira Lee Hayashi: And again i'm going to do my dumb little check of print I because because i'm awfully paranoid, and you can kind of see the reason i'm paranoid about my own coding because of really prone to typos.

497
01:13:31,530 --> 01:13:36,600
Michael Akira Lee Hayashi: And so i'm just going to confirm that I can actually write a for loop that iterate over the right number of things.

498
01:13:36,840 --> 01:13:48,600
Michael Akira Lee Hayashi: we're not going to worry about putting this anywhere, yet we will we'll put the result of this somewhere in a bit, but for the moment let's just get the simulation to work, so we know that on the first step, we need to do is.

499
01:13:53,850 --> 01:13:55,530
Michael Akira Lee Hayashi: A pi zero.

500
01:13:58,230 --> 01:14:01,980
Michael Akira Lee Hayashi: n pi really so let's um.

501
01:14:04,110 --> 01:14:11,070
Michael Akira Lee Hayashi: i'm going to be needlessly explicit again and do this so before I start the loop i'm going to do fi equals pi zero.

502
01:14:12,330 --> 01:14:13,350
Michael Akira Lee Hayashi: Just so that this.

503
01:14:20,190 --> 01:14:29,670
Michael Akira Lee Hayashi: Could I have named this thing pie, yes I didn't because I am trying to be explicit to also pronoun extra typos.

504
01:14:30,750 --> 01:14:33,030
Michael Akira Lee Hayashi: So we need a matrix vector multiply a.

505
01:14:34,440 --> 01:14:37,020
Michael Akira Lee Hayashi: And pie at every time step.

506
01:14:38,280 --> 01:14:46,830
Michael Akira Lee Hayashi: So well let's let's Google that one I think I remember that there's actually a sneaky special operator that will do this.

507
01:14:50,040 --> 01:14:55,650
Michael Akira Lee Hayashi: It is that'd be nice stack overflow Oh, there is okay so.

508
01:14:57,660 --> 01:14:59,940
Michael Akira Lee Hayashi: It turns out conveniently that.

509
01:15:02,310 --> 01:15:08,760
Michael Akira Lee Hayashi: This special operator performs matrix multiplication or matrix vector multiplication.

510
01:15:10,230 --> 01:15:12,060
Michael Akira Lee Hayashi: that's awfully Nice because.

511
01:15:13,110 --> 01:15:22,320
Michael Akira Lee Hayashi: an operator in this case is kind of handy or than a function or it's it's it's clean, so what I could do is something like pie next is equal to a.

512
01:15:24,780 --> 01:15:27,000
Michael Akira Lee Hayashi: And now I could do something like.

513
01:15:29,040 --> 01:15:29,640
Michael Akira Lee Hayashi: pie.

514
01:15:33,090 --> 01:15:33,810
Michael Akira Lee Hayashi: Time next.

515
01:15:34,830 --> 01:15:35,760
Michael Akira Lee Hayashi: While this thing is running.

516
01:15:36,870 --> 01:15:38,640
Michael Akira Lee Hayashi: Oh, this is going to be this is going to be fairly.

517
01:15:40,230 --> 01:15:41,010
Good that's Nice.

518
01:15:43,230 --> 01:15:43,650
Michael Akira Lee Hayashi: So.

519
01:15:45,330 --> 01:15:49,920
Michael Akira Lee Hayashi: These results are going to be rather stupid, for now, but but it's it's fine This is fine.

520
01:15:51,990 --> 01:16:03,420
Michael Akira Lee Hayashi: So here's what here's what we've got so first we printed pie, this is 100 pine next is this, I should probably confirm that this is right, but I don't need to accidentally trance.

521
01:16:05,430 --> 01:16:08,400
Michael Akira Lee Hayashi: transpose anything but I think we're okay.

522
01:16:11,100 --> 01:16:16,380
Michael Akira Lee Hayashi: Because our state vector should be 100 our transition matrix is.

523
01:16:17,670 --> 01:16:18,210
Michael Akira Lee Hayashi: scroll up.

524
01:16:20,070 --> 01:16:24,720
Michael Akira Lee Hayashi: Is this thing, so what we're trying to extract essentially is the first column.

525
01:16:25,440 --> 01:16:38,370
Michael Akira Lee Hayashi: Of this matrix and that does seem to be what came out when we did our matrix vector multiplication, this is indeed the first column of our transition matrix again i'm not doing anything with this so it's not going to go anywhere but.

526
01:16:39,090 --> 01:16:49,410
Michael Akira Lee Hayashi: This is, this is a good amount of the heavy lifting one problem, though, is that what i've gotten is a state distribution vector I don't yet know what the actual state at the next time point is.

527
01:16:49,620 --> 01:16:56,790
Michael Akira Lee Hayashi: If I wanted to do that, what would, I have to do from the state distribution vector to essentially forced this thing to manifest a given state.

528
01:17:05,730 --> 01:17:08,520
Michael Akira Lee Hayashi: As a hint we can think about this as a probability distribution.

529
01:17:45,360 --> 01:17:50,730
Michael Akira Lee Hayashi: Well, one thing I could do is sample from this probability distribution, I could draw a random number.

530
01:17:52,170 --> 01:17:58,350
Michael Akira Lee Hayashi: That takes a specific value, depending on whether any of these things are true.

531
01:17:59,730 --> 01:18:05,130
Michael Akira Lee Hayashi: So what I could do, for example, is suppose I have another vector that's comprised of.

532
01:18:06,330 --> 01:18:15,450
Michael Akira Lee Hayashi: one, two and three, this is what's stored in the vector one gets sampled with probability point nine five to get samples of probability point oh five and three never give samples.

533
01:18:16,830 --> 01:18:36,030
Michael Akira Lee Hayashi: If I draw from this bucket using these probability weights that will tell me what actual state i'm in at the current time, so to do that i'm going to eat and i'm going to need to use a little bit of extra stuff in our so, in particular, I think there's probably a sample function.

534
01:18:38,100 --> 01:18:44,160
Michael Akira Lee Hayashi: And there does appear to be, and this sample function if I wade through the documentation takes a couple of different artists.

535
01:18:45,270 --> 01:18:49,770
Michael Akira Lee Hayashi: takes a variable X, which is a vector of elements from which to sample.

536
01:18:50,850 --> 01:18:54,120
Michael Akira Lee Hayashi: But it also can take a probability vector.

537
01:18:55,980 --> 01:19:04,680
Michael Akira Lee Hayashi: With weights, with the probability weights governing what the probability of drawing any given one of those elements in this vector once it can also do this with or without replacement.

538
01:19:05,010 --> 01:19:12,480
Michael Akira Lee Hayashi: by default, it does not sample with replacement, which can be a gotcha on these things if you need to draw multiple multiple ones of these.

539
01:19:13,230 --> 01:19:32,160
Michael Akira Lee Hayashi: You may or may not want sample with or without replacement So be careful with that, but for the time being, what if I did so cute next number Q, is our name for the next state is going to be sampled and create a little vector because these are going to be the indices of the States.

540
01:19:33,450 --> 01:19:39,210
Michael Akira Lee Hayashi: With prob equal to pi next i'm gonna look out what Q next is.

541
01:19:43,590 --> 01:19:45,480
Michael Akira Lee Hayashi: And we'll see what comes out of this thing.

542
01:19:46,890 --> 01:19:48,090
Michael Akira Lee Hayashi: run oh.

543
01:19:50,610 --> 01:19:55,590
Michael Akira Lee Hayashi: Did I do something, probably too few positive probability, what is the next.

544
01:20:00,030 --> 01:20:00,180
Oh.

545
01:20:04,380 --> 01:20:07,350
Michael Akira Lee Hayashi: Maybe you have to transform variable not know some K.

546
01:20:12,390 --> 01:20:16,440
Michael Akira Lee Hayashi: Do I need to tell it, how many things to sample maybe it requires that argument.

547
01:20:18,840 --> 01:20:38,370
Michael Akira Lee Hayashi: Oh that's bizarre that is really weird apparently N, is a non optional argument here so i'm taking one sample from this thing with this probability distribution, and you can see that, having run this thing several times by enlarge this thing.

548
01:20:40,170 --> 01:20:41,010
Michael Akira Lee Hayashi: Take this out.

549
01:20:42,300 --> 01:20:50,700
Michael Akira Lee Hayashi: By and large, this thing is returning one, so what that means is that most of the times this thing runs what we draw for the next state is.

550
01:20:51,000 --> 01:21:03,150
Michael Akira Lee Hayashi: Never smoker we don't change states, because not changing State had about a 94% probability, so this seems Okay, and if I were to run this thing out longer maybe eventually we'd get we get a change.

551
01:21:04,650 --> 01:21:11,520
Michael Akira Lee Hayashi: Every every so often this thing will will change oh so we're getting it right now we know what the next.

552
01:21:13,740 --> 01:21:29,160
Michael Akira Lee Hayashi: What the next actual state is so the rest of the work here is updating variables that we created already, so we need to update our pie, for example, so let's let's reset pie is equal to wrap 03.

553
01:21:30,000 --> 01:21:39,390
Michael Akira Lee Hayashi: Then we're going to set ty Q next equal to one, because this is going to correspond to the State i'm going to start documenting this so.

554
01:21:54,630 --> 01:21:55,140
Michael Akira Lee Hayashi: one.

555
01:21:56,700 --> 01:21:57,420
Michael Akira Lee Hayashi: And then.

556
01:21:58,500 --> 01:21:58,950
Michael Akira Lee Hayashi: That.

557
01:22:00,750 --> 01:22:10,350
Michael Akira Lee Hayashi: That might actually be enough, because the main thing that we're updating here is high, so let's see.

558
01:22:11,400 --> 01:22:16,080
Michael Akira Lee Hayashi: let's print pie, as we go through this loop let's print pie at the beat getting it.

559
01:22:18,330 --> 01:22:28,560
Michael Akira Lee Hayashi: I might be doing something slightly dangerous your pie might be a reserved keyboard in are reserved keyword in our and I honestly can't remember, so if something causes strange stuff that could.

560
01:22:31,020 --> 01:22:32,220
Michael Akira Lee Hayashi: Okay, so.

561
01:22:33,690 --> 01:22:38,610
Michael Akira Lee Hayashi: This is interesting, so if we look at our state distribution vector we go from.

562
01:22:39,450 --> 01:22:55,050
Michael Akira Lee Hayashi: Former former former never, never, never, never current we stay in current for a bit, then we quit for a bit we go back to current then we bounce back and forth between current and former so on the face of it, this kind of looks like it is actually behaving as it is supposed to.

563
01:22:56,340 --> 01:23:09,450
Michael Akira Lee Hayashi: also note that we never go back to never smoked or so that is a suggestion that our code is actually worked so here we have most of the legwork finished we don't quite have a sensible output, yet, but.

564
01:23:10,920 --> 01:23:15,810
Michael Akira Lee Hayashi: But we'll get there, so now we basically just need the output factors so.

565
01:23:16,890 --> 01:23:21,780
Michael Akira Lee Hayashi: i'm going to do this and slightly dumb format so let's do this.

566
01:23:28,230 --> 01:23:38,040
Michael Akira Lee Hayashi: output is equal to know I don't know I don't know I want to do this and do this iterative Lee and I don't like it, but i'm going to do it anyway.

567
01:23:41,130 --> 01:23:41,790
Michael Akira Lee Hayashi: So.

568
01:23:43,530 --> 01:23:46,680
Michael Akira Lee Hayashi: output equals in a state.

569
01:23:48,390 --> 01:23:49,140
Michael Akira Lee Hayashi: That.

570
01:23:51,720 --> 01:24:02,040
Michael Akira Lee Hayashi: Do this equals C out foot cube next so i'm just concatenate in the next state on to output and the very end of this.

571
01:24:03,390 --> 01:24:04,440
Michael Akira Lee Hayashi: going to return output.

572
01:24:06,120 --> 01:24:07,080
Michael Akira Lee Hayashi: And then we're going to print.

573
01:24:08,550 --> 01:24:10,380
Michael Akira Lee Hayashi: And we'll see what comes out of that business.

574
01:24:11,730 --> 01:24:18,690
Michael Akira Lee Hayashi: So here we have what looks a whole lot to me like an actual state trajectory through our system, and if we run this.

575
01:24:19,200 --> 01:24:27,990
Michael Akira Lee Hayashi: Over and over again, will notice that we get different state trajectories that we stay in some sense, one of the main differences is how long we stay in the never smelter state.

576
01:24:30,270 --> 01:24:38,850
Michael Akira Lee Hayashi: And so what we have here is actually a fully functioning discrete time market model it's smoking States just in time for the break, which is amazing timing.

577
01:24:40,860 --> 01:24:48,840
Michael Akira Lee Hayashi: So we'll come back and maybe talk through additional questions or things like that about the model structure talk through some additional things you can do with models like this.

578
01:24:49,080 --> 01:24:59,220
Michael Akira Lee Hayashi: If you have any quick questions now i'm happy to take one before we break, otherwise we can we'll break and then come back in 15 minutes and keep working through some of this some of this stuff.

579
01:25:13,590 --> 01:25:20,250
Michael Akira Lee Hayashi: Alright well there being no questions let's break for 15 minutes and i'll see you again shortly book season that.

580
01:25:21,540 --> 01:25:26,190
Michael Akira Lee Hayashi: thing and put it back on canvas where it was so hopefully that one works now.

581
01:25:27,450 --> 01:25:27,660
To.

582
01:25:29,400 --> 01:25:34,350
Michael Akira Lee Hayashi: This essentially is what I get for using a lot of copy paste it's always it's always dangerous.

583
01:25:36,210 --> 01:25:41,730
Michael Akira Lee Hayashi: So that's fun, I should also probably put the little.

584
01:25:42,990 --> 01:25:47,700
Michael Akira Lee Hayashi: Environment wiper at the top of my thing, so I can be a little bit more careful about.

585
01:25:50,130 --> 01:25:59,820
Michael Akira Lee Hayashi: about making sure that I don't leave junk in the global environment, which only ever causes problems we put this here it is.

586
01:26:01,470 --> 01:26:01,740
there.

587
01:26:04,080 --> 01:26:04,560
that's better.

588
01:26:05,730 --> 01:26:14,790
Michael Akira Lee Hayashi: Alright, so now that we're back, are there any questions so far about the way that we implemented the simulation procedure for our mark off model.

589
01:26:23,550 --> 01:26:36,030
Caroline Godfrey: i'm assuming eventually we'll get into like it seems like when we simulated it there, we were just simulating how one person moves through the environment and which isn't really necessarily helpful in terms of using.

590
01:26:37,260 --> 01:26:43,740
Caroline Godfrey: The model like you want more of like an aggregate of how a large cohort would move through the model will be good into that.

591
01:26:44,490 --> 01:26:47,370
Michael Akira Lee Hayashi: yeah we can we'll take a look at that right now in.

592
01:26:47,370 --> 01:26:48,180
Caroline Godfrey: fact so.

593
01:26:48,510 --> 01:26:53,250
Michael Akira Lee Hayashi: There are there are kind of two ways to come at this one so.

594
01:26:54,780 --> 01:26:58,770
Michael Akira Lee Hayashi: And the choice of them kind of depends on how large of a population you wants to simulate.

595
01:27:02,100 --> 01:27:07,020
Michael Akira Lee Hayashi: Well, you know what no I take that back it actually does not matter a bit.

596
01:27:08,940 --> 01:27:11,970
Michael Akira Lee Hayashi: There are still two ways to come at this and.

597
01:27:13,140 --> 01:27:18,810
Michael Akira Lee Hayashi: And I think I have a preference for one of the two for elegance sake, but that is to say.

598
01:27:19,380 --> 01:27:29,400
Michael Akira Lee Hayashi: There are multiple ways to roam here, one would be to essentially like each time we simulate this thing we get a vector corresponding to one person's trajectory through this thing.

599
01:27:29,640 --> 01:27:38,640
Michael Akira Lee Hayashi: So it'd be pretty straightforward to just do this, a bunch of times or each of those is an individual person, so we could we could, for example.

600
01:27:40,650 --> 01:27:41,310
Michael Akira Lee Hayashi: We could.

601
01:27:48,990 --> 01:27:56,730
Michael Akira Lee Hayashi: Obviously this is going to be rather silly because i'm not putting the output anywhere in particular, but you get the idea we could do this.

602
01:27:57,810 --> 01:28:04,020
Michael Akira Lee Hayashi: And i'm printing too much that's one thing here that's going to make this little bit gross.

603
01:28:05,550 --> 01:28:09,570
Michael Akira Lee Hayashi: Anyway, we can do this, and now this.

604
01:28:10,830 --> 01:28:15,450
Michael Akira Lee Hayashi: This has trajectories for multiple people I could be a little bit cleaner, that is this.

605
01:28:23,640 --> 01:28:26,280
Michael Akira Lee Hayashi: Oh i'm not sharing screen that's yes, thank you.

606
01:28:28,320 --> 01:28:30,120
Michael Akira Lee Hayashi: So I could I could write a little for loop here.

607
01:28:31,980 --> 01:28:32,220
Michael Akira Lee Hayashi: and

608
01:28:34,650 --> 01:28:42,300
Michael Akira Lee Hayashi: And here we can see that it has simulated five people who have slightly different trajectories sometimes quite different trajectories.

609
01:28:42,810 --> 01:28:49,860
Michael Akira Lee Hayashi: So this is one way, we could do all this unfortunate, so this is one way, we could we could get it that sort of.

610
01:28:50,580 --> 01:29:04,920
Michael Akira Lee Hayashi: need to simulate a larger population thing but it probably won't surprise you that this way is fairly clunky if we needed to simulate a really big population i'm not going to do this, but needless to say.

611
01:29:06,000 --> 01:29:11,100
Michael Akira Lee Hayashi: This could cause us to to be running the model for a rather long time so.

612
01:29:12,210 --> 01:29:20,730
Michael Akira Lee Hayashi: Maybe we maybe we don't particularly want to to do that, instead, maybe, what we want to do is simulate a.

613
01:29:21,690 --> 01:29:28,170
Michael Akira Lee Hayashi: simulate population proportions and if that's the case then instead of using this particular simulation routine.

614
01:29:29,010 --> 01:29:44,790
Michael Akira Lee Hayashi: We can use the one where we just take the transition matrix multiply it by the State distribution vector which represents the population distribution across different states and then let that go for a while, so one way, we could do this i'm going to call this simulate individual.

615
01:29:47,160 --> 01:29:49,350
Michael Akira Lee Hayashi: and, similarly, when this call is made.

616
01:29:50,760 --> 01:29:54,630
Michael Akira Lee Hayashi: that's how it's going to look but let's do this another way so simulate.

617
01:29:57,570 --> 01:30:00,240
Michael Akira Lee Hayashi: portions, and this is going to be.

618
01:30:01,470 --> 01:30:04,380
Michael Akira Lee Hayashi: Really, no meaningfully different from.

619
01:30:05,700 --> 01:30:11,490
Michael Akira Lee Hayashi: Well, the the function definition is not going to look a full time different, but some of the other stuff gets in here so.

620
01:30:14,310 --> 01:30:16,440
Michael Akira Lee Hayashi: Our initial state we're going to.

621
01:30:17,790 --> 01:30:28,170
Michael Akira Lee Hayashi: we're going to leave as it is for now and we'll deal with that later so first we can i'm going to copy paste it's probably not gonna come back to bite me that's fine.

622
01:30:29,490 --> 01:30:31,950
Michael Akira Lee Hayashi: A couple of days, all of us, and probably isn't going to come back to bite me.

623
01:30:33,720 --> 01:30:43,890
Michael Akira Lee Hayashi: Okay let's try that so this should initialize things notice that for the moment i'm still what i'm doing here is i'm initializing this as though it is, it is a synthetic.

624
01:30:44,190 --> 01:30:53,280
Michael Akira Lee Hayashi: Birth cohort essentially so everyone is going to be starting in a non smoking stage and we're going to progress through the model accordingly.

625
01:30:54,750 --> 01:30:58,560
Michael Akira Lee Hayashi: The for loop is really where things start to look a little different so.

626
01:31:00,660 --> 01:31:02,490
Michael Akira Lee Hayashi: I can one.

627
01:31:05,070 --> 01:31:08,010
Michael Akira Lee Hayashi: that's will do right our loop here.

628
01:31:09,570 --> 01:31:13,560
Michael Akira Lee Hayashi: Some of this is going to look pretty similar so we're going to do.

629
01:31:16,560 --> 01:31:18,030
Michael Akira Lee Hayashi: It next equals.

630
01:31:19,830 --> 01:31:27,480
Michael Akira Lee Hayashi: A special multiplication by pie, but then really what we want to do is reassign.

631
01:31:29,160 --> 01:31:38,580
Michael Akira Lee Hayashi: It next year, and this is kind of it, this is really all we need to do to simulate the the proportion version because we're just updating the.

632
01:31:39,060 --> 01:31:48,450
Michael Akira Lee Hayashi: The State distribution vector at every time step under the assumption that the State distribution vector reflects the proportion of the population in each state at each time.

633
01:31:48,810 --> 01:31:58,710
Michael Akira Lee Hayashi: Now there is a way to back this up to drawing individual trajectories from that and we'll talk about it after this I may not implemented explicitly there's a few other things I wanted to look at, but.

634
01:31:59,280 --> 01:32:15,600
Michael Akira Lee Hayashi: This is more or less the game, now we probably do want to, we probably do want to put this in some kind of output matrix so i'm gonna i'm going to change this around a little bit so now we're going to make an output matrix which is like matrix it's going to be.

635
01:32:17,010 --> 01:32:32,250
Michael Akira Lee Hayashi: T steps plus one rows and three columns and I think that's right i've counted right which is always a it's always a thing output one comma is going to be pi zero.

636
01:32:33,390 --> 01:32:35,160
Michael Akira Lee Hayashi: Starting state and then.

637
01:32:37,560 --> 01:32:40,140
Michael Akira Lee Hayashi: What we're gonna do is output.

638
01:32:41,280 --> 01:32:44,730
Michael Akira Lee Hayashi: I plus one is going to be.

639
01:32:45,870 --> 01:32:46,410
Michael Akira Lee Hayashi: pie.

640
01:32:48,030 --> 01:32:51,630
Michael Akira Lee Hayashi: And we'll see what comes out of this version I think this should be enough to make it go.

641
01:32:54,150 --> 01:32:59,880
Michael Akira Lee Hayashi: we'll see if i've got an overly cocky about my ability to do this so we'll get rid of this we don't actually need this right now.

642
01:33:03,390 --> 01:33:05,700
Michael Akira Lee Hayashi: yeah just have completion that's Nice.

643
01:33:07,140 --> 01:33:22,290
Michael Akira Lee Hayashi: And it state let's say that everybody missed this is a birth cohort everyone starts off there, I will talk through ways to change this if we don't want to do that anymore, but for the moment let's hope that we're going to simulate the birth cohort for 80 years.

644
01:33:27,690 --> 01:33:30,510
Michael Akira Lee Hayashi: And that everything I need, I think so, and then we're gonna.

645
01:33:32,550 --> 01:33:37,560
Michael Akira Lee Hayashi: see if it breaks it broke Okay, where did this a break.

646
01:33:43,290 --> 01:33:44,730
Michael Akira Lee Hayashi: Now, did I know.

647
01:33:46,650 --> 01:33:47,340
Michael Akira Lee Hayashi: Did I.

648
01:33:50,040 --> 01:34:05,580
Michael Akira Lee Hayashi: Not multiple of replacement well let's let's examine, to see what I did wrong here print I zero 10 French actually I should do this before I do that because it's going to we know it's going to break it this line, so we don't want to run.

649
01:34:07,620 --> 01:34:11,190
Michael Akira Lee Hayashi: So what have I done here, oh that looks.

650
01:34:12,690 --> 01:34:14,670
Michael Akira Lee Hayashi: That looks questionable oh.

651
01:34:18,240 --> 01:34:24,300
Michael Akira Lee Hayashi: There we go, I did not tell my matrix what to fill itself with start ups, however.

652
01:34:26,880 --> 01:34:38,970
Michael Akira Lee Hayashi: What we do end up with after we run this thing, this is the population trajectories effective right, this is, this is a matrix containing the state distribution vectors for every time step.

653
01:34:39,510 --> 01:34:46,680
Michael Akira Lee Hayashi: So we can see the proportion equivalent of the population that occupies each State, so if I wanted to do something like.

654
01:34:47,910 --> 01:34:50,430
Michael Akira Lee Hayashi: Let me see if I can do a very simple plot.

655
01:34:52,110 --> 01:34:53,940
Michael Akira Lee Hayashi: is going to be isn't it interesting.

656
01:34:55,350 --> 01:35:09,090
Michael Akira Lee Hayashi: out all rose calm one let's see if this is the thing okay so here is the state trajectory or the proportion of the population that is never smoker over the years of the first cohort.

657
01:35:13,470 --> 01:35:20,670
Michael Akira Lee Hayashi: So to recap what i'm explaining for this method is the fact that the State distribution vector from this model at any given time.

658
01:35:20,940 --> 01:35:30,540
Michael Akira Lee Hayashi: Is equivalent Lee the probability that a single person occupies any of those states in the model never smoked or current smoker former smoker or.

659
01:35:31,050 --> 01:35:37,740
Michael Akira Lee Hayashi: The proportion of the population for some population that occupies each of those States never current former.

660
01:35:38,160 --> 01:35:52,530
Michael Akira Lee Hayashi: And by exploiting that equivalency I get a really, really simple simulation loop, in order to simulate an entire population with this market model, and this is a statistically proper trajectory from this model I could draw.

661
01:35:52,980 --> 01:36:03,420
Michael Akira Lee Hayashi: An individual person at any given time here from the probability distribution given by the State distribution vector at that time and they would be properly drawn from.

662
01:36:03,870 --> 01:36:14,430
Michael Akira Lee Hayashi: A population of people subject to these dynamics so that's kind of cool that that's Nice because this is a really simple simulation algorithm, so this is about as Nice as it gets.

663
01:36:17,970 --> 01:36:18,840
Michael Akira Lee Hayashi: Questions at this point.

664
01:36:28,200 --> 01:36:41,580
Michael Akira Lee Hayashi: I suppose the other thing i'm implicitly exploiting is the fact that the transition matrix is time homogenous so it will never change over the entire course of the simulation, which means that I don't ever have to do any weird updating here.

665
01:36:44,070 --> 01:36:53,640
Michael Akira Lee Hayashi: And the only thing that's ever really changing is the state distribution vector, which is only ever updating by that transition matrix time state distribution vector multiplication process.

666
01:36:54,180 --> 01:36:58,710
Michael Akira Lee Hayashi: Which is, which is very, very simple it is possible to have a time in homogenous.

667
01:36:59,310 --> 01:37:07,650
Michael Akira Lee Hayashi: State transition matrix if, for example, you're suspicious, to the fact that this ran for 80 years without any change in any of the of the.

668
01:37:07,980 --> 01:37:13,740
Michael Akira Lee Hayashi: Transition probabilities what you could do is make it you could give the thing multiple.

669
01:37:14,430 --> 01:37:23,580
Michael Akira Lee Hayashi: State transition matrices or another way of thinking about that is essentially a four dimensional state transition matrix such that each each.

670
01:37:24,480 --> 01:37:36,180
Michael Akira Lee Hayashi: Each square sorry no a three dimensional one such that each square in the in the three dimensional matrix corresponds to some amount of time in the simulation so maybe you have one Square.

671
01:37:36,690 --> 01:37:41,040
Michael Akira Lee Hayashi: That you use, for the first 10 years, then another one for the next 10 and so on.

672
01:37:41,610 --> 01:37:48,360
Michael Akira Lee Hayashi: As long as you have an additional data structure that tells you when to switch transition matrices.

673
01:37:48,630 --> 01:37:53,520
Michael Akira Lee Hayashi: Basically, the rest of this will continue to work you just have to have a little bit of fiddling to do with the.

674
01:37:53,760 --> 01:38:01,020
Michael Akira Lee Hayashi: Specific variable you choose, you have a little more logic to keep track of to make sure that you do actually update your transition matrix when you need to.

675
01:38:01,350 --> 01:38:09,600
Michael Akira Lee Hayashi: But a lot of the fundamental guts remain the same so there's not a whole lot of fuss needed to do something like that to better take into account.

676
01:38:09,990 --> 01:38:19,980
Michael Akira Lee Hayashi: Potential changes or perturbations in the system like the biggest one would probably be suppose I want to run the system for 10 years change some policy which changes, one of these fundamental rates.

677
01:38:20,400 --> 01:38:32,160
Michael Akira Lee Hayashi: And then keep running the system there is actually a way to hack that which is, which is a bit dumb but which is totally legal you could run the system, you could run this model for 10 years and then.

678
01:38:32,970 --> 01:38:38,460
Michael Akira Lee Hayashi: output, whatever the state distribution vector was it 10 years give it a new trends like.

679
01:38:39,270 --> 01:38:51,000
Michael Akira Lee Hayashi: call this function again with a different transition matrix that has different rates and then run that one for the rest of your simulation time which is effectively the same thing it's just slightly happier, because you do like a.

680
01:38:51,240 --> 01:38:56,850
Michael Akira Lee Hayashi: Start change something or start stop change some things start stop still legal just.

681
01:38:58,170 --> 01:38:59,040
Michael Akira Lee Hayashi: A little less elegant.

682
01:39:00,540 --> 01:39:01,470
Michael Akira Lee Hayashi: But it does work.

683
01:39:07,260 --> 01:39:11,520
Michael Akira Lee Hayashi: The other questions at this point, why try to remember what I was thinking of next.

684
01:39:13,740 --> 01:39:16,530
Nicolle Krebs: So the plot is.

685
01:39:17,940 --> 01:39:19,710
Nicolle Krebs: The first column correct.

686
01:39:20,280 --> 01:39:21,840
Michael Akira Lee Hayashi: Yes, the matrix.

687
01:39:22,230 --> 01:39:31,980
Nicolle Krebs: And so, is that basically saying about 1% of the population by 80 years is going to.

688
01:39:33,240 --> 01:39:34,620
Nicolle Krebs: Stay a nonsmoker.

689
01:39:35,220 --> 01:39:35,760
Yes.

690
01:39:37,140 --> 01:39:43,200
Michael Akira Lee Hayashi: yeah but and specifically about 1% of the population, never started smoking at all.

691
01:39:46,650 --> 01:39:48,750
Michael Akira Lee Hayashi: One one thing that is a little trickier about the.

692
01:39:48,750 --> 01:39:57,720
Michael Akira Lee Hayashi: interpretation here is that these are essentially prevalence is so this is the prevalence of all of these states at the final year at your age.

693
01:40:00,120 --> 01:40:04,290
Michael Akira Lee Hayashi: So if you wanted to know, for example, how many people.

694
01:40:05,130 --> 01:40:14,490
Michael Akira Lee Hayashi: Ever passed through this state that is a trickier bit of accounting to do, and that would take more logic to actually counter, for example, if you wanted to know how many people ever started smoking.

695
01:40:14,910 --> 01:40:21,240
Michael Akira Lee Hayashi: That actually is a little bit harder, because you need to keep track of every time someone transits into the smoking states.

696
01:40:22,920 --> 01:40:41,070
Michael Akira Lee Hayashi: and so on, so that is, that is a slight limitation to modeling in this structure that you essentially are modeling prevalence overtime and that does sometimes lose a little bit of Resolution on some of the specific events that happened like this the individual simulation method.

697
01:40:42,300 --> 01:40:55,350
Michael Akira Lee Hayashi: This one was kind of Nice because you follow one person, you know exactly what happened to them, so you know how long they smoked in their life, because if you run this model, you can just sum up all the times that their trajectory was a two.

698
01:40:55,830 --> 01:41:03,990
Michael Akira Lee Hayashi: And then you know the total smoking time for that first and that's cool because that's a measure that that we use for for outcomes and things.

699
01:41:05,820 --> 01:41:10,980
Michael Akira Lee Hayashi: But with this population model you do lose that degree of resolutions.

700
01:41:22,020 --> 01:41:23,070
Michael Akira Lee Hayashi: Any other questions.

701
01:41:42,030 --> 01:41:49,770
Michael Akira Lee Hayashi: Alright, so that is that essentially is implementation and simulation for a fairly straightforward discrete time market.

702
01:41:51,510 --> 01:41:57,270
Michael Akira Lee Hayashi: Which is in fact a broader class of models and it might seem like you can do a lot with these models so.

703
01:41:59,190 --> 01:42:08,670
Michael Akira Lee Hayashi: Supposedly didn't think that these are the only three things that can happen in the system suppose we didn't think that never smoker current smoker former smoker were the only states of person can occupy.

704
01:42:09,030 --> 01:42:18,810
Michael Akira Lee Hayashi: that's not terribly hard change really all it is, is a change in the construction of the transition matrix for the system so that we correctly define the number of states that we have.

705
01:42:19,230 --> 01:42:27,450
Michael Akira Lee Hayashi: As well as the way that people transit through and between those states, we can make this transition matrix as big as we want it to be a kind of doesn't matter.

706
01:42:27,900 --> 01:42:40,350
Michael Akira Lee Hayashi: I mean it's going to take more time to run but there's nothing about the framework that means that we're restricted to these small little toy models that only have a few states, we could do something big I i've used these for like.

707
01:42:41,340 --> 01:42:48,990
Michael Akira Lee Hayashi: A little testing of like pauly tobacco stuff where you transit through multiple use categories and things like that and that's a bigger matrix by far.

708
01:42:49,890 --> 01:42:59,820
Michael Akira Lee Hayashi: And it's a more complicated one to estimate and it's more complicated one to work with, but the fundamental machinery of the simulation and everything just doesn't change a whole lot it's still like.

709
01:43:00,960 --> 01:43:08,970
Michael Akira Lee Hayashi: there's only a few things here that are kind of hard coded to the size of this system, one of them, which, if I were doing this in the more general form is.

710
01:43:09,210 --> 01:43:16,710
Michael Akira Lee Hayashi: The size of the initial vector and the size of the output matrix This obviously would change size for a bigger system but.

711
01:43:17,100 --> 01:43:22,170
Michael Akira Lee Hayashi: that's about it there's not a whole lot in here which cares very specifically about the system we're looking at.

712
01:43:22,410 --> 01:43:27,060
Michael Akira Lee Hayashi: The event rates, yes, those are linked to the specific events that we think happen in the system.

713
01:43:27,330 --> 01:43:39,720
Michael Akira Lee Hayashi: But that's not hard to change out, we could add more we could be a little more generic and write these into a vector so that the system just reads event rates, out of a vector and does some other fancy stuff to figure out what your vents those correspond to but.

714
01:43:40,890 --> 01:43:50,550
Michael Akira Lee Hayashi: there's there's not a whole ton of magic here like one of the nice things about writing and implementing some of these models, especially writing implementing Markov models is that.

715
01:43:50,790 --> 01:44:03,720
Michael Akira Lee Hayashi: The framework is really, really generalizable so like you could add almost whatever states you wanted, as long as you still hold the system maintains the mark off property of being memories.

716
01:44:05,880 --> 01:44:16,530
Michael Akira Lee Hayashi: So this sort of code and the the DEMO code that's up on canvas the actual file the one I think that i've called smoking history markup model code on campus under lab to.

717
01:44:17,550 --> 01:44:22,920
Michael Akira Lee Hayashi: That has the model example and also a little bit of extra stuff to.

718
01:44:24,060 --> 01:44:28,350
Michael Akira Lee Hayashi: to simulate a bunch of people and then calculate the total number of smoking years.

719
01:44:28,860 --> 01:44:39,960
Michael Akira Lee Hayashi: For people in that model, so you can look at some of that to see how we might get some of those other pieces of information, but also to see, for example, how I might have run this model if I wanted to simulate a big population.

720
01:44:41,130 --> 01:44:52,950
Michael Akira Lee Hayashi: Using the individual simulation methods, so I could get more individual level data like how long how many smoking years to each person contribute there so that's available as well if you're interested.

721
01:44:57,300 --> 01:45:03,390
Michael Akira Lee Hayashi: What i'd like to do, while we're maybe processing a little bit is I did want to talk a little bit about.

722
01:45:03,810 --> 01:45:15,330
Michael Akira Lee Hayashi: kind of the utility or or caveats or things like that related to using Markov models in some of our research domains are using using stochastic models in general in our research domains so.

723
01:45:15,720 --> 01:45:17,850
Michael Akira Lee Hayashi: i'd like it if you could kind of think about.

724
01:45:18,720 --> 01:45:23,580
Michael Akira Lee Hayashi: Think about research problems that you're interested in that could use a systems modeling approach and.

725
01:45:23,850 --> 01:45:37,620
Michael Akira Lee Hayashi: and think a bit about whether something like a market model would or would not be appropriate for folks that are doing Tobacco Research, this is probably fairly easy because we have a lot of stuff handy for that, but but i'm broadly interested to hear sort of.

726
01:45:39,720 --> 01:45:51,180
Michael Akira Lee Hayashi: Where you Where are you think these sorts of methods have good applications what, what do you think might be hard for them, if there are areas where you're not sure if this would be an appropriate method things like that.

727
01:45:58,920 --> 01:46:11,010
Michael Akira Lee Hayashi: For concreteness we could certainly start in the tobacco realm and think about things like if you wanted to extend a model like this to be more realistic What would you care about what is this missing is often a good place to start.

728
01:46:20,040 --> 01:46:21,780
Michael Akira Lee Hayashi: i'll just quickly read diagram the model.

729
01:46:44,610 --> 01:46:56,940
Caroline Godfrey: You might want to like separate and people who relapse from current smokers because they might have a different probability of attempting to quit again and therefore becoming.

730
01:46:58,320 --> 01:46:59,490
Caroline Godfrey: Former smokers again.

731
01:47:00,030 --> 01:47:01,290
Caroline Godfrey: yeah you're looking for.

732
01:47:01,830 --> 01:47:05,220
Michael Akira Lee Hayashi: yeah stuff like that, so let me actually move over to a whiteboard so you don't have all.

733
01:47:05,220 --> 01:47:05,430
Michael Akira Lee Hayashi: The.

734
01:47:05,490 --> 01:47:07,200
Michael Akira Lee Hayashi: junk from the rest of my screen here.

735
01:47:08,460 --> 01:47:12,390
Michael Akira Lee Hayashi: So we started here what's a different color okay.

736
01:47:15,270 --> 01:47:17,610
Michael Akira Lee Hayashi: warmer, this is what we look like right now.

737
01:47:18,840 --> 01:47:20,160
Michael Akira Lee Hayashi: We could do something like.

738
01:47:22,500 --> 01:47:30,030
Michael Akira Lee Hayashi: Dividing current smokers into current and like never relapsed and relapsed something like this.

739
01:47:31,050 --> 01:47:33,270
Michael Akira Lee Hayashi: So you do this kind of business.

740
01:47:36,090 --> 01:47:41,520
Michael Akira Lee Hayashi: Something like this sort of system that could be a thing, and that would change some of the dynamics, the system.

741
01:47:42,600 --> 01:47:44,880
Michael Akira Lee Hayashi: I know, someone mentioned before the break.

742
01:47:45,900 --> 01:48:01,200
Michael Akira Lee Hayashi: Experimental use, which is very much a thing so maybe we don't think it's reasonable that, on average, everyone who enters this current smoker compartment stays there for 10 years, maybe we think that some of these initiators are.

743
01:48:02,100 --> 01:48:09,060
Michael Akira Lee Hayashi: going to print pretty quickly stop user they're just not gonna it's not going to take for them, or they might kind of.

744
01:48:11,550 --> 01:48:16,530
Michael Akira Lee Hayashi: They might experiment a few times before, before smoking actually take so we could do something like.

745
01:48:17,730 --> 01:48:26,670
Michael Akira Lee Hayashi: i'm going to keep the neighbors are the non smoker and it's going to change meaning very slick I don't know why they're mine one right now, usually happens later sorry if there's background noise.

746
01:48:27,690 --> 01:48:43,020
Michael Akira Lee Hayashi: So we could have experimenters where the experimenters do actually back float here because they don't stupendously meaningfully change the chance of going into a current smoker stage we could also have the relapse stage here and then something like this.

747
01:48:46,650 --> 01:48:58,980
Michael Akira Lee Hayashi: And you can see that as we add states this This makes the system meaningfully more complicated as we're as we're building things in which means a bigger transition matrix which means longer simulation time, which also means more need to estimate.

748
01:49:00,630 --> 01:49:05,700
Michael Akira Lee Hayashi: What these transition probabilities actually are, which can become complicated.

749
01:49:10,530 --> 01:49:25,170
Michael Akira Lee Hayashi: And, in general I think what I want to emphasize is that as we're doing this, a lot of it really is just a question of adding states to the system and adding well arrows between states, indicating how we move between them for our particular system.

750
01:49:28,440 --> 01:49:36,390
Michael Akira Lee Hayashi: or other things, or thoughts about if we if we wanted to if we wanted to make this less of a toy model, what would we care about.

751
01:49:47,040 --> 01:49:49,800
Michael Akira Lee Hayashi: Because this actually probably just this sort of thing.

752
01:49:57,450 --> 01:50:04,740
Caroline Godfrey: You mean like health aides associate with smoking like development of COPD or lung cancer or something, are you just talking about the substance use itself.

753
01:50:06,240 --> 01:50:06,540
Michael Akira Lee Hayashi: well.

754
01:50:06,690 --> 01:50:10,440
Michael Akira Lee Hayashi: Anything really um health states are an interesting one, because that.

755
01:50:10,740 --> 01:50:14,760
Michael Akira Lee Hayashi: That is that can essentially act as a layer on top of.

756
01:50:15,840 --> 01:50:17,970
Michael Akira Lee Hayashi: say a smoking model so.

757
01:50:19,980 --> 01:50:27,180
Michael Akira Lee Hayashi: What I would tend to do on that front there there, there are certainly a lot of cases where, for example, we want to build a model of.

758
01:50:30,480 --> 01:50:34,920
Michael Akira Lee Hayashi: We want to build a model of smoking history, but we also want to put a health model on top of it.

759
01:50:36,420 --> 01:50:39,600
Michael Akira Lee Hayashi: In what I probably would tend to do here is.

760
01:50:41,010 --> 01:50:48,510
Michael Akira Lee Hayashi: Not necessarily I may or may not put the health state model sort of within the same scope as the smoking history model.

761
01:50:49,590 --> 01:51:07,500
Michael Akira Lee Hayashi: Partly because I might find it a little more efficient to simulate smoking histories for my synthetic cohort and then to simulate health histories from the simulated cohort for whom I know the smoking districts, so we could do something like.

762
01:51:08,640 --> 01:51:22,140
Michael Akira Lee Hayashi: suppose you have this model if you're in any of these states, then you have some chance of manifesting some health outcomes so suppose that current smokers have some chance of I don't know getting getting COPD.

763
01:51:23,820 --> 01:51:36,780
Michael Akira Lee Hayashi: Every year, so what you might do is you build a health state model which essentially tells you what's the chance if a person is a current smoker them getting COPD and you take the trajectory.

764
01:51:40,830 --> 01:51:48,000
Michael Akira Lee Hayashi: Whatever from from your smoking model and then you look you iterate through this trajectory and you're like okay.

765
01:51:48,240 --> 01:51:54,120
Michael Akira Lee Hayashi: This person is a nonsmoker in this year, that means that they have X probability of developing COPD and so on.

766
01:51:54,360 --> 01:52:02,310
Michael Akira Lee Hayashi: When they hit this stage, now they might have an increased probability of developing COPD or you might do something that takes into account the entire history where you're like.

767
01:52:02,760 --> 01:52:12,540
Michael Akira Lee Hayashi: i'm going to suppose that there is a increasing probability of developing COPD based on the number of years spent smoking, therefore, for this person I will then.

768
01:52:12,810 --> 01:52:20,700
Michael Akira Lee Hayashi: estimate their risk of COPD based on the total amount of time spent smoke, so you can you can come at the health outcomes part.

769
01:52:21,180 --> 01:52:30,960
Michael Akira Lee Hayashi: By bolting on essentially a health outcomes model to your smoking history model, this is this can be a really nice approach if if i'm.

770
01:52:31,860 --> 01:52:44,550
Michael Akira Lee Hayashi: If you've already got a nicely constructed smoking history model and you don't want to go back in and change the nuts and bolts, to add a health state model on top of it or integrated with that system, you can do this kind of like modular bolt on to it.

771
01:52:44,820 --> 01:52:54,540
Michael Akira Lee Hayashi: Where you where you build the health state model so that it can essentially read the information that the smoking state model outputs.

772
01:52:55,890 --> 01:53:03,420
Michael Akira Lee Hayashi: But you could, of course, build an integrated model, where some of the health states are actual states, so this would be a current smoker with COPD.

773
01:53:04,110 --> 01:53:14,850
Michael Akira Lee Hayashi: And that would be a State internal to this model itself and so that's something that you could track during the model simulation so maybe this is state for.

774
01:53:15,210 --> 01:53:26,550
Michael Akira Lee Hayashi: And now you could go from State to State for, for example, and and that would work fine to either of these from a design perspective or basically fine and it really comes down to what.

775
01:53:27,780 --> 01:53:32,610
Michael Akira Lee Hayashi: Well, how you built your original model what you want to put into that model or.

776
01:53:32,910 --> 01:53:40,860
Michael Akira Lee Hayashi: To a certain extent, whether you think you want to use it in a bunch of other contexts as opposed to one a little more specific to your primary research question.

777
01:53:41,160 --> 01:53:49,260
Michael Akira Lee Hayashi: Like if you think oh i've got the coolest smoking history model in the world and, if I were to add in some additional health states to it.

778
01:53:49,920 --> 01:54:02,550
Michael Akira Lee Hayashi: It gets a little clunky and i'd have to use it to evaluate these specific health States then maybe you just want to keep the smoking history model separate and module early bolt on the health state models and stuff like that.

779
01:54:04,830 --> 01:54:14,310
Michael Akira Lee Hayashi: Other product uses certainly something to think in the model like this, like you were born, by no means restricted to only thinking about a single thing that a person could use this.

780
01:54:14,670 --> 01:54:26,130
Michael Akira Lee Hayashi: This encounter some convenient oryx which are awfully awkward because, as soon as you introduce even a second product now you could go from never smoker to current smoker have one current smoker of both.

781
01:54:26,700 --> 01:54:33,660
Michael Akira Lee Hayashi: user of one or the other, and then you start getting into really wacky combinations with your former relapse compartments and.

782
01:54:33,930 --> 01:54:40,590
Michael Akira Lee Hayashi: I can tell you from personal experience this gets really awkward from Europe to like four products categories and your matrix potentially gets really, really big.

783
01:54:40,920 --> 01:54:44,070
Michael Akira Lee Hayashi: And it gets hard to find data to estimate that matrix and that's rather rather.

784
01:54:44,940 --> 01:54:52,290
Michael Akira Lee Hayashi: Even still do it, it just gets nasty so often when you're thinking about cases like say other product use or in general.

785
01:54:52,620 --> 01:55:02,010
Michael Akira Lee Hayashi: extensions to the model that caused that kind of conspiratorial explosion where by adding a state, you also have to add in combinations of.

786
01:55:02,910 --> 01:55:08,430
Michael Akira Lee Hayashi: ways that those states could interact, you often then have to have a bit of a think about.

787
01:55:08,940 --> 01:55:15,990
Michael Akira Lee Hayashi: Can I reduce the state space back by collapsing, some of those combinations into fewer categories like.

788
01:55:16,470 --> 01:55:27,720
Michael Akira Lee Hayashi: Do I really care if a person specifically using E cigarettes, cigars and cigarettes or do I just care that they're using three products or Do I really just care that they're using cigarettes, plus two products.

789
01:55:27,960 --> 01:55:37,800
Michael Akira Lee Hayashi: And if I can do that then i've shrunk the state space by smashing all of those three combinations into a single compartment into a single state.

790
01:55:38,190 --> 01:55:44,730
Michael Akira Lee Hayashi: And that saves a whole lot of space and saves a whole lot of hassle trying to make an enormous.

791
01:55:45,240 --> 01:55:55,260
Michael Akira Lee Hayashi: An enormous matrix for your system it doesn't always work, because sometimes you do care about the specific combinations and sometimes those are consequential but.

792
01:55:55,800 --> 01:56:07,590
Michael Akira Lee Hayashi: It is, I find that my temptation when I get a model that has convenient works like that is to try to find ways to collapse compartments so I don't end up with this enormous matrix that makes sense.

793
01:56:09,480 --> 01:56:14,280
Michael Akira Lee Hayashi: committed to eric's are always awkward for computers it's a lot of it's a lot of calculation.

794
01:56:27,870 --> 01:56:32,190
Michael Akira Lee Hayashi: Alright, so I think what i'm going to do so, let it percolate for a bit i'm going to move on to.

795
01:56:32,820 --> 01:56:38,610
Michael Akira Lee Hayashi: A section of the second part for today, where we start to look into continuous time market malls because I think.

796
01:56:38,910 --> 01:56:45,150
Michael Akira Lee Hayashi: it's it's useful to have some of that information in him, I don't think we're going to do any kind of coding work on it, because the.

797
01:56:45,720 --> 01:56:55,470
Michael Akira Lee Hayashi: The coding is a little more involved there if you're interested in in simulating continuous time markup change I can't remember if the tobacco simulation class does it I kind of think it does.

798
01:56:56,310 --> 01:57:08,520
Michael Akira Lee Hayashi: If you're at Michigan and you're interested I teach a class in the winter semester that's episode 637 where we do actually you'll you'll see some of the same lecture notes again, but the labs will be more fun and or harder.

799
01:57:10,410 --> 01:57:19,380
Michael Akira Lee Hayashi: And we will actually implement simulation methods for some of the more elaborate methods, as well as just more things from each of these things anyway.

800
01:57:21,210 --> 01:57:23,520
Michael Akira Lee Hayashi: that's my shameless plug for my own class.

801
01:57:26,490 --> 01:57:27,960
Michael Akira Lee Hayashi: So let's take a look at.

802
01:57:30,210 --> 01:57:31,230
think this was the right one.

803
01:57:33,120 --> 01:57:41,070
Michael Akira Lee Hayashi: let's take a look at continuous time markup models, we probably will not get down into this section so much policy we might.

804
01:57:42,300 --> 01:57:48,840
Michael Akira Lee Hayashi: One thing I did want to start with, is the question of whether you use a deterministic or a stochastic model for a given problem.

805
01:57:49,830 --> 01:57:56,730
Michael Akira Lee Hayashi: Because that is a design choice when you're when you're building a mechanistic model, one of the things which is great and terrifying is that.

806
01:57:57,630 --> 01:58:06,150
Michael Akira Lee Hayashi: All of the design decisions are up to you this isn't like a statistical model where you basically throw stuff into a black box method and plug and play.

807
01:58:06,600 --> 01:58:13,950
Michael Akira Lee Hayashi: You have to do a lot of the implementation yourself, which is another it's a it's kind of a subtle one, but it is a practical distinction between.

808
01:58:14,190 --> 01:58:24,330
Michael Akira Lee Hayashi: A lot of complex systems modeling and statistical modeling there aren't as many pre built frameworks, or you can just kind of throw something in specified in a particular way and it'll come out fine.

809
01:58:24,870 --> 01:58:39,090
Michael Akira Lee Hayashi: it's hard to do, in part because there's such a wide diversity of models that a person could think of building, even within a single framework that sometimes making a unified framework or a method to generate models get surprisingly hard.

810
01:58:40,080 --> 01:58:48,390
Michael Akira Lee Hayashi: At any rate, if we think about the difference between deterministic insta cast models, it can help to kind of focus on what the advantages and disadvantages are of each methodology.

811
01:58:49,320 --> 01:58:53,490
Michael Akira Lee Hayashi: So deterministic models are nice because well for one they're fast and.

812
01:58:53,910 --> 01:59:04,110
Michael Akira Lee Hayashi: We do actually care about speed around these parts you don't want to be sitting around for four weeks for your model to run one so we'd find that there was a bug and you have to do it again, you have to wait a few weeks that doesn't make anyone happy.

813
01:59:04,710 --> 01:59:08,220
Michael Akira Lee Hayashi: And that's a good way to stress yourself out a lot during your dissertation.

814
01:59:09,900 --> 01:59:23,160
Michael Akira Lee Hayashi: deterministic models might also have analytical solutions to certain properties like you can usually solve for the equilibrium and an OD model just explicitly like you can do it, you can often solve for thresholds and bifurcation and things like that.

815
01:59:24,360 --> 01:59:34,110
Michael Akira Lee Hayashi: In an SRM model, for example, most of these models, you can analytically calculate the are not the fundamental reproduction number of that model that's cool because that's a really useful quantity.

816
01:59:36,060 --> 01:59:45,270
Michael Akira Lee Hayashi: They tend to work nicely for large populations, because when you get up to a large enough population size, a lot of the individual level variation will tend to kind of average out.

817
01:59:47,370 --> 01:59:54,810
Michael Akira Lee Hayashi: You see this a lot where you're you get some you get a lot of regression to the mean kinds of behavior where, if you look at a small population of people.

818
01:59:55,560 --> 02:00:07,650
Michael Akira Lee Hayashi: The dynamics of a disease spreading in that population will be heavily governed by random chance like did someone recover before they could infect anyone did someone get hit by a rock and and weren't able to go out one day like.

819
02:00:08,160 --> 02:00:17,700
Michael Akira Lee Hayashi: those sorts of little transition Defense matter a lot in smaller systems with smaller populations in a big one, when we're talking thousands up to hundreds of thousands and more people.

820
02:00:18,450 --> 02:00:24,990
Michael Akira Lee Hayashi: A lot of that individual level variation just doesn't matter anymore some still does like you still often have to think about.

821
02:00:25,380 --> 02:00:37,140
Michael Akira Lee Hayashi: types of people in large populations and deterministic models, but a lot of that variation just doesn't matter in the same way that it does in a small model and so these sort these classes work really well in that context and.

822
02:00:38,130 --> 02:00:49,590
Michael Akira Lee Hayashi: And, to be honest in a lot of ways that's when you get to exploit this speed because simulating a large population in an individual based way like if I simulated a million people using my little tobacco model.

823
02:00:49,800 --> 02:00:55,740
Michael Akira Lee Hayashi: It would actually take appreciable time and sit there and chug for a few seconds and i'd get annoyed waiting for it to sit there and chug.

824
02:00:55,950 --> 02:01:03,750
Michael Akira Lee Hayashi: Knowing that I could use a deterministic model which works, just as well for a population of that size and runs almost instantaneous.

825
02:01:04,350 --> 02:01:09,660
Michael Akira Lee Hayashi: On the other hand, population models broadly and deterministic models, particularly.

826
02:01:09,990 --> 02:01:19,740
Michael Akira Lee Hayashi: In sort of the population framework lose detail about individual events we actually saw this in the population version of the Markov model which isn't even a deterministic month so that's kind of an interesting.

827
02:01:20,250 --> 02:01:31,050
Michael Akira Lee Hayashi: edge case but in like OD models in si our models, we don't know who infected whom in that model we don't know how a given person got themselves, in fact.

828
02:01:31,440 --> 02:01:42,420
Michael Akira Lee Hayashi: We just know how many people were infected over time, what the flow of people was among different states, we often need to make stronger distributional assumptions as well i'm.

829
02:01:43,200 --> 02:01:51,120
Michael Akira Lee Hayashi: Just goes, all the way back to the wee hours of this morning, when I was talking about how some power, plus on process.

830
02:01:51,750 --> 02:01:59,400
Michael Akira Lee Hayashi: Has exponentially distributed waiting terms, this is true of transitions between states in pretty much every odd model that you're going to build.

831
02:02:00,060 --> 02:02:03,570
Michael Akira Lee Hayashi: And that is a very strong distributional assumption, because, as I said.

832
02:02:04,140 --> 02:02:17,910
Michael Akira Lee Hayashi: there's a lot of things in this world that do not have negatively exponentially negative exponentially distributed waiting times they just don't like there's some things that will have uniformly distributed waiting times or basically like a points distribution.

833
02:02:19,020 --> 02:02:26,820
Michael Akira Lee Hayashi: And the third, for reasons that are sort of visually evidence this just is not a good approximation to either of these things.

834
02:02:27,810 --> 02:02:34,560
Michael Akira Lee Hayashi: So we have to be a little bit more careful about understanding that those distributional assumptions are there and that that can.

835
02:02:35,370 --> 02:02:48,300
Michael Akira Lee Hayashi: Give us some slightly wacky insights like that, fundamentally, a lot of these models will implicitly mean that a lot of people are transiting through States really fast and it's summer just kind of hanging out for forever till the cows come home.

836
02:02:52,020 --> 02:03:01,320
Michael Akira Lee Hayashi: Perhaps unsurprisingly deterministic models tend to work poorly for small populations, and it is difficult to get a reasonable quantification of variance out of the models.

837
02:03:01,530 --> 02:03:08,130
Michael Akira Lee Hayashi: One of the particular reasons, this is true is that in a small population you tend to get much more extreme events.

838
02:03:08,880 --> 02:03:16,020
Michael Akira Lee Hayashi: You can see that even if you're rolling like a six sided die if you will, that die five times you're going to get a really wacky distribution of dials right.

839
02:03:16,230 --> 02:03:23,370
Michael Akira Lee Hayashi: You might get like three sixes a one and a two and you might conclude, therefore, that this is very unfair.

840
02:03:23,730 --> 02:03:33,990
Michael Akira Lee Hayashi: When really you just didn't roll that die enough to smooth out the the high degree of variation that that is capable of which tends to manifest when you don't have a lot of trials.

841
02:03:34,830 --> 02:03:39,540
Michael Akira Lee Hayashi: same deal for a deterministic model if you're trying to model, a household of four people.

842
02:03:39,900 --> 02:03:45,780
Michael Akira Lee Hayashi: Well, an odd model is probably not a good representation of that system because there's a pretty good chance that.

843
02:03:46,110 --> 02:03:55,860
Michael Akira Lee Hayashi: That that someone gets sick in that household and then they just get better or there's also a pretty good chance that someone gets sick and and everyone gets sick, so you tend to get these sort of all or nothing.

844
02:03:56,550 --> 02:04:14,100
Michael Akira Lee Hayashi: sweeps happening in stuck in in stochastic systems of small populations, but a deterministic model is not going to capture that deterministic model is generally and again i'm talking mostly about OD type models mean field models, if our data looks like this.

845
02:04:15,630 --> 02:04:22,350
Michael Akira Lee Hayashi: What a mean field model is going to do is this, because this is the average of the system.

846
02:04:22,980 --> 02:04:37,290
Michael Akira Lee Hayashi: But did this do a good job of capturing the variance of behavior in the system, no, it did not, fortunately, when we get up to larger populations, while there's still some extreme events you do tend to get more events clustered around the actual mean.

847
02:04:38,550 --> 02:04:40,530
Michael Akira Lee Hayashi: And I mean field approximation works.

848
02:04:44,850 --> 02:04:58,620
Michael Akira Lee Hayashi: By contrast, it probably does not come as a huge surprise, but it's the classic model tends to in general have the advantage of being able to track individual level events, it also being stochastic and having process randomness in the actual model.

849
02:04:59,640 --> 02:05:05,820
Michael Akira Lee Hayashi: gives us an intrinsic way to quantify variance I know the range of events that happened my model because well.

850
02:05:07,110 --> 02:05:08,370
Michael Akira Lee Hayashi: simulating it did that.

851
02:05:10,950 --> 02:05:15,900
Michael Akira Lee Hayashi: We often get to employ more flexible distributional assumptions like.

852
02:05:16,620 --> 02:05:24,390
Michael Akira Lee Hayashi: If you're making a model where people can arrive at a location, after a certain amount of time that waiting time is governed by some probability distribution.

853
02:05:24,660 --> 02:05:27,630
Michael Akira Lee Hayashi: Yes, it is nice and clean and simple to use a person model.

854
02:05:27,930 --> 02:05:34,920
Michael Akira Lee Hayashi: and make that waiting time distribution negative exponential but you don't have to you can do whatever you want, you can make it gamma distributed, you can make it look normal.

855
02:05:35,220 --> 02:05:44,190
Michael Akira Lee Hayashi: You could make one of those weird dumb little point distributions you could do all kinds of wacky stuff you could use some weird distribution that's like multi modal or whatever you want.

856
02:05:44,880 --> 02:05:50,910
Michael Akira Lee Hayashi: You have a lot more flexibility in your distributional assumptions, because you build them into your system.

857
02:05:53,040 --> 02:06:07,620
Michael Akira Lee Hayashi: This can also be a little bit dangerous, because if you pick up bad distribution then you're going to get yourself into trouble awfully quick but flexibility is often powerful in model and because the real world doesn't always obey a nice distributional shape.

858
02:06:09,300 --> 02:06:18,240
Michael Akira Lee Hayashi: i'm stochastic models tend to work pretty well for a wide range of population sizes even up to fairly large populations kind of like we saw with the market model.

859
02:06:18,630 --> 02:06:28,350
Michael Akira Lee Hayashi: You can make a population proportion Markov model that works great for a huge population that has a lot of the same caveats as a mean field O D model and same population.

860
02:06:28,590 --> 02:06:41,760
Michael Akira Lee Hayashi: But it is a market model is to cast a model and it works well for those big populations in general, though I tend to find the stochastic models are most effective in kind of the small to medium sized populations base essentially.

861
02:06:42,150 --> 02:06:59,520
Michael Akira Lee Hayashi: In the space where a deterministic model is going to give you awkward answers because it's missing out on the variance it's it's missing out on the fact that small populations tend to have either zero biased, or like right skewed distributions of their of their outcomes.

862
02:07:00,840 --> 02:07:09,960
Michael Akira Lee Hayashi: Up to kind of mid to middle large sized populations, more or less governed by the efficiency of the simulation and the point at which you start to.

863
02:07:10,710 --> 02:07:18,540
Michael Akira Lee Hayashi: You start to lose the benefit of individual tracking and you start to gain the detriment of my simulation takes a long time to run and i'm getting impatient.

864
02:07:19,800 --> 02:07:30,720
Michael Akira Lee Hayashi: which of course is is largely the primary disadvantage of it's the classic model, they can be slow even fairly small stochastic models like a stochastic si our model.

865
02:07:31,170 --> 02:07:42,690
Michael Akira Lee Hayashi: can be shockingly slow to simulate and takes a surprising amount of compute power to run these are not, these are not computationally light tasks, and so, if you need results quick.

866
02:07:43,650 --> 02:07:49,140
Michael Akira Lee Hayashi: You may not want to use a stochastic model if you're willing to accommodate sort of the caveats for them.

867
02:07:50,100 --> 02:07:54,240
Michael Akira Lee Hayashi: They also tend to be harder to analyze from a mathematical perspective, like.

868
02:07:55,110 --> 02:08:03,900
Michael Akira Lee Hayashi: For newly processes procedures and processes, a lot of Markov models, you can do formal mathematical analysis of things about them like.

869
02:08:04,230 --> 02:08:12,330
Michael Akira Lee Hayashi: You could solve for the stationary distribution there's a lot of properties that are just known in closed form about for some processes and things like that.

870
02:08:12,630 --> 02:08:22,710
Michael Akira Lee Hayashi: But if you're building say a stochastic individual based simulation of a population that has maybe complex scheduling like people people go to work and people use transit and.

871
02:08:23,220 --> 02:08:32,790
Michael Akira Lee Hayashi: Things like that and infection depends on where people are and a bunch of individual level factors, good luck writing an equation to cleanly described the behavior of that system.

872
02:08:33,330 --> 02:08:47,220
Michael Akira Lee Hayashi: You could try and maybe you'll succeed, but i'm not optimistic about that one, so you often have to rely more on numerical analysis system and what this means is simulation analysis which kind of bumps you into the previous problem where.

873
02:08:48,030 --> 02:08:50,790
Michael Akira Lee Hayashi: You not only have to do numerical simulation but.

874
02:08:51,270 --> 02:09:02,250
Michael Akira Lee Hayashi: In a stochastic model you can't just run it once, generally speaking, I mean we we got away with it for the population Markov model because we're actually generating the probability distribution over time.

875
02:09:02,550 --> 02:09:09,390
Michael Akira Lee Hayashi: But if you don't have a way to do that if you don't have a way to generate the probability distribution, and you have to simulate individual trajectories.

876
02:09:11,160 --> 02:09:18,600
Michael Akira Lee Hayashi: you're probably going to have to at minimum run hundreds if not thousands of simulations under the same parametric conditions.

877
02:09:18,960 --> 02:09:23,280
Michael Akira Lee Hayashi: In order to get stable estimates of anything that happens in the system because.

878
02:09:23,550 --> 02:09:35,040
Michael Akira Lee Hayashi: For the same reason that deterministic models were poorly in small populations, if you run your stochastic model three times you might get a trajectory that looks like this one, that looks like this and another one that looks like this.

879
02:09:35,310 --> 02:09:39,120
Michael Akira Lee Hayashi: And you might conclude that you have no idea what your system does because.

880
02:09:40,170 --> 02:09:47,100
Michael Akira Lee Hayashi: This doesn't tell you a whole ton about what the system could do well once you've run the model, a whole bunch of times you'll find that.

881
02:09:47,340 --> 02:09:57,330
Michael Akira Lee Hayashi: Maybe a bunch of the trajectories convergence here every so often there's a weirdo down here and every so often there's a weirdo up here, but most of the trajectories are here bounded by this kind of.

882
02:09:58,950 --> 02:10:00,420
Michael Akira Lee Hayashi: Overall variants.

883
02:10:02,070 --> 02:10:12,480
Michael Akira Lee Hayashi: But this takes hundreds if not thousands, if not 10s of thousands of simulation runs to be able to establish and you tend to need more simulation runs the more.

884
02:10:13,020 --> 02:10:21,180
Michael Akira Lee Hayashi: Well, the more randomness you have in your system, the more events you have in your system, which means more compute time, that also means more debugging more complexity.

885
02:10:21,840 --> 02:10:27,960
Michael Akira Lee Hayashi: Which again a lot of the a lot of the downsides to cast models, I think, in a perfect world, if I had.

886
02:10:28,440 --> 02:10:35,670
Michael Akira Lee Hayashi: If I had the world's most powerful computer i'd probably used to cast models from nearly everything but the but the reality is.

887
02:10:36,570 --> 02:10:43,110
Michael Akira Lee Hayashi: we're not in that world and as powerful as my computers are sometimes there's simulations that are still just going to be slow on them.

888
02:10:43,440 --> 02:10:49,890
Michael Akira Lee Hayashi: And maybe I don't want to tolerate that in a given situation, maybe I don't have time to tolerate that.

889
02:10:50,430 --> 02:10:57,540
Michael Akira Lee Hayashi: I also have to deal with increased complexity, as I make more flexible assumptions if I use weird distributional shapes or something like if my.

890
02:10:57,810 --> 02:11:07,800
Michael Akira Lee Hayashi: My waiting time distribution looks like this well determining anything analytical about the results of that model is hard, because this distributions just wacky and.

891
02:11:08,580 --> 02:11:23,940
Michael Akira Lee Hayashi: it's hard for me to tell if the results that came out of my model makes sense or not, if they're if they're reasonably real as opposed to if there's something fundamentally wrong with them, or if there's a bug or, if I may, if there's an artifact somewhere that that causes a problem so.

892
02:11:25,320 --> 02:11:38,190
Michael Akira Lee Hayashi: Unfortunately there isn't really a free lunch in this world, sometimes the stochastic models, a good choice, sometimes the deterministic models good choice and it comes down to what problem you want model what the scope of the model is supposed to be.

893
02:11:38,580 --> 02:11:48,000
Michael Akira Lee Hayashi: And what kinds of results, you want to get out of it, how much do you care about things like this versus do you just want to see the average behavior of a system because.

894
02:11:48,690 --> 02:11:58,500
Michael Akira Lee Hayashi: you'll get very different answers to the question of what kind of model should I use here if depending on what what the answers to those those preliminary questions or.

895
02:12:01,170 --> 02:12:09,030
Michael Akira Lee Hayashi: Questions or thoughts at this point Are there cases where you're not sure if you'd want to use a deterministic or a stochastic model or anything in that vein.

896
02:12:26,670 --> 02:12:29,700
Rishi Chanderraj: um what one question I had was, I think that.

897
02:12:33,900 --> 02:12:37,920
Rishi Chanderraj: Some of the some of the the computation power.

898
02:12:39,150 --> 02:12:43,770
Rishi Chanderraj: When you're i'm sure that, like when you're coding some of this stuff there are like.

899
02:12:44,790 --> 02:12:52,230
Rishi Chanderraj: Faster you know, like faster with you know, like some we're talking about this before about like readable versus fast.

900
02:12:53,250 --> 02:13:09,720
Rishi Chanderraj: and different languages that might be faster than others is like is that a considered like if there was something that was like a really good model, but it was just so computationally intensive, could you run it and, like something else, and then maybe it gets a little bit more tractable.

901
02:13:10,560 --> 02:13:13,350
Michael Akira Lee Hayashi: yeah absolutely i'm often.

902
02:13:13,770 --> 02:13:15,540
Michael Akira Lee Hayashi: Often, my workflow on modeling.

903
02:13:15,750 --> 02:13:20,610
Michael Akira Lee Hayashi: Is i'll build something that works, first, to make sure that i'm confident that.

904
02:13:21,120 --> 02:13:26,280
Michael Akira Lee Hayashi: I can implement the system properly and that I haven't introduced any bugs in the implementation itself.

905
02:13:26,610 --> 02:13:37,470
Michael Akira Lee Hayashi: And then i'll spend a bunch of time benchmarking the implementation that i've made to try to find out what bottlenecks are slowing the simulations down, it might be that I have an event that.

906
02:13:38,100 --> 02:13:44,670
Michael Akira Lee Hayashi: happens a lot that's a really common way that stochastic simulations will slow down, but you have a fast event something with a short waiting time.

907
02:13:45,420 --> 02:13:52,080
Michael Akira Lee Hayashi: Because the model has to stop an update every time that happens, like, I made a model that explicitly represents like breathing.

908
02:13:52,470 --> 02:14:07,290
Michael Akira Lee Hayashi: people breathe a lot, as it turns out that's a very slow event or too fast event slows down the simulation and so having having done a bit of benchmark analysis to figure out where my bottlenecks are and profile my code now I might be like okay.

909
02:14:08,430 --> 02:14:14,370
Michael Akira Lee Hayashi: How much improvement can I make within the language and within the framework that i've already implemented.

910
02:14:14,730 --> 02:14:26,940
Michael Akira Lee Hayashi: Or, there are other tricks, I can use like throwing in like making a hybrid model that makes that run some things deterministic Lee and some things to caustically like i'll often right hybrid models that treat things like.

911
02:14:27,600 --> 02:14:39,240
Michael Akira Lee Hayashi: bacterial growth and contamination deterministic Lee because there's so many bacteria that a deterministic model works great for those and that's way faster than using a stochastic simulation of the bacterial growth.

912
02:14:39,630 --> 02:14:43,410
Michael Akira Lee Hayashi: So that's the thing you can do that often preserves a lot of your existing framework.

913
02:14:43,770 --> 02:14:51,300
Michael Akira Lee Hayashi: and often there are little optimizations you can do like if you know, a language well if you're comfortable with it, you might know, for example, oh.

914
02:14:51,600 --> 02:15:00,390
Michael Akira Lee Hayashi: Explicit for loops in this language are slow or I think about Python particularly Python is not a fast way, so I will say that in.

915
02:15:01,080 --> 02:15:02,880
Michael Akira Lee Hayashi: To its detriment Python is slow.

916
02:15:03,450 --> 02:15:14,010
Michael Akira Lee Hayashi: Python is also an object oriented language, except that object methods are slow to call so writing object oriented code in Python implicitly creates a performance hit.

917
02:15:14,250 --> 02:15:21,270
Michael Akira Lee Hayashi: And so, when I bumped into that and if my profiling is suggesting that i'm spending a lot of time sitting in functions that are object methods.

918
02:15:21,450 --> 02:15:29,190
Michael Akira Lee Hayashi: I might be like okay i'm going to suck this up and write this as functional code that's no longer object oriented in order to get a little bit of a speed up.

919
02:15:29,610 --> 02:15:36,750
Michael Akira Lee Hayashi: I might conclude equivalent Lee that i'm just i'm just i'm just pushing a rock up a hill only to have it roll back down on me.

920
02:15:37,350 --> 02:15:46,680
Michael Akira Lee Hayashi: And I really just need to implement this in a fundamentally faster language, and then I might suck it up and write something in c++ and spend the rest of my life debugging it.

921
02:15:46,890 --> 02:15:55,110
Michael Akira Lee Hayashi: But it will be very fast sometimes essentially the same implementation in like Python vs a fast language like c++.

922
02:15:55,350 --> 02:16:04,350
Michael Akira Lee Hayashi: is massively different in performance sometimes not so much, I mean and sometimes with the higher level languages it's hard to figure out which one is performing to particular areas like.

923
02:16:04,890 --> 02:16:10,920
Michael Akira Lee Hayashi: Sometimes a language will just be bizarrely slow at a particular thing that you don't think it really should be so.

924
02:16:11,760 --> 02:16:20,220
Michael Akira Lee Hayashi: What this comes down to in a lot of cases is experience with the language experience with the things you're trying to implement when to.

925
02:16:20,760 --> 02:16:24,570
Michael Akira Lee Hayashi: When you know you can take a shortcut to make something that stochastic deterministic.

926
02:16:24,750 --> 02:16:38,550
Michael Akira Lee Hayashi: When you can take little computational shortcuts like evaluating something in a lazy way, so instead of updating whenever something happens you wait to do a bunch of updates until something else happens so you don't have to stop your simulation.

927
02:16:39,330 --> 02:16:45,210
Michael Akira Lee Hayashi: Every like three seconds to make an update so there's there's.

928
02:16:45,840 --> 02:16:56,460
Michael Akira Lee Hayashi: there's a lot of roads to Rome on the kind of performance trade off area, one of the one of the easiest ways to buy yourself performance and stochastic models is to paralyze your model because.

929
02:16:57,360 --> 02:17:03,210
Michael Akira Lee Hayashi: I suggested that when you run a stochastic model, you have to do a bunch of simulations like hundreds to thousands.

930
02:17:03,540 --> 02:17:09,780
Michael Akira Lee Hayashi: Well, each of those simulations does not care at all what's going on in any of the other simulations they're fully independent.

931
02:17:10,020 --> 02:17:18,870
Michael Akira Lee Hayashi: What that means is that they can run on different cores of a multi core system they can even run on different computers, because they just straight up don't care about each other.

932
02:17:19,590 --> 02:17:26,310
Michael Akira Lee Hayashi: So you can sometimes by yourself, a lot of improved performance purely by doing a little bit of clever parallel ization.

933
02:17:26,670 --> 02:17:30,930
Michael Akira Lee Hayashi: to distribute your job among the computation resources available because.

934
02:17:31,290 --> 02:17:38,220
Michael Akira Lee Hayashi: The reality is almost every one of our computers has more than one core and it's processor, so it can do two to four things at once.

935
02:17:38,460 --> 02:17:43,770
Michael Akira Lee Hayashi: For laptops and if you're on if you're on a decent sized desktops you might be able to get up to like I don't know.

936
02:17:44,130 --> 02:17:51,660
Michael Akira Lee Hayashi: Eight to 24 things going at the same time, or more if you've got a really big desktop or you've got a server or a gigantic workstation or something.

937
02:17:51,870 --> 02:17:59,040
Michael Akira Lee Hayashi: So sometimes there's ways to kind of slightly cheat like that, too, by yourself performance through parallel ization as opposed to other kind of optimization.

938
02:17:59,580 --> 02:18:05,520
Michael Akira Lee Hayashi: If it's something that you're going to be using a lot and it's just really slow, sometimes it is worth taking.

939
02:18:06,060 --> 02:18:19,320
Michael Akira Lee Hayashi: Taking a hit and rewriting the thing in a faster language and digging into a bunch of aggressive performance optimization or hiring someone to write the thing in a fast language and and do that performance optimization for you.

940
02:18:21,240 --> 02:18:21,660
Michael Akira Lee Hayashi: But.

941
02:18:22,680 --> 02:18:31,500
Michael Akira Lee Hayashi: There it's another one of those there's a lot of ways to do it and not necessarily one right one because it's going to depend a lot on your project timetable.

942
02:18:32,100 --> 02:18:41,880
Michael Akira Lee Hayashi: What resources, you have available to you both in terms of like what languages, you know and how good you are at optimizing in those languages.

943
02:18:43,170 --> 02:18:50,910
Michael Akira Lee Hayashi: And a lot of stuff like that are there packages which have already kind of written a fast optimized version of a particular tasks.

944
02:18:51,270 --> 02:18:57,330
Michael Akira Lee Hayashi: If that's true and you've written a slower non optimized version of that same routine will use the package.

945
02:18:57,930 --> 02:19:07,740
Michael Akira Lee Hayashi: So there's there's a number of different ways to come at this particular problem which, which can be a pretty sticky one because, once you start running stochastic models.

946
02:19:08,100 --> 02:19:17,820
Michael Akira Lee Hayashi: You will find really fast that these things are slow like I have, I have a have 128 core workstation at school right now that I that I built.

947
02:19:19,350 --> 02:19:21,030
Michael Akira Lee Hayashi: That essentially is is.

948
02:19:21,480 --> 02:19:30,150
Michael Akira Lee Hayashi: loaded 24 seven with tobacco simulation models, because these models are really big and they take a lot of time they have to be paralyzed.

949
02:19:30,330 --> 02:19:42,660
Michael Akira Lee Hayashi: And they take a system on that scale to even finish and reasonable time, so this is a case where you have a combination of like brute forcing through parallel ization plus optimizations and things and.

950
02:19:43,350 --> 02:19:53,220
Michael Akira Lee Hayashi: You still end up with this fairly computationally intensive process so sorry that's a very long answer, but it's really easy to get me off on a computational tangent by asking me about stuff like that so.

951
02:19:54,870 --> 02:19:56,400
Michael Akira Lee Hayashi: This this is your own doing at the end of the day.

952
02:20:00,720 --> 02:20:01,950
Michael Akira Lee Hayashi: Thanks hopefully that's helpful.

953
02:20:02,130 --> 02:20:03,870
Rishi Chanderraj: yeah No, it is, thank you, thank you.

954
02:20:05,580 --> 02:20:06,840
Michael Akira Lee Hayashi: Any other questions about.

955
02:20:07,020 --> 02:20:08,760
Michael Akira Lee Hayashi: deterministic for stochastic models.

956
02:20:20,280 --> 02:20:35,250
Michael Akira Lee Hayashi: Probably the simplest heuristic that I tend to use with deterministic for stochastic models is the question of Do I need to model, a population versus a collection of individuals, and the answer to that question will almost certainly tell me which type, I want to use for given.

957
02:20:40,080 --> 02:20:41,910
Michael Akira Lee Hayashi: works 90% of time.

958
02:20:46,110 --> 02:20:55,770
Michael Akira Lee Hayashi: Alright let's look at let's look at some more stuff we've seen discrete time Markov chains, where you update the system at fixed discrete interests and surprisingly.

959
02:20:57,270 --> 02:21:04,710
Michael Akira Lee Hayashi: A continuous time Markov chain Ben is again maybe unsurprisingly, one where instead of thinking about i'm going to update the system.

960
02:21:05,430 --> 02:21:19,770
Michael Akira Lee Hayashi: At your 12345 events happen in arbitrary continuous time so it's not that we figure out if a person started smoking between your zero and your one now it's that at some point in the future.

961
02:21:21,570 --> 02:21:22,350
Michael Akira Lee Hayashi: Our person.

962
02:21:23,430 --> 02:21:40,800
Michael Akira Lee Hayashi: may start smoking and now we have to start thinking about things like waiting time so, on average, how long is it until that person starts smoking and we think about events and times of events that really is a lot of the core conceptual material for a continuous time markup.

963
02:21:42,240 --> 02:21:49,620
Michael Akira Lee Hayashi: So once again we're going to say that we have some finite state space or accountable state space, this could be numbers, this can be discreet things.

964
02:21:50,400 --> 02:22:00,900
Michael Akira Lee Hayashi: We also want to keep track of what the state of the system is at any given time where again this time is continuous so it can take any of positive real valued number.

965
02:22:02,910 --> 02:22:10,860
Michael Akira Lee Hayashi: And instead of transition probabilities now we care about our transition rates were a rate is defined as probability over time.

966
02:22:11,430 --> 02:22:19,080
Michael Akira Lee Hayashi: Which described transitions between States and our model so if we're thinking about the smoking model going between a nonsmoker and a current smoker.

967
02:22:20,040 --> 02:22:33,930
Michael Akira Lee Hayashi: The the the event that we say corresponds to that is initiation that initiation happens at some rate We actually had one of those before one over 18 years so, on average, it takes 18 years for a person to start smoking.

968
02:22:34,290 --> 02:22:39,930
Michael Akira Lee Hayashi: In our in our previous model and that one over 18 is our rate for for this model.

969
02:22:41,190 --> 02:22:47,070
Michael Akira Lee Hayashi: Again we think about transitions is going from Jay to I are thinking and kind of a matrix see indexing format.

970
02:22:48,510 --> 02:23:04,470
Michael Akira Lee Hayashi: And our our good friend, the facade process comes back here, because in a continuous time Markov model state transitions have exponentially distributed waiting times so if we want to characterize the distribution of time.

971
02:23:05,820 --> 02:23:13,230
Michael Akira Lee Hayashi: for which a person could go from a nonsmoker to a current smoker well that's going to be exponentially distributed, with its characteristic.

972
02:23:13,620 --> 02:23:27,030
Michael Akira Lee Hayashi: parameter being one over the one over the rate or in this case, so if we had our rate Lambda of one over 18 than the average of this distribution is going to be a team.

973
02:23:28,710 --> 02:23:39,450
Michael Akira Lee Hayashi: that's fortunately fortunately exponential distributions are nice and the the it's the expectation of the distribution is equal to one over the rate.

974
02:23:40,530 --> 02:23:53,970
Michael Akira Lee Hayashi: Once again, we have the problem of scale versus rate parameters, so if you happen to see an exponential distribution parameter is using a scale parameter, all that is is this it's one over the rate, which is the average waiting time of the system.

975
02:23:55,200 --> 02:24:01,860
Michael Akira Lee Hayashi: In the same way that the scale parameter for gamma distribution is one over the total rate of that thing.

976
02:24:03,030 --> 02:24:08,550
Michael Akira Lee Hayashi: So the waiting time of getting through that entire chain of exponential instead of just a single one.

977
02:24:09,420 --> 02:24:19,530
Michael Akira Lee Hayashi: Which is just kind of handy it is, it is the one way that those rate for scale parameters have a certain degree of intuitive correspondence that the scale parameters, the inverse of the rate which.

978
02:24:20,130 --> 02:24:30,600
Michael Akira Lee Hayashi: Broadly, we can take to me is the expectation, the expected amount of time until that event happens governed by this process.

979
02:24:35,640 --> 02:24:53,010
Michael Akira Lee Hayashi: We could there's kind of a sneaky way to think about a continuous time Markov chain as having an embedded discrete time Markov chain where what we what we do is, if you recall, I said that a continuous Markov chain chairs about when events happen so.

980
02:24:54,120 --> 02:25:05,280
Michael Akira Lee Hayashi: Someone start smoking here, this is our timeline then someone quit smoking here, then they relapse them they quit and they relapse make quick each of these events.

981
02:25:05,850 --> 02:25:17,820
Michael Akira Lee Hayashi: happened at some time, but what we could do is say suppose there is a discrete time Markov chain where this is the first thing, this is the second thing, this is the third thing.

982
02:25:18,330 --> 02:25:35,550
Michael Akira Lee Hayashi: and so on, because a discrete time Markov chain doesn't necessarily care about the interval between between evaluations of that Markov chain, so we could think about this continuous system as secretly having a discrete Markov chain within.

983
02:25:36,690 --> 02:25:49,770
Michael Akira Lee Hayashi: i'm not going to belabor this and you don't really need to worry about it, but one day in the fullness of time, it may be useful because it may give you a simplified representation of a more complex system in those are always.

984
02:25:50,550 --> 02:25:56,760
Michael Akira Lee Hayashi: So while when we have a continuous time mark of June we usually treat it as continuous and we simulate it as such.

985
02:25:57,210 --> 02:26:08,550
Michael Akira Lee Hayashi: It is technically possible to work from the embedded discrete time Markov chain of that continuous time mark off process and every so often that will buy you a small free lunch.

986
02:26:09,810 --> 02:26:13,590
Michael Akira Lee Hayashi: it's not super common but hey it's not the worst thing to happen to back pocket.

987
02:26:15,060 --> 02:26:24,060
Michael Akira Lee Hayashi: So let's again think about this in terms of smoking, history and then i've chosen different times for this so sorry bear with me here um.

988
02:26:24,990 --> 02:26:30,930
Michael Akira Lee Hayashi: So let's again suppose that we have a smoking model, where we have non smokers current snore smokers and former smokers.

989
02:26:31,500 --> 02:26:39,300
Michael Akira Lee Hayashi: Instead of transition probabilities all we really need now are the transition rates, what is the frequency with which people change states over time.

990
02:26:39,900 --> 02:26:53,100
Michael Akira Lee Hayashi: we're going to suppose that we've made it even simpler system and all that people do is start smoking and quit and we're going to suppose that initiation has a rate of one for 18 years and quitting has a rate of one for 30 years.

991
02:26:54,450 --> 02:27:04,680
Michael Akira Lee Hayashi: We probably care about other things that happened in the system, because these are not the only things that can happen, but if we wanted to add those all we would do is add additional state transitions additional events in the model.

992
02:27:05,040 --> 02:27:10,020
Michael Akira Lee Hayashi: And we decide those appropriate transition rates so.

993
02:27:10,740 --> 02:27:19,230
Michael Akira Lee Hayashi: we're no longer working for a matrix formation anymore like there's not really a meaningful transition matrix now what we have is a list.

994
02:27:19,440 --> 02:27:33,600
Michael Akira Lee Hayashi: of events with their corresponding transition rates so when you see a continuous time mark of model described what you usually want to look for for the meat of the model is, what are the transition events in that model and what are their corresponding rates.

995
02:27:39,360 --> 02:27:40,110
Michael Akira Lee Hayashi: So.

996
02:27:42,150 --> 02:27:50,850
Michael Akira Lee Hayashi: Fortunately, for us, the continuous time market framework is pretty flexible, we can make them multi dimensional if we want.

997
02:27:51,930 --> 02:28:06,540
Michael Akira Lee Hayashi: For example of a reason to do this in the first place, instead of just like a one dimensional sequence of which events happened would be if we wanted to make a continuous time population Markov model I did suggest that.

998
02:28:08,730 --> 02:28:13,320
Michael Akira Lee Hayashi: That if you're doing a population model, you probably want to do a deterministic model.

999
02:28:14,880 --> 02:28:15,420
Michael Akira Lee Hayashi: But.

1000
02:28:17,040 --> 02:28:21,210
Michael Akira Lee Hayashi: Like I said 90% of the time, there is that 10% of the time, where you want a.

1001
02:28:21,690 --> 02:28:29,310
Michael Akira Lee Hayashi: stochastic population well one of those might actually be if you want a like a household transmission model, but you don't necessarily it doesn't have to be.

1002
02:28:29,760 --> 02:28:40,080
Michael Akira Lee Hayashi: Individual based per se, but you do want it to be stochastic now in this kind of world what you're looking at is a system where you have.

1003
02:28:40,770 --> 02:28:56,430
Michael Akira Lee Hayashi: Some number of types of entities in your system where the variable X of y of T is the number of things of a given type at time T, so the cleanest way to think about this in our smoking model is that.

1004
02:28:57,450 --> 02:29:07,650
Michael Akira Lee Hayashi: Our system now is comprised of some number of never smokers some number of current smokers and some number of former smokers at every time in the model.

1005
02:29:07,950 --> 02:29:19,860
Michael Akira Lee Hayashi: And, of course, these numbers are going to change as the model runs so when we have this kind of framework where we're tracking changes in population counts over time in a stochastic continue same Markov chain model.

1006
02:29:20,400 --> 02:29:34,650
Michael Akira Lee Hayashi: The way that we describe our events is as changing the number of things in each State or the number of things in each bucket i'm going to use my terminology is going to get a little bit sloppy here i'm going to say state to describe like.

1007
02:29:35,820 --> 02:29:45,090
Michael Akira Lee Hayashi: Never current former smoker it's not 100% right but it's pretty close, so what happens when you go from never to current smoker when one of these events, fires well.

1008
02:29:45,960 --> 02:29:56,580
Michael Akira Lee Hayashi: You lose one never smoker and you add one former smoker at one current smoker so this transition event causes this change in the state buckets.

1009
02:29:57,030 --> 02:30:08,670
Michael Akira Lee Hayashi: And then that event still happens with with with this rate notice that the rate calculation is different now, we have an actual variable term in the top that we did not before.

1010
02:30:09,360 --> 02:30:26,520
Michael Akira Lee Hayashi: right before the transition from never to current was one over 18 years the way to think about this, and the reason, these are different, is that you should think about this rate as a per capita rate, so this is the rate with which one individual thing goes from end to see.

1011
02:30:27,690 --> 02:30:39,540
Michael Akira Lee Hayashi: These rates, these are total rates or bulk rates is, is what I might choose to call it, so if we want to know the total rate with which some.

1012
02:30:40,290 --> 02:30:50,250
Michael Akira Lee Hayashi: Non smoker start smoking well there's X of n non smokers and each of those X of em non smokers could become a current smoker.

1013
02:30:50,460 --> 02:31:00,300
Michael Akira Lee Hayashi: And they could do so according to our stochastic process, which means that when we think about the rate for anyone becoming a current smoker anyone initiating smoking.

1014
02:31:00,600 --> 02:31:11,070
Michael Akira Lee Hayashi: Now we have to take our per capita rate and multiply it by the number of things in our system eligible to undergo that state transition so since there are X of n.

1015
02:31:11,490 --> 02:31:21,090
Michael Akira Lee Hayashi: Never smokers, we have to multiply our per capita transition rate of one pre teen years by that X event, if T, which gives us our bulk rate for this transition.

1016
02:31:22,890 --> 02:31:34,800
Michael Akira Lee Hayashi: Does that make sense I I often find that per capita versus bulk rates are a common point of confusion in terms of characterizing rates for for models generally so often like to spend a little more time talking through them.

1017
02:31:44,490 --> 02:31:47,910
Michael Akira Lee Hayashi: secretly you actually see these no D models to when you see.

1018
02:31:49,770 --> 02:31:52,350
Michael Akira Lee Hayashi: Something like this, where a as a variable in the system.

1019
02:31:54,780 --> 02:32:09,930
Michael Akira Lee Hayashi: What this is this term is a bulk rate, this is a per capita rate so each a has a rate K of moving from I guess A to B, in this case, but there are a number of a's.

1020
02:32:10,410 --> 02:32:21,450
Michael Akira Lee Hayashi: And so the total rate of transition between, say A and B is K times eight that's the bulk rate or the total rate in exactly the same ways we think about it here.

1021
02:32:21,750 --> 02:32:38,400
Michael Akira Lee Hayashi: So deterministic models, also have a distinction between per capita rates and bulk rates were pretty much every parameter we put in a deterministic model and an OD model is going to be one of these per capita rates and then the bulk rates just get calculated, based on the model structure.

1022
02:32:46,200 --> 02:33:06,180
Michael Akira Lee Hayashi: Alright, so I also alluded to the fact that comfort mental models like odd models do have a correspondence to stochastic models so for a given O D model, you can almost always make a corresponding continuous time Markov chain model of that system.

1023
02:33:08,640 --> 02:33:14,730
Michael Akira Lee Hayashi: In particular, the reason for this is that each of those bulk rate terms in a differential equation.

1024
02:33:15,090 --> 02:33:31,980
Michael Akira Lee Hayashi: can be thought of as the rate parameter for a corresponding person process another way of putting this is each of these define some event in the system that changes, the number of things in that system, so this might be this.

1025
02:33:32,910 --> 02:33:36,480
Michael Akira Lee Hayashi: Right, so if I have an si our model, a fairly classical and refine.

1026
02:33:37,500 --> 02:33:41,820
Michael Akira Lee Hayashi: The dot notation is the equivalent to this is equal to dsd to.

1027
02:33:43,170 --> 02:33:46,590
Michael Akira Lee Hayashi: see this so let's do let's do a very classic si our model.

1028
02:33:47,940 --> 02:33:49,920
Michael Akira Lee Hayashi: This is minus beta si.

1029
02:33:51,000 --> 02:34:00,870
Michael Akira Lee Hayashi: This is beta so I managed to make my s look like a delta that's remarkable minus gamma I this is Gemini.

1030
02:34:01,980 --> 02:34:22,050
Michael Akira Lee Hayashi: So in each of these differential equations we have terms right, so this is a term, this is a term, this is a term, and this is each of these corresponds to an event in a corresponding stochastic system, so this some this beta si term this corresponds to infection.

1031
02:34:26,010 --> 02:34:32,550
Michael Akira Lee Hayashi: Where the gamma I there's a delta gamma symmetrical the gamma is recovered.

1032
02:34:35,700 --> 02:34:45,510
Michael Akira Lee Hayashi: And so we can think about this in the same way as our our stochastic model where we're here oh that's sloppy we had initiation and cessation.

1033
02:34:46,110 --> 02:34:59,310
Michael Akira Lee Hayashi: Changing the state of the system, according to some bulk rate, now we have the same thing, so an infection events this thing is essentially equivalent in a stochastic model to saying s minus one.

1034
02:35:00,240 --> 02:35:06,330
Michael Akira Lee Hayashi: I plus one recovery is equivalent to saying I minus one R plus one.

1035
02:35:06,990 --> 02:35:18,810
Michael Akira Lee Hayashi: So in this way we can use a lot of the information from our O D model to construct an equivalent stochastic model where the stochastic model we still keep track of S I.

1036
02:35:19,140 --> 02:35:29,700
Michael Akira Lee Hayashi: n are over time, in the same way that we did that's getting sloppy in the same way that we did in the deterministic model, except that now our model accommodates the potential for random changes.

1037
02:35:31,050 --> 02:35:43,200
Michael Akira Lee Hayashi: And i'll reiterate here recall that these rate parameters represent the total rate, the bulk rate, so this beta si is the bulk rate of infection it happens to be a nonlinear bulk rate that's legal.

1038
02:35:43,710 --> 02:35:50,190
Michael Akira Lee Hayashi: The gamma I is a linear bulk rate it's just the per capita rate times the number of infectious people.

1039
02:35:51,480 --> 02:35:56,280
Michael Akira Lee Hayashi: So if you can read a deterministic model, and you can read kind of the.

1040
02:35:57,090 --> 02:36:08,400
Michael Akira Lee Hayashi: The terms in that model, and you can understand what those mean you can then build a corresponding stochastic model of that system if you wanted to test say the deterministic model for smaller population or something of that nature.

1041
02:36:10,800 --> 02:36:12,030
Michael Akira Lee Hayashi: Questions or thoughts.

1042
02:36:30,690 --> 02:36:43,020
Michael Akira Lee Hayashi: Well they're being done i'll end this particular bit by saying that one of the uses of this correspondence is that you can test some of the assumptions of odd models, by doing this, like if you're worried.

1043
02:36:43,290 --> 02:36:50,970
Michael Akira Lee Hayashi: that the disease that you're studying or whatever it is that you're studying has an effective population that's a little bit too small for deterministic model.

1044
02:36:51,360 --> 02:36:58,950
Michael Akira Lee Hayashi: You could make a stochastic model and see if the trajectories from this to cast model looks very different from the deterministic model trajectories.

1045
02:36:59,100 --> 02:37:09,600
Michael Akira Lee Hayashi: And if they do, then you're probably right to be suspicious, or if they don't, then you can probably get away with your deterministic models so you can use this particular corpse correspondence for diagnostic purposes.

1046
02:37:09,900 --> 02:37:17,490
Michael Akira Lee Hayashi: And to save yourself some compute work because this system is going to take longer to run into this so that can be nice also.

1047
02:37:21,630 --> 02:37:31,290
Michael Akira Lee Hayashi: All right, I didn't I thought we might not get here but let's let's talk a bit about Monte Carlo methods and simulation methods for continuous time markup processes, because they're a little more involved.

1048
02:37:33,840 --> 02:37:39,780
Michael Akira Lee Hayashi: Monte Carlo methods are a broad umbrella of methods that basically solve a problem by iterative sampling.

1049
02:37:40,710 --> 02:37:45,900
Michael Akira Lee Hayashi: I like to describe this as the way that I learned to explain something to someone i'll usually try one method.

1050
02:37:46,200 --> 02:37:55,710
Michael Akira Lee Hayashi: And it won't make any sense and then i'll try another explanation and it'll make slightly more sense and i'll keep doing that, until eventually come up with an explanation that seems to make sense, the person i'm talking to.

1051
02:37:56,970 --> 02:38:06,300
Michael Akira Lee Hayashi: And so that essentially as a Monte Carlo method you you do a bunch of random sampling and then you use the result of all those random samples you use the composite of the random samples.

1052
02:38:06,570 --> 02:38:12,870
Michael Akira Lee Hayashi: To tell you something about the procedure that you actually wanted a common use, for this is numerical integration so.

1053
02:38:13,950 --> 02:38:21,510
Michael Akira Lee Hayashi: Integration is fundamentally the process of calculating the area under some curve and then this is actually a really useful process like.

1054
02:38:21,870 --> 02:38:35,220
Michael Akira Lee Hayashi: calculus disguises the fact that this is what it is, but that's all the tap room and your integrate right you want to calculate this thing that's the integral of this function now I could do that using calculus or by using numerical integration.

1055
02:38:36,390 --> 02:38:49,200
Michael Akira Lee Hayashi: But if I wanted to I could also calculate this by using a Monte Carlo method, I know the expression for this function, which means that I am able to tell whether value lies above or below the function.

1056
02:38:50,640 --> 02:38:53,580
Michael Akira Lee Hayashi: I also know the domain and range of the function so.

1057
02:38:55,050 --> 02:38:58,980
Michael Akira Lee Hayashi: This area here forms a rectangle about the function.

1058
02:39:00,000 --> 02:39:13,080
Michael Akira Lee Hayashi: So what I could do is essentially throw darts at this board at this rectangle, and each time I throw a dart if a dart lands below the function which I can tell, because I know the value of the function all label that as a hit.

1059
02:39:14,640 --> 02:39:18,030
Michael Akira Lee Hayashi: And if the dart lands above the value of the function.

1060
02:39:19,590 --> 02:39:21,480
Michael Akira Lee Hayashi: I don't know later label that as a miss.

1061
02:39:23,880 --> 02:39:38,190
Michael Akira Lee Hayashi: what's cool about this is that all of these hits because they lie underneath the area, the function, I can use the essentially the proportion of hits to Mrs couples with the total area of the rectangle bounding this function.

1062
02:39:38,760 --> 02:39:45,060
Michael Akira Lee Hayashi: to approximate the value of the integral of this function over this range so.

1063
02:39:46,290 --> 02:39:56,940
Michael Akira Lee Hayashi: If if, for example, 50% of these dots were green compared to the red dots, and this is 10 by five, then the area underneath that curve is 25.

1064
02:39:58,200 --> 02:40:05,790
Michael Akira Lee Hayashi: And I didn't have to do an amount of calculus in order to do that, and this can be a nice method when.

1065
02:40:06,300 --> 02:40:18,630
Michael Akira Lee Hayashi: The actual analytical integral of the function is either impossible or really hard to calculate and so you can get at it through sampling, this can also be a way to numerically integrate a function if, for some reason.

1066
02:40:19,260 --> 02:40:29,490
Michael Akira Lee Hayashi: It defies your ability to numerically integrated using one of the numerical integration routines that we use for O D methods like an oil or method or a rounded cut integrator or.

1067
02:40:29,640 --> 02:40:39,930
Michael Akira Lee Hayashi: One of numerous kinds of numerical integrators every so often those will fail on a function, because the function does something that they just can't handle a lot of cases where this is so, is where you get a model that.

1068
02:40:40,170 --> 02:40:47,100
Michael Akira Lee Hayashi: has really widely oscillating behavior and really sharp peaks and troughs maybe a flat spot and then some peaks and troughs.

1069
02:40:47,640 --> 02:40:56,850
Michael Akira Lee Hayashi: This is hard for a numerical OPS up the numerical integrator to solve because there's a lot of variation there's a lot of change and sometimes there's not a lot of change.

1070
02:40:57,300 --> 02:41:13,590
Michael Akira Lee Hayashi: So if you had a problem, like this and you needed to know the area under the curve you what you might do is Monte Carlo integration to approximate what the area under this curve is without bumping into the problem of your numerical integrator choking on the function and failing.

1071
02:41:15,630 --> 02:41:23,430
Michael Akira Lee Hayashi: A lot of numerical methods are kind of a find something that works for your particular problem situation, so if one thing doesn't work there's often another one that might.

1072
02:41:24,510 --> 02:41:24,900
Michael Akira Lee Hayashi: anyway.

1073
02:41:25,980 --> 02:41:31,650
Michael Akira Lee Hayashi: So I had an example here of estimating the value of pie, by doing a similar kind of.

1074
02:41:33,030 --> 02:41:43,170
Michael Akira Lee Hayashi: Put a thing inside another thing and then figure out how many darks hit inside that thing but frankly I like the integration example better so i'm not really going to get into this, needless to say.

1075
02:41:43,500 --> 02:41:51,750
Michael Akira Lee Hayashi: You can use numerical integration herbs, or you can use Monte Carlo methods in a lot of contexts to estimate values that are hard to do otherwise.

1076
02:41:52,770 --> 02:42:04,650
Michael Akira Lee Hayashi: Of course, the precision of a Monte Carlo method depends on the number of samples you take, and how well you've sampled the space that you're trying to sample so you need both broad coverage and a lot of coverage which.

1077
02:42:05,310 --> 02:42:14,070
Michael Akira Lee Hayashi: Unsurprisingly, makes Monte Carlo methods fairly computationally intensive compared to similar methods for solving a problem, but sometimes, this is what you have to do.

1078
02:42:17,700 --> 02:42:29,280
Michael Akira Lee Hayashi: Why do we care about that from the perspective of simulating a stochastic model well because all of our simulation methods fundamentally are Monte Carlo methods so when we're simulating a continuous time.

1079
02:42:29,700 --> 02:42:40,170
Michael Akira Lee Hayashi: Markov chain what we're doing is we're sampling from some probability distribution and we're using those samples to tell us something about the trajectory of the model.

1080
02:42:40,620 --> 02:42:48,180
Michael Akira Lee Hayashi: One of the classic methods for this, which I think I think my plan for these methods isn't going to talk you through how they work.

1081
02:42:48,990 --> 02:42:54,000
Michael Akira Lee Hayashi: I don't know if i'll necessarily quote them if we do have a good amount spare time, maybe i'll start coding one of these.

1082
02:42:54,420 --> 02:43:03,750
Michael Akira Lee Hayashi: These are the sorts of methods that are hard for me to code blind, because I have to think through a little bit of the implementation so it doesn't always go well doing it like totally live.

1083
02:43:05,640 --> 02:43:18,750
Michael Akira Lee Hayashi: But we'll see so the gillespie exact simulation methods is one of the core methods to simulate a trajectory from a continuous time marketing this thing got developed in the 70s, it was originally designed for chemical reaction systems so.

1084
02:43:20,910 --> 02:43:29,160
Michael Akira Lee Hayashi: chemical reactions tend to obey kinetics laws that look a lot like a like a like some of the ot systems we've seen and.

1085
02:43:30,300 --> 02:43:38,610
Michael Akira Lee Hayashi: that's no mistake, because a lot of the ott models, we use are based on chemical reaction systems, fundamentally, but anyway.

1086
02:43:40,050 --> 02:43:51,090
Michael Akira Lee Hayashi: The this particular simulation method relies on the fact that the waiting times and continuous time Markov chain are put on processes, and so are exponentially distributed.

1087
02:43:52,500 --> 02:44:00,960
Michael Akira Lee Hayashi: This is nice, because we can do the follow for kind of a tl Dr what the gillespie method is doing is it is figuring out.

1088
02:44:01,350 --> 02:44:12,540
Michael Akira Lee Hayashi: When the next event happens in the system and then what that event actually was so breaks the simulation method down essentially it's a two stages that it repeats a whole ton of times until we decide that we're done.

1089
02:44:13,800 --> 02:44:26,430
Michael Akira Lee Hayashi: So we we start our system off in some state, and we have all the rates for all of the events in the system, in particular we're usually given the per capita rates for the events in the system, because those are the parameters.

1090
02:44:27,000 --> 02:44:34,320
Michael Akira Lee Hayashi: And then we success we successively calculate the rate of the system as a whole.

1091
02:44:35,100 --> 02:44:44,340
Michael Akira Lee Hayashi: determine a waiting time and then draw an event from a from essentially a partitions distribution of events, a discrete probability distribution over the events.

1092
02:44:44,730 --> 02:44:48,630
Michael Akira Lee Hayashi: So let me step through the algorithm and then i'll step back and we'll talk about what this means.

1093
02:44:49,590 --> 02:44:58,920
Michael Akira Lee Hayashi: So to do this thing you want to start off by initializing the number of items in each state the per capita rate constants and the total simulation.

1094
02:44:59,520 --> 02:45:08,010
Michael Akira Lee Hayashi: We don't specify a time step, because this is a continuous time method that will cause events to fire at arbitrary times over the course of the simulation.

1095
02:45:09,510 --> 02:45:12,600
Michael Akira Lee Hayashi: Note that this is also designed for use with those models where.

1096
02:45:13,800 --> 02:45:23,850
Michael Akira Lee Hayashi: you're counting the number of things in each state but there's no reason you can't actually use it for an individual based simulation that actually works fine too i've done it it's fine it works.

1097
02:45:25,830 --> 02:45:36,480
Michael Akira Lee Hayashi: The algorithm then proceeds as follows, you calculate the total rate of each possible events by multiplying the per capita rate of that event by the total number of things in the State from which.

1098
02:45:36,690 --> 02:45:50,130
Michael Akira Lee Hayashi: I think comes out of when an event fires, so the from state times the event that modifies that from state, then you sum up all of those total rates to give you the total event rate of the system.

1099
02:45:51,150 --> 02:45:57,750
Michael Akira Lee Hayashi: What this thing is basically saying is that I have a bunch of events that could happen in my system, I could get sick I could recover I could die.

1100
02:45:59,430 --> 02:46:05,400
Michael Akira Lee Hayashi: But what I really wants to know is how frequently does literally anything happened in the system.

1101
02:46:06,420 --> 02:46:12,900
Michael Akira Lee Hayashi: Right now, I don't care if its death or recovery or infection, I just want to know how fast anything is going to happen.

1102
02:46:14,400 --> 02:46:19,950
Michael Akira Lee Hayashi: So that's what this total evaporated, this is what happens when you sum up all of these bulk rates.

1103
02:46:20,610 --> 02:46:32,760
Michael Akira Lee Hayashi: Now i'm going to do the when did an event happen thing so i'm going to draw a random number from an exponential distribution where its rate parameter is this total event rate of the system that I just calculated.

1104
02:46:34,050 --> 02:46:43,440
Michael Akira Lee Hayashi: And that's going to give me the time of the next event, you may see this method described as the times next event method and that's no mistake.

1105
02:46:44,700 --> 02:46:48,870
Michael Akira Lee Hayashi: Now i'm halfway there I know when something happened now I need to know what happened.

1106
02:46:50,160 --> 02:46:56,520
Michael Akira Lee Hayashi: And it might not be immediately obvious how we figure out the relative probability of each event happening in the system.

1107
02:46:56,880 --> 02:47:06,510
Michael Akira Lee Hayashi: It turns out that this can be done, surprisingly, simply, and in fact we can just create a discrete probability distribution, where the probability of a given event happening.

1108
02:47:06,870 --> 02:47:19,440
Michael Akira Lee Hayashi: is just the total rate of that event divided by the total rate of the system, so if this is infection, this would be beta times as times I divided by whatever the sum of all those bulk rates are in the system.

1109
02:47:19,950 --> 02:47:23,190
Michael Akira Lee Hayashi: The reason this works is that what we're drawing is not.

1110
02:47:23,940 --> 02:47:33,330
Michael Akira Lee Hayashi: The probability of a given event unconditionally instead what we're drawing is the probability of that event conditional on the fact that something happens.

1111
02:47:33,750 --> 02:47:51,450
Michael Akira Lee Hayashi: We know that an event happen, we just don't know which one, and the fact that we've made this a conditional probability now means that that conditional probability is given by the relative rate of that specific event where that where it's normalized by the rate of every event.

1112
02:47:52,920 --> 02:48:01,080
Michael Akira Lee Hayashi: Now that we figured out which event happens, we update the counts of things in the system, according to the event that we drew out that should be for whoops.

1113
02:48:02,880 --> 02:48:17,910
Michael Akira Lee Hayashi: As well as when that event happened so we figure out when an event happens, we figure out what events happens, then we update our system to reflect the fact that that event actually happened, and then we just repeat this whole process until we hit our EMS time.

1114
02:48:21,030 --> 02:48:31,290
Michael Akira Lee Hayashi: So that's the gillespie simulation method it's actually it's fairly straightforward to write, although there's a couple of weird little gotchas in there that can that mean that you have to do some accounting but.

1115
02:48:32,610 --> 02:48:38,880
Michael Akira Lee Hayashi: there's nothing terribly magical about it from the perspective of the algorithm what's nice about this is that it will generate a.

1116
02:48:39,270 --> 02:48:50,520
Michael Akira Lee Hayashi: Statistically correct trajectory of the model, it is guaranteed that if you simulate your model, using the gillespie method and didn't write it wrong and you didn't put a bug in there.

1117
02:48:50,940 --> 02:49:04,350
Michael Akira Lee Hayashi: Then any trajectory that comes out of your model has to have been drawn from the probability distribution governing every trajectory that could have come out of that model that's cool because that means that.

1118
02:49:05,610 --> 02:49:16,980
Michael Akira Lee Hayashi: You can do things like established the range of trajectories that can happen in that model you you're guaranteed that none of those are going to be wrong in some sense and that's really nice.

1119
02:49:17,910 --> 02:49:23,940
Michael Akira Lee Hayashi: i've written a little bit of pseudo code here just to kind of give an outline for how one might think about writing this.

1120
02:49:25,530 --> 02:49:43,380
Michael Akira Lee Hayashi: notice that, so I initialize some things I say when I start, I say what my population state vector is, I have a vector that holds all of my event rates i'm assuming in this case that one event corresponds to one event rate sometimes this isn't totally right.

1121
02:49:44,340 --> 02:49:52,320
Michael Akira Lee Hayashi: So there's a little bit more fluff to do there and accounting, but then the primary loop notice here that I use a while, and the reason that I do this is.

1122
02:49:52,740 --> 02:50:07,650
Michael Akira Lee Hayashi: A gillespie simulation is not evenly spaced in time, so the events are going to fire sometimes here like that over here another one over here, something like this and that, so I have no way to write a for loop that gets me through this system.

1123
02:50:08,790 --> 02:50:17,370
Michael Akira Lee Hayashi: What this does also means that I need to make sure that I update things properly in my while loop to actually guarantee that the simulation terminates, otherwise it will never stop.

1124
02:50:17,910 --> 02:50:22,020
Michael Akira Lee Hayashi: So I have to be careful about that and that's a general thing to be careful about when you're writing file loops.

1125
02:50:23,820 --> 02:50:26,610
Michael Akira Lee Hayashi: In this in the while loop I.

1126
02:50:27,630 --> 02:50:30,720
Michael Akira Lee Hayashi: am assuming that there is a helper function that i've written somewhere.

1127
02:50:31,320 --> 02:50:43,410
Michael Akira Lee Hayashi: That calculates what the bulk event rates for every event in the model is so this thing is basically taking an event multiplying it by its corresponding State from which it comes and then storing that in some vector.

1128
02:50:45,510 --> 02:50:52,380
Michael Akira Lee Hayashi: Then I calculate the total rate at system by adding up every element oops every element of this vector.

1129
02:50:53,790 --> 02:51:01,800
Michael Akira Lee Hayashi: Then I draw an exponentially distributed random number, with a rate parameter equal to this total rate that I just calculated.

1130
02:51:02,730 --> 02:51:09,300
Michael Akira Lee Hayashi: Then i'm going to have some new helper function, which is essentially creating that discrete probability distribution.

1131
02:51:09,780 --> 02:51:19,590
Michael Akira Lee Hayashi: That uses these rates and this one to figure out the probability of each event and then it samples any event from that that vector essentially that comes out of this function.

1132
02:51:20,760 --> 02:51:28,830
Michael Akira Lee Hayashi: And then I have some additional helper function to tell me what to do, given the event that fired and how to change the state.

1133
02:51:29,610 --> 02:51:35,040
Michael Akira Lee Hayashi: How to change the value of the State space according to that event I update my time and then I go to so.

1134
02:51:36,030 --> 02:51:38,400
Michael Akira Lee Hayashi: One thing to keep in mind, looking at the pseudo code here is that.

1135
02:51:39,000 --> 02:51:54,960
Michael Akira Lee Hayashi: I would have I would have had to have implemented each of these helper functions to make this go where each of these encompasses a particular bit of the algorithm this calculate event rates, this is doing this stage or sorry No, this is doing this stage.

1136
02:51:56,940 --> 02:52:02,490
Michael Akira Lee Hayashi: This here that's not a helper function that's just something that I can get this is this right here.

1137
02:52:03,480 --> 02:52:09,810
Michael Akira Lee Hayashi: This helper function does have to come from figuring out what event happens, and so it is implementing this essentially.

1138
02:52:10,170 --> 02:52:18,540
Michael Akira Lee Hayashi: create a discrete probability distribution, where each element is the rate of that event divided by the total rate, the bulk rate of that event divided by the total rate.

1139
02:52:19,620 --> 02:52:27,180
Michael Akira Lee Hayashi: And then the final function is the updating one the changes my counts, based on which event happens so often this function is something looks like.

1140
02:52:28,470 --> 02:52:45,330
Michael Akira Lee Hayashi: If he equals one X minus one X equals X minus one I equals I plus one else if the equal to I equals I minus one.

1141
02:52:47,610 --> 02:52:58,020
Michael Akira Lee Hayashi: R equals R plus one so that's what might be inside of this function, there are clever ways to write this, but this would be the most straightforward way to do it using a bunch of logical checks.

1142
02:53:01,620 --> 02:53:12,540
Michael Akira Lee Hayashi: So the gillespie method, as I mentioned, is primarily Nice because it generates exact trajectories they are properly drawn from the distribution of trajectories of that month.

1143
02:53:14,340 --> 02:53:19,020
Michael Akira Lee Hayashi: But, as is usually the case with methods.

1144
02:53:19,560 --> 02:53:25,110
Michael Akira Lee Hayashi: We don't get something for nothing, and the gillespie method is probably the slowest of the simulation methods we could think of.

1145
02:53:25,350 --> 02:53:40,710
Michael Akira Lee Hayashi: To do stochastic simulation because it has to stop, every time the event happens so its speed is governed by whichever event happens fastest in the system, so if you have a model that has a lot of very fast events, a gillespie simulation is going to be really, really slow.

1146
02:53:42,930 --> 02:53:49,890
Michael Akira Lee Hayashi: Which which is this particular leading question suppose my model comprises of things that happen on a timescale of seconds.

1147
02:53:50,160 --> 02:53:56,130
Michael Akira Lee Hayashi: And I need to simulate this model for years i'm going to be waiting for a really long time for that model to complete because.

1148
02:53:56,970 --> 02:54:11,730
Michael Akira Lee Hayashi: Those events just keep happening and the simulation routine has to keep stopping to update the state of the system, every time one of those things happens, and that is a lot and that takes a lot of time and a lot of computations to make that happen.

1149
02:54:12,900 --> 02:54:18,810
Michael Akira Lee Hayashi: Nevertheless, it's often a good starting point, because it's fairly straightforward to code at the end of the day, this is not bad.

1150
02:54:19,350 --> 02:54:26,280
Michael Akira Lee Hayashi: Like these functions, you can be more or less clever about that mean you're writing a thing that's more or less part to code, but they're not.

1151
02:54:26,670 --> 02:54:33,000
Michael Akira Lee Hayashi: there's nothing magical and there's nothing about them, that means you have to dig into the annals of weird coding practice to figure out.

1152
02:54:33,210 --> 02:54:45,810
Michael Akira Lee Hayashi: it's mostly a question of Do you understand how to manipulate variables stored in vectors and then, can you use like logic to figure out what thing goes, where do you have access to a sampling function, or something like that.

1153
02:54:51,870 --> 02:55:00,570
Michael Akira Lee Hayashi: Very quickly, then I am going to give you an introduction to another simulation method which is fairly commonly used my primary purpose of.

1154
02:55:00,990 --> 02:55:07,020
Michael Akira Lee Hayashi: describing these methods is that so when you see them in the literature, when someone else mentioned them you'll be like oh.

1155
02:55:07,290 --> 02:55:24,630
Michael Akira Lee Hayashi: I have this word in my brain somewhere I kind of think I remember what some of it means so that you get a little bit of a hook, because you will see these methods used multiple times in papers that are implementing a stochastic model you'll see tallied been used a lot because.

1156
02:55:26,160 --> 02:55:27,570
Michael Akira Lee Hayashi: gillespie simulation is slow.

1157
02:55:28,050 --> 02:55:35,850
Michael Akira Lee Hayashi: And we don't like slow when we're doing computational models, if we can help it so we could say that, instead of making an exact trajectory.

1158
02:55:36,030 --> 02:55:42,720
Michael Akira Lee Hayashi: let's do an approximation that has discrete time steps so now we're doing the discrete approximations with continuous time process.

1159
02:55:43,170 --> 02:55:53,700
Michael Akira Lee Hayashi: This looks a lot like oilers method of numerical interment integration in oilers method in order to approximate a smooth curve what you do is you take discrete steps.

1160
02:55:56,730 --> 02:56:06,180
Michael Akira Lee Hayashi: Through this curve that tell you where you are at each or what the area is at each of these rectangular blocks.

1161
02:56:06,600 --> 02:56:19,680
Michael Akira Lee Hayashi: And that gives you the area and approximation to the area under the curve and it's a pretty chunky one, but it suffices under reasonable approximations and most numerical integrators under the sun, are doing some variant of this but clever.

1162
02:56:21,060 --> 02:56:31,530
Michael Akira Lee Hayashi: Now the towel weeping method does kind of an analogous thing for a stochastic well what we're going to say is let's suppose that we take discrete time steps through our.

1163
02:56:31,950 --> 02:56:41,280
Michael Akira Lee Hayashi: Our simulation instead of letting events fire whenever they want to know what we're going to say is suppose that between these times steps.

1164
02:56:42,750 --> 02:56:47,520
Michael Akira Lee Hayashi: Some events happen so a red event a purple event and a blue event happened.

1165
02:56:49,470 --> 02:56:56,670
Michael Akira Lee Hayashi: And when my simulation clock ticks over to time step one i'm going to resolve the read the purple and the blue event.

1166
02:56:56,880 --> 02:57:12,180
Michael Akira Lee Hayashi: That happened in this time interval, so this is one of those sort of lazy evaluation methods, where i'm not going to stop and recalculate every time an event happens i'm going to let a few events accumulate and then resolve them all at once, so I save myself some time and doing that.

1167
02:57:13,800 --> 02:57:14,790
Michael Akira Lee Hayashi: in particular.

1168
02:57:16,230 --> 02:57:22,290
Michael Akira Lee Hayashi: What we can rely on is the fact that in one of these intervals, a given event is going to happen.

1169
02:57:23,700 --> 02:57:42,630
Michael Akira Lee Hayashi: A number of times that has put some distributed according to its bulk rate and the size of the timestamp so the change in the number of objects in a given compartment is going to be equal to the number of objects in the compartment when started plus.

1170
02:57:44,460 --> 02:57:56,880
Michael Akira Lee Hayashi: A number of changes equal to a plus on random variable with the total rate times with with a rate parameter equal to the total rate times the time interval So this is the part that saying.

1171
02:57:57,270 --> 02:58:07,050
Michael Akira Lee Hayashi: suppose that to blue events happened in this time step well i'm going to resolve the blue event twice next time my simulation clock ticks over, and they need to change something.

1172
02:58:07,770 --> 02:58:15,210
Michael Akira Lee Hayashi: This can save us quite a lot of time because we aren't stopping to evaluate every single event that fires ever.

1173
02:58:17,370 --> 02:58:28,740
Michael Akira Lee Hayashi: So here's the algorithm i'll talk it through and then we'll talk about when it might be good, and when it might not be so good teams, this is a more complicated one because it has to do a little bit more.

1174
02:58:30,120 --> 02:58:36,690
Michael Akira Lee Hayashi: annoyingly the faster method is a little bit trickier to Code and the the slower method this, this is a lot.

1175
02:58:37,680 --> 02:58:47,580
Michael Akira Lee Hayashi: So we're going to initialize our model, the same ways we did for the gillespie method we're going to set up our initial populations or initial time all of the rates, the per capita rates for events, then.

1176
02:58:48,990 --> 02:58:59,220
Michael Akira Lee Hayashi: Our model we're going to pick a fixed timestamp we don't have to keep this the same every time step in the model often we do because it's convenient but note that we do not have to.

1177
02:59:01,200 --> 02:59:11,490
Michael Akira Lee Hayashi: Then we're going to again calculate the bulk rates for every event in the system, but instead of adding those together to get the total rate the system.

1178
02:59:12,210 --> 02:59:22,920
Michael Akira Lee Hayashi: What we're actually going to do is figure out the number of times each event happened between time T and time T plus town so between now and the next step.

1179
02:59:25,170 --> 02:59:38,400
Michael Akira Lee Hayashi: supposed to green events happened a purple one and two rats and the way that we know the number of times that each event happened is by drawing some random number from a person distribution, whose rate parameter is the.

1180
02:59:40,380 --> 02:59:44,280
Michael Akira Lee Hayashi: The total rate of the event times tell the type of stuff sighs.

1181
02:59:45,450 --> 02:59:51,120
Michael Akira Lee Hayashi: Then, knowing that some events that say the green event happened twice.

1182
02:59:53,070 --> 03:00:07,440
Michael Akira Lee Hayashi: we're going to update the compartments that were influenced by the Green event twice so suppose Green is an infection What this means is that there were two infections between times zero and time zero Plus towel or time towel.

1183
03:00:08,580 --> 03:00:22,950
Michael Akira Lee Hayashi: That means that I need to take two people out of the susceptible compartment and put two people in the infectious compartment because that's how many events happened, but now we have to do an extra little check and then we do this for every event so suppose Green is infection.

1184
03:00:24,450 --> 03:00:31,740
Michael Akira Lee Hayashi: purple is recovery and read his death, so that means that two people were infected one people recovered and two people died.

1185
03:00:32,880 --> 03:00:45,120
Michael Akira Lee Hayashi: Now, because we're using an interval over which multiple events can happen and we're only evaluating at the end of that interval we do have to check that the states of the events, the number of things in each state.

1186
03:00:46,920 --> 03:00:50,400
Michael Akira Lee Hayashi: Is bounded by the condition of the problem and what I mean by that is i'm.

1187
03:00:51,450 --> 03:00:56,580
Michael Akira Lee Hayashi: suppose that I say that two deaths happened, but there was only one person who could have died.

1188
03:00:57,030 --> 03:01:04,230
Michael Akira Lee Hayashi: Well that's bad because, if I tried to subtract two from one I get negative one, and now my whole system goes to plot and everything breaks they get a weird error.

1189
03:01:04,650 --> 03:01:12,060
Michael Akira Lee Hayashi: or, worse, it keeps running and I get really strange results, so if I find an event fires more times than it has people to draw from.

1190
03:01:12,570 --> 03:01:24,300
Michael Akira Lee Hayashi: I have to bound that event execution, to make sure that it doesn't go too many times what this also means that the gillespie method cares about what order you resolve effects it.

1191
03:01:24,870 --> 03:01:35,670
Michael Akira Lee Hayashi: If I have to green events which move to people from green to purple purple event which moves a purple a person from purple to read and then to read events which me move to read people out.

1192
03:01:37,080 --> 03:01:44,370
Michael Akira Lee Hayashi: It matters what order I do those and if I start by moving the Greens, or if I start by moving the purple or if I start by moving the reds.

1193
03:01:44,610 --> 03:01:54,330
Michael Akira Lee Hayashi: So sometimes you have to be a little careful about the order in which you evaluate your events in practice, not a huge amount, because as long as you're doing your boundary check your mostly safe.

1194
03:01:54,870 --> 03:02:07,950
Michael Akira Lee Hayashi: And then you keep going until you stop one nice thing about it, the less be simulation is that you can use a for loop, because if you're using a fixed time step, you know how many times stuff there are between time T and time T mo time big T right.

1195
03:02:09,390 --> 03:02:21,570
Michael Akira Lee Hayashi: So that's nice you get to use a for loop instead of a while loop, and you do gain some speed by using lazy evaluation to only recalculate your system at certain intervals.

1196
03:02:25,980 --> 03:02:31,560
Michael Akira Lee Hayashi: Well i'm not going to go over the pseudo code all that much because it would take there's more to it there.

1197
03:02:33,120 --> 03:02:48,330
Michael Akira Lee Hayashi: The child we think method is almost always faster than the gillespie method, assuming that your tau is big enough, so why is this the case, why is it that you could write a towel leaping method which is basically as slow, as it gillespie method what could you do to make that happen.

1198
03:03:36,570 --> 03:03:41,430
Michael Akira Lee Hayashi: So what happens as I make my TAO smaller as I make my time steps smaller and smaller and smaller.

1199
03:04:08,880 --> 03:04:14,490
Michael Akira Lee Hayashi: So the thing to note here is that the size of your town, the size of your time step pretty much directly.

1200
03:04:14,850 --> 03:04:26,160
Michael Akira Lee Hayashi: corresponds to the expected number of events that will happen in that time step, so if my town is big a lot of events will happen in the time step and that's a fast case, that means that I can evaluate a lot.

1201
03:04:26,520 --> 03:04:39,660
Michael Akira Lee Hayashi: At every time step and that speeds up by a decent thing, however, as my tell gets closer and closer like smaller and smaller, to the point where it starts to get closer to the rate with which events actually happen.

1202
03:04:40,110 --> 03:04:48,480
Michael Akira Lee Hayashi: Well now, my tell leaping simulation looks a lot more like a gillespie simulation and that i'm stopping to recalculate stuff closer to every time.

1203
03:04:48,840 --> 03:04:57,420
Michael Akira Lee Hayashi: An event at all happens tell even gives you the biggest speed up when you can kind of bypass some of the events happening to evaluate multiples at once.

1204
03:04:57,750 --> 03:05:01,890
Michael Akira Lee Hayashi: You can actually write a towel leaping simulation that slower than the gillespie simulation.

1205
03:05:02,160 --> 03:05:12,270
Michael Akira Lee Hayashi: If you make the Tower so small that an expectation know events happened in that towel, which is awfully silly but you could do it, you could make the slowest tell leaping simulation in the entire world.

1206
03:05:12,540 --> 03:05:19,380
Michael Akira Lee Hayashi: By picking an incredibly small town, so that, on average, literally nothing happens in any of these timestamps so you're.

1207
03:05:20,160 --> 03:05:25,560
Michael Akira Lee Hayashi: you're stopping your simulation for no particular reason, in order to keep doing this, so.

1208
03:05:25,920 --> 03:05:36,330
Michael Akira Lee Hayashi: Tell leaping is a little bit trickier and that you have to kind of calibrate your tower so that it's small enough that you can catch a few events happening, but also not so large.

1209
03:05:36,690 --> 03:05:42,810
Michael Akira Lee Hayashi: That you accumulate too many events and you're constantly bumping up against your boundary condition, because if this happens.

1210
03:05:43,140 --> 03:05:58,080
Michael Akira Lee Hayashi: Then you're accumulating error in your simulation trajectory by changing too much all at once, so you tend to have to thread that balance in the towel weeping implementation wearing a gillespie simulation you don't have to think about that at all and that's kind of Nice.

1211
03:06:00,840 --> 03:06:08,760
Michael Akira Lee Hayashi: So that's that's that's that there are additional ways to kind of improve the performance of Intel leaping simulation to make it a little more adaptive.

1212
03:06:09,000 --> 03:06:16,170
Michael Akira Lee Hayashi: stuff like that we're not really going to go over that, but the main thing to keep in mind here between the gillespie and the Tower simulation methods is that.

1213
03:06:16,440 --> 03:06:31,770
Michael Akira Lee Hayashi: gillespie method works by drawing when an event happens and then figuring out what event happens and then updating the system, the towel weeping method takes a time step figures out how many events of any kind happened in that time step resolves them all and then goes again.

1214
03:06:33,270 --> 03:06:38,550
Michael Akira Lee Hayashi: which usually buys yourself some time and usually make things faster.

1215
03:06:39,750 --> 03:06:43,110
Michael Akira Lee Hayashi: Just takes more code to make sure that you're being safe about it.

1216
03:06:45,210 --> 03:06:47,280
Michael Akira Lee Hayashi: So that I think is we're all leave things off today.

1217
03:06:48,090 --> 03:07:01,620
Michael Akira Lee Hayashi: Let me quickly check the schedule tomorrow morning marissa is going to talk a bit about parameter estimation and sensitivity analysis, I believe, and then in the afternoon we'll talk about my absolute favorite topics decision in game theory so that's bound to be fun.

1218
03:07:03,540 --> 03:07:14,730
Michael Akira Lee Hayashi: So while we're wrapping up for today, are there any remaining questions from the material that we've seen today either either the programming that we've done or the kind of the.

1219
03:07:15,780 --> 03:07:17,790
Michael Akira Lee Hayashi: The didactic material the lecture stuff.

1220
03:07:22,050 --> 03:07:25,380
Nicolle Krebs: Will you post, the final code from our today.

1221
03:07:26,010 --> 03:07:31,170
Michael Akira Lee Hayashi: yeah I will do a little bit of cleanup after I sign off and then i'll post that as a separate file.

1222
03:07:33,120 --> 03:07:34,080
Nicolle Krebs: Okay, thank you.

1223
03:07:37,170 --> 03:07:42,600
Michael Akira Lee Hayashi: Again i'm sorry today is probably the most like information dump lecture day because there's.

1224
03:07:42,660 --> 03:07:44,610
Michael Akira Lee Hayashi: stochastic models are a huge.

1225
03:07:44,790 --> 03:07:54,810
Michael Akira Lee Hayashi: Huge domain, that is almost impossible to cover in any compact way, so I would treat these lecture notes as like a framework of resource that you can.

1226
03:07:55,140 --> 03:08:06,180
Michael Akira Lee Hayashi: have to use when you when you need to do stuff with different kinds of stochastic models, but it is, I understand that there's a lot of crap that we that we speed through for this.

1227
03:08:15,390 --> 03:08:22,080
Michael Akira Lee Hayashi: I think come Thursday or Friday we'll probably spend a little bit more time discussing applications of models to specific health areas because.

1228
03:08:22,350 --> 03:08:37,290
Michael Akira Lee Hayashi: By them that gives you a little bit more time to kind of digest a range of methods and think about their applications, so we tend to front load the methodology and the theory and then try to try to ease into a little bit more application later it's very hard to do otherwise I found.

1229
03:08:39,570 --> 03:08:46,530
Michael Akira Lee Hayashi: At any rate, if there's nothing else i'll let you take a whole minute back and and I will see you all tomorrow afternoon.

1230
03:08:48,660 --> 03:08:49,140
Nicolle Krebs: Thank you.

1231
03:08:50,670 --> 03:08:51,240
Michael Akira Lee Hayashi: Thanks everyone.

