1
00:00:43,650 --> 00:00:46,650
Hey. Good morning, everyone. Let's get started.

2
00:00:49,670 --> 00:00:57,500
I just made the announcement on canvas that those were for my office hour on Zoom of June.

3
00:00:57,980 --> 00:01:07,720
It changed from Tuesday to Monday because Tuesday officers were moved to Tuesday and just wanting to diversify the dates.

4
00:01:08,600 --> 00:01:24,320
A 530 to 630 today. So if you don't have a chance to ask a question to me in person in the morning, which is like 950 to 1030, then you're welcome to,

5
00:01:25,440 --> 00:01:42,650
uh, if you, if you want to join in that all night meeting though, the doors in, in the suit suite of my office is now.

6
00:01:43,190 --> 00:01:48,500
I think it's on that. So you probably can come in more easily, just so you know.

7
00:01:50,280 --> 00:01:54,380
Okay. Uh. And.

8
00:01:56,740 --> 00:02:00,970
The midterm project due is on Wednesday.

9
00:02:01,000 --> 00:02:06,010
I'm sure that many of you are having a hard time to.

10
00:02:07,770 --> 00:02:14,370
Making things work and, you know, pretty much everything when it comes to coding.

11
00:02:15,150 --> 00:02:20,530
You know, debugging takes like 80% to, you know.

12
00:02:22,330 --> 00:02:26,170
Close 100% of prime time that to work on.

13
00:02:26,170 --> 00:02:37,900
So it's a it's a long procedure. And when you're when you're when you have some difficulties in you know, understanding some.

14
00:02:39,330 --> 00:02:44,310
Uh, issues that, uh, that doesn't make sense.

15
00:02:45,490 --> 00:02:52,090
Then it's always good to try with, you know, try to debug with a smaller size of data.

16
00:02:52,090 --> 00:03:04,239
So you can definitely try to debug with the with the full data, but you can also easily simulate different sets of labels.

17
00:03:04,240 --> 00:03:10,149
Instead of using 704 dimensions, you can be five dimensional data.

18
00:03:10,150 --> 00:03:14,080
That is, half of half of them are zero.

19
00:03:14,140 --> 00:03:17,350
Half of them are zero. Half of them. And one in this way, half of measure.

20
00:03:17,350 --> 00:03:26,790
Half of them are one this way. So you. You can make. Those examples yourself and try to use them for for your own.

21
00:03:29,730 --> 00:03:32,549
You know, for for your own debugging.

22
00:03:32,550 --> 00:03:40,590
So that's usually in general a useful strategy and that's the advice I would like to give if you are having problems.

23
00:03:40,590 --> 00:03:47,969
So maybe if you have an issue with a numerical precision, maybe it works fine with a five dimensional data,

24
00:03:47,970 --> 00:03:53,520
but when you try to simulate the data, simulate the data in 100 dimension, they might not work.

25
00:03:53,520 --> 00:03:59,700
So then then you can find out a little bit easier to reproduce the problem you have.

26
00:04:00,930 --> 00:04:07,200
So, you know, making similar data is not required, but that's something you may want to consider.

27
00:04:07,620 --> 00:04:11,280
Okay. And any other question before we start?

28
00:04:12,750 --> 00:04:18,020
Okay. Okay.

29
00:04:18,350 --> 00:04:28,700
So we were talking about dynamic programing and uh, we looked at the first problem,

30
00:04:29,960 --> 00:04:35,120
which is that this is the optimal solution and we learned how to create the optimal solution.

31
00:04:36,730 --> 00:04:47,350
Using the recursive formulation and using recursive formulation, I wanted to get to the equations.

32
00:04:47,350 --> 00:04:57,400
So using this recreate recursive uh, formulation and you can implement this using recursion, but also you can easily formulate using this loop.

33
00:04:57,430 --> 00:05:04,659
So I'd always find with you only show the loop implementation, but you can also make a recursive implementation.

34
00:05:04,660 --> 00:05:11,140
In that case, you need to make sure that don't run the record, run the function every time fully.

35
00:05:12,700 --> 00:05:17,889
You just remember the solution in the if the solution is already stored just as

36
00:05:17,890 --> 00:05:22,330
thoroughly so you can you can make the required recursive implementation that way to.

37
00:05:23,870 --> 00:05:33,530
So and we stopped here. So basically we're talking about the minimum distance problem, which is a basically an alignment of two strings.

38
00:05:34,010 --> 00:05:40,340
And when you align a two string, you basically make make alignment like this way.

39
00:05:41,000 --> 00:05:47,570
In this case, uh, when, when there, when there's no pairs here.

40
00:05:47,630 --> 00:05:57,530
So I'm going to say the first string is a reference string and the second, second string is know alternative string.

41
00:05:57,830 --> 00:06:01,430
Then this is alternative string has insertion here.

42
00:06:02,150 --> 00:06:05,479
And in this case, there's a there's a insertion here.

43
00:06:05,480 --> 00:06:10,840
So that is one one letter was inserted compared to the reference string.

44
00:06:10,850 --> 00:06:23,209
There's only another insertion and there's one deletion. So if you align the string this way, then you can calculate the distance pretty easily.

45
00:06:23,210 --> 00:06:26,770
So once you fix the alignment at a distance that is just given, right?

46
00:06:26,790 --> 00:06:33,170
So here this is a one, two, three, four, five, six.

47
00:06:33,470 --> 00:06:38,540
Okay. And you can, you can, you can.

48
00:06:43,110 --> 00:06:52,380
You can make any distance to have a different penalty for mismatches versus insertion and deletion.

49
00:06:52,800 --> 00:06:56,070
Then the decisions will be defined slightly differently.

50
00:06:56,400 --> 00:07:00,420
Right. So the question is how do we come up with.

51
00:07:01,800 --> 00:07:06,030
This alignment so that that's another way to think about this problem.

52
00:07:06,030 --> 00:07:14,220
So once you have alignment and distance can be calculate directly without running any sophisticated algorithm.

53
00:07:15,000 --> 00:07:19,469
So and there are a lot of possible alignments between the two strings.

54
00:07:19,470 --> 00:07:27,600
So it is actually exponential the exponential complexity problem and how do we turn it,

55
00:07:27,600 --> 00:07:33,300
turn the problem into a polynomial problem that the complexity problem.

56
00:07:35,880 --> 00:07:41,860
Okay. So. So.

57
00:07:44,250 --> 00:07:50,880
So the way how you do it is basically, uh, very similar to the Manhattan tourist problem,

58
00:07:51,540 --> 00:07:59,280
but, uh, make each of those letters as rows or columns in this matrix.

59
00:07:59,430 --> 00:08:06,710
Okay. And in this graph there's only a few connected, but this should be fully connected.

60
00:08:06,720 --> 00:08:12,750
So each of them so these are these are like a manhattan tourist problem, exactly like a grid.

61
00:08:12,750 --> 00:08:20,700
And you can move horizontally and vertically, but also you can move this way.

62
00:08:21,060 --> 00:08:21,350
Okay.

63
00:08:22,050 --> 00:08:32,520
So if you move diagonally, that means that you're making a alignment that actually both letters so both the position have some letters like this.

64
00:08:32,520 --> 00:08:36,360
So this is a diagonal movement. This is diagonal movement.

65
00:08:37,050 --> 00:08:40,320
This is diagonal movement even though there is a mismatch penalty here.

66
00:08:40,620 --> 00:08:51,930
Okay. And if you move this way, that means that you are inserting a new string on the on the,

67
00:08:52,350 --> 00:08:55,889
you know, alternate alternative string, but not the reference string.

68
00:08:55,890 --> 00:09:01,320
So sorry. But this this this should be like this case.

69
00:09:01,320 --> 00:09:04,980
This is a distortion. So these going down represent the insertion.

70
00:09:05,940 --> 00:09:13,229
So then if you go horizontally, that means that you are moving the reference string, but not out of this string.

71
00:09:13,230 --> 00:09:19,980
So in this case, okay, so this is how this is correspond to horizontal mode, which is actually division.

72
00:09:21,200 --> 00:09:28,010
Of a character from the reference string. So that's how you can motivate.

73
00:09:28,100 --> 00:09:31,480
And this particular diagram shows only a variable move.

74
00:09:31,490 --> 00:09:38,480
But, you know, you don't need to worry about these actually numbers now because that that it's a less important.

75
00:09:38,630 --> 00:09:47,560
Okay. So, uh, so how do we, how do they make such and such an alignment?

76
00:09:47,580 --> 00:09:57,360
And how do we find an alignment that minimizes these at a distance, is the question we're going to address today.

77
00:09:57,720 --> 00:10:01,950
Okay. So this kind of algorithm has been used the long time.

78
00:10:01,950 --> 00:10:09,600
So DNA sequence alignment, this problem has been really important because you have billions of letters you have in the DNA sequence.

79
00:10:10,170 --> 00:10:20,430
And when you have a sequence data, usually you have a fragment of those 3 million sequences and you want to know where those sequences are located.

80
00:10:20,610 --> 00:10:29,550
And these days we're not using this dynamic programing because it's still very slow if you want it to align a very large string.

81
00:10:29,940 --> 00:10:36,810
But those dynamic program has been helpful in a particular situation where you need an optimal solution.

82
00:10:38,310 --> 00:10:41,580
So that has been used quite a bit and this is much better.

83
00:10:42,810 --> 00:10:47,040
Then, uh, you know, this is a much better than, uh.

84
00:10:53,230 --> 00:10:59,260
The explanation that we do. You may think it's a brute force articulation you can think about.

85
00:11:00,370 --> 00:11:04,110
Okay, so that's. That's that.

86
00:11:05,250 --> 00:11:15,360
That's introduction of a problem. And what's the solution? Okay, so solution is surprisingly similar to what we had before.

87
00:11:15,660 --> 00:11:20,700
Okay. So let's say you have input strings, X and Y.

88
00:11:20,880 --> 00:11:30,870
Okay. They can have a different lat, different length. So let's say the length of the x string x is M, length of string y is an.

89
00:11:31,200 --> 00:11:40,549
Okay. Then what it can do is that, uh, we make a substring.

90
00:11:40,550 --> 00:11:51,860
So X of I means the substring until you know an index I and way of eyes a substring of to the index of j okay.

91
00:11:53,600 --> 00:12:04,900
Then what we define is that we define the is towards the recursively this way minimum and the distance in this way get so.

92
00:12:07,140 --> 00:12:14,820
So it's pretty much similar. If you want it to go vertically or horizontally, then you have only one choice.

93
00:12:14,950 --> 00:12:23,520
So if I equals zero, that means that you can only go to, uh, three in this case.

94
00:12:24,430 --> 00:12:26,440
I mean, depending on which one was X and Y.

95
00:12:26,470 --> 00:12:36,370
So it's a little bit confusing, but let's say let's say just a row is X and column is way just to make it make it easy to understand.

96
00:12:36,380 --> 00:12:39,700
You can you can definitely to switch it switch it a it's a.

97
00:12:40,790 --> 00:12:51,340
You know, it's a symmetric problem. So yeah, if I go I control this means that you have you're moving forward horizontally.

98
00:12:51,430 --> 00:12:56,150
So then you only have a horizontal move. So any distance is j.

99
00:12:56,170 --> 00:13:02,120
So whatever is an x, if j equals zero, then it's a moving vertically.

100
00:13:02,170 --> 00:13:06,190
So that distance chain, there's no other possible moves.

101
00:13:07,150 --> 00:13:11,320
But otherwise you can. You can have a three different.

102
00:13:12,410 --> 00:13:18,210
A way to reach to a sorry, reach to some anywhere.

103
00:13:18,240 --> 00:13:24,299
So when you want to reach somewhere, let's say there's a there's no fully connected graph here,

104
00:13:24,300 --> 00:13:36,990
but let's just find let's just pretend that this is a fully connected, that whenever you have this, okay, then you have three choices.

105
00:13:37,110 --> 00:13:42,489
So let me just try because there's there's not real cases.

106
00:13:42,490 --> 00:13:46,950
So so let's say you you wanted to.

107
00:13:48,280 --> 00:13:51,970
Rich and came the of AIG everything.

108
00:13:52,870 --> 00:13:57,520
Then this is excite exciting things excited when changing.

109
00:13:58,480 --> 00:14:02,650
And you can go from here to here and here again.

110
00:14:03,280 --> 00:14:11,439
So when you when you move horizontally, it means I mean, it's either insertion with the lesion,

111
00:14:11,440 --> 00:14:18,520
depending on the what what character you're looking at. But this is basically the if you move horizontally.

112
00:14:19,000 --> 00:14:28,140
I am so I said that I said the row is actually the column is why this pew pew so you are basically only increasing the length the wide.

113
00:14:28,750 --> 00:14:33,740
So if you think X is a revenue stream this is. This is desertion.

114
00:14:33,940 --> 00:14:37,519
Right. This is a collision. Okay. And each of them.

115
00:14:37,520 --> 00:14:41,380
Because you are inducing a mismatch. Okay. And this.

116
00:14:41,600 --> 00:14:47,250
This will have you have to add one more at a distance.

117
00:14:47,270 --> 00:14:52,620
And these. So. So in this case, because it's dynamic programing.

118
00:14:52,640 --> 00:14:55,790
I'm sorry that I should have done that.

119
00:14:56,180 --> 00:14:59,680
This is okay. I.

120
00:15:01,470 --> 00:15:05,160
So it is because it's dynamic, dynamic programing.

121
00:15:05,860 --> 00:15:11,040
Um you have you assume that this all previous.

122
00:15:14,000 --> 00:15:21,660
And in this case was quite a rated Jimmy minus one game where nobody was the X.

123
00:15:22,600 --> 00:15:28,080
I. I. Minus one and G.

124
00:15:29,130 --> 00:15:34,320
So if you assume that this is a this is all calculated, you just have the ultimate cost about.

125
00:15:34,320 --> 00:15:37,470
You have to pay for one more mismatch penalty here.

126
00:15:38,280 --> 00:15:38,999
Going this way,

127
00:15:39,000 --> 00:15:49,950
also one more mismatch penalty in that going diagonally could could induce a mismatch penalty or not depending on the weather the letter.

128
00:15:49,980 --> 00:15:59,760
So in this case here you need to see the weather and so x0 i and y of J.

129
00:16:00,210 --> 00:16:10,110
If these two letters are the same, then when I when I'm aligning these, they don't have to pay for the mismatch.

130
00:16:10,110 --> 00:16:15,900
So if this is a zero, if this is identical, you pay for the plus zero.

131
00:16:16,020 --> 00:16:25,680
Otherwise plus one other way. So this is basically a key idea underlying this slide.

132
00:16:25,800 --> 00:16:36,900
This slide. Exactly. Explain that. So you only add a penalty when the the letters, the matching.

133
00:16:37,500 --> 00:16:43,560
So newly added letters in the diagonal move is not identical.

134
00:16:43,980 --> 00:16:51,330
Okay. So except for this time on the move, this is actually pretty similar to the main tourist problem.

135
00:16:51,340 --> 00:16:54,610
But now you have three possible choices that are relevant to.

136
00:16:56,970 --> 00:17:00,780
So did you have any questions in this particular formula?

137
00:17:01,260 --> 00:17:04,470
Does it. Does it actually connect to the.

138
00:17:04,590 --> 00:17:08,400
So you there are two steps you need to connect to.

139
00:17:08,430 --> 00:17:18,030
So when you when you look at this equation, you need to connect this equation with this preview, with this sort of a fully connected.

140
00:17:18,090 --> 00:17:24,840
So the graph I wanted you to imagine is that a graph that is fully connected.

141
00:17:24,840 --> 00:17:31,790
So you have all possible choices here of.

142
00:17:33,160 --> 00:17:37,350
Okay. Or possibly choices like this.

143
00:17:37,630 --> 00:17:42,750
Okay. And and it's connected all the way through here.

144
00:17:42,780 --> 00:17:52,110
Right. So. So you have this crap, but the cost here is not fixed, per se.

145
00:17:52,530 --> 00:17:55,200
Well, I mean, it is speaks about this cost.

146
00:17:55,500 --> 00:18:04,739
So this cost, of course, is always one cost is always one that are going to cost quite a bit, you know, or one depending on the weather.

147
00:18:04,740 --> 00:18:15,690
That particular in this case, to to move to this this one, the first letter has to be the same in this case, first letter in the first three.

148
00:18:15,930 --> 00:18:18,560
In the second letter, the first second string has to match.

149
00:18:19,020 --> 00:18:23,220
Then it could be either, you know, a long distance, you know, along the way that, you know, a one.

150
00:18:23,820 --> 00:18:27,960
So you can figure out what the cost is. That's a full graph you actually have.

151
00:18:28,680 --> 00:18:33,530
You don't have to grab you don't have to construct a graph, but this is what what it does.

152
00:18:33,570 --> 00:18:40,590
So you need to connect. These are ways in which this visual concept of this alignment first.

153
00:18:40,890 --> 00:18:44,240
Okay. And also you need to understand this.

154
00:18:44,550 --> 00:18:50,010
Uh, these alignments correspond to this visual alignment, basically.

155
00:18:50,490 --> 00:18:55,560
Okay. So that's the part that might be a little bit tricky to understand.

156
00:18:59,640 --> 00:19:08,040
Okay. So now let's try to implement this work within.

157
00:19:09,350 --> 00:19:16,530
Okay. So. We have this part.

158
00:19:16,800 --> 00:19:21,540
Okay. So you can just try to look at it now.

159
00:19:21,630 --> 00:19:27,110
Okay. So. It's a it's basically the same as before.

160
00:19:27,620 --> 00:19:36,680
We're going to do the backtracking later to to reconstruct the alignment.

161
00:19:36,920 --> 00:19:44,150
But let's not worry about that now. So even this move part, let's only focus on the cost part.

162
00:19:44,990 --> 00:19:51,020
So you basically store a cost of the the string.

163
00:19:51,020 --> 00:20:09,170
So and and so this is the this is a and the length of DN and m so so and these lengths of length of x and m is lengths of n.

164
00:20:10,400 --> 00:20:18,440
And here what we are doing is that the first letter is zero and you're adding the insertion.

165
00:20:19,190 --> 00:20:26,750
So when, when, when you're looking at the first row, then your the cost is zero.

166
00:20:27,050 --> 00:20:36,850
But if the if equal one so first row but equal greater than one, you always add at a cost.

167
00:20:36,860 --> 00:20:42,950
So here this one is a little more advanced because I actually allow the two different cost.

168
00:20:42,960 --> 00:20:46,700
So gap cost and substitute substitution cost.

169
00:20:46,700 --> 00:20:51,050
So gap cost means that you pay port P for.

170
00:20:55,400 --> 00:21:01,350
Sorry. Mm hmm. You you pay for a.

171
00:21:05,730 --> 00:21:12,240
Pay pay for additional cost when you add, when you insert or delete a string.

172
00:21:12,240 --> 00:21:20,370
So that's gap cost. So in this case is always, always a horizontal move, which is a, which is a, you know, insertion or deletion.

173
00:21:20,370 --> 00:21:27,029
So you you add that gap cost same thing here if AJ equal one I calculated in one only the cap

174
00:21:27,030 --> 00:21:34,920
cost and you don't have a choice here but if j equal greater than one equal greater than one.

175
00:21:35,190 --> 00:21:36,420
You have this.

176
00:21:38,130 --> 00:21:46,500
So let's forget about the move and you have these possible three cause that was one is the insertion cost, the other is a deletion clause.

177
00:21:46,800 --> 00:21:57,450
And third is a substitution cost. And a insertion cost is just the previous corresponding node plus gap caused by substitution cost.

178
00:21:57,450 --> 00:22:02,609
You are going diagonally so you are actually checking whether they are the same or not.

179
00:22:02,610 --> 00:22:07,140
If they are different, do you pay for the substitution cause otherwise cost is free.

180
00:22:07,650 --> 00:22:14,670
Okay, so then what? What this is doing is that you are taking the minimum among those three values.

181
00:22:16,380 --> 00:22:22,740
Okay, so, so that's that and this part is a constructing alignment.

182
00:22:22,740 --> 00:22:27,840
So this is not going to be important now. So the algorithm is as simple as this.

183
00:22:28,530 --> 00:22:33,360
One thing I wanted to make sure is that when you construct this string,

184
00:22:34,590 --> 00:22:42,360
you're you need to add empty character in the beginning because it's not always it's not

185
00:22:42,360 --> 00:22:56,339
always a guarantee that you actually can align the string string from the first letter.

186
00:22:56,340 --> 00:22:59,600
So let's say you have I would I algorithm here.

187
00:22:59,670 --> 00:23:13,620
I know g0ritehm and patristic so r to race day.

188
00:23:15,090 --> 00:23:22,020
Okay. So currently this is the current alignment, but let's, let's say the word unit on line.

189
00:23:22,110 --> 00:23:31,260
So I don't know is that the altruistic part is to say I region, let's say this category or something.

190
00:23:31,470 --> 00:23:39,990
Okay, so there's another P then this is the this is the right way and probably optimal way to align it.

191
00:23:40,830 --> 00:23:46,920
Then there is no pairs here. So it could it could it is possible that the first letter doesn't have a pair.

192
00:23:47,610 --> 00:23:53,700
So to allow that, you need to start with empty characters for each of them to allow them.

193
00:23:53,700 --> 00:23:56,759
So that, that's,

194
00:23:56,760 --> 00:24:10,440
that if this part is all unnecessary because it's in it's in the it's in the collab note I actually don't know why this is showing up.

195
00:24:10,770 --> 00:24:18,210
I probably this is this is a problem last week last year's material I guess let me just make sure.

196
00:24:32,640 --> 00:24:37,980
Yeah. Okay. So, uh, yeah.

197
00:24:38,100 --> 00:24:41,460
So that's. That's the beginning of the part. Okay.

198
00:24:43,140 --> 00:24:52,170
So. So we didn't, we didn't go through how to address the the move yet.

199
00:24:52,440 --> 00:24:56,190
But is this clear so far, though, cause part.

200
00:25:00,640 --> 00:25:07,590
Okay. My throat condition is not very good today.

201
00:25:15,560 --> 00:25:20,060
Okay. Now, let's talk about the.

202
00:25:22,970 --> 00:25:27,970
Backtracking. So now you have a same problem.

203
00:25:27,980 --> 00:25:32,100
So in the middle of the forest problem, you want to construct which path you need to go.

204
00:25:32,120 --> 00:25:36,920
You actually need to go from the optimal solution to the beginning.

205
00:25:36,930 --> 00:25:46,640
So you need to reconstruct the path that way. So if is the same thing, if you reconstruct that path, you should be able to create alignment.

206
00:25:46,790 --> 00:25:54,790
So but if you think about it, the creating that, that visual alignment is not that not necessarily that easy.

207
00:25:54,800 --> 00:26:00,200
So we'll just try to figure out how to do it so well.

208
00:26:00,230 --> 00:26:04,820
Storing the alignment is. So if you, you just make your own convention.

209
00:26:04,820 --> 00:26:17,510
So I'm going to say if I have a insertion, which means that I'm moving horizontally, then I'm going to, you know, add, I'm going to store one.

210
00:26:19,580 --> 00:26:27,860
If I have deletion, I'm actually going down vertical movement, then I'm going to say a negative one.

211
00:26:28,850 --> 00:26:32,239
And yeah, sometimes I say insertion and deletion,

212
00:26:32,240 --> 00:26:39,580
switch it because depending on the which one you consider this reference, it's it's insertion deletion is different.

213
00:26:39,590 --> 00:26:44,990
So in the, in this context, it's better to just remember whether this is this is a horizontal move.

214
00:26:45,500 --> 00:26:54,469
This is a vertical move. Right. And in this case, I did I did this right.

215
00:26:54,470 --> 00:26:57,530
So so do the same thing here.

216
00:26:57,860 --> 00:27:00,889
But instead what I hear is of the user, which you don't mean.

217
00:27:00,890 --> 00:27:08,630
So deletion caused the substitution cause insertion caused that in a pick, one pick which one was the minimum.

218
00:27:08,900 --> 00:27:17,540
Okay, then, uh, you take the minimum index and divide by my minus subtract minus two.

219
00:27:17,540 --> 00:27:21,049
That means that, that that alternate of minus one zero or plus one.

220
00:27:21,050 --> 00:27:27,380
So this is convenient. So storing is not hard, but how do we construct alignment?

221
00:27:27,480 --> 00:27:34,030
Okay, so basically what you can do is, well, I make empty string, okay?

222
00:27:34,670 --> 00:27:41,809
And let's, uh, in this case, I'm going to move back from the previous one.

223
00:27:41,810 --> 00:27:53,040
So I'm starting from the end, the end and I equal end and Jake or m so end of this alignment and try to figure out as long as both of them are.

224
00:27:53,120 --> 00:27:57,479
I didn't reach the beginning yet. Then keep doing this.

225
00:27:57,480 --> 00:28:05,629
So if the move is zero, this means is substitution. So I'm going to just add.

226
00:28:05,630 --> 00:28:11,120
So in this case, you're, you're, you're pasting the two strings.

227
00:28:11,870 --> 00:28:18,230
But in this so you are actually adding new characters in the beginning here and here.

228
00:28:18,320 --> 00:28:26,240
Okay. So both of them, you are adding new, new characters and I'm going to create those create a string called edit,

229
00:28:26,690 --> 00:28:34,069
which is which just the saying that this is a when they are the same when they two letters same,

230
00:28:34,070 --> 00:28:42,320
I'm going to print out that if they are different, I'm going to I'm going to say s so there's a subject substitution happened.

231
00:28:43,220 --> 00:28:51,980
Okay, so if, if the movement was the insertion region to remove them is that I don't do anything on X so just put

232
00:28:51,980 --> 00:29:02,059
dash and I add one more characters in Y and only move J and say that this is insertion deletion.

233
00:29:02,060 --> 00:29:11,330
You do the same, but instead instead of updating or updating j i update i only and say deletion.

234
00:29:11,480 --> 00:29:27,300
Okay. So that's that's the way you can do the backtracking. So if you have this function loaded, okay, then you can see that this cause can move.

235
00:29:27,610 --> 00:29:31,380
Okay. So you can show the how, how this, how this worked.

236
00:29:31,830 --> 00:29:36,750
And this alignment basically align the string x and Y is a fruit.

237
00:29:37,260 --> 00:29:40,670
It shows align the string and it says s dot.

238
00:29:40,680 --> 00:29:45,840
So this is substitution. I the this is a match.

239
00:29:46,110 --> 00:29:49,710
And so I is insertion substitution and substitution.

240
00:29:49,720 --> 00:29:54,260
So that's the that's how it works are twisting an algorithm.

241
00:29:54,270 --> 00:29:59,970
If you see this, you'll see that this looks like this.

242
00:30:00,270 --> 00:30:09,149
Okay. And so these are these are just storing the optimal move to to reach each of the node here so

243
00:30:09,150 --> 00:30:16,110
you can reconstruct the optimal path to align any subset subsub string between those two,

244
00:30:16,110 --> 00:30:21,090
which is also interesting. So you have this particular alignment.

245
00:30:21,240 --> 00:30:26,610
So note that there is a if there is a tie, there is no particular algorithm we actually selected.

246
00:30:26,640 --> 00:30:34,860
You can actually make that up when there's a I'm going to always, always select substitution first.

247
00:30:35,130 --> 00:30:43,020
You could have done that. But here I didn't do it. So but you could have done that by modifying this instead of taking minimum.

248
00:30:43,130 --> 00:30:53,070
I'm going to say if the substitution cause it is the same, same, or is the same to the minimum,

249
00:30:53,070 --> 00:30:59,340
I'm going to always select a substitution so you can do this but the switch the mean I think it it prefers deletion

250
00:30:59,340 --> 00:31:09,510
because it when you take the mean I think it's it when there's a tie it returns the just the first O available values.

251
00:31:09,510 --> 00:31:18,120
So you can you can modify this function to say that I prefer substitution over insertions or deletion if that's what you wanted.

252
00:31:18,120 --> 00:31:23,900
So. Okay. But in this case, uh, yeah.

253
00:31:24,000 --> 00:31:28,139
So this is align the strings and this is the added operation.

254
00:31:28,140 --> 00:31:36,810
So we basically added distances. One, two, three, four, five, six and three substitution, one insertion into deletions.

255
00:31:38,580 --> 00:31:44,140
So as I said, this is a very widely used in the DNA sequence alignment.

256
00:31:44,160 --> 00:31:48,750
So as you see, if you have these two DNA sequences here,

257
00:31:48,750 --> 00:31:52,950
you can figure out the best alignment and see what's the minimum number of

258
00:31:52,950 --> 00:32:00,060
substitutions or mutations that need to take to make these two sequences identical.

259
00:32:00,150 --> 00:32:10,530
Okay. That way you can see how similar those two sequences are and you can try to align the sequence in the place that matches the best.

260
00:32:13,600 --> 00:32:20,020
Okay. That's the end of the, the remaining part of the lecture.

261
00:32:20,020 --> 00:32:26,649
16 Dynamic programing is not just useful for these particular applications,

262
00:32:26,650 --> 00:32:31,450
but you actually have a lot of interesting applications you can think about.

263
00:32:31,450 --> 00:32:39,219
So one thing you may want to learn, which I don't cover, is a message pecking order regime in the graph graphical network.

264
00:32:39,220 --> 00:32:49,450
So and the hidden Markov model we're going to jump we're going to uh, hover right now is the.

265
00:32:53,190 --> 00:32:53,490
Yeah.

266
00:32:53,700 --> 00:33:07,560
This this is the, uh, you know, particular instance of the graphical model, but this is more, um, more specialized version by the message of passing,

267
00:33:07,690 --> 00:33:18,809
which is also something that turns turn the apparently exponential problem into a, uh, uh, polynomial problem.

268
00:33:18,810 --> 00:33:21,930
So this is very useful in multiple contexts.

269
00:33:24,010 --> 00:33:27,310
Any question in lecture 16. Okay.

270
00:33:28,630 --> 00:33:38,950
Then we're going to move on to the lecture 17. So, uh, can I can I can can I see a show of hands?

271
00:33:39,700 --> 00:33:44,109
How many people have maybe.

272
00:33:44,110 --> 00:33:47,349
Maybe some of you had heard and heard about the markup.

273
00:33:47,350 --> 00:33:50,980
And how many of you have heard about the markup? Okay.

274
00:33:51,430 --> 00:33:55,690
How many you have used the he I mean, not not implemented,

275
00:33:55,690 --> 00:34:05,290
but use something that you so you may not know but how many people you think you actually use some some software package that uses the markup model.

276
00:34:06,310 --> 00:34:09,580
Okay. There there are three. I see. Okay.

277
00:34:09,910 --> 00:34:13,270
And how many people have implemented your own DiMarco model?

278
00:34:14,790 --> 00:34:25,960
Not yet. Okay. So this is a good this is a good, uh, interesting lesson, especially for those who wanted to implement this.

279
00:34:26,190 --> 00:34:27,850
If you can work on. What else can I see?

280
00:34:30,010 --> 00:34:40,360
So I did not know about my Commodore until I the later year, my Ph.D. and I was fascinated by the sounds so, so amazing.

281
00:34:40,360 --> 00:34:48,430
So. But to understand this, you actually need to take the stochastic process in principle.

282
00:34:48,800 --> 00:34:55,900
Okay. But we obviously don't have many of you haven't learned it.

283
00:34:56,110 --> 00:35:05,830
And I so so I'm going to try to explain very, very basic part of those, the theory.

284
00:35:05,950 --> 00:35:10,870
Okay. So it's okay if if it not everything makes sense.

285
00:35:11,170 --> 00:35:17,890
The reason why I'm trying to give this background is just to try to get everyone on the board.

286
00:35:18,490 --> 00:35:31,209
So and these are pretty theoretical and only requires a six or one analogy, if I believe, okay and understanding of the maximum like estimation.

287
00:35:31,210 --> 00:35:39,250
So it's not going to be too hard even if you didn't take the six, 80, 80 or stochastic process.

288
00:35:39,250 --> 00:35:44,590
I think this is you can you can understand.

289
00:35:44,830 --> 00:35:51,850
Okay. So to understand the Marco model, you need to understand the Marco process first.

290
00:35:51,970 --> 00:35:57,490
To understand Marco process. I think it's better to start off start with a just a typical graphical model.

291
00:35:57,670 --> 00:36:07,809
Okay. So I don't think where we are on this, we are learning practical model as a class, but the Bayesian net is basically a graphical model.

292
00:36:07,810 --> 00:36:11,550
So you're learning it at some point if you're doing the painting.

293
00:36:13,150 --> 00:36:18,430
So graphical model is, you know, based on the Michael Jordan's work,

294
00:36:18,430 --> 00:36:23,950
the word graphical model is a marriage between probability theory and aircraft theory.

295
00:36:23,950 --> 00:36:27,010
So this is a very interesting area.

296
00:36:27,190 --> 00:36:37,480
So graphical model basically models each random variable as a vertex in a graphical representation.

297
00:36:38,110 --> 00:36:44,620
And you're representing the dependency between random variables using on edge.

298
00:36:45,070 --> 00:36:50,530
Okay. So if there is a no edge, these are connected and these are not connected.

299
00:36:50,530 --> 00:36:57,700
If there is a dependency between the variable some some causal relationship or some correlation between the variables,

300
00:36:58,150 --> 00:37:10,270
you can connect between the variable. So it's interesting that when by default you assume that everything might be correlated,

301
00:37:10,450 --> 00:37:15,519
you don't assume that everything is independent by default, right? So well, unless you wanted to.

302
00:37:15,520 --> 00:37:24,880
If you wanted to start with a simplifying assumption. So. So most permissive representation is that you have a graph that everything is connected.

303
00:37:25,210 --> 00:37:31,890
Okay. That's the default. Okay. And the other extreme is that you have a graph that's not there is no edge.

304
00:37:31,900 --> 00:37:35,950
Then all the variables are independent, basically.

305
00:37:36,370 --> 00:37:44,560
So you can think about that. So unconnected pair of vertices, they are independent.

306
00:37:44,680 --> 00:37:52,510
Okay. In a this is a effective way to represent a complex structure between many random variables.

307
00:37:53,980 --> 00:38:01,090
So let's try to think about this example. So you have three graph with a three vertices and two edges.

308
00:38:01,720 --> 00:38:06,290
So here I have three random variable H, An, S and P.

309
00:38:06,310 --> 00:38:11,950
So H is basically whether two, these are two atmospheric pressures, high or low.

310
00:38:12,070 --> 00:38:15,460
Okay. And so H means pressure.

311
00:38:15,670 --> 00:38:27,250
Atmospheric pressure, A s means that today's weather, whether it is sunny or cloudy, so if h h equal one them is high h control, that means low.

312
00:38:27,850 --> 00:38:31,630
If X equals one, that means sunny as equals zero. That means cloudy.

313
00:38:32,740 --> 00:38:35,950
And a p is a plus attenders.

314
00:38:36,260 --> 00:38:39,340
So some some student for one, for okay. For a student.

315
00:38:39,610 --> 00:38:49,749
So let's say this is a this is me. And I tend to attend the class with a certain probability depending on my weather conditions.

316
00:38:49,750 --> 00:38:57,280
So I have a 70% of attending a class if it's sunny and 50% of attending it is of cloud.

317
00:38:57,380 --> 00:38:58,060
Okay. So,

318
00:38:59,650 --> 00:39:16,420
so then so you can model them as a three by two binary variable and you can model their conditional the conditional distribution as given as given h.

319
00:39:16,660 --> 00:39:20,860
Okay. So if or conditional these reject p given us.

320
00:39:20,980 --> 00:39:24,370
Okay. So in this case is h and P are independent.

321
00:39:26,080 --> 00:39:29,470
Well, h m p doesn't have a direct relationship.

322
00:39:29,570 --> 00:39:39,650
Between them. But H and P are connected to to P to S.

323
00:39:39,920 --> 00:39:43,700
So this is not independent in this case.

324
00:39:43,940 --> 00:39:50,480
Okay. But you can also see, are they conditionally independent?

325
00:39:51,680 --> 00:39:52,130
So.

326
00:39:53,210 --> 00:40:01,700
Well, in this case, you can say that this is a condition independent, because once you know the weather, weather, weather, this is sunny or cloudy.

327
00:40:02,090 --> 00:40:12,440
Knowing whether the atmospheric, atmospheric pressure is high or low doesn't affect anything about the knowing

328
00:40:12,740 --> 00:40:18,770
about the distribution of class attendance and in actual graphical model.

329
00:40:18,800 --> 00:40:25,850
This is more complicated when there's a sort of sort of restructure where there's one variable and there's two incoming nodes,

330
00:40:25,860 --> 00:40:29,810
and it's not usually that there's a new.

331
00:40:29,900 --> 00:40:35,540
If you're conditional on something, there's a new connection happens or this is a little bit more complicated,

332
00:40:35,540 --> 00:40:39,740
but we're not going to deal with it here today. Okay.

333
00:40:39,860 --> 00:40:43,190
So now let's try to model this data. Okay.

334
00:40:44,060 --> 00:40:47,160
So this is really like simple modeling.

335
00:40:47,180 --> 00:40:57,230
So let's say I have a marginal probability of one particular day and having low atmospheric pressure is 30% high, becoming 70%.

336
00:40:58,280 --> 00:41:03,730
And I can define the conditional probability of a given h a this way.

337
00:41:03,740 --> 00:41:09,830
So. Well, if it if the current atmospheric pressure is low, there's a 70% of a chance.

338
00:41:09,830 --> 00:41:13,460
This is a cloudy and a 30% of it's sunny.

339
00:41:13,730 --> 00:41:16,730
So this place doesn't doesn't rain at all, I guess.

340
00:41:17,570 --> 00:41:29,000
And if it's high, then there is a 10% of being cloud, 10th of just 10% chance of being cloudy, 90% of chance being sunny.

341
00:41:29,230 --> 00:41:33,260
Okay, so that's the description I'm going to just use.

342
00:41:34,160 --> 00:41:40,280
And this student is very moody student. So they have a half a half chance.

343
00:41:40,280 --> 00:41:44,060
If the weather is cloudy, they have a chance of being absent.

344
00:41:44,480 --> 00:41:49,850
But whether it's sunny, you know, only 10% of chance of being absent in the 90% of being present.

345
00:41:50,150 --> 00:42:00,180
Okay. So then by using these three variable, you can just multiply all these three variables to get the joint distribution.

346
00:42:00,530 --> 00:42:11,810
I think you all know that. So then you can construct this outcome, the probability of joint, the probability of all these three variables in this way.

347
00:42:12,000 --> 00:42:21,590
Right. So once you have this joint probability, you actually can make any inference like what's the probability of like,

348
00:42:22,100 --> 00:42:29,870
you know, what's, what's a probability P given S and H or what is the probability of even P given given H?

349
00:42:30,080 --> 00:42:37,130
You can make a lot of difference. Different inference if you have because you have the full table.

350
00:42:37,490 --> 00:42:43,670
Okay. But if you have a lot of variables like this, you may keeping track of this.

351
00:42:43,670 --> 00:42:47,750
Both table joint distribution is not computation retractable.

352
00:42:48,140 --> 00:42:55,790
Okay. Because of the number of entries you are going to have will increase exponentially.

353
00:42:58,780 --> 00:43:02,590
So so let's ask this question.

354
00:43:02,790 --> 00:43:15,010
Okay. So so the question is, I wanted to know if so this is this is the the mathematically phrasing, this question.

355
00:43:15,640 --> 00:43:18,900
Are H and P independent given this.

356
00:43:19,180 --> 00:43:31,629
Okay. So you can basically to to verify that you need to say that if the probability of HP given this can be decomposed this way,

357
00:43:31,630 --> 00:43:35,920
if you show that that means that this is there independent.

358
00:43:36,640 --> 00:43:41,470
Well, you can actually calculate that because you you have all this probability.

359
00:43:41,480 --> 00:43:46,720
So you can just marginalize in the specific way and come up with a table.

360
00:43:47,170 --> 00:43:53,740
Then you actually have this, okay, so I'm not going to show how I derive with it, but this is very straightforward.

361
00:43:54,190 --> 00:43:59,790
So this is the full table of the probability of H and P given s.

362
00:44:00,070 --> 00:44:06,220
Okay. And you can also calculate the probability of H given this from the full table.

363
00:44:06,340 --> 00:44:09,810
You can calculate the probability P given this from the full table.

364
00:44:09,820 --> 00:44:15,730
So this is the full table. Okay. So what you need to do is try to try to multiply.

365
00:44:15,880 --> 00:44:20,770
Okay. So if you multiply this, this and this, then you get this value.

366
00:44:21,400 --> 00:44:25,120
If you multiply this and second row, you get this value.

367
00:44:25,630 --> 00:44:32,440
If you multiply this, this one and this one, then you you get this value with this value and so on.

368
00:44:32,470 --> 00:44:35,530
So that same thing happens.

369
00:44:35,530 --> 00:44:40,689
You multiply this and this, you get this value multiplying this and this, you get this value.

370
00:44:40,690 --> 00:44:44,080
So basically you can show that this is true.

371
00:44:44,350 --> 00:44:56,800
Okay. So using the full table, we just have a brute force way to show that H and P are conditionally independent with each other.

372
00:44:57,280 --> 00:45:02,500
Okay. So you can show that and to to verify that that actually happens.

373
00:45:03,700 --> 00:45:12,429
So so H and P do not have direct path from one to another, one from the other actually.

374
00:45:12,430 --> 00:45:21,040
So and all paths promoted to P is connected through through s or conditioning on s basically make them independent.

375
00:45:21,340 --> 00:45:27,610
Okay. So that's one useful property of this graphical model.

376
00:45:28,270 --> 00:45:36,210
Okay. So you can, you can use this thing in the more complicated graphical models like this.

377
00:45:36,220 --> 00:45:39,370
In this case, this looks like very complicated.

378
00:45:39,370 --> 00:45:49,630
But if you condition sorry, if your condition on B, A, C, D, E, all of them becomes independent conditional on B,

379
00:45:49,930 --> 00:45:54,160
so that makes the probability in probability inference a lot easier.

380
00:45:54,790 --> 00:46:04,870
So that's a easier to visualize. So this is this is a graphical model gets becomes more more interesting.

381
00:46:05,140 --> 00:46:08,950
Okay. And I'm going to skip through all this, every structure.

382
00:46:08,950 --> 00:46:13,300
And sometimes they can create the new connection and so on.

383
00:46:13,750 --> 00:46:19,329
That's it. That's complicated part. So but this is general a theorem.

384
00:46:19,330 --> 00:46:22,180
So there's a something called the Markov blanket.

385
00:46:22,330 --> 00:46:28,360
So basically, if your condition or condition under all the variable, if you condition all the variables.

386
00:46:28,900 --> 00:46:41,740
So basically, let's say if your conditional conditioning on the immediate parent so or child so any,

387
00:46:41,740 --> 00:46:45,370
any variable that is directly connected to to your variable.

388
00:46:45,370 --> 00:46:52,710
And in this case, because of this something called V structure, you also need to condition on the any variable that goes into the same variable.

389
00:46:52,720 --> 00:46:57,580
So I didn't explain that part. So if that doesn't make sense, that's okay.

390
00:46:58,150 --> 00:47:03,870
So if your condition on all this variable A becomes independent from rest of the world,

391
00:47:03,880 --> 00:47:09,290
so that's and anything else but anything else that is not here.

392
00:47:09,310 --> 00:47:10,590
So that's interesting,

393
00:47:12,680 --> 00:47:20,860
not interesting property you can leverage when you try to model the this distribution in the to some a more efficient computation.

394
00:47:23,380 --> 00:47:28,870
It's a it's okay if you didn't understand this so this is this is just I just wanted to introduce as a general idea.

395
00:47:29,560 --> 00:47:36,310
Okay. So then using this, you can we can define something called the Markov process.

396
00:47:36,520 --> 00:47:44,080
Okay. So basically, marker processes, you have a random variable.

397
00:47:44,260 --> 00:47:49,300
Okay. And you can. Well, this is not not correct.

398
00:47:49,500 --> 00:47:53,590
This is we're actually moving moving things a little bit differently.

399
00:47:53,590 --> 00:48:00,610
But I want you to explain the marker process first in the when I introduce the hidden markup, that that makes more sense to connect them.

400
00:48:01,180 --> 00:48:05,229
But this multiple process also can be represented sort of graphical model.

401
00:48:05,230 --> 00:48:13,600
But in this case, what it does is, you know, you have basically three variables,

402
00:48:13,780 --> 00:48:17,500
three values in this case is one variable, but you have a three values.

403
00:48:17,660 --> 00:48:23,650
Okay. So, so this is not quite correct tomorrow because you actually these are not three independent random variables.

404
00:48:24,430 --> 00:48:31,870
So there. So I just want you to explain the problem, the property between them.

405
00:48:31,870 --> 00:48:47,410
So there is a. So in this case, what I'm doing is I'm modeling a relationship of the weather between the previous day and the next day.

406
00:48:47,890 --> 00:48:55,180
Okay. So that's what I'm doing. Okay. So what what it means is there is a there are three possible weather status.

407
00:48:55,360 --> 00:48:57,340
Sunny, cloudy, rainy. Okay.

408
00:48:58,060 --> 00:49:07,930
And this arrow shows that Markov process is basically describing the relationship between the random variables, between different time points.

409
00:49:08,800 --> 00:49:12,430
So. Or to treat in sequence sequence of random variables.

410
00:49:12,580 --> 00:49:19,960
So in this case, you have well, if if today was sunny, there is a 50% chance that tomorrow is sunny.

411
00:49:20,440 --> 00:49:25,750
30% chance that tomorrow is cloudy. 20% chance is tomorrow is rain.

412
00:49:26,470 --> 00:49:34,420
Same thing. If it today is cloudy, there is a 40% chance of being sunny, 30% been cloudy and 30% rainy and so on.

413
00:49:34,450 --> 00:49:45,070
So this is this is a this is a one way to model the relationship between the between this sequence of random variables.

414
00:49:45,370 --> 00:49:50,649
Okay. So now previously we didn't talk about the sequence random variable at all.

415
00:49:50,650 --> 00:49:57,340
So emergency processes basically explain the sequence of random elements that we're going to connect together with the parameter model.

416
00:49:59,020 --> 00:50:06,579
So. So how do I represent this method mathematically?

417
00:50:06,580 --> 00:50:14,650
So you can replicate this, this procedure with you with three?

418
00:50:16,030 --> 00:50:19,050
Well, I mean, two, two variables here.

419
00:50:19,060 --> 00:50:28,840
The initial probability. So you need to provide what's the initial probability of the the first day becoming sunny from cloudy and rainy.

420
00:50:28,840 --> 00:50:32,020
So you have 70%, 20%, 10%.

421
00:50:32,050 --> 00:50:46,860
Let's say we start with that. Okay. And you can model the probability the next day is a state, a state j given the two previous state is a state high.

422
00:50:48,040 --> 00:50:56,019
So you can represent them as a matrix. So in this case, this means that the 50% of if the two day was sunny, 50%,

423
00:50:56,020 --> 00:51:03,130
30%, 20% chance that the next next days are sunny, cloudy and rainy and so on.

424
00:51:03,400 --> 00:51:10,690
Okay. So then if you have this, you can answer many interesting questions.

425
00:51:11,470 --> 00:51:16,840
So, for example, what is the chance of rain in the day?

426
00:51:18,040 --> 00:51:24,850
Well, in the one, you know, 73, 70%, 20%, 10%.

427
00:51:25,330 --> 00:51:28,840
And how do we get the probability distribution of the second day?

428
00:51:29,620 --> 00:51:41,440
You can calculate individually or actually you can multiply this a transpose and multiply pi.

429
00:51:42,130 --> 00:51:53,290
Then you will have the value. And if you get the third value, that that's the chance of rain in the in the day to why why does it work like that?

430
00:51:53,290 --> 00:52:06,490
So you can we can figure it out. So basically, if you transpose this, you have, you know, .3.2, 0.2, 0.332453 2.433.

431
00:52:08,620 --> 00:52:20,110
And you have 0.1, 0.3, 0.4 and you have 0.7, 0.2, 2.1.

432
00:52:20,160 --> 00:52:27,190
Right? So the chance of raining in the three is basically this.

433
00:52:27,400 --> 00:52:30,850
You multiply this. So it could be. So this is.

434
00:52:31,320 --> 00:52:36,480
Chance of rain when it was sunny. The probability of being sunny is 70%.

435
00:52:37,380 --> 00:52:51,900
The chance of rain when it's cloudy is a 30% and the probability of cloudy is 30% and chance of rain the next day when it's totally raining a 40%.

436
00:52:52,950 --> 00:53:03,510
So it is all right to the if we find a cure, then then you then you have this.

437
00:53:03,690 --> 00:53:13,200
So now if you add them up that there is a marginal probability of a day to becomes rainy.

438
00:53:13,200 --> 00:53:17,640
And I think this is if you add them together point 24.

439
00:53:20,270 --> 00:53:23,389
So if it rains today, how likely it'll rain?

440
00:53:23,390 --> 00:53:28,970
That is two days later. So. So for example, if they they want rain.

441
00:53:29,420 --> 00:53:32,870
What's the probability that. So this is the probability of.

442
00:53:33,860 --> 00:53:38,810
Okay. S. So, uh.

443
00:53:39,290 --> 00:53:42,350
Q. Q. Q of heat plus one.

444
00:53:43,040 --> 00:53:47,989
E. T +22 days later, equal as of three.

445
00:53:47,990 --> 00:53:55,340
This is rain, right? Now, given given that q of t is as of three.

446
00:53:55,430 --> 00:53:59,900
Right. So this is this is what you want to have.

447
00:54:00,740 --> 00:54:10,430
So how how do you how do you calculate this? So in this case, what you want to do is I know that today it rained.

448
00:54:10,730 --> 00:54:14,270
So this is 001. And this is that.

449
00:54:14,290 --> 00:54:22,310
Then if you calculate this, these are probability and that the probability of that next day will rain.

450
00:54:22,760 --> 00:54:30,980
If you multiply the same matrix once more, then that that shows a description of the weather in the two days later.

451
00:54:31,010 --> 00:54:36,140
So this is how it works and that becomes 33%.

452
00:54:37,160 --> 00:54:48,830
Okay. And one more interesting thing is that let's say we start with some some weather and a, what's the distribution of the weather?

453
00:54:49,940 --> 00:54:57,469
If you run this process like infinite amount of time, then there is a stage.

454
00:54:57,470 --> 00:55:06,680
And so the way how you can do that, if it converges to something you should have or let's say there is a some some distribution you have.

455
00:55:07,340 --> 00:55:13,520
And if you even if you multiply this matrix, if the distribution stays the same, that's a stage at this option.

456
00:55:14,180 --> 00:55:17,540
And you can calculate that. And the value is this.

457
00:55:18,610 --> 00:55:22,740
You can. So.

458
00:55:23,160 --> 00:55:30,450
So that's. So for each of these stranger matrix have their own station and distribution in most of the cases.

459
00:55:31,020 --> 00:55:38,180
Okay. So the interesting thing is that the Markov process is only dependent in previous cases.

460
00:55:38,190 --> 00:55:46,020
So. So let's say if a raised to the how likely is it arranged two days later and I gave that 33%.

461
00:55:48,660 --> 00:55:59,850
How about if it hasn't if it hasn't rained for the past three days, how likely will be rain, rain, the rain tomorrow?

462
00:56:00,030 --> 00:56:04,980
Okay. Well, because three days past three days yesterday.

463
00:56:05,250 --> 00:56:10,290
Right. So it's the same thing, right? So, you know, two days ago.

464
00:56:11,940 --> 00:56:21,990
I mean, so, look, let's stick to this. One day or two days ago, three a day with three days in a row, you had, uh, you had a rain.

465
00:56:22,470 --> 00:56:27,030
Then does it increase the chance that it'll rain tomorrow, too?

466
00:56:27,300 --> 00:56:34,100
So the fact that there are two additional previous day that has rained well in real life in maybe,

467
00:56:34,110 --> 00:56:41,880
but here, you know, in this probability, in this amount of process modeling, it does not.

468
00:56:42,190 --> 00:56:50,210
So the reason is that, okay, now everything is going to come, although the region is that we are there.

469
00:56:50,220 --> 00:56:53,930
There are, you know. This is it.

470
00:56:54,440 --> 00:57:04,700
Let's say this is a queue of key queue of people plus one queue of T minus one here, two, minus two and so on.

471
00:57:04,730 --> 00:57:14,450
So then this, you can model them as a graphical model, but they are only dependent on the is the previous date.

472
00:57:15,200 --> 00:57:25,609
Okay. So, so if you if you know that today was today I rate so your condition down in okay and everything

473
00:57:25,610 --> 00:57:32,820
before becomes independent to the to the the rest of the part because you conditioned them again.

474
00:57:33,640 --> 00:57:37,560
So the. So it's the same.

475
00:57:37,580 --> 00:57:47,270
So if you have so let's let's say just that they want a 2 to 3 they for the five.

476
00:57:47,750 --> 00:57:57,620
So you wanted to know the distribution of the five, right. So you the fact that you have rain in the three is enough.

477
00:57:57,800 --> 00:58:02,180
So it doesn't matter whether they won. And then what happened in they were the two.

478
00:58:02,330 --> 00:58:06,920
It doesn't change the probability this region here as long as you know that the three.

479
00:58:07,100 --> 00:58:17,660
Okay. So that's the important property over the Markov process that there is a conditional independent.

480
00:58:17,840 --> 00:58:21,290
Once you want the conditional, it before and after is separating.

481
00:58:25,610 --> 00:58:29,720
So that's all for my Marco process.

482
00:58:30,650 --> 00:58:38,810
And the Marco process is or is a little tricky, but probably being able to understand the Marco model is a little more complicated.

483
00:58:38,990 --> 00:58:45,590
Okay. Now, here is a case where you actually have an unobserved variable, latent variable.

484
00:58:45,830 --> 00:58:53,300
Okay. So in this case, the Marco process of what you observe itself represents some random variable.

485
00:58:53,590 --> 00:59:05,240
Right. So sunny. Cloudy. Okay. But in this case, there is a observed variable that is obvious random variables here.

486
00:59:06,080 --> 00:59:11,060
But observed variable does not follow the Markov process.

487
00:59:11,570 --> 00:59:16,100
Okay. There is a something that follows the Markov process then.

488
00:59:16,550 --> 00:59:19,860
Observed variable just is. You know.

489
00:59:20,480 --> 00:59:26,600
Is this really based on the hidden, hidden variable that follows a markov process?

490
00:59:26,810 --> 00:59:31,160
Okay. So that's the another layer involved.

491
00:59:31,460 --> 00:59:40,430
But that layer is not feasible. So you basically actual state is unobserved.

492
00:59:40,430 --> 00:59:51,020
The Markov process is not observed. And you have a transition between the states that are probably modeled like a markov process.

493
00:59:51,320 --> 00:59:54,680
Okay. So hidden variable following the Markov process.

494
00:59:54,890 --> 01:00:03,110
Okay. And and but the nice thing is that there are some observable variables you can see from the hidden state.

495
01:00:03,500 --> 01:00:17,600
So you can figure you can make a inference about the hidden variable by making some proper inference on the subset of variables.

496
01:00:17,840 --> 01:00:27,290
Okay. So now here is the example of a hidden Markov process here.

497
01:00:27,290 --> 01:00:34,100
Markov model. Okay. So in this case, we have Markov random variable.

498
01:00:34,630 --> 01:00:42,290
Okay. The Markov process, random variable, which is a at atmospheric pressure, whether this is high or low.

499
01:00:43,130 --> 01:00:46,400
Okay. So there is hidden state is a high or low.

500
01:00:46,700 --> 01:00:53,359
Okay. So then we don't know unless we we actually open ourselves.

501
01:00:53,360 --> 01:01:00,589
Right. Okay. And we let's assume that this is the, you know, 19th century.

502
01:01:00,590 --> 01:01:08,390
We don't have a satellite. So you don't know this variable, but you can only make an inference.

503
01:01:08,600 --> 01:01:16,880
Okay. So and there are three observed variables.

504
01:01:17,240 --> 01:01:20,690
Well, three states you can observe from from each of the states.

505
01:01:20,690 --> 01:01:23,510
So basically this says, my,

506
01:01:23,690 --> 01:01:32,149
the atmospheric pressure could be high or low and you can stay high for the 80% chance or you can trend it to the low states,

507
01:01:32,150 --> 01:01:41,390
a 20% chance for the next day. And they fe was low 40% chance to changing to high and a 60% chance to remaining as low.

508
01:01:43,790 --> 01:01:51,440
And if the atmospheric pressure is high, there is 80% of being sunny, 10% being cloudy, 2% being rainy.

509
01:01:51,860 --> 01:01:56,960
If it's low, there is a 10% of sunny, 60% to cloudy and 30% to being rainy.

510
01:01:57,200 --> 01:02:00,200
Okay. So that's the model we're going to talk about.

511
01:02:00,410 --> 01:02:07,820
Okay. So how do we represent this, say he the Merkel model as a as a mathematical notation?

512
01:02:07,940 --> 01:02:11,659
So you have a two, two things.

513
01:02:11,660 --> 01:02:17,510
One is a hidden state. So here now state how your law is not observed.

514
01:02:17,780 --> 01:02:21,920
Okay. And you have outcome. Okay. I observe the weather.

515
01:02:22,040 --> 01:02:29,690
So sunny, cloudy and rainy again. And so it's similar to the Markov states.

516
01:02:29,900 --> 01:02:38,520
But Markov process, we need to provide a, uh, initial state of these, these two hidden variables.

517
01:02:38,520 --> 01:02:46,490
So which is 70%, 30% in this case, and you have a two matrices you're going to need to provide.

518
01:02:46,500 --> 01:02:52,700
One is the transition matrix. So how does those hidden states trend in one from the other?

519
01:02:52,820 --> 01:02:54,950
Okay, that's that's attention matrix.

520
01:02:56,000 --> 01:03:03,380
And you also need to provide that I have observed the outcomes of how do how my observed outcomes are distributed,

521
01:03:04,010 --> 01:03:08,480
given the true human state is, you know, high or low.

522
01:03:08,900 --> 01:03:14,360
So if it's a high, this is this is the distribution, 8010 and 2%.

523
01:03:14,930 --> 01:03:17,930
If it's low, 10%, 6%, 3%. Okay.

524
01:03:18,680 --> 01:03:22,760
So that's the distribution. Okay. So.

525
01:03:23,160 --> 01:03:29,370
So then start all the ingredients you need. You don't need that. You don't need anything else to describe this.

526
01:03:31,290 --> 01:03:34,780
So then you can make a lot of interesting inferences here.

527
01:03:34,800 --> 01:03:38,160
So what is the chance of rain in the day for?

528
01:03:38,310 --> 01:03:43,030
Well, in this case, what you need to do is you need to calculate.

529
01:03:43,080 --> 01:03:48,570
So this is the same as a markov process, right? If you assume that you know the distribution.

530
01:03:48,600 --> 01:03:52,040
So here you have a prior distribution here.

531
01:03:52,050 --> 01:03:59,490
So you're just multiplying, you know, eight a transpose three times and you have this probability.

532
01:03:59,500 --> 01:04:06,920
So this is that probably probability distribution of a high or low in the four and

533
01:04:08,700 --> 01:04:14,640
and what you need to do is that after that I need to multiply this emission matrix.

534
01:04:14,760 --> 01:04:18,510
Okay, so which is the probability of observed outcome given states?

535
01:04:19,380 --> 01:04:27,240
So to get the distribution of the actual outcomes, once you know the distribution of the two states,

536
01:04:27,240 --> 01:04:31,920
so then you can say, oh, they have rain in the chance of rain.

537
01:04:31,920 --> 01:04:35,840
So chance of rain before is 23.3%.

538
01:04:35,850 --> 01:04:40,260
So you can make that kind of inference. Okay.

539
01:04:41,220 --> 01:04:51,800
So this is a political okay and probably more realistic because a lot of our whole process is, you know, you cannot build an actual state.

540
01:04:51,840 --> 01:04:55,110
Exactly. So.

541
01:04:58,660 --> 01:05:04,810
Let's say you have these three parameters, a set of private data.

542
01:05:05,950 --> 01:05:11,860
And what I want to do is this.

543
01:05:12,770 --> 01:05:15,940
Okay, so this is what I want to calculate.

544
01:05:17,050 --> 01:05:20,920
What is the probability of outcome? Sequence of observations.

545
01:05:21,210 --> 01:05:25,270
Okay. Okay. Given given parameters.

546
01:05:25,900 --> 01:05:33,520
Okay. So, for example, you know, the example is I have observations of like hundred days.

547
01:05:33,700 --> 01:05:36,760
Okay. So of weathers. Okay.

548
01:05:37,300 --> 01:05:43,990
And I want to you know, what? What are the you know, what is.

549
01:05:44,080 --> 01:05:55,870
So basically, I have, you know, the observation for 100 days and I don't want to have this.

550
01:05:56,650 --> 01:06:00,460
But what I don't know is I don't know these parameters. Right.

551
01:06:00,700 --> 01:06:03,820
So. Well, so. Well, I know.

552
01:06:04,600 --> 01:06:11,110
So I don't know what the. What the right parameter is. So what I want to do is that I have these observations.

553
01:06:11,890 --> 01:06:16,299
So and I have these parameters. I can fix some of the parameters I can make.

554
01:06:16,300 --> 01:06:24,130
Some of them are known. And I want to know like what kind of parameter maximize like my likelihood for example,

555
01:06:24,790 --> 01:06:29,830
then that all that are basically required to calculate this value.

556
01:06:30,340 --> 01:06:38,850
And if you have this, if you can calculate well you can just use a now the or no l BFG or whatever Argo is.

557
01:06:38,890 --> 01:06:44,500
You can calculate, you can use to optimize this and to find the maximum likely parameters.

558
01:06:45,190 --> 01:06:48,490
So the question is to calculating these value.

559
01:06:48,980 --> 01:06:55,780
And so how do I calculate is value and just calculating the length?

560
01:06:57,220 --> 01:07:07,900
So to calculate the likelihood, you need to do this. So basically you are doing you are doing city of this kind of calculations of, you know.

561
01:07:09,280 --> 01:07:13,180
So how do you do it? You there's. Q Is he the state?

562
01:07:13,450 --> 01:07:17,080
Right. So you go all over the possible state.

563
01:07:17,200 --> 01:07:23,780
So from day one, 200. So the one can be can be all.

564
01:07:23,800 --> 01:07:31,270
No, no, no, no, no. Okay. And I think I, you know, all all could be low.

565
01:07:31,270 --> 01:07:35,950
And the last they could be high. And you can do one, one, one, one, one, one, one.

566
01:07:36,190 --> 01:07:40,000
Okay. So you have two 200 possibilities.

567
01:07:40,540 --> 01:07:44,590
You can because this variable is unknown.

568
01:07:45,400 --> 01:07:49,060
So you can do this. Okay. So.

569
01:07:49,300 --> 01:07:56,340
But enumerate all possible qs and calculate the probability of the q given theta.

570
01:07:56,350 --> 01:07:59,829
This is the problem with the hidden state and I know how to calculate this.

571
01:07:59,830 --> 01:08:09,340
I have all the transition matrix. I can calculate this. If you have a hidden state, I can calculate this probability of all outcome.

572
01:08:09,340 --> 01:08:11,340
Given all the all the hidden state.

573
01:08:11,350 --> 01:08:18,850
I can calculate this because if all state is known, this is every every observer observation becomes independent from the state.

574
01:08:18,860 --> 01:08:23,140
So this is just a simple multiplication. So I know how to do it. This should be g.

575
01:08:23,920 --> 01:08:29,920
The problem is that you need to do the addition across all the combinations.

576
01:08:30,190 --> 01:08:43,470
Okay. So how much does it take? To do that, you need to add two to the 100 times.

577
01:08:44,490 --> 01:08:48,000
So this is a surprisingly slow.

578
01:08:48,150 --> 01:08:51,690
If you have a lot of random variables to marginalize.

579
01:08:52,020 --> 01:08:55,380
Okay. So that is the problem. Okay.

580
01:08:55,920 --> 01:08:58,920
So. Well, this is all you can calculate probability.

581
01:08:59,040 --> 01:09:04,320
So this part you can calculate. This is not hard. This is a simple multiplication.

582
01:09:05,040 --> 01:09:08,790
This part you can calculate. This is also simple multiplication.

583
01:09:08,790 --> 01:09:12,090
You just need to use those three your matrix.

584
01:09:12,270 --> 01:09:24,510
Okay. And this part you can you can calculate by plugging in everything, but it requires this summation across all the hidden states.

585
01:09:25,320 --> 01:09:28,740
How do we do that in a region of of time?

586
01:09:31,070 --> 01:09:35,600
Okay. So that's the computational challenges underlying in the hidden market model.

587
01:09:39,540 --> 01:09:42,600
Okay. So what we need to calculate is this.

588
01:09:42,780 --> 01:09:50,520
But this name computation requires a 2 to 3 possible combinations.

589
01:09:50,760 --> 01:09:54,210
So it exponentially grows with the number of observations.

590
01:09:55,080 --> 01:10:02,580
So it's now competition feasible to calculate these if you if you are in jointly inputting across the large number of states.

591
01:10:03,720 --> 01:10:10,470
Okay. So we need a hopefully a more efficient solution to be able to calculate this value.

592
01:10:11,070 --> 01:10:14,970
Okay. Okay.

593
01:10:15,300 --> 01:10:19,379
So this is a11 possible problem we can tackle.

594
01:10:19,380 --> 01:10:27,300
But this is not the most common problems in the hidden market that we wanted to solve and we wanted to tackle that.

595
01:10:27,510 --> 01:10:30,900
So but this is a good example. Y hidden Markov model.

596
01:10:32,040 --> 01:10:36,060
It is harder than you think in terms of computation.

597
01:10:36,210 --> 01:10:39,540
You just have a lot of hidden states and you don't know what they are.

598
01:10:39,660 --> 01:10:43,830
So you need to marginalize them. That's expensive. Okay. So that's the that's the point.

599
01:10:45,330 --> 01:10:48,720
So now let's talk about a little bit different problem.

600
01:10:48,730 --> 01:10:55,110
So maybe maybe calculating the probability given all this is not that, you know,

601
01:10:56,130 --> 01:11:01,530
this this could happen, but this is probably not the most important inference we want to make.

602
01:11:02,250 --> 01:11:05,930
So this might be more interesting. So let's say I have five.

603
01:11:05,940 --> 01:11:10,950
I observe I have observed whether for five days, sunny, sunny, cloudy, rainy, rainy.

604
01:11:11,580 --> 01:11:14,880
And I don't have a satellite. I'm living in the 19th century.

605
01:11:15,630 --> 01:11:20,280
So what is the disposition of the hidden state?

606
01:11:20,310 --> 01:11:26,430
I wanted to know. I want wanted to infer which which there was was atmospheric pressure was high.

607
01:11:26,430 --> 01:11:29,460
Which state has atmospheric pressure was low.

608
01:11:30,100 --> 01:11:36,180
How do we do it? So then basically we want to know.

609
01:11:36,210 --> 01:11:43,980
We want to infer hidden state of a particular day given all the observation, not a single observation.

610
01:11:44,340 --> 01:11:49,050
Because you know that if you have a multiple observation, they should help because each one is correlated.

611
01:11:49,680 --> 01:11:53,070
And assuming that the parameter is known, so how do we do it?

612
01:11:55,620 --> 01:12:10,080
So to be able to do this and well, I probably it's probably better to show that this is actually a hard problem first.

613
01:12:10,410 --> 01:12:13,920
Okay. So you basically need to calculate this, right?

614
01:12:14,100 --> 01:12:20,130
So let me argue that this without this slide, let me argue that this is a hard problem.

615
01:12:20,730 --> 01:12:26,400
You need to calculate this problem probability. Right. And does this bottom part look familiar?

616
01:12:27,640 --> 01:12:31,410
Bottom part are taking a long time or so.

617
01:12:31,470 --> 01:12:36,600
So it is it is not easy thing to to calculate.

618
01:12:36,600 --> 01:12:44,790
Right. So in the end, you actually have added one more variable.

619
01:12:44,790 --> 01:12:52,130
So it's harder. Okay. So the point is that you need to calculate this again and well,

620
01:12:52,230 --> 01:13:00,840
how do you cope with this if you emit the standard way to do it because you want to make the the denominator that looks like the numerator.

621
01:13:01,110 --> 01:13:07,439
You can actually make it by adding the Q of T and just adding them across all the possible states.

622
01:13:07,440 --> 01:13:11,510
So then it's a basically sort of normalization problem.

623
01:13:11,520 --> 01:13:22,260
So the the problem is basically I want to calculate the probability that you of cu of a TS I and all of the regions.

624
01:13:22,510 --> 01:13:30,030
Okay. So that's what you need to do. So, so then.

625
01:13:31,170 --> 01:13:50,490
Well, I have a bunch of unknown state in Q1 due to Q3 that that that Q T minus one here t t plus one.

626
01:13:53,580 --> 01:13:58,559
Okay. And I have a lot of observations.

627
01:13:58,560 --> 01:14:03,900
Actually, I am one. I have observation.

628
01:14:03,900 --> 01:14:11,310
400 days of weather assay and or or, you know, thousand days, whatever.

629
01:14:11,580 --> 01:14:14,890
Okay. Oh. Sorry. Oh.

630
01:14:15,230 --> 01:14:21,990
What did I do? All.

631
01:14:21,990 --> 01:14:26,820
T-minus one. Oh, one tea for the tea plus one.

632
01:14:28,140 --> 01:14:41,280
Good. What I want to know is that what is the probability of all my observation in this?

633
01:14:42,630 --> 01:14:46,230
Okay. I want to complete the joint project of this book.

634
01:14:47,460 --> 01:14:51,450
How do I do it? Okay. Okay.

635
01:14:52,560 --> 01:14:56,610
So. Well, then.

636
01:14:59,250 --> 01:15:02,430
So there is.

637
01:15:03,720 --> 01:15:11,790
So there is an algorithm that you can complete this probability efficiently using dynamic programing.

638
01:15:12,030 --> 01:15:15,750
Okay. So that's called forward and backward argument.

639
01:15:16,260 --> 01:15:20,890
Okay. So I'm going to show how how you do it in this equation.

640
01:15:20,910 --> 01:15:31,410
Exactly. Show how you do it. But it's probably easier if we, uh, visualize, if you show in the graph.

641
01:15:31,620 --> 01:15:39,720
Okay. So you have an I'm going to divide into four pieces here.

642
01:15:40,920 --> 01:15:49,680
Okay. So everything, everything after here, I'm going to say all t plus one or something.

643
01:15:49,770 --> 01:15:59,040
Or T plus. Okay. Okay. And I'm going to everything before I'm going to say t minus.

644
01:15:59,280 --> 01:16:02,620
Okay. And this is the state. State. Okay.

645
01:16:04,240 --> 01:16:11,310
And so now now it's time to use all the graphical model numbers.

646
01:16:12,150 --> 01:16:20,670
So you see, these are everything connected. So let's say let's say we're conditioning choo choo t.

647
01:16:21,000 --> 01:16:26,700
Okay, then do you see something becomes independent if you're conditioned on duty.

648
01:16:27,600 --> 01:16:31,470
Okay. This is very similar to what.

649
01:16:32,040 --> 01:16:35,790
What's shown here, actually. Oh, yeah.

650
01:16:36,720 --> 01:16:46,060
So in this case, if your conditional B, we learned that the AC, the AC, the E becomes all independent.

651
01:16:46,080 --> 01:16:50,940
Right. Conditionally on B. So we have the same thing here.

652
01:16:52,050 --> 01:16:58,650
So if you condition with your T, all of these previous state, everything is.

653
01:16:58,950 --> 01:17:02,400
And so because of this, this is only dependent.

654
01:17:03,330 --> 01:17:15,420
So these are directly dependent on the base, right? So if you if you condition I'm sure with t the key observation is that all of T minus one,

655
01:17:17,130 --> 01:17:27,620
t minus o t and 0tt plus all of those ratios o becomes conditional.

656
01:17:27,630 --> 01:17:33,030
Dependent. Okay. So that's the observation.

657
01:17:34,050 --> 01:17:40,140
So basically what we are doing is that we are going to make them as conditional.

658
01:17:41,310 --> 01:17:47,280
So. So first, we're going to compute the marginal because this was the probability.

659
01:17:47,610 --> 01:17:53,730
Okay. But then because we computed marginal, we make everything as a conditional here.

660
01:17:53,760 --> 01:17:58,080
Okay. Okay. So you see you see this part.

661
01:17:58,290 --> 01:18:03,180
So these are now can be represented as a separate product here.

662
01:18:04,380 --> 01:18:10,709
Okay. So and well, I actually don't need to separate this little later three part.

663
01:18:10,710 --> 01:18:13,800
I don't need to separate them. So I'm going to just so combine them again.

664
01:18:14,180 --> 01:18:18,780
Okay. So basically what I combine here is that.

665
01:18:19,170 --> 01:18:24,180
Well, I'm going to combine.

666
01:18:28,980 --> 01:18:36,510
This part, separate this part and this part separately and it becomes conditional independent given q.

667
01:18:41,360 --> 01:18:45,320
So that's what I'm doing here so well.

668
01:18:45,330 --> 01:18:49,549
Q. Q Yes, I'm going to model this first as a joint distribution because a.

669
01:18:49,550 --> 01:18:55,460
Q There's got to be some some part that models. Q But this is the same as putting Q.

670
01:18:55,490 --> 01:19:00,260
Q Still on the on here in the making, making them as a conditional so.

671
01:19:00,950 --> 01:19:07,190
So you're basically separating into two part after q t v for duty.

672
01:19:07,430 --> 01:19:16,490
Okay. So once you put it, this is everything that happened after and this is how everything happened in the same day or before.

673
01:19:16,820 --> 01:19:27,090
Okay. So I'm going to say that future probability is a beta and the beta of T I'm going to represent this after the key.

674
01:19:27,110 --> 01:19:31,150
This is my notation. Okay. So I'm going to define this is alpha.

675
01:19:31,850 --> 01:19:42,169
This is a beta. Okay. So. So then, uh, well, I get this situation that I still don't understand.

676
01:19:42,170 --> 01:19:46,400
Why does it help a computation? Okay, so that's the part I didn't get to there yet.

677
01:19:46,820 --> 01:19:51,950
So we're just setting up the problem. But we, we reach the time.

678
01:19:51,950 --> 01:19:59,840
So, uh, that the secret can be revealed in next week because we don't have a class in Wednesday.

679
01:20:01,200 --> 01:20:03,920
Okay. I'll talk to you next week.

