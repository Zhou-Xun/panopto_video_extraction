1
00:00:02,490 --> 00:00:07,020
Okay. Let's get started here.

2
00:00:08,100 --> 00:00:13,500
So we're going to move on to discussing this idea of sequential durability.

3
00:00:13,620 --> 00:00:23,430
It's sort of an alternative set of assumptions that we can use to make causal inference from observed data.

4
00:00:24,490 --> 00:00:32,280
You know, although in the end, I think a lot of them kind of boil back to the same approaches that we've discussed previously.

5
00:00:32,940 --> 00:00:38,610
And finally, I'll finish up with a little bit of a sort of clever discussion of mediation, analysis, view, instrumental variables.

6
00:00:39,420 --> 00:00:53,250
So a special case of randomization, we can basically use this idea of the instrument to do mediation analysis as well as.

7
00:00:59,340 --> 00:01:04,470
Adjustment for a direct causal inference on total effects.

8
00:01:06,300 --> 00:01:06,720
Okay.

9
00:01:06,720 --> 00:01:20,040
So the sequential and AUDIBILITY comes out of a paper by Imai, who's a stats professor at Princeton, does a lot of important work in causal inference.

10
00:01:21,390 --> 00:01:25,650
So he develops a set of assumptions that are termed sequential ignore ability.

11
00:01:26,970 --> 00:01:35,310
So basically considers the joint distribution of our potential outcomes.

12
00:01:35,400 --> 00:01:41,430
Now, under cross world, where you have an actual outcome associated with the treatment and with a mediator

13
00:01:41,430 --> 00:01:45,180
value and then with the mediator potential outcome of the mediator itself,

14
00:01:45,180 --> 00:01:47,700
which now of course just depends on the treatment.

15
00:01:48,390 --> 00:01:56,940
And then again conditional on X that we are basically randomized with respect to the treatment and that

16
00:01:56,940 --> 00:02:04,080
further conditional on an X that this joint distribution actually yields yields independence defendants.

17
00:02:05,970 --> 00:02:11,280
So they also implicitly assume positivity,

18
00:02:11,610 --> 00:02:18,090
which is something that I think is implicitly assumed in the Vanderbilt text, but we don't discuss in detail.

19
00:02:18,180 --> 00:02:26,730
So that's a poor point. So I think sorry, this t should be a.

20
00:02:32,350 --> 00:02:37,270
Here from Birmingham. All right.

21
00:02:37,360 --> 00:02:48,820
So basically that, you know, within whatever level of X you're at, that there's some na zero chance of being assigned to either level of treatment.

22
00:02:49,690 --> 00:02:56,319
And then positivity in the mediation context means also that you can take on

23
00:02:56,320 --> 00:03:01,000
any mediation value within both within all the levels of treatment and any,

24
00:03:01,020 --> 00:03:05,170
any level of X. So, so that's an important point.

25
00:03:08,790 --> 00:03:18,000
So they use the term sequential to refer to the fact that treatment is first assumed to be ignorable given the observed covariance,

26
00:03:18,480 --> 00:03:24,240
pretreatment covariates, and then the mediator is ignorable given the observed coverage of the observed treatment assignment.

27
00:03:25,890 --> 00:03:29,910
So this allows them to kind of step through. We'll see the proof of this in a little bit,

28
00:03:30,690 --> 00:03:39,750
kind of step through various conditioning points to where we can basically use observed data to estimate mediated effects.

29
00:03:43,220 --> 00:03:46,450
So. Okay.

30
00:03:50,320 --> 00:04:00,040
So you might to find a causal mediation effect and direct effect under a given treatment status, basically as.

31
00:04:03,000 --> 00:04:09,810
The effect of changing the mediator from treatment to control of fixing the treatment level.

32
00:04:11,070 --> 00:04:18,300
So that's their mediation effect. Of course, it could be set at either treatment level, at any treatment level.

33
00:04:19,470 --> 00:04:23,970
And then the direct effect. Fix the mediator.

34
00:04:25,320 --> 00:04:30,780
That is potential outcome under given treatment level and then change the actual treatment.

35
00:04:32,960 --> 00:04:43,520
So I can see this kind of corresponds to Vanderbilt's natural, direct and indirect effect or indirect a direct effect.

36
00:04:44,420 --> 00:04:49,040
If we set a figure one year on their kind of causal mediation effect.

37
00:04:52,060 --> 00:04:55,180
I'm sorry. Because I have this backwards. So that. Yes, that.

38
00:04:59,360 --> 00:05:04,190
The natural, direct effect. It's a tape of the one.

39
00:05:17,930 --> 00:05:22,830
Let's see here. So there's the direct effect.

40
00:05:25,120 --> 00:05:28,870
Sorry. Natural, incorrect effect up here.

41
00:05:31,450 --> 00:05:35,029
With Delta with a 4 to 1. All right.

42
00:05:35,030 --> 00:05:41,030
So the Vanderbilt fixes the treatment level one.

43
00:05:42,350 --> 00:05:44,900
And then what's the radiation change between one and zero?

44
00:05:47,690 --> 00:05:56,030
And then their natural direct effect, since the beta value at the control level was zero level and then changes the treatment.

45
00:05:58,100 --> 00:06:09,320
So as in Vanderbilt, if we set the mediation effect, the treatment level, the direct effect of the control level, they sum of the total effect.

46
00:06:15,620 --> 00:06:36,990
Right. So. School.

47
00:06:51,180 --> 00:06:55,600
It's pretty straightforward. It's.

48
00:07:11,560 --> 00:07:19,450
Both expectations and what are your psyche with inside the expectation piece cancel.

49
00:07:42,550 --> 00:07:46,180
So it's the sort of personal components here cancel out.

50
00:07:46,180 --> 00:07:53,589
I'm just left with my expected value of my potential outcome under treatment with the

51
00:07:53,590 --> 00:07:58,900
mediators at a treatment value and minus potential outcome of control with the media,

52
00:07:58,930 --> 00:08:06,820
its control value. Those are just the potential outcomes of treatment control, which is my total effect.

53
00:08:10,410 --> 00:08:24,630
So if I said the consolidation effect under control and the direct effect under treatment, so then I would also get the same result.

54
00:08:33,390 --> 00:08:42,570
So again, trying to sort of decompose this total effect into a direct and indirect effect, additively.

55
00:08:47,120 --> 00:08:56,530
Okay. So. A little a little different about this as they go on.

56
00:08:59,310 --> 00:09:15,110
To basically show their direct and indirect effects, then correspond to observed expected values and are given set of mediators and the control,

57
00:09:15,150 --> 00:09:25,809
the treatment set to whatever treatment risk we're fixing and then averaged over the difference in the mediators under treatment

58
00:09:25,810 --> 00:09:39,240
and control and then integrated out with respect to ex with respect to the mediator value and similarly for indirect effect.

59
00:09:39,510 --> 00:09:42,690
Looking at the difference here and the expected values,

60
00:09:42,990 --> 00:09:48,950
the outcome between treatment and control at a fixed value of the mediator that are in

61
00:09:48,990 --> 00:09:53,610
agreement over that distribution of the mediator at that fixed treatment level an x.

62
00:09:54,960 --> 00:10:01,950
So C in the end, the scripts allow us to kind of come up with a sort of non parametric estimate or doesn't require us to model.

63
00:10:25,350 --> 00:10:36,960
The trick of. But.

64
00:11:02,040 --> 00:11:07,290
So I want to put up these mutual.

65
00:11:44,720 --> 00:11:51,200
That's right. So you sort of have these things always in and around here.

66
00:11:55,410 --> 00:12:18,630
So it's. So I want to work out this distribution of my potential outcome where the mediator is at its value under the alternative treatment.

67
00:12:18,840 --> 00:12:26,460
I will give an x so the start of the usual game.

68
00:12:34,050 --> 00:12:37,110
So I guess we're just using intervals here instead of summations.

69
00:12:38,460 --> 00:12:42,600
So in this categorical you'd be back to the summation piece.

70
00:13:00,850 --> 00:13:12,160
It's basically integrity now in respect to this conditional distribution of an X.

71
00:13:15,520 --> 00:13:19,650
Let's just reiterate the expectations here.

72
00:14:04,340 --> 00:14:10,820
So I'm going to plop this a star in here, and that comes right out of this assumption here.

73
00:14:13,670 --> 00:14:23,920
So that's basically right.

74
00:14:25,340 --> 00:14:36,530
So that condition, these guys are independent given aid and this individual component will also be independent of a condition.

75
00:14:36,530 --> 00:14:43,010
And so me. So I can just bring that in there.

76
00:14:54,840 --> 00:15:03,090
And I can play the same game. To the integrated distribution integrated with.

77
00:15:29,080 --> 00:15:34,020
So this is a little awkward notation here, but it's basically is the idea.

78
00:15:34,720 --> 00:15:57,320
Avery now respect to this distribution of apps they. And so I have the same thing here.

79
00:16:02,450 --> 00:16:05,600
So you're.

80
00:16:50,750 --> 00:16:53,780
And since I had this independence vote, didn't matter what I said.

81
00:16:53,990 --> 00:17:05,830
Hey, out here. Yeah.

82
00:17:11,140 --> 00:17:14,350
Sorry. Except.

83
00:17:38,930 --> 00:17:46,140
So. Right.

84
00:17:46,170 --> 00:18:23,270
So this is the sequential accountability part. Right.

85
00:18:24,560 --> 00:18:29,090
So that that's the second assumption here.

86
00:18:30,530 --> 00:18:37,680
It's important for this piece here. Right. So independence of an intentional outcome of a mediator given an X.

87
00:18:38,870 --> 00:18:43,130
He brought that up. There was a little bit of sleight of hand.

88
00:18:43,310 --> 00:18:48,410
This sequential ignore ability piece, let's just double back and get rid of this.

89
00:19:24,530 --> 00:20:04,940
Sorry. I'm just giving my lines here. Yeah.

90
00:20:17,580 --> 00:20:21,870
Yeah. He's in Europe.

91
00:20:22,820 --> 00:20:32,630
So again, independence of a in our world potential outcome is a matter what value is equal to.

92
00:21:35,040 --> 00:21:45,070
To get an independence of why, and they bring that back and it stays the same.

93
00:21:55,330 --> 00:21:58,960
And since these two things are equal to here.

94
00:22:04,870 --> 00:22:34,040
Have consistency.

95
00:22:41,720 --> 00:22:50,060
My observed mediators correspond to my potential outcome mediators when I'm actually at the values.

96
00:23:00,100 --> 00:23:03,180
The same is true here, right?

97
00:23:03,200 --> 00:23:12,190
Consistently back and A&M and EMS.

98
00:23:18,110 --> 00:23:26,660
So. That's got me from here.

99
00:23:29,850 --> 00:23:33,390
Okay. You're just right.

100
00:23:42,770 --> 00:23:55,650
See. Right.

101
00:24:18,720 --> 00:24:22,170
No, I guess I should. Right. Just marginally then.

102
00:24:25,290 --> 00:25:00,880
Double. Double. So.

103
00:25:06,930 --> 00:25:17,790
All right. So if I integrate over expected the value of Y the M to its expected value Y given M and x,

104
00:25:18,690 --> 00:25:26,880
but integrating respect to M under the control value and then averaging out over the specter of a over its x,

105
00:25:27,900 --> 00:25:38,280
I get an estimate of the expectation of this potential outcome under treatment

106
00:25:38,280 --> 00:25:43,560
level A when a mediator is expected to be set to its alternative treatment level.

107
00:25:44,880 --> 00:25:48,180
So basically this sort of cross world peace.

108
00:25:50,860 --> 00:25:54,640
Using these two assumptions here sequentially, your ability.

109
00:25:57,640 --> 00:26:00,879
So stay out of the way here for a second.

110
00:26:00,880 --> 00:26:12,850
Any questions you can or should be dropping in and out these components, using these assumptions and eventually getting us to the observed values?

111
00:26:33,490 --> 00:26:40,540
So I'm going to leave that up over there and really go.

112
00:26:41,080 --> 00:26:45,450
So other. Right, same condition you're in your life.

113
00:26:46,300 --> 00:26:50,020
Yeah. Yeah. Why is that?

114
00:26:50,590 --> 00:26:54,300
Like, I know there is independence, right? Mm hmm.

115
00:26:54,940 --> 00:26:59,530
Is that why you didn't love me from here to here?

116
00:27:00,280 --> 00:27:04,480
Yeah. Like, at the very beginning, you were doing that, so in the very beginning?

117
00:27:04,790 --> 00:27:07,960
No, I mean, all I'm doing is collecting on X. Oh, right.

118
00:27:08,470 --> 00:27:12,070
So. So this is basically just this.

119
00:27:12,130 --> 00:27:16,780
This is just a statement of. Of sort of your expectations, right?

120
00:27:17,620 --> 00:27:23,710
So, yeah, there's no no assumptions here at all.

121
00:27:25,450 --> 00:27:30,190
Right. And when you're over this. Great. Is that the reason?

122
00:27:39,040 --> 00:27:44,420
Okay. So once we have that, pretty straightforward to pull up the rest of it.

123
00:27:56,590 --> 00:28:20,520
Now. Okay.

124
00:28:21,070 --> 00:28:36,000
So there is currently no one to hear their causal mediation effect or or indirect effect.

125
00:28:37,830 --> 00:28:46,200
Right. So that's sorry, that's the treatment level and the need to switch between zero.

126
00:28:49,860 --> 00:29:00,839
So. Right. So that in this case it was part A or one or name or whatever it is.

127
00:29:00,840 --> 00:29:05,280
And like historically one or zero.

128
00:29:07,200 --> 00:30:13,960
So. Up here.

129
00:30:26,490 --> 00:30:57,130
Right. So I think. So.

130
00:31:17,240 --> 00:31:50,000
Movement. All right.

131
00:31:50,160 --> 00:31:53,969
So I got to think a little bit about I may have to go back and double check and there's a little bit of an

132
00:31:53,970 --> 00:31:59,040
issue here because it's another sort of it's important to be able to sort of integrate this condition,

133
00:31:59,040 --> 00:32:02,160
this respect to a where is this value here?

134
00:32:02,930 --> 00:32:16,110
It seems like it really should be a star. So what if we make that leap then and and go on here?

135
00:32:16,110 --> 00:32:19,500
Here we can pull out everything. Is this.

136
00:32:32,720 --> 00:32:53,580
This is.

137
00:33:15,210 --> 00:33:18,710
Okay. So that gets us to our results in the slide.

138
00:33:34,790 --> 00:33:41,060
It's too late for direct effect.

139
00:34:34,560 --> 00:34:46,920
Here. We just put you in the situation room conditioning on why people did something like a.

140
00:34:59,310 --> 00:35:04,170
So. All right. So we can factor out all this stuff here.

141
00:36:19,300 --> 00:36:27,790
So I mean, so we've been able to show results on the slides.

142
00:36:43,830 --> 00:37:08,910
Question that this part is pretty straightforward. Yes.

143
00:37:09,180 --> 00:37:12,210
Why are we trying to show this? Like, I understand the map.

144
00:37:12,450 --> 00:37:21,330
Yeah. What? What's up? So the goal of this course is to estimate these direct, indirect effects by using observe data.

145
00:37:24,360 --> 00:37:27,420
And the next slide, we'll talk more about that. Precisely.

146
00:37:41,390 --> 00:37:47,030
Right. I mean, it's pretty much correspondingly worked out for Vanderbilt and the coach.

147
00:37:49,790 --> 00:37:53,020
Or we model. I get back to that.

148
00:37:56,000 --> 00:38:03,350
So the one difference here, I can kind of pull this down iteratively.

149
00:38:04,610 --> 00:38:07,730
Okay. Is that.

150
00:38:14,150 --> 00:38:28,880
Categorical. Right.

151
00:38:28,930 --> 00:38:34,930
This is going to be said. Right. This natural, indirect and natural direct effects.

152
00:38:39,960 --> 00:38:44,140
And you fix it. The treatment level, the.

153
00:38:46,550 --> 00:38:50,680
I keep forgetting because these things cause mediation effect.

154
00:38:51,970 --> 00:38:57,100
This causal mediation affected the treatment level and corresponds exactly to the natural indirect effect.

155
00:38:59,590 --> 00:39:06,880
And the not the direct effect at the treatment level corresponds to the natural direct effect.

156
00:39:10,120 --> 00:39:14,860
I'm sorry. The network affected them at the control level.

157
00:39:16,180 --> 00:39:25,149
So and of course that are the most discussion makes no assumptions about the distribution of em so they use universal sign.

158
00:39:25,150 --> 00:39:35,530
But if if I'm an X or discrete then we basically are back to the summation.

159
00:39:35,530 --> 00:39:46,180
So we're in an X, so to correspond. Exactly. So I guess one little thing that that is different here is that is that.

160
00:39:51,840 --> 00:40:09,420
If you famous categorical, they basically argue that you don't really need to set up models, you just estimate it non parametric like.

161
00:40:11,400 --> 00:40:23,520
So basically we look at the probability that M equals two m the mediator is equal to

162
00:40:23,520 --> 00:40:32,009
some value between under treatment and the probability that it's equal to some value,

163
00:40:32,010 --> 00:40:44,430
a little better control. And then we consider the mean of y under treatment.

164
00:40:45,630 --> 00:40:50,460
It's some value m and then we average up where these differences.

165
00:40:52,940 --> 00:40:58,310
So that allows us to estimate this indirect effect.

166
00:41:01,770 --> 00:41:06,479
So we kind of did similar things, except we had these kind of layer models here.

167
00:41:06,480 --> 00:41:11,760
They sort of argue here under these assumptions that you can just do it directly.

168
00:41:13,560 --> 00:41:16,620
Of course, could be unstable. Right?

169
00:41:18,060 --> 00:41:21,150
You might have a problem if.

170
00:41:29,070 --> 00:41:33,830
There are very few observations within one of these countries. So.

171
00:41:35,650 --> 00:41:54,750
But. But you can't avoid modeling. Okay.

172
00:41:54,810 --> 00:42:02,490
So they basically argue their approach is an advantage over the previous approaches because they first of all,

173
00:42:02,490 --> 00:42:10,380
they they argue that conditions are sort of more easily interpretable right now with

174
00:42:10,390 --> 00:42:15,720
a little bit of money or 10 million around this is a little easier to think about.

175
00:42:16,650 --> 00:42:23,340
But in the end, I think they really pretty much match up to everything going back to kind of the original development of this,

176
00:42:23,340 --> 00:42:31,940
which dates back to a proceedings paper by Judith Perl and in turn corresponds to those in the van,

177
00:42:31,940 --> 00:42:35,040
the real textbook and those that were reviewed in her class notes.

178
00:42:39,170 --> 00:42:44,360
So I kind of want to put this in here because sometimes you'll hear these sort of various approaches kicked around.

179
00:42:45,380 --> 00:42:54,350
To my mind, they're kind of the same thing, although the underlying proofs and the sort of utility of them I think is a little different.

180
00:42:56,690 --> 00:43:02,600
For example, you're using this sequential mediation approach, you trying to get this not parametric estimate,

181
00:43:02,690 --> 00:43:08,690
which is a little harder to come by than in the sort of original.

182
00:43:10,570 --> 00:43:20,720
Set of assumptions. Okay.

183
00:43:27,730 --> 00:43:34,060
All right. So I'm going to finish up the day. We're talking about mediation very the instrumental variables.

184
00:43:35,590 --> 00:43:41,620
And I suppose one of the themes here was sort of relating these various approaches to each other.

185
00:43:42,700 --> 00:43:49,660
And here we're going to recast this structural mean model as an instrument of variable analysis under a few assumptions.

186
00:43:50,500 --> 00:43:56,440
When the treatment's randomized to that, there's treatment interactions with the mediator.

187
00:43:56,980 --> 00:44:05,740
This is important because in a second this basically corresponds to the to the instrumental variable assumption.

188
00:44:08,680 --> 00:44:17,020
That that there's some association between the instrumental variable and the outcome,

189
00:44:17,650 --> 00:44:22,480
potential outcome, and that there are no interactions with treatment in a mediator for the outcome.

190
00:44:23,440 --> 00:44:30,490
So this helps to basically get us back to the randomization aspect of the instrumental variable.

191
00:44:36,290 --> 00:44:48,470
So. Let's start by considering our following models.

192
00:44:50,180 --> 00:45:08,030
So. So modeling wise a function of treatment just for covariance and then is a function just of treatment of covariance.

193
00:45:08,030 --> 00:45:11,960
And I'm kind of getting back to the bear and get the idea right.

194
00:45:12,950 --> 00:45:16,310
So both these deltas and epsilon ones are basically mean zero.

195
00:45:18,880 --> 00:45:28,240
So this cauvery adjustment in the main, so we're randomization here can basically be effective on treatment.

196
00:45:28,240 --> 00:45:35,740
So basic idea being that of course when you adjust for axes that you've broken confounding between treatment or exposure in your outcome.

197
00:45:37,570 --> 00:45:41,200
So. So under this.

198
00:45:41,200 --> 00:45:59,179
This. We can we can recast this Bernie Canning approach as a direct effect given by beta one and a direct effect driven by gamma one minus beta one,

199
00:45:59,180 --> 00:46:02,480
which is kind of nice because if you suspect this editing approach,

200
00:46:03,830 --> 00:46:07,510
so idea that we can add the direct and indirect effects together, including effects.

201
00:46:08,990 --> 00:46:12,830
So. Right over here.

202
00:46:28,610 --> 00:47:24,710
Again. But this.

203
00:47:40,130 --> 00:47:44,080
Sometimes it's.

204
00:47:51,060 --> 00:48:16,950
So in direct effect, the effect has been to write.

205
00:48:19,920 --> 00:48:23,390
Fact the treatment of many other crimes.

206
00:48:29,600 --> 00:48:52,650
I can, people. So if we just work out for marginal distribution of why given a small period.

207
00:51:40,380 --> 00:51:47,840
So. Left with.

208
00:51:59,580 --> 00:52:04,860
We care about this and we focus here, particularly this piece here.

209
00:52:05,810 --> 00:52:15,390
Right. So this is the total effective treatment for one. So indirect effect.

210
00:52:25,820 --> 00:52:29,810
I can write. It's three, two, one minus one.

211
00:52:31,160 --> 00:52:34,209
Right before I subtract off beta one.

212
00:52:34,210 --> 00:53:34,660
I'm left with this piece here because. And that's all well and good or I'm being fair and Kenny world but if I have

213
00:53:34,660 --> 00:53:40,780
confounding between the mediator and the outcome then we're in a situation where.

214
00:53:44,400 --> 00:53:48,030
AMITA My Epsilon is given the mediator. It's no longer zero.

215
00:53:49,320 --> 00:54:05,250
Right. So once I conditioned on them, I'm no longer able to sort of have this randomization peace between between them and in a preemptive way.

216
00:54:09,330 --> 00:54:19,010
So if we can find a model. Where I can write my mediator and write.

217
00:54:19,600 --> 00:54:29,770
I have essentially instrumental variable rate so I could find a Z where Z is independent of the device.

218
00:54:30,670 --> 00:54:36,980
But there's a correlation between Z and X. Yeah.

219
00:54:37,400 --> 00:54:49,210
Let's see here. It's nonzero that I can borrow our instrumental variable approach.

220
00:54:55,260 --> 00:54:59,190
But if he is randomized, then by definition.

221
00:55:04,710 --> 00:55:06,600
A model that has an interaction here.

222
00:55:10,120 --> 00:55:23,380
Between A and X, it's going to still be randomized right to plain X by some randomized variable that I'm going to be able to break this correlation.

223
00:55:26,230 --> 00:55:35,170
But as long as there's some ability to predict them from these interactions, then I've got an instrument.

224
00:55:37,680 --> 00:55:45,600
Pretty clever little approach here, basically looking at essentially heterogeneous treatment effects in the media.

225
00:55:46,110 --> 00:55:56,640
And if you don't have those, if the impact of the treatment on the mediators simply doesn't depend on covariance, then you can't use this approach.

226
00:55:58,150 --> 00:56:05,710
But if it does, then you're able to get some grip, so to speak, with this instrument and be able to assess mediation.

227
00:56:08,930 --> 00:56:29,200
We'll see in a second here. So if we do this two squares, least squares analysis, right.

228
00:56:29,210 --> 00:56:38,150
And we first of all predict M now for May X and importantly this interaction and then can ask

229
00:56:38,150 --> 00:56:48,800
why when they extend the predicted values of and then our direct effect remains beta one.

230
00:56:51,750 --> 00:56:55,560
And our indirect effect will be given by theta one minus beta one.

231
00:57:09,140 --> 00:57:32,840
And that's from that piece over there. This also depends on there's no interaction between treatment and mediator.

232
00:57:38,000 --> 00:57:41,090
In order to get this beta one piece right.

233
00:57:43,140 --> 00:57:46,799
There's no the expected value of y given M&A.

234
00:57:46,800 --> 00:57:50,700
I didn't write Baidu three eight times.

235
00:57:50,700 --> 00:57:54,990
Yeah, I do have that. This whole thing kind of collapses.

236
00:57:58,490 --> 00:58:03,980
Relies on this result here, which was basically the beer in Ankeny.

237
00:58:04,610 --> 00:58:11,990
That's better than on Slide nine. Don't we assume that there are treatment interactions with the mediator?

238
00:58:14,580 --> 00:58:20,750
Yes. But there's no interaction between the mediator and the treatment of the outcome.

239
00:58:23,670 --> 00:58:34,090
That's a person on second mind. Yeah. So here, this is the effect of the treatment on the media.

240
00:58:34,120 --> 00:58:39,220
That's what I'm referring to. That's a little unclear, but. So that's this.

241
00:58:42,080 --> 00:58:45,260
It's this piece here. Know it's about interactions. All right? Yeah.

242
00:58:45,320 --> 00:58:53,610
Okay. Right. So. Attribute interaction to the mediator.

243
00:58:54,870 --> 00:59:00,090
There are some covariates that whether some difference affects a meter, but there's no interaction contributing to the outcome.

244
00:59:00,540 --> 00:59:06,160
There can be interactions with other covariates. And the mediator.

245
00:59:06,700 --> 00:59:09,849
And they. And in the treatment with the outcome.

246
00:59:09,850 --> 00:59:13,660
But not the mediator. You know, between the treatment. The mediators and so.

247
00:59:15,640 --> 00:59:18,850
It's intermediate variable, you know, baseline coverage stuff going on.

248
00:59:32,070 --> 00:59:39,290
Okay. And the question. Okay.

249
00:59:39,760 --> 00:59:47,470
So we'll finish up the return to the returning to the Physician Encouragement study.

250
00:59:49,330 --> 00:59:54,130
Again, we're not really expecting direct and indirect effects. We're not expecting large direct effects here.

251
00:59:54,340 --> 00:59:59,350
But it's a nice example because it personalized, we'll ramp.

252
01:00:00,670 --> 01:00:07,540
And secondly, assessing this exclusion restriction is is one of the features that direct indirect effects can do.

253
01:00:09,010 --> 01:00:17,650
So so we're going to start off by saying our ordinary squares model.

254
01:00:19,930 --> 01:00:24,280
So our goal here is to get this overall treatment effect to be adjusted for covariates.

255
01:00:24,350 --> 01:00:30,459
Now we have randomization, so we don't expect any bias in the estimation of theta one if we ignore this.

256
01:00:30,460 --> 01:00:38,450
But we might get some somewhat. Reduction and variance.

257
01:00:39,920 --> 01:00:50,580
So. And we can use our baseline CCD as one of the covariates and we'll put an age also.

258
01:00:52,740 --> 01:00:57,000
So it's not really significant effect baseline, obviously it's pretty big.

259
01:00:58,110 --> 01:01:05,400
It's a depression measure. So a higher your baseline depression likely had a higher depression measure at your final outcome,

260
01:01:05,580 --> 01:01:11,760
although there's a pretty substantial treatment effect here, although it doesn't quite reach never evidence.

261
01:01:14,490 --> 01:01:21,630
It's all samples here, you. Okay.

262
01:01:21,960 --> 01:01:27,210
So now we have to go on and just refer to our assumptions here.

263
01:01:28,210 --> 01:01:33,900
Right. This one we got by by definition because of the way that this was a randomized trial.

264
01:01:34,410 --> 01:01:36,420
So now we're going to assess to.

265
01:01:44,620 --> 01:01:52,960
So would we be able to cover this interaction with the association with treatment assigned to treatment taken so well.

266
01:01:55,120 --> 01:02:00,370
I have my two covariates, so I put in my treatment of my main effects.

267
01:02:01,600 --> 01:02:06,220
So not much going on here with baseline, but the first seem to be some issue with age.

268
01:02:08,410 --> 01:02:12,520
The treatment seems less effective with it.

269
01:02:12,520 --> 01:02:19,270
With age, right? The bigger this number is, then the smaller the effective treatment is.

270
01:02:21,130 --> 01:02:25,810
So. And I just did an overall test.

271
01:02:26,920 --> 01:02:34,510
I have a couple of things here still suggests that we can use these interaction terms as instrumental variables.

272
01:02:36,880 --> 01:02:41,800
So now for the last part, I'm just going to have to make this assumption that they are independent.

273
01:02:43,690 --> 01:02:52,270
I'm sorry that there's no interaction between M&A, although I think in our earlier analysis, we also saw little evidence of that.

274
01:02:53,590 --> 01:02:57,100
So I'm going to go ahead and just use my two stage lead square estimate.

275
01:02:59,750 --> 01:03:07,690
So. So here's my outcome model.

276
01:03:13,650 --> 01:03:19,050
So of course, money to that sort of piece up there.

277
01:03:20,460 --> 01:03:24,180
And for my mediator model. Right, I wouldn't include my interactions.

278
01:03:28,340 --> 01:03:33,890
And it's always a good idea, I think, just to use the the sort of robust variance estimate.

279
01:03:44,680 --> 01:03:46,030
So for stage regression,

280
01:03:46,060 --> 01:03:56,530
just sort of showing there is some predictive value on the mediator in terms of Baseline C CD age and the interactions on each.

281
01:04:04,180 --> 01:04:23,140
And then. A two stage live scores estimate her direct effect and there's about .05 some indirect effect I get.

282
01:04:27,760 --> 01:04:34,630
I'm going back to this right here and subtracting off.

283
01:04:42,800 --> 01:04:52,100
This direct effect has to be so that fatal one -3.20 -4.05 is my beta one.

284
01:04:53,330 --> 01:04:56,830
So that leaves me with the indirect effect estimate.

285
01:04:56,840 --> 01:05:03,530
So the effect essentially of taking the treatment given assigned to it about -2.7.

286
01:05:04,610 --> 01:05:09,259
So, all right.

287
01:05:09,260 --> 01:05:18,560
So this is a little different than what we saw before. We can I guess I should know, we computer 95% credible interval for this direct effect.

288
01:05:19,010 --> 01:05:28,080
Very wide. Indirect effect probably best to bootstrap that we're.

289
01:05:30,730 --> 01:05:35,330
So. If you go back.

290
01:05:37,840 --> 01:05:43,360
1066 minutes put up. Time.

291
01:06:17,910 --> 01:06:23,940
So this was our approach using the sort of van der Waals modeling.

292
01:06:33,230 --> 01:06:40,210
So there. The result here was a one negative .09.

293
01:06:41,620 --> 01:06:44,860
The resulting the large bigger indirect effect.

294
01:06:47,130 --> 01:06:51,090
So here, I guess if we were to do a proportion. All right.

295
01:06:51,850 --> 01:06:57,719
So compute the proportion here.

296
01:06:57,720 --> 01:07:04,260
That would be 0.5 over negative .32. So I know something order about 50% instead of 3%.

297
01:07:04,740 --> 01:07:11,820
But again, very, very wide and actually a much wider interval than we found with this modeling approach.

298
01:07:15,840 --> 01:07:20,960
So. All right. So I'll finish up with a couple of questions to you folks.

299
01:07:24,270 --> 01:07:29,430
So why are we getting sort of different instruments, different instruments on them?

300
01:07:30,380 --> 01:07:44,170
Point instrument speculate on. Not terribly.

301
01:07:49,880 --> 01:07:53,330
Right. I'm just going to go. Yes.

302
01:07:54,200 --> 01:07:58,159
Right. Right. So it's a it's sort of a more non parametric approach.

303
01:07:58,160 --> 01:08:01,920
There's no model involved yet.

304
01:08:01,950 --> 01:08:08,960
It's an attempt to observe confounding rather than using modeling based on X linear model, based on X, this instrumental variable.

305
01:08:11,960 --> 01:08:16,940
And any thoughts as to why the intervals for additional variable pressure so much wider?

306
01:08:19,100 --> 01:08:23,970
I'm going to give a hint to that by. Back to.

307
01:08:30,900 --> 01:08:49,010
Actually. I'll put it here. So he's instrumental, very worldly, usually in this sort of struggle between.

308
01:08:50,310 --> 01:08:55,460
A good instrument with respect to randomization and a good instrument with respect to what?

309
01:08:57,060 --> 01:09:03,900
Explaining, explaining, yes, the predictive power. So this isn't terribly horrible, but it's not great.

310
01:09:04,400 --> 01:09:09,420
Right. So basically, this interaction is almost basically zero.

311
01:09:09,480 --> 01:09:12,719
Right. And we do have a linear reaction age.

312
01:09:12,720 --> 01:09:20,910
So my estimate isn't large. The p value is pretty big. A little more power, but it's still a not terribly powerful instrument.

313
01:09:22,650 --> 01:09:27,210
So one way to deal with that is with a big sample size.

314
01:09:28,560 --> 01:09:33,270
Unfortunately, here we have to remember 71 observations.

315
01:09:34,740 --> 01:09:39,270
So so that doesn't help us here.

316
01:09:39,480 --> 01:09:44,580
So but as you know, that's true example, I think it's pretty there for us.

317
01:09:46,050 --> 01:09:55,200
So. So the trick is to basically turn this this sort of treatment heterogeneity into an instrument and then then go from there.

318
01:09:55,410 --> 01:10:02,430
But it does require that you have some good treatment, heterogeneity, absence of that, you aren't going to have a very strong instrument.

319
01:10:05,970 --> 01:10:13,920
It's no. So okay.

320
01:10:13,920 --> 01:10:16,620
So just to kind of give a little bit of roadmap here going out,

321
01:10:18,840 --> 01:10:26,550
this kind of concludes this sort of discussion of causal effect as to end approaches, the direct indirect effects.

322
01:10:29,130 --> 01:10:35,010
So I'm going to we're going to kind of go back and sort of try to put these pieces together a little

323
01:10:35,010 --> 01:10:40,860
bit to sort of principle stratification or causal association with the sort of direct indirect effect,

324
01:10:41,820 --> 01:10:46,260
causal effect approach, sort of discuss how they overlap, where they don't.

325
01:10:47,820 --> 01:10:50,250
Maybe some bit of the strengths and weaknesses of each.

326
01:10:51,390 --> 01:10:58,140
And to my mind, that'll actually cover pretty much the core of the class, at least what I know about causal inference.

327
01:10:59,520 --> 01:11:06,960
And again, it's sort of base form. So if we have time after that, we're going to go a little bit into time varying.

328
01:11:07,980 --> 01:11:14,390
So I mean, I know that everybody's taking survival analysis, so it's all like that, like the Bayesian stuff.

329
01:11:14,400 --> 01:11:21,300
I'll have a very brief review of that material and then we'll get into the big discussion on that,

330
01:11:21,330 --> 01:11:26,549
that the tricky thing on that is, is there's a little bit of we've seen with mediation, right?

331
01:11:26,550 --> 01:11:40,830
As soon as we're trying to look at things there where the impact of what we're trying to estimate causally is observed sort of post treatment,

332
01:11:41,880 --> 01:11:45,960
then we sort of have to be kind of thinking counterfactual.

333
01:11:46,900 --> 01:11:51,810
So, so of course, any time to event thing, we're going to be following over time, right?

334
01:11:52,080 --> 01:11:55,229
So, so let's have a little discussion.

335
01:11:55,230 --> 01:12:04,560
In particular, things like hazard ratios may no longer be as easy to interpret, at least directly or as as causal estimates.

336
01:12:06,330 --> 01:12:10,410
So so there may be some alternative approaches that we're sort of we'll focus on instead.

337
01:12:12,330 --> 01:12:20,940
And then, of course, if if treatments themselves can be changed over time,

338
01:12:21,840 --> 01:12:28,229
then then of course, this sort of confounding by treatment thing becomes more important.

339
01:12:28,230 --> 01:12:33,270
And there's some of these approaches that have been adapted into to a.

340
01:12:36,050 --> 01:12:40,250
Into it to a multiple exposure or multiple treatment setting.

341
01:12:41,300 --> 01:12:49,190
So that'll definitely take us out beyond that to and beyond the end of the semester so that we are a ramp up.

342
01:12:51,280 --> 01:12:54,700
Okay. Cool. All right. I'm around this week.

343
01:12:54,700 --> 01:12:57,760
I'll see you. But if you want to pop in there on Monday or Tuesday.

