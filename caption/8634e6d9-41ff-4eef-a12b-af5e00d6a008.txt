1
00:00:00,600 --> 00:00:03,600
A little close to the altar.

2
00:00:04,090 --> 00:00:13,980
I think we have three days on Tuesday and one on Thursday, so that we're a little post-Christmas on this day.

3
00:00:18,270 --> 00:00:24,569
We'll have to. Okay.

4
00:00:24,570 --> 00:00:32,020
Again, first I got a little bit I'm not sure how many of you got your exam paper back because I think

5
00:00:32,280 --> 00:00:40,170
Struble sent out an email saying that you need to examine every aspect and if you have a yes,

6
00:00:40,230 --> 00:00:51,330
then you probably can find your loved ones. And we have lots of so I just want to show that just like last time, which was longer.

7
00:00:51,330 --> 00:01:01,470
So very quickly with this fusion of so here I loaded this since 52.

8
00:01:01,860 --> 00:01:10,460
This is the description of the. This one is a decision the.

9
00:01:13,180 --> 00:01:19,030
Of the greats. So overall, I think that the exam choice was easier than it was.

10
00:01:20,030 --> 00:01:29,080
So I think concentrated in the Israelis is quite a skilled.

11
00:01:29,530 --> 00:01:39,570
But anyway, so this is just for inference so that the total total score I think is 85 and another meeting is 78.

12
00:01:39,580 --> 00:01:42,990
So it's. So.

13
00:01:43,100 --> 00:01:45,450
So I think overall, I think you guys did great.

14
00:01:46,860 --> 00:01:57,000
So again, if you have any questions or concerns or anything like that, feel free to reach out to me and then we can set out in time and talk.

15
00:02:03,700 --> 00:02:08,650
Yeah, that's that. So now for the final third act, just a few words.

16
00:02:08,680 --> 00:02:17,559
I mean, I think some of you actually draw the final word that some of you probably did not know which which is,

17
00:02:17,560 --> 00:02:21,220
I mean, which is quite a quite a major, I think, final product.

18
00:02:21,250 --> 00:02:25,930
There is, of course, always some some benefits of having a son.

19
00:02:25,930 --> 00:02:36,070
And also there there might be issues. And hopefully you guys can overcome the challenges that you're encounter.

20
00:02:37,100 --> 00:02:47,960
If you have any any issues that you would like to reach out to me, just feel free to me know so that I can be okay with your car.

21
00:02:49,520 --> 00:02:59,630
But hopefully you guys have a way of dividing up the work in a way, a good car ride with each other.

22
00:02:59,640 --> 00:03:04,980
Because again, the purpose of the product, I think, to serve two main purposes.

23
00:03:05,000 --> 00:03:10,010
One is, of course, to apply what you have learned in this course, what we have covered.

24
00:03:10,550 --> 00:03:21,470
And another is to share the experience of doing collaborative work and, you know, accumulate the skills of working with each other.

25
00:03:22,340 --> 00:03:31,820
That's another important sort of thing from your previous collaboration experience.

26
00:03:32,300 --> 00:03:44,480
So you may or may not find this enjoyable community, which is part of the training, part of the program in master history, master program especially.

27
00:03:44,960 --> 00:03:49,550
So as you got started, know a lot of different courses.

28
00:03:49,550 --> 00:03:55,730
You will see different programs, especially six, nine, nine, four or five major projects.

29
00:03:56,900 --> 00:04:04,340
Hopefully by then that means will reduce to the action of.

30
00:04:04,340 --> 00:04:07,130
Okay. And another thing is about the projects.

31
00:04:08,240 --> 00:04:14,510
I got a lot of questions about the program, for example, on diagnosis, on model selection, on how to build the model.

32
00:04:14,520 --> 00:04:25,630
And of the question I think are. So you guys had those questions, I think, before many of you had other questions,

33
00:04:26,050 --> 00:04:35,910
had those questions because you still think of the stereo analysis as a crack analysis or incrementalism or a yes or no.

34
00:04:35,920 --> 00:04:48,630
I guess, for example, when I was like, Oh brother, if you look at a residual plot, it's either, oh, there, there, there, there is no cousin there.

35
00:04:48,700 --> 00:04:53,290
While there is a mileage on that comes very low assumption and we have to address it or oh,

36
00:04:53,290 --> 00:04:57,790
there is absolutely no cause, no violation of that kind of assumption.

37
00:04:58,120 --> 00:05:01,460
So you are to it's not that a case, it's the analysis.

38
00:05:02,260 --> 00:05:10,360
This is something I try to I think I mentioned a few times, but probably not emphasized too much when it comes.

39
00:05:10,360 --> 00:05:13,840
Of course, when we talk about, of course, material, we try to be rigorous.

40
00:05:14,290 --> 00:05:19,630
And also in our DNA analysis, we need to be rigorous. We need to be to be very careful.

41
00:05:20,080 --> 00:05:31,210
But on the other hand, there are masses there is a certain level of the so, so, so therefore the results can be a little bit subjective.

42
00:05:31,360 --> 00:05:40,080
Okay. So because depending on, for example, if you do model, diagnostic model diagnostics by looking at a residual plot and some people might,

43
00:05:40,320 --> 00:05:46,420
might think, oh, that looks pretty good to me, I don't think there's a very clear validation of not comfortable.

44
00:05:46,450 --> 00:05:53,329
There is assumption where there is now the assumption for some other people by saying, oh, there there seems to be,

45
00:05:53,330 --> 00:05:59,350
you know, how it would help you can do what seems to be some deviations from the from the from the line.

46
00:06:02,080 --> 00:06:12,270
So that's is because of this. I mean, in the analysis, you will see when different people analyze the same data, they will end up with a super model.

47
00:06:12,430 --> 00:06:17,860
They're likely to go with different models. But it doesn't mean that one model is absolutely correct.

48
00:06:17,980 --> 00:06:19,810
The other model is just absolutely wrong.

49
00:06:20,440 --> 00:06:32,890
It's just that it just depends on what criteria work material used and whether you think that's that's she's a result of these, you know, good or not.

50
00:06:33,370 --> 00:06:37,090
So there is a certain level of some activity over there.

51
00:06:38,950 --> 00:06:42,700
So I try to measure that while I won't mention those,

52
00:06:42,700 --> 00:06:52,389
because no one has a question as if they are more like a unit where than you guys need to follow.

53
00:06:52,390 --> 00:06:56,710
And then there was no ability to make model. In the end that's not the case.

54
00:06:57,610 --> 00:07:06,970
So I think we have 22 groups in total and it wouldn't be surprising at all if each group among their own model in the end.

55
00:07:08,380 --> 00:07:15,220
So but I think the important thing is that if you apply different techniques we have learned and also the model,

56
00:07:15,760 --> 00:07:19,090
the seven year model to argue why your model is reasonable.

57
00:07:21,400 --> 00:07:28,870
So that's that's the most important thing because whatever model we build is going to be an approximation to the truth and we never know the truth.

58
00:07:29,350 --> 00:07:34,930
So, you know, when we talk about approximation to the truth, there are different approximations.

59
00:07:35,340 --> 00:07:39,670
And it's not necessarily there's one way to approximate the truth.

60
00:07:40,120 --> 00:07:44,980
So that's something you might want to keep in mind when you do models.

61
00:07:45,790 --> 00:07:48,430
There's no if you look at different papers, for example.

62
00:07:48,730 --> 00:07:57,820
And so that's that's also a reason why if you read the papers, you will see sometimes even contradictory conclusions.

63
00:07:57,820 --> 00:08:02,020
For example, some people some people claim, oh, drinking coffee is good for health.

64
00:08:02,560 --> 00:08:06,790
Some people in cycling might make the conclusion that life is not so good,

65
00:08:06,790 --> 00:08:14,200
is out that so but it really depends on some kind of on the sample sample you collect

66
00:08:15,010 --> 00:08:21,489
depends on how you allies better sometimes you may overconsuming you're not that different.

67
00:08:21,490 --> 00:08:24,610
People may draw conclusions in the end.

68
00:08:25,660 --> 00:08:33,240
But again, the most important thing is that we apply the techniques we learned rigorously and

69
00:08:33,340 --> 00:08:40,090
that we should be able to defend what we how we do in our model and defend our.

70
00:08:42,500 --> 00:08:46,399
Okay. So that's one thing.

71
00:08:46,400 --> 00:08:51,440
And today we're going to open this.

72
00:08:51,740 --> 00:08:55,549
So we're going to finish the last module and that is module selection,

73
00:08:55,550 --> 00:09:01,970
I believe many of you have already actually probably I know you've learned this in your previous

74
00:09:05,060 --> 00:09:11,299
in some previous courses or you have you have taken a look at the material from the textbook.

75
00:09:11,300 --> 00:09:18,080
But anyway, so I've already got questions about models to action using for memorization.

76
00:09:18,320 --> 00:09:22,820
But here, let's try to take a more systematic look at of this.

77
00:09:22,910 --> 00:09:34,110
People have means of selecting models. So bottom selection now we want to do is to distinguish truth.

78
00:09:34,160 --> 00:09:39,440
While the purpose there are two main scenarios for model selection.

79
00:09:39,440 --> 00:09:48,960
One is for inference and one is for relation models line for inference inference during cross translation and you know,

80
00:09:49,010 --> 00:09:58,370
make it well generally speaking, it's, it's, it's, it's made a conclusion about so many facts we are particularly interested in.

81
00:09:58,610 --> 00:10:06,140
So we want to, we formulate a model and the model involved parameter data and then we want to estimate a data and,

82
00:10:07,000 --> 00:10:12,380
and make a conclusion about beta, essentially to construct confidence intervals and doing all the testing about them.

83
00:10:12,800 --> 00:10:17,490
So this is what we mean by inference. So we formulate a model, right?

84
00:10:17,510 --> 00:10:28,490
So for example, the Y for inference, you will follow tomorrow night's debate on the plus plus.

85
00:10:28,850 --> 00:10:38,840
This is all in fact before entering sort of so formulate a model and the goal is based on your scientific knowledge and based on your interest.

86
00:10:40,250 --> 00:10:43,969
So what happens is you want to test, you follow this linear model, for example,

87
00:10:43,970 --> 00:10:50,840
and then your interest is to estimate a beta and then you want to assume the beta as accurate as possible.

88
00:10:50,900 --> 00:10:54,680
That's the goal of estimation, of inference.

89
00:10:55,880 --> 00:11:01,010
And in this sense then we would like to have unbiased upon estimation, point estimate.

90
00:11:01,100 --> 00:11:06,890
The reason it's all unbiased is evidence that means operation of beta hat is equal to beta.

91
00:11:07,280 --> 00:11:17,090
So this is based on the, the, the consideration that now when we analyze data, our analysis is based on this particular sample.

92
00:11:18,440 --> 00:11:25,550
So we've got a particular beta hat, but if you collect another sample, you'll get another different beta hat and you can't another sample.

93
00:11:25,610 --> 00:11:29,719
I mean beta had better and a lot of apple you'll get another beta how about it.

94
00:11:29,720 --> 00:11:37,760
So but it's 90% plus you clat you will get a different beta hat values but at least on average they use pan-Asian.

95
00:11:37,760 --> 00:11:46,040
On average a beta hat is equal to the true beta, but for any particular beta hat about itself is not equal to not true.

96
00:11:46,310 --> 00:11:49,160
So that's what we call by unbiased point out.

97
00:11:49,160 --> 00:11:57,920
So for for inference, for estimation of beta, usually we like to have some in business and also when we consider our accommodation,

98
00:11:57,920 --> 00:12:02,690
our will and could not have all the testing of we need standard error.

99
00:12:02,690 --> 00:12:07,910
So so we will have to have tool to estimate a beta as accurate as possible.

100
00:12:08,390 --> 00:12:11,870
So that's for users. Now model selection for prediction.

101
00:12:11,870 --> 00:12:15,709
This is slightly different. Look for prediction.

102
00:12:15,710 --> 00:12:20,150
You are the we do not care the estimate of a single beta anymore.

103
00:12:20,150 --> 00:12:28,910
So the the focus then is more on the fitted the model model in itself how well the model approximate the truth.

104
00:12:30,290 --> 00:12:34,570
So each single factor as mate doesn't matter too much.

105
00:12:34,580 --> 00:12:36,740
The beta had a can even be biased.

106
00:12:38,030 --> 00:12:47,990
So of course I mean the more accurate beta hat is generous they give a more accurate prediction is but one but when the main purpose is predictions,

107
00:12:48,500 --> 00:12:52,790
then you are that we do not care that much about each individual beta.

108
00:12:52,790 --> 00:13:02,480
So for example, if I could have a slight and biased beta, but if there is no variation at all in my data, it might be in a hat.

109
00:13:02,670 --> 00:13:07,760
So it is very precise but maybe slightly biased than this.

110
00:13:08,330 --> 00:13:11,780
Again, I could also have a very good prediction compared to the case.

111
00:13:12,050 --> 00:13:15,290
Although Beta has it, I'm biased but it has a huge bears.

112
00:13:15,590 --> 00:13:22,430
Then the prediction may not be good in the hedge. Okay, so that's the two two scenarios.

113
00:13:22,430 --> 00:13:34,220
And if she is too large, that means if you have two medical errors and you re you run into a risk of the so-called overfitting.

114
00:13:35,180 --> 00:13:37,700
Overfitting. So you have you have the raw data.

115
00:13:38,330 --> 00:13:45,950
And if you consider combining covariance, that means you build a very complex model as a linear regression model.

116
00:13:45,950 --> 00:13:52,040
You include 100 covariates, 100 X, I mean, as a model is quite a complex and maybe some interactions as well.

117
00:13:52,040 --> 00:13:55,819
So we have a complex model, we have a very complex model.

118
00:13:55,820 --> 00:14:02,450
You run the risk, you are under the risk of overfitting your data because your data does have noise,

119
00:14:02,720 --> 00:14:10,040
not errors in your data you observe is sigma is true saying is there is relevant missing or data so there is noise.

120
00:14:10,970 --> 00:14:17,510
So if you fit a very complex model, then you are starting to fit noise in order and event.

121
00:14:18,080 --> 00:14:26,260
If you apply the model, you build it to a different dataset. You are going to see really very bad performance because the noise in this part is.

122
00:14:26,350 --> 00:14:34,060
Their data may not be the same as in another dataset and even fitting noise in this particular dataset.

123
00:14:34,240 --> 00:14:40,330
And then the performance of the model in your feed, another dataset, it is going to be like it's going to be better.

124
00:14:40,960 --> 00:14:48,490
So we do not want the model to be over complex so we do not have one over overfitting.

125
00:14:54,960 --> 00:14:58,580
Yeah. So this is actually the same the same point.

126
00:14:58,640 --> 00:15:06,110
So suppose we have, you know, 30 covariates equal to 50 just 50 observations for a 30 covariates.

127
00:15:06,770 --> 00:15:12,170
In this case, you know, we could feed a model by through all the covariates in the model.

128
00:15:12,950 --> 00:15:17,420
And that's one way to fill the model that included all the components in this case.

129
00:15:17,990 --> 00:15:22,610
Well well, let's say let's let's here for for for simplicity.

130
00:15:22,610 --> 00:15:27,440
Let's just consider that the true model is indeed of the model that has over 30 covariates.

131
00:15:28,250 --> 00:15:33,020
So that if we throw all these into the models, so we get a true model again tomorrow.

132
00:15:33,590 --> 00:15:38,150
However, you only have 50 subject information from 50 subjects.

133
00:15:38,180 --> 00:15:42,790
Now you're trying to estimate the 32 or maybe 31 beta plus.

134
00:15:42,800 --> 00:15:47,840
The interesting result you estimate is 30 or 31 betas using this 50 data point.

135
00:15:48,890 --> 00:15:54,590
Well, mathematically, you may get a bias that has major excitation of beta had a still you would have beta.

136
00:15:54,590 --> 00:15:57,909
However, because your information,

137
00:15:57,910 --> 00:16:10,040
your data is that it is not large at all then your your as made beta hat is very inaccurate where the virus is very large.

138
00:16:10,670 --> 00:16:15,229
This the reason is well, if you think about so you have this particular of the individual.

139
00:16:15,230 --> 00:16:20,700
If you consolidate dataset with another individual, that means your go to if you say to the same,

140
00:16:20,700 --> 00:16:24,470
well, you're going to probably get a dramatically different theta hat.

141
00:16:24,980 --> 00:16:30,110
And if you clear another route outside of your another dramatically different beta hat.

142
00:16:31,550 --> 00:16:37,100
So, so, so although in this case we got a loss last meter, the bears may be very large.

143
00:16:38,180 --> 00:16:44,270
On the other hand, we could have a tomorrow using, for example, just the five strongest predictor.

144
00:16:44,750 --> 00:16:55,310
So let's say we if we find a predictor with that, with that, the smallest with the least P-value, we just include those five in this case.

145
00:16:55,670 --> 00:17:05,200
Now, because the true model has 30 ish queries, but here we only with five so established under the true models without.

146
00:17:05,900 --> 00:17:15,830
However, because we use information from the subjects we now, we only need this five beta 62 plus intercept.

147
00:17:16,970 --> 00:17:24,140
So we are able to estimate the beta pretty well or at least relatively well and is the better than in the first case.

148
00:17:24,680 --> 00:17:31,010
So then in this case, the beta has maybe biased because it's not a quadratic, it may be biased.

149
00:17:31,580 --> 00:17:36,980
However, we are able to get that maybe a much smaller difference in the end.

150
00:17:38,450 --> 00:17:49,910
So what we do, the model there is a balance like we need to consider these two fold of the normal complexity and also that sort of personality.

151
00:17:49,970 --> 00:17:56,870
So on one hand, we want the model to be compact enough so that it's a good approximation to the truth.

152
00:17:57,530 --> 00:18:04,580
On the other hand, we do not allow the model to be fallbacks so that we can only start a of noise

153
00:18:04,700 --> 00:18:09,960
of the data for which just simply do not have enough information in our data.

154
00:18:12,290 --> 00:18:20,660
And also the over contact model is very difficult to interpret will be the model is that there's always a balance between this.

155
00:18:21,290 --> 00:18:27,259
So this is you guys can probably imagine this is another reason why many of you will come up with a different model

156
00:18:27,260 --> 00:18:37,310
analyzing the same data because because matter is enough to include just five variable reliable actually six as I would.

157
00:18:41,170 --> 00:18:47,080
Yeah. But anyway, this is just a general principle, so the model needs to be complex enough.

158
00:18:47,860 --> 00:18:56,110
But on the other hand, it cannot be too complex. And then for model selection.

159
00:18:56,350 --> 00:19:03,640
Well, for for both prediction purposes and inference purposes usually involve the following major steps.

160
00:19:04,030 --> 00:19:14,670
And in this lecture, we're going to go over this major steps. So the first one is to specify is to specify a maximum or full model.

161
00:19:15,790 --> 00:19:22,030
So let's take a look at the first step. The first step is to specify a max model.

162
00:19:22,600 --> 00:19:31,089
This may or may not be necessary, but for linear regression we are considering in the case of a low dimensional case,

163
00:19:31,090 --> 00:19:36,430
in a sense that at the number we are, as we can see right here in this course, is not large.

164
00:19:36,430 --> 00:19:42,280
We do not consider a hypothetical case. So in this case it is possible to consider this maximum model.

165
00:19:43,270 --> 00:19:46,899
But maximal model is not in our dataset.

166
00:19:46,900 --> 00:19:55,960
Let's say you have 30 covariance of and then your maximum model would the model that includes was only covariance.

167
00:19:56,130 --> 00:19:59,950
And so you have a list of covariates, you observe that you have that dataset.

168
00:20:03,430 --> 00:20:06,549
And then the max model is actually that model.

169
00:20:06,550 --> 00:20:16,000
That includes models, of course. And I mean, this this concept of canon law is a little bit still a little bit vague because,

170
00:20:16,000 --> 00:20:19,450
well, whether then my next model should include all the interactions,

171
00:20:21,100 --> 00:20:27,040
but it does then like include to it rational through interactions, learning how to order polynomials.

172
00:20:27,040 --> 00:20:30,909
Right. So, so all of these questions. But we do not need to worry.

173
00:20:30,910 --> 00:20:38,770
Let's not worry about that. Let's just just just think of the thing about this conceptually.

174
00:20:38,770 --> 00:20:43,809
So you have a bunch of covariance and then you have sort of the maximum model

175
00:20:43,810 --> 00:20:48,010
that you can build that that is the model that includes all these elements.

176
00:20:48,310 --> 00:20:57,520
And of that, what we want to look at smaller models and compare to that to the maximum model and select the baseline.

177
00:20:59,410 --> 00:21:11,230
So, so first we need to be clear what are the variables are and that that leads to that so-called maximum model and that we need to inspect the data.

178
00:21:12,700 --> 00:21:21,580
This is a very important stab. I hope you guys have done this in the first project that is to establish the covariance.

179
00:21:21,610 --> 00:21:26,260
While there are certain things we need to pay attention to. Look over here, this must be scored on a meaningful scale.

180
00:21:26,560 --> 00:21:30,010
So for example, hey, if you if you see age, you know,

181
00:21:30,010 --> 00:21:42,819
equal to all because there is a not narrative out of rage that's definitely not within the normal range or if you see a H like two hundreds something,

182
00:21:42,820 --> 00:21:50,590
right? So hopefully someday in the future, people live longer than that as well as that.

183
00:21:50,590 --> 00:21:57,590
But, but, but, I mean 200 now it does seem to be a not within a normal meaningful range.

184
00:21:57,590 --> 00:22:01,720
Right. So so as well such values we need to pay attention to.

185
00:22:02,020 --> 00:22:06,819
And also the collaboration would have sufficient variability.

186
00:22:06,820 --> 00:22:11,170
By that I mean, for example, if you look at the page as a covariant,

187
00:22:11,320 --> 00:22:26,059
if it's the sub most of your dataset only of course updates with age 45 let's say then these and then then basically age is not a very good predictor.

188
00:22:26,060 --> 00:22:33,160
It will be included in the model because because there is no variation in age and

189
00:22:33,160 --> 00:22:37,639
also the covariance should be there should be high correlation among covariance.

190
00:22:37,640 --> 00:22:43,719
So this can be checked by looking at the F, right?

191
00:22:43,720 --> 00:22:50,380
And also the correlation to the symbol and correlation matrix probability correlation among those covariates.

192
00:22:51,850 --> 00:23:00,790
And another consideration is the size of the model. So with what we think, think about how many covariates we should include in the model.

193
00:23:01,000 --> 00:23:13,360
So there is a general guideline that is that the number of we should have at least five subjects for each parameter estimate.

194
00:23:13,780 --> 00:23:17,920
So for example, if you're if you only have 50 subjects in total,

195
00:23:18,340 --> 00:23:25,540
in some cases equal to 50, then you probably animals in 1 to 10 players in some people,

196
00:23:25,960 --> 00:23:31,790
some other people might actually use in a larger event where you could have something as part or parameter this,

197
00:23:31,790 --> 00:23:38,680
that or this also depends on what model you said for a simple linear regression model for linear level model is relatively easy to.

198
00:23:39,500 --> 00:23:47,480
But from the generalized model, other models may be more complex or are slightly more samples for each passenger.

199
00:23:49,010 --> 00:23:57,830
But what I hear is that if you need a while, so you do need to control the total number of RAM during the model.

200
00:24:00,230 --> 00:24:04,730
Also, another thing is that while to specify the model is not pure,

201
00:24:04,730 --> 00:24:16,670
this logistical consideration overcomes in maybe all hands that we need to work with people from somebody, the area and hear their insights.

202
00:24:16,820 --> 00:24:20,230
What model makes sense? Because this is a slightly bigger problem.

203
00:24:20,300 --> 00:24:25,520
It's not only a statistical problem. And so that's not, you know, the first step.

204
00:24:26,060 --> 00:24:33,530
So the second step is to specify a criteria for comparing different models.

205
00:24:33,590 --> 00:24:37,010
So our goal is to select a model that we think is very reasonable.

206
00:24:37,010 --> 00:24:48,410
So we need to compare different models and how, how well the here, you know, we want to see our what is the how well the model fits the current data.

207
00:24:48,800 --> 00:24:52,790
So we have a current data like for example, in your course prototype you have a beta.

208
00:24:52,790 --> 00:24:59,050
So that's what we mean by car data. And oftentimes we call this the training data as well.

209
00:24:59,060 --> 00:25:10,560
So we want to see how well the model fits the the current data, we're training them and we can also see how well the model predicts future responses.

210
00:25:10,570 --> 00:25:16,490
So if you click on new data that if you have some new data, how well the model you build,

211
00:25:16,490 --> 00:25:21,260
new car to build, how well the model can predict the results for the new datasets.

212
00:25:22,250 --> 00:25:27,510
So that's the second step of. Yeah.

213
00:25:27,520 --> 00:25:36,840
So but we will skip the sign a step for now because we are going to spend lots of time later in this lecture.

214
00:25:36,850 --> 00:25:44,650
Let's first finish the other a third start and then we will come back to stab to it because that's the limits that we want to focus on.

215
00:25:44,860 --> 00:25:48,190
But now first, let's look at the the third. Yeah.

216
00:25:48,250 --> 00:25:55,570
The third step then is well, after we after we specify the criterion.

217
00:25:56,260 --> 00:26:04,660
After we specify criterion, and then we compare different models under this criterion, under this lack of criterion.

218
00:26:05,170 --> 00:26:10,180
And then we call that we select the best one, the best one. I'll open here and define it by two.

219
00:26:11,440 --> 00:26:15,750
And here the selection can be carried out by well,

220
00:26:16,270 --> 00:26:22,930
one is the so called all possible subsets regression epr, the other one is the forward backward hybrid.

221
00:26:23,620 --> 00:26:26,920
So now let's take a look at this one by one.

222
00:26:28,120 --> 00:26:37,000
So suppose now that we have already defined appropriate criterion for psychomotor, so later we'll come back for that to look at different.

223
00:26:37,840 --> 00:26:46,059
Now let's say that we already have a fact here and for example P P-value. Right, and oh yeah indeed here.

224
00:26:46,060 --> 00:26:49,990
I mean, let's let's say we take the P value as the as a criterion.

225
00:26:50,740 --> 00:26:59,020
And so one way to select the model is the so-called oh possible subset of regression.

226
00:27:00,280 --> 00:27:12,879
Oh, this is I mean, this is an option, but a usually it's a very difficult to to implement, especially if I have a large number of covariates.

227
00:27:12,880 --> 00:27:17,680
So, so here we do not worry about this for large this.

228
00:27:17,680 --> 00:27:24,430
What this means is that if you have ten covariates, then I would consider any combination of these ten covariates.

229
00:27:25,240 --> 00:27:32,740
I could choose one any, any one from this tent. I could choose any to the extent I could choose any three of the ten and so forth.

230
00:27:33,040 --> 00:27:36,580
And then for each choice I have a model, right?

231
00:27:36,640 --> 00:27:40,090
I can go to the corresponding comparison, have a model, then I,

232
00:27:40,090 --> 00:27:48,610
then I have an exhaustive list of all possible models that I will just look at them one by one and then compare them based on the criterion,

233
00:27:48,610 --> 00:27:56,559
which is why it's up to and then take the last one. So that is mathematically that, that is this has to be to be good.

234
00:27:56,560 --> 00:27:58,090
But in reality, there's,

235
00:27:58,090 --> 00:28:07,540
there's fewer and there is no way that we can do that because the total number of models do go off very quickly with a number of queries.

236
00:28:08,590 --> 00:28:15,520
So this is not typically a you are this is not a feasible option you or this is not a lot of people.

237
00:28:19,270 --> 00:28:24,010
So of course in practice then we will have to have some more automated selection.

238
00:28:26,170 --> 00:28:32,470
So there are three types of selection commonly used.

239
00:28:32,500 --> 00:28:36,390
One is first that I realize that word elimination and that established.

240
00:28:38,330 --> 00:28:45,020
So the affirmative selection, the first selection starts with the no model and add a covariance of one another.

241
00:28:45,290 --> 00:28:49,130
So we can take a look at this for selection in more detail.

242
00:28:50,870 --> 00:28:58,399
So for forward a selection, we first need to specify the threshold p value because now we're looking at it.

243
00:28:58,400 --> 00:29:08,270
So if you got a threshold for inclusion, this means that only the coverage that has p value, that's the bottom five that we will include in the model.

244
00:29:08,900 --> 00:29:14,660
So only less than 45, we consider this. In fact, it's quite a significant one.

245
00:29:14,960 --> 00:29:22,620
So we first we need to specify this of the inclusion p value, the threshold for if you had, if you were able to be quantified.

246
00:29:25,070 --> 00:29:29,750
And then we will begin with a no model. That means there is no comparison at all.

247
00:29:29,750 --> 00:29:33,590
We just have the intercept and a starting from there.

248
00:29:33,620 --> 00:29:37,939
Now I have only have intercept. Then I will include the covariance.

249
00:29:37,940 --> 00:29:41,030
Let's say I have ten covariance. I include the columns one by one.

250
00:29:41,390 --> 00:29:49,310
I'll first build a model with the first coverage and then I'll build a model with only the second coverage and then with only the third coverage.

251
00:29:49,310 --> 00:29:55,550
So that in the and I'll have ten models each one with one of those ten progress at it.

252
00:29:56,000 --> 00:30:00,560
And then I will look at this ten models and then the corresponding p value for

253
00:30:00,740 --> 00:30:04,880
for each covariate in the model and I will see which p values the smallest.

254
00:30:05,780 --> 00:30:12,110
Smallest is the most significant. I'll look at which one is modest and whether that's smaller than 25.

255
00:30:12,650 --> 00:30:17,880
Then if it is smaller than 45, then I will now add that into the models,

256
00:30:18,290 --> 00:30:25,760
which means that a now let's say x five has the smallest p value, then an x five into my model.

257
00:30:26,090 --> 00:30:39,770
So then my car, the model is a model has intercept an x five and x five and then starting from there I will look out of the rest of the comparison.

258
00:30:39,770 --> 00:30:45,380
Then I will add further x one into the model of the model that has x1 added.

259
00:30:45,980 --> 00:30:51,500
And then I will build a model that has X added extra little added into the model that

260
00:30:51,500 --> 00:30:58,220
has x five already and then I will add three and then build up in this case my models.

261
00:30:58,580 --> 00:31:00,739
And then for all those nine models,

262
00:31:00,740 --> 00:31:11,120
I will look at the p value for each of the new covariates added into the model and then I will pick the one that has smaller p value.

263
00:31:11,690 --> 00:31:19,340
And if the p value is still smaller than five out of that into the model and I will proceed in this way.

264
00:31:20,000 --> 00:31:28,850
Right. So in tuned into either I include all the covariates or all the p values are larger than five.

265
00:31:28,850 --> 00:31:32,240
So I stop. I will not include anymore. Yes.

266
00:31:32,990 --> 00:31:41,630
If if my research question is specifically about say like x one,

267
00:31:42,770 --> 00:31:47,780
does it make sense to automatically include that from the start and then go from there?

268
00:31:47,780 --> 00:31:55,579
Yeah, definitely. So if you're interested in is in a while, there is a particular X one that A you're definitely interested in,

269
00:31:55,580 --> 00:31:57,850
then you should always keep in the model there.

270
00:31:57,950 --> 00:32:04,310
I think a SAS or R should have such an option that allows you to keep certain variables always in the model.

271
00:32:08,770 --> 00:32:14,980
Yeah. So this is basically what a forward selection procedure is.

272
00:32:15,700 --> 00:32:21,040
So the procedure terminates when no more covariates meet this criteria.

273
00:32:21,460 --> 00:32:26,080
Or I mean what? All covariates have been added into the model.

274
00:32:26,860 --> 00:32:34,560
So now this procedure starts again. See a source from the no model that has no coverage that eventually expands the law.

275
00:32:36,070 --> 00:32:39,340
In this process, it would never remove a of it.

276
00:32:39,520 --> 00:32:43,330
So one of the collaborators added into the model. It always stayed in the model.

277
00:32:44,260 --> 00:32:46,660
It will stay there forever until we reach the very end.

278
00:32:50,550 --> 00:32:56,250
So of course, in the process, I think many of you probably have made such an observation sometimes.

279
00:32:57,410 --> 00:33:03,140
You look at this particular step, you see this whole matter is highly significant added into the law.

280
00:33:03,150 --> 00:33:10,110
But then we moved from that step. After adding a new variable, now the previous lot becomes insignificant.

281
00:33:10,290 --> 00:33:15,510
That's that can happen that that's totally possible and that can definitely happen.

282
00:33:16,470 --> 00:33:21,600
But the further forward said, it doesn't really look at that anymore.

283
00:33:21,600 --> 00:33:28,290
So that covariance was it's added into the model in a space in every movement.

284
00:33:28,500 --> 00:33:34,830
So that's what the forward selection procedure is now, the backward elimination.

285
00:33:35,940 --> 00:33:48,050
This work in the opposite way. So here again, we need to specify a view that over X for for for exclusion.

286
00:33:48,870 --> 00:33:55,320
And then while this procedure began with a maximum model, that means you throw all the covariance into the model, right?

287
00:33:55,620 --> 00:34:05,310
Of course. I mean, this becomes a little bit. There's still a certain level of it's still a vague.

288
00:34:06,190 --> 00:34:12,300
And for example, when we talk about maximum order of model, do we just throw the all the main facts where we throw all the modeling,

289
00:34:12,590 --> 00:34:18,150
the interaction says, well, where do we throw the sum of the terms as well?

290
00:34:18,360 --> 00:34:26,189
Or we're throwing rational as well. So, so but typically if you have a hard number of covariates,

291
00:34:26,190 --> 00:34:30,930
we would just try to store the main facts without worrying too much about the interaction first.

292
00:34:31,800 --> 00:34:37,710
And then once we come up with the model that has all the main facts, then we can start to think about the interactions.

293
00:34:38,400 --> 00:34:42,120
So here, let's just consider the case where we throw all the million facts into the model.

294
00:34:42,150 --> 00:34:51,390
So this is the maximum model. And starting from there, we actually build we remove one coverage at a time.

295
00:34:52,320 --> 00:34:57,479
So then we remove the first covariate. We have a model that we remove the second covariate.

296
00:34:57,480 --> 00:35:03,630
We have a model. Then we remove the third, third one by one result of just one at a one variable.

297
00:35:04,120 --> 00:35:08,460
At that point, I want. So, so then we have this different models.

298
00:35:08,580 --> 00:35:13,200
Each one has one couple that are less than the of the next model.

299
00:35:13,590 --> 00:35:19,770
Then we look at these models and under our criterion, which one is the best.

300
00:35:20,190 --> 00:35:27,390
So in this case which covariate removed corresponds to the largest p value and whether that p value is larger than 25.

301
00:35:27,990 --> 00:35:35,970
And if it is so we find the largest p value and it is longer than five that we remove that from the law.

302
00:35:36,600 --> 00:35:46,200
So then our model now has P minus one covariates because we are going to remove the one and then we will do the same thing and remove the next.

303
00:35:46,890 --> 00:35:57,670
And then we will keep doing in to either, you know, there's no covariate left that can be removed or you remove all the coverage.

304
00:35:59,940 --> 00:36:03,060
So this is how the backward elimination works.

305
00:36:03,390 --> 00:36:08,760
It just works the opposite way to for a action.

306
00:36:09,420 --> 00:36:19,740
So the backward elimination, then you can imagine that after a covariate is removed, it can never it never comes back to the model.

307
00:36:20,430 --> 00:36:24,600
So this is a feature that we're at elimination.

308
00:36:26,040 --> 00:36:35,240
And then in practice what works better might be the so called stepwise regression.

309
00:36:35,250 --> 00:36:42,030
This is sort of a combination of both. So in this case, we were the first of these by the inclusion criteria,

310
00:36:42,030 --> 00:36:50,520
inclusion probability p value cut of review out of the exclusion order for the cutoff for P value.

311
00:36:51,180 --> 00:36:53,219
And then we will begin with the no model.

312
00:36:53,220 --> 00:37:03,060
We still begin with the smallest model number and then we proceed as in the forward a selection or you start.

313
00:37:03,060 --> 00:37:07,590
Now we add the most restrictive on a covariate as long as the p value.

314
00:37:07,590 --> 00:37:13,670
While we find the smallest p value, even the value is less than the cutoff that we will carry.

315
00:37:15,840 --> 00:37:21,060
And then on the other hand, in the meanwhile, we will find the largest p value.

316
00:37:21,630 --> 00:37:31,050
And if the largest p value is larger than this cutoff t oh, then we will remove of the least significant contact.

317
00:37:31,140 --> 00:37:37,710
So this procedure allows us to simultaneously act and to remove covariance.

318
00:37:40,260 --> 00:37:44,220
And then the procedure terminates with no more covariance anywhere.

319
00:37:44,400 --> 00:37:50,410
It. Um.

320
00:37:53,690 --> 00:37:56,780
Yeah. This, this, this. This is what?

321
00:37:57,320 --> 00:38:07,610
These are the three, like, modest in action procedure that we could take further action and establish action,

322
00:38:08,090 --> 00:38:14,090
and we just start talking about how they work. Of course, when you run, are we're going to recess?

323
00:38:14,600 --> 00:38:17,629
We are. We do not need to implement this ourself.

324
00:38:17,630 --> 00:38:26,690
I mean, these three procedure, they are well implemented by, by ah and by SAS and by any other good in somewhere.

325
00:38:26,900 --> 00:38:30,110
So we just need to ask SAS or ah to do this for us.

326
00:38:32,890 --> 00:38:34,570
So that's that's three.

327
00:38:37,420 --> 00:38:49,150
Procedure now for the selection, for the cut off, I mean, for the execution cut outs from p o, this is the p value cut out for p value.

328
00:38:50,760 --> 00:38:56,470
Usually people use different cut out.

329
00:38:56,530 --> 00:39:00,760
So some people might use it on a ten a some people might use 1 to 5.

330
00:39:02,590 --> 00:39:10,540
And again, I mean, if you set a different a different cutoff, then you will get different variables in your model.

331
00:39:10,900 --> 00:39:15,580
So this is out of out.

332
00:39:16,420 --> 00:39:19,989
And also, people want to set this larger than the execution,

333
00:39:19,990 --> 00:39:26,800
the cutoff for execution when the P value is larger than the color of the is larger than that allowed for the inclusion if you are.

334
00:39:27,280 --> 00:39:33,070
Well, the reason is that, though, by setting this to be small, the pie to be small,

335
00:39:33,080 --> 00:39:40,870
that means only the variables that have p value less than five or very small p value that I mean, could that mean the model?

336
00:39:41,080 --> 00:39:47,620
So in other words, we only well, we, we only include the variable that we know is highly significant.

337
00:39:49,630 --> 00:39:55,840
And we saw out of this P oh to be relatively large because based on the consideration

338
00:39:55,840 --> 00:40:02,440
that we remove a variable only we think it's highly insignificant as a one.

339
00:40:02,440 --> 00:40:07,180
The P value is very large. We remove only in that case we removed that.

340
00:40:07,720 --> 00:40:16,270
So we do not allow to very easily of error. So we remove it only if we truly believe it is insignificant.

341
00:40:16,510 --> 00:40:23,590
So this is the rationale behind setting the cutoff for these two values.

342
00:40:32,520 --> 00:40:37,659
Okay. So that's. That's not.

343
00:40:37,660 --> 00:40:41,350
And then let's take a look at, you know, these procedures.

344
00:40:41,890 --> 00:40:44,980
They do have some drawbacks, some limitations.

345
00:40:45,010 --> 00:40:53,170
Now, let's take a look at these. One is that these procedures, there's no way.

346
00:40:53,510 --> 00:40:56,970
There's no guarantee that they will find the optimal model.

347
00:40:57,580 --> 00:41:00,800
So that's one thing I try to emphasize there.

348
00:41:00,990 --> 00:41:10,870
There's no guarantee at all. So if you apply, for example, if you if two of you apply the first selection of five different callable,

349
00:41:11,110 --> 00:41:17,470
if one of you use a one as the cost of another one, you know, five, that cut off you will end up with different models.

350
00:41:17,950 --> 00:41:21,220
It's not to say that one is correct, one is wrong.

351
00:41:21,430 --> 00:41:25,630
It's just you use different cut off two or three coverage.

352
00:41:26,200 --> 00:41:32,590
So it's it's totally plausible. You know, sometimes it's it's almost inevitable that you will not be more model.

353
00:41:33,370 --> 00:41:37,780
So, for example, if you only include two covariates, you might end up with none.

354
00:41:38,140 --> 00:41:46,510
Oh, sorry. So that means. Well, if you in the first step, if you do a step by step action in the first step,

355
00:41:46,510 --> 00:41:51,670
you might end up with x one alone in the model for the way to do another step.

356
00:41:52,060 --> 00:41:55,480
You might have model x two and three.

357
00:41:55,660 --> 00:42:04,719
So, so all of these are plausible. And also, I think many of you have already observed this in, of course, throw it out.

358
00:42:04,720 --> 00:42:08,560
So some covariates there are only significant in the presence of others.

359
00:42:09,140 --> 00:42:15,470
So if you do not include if you didn't include other communities, then this comparison isn't right.

360
00:42:16,150 --> 00:42:18,190
So that's also possible.

361
00:42:21,790 --> 00:42:30,200
So at the beginning, you might sort of see all these things, but these are all written results of, you know, the procedure themselves.

362
00:42:30,220 --> 00:42:36,340
It's not that we have mathematical error behind the theory, it's just that that's how the procedure works.

363
00:42:38,020 --> 00:42:40,100
And also one piece very large.

364
00:42:41,260 --> 00:42:49,900
The procedure breaks down by better lot would be, especially when you have more number crunchers, that number of subjects in a cross-section.

365
00:42:51,190 --> 00:42:56,020
So, for example, if you start with an end, you can we cannot do a backwards elimination.

366
00:42:57,280 --> 00:43:01,990
And also, when there is money flow guaranteed, then we might run into trouble.

367
00:43:02,860 --> 00:43:08,040
And also if tests are now problematic for these procedures.

368
00:43:08,050 --> 00:43:19,800
So for this procedure, as you already. Even if you read a paper, some people might still carry out a task or key task or things like that.

369
00:43:19,810 --> 00:43:27,780
After selection, however, those procedures are problematic because people still feel that.

370
00:43:27,790 --> 00:43:33,670
I mean, some people still do that. So but if you're a little person now that this task will become problematic for these folks.

371
00:43:33,910 --> 00:43:39,250
The reason is that not if we far worse like affirmative action, but our past.

372
00:43:40,930 --> 00:43:48,400
If you recall from the first letter star from the simplest models and then start to the model starts to grow and become more complex.

373
00:43:49,060 --> 00:43:57,879
But in the early stage, if you compare a similar set up, like a similar model versus a similar model, you have a reason of the complex model.

374
00:43:57,880 --> 00:44:01,780
Yet if you just complex, compare it literally to simple model.

375
00:44:02,530 --> 00:44:11,200
And then if you carried out our test, recall that APT has involved the Coalition Sigma Square CMOs were hacked, the CMOS word had as measured.

376
00:44:11,530 --> 00:44:17,110
So because of the simple model are likely to be cracked a simple but are likely to be incorrect.

377
00:44:17,650 --> 00:44:21,610
In that case you your a square is incorrect. As a matter of the true.

378
00:44:22,000 --> 00:44:28,600
I don't see much square because of a C much. We are estimated by more complex model that it's closer to the truth.

379
00:44:29,950 --> 00:44:39,670
So in this case we are using an incorrect, seamless square hat that actually makes the av-test conservative on evaluating nano risk.

380
00:44:41,080 --> 00:44:46,090
And also when you compare this different models, you are making multiple comparisons,

381
00:44:46,090 --> 00:44:51,069
you're considering different models, a bunch of different models, and you're comparing them one by one.

382
00:44:51,070 --> 00:44:58,720
And then that means you're making multiple comparisons and in this one, making multiple comparisons, easily trying to well,

383
00:44:58,900 --> 00:45:07,240
essentially what it means is that we are asking the data to match so that it just has this amount of information.

384
00:45:07,240 --> 00:45:11,740
But A, you are actually asking to what you are asking the data to compare so many different models.

385
00:45:12,100 --> 00:45:17,620
And in the end we may get a small pick out just by just by chance.

386
00:45:19,840 --> 00:45:25,479
So if you if you control the data like too much, so eventually it will confess.

387
00:45:25,480 --> 00:45:28,750
I mean, it will just give you whatever resulting your accuracy.

388
00:45:28,750 --> 00:45:39,040
So this investment multiple comparisons, the drawback and also the even if you come up with the final model,

389
00:45:39,040 --> 00:45:48,879
you end up and let's say in the end through this procedure and with a model and with five covariates and this is your final model even for this final,

390
00:45:48,880 --> 00:45:52,150
final model carrying out have test is problematic.

391
00:45:52,540 --> 00:46:00,980
The reason is that our test is under the assumption that we do not estimate the number parameters number comparison available.

392
00:46:01,070 --> 00:46:05,080
We just estimate. So if you tell me the true model has five betas,

393
00:46:05,350 --> 00:46:11,260
have this five betas that how we use my data to just ask me the five data, then I can carry out our test.

394
00:46:11,980 --> 00:46:19,059
But now what we are doing is that we are using our data to estimate the number of queries as well.

395
00:46:19,060 --> 00:46:25,750
We don't know how many covariates should be included and we just go through this for a standard procedure of the procedure tells us,

396
00:46:25,750 --> 00:46:30,430
oh, you should including this five years and then it is this five.

397
00:46:30,430 --> 00:46:36,370
It's also estimating from the data and in this case, the our test is not under a value passed.

398
00:46:37,720 --> 00:46:41,980
So that's another problem. The problems are in the literature.

399
00:46:42,100 --> 00:46:46,120
I think if you refer many people,

400
00:46:46,720 --> 00:46:54,040
you will see that people some people are still carrying out our test even after a forward resolution with the final model.

401
00:46:56,380 --> 00:47:00,370
Mathematically, that's not a crash, but many people still do it.

402
00:47:03,310 --> 00:47:09,760
So that's. Yeah. This procedure have already been implemented in SAS and air.

403
00:47:13,510 --> 00:47:21,130
Okay. So that's. Now, let's take a look at it like a very quick example.

404
00:47:23,930 --> 00:47:27,300
We've yet to give a flavor because, I mean,

405
00:47:27,530 --> 00:47:33,920
it involves some criteria that we need to observe and we talk about those the selection criteria when you come back for this example.

406
00:47:34,490 --> 00:47:38,090
So this is an example here we have a few questions about age.

407
00:47:38,090 --> 00:47:50,149
We have weight, we have time to run one mile and resting pulse, maximum pulse in the palace and a lot of oxygen uptake.

408
00:47:50,150 --> 00:48:00,230
I think this is the response. But anyway, so it's wise to model the oxygen uptake by using the other covariates.

409
00:48:00,560 --> 00:48:07,879
So we have a few covariates now for this example, once you have this data set, as we mentioned,

410
00:48:07,880 --> 00:48:11,690
the first the first thing you might want to do is while the maximum model here we

411
00:48:11,690 --> 00:48:16,910
consider let's just consider the model that has all these three effects of all of that.

412
00:48:17,270 --> 00:48:25,370
Let's not worry about what actually cause the next model is model for the fact that last thing we want

413
00:48:25,840 --> 00:48:34,459
to look at is the whether there is molecule inheritance so that if we calculate the F and we see that,

414
00:48:34,460 --> 00:48:45,590
okay, so these are the results and there are some really large ones like aged eight or nine around age eight or nine.

415
00:48:46,610 --> 00:48:52,489
But if we use the value of longer than ten as the cutoff, then, then there it seems to be okay.

416
00:48:52,490 --> 00:48:58,520
Right. So, so I guess it's okay if we just leave it like that and don't worry too much about it.

417
00:48:59,210 --> 00:49:06,290
But some people might want to go further and investigate this a little bit and see whether what they mean,

418
00:49:06,920 --> 00:49:10,550
because indeed, you can see that at both ends of the matter, the pulse.

419
00:49:11,630 --> 00:49:15,350
But it's just probably at a different, different time point.

420
00:49:15,590 --> 00:49:19,070
So these these two are likely highly correlated.

421
00:49:19,430 --> 00:49:27,560
So your model then you could think about removing one of these rather than including both in the model.

422
00:49:28,100 --> 00:49:37,370
But based on these two, we all have values. Now if we use ten as the cutoff that this this two numbers are not a particularly alarming so.

423
00:49:41,460 --> 00:49:44,830
So I mean here I mean, I think many of you also ask the question.

424
00:49:44,830 --> 00:49:55,830
So once you see this, then you you could just leave it like that or you could emasculate further and decide to remove one and just use one.

425
00:49:55,870 --> 00:50:02,100
You both are okay. I don't think there is an absolute way of doing that.

426
00:50:03,120 --> 00:50:07,029
So. Yeah.

427
00:50:07,030 --> 00:50:16,150
So that's that. And then if we consider forward the first lecture, if we use the inclusion probability for the quad one,

428
00:50:16,510 --> 00:50:25,870
then this is the model like at the moment, a few of the procedure models produced by the procedure, so as the first step.

429
00:50:27,800 --> 00:50:37,750
If there was an actual real edge this variable into the model and this one has the least P-value and the P value is less than one one.

430
00:50:37,760 --> 00:50:45,790
So it has this there in the model and then at the second step the procedure and edge of the model.

431
00:50:45,800 --> 00:50:51,710
And then the third step to ask this and then it asked us, then it stopped.

432
00:50:52,040 --> 00:50:58,550
So which means that the first action gives us a model that has these for covariance.

433
00:50:59,450 --> 00:51:09,590
These are covariance. And then if you look at the different criteria here, well, these are different criteria to pick the model.

434
00:51:10,070 --> 00:51:15,560
We have to talk about these. Yeah, some of these we have seen some of them we haven't, which we will talk about.

435
00:51:16,070 --> 00:51:20,870
So for example, for hours we are going to see that our square is actually increasing.

436
00:51:21,170 --> 00:51:26,930
Right? So as we add a more and more variable, this is disagreeing with our step step our sending R squared.

437
00:51:27,320 --> 00:51:34,010
The more covariance we have, we can see that a number is increasing the adjusted R square.

438
00:51:34,220 --> 00:51:36,950
Also, if we use adjusted our square as the criterion,

439
00:51:37,340 --> 00:51:47,930
we can see that a number also while the last one slightly oh sorry for the loss but also because we can see that adjusted R squared also increases.

440
00:51:49,460 --> 00:51:56,870
So these are all indication that, you know, having this four variables is probably good.

441
00:51:57,800 --> 00:52:02,090
And we will talk about the outlook of criterion in a few minutes.

442
00:52:04,150 --> 00:52:12,890
So that's far reaction. Now, if we just include what if we use this or level five as the cutoff for inclusion value,

443
00:52:13,740 --> 00:52:19,570
then it turns out that the procedure for selection will only include this single variable.

444
00:52:20,260 --> 00:52:23,320
So your model, your final model will only have the single variable.

445
00:52:27,730 --> 00:52:37,210
Again, if you compare this to there's no well, this is not to say that, you know, one of these well, these is absolute crap.

446
00:52:37,420 --> 00:52:46,360
The other one is absolutely wrong. It's just that if you use different copies, content has the cutoff for you use for the five as the cutoff,

447
00:52:46,720 --> 00:52:54,700
and then you will end up with different models. But of course, in practice people most people I guess would use what, level five as the cutoff.

448
00:52:54,850 --> 00:53:03,489
This is asking to make sure that the model include sort of the variable.

449
00:53:03,490 --> 00:53:07,360
We could indeed they are they are highly significant.

450
00:53:09,740 --> 00:53:15,290
But if you but if for some reason you were staying for the fall one, is that a more reasonable cutoff?

451
00:53:15,530 --> 00:53:20,150
You can happen to use it, then you will just end up with a different model of coverage.

452
00:53:23,290 --> 00:53:28,360
And then we have the let's let's finish the this few slides.

453
00:53:31,550 --> 00:53:38,180
And that if we apply a bad word, elimination now with this cut off, that we will adopt this model.

454
00:53:38,210 --> 00:53:43,460
So the first step, remove this variable and assign segments that reduce this variable.

455
00:53:43,460 --> 00:53:49,700
So in total, there will be two variables removed from the numbers from the model.

456
00:53:49,700 --> 00:53:52,849
And then in total I think we have six covariates.

457
00:53:52,850 --> 00:53:58,310
So after removing this tool, we still have six, so we still have four colors.

458
00:53:59,390 --> 00:54:05,180
And of course you can consider using a different cutoff on the five instead of one one.

459
00:54:05,180 --> 00:54:08,569
Then you will just remove one variable from the formula.

460
00:54:08,570 --> 00:54:12,740
So your final model will have five covariates.

461
00:54:16,550 --> 00:54:22,550
Okay. So I think that let's take a five minute break and then we will be have.

462
00:54:30,670 --> 00:54:31,930
Okay, so, for example,

463
00:54:31,930 --> 00:54:44,170
we just went over and that's I guess this is sort of give give you guys a of how the the for member selection how this procedure run.

464
00:54:45,040 --> 00:54:51,340
And also one thing one point I like late again is that I use a different cutoff.

465
00:54:51,640 --> 00:54:55,720
You will have different models in the end, which is totally fine.

466
00:54:57,300 --> 00:55:11,530
And then there's another consideration that is categorizing h i so my is convenience or is common a very common practice

467
00:55:11,680 --> 00:55:18,550
to categorize age when doing good analysis that this is not only true for age but for for many other variables as well.

468
00:55:18,550 --> 00:55:26,070
For example, for income, if you only include comprehensive covariate, that you could include income as a,

469
00:55:26,370 --> 00:55:33,760
as a, as a, as a continuous variable if your variable clerk is in view of the actual income.

470
00:55:34,270 --> 00:55:39,720
But you could also break it down into a few categories like no middle income in high income, right?

471
00:55:39,740 --> 00:55:44,530
So, so, so categorizing a continuous variable.

472
00:55:44,530 --> 00:55:46,750
This is a commonly used technique.

473
00:55:47,860 --> 00:55:57,010
And by doing that here, let's say we categorize age into two different categories and between 3748, not between 40 and 58.

474
00:55:57,520 --> 00:56:02,920
Right. So then they become binary. Is that of having continuous h h become binary.

475
00:56:03,550 --> 00:56:10,270
Now if you include well not if you consider this age fine range as a category is

476
00:56:10,300 --> 00:56:16,360
that of that original cadenas age that if you run the model for working hours,

477
00:56:17,110 --> 00:56:23,560
then you will hear that this is affirmative action and of that you will run,

478
00:56:23,640 --> 00:56:32,830
you will have a modal in the end and then you will see that this our squares might be excluded as compared R-squared numbers compare them.

479
00:56:33,490 --> 00:56:36,510
They are very likely different. Yes, they are easy.

480
00:56:36,730 --> 00:56:40,120
For example, here is for a four or five.

481
00:56:42,270 --> 00:56:49,200
And here is the .8515.

482
00:56:49,440 --> 00:56:56,070
So the other words, by and by breaking into different categories, including a categorical age,

483
00:56:57,240 --> 00:57:02,980
you either end up with the same model, but in the model, theater becomes different.

484
00:57:03,180 --> 00:57:04,710
Our square, for example, confusion.

485
00:57:04,950 --> 00:57:15,060
Or it's also possible that you don't in India that you have a different model so that the variable selected under the model of a slider change,

486
00:57:15,420 --> 00:57:20,670
if you categorization this can well, this is totally possible, this can definitely happen.

487
00:57:22,980 --> 00:57:30,180
And but when you come to the question whether you should include age as continuous or in college as categorical,

488
00:57:30,690 --> 00:57:39,870
that is not that cannot be complete answer by looking at stuff that yesterday or results alone that's sometimes

489
00:57:39,880 --> 00:57:47,609
that's also a consideration based on you know ease of communication is you know dissemination is out for example,

490
00:57:47,610 --> 00:57:49,350
if it is continuous.

491
00:57:49,800 --> 00:57:59,700
So then when you expand, if I had two people that you would explain it as of a one year increase in age, I see this large increase in what average?

492
00:58:00,480 --> 00:58:06,910
But if you break age into, you know, young people, old or younger people, older people, for example,

493
00:58:06,910 --> 00:58:14,260
of this two category, then you could simply explain it as, oh, compared to younger people like about that,

494
00:58:14,290 --> 00:58:23,010
what are the fact is for the older people and so so depending on which interpretation you I to have you think easier

495
00:58:23,160 --> 00:58:31,500
is easier for for people to understand that may also be a consideration be a factor to decide what covariate,

496
00:58:32,010 --> 00:58:39,750
what age to use, whether continuous or okay so that's this example.

497
00:58:39,930 --> 00:58:44,340
Now that's. Yeah.

498
00:58:45,360 --> 00:58:52,249
So let's. Continue our discussion.

499
00:58:52,250 --> 00:58:55,760
Now, we have looked at on step one.

500
00:58:55,760 --> 00:59:01,340
That is sort of just to be clear, what the maximum model is.

501
00:59:01,640 --> 00:59:05,850
And the next step three, that is after we specify, after we are,

502
00:59:05,900 --> 00:59:15,420
we choose a criteria to use for compare different models that we can carry out and forward backward a hybrid selection.

503
00:59:15,950 --> 00:59:22,490
Now let's take a look at a step to that is what criteria can we use to compare different models?

504
00:59:23,510 --> 00:59:29,960
So what happened here we can use? It turns out that there are several criteria we can use.

505
00:59:29,960 --> 00:59:33,590
There are many to use and the first one is R squared.

506
00:59:35,480 --> 00:59:39,350
First one is are we are. Now we should be very familiar with R squared.

507
00:59:39,740 --> 00:59:46,940
So our square is the correlation between the feed value for y and actual that well the square of the information.

508
00:59:48,590 --> 00:59:53,830
But one drawback of our square, we all know that it's actually not decreasing.

509
00:59:54,820 --> 00:59:59,260
Well, cobras are adding. So if you add more coverage are square will increase.

510
00:59:59,530 --> 01:00:06,760
Even if the coverage has nothing to do with your response, you will see a slight increase in in our square.

511
01:00:06,970 --> 01:00:11,820
So this is not new. So that's the reason why we introduced the so-called adjusted.

512
01:00:11,840 --> 01:00:16,900
Our square is defined in this way. So this adjusted our square.

513
01:00:17,380 --> 01:00:22,600
It could either. But when you add more covariance, it could either increase or decrease.

514
01:00:23,260 --> 01:00:34,990
So. So so it actually in this sense, it encourages you to add the the more relevant covariance and not not adding the less relative covariance.

515
01:00:37,120 --> 01:00:43,030
So we used our square to select answer or does far square just to compare different models.

516
01:00:43,240 --> 01:00:47,080
We would prefer the model that has larger adjust our square.

517
01:00:48,400 --> 01:00:52,150
So that's adjusted our square. So essentially adjusted our square.

518
01:00:53,080 --> 01:01:02,540
If you look at how it's calculated as as Y and this is fixed once we are given the dataset as is Y about values fixed in minus one.

519
01:01:02,560 --> 01:01:04,390
Of course the symbol size n is fixed.

520
01:01:04,780 --> 01:01:14,680
So then what changes across different models is, as we'll see my test square depending on which model you're looking at the same square.

521
01:01:15,410 --> 01:01:24,100
So, so in other words, our square or just our square, this criterion is equivalent to the here using a similar have a square.

522
01:01:25,480 --> 01:01:33,160
So which is actually the third criterion. So the single how to square the cinema, how to square.

523
01:01:33,340 --> 01:01:45,840
Now if we include just p covariance that recall that Sigma Sigma Square is defined as areas on square divided by an amount of key and so.

524
01:01:48,670 --> 01:01:52,930
So that's that's let's see why had a square when you have P covariant.

525
01:01:53,140 --> 01:02:04,450
Now if you add one more covariate then you will have as I see a horizontal square for for this new model, the number parameter becomes M minus one.

526
01:02:05,260 --> 01:02:12,910
And actually when you add this additional covariate on both the top numerator and denominator, both actually decrease.

527
01:02:13,600 --> 01:02:24,010
And so in the edge this one could either then the ratio could either increase or decrease depending on whether the new variable you add,

528
01:02:24,820 --> 01:02:29,120
depending on how large you can reduce the error some square.

529
01:02:29,500 --> 01:02:38,290
So. So in other words then we would only prefer the the covariance,

530
01:02:38,290 --> 01:02:43,479
adding the covariance that are indeed that can significantly reduce some of reviews to address on the

531
01:02:43,480 --> 01:02:50,410
square for the ones that that does not substantially reduce some of the square that we will not add one.

532
01:02:50,890 --> 01:02:55,659
So these three criterion here, the our square address, our square and sigma,

533
01:02:55,660 --> 01:03:04,900
how to square these are all four of these are the so-called maybe outcomes back here.

534
01:03:06,160 --> 01:03:13,600
These are the so-called treating error, like not a reflection of the training.

535
01:03:13,930 --> 01:03:24,190
So this is the criterion by treating our what we mean is that so this is a concept that's not a not very define here.

536
01:03:26,080 --> 01:03:29,590
So when you analyze the data, when you do a third act,

537
01:03:29,590 --> 01:03:40,930
so you have you or do either knows action and then you build a model and either either they make a prediction then.

538
01:03:42,920 --> 01:03:46,220
General speaking, we will have to see how well he performs.

539
01:03:46,370 --> 01:03:52,880
All the different views that I saw. So the first day I had a very appealing model that's year to call it a training

540
01:03:52,880 --> 01:03:57,050
business that you train or model is all that's called training below that.

541
01:03:57,710 --> 01:04:01,040
And then there is another data set where you can test the performance.

542
01:04:01,340 --> 01:04:09,140
That's theoretical. In the past, it doesn't add up for the training on the transaction, the bidder on which you build or model,

543
01:04:09,140 --> 01:04:15,439
train or model that and whatever criteria are used based on that analysis alone is one that they a want.

544
01:04:15,440 --> 01:04:19,399
That's the call. That call, the training, the training, training.

545
01:04:19,400 --> 01:04:23,600
And so that is how well the model office took the card data.

546
01:04:24,560 --> 01:04:26,660
So the card and if I give you a dataset,

547
01:04:27,050 --> 01:04:35,509
I ask you to do the whole you can build a very complex model based on this dataset I give you and very complex.

548
01:04:35,510 --> 01:04:38,750
So that is. But they don't very well.

549
01:04:39,380 --> 01:04:47,810
So in other words, you could actually even think about if I give you, you know, ten data points, let's say that I'm making this up,

550
01:04:47,870 --> 01:04:54,350
I'll give you a target of once you could have built a model with ten parameters so that it fits the data perfectly.

551
01:04:54,740 --> 01:04:58,130
So you do something, you have a different parameter. So it appears that data perfect.

552
01:04:59,560 --> 01:05:02,970
What if I give you an hour later? A pastor does in the past.

553
01:05:03,420 --> 01:05:07,530
The model you build based on the Trinity as if Ramona is overly complex.

554
01:05:08,400 --> 01:05:16,140
The performance on account of status that may not be that good because your your feeling annoys Trinity as much.

555
01:05:16,610 --> 01:05:21,720
So here the square addresses are square.

556
01:05:21,720 --> 01:05:31,409
Assume a square at least three criteria. They are the so-called trinity above the criteria for the treating area.

557
01:05:31,410 --> 01:05:34,460
So they look at how well about affairs to the current dataset.

558
01:05:35,430 --> 01:05:39,989
So we do have a bunch of other criteria that we will look at in a few seconds that

559
01:05:39,990 --> 01:05:46,170
actually evaluate the how the model performs when predicting future responses.

560
01:05:46,920 --> 01:05:50,880
Okay. So if I give you a beauty, look at how well our model performs.

561
01:05:52,420 --> 01:06:03,930
And this is the so-called test error and that is the the other two criteria of criteria.

562
01:06:03,930 --> 01:06:08,009
So what is predict prediction sample square?

563
01:06:08,010 --> 01:06:13,440
The other one is model's key. And we also have the CBC.

564
01:06:13,440 --> 01:06:17,759
But because of the limitation, we won't be able to cover this.

565
01:06:17,760 --> 01:06:27,110
But now let's take a look at the the the the other two criteria for prediction is on the square and now simply.

566
01:06:29,620 --> 01:06:32,520
Yeah. This leads to summarize what I just mentioned.

567
01:06:32,530 --> 01:06:42,939
So these three criteria, well, people use them, but we should be clear that these criteria they are first of all,

568
01:06:42,940 --> 01:06:48,730
they are all functions of abstract abstract to calculate it based on your training data,

569
01:06:48,970 --> 01:06:56,410
the data that you feed of a model of the for example, Rachel, for example, the seamless word A this is equal to one.

570
01:07:02,410 --> 01:07:05,710
Fred, this is equal feelings. Okay.

571
01:07:05,710 --> 01:07:09,520
So it reflects how well the model fits the card data.

572
01:07:10,540 --> 01:07:16,070
So I give you a DNA that you fit her model and you look at how well the model fish.

573
01:07:16,280 --> 01:07:25,540
Fish, and you can you can look at the different criteria, but they do not reflect how well the model predicted future responses.

574
01:07:27,310 --> 01:07:32,440
So if I give you a new dataset or a new observation, so for example, let's say your data is out of you,

575
01:07:32,650 --> 01:07:40,450
you build a model, you are able to to predict people's income based on their race gender outlook.

576
01:07:40,900 --> 01:07:45,670
Now, now I give you a new dataset, new new subjects, not nowadays.

577
01:07:45,670 --> 01:07:54,940
Ideas that you have use like a new person. I tell you, what are the person's age and gender level and how?

578
01:07:54,940 --> 01:07:58,690
Well, then let's take a look at how your model can predict this person's income.

579
01:07:59,320 --> 01:08:13,450
So this look right here does not reflect that the prediction, performance prediction and the problem of using these three criteria,

580
01:08:14,610 --> 01:08:23,840
those are all by only looking at the current data is that these residuals you are underestimating the Twitter underestimate.

581
01:08:24,940 --> 01:08:35,560
So. So you are the worst. Well, the SSD, based on this estimate, the residual the SSD is smaller than the true test.

582
01:08:36,970 --> 01:08:42,429
So here we are not going to show this. We are not going to show this.

583
01:08:42,430 --> 01:08:45,790
But but this is a fact.

584
01:08:46,450 --> 01:08:50,079
So this actually makes it less desirable? Well, not more.

585
01:08:50,080 --> 01:08:55,330
And it's not a complete desirable to focus on those exclusive focus on this through material.

586
01:08:55,330 --> 01:09:02,500
Because the error, as I see Aristotle Square will absolutely underestimate the true.

587
01:09:04,930 --> 01:09:16,570
So then so now where's the treating error is often overly optimistic in it underestimated failure.

588
01:09:17,350 --> 01:09:24,169
So if you look at your model field and look by using criteria only using the military to beat us at maturity,

589
01:09:24,170 --> 01:09:31,300
it tells you it's more altruistic then than it actually is.

590
01:09:33,370 --> 01:09:40,240
Okay, so. And then we will go catch.

591
01:09:43,130 --> 01:09:57,320
How well the model predicts future responses. And here we will actually look at the so called prediction error residuals.

592
01:10:08,730 --> 01:10:12,500
Sorry. Yeah. So here we consider a different kind of religion.

593
01:10:12,530 --> 01:10:17,030
This is the so-called Achilles heel. Residual or predation or residual.

594
01:10:17,810 --> 01:10:27,670
Now, let's take a look at what it is. So here, while this novel just seems a little bit complex, but it's easy to understand.

595
01:10:27,730 --> 01:10:33,040
So this is let's forget about this division for a bit and let's just look at it.

596
01:10:33,040 --> 01:10:42,040
What this is why it is the actual observed response value for the subject, your data set.

597
01:10:43,810 --> 01:10:46,870
And then this is what I had minus I.

598
01:10:48,280 --> 01:11:01,120
This is actually the predicted Y. So for the arts individual, for the individual, you try to make a prediction of the individual's results.

599
01:11:01,750 --> 01:11:11,980
Or when you make a prediction, the model that you are using to make a prediction model is built based on the idea of moving on a subject.

600
01:11:13,420 --> 01:11:17,920
So in other words, you first remove this particular subject, you get it wrong,

601
01:11:18,670 --> 01:11:26,410
and then you use the views of your model to to predict the Y value for this particular subject.

602
01:11:27,220 --> 01:11:34,450
The reason well, the rationale behind doing this is that is that.

603
01:11:35,050 --> 01:11:38,780
So think. Maybe a.

604
01:11:39,640 --> 01:11:44,020
Didn't emphasize that. Maybe I didn't have so.

605
01:11:45,980 --> 01:11:53,780
So the reason we do that is because this one I had itself in and what they are, they are not independent.

606
01:11:54,260 --> 01:12:04,490
And this actually in the closet was is that the Y had a maybe arbitrary, arbitrary, artificially drawn force towards the actual observer model.

607
01:12:05,120 --> 01:12:08,360
So they are not independent. This is relatively easy to see.

608
01:12:08,930 --> 01:12:21,680
The reason is that because what I have is or the quote y hat is equal to h times y had a matrix, perhaps y.

609
01:12:24,250 --> 01:12:28,660
So in other words, each why I here why I had to here.

610
01:12:28,690 --> 01:12:32,590
If you look at the eyes, think about what had a for for the highest individual.

611
01:12:33,190 --> 01:12:36,550
It is a linear linear combination.

612
01:12:37,660 --> 01:12:43,900
It is a linear combination of the whole vector of observed value.

613
01:12:44,770 --> 01:12:48,700
So in other words, it is also apparent also involve y.

614
01:12:50,440 --> 01:12:54,940
So here we don't need to really get into the mass media study.

615
01:12:54,940 --> 01:12:58,640
But you can we can imagine we can imagine this. We can think of this intuitively.

616
01:12:58,660 --> 01:13:03,140
So now you say, I am in the dataset, right?

617
01:13:03,400 --> 01:13:06,380
And then you want to predict my value, like what I have.

618
01:13:08,470 --> 01:13:18,970
But we pretty much value the model you used to predict about that your model Peter had resolved to bring out the better had one count.

619
01:13:18,970 --> 01:13:27,670
No. Better have you actually use my actual observer value to calculate that because you use every data point in the dataset.

620
01:13:28,150 --> 01:13:32,320
So you say you fit a model, linear regression model for the whole dataset to come a bit a hat.

621
01:13:32,590 --> 01:13:40,419
Now, of course, my point is included in that is that so you actually use by the other point to estimate better hat and then you

622
01:13:40,420 --> 01:13:46,960
are using the better hat not to predict my my madam y hat because Peter had it depends on my actual value.

623
01:13:47,230 --> 01:13:54,220
Now of course eventually you use that to predict y that is the predictive y hat depends on my actual observation.

624
01:13:54,580 --> 01:14:02,710
So they are not independent. So the y i have is not an independent of Y.

625
01:14:03,160 --> 01:14:11,980
So this actually results in the the you know, the residual residuals actually underestimated the travel.

626
01:14:14,080 --> 01:14:23,080
So that is the reason why here is that of making the prediction of my value by

627
01:14:23,200 --> 01:14:26,830
using the bit that has not actually calculated based on my actual observer value.

628
01:14:27,250 --> 01:14:32,140
So when you see the model, you first remove my data plotted from the dataset.

629
01:14:33,160 --> 01:14:43,479
And so then using the rest of the data points, you build a model you have with the examiner how it is calculated not using my data point.

630
01:14:43,480 --> 01:14:53,710
L Right, it has nothing to do with my data point because I got removed that you can have a hack and then you use that to being a hat estimate by my Y.

631
01:14:54,490 --> 01:14:57,160
And then while the estimated y,

632
01:14:57,190 --> 01:15:06,550
the predicted y does not observe what you call full involvement because I never use my actual value when you make a prediction.

633
01:15:07,810 --> 01:15:12,340
So that is the y, this y hat minus I means.

634
01:15:12,700 --> 01:15:26,550
So is the predictive value for the ice observation based on the model that when you lot of us in the first remove that's what this location.

635
01:15:29,240 --> 01:15:34,980
And then the difference is this this this residual so-called deleted residual interpretation.

636
01:15:35,000 --> 01:15:44,120
Every residual. Okay. And now notice that of this why this predictive value is independent of the actual

637
01:15:44,270 --> 01:15:55,240
observed by this makes the error you know frankly the quantifying the true error dataset.

638
01:15:57,760 --> 01:16:05,110
And well, then it will seem that well, in order to calculate this, we will be too afraid of the model many, many times,

639
01:16:05,110 --> 01:16:10,630
because each time you will need to remove one data point and fail model in making the corresponding position.

640
01:16:10,870 --> 01:16:14,240
But as we bring your rationale, it turns out that you don't need to do that.

641
01:16:14,260 --> 01:16:17,950
I mean, this this had to be simply equal to absolute.

642
01:16:18,160 --> 01:16:21,670
I had divided by one minus the average.

643
01:16:24,220 --> 01:16:31,269
Okay. So this residual is also known as the the predict the prediction sample squared.

644
01:16:31,270 --> 01:16:33,390
So this name you're going to separate from here.

645
01:16:33,400 --> 01:16:48,160
So this is the prediction sum of square the prep Oriana was the press residual the rationale behind this is if you think about this procedure

646
01:16:48,580 --> 01:16:59,980
this procedure because it'll remove my data point from the data weighing below the model and let me make a prediction on my response.

647
01:17:00,520 --> 01:17:05,080
This is sort of like you create my data point as a future observation.

648
01:17:05,830 --> 01:17:11,890
So your data set from the beginning, you could just imagine your dataset and you didn't even click on my data point.

649
01:17:12,820 --> 01:17:15,280
You just climbed into like the rest of the subjects.

650
01:17:15,730 --> 01:17:25,810
And then you build a model and then you look at my like you consider like minded upload as a future observation and if you try to use the that

651
01:17:26,380 --> 01:17:36,310
to build a model to predict my my way so this actually pretended as a future data point and then in a better is a performance of prediction.

652
01:17:37,060 --> 01:17:43,390
So here we are because we are trying to construct criteria for for release of prediction.

653
01:17:43,420 --> 01:17:50,800
So this is right. We move one to build the model and then try to predict a particular one.

654
01:17:52,570 --> 01:17:56,470
So then once we have this so called a premise residual,

655
01:17:57,190 --> 01:18:05,710
then what we define different criteria is that of using this absolute I have square to define different criteria.

656
01:18:05,980 --> 01:18:15,970
We would use this new newly constructed the prediction error residual residual to define a different criteria.

657
01:18:18,010 --> 01:18:22,450
And then we have the column models of Arizona Square and our square.

658
01:18:22,450 --> 01:18:31,060
So we have done the the press somehow square sorry, the predictions of the square.

659
01:18:31,420 --> 01:18:38,020
And also we have the prediction R squared and these are just the counterparts of these two.

660
01:18:39,330 --> 01:18:47,390
But these two. Matters, the sort of the treaty.

661
01:18:47,750 --> 01:18:53,909
Right. So because this this tool only used to beat us at in America, sort of sort of a treaty.

662
01:18:53,910 --> 01:18:58,470
How about these tools that we passed here?

663
01:19:01,880 --> 01:19:08,260
Well, you do not explicitly have a past data, but by removing one data point,

664
01:19:08,560 --> 01:19:14,530
you sort of use that one data point as the test to see how well your model performs.

665
01:19:14,800 --> 01:19:22,530
Making Prediction of Future Observation. Okay.

666
01:19:22,770 --> 01:19:30,600
So then the prediction somewhat square is defined as the sum of the squares of this press residual.

667
01:19:31,500 --> 01:19:34,860
So the other words, the sum of the square of this guy.

668
01:19:35,460 --> 01:19:38,580
This is how the prediction sum of square is defined.

669
01:19:41,860 --> 01:19:45,760
And then we will pick what we compare different models.

670
01:19:46,240 --> 01:19:50,380
We will pick the model that has the lowest prediction sounds.

671
01:19:50,380 --> 01:19:55,510
When. This is one criterion to consider.

672
01:19:55,750 --> 01:20:04,780
Another point here is the predation R-squared. The predation elsewhere is similar defined to our square, but is defined here.

673
01:20:04,960 --> 01:20:12,880
Is that using fancy uses to predict the predation somewhat square so it matters.

674
01:20:12,880 --> 01:20:19,990
Ability to predict future responses is how well your model is able to predict future.

675
01:20:20,350 --> 01:20:33,500
Future response. Well, if you compare this this our production, our square to our square or just our square than our square or just our square,

676
01:20:33,800 --> 01:20:39,499
they actually are more of an assessment of the model's ability to predict,

677
01:20:39,500 --> 01:20:49,430
correlate data because you build your model based on all the current data points and just sort of compare how well the model predicts.

678
01:20:52,460 --> 01:20:55,420
Compared to an actual battle, but at least based on current data.

679
01:20:58,150 --> 01:21:07,450
And this whole procedure here actually is based on a much more general rationale that the so-called leaf went out of cross-validation.

680
01:21:08,110 --> 01:21:19,060
This is in common commonly seen in I think you will you definitely see this in in other courses as well maybe a much more detailed way.

681
01:21:20,260 --> 01:21:30,430
So leave one out of cross validation. Well, maybe we can talk about we have a few slides on Carlsbad Visual.

682
01:21:30,460 --> 01:21:37,480
Maybe. Maybe we want to start talking about health management right there, I think make things a little bit easier.

683
01:21:42,120 --> 01:21:46,820
Okay. And then now we have different residual.

684
01:21:46,830 --> 01:21:57,420
If you look at so far in this course what we what we started to talk about Comodo diagnostics, we have introduced different types of residuals.

685
01:21:57,450 --> 01:22:07,770
Now this table type of summarize match. So if we have the ordinary residual right, that's simply that's the most commonly considered one.

686
01:22:08,550 --> 01:22:12,170
That's simply why on minus the predictive value.

687
01:22:12,750 --> 01:22:15,960
One that's the conventional residual. Ordinary residual.

688
01:22:16,950 --> 01:22:21,810
And it's very easy to show match the residual follow this normal distribution.

689
01:22:23,040 --> 01:22:30,660
But we have shown this this is easy to show because because this is just a reminder.

690
01:22:30,840 --> 01:22:34,350
So I think you guys can work out the details because. Armstrong.

691
01:22:34,800 --> 01:22:41,460
But if we write it as a as a matrix vector form capsule, hat is equal to y minus y hat.

692
01:22:43,450 --> 01:22:51,060
Right. And then this is equal to I and minus h times y ice.

693
01:22:51,070 --> 01:23:01,220
I don't know the matrix. H is the hap matrix. And then, of course, the parents of Eminem had a sequel to you.

694
01:23:01,630 --> 01:23:08,410
I, I love this age times awareness of why times minus age evolves.

695
01:23:09,220 --> 01:23:13,480
But I want to say just symmetric. So the transparency is just equal to itself.

696
01:23:14,260 --> 01:23:23,470
And that because there is a why we assume it has sigma squared times all the metrics and I why does age this is important.

697
01:23:23,740 --> 01:23:30,100
So what is left is the sky. And then here we have that.

698
01:23:30,120 --> 01:23:39,350
Of course, if you look at an individual that's absolute, I had, you know, follows normal distribution with very similar square one minus II.

699
01:23:39,940 --> 01:23:43,540
And so that's that's how we got to a normal distribution.

700
01:23:45,930 --> 01:23:49,500
And then for the press, the residual.

701
01:23:50,130 --> 01:23:53,700
Well, because it again mathematically is equal to this.

702
01:23:55,080 --> 01:24:03,840
Then, of course, now we can very easily figure out what disruption it has, because we already know that absolutely none of the solution.

703
01:24:04,140 --> 01:24:09,810
And this is just a scale of absolute or absolute I had.

704
01:24:11,160 --> 01:24:16,230
So this is of present residual and then we have a standardized residual.

705
01:24:16,800 --> 01:24:27,510
And so that's absolute. I have divided by and standardized by Sigma hat and this one roughly the following normal distribution of the solution.

706
01:24:30,300 --> 01:24:39,689
So as we measured the the benefit of doing this is that absolute itself is depends on the unit of what it has the same

707
01:24:39,690 --> 01:24:48,300
unit as what and then depending on the unit of why that this this value of absolute could could be rather arbitrary.

708
01:24:48,570 --> 01:24:52,860
If you change the unit of why not magnitude, we also change.

709
01:24:53,310 --> 01:25:01,740
But if you standardize it that then the magnitudes will stay constant will will stay the same.

710
01:25:01,740 --> 01:25:05,010
So that of distribution roughly followed standard normal distribution.

711
01:25:07,370 --> 01:25:14,470
And then we have the so-called internal is still a nice residual and then we have the external is still nice residual.

712
01:25:15,250 --> 01:25:20,160
So we have all these different all these tools in probability.

713
01:25:20,740 --> 01:25:27,520
But when the sample size is large, they all follow normal and they follow normal discussion.

714
01:25:29,380 --> 01:25:35,190
So previous of it, we never use this residuals to make a residual plots, especially, you know,

715
01:25:35,200 --> 01:25:41,800
we they thought of that the raw residual, congressional residual would make a class of a standardized residual.

716
01:25:42,340 --> 01:25:53,770
And sometimes we also look at the colon as graphical tools to check or to do model diagnostic diagnostics to see

717
01:25:53,770 --> 01:26:03,710
whether there is any clear severe deviation or a violation of the model assumption that inarguably abundance,

718
01:26:04,150 --> 01:26:07,380
that equal variance normality itself.

719
01:26:09,580 --> 01:26:15,220
But no, actually, now we introduce this, the so-called press residuals.

720
01:26:15,520 --> 01:26:24,790
This is to look at sort of the prediction error in how well we were model preferred to make a prediction of a future observation.

721
01:26:26,580 --> 01:26:30,780
Yeah. So this table summarizes only a commonly seen residual.

722
01:26:31,680 --> 01:26:35,310
Okay. So that is one criteria.

723
01:26:35,430 --> 01:26:41,190
So I want to summarize a little bit because I mean, here we are destroying all the history of guys.

724
01:26:44,820 --> 01:26:52,720
Just try to stop. So let's just go back. It's worthwhile to look at it, to look at what we are doing.

725
01:26:52,740 --> 01:27:01,590
So what we're doing now is actually we are looking at the criteria where we're defining different criteria for comparing models.

726
01:27:01,980 --> 01:27:06,850
Remember that our goal is to select the best model for how to define the best.

727
01:27:06,910 --> 01:27:11,490
We have to be clear what criteria we are using to define the best.

728
01:27:12,240 --> 01:27:18,020
And of course, p value is one criterion to look at you.

729
01:27:18,240 --> 01:27:20,970
We're looking at a bunch of other criteria.

730
01:27:21,360 --> 01:27:30,120
So as we measure these three, they are more of the the criteria used to look at the treating error, how well the model perform for the card.

731
01:27:30,900 --> 01:27:39,450
But then we have these tools, these sort of matter how well the model predicts future observation and a process.

732
01:27:39,450 --> 01:27:43,200
We just define what are the press is.

733
01:27:43,620 --> 01:27:48,929
And that is just a sample square but not using that the conventional residual.

734
01:27:48,930 --> 01:27:54,660
Can we use this one out word or prediction error residual.

735
01:27:56,430 --> 01:28:00,419
Okay. So that's some criteria we can use.

736
01:28:00,420 --> 01:28:08,940
Then another one is the so called values C, P, and so below c, p.

737
01:28:08,940 --> 01:28:14,069
This criterion is based on the consideration that, well,

738
01:28:14,070 --> 01:28:22,410
we try to make a prediction for a future observation, like the prediction to be as accurate as possible.

739
01:28:23,100 --> 01:28:31,410
Right. But if you think about the accuracy of this prediction, the accuracy actually is based on two things,

740
01:28:32,190 --> 01:28:37,610
is based on the bias of the prediction and also is based on the variation of the prediction.

741
01:28:38,760 --> 01:28:45,150
So if your true observation is here, this is the truth.

742
01:28:45,260 --> 01:28:48,470
A true observation is accurate. Well, maybe y.

743
01:28:52,220 --> 01:28:57,349
So one, because he raises the bar so that of the probation.

744
01:28:57,350 --> 01:29:05,600
So ideally we want the bars to be as small as possible because if you have a bias operation,

745
01:29:05,600 --> 01:29:10,260
that means, well, for one prediction, like for one one they take us out of.

746
01:29:12,170 --> 01:29:17,270
So so if you make prediction was you might you had predicted better to be here you make another

747
01:29:18,020 --> 01:29:22,880
prediction you might not be here you make another prediction you might predictive value to be here.

748
01:29:23,360 --> 01:29:26,390
So all of these values are smaller or larger than Y.

749
01:29:26,780 --> 01:29:32,300
So they are they are biased in order to the Y. So bias is another one is.

750
01:29:34,130 --> 01:29:39,830
So we would like to have the bias to be as much as possible and other considerations that the virus.

751
01:29:40,430 --> 01:29:49,550
So for one model you might have predicted to the Y to be you know, to be closer to Y, there is variation but A for another model,

752
01:29:49,550 --> 01:29:57,890
you might make it to make a prediction or you might predict the Y heights will be far away from the actual Y.

753
01:29:58,160 --> 01:30:08,510
So then there is a larger variation. So my point is that if you are to keep the accuracy, content, accuracy of the prediction,

754
01:30:08,720 --> 01:30:13,700
you like the bias to be as much as possible, but also you want the bitterness to be as small as possible.

755
01:30:14,180 --> 01:30:18,110
And the mousy piece actually falls into account.

756
01:30:19,400 --> 01:30:22,880
So if we consider this criteria, this so-called total variation,

757
01:30:24,170 --> 01:30:32,750
so is is average a standardized average of the square of the bias and the variance of the prediction?

758
01:30:36,560 --> 01:30:45,320
And then the memo CPA tries to estimate this very square plus star by square plus variance.

759
01:30:46,970 --> 01:30:57,260
And it turns out to have this expression, let's not worry too much about the mathematical details, but let's just use this as a fact.

760
01:30:57,270 --> 01:31:07,600
So Mel, LCP is the estimate of the total variation and turns out that Mel C p is equal to one over in one word, assembly sized.

761
01:31:09,170 --> 01:31:13,790
This is the error sum of square based on your training dataset, right?

762
01:31:13,820 --> 01:31:18,250
This is the treating error of the Carter model. You look at a tiny Harold McCarthy.

763
01:31:19,190 --> 01:31:28,830
This is as I see. But we know that as I see the error with some square as a margin of error, some square underestimate sigma squared.

764
01:31:28,960 --> 01:31:34,040
I guess that's what we we try to point out here.

765
01:31:35,240 --> 01:31:44,270
So the SSA as the underestimate that the true error should be resolved,

766
01:31:44,270 --> 01:31:53,930
that that will simply see it add adjustment to that so that it probably estimate the true error.

767
01:31:54,710 --> 01:31:58,310
So this adjustment this is the adjustment for overestimation.

768
01:31:58,340 --> 01:32:05,860
So it is two p times sigma squared for we're seeing as we're full.

769
01:32:05,870 --> 01:32:12,830
This is as I see error some square for the full model divided by and minus the number from train the full model.

770
01:32:16,470 --> 01:32:19,620
Okay. So this is what else sheet is.

771
01:32:20,190 --> 01:32:28,380
So again, I mean, we here we admit the details like why this is a good estimate of the total variation.

772
01:32:28,800 --> 01:32:39,030
But let's not worry too much about that. So let's just rely on our sort of intuition results.

773
01:32:39,300 --> 01:32:44,970
So it has a component of error sample squared, but our results square underestimated the true ever.

774
01:32:45,210 --> 01:32:46,800
So that we have just been true.

775
01:32:49,620 --> 01:33:03,720
So but now low see this is also a criterion for the test, like how well the model performs when predicting a future observation.

776
01:33:04,740 --> 01:33:09,060
So mellow sepia strikes a balance between bias and appearance.

777
01:33:10,770 --> 01:33:16,530
So here the reason is that now if you increase the number of parameter in the model,

778
01:33:17,580 --> 01:33:25,530
if you increase number of country in the model, then typically speaking, the variance of the production also increases.

779
01:33:25,590 --> 01:33:31,800
This is very intuitive to understand because let's say you compare two models.

780
01:33:32,070 --> 01:33:35,280
One model has five parameters provide.

781
01:33:36,330 --> 01:33:42,630
Another one has ten parameters. People do that because your data now is fixed.

782
01:33:42,870 --> 01:33:46,080
You just have these six amount of data points.

783
01:33:47,130 --> 01:33:51,689
And of course, if you use this data, they are going to fix data points.

784
01:33:51,690 --> 01:33:57,690
So ask me to five parameters. You are able to act well estimate the more precisely so.

785
01:33:57,990 --> 01:34:04,290
But if you use the same amount of information to estimate ten parameters, many of them estimate them less well.

786
01:34:04,890 --> 01:34:08,130
So there is more variation, estimate more parameters.

787
01:34:10,970 --> 01:34:18,630
So in fellowship we can see that now as the parameter increases, number parameter increases.

788
01:34:19,970 --> 01:34:29,539
Of course, the error is almost Moscow, our decrease. We know that if we add more clarity in the model than errors when error in some square increase.

789
01:34:29,540 --> 01:34:36,510
So this part decrease fudge. This part actually will increase.

790
01:34:36,840 --> 01:34:43,680
And this part. This is this part. And this is this part.

791
01:34:46,120 --> 01:34:47,980
So this bar will increase.

792
01:34:48,670 --> 01:34:58,240
So in other words, now, where you the increased number of covariates, is not it necessary that fellowship always increase or always decrease?

793
01:34:58,690 --> 01:35:03,280
It strikes the balance between between this and this.

794
01:35:03,920 --> 01:35:07,740
Right. So precisely, again, to strike a balance between bias and events.

795
01:35:08,200 --> 01:35:10,960
So you do not want to have a two hour of a bias.

796
01:35:11,350 --> 01:35:20,470
On the other hand, you do not want to have a too large of a variance so that if you keep both under control, then you have total variation of control.

797
01:35:20,470 --> 01:35:26,230
So you may have to have a go to pronation. So that's essentially what now OCP is about.

798
01:35:26,530 --> 01:35:30,340
So it doesn't allow you to include too many covariance.

799
01:35:30,760 --> 01:35:34,780
But on the other hand, it does allow you to include a few covariates.

800
01:35:35,170 --> 01:35:38,320
So you can sort of find the balance in the middle.

801
01:35:38,500 --> 01:35:45,070
So that include, you know, the right number of covariance in the model I use LCP.

802
01:35:47,120 --> 01:35:51,320
Okay. So that's another criteria that is commonly used.

803
01:35:55,560 --> 01:35:59,010
Okay. So now we have talking about, you know, stop two as well.

804
01:35:59,010 --> 01:36:06,780
So so here we specify we have seen different different criteria, different material to compare different models.

805
01:36:07,110 --> 01:36:12,900
So with these these three they as they are for well,

806
01:36:13,080 --> 01:36:19,340
they are for the training like how well the motor fails car data and then we look at the balance

807
01:36:19,500 --> 01:36:26,190
P and also the press right to to look at how well model produced future responses by the ACP.

808
01:36:26,200 --> 01:36:30,270
I see these are also widely used, but we don't have time to cover them.

809
01:36:30,540 --> 01:36:39,269
The thing you guys will see this in 651. We talk about generalized vehicle models and these these to the information based criteria.

810
01:36:39,270 --> 01:36:44,579
These are also widely used criteria. Okay.

811
01:36:44,580 --> 01:36:54,270
So then after we are clear what criteria to to use to compare models, then the step three, we can carry out the forward to the backward,

812
01:36:54,540 --> 01:37:01,800
the hybrid selection, and then we can order an angle or selected criteria, particular truly criterion.

813
01:37:02,040 --> 01:37:08,510
We can compare those different models and that in the end will end up with a motive.

814
01:37:09,120 --> 01:37:16,800
And in this process, well, if you look have this criterion here, like these criteria,

815
01:37:17,670 --> 01:37:24,149
they are sort of the so-called indirect estimate of test, our indirect estimates,

816
01:37:24,150 --> 01:37:28,290
our because we are using some mathematical expressions, you know,

817
01:37:28,380 --> 01:37:33,119
making some approximations and trying to estimate the test and or how well the

818
01:37:33,120 --> 01:37:37,020
model performed either on the treated dataset or on the testing assumptions.

819
01:37:38,100 --> 01:37:45,210
There is a way to direct an estimate of test, and this is based on cross-validation organization.

820
01:37:45,210 --> 01:37:57,540
In addition, these are very commonly used technique of let's okay, so let's look at the,

821
01:37:58,440 --> 01:38:03,000
the cross tradition that we will make a very quick comment on this particular example.

822
01:38:03,600 --> 01:38:10,620
So the flow studies model, validation modeling addition, what it means is that we build our models.

823
01:38:11,310 --> 01:38:14,640
Now we want to see how the model prefer on a new dataset.

824
01:38:17,940 --> 01:38:24,120
This is especially important because again, if you build the model of the same dataset,

825
01:38:24,180 --> 01:38:29,040
the big assessment of your model, almost 70%, sometimes you you know, we are using the data twice.

826
01:38:29,370 --> 01:38:34,350
So we do not probably have the best idea how the model performed in general.

827
01:38:34,800 --> 01:38:42,539
So the ideal cases, we built a model in the Taylor dataset, then we collected our data that we make ourselves and how the model we test,

828
01:38:42,540 --> 01:38:50,069
how the model prefer newly does that's called model validation and k cross key for the personalization.

829
01:38:50,070 --> 01:38:57,960
This is of course in reality, oftentimes we do not have the luxury of cloud computing assets.

830
01:38:58,410 --> 01:39:02,190
We only have the power or resources to collect one dataset.

831
01:39:02,910 --> 01:39:07,530
So that means that we do not have outcomes, we do not have a separate test dataset.

832
01:39:07,860 --> 01:39:18,360
So then how do we more objectively to test our to evaluate our model then cross-validation is a very useful alternative.

833
01:39:19,380 --> 01:39:23,190
So how that works is that you only have one dataset.

834
01:39:23,760 --> 01:39:34,440
Okay, that's no problem. I will further divide the dataset into two parts, but one part I would fit the model I'll be able to.

835
01:39:34,690 --> 01:39:37,800
And then with another part of test automotive preferred.

836
01:39:38,130 --> 01:39:45,990
So here I would split the data into different parts, let's say like five for cross-validation.

837
01:39:46,140 --> 01:39:58,449
So then I will split my dataset into five files and then I will build a lab model using, well, 4/5 of the data and 80% of the data.

838
01:39:58,450 --> 01:40:06,210
And I will be with my model and then I will test how the model prefer, make the rest 20% of the data.

839
01:40:07,800 --> 01:40:11,820
And I would do this, you know, a few times like five times in total.

840
01:40:12,180 --> 01:40:23,399
So then I will because I divided the data into five, five, four, 550 cars, then I will use these three and like four parts to train my model,

841
01:40:23,400 --> 01:40:29,430
to build that model and then I'll test my model of seven and the similarity I will build

842
01:40:29,430 --> 01:40:34,880
my tomorrow using these four parts and test my model on this part and I will do this,

843
01:40:34,890 --> 01:40:45,390
keep doing this, and then I will have the performance, you know, for each of these five Uber ways.

844
01:40:45,780 --> 01:40:50,700
And then my final performance is sort of every so, so idea performance here you can look at,

845
01:40:51,030 --> 01:40:54,510
you know, for example, model ACP as our criterion or you could look at.

846
01:40:54,990 --> 01:41:01,960
CPAC as of right here. But anyway, so each performance here, this is a quality that you can summarize first and calculate.

847
01:41:02,460 --> 01:41:06,000
And then in the end, you can average this over the five.

848
01:41:08,080 --> 01:41:11,320
There's five different ways. It's not from the data.

849
01:41:12,190 --> 01:41:15,670
And then you can compare the model.

850
01:41:16,090 --> 01:41:19,600
So let's say you have model Y, you have model two, right?

851
01:41:19,600 --> 01:41:27,490
For model one, you do this cross-validation and then you train the data and then you has a performance

852
01:41:27,580 --> 01:41:32,830
and kind of an average performance and a model to you do the same reason you pass data,

853
01:41:33,700 --> 01:41:36,880
train data you find true in the model, you test the model,

854
01:41:37,060 --> 01:41:44,460
you have the average performance and then you compare that to every performance and then you can select to the model that has kind of a promise.

855
01:41:44,920 --> 01:41:53,710
So in this way, although we didn't collect a separate test dataset, but we, you know,

856
01:41:53,980 --> 01:42:01,780
artificially we separate our a single dataset into people's hearts so that we are able to train the model and the test model.

857
01:42:01,960 --> 01:42:07,030
And we have a relatively objective assessment of how well the model performed.

858
01:42:07,420 --> 01:42:10,630
And that's not so-called okay, fold validation.

859
01:42:13,060 --> 01:42:16,840
Okay. So that's the case for transportation.

860
01:42:17,860 --> 01:42:23,710
And now let's let me very quickly talk about this example, because there's one important point I would like to make.

861
01:42:24,350 --> 01:42:27,840
Now, consider this example. This is a simulation example.

862
01:42:27,850 --> 01:42:36,460
So in other words, this artificially created how consider y depends on these for x this particular way.

863
01:42:36,830 --> 01:42:43,510
Now, in this model, we actually artificially make this very small.

864
01:42:43,690 --> 01:42:49,599
So the true model, although the true model does depend on what does depend on x three model,

865
01:42:49,600 --> 01:42:56,010
in fact, in fact of f3r why that is very small 1a1 over 1000 plus one.

866
01:42:57,430 --> 01:43:04,479
So in this case, if you select model using here, we can use for the Criterion Tool to select a model.

867
01:43:04,480 --> 01:43:08,800
Right? We do not think there's a probability on a forward selection.

868
01:43:08,810 --> 01:43:16,510
But anyway, so for you, if you simply compare the three models, you can see that the R Square,

869
01:43:16,510 --> 01:43:20,800
of course, the more covariates you include while R Square always increases.

870
01:43:21,250 --> 01:43:25,479
Now see the square in this particular case?

871
01:43:25,480 --> 01:43:28,670
Well, I'm here. It was a little bit.

872
01:43:28,690 --> 01:43:36,040
But then if you look at here, this becomes slightly larger than this and adjusted our square.

873
01:43:37,480 --> 01:43:42,100
Well, it increases from here to here. It increase that it decreases.

874
01:43:45,030 --> 01:43:50,220
Yeah. So. Well, I guess the point I'm trying to make is that now we rely on, for example,

875
01:43:50,220 --> 01:43:59,280
models CPE to select the model who compare the three lions who would pick the smoking model with the smallest model of the city.

876
01:43:59,520 --> 01:44:09,300
So that is this model right here. That is the second more model without, you know, without the at three in the model.

877
01:44:10,860 --> 01:44:15,000
And if you pick this model, that's perfectly fine.

878
01:44:15,900 --> 01:44:23,850
That's perfectly fine. So especially in this case, although we know about, you know, the true model does depend on X three.

879
01:44:24,540 --> 01:44:35,550
Those are going to have three. However, that you found three is so small that having it may not actually help us to approximate the truth.

880
01:44:35,820 --> 01:44:43,920
So in other words, the having three, that means you will need to use your data to estimate this effect as well.

881
01:44:44,880 --> 01:44:59,159
And the price that you pay in estimating this particular effect may not mean oh well compensate the sorry the so the benefit by including this the

882
01:44:59,160 --> 01:45:08,340
benefit by including this covariate in the model you're not compensated by the price you pay by using our data to estimate this additional data.

883
01:45:09,570 --> 01:45:18,000
So in other words, without including this, even though we know it's not a cracked model, even though it's not a perfect model,

884
01:45:18,660 --> 01:45:31,020
but it may be a very good approximation to the true and the parameter estimates may actually be more accurate then if you included this covariance,

885
01:45:31,260 --> 01:45:39,860
although you've got a true model here for me, you may not have estimate of parameter as well as we exclude as coverage.

886
01:45:40,370 --> 01:45:44,460
So so this is actually very common in practice.

887
01:45:44,670 --> 01:45:49,380
So the point is that all the models, they are an approximation to the truth.

888
01:45:49,470 --> 01:45:55,020
We are looking for the best approximation for the tools because we never know that the true model

889
01:45:55,740 --> 01:46:02,010
and this different criterion we are relying on to actually search for that best approximation.

890
01:46:02,550 --> 01:46:11,060
And so if you use different criteria and likely you end up with the different models, but that's okay.

891
01:46:11,070 --> 01:46:15,990
So as long as you can probably justify argument where we're defending your model,

892
01:46:16,380 --> 01:46:20,250
you have a rigorous way of searching for the model, then that is fine.

893
01:46:21,270 --> 01:46:26,070
Okay. Sorry guys that we run over. So yeah, I think this is the end of lecture.

894
01:46:26,080 --> 01:46:32,540
So I will next week will be transitions and the Order Flow Foundation will post that later today.

895
01:46:32,610 --> 01:46:40,950
So we just working that out. So and then the report is due, Bella is next Friday and on Friday night.

896
01:46:42,600 --> 01:46:46,090
So good luck transitioning on the report.

897
01:46:46,590 --> 01:46:50,370
Yes. What's the location of the presentations? Oh, it's in the auditorium.

898
01:46:50,970 --> 01:46:54,230
So we will we will have all around. There is the gathering. Oh, no.

899
01:46:57,990 --> 01:47:03,390
Oh, by the way, so if you guys haven't done so so please, please fill out the all the information.

900
01:47:04,790 --> 01:47:09,000
I want to do that because I.

