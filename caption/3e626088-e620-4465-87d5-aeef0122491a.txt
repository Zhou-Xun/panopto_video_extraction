1
00:00:00,690 --> 00:00:04,660
I know. I later found out.

2
00:00:05,190 --> 00:00:08,850
I was like, Oh, let's go.

3
00:00:09,290 --> 00:00:15,900
Are you going to the. You know, like so much of your time.

4
00:00:16,680 --> 00:00:28,500
All right. I have to say, I'm really sad, because I would also like to see, you know, not just,

5
00:00:28,770 --> 00:00:38,880
you know, convince me right now, because I just might want to watch my brother.

6
00:00:40,130 --> 00:00:45,970
Yeah. I just. I see what happens. I know.

7
00:00:49,850 --> 00:00:58,260
I got accepted. I got to do something, so maybe I'll be.

8
00:01:00,750 --> 00:01:08,489
Because basically, anything like that.

9
00:01:08,490 --> 00:01:14,730
And then it's like with me. I don't know if you think this is.

10
00:01:15,530 --> 00:01:21,210
I guess it's I feel like I was like. I think it was like like what I think.

11
00:01:21,520 --> 00:01:26,410
And I was like, well, let me just ask you.

12
00:01:27,810 --> 00:01:47,700
Like this and like this. And I was like, you know how even though it's like it's like it's unfortunate.

13
00:01:47,700 --> 00:01:56,640
It's like it's like you have a time warp drive in between words.

14
00:01:56,690 --> 00:02:27,950
So, you know, it's a very, very appealing to be able to do something else.

15
00:02:42,980 --> 00:03:27,730
Well, I think it's also something that I would like to stress that we have or I think it's clear last

16
00:03:27,730 --> 00:03:46,880
year that that was going to be a standardized way of improving competition testing and even like,

17
00:03:47,640 --> 00:04:09,260
you know, but at least back to where it was, like, well, you know,

18
00:04:10,360 --> 00:04:24,940
we think they're like 70 over 90 competitors, like from animals in Kansas, really close to 12.

19
00:04:37,100 --> 00:04:50,380
Because, you know, I know this week is all about making numbers meaningful.

20
00:04:51,490 --> 00:04:53,379
We've talked a little bit about numeracy.

21
00:04:53,380 --> 00:04:59,410
We've talked about labels, we've talked about visuals some degree, but we're going to bring those all together.

22
00:04:59,510 --> 00:05:07,150
The purpose of bringing them all together is to set you up for your next assignment, which is do next Monday.

23
00:05:07,690 --> 00:05:11,480
So the assignment is in the syllabus. It's all there already.

24
00:05:11,520 --> 00:05:13,120
You can take a look at it whenever you feel like it.

25
00:05:13,870 --> 00:05:25,870
The task is to create two letters, each of which is returning a test result to an individual recipient.

26
00:05:27,400 --> 00:05:32,170
One of those is about ending drinking water.

27
00:05:33,250 --> 00:05:42,860
The other is about CD4 count. It is a measure of a particular type of immune cell being.

28
00:05:44,090 --> 00:05:49,940
Goal of this is to have you back a goal that is not.

29
00:05:50,870 --> 00:05:55,820
To have you give people an education about these particular risks.

30
00:05:56,620 --> 00:05:57,740
Okay. I want to separate.

31
00:05:57,860 --> 00:06:05,810
We might, under different circumstances, want to be giving people background about these risks, information about remediation measures,

32
00:06:06,290 --> 00:06:10,519
all the kinds of things that we might do in health education to help people understand these risks.

33
00:06:10,520 --> 00:06:14,330
That is not your task. Your task is narrower.

34
00:06:15,760 --> 00:06:24,270
Giving them their result and you're helping them to understand whether their result is good or bad.

35
00:06:24,810 --> 00:06:30,030
Doesn't it make you want to then say, based upon this result,

36
00:06:30,030 --> 00:06:34,349
you should go look at this type of information to potentially find out or go talk to somebody?

37
00:06:34,350 --> 00:06:36,900
That's great, but that's not your task for this.

38
00:06:36,990 --> 00:06:46,440
And I'm focusing really narrowly in this assignment on the way in which you represent that test result and nothing else.

39
00:06:49,020 --> 00:06:55,910
So let's talk about today extensively the tools that you have available to you

40
00:06:56,880 --> 00:07:03,290
and make note of the numbers and when do we want to use them and when do we not?

41
00:07:04,290 --> 00:07:10,140
What are the pros and cons? What's the strengths and weaknesses of different approaches to impact numbers?

42
00:07:11,320 --> 00:07:12,540
I'm also going to get really,

43
00:07:12,540 --> 00:07:23,250
really micro you having you look at graphics and understand the specific features that people will pay attention to or not pay attention to,

44
00:07:23,630 --> 00:07:28,530
sort of a graphic sort of broadly last class. This class is where we're getting down to the weeds.

45
00:07:30,740 --> 00:07:37,700
Because the leaves matter. And it really does matter what you put into your graphic as to how somebody can

46
00:07:37,700 --> 00:07:47,530
interpret a felony just cause they're obviously going through this stuff today is.

47
00:07:48,470 --> 00:07:57,140
There is this class is basically a workshop class. We're not going to go through the stuff for the specific risks that are part of the assignment.

48
00:07:57,290 --> 00:08:03,860
I'm going to ask you to bring in another type of test result that you might be interested in communicating,

49
00:08:04,040 --> 00:08:08,150
but you can't use the ones that we're doing for the assignment you can bring anything else,

50
00:08:09,590 --> 00:08:20,870
could be environmental, could be a biomarker that's medical value, etc. It has to be quantitative, like not positive or negative, but like number.

51
00:08:22,040 --> 00:08:27,170
And now we're going to go through some exercises based upon the article actually read for today,

52
00:08:28,370 --> 00:08:33,199
all those steps, the different things that you need to know about that particular type of data.

53
00:08:33,200 --> 00:08:36,049
And we're going to do that in class and I'm going to circulate and we're going to sort of like,

54
00:08:36,050 --> 00:08:43,280
how do we think about figuring out how to make a particular type of data understandable to an audience that has not seen it?

55
00:08:47,350 --> 00:08:52,520
So let me just pause here. Any questions about what I'm looking for in this assignment?

56
00:08:57,890 --> 00:09:00,140
A few specific pieces of advice.

57
00:09:00,160 --> 00:09:09,440
One, and this is all in the syllabus, but I would just reiterate, but you must include a form of graphic on each letter.

58
00:09:09,950 --> 00:09:14,629
You can't just be a people. They're not just a table.

59
00:09:14,630 --> 00:09:28,650
Does not count as a graphic. We are going to talk about a lot today.

60
00:09:30,900 --> 00:09:37,620
Think about not just how you're representing there in number, but the whole space of possible numbers.

61
00:09:43,000 --> 00:09:48,040
But ultimately what I'm going to be looking for, and that is when I look at it,

62
00:09:50,080 --> 00:09:55,780
would a naive person, somebody who has never seen this type of test result before.

63
00:09:58,380 --> 00:10:02,610
They'll be able to answer the question if it's good or bad.

64
00:10:06,170 --> 00:10:11,970
Or neutral or how would they arrive at that understanding?

65
00:10:13,950 --> 00:10:24,000
There are a lot of tools available to you before we talk about how we use those tools to establish our goals and not overwhelm people.

66
00:10:24,720 --> 00:10:28,410
Like this is not necessarily a throw everything in the kitchen sink in situation.

67
00:10:29,220 --> 00:10:32,610
So there's choice and thought that needs to go into this process.

68
00:10:37,620 --> 00:10:45,390
I will say. This is sort of one of the skills I'm most hoping you take away from this course.

69
00:10:47,440 --> 00:11:00,220
We in our field, whether that's public health, whether that's in clinical medicine, whether that's in other kinds of fields where we have.

70
00:11:02,100 --> 00:11:04,830
You're not necessarily generating the data, although sometimes we are.

71
00:11:06,240 --> 00:11:13,710
We're not always the one who is literally face to face with the user, the patients, the community representatives, the policymakers.

72
00:11:14,580 --> 00:11:18,060
But we sit in that liminal space.

73
00:11:18,920 --> 00:11:30,170
Between the data and the humanity. The. It is our job to make those data mean something to the people who need it.

74
00:11:31,260 --> 00:11:39,140
This is what this part of this course is all about and all the tools that we have available to us to make that happen.

75
00:11:41,370 --> 00:11:46,260
And there's a lot of. Our. In that skill.

76
00:11:48,070 --> 00:11:51,370
Equipped you with tools that can be used for good and for bad.

77
00:11:53,340 --> 00:12:00,979
But. Part of what motivates me is the belief that there yeah, we we need to do a lot of science.

78
00:12:00,980 --> 00:12:05,750
We need to learn a lot of things to make the world a better place. We need to use what we already know.

79
00:12:07,470 --> 00:12:12,510
[INAUDIBLE] of a lot of science, both individual and collective.

80
00:12:12,550 --> 00:12:17,700
It doesn't get you because people don't understand what it means to change that.

81
00:12:20,000 --> 00:12:23,120
So that's the motivation for today. That's where we're going.

82
00:12:23,870 --> 00:12:33,170
Before I get into the specific examples that I've got, let's go through at least a few of the examples that you guys brought up in your writings.

83
00:12:34,160 --> 00:12:39,170
And the first one, it's kind of silly, but it's a nice place to set it up.

84
00:12:40,830 --> 00:12:44,990
Almost about mango. Yeah. So it goes like that.

85
00:12:46,100 --> 00:12:52,390
So a couple of weeks ago, I took for that just to get a check off the backs of a few pounds.

86
00:12:52,850 --> 00:12:56,320
And, you know, they didn't have to consume too much.

87
00:12:56,330 --> 00:13:01,190
I knew that demand was, like, a lot for a cat, and that was good.

88
00:13:01,190 --> 00:13:06,850
But and 2 hours after the appointment gave me his discharge summary, you know,

89
00:13:07,370 --> 00:13:11,930
they had all of his items and stuff like that and also containing the body condition score.

90
00:13:12,440 --> 00:13:20,140
But she got a five out of nine. I thought. What does a five out of nine mean?

91
00:13:24,160 --> 00:13:28,000
I mean, this is actually a useful point. What would you assume it would mean?

92
00:13:28,930 --> 00:13:32,610
At least five out of nine. Asked why?

93
00:13:35,100 --> 00:13:40,440
So like nine out of nine would be good, right? Okay. So the structure here matters.

94
00:13:40,440 --> 00:13:45,260
Like, what are we assuming the scale is representing? It could be that good.

95
00:13:45,270 --> 00:13:49,770
So nine would be good. One would be terrible. What else could this represent?

96
00:13:50,430 --> 00:13:53,150
Could be neutral. 509 is like halfway there.

97
00:13:53,160 --> 00:13:59,639
So a different way of thinking about this would be the heavier lighter five is somewhere in the middle so that maybe it's good, maybe it's not.

98
00:13:59,640 --> 00:14:07,380
But it's certainly what you're inferring is from a number of middle meanings from the what is it?

99
00:14:07,970 --> 00:14:15,000
Uh, w exactly so ideal, but so numbers four or five would be ideal.

100
00:14:15,360 --> 00:14:18,390
Why would it be two then. That would be obvious.

101
00:14:20,010 --> 00:14:26,460
So and then. So he was a five, but a six would be above ideal, which is like a little bit.

102
00:14:26,550 --> 00:14:30,630
It's like the number before overweight. So he's almost.

103
00:14:31,900 --> 00:14:40,300
Overweight and on son's like almost there. But I had to do a Google search to find the actual, like, body condition score.

104
00:14:40,350 --> 00:14:45,819
Like, the diagram didn't actually know what that meant because on the discharge summary

105
00:14:45,820 --> 00:14:50,320
just gave me a five out and I did not explain what that meant for anything.

106
00:14:50,770 --> 00:14:55,420
This is a perfect example of the problem you're getting, the results.

107
00:14:55,780 --> 00:14:59,560
You want to know what they mean, but the result itself does not give you the scale.

108
00:15:01,120 --> 00:15:08,980
So you had to go Google what the scale meant in order to figure out what that problem, how to calibrate yourself once you did.

109
00:15:09,430 --> 00:15:12,500
You got a lot of information from that. So notice what I mean.

110
00:15:12,590 --> 00:15:20,139
It was just talking about like it's not just knowing which category it's in, but you recognize the fact it was in the upper end of that category.

111
00:15:20,140 --> 00:15:26,020
So maybe it's on the borderline and you're taking away a lot of not an urgent response.

112
00:15:26,020 --> 00:15:33,130
But hey, you can't get any more of your truth, any more truthful kind of response.

113
00:15:35,320 --> 00:15:39,420
Useful. We should not do it right.

114
00:15:39,650 --> 00:15:45,370
We should if we're going to use that quantitative information, if I'm going to provide it to you as the in this case,

115
00:15:45,580 --> 00:15:50,230
patient representative, it should be transparent what that means.

116
00:15:51,310 --> 00:15:55,150
Now, there are multiple ways we could have do that. Why the heck is this a number score in the first place?

117
00:15:56,120 --> 00:16:02,499
Is that valuable to have phrased it in a number of forms, and you may or may not, we could have that conversation.

118
00:16:02,500 --> 00:16:06,310
But but notice we you know, there's a question, why are we using a number here?

119
00:16:07,420 --> 00:16:15,069
This, by the way, also that part of the problem here is that the clinicians may derive automatic information

120
00:16:15,070 --> 00:16:20,920
when they hear a five out of nine because they're hearing this scale multiple times a day,

121
00:16:21,040 --> 00:16:26,560
over and over again. They're trying to think about it. It's instantly understandable to them.

122
00:16:27,040 --> 00:16:30,850
It's not instantly understandable because most of the people who are being given to.

123
00:16:32,080 --> 00:16:42,060
So there is the disconnect. Another example, probably 60 decibels.

124
00:16:42,340 --> 00:16:52,899
Yes. So I listen to music on my phone a lot of the day and my phone like tracks like how many decibels?

125
00:16:52,900 --> 00:16:56,080
I'm like listening to it under like the health app, like iPhone.

126
00:16:57,000 --> 00:17:01,720
And so I was like looking it up, I'm like, oh, 60 decibels. I have no idea what that means.

127
00:17:02,920 --> 00:17:09,760
But luckily, right under that number that it provides, there's like this article level of decibels.

128
00:17:10,060 --> 00:17:13,630
So I looked at it and there's like actually like a really good infographic and it was,

129
00:17:14,350 --> 00:17:19,740
it would give you like certain ranges of decibels and what they're comparable to.

130
00:17:19,750 --> 00:17:27,490
So like 30 to 39 decibels is like whispering I think be like seven.

131
00:17:27,520 --> 00:17:35,200
These were like allowed conversation like in the sixties was like a regular conversation.

132
00:17:35,650 --> 00:17:42,100
In the eighties, it was like a loud restaurant. And then once you get over 100, that's more like an ambulance siren.

133
00:17:44,380 --> 00:17:48,820
So that really helped me like, kind of like put it in perspective, like, oh, okay.

134
00:17:48,820 --> 00:17:50,830
I'm not, like, listening to my music too loud.

135
00:17:51,310 --> 00:18:00,310
Now, when you went looking for that, it was not provided at the same place as your numbers, but you had to go look it up, correct?

136
00:18:00,940 --> 00:18:06,610
It was like a link right under it. So you do you did have to click it and like I'm curious about it.

137
00:18:07,090 --> 00:18:11,229
So another piece I want to highlight here is there's a difference between that having that

138
00:18:11,230 --> 00:18:16,990
skill available and having it presented at the same time that the data is being presented.

139
00:18:18,550 --> 00:18:22,990
So there are lots of situations in which we use legends, like you can look up what this means.

140
00:18:24,160 --> 00:18:32,020
But if we want to think about reducing the cognitive barriers and enabling people to derive as much meaning as possible from the results,

141
00:18:32,530 --> 00:18:36,460
you shouldn't have to click on a link. You shouldn't have to look someplace else. It should be right there.

142
00:18:38,130 --> 00:18:44,610
So another component of what we ought to be thinking about is how do we minimize the amount of physical effort,

143
00:18:44,610 --> 00:18:50,040
cognitive effort, etc., that we have to go through in order to get the meaning of the data?

144
00:18:51,870 --> 00:18:55,949
Yeah, it's kind of curious. How do you feel logarithmic scales represented?

145
00:18:55,950 --> 00:19:02,270
Because it's kind of inherently not intuitive. I mean, so noise is analog scale, so is earthquakes like Richter scale.

146
00:19:02,280 --> 00:19:08,770
And so normalizing when people think it's like, Oh, it's ten points higher, but it's actually would be like a thousand points higher.

147
00:19:08,790 --> 00:19:11,160
So this is a great question.

148
00:19:11,220 --> 00:19:17,280
There are a few, but also the ones you just listed are some of the most common logarithmic scale, although they do pop up someplace else.

149
00:19:19,470 --> 00:19:32,280
I have a complicated answer and it's really driven by the recognition that different people have different needs.

150
00:19:34,070 --> 00:19:44,230
So. A scientist of any type has to understand when they're facing a Olivia relationship or an exponential relationship.

151
00:19:45,570 --> 00:19:53,990
So. You know, I'm making a graphic that has anything to do with.

152
00:19:56,310 --> 00:20:00,810
I want to communicate risk. I want to communicate some kind of severity, magnitude.

153
00:20:01,230 --> 00:20:10,200
It's got to show that exponential relationship, because otherwise we're inferring something from the linearity of space that is not actual.

154
00:20:12,510 --> 00:20:19,500
Most people don't actually have to interact with it at that fine level.

155
00:20:19,650 --> 00:20:22,890
And Emily's example is actually a beautiful example of this.

156
00:20:23,340 --> 00:20:29,940
Like, you don't need to know precisely how much larger, how much louder.

157
00:20:31,110 --> 00:20:37,110
75 decibels is. What's a 60 doesn't need to know is to calibrate.

158
00:20:38,010 --> 00:20:42,240
So notice what was done. Emily got anchor points.

159
00:20:43,140 --> 00:20:47,340
This is equal to that. This is equal to this. This is equal to this.

160
00:20:47,790 --> 00:20:55,319
And as long as those anchor points are well calibrated, you're already doing the exponential relationship in your mind unconsciously.

161
00:20:55,320 --> 00:20:58,440
Like you're going from, oh, wait a second. A normal conversation.

162
00:20:58,440 --> 00:21:02,790
Like what we're having here. To a ambulance siren.

163
00:21:04,300 --> 00:21:11,410
It's only 40 decibels worth a change, but in your mind you're going, well, those are really different things, which is accomplishing that goal.

164
00:21:12,730 --> 00:21:22,030
So this is a situation in which, rather than worrying about quantitative precision, providing those reference points accomplishes the goal.

165
00:21:22,840 --> 00:21:28,570
And if you look at, um, you know, in many ways that's the way I think.

166
00:21:28,590 --> 00:21:33,280
I mean, I grew up in California. I'm very familiar with the Richter scale from thinking about earthquakes.

167
00:21:34,900 --> 00:21:39,090
I.A., I don't really understand the exponential relationship.

168
00:21:39,100 --> 00:21:42,980
What I know is. You know, I don't feel a four.

169
00:21:43,130 --> 00:21:49,250
Usually a five and a half things are moving, but not, you know, stuff might fall off a shelf.

170
00:21:49,250 --> 00:21:55,370
But I'm not really freaked out. Anything over six is causing some damage and a seven is a catastrophe.

171
00:21:57,140 --> 00:22:04,730
And that's pretty much all I'm remembering. But it's enough that if I hear that there's a three part earthquake, I'm like, Who cares?

172
00:22:05,300 --> 00:22:13,810
And if I hear that it's a 6.5, I'm like, Whoa. I think it's enough to calibrate what I need to do with the data.

173
00:22:14,200 --> 00:22:18,380
So that's my answer to this, is that maybe we don't worry when we're talking about the audiences.

174
00:22:18,400 --> 00:22:23,530
I mean, I worry unnecessarily about. Visually showing that curve.

175
00:22:23,600 --> 00:22:26,710
We show that what we care about is giving them really good reference points.

176
00:22:27,640 --> 00:22:33,430
Thank you. Yeah, it's a great question and something that we run up against on an ongoing basis so far.

177
00:22:33,610 --> 00:22:39,129
Let me give you a concrete example. This is a minor, minor detour.

178
00:22:39,130 --> 00:22:51,160
But if you want to have a minor detour into exponential relationships.

179
00:22:59,140 --> 00:23:03,640
Imagine the people, one of them.

180
00:23:04,000 --> 00:23:08,280
They're both the same age and generally very similar health.

181
00:23:08,290 --> 00:23:12,000
Like I want you to treat these as two essentially equivalent people in this hypothetical one.

182
00:23:12,670 --> 00:23:15,340
Let's start with two people that are basically the same except.

183
00:23:16,550 --> 00:23:23,420
Blood pressure, and I'm only gonna work with the top number of the systolic number here just to make life simple.

184
00:23:23,720 --> 00:23:31,190
But the basic principle applies a person a.

185
00:23:32,950 --> 00:23:36,130
As a 70.

186
00:23:41,200 --> 00:23:52,570
Personally, I pressure one. So easy question, who is at greater cardiovascular risk?

187
00:23:52,840 --> 00:23:58,930
Okay. It's like this is easy. We know that blood pressure is related to cardiovascular risk.

188
00:23:58,930 --> 00:24:03,070
We don't necessarily have to know details. We know higher is bad.

189
00:24:04,450 --> 00:24:07,480
170 is higher than 150. Straightforward.

190
00:24:08,250 --> 00:24:12,380
Yeah. They both side.

191
00:24:12,700 --> 00:24:22,020
They're going to try and reduce the blood pressure. So they go off and they both think their diet and exercise.

192
00:24:22,780 --> 00:24:28,330
Otherwise before being to try and reduce about how about a month, let's say three months later.

193
00:24:29,780 --> 00:24:35,720
And the person was about 70 down to 150.

194
00:24:36,700 --> 00:24:40,390
And the person who wasn't 150 is down to 130.

195
00:24:41,380 --> 00:24:46,770
I've. So in both cases, they have reduced.

196
00:24:47,830 --> 00:24:51,250
The blood pressure by an absolute difference of 20.

197
00:24:52,730 --> 00:24:56,120
Here's the question. Who reduced their risk?

198
00:24:56,750 --> 00:25:00,870
Most. Person A what?

199
00:25:01,790 --> 00:25:07,550
Because they were at a higher risk to begin with. And so the difference in even though the magnitude is the same.

200
00:25:10,580 --> 00:25:13,850
I can see how you can argue the other way now that I'm saying it out loud.

201
00:25:13,850 --> 00:25:19,700
But I think it's because the person that was at such high risk to begin with, they dropped down to a lower risk.

202
00:25:20,180 --> 00:25:26,830
That difference was bigger than the change in B, even though they were also at risk and dropped down to a secret.

203
00:25:26,870 --> 00:25:35,630
So this is complicated, right? So now we're getting into what is the relationship between the level of the number and the risk.

204
00:25:37,580 --> 00:25:44,030
Anybody want to argue that it's the same? You would argue that the person be reduce the risk of most.

205
00:25:46,240 --> 00:25:50,830
Yeah. I just think like in terms of like blood pressure management guidelines,

206
00:25:50,830 --> 00:25:59,770
we usually try to get to a goal of 130 or less because yeah, we're for health outcomes, cardiovascular risk factors.

207
00:25:59,770 --> 00:26:04,810
So noticeably that just the low end, would you say you set a target goal?

208
00:26:04,930 --> 00:26:09,669
Yeah, this person is probably at that goal.

209
00:26:09,670 --> 00:26:14,770
Like wherever we set the line, 130 is often a line that we target for blood pressure, systolic blood pressure.

210
00:26:14,770 --> 00:26:19,290
So this person is at goal. This person is not. Okay.

211
00:26:19,500 --> 00:26:23,490
I started here and this is totally obvious. A is at higher risk than B we're not arguing about.

212
00:26:23,500 --> 00:26:26,970
This is very straightforward. But the question here becomes.

213
00:26:28,190 --> 00:26:34,280
Does the fact that this person got the goal, meaning that they did a financial risk reduction.

214
00:26:36,180 --> 00:26:40,320
We're not. If this is still confusing.

215
00:26:40,770 --> 00:26:50,910
Let me give you a different version of the same problem. Let's imagine a person a smoked two packs a day.

216
00:26:52,740 --> 00:26:59,400
I personally smoked one pack a day and they both tried to cut back how that they smoke.

217
00:27:00,460 --> 00:27:05,200
And this person went down to one and a half trucks. And this person has a crack at it.

218
00:27:06,630 --> 00:27:13,070
Which person reduced the risk of lung cancer the most? I would still argue person.

219
00:27:13,190 --> 00:27:17,929
I mean, smoking obviously is bad, but there's food you can plant in the curb.

220
00:27:17,930 --> 00:27:22,550
I mean, I don't know if at the data, but one cigaret is definitely less bad than ten.

221
00:27:22,760 --> 00:27:29,660
And so somewhere along that function they reduce. So the key question here is what's the relationship between risk?

222
00:27:31,180 --> 00:27:36,420
And whatever number we have down here, this could be systolic blood pressure.

223
00:27:36,460 --> 00:27:39,820
This could be number of cigaret, smoke, etc.

224
00:27:41,840 --> 00:27:46,159
If it's linear. It doesn't matter what he is.

225
00:27:46,160 --> 00:27:55,370
2010 Cigarets is ten Cigarets, but both smoking risk and blood pressure risk is exponentially.

226
00:27:56,570 --> 00:28:00,990
And so when you're out here. This one.

227
00:28:04,090 --> 00:28:07,600
One computer here is a big drop.

228
00:28:08,670 --> 00:28:12,900
Going from here to here is a draw, but it's not as big.

229
00:28:15,950 --> 00:28:20,540
Even though the person got to go.

230
00:28:24,900 --> 00:28:26,130
Let's think about that for a second.

231
00:28:27,190 --> 00:28:34,709
And this is challenging because what it means is that is it really the case of somebody going from two packs a day,

232
00:28:34,710 --> 00:28:40,830
one pack a day is helping their risk more than somebody who goes to one pack a day to quit.

233
00:28:46,380 --> 00:28:50,840
All right. This would argue. Yes. Isn't this the whole idea of harm reduction?

234
00:28:51,180 --> 00:29:00,260
Yes. Yes, it is. But notice how many of our conversations are not about reducing the extremes.

235
00:29:00,560 --> 00:29:01,700
They are about getting to goal.

236
00:29:03,070 --> 00:29:10,300
Whether we're talking about quitting smoking, whether we are talking about giving blood pressure to goal, setting weight to goal.

237
00:29:10,570 --> 00:29:16,170
All of these biomarkers. If the underlying relationship.

238
00:29:17,100 --> 00:29:23,960
Is exponential. Getting that last step to go buys us actually relatively little.

239
00:29:25,360 --> 00:29:29,660
The people who really are at risk are the ones who are at the extremes.

240
00:29:30,380 --> 00:29:35,280
The more extreme they are. It's not just linearly, but exponentially.

241
00:29:35,300 --> 00:29:42,920
The more risk they face and the more benefit they can receive by taking even incremental steps in reducing that rate.

242
00:29:45,940 --> 00:29:54,820
This is not the way we often talk. There's a lot of language in the way in which we talk about weight, about what kind of about cholesterol.

243
00:29:55,300 --> 00:30:00,280
It is about cool, cool, cool is what matters. It's the only thing that counts for a clinician.

244
00:30:01,120 --> 00:30:07,320
You won't talk about problems from incentives. If clinicians are rewarded for the percentage of their patients who get to goal,

245
00:30:08,670 --> 00:30:14,680
then the person who goes from 170 to 150 doesn't buy them anything in their performance evaluation.

246
00:30:15,190 --> 00:30:20,020
But the person who goes from 150 to 130 does. That's no problem.

247
00:30:23,740 --> 00:30:30,420
All right. So this was a useful but substantial point.

248
00:30:30,500 --> 00:30:39,990
So let me. Yvonne for her. Thinking of all of these types of things.

249
00:30:40,650 --> 00:30:53,580
I thought, Drew, you were talking about cholesterol or so and and the sort of like, well, how do I calibrate myself?

250
00:30:53,580 --> 00:30:56,820
I have the number, but I'm not sure I know what I'm supposed to think about this number.

251
00:30:57,540 --> 00:31:04,560
Yeah. So it's actually for cholesterol. And so for cholesterol, it is less than or equal to 200.

252
00:31:04,950 --> 00:31:07,959
And I was at two or two for white blood cell count.

253
00:31:07,960 --> 00:31:11,120
It was 3.8 to 10.8 and I was at 3.4.

254
00:31:11,970 --> 00:31:16,920
So like the rest was green and it also have like the range.

255
00:31:16,920 --> 00:31:20,760
But to me that still didn't matter because I'm like, what does this mean to me?

256
00:31:21,030 --> 00:31:26,249
Like is that really high like risk for like the cholesterol and the white blood cell count?

257
00:31:26,250 --> 00:31:32,700
Or is it like so close that it doesn't matter? So I was confused on like what I needed to do.

258
00:31:32,880 --> 00:31:42,090
Right. And so notice the key question here is if the categorization scheme that is being given to you so red versus green is essentially a binary,

259
00:31:42,090 --> 00:31:45,629
you're good, you're not good is triggering.

260
00:31:45,630 --> 00:31:48,270
This is bad. What are you supposed to take away from that?

261
00:31:48,860 --> 00:31:55,380
And this could be anything from how you should talk to somebody about this and figure out what's going on.

262
00:31:55,890 --> 00:32:01,950
Do you need to be taking immediate action and going to an emergency department?

263
00:32:02,640 --> 00:32:09,030
Obviously not the latter. But you're right, it's not telling you where you fall on that spectrum.

264
00:32:09,850 --> 00:32:13,540
And of course, this is going to be different for different types of situations, for different people.

265
00:32:15,870 --> 00:32:25,550
That. There's both the absolute risk and the sense of what is the cardiovascular risk that might be associated with that two or two lateral?

266
00:32:26,890 --> 00:32:30,160
And then there's the historical question.

267
00:32:30,550 --> 00:32:33,800
If your cholesterol six months earlier had been 160.

268
00:32:36,230 --> 00:32:44,210
You might want to tell you pay attention, not because you're at 202, but because you've gone up 42 points in the last six months, which is a lot.

269
00:32:46,150 --> 00:32:56,840
And calibrating, being able to notice that. The reason I wanted to bring up Audrey's example is because we often emphasize when we're

270
00:32:56,840 --> 00:33:01,430
thinking about communicating numbers like how well people respond when it's really bad.

271
00:33:02,180 --> 00:33:06,290
Yes, I want to make sure that when a number is really bad that they notice that.

272
00:33:07,130 --> 00:33:11,150
But equally as important is those tipping point ones.

273
00:33:12,980 --> 00:33:16,490
That is the person that this is example.

274
00:33:17,060 --> 00:33:21,130
You recognize that? Well, I don't know what is in the ideal way.

275
00:33:21,140 --> 00:33:23,510
They were right on the edge of the ideal weight.

276
00:33:25,430 --> 00:33:32,740
You recognized that while you were cholesterol level and were outside of the normal range, they weren't that far outside of Earth.

277
00:33:32,770 --> 00:33:37,090
And by the way, that far is a very judgment call.

278
00:33:37,320 --> 00:33:42,100
Like, how does one know? Well, I guarantee you, your clinician does.

279
00:33:43,350 --> 00:33:53,790
Because the training that's involved involves understanding essentially how much to respond to different levels of each number.

280
00:33:55,590 --> 00:33:57,780
We as an audience don't necessarily get that.

281
00:33:58,590 --> 00:34:05,160
So the push here is how do we present that type of information in a way that calibrates people to what it means?

282
00:34:09,340 --> 00:34:14,020
On to one last one on this Israeli. You're talking about your dad, if I remember.

283
00:34:14,170 --> 00:34:21,820
What about blood pressure? Yes. So he's been having some so back surgery.

284
00:34:22,450 --> 00:34:27,010
He already has cardiovascular issues, to be honest. So antidiabetic.

285
00:34:27,670 --> 00:34:31,830
So this past summer, he's been having some serious blood pressure issues where I don't like.

286
00:34:32,410 --> 00:34:38,550
[INAUDIBLE] get super dizzy and almost pass out and get very nauseous.

287
00:34:38,560 --> 00:34:43,000
So we started going to the doctor, see what they could do if put him on some different medications.

288
00:34:43,010 --> 00:34:48,510
And has it worked so that his doctor recommended that he just like it and monitor?

289
00:34:49,850 --> 00:34:53,020
My dad is very not tech savvy at all,

290
00:34:53,020 --> 00:35:05,380
so we had a walk through how to use it and essentially he could take it himself and with no reference to what the numbers meant.

291
00:35:05,770 --> 00:35:08,770
I thought it was really nice that the box, not the box,

292
00:35:08,770 --> 00:35:18,610
but the device would flash like green when his blood pressure was okay blue if it was like super low or yellow when he was getting high,

293
00:35:18,610 --> 00:35:21,940
and then it would flash red when he was like super high, he should contact us.

294
00:35:24,130 --> 00:35:36,100
So the reason I want to bring up your example is notice the who has the power to control your dad's reaction to the blood pressure.

295
00:35:36,910 --> 00:35:46,510
His blood pressure levels. The device manufacturer, what they chose to set as the thresholds for what gets read,

296
00:35:46,510 --> 00:35:52,330
what gets orange, what gets yellow, what gets created, etc. is determining the outcome here.

297
00:35:54,900 --> 00:36:04,250
But that's an arbitrary choice that we might collectively as a society, as a group of medical professionals and health professionals,

298
00:36:04,250 --> 00:36:10,580
say, hey, we want to categorize values that are, let's say, about 160 as read.

299
00:36:11,240 --> 00:36:15,170
Again, I make it up that number. Maybe that's different than the number that we ought to be there.

300
00:36:15,350 --> 00:36:22,640
But that's the point. We don't have any attention to what the number is that pay attention to the color.

301
00:36:22,850 --> 00:36:24,670
That's the only thing he's paying attention to.

302
00:36:26,210 --> 00:36:34,380
And that's maybe okay in the sense that that's sufficient level of detail to allow him to know, Hey, what am I doing?

303
00:36:34,400 --> 00:36:40,130
What happened today? What happened yesterday? Did I remember my medications, etc., and to make appropriate changes.

304
00:36:41,030 --> 00:36:44,450
But he's not going to pick up any variation within those categories.

305
00:36:45,050 --> 00:36:53,420
Like if it comes back yellow today and yellow tomorrow, even if those numbers were off by ten or 15, he didn't notice that.

306
00:36:53,870 --> 00:37:00,380
He's just noticing there was yellow. So we're losing a lot of granularity in that.

307
00:37:01,550 --> 00:37:07,460
Okay. If you're the doctor, know that your dad maybe.

308
00:37:08,610 --> 00:37:10,560
Because maybe it doesn't matter at that stage.

309
00:37:12,790 --> 00:37:18,490
I'm not necessarily arguing that when we're communicating test results, we're trying to turn people into mini health professionals.

310
00:37:19,090 --> 00:37:26,980
What we're trying to do is to meet their needs and their needs might be binary, okay or not, their needs might be categorical.

311
00:37:27,910 --> 00:37:34,360
Pretty much the way your father is responding to the blood pressure, their needs might be a more nuanced and depending upon the situation.

312
00:37:36,420 --> 00:37:40,860
And it's that question that really should be to one of these proceedings.

313
00:37:45,000 --> 00:37:49,350
So I show a couple graphic examples.

314
00:37:50,540 --> 00:37:57,109
But I'm going to take us back for a moment more about probabilities in these quantities,

315
00:37:57,110 --> 00:38:02,899
because I want to set up where we're going in terms of audience and these are all graphics you've seen before,

316
00:38:02,900 --> 00:38:05,240
but I'm just going to talk the talk through them in detail.

317
00:38:16,730 --> 00:38:26,950
So this is the bar chart that we saw last class about sleep quality, where the same percentage is the percentage and it's complement.

318
00:38:26,970 --> 00:38:37,970
So we have the 71% had 14 or fewer days where they felt they did not get enough good sleep and 29% if they got 1 to 14 days.

319
00:38:39,720 --> 00:38:45,210
I think the labels I put in here are wrong, but that's okay. Here is the same percentage.

320
00:38:47,760 --> 00:38:52,140
You know, I tried to read format 7129.

321
00:38:57,170 --> 00:39:10,990
What's different here? How do these trees end up evoking the same understanding or different understanding?

322
00:39:13,860 --> 00:39:18,090
There's no single right answer here. I just want to share your reflections.

323
00:39:19,130 --> 00:39:27,240
Yeah, I think with the right, it's very easy to see a hole to understand the proportions.

324
00:39:27,840 --> 00:39:33,270
Whereas, like in the bar chart, the y axis stops at 80 and it's hard to.

325
00:39:34,280 --> 00:39:42,610
Understand that these two are complements to each other. And then the other thing that my eye is drawn to is the 71% comes first,

326
00:39:42,620 --> 00:39:49,459
whereas like my eye is drawn to the 30 or the 29 and iconic, I notice that that's a choice.

327
00:39:49,460 --> 00:39:57,380
Like we could have set this up with the 29 down here, the 71 on top, whichever one you would have gone more to focus your eye on.

328
00:39:57,950 --> 00:40:06,950
By the way, notice also that choice of a color matter a lot like I could make the 71.

329
00:40:08,070 --> 00:40:12,660
This bright blue and turn that 29 inch sort of faded gray.

330
00:40:12,660 --> 00:40:16,930
And you would zoom in on the 71. Or vice versa.

331
00:40:19,070 --> 00:40:22,340
But I just bring up a really critical piece here.

332
00:40:24,630 --> 00:40:29,600
What is the possible range of a probability? Know.

333
00:40:30,770 --> 00:40:35,790
100. Can't have in this kind of contract.

334
00:40:35,820 --> 00:40:39,720
We're not talking about relative probability. We're talking about absolute rates.

335
00:40:40,290 --> 00:40:50,020
You cannot have a probability of 110. So a graphic.

336
00:40:50,410 --> 00:40:55,300
This could be a snack bar. We could have taken this piece here and put it up here.

337
00:40:56,340 --> 00:40:58,200
And you would have gotten something which, by the way,

338
00:40:58,200 --> 00:41:03,900
it looks about the same height and about the same at the same proportions as the icon array over here.

339
00:41:03,910 --> 00:41:11,920
Wouldn't be that hard to do it. But a probability is inherently founded.

340
00:41:14,880 --> 00:41:23,280
Look, there's no arrows here at the bottom or the top of this bar because it's the proportion, you know, the absolute width.

341
00:41:25,330 --> 00:41:30,310
What we're representing in these types of graphics is the data itself.

342
00:41:31,090 --> 00:41:36,760
The taller the bar, the bigger the number, the more I count, the bigger the number.

343
00:41:39,290 --> 00:41:43,220
Very different than the types of graphics I show you in a moment.

344
00:41:43,930 --> 00:41:49,930
We're often representing quantities. So one of the key things to think about when we're talking about graphics of data is,

345
00:41:50,570 --> 00:41:58,580
is the graphics showing the magnitude of the data or is the graphics showing the space of possible data?

346
00:42:00,720 --> 00:42:03,870
And then you place that number within that possible space.

347
00:42:04,950 --> 00:42:08,610
These graphics are both showing the data. More icons equals more risk.

348
00:42:13,580 --> 00:42:17,180
This is showing the space of the data.

349
00:42:20,930 --> 00:42:26,660
I'm going to plant a lot of features here, which would be your unconsciously processing all matter.

350
00:42:27,620 --> 00:42:31,680
One. Range.

351
00:42:33,430 --> 00:42:38,500
Four zero. Why is this not zero?

352
00:42:39,690 --> 00:42:43,200
Because if your hemoglobin is zero, you are dead.

353
00:42:43,690 --> 00:42:52,140
But if you do not observe hemoglobin A1, see values of zero in any practical context.

354
00:42:54,060 --> 00:42:59,880
So allow the graphic to go down to zero is distorting your perception.

355
00:43:01,710 --> 00:43:05,460
By making you think that that value is possible when it is not.

356
00:43:12,060 --> 00:43:15,280
Nine. Now, here's an interesting question.

357
00:43:15,280 --> 00:43:19,330
Why is it not? Or more to the point, how would you think about.

358
00:43:19,450 --> 00:43:30,620
What should the value be for the top end of this graph? Based on the fact that there's no zero autism passed nine, he said.

359
00:43:30,650 --> 00:43:37,670
However, that might not be able to claim that it is possible to have hemoglobin ANC values higher than that.

360
00:43:37,850 --> 00:43:42,950
But you're asking the right question, like, what should I, what should I be taking away from where that point is ended?

361
00:43:44,740 --> 00:43:48,819
Is this the range of possible values?

362
00:43:48,820 --> 00:43:54,580
Like is it possible to go past here back to this in a second,

363
00:43:54,580 --> 00:44:01,900
but just pause here and reflect on how critical it is that you are paying attention to what the scale is here.

364
00:44:02,860 --> 00:44:07,660
If you don't pick up what the end points are, you are not actually processing.

365
00:44:10,030 --> 00:44:16,160
Yeah. You.

366
00:44:18,270 --> 00:44:24,890
Is there an arrow? It's not that at all.

367
00:44:24,900 --> 00:44:33,180
Peace here is that there can extend beyond this range.

368
00:44:33,210 --> 00:44:38,910
So whatever it is, it is not a hard end point, you write.

369
00:44:39,300 --> 00:44:44,070
In theory, you could get values higher than not in theory to get out of lower than fourth.

370
00:44:45,600 --> 00:44:54,450
So it matters. Let's think about other lower values it would be useful to think about.

371
00:45:08,060 --> 00:45:17,400
Well, temperature. I do want to make a graph like this for today's temperature.

372
00:45:17,670 --> 00:45:23,549
We have arrows because it can, in fact, get really cold and it can, in fact get really hot.

373
00:45:23,550 --> 00:45:31,140
Even though we probably wouldn't show a graphic going up to, let's say, 150 degrees Fahrenheit,

374
00:45:31,410 --> 00:45:35,399
we probably wouldn't show a graphic going down to -100 degrees Fahrenheit,

375
00:45:35,400 --> 00:45:41,250
because in the kinds of spaces that we live as humans, we don't get those kinds of temperatures.

376
00:45:44,860 --> 00:45:52,160
That's important. What did I just do there?

377
00:45:54,750 --> 00:45:58,180
This is part of his dad's problem. I.

378
00:46:00,160 --> 00:46:05,180
Here. I value my perception.

379
00:46:05,270 --> 00:46:11,420
Here is my result. It's really obvious where I am. What am I going to compare myself against?

380
00:46:12,770 --> 00:46:15,770
I think I'm going to compare myself against the standard range.

381
00:46:16,370 --> 00:46:21,500
And what else? The actual distance.

382
00:46:22,230 --> 00:46:29,540
Yeah. So you're going to be visually measuring like, wow, that's this far away from whatever sense in the sense that Audrey was thinking like,

383
00:46:29,840 --> 00:46:35,870
I'm outside of the green, but how far I'm going to be driven by that visual distance.

384
00:46:38,900 --> 00:46:42,720
There's another key piece here. What else can I compare myself against?

385
00:46:49,750 --> 00:46:53,700
We've just been talking about it for the last 5 minutes. To the maximum.

386
00:46:55,110 --> 00:46:58,980
To the maximum. I mean, to nine yards.

387
00:46:59,910 --> 00:47:03,630
We are unconsciously measuring this distance.

388
00:47:05,470 --> 00:47:12,380
And this distance. By the way, I have asked to have qualitative data on this.

389
00:47:12,650 --> 00:47:15,050
We've done interviews with people getting graphics like this.

390
00:47:15,680 --> 00:47:26,480
If more result is older, people start using language like I'm going to fall off the end, I'm getting close to the edge,

391
00:47:27,140 --> 00:47:33,049
etc. literally using the language of space to describe the meaning of risk that

392
00:47:33,050 --> 00:47:37,460
they're deriving from the graphic in metrics that here you're in the middle,

393
00:47:38,090 --> 00:47:43,830
like this is a safe space. Edges are not safe spaces.

394
00:47:44,870 --> 00:47:51,740
And so whether your value drops into the edge or the middle changes the feeling someone's going to get the from.

395
00:47:56,410 --> 00:48:00,100
Now we can push this by categorizing.

396
00:48:01,250 --> 00:48:07,569
Yeah. Using a stoplight graphic here, because we have a lot of emotional meaning in this culture tied up with red,

397
00:48:07,570 --> 00:48:14,680
yellow, green type of [INAUDIBLE] type of categorization. But there's also words here like borderline high, high, very high, etc.

398
00:48:15,480 --> 00:48:20,200
For that being noticed, by the way, this is not in some separate legend.

399
00:48:21,570 --> 00:48:37,230
I think those labels are right next to the Rangers. Anyway, when I first started doing this project, we did a study looking at the color scheme.

400
00:48:38,620 --> 00:48:46,059
There are differences in whether or not you use red, red, yellow, green versus shades of a single color versus black and whites,

401
00:48:46,060 --> 00:48:55,000
etc. There is meaning that comes from that and there is both positives and negatives to using this red, yellow, green color scheme.

402
00:48:56,770 --> 00:49:07,420
To quote one of the patients who we were working with at the time, if your value makes you feel like you're a bad patient.

403
00:49:11,980 --> 00:49:20,470
That's not always a good thing. The pinpoint of maintaining patient autonomy, encouraging somebody to keep going.

404
00:49:22,510 --> 00:49:29,650
Like it is what you want to convey is danger to action.

405
00:49:31,030 --> 00:49:35,830
So color is powerful. Use it, but use it intentionally.

406
00:49:38,020 --> 00:49:46,250
One other thing I want to show you. This is the same number.

407
00:49:47,570 --> 00:49:52,330
Same categories. It's not the same.

408
00:49:56,270 --> 00:50:03,130
So what did I do here? This one is up to nine.

409
00:50:04,210 --> 00:50:09,070
This one goes from 3 to 13. All they do is change the scale.

410
00:50:10,390 --> 00:50:14,130
But. My guess is.

411
00:50:15,640 --> 00:50:23,630
You're more worried here than you are here. Because all these visual cues.

412
00:50:24,790 --> 00:50:30,640
You're unconsciously processing left to right, you're processing the visual distance from the green.

413
00:50:32,410 --> 00:50:36,730
It's still labeled high. Everything is still proportionate.

414
00:50:39,330 --> 00:50:40,580
It's not the same as response.

415
00:50:42,480 --> 00:50:50,620
So if you're going to be showing, as you will be for your assignment coming up on Monday, you're going to be showing result.

416
00:50:51,360 --> 00:50:54,600
A key question is, what's the scale?

417
00:50:55,260 --> 00:51:02,640
How big of a range do you want to be showing? Because it's going to change how responsive people feel to a difference.

418
00:51:03,210 --> 00:51:07,200
By the way, I use the hemoglobin I want to see as an example for an important reason.

419
00:51:07,440 --> 00:51:14,460
I notice that these are all percentages, the percentages that range in a really narrow range.

420
00:51:15,430 --> 00:51:18,760
But if I put this on a 0 to 100, it would be stupid.

421
00:51:20,000 --> 00:51:26,100
Make no sense. We would never see that in real world. But I also know.

422
00:51:27,430 --> 00:51:31,750
But from the standpoint of managing, say, diabetes, type two diabetes.

423
00:51:33,070 --> 00:51:38,980
If you change your hemoglobin and let's see a half a percentage point, point 5%.

424
00:51:40,160 --> 00:51:50,380
That's a clinically significant change. So we're stuck with this trade off between I give you this.

425
00:51:51,190 --> 00:51:54,640
It makes each seem bigger.

426
00:51:55,510 --> 00:51:59,770
That might be a really good thing. I want somebody to notice if they're here versus here.

427
00:52:00,400 --> 00:52:05,650
Also notice if they're here versus here. That might be an important thing to be reinforcing.

428
00:52:06,810 --> 00:52:16,700
On the other hand. I use this scale and I test somebody who's got really uncontrolled diabetes and their value is ten.

429
00:52:17,780 --> 00:52:26,670
What do you want to do? I'll tell you what the hospital system does.

430
00:52:29,070 --> 00:52:33,360
I don't know if you I know what Michigan Medicine does in their patient portal.

431
00:52:33,810 --> 00:52:37,300
I don't know whether this is true in every version of these portals out there.

432
00:52:37,350 --> 00:52:41,610
So I'm going to describe what you actually see in this new medicine.

433
00:52:48,620 --> 00:52:57,860
You don't have. So I'm going to have to do some green. But you see, in Michigan, medicine is autographs that look.

434
00:53:03,160 --> 00:53:11,520
That's. And if you've got more than one of them.

435
00:53:16,510 --> 00:53:20,670
This could be. Or.

436
00:53:23,470 --> 00:53:31,650
Good morning when and see these. What is clear is not you or.

437
00:53:38,200 --> 00:53:44,630
And for. My blood cells gave me off the numbers off the top of your head.

438
00:53:44,650 --> 00:53:50,980
What was it? 3.4. 8.8 to 10.3.

439
00:53:54,130 --> 00:53:58,350
Notice what they do. Calibrate all the grass.

440
00:53:58,460 --> 00:54:08,250
So the normal range is exactly the same. Visual distances. If you're in the normal range, this is not actually a problem.

441
00:54:08,340 --> 00:54:12,059
What is it doing is helping you see, am I in the middle of the normal range of my.

442
00:54:12,060 --> 00:54:19,510
At the edge of the normal range. Right. But if and if your value is outside by a little bit.

443
00:54:20,020 --> 00:54:29,830
So let's say to use Audrey's example, your values here with your 3.4 is not a problem.

444
00:54:33,420 --> 00:54:43,710
But if you have an extreme value, let's say something along the lines of the 6.7 we have up here.

445
00:54:50,120 --> 00:54:57,180
They shrink range. The was like this.

446
00:55:00,910 --> 00:55:11,240
And your 6.7 is. Notice how complicated this gets?

447
00:55:11,800 --> 00:55:19,820
Like, how much do you shrink it? Do you put the value here or do you put the value out here?

448
00:55:20,000 --> 00:55:23,930
We could put a 6.7 out there. It's totally arbitrary.

449
00:55:23,960 --> 00:55:28,370
What scaling I'm using here. But I guarantee you, in fact, have what people think about it.

450
00:55:36,190 --> 00:55:44,530
There's no simple answers here. Whatever scale you choose will make small differences seem bigger or smaller.

451
00:55:44,680 --> 00:55:49,749
Whatever end points you choose will imply either some values are seen as

452
00:55:49,750 --> 00:55:55,720
extreme or compress the scale of things that you would expect to see normally.

453
00:55:57,070 --> 00:56:05,420
I'll give you another example. So one of the environmental contamination problems du jour is PFOA?

454
00:56:05,530 --> 00:56:10,059
Yes. Don't ask me to remember what the famous acronym stands for.

455
00:56:10,060 --> 00:56:16,030
I couldn't possibly, Tony. These are the chemicals often used previously in firefighting.

456
00:56:16,930 --> 00:56:20,530
There's a major contaminations that a lot of military faces.

457
00:56:21,940 --> 00:56:25,570
They get into the water supply. They have a long half life. They're still around.

458
00:56:26,080 --> 00:56:31,430
A lot of problems. You look at the data on PFC, PFC concentrations.

459
00:56:32,490 --> 00:56:40,220
Most families will know you will observe fall between, say, one and or 2020.

460
00:56:40,350 --> 00:56:44,700
But the context again, I'm glossing over the units here because it doesn't really matter.

461
00:56:45,030 --> 00:56:47,490
The point I want to make is how do you want to visually show?

462
00:56:48,670 --> 00:56:56,590
Let's say a value of 15, when most of the values that you would have in the communities around you might be between zero and 20.

463
00:56:57,910 --> 00:56:59,980
And some communities have values of a thousand.

464
00:57:03,880 --> 00:57:09,640
If you make the graphics that you show that thousand 0 to 20 is way over here in this tiny little range.

465
00:57:10,840 --> 00:57:17,180
Even the variations in here are actually kind of important. If you blow this up.

466
00:57:17,180 --> 00:57:23,540
So let's say 0 to 20, you are not representing the thousand because 1000 is in the next building.

467
00:57:27,410 --> 00:57:34,130
We're going to do a lot. That is no simple answer. Yeah, if that's the case, we're like, even if you're not highly numerate,

468
00:57:34,670 --> 00:57:39,680
you could tell the difference between like if you had that normal scale, right?

469
00:57:39,710 --> 00:57:44,090
And then you had maybe like a tick, tick, tick. But I mean, to break the scale.

470
00:57:44,090 --> 00:57:53,080
Exactly. And then. And then you wrote a thousand. Yeah. You know, having that number of thousand, even if it's not visually, you know, proportionate.

471
00:57:53,600 --> 00:57:58,310
So and yes, there are pros and cons to breaking the scale.

472
00:58:00,290 --> 00:58:07,040
The problem is, if you truly show it as an outlier like it's off the scale, people will remember it's off the scale.

473
00:58:07,040 --> 00:58:10,190
They will take away that emotional sense of, I'm off the scale.

474
00:58:11,480 --> 00:58:20,320
They will completely not calibrate how far off the scale, but they'll have exactly the same reaction if that number was 50 or 100 or a thousand.

475
00:58:27,800 --> 00:58:33,470
Maybe the more numerous people will do better, but they'll do better simply because they're working with the numbers.

476
00:58:33,500 --> 00:58:39,260
Not anything to do with the prepositions. So again, this goes back to your purpose.

477
00:58:39,590 --> 00:58:47,900
If your purpose is I want you to be productive, you're free the heck out because your value is off the end of the scale.

478
00:58:48,920 --> 00:58:53,420
Go ahead and do that. But it's not necessarily accomplishing anything else.

479
00:58:54,740 --> 00:59:00,560
If your purpose is to give people any sense of calibration, you're not to accomplish that.

480
00:59:01,070 --> 00:59:04,540
So. Now what is your context?

481
00:59:04,540 --> 00:59:12,310
If I am returning an environmental quality report to a community and they're the community that has the thousand?

482
00:59:13,390 --> 00:59:18,790
Maybe I'll go with that. What's my purpose to alarm that community?

483
00:59:18,820 --> 00:59:22,060
They are extremely high and they need to take action immediately.

484
00:59:22,630 --> 00:59:26,620
And I will feel like being highly persuasive in the way in which I do that.

485
00:59:27,430 --> 00:59:33,999
But if they're not the community that has the thousand, I might want to exclude that data point from whatever visualization I'm giving them,

486
00:59:34,000 --> 00:59:42,580
because it's going to make everything else seem trivial. And I'm not actually serving that community's need by showing that these outliers exist.

487
00:59:44,500 --> 00:59:50,410
Is that manipulation? [INAUDIBLE], yeah. Are you okay with it?

488
00:59:51,400 --> 00:59:56,610
That's the question of the day. So.

489
00:59:59,900 --> 01:00:05,420
This takes me into the question, Annie, you brought up in your music,

490
01:00:06,440 --> 01:00:12,559
which is you're talking about in a medical context, but we're getting here to an environmental context.

491
01:00:12,560 --> 01:00:18,730
Let's talk about it more openly. And this can one communication serve multiple audiences?

492
01:00:18,740 --> 01:00:24,379
So talk about what you're talking about reusing, because I think this is where we need to spend the rest of the day talking about I was

493
01:00:24,380 --> 01:00:29,030
talking about just the availability of test results to patients sort of immediately.

494
01:00:29,900 --> 01:00:35,270
So patients are often receiving results before doctors have a chance to talk to them about them or frame them for them.

495
01:00:36,230 --> 01:00:43,730
And so I was sort of talking about a tension between providing those results and allowing that transparency and that immediacy,

496
01:00:43,730 --> 01:00:48,440
especially given that promotes and doesn't always immediately reach out to patients,

497
01:00:49,820 --> 01:00:54,290
but in a way that is not always useful to them and can often be really alarming versus

498
01:00:54,290 --> 01:00:58,430
trying to change those results so that they're more understandable for patients,

499
01:00:58,610 --> 01:01:03,290
where then you lose a lot of nuance that's actually useful when you're trying to communicate between providers.

500
01:01:04,320 --> 01:01:07,350
So what do you have to do this on your own?

501
01:01:09,750 --> 01:01:12,420
I mean, what leads you to say that you're going to lose that nuance?

502
01:01:12,660 --> 01:01:17,310
I think you're not alone in having that feeling, but this is a really critical question for us to wrestle with.

503
01:01:17,490 --> 01:01:24,360
I mean, I was so the example I was using was an MRI result for a patient who had had a stroke and she was developing some edema,

504
01:01:24,360 --> 01:01:28,350
like swelling around the stroke, which is normal, but it's something we keep an eye on.

505
01:01:29,640 --> 01:01:31,799
And we had been monitoring her for bleeding.

506
01:01:31,800 --> 01:01:36,690
So when she was reading about like fluid collection and swelling, she thought she was reading about bleeding.

507
01:01:37,800 --> 01:01:45,170
So I think it is you know, it was a result that wasn't particularly useful to her because it wasn't it wasn't the bad thing.

508
01:01:45,510 --> 01:01:52,050
And it was hard for her in context of just that report to take away the nuance of that.

509
01:01:52,110 --> 01:01:55,740
But I do think it was important for the team to be able to monitor edema.

510
01:01:56,220 --> 01:02:02,960
So. I'm turned to everybody else because I want you to hear what Annie is saying.

511
01:02:04,570 --> 01:02:09,760
The expert knowledge that is enabling Annie to understand the meaning that is

512
01:02:09,760 --> 01:02:15,640
not necessarily being communicated in the report that the patient is safe.

513
01:02:16,540 --> 01:02:19,020
So what you said several critical things here.

514
01:02:19,030 --> 01:02:26,800
What what are you picking up that helps you understand what does the patient actually need to be able to be well calibrated in this context?

515
01:02:29,140 --> 01:02:30,520
There's differences of language.

516
01:02:30,550 --> 01:02:39,090
I mean, like it was mentioning, like she was using the words for like tissue, liquid liquids, stuff for the page interpreted as blood.

517
01:02:39,130 --> 01:02:47,440
And so that's kind of a very different interpretation. And I would even put it more nuanced in the sense that there were two different things.

518
01:02:48,750 --> 01:02:57,229
That the patient was confusing. So if there had been a lot that the report would look this way.

519
01:02:57,230 --> 01:03:02,100
But if there was something that said okay. Blood volume and other fluid volume.

520
01:03:02,550 --> 01:03:06,300
The patient would not have had that confusion because the patient did have the anchor point.

521
01:03:06,510 --> 01:03:10,800
I am worried about blood. What else is there?

522
01:03:12,720 --> 01:03:24,310
I have a couple of really critical things. If the foot swelling immediately dangerous.

523
01:03:25,420 --> 01:03:29,140
No, it's normal. That was a key word you used.

524
01:03:29,350 --> 01:03:37,330
You used the calibration of this value. Whatever it is, however it was represented, it was within the range of what would be expected.

525
01:03:38,620 --> 01:03:42,970
What is the patient actually trying to understand? Am I doing well or not?

526
01:03:44,620 --> 01:03:51,370
It is the values that are being observed. What would be expected for a person like me?

527
01:03:52,530 --> 01:03:58,800
Few words there like me. Not a normal, healthy patient, not a person who hasn't had a stroke.

528
01:03:59,490 --> 01:04:03,150
For a patient who has had a stroke. Person with life.

529
01:04:05,210 --> 01:04:08,240
Now, I didn't show you today the graphics I just put up there.

530
01:04:10,110 --> 01:04:13,950
The same problem in the context of diabetes, but I'll try and describe it.

531
01:04:16,610 --> 01:04:23,630
The standard range for hemoglobin A1 C was 4.5 to 5.6 or seven, something like that.

532
01:04:24,080 --> 01:04:28,700
Whatever. That value is what? What do you think that that means?

533
01:04:28,970 --> 01:04:34,750
That standard range that I kept across? Not a trick question.

534
01:04:36,400 --> 01:04:39,630
What is the standard range? Yeah.

535
01:04:39,960 --> 01:04:45,990
So, Ranger, if you don't have any diabetes, any issue with your range that.

536
01:04:47,260 --> 01:04:51,610
Guarantee that you're in. Where does that number come from? You're right.

537
01:04:51,610 --> 01:04:53,170
But there's nuances here that are important.

538
01:04:54,310 --> 01:05:03,219
Average population level or target population of people who do not have any condition associated with hemoglobin.

539
01:05:03,220 --> 01:05:10,000
I want to see what is the distribution that you would expect to see within that population.

540
01:05:10,030 --> 01:05:14,170
By the way, this, like any statistical distribution, has tails.

541
01:05:15,590 --> 01:05:19,580
Depending upon how this is marked, it might be the 95th percentile, etc.

542
01:05:20,120 --> 01:05:26,510
There are some people who are normal in their normal, healthy state who fall outside of those ranges.

543
01:05:27,790 --> 01:05:32,140
I had one, but I didn't go in and see if you measure my platelets.

544
01:05:33,040 --> 01:05:36,369
I platelets. Platelets are normally between 150 and 400.

545
01:05:36,370 --> 01:05:40,210
My platelets have been above 150 like once or twice in the last decade.

546
01:05:40,780 --> 01:05:45,340
I sit at about 140. Extremely consistently.

547
01:05:47,630 --> 01:05:50,960
Who cares? That is my normal.

548
01:05:52,580 --> 01:05:57,020
I had to learn not to react when every time I get a platelet count,

549
01:05:57,230 --> 01:06:02,600
my values fall outside and they get flagged and they're red because it doesn't work for me.

550
01:06:04,540 --> 01:06:09,840
Yeah. If you are already diagnosed.

551
01:06:11,520 --> 01:06:19,410
And say, I have two diabetes. You're not going to get capability to sit down.

552
01:06:22,000 --> 01:06:31,819
You got to happen? Pretty much. Target value again, reflected what was often described in medical consultations.

553
01:06:31,820 --> 01:06:41,210
You can argue with me about the details. And the point is right. Many type two patients with type two diabetes are given target goals of below seven.

554
01:06:43,420 --> 01:06:51,070
Those 6.7 numbers that I showed you up there would have been well within the space of meeting goals for those people.

555
01:06:52,200 --> 01:06:56,430
But if I showed you the them, the graph that I gave you, that's not what they would get.

556
01:06:58,330 --> 01:07:02,080
They would be looking at it being labeled high. They would be looking at it labeled orange.

557
01:07:02,110 --> 01:07:06,220
They would look at you looking at it as clearly outside of the green rating.

558
01:07:06,940 --> 01:07:12,790
And they would be taking away and failing even though they are reading the target goal.

559
01:07:16,160 --> 01:07:19,470
So I would argue we shouldn't even be giving them the standard rate.

560
01:07:19,490 --> 01:07:27,530
It's not relevant to them. Just in the same way that the amount of swelling that your patient had is not, you know,

561
01:07:28,070 --> 01:07:33,260
the normal values is not relevant to somebody who, you know, has already had a stroke.

562
01:07:33,980 --> 01:07:41,030
What the relevant reference point is, what is the range of swelling that we would expect to see for somebody, say, a week after a stroke?

563
01:07:41,060 --> 01:07:45,850
What is what is the calibration that we would expect to see of people like you?

564
01:07:47,880 --> 01:07:51,980
But if we only had one reference range and that's healthy patients,

565
01:07:52,820 --> 01:07:58,520
then we're going to break that rule pretty much every time we give it to somebody who already has a condition.

566
01:07:59,060 --> 01:08:02,420
They already have cancer. Who already has diabetes, who already has a stroke.

567
01:08:05,860 --> 01:08:09,490
So that's one of the points I wanted to make here. But the other one is this.

568
01:08:11,350 --> 01:08:18,610
Is it a problem to create something for patients that gives them that calibration?

569
01:08:19,510 --> 01:08:26,650
Let's say we imagine creating a great graphic is what you guys are going to do over the course of the next week for the user, for the patient.

570
01:08:27,900 --> 01:08:38,290
Is it a problem? If told them this amount of swelling is within, the range of that would be expected for patients with a stroke.

571
01:08:42,790 --> 01:08:46,210
I'm just not sure. Everything maps that easily onto a graphic.

572
01:08:46,510 --> 01:08:51,970
Oh, not everything maps that easily, period. Let's just end the sentence there and recognize this is complicated.

573
01:08:52,720 --> 01:08:57,160
But I want to challenge the presumption.

574
01:08:58,110 --> 01:09:04,680
That a communication that meets patients needs is not effective or a professional answer.

575
01:09:06,000 --> 01:09:08,549
I acknowledge that professional audiences have particular needs,

576
01:09:08,550 --> 01:09:14,430
certainly a need for a level of precision that many patient audiences or public audiences do not have.

577
01:09:16,170 --> 01:09:24,930
But if I give you a number and calibrate you to the relevant reference standards, whether that's mangoes,

578
01:09:24,930 --> 01:09:34,050
weight calibrations or the amount of swelling that might be expected for patients at different stages of recovery from a stroke.

579
01:09:36,250 --> 01:09:40,750
That's redundant information for the professionals. They probably already know it.

580
01:09:41,020 --> 01:09:46,240
It's critical information for the patient. Because it's redundant.

581
01:09:46,250 --> 01:09:50,080
It's also probably not going to harm the clinician to have that being restated again.

582
01:09:54,360 --> 01:10:10,500
Now. You can't take this too far. If you throw in every color coding and labeling and reference standard and you can overwhelm people with context.

583
01:10:10,920 --> 01:10:19,330
I have hard research data to show it. So the question is not more people like that,

584
01:10:22,870 --> 01:10:29,770
but my take away from you for today is this We spend a lot of time giving people access to data, public health.

585
01:10:30,250 --> 01:10:36,200
I think that is. Think about how many times they don't even know whether it's good or bad.

586
01:10:37,300 --> 01:10:41,080
And how that likely translates into the use of those data.

587
01:10:42,830 --> 01:10:46,340
You have a lot of opportunity to make things happen.

588
01:10:46,820 --> 01:10:54,350
And the question of the day, which is where I want to go right now, is. If we give people all this stuff.

589
01:10:56,690 --> 01:11:02,540
Standards, comparison data. You know, pictures of cats being obese or not, whatever.

590
01:11:04,880 --> 01:11:08,630
Are we manipulating them? You know, my answer is yes.

591
01:11:10,640 --> 01:11:18,020
Okay. Well, when is it okay? Or what guidelines should we be using to decide how much guidance that we are providing?

592
01:11:18,860 --> 01:11:23,870
So the question I want you to wrestle with and take like three or 4 minutes and turn to your neighbor and ask is.

593
01:11:25,890 --> 01:11:35,010
What are the situations in which providing this type of categorization or labeling or or reference standards is going to cause a problem?

594
01:11:39,430 --> 01:11:44,320
And I think I hope I have convinced you that there are lots of situations in which it's critical and it would be value.

595
01:11:45,340 --> 01:11:49,660
So what are the limits of this? Okay, just wrestle with that for a few.

596
01:11:49,960 --> 01:11:59,410
We'll come back to it on Thursday class as well. When we when we get into the example and wrestle with, is any of this bothering you, turning you?

597
01:12:00,040 --> 01:12:03,270
And if so, what? All right.

598
01:12:03,750 --> 01:12:11,090
It works. I mean, obviously, impact is everything as well.

599
01:12:13,260 --> 01:12:24,730
One topic and this year, I mean, is it worth at all or nothing?

600
01:12:24,840 --> 01:12:42,120
We can do a scenario not necessarily sweeping and it's not like 20 somethings emailing on the way,

601
01:12:42,120 --> 01:12:53,030
like it's about how I feel like I new company or something like that.

602
01:12:54,750 --> 01:13:11,720
So I still actually feel better about what happens and I don't really have to write it like I recognize it saying,

603
01:13:11,730 --> 01:13:21,050
Oh, you're so everybody's their own worst enemy and we all have that.

604
01:13:21,130 --> 01:13:28,560
That was not something that has been written by a human being.

605
01:13:29,550 --> 01:13:42,240
Yeah, you're right. In fact, it's almost like getting ready to do something like that.

606
01:13:42,240 --> 01:13:53,060
Are trying and trying to write a letter.

607
01:13:53,290 --> 01:13:59,459
I say yes.

608
01:13:59,460 --> 01:14:10,090
Celebrating, getting around. Not as if you just don't even know what it is, you know, so that they can use a similar standard.

609
01:14:10,220 --> 01:14:25,960
That sometimes would be good in the sense that you might have like very high expectations that's really going to do it.

610
01:14:26,760 --> 01:14:31,830
I actually I don't think it's that she was talking about the blood pressure monitoring and I was like,

611
01:14:32,340 --> 01:14:38,129
I could write the kind of individualized that I personally like the fact that the manufacturer would do that.

612
01:14:38,130 --> 01:14:58,860
You wouldn't do that all through, it seems like. Why why does it go from free to read something as great as like the French word for your money?

613
01:14:59,640 --> 01:15:08,190
That's what I got to give you a lot of calls.

614
01:15:08,700 --> 01:15:14,850
Yeah. Like it seems like right now and in the past,

615
01:15:16,260 --> 01:15:40,350
usually that puts you in your life line while the single person was like, God, it's not like I know this.

616
01:15:41,580 --> 01:15:45,880
You know, you can't call it often in your life.

617
01:15:45,990 --> 01:15:49,850
That's the one thing that I still go.

618
01:15:50,760 --> 01:15:56,010
I know. The other stuff again was like that.

619
01:15:56,010 --> 01:16:04,950
Like, I like I'm not like someone like like everyone.

620
01:16:05,760 --> 01:16:12,810
Like a real concern on something like that, I think.

621
01:16:15,980 --> 01:16:20,130
Yeah, yeah, that's good.

622
01:16:21,630 --> 01:16:34,920
I mean that an awful thing when you come up with just like this system in which providing context and actionable

623
01:16:34,920 --> 01:16:40,200
categorization and a reference to whatever might be problematic or things that are making you worried about.

624
01:16:42,090 --> 01:16:46,440
Yeah, we kind of talked about how people could like Google their own reason to say

625
01:16:46,440 --> 01:16:50,060
that we like gave them more of a tailored scale based on like the condition.

626
01:16:50,070 --> 01:16:55,830
Now like people Google things all the time what if they look it up online you to they need

627
01:16:55,830 --> 01:17:00,390
to know why their what you're giving them is different than what they might see elsewhere.

628
01:17:01,320 --> 01:17:06,040
Yeah, that's a. Big deal. Notice that there was an obvious answer for that, like you can explain.

629
01:17:06,060 --> 01:17:14,520
Here is you know, here is your target is because you are diagnosed with this, because you are this gender, because you are this age range.

630
01:17:14,850 --> 01:17:18,380
Whatever the appropriate calibration factors might be.

631
01:17:18,390 --> 01:17:18,990
But you're right,

632
01:17:19,290 --> 01:17:24,840
you can't just throw something that's different than what somebody might see somewhere else and then expect them to be okay with that.

633
01:17:25,680 --> 01:17:30,629
And what else? Yeah.

634
01:17:30,630 --> 01:17:34,230
You know, I'm making it, like, personalized. Like, what does it mean for their body?

635
01:17:34,590 --> 01:17:39,780
What does that mean for like. I mean, it's maybe I have a higher risk behavior.

636
01:17:39,930 --> 01:17:43,410
And how do you, like, bring those things up? Maybe that's like an offshoot of something else, but.

637
01:17:44,940 --> 01:17:48,509
So this is in some sense a similar kind of question to what Cindy brought up in the

638
01:17:48,510 --> 01:17:55,829
sense of how are you associating your personal characteristics with the instructions?

639
01:17:55,830 --> 01:17:59,010
Essentially, you're being given by however you're formatting this.

640
01:17:59,010 --> 01:18:06,959
If you're being if there's a mismatch there for whatever reason, then that's going to cause a problem,

641
01:18:06,960 --> 01:18:11,640
either in the sense of leading you to act or not act in a way that's not really

642
01:18:11,640 --> 01:18:15,150
what you want to be doing or to disrupt your trust in what's being given to you.

643
01:18:16,730 --> 01:18:23,940
Oh, yeah. Elizabeth brought up how she kind of, like, manipulates her, like, medical device,

644
01:18:25,440 --> 01:18:31,739
like sugar graph on her phone that like the app for the medical device so that the range fits more into,

645
01:18:31,740 --> 01:18:35,910
like, work or just fall into doesn't look so alarming all the time.

646
01:18:35,910 --> 01:18:41,100
And also like it was like a flatline for a while because the range wasn't like big enough.

647
01:18:41,190 --> 01:18:48,570
So yeah, yeah. It's because how they have an app that goes along with it that tells you how much time you're in the zone.

648
01:18:48,960 --> 01:18:52,200
And I was diagnosed, I was in the 500 range.

649
01:18:52,650 --> 01:18:57,110
So when you look at the graph and it says 0% of time in the range, that's horrible.

650
01:18:57,360 --> 01:19:05,579
So at first my doctor recommend okay, put your range anything below 300 and with an asterisk next to it.

651
01:19:05,580 --> 01:19:12,030
Wow, that's not the end goal. Don't think that just because that's a lot lower means that that's where you want to end up.

652
01:19:12,210 --> 01:19:18,840
Right. But it's hard to make progress when you feel like there's no way to be doing something right.

653
01:19:20,550 --> 01:19:24,510
So that's a great place to end this conversation because there's so many situations.

654
01:19:24,510 --> 01:19:34,980
Let's think about step counts, let's talk about rates, whatever, where intermediate goal setting is different than end goal setting.

655
01:19:37,010 --> 01:19:41,660
If we set a goal that is unachievable and we get demotivated,

656
01:19:41,840 --> 01:19:48,499
if we set a goal where we can see the incremental changes occurring and we pay attention to the range of

657
01:19:48,500 --> 01:19:54,980
variation like I did X and my blood sugar has changed by this amount that facilitates the feedback loop.

658
01:19:54,990 --> 01:20:01,790
So the idea of calibrating to the person's individual, whatever range is meaningful to that person, is really valuable.

659
01:20:02,390 --> 01:20:07,280
Now technology can facilitate that, but this is also a numeracy test.

660
01:20:07,370 --> 01:20:13,100
Highly numerate. People are going to be far more comfortable engaging in this kind of conversation and less number of people will.

661
01:20:14,630 --> 01:20:18,140
There is a tension here. Like any alien over person.

662
01:20:18,140 --> 01:20:20,030
If we oversimplify, I get annoyed.

663
01:20:21,960 --> 01:20:28,830
We have a less number of personnel to keep forcing them to look at numbers as opposed to, for example, these data is just getting colored categories.

664
01:20:29,430 --> 01:20:36,579
They may get frustrated. There's no simple answer here, but this is the choice that we always have to be engaged with.

665
01:20:36,580 --> 01:20:38,409
What's the right level of information?

666
01:20:38,410 --> 01:20:46,030
What's the right categories or not, reference points or not, targets or not, etc., for each and a person's needs.

667
01:20:46,510 --> 01:20:50,950
And that is the question I want you guys to be thinking about as you move into the assignment you're going to be working out.

668
01:20:51,820 --> 01:20:58,020
All right. So remember, for next class, come up with a particular type of measurement in mind.

669
01:20:58,030 --> 01:21:03,009
If you want to workshop one, work here, something that will be meaningful to you.

670
01:21:03,010 --> 01:21:08,140
It must be quantitative. Can't just be yes or no, binary, positive, negative or positive quantitative.

671
01:21:08,740 --> 01:21:12,250
But you want to work in environmental space. Great. You want to work on biomarkers.

672
01:21:12,250 --> 01:21:15,720
That's great. I don't care right now.

673
01:21:15,790 --> 01:21:23,960
Thursday. I want to follow up on this because.

674
01:21:25,470 --> 01:21:31,830
I think you stay positive, but I feel like I'm not a good team.

675
01:21:34,810 --> 01:21:45,940
I wasn't going to make the to someone like.

676
01:21:49,110 --> 01:22:03,040
But right now, I, you know, I don't really care if you're not my thing.

677
01:22:04,950 --> 01:22:26,590
Yes. You have to. Like I said, I'm still like literally to think of something and I don't know if I ready someone, but I was just like, I don't know.

678
01:22:27,510 --> 01:22:31,400
Like, I don't know. Yeah. I took a look at what to do now.

679
01:22:31,620 --> 01:22:42,720
All the smells that I have has. I mean, this is hardly possible.

680
01:22:44,310 --> 01:22:49,260
This is like a direct this with my impact, and that's what I want.

681
01:22:49,800 --> 01:22:56,160
This is just another one that's working. It's like halfway through, going through, like physical activity.

682
01:22:56,550 --> 01:23:15,000
And we just get back to that kind of quantitative measure that you would think is important for you to take away.

683
01:23:18,170 --> 01:23:30,070
Personally, I love getting all of my data during my time in the top five 1% over the course of nine months or so.

684
01:23:30,090 --> 01:23:36,110
And of course, sometimes the rest online or expecting sort of for the assignment to do a mandate.

685
01:23:36,680 --> 01:23:42,080
No time to be creating the group. I talk about this on Thursday.

686
01:23:42,740 --> 01:23:48,890
It does not mean to be pretty is to have the features that we were talking about today.

687
01:23:49,730 --> 01:23:52,800
So I will be looking at a specific range.

688
01:23:53,810 --> 01:23:57,710
I will be looking at range and what's marked and what's colored and what's labeled, etc.

689
01:23:59,590 --> 01:24:04,840
If you want to use a computer program to make it fine. If you want to scribble it and take a picture, fine.

690
01:24:05,710 --> 01:24:10,600
This is not graphic design. I'm looking at it.

691
01:24:11,140 --> 01:24:16,300
Does the visual that you're using have the features that it needs to have?

692
01:24:17,290 --> 01:24:21,040
That's the only thing I'm going to worry about. And that's that's for Monday.

693
01:24:21,040 --> 01:24:24,609
For tomorrow. And I tried Thursday for Thursday.

694
01:24:24,610 --> 01:24:28,390
All I want you to do is to pick a type of data that you want to work with.

695
01:24:28,930 --> 01:24:35,110
So if you want to work with thyroid hormone levels or PFOA levels or something,

696
01:24:35,200 --> 01:24:38,320
the only rule is you can't be using the stuff that we're going to be actually doing for the exam.

697
01:24:39,070 --> 01:24:45,370
But another type of data and then we're going to go through that little worksheet set of questions.

698
01:24:45,370 --> 01:24:50,980
That was in my article. I had like 30 different questions about, Yeah, we're going to do that.

699
01:24:51,070 --> 01:24:57,910
Okay. And also, I have I will have my wisdom teeth extraction surgery on Friday afternoon.

700
01:24:57,940 --> 01:24:58,660
I'm so sorry.

