1
00:00:00,800 --> 00:00:37,660
I mean, I think I would be less weirded out by the tables if the situation didn't literally change every week when I entered the room,

2
00:00:39,330 --> 00:00:45,270
which was unlikely.

3
00:00:45,540 --> 00:01:06,710
Exactly. Exactly. It's not quite what I think.

4
00:01:08,070 --> 00:01:19,990
I know. I, I know because I know what it's like to be spent without ever.

5
00:01:20,010 --> 00:01:32,620
You just know it all the time. Yeah.

6
00:01:41,060 --> 00:02:01,560
Yeah. And you know what?

7
00:02:03,450 --> 00:02:16,020
Know. I guess I appreciate the that sitting here.

8
00:02:22,040 --> 00:02:29,100
You started attacking me.

9
00:02:33,430 --> 00:02:45,260
Yeah, that's right. She said to come on.

10
00:02:45,770 --> 00:02:48,920
Oh. Yeah.

11
00:02:52,720 --> 00:03:05,150
Not actually saying it was the U.N. forces within 48 hours.

12
00:03:06,530 --> 00:03:14,490
Yeah. Yeah, exactly.

13
00:03:21,980 --> 00:03:34,100
The first day was as long as I'm really tired at the time to do it and say I'm

14
00:03:34,100 --> 00:03:43,430
going to take all that because they are trying to do all this like everything.

15
00:03:45,120 --> 00:04:01,580
So I wanted to continue it and I wasn't able to create something I signed up for sometimes.

16
00:04:02,150 --> 00:04:33,900
And then I do. Like I said, I decided to do something to understand the things I did.

17
00:04:33,950 --> 00:04:47,720
Time? Yes. Opportunity for me.

18
00:05:09,930 --> 00:05:22,330
All right. So today is going to be sort of a whirlwind tour of visuals.

19
00:05:24,520 --> 00:05:34,720
And I want to say right from the start that this is its own topic worthy of going on before class, etc.

20
00:05:36,400 --> 00:05:40,090
I'll tell you where we're going to go and acknowledge where we're not going to go,

21
00:05:41,290 --> 00:05:47,229
because a huge field of data visualization, which is really at least part of it,

22
00:05:47,230 --> 00:05:55,090
is really grounded on the question of how do we use visualization techniques to understand what the data are telling us,

23
00:05:55,510 --> 00:05:57,370
what are the patterns that exist within it?

24
00:05:58,650 --> 00:06:04,480
You can take the same data set and put it in different visuals and certain things become more or less clear.

25
00:06:04,510 --> 00:06:06,730
We're going to come back to that from a communication design.

26
00:06:07,720 --> 00:06:12,700
That is a really powerful thing, and especially when you think about large data sets and understanding what exists within them.

27
00:06:13,390 --> 00:06:19,980
I'm not going to go live. In fact, if anything, this class, I'm going to focus much more on the opposite end of the spectrum.

28
00:06:20,820 --> 00:06:32,220
How do we use visuals to show one number or one line or one relationship as clearly as possible?

29
00:06:34,590 --> 00:06:39,070
Another thing that data visuals do. Is.

30
00:06:47,560 --> 00:06:54,550
Individuals are stories. We'll get into that to some degree today.

31
00:06:55,060 --> 00:07:07,540
But I want to be I want to start this conversation from the premise that this is not a conversation about what is the right way to do something.

32
00:07:07,540 --> 00:07:12,820
There are wrong ways, don't get me wrong. There are bad ways to visualize data, to present data.

33
00:07:15,050 --> 00:07:23,390
But I want to start from a fundamental premise that there is no such thing as an unbiased data visual.

34
00:07:27,350 --> 00:07:40,520
Every data visualization and every data presentation is in some way biased by the choices that we as the designer choose to include or not include,

35
00:07:40,820 --> 00:07:49,310
which residuals we choose to present the data in, etc. We are shaping what people are going to take away from the data.

36
00:07:51,110 --> 00:07:54,470
So on that.

37
00:07:56,790 --> 00:08:06,419
We are. This is not the unbiased way of presenting the data, because whatever graphic you give me,

38
00:08:06,420 --> 00:08:14,220
I will tell you the way in which you are shaping, changing, modifying, manipulating your audience.

39
00:08:17,470 --> 00:08:21,160
So the conversation where we're going and this is why the question of the day is up here,

40
00:08:21,160 --> 00:08:27,250
it's about what are the ethical principles that we ought to hold on to when we're thinking about visualizing data,

41
00:08:27,250 --> 00:08:32,670
when we're presenting data to audiences? What is okay for us to do and what is not.

42
00:08:34,590 --> 00:08:38,250
Unless you wrestle with that question throughout the day and I'll come back to it.

43
00:08:41,490 --> 00:08:47,760
But I want to start with some definitions because unfortunately,

44
00:08:48,540 --> 00:08:53,280
at least in the English language, we don't necessarily use the same terms, the same things.

45
00:08:54,480 --> 00:09:11,100
So I use data visual to mean graphics of some kind that represent data points or data sets.

46
00:09:13,920 --> 00:09:20,639
I do not include in that. And by the way, if you include an example that is I'm going to now say is not what I was looking for in your musings.

47
00:09:20,640 --> 00:09:26,010
Totally fine. That's why we're having this conversation. I don't mean a table.

48
00:09:26,550 --> 00:09:29,670
A table is different than a visual table.

49
00:09:29,670 --> 00:09:35,010
Reports the numbers. It requires you to process what those numbers mean to understand any relationships with them.

50
00:09:36,090 --> 00:09:45,660
A visual is graphically in space, in two dimensional space or three dimensional space, representing those data in some form.

51
00:09:47,600 --> 00:09:50,900
My size or height or position.

52
00:09:51,920 --> 00:09:57,500
So in a way that a table does not, visual is going to be something more than a table.

53
00:09:59,590 --> 00:10:06,030
The individual is also not our separate data, visual or infographic.

54
00:10:08,050 --> 00:10:13,680
The infographic may have data visuals embedded in them like an infographic and have a pie chart in it.

55
00:10:13,680 --> 00:10:17,370
Or it can have our or, you know, lots of other things in it. That's fine.

56
00:10:17,770 --> 00:10:24,000
The infographic is, in my mind, much closer to a graphic novel than the date.

57
00:10:24,010 --> 00:10:34,500
A visual infographic is a story fold in some words and some pictures and some data graphics.

58
00:10:36,270 --> 00:10:41,250
But it's a story, and there's a great role for infographics in health communication.

59
00:10:41,280 --> 00:10:47,360
Don't get me wrong, I'm not going to go there in this class, but that's not what I'm going to focus on.

60
00:10:47,370 --> 00:10:50,729
I'm going to get us more micro focusing on individual data,

61
00:10:50,730 --> 00:10:57,390
graphics and visualizations to have us think through, okay, what is this thing and what is it trying to do?

62
00:11:02,000 --> 00:11:05,330
And nor am I meaning.

63
00:11:08,450 --> 00:11:10,250
This is what I call illustrations.

64
00:11:10,640 --> 00:11:17,590
So several of you in your musings give an example of something which I guess on its surface is a data visual, but really I don't think of it that way.

65
00:11:17,800 --> 00:11:26,310
It's an illustration, which is the myplate nutrition thing that shows me how your plate ought to be one

66
00:11:26,310 --> 00:11:31,520
quarter protein and one quarter of starches and half vegetables that are like,

67
00:11:31,730 --> 00:11:38,510
okay, yes, it's kind of a pie chart, but really it's a concrete representation of the things that we're talking about.

68
00:11:42,180 --> 00:11:52,690
Yes. It's kind of a hybrid, but. I wouldn't necessarily think that the primary thing you're going to take away from that is 25, 25, 54.

69
00:11:52,690 --> 00:11:57,999
It's going to take away from that is relative sizes of how much stuff you ought to be doing.

70
00:11:58,000 --> 00:12:07,640
And in a relatively noncompetitive way, by the way, there's totally a place for that, like in my other class where I talk a lot about memorability.

71
00:12:07,660 --> 00:12:15,220
How do we make messages memorable? We spend a lot of time talking about concreteness, and my plate is a great example of concreteness.

72
00:12:15,790 --> 00:12:19,060
That's what your plate ought to look like to have a balance. Great.

73
00:12:19,840 --> 00:12:25,520
But that's not what we're doing here. But.

74
00:12:26,570 --> 00:12:32,160
There's a lot of data graphics that we see and that we create in.

75
00:12:33,560 --> 00:12:40,400
They are trying to do certain things, and that's what I want to spend the time talking about and the starting point actually.

76
00:12:45,130 --> 00:12:51,070
Emma, you're actually in your views and kind of making the point I want to make in today's class.

77
00:12:51,070 --> 00:12:56,330
So I want to just start you off with it and let you talk about what you were talking about in your musing about purpose,

78
00:12:56,900 --> 00:13:00,170
and then let that set the stage for what we're going to do for the rest of today.

79
00:13:00,240 --> 00:13:15,540
Okay. Oh, yeah.

80
00:13:15,570 --> 00:13:18,420
Okay. Well, I recently wrote about my music. How?

81
00:13:19,850 --> 00:13:25,190
And one of the readings they talked about how this it's really accessible and really easy now to make data visualizations.

82
00:13:25,190 --> 00:13:30,649
And so people think, oh, because I can just like create one on Google Drive or something like that, or I can build that.

83
00:13:30,650 --> 00:13:37,400
Like it's really intuitive and I know what I'm doing, but that's really not the case that like in every single like research about

84
00:13:37,400 --> 00:13:42,350
this topic out of grad school or any like the class I taught for our class,

85
00:13:43,070 --> 00:13:48,200
we spent a really long chunk of time learning the proper techniques for creating a data visualization.

86
00:13:48,200 --> 00:13:56,370
And because it takes so much time to learn the actual concrete techniques, it's like really not as intuitive as people think.

87
00:13:56,390 --> 00:14:01,310
I guess. Yeah. And the main point I want to take away from this is.

88
00:14:02,740 --> 00:14:10,930
There are multiple ways to show the same data, which means what you choose to do is going to change what people are going to take away from.

89
00:14:13,430 --> 00:14:18,330
War or anything else. What I want you to walk away from today is you need to know what it is you're trying to do.

90
00:14:19,050 --> 00:14:22,310
You may or may not have all the skills to do it right.

91
00:14:22,320 --> 00:14:30,900
That's the skill building that I was talking about. But there are certain things that are classic problems that we just simply should never be doing,

92
00:14:31,380 --> 00:14:38,490
and there are certain choices that we should be making very consciously about how we're representing that I'm going to pull.

93
00:14:38,910 --> 00:14:42,330
We go through a lot of examples from what you guys gave me in your musings.

94
00:14:42,480 --> 00:14:48,780
Thank you very much. Always very helpful. And I want to start from that idea of.

95
00:14:50,630 --> 00:14:54,920
What are we trying to accomplish? Like, why are you giving me a graphic in the first place?

96
00:14:57,600 --> 00:15:02,790
Because and I will also acknowledge one of the answers to that question is.

97
00:15:03,850 --> 00:15:05,110
So you'll trust me more.

98
00:15:08,520 --> 00:15:18,900
One of the ways in which we use graphics and communication is that at least for more graphically literate people and more numerate people,

99
00:15:19,380 --> 00:15:24,780
the fact that there is a visual boosts our trust in that message.

100
00:15:25,470 --> 00:15:29,970
Even if we pay no attention to the message, even if we process absolutely nothing from it.

101
00:15:30,420 --> 00:15:39,980
The presence of that has an effect. Which newspapers leverage all the time.

102
00:15:42,000 --> 00:15:47,860
Pop up, drop a little graphic into your news story and all of a sudden, ooh, it's got data.

103
00:15:48,670 --> 00:15:55,090
And that's changing our reaction to that message in a way that may not be about what the content of that graphic is,

104
00:15:55,090 --> 00:16:07,450
but it's simply about the fact that it's there. So a couple of you talked about a salient example to many of us in this moment of appeal.

105
00:16:07,460 --> 00:16:11,810
And he said, I think talk about good case counts as a starting point.

106
00:16:12,650 --> 00:16:22,700
So let's start there. What do we want to know about COVID case counts?

107
00:16:25,520 --> 00:16:30,950
I can make up numbers here, but the point is, I want to I want to step back from the data from the start and say,

108
00:16:31,520 --> 00:16:40,450
why are we giving the case counts in the first place? And hence what kinds of graphics might be best to achieve what we're trying to do with that?

109
00:16:42,070 --> 00:16:44,350
So we know.

110
00:16:45,430 --> 00:16:53,890
Because we try at least try to track this appropriately, the number of cases that are existing in different locations at different points in time.

111
00:16:55,140 --> 00:17:02,030
That's the data set that we have available to us. So what might our purposes be?

112
00:17:02,950 --> 00:17:14,200
For those data. But I'm definitely interested in these trends increasing numbers.

113
00:17:15,040 --> 00:17:25,419
So one purpose might be to understand in the present moment, maybe, maybe at the national level, maybe at the local level, whatever our things.

114
00:17:25,420 --> 00:17:31,510
What's the pattern with old time trends going up or down, constant, etc.?

115
00:17:32,260 --> 00:17:35,920
No, if that's what we care about.

116
00:17:37,220 --> 00:17:43,430
Then we are deprecating. We are reducing attention to the absolute level of risk that we are facing.

117
00:17:44,450 --> 00:17:48,840
Prioritizing the pattern over the levels.

118
00:17:51,430 --> 00:17:55,120
So I might not know or remember or even process.

119
00:17:56,110 --> 00:18:00,350
You know, is this a high background level of risk or a lower background level of risk?

120
00:18:00,380 --> 00:18:06,530
What I'm processing is it's getting worse. If you think about sort of how this plays out,

121
00:18:07,970 --> 00:18:14,690
we saw lots of data graphics and lots of data communications about COVID in early 2020 that were all about It's going up,

122
00:18:14,690 --> 00:18:19,620
it's going up, it's going up, it's going up at case count levels that right now would seem like a win.

123
00:18:19,810 --> 00:18:25,960
Like it's nothing. But the message in that moment was direction.

124
00:18:27,460 --> 00:18:32,320
So what kinds of graphics to draw action?

125
00:18:34,240 --> 00:18:39,940
Well, put it this way. Which would you rather do if what you cared about is direction?

126
00:18:40,950 --> 00:18:44,880
Would you rather have a graphic that looks like this? Or if you rather have.

127
00:18:51,750 --> 00:18:55,880
Which one emphasizes the direction and Minecraft?

128
00:18:56,100 --> 00:19:04,830
Absolutely. A line graph is a graphic format is going to prioritize direction pattern over level.

129
00:19:08,760 --> 00:19:13,460
So when we see line graphs. They are making us pay.

130
00:19:13,740 --> 00:19:18,040
Wow. Wow. It's going up. I am not paying attention to whatever is over here.

131
00:19:18,550 --> 00:19:28,460
I'm not paying attention to the scale. Here at least we are looking at sort of like it's this high at this high of this off.

132
00:19:29,330 --> 00:19:36,890
Yeah, not necessarily always going to give us what we want, but it's that choice is an example of a data visualization.

133
00:19:38,470 --> 00:19:42,250
Decisions that are going to change what somebody takes away from the good, the bad.

134
00:19:51,950 --> 00:20:01,100
When do we care about something like this? Like, when might you want to focus on case counts more in a level way rather than in a pattern with.

135
00:20:03,800 --> 00:20:09,140
Yeah. If you're, like, comparing different demographics and like different like age groups.

136
00:20:09,440 --> 00:20:20,300
Right. So notice graphics that look like this is kind of I mean, you can see there's differences, but it's not necessarily.

137
00:20:20,600 --> 00:20:32,210
How big are those, etc.? Whereas graphics that look like this, whatever structure we have here, each pair is easy to compare.

138
00:20:35,680 --> 00:20:42,790
Now I'm intentionally shaping this so that, let's say two different demographic groups are right next to each other.

139
00:20:43,930 --> 00:20:48,760
I could instead do.

140
00:20:58,420 --> 00:21:02,840
This kind of traffic, you know, Route A versus group B.

141
00:21:04,650 --> 00:21:15,219
Same data. It's a lot harder to do the A versus B comparisons, because here I have to say, okay,

142
00:21:15,220 --> 00:21:21,160
I'm going to compare this one to this one as opposed to these two things which are right next to each other.

143
00:21:21,910 --> 00:21:27,580
So a key idea of data visualization is vehicle proximity, but it's close to each other.

144
00:21:30,120 --> 00:21:34,949
You make choices about the organization of the data? Things that are close to each other are easy to compare.

145
00:21:34,950 --> 00:21:43,800
Things are separate from each other, are hard to compare. So I can take again, even just working with the bar chart.

146
00:21:44,190 --> 00:21:51,060
I can make a different choice, highlight the time trend versus the group comparisons.

147
00:21:53,490 --> 00:22:03,030
And that should be done consciously, intentionally, because we want you to be paying attention to that difference or we don't.

148
00:22:09,320 --> 00:22:14,420
So when we get into these examples, I would be asking this question.

149
00:22:16,100 --> 00:22:19,130
What is the takeaway? What is the message?

150
00:22:19,610 --> 00:22:28,100
More than like there's there should be 111114 takeaway message from a data visual.

151
00:22:29,120 --> 00:22:33,169
The idea that you're going to present a data visual and it's going to have this and this and this.

152
00:22:33,170 --> 00:22:37,220
No, it's not okay. It may all be there.

153
00:22:38,090 --> 00:22:42,330
The visual is a message and it's only going to get across one thing maximal.

154
00:22:42,660 --> 00:22:50,030
What is that? One of the things that it's getting across. All right.

155
00:22:50,760 --> 00:22:56,400
So. Let's look at some of the employees.

156
00:23:08,380 --> 00:23:14,780
Airline, right. What do you take away from this line?

157
00:23:16,930 --> 00:23:20,050
Quick gut reaction. What is this graph telling you?

158
00:23:24,410 --> 00:23:33,890
Yes. No change or lack of change. So notice the use of the line as opposed to bars is emphasizing pattern.

159
00:23:35,090 --> 00:23:42,610
But the flatness of this line is. Three leaves, it feels very flat.

160
00:23:43,480 --> 00:23:53,680
The fact that the points each of these point markers is so big such that the line is all kept within the diameter of those points is reinforcing.

161
00:23:53,980 --> 00:24:00,910
That makes it feel like nothing's changed here. Yeah.

162
00:24:00,930 --> 00:24:11,169
That's probably what I would take away from. I'm just going to this is just going to be me talking out loud a lot today sort of things.

163
00:24:11,170 --> 00:24:18,190
I know it's one this is okay. So the very clear about is a maximum total score here of 100.

164
00:24:18,520 --> 00:24:27,490
And the scale here represents the full range. You ever see something in which the graphic isn't representing the full possible range?

165
00:24:27,500 --> 00:24:31,100
Like if this graphic had cut off at 80, I would be pissed.

166
00:24:31,550 --> 00:24:35,330
I don't do that. That's one of the absolute do not do's.

167
00:24:37,100 --> 00:24:40,770
Why? Because it distorts the visual perceptions of the magnitude.

168
00:24:40,800 --> 00:24:48,500
It would make the variance seem larger than it actually is. The time intervals are spaced evenly.

169
00:24:48,500 --> 00:24:51,650
That's good. That's not always the case. Always check something like that.

170
00:24:52,780 --> 00:24:56,590
But agree. What am I taking away from this? Not much is changing.

171
00:24:57,280 --> 00:25:04,059
If you were intending for people to note that the word 59 rather than 56,

172
00:25:04,060 --> 00:25:08,170
and that that's a change compared to where we started ten years ago, this is not a good graph.

173
00:25:09,250 --> 00:25:18,220
He is not accomplishing that goal. Here's another line graph.

174
00:25:22,960 --> 00:25:29,530
Just in case you can't read it. Adjusted rates of drug overdose deaths involving prescription opioids.

175
00:25:29,530 --> 00:25:32,650
Heroin. Cocaine cycle stimulants. And synthetic opioid.

176
00:25:35,000 --> 00:25:38,870
So what do you take away from this?

177
00:25:39,230 --> 00:25:43,460
And even if you can't read the Legends, just sort of tell me what it is you're picking up from the graphic itself.

178
00:25:45,140 --> 00:25:48,580
Yeah. There's a pretty steep increase in whatever that wanted to do.

179
00:25:48,640 --> 00:25:55,300
I know that this there is this particular line here, which is the synthetic opioids where you see the trend.

180
00:25:55,760 --> 00:26:01,610
So what do you pick up here? Because it's a line graph. You're picking up the thing that goes up versus the things that don't.

181
00:26:05,300 --> 00:26:08,300
Notice how hard it is to read the legends?

182
00:26:08,630 --> 00:26:13,160
How hard it is to read the numbers on the side. Your perception of absolute magnitude here is minimal.

183
00:26:15,990 --> 00:26:19,170
That may be okay. But notice also, by the way.

184
00:26:20,590 --> 00:26:25,930
This line here. On a percentage basis.

185
00:26:27,320 --> 00:26:33,230
It's roughly 4 to 5 times over this time interval.

186
00:26:33,890 --> 00:26:42,050
You're probably not noticing it very much because in contrast to the other ones, that slope gets lost.

187
00:26:45,080 --> 00:26:48,860
In part because it ends up in the same place as the other ones,

188
00:26:48,860 --> 00:26:52,690
in part because it starts a lot like it's just sort of this part of this morass of stuff.

189
00:26:52,730 --> 00:26:59,510
You're not actually distinguishing much here. Now that particular one is psycho stimulant.

190
00:26:59,510 --> 00:27:06,530
So if I really wanted you to pay attention to the fact that psycho stimulant overdose deaths are really increasing,

191
00:27:06,530 --> 00:27:10,970
even though they aren't as high as some other things, that's not being communicated well here.

192
00:27:20,970 --> 00:27:25,100
Here's another one. When you take away from it.

193
00:27:34,750 --> 00:27:41,560
And so number one, more than anything else, you're probably taking away that everything is going down at the end.

194
00:27:42,050 --> 00:27:47,470
So you're taking away the macro pattern more than you are focusing on the differences between the lot.

195
00:27:47,710 --> 00:27:58,280
That's the secondary message. And if the point here is that, if I remember correctly, this is about levels of physical activity.

196
00:27:58,280 --> 00:28:02,270
So no physical activity, moderate physical activity and high physical activity.

197
00:28:02,600 --> 00:28:09,800
If the point is, look, the amount of physical activity that you engage in actually does give you some significant survival benefit.

198
00:28:10,870 --> 00:28:17,529
It's there. But you to get past that sort of first level message about everybody is going to be likely

199
00:28:17,530 --> 00:28:24,130
to only survive maybe 6 to 8 years in order to start to engage in that difference.

200
00:28:24,550 --> 00:28:28,030
If I wanted to highlight that difference more.

201
00:28:29,750 --> 00:28:36,560
Maybe we really need to think about some other ways of emphasizing the magnitudes of the difference, like right here.

202
00:28:37,100 --> 00:28:46,150
This is like a doubling of survival year nine. Did you get that in your head?

203
00:28:46,210 --> 00:28:50,540
Just pay attention like this. This is a perfectly accurate data. I is wrong with it.

204
00:28:51,440 --> 00:29:03,260
But from a message design standpoint. If I if my intent is to motivate you to engage in physical activity because it has this benefit,

205
00:29:03,920 --> 00:29:10,760
this is not as effective evoking a sense of effectiveness as some other graphic representations might be.

206
00:29:13,850 --> 00:29:21,830
For example, I would think about transforming this into that bar chart, that pair bar chart that I was sketching out over there.

207
00:29:22,460 --> 00:29:25,970
So that when we got to your state of mind, you would see this bar.

208
00:29:25,970 --> 00:29:39,060
Those bars are really different. This is a complicated graphic.

209
00:29:40,700 --> 00:29:43,870
But look at it simply. What do you take away from.

210
00:29:56,580 --> 00:30:01,170
Yeah. You're both going up, but consistently a little bit higher than the rest.

211
00:30:01,920 --> 00:30:07,790
Yeah. So if the big pattern you get here is both are better at the right.

212
00:30:07,800 --> 00:30:17,460
So what this means is this is measuring accuracy of pulse oximetry and measuring oxygen saturation between white patients and black patients.

213
00:30:17,940 --> 00:30:21,750
The higher oxygen saturation is both the more accurate everybody is.

214
00:30:23,970 --> 00:30:27,070
There is a difference. Fever. But.

215
00:30:28,030 --> 00:30:32,799
At lower levels, which, by the way, let's just pay attention here. When do you really care about this?

216
00:30:32,800 --> 00:30:36,180
When their oxygen saturation is high or when it's low?

217
00:30:36,190 --> 00:30:41,590
We care about it when it's low. So this matters the most at the levels where the disparity exists.

218
00:30:43,300 --> 00:30:48,190
It's. Now, what is this graphic trying to do?

219
00:30:48,550 --> 00:30:54,580
It's using a box, but it's showing variance of measurements at different levels.

220
00:30:54,880 --> 00:31:05,260
So it's trying to communicate trend and disparity between the two population and level of variation that exists at any given point.

221
00:31:08,160 --> 00:31:13,530
One of my general rules as a communication designer is don't try to do more than one thing at a time.

222
00:31:15,040 --> 00:31:21,250
If you want to show the trend, it was a line graph. It would be for you to pick up the trend a whole lot easier if you want to show the disparity.

223
00:31:22,210 --> 00:31:26,710
Maybe do borrowed, maybe do something else. Let's highlight the disparity. You want to show the variance.

224
00:31:26,710 --> 00:31:32,020
Let's show the variance. And not trying to be accomplishing anything else. But by trying to do all three things at once.

225
00:31:32,640 --> 00:31:36,190
We end up with a really busy graphic. It.

226
00:31:36,240 --> 00:31:39,090
It's difficult to extract any of these pieces.

227
00:31:42,060 --> 00:31:46,170
And you're going to say to me, yes, but if I only give you a polygraph, they don't know what the variability is.

228
00:31:46,170 --> 00:31:50,190
And I say, yes, I know that's the way I'm going to bias you today, because that's my message.

229
00:31:54,560 --> 00:32:03,230
One of my messages to you is we're thinking as a communication designer, you are not aiming for completeness necessarily.

230
00:32:03,470 --> 00:32:11,590
You are aiming to accomplish your messaging goal. Pick on what it is your goal is.

231
00:32:11,600 --> 00:32:17,089
If you wanted to highlight the disparity between the accuracy between white patients and black patients,

232
00:32:17,090 --> 00:32:23,000
which I think is really the takeaway message of this study, they could have done so much more clearly.

233
00:32:26,530 --> 00:32:33,580
Rather than the most complete reporting of the data, would have been a more impactful communication of that disparate.

234
00:32:50,570 --> 00:32:54,780
I forget who got this one. Where did you get it? It was one of.

235
00:32:57,650 --> 00:33:01,330
This was. But there's so many things wrong.

236
00:33:07,710 --> 00:33:14,850
So one of the things I'm going to emphasize over and over in this class, in this today is when we're talking about graphics, the key question here is,

237
00:33:16,280 --> 00:33:23,639
are you trying to represent a quantity that can have any level or are you trying

238
00:33:23,640 --> 00:33:26,910
to represent something that for which there is a bounded range of possibilities?

239
00:33:27,450 --> 00:33:31,319
We're talking about percentages. The percentages are ratios.

240
00:33:31,320 --> 00:33:36,180
They're out of 100. This is a fundamental truth of percentages.

241
00:33:37,020 --> 00:33:40,920
51 plus 43 plus 34 is not 100.

242
00:33:44,280 --> 00:33:47,290
You get so distorted of what I mean,

243
00:33:47,510 --> 00:33:57,320
maybe these I'm not even sure whether this the ratio of this to this is 51 to 43 or whether you knows this is just a nightmare.

244
00:33:58,790 --> 00:34:06,230
But it's a good introduction to the idea. That if you're representing something that has a fixed range.

245
00:34:07,830 --> 00:34:10,860
We a visual needs to represent that range.

246
00:34:12,330 --> 00:34:17,160
If it's a percentage and it's out of 100, you must represented out of 150.

247
00:34:17,250 --> 00:34:26,610
So it's really bad numbers. But on the other hand, I think their argument is pretty clear for talking about framing in this.

248
00:34:26,610 --> 00:34:33,120
Like they're probably saying, they want to show that there's more people who are trying marijuana today compared to 1987.

249
00:34:33,450 --> 00:34:38,220
And even though it's like percent of the wrong, that kind of did accomplish their goal today.

250
00:34:38,910 --> 00:34:43,440
Well, I guess I'm assuming. So you're assuming that you're able to extract from this.

251
00:34:44,590 --> 00:34:48,070
That the 51 is larger than the 43 and 34.

252
00:34:48,340 --> 00:34:56,690
Probably true. They're using wedges of a exploded pie to represent time.

253
00:34:58,650 --> 00:35:04,760
I, I don't know when this graphic was done, but it was 1999, so it was 1999.

254
00:35:04,760 --> 00:35:11,419
I did the idea in 1997. That's one thing is this is 2022, you know, the 21 and 1997.

255
00:35:11,420 --> 00:35:16,540
This is a very different thing and I have no idea what it is being represented here.

256
00:35:18,440 --> 00:35:24,760
And. If your point is that your goal is to show a trend,

257
00:35:25,450 --> 00:35:32,020
why are we doing this in this format when other visual formats like line graphs will make that trend much more visually sailing?

258
00:35:36,140 --> 00:35:40,720
So. You're going to hear me talk about part two whole.

259
00:35:42,090 --> 00:35:46,610
We evaluate something like a pie chart in part to hold structure.

260
00:35:49,760 --> 00:35:56,310
51% implies more than half that the which is less than a half.

261
00:35:57,960 --> 00:36:01,560
Woops. That doesn't make sense.

262
00:36:01,590 --> 00:36:05,970
That incongruity may not be conscious, but it's still there.

263
00:36:08,370 --> 00:36:13,650
So there's a meaning of the percentage in that is not being accurately represented here.

264
00:36:18,660 --> 00:36:26,910
I. So we have a part of all that we're good, like on that dimension.

265
00:36:27,310 --> 00:36:32,560
There is no distortion of the wedge size versus the percentages in this graph.

266
00:36:34,150 --> 00:36:39,910
What is this supposed to tell me? A lot going on.

267
00:36:40,450 --> 00:36:44,649
There's a lot of different. So these are different organizations, health centers,

268
00:36:44,650 --> 00:36:49,600
etc. There are lots of different organizations who are doing whatever it is that this is representing.

269
00:36:49,900 --> 00:36:57,670
And apparently Johns Hopkins does a lot of them. I don't want us to worry about what the what the numerical context is.

270
00:36:57,670 --> 00:37:00,850
I'm just want you to process the visual. What are you taking away?

271
00:37:01,780 --> 00:37:06,520
Because the most salient thing here is not specified, which tells me nothing.

272
00:37:11,450 --> 00:37:15,860
And there's no grouping, as far as I can tell of this.

273
00:37:16,220 --> 00:37:21,320
Like some of these organizations are places like National Journal, Madison, an Office of National Statistics,

274
00:37:21,890 --> 00:37:26,190
and some of them are South Dakota, Department of Health and the Health Department of South Africa.

275
00:37:26,210 --> 00:37:30,890
Like, am I supposed to be taking away what kind of organizations these are where they are?

276
00:37:31,130 --> 00:37:37,910
Is there any pattern here that I'm supposed to be taking away? Well, all I'm getting is Johns Hopkins does a lot.

277
00:37:37,940 --> 00:37:41,750
Everybody else does a little. And. That's about it.

278
00:37:45,830 --> 00:37:51,200
So if our purpose was to represent two whole ratios.

279
00:37:55,580 --> 00:38:02,969
Well, let's put it this way. Imagine for the moment that these are small enough.

280
00:38:02,970 --> 00:38:13,350
I can probably pull this off each. How big is this wedge here?

281
00:38:15,630 --> 00:38:20,790
Black one, you know, it's smallish.

282
00:38:22,530 --> 00:38:26,450
It's not wide, but it's. It's pretty small.

283
00:38:27,560 --> 00:38:34,160
I charts are some of the least precise visual displays to possible.

284
00:38:35,110 --> 00:38:41,870
Why? Because in our visual processing system, there's an ordering of what we do, consciously or unconsciously.

285
00:38:43,440 --> 00:38:46,980
The first and most fundamental level of processing is couched.

286
00:38:48,780 --> 00:38:55,679
I hear many animals have some degree of representation or they can look at something and recognize the difference between.

287
00:38:55,680 --> 00:39:05,720
There are three things and there are five things. So the process count first, then comes linear distance i length.

288
00:39:09,540 --> 00:39:17,670
What pie charts you. Area is a two dimensional space, which is much harder to estimate visually.

289
00:39:18,790 --> 00:39:24,920
And rotational angle you like.

290
00:39:24,940 --> 00:39:30,819
We are terrible at estimating rotational angle so you can if you want to use pie charts,

291
00:39:30,820 --> 00:39:35,530
you might be able to get most people to recognize the difference between 75% to 50%.

292
00:39:35,530 --> 00:39:39,580
But you will never get anybody to recognize the difference between 20% to 25.

293
00:39:42,390 --> 00:39:51,270
The level of precision is terrible. So if you want to use a particle, you would never use it with lots and lots of little wedges.

294
00:39:51,270 --> 00:39:58,650
You might only use it to represent big things rhat radically different levels of energy because we're familiar with it, etc.

295
00:39:58,980 --> 00:40:07,280
I'll argue there's alternatives as well. So now let's look at something that's a little bit better.

296
00:40:07,850 --> 00:40:13,960
Okay. So you have this sense of good things to it.

297
00:40:14,590 --> 00:40:19,270
Like in the middle, it tells you what the denominator is. Okay, so we got 480,000 deaths.

298
00:40:19,540 --> 00:40:24,790
That's what we're working with now, splitting of up into 1 to 6 categories.

299
00:40:26,170 --> 00:40:35,440
And the stuff on the left are the two big ones, which is probably what I want you to be paying most attention to anyway.

300
00:40:36,580 --> 00:40:42,930
Okay. It's good. But let me ask you this.

301
00:40:45,150 --> 00:40:48,150
Why is lung cancer on the top left?

302
00:40:52,710 --> 00:41:00,210
Yeah. Listen, the ratings that we've been conditioned here in the U.S. to read from top to bottom, from left to right.

303
00:41:00,210 --> 00:41:03,670
So the most. Apparent things.

304
00:41:03,680 --> 00:41:07,550
And so it draws our attention most to lung cancer.

305
00:41:08,750 --> 00:41:13,250
What does the data tell us? It's not the biggest. It's not the biggest one.

306
00:41:15,230 --> 00:41:23,450
So if we wanted to organize your attention by what is the largest cause of heart disease ought to

307
00:41:23,450 --> 00:41:29,660
be in the upper left lung cancer ought to be down here so that as we rotate around this graph,

308
00:41:29,780 --> 00:41:35,729
we are going in order of size. I have lung cancer worries.

309
00:41:35,730 --> 00:41:40,530
I have no idea. Somebody wanted lung cancer to be the thing that you paid attention to.

310
00:41:43,950 --> 00:41:46,650
There's a manipulation of your visual attention.

311
00:41:46,980 --> 00:41:53,670
Your perception unconsciously was that lung cancer was going to be bigger than heart disease because of its positioning in this graphic,

312
00:41:55,090 --> 00:41:57,710
I was just going to say it's probably easier.

313
00:41:57,720 --> 00:42:04,770
They were probably thinking it's easier to make the association between smoking and lung cancer than it is smoking and heart disease.

314
00:42:05,400 --> 00:42:13,049
But that's essentially what they're doing is they're kind of lying with the statistics by not emphasizing that it's actually heart disease.

315
00:42:13,050 --> 00:42:13,940
That's the biggest piece.

316
00:42:13,950 --> 00:42:22,050
And if I'm sitting here as a communicator and you already have an association between Lyme disease and lung cancer and smoking,

317
00:42:23,100 --> 00:42:24,899
what is my purpose behind this graphic?

318
00:42:24,900 --> 00:42:35,000
I might want to break that association, help you understand that, in fact, heart disease is a more common cause of disease from Cigarets.

319
00:42:37,320 --> 00:42:40,740
And so that's getting lost you. This goes back to the question.

320
00:42:40,740 --> 00:42:45,500
This is why we started with Eva's question. What's the purpose here? What is the takeaway that we're trying to get from this?

321
00:42:46,320 --> 00:42:52,890
If my purpose is for you to know what is most likely to happen to you as a result of smoking cigarets this is not doing that.

322
00:42:55,280 --> 00:42:59,269
So like this could be going a little bit off of the discussion.

323
00:42:59,270 --> 00:43:03,559
But wouldn't it be like you surprise me, like taking something that you're familiar with,

324
00:43:03,560 --> 00:43:07,940
like, okay, smoking of lung cancer and then introduce newer concepts for people.

325
00:43:08,240 --> 00:43:14,590
So if we wanted to do that. That might be.

326
00:43:15,070 --> 00:43:22,210
I mean, my reaction to that is I don't want to distort the presentation to accomplish that goal.

327
00:43:22,810 --> 00:43:28,840
But what I might do is introduce this in a way that guides people to that realization.

328
00:43:28,960 --> 00:43:36,130
So I have this graphic been flipped so that heart disease was up here and disease or lung cancer was down here.

329
00:43:38,680 --> 00:43:42,430
I might have started the conversation about this graphic and saying, you know,

330
00:43:42,700 --> 00:43:47,290
we think mostly about the fact that cigarets and there's a lot of association between Cigarets and lung cancer.

331
00:43:47,290 --> 00:43:53,500
And in fact, there's lots of lung cancer. That's cause it is the second largest cause of death.

332
00:43:55,040 --> 00:43:59,660
On Cigaret and draw their attention there. But then use that contrast to say.

333
00:43:59,750 --> 00:44:03,050
But notice that it isn't the first one. What's at the top? Heart disease.

334
00:44:03,140 --> 00:44:06,610
My primary message might then be Pay attention to heart disease.

335
00:44:07,450 --> 00:44:11,570
This is in fact the largest consequence in terms of mortality of cigaret smoking.

336
00:44:12,260 --> 00:44:18,920
So good thinking about like we may want to make that connection, but I would never want to distort the visual.

337
00:44:20,140 --> 00:44:21,459
Based upon prior knowledge.

338
00:44:21,460 --> 00:44:29,920
I want the visual to be as fair of a representation of the data in a way that supports my primary message and that second piece.

339
00:44:29,920 --> 00:44:34,000
That's hard. Yeah. So would you argue that this is distorting the data?

340
00:44:34,060 --> 00:44:37,680
Yes. In it. Let me be clear.

341
00:44:38,640 --> 00:44:42,690
It is not distorting of the data in the sense that the wedges are proportionate.

342
00:44:42,870 --> 00:44:52,950
It is showing the whole relationship. It is distorting the data in that it is set up where we think it's representing things in order, but it is not.

343
00:44:53,940 --> 00:44:57,690
And that cruelty between what I think the graphic is doing,

344
00:44:58,260 --> 00:45:05,850
because everything else we go around is in order of magnitude, like if this was in alphabetical order.

345
00:45:06,450 --> 00:45:12,870
So we started with chronic. We started here as achl0s.

346
00:45:13,440 --> 00:45:16,889
That was like, Oh, it's an alphabet. I want to do this alphabetical order.

347
00:45:16,890 --> 00:45:23,690
But you didn't. But okay. If this was states like there are lots of things in which we organize by alphabet.

348
00:45:23,710 --> 00:45:29,970
Alphabet, alphabetical order. Fine. Then it's not the story, because I'm understanding why the pattern is there.

349
00:45:30,240 --> 00:45:35,040
What's weird about this to me, if you have a pattern that makes that isn't anything that I can explain.

350
00:45:36,410 --> 00:45:41,160
Yeah. Then would it be okay to have this type of visual with, like, distorting the data?

351
00:45:41,180 --> 00:45:49,760
The goal was like, this was included in something aimed at increasing lung cancer screening per se egg or that still a problem.

352
00:45:51,160 --> 00:45:54,970
So you are asking a very fair ethical question.

353
00:45:55,180 --> 00:46:00,910
Yes. Is it acceptable to distort people's understanding of the.

354
00:46:02,090 --> 00:46:07,430
Proportion of deaths. Caused by each of these conditions.

355
00:46:07,760 --> 00:46:17,540
In order to achieve the goal of having people pay attention to that, there is no simple answer to that.

356
00:46:18,110 --> 00:46:25,190
As long as you know you are manipulating and distorting somebody's perceptions, you can ask yourself that question.

357
00:46:25,200 --> 00:46:34,370
I tend to shy away from that, in part because when we get into the business of manipulating individuals, we lose people's trust.

358
00:46:34,370 --> 00:46:38,810
And that carries forward well beyond the given situation.

359
00:46:39,800 --> 00:46:48,360
But that is the underlying question. Now let's look at Barbara's.

360
00:46:49,940 --> 00:46:57,920
So. I wanted to start with talking about bar graphs with this one because this has some pretty decent things to it.

361
00:47:01,560 --> 00:47:06,120
We have noticed how simple this is. We have three groups with three bars.

362
00:47:06,240 --> 00:47:09,600
And that's it. And.

363
00:47:11,160 --> 00:47:14,220
What am I supposed to take away from it? I'm supposed to take away from it.

364
00:47:14,250 --> 00:47:19,170
Look, the pattern is different between this here, here and here.

365
00:47:19,870 --> 00:47:24,050
That's the first thing I like. Wow. That's a really different pattern in each of these three things.

366
00:47:24,060 --> 00:47:29,760
What's going on here? And I love the fact that they've got this label drawn to the one high blue bars.

367
00:47:29,760 --> 00:47:33,480
Like what? I know. Okay, here. Cancer is really high.

368
00:47:33,960 --> 00:47:38,730
Here, cancer is really low, like, oh, okay. So now I'm getting into what is the different pattern here?

369
00:47:40,970 --> 00:47:44,010
Again. Notice this.

370
00:47:45,150 --> 00:47:49,910
This access is really minimized. It's hard for me to understand.

371
00:47:50,960 --> 00:47:56,840
But I'm seeing the pattern now. My one complaint about this.

372
00:47:58,210 --> 00:48:07,790
Is this just showing? Percentages are two whole relationships, and yet the access only goes up to 60%.

373
00:48:10,080 --> 00:48:16,780
You could have done this in a graphic format, but many people do not use very often.

374
00:48:18,420 --> 00:48:25,830
It has some real benefits, which would be a stacked bar structure.

375
00:48:26,880 --> 00:48:30,710
So. Something that looks like.

376
00:48:34,980 --> 00:48:54,710
This verse is. This is showing the full range of hard to hold.

377
00:48:56,200 --> 00:48:59,310
What do I see this blue as much bigger than that here.

378
00:48:59,730 --> 00:49:05,550
Now they're much more equal, I think. Yes, the same thing here, but it's not showing the path.

379
00:49:05,570 --> 00:49:09,350
All right. This is not bad. Don't get me wrong. I'm not going to I'm not going to really trash this graphic.

380
00:49:09,360 --> 00:49:15,870
I think there's a lot of good at it. But I want you to pay attention to the fact that it's not showing cleanly that part.

381
00:49:15,870 --> 00:49:22,139
The whole anytime you take a whole you breaking into separate bars, you're undermining that understanding that there is,

382
00:49:22,140 --> 00:49:27,450
in fact, a hole that this number cannot go up without these going down.

383
00:49:35,630 --> 00:49:38,360
And here's an example where Republicans really salient.

384
00:49:39,830 --> 00:49:47,660
So again, I'll read off the legend to your flip behavior as during the past month, how many hours of actual sleep did you typically get each night?

385
00:49:47,870 --> 00:49:52,970
Seven or fewer hours. More than 7 hours. Those two things add up to 100.

386
00:49:52,980 --> 00:50:01,420
Why are they two different bars? You can't get one of those bars to go higher without the other one going down.

387
00:50:01,450 --> 00:50:06,249
It doesn't show the parts of a relationship. A pie chart would do this.

388
00:50:06,250 --> 00:50:10,360
Okay. Although again, we'd lose the precision graphic like that would do that.

389
00:50:10,360 --> 00:50:18,460
Just pop. Yes.

390
00:50:19,510 --> 00:50:23,140
What will we be losing in precision with the pie chart? I'm sorry.

391
00:50:23,350 --> 00:50:29,980
Why would we be losing precision with a pie chart? So this is 71% versus 29%.

392
00:50:30,220 --> 00:50:37,390
The pie chart that you would generate would come so close to being 75, 25 that that's probably what most people would take away from it.

393
00:50:37,420 --> 00:50:40,720
You wouldn't get the 71 versus 75 level of precision.

394
00:50:43,000 --> 00:50:48,100
Because you just label it. I. Why don't we quit label?

395
00:50:50,290 --> 00:50:59,590
And what is the implication of labeling? And then again, people are going to read it.

396
00:51:00,010 --> 00:51:07,000
So you're going to translate the mental processing of that graphic away from the unconscious.

397
00:51:07,010 --> 00:51:10,600
How big is this area toward reading numbers?

398
00:51:12,130 --> 00:51:16,810
And everybody read numbers equally well. You know, we just went through this with numeracy.

399
00:51:17,410 --> 00:51:22,330
Then you're relying upon data labels to communicate your data.

400
00:51:22,750 --> 00:51:28,239
You are prioritizing high numerate people who will focus in on those numbers and read

401
00:51:28,240 --> 00:51:35,130
them and do prioritizing less numerate people who will not process those numbers.

402
00:51:35,140 --> 00:51:43,570
They will only be processing the visual. And they will be less able to derive the meaning that you want from that.

403
00:51:43,570 --> 00:51:50,229
Right. So, you know, I look at this, I know that as a highly numeric person, my I goes to the data level.

404
00:51:50,230 --> 00:51:55,060
It says 71%, 29%. I will process the data from there.

405
00:51:56,190 --> 00:52:02,990
I also know that a less numerate person will not read those numbers and they will get only the relative sense of height.

406
00:52:03,720 --> 00:52:13,800
That's all they're going to take away from the fact. So they levels are fine, but let's own the consequences of them.

407
00:52:14,190 --> 00:52:18,600
Yeah. I'm sorry. How is that any more precise than a pie chart from.

408
00:52:20,150 --> 00:52:25,660
If you're if you're assuming that low rent, people are just going to take high and low.

409
00:52:27,330 --> 00:52:37,830
Well, what's the big deal? If you know the picture, it looks like it's 75, 25, an AP problem if you don't care about precision like so.

410
00:52:37,830 --> 00:52:41,880
There are plenty of situations in which all we're trying to do is communicate really coarsely.

411
00:52:42,220 --> 00:52:48,299
This is way bigger than that, in which case. But just all of that, you're not actually communicating a very precise number.

412
00:52:48,300 --> 00:52:52,860
You're communicating a very loose sense of large or small.

413
00:52:54,920 --> 00:53:02,350
Precision sometimes doesn't matter at all. But be conscious that you're losing that when you make a choice to go down that pathway.

414
00:53:08,840 --> 00:53:11,239
I kind of read this, by the way,

415
00:53:11,240 --> 00:53:18,170
this graphic has approximately I think we've now counted 32 different terms that are used to represent this type of graphic.

416
00:53:18,560 --> 00:53:19,820
I kind of read pictogram.

417
00:53:20,450 --> 00:53:28,129
All of people say the line and I will use the term icon array because I think that's the thing that's becoming most prevalent here.

418
00:53:28,130 --> 00:53:32,540
You have houses we often use. People got to read stuff about this.

419
00:53:33,860 --> 00:53:39,010
Why is this? One.

420
00:53:39,130 --> 00:53:42,970
Remember what I was saying about visual processing? The first thing we process is count.

421
00:53:43,570 --> 00:53:48,670
You can count this. Even if you are not consciously counting it, you are unconsciously counting.

422
00:53:50,460 --> 00:53:55,250
Two, it has the same part two whole relationship that we've got in a pie chart of our chart.

423
00:53:55,250 --> 00:54:00,540
Two things like that. Three. You also have a secondary height.

424
00:54:00,560 --> 00:54:04,010
Q Like, how tall is this?

425
00:54:04,010 --> 00:54:09,800
How tall is that is an imperfect but not bad estimate of the ratios being represented.

426
00:54:11,880 --> 00:54:22,050
And for because you're counting this type of graphics more than most, which is really good at showing small differences.

427
00:54:23,220 --> 00:54:28,240
So, you know, this is 26, even though you know.

428
00:54:28,470 --> 00:54:32,010
Well, I guess down here down here is where it actually says 26.

429
00:54:32,010 --> 00:54:36,360
But I didn't even notice that this this I just looked at this like, okay, two rows, each one's a ten.

430
00:54:36,360 --> 00:54:45,050
They're six. They're 26. Well, I've done. I picked up a level of precision with this type of graphic that you wouldn't pick up with a bar chart.

431
00:54:47,720 --> 00:54:53,960
That is appropriate. There's lots of weaknesses to this kind of thing, and especially if you want to talk about really small ratios.

432
00:54:54,110 --> 00:54:57,140
I try to do this with a thousand or 10,000.

433
00:54:58,550 --> 00:55:01,640
But then again, nothing really well represents those kinds of ratios.

434
00:55:05,360 --> 00:55:16,210
Now we get things like this. Everybody's sort of like.

435
00:55:20,350 --> 00:55:29,150
First of all. I am not completely sure what the 94% of the 94% is represented.

436
00:55:29,160 --> 00:55:39,930
I think that's not actually visually shown here. I'm hoping that those dots actually do count to 229, but I have no idea if that's true.

437
00:55:39,930 --> 00:55:43,780
And if it's not true, that's a distortion. And.

438
00:55:45,020 --> 00:55:49,130
Like, Okay, it's the shape of Africa I got. We're talking about Africa, but.

439
00:55:49,430 --> 00:55:52,010
But this is not helping me process the number in any way.

440
00:55:55,340 --> 00:55:59,690
I wanted to show you this, to set up some of the stuff that was going to come later in my list of examples,

441
00:55:59,690 --> 00:56:05,420
because a number of you gave examples that are maps and there's a whole set of important things to talk about data maps.

442
00:56:07,760 --> 00:56:11,750
Before that. I want to talk a little bit more about a couple other things. Here's a small.

443
00:56:13,350 --> 00:56:18,980
At a bar charts. What's good?

444
00:56:19,100 --> 00:56:33,300
What are you getting from this? What's good about this? What's not so good about this? It shows hierarchy.

445
00:56:33,810 --> 00:56:35,100
It does show hierarchy.

446
00:56:35,520 --> 00:56:45,000
It shows that one of the things you take away quite quickly is that the rates for the top, which is white, are much bigger than everybody else.

447
00:56:48,870 --> 00:56:59,040
NORRIS One of the things you do not as easily pick up is the size of the male female differences by separating genders.

448
00:56:59,130 --> 00:57:05,790
You are making it harder to make gender comparisons and easier to make demographic group comparisons.

449
00:57:06,270 --> 00:57:10,970
That may be fine or not fine, depending upon your purpose. Let's just own what it's doing here.

450
00:57:12,490 --> 00:57:17,410
The other thing I want to point out is what is the statistic rate per 100,000 people?

451
00:57:18,430 --> 00:57:23,110
So 100,000 if we were to visually represent this.

452
00:57:24,360 --> 00:57:27,790
That's pointing north. This is probably somewhere around lancing. I don't know.

453
00:57:27,790 --> 00:57:31,030
I mean, like, we're not actually showing the denominator here.

454
00:57:32,100 --> 00:57:37,570
We're only showing the numerator. So this is not actually representing the ratio at all.

455
00:57:38,620 --> 00:57:43,930
It should be showing differences in the in the numerators and the counts for these different populations.

456
00:57:44,920 --> 00:57:50,730
That's fine. But let's on what it is any. How common is it to put it sideways like that?

457
00:57:55,910 --> 00:57:59,860
We do it in a way. I mean, again, there's tradeoffs, like, where is your eye drawn?

458
00:58:00,040 --> 00:58:03,160
My eyes drawn to the top. At the top. Right.

459
00:58:04,290 --> 00:58:06,870
What if I hadn't noticed the size of the white bar?

460
00:58:07,770 --> 00:58:14,250
If I reorganized it and made it left to right and we had vertical bars, maybe I would have the same emphasis in terms of where my eyes draw.

461
00:58:15,120 --> 00:58:16,950
You could do this in different orientations.

462
00:58:18,060 --> 00:58:26,430
There is some work on horizontal versus vertical bar comprehension in terms of reaction time and accuracy.

463
00:58:27,060 --> 00:58:35,040
My understanding is that it's not huge. We're still measuring distance in our minds and we're pretty decent about going this way versus that way.

464
00:58:40,440 --> 00:58:43,920
Just this one.

465
00:58:45,360 --> 00:58:51,989
There's so much subtle stuff going wrong here. The piece you're not picking up is political.

466
00:58:51,990 --> 00:58:55,800
It's hard for you to read. These are dates down here. Let me read the date.

467
00:58:56,790 --> 00:59:00,630
April 28th. April 27th. April 29th.

468
00:59:01,380 --> 00:59:05,040
May 1st. April 30th. And the fourth.

469
00:59:07,670 --> 00:59:12,270
What's the. So what's the pattern here?

470
00:59:12,510 --> 00:59:17,100
They've organized dates from largest to smallest.

471
00:59:18,690 --> 00:59:22,740
But time we expect to go linearly.

472
00:59:23,710 --> 00:59:31,920
So if, by the way, I'm not even sure of how there is this based upon the average height here because this one drops

473
00:59:31,920 --> 00:59:36,960
down to like I don't I don't I literally don't know what they're trying to do with this guy.

474
00:59:41,140 --> 00:59:45,360
In five counties. You have a whole bunch of different times you have. I don't get it.

475
00:59:49,140 --> 00:59:59,719
So whatever he was trying to accomplish, he didn't do well. Here's another complicated graph that I think has some more to speak to it.

476
00:59:59,720 --> 01:00:05,030
So this is really weird. You don't usually see bar charts going down, but we're talking about death.

477
01:00:05,810 --> 01:00:08,930
So there is a logic here. Why? Why is it red?

478
01:00:08,960 --> 01:00:19,340
Why is it going down? Because of death. You've got five good magnitude going down.

479
01:00:19,430 --> 01:00:23,720
Okay. You've got different colors representing different regions of the world.

480
01:00:26,010 --> 01:00:29,530
Now. What do you take away from this? We do not take away from.

481
01:00:34,560 --> 01:00:39,030
Is what I get. You see, the overall pattern is like, I know.

482
01:00:40,470 --> 01:00:45,960
This and this, or when the main peaks globally were in terms of COVID 19 deaths.

483
01:00:46,860 --> 01:00:49,979
That's easy to pick up. What is this?

484
01:00:49,980 --> 01:00:56,190
Trying to tell us, however, is also patterns within different parts of the world.

485
01:00:56,970 --> 01:01:02,970
It's much harder to pull that out. Like I can tell fairly easily that Europe was low here and then blew up here.

486
01:01:03,660 --> 01:01:10,770
But America's is big here and it's also been here. Are these big I like I can't do that comparison because they're not visually close to each other.

487
01:01:12,090 --> 01:01:18,690
So I've lost what the pattern is in the Americas. I can only see the big power.

488
01:01:18,960 --> 01:01:22,980
Which means why am I giving you. Giving me all that level of detail if I can't pull it out?

489
01:01:23,370 --> 01:01:24,659
Yeah. I just want to agree with you.

490
01:01:24,660 --> 01:01:32,460
I don't understand why they they choose gradients for groups like this when contrasting colors would do the job much better.

491
01:01:32,730 --> 01:01:36,510
Well, notice that even if you gave me contrasting colors, the problem still remains.

492
01:01:36,510 --> 01:01:43,350
Like if it was a super contrast in color. And I could easily tell what the wedge what it would help a little bit, but not solve the problem for sure.

493
01:01:44,640 --> 01:01:48,930
We'll talk about color in a moment. Well, I'll just defend this one since this was actually mine.

494
01:01:49,830 --> 01:01:54,719
I think I think what you're touching on is they tried to add a secondary focus it and it really

495
01:01:54,720 --> 01:02:00,420
wasn't a good idea to do it in a manner like if they had just talked about it as todos alone,

496
01:02:00,420 --> 01:02:04,410
it would have been probably less confusing than trying to break it down.

497
01:02:04,530 --> 01:02:09,510
I have no problem with this for the totals. Like it's really obvious what the pattern is over time.

498
01:02:10,580 --> 01:02:16,790
That's great if that's what my message is. If you want to highlight regional differences, you needed something else to make that.

499
01:02:16,940 --> 01:02:23,480
That's exactly. And again, this goes back to the idea of one doing one thing at a time.

500
01:02:23,490 --> 01:02:28,980
Please know that you're trying to not represent everything about the data that you're trying to craft a message.

501
01:02:29,610 --> 01:02:36,670
What is that message that you want to get across? Yeah, no, no, no.

502
01:02:36,720 --> 01:02:41,940
It's a3d, you know, it's a lack of pattern. No, do I can't, you know.

503
01:02:45,250 --> 01:02:47,260
By the way, an important point.

504
01:02:50,850 --> 01:03:00,570
3D graphics are structurally harder to read because even if I just take one of these bars and I'm trying to measure, remember, bars are height.

505
01:03:00,820 --> 01:03:07,139
I'm trying to measure height. I have to add my measure of this top right here or this side print or this.

506
01:03:07,140 --> 01:03:13,800
Bottom point. It's ambiguous. What is the height that I'm supposed to be reading off of this graphic?

507
01:03:15,750 --> 01:03:20,820
So general rule 3D graphs are less understood and 2D graphs.

508
01:03:22,120 --> 01:03:27,190
Here's the one that's really annoying. Animated graphs are less understood than static graphs.

509
01:03:29,680 --> 01:03:33,669
Why? Because you're pinning all of your conscious attention on looking at the cool

510
01:03:33,670 --> 01:03:37,570
animation and you're not processing the visual heights or the areas represented.

511
01:03:37,930 --> 01:03:46,240
I've done two or three visual studies of patient perceptions using animated graphics.

512
01:03:46,520 --> 01:03:49,810
We've tried everything. I have yet to have animation help ever.

513
01:03:53,360 --> 01:04:01,400
In fact, one of the titles of the paper is cool but counterproductive. So let's talk about maps.

514
01:04:04,700 --> 01:04:11,719
This is a classic. Adelman. You've got counties in Michigan, you've got intensity of color.

515
01:04:11,720 --> 01:04:15,650
It's a darkness versus light. This is the cue that we're picking up on.

516
01:04:16,930 --> 01:04:20,790
Okay. What do you get from this graphic?

517
01:04:21,050 --> 01:04:27,600
Like, what's good about it? There's a lot of good here.

518
01:04:27,680 --> 01:04:30,720
Like, I'm not. This is not me. You want to be wrong.

519
01:04:36,740 --> 01:04:41,940
Yeah, but with color, you generally assume it's something gets darker, it gets more serious.

520
01:04:41,960 --> 01:04:51,270
So if it hadn't just been random colors like blue is low and green is high or something like that, you wouldn't have thought that's what it was.

521
01:04:51,590 --> 01:04:56,499
This is a situation in which color gradients are actually serving us well. Like I have a sense of darker.

522
01:04:56,500 --> 01:04:59,800
It means more. And that's fair.

523
01:04:59,830 --> 01:05:04,270
Like, there's more stuff happening in the southeast of Michigan than there is in the Upper Peninsula.

524
01:05:05,500 --> 01:05:14,590
That that really clearly. Obviously with a map, it's sometimes hard to see specific spatial patterns.

525
01:05:14,590 --> 01:05:21,400
But if you care about a particular location and you can find your location like I know this is Washtenaw County, we are here.

526
01:05:24,740 --> 01:05:28,880
So, okay, we're in the high zone, but we're not as dark as the counties next to us.

527
01:05:28,900 --> 01:05:36,340
Okay. That's what I've got there. I'm going to show you some ways in which these graphics this is not bad, by the way.

528
01:05:37,330 --> 01:05:49,160
I'm going to show you ways in which these graphics go wrong. Why this color scheme?

529
01:05:51,530 --> 01:05:57,230
There's an answer here. I have. I have an immediate answer. What do we stop?

530
01:05:58,040 --> 01:06:03,860
Yeah, we have emotional associations with red, yellow, red, orange, yellow, green.

531
01:06:04,980 --> 01:06:08,390
Humans in this society. Let's acknowledge that's cultural.

532
01:06:09,080 --> 01:06:14,330
So greed is good. The implication is if you are in a relocation, you are good.

533
01:06:15,850 --> 01:06:19,920
If you are in one location. Not so good.

534
01:06:20,820 --> 01:06:25,240
Yes. This is a dark orange moving towards red. That. Notice.

535
01:06:25,690 --> 01:06:30,430
Who knows what the levels of this is, right? All the legit tells us is low versus high.

536
01:06:30,730 --> 01:06:34,530
So whatever quantitative magnitude is underlined, the that is long gone.

537
01:06:34,960 --> 01:06:37,990
That all get it to be last part. Talking about labels.

538
01:06:38,320 --> 01:06:41,580
This is labels in a graph. Yeah.

539
01:06:42,220 --> 01:06:47,890
Correct me if I'm wrong, cause I can't see. Great. But I don't even see the highest red color correct on the graph.

540
01:06:47,890 --> 01:06:51,570
So why make the scale go further than any of the data does?

541
01:06:52,340 --> 01:06:55,389
Oh, no, this this color is this color. Oh, okay.

542
01:06:55,390 --> 01:07:00,780
Okay. They've they've basically split this into group.

543
01:07:00,820 --> 01:07:06,500
It's now key question here. Um. What is the most common color?

544
01:07:08,100 --> 01:07:21,060
95 area. Is that because there is some absolute threshold that was defined to say low levels are X and moderate levels are Y,

545
01:07:21,420 --> 01:07:31,650
or is that because they're sorting areas by population and we have a lot of areas in this country that have low population and this is just tertiles.

546
01:07:34,990 --> 01:07:38,860
I remember when we moved from data to area.

547
01:07:39,100 --> 01:07:43,690
Unless we're talking about characteristics of the physical area, we're talking about people.

548
01:07:43,690 --> 01:07:46,990
People are not evenly distributed. We have concentrated like.

549
01:07:47,990 --> 01:07:51,209
What's going on? Right here and here.

550
01:07:51,210 --> 01:07:57,410
Right there is Cleveland. There's Detroit is a whole lot more people than in a lot of the other parts of those states.

551
01:07:58,720 --> 01:08:02,860
So that's unconscious. We are not consciously representing this.

552
01:08:02,860 --> 01:08:06,610
And at least one or two you talked about electoral maps like voting maps.

553
01:08:07,180 --> 01:08:12,100
Same issue pops up like you look at a map like this, a voting patterns,

554
01:08:12,550 --> 01:08:19,270
and it shows a lot of areas of the country that are predominantly more conservative or Republican in terms of their voting.

555
01:08:19,870 --> 01:08:23,530
But if you think in terms of population, that's because.

556
01:08:24,560 --> 01:08:29,090
Republican voters tend to be in more worlds, more common in more rural areas.

557
01:08:29,540 --> 01:08:32,750
Democratic voters tend to be more urban areas.

558
01:08:32,870 --> 01:08:37,610
They are concentrated. So here's another map.

559
01:08:38,680 --> 01:08:43,840
Air pollution exposure in Brussels. Concentrations of black carbon at 2.5.

560
01:08:45,540 --> 01:08:48,809
Color gradient here represents darker means more.

561
01:08:48,810 --> 01:08:52,320
More is bad luck and all things we see before.

562
01:08:53,340 --> 01:09:01,920
One key things that I want you to notice about this. Why are the scales the way they are?

563
01:09:03,630 --> 01:09:08,730
I look at this. 4.21.3.

564
01:09:08,730 --> 01:09:15,000
1.4 to 1.8. 1.92.1.5 range for range.

565
01:09:15,000 --> 01:09:19,020
0.3 range. Point three range and then eight.

566
01:09:22,390 --> 01:09:27,010
What? What? What? What's going on here? I'll tell you what's going on.

567
01:09:27,820 --> 01:09:33,820
I mean, I was just going to say there's probably some lower baseline limit, but then they're also trying to indicate the magnitude that.

568
01:09:34,060 --> 01:09:40,959
So, like, maybe there's like a high risk threshold at 2.5, but then there's also like access levels of beyond that.

569
01:09:40,960 --> 01:09:47,050
So that's showing that like just because it's it's at 2.5 to infinity, there is like an upper limit.

570
01:09:47,530 --> 01:09:49,450
So there are two possible answers here.

571
01:09:49,480 --> 01:10:01,480
You have speculated one, which is that these categories are based upon some appropriate categorization of levels as mapping to risk the opposite one,

572
01:10:01,480 --> 01:10:07,720
which is, I think, more likely what is true is the range of values that were observed goes from 0.8 to 10.5.

573
01:10:08,080 --> 01:10:14,229
They split it into quintiles and the darkest red is the is the darkest quintile,

574
01:10:14,230 --> 01:10:18,219
which happens to be over a big long range because there's a couple outliers that

575
01:10:18,220 --> 01:10:23,720
are really high and most of the values are down in the two or three range, but you don't know.

576
01:10:25,180 --> 01:10:34,860
And so the reason I want to show this I want is a. How many of you have gone to see, like, maps like this?

577
01:10:36,270 --> 01:10:42,329
Over 19 cumulative case counts over the course of the pandemic?

578
01:10:42,330 --> 01:10:48,360
I don't mean like right now, but the cumulative stuff The New York Times has that lots of ones, the places that have these kind of graphics.

579
01:10:50,610 --> 01:10:56,910
They used the same kind of color gradient to represent places that have had more COVID 19 cases versus last.

580
01:11:00,220 --> 01:11:07,360
But this. Though I know this to be true for New York Times, it must be true for every well.

581
01:11:07,960 --> 01:11:16,210
They have been using the same basically orange color scheme to represent density in terms of more cases versus the last four two years.

582
01:11:17,350 --> 01:11:23,830
They've had to recalibrate what those colors meant at least 3 to 4 times over the course of the pandemic,

583
01:11:24,460 --> 01:11:28,840
to what was dark orange two years ago, is now a light orange.

584
01:11:32,410 --> 01:11:36,520
What people are graphics show. They show relative information.

585
01:11:37,510 --> 01:11:42,370
This is talk. This is above average and below average in graphic form.

586
01:11:44,680 --> 01:11:54,130
They are not showing cleanly absolute levels because you have to do that mapping to the meaning of those categories in order to derive that.

587
01:11:55,030 --> 01:12:01,360
So even though every time I go look at those maps, I see that Michigan has roughly the same color.

588
01:12:02,650 --> 01:12:06,430
It's completely masking the fact that those numbers are going up and up and up over.

589
01:12:12,940 --> 01:12:16,089
One last one. Another Coen map.

590
01:12:16,090 --> 01:12:23,350
This is from Colorado showing physical locations have outbreaks in couple I guess about a week ago.

591
01:12:24,820 --> 01:12:30,760
Same basic point we were just talking about here. What do you get from it without even knowing what these things are?

592
01:12:30,790 --> 01:12:35,860
What I see is that lots of whatever this is are here and here and here.

593
01:12:38,520 --> 01:12:44,530
This is. Denver and Boulder and Colorado Springs and Pueblo like this is just a population

594
01:12:44,530 --> 01:12:49,389
that isn't telling me anything other than the population density in this space.

595
01:12:49,390 --> 01:12:56,290
I have no idea whether the rate of COVID 19 infections is different in one place versus another, because that's not what this is showing.

596
01:13:00,310 --> 01:13:13,210
I. So take the last few minutes of all these attacks, and we've talked about lots of things that go well in these graph.

597
01:13:13,330 --> 01:13:20,120
We talk lots of things that don't necessarily go well. You're going to be designing graphics, going to be designed ways to put forward doing it.

598
01:13:21,120 --> 01:13:24,660
What are you going to take away from this? What are the principles that you want to hold on to?

599
01:13:24,680 --> 01:13:32,400
That said, I want to make sure when I'm developing graphics that I do X or that I don't do what just that a few at your table talking through.

600
01:13:32,430 --> 01:13:37,950
What is it you're going to take away as a core ideas of what a good photographer should be?

601
01:13:44,350 --> 01:14:11,400
It's kind of it's not like they're just they're still trying to manage so many examples of distortions.

602
01:14:12,810 --> 01:14:23,680
Yes. Yes, I think that's correct. But I think there is a possibility it takes away from what you're trying to do.

603
01:14:23,700 --> 01:14:46,680
And I think it's not something that I think it's very likely that some of these graphs would be like Greek and three medical errors.

604
01:14:48,210 --> 01:14:57,250
And I think the goal is 1% higher than the second was.

605
01:14:58,040 --> 01:15:01,410
It was my time. I think I was right. Yeah. Yeah.

606
01:15:03,330 --> 01:15:08,140
You know, I don't know.

607
01:15:08,510 --> 01:15:42,030
I think that like a general audience and everything like that, because these are young men and there's a lot of like a lot more experience.

608
01:15:46,470 --> 01:15:57,650
Like I, you know, I had to dress like like what is what is this person?

609
01:15:58,540 --> 01:16:08,209
I can't breathe. Yeah, I, you know, I think yeah, that's true.

610
01:16:08,210 --> 01:16:24,760
But if we understood, it can be really important, like or something like that.

611
01:16:24,890 --> 01:16:32,910
It's like, am I making it more useful?

612
01:16:32,910 --> 01:16:53,730
I think not only for me, it's not like I don't want to be like, all right.

613
01:16:54,450 --> 01:16:58,950
Oh, is that just like, I don't want last thing I want to say, I'll let you guys go.

614
01:16:59,820 --> 01:17:03,149
So we're hearing some of your conversations.

615
01:17:03,150 --> 01:17:08,670
One of the things that come up that's important is honest.

616
01:17:09,810 --> 01:17:21,950
Who are you making this for? That's so critical in part because what your goal is is going to be different often for different audiences.

617
01:17:22,460 --> 01:17:25,760
That may be because different audiences need to focus on different things,

618
01:17:26,420 --> 01:17:29,960
and it may be because different audiences will already understand certain things.

619
01:17:31,140 --> 01:17:36,709
So the transition here that I'm trying to set you up for is what you're going to read about for next class,

620
01:17:36,710 --> 01:17:41,480
is that idea of information to evaluate ability idea.

621
01:17:41,480 --> 01:17:46,370
Here is how do we derive meaning from a data point?

622
01:17:48,470 --> 01:17:54,530
How do we use our contextual knowledge, our background knowledge to understand what is good and what is?

623
01:17:56,600 --> 01:18:06,080
And what we didn't talk about today, which was also important, is graphics afford us not just the opportunity to represent the data,

624
01:18:06,560 --> 01:18:14,389
but to provide the standards against what expense, data and compare are comparing within, you know, this bar versus that bar.

625
01:18:14,390 --> 01:18:17,900
We're setting up one type of high value ability, one type of comparison.

626
01:18:18,440 --> 01:18:27,499
When we provide some kind of access level or threshold, we set up a different type of comparison, etc. and attention.

627
01:18:27,500 --> 01:18:32,690
As you're reading the articles and as you start to think about from using for

628
01:18:32,700 --> 01:18:37,280
next class about this idea of how do we know whether something is good or bad?

629
01:18:37,940 --> 01:18:45,200
Because where we're going is towards the next assignment. The next assignment that you're going to be doing is to make a test result.

630
01:18:45,620 --> 01:18:49,100
Return letter in that result is a single number.

631
01:18:49,970 --> 01:18:57,830
In that letter, I want to ask you to leverage all the ideas that we've been talking about, things like labels, things like graphics.

632
01:18:57,830 --> 01:19:06,830
You must have a graphic and context to make that number more intuitively meaningful for the recipient.

633
01:19:07,430 --> 01:19:13,190
And so this is sort of pulling together all the stuff we've been doing for like the last three or four classes, moving it towards that point.

634
01:19:15,690 --> 01:19:21,120
But obviously what you need to give to, say, a patient who has never seen this number before.

635
01:19:21,540 --> 01:19:25,620
And what you might need to give to a doctor who sees that number all the time might be different.

636
01:19:26,610 --> 01:19:32,100
Think about that stuff as you move forward and how that gets manifested not just in the numbers but the graphics of time.

637
01:19:33,270 --> 01:19:41,009
So let me wrap you up there. Keep talking about this stuff, but I want you to to know where we're going, because at the time that's coming up,

638
01:19:41,010 --> 01:20:15,810
I think in about a week and a half or so, I want to see whether or not we got started.

639
01:20:17,070 --> 01:20:29,070
Yes. Yes, I have to say.

640
01:20:29,430 --> 01:20:45,900
Yeah, I tell you that for me, it looks like there is something else.

641
01:20:47,800 --> 01:20:58,290
But I think I did not want to ask you that.

642
01:21:00,060 --> 01:21:18,570
I don't know exactly what that was like for you, because I thought of this year and a half.

643
01:21:19,650 --> 01:21:26,850
I guess that's always going to be providing me things.

644
01:21:27,210 --> 01:21:42,090
Thank you. What's all this time with you for taking over that you're taking place?

645
01:21:42,780 --> 01:21:58,020
I was just thinking within the hour or so the.

646
01:22:00,750 --> 01:22:09,560
Implication of having two separate farms. In my mind, I think most people find that those are two independent observations,

647
01:22:10,280 --> 01:22:18,770
A and B, but they're not saying I am not going to move to Mars, are living longer.

648
01:22:19,370 --> 01:22:28,390
One goes off, the other one must go down. In terms of the visual language are the ones that show me that it is not perfect make.

649
01:22:28,400 --> 01:22:30,470
I think that these two things are really.

650
01:22:33,380 --> 01:22:46,070
So anything that shows a hole and then divisions of that whole approach that that provides a kind of ray of the kind of personal suffering.

651
01:22:47,650 --> 01:22:52,760
Then essentially you run the risk of creating something that looks like that crazy bar,

652
01:22:52,820 --> 01:23:00,080
that crazy pie chart that we saw that didn't add up to 100 because you're using something that implies a hole, but it isn't.

653
01:23:02,870 --> 01:23:06,080
So if you would just do a set of the legends of this color.

654
01:23:06,200 --> 01:23:10,100
Yes. Mm hmm. Okay. Thank you.

655
01:23:14,170 --> 01:23:23,770
All right. Let's put that idea to a few of the things that he's getting to do for Andrew and

656
01:23:23,800 --> 01:23:29,440
be find out why my phone is blowing up through our house and then we can chat.

657
01:23:29,640 --> 01:23:29,860
Okay.

