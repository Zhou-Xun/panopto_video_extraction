1
00:00:05,939 --> 00:00:11,939
will introduce the concepts of random error and systematic error in epidemiology.

2
00:00:11,939 --> 00:00:18,939
This is a really important topic because there are two main sources of error in epidemiologic studies.

3
00:00:18,939 --> 00:00:23,939
The first being random error and the second being systematic error.

4
00:00:23,939 --> 00:00:33,939
Let's imagine flipping a fair coin a certain number of times and wanting to know the probability of getting heads 50 percent of the time.

5
00:00:33,939 --> 00:00:41,939
And by a fair coin here, I mean an unbiased coin that has an equal probability of turning up heads and turning up tails.

6
00:00:41,939 --> 00:00:48,939
So if we flip this fair coin 10 times, there's actually a pretty low probability of getting exactly five heads.

7
00:00:48,939 --> 00:00:57,939
It's about 25 percent. Now, let's imagine that we flip this fair coin 1000 times.

8
00:00:57,939 --> 00:01:04,939
And the probability gets better. There's actually an eighty nine percent probability of getting between four hundred and

9
00:01:04,939 --> 00:01:11,939
seventy five and five hundred and twenty five heads on 1000 coin flips of this fair coin.

10
00:01:11,939 --> 00:01:16,939
I'll note here is that the probability of getting exactly 500 heads is actually very low.

11
00:01:16,939 --> 00:01:26,939
This is due to random error, but we're highly, highly likely to get a number that is very close to five hundred heads on 1000 coin flips.

12
00:01:26,939 --> 00:01:36,939
So the likelihood of getting heads about 50 percent of the time goes up as the number of coin flips increases.

13
00:01:36,939 --> 00:01:43,939
And the reason why we don't get heads exactly 50 percent of the time is, of course, random error.

14
00:01:43,939 --> 00:01:51,939
And so you saw and you can demonstrate this for yourself, that as the number of coin flips increases,

15
00:01:51,939 --> 00:02:01,939
the more likely we are to get five heads or heads 50 percent of the time or close to 50 percent of the time.

16
00:02:01,939 --> 00:02:10,939
Analogous to getting heads close to 50 percent of the time as we increase the number of coin flips in an epidemiological study,

17
00:02:10,939 --> 00:02:14,939
as the sample size increases. That is the number of people in our study.

18
00:02:14,939 --> 00:02:24,939
The degree of random error in the estimates that we get from that study decreases.

19
00:02:24,939 --> 00:02:29,939
Now, let's imagine flipping an unfair coin and by unfair,

20
00:02:29,939 --> 00:02:37,939
let's say maybe you like the coin is weighted and let's say it comes up heads 70 percent of the time instead of 50 percent of the time.

21
00:02:37,939 --> 00:02:49,939
So what happens if we flip this coin 1000 times? We are highly likely to get approximately 500 heads, as we did with a fair coin, but now, rather,

22
00:02:49,939 --> 00:02:57,939
we have a 90 percent probability of getting something between six hundred and seventy five and seven hundred and twenty five heads.

23
00:02:57,939 --> 00:03:06,939
And so if we expect a coin to come up heads half the time, but it's coming up heads more like 70 percent of the time.

24
00:03:06,939 --> 00:03:12,939
This is what is giving us or this is what we call systematic error or bias.

25
00:03:12,939 --> 00:03:23,939
And that's what's represented here by this unfair coin. So thinking about having a fair coin and the error that we get in,

26
00:03:23,939 --> 00:03:33,939
whether or not we get heads 50 percent of the time and a certain number of trials is analogous to random error in epidemiologic studies.

27
00:03:33,939 --> 00:03:42,939
When we have an unfair coin and we flip it a certain number of times and it comes up with a with heads a certain number of times,

28
00:03:42,939 --> 00:03:51,939
that does not represent 50 percent or approximately 50 percent when we expect it to represent 50 percent or approximately 50 percent.

29
00:03:51,939 --> 00:04:03,939
This is what is analogous to systematic error. The terminology here is very important in epidemiology, random error is also referred to as variance.

30
00:04:03,939 --> 00:04:07,939
And we call a lack of random error. Precision.

31
00:04:07,939 --> 00:04:15,939
With respect to systematic error, this is also known as bias, and we call a lack of systematic error validity.

32
00:04:15,939 --> 00:04:20,939
These are common phrases that we are going to use throughout the rest of this course in the

33
00:04:20,939 --> 00:04:26,939
remainder of this session on random error and the upcoming sessions on forms of systematic error.

34
00:04:26,939 --> 00:04:35,939
These are also phrases that you will often read in the literature and in textbooks, in epidemiology.

35
00:04:35,939 --> 00:04:45,939
And the numbers that we care about estimating and epidemiology, such as the magnitude of association between an exposure and a disease outcome,

36
00:04:45,939 --> 00:04:52,939
can be estimated with a combination of varying degrees of precision and validity,

37
00:04:52,939 --> 00:05:00,939
which depends on the accuracy, quality and appropriateness of the study designs and the measurement tools that we use to assess exposures,

38
00:05:00,939 --> 00:05:05,939
outcomes and their associations with one another.

39
00:05:05,939 --> 00:05:14,939
So every time you look at a measure of association that comes from an epidemiologic study that is based on inferences or I

40
00:05:14,939 --> 00:05:23,939
guess measurements actually that are made from some study population that has been drawn from an underlying based population,

41
00:05:23,939 --> 00:05:30,939
that measure of association is going to be estimated with a certain degree of precision and validity.

42
00:05:30,939 --> 00:05:36,939
And it's our job as epidemiologists to interpret what that measure of association means,

43
00:05:36,939 --> 00:05:43,939
given the level of precision and validity that we can either directly tell that that measure of

44
00:05:43,939 --> 00:05:50,939
association has or what we can infer about it from reading and understanding how the study was designed,

45
00:05:50,939 --> 00:05:56,939
conducted and analyzed. And so this slide, I think, is extremely helpful,

46
00:05:56,939 --> 00:06:04,939
and it shows the four basic combinations that we can have with with respect to precision and validity.

47
00:06:04,939 --> 00:06:10,939
And so it's useful to think about this in terms of a target with a bull's eye in the middle.

48
00:06:10,939 --> 00:06:19,939
So going from left to right, the bull's eye, or I suppose the target on the left hand side indicates a measure of association that is not precise.

49
00:06:19,939 --> 00:06:28,939
And it is not valid. It is not precise because the dots on the target are spread quite widely from each other.

50
00:06:28,939 --> 00:06:32,939
They do not converge to a narrow target.

51
00:06:32,939 --> 00:06:41,939
It is not valid because they do are not centered around the target of or oppose the bull's eye on this target.

52
00:06:41,939 --> 00:06:49,939
If that if the bull's eye is what is the true measure of association that we are attempting to estimate?

53
00:06:49,939 --> 00:06:56,939
Second from the left. This target shows us an association that is not precise but is valid.

54
00:06:56,939 --> 00:07:02,939
The reason why it is valid is that the four dots do center around the bull's eye of the target.

55
00:07:02,939 --> 00:07:06,939
But it is not precise because they are not close to the target, to the bull's eye.

56
00:07:06,939 --> 00:07:13,939
And they're also not terribly close to one another. Moving one step further to the right.

57
00:07:13,939 --> 00:07:19,939
This target shows a measure of association that would be considered precise but not valid.

58
00:07:19,939 --> 00:07:27,939
And so it is not valid because as you can see, the dots on the target are nowhere near the bull's eye.

59
00:07:27,939 --> 00:07:35,939
But it is considered to be precise, because the four dots are very close to one another.

60
00:07:35,939 --> 00:07:44,939
So they're very tight. And so what this particular target shows is that we have actually managed to measure something very well and precisely,

61
00:07:44,939 --> 00:07:47,939
but we've measured the wrong thing.

62
00:07:47,939 --> 00:07:57,939
And finally, the target on the right hand side of the slide shows or represents a measure of association that is both precise and valid.

63
00:07:57,939 --> 00:08:02,939
And this is ultimately what we always want to do, an epidemiologic research.

64
00:08:02,939 --> 00:08:11,939
We want to we want to have a valid association. That is, we want to have a true measurement of the thing that we are trying to measure.

65
00:08:11,939 --> 00:08:24,939
And we want it to be precise. We want to be. We want to have low random error and low variance in that association.

66
00:08:24,939 --> 00:08:28,939
And finally, I want to give a note on validity.

67
00:08:28,939 --> 00:08:37,939
So earlier I defined validity as a lack of systematic error or a lack of bias in an epidemiologic study.

68
00:08:37,939 --> 00:08:43,939
Essentially, there are three major threats to validity in epidemiologic studies.

69
00:08:43,939 --> 00:08:51,939
In other words, these are three forms of systematic error or bias that are pervasive in epidemiologic research.

70
00:08:51,939 --> 00:09:02,939
The first is confounding bias, and this is where the exposed and non exposed groups in an observational study are not exchangeable with one another.

71
00:09:02,939 --> 00:09:09,939
This is also referred to as having a third variable that explains the observed relationship between the

72
00:09:09,939 --> 00:09:16,939
exposure and the outcome variable or a common cause that is unmeasured or otherwise not accounted for.

73
00:09:16,939 --> 00:09:21,939
Of both the exposure and the outcome. If this is confusing.

74
00:09:21,939 --> 00:09:25,939
One of the upcoming sessions will focus on confounding bias and a lot more detail.

75
00:09:25,939 --> 00:09:33,939
So it will become clear, I promise. The second major threat to validity is selection bias.

76
00:09:33,939 --> 00:09:42,939
The third is information bias, and I've defined these here and I these are definitely oversimplifications,

77
00:09:42,939 --> 00:09:49,939
but these are very easy ways to think about it. Selection bias happens when you have the wrong people in your study and information

78
00:09:49,939 --> 00:09:53,939
bias happens when you didn't measure the exposure and outcome correctly.

79
00:09:53,939 --> 00:10:02,939
You will see why these are oversimplifications, because there are certain ways in which having the wrong people in your study matter more than others.

80
00:10:02,939 --> 00:10:10,939
And there are certain ways in which measuring the outcome or exposure incorrectly matters or may not actually matter so much.

81
00:10:10,939 --> 00:10:21,939
But in the next three sessions, we will go over these three forms of systematic error or bias in a lot more detail.

82
00:10:21,939 --> 00:10:24,939
And finally, a note on precision.

83
00:10:24,939 --> 00:10:32,939
So we accept that random error is present in all epidemiologic studies, and this is because we do sampling in epidemiology, all studies,

84
00:10:32,939 --> 00:10:41,939
even if perfectly conducted, are a sample of the underlying population and therefore may still differ from the true causal association.

85
00:10:41,939 --> 00:10:48,939
This is because people who end up in our study may differ from those in the underlying population, potentially by chance,

86
00:10:48,939 --> 00:10:55,939
especially if we are doing a small study, but potentially in a systematic way that could induce selection bias.

87
00:10:55,939 --> 00:10:59,939
That is an issue that is related to validity, not random error.

88
00:10:59,939 --> 00:11:09,939
So the reasons why we do the reasons why sampling might affect the associations that we observe can be due to both random and systematic error.

89
00:11:09,939 --> 00:11:15,939
That's a little bit of a side note for now. And finally, we use statistics to quantify the role of chance and studies.

90
00:11:15,939 --> 00:11:23,939
And so we do this by we always incorporate random error terms in our statistical models and we use P values and

91
00:11:23,939 --> 00:11:30,939
confidence intervals to indicate the level of precision that we have in the estimates that we come up with.

92
00:11:30,939 --> 00:11:36,939
That's the end of part one. The next is actually a detour going back to Dags.

93
00:11:36,939 --> 00:11:44,939
I'd like to have everyone register for the. Draw your assumptions edX mini course and complete some of the early videos in that course.

94
00:11:44,939 --> 00:11:51,939
They are very short, only two to three minutes long. And this is useful because this course is going to relate.

95
00:11:51,939 --> 00:11:58,961
Dag's to various forms of bias that we are going to talk about in the upcoming sessions.

