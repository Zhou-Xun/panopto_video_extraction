1
00:00:00,740 --> 00:00:05,620
Hello, welcome to this lecture covering
measures of association and regression.

2
00:00:05,620 --> 00:00:11,540
In this lecture, we'll begin covering
the concepts of simple linear regression.

3
00:00:11,540 --> 00:00:14,994
Now correlation is an excellent
way to quantify two continuous

4
00:00:14,994 --> 00:00:17,860
variables are related to each other.

5
00:00:17,860 --> 00:00:22,440
However, It fails to tell us directly
how changes in one variable will impact

6
00:00:22,440 --> 00:00:25,100
changes in another variable.

7
00:00:25,100 --> 00:00:29,890
For example, I may know that if I lose
weight, I can lower my blood pressure,

8
00:00:29,890 --> 00:00:34,630
but I might wonder if I lose 10 pounds,
just exactly how much lower.

9
00:00:34,630 --> 00:00:37,340
Will I expect my blood pressure to be?

10
00:00:37,340 --> 00:00:40,354
Put another way,
if I have a target blood pressure level,

11
00:00:40,354 --> 00:00:44,680
how much weight would I need to lose
in order to get to that target?

12
00:00:44,680 --> 00:00:48,524
These last two questions cannot be
answered directly from a correlation

13
00:00:48,524 --> 00:00:49,880
coefficient.

14
00:00:49,880 --> 00:00:53,788
They can only be answered through
a mathematical model of the data Which we

15
00:00:53,788 --> 00:00:57,509
call the near regression.

16
00:00:57,509 --> 00:01:01,575
Our learning objectives are first to
be able to write the equation for

17
00:01:01,575 --> 00:01:05,995
a regression model to then correctly
state the interpretation of the slope

18
00:01:05,995 --> 00:01:10,832
coefficient in that regression mode and
then to best understand how the concept of

19
00:01:10,832 --> 00:01:15,110
least squares is used to determine
the best fitting regression model for

20
00:01:15,110 --> 00:01:17,890
a given set of data.

21
00:01:17,890 --> 00:01:20,730
Now we return to the scatterplot
of Segal and Rothman.

22
00:01:20,730 --> 00:01:24,321
Looking at the association between
firearm ownership in a state and

23
00:01:24,321 --> 00:01:27,940
the corresponding rate of male
firearm suicides 400,000.

24
00:01:27,940 --> 00:01:30,676
We saw a strong positive
association between

25
00:01:30,676 --> 00:01:36,690
these two quantities with a Pearson's
correlation coefficient of 0.84.

26
00:01:36,690 --> 00:01:41,127
Now visually we can see that there's an
upward trend on these data and therefore,

27
00:01:41,127 --> 00:01:45,113
we could think of a line that fits into
these data that describe this upward

28
00:01:45,113 --> 00:01:47,150
pattern.

29
00:01:47,150 --> 00:01:51,247
Now, any line can be expressed
through this equation,

30
00:01:51,247 --> 00:01:56,200
we take the x value,
we multiply by the slope coefficient.

31
00:01:56,200 --> 00:01:58,600
We add an amount we call the intercept,
and

32
00:01:58,600 --> 00:02:02,220
that produces the corresponding value for
y.

33
00:02:02,220 --> 00:02:07,418
For example, if a state had around 40% for
its firearm ownership,

34
00:02:07,418 --> 00:02:12,550
the line would tell me the rate
of male firearm suicides.

35
00:02:12,550 --> 00:02:17,245
Likewise, there might be another state
with this amount of firearm ownership, and

36
00:02:17,245 --> 00:02:19,031
it has a corresponding value for

37
00:02:19,031 --> 00:02:22,360
the suicide rate that is
predicted by the line.

38
00:02:22,360 --> 00:02:25,318
Then we can look at the difference
between the two x values,

39
00:02:25,318 --> 00:02:28,810
they would have a corresponding
difference in their y values.

40
00:02:28,810 --> 00:02:33,950
We call the difference in x delta x and
the difference in Y, delta y.

41
00:02:33,950 --> 00:02:37,794
Mathematically we know that if we
take the differences in the axis and

42
00:02:37,794 --> 00:02:41,306
we multiply by the slope that
produces that change in the y's,

43
00:02:41,306 --> 00:02:45,660
leading to the equation that we'll
probably seen in a natural request.

44
00:02:45,660 --> 00:02:50,385
Stating that the slope the line is equal
to the change in Y or the change in X,

45
00:02:50,385 --> 00:02:55,090
or that the slope is equal
to the rise over the run.

46
00:02:55,090 --> 00:02:59,730
Now if we have a specific change in X,
suppose, we have two states that differ in

47
00:02:59,730 --> 00:03:05,550
their firearm ownership by only one
percentage point say 40 verses 39 percent.

48
00:03:05,550 --> 00:03:10,009
Those two states have firearm suicide
rates that differ by an amount that is

49
00:03:10,009 --> 00:03:13,901
the slope coefficient times their
difference in X, which is 1 so

50
00:03:13,901 --> 00:03:19,490
that the difference in the suicide
rates Is exactly the slope coefficient.

51
00:03:19,490 --> 00:03:24,468
This leads to the interpretation
of a slope coefficient, and

52
00:03:24,468 --> 00:03:30,212
that beta summarizes how Y would change
when we change X by one-unit but

53
00:03:30,212 --> 00:03:36,241
in this data, we can see that at a rate
of 40% of citizens owning firearms

54
00:03:36,241 --> 00:03:42,830
States with that value do not all have
the same rate of male firearm suicides.

55
00:03:42,830 --> 00:03:47,369
That for a given x,
y is not one number for every state,

56
00:03:47,369 --> 00:03:54,180
It has many possible values and
therefore, any value y any suicide rate.

57
00:03:54,180 --> 00:03:57,890
Is a value measured by the line plus or
minus a deviation or

58
00:03:57,890 --> 00:04:01,660
an error which are represented
with the letter E.

59
00:04:01,660 --> 00:04:08,160
These errors are used for us to figure out
which of the lines fits our data the best.

60
00:04:08,160 --> 00:04:12,140
Again, alpha and
beta are the intercept and the slope.

61
00:04:12,140 --> 00:04:16,147
The population will use Greek letters for
the intercept and the slope and

62
00:04:16,147 --> 00:04:17,940
the population.

63
00:04:17,940 --> 00:04:21,139
From the data,
we will estimate alpha with a value a, and

64
00:04:21,139 --> 00:04:25,860
we'll estimate beta with
a quantity that we'll call b.

65
00:04:25,860 --> 00:04:29,960
So I've drawn a line here with
an intercept of a and a slope of b.

66
00:04:29,960 --> 00:04:34,354
And we can see that each of my data points
has a certain amount of distance above or

67
00:04:34,354 --> 00:04:35,820
below the line.

68
00:04:35,820 --> 00:04:39,320
And I highlight one point here XiYi.

69
00:04:39,320 --> 00:04:44,265
That point is above the line,
the predicted value from the line for x i,

70
00:04:44,265 --> 00:04:49,211
the value should be Yi hat that's
the value of the line says y should be,

71
00:04:49,211 --> 00:04:51,560
but I did not see that value.

72
00:04:51,560 --> 00:04:56,360
I saw a different y that difference
is what I call the residual.

73
00:04:56,360 --> 00:05:00,375
This is the difference between
what the line says y should be And

74
00:05:00,375 --> 00:05:03,020
what I actually saw in my data.

75
00:05:03,020 --> 00:05:06,370
So points above the line will
have a negative residual, and

76
00:05:06,370 --> 00:05:10,570
points below the line will
have a positive residual.

77
00:05:10,570 --> 00:05:14,329
Now I don't care whether a line
is above or below the line,

78
00:05:14,329 --> 00:05:17,500
I simply care how far it is from the line.

79
00:05:17,500 --> 00:05:21,896
Therefore I don't focus on the errors
themselves or the residuals,

80
00:05:21,896 --> 00:05:25,500
I focus on the square of those numbers.

81
00:05:25,500 --> 00:05:29,940
And if our data fit this line, well,
then these squared error should be small.

82
00:05:29,940 --> 00:05:35,930
The closer the points are to this line,
the better I know I have the right line.

83
00:05:35,930 --> 00:05:39,553
And so therefore, like I do in
many instances in this course,

84
00:05:39,553 --> 00:05:43,037
I'm going to take an average of
all these squared distances,

85
00:05:43,037 --> 00:05:45,840
and I don't divide by n,
I divide by n minus 2.

86
00:05:45,840 --> 00:05:51,030
But this amount here is called
the mean squared error or MSE.

87
00:05:51,030 --> 00:05:55,000
It quantifies how well
the points fit to the line.

88
00:05:55,000 --> 00:05:57,846
I want that number to be as small
as possible, because again,

89
00:05:57,846 --> 00:06:01,462
I could think about drawing a slightly
different line through these points and

90
00:06:01,462 --> 00:06:05,730
that would give me a slightly
different mean square error.

91
00:06:05,730 --> 00:06:10,700
I can find a line that has the smallest
possible value for the mean squared error.

92
00:06:10,700 --> 00:06:12,950
This is my best fitting line.

93
00:06:12,950 --> 00:06:15,950
And again, this is the process
known as least squares.

94
00:06:15,950 --> 00:06:21,040
Because I'm finding the line that has the
least value for the mean squared error.

95
00:06:21,040 --> 00:06:25,233
Now through least squares, we get the
resulting equations for the intercept and

96
00:06:25,233 --> 00:06:29,040
the slope for
the best fitting line through our data.

97
00:06:29,040 --> 00:06:33,910
The slope is equal to the ratio of
the sample covariance of X and Y.

98
00:06:33,910 --> 00:06:36,780
To the variance of x, and the equation for

99
00:06:36,780 --> 00:06:41,618
the intercept tells us that the line
that we get must exactly intersect

100
00:06:41,618 --> 00:06:47,260
through the point that is the mean
of the x's and the mean of the y's.

101
00:06:47,260 --> 00:06:52,284
Now if I use least squares to fit
a line through the data of seagull,

102
00:06:52,284 --> 00:06:57,990
and Rothman I get a line that has
an intercept of one and a slope of 0.32.

103
00:06:57,990 --> 00:07:02,452
So for example, if I returned to
a state with 40% of its residents,

104
00:07:02,452 --> 00:07:06,463
owning firearms, the model,
the line expects that the number

105
00:07:06,463 --> 00:07:10,830
per a hundred thousand of
firearm suicides in that state.

106
00:07:10,830 --> 00:07:16,235
Is 40 times the slope of point 3,
2 plus the intercept of 1,

107
00:07:16,235 --> 00:07:20,560
giving me 13.8 per 100,000 suicides.

108
00:07:20,560 --> 00:07:23,740
Now again,
our regression line is not perfect.

109
00:07:23,740 --> 00:07:27,130
Every point does not
fit this line Exactly.

110
00:07:27,130 --> 00:07:30,630
There are some points that
are very close or on the line.

111
00:07:30,630 --> 00:07:34,794
So our model does a good job of
estimating the suicide ratej But for

112
00:07:34,794 --> 00:07:38,060
some states the suicide
rates are over estimated.

113
00:07:38,060 --> 00:07:42,866
The line is above what the actual Y value
is for those states, and the model tends

114
00:07:42,866 --> 00:07:49,330
to underestimate some of the suicide rates
because the points are above the line.

115
00:07:49,330 --> 00:07:50,398
So at this point,

116
00:07:50,398 --> 00:07:55,230
we discussed how to fit a regression
line to a specific set of data.

117
00:07:55,230 --> 00:07:59,380
And once we've done so we have two
further questions we'd like to address.

118
00:07:59,380 --> 00:08:02,892
First, how do we use the regression
line from our data to

119
00:08:02,892 --> 00:08:05,510
make inference back to the population and

120
00:08:05,510 --> 00:08:12,359
how does the fitted regression line relate
back to Pearson's correlation coefficient.

