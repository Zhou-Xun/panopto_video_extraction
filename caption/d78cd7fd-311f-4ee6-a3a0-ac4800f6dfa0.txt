1
00:00:01,000 --> 00:00:09,000
Hi, everyone. Welcome to the module on selection bias.

2
00:00:09,000 --> 00:00:21,000
So selection bias is a type of systematic her that relates to the way that participants are selected into and are retained in a study,

3
00:00:21,000 --> 00:00:25,000
you'll hear that several times throughout this presentation.

4
00:00:25,000 --> 00:00:34,000
You can see here a schematic of the different types of error or the major different types of error that we think about an epidemiologic studies.

5
00:00:34,000 --> 00:00:39,000
There is broadly classified into random error, systematic or.

6
00:00:39,000 --> 00:00:43,000
Lack of random error is called precision and lack of systematic error.

7
00:00:43,000 --> 00:00:53,000
It's called validity. You can see under systematic error that selection bias is one of three major types of systematic error in epidemiologic studies.

8
00:00:53,000 --> 00:01:03,000
The other two being information, bias and confounding. So what distinguishes random error from systematic error?

9
00:01:03,000 --> 00:01:09,000
This is likely a review, but it sets the stage for learning about selection bias.

10
00:01:09,000 --> 00:01:15,000
So one major difference is that random error tends to get smaller, sample size gets larger.

11
00:01:15,000 --> 00:01:15,770
This isn't the case with systematic error. No matter how large your study gets, systematic error.

12
00:01:21,672 --> 00:01:27,672
Let's say your truth. The answer you're trying to get is the bull's eye.

13
00:01:27,672 --> 00:01:32,672
All the way to the right. We have both a precise and valid measurement.

14
00:01:32,672 --> 00:01:39,672
The dots are clustered around the center, which is the truth. And the dots are close together.

15
00:01:39,672 --> 00:01:44,672
Moving to the left, we see a precise but not valid measure.

16
00:01:44,672 --> 00:01:50,672
The mean or the estimate that we would get from such a study or analysis would not be the truth,

17
00:01:50,672 --> 00:01:55,672
but it lacks random error because the dots are clustered.

18
00:01:55,672 --> 00:02:04,672
And you can see the difference with the next two. So selection bias definitions.

19
00:02:04,672 --> 00:02:11,672
So selection bias is distinct from confounding and information bias. The other two types of systematic error we mentioned because of its mechanisms.

20
00:02:11,672 --> 00:02:20,672
Again, it's related to the way that. Participants are recruited into and retained within a study.

21
00:02:20,672 --> 00:02:26,672
It's similar to confounding because it's a violation of exchange ability.

22
00:02:26,672 --> 00:02:34,672
Again, exchange ability is essentially means that the probability that a participant in the study receive the actual treatment that they received.

23
00:02:34,672 --> 00:02:43,672
Probability of a equal smiley is not independent of their counterfactual outcome, given a.

24
00:02:43,672 --> 00:02:48,672
Selection bias and confounding both violate this principle.

25
00:02:48,672 --> 00:02:53,672
A traditional definition confounding that can be found in the Szklo book is selection bias

26
00:02:53,672 --> 00:02:57,672
is present when individuals have different probabilities of being included or retained.

27
00:02:57,672 --> 00:03:04,672
In a study sample, according to relevant characteristics, namely the exposure and the outcome of interest,

28
00:03:04,672 --> 00:03:09,672
that's important because we'll learn that in order for selection bias to be present.

29
00:03:09,672 --> 00:03:19,672
Retention into a study or differential, loss of follow up needs to be related to both the exposure and the outcome of interest.

30
00:03:19,672 --> 00:03:25,672
There's also something called the structural definition of selection bias. The structural definition of selection bias.

31
00:03:25,672 --> 00:03:31,672
This is taken from a landmark paper by Mikhail Hernon and his colleagues.

32
00:03:31,672 --> 00:03:34,672
Bias resulting from conditioning on a common effect.

33
00:03:34,672 --> 00:03:42,672
Also known as a collider of two variables, one of which is the exposure or associated with the exposure.

34
00:03:42,672 --> 00:03:47,672
And the other is either the outcome or associated with the outcome.

35
00:03:47,672 --> 00:04:00,672
What does this mean and why do we need another definition? To understand this better, we need a basic review of dags and colliders.

36
00:04:00,672 --> 00:04:08,672
As you know, dogs are diagrams that epidemiologists and people in other fields can use to visualize statistical relationships in data,

37
00:04:08,672 --> 00:04:16,672
and it helps with causal inference. In DAGs, a direct arrow between one variable and another.

38
00:04:16,672 --> 00:04:26,672
In this case, a to Y means that a causus Y. And Dag's generally time flows left to right and top to bottom.

39
00:04:26,672 --> 00:04:31,672
Always remember that DAGs represent our assumptions and our knowledge about causal relationships.

40
00:04:31,672 --> 00:04:39,672
They're not magic. They're just models that help us do good research. DAGS are never cyclic because they are time specific.

41
00:04:39,672 --> 00:04:46,672
So what does that mean? DAGs are acyclic because they're times specific.

42
00:04:46,672 --> 00:04:52,672
There's a tendency to want to visualize feedback loops sometimes when thinking about causal relationships.

43
00:04:52,672 --> 00:04:59,672
In a DAG, though, since it's time specific, you can't have these feedback loops like we see in the top here.

44
00:04:59,672 --> 00:05:07,672
That A causes Y and then Y causes A. The way that a relationship like that would be presented in a DAG.

45
00:05:07,672 --> 00:05:17,672
Is that a at time one causes Y at time one Y at time one causes A at time two causes y at time two.

46
00:05:17,672 --> 00:05:24,672
More DAG basics

47
00:05:24,672 --> 00:05:29,672
Dogs help us understand the different ways that we can see statistical associations and data.

48
00:05:29,672 --> 00:05:35,672
There are three basic ways that we can see statistical associations. This is a simplification.

49
00:05:35,672 --> 00:05:42,672
Either, as we saw in the first example, A causes Y, a direct arrow between A and Y?

50
00:05:42,672 --> 00:05:49,672
A and Y share a common cause. This is also known as confounding in this case, C causes both A and Y.

51
00:05:49,672 --> 00:05:58,672
And as such, if we don't adjust for C, we'll see a statistical relationship between A and Y. The third type is known as colliders stratification.

52
00:05:58,672 --> 00:06:01,672
In this case, A and Y share a common effect, which is S.

53
00:06:01,672 --> 00:06:13,672
S is also called a collider. In order to see an association between A and Y in the data

54
00:06:13,672 --> 00:06:19,672
We must actually condition on S through restriction or adjustment in a model.

55
00:06:19,672 --> 00:06:30,672
Additionally, we can get collider stratification bias not only adjusting for a collider but alternatively a descendant of a collider.

56
00:06:30,672 --> 00:06:38,672
We'll talk more about that in a minute. Collider, stratification is important for understanding.

57
00:06:38,672 --> 00:06:45,672
It's important to understand when thinking about selection bias because it's the way we represent selection bias in DAGS.

58
00:06:45,672 --> 00:06:55,672
Conditioning on a collider again can induce a statistical association in more complex ways, not just the simple way of A causes S and Y causes S.

59
00:06:55,672 --> 00:06:59,672
These are some alternative

60
00:06:59,672 --> 00:07:07,672
DAG representations of selection, bias on the left hand side, you can see it's quite complex involving many variables on the right.

61
00:07:07,672 --> 00:07:16,672
It also includes more variables. But in this case, we're adjusting not directly on Collider L, which is a common effect of 
 A and U.

62
00:07:16,672 --> 00:07:28,672
But we're adjusting on C, which is a descendant of a collider, meaning that it is an effect of L.

63
00:07:28,672 --> 00:07:33,672
Generally in this case, when we're adjusting on the descendant of a collider rather than the collider itself

64
00:07:33,672 --> 00:07:39,672
we can assume that the amount of selection bias induced will be less generally than directly

65
00:07:39,672 --> 00:07:48,672
Conditioning on L. So colliders are really weird.

66
00:07:48,672 --> 00:07:53,672
Not intuitive at all. So it helps to have these sort of heuristic relational models in your mind

67
00:07:53,672 --> 00:07:57,672
to think about the way that colliders can induce statistical associations.

68
00:07:57,672 --> 00:08:01,672
So let's say we wanted to ask the question: Did it rain last night?

69
00:08:01,672 --> 00:08:11,672
So to answer this question, we go out on days and observe the sidewalk only when it's wet.

70
00:08:11,672 --> 00:08:18,672
So the sidewalk can be wet for two reasons as depicted in the DAG. It can either have rained last night or your neighbor ran the sprinkler.

71
00:08:18,672 --> 00:08:27,672
If we know in this case that the sidewalk is wet and your neighbor said that their sprinkler was broken, then it probably rained.

72
00:08:27,672 --> 00:08:32,672
In this case, knowing about one thing gives us information about the other.

73
00:08:32,672 --> 00:08:47,672
This equates to observing a statistical relationship. In this case, it's impossible that whether or not your neighbor ran the sprinkler

74
00:08:47,672 --> 00:08:51,672
affected the rain. Because certainly running a sprinkler doesn't cause it to have rain last night.

75
00:08:51,672 --> 00:08:57,672
But because we only observed because we only try to answer this question when the sidewalk as wet,

76
00:08:57,672 --> 00:09:07,672
we can observe this statistical association between rain and sprinkler. So, again, why do we need a structural definition?

77
00:09:07,672 --> 00:09:12,672
One good reason is that it helps us represent selection bias and DAGs. Also,

78
00:09:12,672 --> 00:09:16,672
It helps us have a unified framework for thinking about selection bias.

79
00:09:16,672 --> 00:09:21,672
Selection bias takes on a lot different forms, depending on the type of epidemiologic study.

80
00:09:21,672 --> 00:09:32,672
But because of our structural definition, we understand the common relationship between different types of selection bias in different studies.

81
00:09:32,672 --> 00:09:39,672
So this is a contrast, of sort of a more traditional and structural depiction of selection bias. On the right hand side is

82
00:09:39,672 --> 00:09:44,672
the structural depiction of selection bias in a DAG like we talked about before on the left hand side,

83
00:09:44,672 --> 00:09:50,672
This is a really common, traditional way of observing or thinking about selection bias in terms of a two by two table.

84
00:09:50,672 --> 00:09:55,672
It's also really useful sometimes for predicting the magnitude and direction of selection bias.

85
00:09:55,672 --> 00:09:58,672
We'll learn more about that in the synchronous lecture.

86
00:09:58,672 --> 00:10:06,672
But generally, you write out your two by two table that you might use to calculate a relative risk or risk ratio.

87
00:10:06,672 --> 00:10:19,672
And you think about what cells are inflated or deflated, depending on the type of selection or retention you have in the study.

88
00:10:19,672 --> 00:10:26,672
So some classic examples of selection bias. There are many ways that a study can be subject to selection bias and learning

89
00:10:26,672 --> 00:10:32,672
about well accepted types of selection bias can help us with finding it in our own studies.

90
00:10:32,672 --> 00:10:39,672
The structure of selection bias in different depending on the type of study.

91
00:10:39,672 --> 00:10:42,672
So the structure of sacrifice is different depending on this.

92
00:10:42,672 --> 00:10:49,672
The epidemiologic study we're talking about, and that's true for case control studies, cohort studies, RCT, ecologic studies.

93
00:10:49,672 --> 00:10:59,672
This is EqualLogic studies, too, and cross-sectional studies. I'll be sure to add those to the slide.

94
00:10:59,672 --> 00:11:07,672
So traditionally, case control studies are thought to be the most vulnerable to selection bias and

95
00:11:07,672 --> 00:11:12,672
Case control studies are often subject to a type of selection bias known as Berkson's bias.

96
00:11:12,672 --> 00:11:17,672
This is particularly relevant for hospital based or health system based case control studies.

97
00:11:17,672 --> 00:11:22,672
It occurs when controls are not selected independent of the exposure.

98
00:11:22,672 --> 00:11:30,672
We know that that is a violation of something called the study base principle. We learn that from the module on case control studies.

99
00:11:30,672 --> 00:11:38,672
Case control studies are thought to be particularly susceptible to selection bias because at the very least, the outcome is associated with selection.

100
00:11:38,672 --> 00:11:44,672
Remember that in case control studies, ideally you capture all the cases and only a subset of healthy controls.

101
00:11:44,672 --> 00:11:52,672
That means that there surely is a causal relationship between the outcome itself and being selected into the study.

102
00:11:52,672 --> 00:11:59,672
On the bottom there. There is a DAG depiction of Berkson's bias.

103
00:11:59,672 --> 00:12:04,672
This case represents a hospital based case control study of malnutrition, A on depression Y

104
00:12:04,672 --> 00:12:10,672
Because of the study design, we know that those with depression are more likely to be included in the study.

105
00:12:10,672 --> 00:12:15,672
So that's where we get our arrow from Y to C. Malnutrition itself can can likely

106
00:12:15,672 --> 00:12:20,672
be a cause of somebody being admitted to a hospital or being in a health system.

107
00:12:20,672 --> 00:12:25,672
Let's say we did this case control study in an outpatient health center where we took

108
00:12:25,672 --> 00:12:32,672
cases of clinical depression and then selected our controls from a dietary clinic.

109
00:12:32,672 --> 00:12:38,672
People would be more likely to be malnourished if we select controls from the dietary clinic.

110
00:12:38,672 --> 00:12:47,672
This is also called Berkson's Bias, again, because it was first recognized or hypothesized by a physician named Berkson.

111
00:12:47,672 --> 00:12:55,672
This is sort of the most simple example of selection, bias, selection, bias and cohort studies.

112
00:12:55,672 --> 00:12:58,672
So selection bias in cohort size is a little bit different.

113
00:12:58,672 --> 00:13:04,672
It typically arises because of loss to follow up or mortality related to both the outcome or exposure.

114
00:13:04,672 --> 00:13:08,672
You can think of mortality as a certain kind of loss to follow. We don't know what would have happened

115
00:13:08,672 --> 00:13:14,672
to a person in the future if they hadn't died.

116
00:13:14,672 --> 00:13:21,672
We can see a depiction of selection bias in cohort studies on the slide.

117
00:13:21,672 --> 00:13:26,672
This DAG represents a study of occupational exposure, A on the risk of stroke Y

118
00:13:26,672 --> 00:13:32,672
The terrible working conditions of a job represented by W.

119
00:13:32,672 --> 00:13:43,672
Let's say a job in a meat packing plant where the person is working in a refrigerated environment.

120
00:13:43,672 --> 00:13:51,672
So the conditions of the job are represented by W. is a common cause of the exposure.

121
00:13:51,672 --> 00:13:56,672
A, let's say we're studying exposure to a certain preservative in that meat packing plant.

122
00:13:56,672 --> 00:14:05,672
On the risk of stroke. So the terrible working conditions W is a common cause of the exposure

123
00:14:05,672 --> 00:14:14,672
and the likelihood that a person will quit, C. So if we enroll a bunch of people who work in this occupational setting, we're going to lose people.

124
00:14:14,672 --> 00:14:22,672
And we only follow them up when they're actually working. We're gonna lose people differentially related to the outcome and the exposure.

125
00:14:22,672 --> 00:14:26,672
So the horrible conditions are a common cause of exposure

126
00:14:26,672 --> 00:14:30,672
and the likelihood that a person will quit. Underlying health status U

127
00:14:30,672 --> 00:14:36,672
is a cause of stroke and also a cause

128
00:14:36,672 --> 00:14:43,672
also a cause of L, which is a deteriorating physical health, which is a cause of a person quitting as well.

129
00:14:43,672 --> 00:14:51,672
This type of bias is also known as the healthy worker effect. This generally happens when we recruit a special exposure cohort from an occupational

130
00:14:51,672 --> 00:14:58,672
setting and can only follow those people through time when they are actually on the job.

131
00:14:58,672 --> 00:15:06,672
Be aware that there is another type of bias that is sometimes also referred to as the healthy worker effect or healthy worker bias.

132
00:15:06,672 --> 00:15:14,672
That type of bias is related more to confounding, whereby people in an occupational setting are compared to the general public.

133
00:15:14,672 --> 00:15:20,672
In general, people who are working tend to be more healthy than the people in the general public.

134
00:15:20,672 --> 00:15:25,672
And so you get this sort of confounding by underlying health status or maybe chronic conditions.

135
00:15:25,672 --> 00:15:35,672
That's not the case here. This is truly a case of differential lost to follow up and 
 a special exposure cohort.

136
00:15:35,672 --> 00:15:41,672
Selection bias in cross-sectional studies, cross-sectional studies are also susceptible to selection bias.

137
00:15:41,672 --> 00:15:44,672
Sometimes this is referred to as incidence prevalence bias.

138
00:15:44,672 --> 00:15:51,672
Prevalent in cases with better prognosis or underlying health are more likely to show up in your study.

139
00:15:51,672 --> 00:15:56,672
So this DAG depicts a study of the effect of folic acid at conception

140
00:15:56,672 --> 00:16:04,672
on the prevalence of birth defects. Birth defects make it more likely that there will be a miscarriage.

141
00:16:04,672 --> 00:16:09,672
Only those babies born will be included in the study which makes this a cross-sectional study.

142
00:16:09,672 --> 00:16:15,672
It's a matter of the prevalence of birth defects related to folic acid intake.

143
00:16:15,672 --> 00:16:17,672
Folic acetate intake itself

144
00:16:17,672 --> 00:16:30,672
In this case causes a reduction in the likelihood that there will be a miscarriage and the presence of birth defects will also independently cause

145
00:16:30,672 --> 00:16:36,672
an increase in the likelihood that there will be a miscarriage.

146
00:16:36,672 --> 00:16:41,672
And so in that way, both the exposure and the outcome are related to

147
00:16:41,672 --> 00:16:51,672
selection into the study, which means that only babies that were brought to term.

148
00:16:51,672 --> 00:16:58,672
Selection bias in randomized controlled trials. RCTs are often thought to be the "gold standard" of causal inference.

149
00:16:58,672 --> 00:17:02,672
They are less likely to be subject to confounding because of random treatment assignment.

150
00:17:02,672 --> 00:17:07,672
They're equally likely to be subject to selection bias because of lost a follow up.

151
00:17:07,672 --> 00:17:16,672
This DAG represents a study of the effect of AZT on the development of AIDS, in this case treatment, A and illness severity U

152
00:17:16,672 --> 00:17:22,672
are both causes of side effects, L which lead to drop out of the study.

153
00:17:22,672 --> 00:17:35,672
We can see here that this selection bias is resulting from conditioning on a descendant of collider rather than the collider itself.

154
00:17:35,672 --> 00:17:43,672
So the key points of this lecture. Selection bias is a type of systematic error related to the recruitment or retention of participants.

155
00:17:43,672 --> 00:17:49,672
Remember, this systematic error doesn't get better with larger sample size.

156
00:17:49,672 --> 00:17:53,672
We must directly address it either in our study design or our analysis.

157
00:17:53,672 --> 00:18:00,672
Recruitment or retention must be related to both the exposure and the outcome to cause bias.

158
00:18:00,672 --> 00:18:08,672
If recruitment or retention is related to only the exposure or only the outcome, then it will not create bias.

159
00:18:08,672 --> 00:18:17,672
We can visualize selection bias on DAGs using the conceptual definition of collider stratification, bias. All types of studies,

160
00:18:17,672 --> 00:18:25,672
case control cohort ecologic and randomized controlled  trials are all subject to selection bias, but it might look different,

161
00:18:25,672 --> 00:18:33,672
the structure of the selection bias itself, depending on the type of study. Next session, we'll do a brief review of these concepts.

162
00:18:33,672 --> 00:18:40,672
We'll practice predicting the direction of selection bias. We'll look at some methods for detecting selection bias in a study.

163
00:18:40,672 --> 00:18:44,672
We'll also look at some methods for preventing or adjusting for selection bias.

164
00:18:44,672 --> 00:18:49,672
And if we have time, we'll go through the inverse probability of selection example.

165
00:18:49,672 --> 00:18:50,397
That's on the back of the cheat sheet that accurately referred to in the next video.

