1
00:00:09,550 --> 00:00:25,700
Okay. Good morning, everyone. So, um, let's first look at, uh, what we had.

2
00:00:26,580 --> 00:00:35,729
In the past lecture, we started with building up some premise for why we need a new mode of convergence,

3
00:00:35,730 --> 00:00:43,410
which is convergence in distribution and in the context of proving properties of different estimates.

4
00:00:44,040 --> 00:00:54,240
So one of the final steps in the procedure was to show that the distribution is asymptotically normal or something else.

5
00:00:54,750 --> 00:01:04,500
So for that statement, so we have a rigorous we needed a rigorous set of notions to describe that.

6
00:01:05,370 --> 00:01:10,590
And we had two versions of convergence in distribution.

7
00:01:11,130 --> 00:01:22,410
So one was when the distribution function of a random variable of a sequence of random variables.

8
00:01:23,460 --> 00:01:27,780
So that's a distribution function of one member of that sequence, right?

9
00:01:27,790 --> 00:01:36,329
The not the joint of the whole sequence when it goes to the distribution,

10
00:01:36,330 --> 00:01:46,200
the CDF of the limiting one and these sees for any point of continuity or every.

11
00:01:49,710 --> 00:01:52,860
I don't know in this context if there is an idea of difference.

12
00:01:55,370 --> 00:01:58,790
So native English speakers can correct me if I'm wrong.

13
00:02:00,350 --> 00:02:03,820
For any point of continuity of the limiting city.

14
00:02:03,830 --> 00:02:15,010
If. Unity of.

15
00:02:24,220 --> 00:02:29,470
Thanks. See there was.

16
00:02:31,190 --> 00:02:40,940
If there is some sound. Because you alerted me to the fact that one of the lectures did not have sound in it.

17
00:02:40,940 --> 00:02:44,750
So. Remind me to check if the sound is going.

18
00:02:48,550 --> 00:02:59,910
And by the way, if that happens, I'm also recording it on Zoom where you have my face and the soundtrack to it that goes through this all.

19
00:03:00,990 --> 00:03:06,270
Thing. Yeah. And, uh, so worst case scenario, you're killing her.

20
00:03:07,050 --> 00:03:14,610
Look at the track over there. So I just published all the previous Zoom lectures, so apparently they were not published automatically.

21
00:03:17,130 --> 00:03:22,050
And Zoom also has a transcript as a text so you can save it.

22
00:03:24,660 --> 00:03:30,060
So I'm thinking that at some point I will build this transcript into the notes.

23
00:03:30,820 --> 00:03:36,180
Then it will look like a book thing. But I haven't done it yet.

24
00:03:36,900 --> 00:03:47,940
Okay, so that was one definition of. The in rigorous terms, this is convergence and distribution.

25
00:03:58,010 --> 00:04:05,360
And another one was motivated by a functional argument that was weak convergence.

26
00:04:12,240 --> 00:04:24,330
Right. That's when the expected value of half of X and went to the expected value of f of x.

27
00:04:25,230 --> 00:04:28,530
This time is for any bounded continuous f.

28
00:04:38,240 --> 00:04:45,950
So the reason why I call this thing a functional thing, because it's a property defined for a class of functions, not just for one of them.

29
00:04:46,730 --> 00:04:49,970
Right then we had the portmanteau lemma.

30
00:04:55,560 --> 00:04:59,250
That said, both definitions.

31
00:05:00,960 --> 00:05:11,510
Embossed or equivalent. And this is why I using the terms convergence and distribution and convergence.

32
00:05:12,110 --> 00:05:21,710
We convergence interchangeably and we also using the one or the other version in the proofs depending on what's what's convenient.

33
00:05:23,540 --> 00:05:28,190
Okay. So we also have the parental control dilemma.

34
00:05:28,920 --> 00:05:34,870
And so that allowed us as a corollary, um.

35
00:05:36,170 --> 00:05:40,070
To, uh, claim almost true convergence.

36
00:05:40,730 --> 00:05:46,590
Uh, because usually, uh, it's much easier to look at convergence and probability them.

37
00:05:46,610 --> 00:05:49,660
They almost true. And to prove it right. Yeah.

38
00:05:49,680 --> 00:05:56,940
And based on these, uh, so it's actually helpful to have some, uh,

39
00:05:56,990 --> 00:06:03,740
sufficient conditions for almost true convergence that are formulated in terms of, uh, probabilities.

40
00:06:04,670 --> 00:06:09,500
Right. And they look somewhat stronger than convergence in probability.

41
00:06:10,160 --> 00:06:19,940
Yeah. One of them is that the series of events, uh, converges, then that requires the probability of event of the sequence of events,

42
00:06:19,940 --> 00:06:27,860
uh, to go to zero fast, uh, at a certain rate to make that series converge.

43
00:06:29,420 --> 00:06:34,070
And so from the convergence of that series, we have almost a convergence.

44
00:06:35,210 --> 00:06:41,780
Uh, this was also in the last lecture, uh, then we briefly looked at the Kashi sequences.

45
00:06:42,110 --> 00:06:47,390
So that's just for your information, I don't think we're using them in any way here.

46
00:06:48,800 --> 00:06:56,060
Uh, um, we had a lemma that we used the to prove.

47
00:06:56,170 --> 00:07:04,040
Uh, Slutsky. A couple of Slutsky type statements univariate.

48
00:07:08,330 --> 00:07:14,330
And the reason why I'm calling it Slutsky type is because there are several of them.

49
00:07:15,050 --> 00:07:21,440
And if we kind of formulate them in aggregate in a sloppy way, that would be so.

50
00:07:21,700 --> 00:07:29,390
If we approving something that converges that's supposed to have some asymptotic distribution converge weakly.

51
00:07:30,820 --> 00:07:39,370
To some distribution. Then in their proof we can replace things that conversion probability to constants by those constants.

52
00:07:40,180 --> 00:07:45,430
Yeah. Actually more broadly things convert equivalent in probability.

53
00:07:45,850 --> 00:07:49,130
That's when the. The difference.

54
00:07:49,580 --> 00:07:58,280
That's when I have two sequences of random variables, and the difference between them, uh, goes to zero in probability.

55
00:07:58,280 --> 00:08:02,960
Then I can replace one by the other in a week convergence argument.

56
00:08:04,640 --> 00:08:11,930
And so we have it for the sum of random variables.

57
00:08:12,770 --> 00:08:18,290
So X and plus Y has the same limit as an x and.

58
00:08:28,470 --> 00:08:34,000
Limiting distribution. Yes.

59
00:08:34,710 --> 00:08:40,810
And when? White girls in probability to zero.

60
00:08:41,620 --> 00:08:58,120
We had another one that we just formulated six times white and this is same our same thing if or when y and converges to one.

61
00:09:00,350 --> 00:09:09,710
In probability. We proved that things.

62
00:09:12,560 --> 00:09:15,950
And this is where the last lecture ended.

63
00:09:16,760 --> 00:09:23,210
So today we are basically so in the last lecture I was Lewicki was, uh, univariate.

64
00:09:28,050 --> 00:09:34,830
So we were thinking about, uh, just one CDF of a univariate distribution.

65
00:09:35,940 --> 00:09:43,740
Uh, converging somewhere and both X and Y and we're, uh, numbers, not vectors.

66
00:09:44,190 --> 00:09:55,350
So today we're extending into, uh, the multivariate, uh, types of statements and also adding some more useful facts to the story.

67
00:09:56,740 --> 00:10:05,070
Now, when we considered, uh, uh, sufficient conditions for industrial convergence,

68
00:10:06,210 --> 00:10:16,830
so we had some and from one to infinity probability of X and minus x.

69
00:10:19,830 --> 00:10:27,360
Uh, greater than epsilon. So this was supposed to converge, right?

70
00:10:28,660 --> 00:10:40,780
And then we had, uh, then this implied, as we proved it, that things that exame converges to excellence truly.

71
00:10:41,710 --> 00:10:52,390
So we can prove a somewhat different version of that statement where we allow actually epsilon to depend on em,

72
00:10:53,350 --> 00:11:00,660
but in such a way that epsilon and converges in a monetary fashion to zero.

73
00:11:00,670 --> 00:11:22,680
Right. So these are numbers greater than zero. And then we have X and Y converging almost surely to X.

74
00:11:32,940 --> 00:11:40,200
So intuitively, it's a stronger, somewhat stronger condition than the one implied by thing.

75
00:11:40,200 --> 00:11:46,679
But I can totally limit even though. Uh, so if you remember, the barrel can tell me.

76
00:11:46,680 --> 00:11:55,860
So let's formulate it again. So I have some of em from one to infinity, probabilities of some events.

77
00:11:55,860 --> 00:12:01,440
E m Right. And they were supposed to converge.

78
00:12:03,350 --> 00:12:08,300
The series is supposed to converge, then the probability of live soup.

79
00:12:11,880 --> 00:12:16,740
Of it is and goes to infinity was zero.

80
00:12:18,090 --> 00:12:22,950
That's how the better l on telly looked like.

81
00:12:23,070 --> 00:12:31,080
Right. And then we did a corollary by substituting, uh, instead of the events and the.

82
00:12:33,130 --> 00:12:37,200
X and minus X greater than epsilon red,

83
00:12:37,210 --> 00:12:47,860
the ones that are showing in the convergence in one of the equivalent definitions for almost true a convergence.

84
00:12:47,860 --> 00:12:52,390
Right. So remember the convergence in probability was.

85
00:12:53,200 --> 00:12:59,460
LIM So both the probability of m uh, uh, being zero, right?

86
00:12:59,470 --> 00:13:06,940
And this would be a limb slope of a sequence of numbers that are probabilities of if we switch probability of.

87
00:13:06,940 --> 00:13:14,380
LIM So, so then we obtain the one of the equivalent definitions for almost all conventions.

88
00:13:16,590 --> 00:13:30,870
Okay. And so now the idea is just to repeat, the corollary of Burrell can tell me, except that the event will now be epsilon instead of the epsilon.

89
00:13:31,180 --> 00:13:36,360
The that's a somewhat stronger thing because Epsilon is allowed to go to zero.

90
00:13:42,670 --> 00:13:46,210
So let's see.

91
00:13:46,330 --> 00:13:50,900
And so we're just revisiting the cut.

92
00:13:51,740 --> 00:14:00,200
Uh. Well, it's broken telly, so we have X and minus x.

93
00:14:01,850 --> 00:14:11,910
No greater than absolute am. And by the belt and tele.

94
00:14:15,620 --> 00:14:22,310
Because we were given that the series with this being and.

95
00:14:24,570 --> 00:14:29,880
Is less than infinity. If right then probability liam super m must be zero.

96
00:14:31,990 --> 00:14:38,170
We have. Probability super.

97
00:14:41,150 --> 00:14:45,000
And. Of the events.

98
00:14:46,810 --> 00:14:51,650
X and minus X grades and.

99
00:14:54,150 --> 00:15:04,809
So this is zero. And the equivalent statement.

100
00:15:04,810 --> 00:15:07,870
Right, is that's the probability of. Lim.

101
00:15:07,870 --> 00:15:15,760
So lim. Even if we take the compliment of the previous statement.

102
00:15:20,200 --> 00:15:23,739
We will have eons and goes to infinity.

103
00:15:23,740 --> 00:15:27,640
And then the sign of the inequality will be switched.

104
00:15:33,380 --> 00:15:37,190
And this is going to go. This is going to be one.

105
00:15:37,490 --> 00:15:40,640
All right. So as as a probability of the complement.

106
00:15:43,030 --> 00:15:47,200
And this in turn, means that.

107
00:15:50,890 --> 00:15:54,300
There exists. So for any army in this name in.

108
00:16:00,110 --> 00:16:07,310
And the probability of the Senate votes is equal to one by the previous line.

109
00:16:08,000 --> 00:16:18,780
Which means. And this is how the probability.

110
00:16:20,640 --> 00:16:23,730
Of one. So that is for.

111
00:16:27,290 --> 00:16:30,679
For every army, except perhaps a set of measures.

112
00:16:30,680 --> 00:16:47,330
Zero. It's sort of it's an equivalent statement.

113
00:16:53,300 --> 00:17:01,100
So I can find some number in one of they'll.

114
00:17:03,120 --> 00:17:10,350
Such depth. So all the events will be happening in the tail.

115
00:17:10,380 --> 00:17:13,410
In the end, one tail of my sequence.

116
00:17:16,570 --> 00:17:19,810
So this is going to be less equal. Absolutely. And.

117
00:17:22,060 --> 00:17:34,880
So for any ill. Great seven and one of the ints for any the as well, except perhaps a set of measure zero.

118
00:17:40,220 --> 00:17:44,420
Okay. So that's one thing that's going on.

119
00:17:44,430 --> 00:17:48,169
And then, uh, there's another thing.

120
00:17:48,170 --> 00:17:57,739
So my epsilon and there's a sequence of numbers going to zero so I can find because of that.

121
00:17:57,740 --> 00:17:59,810
So this is a page out of calculus.

122
00:18:00,650 --> 00:18:11,780
Uh, similar statement I can find into the does not depend on me because epsilon is just a sequence of numbers given to us externally.

123
00:18:12,410 --> 00:18:18,370
Um, such that. My Absalom.

124
00:18:18,370 --> 00:18:25,360
And there's going to be less than some other epsilon greater than zero for any.

125
00:18:26,500 --> 00:18:30,190
And in the tale of my absolom and sequence.

126
00:18:34,290 --> 00:18:37,470
This is simply tell to this.

127
00:18:38,990 --> 00:18:46,230
Sequence convergence. Sequence of numbers.

128
00:18:51,850 --> 00:19:02,590
Okay. So then I can set am equals the maximum between one and two.

129
00:19:08,710 --> 00:19:12,790
And then that means that I found this.

130
00:19:12,830 --> 00:19:18,880
And so there exists and for any epsilon greater than zero.

131
00:19:20,400 --> 00:19:37,560
So that's. That's this epsilon, right? So for any epsilon greater than zero, I managed to find an as a maximum of two other.

132
00:19:38,440 --> 00:19:46,020
And such that my accent of the minus x so far may go.

133
00:19:48,290 --> 00:19:51,640
Uh, is less equal.

134
00:19:51,650 --> 00:19:55,100
Absolutely. And in the epsilon and is less than the epsilon.

135
00:19:57,470 --> 00:20:03,650
And this is supposed to happen for a new and greater than the end I found.

136
00:20:04,970 --> 00:20:11,150
And this is just the definition. And this is for any army except perhaps.

137
00:20:14,610 --> 00:20:19,830
Outside of Measure zero. And that's the definition of almost sure convergence.

138
00:20:20,220 --> 00:20:23,820
So that means that it's an.

139
00:20:26,460 --> 00:20:30,300
On the verges almost surely to attacks.

140
00:20:35,640 --> 00:20:48,720
Okay. So there's nothing more than combining two numbers, one from Epsilon and convergence and the other one, uh, from convergence of probabilities.

141
00:20:51,950 --> 00:21:01,010
So that allows us to be a little more flexible with this condition for almost full convergence.

142
00:21:03,290 --> 00:21:12,390
You can call it the weaker condition than. The one that's so.

143
00:21:12,400 --> 00:21:16,570
Both are implied by the burial. Continue. Okay.

144
00:21:19,180 --> 00:21:35,880
So now there is a theorem. So suppose I have, uh, x and converging in probability to x.

145
00:21:39,610 --> 00:21:43,810
And the theorem says that from any such sequence.

146
00:21:52,180 --> 00:22:01,690
Extreme search, meaning the one that converges in probability to some random variable x i can extract.

147
00:22:05,620 --> 00:22:12,290
We can always extract. The subsequent.

148
00:22:18,180 --> 00:22:30,180
Let's say X and K where the index is K the convergence almost truly two x.

149
00:22:47,590 --> 00:22:53,980
Okay. So before we start the proof, let's go back to our example.

150
00:22:58,570 --> 00:23:04,800
We called the example. We had.

151
00:23:07,110 --> 00:23:17,730
On X and virgin in probability two x but x and not converging almost surely two x.

152
00:23:20,850 --> 00:23:21,149
Right.

153
00:23:21,150 --> 00:23:36,180
So is the theory is true then despite the fact that exam does now go almost truly to X, I can actually sample a subsequent system that will converge.

154
00:23:36,390 --> 00:23:39,720
They can find six such sub sequences that will converge.

155
00:23:40,910 --> 00:23:44,930
Almost truly to X. And remember how it went.

156
00:23:45,320 --> 00:23:55,520
So we had we started with an impulse like this between zero and one, and we were shrinking the impulse.

157
00:23:55,520 --> 00:24:01,880
So that area and then it went to zero. So that ensured convergence and probability.

158
00:24:05,050 --> 00:24:15,810
So that was happening with them. And so we had to in this case, we had I and am right and things that went with him.

159
00:24:19,010 --> 00:24:23,540
Were these and I.

160
00:24:26,000 --> 00:24:34,850
And the impulse was shrinking within and also it was running from left to right.

161
00:24:35,090 --> 00:24:39,370
This strategy was with I. Remember.

162
00:24:43,980 --> 00:24:50,940
And it's the running parts that did not allow it to converge almost truly, because for any omega it shows,

163
00:24:50,940 --> 00:24:58,210
which is a number between zero and one with a sample space, there will be a point, uh,

164
00:24:59,400 --> 00:25:07,740
in the yeah, I write for 80 and where the impulse would be right over that point and that will spoil the

165
00:25:08,430 --> 00:25:15,120
convergence in probability because there's a violator in every tailed no matter how we go about it.

166
00:25:15,990 --> 00:25:23,940
Right. But then we said there we also had a fact that, uh, if we have.

167
00:25:26,820 --> 00:25:32,580
And monotonic so we can extract amounts and export sequence out of this.

168
00:25:48,820 --> 00:25:53,230
Right. And to do that, we just need to fix the eye, right?

169
00:25:57,450 --> 00:26:01,860
And by fixing, let's say I at one, right.

170
00:26:02,370 --> 00:26:07,440
So if I fix the I one, then what I have is.

171
00:26:10,700 --> 00:26:14,339
The just the original impulse shrinking.

172
00:26:14,340 --> 00:26:17,870
And there's nothing else it's going to be going on.

173
00:26:18,020 --> 00:26:26,340
Right? So. Right.

174
00:26:27,560 --> 00:26:30,950
And the width of that thing is one of.

175
00:26:33,030 --> 00:26:44,100
So it's just this shrinking that makes the sequence monotonic, and it also makes a sub sequence that does go almost truly to zero.

176
00:26:44,310 --> 00:26:50,340
Right. Because I sooner or later write with them sufficiently large.

177
00:26:50,640 --> 00:26:58,320
I won't have any violators. Uh, because for any omega, uh, between zero and one, I will have.

178
00:26:59,820 --> 00:27:08,240
The. The dam, which is an indicator function represented by their labels.

179
00:27:08,720 --> 00:27:17,450
So it will be a zero. And the one, if I choose, only be equal to zero.

180
00:27:18,080 --> 00:27:27,500
They will all be equal to one. So in any case, the difference will will actually be zero between Zealand X and.

181
00:27:34,490 --> 00:27:41,300
Well, the key is actually a pair derived from a pair I equals one.

182
00:27:41,450 --> 00:27:44,620
And then. That's a you.

183
00:27:57,040 --> 00:28:03,680
So to indicate to. Equals zero.

184
00:28:08,810 --> 00:28:12,780
Some sequence. Very cheap, almost surely.

185
00:28:18,560 --> 00:28:22,370
Okay. So this is an example that gives good intuition for.

186
00:28:23,910 --> 00:28:31,340
Why is this possible? So now we can, uh, go about the proof.

187
00:28:40,560 --> 00:28:45,930
So well. We do have XM going in probability to x.

188
00:28:47,540 --> 00:28:55,730
Right. And I'm at liberty to choose absolom and that there was in probability to zero.

189
00:28:56,330 --> 00:29:00,650
So it's clear that I'm trying to use the previous lemma.

190
00:29:01,460 --> 00:29:10,920
So this lemma is here for a reason. Give me the opportunity to do the proof so I can choose Delta.

191
00:29:12,420 --> 00:29:19,809
Equals one over k squared. And such.

192
00:29:19,810 --> 00:29:23,410
That's, of course. So it doesn't have to be the case.

193
00:29:24,370 --> 00:29:28,990
So all I want is that the sum of the series?

194
00:29:32,740 --> 00:29:40,640
Is less than infinity, right? It would suffice to choose Delta as one of the key to what?

195
00:29:40,660 --> 00:29:45,430
Plus, Epsilon. Epsilon is some number greater than zero.

196
00:29:48,580 --> 00:30:18,250
Okay, then. And because I have x and girls and probability to x I can find in k such that the probability of x in t minus x greater than epsilon k.

197
00:30:22,260 --> 00:30:27,070
And this is less than one of a case squared.

198
00:30:27,750 --> 00:30:35,130
So why is that? So that goes by definition of convergence in probability.

199
00:30:39,320 --> 00:30:44,030
So you remember the definition. So it had an epsilon to it and a delta.

200
00:30:45,200 --> 00:30:51,830
Right. So with so I'm applying this definition with K being fixed.

201
00:30:56,220 --> 00:31:03,740
So that I can turn a blind eye on the key. Now, the thing that convergence is.

202
00:31:04,430 --> 00:31:10,490
So I am choosing. Am okay.

203
00:31:11,690 --> 00:31:15,110
That's the only variable thing here.

204
00:31:15,230 --> 00:31:19,930
And my. So we are referring to definitions.

205
00:31:19,940 --> 00:31:23,330
This is my epsilon, right? With K being fixed.

206
00:31:23,870 --> 00:31:27,320
I can drop the index and this is my delta.

207
00:31:30,060 --> 00:31:34,830
From the definition of convergence and probability. And this is my.

208
00:31:34,920 --> 00:31:46,860
And from that definition. Right. So the definition says that I can find for any epsilon and delta greater than zero, I can find them am, uh,

209
00:31:47,070 --> 00:31:58,530
meaning large enough such that this probability that's the deviation of exam minus x from being greater than epsilon,

210
00:31:59,940 --> 00:32:03,959
these probability will be less than delta. So that's the definition.

211
00:32:03,960 --> 00:32:08,160
So with K being fixed. So in the case my only number.

212
00:32:08,850 --> 00:32:13,140
So that's how the definition is working in this particular case.

213
00:32:21,370 --> 00:32:31,810
So they. What we have is that with m k chosen in such a way.

214
00:32:32,860 --> 00:32:38,950
And then I can. I can exercise.

215
00:32:45,360 --> 00:32:54,010
This procedure now. Four K equals one, two and so on.

216
00:32:54,620 --> 00:33:02,109
Right? So one key was fixed. I'm using the definition and finding the number and key such that this property takes place.

217
00:33:02,110 --> 00:33:08,020
Right. But then I recall and change that keys is an arbitrary number that I fixed.

218
00:33:08,470 --> 00:33:15,610
So I change it. I to go back to the definition, I find another key now for a different number.

219
00:33:15,760 --> 00:33:23,080
So that would give me a subsequent. So I am getting.

220
00:33:24,040 --> 00:33:30,810
We are getting. Subsequent.

221
00:33:36,570 --> 00:33:44,220
X and k this way such that the sum.

222
00:33:46,100 --> 00:33:57,440
Okay. From one to infinity, our ability x and k minus x greater than them.

223
00:33:57,440 --> 00:34:08,450
So K is less than infinity just because the series one over t squared converges.

224
00:34:12,850 --> 00:34:36,860
So we can actually write this thing. And then I can use the, uh, previous number.

225
00:34:45,070 --> 00:34:52,400
We have Excel K converging almost surely to fix it.

226
00:34:52,480 --> 00:34:55,540
And this is what we intended to show.

227
00:34:57,890 --> 00:35:02,810
From the very beginning. Okay.

228
00:35:03,020 --> 00:35:09,610
So another. Useful serum.

229
00:35:14,510 --> 00:35:17,600
That they will not prove for the sake of time.

230
00:35:17,600 --> 00:35:21,260
But it's kind of intuitively clear why this is the case.

231
00:35:21,770 --> 00:35:40,760
So it's a continuous mapping theory. And it says that if I have a converging sequence,

232
00:35:41,060 --> 00:35:51,380
there's an equivalent of this theorem in calculus or many other branches of mathematics that have convergences in them.

233
00:35:52,150 --> 00:35:58,490
And this is convergence, either in distribution or convergence.

234
00:35:58,940 --> 00:36:02,059
They almost draw one or convergence in probability.

235
00:36:02,060 --> 00:36:04,460
It doesn't matter them.

236
00:36:05,030 --> 00:36:14,480
If I act by continuous function, then the elements of my sequence and the limits, then it won't change anything about the convergence.

237
00:36:22,770 --> 00:36:31,930
And the thing that makes that happen is the epsilon delta language in the continuity that defines the continuity of our.

238
00:36:33,890 --> 00:36:38,020
It's just to save time. It's without proof.

239
00:36:46,620 --> 00:36:53,040
Okay. So the previous lecture we have the slope scheme, the univariate form.

240
00:36:57,190 --> 00:37:04,900
Uh, namely, in the form of adding something or in the form of multiplying by something.

241
00:37:06,150 --> 00:37:16,120
Um, so now we, it's actually rarely used in the univariate form because we have, we were talking about estimates.

242
00:37:16,120 --> 00:37:19,960
That's usually a vector of parameters that we're estimating.

243
00:37:22,910 --> 00:37:30,870
Not just one parameter. So we can have a multivariate version of this.

244
00:37:30,880 --> 00:37:34,030
Lewicki. Yeah, there are several effects.

245
00:37:35,350 --> 00:37:57,950
To that matter. You may be calling him Slutsky because that would be.

246
00:37:59,560 --> 00:38:04,200
The way you just read it in English. That's a Slavic name.

247
00:38:04,210 --> 00:38:12,120
That's why I'm calling him Slutsky. Okay, then the theorem.

248
00:38:15,060 --> 00:38:22,050
He's like this. So if it's an ad, those weekly two ads.

249
00:38:23,800 --> 00:38:27,160
And now both. I know, Victor.

250
00:38:29,860 --> 00:38:36,920
And taxes on that. Random variable.

251
00:38:38,360 --> 00:38:42,140
And then I have another.

252
00:38:47,090 --> 00:38:49,370
Random, Victor. Why am.

253
00:38:53,480 --> 00:39:08,000
Such that it's equivalent in probability to X and in the sense that x and minus y and the norm of it is in probability to zero.

254
00:39:12,250 --> 00:39:17,920
Right. And we need the reminder. What's the norm is over and the variable.

255
00:39:18,430 --> 00:39:21,550
So in general. So definition of a norm.

256
00:39:31,130 --> 00:39:39,680
So it has three axioms. So the norm of X plus y is less equals.

257
00:39:40,490 --> 00:39:44,810
More and more facts. Was not why.

258
00:39:45,500 --> 00:39:49,650
So this is in general a concept from functional analysis.

259
00:39:49,670 --> 00:39:53,370
So X and Y are any objects.

260
00:39:53,420 --> 00:40:03,020
Right. So in calculus, you may have seen these in terms of numbers in uh, uh, linear algebra.

261
00:40:03,240 --> 00:40:08,870
You can say that X and Y being vectors and the norm was the length of a vector.

262
00:40:09,620 --> 00:40:20,610
And with numbers, it's just the absolute value of a number. And with functions, it's defined in a number of different ways.

263
00:40:21,330 --> 00:40:29,850
In for random variables, the definition was the norm a random variable x.

264
00:40:31,940 --> 00:40:38,770
So that was an integral, uh, so it was a square with.

265
00:40:38,780 --> 00:40:43,200
Right. All of an integral.

266
00:40:46,700 --> 00:40:50,120
So this is a random vector.

267
00:40:52,240 --> 00:40:57,810
That's something like this, right? This is how we defined it.

268
00:40:58,650 --> 00:41:05,830
So the second axiom is that it behaves linearly with respect to constants.

269
00:41:05,850 --> 00:41:12,020
So if I have eight times X. Then I can take the constant out.

270
00:41:18,820 --> 00:41:24,790
So you can think of X as a vector. That's a useful analogy that gives the necessary information, right?

271
00:41:25,240 --> 00:41:34,090
So multiply a vector by number. Its length is the absolute value of that number, times the length of x.

272
00:41:34,870 --> 00:41:38,320
And then the third property is that.

273
00:41:39,130 --> 00:41:43,990
So the length of the x object is zero.

274
00:41:45,370 --> 00:41:49,360
Then that means that this object is zero in some sense.

275
00:41:53,070 --> 00:42:02,040
So if facts is a vector, then all components are zero effects is a function, then it's a function that's uniform to zero.

276
00:42:06,910 --> 00:42:13,380
Yeah. We can make a note. That.

277
00:42:14,820 --> 00:42:19,620
So if I take X minus the mean value of x and the norm of it.

278
00:42:20,400 --> 00:42:35,440
So what would that be? So if we exercise this expression right, it will be a square odds of the expectation.

279
00:42:41,360 --> 00:42:47,120
The expectation of X minus New Square, right.

280
00:42:47,660 --> 00:42:51,980
If this is a scalar saying that's a signal, right?

281
00:42:54,640 --> 00:42:59,230
So there's a relationship of a norm to variance.

282
00:43:00,780 --> 00:43:09,020
In that sense. And it will become a covariance matrix.

283
00:43:18,790 --> 00:43:30,520
Effects is a factor. Okay. So that was just the reminder and the list of quick facts about the norms now that we're using them.

284
00:43:33,610 --> 00:43:44,139
Okay. And the statement says that then so coming back to the Syrians have the sequence of accidental virgin 2xi have another vector that that's

285
00:43:44,140 --> 00:43:54,310
a Google and in probability to examine in the sense that it norm of the difference between Z and Y and converges in probability to zero.

286
00:43:55,000 --> 00:44:06,100
And this would mean that, uh, y and uh will also converge in uh, probability to x.

287
00:44:08,750 --> 00:44:13,820
Right. So in this version of Slutsky, it's not about the constant, it's about.

288
00:44:14,480 --> 00:44:23,690
So if I have any random variable or a combination of those in a converging.

289
00:44:24,610 --> 00:44:30,490
Uh, in something that would converge weekly to X, uh,

290
00:44:30,760 --> 00:44:41,380
and that combination I can replace by perhaps a simple expression that converges in probability, uh, to some other random variable.

291
00:44:41,860 --> 00:44:49,030
So then the substituting the limits in probability one one change anything.

292
00:44:52,450 --> 00:44:56,950
Well, substituting a sequence that has a limit of zero in probability.

293
00:44:58,760 --> 00:45:01,760
Okay. So let's do the proof.

294
00:45:08,340 --> 00:45:16,390
So for. Again, we talked about using either definition depending on which one is convenient.

295
00:45:16,720 --> 00:45:20,799
So this time it's more convenient to use the functional definition, right?

296
00:45:20,800 --> 00:45:27,760
So for any bounded continuous function f so my expectations are supposed to converge.

297
00:45:30,400 --> 00:45:34,810
So I will start by, uh, taking, uh.

298
00:45:36,950 --> 00:45:47,680
An arbitrary. Take if is a bounded and continuous function.

299
00:45:57,410 --> 00:46:00,950
And I will then consider the.

300
00:46:02,470 --> 00:46:05,620
Norm of the difference between.

301
00:46:06,590 --> 00:46:12,700
E of f of x and. Mind us.

302
00:46:13,150 --> 00:46:17,900
He. F of x.

303
00:46:25,060 --> 00:46:28,600
Now this is, of course, by linearity of expectation.

304
00:46:29,290 --> 00:46:33,010
Norm of the expectation of.

305
00:46:34,260 --> 00:46:50,370
Of X and minus X. And let me add one more property.

306
00:46:52,170 --> 00:46:59,370
So the axiom one for the norm is sometimes called the triangular inequality.

307
00:47:11,740 --> 00:47:17,950
And it's certainly valid not just for two elements X and Y.

308
00:47:18,310 --> 00:47:26,680
It's valid for any number of them. So.

309
00:47:26,690 --> 00:47:29,750
And with with.

310
00:47:30,970 --> 00:47:34,210
X, Y, Z. And so on.

311
00:47:35,050 --> 00:47:49,000
Right. I will have this axiom in the form that the norm of the sum of whatever is less or equal, some of the norm of that whatever.

312
00:47:51,800 --> 00:47:57,750
And integrals, if you remember, when defined as minutes of songs.

313
00:47:58,490 --> 00:48:02,960
So that would be the case for the integral as well.

314
00:48:05,900 --> 00:48:10,040
Well, that's an equal. In the.

315
00:48:13,140 --> 00:48:21,390
Of the norm. And so expectation is an integral than normal.

316
00:48:21,390 --> 00:48:28,050
The expectation of whatever is less equal expectation.

317
00:48:29,430 --> 00:48:39,920
The normal start to whatever. So these are all versions of the triangulating, the quality and.

318
00:48:43,280 --> 00:48:48,170
So you my sense of connection to some inequalities here as well.

319
00:48:49,880 --> 00:48:54,770
But that's inconsequential for now. So is.

320
00:48:57,610 --> 00:49:02,230
That means if I'm exchanging the norm and the expectation, I'm getting something bigger.

321
00:49:04,250 --> 00:49:08,450
So this is all to say that by the triangle, triangular inequality.

322
00:49:16,820 --> 00:49:22,250
It can exchange the expectation on the norm and obtain something bigger.

323
00:49:38,900 --> 00:49:45,920
Okay. So then I will split my army into two pieces.

324
00:50:06,170 --> 00:50:12,050
And one piece will be where the norm is less.

325
00:50:12,470 --> 00:50:23,730
We call some epsilon greater than zero. And so it's compliments and that's where the norm is greater than that possible.

326
00:50:26,330 --> 00:50:29,940
I can always flip on and get into some event and it's comfortable.

327
00:50:34,210 --> 00:50:40,740
So then. Call this a star.

328
00:50:41,310 --> 00:50:44,700
I can continue writing. The star is.

329
00:50:47,640 --> 00:50:53,340
No. So my expectation is an integral role with a full Omega, right?

330
00:50:57,160 --> 00:51:01,510
He's an integral role model for one. And Omega is a multi space here.

331
00:51:02,380 --> 00:51:07,060
Of course it's all vectors of variables. Um.

332
00:51:07,780 --> 00:51:15,360
But then. So I will have, uh, my, when I'm splitting the integral into two pieces.

333
00:51:15,370 --> 00:51:32,230
So one would be an integral, although the area where the norm is less or equal epsilon and another one would be in the growth.

334
00:51:37,660 --> 00:51:40,810
Perhaps I should put three dots here. It's because. I mean.

335
00:51:41,770 --> 00:51:45,340
A pretty specific thing, right? That's the difference between the functions that.

336
00:51:49,250 --> 00:51:53,630
Not because usually one dot we use for an arbitrary object so.

337
00:51:54,770 --> 00:52:06,760
This case. It's not the tree. That's when this difference in math is greater than that.

338
00:52:06,800 --> 00:52:11,780
So. So they seize the.

339
00:52:13,540 --> 00:52:20,480
What I'm using. Yes. Three dots. Just to save space.

340
00:52:23,560 --> 00:52:27,640
And then. So we will consider these terms separately.

341
00:52:28,870 --> 00:52:35,840
And first of all. Will consider the second one.

342
00:52:39,070 --> 00:52:44,100
Expected value. The norm.

343
00:52:46,400 --> 00:52:51,650
When this norm is Greater Epsilon.

344
00:53:00,930 --> 00:53:04,830
So I have my arm is bounded.

345
00:53:09,980 --> 00:53:18,080
Right. So that means that my norm was less so equal than some kind of a constant.

346
00:53:19,870 --> 00:53:26,560
Then this is less equal than this constant times expectation.

347
00:53:27,860 --> 00:53:34,390
Uh, so the integral, uh, is taken over the area where Norm is greater than Epsilon.

348
00:53:35,110 --> 00:53:40,800
Right? So when I take the constant out, I just have an integral over that area.

349
00:53:40,810 --> 00:53:48,910
So that would make the probability of this event no greater than the epsilon.

350
00:53:51,190 --> 00:53:59,440
Right. And it's given to me in the conditions of the theory that this guy goes to zero

351
00:53:59,440 --> 00:54:04,659
in probability and for a continuous function they have by the continuous med.

352
00:54:04,660 --> 00:54:11,650
In theory, this implies that if I act by a function are from both of them, which is what the three dots stand for.

353
00:54:12,580 --> 00:54:15,780
I will also have. Uh.

354
00:54:20,280 --> 00:54:26,440
Then. So this norm. Just a reminder, this is a normal if.

355
00:54:27,620 --> 00:54:31,070
Text and minus assets tax.

356
00:54:33,620 --> 00:54:37,460
Right. My ex. And.

357
00:54:43,400 --> 00:55:05,580
It's not. See.

358
00:55:06,980 --> 00:55:11,810
Let's do a break. Starting on the wrong foot here.

359
00:56:59,100 --> 00:57:09,900
Yeah. So did you.

360
00:57:11,040 --> 00:57:14,700
Was that you who sent homework to this instead of homework?

361
00:57:15,240 --> 00:57:21,600
Well, it's just some place. So I don't have your homework. One so we can do one.

362
00:57:21,700 --> 00:57:24,960
One of two things. So you can just send it to me. Okay.

363
00:57:26,000 --> 00:57:31,670
Yeah. They'll trust you. Or I can drop it from the great, you know, a.

364
00:57:33,150 --> 00:57:36,200
Okay. There's a50. Right.

365
00:57:36,600 --> 00:57:40,110
So it's not in the system. It doesn't create a backup.

366
00:57:40,240 --> 00:57:44,340
So if you send the new one, it replaces it. So I couldn't find this.

367
00:57:44,580 --> 01:01:49,040
No problem. Don't worry about that. Okay.

368
01:01:49,490 --> 01:01:53,930
Shall we continue? So I messed up the start.

369
01:01:54,000 --> 01:02:06,870
That's why. Fortunately, there was time for a break because I have convergence in probability for this difference, not for these two guys.

370
01:02:07,020 --> 01:02:16,620
Right. And I started with the yields F of X and minus E, F of X, and then I couldn't use this this thing.

371
01:02:17,340 --> 01:02:22,400
Right. So I need to start with X and minus F of Y, right.

372
01:02:22,410 --> 01:02:29,070
So that I can use convergence of probability. So we make that change.

373
01:02:29,220 --> 01:02:37,920
So now my three dots is the difference between an F of X and Y.

374
01:02:39,660 --> 01:02:44,880
So then with me splitting things like these.

375
01:02:48,280 --> 01:02:51,880
Uh, so this is where I got. So this thing doesn't change.

376
01:02:53,020 --> 01:03:13,400
And now because. X and nor of x and minus y, and converges in probability to zero, and by the continuous mapping fearing.

377
01:03:21,390 --> 01:03:25,620
The same is true about half of x and minus.

378
01:03:27,090 --> 01:03:44,390
Therefore I am. And from this one it follows that this probability with three dots is just the difference between Apple selling for y and.

379
01:03:46,740 --> 01:03:51,620
We have that the probability of.

380
01:03:53,060 --> 01:04:01,490
This guy goes to zero. Okay.

381
01:04:01,490 --> 01:04:06,080
So that means that this whole term.

382
01:04:08,720 --> 01:04:26,770
Those two zero. So I can make it smaller than any number of ones because of that.

383
01:04:28,030 --> 01:04:36,010
And then. So as far as the first term goes.

384
01:04:45,840 --> 01:04:49,380
So the first term is this one.

385
01:05:23,680 --> 01:05:39,340
So with this one, they can use the same argument to say that it's less of equal epsilon times, the probability that the norm is less equal epsilon.

386
01:05:40,090 --> 01:05:50,620
So this time is because. So I'm taking an integral over the area where the norm of the three dots is less or equal epsilon.

387
01:05:50,950 --> 01:05:54,670
So the largest value of this norm is epsilon.

388
01:05:55,160 --> 01:06:04,330
So I'm getting something larger if I replace these by its largest value in this area and that's the epsilon,

389
01:06:04,630 --> 01:06:07,840
then epsilon goes out instead of the constant.

390
01:06:09,820 --> 01:06:14,530
So it's similar to the previous argument, except that I'm not using my meds,

391
01:06:14,530 --> 01:06:22,120
revising the norm by the constant that's implied by the bounds of character of the function I have.

392
01:06:22,990 --> 01:06:28,600
I am using the fact that the integral is over the area where the norm is less or equal epsilon.

393
01:06:32,220 --> 01:06:35,850
So in this area.

394
01:06:39,070 --> 01:06:47,830
The. Maximum. This new analog is less than equal epsilon.

395
01:06:55,110 --> 01:07:00,659
I replace. The function under the integral by its largest menu.

396
01:07:00,660 --> 01:07:10,080
This is what's going on. And so this probability.

397
01:07:15,280 --> 01:07:19,030
Less equal and so on. So it's less week one.

398
01:07:20,080 --> 01:07:26,950
Right. So this time I'm using the fact that this gap is bounded and epsilon was arbitrary number.

399
01:07:30,330 --> 01:07:34,500
Someone greater than zero was the tree.

400
01:07:38,920 --> 01:07:44,750
Number. That can be.

401
01:07:48,920 --> 01:07:56,150
My go to zero. Right.

402
01:07:56,160 --> 01:08:02,490
And so these arguments, I got both terms going to zero one way or another.

403
01:08:03,630 --> 01:08:10,530
So that means that I have zero lenience for the thing that I started with and the thing

404
01:08:10,530 --> 01:08:20,010
I started with was the norm of this difference between F of X and y and expectations.

405
01:08:21,620 --> 01:08:39,670
So then I have the limit. Yeah girls to infinity normal expected value of X and so spelling back with the three dots are.

406
01:08:42,920 --> 01:08:52,100
Minus the expected value of y in. So this is equal to zero.

407
01:08:59,990 --> 01:09:11,700
Now. My ex and girls weekly two acts.

408
01:09:12,810 --> 01:09:15,880
And that means. Uh.

409
01:09:17,460 --> 01:09:23,910
That's my year of F of X and.

410
01:09:25,920 --> 01:09:30,440
Converges to. F of X, right.

411
01:09:30,510 --> 01:09:39,920
Because F was an arbitrary. Bounded in a continuous function.

412
01:09:49,670 --> 01:10:08,320
So that means that there's zero. So I guess I can't replace them for that sound by its limits expectation.

413
01:10:10,850 --> 01:10:20,870
And then the only limit would be. Half of y and.

414
01:10:26,170 --> 01:10:42,180
Wait. And this is zero.

415
01:10:47,380 --> 01:10:52,380
And then this means that the.

416
01:10:53,600 --> 01:10:57,710
Of F of x is the limit.

417
01:11:06,550 --> 01:11:11,130
Each of us of whom I am. And this is by.

418
01:11:15,630 --> 01:11:19,140
By the third axiom of the norm.

419
01:11:20,070 --> 01:11:26,100
Right. So if something other than the norm is zero, then that means that something under the norm is also zero.

420
01:11:33,030 --> 01:11:36,820
See all three. No, I'm.

421
01:11:44,550 --> 01:11:48,210
Okay. And what I see here that this is.

422
01:11:50,200 --> 01:11:55,840
A definition. Yes.

423
01:11:56,450 --> 01:12:02,000
Of my in verging weekly to half of x.

424
01:12:10,080 --> 01:12:14,010
And I can drop the F by the continuous mapping theorem.

425
01:12:24,240 --> 01:12:30,190
So I have. That's why I am. There was a weekly two acts.

426
01:12:36,820 --> 01:12:42,840
And this is what we intended to show from the very beginning.

427
01:12:42,850 --> 01:12:48,160
So that's the statement of the theorems. So that makes the end of proof.

428
01:12:53,570 --> 01:13:00,440
Okay. Okay.

429
01:13:00,590 --> 01:13:05,660
So that's it for today. We will continue on on Wednesday.

