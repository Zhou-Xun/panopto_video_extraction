1
00:00:00,210 --> 00:00:08,690
Any question is from our last lecture. Your questions.

2
00:00:08,960 --> 00:00:17,350
Okay. Then we'll continue the discussion about the.

3
00:00:18,660 --> 00:00:26,510
So as we mentioned, consistency, unity is I mean, the two properties usually are paired together.

4
00:00:26,520 --> 00:00:29,290
So consistency and that's not even normality, right?

5
00:00:29,310 --> 00:00:36,690
So consistency really means that as you're getting more and more information, as you have larger and larger assembled size,

6
00:00:36,810 --> 00:00:41,430
your estimate is getting closer and closer to the truth and eventually becomes the truth.

7
00:00:41,590 --> 00:00:47,549
So it means that there's no systematic bias. So resistance is usually a these are these are property.

8
00:00:47,550 --> 00:00:53,850
If you have some estimate or that is not even consistent, that means that no matter how large your sample size is,

9
00:00:53,850 --> 00:00:58,240
there is always going to be a discrepancy between your estimate and the true value you are in.

10
00:00:58,260 --> 00:01:05,330
A That's not a desirable. But of course, here we're not talking about, you know, the so called veterans, like why is there a tradeoff result?

11
00:01:05,570 --> 00:01:12,690
So if you take that under other some on some other criteria, like a newsletter, for example,

12
00:01:12,690 --> 00:01:17,129
then I think my change but now let's while we're talking about the bias itself.

13
00:01:17,130 --> 00:01:25,780
So of course it is desirable to have estimates that are not biased and a consistency means that automatically the bias disappears, right?

14
00:01:25,800 --> 00:01:31,560
So, so once we have a consistency, that means we are getting closer and closer to the truth.

15
00:01:31,800 --> 00:01:35,610
Now we just need to focus on well in our design of the behavior of an estimate.

16
00:01:35,610 --> 00:01:39,390
And we just need to focus on the neighborhood of the truth.

17
00:01:39,930 --> 00:01:46,080
And that's actually not in reality how like why here we have in less time?

18
00:01:46,740 --> 00:01:53,420
Well, first of all, I think in the papers we talk about running a marathon.

19
00:01:53,430 --> 00:01:58,880
Typically, you'll see that, you know, the difference is multiplied by it is skewed by this of.

20
00:01:58,980 --> 00:02:10,440
Yeah, right. This is the so called a parametric the range. This sort of again this scaling actually may makes this quantity,

21
00:02:10,440 --> 00:02:20,520
this whole quality here converges in this direction to a normal and this sort of in this difficulty is called the parametric rate.

22
00:02:21,270 --> 00:02:28,620
So this is sort of in this parametric area is for the case where while the more

23
00:02:28,740 --> 00:02:34,170
measured the more center case where a number of parameters P does not end with N,

24
00:02:34,230 --> 00:02:37,379
so we have fixed number parameter. Just imagine the linear regression model.

25
00:02:37,380 --> 00:02:45,180
For example, you have a fixed number of vision, let's say ten or 15, but this number does not change with the sample size.

26
00:02:45,990 --> 00:02:52,980
And also we consider parametric models in a some parametric models, they also have this convergence rate.

27
00:02:55,140 --> 00:02:59,730
So in other words, I mean for some other situations like for example,

28
00:02:59,730 --> 00:03:05,340
non parametric regression, if you consider terminal regression for example, and then this.

29
00:03:06,700 --> 00:03:09,150
This will not be a struggle in anymore.

30
00:03:09,160 --> 00:03:19,030
It depends on the bandwidth used in the terminal function and also some other regression, like a high dimensional regression.

31
00:03:19,150 --> 00:03:22,420
The symbol on is the number of parameter increases the sample size.

32
00:03:22,780 --> 00:03:28,959
Then the scaling parameters factor is also not it's not a square root of an either.

33
00:03:28,960 --> 00:03:42,070
And so so this we have this square in here for the conventional parametric and fixed number of Andrew Case, but that's the main focus of this course.

34
00:03:42,520 --> 00:03:44,770
Okay. So then plus time,

35
00:03:44,770 --> 00:03:53,500
we start to talk about how to establish the next how big is that to the how to establish a study of normality once we have a consistency.

36
00:03:57,520 --> 00:04:03,640
And we were trying to first look at the fundamental idea behind the establishment of a modern world.

37
00:04:03,710 --> 00:04:08,830
It turns out that there is a very structured and systematic way.

38
00:04:09,160 --> 00:04:14,229
It's just like an algorithm. So this is establishing a model of normality early.

39
00:04:14,230 --> 00:04:21,370
It's a lot easier than establishing consistency with consistency because consistency is a global average.

40
00:04:21,790 --> 00:04:31,900
So we look at it because you have to look at a function, a globally and then under some conditions then you establish consistency.

41
00:04:32,260 --> 00:04:35,190
But a smarter analogy is more a local poverty.

42
00:04:35,230 --> 00:04:42,550
The stuff you just look at of the neighborhood, of the truth and the establishment of a it's not a normality.

43
00:04:42,910 --> 00:04:47,440
There is a kind of a routine procedure is more like an algorithm that we can follow.

44
00:04:47,890 --> 00:04:55,090
And now they're trying to illustrate the idea of openness and some sort of algorithm using that.

45
00:04:55,660 --> 00:04:58,150
Now let's get a refresh, remembering what we are doing.

46
00:04:59,020 --> 00:05:08,020
So suppose that, you know, here we have more time maximizing the log likelihood and we assume it's differentiable.

47
00:05:08,050 --> 00:05:11,470
So once these be vertical, then we have the square equation.

48
00:05:11,890 --> 00:05:15,790
So that's taking a first order, George, of log likelihood of that's a square.

49
00:05:15,790 --> 00:05:24,750
And then now you satisfy that square equation and once well and then if we are further assume that my livelihood is twice continuously rational

50
00:05:25,450 --> 00:05:31,930
and then we can apply the silver medal theorem because we have take second order version and also send out an intermediate continuous.

51
00:05:32,470 --> 00:05:41,330
So. So then we just take. The while, we just apply the minimalism to this guy.

52
00:05:41,930 --> 00:05:46,550
Then what we have is, while I've been able to sit on zero.

53
00:05:46,760 --> 00:05:59,140
So what we have is this. Plus this. After we got here, we solve for this thing to have -0, and then we multiply both sides by two out of here.

54
00:05:59,460 --> 00:06:06,020
That's how we got to the last line. And once we got to the last line, then.

55
00:06:07,680 --> 00:06:12,540
If we realize that here is how this bracket is. This is a sample average.

56
00:06:13,700 --> 00:06:17,710
And simple everyday people forget about this for a minute in a bar for a minute.

57
00:06:17,720 --> 00:06:23,690
A few of our also depends on the being on the rise. But if you forget about the bar for a minute now,

58
00:06:24,140 --> 00:06:30,970
the simple average of a bunch of random variables and these random variables, they are either because the guys are right.

59
00:06:31,310 --> 00:06:35,890
So let's first let's fix this system for any faith in.

60
00:06:37,080 --> 00:06:42,740
And then if we apply a lot like number, so the symbol average will converge to exaggeration.

61
00:06:43,410 --> 00:06:49,560
Right. And but of course, the speed of our complicates things because see, the bar depends on the data as well.

62
00:06:49,960 --> 00:06:56,490
The we call one theta bar is theta bar is some value between some battle between theta heavy and a of zero.

63
00:06:57,300 --> 00:06:58,990
But a theta has depends on the data.

64
00:06:59,190 --> 00:07:05,510
All the data point I had is now of course if you gonna hold of the eyes that means Theta Bar also has a hold of the eyes.

65
00:07:06,030 --> 00:07:13,060
So that means that if you look at this. This ceremonial duty evaluate after the bar.

66
00:07:13,300 --> 00:07:17,620
These are not ideas anymore because each one I don't see the bar.

67
00:07:18,220 --> 00:07:22,450
These are not ideas over the conventional Lovelock number does not apply here.

68
00:07:23,320 --> 00:07:29,170
La la la la la. Number one is that they're good to the ideas.

69
00:07:29,380 --> 00:07:33,510
However, we are able to apply the so-called uniform with a lot of rock them.

70
00:07:33,850 --> 00:07:39,820
We talk about the we are talking about that in slightly more detail in a few minutes.

71
00:07:40,270 --> 00:07:46,310
But now, by applying the. Uniform.

72
00:07:46,720 --> 00:07:56,890
A lot of the numbers this will converge in probability to is that if we use age to denote the information.

73
00:08:06,930 --> 00:08:16,740
And the better. He values the truth. The reason that now in concert is to raise the bar and leads me to say I haven't seen a zero,

74
00:08:16,800 --> 00:08:21,270
but we know an estimate of how to convert is probably zero because it consistent.

75
00:08:21,810 --> 00:08:28,770
So then as the sample size increases, this is the novago also can work together.

76
00:08:29,670 --> 00:08:33,120
So that's what happens to this this guy.

77
00:08:33,630 --> 00:08:39,120
And then for the second guy, as we mentioned very briefly in the last lecture.

78
00:08:39,870 --> 00:08:44,160
So the second I here, if you look at the inside of the song.

79
00:08:46,310 --> 00:08:48,770
This. It helps.

80
00:08:48,770 --> 00:08:56,540
You can just give it another name you can call it a otherwise is just another run a miracle thunder and the sky blue eyes four different eyes.

81
00:08:56,540 --> 00:09:03,170
They are I and they do not depend on theta because this function they are evaluated at zero, right?

82
00:09:03,220 --> 00:09:06,050
So, so these are just a bunch of running parables.

83
00:09:06,800 --> 00:09:16,670
And because this is the source of delta theta, this is the score, the log and a likelihood so that the score zero is equal to zero.

84
00:09:17,060 --> 00:09:25,140
So in other words, if we call this whole thing w high, that is that W is equal to zero and w i's they they are idea.

85
00:09:25,240 --> 00:09:29,720
So then from a central venous here we know that this over here.

86
00:09:33,560 --> 00:09:42,440
This thing command is in decision to a norm, and so it will apply to the central bank emergency.

87
00:09:42,740 --> 00:09:47,270
India's return to normal would mean zero unless the various is equal.

88
00:09:47,270 --> 00:09:50,510
G And we used to be known to the Avengers here.

89
00:09:52,200 --> 00:09:53,880
Well is actually if you recall,

90
00:09:54,150 --> 00:10:03,190
the central theme is there are many absolute equal to the bearers of w-what in a convergence normal would mean zero and there is a w life,

91
00:10:03,930 --> 00:10:11,790
but a w high is a score. So the variance of the score is actually things that Asian health score can score transports.

92
00:10:12,790 --> 00:10:29,430
So here we have this foundation, the score which is long zero times on right range and this one eight.

93
00:10:37,260 --> 00:10:46,080
But principles. So to convert is to set a normal decision.

94
00:10:50,820 --> 00:11:01,560
Okay. So then if we see what we have now, so squirt them in times theta had a -0 zero that is equal to.

95
00:11:02,880 --> 00:11:09,660
Something small part of the few things, and then one factor converging probably due to a customer matrix.

96
00:11:11,360 --> 00:11:16,640
The second term converting disillusion to normal so that if we apply the Slattery Theorem.

97
00:11:17,580 --> 00:11:21,760
This whole thing will convert is the product will convert will convert into this fusion.

98
00:11:21,990 --> 00:11:38,040
This is actually based on applying. Just lastly theorem and convert is to have a narrative in the French.

99
00:11:38,200 --> 00:11:41,800
Then we have a H inverse.

100
00:11:44,500 --> 00:11:47,950
As normal would be zero. But there was.

101
00:11:54,160 --> 00:12:03,129
And here while we have age inverse because while the symbol average here inside the brackets emerges

102
00:12:03,130 --> 00:12:09,370
to age and then inverse function is a continuous function rather than if we apply the Islamic theorem.

103
00:12:09,370 --> 00:12:16,210
So if this symbol every convert is to h in probability, that is inverse converges to the inverse of H.

104
00:12:16,510 --> 00:12:27,220
And that's why we here we have a inverse. Beijing was and then this is as an equal to normal will mean zero and J.

105
00:12:27,420 --> 00:12:31,380
Imus. This is. By applying the.

106
00:12:41,360 --> 00:12:49,610
The information quality. Which says that H.

107
00:12:58,070 --> 00:13:05,930
Is equally damaging if you recover the information qualities from the emotions that the score function or likelihood of a score function.

108
00:13:06,150 --> 00:13:12,860
These additional the score time score transpose is equal to negative things that I would urge on this score.

109
00:13:13,420 --> 00:13:18,230
And so that's what we learned from it. So that's a priority of the score function.

110
00:13:18,740 --> 00:13:21,470
So that's the so-called information quality. I'm not sure if any.

111
00:13:21,650 --> 00:13:29,780
I think last year in my section six or two, I tried to emphasize this, but I'm not sure about the other section.

112
00:13:29,780 --> 00:13:34,249
But if I don't matter to Mark, this is just a name. Well, essentially it is this equality.

113
00:13:34,250 --> 00:13:39,000
So the score is on. The score is equal to 96.

114
00:13:39,050 --> 00:13:42,370
That is an urgent. Okay.

115
00:13:42,380 --> 00:13:50,660
So then if you look out here now finally we get a summary of this fusion of this word of Empire State of mind set of zero.

116
00:13:51,110 --> 00:13:54,920
And that's that's the typical normal description.

117
00:13:55,580 --> 00:14:04,790
We have seen this trend. So this option and this is how the is not even a normality is established as long a new series is average

118
00:14:04,790 --> 00:14:13,099
for now and it turns out that this procedure if you look at what we have done like we have first of all,

119
00:14:13,100 --> 00:14:17,870
we have expressed the now as the solution to our equation, to the square equation,

120
00:14:18,260 --> 00:14:25,700
and then we apply that the model theorem and to expect the square equation and then we

121
00:14:25,700 --> 00:14:33,620
solve for Squirtle Square of the end times theta -0 had a -0 and then we apply that.

122
00:14:33,800 --> 00:14:38,540
We have a large number in the theorem and that's last theorem and then we got a final result.

123
00:14:38,660 --> 00:14:47,809
It turns out this, this is more like an algorithm. You can apply this roughly almost exactly the same procedure to different meters.

124
00:14:47,810 --> 00:14:50,959
Then you are able to establish this normality.

125
00:14:50,960 --> 00:14:58,130
But these are massive meters. Now let's take a look at this is using emoji as an example.

126
00:14:58,250 --> 00:15:02,920
Now let's take a look at the common structures behind the hundreds.

127
00:15:03,190 --> 00:15:07,760
And we will look at the. A more general result.

128
00:16:16,400 --> 00:16:25,490
So to establish normality, typically what we want to have in the end is an expression like this in the first line.

129
00:16:26,900 --> 00:16:33,350
So the stratum in theta had a mindset of zero is equal to one respectively, in summation.

130
00:16:33,550 --> 00:16:42,260
And these are something we have a function of the height of the data and then plus some, you know, this is small p one.

131
00:16:43,400 --> 00:16:50,540
I'm not sure. Have you guys seen this notation from six of us from eight or 100?

132
00:16:50,540 --> 00:16:53,670
How have you guys covered? This is a better one. Okay. Okay.

133
00:16:53,690 --> 00:16:58,430
So that's. That's right. So essentially what this means is that what this means is that.

134
00:17:01,520 --> 00:17:06,740
It compares to zero in would write so as as in go through third infinity now this term is

135
00:17:06,920 --> 00:17:12,950
just disappear is only a small small term so it's negligible compared to the first term.

136
00:17:15,450 --> 00:17:24,810
So the fire function here, the fire function has zero things that even is equal to zero and then the variance of the five function exists.

137
00:17:25,650 --> 00:17:30,690
So when we try to derive a much of normality in the end,

138
00:17:30,900 --> 00:17:38,580
essentially what we are looking for is an expression like this in first line, or in other words, we are looking for this file.

139
00:17:38,910 --> 00:17:45,300
So once we have this slide, we're almost done. So oftentimes people just sit well.

140
00:17:45,810 --> 00:17:50,280
When people are established as not even around, people will simply stop at a first one.

141
00:17:50,550 --> 00:17:52,710
The reason is that once you get in the first line,

142
00:17:53,430 --> 00:18:00,250
it's the result is sort of them because then the the because the fine has new zero and the variance is finite.

143
00:18:00,270 --> 00:18:02,190
Then if you apply the theorem,

144
00:18:02,490 --> 00:18:08,270
then this whole thing converting this built into a normal with a mean zero and a variance equal to the variance of fine.

145
00:18:09,010 --> 00:18:12,270
It's all on that equal you have by some will be the theorem.

146
00:18:12,270 --> 00:18:18,030
You have a summary of analysis. So to establish this as an analogy,

147
00:18:18,030 --> 00:18:25,830
we just need to essentially we are we're looking for these fractions like in the first line here and this is the corpus.

148
00:18:26,190 --> 00:18:33,180
Well, well if, if we are able expressly to have in this way then see the habeas corpus money would be.

149
00:19:01,770 --> 00:19:09,090
Well, because because the symbolism of this spot fires the eyes and the fire see is the so called influence function.

150
00:19:10,320 --> 00:19:16,920
This is the terminology from the last delivery term because the fight it quantifies how

151
00:19:16,920 --> 00:19:23,790
each the eye how easily that point influence as later than solely upon influence function.

152
00:19:26,490 --> 00:19:32,550
And then once we get to the influence function, then central limit theorem implies that.

153
00:19:46,270 --> 00:19:50,260
Implies that this will convert in his version.

154
00:19:50,530 --> 00:19:54,550
What normal would mean zero and appearance equal to the variance of five.

155
00:20:02,740 --> 00:20:11,139
Now let's try to connect to. Let's try to see how and how you can be expressed in such a small honor, such a common structure.

156
00:20:11,140 --> 00:20:25,290
As for me. I would go back to the strategist for now.

157
00:20:30,420 --> 00:20:35,340
We have expressed now in this particular way. So this is out of control.

158
00:20:36,390 --> 00:20:46,070
This matrix inverse times this. So it almost looked like you know, that that was not even a linear expansion of it.

159
00:20:46,620 --> 00:20:50,700
This is right over here, but it's not quite fashion yet.

160
00:20:50,940 --> 00:20:56,010
The reason is that here you can look at this function, this only dependency.

161
00:20:56,530 --> 00:21:01,980
And this is a function of zero. But you should have any estimate in that.

162
00:21:03,850 --> 00:21:07,390
So that's why that's I mean,

163
00:21:07,470 --> 00:21:12,690
this is required because we are going to apply a central linear theorem which

164
00:21:12,690 --> 00:21:18,410
says that which means the five Z to be highly likely to be in one another.

165
00:21:19,020 --> 00:21:24,780
So it shouldn't be an estimate. But if you look at the now, do you hear this expression?

166
00:21:25,690 --> 00:21:32,650
This matrix here, it depends on feeder bar. Lastly, the bar is estimated, CFR is estimated so.

167
00:21:32,990 --> 00:21:38,590
So if you look at this line along, it's similar to what we want it to have.

168
00:21:38,590 --> 00:21:43,420
But it's not exactly, exactly that. What we have is presage.

169
00:21:46,270 --> 00:21:52,200
I'm in and. Through a very simple confirmation we can.

170
00:22:46,970 --> 00:22:58,730
Okay. So what we did here was simply we and we simply kind of added this negative eight inverse and subtract this -18 verse.

171
00:22:59,300 --> 00:23:05,770
Right. And do we call that age inverse? Is. Our age is actually the.

172
00:23:08,280 --> 00:23:12,900
Age is the kind of limit. Of this guy.

173
00:23:12,930 --> 00:23:16,580
The symbol average of this convert is in probability to this age.

174
00:23:18,000 --> 00:23:23,820
So then the difference between the symbol, average and age should be negligible.

175
00:23:24,370 --> 00:23:31,110
They can be as one holidays and not related to the other. But of course, the differences is negligible when the symbol size is large.

176
00:23:31,590 --> 00:23:39,030
Now, what I do here is that I added this negative h inverse.

177
00:23:39,390 --> 00:23:43,080
Then I subtract some time in this -18 months.

178
00:23:43,920 --> 00:23:48,600
So. And then I group these two together.

179
00:23:51,400 --> 00:23:56,540
Right. So does everybody follow me on?

180
00:23:57,130 --> 00:24:06,760
So then the reason why I'm doing this is now if we look at this whole thing here, I can call this thing the fight of the sky.

181
00:24:07,300 --> 00:24:11,080
This does not depend on any estimated quantity, right?

182
00:24:11,110 --> 00:24:17,620
Age is a fixed matrix across the meter because that is the ability to do so.

183
00:24:17,620 --> 00:24:21,940
It is based on it and then the score is zero.

184
00:24:21,970 --> 00:24:31,040
This is also why this is just an error. So I can call this this thing here, this file or file.

185
00:24:32,860 --> 00:24:42,630
And then because the symbol, we know that a symbol average, this symbol, every convert is to h, then of course these inverse commands to end immerse.

186
00:24:43,330 --> 00:24:45,070
Then the difference between is true.

187
00:24:45,670 --> 00:24:54,160
If I look at the difference, the difference is actually equal to small p one because because one convert is to the other.

188
00:24:54,610 --> 00:25:04,690
The difference is negligible. And then if I look at this right over here now,

189
00:25:04,720 --> 00:25:13,930
the central Lima Theorem says that this one should convert is should convert to normal for normal, run the variable notice in this version.

190
00:25:14,710 --> 00:25:17,880
So, of course, then this is big. Okay.

191
00:25:17,890 --> 00:25:23,350
What is it? Just a center run variable is called a normal distortion.

192
00:25:23,710 --> 00:25:28,690
So it's a big one. So then we have a small b1415.

193
00:25:28,690 --> 00:25:32,770
Our big only one term, of course, is small, B one is negligible.

194
00:25:33,340 --> 00:25:44,200
So in other words, we have retained the square root of N consider have -0 zero in exactly the same form that we wanted to write.

195
00:25:44,200 --> 00:26:00,280
So here the expansion of so we have we have five Z that has plaza small B one term so that indeed.

196
00:26:00,610 --> 00:26:04,530
Now after this we realize that new employees just fabricates.

197
00:26:04,870 --> 00:26:08,230
So we can begin to put it under this common structure.

198
00:26:13,120 --> 00:26:21,249
Yes. I with a gradient. So it looks like you have two things in the subscript ingredient in the start of the second term.

199
00:26:21,250 --> 00:26:25,310
But I'm wondering what that is in here. Yeah. Oh this means the second.

200
00:26:26,150 --> 00:26:33,580
Okay. Yeah. So, um, so I mean delta theta, I mean a function, a g theta, for example.

201
00:26:33,580 --> 00:26:39,909
This means that the gradient or the first order or the jakobi may be right.

202
00:26:39,910 --> 00:26:46,990
So then this is why this is actually equal to download theta than Delta Sigma.

203
00:26:48,550 --> 00:26:58,500
This is just descending order or it has a matrix. Okay.

204
00:26:58,590 --> 00:27:10,200
Any other questions? Okay.

205
00:27:10,200 --> 00:27:14,790
So this is the. The comments, Roger.

206
00:27:14,820 --> 00:27:20,970
Now, let's take a look at. Now we want to show a general theorem for M estimation.

207
00:28:28,150 --> 00:28:34,900
So we consider a general m affirmation that is derived by maximizing the q

208
00:28:34,900 --> 00:28:41,900
inherent going to have to function and to establish as normal osmotic normality.

209
00:28:41,920 --> 00:28:51,420
We assume that it is already consistent and and the consistency can be established by firm 1.1.

210
00:28:51,490 --> 00:28:53,950
Right. So we are to assume that we have already done that.

211
00:28:54,340 --> 00:29:03,550
We have a consistency and now we want to establish the summary in analogy of this that's made up of now we need to make a few assumptions.

212
00:29:03,940 --> 00:29:07,599
One assumption is that the first assumption is that a zero the true value is

213
00:29:07,600 --> 00:29:13,330
inside the parameter space is not on the boundary is inside parameters things.

214
00:29:13,690 --> 00:29:22,410
The reason is that if it is on the boundary because theta has to convert is to theta zero, nothing happens.

215
00:29:22,540 --> 00:29:27,520
But essentially what eventually is going to be boundary as well, then we cannot take Divergent anymore.

216
00:29:27,730 --> 00:29:36,010
So on a boundary point we cannot take the root. So that's the reason why we require theta zero to be inside the parameter spaces

217
00:29:36,010 --> 00:29:40,300
and pure reports so that we can take root in a neighborhood of theta zero.

218
00:30:29,140 --> 00:30:36,760
And also we assume that the objective function is twice continuously differentiable in a neighborhood of center zero.

219
00:30:36,760 --> 00:30:41,499
And this is for most of the problem that we consider.

220
00:30:41,500 --> 00:30:43,830
This is our this is satisfied, right?

221
00:30:43,870 --> 00:30:55,650
So we do consider either near margin or generalizing a region as long as you know that I mean, that functions pretty smoothly, not so essential.

222
00:30:56,560 --> 00:31:02,800
So we can take good examples and then we assume that.

223
00:31:16,910 --> 00:31:23,120
We assume that this guy. Climate is in dispute and for normal.

224
00:31:23,120 --> 00:31:31,129
This is sort of a high level assumption. I mean, of course, you can this is this can usually be submerged by an appliance.

225
00:31:31,130 --> 00:31:36,430
And we need to film this. If you want to connect this to our previous example, for example, you're.

226
00:31:38,100 --> 00:31:43,200
For example when a new case for the new case now.

227
00:31:44,060 --> 00:31:52,890
This guy. This is actually equal to.

228
00:32:03,050 --> 00:32:08,660
We will do this. But he would do that.

229
00:32:10,520 --> 00:32:18,950
And then, of course, this converts to a norm of his future because simply apply to this score function.

230
00:32:20,690 --> 00:32:29,360
So here I mean, this is a relatively high level assumption, but you can easily establish that it's based on his own family.

231
00:32:29,690 --> 00:32:35,390
So you just make this assumption to make the transition of the theorem easier.

232
00:32:36,950 --> 00:32:42,620
And then. There exists a function of theta.

233
00:33:35,290 --> 00:33:43,630
And while there exist central function interest data that is continuous, at least continuous out of the true value.

234
00:33:45,040 --> 00:33:50,890
And also this signal emerges to this end theta uniformly.

235
00:33:52,200 --> 00:34:01,079
On a small neighborhood of below zero. This may also look a little bit hard to follow at the beginning, but again,

236
00:34:01,080 --> 00:34:08,250
if you connect this addition to the previous again so that's why we we use the allow you to illustrate that idea.

237
00:34:08,270 --> 00:34:12,930
So we want to continue this to the previous case and now you place.

238
00:34:13,600 --> 00:34:22,100
So in the menu case this is actually the second order of the origin of killed in passing, right?

239
00:34:22,170 --> 00:34:26,250
This is the second order route and evaluate in a bar.

240
00:34:26,820 --> 00:34:29,370
But now let's just a consider this to be a functional place.

241
00:34:29,620 --> 00:34:39,239
I'm not exactly that's in a bar but consider this to a function there and then age would be in this case would be the installation of that function.

242
00:34:39,240 --> 00:34:45,840
Okay. Okay. So here age is just images because we evaluate this as zero.

243
00:34:46,590 --> 00:34:53,190
Let's consider now H function H as a function theta, which is the foundation of the set,

244
00:34:53,190 --> 00:35:04,240
an older version of this Q and have said so and indeed it exists so because of a lot of large numbers or things that we can assume that you have.

245
00:35:05,220 --> 00:35:11,130
So then this collision here, this fourth collision is simply, you know,

246
00:35:11,200 --> 00:35:18,660
formalize that I just make it formal and make this assumption that there is such an age function.

247
00:35:19,290 --> 00:35:24,540
And the second on the verge of this convergence to age and uniform.

248
00:35:28,800 --> 00:35:36,830
And while again, in the new case, this age is simply the excitation of the so-called revolution of humanity.

249
00:35:42,430 --> 00:35:50,150
And also we assume this age. Is equal to age zero.

250
00:35:50,180 --> 00:35:53,560
This is not suitable. So it is in vertical.

251
00:36:08,320 --> 00:36:15,130
Okay. And again, if you want to connect those conditions to the previous and how you can spend this age would be.

252
00:36:18,810 --> 00:36:27,330
This ain't over here. They said this is a convertible so that you can take the Bahamas.

253
00:36:27,930 --> 00:36:30,420
So under all these conditions, then.

254
00:36:34,400 --> 00:36:44,360
They had a minor fit a0a month have an introvert ism is rooted to normal with a mean zero and age rebels equal to age inverse tenancy.

255
00:36:44,360 --> 00:36:57,590
Two months. 18 years. So this result here gives the US, not even Ramallah, a general estimate.

256
00:36:58,220 --> 00:37:02,250
Of course, under some conditions. And also, we are here.

257
00:37:02,270 --> 00:37:06,440
We are very explicit about what those conditions are and what is of some.

258
00:37:11,290 --> 00:37:18,030
So any question about this theorem in a cell, we will look at a sketch of its proof.

259
00:37:18,040 --> 00:37:21,430
But before we do that, any question about the material itself?

260
00:37:26,230 --> 00:37:29,320
Okay. Now, let's take a quick look at the proof.

261
00:37:30,780 --> 00:37:39,360
This is a sketch of the proof. Now, by sketch, we mean that it's not super rigorous.

262
00:37:39,780 --> 00:37:47,010
It is reversed. But we all made it some technical details to illustrate the main ideas in steps,

263
00:37:48,600 --> 00:37:56,580
because to make it a super rigorous is a lot of very tedious, very detailed arguments needed.

264
00:37:57,120 --> 00:37:59,790
But we just need to focus on the big picture here.

265
00:38:00,930 --> 00:38:08,850
So the proof is actually quite similar to the algorithm for the L0 described for that and I'll use an analogy as an example.

266
00:38:09,900 --> 00:38:17,190
Let's take a look at it. So because Peter had a convergence, you probably do two or see the zero.

267
00:38:17,380 --> 00:38:22,140
And as we have already assumed this and we have assumed the one.

268
00:38:22,140 --> 00:38:25,350
We have assumed the two. So one says that.

269
00:38:28,250 --> 00:38:35,160
Someone says that. Zero zero is the exact interior point of the parameter space.

270
00:38:35,610 --> 00:38:47,040
And to sense that the function we are looking at is a continuous principle, not because if we put all these three together like, you know,

271
00:38:47,190 --> 00:38:57,899
the consistency in one and two together, what it means is that not because zero zero is inside, well, is an interior point and a filter.

272
00:38:57,900 --> 00:39:03,570
How to convert is to zero zero. So eventually theater hat will also be an accurate point.

273
00:39:04,390 --> 00:39:07,630
Right, because it's getting closer and closer to that. Correct.

274
00:39:07,680 --> 00:39:13,500
True zero. So it also will have done will eventually fall into the space as an interior point.

275
00:39:14,100 --> 00:39:18,780
So was it is in pure point now because the objective evaporates continuous.

276
00:39:19,260 --> 00:39:27,930
So we can take a variety of the objective function, then evaluate it out of the hat so we can talk about the urge to the hat.

277
00:39:28,410 --> 00:39:37,380
So this is so this three collisions, putting them together, it implies that we can tell you that the diversity of the objective function,

278
00:39:37,990 --> 00:39:42,600
a theater hat and then evaluate and see the hat, this is equal to zero.

279
00:39:46,220 --> 00:39:49,710
Right. Does everybody follow this line of argument?

280
00:39:49,730 --> 00:39:57,770
Okay. And but here we want to be sort of reversed so this thing happens or occur.

281
00:39:57,830 --> 00:40:05,149
This event occurs with the probably the approach is one that's one and become very large because feedback is

282
00:40:05,150 --> 00:40:12,920
close to zero or only one sample size is very large or sorry or or at least one sample size is very large.

283
00:40:13,490 --> 00:40:19,610
So here it's safe to say that this one would probably the appropriate way.

284
00:40:19,640 --> 00:40:28,340
So what sample size is large? Now we can take a majority out of the hat and then certify that sort of a score equation.

285
00:40:28,560 --> 00:40:32,630
And the second first of all, to do that, you will do it. Okay.

286
00:40:32,840 --> 00:40:38,990
So what we've got here. Then we can apply a new model of zero.

287
00:40:39,350 --> 00:40:46,670
Let's apply to be valid here. Okay. So this implies that this is by being value.

288
00:40:47,880 --> 00:40:50,950
Earlier we had the.

289
00:40:57,310 --> 00:41:02,290
So the zero is equal to this, plus the second order guarantee.

290
00:41:04,950 --> 00:41:10,260
Evaluated at a feeder bar one times through the heart monitors.

291
00:41:15,710 --> 00:41:22,520
This is just a simple application on the battlefield. And we've seeing some battle because there have been a few.

292
00:41:23,870 --> 00:41:31,970
And then you have similar with before with the software that I have, I don't see the end of that multiplied by square.

293
00:41:32,090 --> 00:42:19,690
We have. Okay.

294
00:42:19,840 --> 00:42:26,559
And then we just and this is just to introduce an agent to simplify this a week we we call this

295
00:42:26,560 --> 00:42:35,610
function here the age function 700 to urge you to have recorded on this indicator that have.

296
00:42:39,520 --> 00:42:52,040
So this is why we we got and then. First of all,

297
00:42:52,040 --> 00:42:57,950
we noticed that the Cedar Bar most concerning probably the reason is that the bar

298
00:42:58,130 --> 00:43:02,780
is somebody would be two feet a half empty and the theater had a converted street.

299
00:43:03,420 --> 00:43:06,890
Then, of course, the bar must also convert to fix it.

300
00:43:07,550 --> 00:43:14,900
So in a bar converted to a theater zero and then a vision commission for comedian for is that.

301
00:43:16,620 --> 00:43:31,500
Canadian reports that there exist this age data which is continuous, and also the psychology of your head converting to age.

302
00:43:33,470 --> 00:43:41,450
Okay. So but we are we have already had to rewrite this second order in order to be able to and had a hat.

303
00:43:42,140 --> 00:43:49,480
Right. So now let's take a look at what happens if we apply this condition of revision four or something, four.

304
00:43:50,030 --> 00:43:55,040
So this implies that. Now, if I look at the difference between this.

305
00:44:02,650 --> 00:44:15,100
I look at the difference between this? So that is simply the second order of duty of a year and a half.

306
00:44:15,310 --> 00:44:19,240
I look at the difference between each head of the bar and H.

307
00:44:19,780 --> 00:44:23,650
H is if theta have a look at the difference between history.

308
00:44:24,890 --> 00:44:30,910
The difference between these two is negligible. So the reason is that I can write it this way.

309
00:44:30,910 --> 00:44:46,910
I use a triangular in quality here. Reference.

310
00:44:46,940 --> 00:44:55,400
I apply a triangle. Triangle in part. Right.

311
00:44:55,670 --> 00:44:57,170
And then secondly.

312
00:44:57,200 --> 00:45:07,760
Now, for for this first term here that I apply the assumption here because the assumption for a sense that a second cause that's that.

313
00:45:09,840 --> 00:45:17,910
In a business, each have each have. They have a central process that each have better and better there a difference?

314
00:45:19,770 --> 00:45:23,070
Is arbitrary, too small for anything uniform.

315
00:45:24,720 --> 00:45:27,470
Then if I apply the results, then of course.

316
00:45:27,480 --> 00:45:35,160
Now if I have that result for the bar in a bar inside of me, what would have been a zero reason, of course,

317
00:45:35,160 --> 00:45:42,230
if I had an example, then this is going to be smaller than or equal to the super in like the function.

318
00:45:42,240 --> 00:45:48,570
The difference is the thinner bar, of course, is less than or equal to the the function of the supermarket essential.

319
00:46:08,890 --> 00:46:20,130
Okay. But a commission can take a while assumption for sense that the supreme as to the commodities within the first term commodities do.

320
00:46:22,660 --> 00:46:25,990
Now what about the second term? The second term also converges with zero.

321
00:46:26,590 --> 00:46:34,840
The reason is that we assume cohesion for a sense that agents and U.S. agents communities are doing.

322
00:46:36,340 --> 00:46:44,910
And of course, the bar converges to zero. So once it is continuous, then each of our murders will take a different.

323
00:46:44,930 --> 00:46:50,620
This is just a continuous mapping theorem applied to see the bond or a 5 to 8 function.

324
00:46:50,950 --> 00:46:54,760
So basically the ozone murders to zero. So.

325
00:46:54,910 --> 00:46:59,110
So then the sum of this will of course convert is in probability to zero.

326
00:47:08,710 --> 00:47:14,490
Okay. So does everybody follow the argument so far? Okay.

327
00:47:15,420 --> 00:47:28,020
So then. If I look at a condition five or assumption 505 says that age is the single word if age is not singular.

328
00:47:30,160 --> 00:47:39,400
Mm hmm. And we just derived that h had theta bar minus H the norm normal converted to zero.

329
00:47:39,580 --> 00:47:44,050
That essentially means that eight have been a bar convert is in probability to age.

330
00:47:45,010 --> 00:47:55,840
Right but age is invert reversible. So that of course he was a page out of the park where it is impossible to imagine age.

331
00:47:55,870 --> 00:48:12,520
He was. And this is simply because age is convertible in 18.4 and a matrix inverse is a continuous function.

332
00:48:15,940 --> 00:48:24,470
So if we put all these things together. Now let's go back to the the.

333
00:48:26,780 --> 00:48:36,620
So this is right in here because after applying the Bible of zero, we have expressed the square in terms see the hand amount is zero as this.

334
00:48:37,680 --> 00:48:44,150
Right. And now what we have done is that we have shown this guy the first from here.

335
00:48:44,540 --> 00:48:48,140
The first factor here commands in probability to negative eight inverse.

336
00:48:50,370 --> 00:48:55,260
It is probably easier. And also for the second factor here.

337
00:48:55,950 --> 00:49:00,169
This guy, we have assumed. That's our provision.

338
00:49:00,170 --> 00:49:06,920
Three We have assumed in a converted to normal distribution that we can simply apply

339
00:49:07,100 --> 00:49:19,010
slides and feel the product will convert to normal and then of some degree of plus.

340
00:49:33,590 --> 00:49:49,790
While implying that these are some. Okay.

341
00:49:49,790 --> 00:49:56,540
So that concludes our approach to any questions.

342
00:50:01,020 --> 00:50:11,540
So if you look at the whole crew here, I mean, this essentially essentially is the same procedure as the procedure we do not even remotely for now.

343
00:50:12,360 --> 00:50:20,280
Right. It's just and now is a more general theory. This is far from an end, but essentially it's the same.

344
00:50:21,450 --> 00:50:24,230
So in the middle, we actually applied the malware theorem.

345
00:50:24,240 --> 00:50:34,920
We have applied the slide theorem and also most of the assumptions we have made just to make the procedure rigorous.

346
00:50:40,180 --> 00:50:46,690
Okay. This actually this result is about a study of this fusion of nature.

347
00:50:48,350 --> 00:50:53,060
Okay. So and question there is no question then we will move on to the next topic.

348
00:50:57,810 --> 00:51:29,260
Okay. So the next topic is, is the so-called estimating equations or I think you know, why you probably talk about this later.

349
00:51:29,330 --> 00:51:41,600
I didn't talk about it as Z. So Business Z as near Z stands for 000 of an equation or zero as standpoint.

350
00:51:41,870 --> 00:51:46,700
Now let's talk about as many equations by solving which we will get to the Z.

351
00:52:12,920 --> 00:52:17,960
So for as many equations, this is typically the model assumption for as many equations.

352
00:52:19,010 --> 00:52:25,820
So as many equations generate is a same parametric model in the sense that you do not specify the components vision of the data.

353
00:52:26,210 --> 00:52:32,570
So if you consider maximum like last mater, you also, while you always respond to this fusion, you are similar data for normal.

354
00:52:32,570 --> 00:52:39,980
Those version or whole experimental are all a puzzle. This version always spins out of this unit, but we're estimating equations.

355
00:52:40,220 --> 00:52:44,150
This is some parametric model. It does not specify the whole distribution.

356
00:52:44,150 --> 00:52:49,370
You just assume the data that is fusion satisfy. You know, they use original this function.

357
00:52:49,370 --> 00:52:58,790
You can do zero for example like with very simple example would be you can data you think that the

358
00:52:58,790 --> 00:53:04,490
data is generated from a news fusion where the first moment where the mean is equal to the variance.

359
00:53:05,970 --> 00:53:11,220
Now, of course, posing this notion is such an example I posed is going to be known to millions of Americans.

360
00:53:11,700 --> 00:53:16,680
Well, I say that if you are not willing to assume that data is generally triumphalism, you think that's too restrictive.

361
00:53:18,360 --> 00:53:27,870
So but I do believe that, you know, that these still are allowed to sue to generate other municipal events than you can simply assume to equation.

362
00:53:27,990 --> 00:53:32,790
I mean, it has all the grandeur. If I didn't embarrass you, then I'm sorry.

363
00:53:32,830 --> 00:53:40,970
But, you know, the first moment of the first moment you had a family member around her.

364
00:53:41,120 --> 00:53:46,530
So so then you have two equations basically specify that the relationship between the first two moments.

365
00:53:47,760 --> 00:53:50,940
So that's what we mean by as made in equations.

366
00:53:52,530 --> 00:53:54,240
And typically well there are two.

367
00:53:56,180 --> 00:54:06,950
Of course, this one is that if we look at the mention of Gianna Theta, imagine G, of course it's how many equations you have.

368
00:54:07,670 --> 00:54:10,940
And the measure theta is, is the number of parameters you have.

369
00:54:11,720 --> 00:54:16,970
Now, if you have the same number of countries as the number of equation or number of divisions,

370
00:54:16,970 --> 00:54:23,390
the same is equal to the number of primary one you can directly solve theta by.

371
00:54:31,830 --> 00:54:37,250
By solving this equation. But because you have five parameters,

372
00:54:37,370 --> 00:54:43,400
then you have five equations that in principle you are able to solve this equation together to determine your estimate.

373
00:54:43,940 --> 00:55:01,770
So this is the so called ZF. ZAKARIA So in this as you get the seat of Mali as a special tribal leader, because now you solved the square equation.

374
00:55:40,040 --> 00:55:46,250
A more commonly seen case is you have more equations than the normal parameters.

375
00:55:47,880 --> 00:55:54,810
Were included in a number of parameters. Just consider the example we have about so you assume the data follow.

376
00:55:54,820 --> 00:55:58,860
This routine is generally from a dashboard where the mean is equal to the boundaries.

377
00:56:00,960 --> 00:56:05,430
Then you only have one prime. The mean parameter is equal to the various ground you want to have.

378
00:56:05,430 --> 00:56:08,730
You want data that's false to meet the boundaries.

379
00:56:09,480 --> 00:56:17,129
However, the mean is as the corresponds to the first moment and the variance corresponds to a second moment when to estimate a fever.

380
00:56:17,130 --> 00:56:18,330
Then you have two equations.

381
00:56:19,260 --> 00:56:25,740
You can specify the equation based on the first moment and another in the second moment, but you only have one parameter, so that's okay as well.

382
00:56:26,040 --> 00:56:29,850
You have more equations than the number of parameters.

383
00:56:30,300 --> 00:56:36,480
In that case. Generally speaking, there's no easy solution to this equation.

384
00:56:37,740 --> 00:56:42,930
There's no point feeling that you're actually threatened by all this, including simultaneously.

385
00:56:43,320 --> 00:56:49,220
But there are methods available in the literature that allows you to estimate theta.

386
00:56:49,380 --> 00:56:54,720
If you have more conclusions than normal rumors, then that includes the generalized matter moments.

387
00:56:55,380 --> 00:56:59,790
So that includes that both are widely used results.

388
00:57:01,320 --> 00:57:06,600
But for this course we are not going to talk about any of this methods.

389
00:57:06,870 --> 00:57:14,140
But I just want to point out there's such a situation where the number of counters is larger than the number of equations, larger than the number of.

390
00:57:15,020 --> 00:57:19,850
Now, the example that we are going to use is the G.

391
00:57:22,630 --> 00:57:32,770
So I think that all of you have taken six, maybe three houses, so that, of course, you must have learned generalized equations.

392
00:57:33,340 --> 00:57:37,000
So I think we can use this as an example.

393
00:57:37,630 --> 00:58:14,280
You. So this is one of the g one of the motorways.

394
00:58:15,900 --> 00:58:21,209
So we have a supposing carburetor from, you know, from an individual's eyes,

395
00:58:21,210 --> 00:58:26,040
you know, to mind the individual and then you follow each subject repeatedly.

396
00:58:26,460 --> 00:58:31,790
So you follow it, although is somebody that has to visit and ah, you can't do that.

397
00:58:31,800 --> 00:58:39,160
So why idea is that the the beta measurement at the dates visit for somebody high and the you measure

398
00:58:39,160 --> 00:58:46,799
of covariance exercise as well and the G does not specify the the whole distribution of the data.

399
00:58:46,800 --> 00:58:50,460
Right. Only models that meet the values of Y, even X.

400
00:58:50,880 --> 00:58:56,370
So let's assume that an intelligent Y given that is given by this meal is a known function.

401
00:58:56,850 --> 00:59:05,850
So it depends on the covariance and also depends on some parameter beta evidence how we like to estimate the probability.

402
00:59:08,600 --> 00:59:28,320
And then to estimate a beta zero. If you.

403
01:00:33,120 --> 01:00:47,720
So what else made a better zero? While the SB equation approach is to take an arbitrary matrix function of data and data on the ground,

404
01:00:48,260 --> 01:00:52,940
so it's a P by T matrix and PS the dimensional theta.

405
01:00:54,170 --> 01:01:01,280
So after we make an arbitrary such a matrix, then we modify.

406
01:01:01,760 --> 01:01:08,060
This is sort of the residual one minus y, y, j minus, you know, the beauty.

407
01:01:08,900 --> 01:01:12,710
So this is sort of what we do as a leader at a deeper visit.

408
01:01:13,610 --> 01:01:19,070
And this is, of course, the key by one factor, because we have t visits by one factor.

409
01:01:19,430 --> 01:01:26,600
And then if we multiply it by an arbitrary P by key matrix, then we have a P by one factor in the hand.

410
01:01:27,790 --> 01:01:33,220
So this whole thing is people a vector and of these foundation of this is equal to zero.

411
01:01:33,520 --> 01:01:36,910
The reason is that this is very easy.

412
01:01:37,060 --> 01:01:42,130
So you can you can tell a disease that Asian by first Asian all acts the first.

413
01:01:42,250 --> 01:01:51,190
You know, I ask if your condition are X, then of course, the this thing can be well without the examination comes on X.

414
01:01:51,640 --> 01:01:58,000
And then the second God I did it all x things that is in 020, because that's our moral assumption.

415
01:01:58,480 --> 01:02:05,440
So for the second diamond, you don't actually see, which makes the whole foundation people who do.

416
01:02:07,500 --> 01:02:15,450
Okay. So the reason that we are doing this is now we can with this becomes a special case of the as many equations.

417
01:02:15,840 --> 01:02:25,890
So you can call this C times, this residual, you can call that as your G function, as making functions, and g is indeed a function of your theta.

418
01:02:26,280 --> 01:02:37,950
Uh, now Z has really has as to why that's so we can use it to denote the combination y an x and also is a,

419
01:02:38,730 --> 01:02:42,560
it's a function of the prime feeling in this case is faith.

420
01:02:43,800 --> 01:02:46,500
So then that is not even jus equal to zero.

421
01:02:47,580 --> 01:03:00,690
So indeed now this g can be considered as a special case of of the general data, can be or can be solved as by using as many equations.

422
01:03:00,900 --> 01:03:07,500
And here and then the g is a special case of this by taking a particular C matrix.

423
01:03:08,220 --> 01:03:15,150
So the G takes if you recall what did you is.

424
01:04:59,620 --> 01:05:06,310
I do recall what it used g actually takes to see this a vehicular matrix.

425
01:05:08,170 --> 01:05:19,030
And it's the paradox of the the gradient matrix of the mean vector that we saw in the New York Times,

426
01:05:19,210 --> 01:05:23,470
the inverse of the variance matrix for inverse of the second moment.

427
01:05:23,870 --> 01:05:31,620
It's a very interesting analogy, of course. Of course, because we didn't specify the model for the second moment.

428
01:05:31,630 --> 01:05:38,140
If you look at our model assumption from a vector, we only specify the model for the first moment for the mean.

429
01:05:38,350 --> 01:05:43,720
We only assume the mean following this model. Now of course, then G.

430
01:05:45,440 --> 01:05:48,679
Make some assumption about various as well.

431
01:05:48,680 --> 01:05:54,630
It assumes so-called working model for the balance working working correlation, for example.

432
01:05:54,920 --> 01:06:03,280
So gee, I think you probably have a lot of out of the working correlation one version come on similar right but that's sort of the,

433
01:06:03,530 --> 01:06:07,760
you know, a working model for that for the second a moment that's not in the model interest.

434
01:06:08,180 --> 01:06:10,129
But anyway, so you need to assume that.

435
01:06:10,130 --> 01:06:20,810
So then the G as you compose the second the moments, that's the variance covariance matrix of it matters in this particular way.

436
01:06:22,130 --> 01:06:25,490
So we see here this is a diagonal matrix.

437
01:06:25,580 --> 01:06:34,190
One is out of the elements, the variance of the y t y y js at different visit and of a in the middle.

438
01:06:34,190 --> 01:06:40,160
This is the correlation matrix. The correlation matrix for all the repeated matters.

439
01:06:41,000 --> 01:06:45,350
And then you can assume different things.

440
01:06:45,440 --> 01:07:15,290
Structure for the correlation matrix. Energy you just assumes makes deeper into a working correlation assumption about the production metrics.

441
01:07:15,290 --> 01:07:23,120
For example, it assumes that a equal to an energy matrix that is simply assuming that all of the batteries are independent.

442
01:07:23,690 --> 01:07:27,860
Or you could assume that the combined synergy that's.

443
01:07:32,020 --> 01:07:37,490
Without an owner review. The matter is they have that we have equal correlations or.

444
01:07:51,040 --> 01:08:00,710
Or you could assume that the only adjacent matters that are covered, indeed none of the matters that are not addressed, then they are independent.

445
01:08:01,120 --> 01:08:06,549
This is another time. Of course you have all these different assumptions, but that's G, right.

446
01:08:06,550 --> 01:08:10,930
He assumes a varied like working working model for fairness.

447
01:08:11,710 --> 01:08:15,490
And once you take this, see as as we mentioned.

448
01:08:15,520 --> 01:08:25,540
So you take this federal seat. And once we take this federal seat, then later, Jean, to the hat in a ESOPs.

449
01:08:27,100 --> 01:08:47,520
This equation. But.

450
01:09:09,250 --> 01:09:12,400
Okay. So this is what a G, as we heard is. It is solve this equation.

451
01:09:19,710 --> 01:09:23,430
So this is an example of that as maybe equations.

452
01:09:24,570 --> 01:09:30,180
Now let's take a look at the general result regarding to the Z aspect.

453
01:09:32,040 --> 01:09:35,230
So G. S matrix is just. Yes.

454
01:09:58,970 --> 01:10:04,150
So yeah, I wanted to make it very clear that on the basis of what we mean,

455
01:10:04,160 --> 01:10:15,620
these three to have inside this equation some of these equations for me, other words, now we are for this cause.

456
01:10:15,620 --> 01:10:20,870
We are considering a case where the number of the equation is equal to the number on ground.

457
01:10:21,890 --> 01:10:28,540
We we are not looking at it is so by so then by solving this equation, we have to.

458
01:10:28,560 --> 01:10:34,360
So now we are trying to look at the properties of this data.

459
01:10:46,420 --> 01:10:53,320
Now for Zia's major, we are going to we are not going to be as detailed as the M as they are.

460
01:10:53,590 --> 01:10:57,400
So for M as major, when we talk about a consistency of reality,

461
01:10:57,850 --> 01:11:06,460
we supposed to list all the provisions that are needed for these major cities, civilization under a certain regularity conditions.

462
01:11:07,270 --> 01:11:14,349
The conditions are similar to them, and our estimates are not not some of them.

463
01:11:14,350 --> 01:11:18,130
They are they're very similar. Some of them are because of the Libyan equation.

464
01:11:18,790 --> 01:11:25,680
So this you might see this phrase and also I read the papers and under a certain regard,

465
01:11:26,200 --> 01:11:33,310
this is a phrase that some people but sometimes people are indeed is when people say that is the they are super clear what conditions they meet.

466
01:11:33,640 --> 01:11:37,900
But some of the others themselves problem has a role here.

467
01:11:37,900 --> 01:11:41,370
They want to welcome the news, but they see this anyway.

468
01:11:41,410 --> 01:11:56,110
And so nowadays people are not super picky about this as long as, you know, intuitively, the crack of dawn asked me to describe it,

469
01:11:56,110 --> 01:12:04,450
describe it, and then then if some somebody go through the detail of religion, they should ask me that I should be consistent.

470
01:12:04,540 --> 01:12:12,879
Should it be normally disputed? This and then people are not so worried about executions because people know

471
01:12:12,880 --> 01:12:18,370
that some conditions they are just for harvest are not there heart attack.

472
01:12:19,540 --> 01:12:29,350
So for now we just and for this year we have take this approach so under certain regularity conditions we have had a convert is to think to do.

473
01:12:29,920 --> 01:12:36,360
So we have consistence. And secondly.

474
01:12:44,870 --> 01:13:30,129
We have ground. Okay.

475
01:13:30,130 --> 01:13:34,530
So here there is a there is a transport over here.

476
01:13:34,960 --> 01:13:41,500
This is important transformers in a major part of this movie.

477
01:13:41,770 --> 01:13:45,280
This is the Transformers on this matrix.

478
01:13:52,550 --> 01:13:55,790
Okay. So this is the result for.

479
01:13:59,500 --> 01:14:04,600
The two properties were zero. Now, let's take a very quick look at the.

480
01:14:19,420 --> 01:14:31,030
So to prove consistency, we can directly make use of the theory consistency of air as a meter so the to will probably

481
01:14:31,030 --> 01:14:35,650
be fun and that Hamas leaders can see Gaza as made or to be a special Hamas leader.

482
01:14:35,680 --> 01:14:41,139
Then we can drag the fiber system down for mass so that the way to consider

483
01:14:41,140 --> 01:14:45,940
the gas meter as a special case of an escalator is to define this function.

484
01:14:46,360 --> 01:14:50,710
The Q in the function, we define it to be.

485
01:15:32,400 --> 01:15:46,320
Yeah, that would be fine. Q On the have been a simply to be the sort of rally form of this because theater had a SOPs symbol average of zero.

486
01:15:47,130 --> 01:15:52,010
The course theater had must minimize the column writing form, I swear.

487
01:15:52,380 --> 01:16:00,060
So this is this is just a sort of this is the square in the multidimensional for my special case.

488
01:16:00,780 --> 01:16:12,000
So I then if g was our if theta stop the symbol average of G2 zero down theta had minimized the square of this event in the middle.

489
01:16:12,570 --> 01:16:18,120
Well, I put a value in a friend, so it must maximize the value of the square.

490
01:16:18,690 --> 01:16:26,730
So if I'm to realize this that we can directly apply 1.1.

491
01:16:35,410 --> 01:16:55,000
They had to convert is probably used to. So that's the consistency of say that again that's by simply by considering their habits.

492
01:16:55,350 --> 01:17:03,389
Yeah. Okay.

493
01:17:03,390 --> 01:17:07,049
So here we are, right on time.

494
01:17:07,050 --> 01:17:13,680
So I think we go. Yeah, we'll stop here and we will continue to extract.

495
01:17:21,860 --> 01:17:26,840
But we are.

496
01:17:31,170 --> 01:17:36,090
Oh, I apologize, guys. I forgot to turn on the recording, so.

497
01:17:36,360 --> 01:17:40,440
So there is probably no recording for this lecture on day.

498
01:17:46,610 --> 01:17:55,680
I So this is a demo again.

499
01:17:56,070 --> 01:18:01,080
Just make up and do it for your convenience.

500
01:18:02,730 --> 01:18:06,450
Yeah. You should be able.

