1
00:00:05,290 --> 00:00:15,340
Okay. Yeah.

2
00:00:18,980 --> 00:00:26,030
Okay. So, yeah, let's get started. So, yeah, this is on the homepage and if you sign here,

3
00:00:26,030 --> 00:00:36,080
this is really some of the notes for the kind of a lot of the methods that have compiled the notes here.

4
00:00:37,070 --> 00:00:40,540
It's just that they're directly from the Yeah.

5
00:00:41,480 --> 00:00:50,900
Home page of the canvas, like this kind of GitHub site. So it's just has an absolute cover, all of it, this class or maybe I'll add some new things,

6
00:00:50,900 --> 00:00:59,120
but I think we're at least definitely going to cover mixed models and, uh, missing data to start things off, so.

7
00:01:00,620 --> 00:01:09,630
All right, so let's see. So. So I think probably a big move.

8
00:01:11,150 --> 00:01:22,070
Personally, I think a big proportion of your projects will involve longitudinal data, although maybe not 100%,

9
00:01:22,070 --> 00:01:31,370
but I think quite a few will have some type of longitudinal data analysis since this dataset has collected a lot of observations over time.

10
00:01:32,210 --> 00:01:42,020
So I think we'll basically talk today about mixed models, which is kind of one of the main ways of doing longitudinal data analysis.

11
00:01:43,340 --> 00:01:47,690
I think we're going to talk about these in a week or so.

12
00:01:49,100 --> 00:02:04,970
So it's just kind of a review hopefully for most people or either they've done it on 653 or maybe there's maybe a little bit of new material as well.

13
00:02:06,200 --> 00:02:09,410
Okay. So the longitudinal data is just at least.

14
00:02:10,900 --> 00:02:15,140
For this class. It's basically data that has multiple individuals.

15
00:02:15,730 --> 00:02:21,160
They don't necessarily have to be individuals, but they can be units that you're analyzing.

16
00:02:21,160 --> 00:02:27,340
But I mean, for this study, they're they're individuals. So you have many individuals.

17
00:02:27,340 --> 00:02:32,800
And then for each individual, you kind of have some measurement. Multiple measurements over time.

18
00:02:32,830 --> 00:02:35,710
So it's all kind of longitudinal data is.

19
00:02:37,030 --> 00:02:46,810
So for the notation for these notes, I'm just going to say y y j is the kind of the outcome of interest for an individual.

20
00:02:47,380 --> 00:02:54,850
I In time. T. J So the observation times could potentially be different.

21
00:02:54,850 --> 00:03:03,310
So that's what we have, T.J. But in some cases they're observed at the exact same times.

22
00:03:04,650 --> 00:03:10,770
So it wouldn't depend on I, but in many cases it can depend on you can have different observation times.

23
00:03:10,770 --> 00:03:16,410
So and that's the case for this study. So why is the outcome at time?

24
00:03:16,430 --> 00:03:25,320
T.J., you basically have and I will in my observations for each for each person.

25
00:03:26,540 --> 00:03:29,449
Okay. So that could be different across individuals.

26
00:03:29,450 --> 00:03:37,069
You don't have the same sample size for each individual and then the total number of individuals is in the notation of,

27
00:03:37,070 --> 00:03:45,290
and uh, that I'll use for the end people and each one has kind of in eye observations.

28
00:03:45,980 --> 00:03:56,210
And then for each person you're going to have a basically a vector or a vector and each, um, uh, a vector at each type point.

29
00:03:57,610 --> 00:04:07,280
Um. So ExigÃ© is kind of a p dimensional vector that has covariates for time.

30
00:04:07,880 --> 00:04:11,900
So these could contain covariates that.

31
00:04:12,990 --> 00:04:19,500
Either change over time or don't change over time. But you could still write them as in this form.

32
00:04:19,500 --> 00:04:25,170
It would just kind of repeat it.

33
00:04:25,170 --> 00:04:29,790
If it's not a time varying covariate just kind of repeat the same value at each time point.

34
00:04:30,510 --> 00:04:35,219
Okay. All right. So I guess I just wanted to make a note.

35
00:04:35,220 --> 00:04:39,710
So for a. For your project.

36
00:04:39,770 --> 00:04:49,310
It's you. You know, you might not. Or it's likely you won't have the data kind of in a nice form,

37
00:04:49,610 --> 00:05:02,240
at least in the sense that you're not going to have a y j and then a separate kind of excited j and that you get directly for each time point.

38
00:05:02,950 --> 00:05:06,529
So yeah, it's just something to keep in mind.

39
00:05:06,530 --> 00:05:12,860
So you prior, depending on your topic, you may have to do some kind of pre-processing of the data.

40
00:05:14,990 --> 00:05:22,550
So. I mean, it doesn't have to be complicated.

41
00:05:23,560 --> 00:05:28,030
He may just have to do some type of pre-processing pre processing that makes sense.

42
00:05:28,030 --> 00:05:38,710
So for example, you have the outcome of interest as it is only measured once per day, for example, but you had your covariates of interest,

43
00:05:39,670 --> 00:05:47,880
you could have some kind of movement data and where you have kind of many observations from per day basis.

44
00:05:48,970 --> 00:05:54,600
So that would be the covariate of interest. So you would have to kind of organize that in some way.

45
00:05:54,610 --> 00:06:03,849
I mean, I think a kind of a direct way of doing that might be just taking the, uh, the average for that day of your movement data.

46
00:06:03,850 --> 00:06:06,250
So that would be kind of your exercise j for that day.

47
00:06:06,670 --> 00:06:17,860
So usually something, something like that would be what you would need to do to kind of organize it in the traditional longitudinal data format.

48
00:06:18,580 --> 00:06:28,390
Um, so, yeah, this is basically, I'm kind of talking about situations where you're kind of your outcomes and your,

49
00:06:28,780 --> 00:06:31,960
your covariance are not exactly matched in time.

50
00:06:32,560 --> 00:06:41,020
So, you know, for example, you have more, you observe X IJA more often than Y AJC would perhaps take,

51
00:06:41,620 --> 00:06:53,739
take some type of average to get to kind of match up y i j or exi j or you may even observe the same number of outcomes,

52
00:06:53,740 --> 00:06:59,290
but they're, they're not observed at the exact same time.

53
00:06:59,290 --> 00:07:08,380
In that case, you can, you know, perhaps you want to match it to kind of the nearest YJ, something like that.

54
00:07:09,580 --> 00:07:18,010
But I think we'll probably, we'll probably mention more about this, which once people get in, get into their projects,

55
00:07:18,010 --> 00:07:23,739
many different ways of kind of processing the data so that it's in the traditional

56
00:07:23,740 --> 00:07:28,210
longitudinal format where you have you kind of everything's matched up in time.

57
00:07:29,050 --> 00:07:33,240
Okay. So this is just an example, uh.

58
00:07:35,780 --> 00:07:43,459
I guess just to discuss this, describe some aspects of mixed models and just how to use the LME for package.

59
00:07:43,460 --> 00:07:51,740
So I'm going to talk about that later. LME four package is kind of I still think it's the main packaging are for doing mixed models.

60
00:07:51,740 --> 00:07:58,620
So this is the. Sleep study data, or at least this is like a subset of the sleep study data.

61
00:08:01,080 --> 00:08:08,950
So the sleep study data, I think. Figure exactly how many people there were, maybe 20 or something like that.

62
00:08:10,180 --> 00:08:15,819
And they basically recorded measurements at kind of time, zero, which I guess is the baseline.

63
00:08:15,820 --> 00:08:21,130
And they record something every day up until the ninth day.

64
00:08:21,340 --> 00:08:27,160
So they have each person has ten measurements. Okay.

65
00:08:27,360 --> 00:08:30,590
And so I think the outcome of interest is a reaction time.

66
00:08:31,960 --> 00:08:35,540
Okay. So each person has ten measurements.

67
00:08:35,540 --> 00:08:46,639
That's what's plotted here. So I'm kind of. So each kind of each point on this graph is like a y i j it's a measurement made out of specific time.

68
00:08:46,640 --> 00:08:52,610
And I've tried to kind of connect the observations for a given individual with, with the lines.

69
00:08:52,730 --> 00:09:02,030
Okay. So like this, this is one person like if you trace this, I think it goes up here.

70
00:09:02,570 --> 00:09:06,860
So it's kind of been the reaction time over time for one person.

71
00:09:07,310 --> 00:09:15,330
Okay. So you can you can see that there is kind of a, uh, I would say in general there's an overall trend,

72
00:09:16,140 --> 00:09:22,440
you know, where reaction time is increasing over the days.

73
00:09:23,210 --> 00:09:26,100
Um, but there's definitely a lot of kind of variability.

74
00:09:26,290 --> 00:09:32,099
You know, some people well, I mean, they start off a lot lower and it doesn't really change all that much.

75
00:09:32,100 --> 00:09:35,160
So these two kind of people at the bottom.

76
00:09:37,950 --> 00:09:41,540
You know, they start off with a great reaction time and it doesn't really change that much.

77
00:09:42,350 --> 00:09:50,720
But some other people, there's kind of a lot of a little bit more of a somewhat of a clear and a positive trend over time.

78
00:09:50,870 --> 00:09:57,079
So this is one way of representing longitudinal data, sort of a graph like this.

79
00:09:57,080 --> 00:10:03,180
And then. This type of thing can get messier if you have a lot of individuals.

80
00:10:03,180 --> 00:10:08,030
But for. Kind of a moderate amount number of individuals.

81
00:10:08,060 --> 00:10:12,280
This type of plight is sometimes useful. Okay.

82
00:10:13,120 --> 00:10:16,779
So, yeah, this is just a this is an example of a small longitudinal study.

83
00:10:16,780 --> 00:10:27,340
You could look at it yourself. It's an LME for package. So for this this data set, the time points are actually the same for every individual.

84
00:10:27,610 --> 00:10:35,310
Like you observe them daily. So it really, really doesn't depend on time.

85
00:10:35,730 --> 00:10:39,960
So you could say, at least in this case, T equals t j.

86
00:10:42,330 --> 00:10:49,409
And then the outcome of interest, why it is, is the reaction time.

87
00:10:49,410 --> 00:10:52,649
And so that's basically the reaction time,

88
00:10:52,650 --> 00:11:06,190
a precise individual at time point t j and then so the time points in this case we have t one and I guess you could start at zero if you wanted to,

89
00:11:06,190 --> 00:11:15,170
but I usually start everything from one. So if you have t one up to ten, kind of zero up to nine.

90
00:11:15,180 --> 00:11:21,250
Those are the time points that we have in this study. Okay.

91
00:11:21,300 --> 00:11:31,210
So that's. So I guess just a more of a motivating example, uh, and we'll come back to,

92
00:11:31,220 --> 00:11:37,190
to a little bit when we talk about how to use the LME, the LME for package.

93
00:11:38,410 --> 00:11:43,780
So I think if you're doing like a regression kind of a regression analysis for longitudinal data,

94
00:11:44,380 --> 00:11:51,850
I think they can basically at least most of the common ones can be classified into one of these three types of models.

95
00:11:55,000 --> 00:12:03,820
I think what we're going to discuss in this class is are kind of random effects, mixed models and then marginal models.

96
00:12:04,480 --> 00:12:09,190
I think those are probably the most more common. There's also transition models.

97
00:12:10,560 --> 00:12:14,080
Know if you want to use one, you're here, you're free to do so.

98
00:12:14,080 --> 00:12:21,310
But I think it's probably a little bit less commonly is kind of a standard data analysis tool.

99
00:12:22,030 --> 00:12:25,329
So. Uh, so what?

100
00:12:25,330 --> 00:12:31,890
Our random effects are mixed models. It's basically more or less a standard type of regression model.

101
00:12:31,900 --> 00:12:43,340
It's just that you add. Some type of random effect or collection of random effects to the I like the main function for each individual.

102
00:12:43,340 --> 00:12:49,069
So in a regression, kind of a standard regression model,

103
00:12:49,070 --> 00:12:56,450
you have kind of the mean function as a model, as a linear function of the covariates for a random,

104
00:12:56,450 --> 00:12:57,379
for a mixed model,

105
00:12:57,380 --> 00:13:06,620
you're just basically adding random effects for each person and you're kind of adding that to them to the standard type of regression model.

106
00:13:07,550 --> 00:13:13,790
And then these random effects are you to think of them as random regression coefficients.

107
00:13:14,690 --> 00:13:21,229
So these are basically you view them as some they're basically like a sample from some

108
00:13:21,230 --> 00:13:27,890
distributions and the most common is going to be so normal or multivariate normal.

109
00:13:29,080 --> 00:13:33,830
That's basically what's in the test and most standard software.

110
00:13:36,930 --> 00:13:46,800
The other kind of the other main approach for analyzing longitudinal data is marginal models.

111
00:13:48,780 --> 00:13:54,960
So here they're kind of the regression coefficients have a type of population, average interpretation.

112
00:13:57,950 --> 00:14:00,319
And you you don't add random effects.

113
00:14:00,320 --> 00:14:12,560
You kind of only model the kind of the mean of y i j directly and the correlation structure of, of, of, of this kind of factor.

114
00:14:12,570 --> 00:14:17,590
Those are kind of the two main components of marginal models in p models.

115
00:14:17,600 --> 00:14:23,090
I mean, for each y, i j and then, uh, there's, there's at least some aspect.

116
00:14:24,270 --> 00:14:27,989
Of this joint distribution and you have two models.

117
00:14:27,990 --> 00:14:37,710
So this is kind of a vector and you might assume something about the correlation between components of this vector.

118
00:14:38,580 --> 00:14:46,680
So your generalized estimating equations are the most common approach for marginal models.

119
00:14:47,700 --> 00:14:52,980
So we'll talk about them next, next week or shortly thereafter.

120
00:14:54,780 --> 00:14:59,340
And then transition models, you know, we're not really going to discuss, but.

121
00:15:03,390 --> 00:15:07,430
Yeah. They are used to, you know, someone, but I think probably a little bit less common,

122
00:15:07,430 --> 00:15:13,040
at least in kind of like standard data analysis here for transition models,

123
00:15:13,700 --> 00:15:24,230
it's kind of like a you're basically specifying some probability model for, you know, the distribution of your outcome at Y a given.

124
00:15:25,220 --> 00:15:30,050
Well, it could be given kind of all of the stuff that happens before y.

125
00:15:30,920 --> 00:15:35,720
I mean, often you might just condition on the previous time point.

126
00:15:35,730 --> 00:15:43,250
So it's kind of like a mark off assumption. Um, so that, that's a, that's also a valid approach.

127
00:15:43,250 --> 00:15:49,000
But really what we discussed here. So here, let's just kind of.

128
00:15:49,010 --> 00:15:53,589
Right. I guess. Oh. Yeah.

129
00:15:53,590 --> 00:16:00,190
I just wanted to compare this, I guess mixed models with kind of traditional, traditional regression model.

130
00:16:00,190 --> 00:16:04,120
So this is, uh, you know, let's say y ECGs continuous.

131
00:16:04,120 --> 00:16:09,820
This would be like if you just ignore the fact that we're looking at longitudinal data,

132
00:16:10,360 --> 00:16:13,480
we just kind of stack all the observations on top of each other.

133
00:16:14,560 --> 00:16:18,010
Uh, and you're doing like a standard regression approach.

134
00:16:18,010 --> 00:16:20,950
This would be kind of the model that you would use, right?

135
00:16:21,710 --> 00:16:30,980
Uh, you have some intercept and then the outcome, just a linear combination of your covariance plus a residual term, the J.

136
00:16:32,350 --> 00:16:41,410
So this would be kind of to the standard regression approach instead of ignoring the fact that if we're looking at longitudinal data.

137
00:16:46,060 --> 00:16:54,340
So, you know, these covariates could contain kind of individual information such as smoking or or age at times.

138
00:16:54,630 --> 00:17:03,880
J Often you also want to put in, put in the time points themselves or functions of the time points themselves in exigÃ©.

139
00:17:03,880 --> 00:17:11,380
So this is kind of a general notation you could excite j could have t j or functions of t j inside of it,

140
00:17:11,860 --> 00:17:19,450
just so that you can allow the mean function to change over time, which is what you also want to do.

141
00:17:20,110 --> 00:17:31,540
So if you want to allow the mean function to change over time, you would have to have t inside of this vector x ija.

142
00:17:32,950 --> 00:17:36,080
Okay. So. Okay.

143
00:17:37,900 --> 00:17:41,540
So what are some features of this regression model with?

144
00:17:42,250 --> 00:17:49,840
I would say that a non and mixed effects regression models. It's basically I guess one thing to note is that.

145
00:17:51,670 --> 00:17:55,500
Okay, so the same kind of mean function. Uh.

146
00:17:57,460 --> 00:18:06,400
So this is the same value of the mean function applies to different individuals as long as they have the same value of exigÃ©.

147
00:18:06,400 --> 00:18:15,549
So if we have person A as a covariate exigÃ© and person B has the exact same set of covariates,

148
00:18:15,550 --> 00:18:20,050
you would predict the same kind of mean mean outcome for those two individuals.

149
00:18:23,540 --> 00:18:24,380
So.

150
00:18:27,250 --> 00:18:38,800
What kind of mixed models allow you to do is to allow for heterogeneity across individuals, even if they have the exact same covariance vector exi j.

151
00:18:43,450 --> 00:18:49,150
So you could see that this here. So this is a, uh.

152
00:18:49,300 --> 00:18:53,320
So this is so what this is is.

153
00:18:55,480 --> 00:18:58,520
I guess this is separate regression lines for each person.

154
00:18:58,540 --> 00:19:02,230
So here I've plotted data for three three individuals.

155
00:19:05,390 --> 00:19:15,700
So of subject 308 is the circle or the empty circle 309 Is there the x down here in three, three, three is the solid circle.

156
00:19:16,240 --> 00:19:24,940
So you can see there's kind of a a lot of variability in the relationship between reaction time and time.

157
00:19:25,740 --> 00:19:33,910
Uh, across the three individuals, there's kind of. You know this you know, this slope is kind of moderately positive.

158
00:19:33,910 --> 00:19:42,280
This is basically flat. And this is kind of a very strong relationship with reaction over time.

159
00:19:43,000 --> 00:19:56,180
So I think that one way to think about the mixed models is mixed models allows you to kind of model this this type of variability, right?

160
00:19:56,230 --> 00:20:02,850
So that it is a classic regression. You're just you're saying all of these three sets.

161
00:20:02,990 --> 00:20:09,350
And in this example, we actually don't. Have any kind of individual specific covariance.

162
00:20:09,920 --> 00:20:11,270
The only covariate is time.

163
00:20:12,020 --> 00:20:22,760
So if you were to fit this model to this sleep study data here basically saying that kind of everybody has the same mean function over time.

164
00:20:23,640 --> 00:20:32,690
Okay. And then the rest is just residual with a mixed model.

165
00:20:32,700 --> 00:20:39,200
Well, I guess we'll write down the the model in a second here, allowing you can allow each person to have a different.

166
00:20:42,700 --> 00:20:52,420
Intercept and a different slogan. So it kind of you know, it's basically think of it as, you know, better capturing the the variability in the data.

167
00:20:53,170 --> 00:21:01,030
So, I mean, you could fit a a regular regression without mixed effects, but it's basically you're going to fit, uh,

168
00:21:01,270 --> 00:21:08,380
kind of a single line for everybody and there's kind of going to be a lot of, uh, there's going to be a lot of residual variability.

169
00:21:08,980 --> 00:21:14,380
And here I think if you allow kind of a slope and a different slope and intercept for each person,

170
00:21:14,800 --> 00:21:19,240
you kind of capture more of that kind of residual variation.

171
00:21:20,220 --> 00:21:24,560
All right. So that's. Okay.

172
00:21:24,800 --> 00:21:28,970
So I think I just said that. So, yeah, this this figure.

173
00:21:30,140 --> 00:21:36,200
You know, there's heterogeneity in the relationship between study day and response time across individuals.

174
00:21:40,410 --> 00:21:44,220
So I think mixed models allow you to better capture that heterogeneity.

175
00:21:47,310 --> 00:21:53,050
Okay. So I think this just summarizes both things.

176
00:21:53,070 --> 00:21:57,960
So. So this would be the model if you didn't.

177
00:21:58,050 --> 00:22:01,890
This is the non mixed effects model for the sleep study data.

178
00:22:02,430 --> 00:22:10,200
So we just did that kind of classic regression approach, ignoring the fact that we're looking at the longitudinal data.

179
00:22:10,200 --> 00:22:15,149
This would be kind of the model that you would use. So everybody has the same main function.

180
00:22:15,150 --> 00:22:18,450
It would be beta zero plus beta one times. T j.

181
00:22:20,520 --> 00:22:25,080
So if we're doing a mixed model, this is basically the type of model that you're fitting, or at least.

182
00:22:26,470 --> 00:22:31,030
If we have a random intercept and stopped. So you still have the same.

183
00:22:32,330 --> 00:22:38,540
Our main function for. Fear.

184
00:22:39,400 --> 00:22:43,990
You still have the same part of this main function beta zero plus beta one t.j.

185
00:22:44,800 --> 00:22:54,570
But we're going to add a quote unquote random slope, which I'll call UI zero and then a random sorry, this is safe slope.

186
00:22:54,580 --> 00:22:57,790
This is random intercept UI zero.

187
00:22:58,660 --> 00:23:02,800
And then a random slope is UI one. Okay, well.

188
00:23:04,680 --> 00:23:07,710
Yeah. Okay. Yeah, we'll call it. It's a random slope.

189
00:23:08,310 --> 00:23:18,660
So basically so he's beta zero and beta one are are called like the fixed effects are the

190
00:23:18,660 --> 00:23:23,489
regression coefficients for the fixed effects and these guys are like the random effects.

191
00:23:23,490 --> 00:23:29,990
That's usually the way it's stated. And so you, the way you can interpret this is uh,

192
00:23:30,600 --> 00:23:38,850
beta zero plus UI zero intercept four for the nice person and then beta one plus

193
00:23:38,850 --> 00:23:43,709
UI one is the slope for the highest person that's the leader at for this model.

194
00:23:43,710 --> 00:23:50,970
That's the way that I would interpret it. So this allows a different intercept and slope for each for each person.

195
00:23:52,390 --> 00:24:01,470
Okay. Uh. Okay. So, yeah, I mean, if we're assuming for assuming that the guys are sampled from some distribution,

196
00:24:01,950 --> 00:24:06,959
these are these are would be called random effects typically.

197
00:24:06,960 --> 00:24:09,620
And then. I mean,

198
00:24:09,620 --> 00:24:20,240
the most common assumption is to assume that these are from multivariate normal distribution with mean zero and that that's what's implemented.

199
00:24:22,350 --> 00:24:25,460
It's standard software. Okay.

200
00:24:26,790 --> 00:24:36,519
So. Yeah, this is called mixed martial arts because it's a it's a mix of fixed effects and random effects.

201
00:24:36,520 --> 00:24:39,760
That's really the main reason.

202
00:24:42,180 --> 00:24:45,630
Okay. So that's that's a linear, mixed model.

203
00:24:45,870 --> 00:24:48,870
It looks something like this at least for the sleep study data.

204
00:24:52,350 --> 00:24:58,590
And I guess I'll go this briefly. I just wrote kind of the general like the general form of a linear mixed model.

205
00:24:59,250 --> 00:25:03,930
So a general form or a linear mixed model for your outcome.

206
00:25:03,930 --> 00:25:08,190
Y i j is just this exact j transpose times beta.

207
00:25:08,190 --> 00:25:11,129
So this is like the fixed effects part.

208
00:25:11,130 --> 00:25:23,220
And then in general, you can write the random effects part of this at some some other vector here z i j times a vector of random effects.

209
00:25:23,490 --> 00:25:29,470
Okay. Okay. So that's kind of a general form.

210
00:25:33,170 --> 00:25:41,210
So. I guess I just wrote that sometimes it's helpful to know this as well.

211
00:25:41,600 --> 00:25:50,329
So if you actually stack kind of all your responses into a huge long vector, so you basically stack them on top of each other.

212
00:25:50,330 --> 00:25:58,400
So the total number of observations is actually the sum of the ink because each person is in K observations.

213
00:25:58,520 --> 00:26:01,760
So you go from one to M, so that would be the length.

214
00:26:05,360 --> 00:26:11,810
And then you could do the same thing with your, your random effects. Um, so here that would have links.

215
00:26:13,190 --> 00:26:18,019
Oh. Oh, yeah, yeah, yeah. Like m times he plus one.

216
00:26:18,020 --> 00:26:22,960
I was assuming like the dimension of this UI is q plus one.

217
00:26:23,630 --> 00:26:37,070
So since each person gets a vector, a random effect vector of length, Q plus one and a total stack vector, you would have length M times Q plus one.

218
00:26:37,910 --> 00:26:41,060
So you can write down if you kind of stack everything.

219
00:26:41,990 --> 00:26:51,590
On top of each other. You can you can actually just write your linear mix model as in the matrix vector form and the following way,

220
00:26:51,590 --> 00:26:57,080
it's just a kind of an x, beta plus a, z, u plus E.

221
00:26:57,140 --> 00:27:05,300
So there's, there's for a linear mixed model where you in some sense kind of have an X design matrix and then the design matrix.

222
00:27:05,840 --> 00:27:08,479
I think one of the reasons I mentioned this,

223
00:27:08,480 --> 00:27:16,700
just because if you're fitting something with Elm before you can extract the the X matrix and the Z matrix.

224
00:27:16,700 --> 00:27:29,420
So sometimes it's, I think it's useful just to double check that the design matrix and the Z matrix are kind of matching what you expected.

225
00:27:29,840 --> 00:27:39,320
Okay. So just yeah, it's just good to know that when you're kind of extracting the model matrix in the Z matrix in LME four,

226
00:27:39,590 --> 00:27:42,710
it's kind of corresponding to this, this type of model.

227
00:27:45,710 --> 00:27:51,770
So that's the question so far, is it?

228
00:27:53,190 --> 00:28:02,360
Were you talking or is it reasonably clear?

229
00:28:02,370 --> 00:28:15,840
So. Yeah, I just wanted to also mention, I guess, why there's an advantage of using random effects, at least for longitudinal data.

230
00:28:15,850 --> 00:28:18,270
So one thing that you want to do in your.

231
00:28:20,590 --> 00:28:28,930
Looking at longitudinal data is to account for kind of the recenser of answer the question about the previous ocean closure.

232
00:28:30,820 --> 00:28:39,670
What's it like date of the children? So that's the first one for you to sort of made it to the third.

233
00:28:40,930 --> 00:28:46,379
Oh, this one. Yeah. Oh. Yeah.

234
00:28:46,380 --> 00:28:49,620
I guess I could have written in a different way. I was just saying that the.

235
00:28:50,940 --> 00:28:56,910
Well, let's see. Right. Why did I write it that way? I think I want to be the zero, actually.

236
00:28:57,810 --> 00:29:01,200
Yeah, I might have copied and pasted it. Yeah, that should be beta zero.

237
00:29:01,950 --> 00:29:07,390
Yeah, I was just saying that the, uh, like the first column of this as a is all ones.

238
00:29:07,470 --> 00:29:18,020
Yeah, yeah. Actually, I think it's a typo correction. Ever since, moving to Los Angeles like the two rappers.

239
00:29:23,360 --> 00:29:26,470
And it's not the same. I don't know.

240
00:29:26,500 --> 00:29:29,840
I don't know if I have to write it this way or if I used it later on.

241
00:29:30,650 --> 00:29:37,130
No, I was thinking better correspondence to the I think I was trying to get it to match to this type of thing.

242
00:29:37,820 --> 00:29:41,120
So way to correspond to that X and then we have a data zero.

243
00:29:41,900 --> 00:29:47,840
But yeah, so the beta till was like just combining the beta, not in beta.

244
00:29:52,520 --> 00:29:56,000
That's a good point. Any other questions?

245
00:29:59,130 --> 00:30:02,550
Well. All right. So.

246
00:30:04,380 --> 00:30:08,520
Yeah. I just make a quick point about why you want to use random effects.

247
00:30:11,220 --> 00:30:13,290
So one thing that you want to do when you.

248
00:30:14,760 --> 00:30:19,830
When your modeling longitudinal data is to account for a kind of what's called the within subject correlation.

249
00:30:20,580 --> 00:30:25,559
So that's basically you're not assuming that all the observations are independent.

250
00:30:25,560 --> 00:30:35,220
So kind of observation to different observations made for the same person should have some correlation since they're made from the same person.

251
00:30:36,580 --> 00:30:38,800
So when you're doing kind of a mixed model,

252
00:30:39,370 --> 00:30:49,390
you kind of automatically or there's at least automatically some correlation between observation on the same individual.

253
00:30:51,620 --> 00:30:55,129
At least kind of as a byproduct of using a mixed model.

254
00:30:55,130 --> 00:30:57,530
So you can actually work out the correlation here.

255
00:31:02,140 --> 00:31:06,969
It's not always necessarily the best form of the correlation, but it does it does generate some correlation.

256
00:31:06,970 --> 00:31:15,760
And then you're kind of going to estimate the sigma squared and this this made this matrix sigma sigma tao.

257
00:31:15,760 --> 00:31:19,690
So that will kind of estimate the proper level of correlation.

258
00:31:20,140 --> 00:31:27,340
Okay. So that's kind of one advantage of using mixed model to kind of automatically at least allows

259
00:31:27,340 --> 00:31:33,190
for some correlative correlation between different observations from the same person.

260
00:31:34,380 --> 00:31:38,140
Okay. Okay. Oh, yeah.

261
00:31:38,140 --> 00:31:44,320
I just thought I'd mention this. I think it's maybe sometimes a criticism of using mixed models.

262
00:31:44,320 --> 00:31:50,620
At least if you're doing mixed models for longitudinal data where you're only using a random intercept.

263
00:31:50,620 --> 00:31:59,300
So a lot of times you see. People you only use are a random intercept.

264
00:31:59,930 --> 00:32:05,690
And so the correlation between any two observations on the same person has this form.

265
00:32:06,760 --> 00:32:11,570
Um, so one thing I would note about this is that this doesn't change over time.

266
00:32:12,380 --> 00:32:19,220
So that might be a criticism since you might think that kind of observations that are far apart in

267
00:32:19,220 --> 00:32:24,590
time have slower correlation and may be observations that are right next to each other in time.

268
00:32:25,490 --> 00:32:34,370
So that's maybe something to keep in mind. If you add a kind of a random slope that that will allow for some change over time.

269
00:32:35,520 --> 00:32:39,040
Okay. So let's see it. Okay.

270
00:32:41,830 --> 00:32:42,310
Okay.

271
00:32:43,240 --> 00:32:53,980
So at least one of the goals of your data analysis, I mean, in many cases you just want to report estimates of the betas and and confidence intervals.

272
00:32:55,060 --> 00:33:02,379
But something else you might want to report is at least try to capture the, you know, the heterogeneity across individuals.

273
00:33:02,380 --> 00:33:09,250
How much does this. How much does the relationship between your lie and exchange across individuals?

274
00:33:11,080 --> 00:33:16,570
So one way is just to look at the estimate of the variance of your random effects.

275
00:33:17,080 --> 00:33:24,220
So when you fit this in LME for you're going to get estimates of the variance of your random effects.

276
00:33:24,910 --> 00:33:31,990
Okay. So if you get an estimate of your variance, that's kind of a lot greater than zero.

277
00:33:34,330 --> 00:33:38,530
Yeah, that's kind of an indication.

278
00:33:38,530 --> 00:33:45,370
There's kind of substantial variability in the regression coefficient kind of corresponding to usage across individuals.

279
00:33:47,620 --> 00:33:55,480
So for example, I mean, I guess you do kind of have to interpret what's substantially greater than zero is, but you can look at.

280
00:33:59,600 --> 00:34:06,940
Guess different tests. But if if you're looking at the sleep study data, for example,

281
00:34:07,630 --> 00:34:13,450
let's say if you fit the same type of model where you have a random slope and random intercept for each person.

282
00:34:15,920 --> 00:34:22,550
So let's say when you fit this, let's say the estimated variance of this is it's kind of big.

283
00:34:22,960 --> 00:34:27,650
I mean, I guess you have to look at the scale of your outcome to determine what's what's big or not.

284
00:34:30,640 --> 00:34:36,670
But the interpretation of kind of a large variance of UI one is basically that the

285
00:34:36,670 --> 00:34:43,270
relationship between the number of days and reaction time varies a lot across individuals.

286
00:34:43,720 --> 00:34:54,910
Okay. So like beta one plus UI one, that, that's like the slope that captures the relationship between reaction time and over time.

287
00:34:55,330 --> 00:35:03,570
So if there's a lot of variability and this kind of suggests that there's a lot of variability in that relationship,

288
00:35:03,580 --> 00:35:12,630
so some people might have a perfectly flat slope and some people might kind of change a lot over time.

289
00:35:12,640 --> 00:35:17,620
So they might have their reaction time increase a lot over time. Okay.

290
00:35:19,650 --> 00:35:25,760
So let's see. And this is quite as important as the other stuff.

291
00:35:29,240 --> 00:35:39,650
These blocks are basically kind of, I would say, her estimates of a response, somebody's response at a particular time or collection of time points.

292
00:35:43,620 --> 00:35:47,640
So that's something else you can do from a linear mixed model maybe.

293
00:35:49,350 --> 00:35:54,570
Yeah. So I think the in your analysis, you may or may not want to do this.

294
00:35:54,960 --> 00:35:58,140
I think if you want to. Yeah.

295
00:35:58,470 --> 00:36:01,020
Yeah. If there's some particular time point or.

296
00:36:03,590 --> 00:36:10,280
Collection of tired points where you want to predict an outcome and see how it varies across individuals.

297
00:36:11,450 --> 00:36:23,180
Sometimes reporting these these blocks is useful, and maybe I'll discuss it later if if there's interest.

298
00:36:24,350 --> 00:36:33,959
Okay. All right. So another thing that you might need to handle depending on your project is basically generalized, linear, mixed models.

299
00:36:33,960 --> 00:36:38,160
That's just. It's very it's the same idea as mixed models.

300
00:36:38,160 --> 00:36:42,990
This is just a modification that allows you to handle non non continuous outcomes.

301
00:36:43,590 --> 00:36:53,160
So I think, you know, basically probably for this class it would the most common things would be if you have a binary outcome or account outcome.

302
00:36:54,650 --> 00:36:59,100
Um, okay. So a generalized linear mixed model allows you to do that.

303
00:37:02,510 --> 00:37:10,220
So basically with a generalized linear, mixed model, it's pretty much the same formulation as a regular linear mixed model.

304
00:37:10,880 --> 00:37:15,980
The only difference is that you're basically assuming that a a generalized.

305
00:37:17,310 --> 00:37:22,290
Linear model holds for conditional on or value of the random effect.

306
00:37:22,300 --> 00:37:33,209
So assuming you kind of know them, the value of the random effects for each person and you write down a generalized linear model for that,

307
00:37:33,210 --> 00:37:36,600
that would be a general wise linear mix them all. So maybe.

308
00:37:38,290 --> 00:37:44,200
Well. I think it will be clear for a break down model.

309
00:37:45,310 --> 00:37:51,880
Okay. So if you're doing binary outcomes, the usual approach is logistic regression, although you could do it,

310
00:37:52,750 --> 00:37:58,510
sort of we could do a different link function, but this is probably the most common one.

311
00:37:58,510 --> 00:38:09,160
So for doing logistic regression without any mixed models or anything, uh, these are the kinds of three key assumptions.

312
00:38:09,170 --> 00:38:12,820
So you usually assume that your outcomes are independent.

313
00:38:13,420 --> 00:38:15,760
Each one follows a formulae distribution,

314
00:38:17,290 --> 00:38:27,400
and then you assume that kind of your log odds parameter it's a log of P over one minus P is a linear combination of the covariance.

315
00:38:27,940 --> 00:38:37,100
Okay. So when you're doing a geo m inversion of this, it's it's pretty much the the same thing.

316
00:38:37,540 --> 00:38:45,370
Well, almost the same thing. I would say the key thing is kind of everything is like conditional on your random effects.

317
00:38:45,640 --> 00:38:48,850
Okay. Okay.

318
00:38:49,450 --> 00:38:56,320
So I guess, yeah. These are the three assumptions in a generalized, linear, mixed model version of.

319
00:38:57,470 --> 00:39:05,570
Uh, logistic regression. So you assume this is that data for one person.

320
00:39:05,690 --> 00:39:10,340
So kind of conditional on that, that your vector of random effects that are independent.

321
00:39:11,410 --> 00:39:16,490
Um, so this is just for one person. And then of course across persons they also assume.

322
00:39:17,550 --> 00:39:24,590
Across individuals. They are also assumed to be independent and then conditional on UI.

323
00:39:24,610 --> 00:39:30,060
You assume that the y i js are Bernoulli with this success probability.

324
00:39:31,070 --> 00:39:37,220
Okay. So they're all Bernoulli, but their success probability depends on the random effects.

325
00:39:37,700 --> 00:39:38,540
That's probably the main.

326
00:39:39,230 --> 00:39:47,510
The main difference between this and a regular logistic regression is that your success probability depends on your vector of random effects.

327
00:39:48,380 --> 00:39:57,720
And then. Basically your long odds parameter is a linear combination of your your covariance and the random effects.

328
00:39:58,230 --> 00:40:05,970
So you're just having kind of this extra Z UI as compared to a regular logistic regression.

329
00:40:06,600 --> 00:40:13,680
Okay. And then as with a linear mixed model, you usually assume that your vector of random effects is multivariate normal.

330
00:40:15,300 --> 00:40:25,500
So that is those are the assumptions about which generalized linear mixed models for for binary outcomes, for account outcomes.

331
00:40:27,940 --> 00:40:33,300
It's sort of similar. Let's say you're doing a plus on regression.

332
00:40:33,900 --> 00:40:42,940
So here. The model is that the Y YJ giving UI or at least their their independent conditionally on UI,

333
00:40:44,140 --> 00:40:49,270
their place on with this mean UI j in the mean depends on the random effects.

334
00:40:49,990 --> 00:40:53,490
Okay. And then you're going to do something similar.

335
00:40:53,520 --> 00:41:02,770
So like log ui j is exi j transpose data plus the ija transposon you.

336
00:41:03,460 --> 00:41:09,130
That's going to be the typical way to model the mean function using a log link.

337
00:41:13,930 --> 00:41:23,560
Okay. Also negative binomial models are also quite common as well, where you have an extra parameter free.

338
00:41:26,570 --> 00:41:33,110
But it's still kind of a similar type of model and where the meaning of your outcome depends on your vector of random effects.

339
00:41:36,220 --> 00:41:43,420
Okay. So for current data, it's typical to model, use a log link basically.

340
00:41:43,420 --> 00:41:54,580
So the log of the main function is kind of has the same type of when you're mixed model form, it's exactly transpose data plus CIJ transpose UI.

341
00:41:59,030 --> 00:42:08,480
So this is what you're assuming if you're doing kind of a per person model with with with random effects.

342
00:42:09,200 --> 00:42:18,629
So I don't think we have. That much time. So I'll probably talk about this a little bit more in a later later class.

343
00:42:18,630 --> 00:42:23,430
Well, at least. Discuss how to get started.

344
00:42:24,450 --> 00:42:33,150
So I say LME four is really still the standard kind of package for fitting when you're mixed models and generalized linear mixed models.

345
00:42:35,140 --> 00:42:43,440
So I don't know if anybody is using Python. I think the. I think there's more than one, but I think this one is fairly popular.

346
00:42:44,060 --> 00:42:47,820
The mixed selling function from from stat models.

347
00:42:48,570 --> 00:42:55,220
So but at least I'm going to go through the details of that before.

348
00:42:55,230 --> 00:43:04,020
So let me for package the sleep study data is kind of comes with that package.

349
00:43:07,860 --> 00:43:17,490
Okay. So she'll go to sleep, study data. So we'll notice that it has 180 observations and three kind of columns.

350
00:43:17,790 --> 00:43:26,969
Okay. So basically what this means, there's 18 individuals in the study and each person has ten observations.

351
00:43:26,970 --> 00:43:34,500
So it basically as a way alamy for works is that when you fit in,

352
00:43:34,500 --> 00:43:42,510
it assumes that the longitudinal data are stored in long format, which basically means that each row has a.

353
00:43:45,920 --> 00:43:50,870
Contains a different observation, different observation at a different time point.

354
00:43:51,320 --> 00:43:54,740
Okay. So in this case, that's 180. There's like.

355
00:43:56,680 --> 00:44:03,050
180. That's basically the number of individuals, times the number of time points that we observe.

356
00:44:03,100 --> 00:44:08,280
So so we have three columns.

357
00:44:08,280 --> 00:44:13,960
So what it stores in the data set is basically the outcome, which is the reaction time.

358
00:44:14,740 --> 00:44:18,340
And then for each person that gives you the day at which that was recorded.

359
00:44:18,340 --> 00:44:21,850
And then there's also a subject identifier. Okay.

360
00:44:22,300 --> 00:44:26,590
So there should be ten unique values for this subject identifier.

361
00:44:28,720 --> 00:44:36,460
So that's the way it's stored. Yeah, that's just what I said. So kind of if you're using LME for.

362
00:44:38,540 --> 00:44:45,290
The. Your data should be in long form, at least before you run any of the functions that do any estimation.

363
00:44:46,880 --> 00:44:55,190
Okay. So the Elmer or Ellen Miller function is kind of the main function that fits linear or mixed models.

364
00:44:57,580 --> 00:45:07,440
So the kind of the syntax is has a lot of the same features as the main L and function for fitting linear models and R, I mean,

365
00:45:07,450 --> 00:45:17,230
there's some extra features that kinda the way it's set up is to look a lot, look much like the l m function, you know.

366
00:45:17,500 --> 00:45:22,360
Okay. So the main thing you have to worry about when you're fitting in.

367
00:45:22,360 --> 00:45:29,799
L am with me and tell me our function is basically that you just kind of specify

368
00:45:29,800 --> 00:45:35,680
the x part of your model correctly and the z part of your your model correctly.

369
00:45:38,330 --> 00:45:44,510
So the way you do your ex part of your model is basically just using the same kind of syntax that you used.

370
00:45:44,750 --> 00:45:56,360
Do it now. So in function so you have your outcome is tilde times usually a covariance, the name of a covariate plus some other covariate, etc.

371
00:45:57,080 --> 00:46:03,350
And then the, the other main part is the, is the Z part.

372
00:46:04,130 --> 00:46:14,390
So the way this is done is actually the, the, the formula notations kind of similar, but you just have to make sure.

373
00:46:15,910 --> 00:46:20,470
You kind of understand what this grouping variable is so that a grouping variable.

374
00:46:22,320 --> 00:46:29,130
Really for this class, it's going to be the variable that gives you the stuff that identifies each individual.

375
00:46:29,160 --> 00:46:34,020
So in this case, it would be subject, it's based.

376
00:46:34,030 --> 00:46:41,590
So you have to. So if you were doing this for the sleep study data, you would put the name of the variable subject here.

377
00:46:41,980 --> 00:46:46,690
And the formula is just the. But when you're.

378
00:46:50,040 --> 00:46:54,549
I guess the linear model that you want to apply within each group or at least

379
00:46:54,550 --> 00:46:59,460
the the random effects on your model that you want to apply to each group.

380
00:47:00,300 --> 00:47:06,300
That's kind of the interpretation here. So that's kind of just the key.

381
00:47:06,450 --> 00:47:15,090
If you haven't done it before, I think that's the key thing to to get used to is specifying the correct formula by group.

382
00:47:15,390 --> 00:47:19,980
Okay. And then for a for this class, the grouping very well.

383
00:47:20,160 --> 00:47:23,430
Me it's going to be the, the variable that identifies each person.

384
00:47:24,980 --> 00:47:28,800
Okay. Maybe we'll just stop it since we're. We're. No.

385
00:47:28,810 --> 00:47:39,690
At times they finish most of it. But I just I probably just to a later class all I do is walk through the some at least how to use help me for.

386
00:47:41,570 --> 00:47:46,370
So I'll send you quick things just very briefly.

387
00:47:46,370 --> 00:47:51,130
One is. So I went through and uploaded most of your information.

388
00:47:51,140 --> 00:47:55,010
I think there were three people. My computer decided to update while I was doing it.

389
00:47:55,200 --> 00:48:02,950
33 people who I assume they finished second and here's, but they need to upload it to canvas.

390
00:48:02,960 --> 00:48:04,970
So there's three people just double checked check.

391
00:48:04,970 --> 00:48:12,620
I can email those people once my computer updates, but just double check that you've uploaded the peers and the happen to canvas.

392
00:48:13,070 --> 00:48:17,209
Once that's done, I've already put it in the Google drive and you know, precision health.

393
00:48:17,210 --> 00:48:23,890
So that's it. And again, then on Thursday, we'll talk about how to use Great Lakes.

394
00:48:23,900 --> 00:48:30,950
So in terms of set up on your end, all I would look at is just there's a website for Great Lakes computing.

395
00:48:30,950 --> 00:48:38,120
If you want to just take a tutorial videos, if you want to take a look just to kind of get acclimated to that, that might be helpful.

396
00:48:38,510 --> 00:48:41,960
Otherwise, that's Thursday.

397
00:48:42,890 --> 00:48:49,129
Yep. There we go. Next week will be all about getting you access, getting you acclimated to the data set,

398
00:48:49,130 --> 00:48:55,100
and then going over maybe this a little bit more than is just trying to give you the basic tools to analyze the data.

399
00:48:55,610 --> 00:49:02,120
And then the following week is when Amy and Siri can visit on the following Thursday,

400
00:49:02,660 --> 00:49:08,209
and the goal will be that they'll present for part of it and then answer any questions you have about the data or questions you might have.

401
00:49:08,210 --> 00:49:14,870
So my main point is next week is really about you guys getting into the data set, starting to think about the question you want to ask.

402
00:49:15,350 --> 00:49:21,320
And that way when they come and visit on the following Thursday, you will have some actual questions about okay.

