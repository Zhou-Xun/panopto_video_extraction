1
00:00:04,100 --> 00:00:09,310
It's okay.

2
00:00:12,570 --> 00:00:18,360
It's all right. I don't wanna hear the topic of the semester.

3
00:00:19,390 --> 00:00:28,530
By the way, it's probably a good use of the semester that I haven't been with you.

4
00:00:28,740 --> 00:00:33,240
Well, I'm also quite nervous toward the end of the semester.

5
00:00:33,480 --> 00:00:37,530
I talked to the New York Times. They couldn't let me finish on the lecture.

6
00:00:37,950 --> 00:00:41,550
Finally, I hear the last topic of the semester.

7
00:00:42,210 --> 00:00:45,240
Hopefully I'll still be able to make it on Thursday.

8
00:00:46,440 --> 00:00:50,669
But just in case that I missed the class on Thursday,

9
00:00:50,670 --> 00:01:00,570
just want to say it has been a great semester of teaching and also it's a lot of pleasure, you know, to finally be able to teach in person.

10
00:01:00,810 --> 00:01:09,540
I hope you also learn something useful from the class. And in terms of the final, again, a couple things to remind you.

11
00:01:10,350 --> 00:01:16,920
The final will be on December the 15th. Right. So it's going to be from 1030 to 12, 32 hours.

12
00:01:17,520 --> 00:01:26,370
The format is going to be very similar to the midterm, except that it will provide the distribution table to.

13
00:01:27,240 --> 00:01:30,299
But you have closed both closed now.

14
00:01:30,300 --> 00:01:36,060
It's going to be comprehensive, but the first that's going to be on the second half of the semester.

15
00:01:36,360 --> 00:01:49,470
So we already how the study guide on campus so you can take a look if you haven't also passed the last year's final exam as the practice example.

16
00:01:50,280 --> 00:01:54,240
Later on we will post the solutions, but so far it's just the questions.

17
00:01:54,450 --> 00:02:02,850
So you can take that as a practice, although, you know, it's no guarantee that the questions will be similar or whatsoever.

18
00:02:03,120 --> 00:02:06,810
But at least they give you some sense of what the final is going to be like.

19
00:02:08,040 --> 00:02:14,009
Right. So can time yourself work on those problems that say whether I have a go ahead

20
00:02:14,010 --> 00:02:19,530
on the study guide also contains some information about what you should,

21
00:02:19,920 --> 00:02:29,909
you know, focus on what are the most important things that you can you'll learn from the semester and how to prepare

22
00:02:29,910 --> 00:02:35,790
for the final text and make sure that I come to the office hours if you have any questions and homework.

23
00:02:35,790 --> 00:02:44,550
12 is going to be a practice as well with one class, so we will post the solutions later on for homework,

24
00:02:44,950 --> 00:02:49,590
but I encourage you to work on those problems without the vocabulary.

25
00:02:51,090 --> 00:03:01,229
So a very useful exercise, especially given that we don't have, you know, homework questions required on this part of the lecture.

26
00:03:01,230 --> 00:03:10,040
But it's definitely a very important topic for the final exam.

27
00:03:10,050 --> 00:03:13,640
Closed book closed. No real calculator. Yeah.

28
00:03:13,740 --> 00:03:17,940
You got to provide that distribution table, right. Any questions?

29
00:03:22,370 --> 00:03:26,600
So let's look at the last topic of the semester. Nicole Recall.

30
00:03:26,610 --> 00:03:34,819
What do I have to talk about in the past couple of years after talking about this random samples we particularly

31
00:03:34,820 --> 00:03:43,070
focus on this sample mean right and introduce the first important theorem which is called the law of class number.

32
00:03:43,460 --> 00:03:48,020
Are we strong law class number one, the law of large number.

33
00:03:49,190 --> 00:03:51,920
We say that the sample means, you know,

34
00:03:51,930 --> 00:04:04,160
divided times party will converge in distribution in probability to the population it as far as the random sample from certain distributions.

35
00:04:05,030 --> 00:04:08,780
Finally, find out about some irregularity examinations.

36
00:04:09,050 --> 00:04:14,230
We always have this convergence in probability. Which is sort of intuitive, right?

37
00:04:14,620 --> 00:04:20,050
If you had a bunch of samples taken on average, that should converge to the population.

38
00:04:20,810 --> 00:04:31,680
So that's what the last number tells us. And later on, we talk about the central limit there, which is one step farther from this large number.

39
00:04:33,550 --> 00:04:40,629
But sometimes we are interested not only in what this single number, this sample average converts to,

40
00:04:40,630 --> 00:04:46,510
but also we want to get a sense of the distribution so that in order to get the distribution,

41
00:04:46,510 --> 00:04:53,290
we need to use some common sense to magnify this as far because without that magnifier,

42
00:04:53,620 --> 00:04:59,110
these apps are going to converge to a degenerate distribution because a single data point, right?

43
00:04:59,650 --> 00:05:14,390
So the magic scaling parameter is this a square root of N and with square root of an and we know square and times are minus a population minimal.

44
00:05:14,880 --> 00:05:32,440
What a converge in distribution to a normal distribution with variance being squared right here x one and by the name you and Baron Sigma Square.

45
00:05:33,040 --> 00:05:40,179
And we do not require you to control that distributional assumption that lines their

46
00:05:40,180 --> 00:05:45,730
idea with mean you very well always have is that small part number and control limit.

47
00:05:46,780 --> 00:05:54,490
Again the central limit there on tells us something about the limit in distribution for this simple right so that's the take away from

48
00:05:54,610 --> 00:06:06,340
three is that so with those two important theorems one national possible to ask next is what about transformation of this x bar?

49
00:06:06,970 --> 00:06:08,080
Because in practice,

50
00:06:09,820 --> 00:06:17,560
more often than not we are not only interested in this that is limiting distribution of expr but rather some function of exponent.

51
00:06:18,700 --> 00:06:26,860
So what is my main focus? Let's say I have a particular function G that applied to this x bar.

52
00:06:27,100 --> 00:06:31,120
What I if I want to get a sense of the limit and distribution of this g of x bar.

53
00:06:33,710 --> 00:06:37,280
So for simplicity, not to assume this G function is continuous.

54
00:06:38,000 --> 00:06:40,280
All right. It's a continuous one. That is the regular function.

55
00:06:40,790 --> 00:06:47,370
So from the old last number or from the large number and the continuous Malcolm Theorem, what do we know about this?

56
00:06:47,690 --> 00:06:50,719
That's us as NGOs.

57
00:06:50,720 --> 00:06:54,220
They invented a this guy would have converged right? In probability.

58
00:06:54,230 --> 00:07:00,650
To what? If you have milk, that's a direct result from the continuous matter.

59
00:07:01,460 --> 00:07:05,290
But what if we want to get the limited distribution of this price pass?

60
00:07:06,090 --> 00:07:09,410
Well, now we need time.

61
00:07:10,230 --> 00:07:24,680
And so today we're going to focus on the Delta method and take a look at what is this guy going to convert to Jehovah expr minus g of meal times.

62
00:07:24,860 --> 00:07:28,580
This magic number screwed up and what converts to distribution.

63
00:07:29,150 --> 00:07:31,730
So that's what the Delta method accounts.

64
00:07:34,580 --> 00:07:44,090
So before introducing the downtime method, there are a couple of prerequisite theorems that we have to take a look at.

65
00:07:45,200 --> 00:07:49,370
So the Delta method is for the same topic distribution of some function of the random variable.

66
00:07:49,820 --> 00:07:57,230
So for some function or any function g acts that has derivative of our r,

67
00:07:57,530 --> 00:08:04,920
we denotes this g superscript parentheses r as the RS derivative of this function.

68
00:08:05,480 --> 00:08:12,860
Then we always have this teeter expansion. So this is something that you probably have learned from the calculus class.

69
00:08:13,130 --> 00:08:20,960
You can always expand the function at a given constant and approximate a function using a polynomial function.

70
00:08:21,530 --> 00:08:29,359
So that's what the Territory expansion is about. And particularly you can approximate this g function,

71
00:08:29,360 --> 00:08:40,010
this g of X using these are our our territory expansion or our order polynomial function which takes this particular form.

72
00:08:40,310 --> 00:08:49,400
It's a summation I from zero to R and the constant is g to the derivative of g i's derivative

73
00:08:49,400 --> 00:08:57,920
of g value that's constant divided by factorial times x minus eight to the power of an x.

74
00:08:58,640 --> 00:09:01,910
So this a is a point where we want to.

75
00:09:04,360 --> 00:09:11,700
Expand this function. By other words, you can consider the first order.

76
00:09:11,710 --> 00:09:22,360
Taylor Expansion objects. It's just this function so g as is equal to g a which is the zero outer derivative of G, right?

77
00:09:23,680 --> 00:09:31,480
Plus the first order of g function. If I'm at this 8.3 times x minus eight plus the remainder term.

78
00:09:32,080 --> 00:09:35,710
So what that means is if you have a function that looks like this.

79
00:09:36,130 --> 00:09:40,450
So this is our Jay function. And this is your point.

80
00:09:41,050 --> 00:09:45,400
So this is the x axis, y axis.

81
00:09:46,000 --> 00:09:53,290
So if you want to approximate the function at this particular point and actually for a you can use a linear approximation,

82
00:09:53,620 --> 00:09:59,050
that's going to be the tangent line. The tenderloin of this of this function.

83
00:09:59,560 --> 00:10:07,720
And the mathematical expression of that tangent is exactly making this form g of a plus

84
00:10:08,230 --> 00:10:16,060
g primate first order of g f over eight times X minus eight last time a remainder term.

85
00:10:17,360 --> 00:10:22,420
Right. So these is the first order theta expansion of this function.

86
00:10:24,800 --> 00:10:29,660
And if you apply if you plug in a on both sides of the equation,

87
00:10:29,660 --> 00:10:36,350
you will see that the log on side is going to be exactly equal to the right hand side because the higher order time going to go away,

88
00:10:38,240 --> 00:10:44,540
the higher order term always have this X minus eight. So it actually is it is equal to all of this.

89
00:10:44,540 --> 00:10:50,569
X minus eight is equal to zero. So the higher order way on the right hand side, both equality.

90
00:10:50,570 --> 00:10:57,290
Okay, so which means this is indeed a tangent line is touching that original function.

91
00:10:57,950 --> 00:11:05,590
Okay. And also if you take the first order derivative on both side of the equation, you will see that both sides are equal to a g prime a.

92
00:11:07,410 --> 00:11:15,710
The other was at this point the slope of this tangent lot and the derivative of this chance function is equal.

93
00:11:16,070 --> 00:11:25,430
So that's why it's a first order approximation. Similarly extended time of the second order expansion, which is addition to what you have.

94
00:11:25,430 --> 00:11:31,040
For the first order of a first order approximation, you have this additional second order term,

95
00:11:31,700 --> 00:11:36,950
one over two G double prime to the second order derivative.

96
00:11:37,220 --> 00:11:44,300
You got about eight times x minus a square. So what that means you have a classic function.

97
00:11:47,240 --> 00:11:55,910
And it's touching this function. And so this the bass line is a quadratic function that touched the original function

98
00:11:56,210 --> 00:12:00,530
with equal first order and second order derivative at that particular point.

99
00:12:01,730 --> 00:12:05,340
So that's the second Outer Taylor expansion of the X function.

100
00:12:06,200 --> 00:12:10,800
Again, you have this Romanow term to make sure I capture all the discrepancies.

101
00:12:10,820 --> 00:12:13,960
Beyonce I see quite simple.

102
00:12:14,120 --> 00:12:19,940
I can think about a higher order expression. But the general formula for the tenor, it's like this.

103
00:12:20,480 --> 00:12:28,219
That's the summation from zero to r g to different order of repeating different order of derivative

104
00:12:28,220 --> 00:12:36,550
of this g function value at eight divided by three times this is order polynomial times.

105
00:12:37,130 --> 00:12:42,020
The power of the same expression is not familiar to you.

106
00:12:42,660 --> 00:12:46,640
And take a look at your previous lecture notes from Calculus.

107
00:12:47,090 --> 00:12:53,710
So just remind yourself that our expansion and also some or some commonly used functions.

108
00:12:53,720 --> 00:13:00,050
Yes, we do expect you to know, you know, the the expansion.

109
00:13:01,790 --> 00:13:07,490
So like, for example, the exponential function, exponential to the power of X,

110
00:13:07,940 --> 00:13:14,209
what is that expansion at a given time, at a given point or a log function?

111
00:13:14,210 --> 00:13:17,810
What is that expansion that I came upon and so on, so forth.

112
00:13:18,090 --> 00:13:23,120
And so the expansion is a approximation.

113
00:13:23,270 --> 00:13:34,640
Approximation of the original function as X approaching a base function will be the stellar expansion of this high,

114
00:13:34,730 --> 00:13:39,200
high order polynomial function, and I'd be approximating the original function.

115
00:13:40,100 --> 00:13:44,930
So that's the nice property of the expansion. More specifically,

116
00:13:45,200 --> 00:13:58,490
we have this Taylor Theorem saying that if we didn't know this t r a at the our order derivative of this j function evaluated as equal,

117
00:13:59,090 --> 00:14:03,410
then we always have this limiting result.

118
00:14:04,220 --> 00:14:12,320
That is, if the ax goes to a the difference between the original function and this result are

119
00:14:12,320 --> 00:14:19,280
ten expansions divided by x minus eight to the power of R will be equal to zero.

120
00:14:22,050 --> 00:14:26,090
Right. So that's what the Taylor Theorem tells us.

121
00:14:26,480 --> 00:14:31,790
So what that means is that these two functions, this original function and the Taylor expansion,

122
00:14:32,210 --> 00:14:45,000
its hours order on a normal will be very close to one another and it will be close to one another in a very high order, higher than the hours.

123
00:14:46,880 --> 00:14:50,450
And so you're talking about a first order, Taylor expansion.

124
00:14:50,870 --> 00:14:59,030
Then these two function well approaching one another faster than X minus a approaching zero.

125
00:15:00,620 --> 00:15:05,870
That's what the Taylor expansion tells us. And it works for any ah, any order.

126
00:15:08,810 --> 00:15:19,340
We want to prove this theorem here in this class, but we're going to use this results to prove our Delta method.

127
00:15:25,480 --> 00:15:32,530
Any questions about the territory? I can assume this is something that you have said before.

128
00:15:33,010 --> 00:15:36,010
So this is just a review of what you already know.

129
00:15:36,440 --> 00:15:40,120
Okay, so that's the Twitter theorem.

130
00:15:40,930 --> 00:15:46,470
Basically, the bottom line is, for any function, any recall, they behave the function.

131
00:15:46,480 --> 00:15:51,430
You can always use a polynomial to approximate that function very well.

132
00:15:51,800 --> 00:15:54,370
Okay. So that's what the data theorem tells us.

133
00:15:56,650 --> 00:16:04,780
So the next theorem that we are going to need to prepare for the delta method is called the mean value theorem.

134
00:16:06,010 --> 00:16:10,210
So the minimum theorem is states as follows.

135
00:16:13,000 --> 00:16:21,100
So if G prime, the first auto derivative of this g function exists between two points and x,

136
00:16:21,580 --> 00:16:32,050
then we can always x plus x using this linear approximation where a star is some value between an x.

137
00:16:32,380 --> 00:16:38,550
So what that means is, first of all, if g prime exist, what do we know about the x?

138
00:16:41,950 --> 00:16:48,880
If the derivative of a function exists between two points, what do we know about the function as a container as it is contains?

139
00:16:48,970 --> 00:16:54,250
Right. And what else do I know? It's not right.

140
00:16:54,490 --> 00:16:59,280
It's just. All we know is that it's okay. Actually, that's the beauty of this.

141
00:16:59,290 --> 00:17:04,360
I mean, by a theorem, it has a very few conditions.

142
00:17:04,900 --> 00:17:13,510
The only conditions for it to hold is we have a continuous function that has the derivative first order derivative between two points.

143
00:17:14,140 --> 00:17:18,820
As long as we have a function that has a continuous first order derivative.

144
00:17:19,200 --> 00:17:31,840
They always say this is you are a point at point and consider any function that is continuous between these two points.

145
00:17:32,290 --> 00:17:43,150
Okay. So this is our key x function. So what this function means is this jacks value can always be.

146
00:17:48,010 --> 00:18:00,160
It's always equal to the g a plus this quantity times the difference between acts on a piano words.

147
00:18:00,520 --> 00:18:03,770
This guy is g one.

148
00:18:03,910 --> 00:18:10,210
A star is equal to the slope of this bass line that conducting this to dance.

149
00:18:12,070 --> 00:18:21,340
In other words, what this meme body theorem says is that there always exist a star such that the derivative of the

150
00:18:21,340 --> 00:18:28,300
function at a star is equal to the derivative of this line that connecting the two adults to adults.

151
00:18:29,740 --> 00:18:39,190
So conceptually, what that means is if you shift that, if you move that that line, that connecting the two end points up and down,

152
00:18:39,190 --> 00:18:48,010
you will always be able to find a point between an X such that that line becomes a tangent line of this function.

153
00:18:50,080 --> 00:19:03,129
Right? So for example, you can move the line in parallel and it would be about the same at a certain point and would touch the original

154
00:19:03,130 --> 00:19:12,340
function such that a derivative of that function at that point is equal to the slope of that parallel line.

155
00:19:13,000 --> 00:19:19,809
If that's the case, then there's zero. And for any continuous function that would always help see other words.

156
00:19:19,810 --> 00:19:22,690
For any continuous function, you can always do with that practice.

157
00:19:22,990 --> 00:19:30,730
It can always move that line up and down to find a point where that line becomes a tangent line by the original function.

158
00:19:31,450 --> 00:19:41,650
So that's what you mean by that tells us. So this is the slope.

159
00:19:41,980 --> 00:19:45,550
It's g prime and stock.

160
00:19:46,480 --> 00:19:57,020
But this one is. And if you find it a point, most derivative is equal to the slope of this this line that nothing.

161
00:19:57,110 --> 00:20:02,050
And then, of course, this equation won't hold.

162
00:20:02,570 --> 00:20:06,730
Right? The g x would always be equal to the g eight plus that slope.

163
00:20:07,360 --> 00:20:11,620
Multiply the the distance between that snake.

164
00:20:12,580 --> 00:20:19,150
Yes, I'm sorry, but this is a starting XI that I am sorry if I miss this, but is a star unique?

165
00:20:19,960 --> 00:20:22,960
Is star is what? Is it unique or can there be multiple?

166
00:20:23,080 --> 00:20:30,340
A star can be multiple. So all of us are not all of that said, but this theorem is that many exist such a star.

167
00:20:30,630 --> 00:20:36,640
It doesn't require it to be unique. Like in this example, I would say there are two such a stars.

168
00:20:36,940 --> 00:20:43,420
If you move this line down, you find another point or the tangent.

169
00:20:45,920 --> 00:20:53,570
So that's putting our prime at another eight star such that it satisfies this equation.

170
00:20:54,380 --> 00:21:02,980
It doesn't have to be unique. And again, as I said, Your Honor, for the mean by the theorem to hold,

171
00:21:03,220 --> 00:21:09,100
all we need is the function is continuous and has first order to remedy this animal.

172
00:21:09,670 --> 00:21:19,629
As long as that hold, we always have this tradition. You can always find such a point, at least one such point where the derivative multiplied.

173
00:21:19,630 --> 00:21:24,190
But this that adds a plus to its ecology x.

174
00:21:26,100 --> 00:21:30,200
Right. Hopefully this figure gives you a sense of why that's the case.

175
00:21:30,650 --> 00:21:36,200
You always move this along up and down to find a place where this line has the original function.

176
00:21:36,830 --> 00:21:40,280
And that touching point is going to be you are a star.

177
00:21:40,340 --> 00:21:47,120
That's important. Touching point. Going to be your star. And the slope at that point is g primate star.

178
00:21:50,450 --> 00:22:02,220
So that's the Miyamoto Theorem. So basically those two theories, literary expansion and the M.A. Theorem, we're ready to prove that Delta method.

179
00:22:03,150 --> 00:22:13,770
And here is the formal statement of the Delta method, like, why be a sequence of random marvels that satisfy these convergence?

180
00:22:14,400 --> 00:22:26,340
All right. And so far, the most common Y and that satisfy this particular convergence is the sample mean.

181
00:22:26,610 --> 00:22:34,410
Right. So from the central limit there and we know that if y n is the sample mean of some random samples,

182
00:22:34,860 --> 00:22:38,880
then we can always have this convergence of this type.

183
00:22:40,170 --> 00:22:47,249
If when the sample mean, then we know the sample mean minus the population mean multiply the square root of n going to

184
00:22:47,250 --> 00:22:52,470
converge and distribution to a normal with mean zero balance being the population variance.

185
00:22:53,160 --> 00:22:59,489
So that's what we know. But it also applies to other sequences.

186
00:22:59,490 --> 00:23:05,790
If you have another sequence, not necessarily sample mean, but some other statistic that also satisfy this.

187
00:23:06,780 --> 00:23:12,660
We can always we can also apply the Delta another. So all we require is we have a sequence of event available.

188
00:23:12,960 --> 00:23:22,980
Satisfy this convergence done for any function g which satisfy the following first.

189
00:23:26,430 --> 00:23:29,580
The first order derivatives exist and it continues.

190
00:23:30,550 --> 00:23:37,410
Okay. So first, at this time, continuous and second the first order derivative.

191
00:23:38,280 --> 00:23:41,640
A value or not, this theta is not equal to zero.

192
00:23:41,970 --> 00:23:47,010
So this theta is this data in the central limit theorem.

193
00:23:47,010 --> 00:23:56,490
This is the population mean. If the g prime the value of theta is not zero, then we always have the following result.

194
00:23:58,500 --> 00:24:01,590
That's why we why we want the square root of end times.

195
00:24:01,890 --> 00:24:09,480
This function applied to the sequence minus the same function applying to this step theta would always converge.

196
00:24:09,480 --> 00:24:15,360
We'd also converge in distribution to a normal. Now it's a normal with a slightly different balance.

197
00:24:15,660 --> 00:24:21,180
The virus has this particular form that is our original Sigma Square Times,

198
00:24:21,510 --> 00:24:28,230
the first order derivative of theta, the first order derivative of g evaluated theta squared.

199
00:24:29,790 --> 00:24:33,600
So that's called the delta method, right?

200
00:24:33,840 --> 00:24:49,860
So that's the Delta method. So in this theorem, a couple of important points that I want to emphasize before we move on to talk about the proofs.

201
00:24:50,220 --> 00:24:54,990
First of all, take a look at the conditions for this Delta method.

202
00:25:03,800 --> 00:25:08,600
So the first condition we need to have a convergence, a square root of and time,

203
00:25:08,660 --> 00:25:14,480
some sequence of random variables has this kind of convergence in distribution to a normal distribution.

204
00:25:14,960 --> 00:25:19,160
So that's the first requirement. All right. Second requirement.

205
00:25:19,460 --> 00:25:23,180
We need a function. We need a function to have first order derivative.

206
00:25:25,040 --> 00:25:29,630
And third, we need the first order of derivative to be continuous.

207
00:25:32,120 --> 00:25:38,360
And fourth, we need to force out a derivative at theta not to be equal to zero.

208
00:25:40,010 --> 00:25:42,499
So we need four conditions with this.

209
00:25:42,500 --> 00:25:51,140
Four conditions we always have the following conclusion, and we always have the following convergence and distribution for Geo Wire.

210
00:25:54,290 --> 00:26:03,080
Later on, we will say why we need such poor conditions. Every single one of these conditions matters, and in particular the number three,

211
00:26:03,320 --> 00:26:09,770
the g one is continuous, is stronger than saying g is continuous right g.

212
00:26:09,770 --> 00:26:18,680
Why exist already implies g is continuous. So in addition to that, we also require the first on a derivative also to be continuous.

213
00:26:19,400 --> 00:26:27,050
I'll see in a second line uppercase. Okay. But for now, keep in mind that we need these four conditions in order to derive this Delta method.

214
00:26:29,090 --> 00:26:32,090
Any question so far? Yes.

215
00:26:32,540 --> 00:26:41,570
So for this, the continuity and differential utility only need to hold on the domain that the Y and B or on anything.

216
00:26:42,200 --> 00:26:48,290
Very good question. So for these conditions, we need them to code for the support of Lion.

217
00:26:50,240 --> 00:27:00,410
Okay. So we need them for the entire support of Lion, not then there are different versions of this delta method.

218
00:27:00,440 --> 00:27:08,210
I can relax one condition or the other like we have what we have sent in the last number and the central limit theorem.

219
00:27:08,480 --> 00:27:16,410
But the most standard delta method require these to hold for the entire support to go board.

220
00:27:16,460 --> 00:27:27,210
And a couple of complications. And for all of the questions that you are being asked, know will either be,

221
00:27:27,630 --> 00:27:34,110
you know, the conditions will either hold for all the support or none of it.

222
00:27:34,800 --> 00:27:44,220
Do you want to ask the tricky question of whether when the conditions are met for some of the support, but not all?

223
00:27:44,250 --> 00:27:47,550
So you won't be testing out those type of tricky questions,

224
00:27:48,120 --> 00:27:56,810
but there could be different results of those conditions depending on what additional conditions you have, on options on the questions.

225
00:27:58,920 --> 00:28:07,380
All right. So now let's take a look at the proof. Actually, we have all the preparation that we will need to prove this result.

226
00:28:09,480 --> 00:28:16,230
And I wanted you to take a shot on this proof by breaking it down into different steps.

227
00:28:16,590 --> 00:28:23,460
So first step is try to prove that y and converged improbability to theta.

228
00:28:24,400 --> 00:28:28,200
Okay. So based on these conditions first.

229
00:28:29,970 --> 00:28:33,540
So why uncovers improbability to thing?

230
00:28:34,860 --> 00:28:38,130
So take a couple minutes and see whether it can progress.

231
00:28:40,490 --> 00:28:50,640
And this one, two, three and four. All the conditions these conditions try to prove why uncovers probabilities to be.

232
00:31:41,960 --> 00:31:50,340
You. Show me your hand if you've got it.

233
00:32:02,030 --> 00:32:07,370
Think about the theorems that we have learned about convergence.

234
00:32:08,450 --> 00:33:04,240
Which one can you take advantage of in this case? Got it.

235
00:33:06,740 --> 00:33:14,149
I mean, I didn't get it. All right.

236
00:33:14,150 --> 00:33:17,240
So let's look at this together. Maybe you are overthinking in this case.

237
00:33:18,050 --> 00:33:23,750
So the goal here is to show that Y uncovers improbability for theta.

238
00:33:24,350 --> 00:33:30,650
First of all, this is that they generate convergence, right? This converging to a single number.

239
00:33:32,240 --> 00:33:45,620
So looking at this conditions, then we have to three and four does not apply because we don't even need that transformation at this function yet.

240
00:33:46,120 --> 00:33:52,790
Right. We don't care about this function to prove this wire converts to P, so all we need is collision one.

241
00:33:53,870 --> 00:34:03,770
So what a condition one tells us is that if a magnify this y and minus theta by this square root of n, then we have a convergence to a distribution.

242
00:34:05,240 --> 00:34:07,640
Recall that when we talk about the central limit theorem,

243
00:34:07,940 --> 00:34:13,459
the only reason that I want to use this additional magnifier is because the original Y in the

244
00:34:13,460 --> 00:34:21,050
original sample mean converge to the number two quickly so it becomes a degenerated convergence.

245
00:34:22,850 --> 00:34:27,020
So then we need a magnifier to slow down that convergence.

246
00:34:27,800 --> 00:34:31,880
To give us a distribution. Right here is exactly the opposite.

247
00:34:32,810 --> 00:34:37,370
What do we know from the condition is that with this magnifier, it converts for distribution.

248
00:34:37,670 --> 00:34:44,300
What do we want to show is that this Y and without this magnify converge to the theta two to this single number.

249
00:34:44,990 --> 00:34:51,710
So is exactly in the reverse process. So you want it to show Y on converge improper going to theta.

250
00:34:52,730 --> 00:34:56,300
We can start from this convergence in distribution.

251
00:35:01,590 --> 00:35:09,210
So this is what we know, right? So we can work on this Magnifier Square root of event.

252
00:35:10,050 --> 00:35:13,530
We know that as angles to Infinity Square, one of them will explode.

253
00:35:13,740 --> 00:35:22,680
Right. Well, go to infinity. Then what about a one over square root of it all converts to zero, right?

254
00:35:25,370 --> 00:35:32,210
And that convergence is also a convergence, interoperability or convergence on maturity, of convergence in distribution, whatever we call it,

255
00:35:32,600 --> 00:35:41,600
because it's just that you generate a sequence of the general rhinovirus to another degenerate rhinovirus, all the employed mass.

256
00:35:42,030 --> 00:35:54,050
And so this is a convergence. Now we know then with these two result, but theorems surely apply to God, the convergence of a wire.

257
00:35:54,710 --> 00:36:01,720
How do we cancel out this magnifier, this continuous mapping group?

258
00:36:02,030 --> 00:36:05,590
Continuous, maybe for more years.

259
00:36:06,740 --> 00:36:12,490
If you multiply them together, what it is, it's not ask, is there?

260
00:36:12,900 --> 00:36:17,780
All right. So continuous mapping means you apply some continuous transformation.

261
00:36:18,690 --> 00:36:22,910
But here you are doing the multiplication. So you get to the point. You've got a point, correct?

262
00:36:23,270 --> 00:36:26,390
For the name. It's a name. It's classic. It's there.

263
00:36:26,900 --> 00:36:30,740
Right. So in the first case, we exactly have this set up.

264
00:36:31,100 --> 00:36:35,780
If you have one convergence institution, another convergence in probability,

265
00:36:36,110 --> 00:36:42,170
if you multiply the two sequences, then you still have a convergence in distribution.

266
00:36:43,610 --> 00:36:55,060
So by last case. My classic theorem.

267
00:36:55,330 --> 00:37:04,120
What do we know is that if we multiply these two sequences so one over square root of n times, the square root of Y,

268
00:37:04,120 --> 00:37:13,300
a minus theta that will also convert in distribution right to the product of this to limiting distribution.

269
00:37:13,540 --> 00:37:15,820
So what is the product of this two limiting distribution?

270
00:37:18,070 --> 00:37:25,900
What is the normal they are they generate what's the product zero zero multiply anything zero.

271
00:37:26,420 --> 00:37:29,710
And if you multiply this to eliminate distribution, that's also zero.

272
00:37:30,280 --> 00:37:37,180
So what that tells us is that y and my theta in conversion distribution to zero.

273
00:37:39,670 --> 00:37:42,760
So you say the connection.

274
00:37:42,790 --> 00:37:46,690
So now you have y and minus theta converging distribution to zero.

275
00:37:47,080 --> 00:37:59,409
What you want is y and convert in probability theta and that we can rely on the fact that convergence

276
00:37:59,410 --> 00:38:05,620
and distribution to a degenerate distribution is equivalent to say convergence probability.

277
00:38:06,250 --> 00:38:11,830
So that is that is y and minus theta convergence in probability to zero.

278
00:38:12,100 --> 00:38:16,210
And which is why a converge improbability to theta.

279
00:38:17,950 --> 00:38:24,910
Okay. So that way we got this a first result that we need for the subsequent proof.

280
00:38:26,350 --> 00:38:31,000
So again, as proof is the reverse process for the central limit theorem.

281
00:38:32,170 --> 00:38:40,600
Instead of focusing on this limiting distribution, we are interested in getting a limit in value for this sequence of random barrels.

282
00:38:41,380 --> 00:38:50,440
I was studying the way is this concept, this magnifier, but this is a simpler case than the central limit theorem because the magnifier is closed.

283
00:38:50,440 --> 00:38:57,370
So what? Over the magnifier are going to shrink to zero. Then we can directly apply this classic theorem to go to what we want.

284
00:38:57,670 --> 00:39:01,210
The point convergence for this step. Y anything else?

285
00:39:01,580 --> 00:39:07,870
Yes. How come we have to say that it converges in probability instead of in distribution?

286
00:39:08,330 --> 00:39:16,180
And so, if you recall convergence, improbability implies a convergence distribution, right?

287
00:39:16,570 --> 00:39:23,140
That's the general result. The only exception is when you are limiting distribution is to generate.

288
00:39:23,440 --> 00:39:29,440
Then this to becomes equivalent. Now recall that conclusion.

289
00:39:29,860 --> 00:39:32,260
So far, limited distribution is just a number.

290
00:39:32,680 --> 00:39:39,220
If it's degenerate, then it's the same thing for convergence and distribution on convergence in probability.

291
00:39:39,950 --> 00:39:46,090
Okay, I say prove that. So we could just say that convergence and distribution and yes.

292
00:39:46,240 --> 00:39:49,450
Is equivalent if you are limiting distributions to generate.

293
00:39:49,510 --> 00:39:53,770
In this case, of course it's to generate some single number.

294
00:39:54,310 --> 00:40:00,460
So that's why we have this Y and converge in probability to ask any other questions.

295
00:40:03,340 --> 00:40:05,080
So that's the first result that we need.

296
00:40:06,730 --> 00:40:15,940
And now we can use the mean theorem, the Miyamoto Theorem, and the classic theorem again to prove the Delta method.

297
00:40:18,520 --> 00:40:26,320
First of all, using the mean by theorem, we can get this g.

298
00:40:27,250 --> 00:40:31,030
Why has it? Oh, this is what our target is, right?

299
00:40:31,390 --> 00:40:37,690
G y and minus g theta is equal to g.

300
00:40:38,200 --> 00:40:48,040
First order derivative evaluated. At some points they see the Star Times Y and minus beta.

301
00:40:50,950 --> 00:40:57,790
And the reason why we can use this memory theorem is because this g first order derivative exist.

302
00:40:59,200 --> 00:41:02,890
So that's part of the condition. Right. So that's the existing condition.

303
00:41:05,050 --> 00:41:17,080
Since G one exists, we can apply that mean if there might have to convert this g y and minus g theta with this quantity.

304
00:41:17,740 --> 00:41:21,430
So g one theta star times y at minus theta.

305
00:41:23,230 --> 00:41:28,870
And the reason why we want to do it is because a lot of inside is what is required in the Delta method.

306
00:41:28,960 --> 00:41:36,130
Right. But the right hand side is what we know with of course, with some additional scaling.

307
00:41:36,790 --> 00:41:39,100
We know the convergence of this y and theta.

308
00:41:39,310 --> 00:41:45,640
So this Myanmar already established the bridge between what do we want to prove and what do we have on the conditions?

309
00:41:46,310 --> 00:41:53,660
Okay. And here the Theta Star is somebody between Y, A and B.

310
00:41:55,540 --> 00:42:08,050
So that's the memory theorem. Then we know the square root of and now we can take a look at our target.

311
00:42:10,400 --> 00:42:20,710
So this is the left hand side of the Delta method scoring ten times this going on minus g theta now is equal to a square root of ag1.

312
00:42:21,250 --> 00:42:25,120
See the star y and minus theta.

313
00:42:27,070 --> 00:42:32,530
All right. So if you look at the right hand side, first of all, we noticed.

314
00:42:35,070 --> 00:42:39,010
This guy, right? Square root of hand y theta.

315
00:42:39,870 --> 00:42:44,250
And recall that we know what it's converged to square it up in Times Square.

316
00:42:44,520 --> 00:42:50,340
Theater, commerce and distribution and normal zero six square.

317
00:42:50,860 --> 00:43:02,190
So that's from condition one. So the only thing that standing in the way if this additional term she one trader saw and this guy is not a constant.

318
00:43:02,340 --> 00:43:07,650
Why is that not a constant?

319
00:43:08,190 --> 00:43:16,909
Why not? Six months ago, the quiet and still random sit up stories.

320
00:43:16,910 --> 00:43:21,410
What is and is still random? Why is random?

321
00:43:21,410 --> 00:43:25,010
But I'm talking about this t one star status star.

322
00:43:26,240 --> 00:43:30,980
If this t one status star is a constant that pretty much wear down right.

323
00:43:31,490 --> 00:43:40,490
If you're multiply in constant on both side of this limit in distribution, that's the end of the story but it's not a tells us why that's not.

324
00:43:47,880 --> 00:43:51,840
So think about this. Say to start for different.

325
00:43:52,410 --> 00:43:59,580
If I say to start the same stuff.

326
00:44:00,000 --> 00:44:09,290
I mean what if there are only tells us there exists such a theta start for each pair of theta.

327
00:44:10,440 --> 00:44:14,670
But as you are wired and change, the theta star would also change.

328
00:44:15,330 --> 00:44:18,780
There is no guarantee that a star would always stay at the same point.

329
00:44:19,230 --> 00:44:26,310
In fact, it couldn't because y from the previous result we know why it is strengthened to theta.

330
00:44:27,240 --> 00:44:33,300
So no matter where your beta star is, as long as it's not exactly called a theta, it will also change along the way.

331
00:44:34,170 --> 00:44:39,480
So that's why this G, Y, and g one Theta Star is not a constant.

332
00:44:40,290 --> 00:44:49,700
It's actually rigorously speaking. You should also point a small n anything in that subscript indicating this also change with n.

333
00:44:53,290 --> 00:44:57,860
That makes sense to the state as they are charged with and with different wire.

334
00:44:57,910 --> 00:45:05,020
You've got a different set of start. And so that's why you cannot simply just treat it as a constant.

335
00:45:05,320 --> 00:45:11,170
And got the final result I want you can get is this.

336
00:45:20,420 --> 00:45:24,800
Why? Why do we have this?

337
00:45:44,340 --> 00:45:49,230
So in no state, OnStar is between the wire. That's from the memo right there.

338
00:45:49,650 --> 00:45:55,800
Right. We also know from the previous result why and what a converging probability, two or three.

339
00:45:57,420 --> 00:46:01,440
So while it is shrinking to theta theta, its constant state of never change.

340
00:46:01,530 --> 00:46:08,160
Right. If one is strengthens the center and theta and star is between this y and theta.

341
00:46:08,880 --> 00:46:17,750
So it has to shrink to theta as well. So that's why we have to take one step back.

342
00:46:37,680 --> 00:47:02,790
It's. So you can prove by checking the definition that Theta and Star would also converge in probability to theta.

343
00:47:03,210 --> 00:47:04,920
Because of this two results,

344
00:47:06,060 --> 00:47:15,780
the results that we just so fly on converging probability theta and the fact that a star is between why theta and with that we

345
00:47:15,780 --> 00:47:34,079
can have g theta and star derivative also converge improbability between the g first order derivative theta and what they do.

346
00:47:34,080 --> 00:47:41,370
We used to have the final two to have the last line of the last convergence.

347
00:47:42,970 --> 00:47:51,150
Yes. And he was mapping every continuous matter. And that's why we need the first auto derivative to be continuous,

348
00:47:51,150 --> 00:48:01,170
because this g first order derivative is a function that we apply to this to both side of this convergence.

349
00:48:02,340 --> 00:48:20,560
So this is continuous mapping. So we have this convergence in distribution and this convergence improbability.

350
00:48:21,130 --> 00:48:26,260
Now, if you look at a what do we want? It's the product of two sequences.

351
00:48:26,770 --> 00:48:30,980
So what we know we can use last case theorem again, right?

352
00:48:31,540 --> 00:48:35,110
Use to ask ourselves again to multiply these two sequences.

353
00:48:35,410 --> 00:48:46,620
And it got another convergence in distribution so you can work out the the remaining okay so protocol,

354
00:48:46,640 --> 00:48:53,400
this convergence and distribution and this convergence improbability using this classical theorem,

355
00:48:53,410 --> 00:48:56,830
say what you have got as a limiting distribution of this kind.

356
00:49:52,880 --> 00:50:03,410
Hey, I'll be right out. So the paradox of this two sequences also converge in distribution to the product of the limited distribution.

357
00:50:04,150 --> 00:50:11,240
Okay, so the paradox of the limiting distribution. On the one hand, you have this that normal distribution with means you are about a Sigma Square.

358
00:50:11,480 --> 00:50:19,430
On the other hand, you have this constant. If you multiply a constant with a normal, it's still got a null, right?

359
00:50:20,030 --> 00:50:23,450
You multiply a then with another unavailable and still have a normal amount of variable.

360
00:50:24,020 --> 00:50:29,580
The mean going to be the original mean multiplying the constant and the virus is going to be the original barrons.

361
00:50:29,690 --> 00:50:39,830
Multiply that constant square. So that's why we have a limiting distribution of normal, which means zero variance being sigma squared times this g.

362
00:50:40,250 --> 00:50:43,250
First of all, a derivative if you have theta squared.

363
00:50:44,760 --> 00:50:54,140
And that's our final result by the Delta method. Okay, so the left hand side is squaring up and job lion minus two feet on the right hand side.

364
00:50:54,150 --> 00:51:00,510
Is that normal with this particular army reference? Any questions?

365
00:51:02,710 --> 00:51:10,030
So one note that I want to make is that if you now if you look back at all of these conditions,

366
00:51:11,050 --> 00:51:15,220
of course, an Asian one is definitely required in multiple places.

367
00:51:15,850 --> 00:51:23,290
And the reason why we need this existence is to use continuous math right in the center stuff.

368
00:51:26,140 --> 00:51:34,050
So that's why we require g one to exist. And the reason actually sorry, that's not mapping.

369
00:51:34,650 --> 00:51:39,440
We require g one to exist because we need to use the memorial theorem.

370
00:51:44,850 --> 00:51:49,950
And we require that, first of all, the derivative to be continuous because we need continuous mapping.

371
00:51:54,560 --> 00:52:00,560
And finally, this jeep from theta is not even for a zero, because if it's equal to zero,

372
00:52:00,800 --> 00:52:05,510
then the parent is going to be the limited distribution, kind of going to have a zero tolerance.

373
00:52:06,500 --> 00:52:10,040
It still holds, but it's going to be a degenerate case.

374
00:52:11,150 --> 00:52:14,810
All right. The results still hold. ADR j zero.

375
00:52:15,920 --> 00:52:23,000
And instead of converting to a distribution in that case, all converging to win it January distribution, which is zero.

376
00:52:24,230 --> 00:52:28,520
The results still hold. Okay. It's just it's not going to be a distribution.

377
00:52:28,520 --> 00:52:37,030
It's going to be a number. So that's why in most cases people would require t prime theta now to be equal to zero.

378
00:52:37,040 --> 00:52:40,750
Otherwise you would just get a number. It's not a distribution.

379
00:52:41,380 --> 00:52:46,690
So that's why we need all these conditions. All right. So let's take a break and continue to.

380
00:52:52,240 --> 00:52:59,750
No truth to her.

381
00:53:00,550 --> 00:53:16,680
No. I mean, you don't have to go through.

382
00:53:17,370 --> 00:53:20,430
Is this attention to us?

383
00:53:20,840 --> 00:54:27,760
It's got to be for you to make use of Chris after up to 3 minutes.

384
00:54:29,560 --> 00:55:00,310
So you think you're not gonna know what to do with your life?

385
00:55:06,500 --> 00:55:10,420
So I'll have to tell you.

386
00:55:15,570 --> 00:55:36,320
Ask about the crisis in Syria,

387
00:55:41,610 --> 00:55:54,330
and you'll see that it's important to talk about and some people don't want

388
00:55:54,350 --> 00:56:09,290
to talk about somebody like you just because you think that that's not true.

389
00:56:09,470 --> 00:56:27,530
And if you think you should, you would think, yeah, yeah, I like to hear that.

390
00:56:28,910 --> 00:57:11,720
I mean, it's also important to strive to be able to talk about something you just can't.

391
00:57:14,630 --> 00:57:34,040
She should be taking his place.

392
00:57:35,280 --> 00:57:56,990
You know, this is not the time to read this crap.

393
00:57:57,620 --> 00:58:06,510
It seems like you never feel like you're one of three.

394
00:58:07,570 --> 00:58:11,580
It's always probably think.

395
00:58:11,630 --> 00:58:25,000
I know. I just felt like I never really felt like that before.

396
00:58:25,850 --> 00:58:41,890
That was okay.

397
00:58:43,690 --> 00:58:55,790
So. So when we were just now where we are, why did I start as a random then?

398
00:58:55,970 --> 00:58:58,640
The star is not random.

399
00:59:01,970 --> 00:59:16,700
I'm trying to understand I would think about this because this is this is not, you know, where are we saying that this story this hour,

400
00:59:16,790 --> 00:59:26,660
it is start at the time it is you can consider it to be a random I mean, an alternate, only a sequence.

401
00:59:26,690 --> 00:59:32,120
Right. And so it's a sequence that concerns to single number.

402
00:59:32,120 --> 00:59:46,500
So whether or not it's right because as long as it's a sequence you can always consider, even if not even in some respects, just that's a generation.

403
00:59:48,680 --> 00:59:59,600
You're right. That's it. I don't know why it is random.

404
00:59:59,600 --> 01:00:08,120
In other words, one could take different values and possibly also be random depending on where.

405
01:00:08,930 --> 01:00:21,620
What is the realization of like in English? So when we deal with seemingly random criminals world, are we allowed to say zero data?

406
01:00:21,720 --> 01:00:37,830
And that's the reason why we value theorem technically dividing more than four y

407
01:00:37,870 --> 01:00:50,370
and minus theta one minus what doesn't have to be my data or whatever where why?

408
01:00:50,390 --> 01:00:58,590
It's always these products that make that migration for say, because they can't converge.

409
01:01:00,910 --> 01:01:22,500
But to deal with the realization of complexity, we transform the way I want to say, because it's an approximation of the derivative.

410
01:01:23,250 --> 01:01:26,670
Sure, you don't have to exaggerate.

411
01:01:28,170 --> 01:01:35,070
You can always prove that. Or in this form it only happens in of itself.

412
01:01:35,580 --> 01:01:45,030
Even if that's easy for other countries, it's more difficult to be this helpful and worried about this kind of thing.

413
01:01:52,170 --> 01:02:00,090
All right. So let's continue and just another look at this Delta method.

414
01:02:00,370 --> 01:02:10,190
Again, the conclusion is we can have this limited distribution for the transformation of our original sequence of running variables.

415
01:02:10,840 --> 01:02:21,410
Okay. As long as this transformation satisfy these two, three and four conditions, the horizontal derivative exists and continues.

416
01:02:21,810 --> 01:02:23,700
And also it's not equal to zero.

417
01:02:23,940 --> 01:02:33,810
And as long as all of this conditions are satisfied, we have this new limited distribution of marginal player, new things.

418
01:02:36,720 --> 01:02:44,790
So this proof, if you think about the proof, it actually consists of several steps.

419
01:02:45,120 --> 01:02:52,740
First of all, we know the convergence of we know the convergence of the original sequence.

420
01:02:52,750 --> 01:02:56,910
Why I multiply this scaling parameters square.

421
01:02:57,150 --> 01:03:06,540
And if we want to get the new convergence for this new sequence, the the difference is in this transformation function.

422
01:03:07,800 --> 01:03:13,470
So that's why we need of a way to bridge the difference between the left hand side.

423
01:03:14,100 --> 01:03:14,940
On the other hand,

424
01:03:14,940 --> 01:03:26,310
size on both convergence and the way that we use the theorem that we use to bridge that difference is the memory of theorem with the Miyamoto Theorem.

425
01:03:26,550 --> 01:03:37,980
We can convert this G, y and minus g theta to y and my theta multiply some additional term just to be the star.

426
01:03:38,490 --> 01:03:40,920
And then the rest is using the surrogate theorem.

427
01:03:41,460 --> 01:03:48,780
And because we need to use that classic theorem, we need to first show that we can convert in probability to a constant.

428
01:03:49,380 --> 01:03:54,260
So that's sort of the, uh, the foundation of this proof, really.

429
01:03:54,270 --> 01:04:00,719
You can work it from what you want to prove and see what you have from the position and build a

430
01:04:00,720 --> 01:04:08,550
connection or build a bridge based on the difference between what you have and what we want to prove.

431
01:04:10,560 --> 01:04:15,240
So the end of the day, this is a new limited distribution with a mean being,

432
01:04:15,240 --> 01:04:21,480
zero balance being this sigma squared times the first on a derivative evaluated a theta squared.

433
01:04:22,860 --> 01:04:30,460
So the best is that that was a method. Now, let's take a look at a couple of examples to familiarize ourselves with this method.

434
01:04:31,030 --> 01:04:35,170
First example consider ask one toxin being the I.D.

435
01:04:35,380 --> 01:04:40,420
Random samples with MIMO and variance in a square where MU is not equal to zero.

436
01:04:41,590 --> 01:04:46,000
What is the sum tonic distribution for a square root of x bar?

437
01:04:48,170 --> 01:04:57,380
Take a couple minutes, think about how to use the downtime method to gather some tonic distribution for this next bar square.

438
01:04:57,740 --> 01:05:07,810
Again, when we see a asymptotic distribution, what do we mean is that you have two properties center and the scale this random are two

439
01:05:07,820 --> 01:05:15,910
got the limited distribution and most often the scaling parameter is square root of us.

440
01:05:16,880 --> 01:05:21,320
I covered some different scaling parameters and most of this is square.

441
01:05:21,320 --> 01:05:25,190
But okay, that's what we mean by asymptotic distribution.

442
01:05:25,580 --> 01:05:28,010
So whenever you say the word system tariff,

443
01:05:28,250 --> 01:05:38,360
it means you have to work out the corresponding center and scaling of that random barrel to get the limited distribution.

444
01:08:25,340 --> 01:09:10,010
It's. And one more minute.

445
01:10:06,560 --> 01:10:16,100
All right. So let's look at this problem together. So the question I ask, what is the sometime distribution for square of the sample mean square?

446
01:10:17,060 --> 01:10:25,280
The very first thing that should come to your mind is first, what do we know about this sample mean from the central limit theorem?

447
01:10:25,280 --> 01:10:31,940
We know they centrality attribution by spark. All right, so that's something that we we know.

448
01:10:33,620 --> 01:10:38,680
And the question asked about the sample sample means square. So it's a function of the sample.

449
01:10:39,890 --> 01:10:47,900
So that reminds us of the Delta method. If we can got the same type of distribution for X mean first for the sample mean first,

450
01:10:48,440 --> 01:10:53,960
then we can apply the delta method after checking all the conditions are satisfied

451
01:10:54,680 --> 01:10:59,090
and that will give us some kind of distribution for the sample mean squared.

452
01:11:00,050 --> 01:11:05,270
That's the way to solve this problem.

453
01:11:05,660 --> 01:11:15,410
So first, then first as far from Central Limit Theorem, we know that as far minus the population mean,

454
01:11:15,950 --> 01:11:22,999
multiply this square without n converge in distribution to normal zero sigma

455
01:11:23,000 --> 01:11:31,730
square right because x12x and they are ivy with the same me and same barracks.

456
01:11:32,330 --> 01:11:36,980
So by the Manila Central Limit theorem, we have this convergence in distribution.

457
01:11:38,810 --> 01:11:46,820
Okay? And now we have to work on this X bar square, which implies the G function.

458
01:11:49,090 --> 01:11:52,430
Is. X squared. Right.

459
01:11:52,520 --> 01:11:59,630
So that's the function we want to apply to our sequence of random marbles and this a main parameter.

460
01:12:01,100 --> 01:12:09,140
So if you look at this g function of x squared that satisfy all the conditions for the delta method.

461
01:12:09,410 --> 01:12:12,580
First of all, the first derivative exists. Right.

462
01:12:13,080 --> 01:12:18,440
So the prime x is just two x which exists and it's also continuous.

463
01:12:19,850 --> 01:12:25,340
And also g prime mu is equal to two times mil.

464
01:12:27,540 --> 01:12:31,890
By this condition we're not able to zero in know that j primary is also not zero.

465
01:12:32,490 --> 01:12:36,630
So all the conditions are satisfied. Then we can use the delta method.

466
01:12:39,520 --> 01:12:51,100
Which tells us if you apply this function to X bar and you also converting distribution to a normal distribution,

467
01:12:51,520 --> 01:12:56,830
which means you're embarrassed being what original sigma squared times.

468
01:12:59,150 --> 01:13:03,200
But it's a crime.

469
01:13:04,160 --> 01:13:08,540
Neil Square. All right.

470
01:13:09,290 --> 01:13:22,370
And now you can plug in what you have. So square and g as far as just the taxpayer square minus meter square converge in distribution to normal zero.

471
01:13:23,270 --> 01:13:27,890
So it's g prime who is to muse for muse square?

472
01:13:28,310 --> 01:13:35,430
Sigma Square. And there it got a center distribution by Expr Square.

473
01:13:35,970 --> 01:13:48,470
So they. Center of that next hour square is this music square and the scary in the same square with all with bass scenery and scaling.

474
01:13:48,620 --> 01:13:51,950
You have this convergence and distribution to a distribution,

475
01:13:52,550 --> 01:14:00,040
but normal distribution with this me and these parents that give you the same three distribution bodies at Spar Square.

476
01:14:03,050 --> 01:14:14,460
Any questions? So that's how you can use the Delta method.

477
01:14:15,240 --> 01:14:21,899
Again, the very first thing to you to to to derive before to use the delta method is first you need

478
01:14:21,900 --> 01:14:27,000
to kind of sequence that converging distribution to a distribution to a normal distribution.

479
01:14:28,170 --> 01:14:29,340
That's the very first thing.

480
01:14:29,790 --> 01:14:39,000
And based on what I have learned so far, pretty much all we know is that the central limit theorem gave us that convergence.

481
01:14:39,270 --> 01:14:43,530
Right? So always a look for the sample mean in the first place,

482
01:14:44,070 --> 01:14:52,080
the central limit zero and then apply the delta method on that central limit ceremony and you got the final result.

483
01:14:52,440 --> 01:14:57,060
And so in this particular case, we do require mu not equal to zero.

484
01:14:57,690 --> 01:15:19,100
So what would happen in a formula is equal to zero. Yes, we have the degenerate case.

485
01:15:19,850 --> 01:15:26,810
So mule is equal to zero. What about the original central limit theorem?

486
01:15:27,120 --> 01:15:31,940
Can we still have a convergence in distribution or a degenerate?

487
01:15:36,740 --> 01:15:44,350
It doesn't affect that. Right. So I still have. This convergence and distribution to a normal distribution.

488
01:15:45,280 --> 01:15:50,590
So the first step is not affected. And what do got affected in the second step?

489
01:15:53,410 --> 01:15:58,660
As Jonathan said, it's going to be a degenerate case because the new virus is going to be zero.

490
01:15:59,200 --> 01:16:07,810
Right. So what you have is square of an X bar square kind of converting distribution to zero,

491
01:16:09,190 --> 01:16:15,010
which is still correct, but it's not called a scenario distribution and more because it's degenerate.

492
01:16:16,240 --> 01:16:24,310
It just says square root of N Thomas's X bar square still converge, but it's converged to a single number.

493
01:16:25,600 --> 01:16:32,259
It doesn't converge for distribution coliseum color distribution channel.

494
01:16:32,260 --> 01:16:41,979
Where's the square root of hand is not magnifying this the sequence enough to give us a distribution and

495
01:16:41,980 --> 01:16:51,280
we don't know what it would be a better scaling parameter if we multiply n which is a stronger magnifier.

496
01:16:52,600 --> 01:17:01,420
We don't know what that converts to because we don't have such a such a theorem that take the square root of.

497
01:17:04,200 --> 01:17:14,680
Take the square root of this. Take the square root of a convergence in distribution to another distribution.

498
01:17:14,920 --> 01:17:20,680
So we do not have such results. So we don't know what would be a magic scaling problem in this case.

499
01:17:20,890 --> 01:17:28,890
All we know is that this the regularly used square root of and is now strong enough to still give us a degenerate hardness.

500
01:17:29,410 --> 01:17:36,910
Okay. A basic conclusion is still correct. They still have this convergence, but it's just not a distribution.

501
01:17:38,150 --> 01:17:40,540
All right. Nice example.

502
01:17:42,940 --> 01:17:57,520
x12 axon being random samples from a positive and being positive random random samples with me amu and various Sigma Square AMU is greater than zero.

503
01:17:58,270 --> 01:18:05,440
The question is what is the SIM card distribution? The reciprocal of the sample is one over x bar.

504
01:20:18,490 --> 01:21:03,090
Hearings. I. All right.

505
01:21:03,090 --> 01:21:08,780
So what's the first step in order to gather some kind of distribution for one of our spas?

506
01:21:10,590 --> 01:21:22,040
What should we get first? Either tackle this problem.

507
01:21:26,200 --> 01:21:30,550
Yes, we did find them, which is a transformation.

508
01:21:31,690 --> 01:21:39,040
But you define a transformation and then take the very same name, a derivative.

509
01:21:39,490 --> 01:21:45,790
And another very important fact is you need to use the one central, central element there.

510
01:21:45,910 --> 01:21:54,880
Right? So you can work from this X bar first by directly applying the central limit theorem, you got X.

511
01:21:56,530 --> 01:22:04,040
That's. As for modest meals, formal and converging distribution to normal,

512
01:22:04,130 --> 01:22:10,160
this means zero has become a square and noticing that the transformation in this case.

513
01:22:13,160 --> 01:22:17,310
This one over access. I want Iraq's.

514
01:22:17,480 --> 01:22:22,460
We need to take a look at the derivative, which is not a one over a square.

515
01:22:22,850 --> 01:22:33,230
All right. So it does exist for the support of this random variable, which is zero to infinity, and it also continues on that support.

516
01:22:34,760 --> 01:22:38,300
Also, the chain prime meal is not equal to zero.

517
01:22:39,260 --> 01:22:40,940
So all three conditions are satisfied.

518
01:22:41,240 --> 01:22:50,780
So I'm going to go back to the and then you can apply the Delta method and you got one over x bar minus one over meal.

519
01:22:51,200 --> 01:22:54,230
Convert in distribution to zero.

520
01:22:54,320 --> 01:22:59,210
Sigma Square and G prime new square.

521
01:23:00,530 --> 01:23:03,970
So g prime is here plugging in mu.

522
01:23:04,670 --> 01:23:09,960
All right, so you got one over mu squared and squared.

523
01:23:10,430 --> 01:23:16,100
So one over meal to the power of four. So that's your limiting distribution.

524
01:23:17,450 --> 01:23:22,220
And so this is the result. Or as we argued before,

525
01:23:22,520 --> 01:23:43,150
you can also write in this one over square root of one over x bar is approximate until I follow a normal distribution with zero one over to you and.

526
01:23:49,330 --> 01:23:55,390
Sigma squared over end times mutual hour, and for some that's the equivalent expression.

527
01:23:56,260 --> 01:24:04,419
So both are correct either in right convergence and distribution to our distribution that has not involved in ten or around

528
01:24:04,420 --> 01:24:13,300
this approximate volume in normal distribution with corresponding mean and corresponding various the various account content.

529
01:24:13,810 --> 01:24:20,830
And those are correct right questions.

530
01:24:26,660 --> 01:24:31,100
So now no question. Take a look at the practice problems.

531
01:24:37,240 --> 01:24:40,570
Work on a couple of more exercise.

532
01:24:48,020 --> 01:24:53,060
So by the way, the final review contains the study guide, as I mentioned.

533
01:24:53,600 --> 01:25:02,510
So take a look. It has some important topics that you need to work your work out to prepare about final.

534
01:25:03,050 --> 01:25:08,450
And you can also find the final exam from last year.

535
01:25:08,880 --> 01:25:16,670
Okay. So these are the questions I want to work on now is.

536
01:25:23,680 --> 01:25:29,110
Let's take out take a look at the homework questions in particular.

537
01:25:29,620 --> 01:25:38,440
First, take a look at this number three and see how can we use what did we learn today to solve this problem?

538
01:25:39,910 --> 01:25:44,110
So ask one to have some of the I.D. uniform running barrels from 0 to 1.

539
01:25:44,890 --> 01:25:52,120
And this gene, which is defined as the product of X II to the power of one over ten.

540
01:25:53,650 --> 01:25:57,910
These are the geometric mean for this random sample.

541
01:25:58,510 --> 01:26:17,500
It's zoom in a little bit. So this gene is defined as a geometric image of the random sample of size.

542
01:26:18,070 --> 01:26:25,420
And so the first question asks you to show Gene and converge in probability to this e to the negative one.

543
01:26:26,890 --> 01:26:34,870
And second question asks you to find a limited distribution of this guy, in other words, with some type of distribution for this GM.

544
01:26:35,140 --> 01:26:40,060
So this case, we do provide with the century and a scanning already.

545
01:26:40,060 --> 01:26:44,710
So only to do is to say what this guy converts to in distribution.

546
01:26:45,640 --> 01:26:55,310
So that's what I'm y means to find that limiting distribution of this guy is a cool way to answer this question or slightly more difficult.

547
01:26:55,310 --> 01:26:58,660
A way to answer this question is what is that some type of distribution?

548
01:26:59,980 --> 01:27:06,460
If that's the case, then you have to work out this entering the center and scaling parameter.

549
01:27:07,750 --> 01:27:16,480
We are providing that. So let's take a look at this question and take a couple of minutes, try to see if you can solve this problem.

550
01:27:19,210 --> 01:27:25,270
Slightly trickier than the example that we have shown. We have seen right now.

551
01:30:33,690 --> 01:30:55,300
It's. Yes.

552
01:33:16,310 --> 01:34:08,410
If. He's more time criminal.

553
01:34:09,930 --> 01:34:14,340
And if you got it. One more minute.

554
01:35:10,190 --> 01:35:16,260
All right. So let's look at this problem together and see how we can tackle this.

555
01:35:17,420 --> 01:35:27,320
The first question asked you about the convergence, improbability, the convergence of this gene in probability to a constant.

556
01:35:28,610 --> 01:35:37,040
So to prove convergence in probability in general, we have limited ways, right?

557
01:35:37,070 --> 01:35:43,879
One is use the definition by writing of the definition of this convergence in probability.

558
01:35:43,880 --> 01:35:51,340
Essentially what we are trying to prove is the limit of the probability of this together,

559
01:35:51,380 --> 01:35:58,070
minus e two an active one absolute value greater than some absolute strength of zero.

560
01:35:59,330 --> 01:36:06,440
That's the definition. And in this case, if you write the absolute difference between generally and an active one,

561
01:36:08,780 --> 01:36:15,730
it doesn't give us any, but it doesn't seem to be able to further simplify.

562
01:36:17,840 --> 01:36:26,330
Cannot be simplified further. So which means using the definition may not be the best way to solve this problem.

563
01:36:27,020 --> 01:36:31,130
Alternatively, we can use a rather large number.

564
01:36:31,640 --> 01:36:39,430
That's another theorem that can give us convergence in probability, especially for emergence and probability to encounter.

565
01:36:41,240 --> 01:36:52,790
But if you look at Gianna, it's not exactly a simple meme, but it's close to a sample in the sense it's a geometric right.

566
01:36:53,330 --> 01:36:56,870
Not exactly an arithmetic mean, but it's a geometric mean.

567
01:36:58,300 --> 01:37:06,850
So we can build a connection between that geometric mean arithmetic mean by taking a log transformation.

568
01:37:07,580 --> 01:37:11,290
Right. So if you take the log transformation of this gene.

569
01:37:15,580 --> 01:37:20,049
Well say immediately not that is equal to one over.

570
01:37:20,050 --> 01:37:25,240
And the summation I have from one to a log of.

571
01:37:28,290 --> 01:37:32,340
And that looks more like a sample. Me, right.

572
01:37:32,370 --> 01:37:38,430
Although it's not a sample meal, actually, but it's some of the some of it is actually our idea.

573
01:37:38,790 --> 01:37:43,260
We know the I guanxi are also ivy, right?

574
01:37:43,360 --> 01:37:52,530
Epoxies are mutually independent. Now, of course, the law of Aksai are also mutually dependent and impacts are all the same distribution logs.

575
01:37:52,530 --> 01:37:59,640
I also follow the same distribution. So it does represent a sample mean.

576
01:38:00,180 --> 01:38:03,420
It's a sample mean of the Linux.

577
01:38:06,160 --> 01:38:12,040
And that would allow us to use a large number.

578
01:38:13,390 --> 01:38:17,290
And in terms of this large transformation,

579
01:38:17,290 --> 01:38:25,059
we can always have an enormous transformation carried on using a continuous mapping which

580
01:38:25,060 --> 01:38:32,230
preserve the convergence and improbability of that idea approving the first result.

581
01:38:33,790 --> 01:38:37,899
So then the question boils down to what is the distribution?

582
01:38:37,900 --> 01:38:45,220
Well, what is the mean for this log acts? So if as follows, I'd call this a uniform distribution.

583
01:38:46,570 --> 01:38:51,010
We can denote Y to be a log of outside.

584
01:38:52,090 --> 01:38:56,530
Now we can use what do we learn in the univariate transformation?

585
01:38:57,530 --> 01:39:02,410
So x y is equal to the E to the y, right?

586
01:39:02,800 --> 01:39:06,580
So y y.

587
01:39:07,280 --> 01:39:18,600
And be equal to have x. E to the Y times, a derivative of that which is aid to the Y.

588
01:39:19,980 --> 01:39:24,300
Absolutely. So that's going to be equal to one time aid to the Y.

589
01:39:25,620 --> 01:39:29,159
So basically give us the PDF for this transform.

590
01:39:29,160 --> 01:39:36,300
Run a variable and if ax is from 0 to 1, we know y is less than zero.

591
01:39:38,430 --> 01:39:45,270
Right? And in fact, if you have a PDF in this form, what is the name opposite its distribution?

592
01:39:48,060 --> 01:39:57,570
All they don't see immediately. But if you take a negative sign up, what you have exponential is exponential distribution.

593
01:39:58,170 --> 01:40:08,550
If you take an active Y. So if your ax is a uniform number that the log transformation of X is an active exponential distribution.

594
01:40:09,450 --> 01:40:14,580
And we know everything about exponential distribution, we know the mean, the barrons, etc.

595
01:40:14,880 --> 01:40:24,800
So that just give us the expectation of log x is negative one, right?

596
01:40:25,950 --> 01:40:42,600
So that's why there's a lot of G and converge in probability to the expectation of the log, which is negative one.

597
01:40:44,550 --> 01:40:54,540
Now to get to our final result, we just need to apply exponential transformation on both side of this cards and apply to containers,

598
01:40:54,540 --> 01:40:57,730
maybe to apply attention on both sides.

599
01:40:58,080 --> 01:41:03,090
You got G and converting probability to E to the negative one.

600
01:41:04,560 --> 01:41:09,510
Right. So that's how we can take advantage of this log.

601
01:41:09,510 --> 01:41:14,480
Last number to prove the first one. So I'll give you another couple minutes.

602
01:41:15,410 --> 01:41:18,830
You can try to prove the second using a similar idea.

603
01:45:02,020 --> 01:45:05,530
All right. Well, the second part can go to the limited distribution directly.

604
01:45:11,900 --> 01:45:20,360
There are things that I can give you that lemon in the distribution machine minus E the one directly.

605
01:45:22,160 --> 01:45:33,350
Probably not. Right. You do not have a theorem for this geometric mean Morris James and a limited distribution for that.

606
01:45:33,740 --> 01:45:39,550
But again, same as the first question. We can take advantage of this log transform.

607
01:45:39,770 --> 01:45:50,550
And once we do the log transformation, we can apply the central limit error because log jam is a sample mean, right?

608
01:45:51,860 --> 01:45:57,980
Once we have a sample mean, you can always apply the central limit theorem which gave you this convergence and distribution.

609
01:45:59,300 --> 01:46:00,950
So that should be our starting point.

610
01:46:02,660 --> 01:46:12,950
So instead of working directly on this G and minus E to the actor one as first to work on this log object minus negative one.

611
01:46:13,660 --> 01:46:20,330
Okay. So by central limit theorem, we know there's a log in.

612
01:46:20,450 --> 01:46:24,980
Is the sample mean of the law? Exactly right.

613
01:46:25,640 --> 01:46:30,710
So by central limit theorem, we know for each log oxide, the mean is not a one.

614
01:46:31,100 --> 01:46:41,150
The variance is one. A log as high as an activity potential is parameter one so mean equal to one virus equal to two.

615
01:46:42,050 --> 01:46:53,800
And so by far, Lazenby, you know, that's the common distribution that you should have some of memorize this are important statistics by heart.

616
01:46:53,810 --> 01:47:00,980
It's a very commonly used part. Exponential random variable means one variance to get nominated equal to one.

617
01:47:01,420 --> 01:47:07,760
Okay, so now we can write down its limited distribution as zero and two.

618
01:47:10,100 --> 01:47:12,170
So that's directly from Central Limit theorem.

619
01:47:13,220 --> 01:47:21,140
And with that, we can take one step further, take out limiting distribution or g n minus E to the next one.

620
01:47:22,100 --> 01:47:31,090
So what is that transformation? That's a natural transformation, right?

621
01:47:31,470 --> 01:47:34,970
I understand transformation applied to this sequence over antivirals.

622
01:47:35,260 --> 01:47:39,260
What if gave you a gene and the explosion transformation?

623
01:47:39,980 --> 01:47:45,770
The first derivative is so sweet and utterly possessed and it continues.

624
01:47:46,160 --> 01:47:49,580
And if you apply it to like this one is not a part of zero.

625
01:47:49,580 --> 01:48:01,110
So everything checks out. So if you apply the Delta method now you got some momentum and G and I e to the log g and.

626
01:48:05,100 --> 01:48:12,890
Minus E to the negative one converge in distribution to an.

627
01:48:15,700 --> 01:48:22,720
Normal. Zero. E to the negative one squared.

628
01:48:24,790 --> 01:48:33,170
And it's too. And the barons times the cheap prime new squared.

629
01:48:35,560 --> 01:48:41,389
All right, so that's normal. 02e2.

630
01:48:41,390 --> 01:48:48,170
Inactive, active, two. All right, I should do this.

631
01:48:48,170 --> 01:48:51,920
One or two. One, one. Right. My bet.

632
01:48:59,610 --> 01:49:04,320
So the barons is one. So. And the remaining derivation.

633
01:49:04,440 --> 01:49:08,130
Correct. All right. So finally, you have this unlimited distribution.

634
01:49:08,550 --> 01:49:18,620
Again, if you look back at this problem, we do not directly have central limit theorem or large number for this gene sequence.

635
01:49:19,500 --> 01:49:22,780
But what we do observe is we summon transformation.

636
01:49:22,860 --> 01:49:31,830
You can create a sequence of simple means, and once you have a simple mean, things become much easier.

637
01:49:32,580 --> 01:49:39,060
Actually, that should always be the first thought when we deal with this problems.

638
01:49:39,540 --> 01:49:48,720
Try to create a simple meaning from the sequence. If you can somehow find a transformation that convert your sequence into a simple means.

639
01:49:49,290 --> 01:49:53,310
Now you can always apply this the large number or the central element.

640
01:49:55,470 --> 01:49:59,860
And with this additional escape from continuous mapping the automated.

