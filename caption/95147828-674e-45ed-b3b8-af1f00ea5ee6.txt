1
00:00:08,910 --> 00:00:13,620
As in life errors happen. And we see this in epidemiology as well.

2
00:00:14,190 --> 00:00:20,160
In our last video, we talked about what happens when errors are similar between groups or non differential.

3
00:00:20,730 --> 00:00:21,480
In this video,

4
00:00:21,480 --> 00:00:29,010
we're going to focus on the scenario where errors do differ between groups and we're going to talk about the impacts of these differential errors.

5
00:00:30,300 --> 00:00:39,450
Specifically, I'll walk you through identifying and describing common causes of differential error and the information bias that likely happens.

6
00:00:40,750 --> 00:00:46,420
So some of the most common examples of differential errors come from investigators themselves,

7
00:00:46,840 --> 00:00:52,780
where they're over or underreporting some outcome as a result of their previous knowledge or hypotheses.

8
00:00:53,590 --> 00:00:59,110
Now, this can happen intentionally within the context of trying to provide the best care for patients.

9
00:00:59,770 --> 00:01:06,610
For example, women who are on oral contraception have a higher risk of deep vein thrombosis.

10
00:01:07,150 --> 00:01:14,680
As a result, physicians tend to screen people on oral contraception more carefully for deep vein thrombosis,

11
00:01:14,680 --> 00:01:19,960
which is also called DVT, is more carefully than women who are not on oral contraception.

12
00:01:21,230 --> 00:01:26,840
Now. It can also happen that some of these errors sneak in in more subconscious ways.

13
00:01:27,440 --> 00:01:34,850
So let's take, for example, an investigator who's studying blood pressure as a function of some particular exposure.

14
00:01:35,690 --> 00:01:39,919
Now, blood pressure, if recorded by hand, has a little bit of noise in it.

15
00:01:39,920 --> 00:01:45,020
And so you can wind up rounding up or rounding down relatively easily.

16
00:01:45,590 --> 00:01:51,050
So it is quite possible that if the investigator knows who is exposed and who is not,

17
00:01:51,320 --> 00:01:56,870
they might subconsciously more frequently round up when it's somebody they know to be exposed and

18
00:01:56,870 --> 00:02:02,900
round down when they know it's somebody unexposed just because it's consistent with their hypothesis.

19
00:02:03,740 --> 00:02:07,400
Similarly, when interviewing somebody about cognitive functioning,

20
00:02:07,700 --> 00:02:12,919
you can imagine that a technician or a physician might prod somebody or give more leading

21
00:02:12,920 --> 00:02:17,900
questions to someone that they suspect is supposed to be performing better than they are,

22
00:02:18,350 --> 00:02:22,040
thereby introducing different errors between groups.

23
00:02:23,290 --> 00:02:31,090
Now, not surprisingly, these different errors can have very important impacts on associations that we can see between exposures and outcomes.

24
00:02:31,840 --> 00:02:38,799
So let's take, for example, a scenario that we talked about previously with the increased surveillance for DVT or deep

25
00:02:38,800 --> 00:02:44,800
vein thrombosis for women who are on oral contraception as compared to those who are not.

26
00:02:45,280 --> 00:02:48,970
And specifically, we're going to walk through some different kinds of numbers.

27
00:02:50,300 --> 00:02:55,760
So here we start with a two by two table that's assumed to be the true counts.

28
00:02:56,120 --> 00:03:01,009
If we were able to obtain perfect data in this particular scenario,

29
00:03:01,010 --> 00:03:08,360
we have a true odds ratio of 1.5 indicating that women with DVT have one and a half

30
00:03:08,360 --> 00:03:13,400
times the odds of being on oral contraception than those who did not have DVT.

31
00:03:14,870 --> 00:03:24,470
Now, if we assume that doctors misclassify many of those individuals who are not on oral contraception here misclassifying 50%,

32
00:03:24,950 --> 00:03:32,630
but they do a much better job of capturing the cases among those who are on oral contraception here, capturing 90%.

33
00:03:33,260 --> 00:03:40,910
What we see is that these errors will result in an exaggeration of the association in our observed data.

34
00:03:41,480 --> 00:03:46,160
In other words, we're going to bias our results away from the null value of one.

35
00:03:47,420 --> 00:03:53,720
Now, you can imagine that differential misclassification does not always have to bias the results away from the null.

36
00:03:54,500 --> 00:04:00,800
Here, I'm showing an example of what would happen if we had error only among those with exposure,

37
00:04:01,220 --> 00:04:04,820
which really here is probably counter to fact in the real world.

38
00:04:05,690 --> 00:04:11,599
However, in this scenario you can see that we actually have biased our results towards the null and

39
00:04:11,600 --> 00:04:17,300
it appears as if oral contraception use is actually protective of deep vein thrombosis.

40
00:04:17,840 --> 00:04:26,590
Clearly, we're getting the wrong answer here. Differential errors and the associations don't only have to occur due to the investigator.

41
00:04:27,100 --> 00:04:32,650
In fact, it's not uncommon for participants themselves to also be a source of differential error.

42
00:04:33,410 --> 00:04:36,670
Well-known examples of this are likely recall bias,

43
00:04:36,670 --> 00:04:44,080
where most of the healthy individuals don't spend a long time thinking about all of the exposures that they've experienced in life.

44
00:04:45,320 --> 00:04:53,630
Individuals with disease may have spent a much longer time thinking about why they got that disease and what exposures they've had in their lifetime.

45
00:04:54,260 --> 00:04:59,870
As a result, they may over report exposures with respect to those without disease.

46
00:05:01,370 --> 00:05:05,150
Similarly, there are sometimes issues of desirability bias.

47
00:05:05,480 --> 00:05:11,630
And what that means is that a participant might actually lie about their information in order to meet social norms.

48
00:05:12,230 --> 00:05:16,549
An example of this might be that overweight individuals might be more likely to

49
00:05:16,550 --> 00:05:21,800
under-report their true consumption of candy due to social desirability bias.

50
00:05:23,910 --> 00:05:29,729
Now. Bias by participants can also be likely if individuals are asked about illegal

51
00:05:29,730 --> 00:05:33,690
events or other things that they really just don't want people to know about.

52
00:05:34,320 --> 00:05:40,380
So, for example, let's take the scenario where we're conducting a case control study of car crashes and drinking.

53
00:05:41,190 --> 00:05:46,139
Those individuals who've been in car crashes may be more likely to underreport their

54
00:05:46,140 --> 00:05:51,660
alcohol consumption in the hours before their crash than people who had no car crash.

55
00:05:52,140 --> 00:05:58,560
Of course, the reason why is because they're fearful of going into jail or otherwise being held accountable for the crash.

56
00:05:59,960 --> 00:06:05,210
Now using this exact scenario about drinking and car crashes as our next example,

57
00:06:05,690 --> 00:06:14,210
we might expect to see that a true association between drinking and car crashes is quite high here, say with an odds ratio of nearly three.

58
00:06:15,370 --> 00:06:19,960
If those who had been in car crashes dramatically underreported their drinking,

59
00:06:20,440 --> 00:06:28,890
it may actually appear in our observed and misclassified data that there is no association, all between drinking and car crashes.

60
00:06:30,190 --> 00:06:37,360
These examples were both for categorical outcomes, but you can imagine that there would be similar effects for continuous data as well.

61
00:06:38,020 --> 00:06:47,950
So here I'm starting by just showing you the true distribution of tetrachloride, ethylene or PCE among cancer patients and healthy individuals.

62
00:06:49,150 --> 00:06:56,410
If we have inaccuracies of the PC e distribution, but it happens in only one of the two groups.

63
00:06:56,830 --> 00:07:06,730
What we will see is that we shift the curves either closer or further away, depending on whether or not our measurement is either too high or too low.

64
00:07:07,270 --> 00:07:12,610
In effect, what we are doing is we are biasing the mean difference by only shifting one

65
00:07:12,610 --> 00:07:16,870
of the curves or shifting one of the curves more than we shift the other one.

66
00:07:17,800 --> 00:07:23,830
Now, differential precision of our exposure has less of an impact on the mean values,

67
00:07:24,130 --> 00:07:29,320
but it's certainly expected to reduce our statistical power to detect associations between the groups.

68
00:07:30,250 --> 00:07:35,790
Now that we've learned that differential error can result in information bias that can be towards or away from the null,

69
00:07:36,130 --> 00:07:43,990
how do we predict the directionality? Well, one way is to return to our trusty two by two tables and realize that any errors

70
00:07:43,990 --> 00:07:49,000
that increase the cells of A or D will overestimate the true association.

71
00:07:49,540 --> 00:07:53,860
In other words, we're going to see something that in magnitude is too large.

72
00:07:54,610 --> 00:08:02,950
Therefore, if an exposure is bad for your health, we will see an exaggeration of the association or movement away from the null.

73
00:08:04,000 --> 00:08:10,120
If an exposure is protective, then it's likely to make it look less protective than it is.

74
00:08:10,720 --> 00:08:18,340
This movement will be towards the null, but in fact it can even pass the null and make that exposure look harmful.

75
00:08:20,080 --> 00:08:27,730
In contrast, any errors that increase the counts in cells B and C will underestimate our true association.

76
00:08:28,090 --> 00:08:32,590
In other words, with respect to true magnitude, we would see something that is too small.

77
00:08:33,340 --> 00:08:41,050
Now, if an exposure was bad for health, you would expect to see the Observed Association look less harmful than truth,

78
00:08:41,320 --> 00:08:50,650
and it could even make it look protective. Whereas if there is a truly protective exposure for the disease status, it will make it look even more so.

79
00:08:52,310 --> 00:08:57,980
So in summary, this is all to say that differential errors are quite dangerous in epidemiologic

80
00:08:57,980 --> 00:09:02,350
studies because they can result in bias either towards or away from the novel.

