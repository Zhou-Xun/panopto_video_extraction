1
00:00:02,520 --> 00:00:06,560
An important part.

2
00:00:10,050 --> 00:02:02,600
A lot of work here and lots of offices, but I don't think there's actually a lot of interest as we start to see this.

3
00:03:25,750 --> 00:03:58,110
Quick question was, did you finish Christmas this past two weeks?

4
00:03:58,310 --> 00:04:10,140
Which. All right.

5
00:04:11,310 --> 00:04:19,260
A lot of us from The Times would didn't think it would be that complicated later on.

6
00:04:21,510 --> 00:04:36,330
So before we get started talking through today, let me remind you of your first assignment due on Monday at the start of the task force.

7
00:04:36,360 --> 00:04:47,100
Basically, what we do, the last class had a specific risk syllabus is cooking food.

8
00:04:48,360 --> 00:04:59,040
And I want you to engage in both of the sides of the analytical and experiential dichotomy that we talked about in the last class.

9
00:04:59,790 --> 00:05:03,720
So I'm looking for here and I want to be really clear about this.

10
00:05:05,200 --> 00:05:11,810
Many different things can create. Thought or can create emotion.

11
00:05:12,140 --> 00:05:17,690
But that is not what the question I'm asking you. I'm asking you is what are the inputs?

12
00:05:18,890 --> 00:05:29,060
So what are the things that you would see here that you would engage with with your analytical system?

13
00:05:32,730 --> 00:05:44,150
What are the experiences, what are the things that may leave your experiential system, your emotional system to endure?

14
00:05:45,900 --> 00:05:48,120
You're in the business of designing communications.

15
00:05:48,690 --> 00:05:59,730
So I'm finding our focus here on what are the different things that someone might interact with that would lead them to develop.

16
00:06:00,670 --> 00:06:02,920
But over time, experiential learning.

17
00:06:04,100 --> 00:06:10,970
What are the things that they might interact with at one point in time or in time that would lead them to have conscious and political beliefs?

18
00:06:14,770 --> 00:06:19,099
Attention. What? It's basically too short answer.

19
00:06:19,100 --> 00:06:24,280
So treat each of these as a separate, short answer. The lime is the key thing.

20
00:06:24,670 --> 00:06:30,460
I'm going to be looking more than anything else and making sure that you're classifying things in the right place.

21
00:06:31,150 --> 00:06:39,550
Notice, by the way, that. Things that you might think about might also generate emotions.

22
00:06:41,330 --> 00:06:48,140
And experiences that you might have might also generate factual knowledge, things that you would think about consciously.

23
00:06:48,800 --> 00:06:59,600
That's true, and that's fine. But then still want you to focus more on the inputs on what are the which system is going to engage first and foremost.

24
00:07:02,570 --> 00:07:11,480
I'm asking this because I want us to really be clear about where do our communications engage with one system and when do they engage with another?

25
00:07:12,680 --> 00:07:20,040
Where the communication design business. You don't have to be super long.

26
00:07:20,790 --> 00:07:25,020
You don't need to be concrete and specific. I'll just sort of wave hands.

27
00:07:25,830 --> 00:07:29,420
Be really specific examples of a type of things.

28
00:07:31,740 --> 00:07:37,590
The other piece of advice here is pay attention to what does occur.

29
00:07:38,250 --> 00:07:46,740
Pay attention to what is consciously thought about it, to what is not happening or not consciously thought about.

30
00:07:48,490 --> 00:07:52,780
Both of these are important. This is not about completeness.

31
00:07:53,080 --> 00:08:00,190
It's not like there's some master list of every last possible thing that somebody would think about or every last possible experience they might have.

32
00:08:00,910 --> 00:08:06,580
But give me good examples of the kinds of categories of stuff that come up and.

33
00:08:09,870 --> 00:08:14,620
Any questions about this? I'd have to be super long.

34
00:08:20,090 --> 00:08:23,980
Maybe you have a quick example of what you're talking about. Well.

35
00:08:25,540 --> 00:08:31,069
Remind me which risks we talked about on Tuesday. I remember all the examples.

36
00:08:31,070 --> 00:08:36,650
We had three lots of them. This was a smoking gun.

37
00:08:37,220 --> 00:08:50,030
So let's play this out. What are what is this thing that you might see or read or hear about smoking that would engage your analytic assessment?

38
00:08:51,270 --> 00:08:55,530
Yeah. I mean, surgeon general's warning in the back in general warning.

39
00:08:56,220 --> 00:09:01,500
The general general warning is the fact that it's there is a warning itself.

40
00:09:01,800 --> 00:09:04,890
You may have thoughts and conscious beliefs about why that warning is there.

41
00:09:05,640 --> 00:09:09,750
That's analytical right now.

42
00:09:09,750 --> 00:09:15,120
It's doing one on one on the other side. An experience like smoking.

43
00:09:15,480 --> 00:09:20,730
Yeah, maybe like a black lung is so specific.

44
00:09:21,060 --> 00:09:25,630
How are you interacting with that? Like fear or.

45
00:09:25,780 --> 00:09:29,890
No, no, no. I mean, like, in what context are black lungs coming up?

46
00:09:30,670 --> 00:09:36,850
Is this a picture in a textbook? Is this you go so then is this you have some imaginary life?

47
00:09:37,090 --> 00:09:44,140
No. More like those. Those, I don't know, commercials or fliers, you see, that are like, this is what could happen if you smoke.

48
00:09:44,320 --> 00:09:48,100
Okay. So this is actually a pretty good example.

49
00:09:48,700 --> 00:09:56,260
What I think you're leaning towards is a belief that that picture will immediately evoke a feeling of disgust.

50
00:09:56,470 --> 00:10:00,850
Right. So there clearly is a emotional reaction to it.

51
00:10:02,680 --> 00:10:08,350
And there is also some potential for you to have conscious, analytical thought about.

52
00:10:09,440 --> 00:10:12,770
Is that what happens to me when I'm somebody who smokes, etc.?

53
00:10:13,040 --> 00:10:23,050
So the same stimulus has some potential to be generating emotions and partnerships.

54
00:10:23,060 --> 00:10:27,590
So in that case, you're basically making the argument that it's primarily an emotional one, and that's fine.

55
00:10:27,590 --> 00:10:29,500
But what notice what I'm saying to you,

56
00:10:29,510 --> 00:10:40,309
like you got to be concrete about how do you think this stimulus is going to lead to analytical thought or lead to emotion or potentially of votes?

57
00:10:40,310 --> 00:10:46,190
But you're going to be concrete about that. What experience will be more like a family member?

58
00:10:46,190 --> 00:10:49,969
You have got cancer and was a smoker.

59
00:10:49,970 --> 00:10:58,670
And so, you know, because it's statistically possible that that was from smoking, that that would be an experiential, the simplest version of this.

60
00:10:58,670 --> 00:11:02,720
Yes, you have a family member. They smoked.

61
00:11:03,470 --> 00:11:09,520
They had a bad thing happen to them. If you attribute to that form that is experiential.

62
00:11:09,770 --> 00:11:15,950
Like you notice the contrast. You had a family member who smoked, who didn't get cancer.

63
00:11:17,110 --> 00:11:21,220
You might have a different level of experience or thought about the risks of smoking.

64
00:11:22,260 --> 00:11:29,970
That is the kinds of stuff we're talking about. Do you want us to only talk about things that increase risk or can we talk about, oh, okay.

65
00:11:30,840 --> 00:11:38,850
So like we had mentioned like bad examples and I'll feel like if someone else had a family member who did smoke and never got it like one night,

66
00:11:38,880 --> 00:11:42,600
if you only told on one side of that or the other, you will be incomplete.

67
00:11:43,850 --> 00:11:51,320
Make sure to pay attention to the things that increase our risk perceptions as well as the things that decrease our risk perception on both sides.

68
00:11:56,400 --> 00:11:59,790
Don't overthink this. This is not actually that complicated.

69
00:11:59,820 --> 00:12:03,330
We've got lots of examples. You're just applying the same idea to a new risk.

70
00:12:06,540 --> 00:12:12,060
Don't feel as though. The other thing is I'm asking for what I'm asking.

71
00:12:12,960 --> 00:12:18,810
Dollar and over anticipate and throw me lots of other stuff that I didn't actually ask for.

72
00:12:19,050 --> 00:12:25,490
This, by the way, is going to be a theme in terms of the assignments for this class. If you are like, Well, we need to give them background.

73
00:12:25,500 --> 00:12:30,210
No, I ask for background, but I asked for the specific thing.

74
00:12:31,320 --> 00:12:42,560
So. Narrow, focused, concrete, good examples, much like what we're doing with these musings, much like what we're doing in the discussion today.

75
00:12:42,950 --> 00:12:44,390
That's really what I'm driving at here.

76
00:12:45,050 --> 00:12:52,850
And the danger that comes up is you get lost in in larger things and you get pulled off into things, which may be true about that risk,

77
00:12:52,850 --> 00:12:59,420
but which don't actually help me know whether or not you're understanding this analytical work experiential distinction.

78
00:12:59,980 --> 00:13:06,050
The last thing I'll say about this is it's only 10.0 panic.

79
00:13:08,360 --> 00:13:11,360
This is getting our our thinking going.

80
00:13:13,280 --> 00:13:18,740
And it's a good first assignment because it helps us make sure that you've got these sort of fundamental ideas in hand.

81
00:13:19,730 --> 00:13:26,809
But if it doesn't, if you don't get it as well as you would like, don't stress about that.

82
00:13:26,810 --> 00:13:33,890
Learn from it. This will hold on to this will be useful as you move into disaster relief.

83
00:13:34,550 --> 00:13:39,800
If as you're I mean, it's not like I'm going to review drafts on it, but if you're going through this over the weekend and you're like,

84
00:13:39,820 --> 00:13:44,420
I'm not sure quite what he was meaning by that, feel free to shoot me an email.

85
00:13:44,420 --> 00:13:51,810
I do not guarantee immediate response. I will respond when I look at my email and I try to do so fairly regularly.

86
00:13:54,550 --> 00:13:58,290
Any other questions? Okay.

87
00:13:59,040 --> 00:14:05,639
All right. So today, obviously, is to some degree an extension of what we were talking about before.

88
00:14:05,640 --> 00:14:09,240
But I really wanted to focus today on this idea of experience, obviously.

89
00:14:10,230 --> 00:14:15,300
And I don't just mean that in the experiential, we have experiential learning.

90
00:14:15,870 --> 00:14:24,900
I want to dove into the human experience of this. What is it like to be at risk?

91
00:14:26,190 --> 00:14:27,690
That is a state of being.

92
00:14:28,290 --> 00:14:38,759
And one of the important things we talk about in this class is, in one sense, we are all always at risk all the time for all kinds of things.

93
00:14:38,760 --> 00:14:42,400
They are either high probability or low probability. They happen, they don't happen, etc.

94
00:14:43,410 --> 00:14:52,260
But we'll find about today is there are some moments when we are aware of that risk.

95
00:14:53,420 --> 00:15:02,230
That something might happen to us. That awareness shapes our behavior, shapes our emotions, shapes our state of being.

96
00:15:04,130 --> 00:15:13,220
And we need to understand and wrestle with what is this thing that is the experience at risk if we're going to talk to people about it.

97
00:15:13,880 --> 00:15:18,620
Because and let me put one of my main points out right up front the fact.

98
00:15:20,070 --> 00:15:28,300
Communicating about risk. Is an intervention on our target audience that changes them for.

99
00:15:35,360 --> 00:15:37,640
We are intervening just as much as a surgeon is.

100
00:15:39,390 --> 00:15:48,960
You can't change someone's life, their decisions, their happiness, their anxiety levels through our messages.

101
00:15:49,650 --> 00:15:55,740
So we better think through what is it is the experience that we are creating and or what is the experience that we are changing,

102
00:15:55,740 --> 00:16:01,290
that we are making better? So there's lots of different examples that you guys came up with.

103
00:16:01,320 --> 00:16:05,940
This was a part of it. Today is a great day from the standpoint of showing why I do the musings.

104
00:16:06,460 --> 00:16:15,090
I've got 12 or 15 and be able to get to a more that I won't get to, all of which are talking about your or your family members or your friends.

105
00:16:15,480 --> 00:16:18,930
Lived experience of what is this thing.

106
00:16:19,560 --> 00:16:23,880
It is about being at risk. I thank you for sharing.

107
00:16:23,970 --> 00:16:27,150
Please feel free to share which or not you're comfortable.

108
00:16:28,770 --> 00:16:33,900
But this is what this this day. And a lot of what this course is about is seeing how this stuff plays out in our lives.

109
00:16:35,490 --> 00:16:38,900
And I want to start, if you don't mind, Elizabeth.

110
00:16:40,650 --> 00:16:44,100
Here you are. You might talk about your experiences. I don't.

111
00:16:47,220 --> 00:16:53,700
So I was talking about when I got diagnosed with diabetes, which was actually just two years ago because I am an outlier.

112
00:16:53,760 --> 00:17:00,870
Normally it's earlier, but and I had a blood sugar that was originally in the four hundreds, which is incredibly high.

113
00:17:00,870 --> 00:17:06,180
And I found out about this completely randomly when I just had a blood test for another condition.

114
00:17:07,050 --> 00:17:11,010
And it took a lot of effort to get my sugars down.

115
00:17:11,010 --> 00:17:16,020
But eventually, after a couple of months, I would start in the somewhat appropriate range of the two hundreds,

116
00:17:16,020 --> 00:17:20,970
and it felt like my doctors were incredibly positive, which I understood.

117
00:17:21,060 --> 00:17:25,200
But at the same time, what I kept focusing on was that, all right,

118
00:17:25,410 --> 00:17:37,110
I am giving a lot of pulses of insulin and taking a lot of blood sugar tests and waking up in the middle of night when I'm getting alarm saying,

119
00:17:37,410 --> 00:17:45,360
Oh, sugar is high, or sometimes your sugar is low. And sometimes one of the hardest parts was not even feeling normal.

120
00:17:45,870 --> 00:17:48,929
I don't like to use that term, but when my friends would say,

121
00:17:48,930 --> 00:17:55,110
We're going out for ice cream and I'd be sorry I can't have ice cream, that makes my sugar too high and.

122
00:17:56,960 --> 00:18:03,560
The sense that I doctors could not understand that there was more to it than just the numbers of my blood sugar.

123
00:18:03,870 --> 00:18:07,850
There were other things to consider in how this was impacted me.

124
00:18:09,420 --> 00:18:20,150
Yeah, I think. I can't. Overstate how much your experience mirrors that of so many people I have talked with about.

125
00:18:21,080 --> 00:18:26,450
There are many different kinds of diagnoses, many different kinds of drugs through medical issues.

126
00:18:28,250 --> 00:18:35,430
I'm just going to tick off a few things. It's not just the numbers, even though the conversation is often about the numbers.

127
00:18:37,710 --> 00:18:45,360
The loss, and I'll use this word intentionally, the grieving of the losses of your life,

128
00:18:45,360 --> 00:18:53,190
the way in which one's life has been changed by the fact that now you have this thing, which, by the way, it's also taken off.

129
00:18:53,820 --> 00:18:59,850
You didn't experience the thing. You picked it up because somebody ran a test and came back with a number.

130
00:19:00,330 --> 00:19:03,570
So you weren't feeling awful when this whole journey started.

131
00:19:05,220 --> 00:19:13,710
But now, because some person somewhere has said you are at risk, your life has changed.

132
00:19:15,140 --> 00:19:23,840
That is a common story and it is the product of presentation.

133
00:19:26,090 --> 00:19:31,760
So all of what we need to talk about, I mean, that doesn't mean you're not motivated to manage your condition.

134
00:19:31,760 --> 00:19:36,410
That doesn't mean it was wrong to engage in this conversation about risk, but it does mean it has costs.

135
00:19:37,580 --> 00:19:45,620
Those costs are real. Engage with that as we think about when is it appropriate to do what kind of communication, etc. What are our goals?

136
00:19:50,630 --> 00:19:53,630
Let. That's.

137
00:19:56,770 --> 00:20:04,810
You were talking about skin cancer risk and sort of dual sources of inspiration,

138
00:20:05,260 --> 00:20:11,229
one being much more sort of analytical and in terms of academic knowledge and the other being interactions with your family.

139
00:20:11,230 --> 00:20:14,410
And that sets up a nice contrast that I want to talk about.

140
00:20:15,330 --> 00:20:21,320
Yeah. So I just kind of wrote about how growing up my family didn't really have, like, sunscreen culture.

141
00:20:21,340 --> 00:20:28,740
Like, it wasn't like part of our life. Like, not really use sunscreen if I didn't do it growing up and we're still kind of exposed.

142
00:20:28,750 --> 00:20:35,590
Like when I go to the dermatologist for something unrelated, I would see pictures of different stages of skin cancer,

143
00:20:35,590 --> 00:20:43,419
but didn't really feel like it applied to me since my dad members were fine and they didn't use sunscreen when I was my wife,

144
00:20:43,420 --> 00:20:46,780
you know, didn't move me to action or anything.

145
00:20:47,200 --> 00:20:50,049
But then when I was in college, I'm about chemistry major.

146
00:20:50,050 --> 00:20:59,530
So my first like some molecular biology class really getting into the molecular level of what happens from repeated sun exposure.

147
00:20:59,530 --> 00:21:05,969
So learning about how your DNA like literally changes and exposure can lead to skin cancer.

148
00:21:05,970 --> 00:21:07,580
And then I was like kind of worried.

149
00:21:07,580 --> 00:21:15,940
So I started wearing sunscreen a lot and I try to diligently still do that and tried to communicate some of those risks, I guess, to my family.

150
00:21:15,940 --> 00:21:23,889
But they really were really feeling it like my grandpa, who was 80 years old, but he, like every day in the summer,

151
00:21:23,890 --> 00:21:29,469
mows a bunch of lawns and was always, you never wear sunscreen and never got skin cancer.

152
00:21:29,470 --> 00:21:38,680
So. It's usually like what they say. So the reason I want to share your example is the beginning part of your story.

153
00:21:38,950 --> 00:21:44,950
The academic side is sort of the prototype for what we might think of as public health communication.

154
00:21:46,000 --> 00:21:53,440
You weren't given facts about how sun exposure causes changes in your skin that might lead to cancer,

155
00:21:53,770 --> 00:22:00,670
and that motivated you as an individual to change your behavior in ways to protect yourself against this risk.

156
00:22:01,120 --> 00:22:07,450
But if you want to talk about the prototype of, hey, let's give people information and hopefully that will make them safer.

157
00:22:07,870 --> 00:22:14,079
That's the story. And then we have your grandfather, for whom that information changed.

158
00:22:14,080 --> 00:22:17,680
Nothing. Why?

159
00:22:18,580 --> 00:22:22,870
Because they have lived their whole life and they have been exposed and nothing bad happened

160
00:22:22,870 --> 00:22:26,859
to them and sound like this experiential learning stuff we were talking about on Tuesday.

161
00:22:26,860 --> 00:22:33,490
Of course it does. So. That is also true.

162
00:22:35,780 --> 00:22:44,540
Your grandfather does not have skin cancer. That truth is a powerful part of the pushback against the analytical knowledge that we have.

163
00:22:46,300 --> 00:22:55,910
So. None of this surprises me because I have no expectation that analytical knowledge is always going to be persuasive.

164
00:22:56,690 --> 00:23:01,970
But we have to recognize that both things can, under some circumstances, shape our behaviors.

165
00:23:03,500 --> 00:23:07,819
And in this case. Yeah, you're having a conversation.

166
00:23:07,820 --> 00:23:13,520
Maybe. Maybe there are other things that may ultimately change your family member's behavior or not.

167
00:23:13,670 --> 00:23:16,160
But that's. This is the problem that we all face.

168
00:23:19,330 --> 00:23:23,920
And by the way, today I'm just going to be hitting on a topic and moving on because I got so many to run through.

169
00:23:25,570 --> 00:23:25,990
Yeah.

170
00:23:28,000 --> 00:23:35,110
You talk about social networks and the connections between people and how that influences risk, and that's seems like a nice transition from this.

171
00:23:36,130 --> 00:23:42,250
So learning that you say that because I had the same thought in my head, so I'm glad to know we're on the same page.

172
00:23:42,280 --> 00:23:48,700
Yeah. So my example, for those who are sensitive to the subject, I'm going to be talking about suicide.

173
00:23:50,710 --> 00:23:56,800
This came to the forefront of my mind because my neighbor actually died of suicide this week.

174
00:23:57,670 --> 00:24:04,660
And she leaves behind a 13 year old and a husband. And my own mother died of suicide in 2015.

175
00:24:05,320 --> 00:24:17,080
And what I talked about is, as someone who is I inherited those mental illnesses from my mother and as somebody who is living with those conditions,

176
00:24:17,080 --> 00:24:21,399
something that I think specifically with mental illness that people tend to forget

177
00:24:21,400 --> 00:24:29,250
is that you're still you you're you still have your your brain and your know,

178
00:24:29,260 --> 00:24:32,220
your rationale and all of this logic.

179
00:24:32,230 --> 00:24:41,889
It's just that the mental illness itself disrupts your the organ that essentially helps you make decisions and be rational and all of those things.

180
00:24:41,890 --> 00:24:48,880
So it's like you as the person experiencing mental illness might feel like you're making rational decisions.

181
00:24:49,750 --> 00:24:55,480
For example, like my mother made the decision to go cold turkey off of her.

182
00:24:56,940 --> 00:25:01,290
Medications because she felt like they weren't servicing her.

183
00:25:02,490 --> 00:25:10,290
And I feel like if there were better conversations around risk or what I brought up was that.

184
00:25:12,460 --> 00:25:16,020
So much of our experience can be shaped by our family members.

185
00:25:16,030 --> 00:25:22,959
And I think of that conversation, Cindy, that you had with your grandfather, that maybe the conversation about sunscreen didn't work.

186
00:25:22,960 --> 00:25:30,550
But there are other conversations that we can be having. And I specifically related it to the MANHEIMER article, because in that article,

187
00:25:30,550 --> 00:25:34,750
that's the one where he's the doctor and he gets cancer and now he's a patient.

188
00:25:35,740 --> 00:25:40,569
And he specifically talks about how he wanted to die, he wanted to give up treatment.

189
00:25:40,570 --> 00:25:46,390
And even though it was not a rational, you know, the statistics were on his side, but he just gave up.

190
00:25:46,630 --> 00:25:51,220
But his wife was the one who convinced him otherwise.

191
00:25:51,250 --> 00:25:56,290
And so I sort of tied that experience to my lived experience and thought, you know,

192
00:25:56,290 --> 00:26:03,960
maybe if we had more conversations or if we reframed who the audience of our risk communication is like,

193
00:26:04,000 --> 00:26:10,809
the audience doesn't always have to be the person who's directly at risk, can be people related to them who have influence.

194
00:26:10,810 --> 00:26:17,380
And maybe it's not just family, maybe it's our friends or, you know, community leaders or people who are important to us.

195
00:26:18,490 --> 00:26:21,550
So there was so much packed into what you just shared.

196
00:26:23,970 --> 00:26:33,450
Certainly I want to start by acknowledging the last point, because there are so many people who affect an individual's experience of risk.

197
00:26:33,660 --> 00:26:40,799
There is the family members. There is. I mean, if we go back to the, you know, friends asking about going out for ice cream,

198
00:26:40,800 --> 00:26:45,520
that is another component of, you know, is that shared with them?

199
00:26:45,540 --> 00:26:51,840
How do they react to that? How does that how do you feel? Do you put yourself at risk because you want to maintain their social connection?

200
00:26:54,390 --> 00:27:09,360
There is additionally the you bring up this reality that the same risk looks different when you are the one who are experiencing the

201
00:27:09,360 --> 00:27:19,229
potential consequences of that thing versus someone outside looking at that situation from their perspective where they may care about you,

202
00:27:19,230 --> 00:27:22,070
but they are themselves not going to experience.

203
00:27:24,460 --> 00:27:33,760
And in fact, there is a literature I have contributed to this to some degree on what are referred to as self other differences in risk perceptions.

204
00:27:34,570 --> 00:27:41,360
The same risk is looked at. I might put myself at this risk, but I won't put my kid at that risk.

205
00:27:42,050 --> 00:27:48,920
I think about childhood vaccination contact. Parents will put themselves at that risk, but they won't put their kid at risk or vice versa.

206
00:27:49,000 --> 00:27:56,630
It depends a lot on how get framed. But the point about, you know, how is this seen from when you're the one experiencing it?

207
00:27:58,010 --> 00:28:10,700
Is part of your your sharing of issues, of management, of medications for long term conditions.

208
00:28:10,700 --> 00:28:15,740
And do I need this? And when does it feel like I have to get off of this?

209
00:28:16,800 --> 00:28:21,400
Well from the outside might look at that and go.

210
00:28:22,020 --> 00:28:27,600
Course they need to be on. This is a major risk though it affects them from the inside.

211
00:28:28,790 --> 00:28:33,740
You are experiencing what that medication or that treatment is doing to you?

212
00:28:34,040 --> 00:28:43,150
Yeah. Can I just share very quickly that the reason my mother stopped taking her medications, something that she knew the risks.

213
00:28:43,160 --> 00:28:49,700
But she's the mother of five and she had brain fog, really intense, bad memory loss.

214
00:28:50,180 --> 00:28:54,530
It was just incompatible. And she felt like she couldn't speak to her doctors about it.

215
00:28:54,670 --> 00:29:05,450
Yeah. And variants of that story unfold, I mean, unfortunately, often in medications or treatments for various forms of mental illness.

216
00:29:05,720 --> 00:29:09,380
Certainly I've heard variants of that for that story regarding schizophrenia.

217
00:29:11,920 --> 00:29:21,760
But even other things, I mean, one of the most commonly prescribed medications stands to reduce cholesterol levels.

218
00:29:23,140 --> 00:29:24,760
Statins do have side effects.

219
00:29:25,180 --> 00:29:32,170
One of the most common experiences is it's down, get started and discontinued within the first six months because of the side effects.

220
00:29:32,770 --> 00:29:38,530
And if we don't have that conversation about the lived experience of my life is

221
00:29:38,530 --> 00:29:43,989
being changed because I'm taking this damn bed versus this downstream risk,

222
00:29:43,990 --> 00:29:52,490
which might happen to me or might not happen to me. We're not actually engaging in the experience of the true risks which are in competition to each.

223
00:29:54,750 --> 00:29:59,520
So that's, again, a story that unfolds in many, many contexts. I have my own variant of this story.

224
00:30:02,670 --> 00:30:06,930
I've already told you that I went through the transplant.

225
00:30:08,100 --> 00:30:13,140
Something which truly could have killed me. I.

226
00:30:14,280 --> 00:30:17,100
Looking back on it now, recognize it much better than I did in the moment.

227
00:30:17,730 --> 00:30:25,350
I had a very different perspective on that choice than my parents did for my parents.

228
00:30:26,280 --> 00:30:29,609
There was never a question in their mind that I was going to go forward and do the transplant.

229
00:30:29,610 --> 00:30:32,520
It was the only way that their kid would be saved.

230
00:30:33,860 --> 00:30:39,860
I was looking at all these experiences of people suffering through the chemotherapy and all of the pain

231
00:30:39,860 --> 00:30:46,750
and all of the cost that would come through going through that and I almost talk myself out of it.

232
00:30:47,420 --> 00:30:54,920
There is literally a moment when my wife talked to me out of it, much like MANHEIMER talk and my first wife talked him out of it.

233
00:30:57,330 --> 00:31:03,390
I eventually did the transplant. That is why I am here. I have a full understanding of.

234
00:31:04,690 --> 00:31:10,630
The fear that comes with facing those kinds of risks, the cost that comes with experience of certain types of things,

235
00:31:11,410 --> 00:31:14,710
and the ways in which that can help you to make one decision versus another.

236
00:31:16,330 --> 00:31:20,680
This is hard stuff and I want us to make the own that.

237
00:31:20,680 --> 00:31:25,570
There is no such thing as a simple, oh, of course you're going to do this kind of situation here.

238
00:31:27,430 --> 00:31:35,560
And that's part of the challenge that we face, even if it's something as simple as, hey, I want to make sure you get a COVID 19 vaccine booster.

239
00:31:38,840 --> 00:31:41,870
Because there's still pieces of this in that kind of a decision.

240
00:31:45,840 --> 00:31:53,880
Thank you, by the way. Speaking of COVID, I was like four or five people who talked about COVID in different ways.

241
00:31:53,900 --> 00:31:59,920
I want to touch upon a few of them. And let's start with Sara.

242
00:32:00,820 --> 00:32:08,200
Yeah. You brought up in particular this idea of the thing that I'm hooked on from your music was this idea of the

243
00:32:08,200 --> 00:32:13,540
importance of trusted leaders in communities and how that plays into the way in which we think about COVID.

244
00:32:16,740 --> 00:32:28,920
So I wrote about I used to be someone who managed COVID 19 outbreaks in childcare facilities, so I would provide guidance to care providers.

245
00:32:28,920 --> 00:32:34,380
Daycare providers are supposed to give that guidance to parents, but the issue tends.

246
00:32:37,410 --> 00:32:48,890
It's hard when actually it's hard when when giving guidance care providers and they're the ones who are trusting us to give information.

247
00:32:49,370 --> 00:32:54,590
And then parents are believing that because they're already on the flip side

248
00:32:54,600 --> 00:33:00,150
when we're managing minority groups and try to get them to get vaccinated,

249
00:33:02,010 --> 00:33:07,860
because there are a kind of sharing of historical risk of syphilis study that.

250
00:33:09,020 --> 00:33:13,860
They don't to the safety of the vaccine.

251
00:33:14,610 --> 00:33:20,730
So we gather in community leaders who work with those groups and say like, hey, you've been vaccinated, you should trust them.

252
00:33:21,810 --> 00:33:24,020
Enough information of this vaccine is safe.

253
00:33:25,050 --> 00:33:33,210
That's just the dichotomy that it's a lot of distrust within government officials to try to get guidance to data provider sources,

254
00:33:34,530 --> 00:33:37,740
giving information to leaders who can't connect to this.

255
00:33:39,090 --> 00:33:43,290
Yeah, I mean, one thing I do want to, at least from my perspective, I don't necessarily think is that.

256
00:33:45,230 --> 00:33:48,500
You know, people's awareness of the historical pattern.

257
00:33:49,460 --> 00:33:56,660
It's not that they aren't aware of the positive benefits. It's just that that that experience is another risk that they take seriously.

258
00:33:57,890 --> 00:34:08,000
They look at that history for fair reasons and say historically there were moments in time when government officials,

259
00:34:08,000 --> 00:34:11,810
when health leaders said that it was going to be okay and it wasn't.

260
00:34:12,260 --> 00:34:17,690
And I have to incorporate that in my sense of safety or lack thereof in this moment.

261
00:34:19,010 --> 00:34:26,299
And. The strategy of saying, well, okay, I can stand here all day and say to you that this vaccine is safe,

262
00:34:26,300 --> 00:34:32,820
but I am not the person who is going to be able to shoot. Feel like I have acknowledged this historical background.

263
00:34:33,150 --> 00:34:38,700
We need people who you look at and say, You are like me, you are a leader who I look up to.

264
00:34:38,700 --> 00:34:42,210
That can be a community leader. I could be a religious leader.

265
00:34:42,510 --> 00:34:52,700
Like it's different for every context. But the role of the author who has looked at the risk and said, yes,

266
00:34:52,700 --> 00:34:57,530
this is something that I am willing to engage in, is a powerful influence on our behavior.

267
00:34:57,560 --> 00:35:07,550
Now, I want to say a caveat here. If we get in the business of saying.

268
00:35:09,740 --> 00:35:13,010
Well, they thought it was okay. So you should too.

269
00:35:14,700 --> 00:35:21,540
It is almost always going to fail. It's going to fail because.

270
00:35:23,700 --> 00:35:27,480
We care about our own autonomy. Be able to make our choices.

271
00:35:27,810 --> 00:35:36,840
And just because some expert somewhere or even just because my religious leader or my congressperson or my neighbor says,

272
00:35:36,840 --> 00:35:41,260
well, I think it's good if I don't think I have a choice that.

273
00:35:43,950 --> 00:35:50,609
So there's lots of situations in which all the health care industry basically said, Oh,

274
00:35:50,610 --> 00:35:54,870
well, you accepted a risk this small before, therefore you should be fine with this one.

275
00:35:56,640 --> 00:36:03,110
I'm going to. Just because somebody has accepted one arrest never guarantees that they will accept another.

276
00:36:04,820 --> 00:36:10,400
And allowing people to have that sense of, I can make my own choice.

277
00:36:11,030 --> 00:36:17,020
One of the things I feel is really important. It doesn't mean that we don't want them to make a particular choice.

278
00:36:17,030 --> 00:36:24,080
It doesn't mean that that background is irrelevant. I certainly agree with you in a sense that engaging with those community leaders,

279
00:36:24,110 --> 00:36:27,680
being able to have those people be part of the conversation is critical.

280
00:36:28,460 --> 00:36:34,340
To be able to get people's trust, to get the information, to even just listen to in the first place.

281
00:36:35,120 --> 00:36:42,500
But that doesn't mean that they're automatically going to say yes. So.

282
00:36:46,640 --> 00:36:54,530
Connect the dots from a couple of different things. We talked about sort of the costs of risk we've talked about covered a little bit, you know.

283
00:36:55,970 --> 00:37:03,140
I remember correctly you were musing about sort of I sort of have these shorthand notes and I know I'm not capturing it all,

284
00:37:03,770 --> 00:37:10,800
but my notes are basically saying sort of the human cost of the things we are giving up and

285
00:37:10,820 --> 00:37:14,930
changing in our lives as a result of COVID and the way that plays into the COVID decision making.

286
00:37:14,930 --> 00:37:21,739
And I want to make sure we come back to that point. Yeah, I was writing and playing it up,

287
00:37:21,740 --> 00:37:27,530
but I was thinking about the discussion and like the Adam Grant New York Times piece

288
00:37:27,530 --> 00:37:34,100
about the use of fear and communications and how that necessarily work as well for COVID.

289
00:37:34,640 --> 00:37:45,200
And I was kind of reflecting on how dangerous your communication is with COVID because of how traumatizing the experience is for everyone,

290
00:37:45,200 --> 00:37:50,960
especially because some of the interventions that they brought up that would be effective fear,

291
00:37:51,080 --> 00:37:54,290
communication or things like wearing a seatbelt or smoking cessation.

292
00:37:54,290 --> 00:38:01,670
But some of the interventions for COVID really don't see your loved ones or visit your loved ones in the hospital when they're going to die.

293
00:38:02,180 --> 00:38:11,330
And so it kind of also made me think back about the something from Monday or Tuesday about kind of

294
00:38:12,110 --> 00:38:20,290
ensuring that you consider the risk of fear and kind of like the terror caused by the war on terrorism.

295
00:38:21,980 --> 00:38:27,170
And even if it isn't, I just want to before we get into the details here and I want to spend some time talking about this,

296
00:38:28,310 --> 00:38:30,020
even if it isn't fear analytically,

297
00:38:30,020 --> 00:38:38,480
you might be sitting there very consciously and analytically saying, I know that my I have 80 year old parents who live near me.

298
00:38:38,690 --> 00:38:46,580
I know that my 80 year old parents, if they get COVID, are particularly likely to experience serious disease or might die from it.

299
00:38:47,210 --> 00:38:51,860
I know that I don't want that to occur. I know that one way to protect that is not to see them.

300
00:38:52,100 --> 00:38:57,680
That's all very analytical. It's logical, it's still costly, it's still real.

301
00:38:59,000 --> 00:39:06,020
And when we put in place a policy that says, no, you can't go see someone in a particular context,

302
00:39:06,410 --> 00:39:12,260
not only are we having an effect on the likelihood of transmission of COVID,

303
00:39:12,260 --> 00:39:16,610
we are having an effect on the social bonds between those people who are having an effect on mental health.

304
00:39:17,030 --> 00:39:23,010
We are having an effect on. The lives of all the people who are affected by the.

305
00:39:23,900 --> 00:39:27,020
That's where I want to go with this. Take a moment.

306
00:39:28,420 --> 00:39:32,200
Think back. It's March 2020.

307
00:39:34,530 --> 00:39:39,120
Over is just starting to happen, starting to really affect lives.

308
00:39:39,240 --> 00:39:47,520
I remember the day Michigan sort of went into, okay, we are going to take this seriously, we're going to start shutting things down, etc.

309
00:39:51,980 --> 00:39:56,630
All place herself in that moment. What was the experience?

310
00:40:00,050 --> 00:40:06,080
Do you remember about the experience of that moment in time when you felt maybe you felt at risk,

311
00:40:06,740 --> 00:40:09,890
maybe you didn't feel at risk, but we were certainly talking about risk.

312
00:40:13,070 --> 00:40:19,400
Yeah. I honestly, I was like on campus when we got the notification, I was honestly like,

313
00:40:19,730 --> 00:40:26,620
So what about the rest of the school you like I didn't even think about like, oh, like so are we not going to school?

314
00:40:26,750 --> 00:40:30,860
Yeah, I was more confused then. I was like, scared.

315
00:40:31,670 --> 00:40:35,410
Like, what does this mean? I really think this is important.

316
00:40:35,540 --> 00:40:45,580
So go ahead. Oh, yeah. And seeing the grocery stores empty, that was more scary for me than, like, the risk of actually catching COVID in Michigan.

317
00:40:45,610 --> 00:40:51,190
I still have a picture of the first time I went to Trader Joe's in Ann Arbor after all the shutdowns started happening.

318
00:40:52,000 --> 00:40:55,750
Normally go in Zippy and I couldn't get in and out of that place in 15 minutes.

319
00:40:56,290 --> 00:40:59,350
I waited an hour and 20 minutes before I got in the door.

320
00:41:02,490 --> 00:41:09,740
My life was disrupted. Your life was disrupted. That is just as much a risk that we need to talk about as anything else.

321
00:41:11,320 --> 00:41:17,050
But I remember when the shutdowns happened and there were a whole lot of really pissed off business owners.

322
00:41:19,350 --> 00:41:22,020
And there were some people were like, Come on, we have to do this right.

323
00:41:22,150 --> 00:41:26,370
And I'm not diminishing in any way the public health importance of minimizing the spread of COVID,

324
00:41:26,370 --> 00:41:32,970
etc., etc., etc. This is their life, their job, their business, their income.

325
00:41:33,480 --> 00:41:37,980
That is just as much part of the risk, part of the disruption of their lives as everything else.

326
00:41:39,530 --> 00:41:43,010
And when we say to somebody, no, you have to shut down.

327
00:41:43,220 --> 00:41:46,880
You can't have your business open. You can't do X, Y or Z.

328
00:41:47,840 --> 00:41:56,389
That is part of the risks that we are talking about. So when we had this unfold, we had people.

329
00:41:56,390 --> 00:41:57,880
Just once we had people.

330
00:41:59,170 --> 00:42:08,560
Essentially faced with huge disruptions to their sense of personal safety and huge disruptions to everything else that they cared about in life.

331
00:42:10,420 --> 00:42:16,800
Somehow we had to choose. And one has to acknowledge here is that not everybody's gonna make the same choice.

332
00:42:16,820 --> 00:42:21,260
It's not that we don't see these risks. It's that they are both weighing on us.

333
00:42:22,040 --> 00:42:27,140
And what, based upon our values, our situations, etc., where we are prioritizing one versus the other.

334
00:42:28,040 --> 00:42:34,560
Yeah, I was using the thing like Dumbo that woke us back in 2020.

335
00:42:34,580 --> 00:42:40,630
I am doing my last year of my nursing school. I'll be required to have certain hours of practice.

336
00:42:40,640 --> 00:42:49,010
Are at the hospital. Yeah. When that thing hits where most of us are not able to finish the required clinical hours on time.

337
00:42:49,430 --> 00:43:02,809
Our concern is, can we graduate? And then we we feel like as donors, we feel we are capable to handle or be part of the COVID crisis by the hospital.

338
00:43:02,810 --> 00:43:04,850
And the school thing is, is not safe. Yup.

339
00:43:05,540 --> 00:43:11,330
And by the way, let's also acknowledge the other flipside, whether in the health care system or in the grocery store,

340
00:43:12,020 --> 00:43:20,960
at that moment in time, you had people whose livelihood, whether that as a student, whether that as in their job, etc.

341
00:43:22,650 --> 00:43:27,090
Forced themselves into positions they knew were risky.

342
00:43:27,960 --> 00:43:36,950
They knew they were going to be exposed. And that is a different kind of experience than one that we voluntarily choose.

343
00:43:38,480 --> 00:43:46,490
If I choose to go and sit in a restaurant and essentially pick my mouth open and potentially be exposed,

344
00:43:47,030 --> 00:43:53,060
that is a different kind of experience than the grocery store worker who has to be standing

345
00:43:53,450 --> 00:43:59,030
four feet away face to face with a whole slew of people for 8 hours a day checking people out.

346
00:44:01,440 --> 00:44:04,470
They were. I mean, we adopted the.

347
00:44:05,530 --> 00:44:11,080
Marketing language of calling people like grocery store workers, frontline workers, and they are in that sense.

348
00:44:11,470 --> 00:44:17,840
But it's important that we acknowledge that is their own risk experience, because it's not just they know that they are being exposed.

349
00:44:17,900 --> 00:44:19,030
They didn't have a choice in the matter.

350
00:44:22,500 --> 00:44:31,739
Just like health care workers who were, in fact seeing COVID patients and are seeing COVID patients don't have that choice in the sense of,

351
00:44:31,740 --> 00:44:34,890
am I going to choose to be exposed or not? They face that threat.

352
00:44:35,120 --> 00:44:41,700
Yeah, yeah. That was my experience. I was a resident physician in surgery, so they turned us into a procedure last year.

353
00:44:42,960 --> 00:44:46,670
So we were doing pretty much every procedure on all of the COVID patients.

354
00:44:46,680 --> 00:44:53,670
It was the scariest time in my life. Something completely unexpected was my first year of training ever.

355
00:44:54,270 --> 00:44:57,430
And then I think one of the bigger things, too, is like not even just being scared to to work,

356
00:44:57,540 --> 00:45:01,620
was scared to, like, get groceries because I was afraid of exposing other people.

357
00:45:01,860 --> 00:45:06,299
So it was like this compounding fear at all times of like, I work is risky,

358
00:45:06,300 --> 00:45:10,230
but then like I can exposing other people and like it was just a really challenging.

359
00:45:11,130 --> 00:45:16,230
I remember how working with some of the clinician colleagues of mine very early

360
00:45:16,230 --> 00:45:20,370
and this is why you have to place it in context very early in the pandemic.

361
00:45:21,810 --> 00:45:26,550
Of their habits. On how they hide their fundamental trait.

362
00:45:26,580 --> 00:45:29,400
I remember one person talking about how they.

363
00:45:30,530 --> 00:45:36,200
We go home and they would go in the back door and they would strip off all of their clothes and they would

364
00:45:36,200 --> 00:45:40,610
wash themselves up and they would not actually see their kids because their kids would have gone to bed.

365
00:45:40,790 --> 00:45:46,990
And that was their life for those first few months. Now notice this is both.

366
00:45:48,930 --> 00:45:56,130
Looking back from a historical standpoint, we now know much more about the disease and its forms of transmission.

367
00:45:56,490 --> 00:46:02,520
And some of those behaviors may not seem like, well, maybe they weren't necessary, but we didn't know that then.

368
00:46:02,530 --> 00:46:08,880
So remember I went back to that that uncertainty and the onus is on like we're still up in that unknown space.

369
00:46:09,870 --> 00:46:16,499
And so there's huge amounts of the fear of the experience here is about, I'm going to do this thing.

370
00:46:16,500 --> 00:46:21,549
I don't actually know whether this thing is necessary or not, but at least it's a thing that I can do.

371
00:46:21,550 --> 00:46:30,200
And it's going to give me a sense of control. And we hope that we're picking the things that are going to manage our actual risk.

372
00:46:30,200 --> 00:46:36,189
But part of. Lived experience of risk is that uncertainty?

373
00:46:36,190 --> 00:46:39,250
I don't know whether or not what I'm doing makes a difference.

374
00:46:41,170 --> 00:46:45,310
Now another component. I mean, there's a whole spectrum of stuff here.

375
00:46:45,320 --> 00:46:51,790
This is why this is such a hard day. There's so much content here, like what we're talking about, early COVID.

376
00:46:51,850 --> 00:46:57,370
There's a lot of this uncertainty. There are other risks where we know it's not.

377
00:46:57,640 --> 00:47:03,940
It's just it's random. I know a lot about radar.

378
00:47:05,040 --> 00:47:10,020
I know that living in my house is exposing betray a small but distinct amount of freedom.

379
00:47:10,590 --> 00:47:17,910
I know that on a population level some people are going to get lung cancer caused by radon exposure.

380
00:47:18,480 --> 00:47:21,210
I have no idea whether I'm going to be exposed or not,

381
00:47:21,630 --> 00:47:25,980
and there's nothing I can do other than moving out or trying to do the level of radon I'm exposed to,

382
00:47:26,400 --> 00:47:33,470
to change whether I happen to be one of those people. And so I live with that.

383
00:47:35,070 --> 00:47:39,649
And that's another part of this experience. All right.

384
00:47:39,650 --> 00:47:47,490
Got to keep moving. Erica.

385
00:47:51,160 --> 00:47:55,750
You were talking in your musing about ambassador? Yes.

386
00:47:56,650 --> 00:48:04,360
So my musing was kind of more about people's experiential kind of analysis of risk over the summer.

387
00:48:05,010 --> 00:48:08,920
You know, I guess I would consider her a family friend, but it weren't that close.

388
00:48:08,980 --> 00:48:12,130
She unfortunately contracted COVID and passed away from it.

389
00:48:13,120 --> 00:48:19,389
And she was also friends or acquaintances with some of my family members who tend to buy

390
00:48:19,390 --> 00:48:24,670
more into some of the conspiracy theories surrounding COVID and other things as well.

391
00:48:25,630 --> 00:48:33,390
But when this family friend was in the hospital, she was given remdesivir for treatment, which is, you know, unapproved.

392
00:48:33,400 --> 00:48:43,120
And that you we use treatment for COVID 19. And my family members were just so up in arms about it and saying that that was, you know,

393
00:48:43,600 --> 00:48:51,009
they should she should have been given, like, ivermectin and hydroxychloroquine after she passed away.

394
00:48:51,010 --> 00:48:54,490
They're saying that she shouldn't have been given remdesivir. She should have been given these drugs.

395
00:48:55,720 --> 00:49:01,000
And then also sort of really advocating against you, supreme dose of you're like, nobody should go to the hospital.

396
00:49:01,000 --> 00:49:07,989
You shouldn't really do anything. And if you have COVID besides take, you know, ivermectin or hydroxychloroquine,

397
00:49:07,990 --> 00:49:13,260
because remdesivir in the hospital will kill you because that was their learning experience.

398
00:49:13,280 --> 00:49:22,030
We hadn't really we've been fortunate in that we hadn't really known anyone or experienced or lost due to COVID prior to this person passing away.

399
00:49:22,750 --> 00:49:27,310
So this experience of what happened I mean, let me let me break down the story here.

400
00:49:28,120 --> 00:49:37,150
Person gets sick with COVID. The person engages in a certificate, going to the hospital, taking the medication.

401
00:49:38,560 --> 00:49:43,360
They experience an outcome, in this case a negative outcome.

402
00:49:43,930 --> 00:49:54,030
And also what? We could find thousands of other people whose story is exactly the same, who have positive outcomes, who survive, who move on.

403
00:49:54,210 --> 00:49:58,080
And in fact, the studies show that when you take Remdesivir,

404
00:49:58,590 --> 00:50:04,500
you are more likely to have that positive outcome than if you don't for the appropriate populations.

405
00:50:04,620 --> 00:50:10,520
That's why we do clinical trials. Fundamentally change the reality of this particular story.

406
00:50:11,330 --> 00:50:18,830
This person engaged in this behavior. They had the negative outcome and the experience of your family and.

407
00:50:20,840 --> 00:50:26,520
Such is the causal. Story making, for lack of a better term.

408
00:50:26,940 --> 00:50:30,360
Well, it must be that the hospital is the causal factor.

409
00:50:30,360 --> 00:50:37,100
It must be that this drug is the causal factor. And this other thing might have made a different outcome.

410
00:50:37,550 --> 00:50:42,440
You know, but it might have. This is this incredibly annoying thing about risk.

411
00:50:43,160 --> 00:50:47,830
It could be that that person might have had a different outcome had they gone down a different path.

412
00:50:47,860 --> 00:50:55,939
But we'll never know. All we know is that the population level people who go down this pathway are

413
00:50:55,940 --> 00:51:02,910
more likely to have positive outcomes that people who go down that pathway. You know, we talked about smoking.

414
00:51:04,160 --> 00:51:08,120
Smoking is a causal factor for lung cancer.

415
00:51:09,250 --> 00:51:18,400
And you can always find somebody who smoked 32 packs a day for 30 years when nothing bad happened to them.

416
00:51:18,850 --> 00:51:22,210
For a lung standpoint, they exist. You can always find them.

417
00:51:23,800 --> 00:51:27,270
You want to talk about cancer screening? Want to talk about.

418
00:51:28,550 --> 00:51:36,770
Why do we have, for example, age ranges for cancer screening like we don't have widespread mammography for 35 year olds?

419
00:51:37,610 --> 00:51:42,350
Because it's not cost effective, because it will cause potential harms from exposing people to the radiation.

420
00:51:43,800 --> 00:51:50,010
But then you find a 35 year old woman whose life would have been saved by having a mammogram.

421
00:51:50,190 --> 00:51:53,490
Absolutely. You can always find those cases.

422
00:51:55,690 --> 00:51:59,740
This population to individual thing is.

423
00:52:00,790 --> 00:52:05,460
Nearly half. Because the experience of risk is outcomes.

424
00:52:06,390 --> 00:52:11,790
I see this person for, you know. Not surviving COVID.

425
00:52:12,880 --> 00:52:16,780
Despite the fact that they engage in behaviors of behavior.

426
00:52:19,050 --> 00:52:29,460
And yet we've got to turn around like the doctor in the Curzon story and make the same call for the next patient.

427
00:52:30,850 --> 00:52:36,490
And say to the next patient, you have COVID, you should take Remdesivir, this would help you, etc.

428
00:52:39,310 --> 00:52:43,630
And when the next patient looks back at the previous one and says, Yeah, but they died,

429
00:52:44,560 --> 00:52:50,800
we somehow have to be able to say, I know, and I still believe this is the right choice.

430
00:52:53,400 --> 00:53:00,549
And that's hard. This is what I'm going to talk about in a little bit.

431
00:53:00,550 --> 00:53:05,650
When we when we break up into small groups is the distinction between the individual and the population.

432
00:53:07,020 --> 00:53:09,890
Plus nobody actually experiences.

433
00:53:11,220 --> 00:53:18,600
Probability we fear its risk, but the conscious knowledge of being at risk is a huge thing as all of these stories have talked about.

434
00:53:19,080 --> 00:53:24,450
We don't actually experience probabilities, we experience outcomes. The good thing happens or it doesn't, the bad thing happens.

435
00:53:26,430 --> 00:53:32,710
And. It is our emotions and our cognitions about that uncertainty.

436
00:53:33,070 --> 00:53:40,690
That is what the experience of risk is all about. The I don't know when the next person is going to be the one to give me coke or not.

437
00:53:44,210 --> 00:53:48,590
So yeah, I wanted to make sure we brought this particular story up because it's so common.

438
00:53:49,690 --> 00:53:55,290
And by the way, let's dance. Notice it's not symmetrical. In the sense that.

439
00:53:57,170 --> 00:54:03,380
Since your story is someone who engaged in a preventive behavior or behavior that we might say is a good thing to do,

440
00:54:03,590 --> 00:54:06,890
and yet the bad thing occurred and it's very mentally salient.

441
00:54:07,670 --> 00:54:15,380
Now, let's flip all of those pieces. The people who engage in the bad behaviors.

442
00:54:17,260 --> 00:54:22,600
But by chance and circumstance happen to end up with good outcomes.

443
00:54:22,600 --> 00:54:25,630
We don't tend to have those stories circulated nearly as much.

444
00:54:27,020 --> 00:54:30,530
Yeah. Just going off with sort of my story.

445
00:54:30,530 --> 00:54:34,010
An additional piece is the woman who passed away.

446
00:54:34,040 --> 00:54:37,399
Her entire family also got COVID and they were also all hospitalized.

447
00:54:37,400 --> 00:54:41,870
At the same time. She was a little bit excreting symptoms, a little bit worse than they were.

448
00:54:41,870 --> 00:54:45,859
So she was not necessarily coherent when she consented to Remdesivir.

449
00:54:45,860 --> 00:54:51,559
I don't really know how that all worked up. Her other family members declined it and then they all ended up out of the hospital.

450
00:54:51,560 --> 00:54:55,370
So I think that was something else that came more into that puzzle.

451
00:54:55,370 --> 00:55:02,570
Again, um, but for the airports around this because it's not causal, it's correlational causal outcomes that contribute to that.

452
00:55:02,960 --> 00:55:11,210
But this is of course is the problem. We can't we as an individual could not actually see a large enough sample of

453
00:55:11,210 --> 00:55:15,320
outcomes to have a statistically appropriate understanding of what we saw,

454
00:55:16,340 --> 00:55:20,190
especially when we get to small, small risks. Like.

455
00:55:21,230 --> 00:55:26,960
Maybe we can get a reasonably a statistically sample, good sample of things like, you know,

456
00:55:27,350 --> 00:55:31,400
how likely is it that this milk that smells bad is actually going to make me throw up?

457
00:55:32,390 --> 00:55:35,290
Okay. We could probably get some some real world experience about that.

458
00:55:35,300 --> 00:55:38,660
But if we're talking about other kinds of stuff, we just don't get enough experience.

459
00:55:39,600 --> 00:55:42,179
Even most clinicians don't get enough experience. And by the way,

460
00:55:42,180 --> 00:55:50,250
there's a whole conversation that we could have about how clinical decision making is biased by what happened in the last five patients.

461
00:55:54,100 --> 00:56:03,250
And how hard it is for those who are giving recommendations about risk clinicians and otherwise to not be biased by the last specific instances.

462
00:56:09,610 --> 00:56:16,610
That. I'm just going to bookmark this and move on.

463
00:56:16,640 --> 00:56:22,130
Abby, I know you were talking about very similar kinds of stuff in terms of when we talk about risk factors,

464
00:56:22,550 --> 00:56:26,660
that there are things which are this predicts that,

465
00:56:26,660 --> 00:56:33,770
but it doesn't actually mean that if you have this guarantee, is it because the curves of those probabilities are so overlapping?

466
00:56:34,220 --> 00:56:38,720
I could spend a long time on that. I'm going to skip over it for the moment just because for the purposes of time.

467
00:56:38,720 --> 00:56:45,670
But it's a similar kind of issue like yeah, the mortality curve of smokers versus non smokers are separated.

468
00:56:45,680 --> 00:56:50,150
Mortality is higher in smokers. That doesn't mean you don't have people on either tail.

469
00:56:50,750 --> 00:56:55,910
It doesn't mean it's a perfect predictor. But I want to look forward to.

470
00:56:57,940 --> 00:57:02,660
Kayla. You're saying, Mikael?

471
00:57:03,110 --> 00:57:08,870
Yeah. Sorry. You were talking about appendicitis.

472
00:57:08,950 --> 00:57:16,040
I thought correctly. So I happened to have a particular research connection to this question.

473
00:57:16,040 --> 00:57:21,590
So I want to share what you were talking about. And I wanted to share my that a person I know who was working on this.

474
00:57:21,830 --> 00:57:27,889
Yeah. So I was talking about how like in medicine we try to do everything evidence based and like a good

475
00:57:27,890 --> 00:57:34,850
example of when we rely more on like clinical intuition rather than any sort of testing is appendicitis.

476
00:57:35,270 --> 00:57:41,720
What we do is we calculate an alvarado's score, which is usually based off of a little bit of bloodwork and a really quick physical exam.

477
00:57:42,440 --> 00:57:50,090
And if you meet a certain score based on the criteria, we say, Yep, you have appendicitis and we take you to the ah, the O.R.,

478
00:57:51,620 --> 00:57:56,959
which I said that I think, you know, like when I was working as a general surgery resident, I was like, Of course that makes sense.

479
00:57:56,960 --> 00:58:03,470
We don't need to irradiate everybody. They don't need to get a CAT scan. But then on the other hand, like if I was a patient,

480
00:58:03,470 --> 00:58:08,030
would I feel comfortable just having somebody like Price on my stomach for less than 5 seconds and be like,

481
00:58:08,030 --> 00:58:13,700
Yep, you're going to the gym or you're going to the operating room now, and like how that kind of like dichotomy exists.

482
00:58:13,700 --> 00:58:19,189
And I talked a little bit about my own experiences recently having and EGD and like

483
00:58:19,190 --> 00:58:24,200
I have done those myself multiple times and how I've never thought twice about it.

484
00:58:24,200 --> 00:58:30,750
But then like being in a patient shows, it's kind of really made me rethink some of that risk communication I had done previously.

485
00:58:31,700 --> 00:58:34,070
So the appendicitis example is a really good one.

486
00:58:34,130 --> 00:58:41,180
It's interesting you highlighted the question of how how is a patient going to feel if somebody presses on their belly for 5 seconds and says,

487
00:58:41,180 --> 00:58:45,170
okay, you going to go to the PR? I want to look at the opposite side.

488
00:58:45,530 --> 00:58:48,589
How is somebody going to feel if their stomach is really,

489
00:58:48,590 --> 00:58:55,940
really hurting and somebody presses on their stomach for 5 seconds and runs the blood test that you don't understand and then tells you,

490
00:58:55,940 --> 00:59:02,450
no, actually, you just need to go home. You're going to be fine. Are you okay with that?

491
00:59:04,280 --> 00:59:09,350
Now you push it even a little bit further. Now, imagine it's your two year old infant.

492
00:59:10,560 --> 00:59:18,030
You're okay with that? That is the reality of emergency department diagnoses about appendicitis.

493
00:59:18,930 --> 00:59:23,970
You're going to make those quick judgments based upon evidence. Probabilistically, that's appropriate.

494
00:59:24,550 --> 00:59:28,560
We're not putting people through radiation they don't need we're not putting people in surgery.

495
00:59:28,590 --> 00:59:33,900
Hopefully it is unnecessary, but it's going to be errors on both sides.

496
00:59:33,960 --> 00:59:40,200
We're going to have people who go through surgery who would have been fine. We're going to have people who will get worse because they, in fact,

497
00:59:40,200 --> 00:59:46,410
do have appendicitis that will need intervention and that's going to get delayed or potentially it's going to rupture, etc.

498
00:59:47,550 --> 00:59:52,800
So the reason I happened to know a lot about this discussion is I just like two weeks ago had a conversation with

499
00:59:52,800 --> 01:00:00,150
the commission about their research ground and they are really working on the question of how does this play out?

500
01:00:00,150 --> 01:00:06,690
Not in places like U of M will enroll you down the hall and have an ultrasound or a CT scan done very quickly.

501
01:00:07,110 --> 01:00:11,730
But how does this play out in a community hospital in which your choices might be?

502
01:00:13,590 --> 01:00:20,460
To expose you to a CT scan and all of the radiation and risk that comes with that or send you home.

503
01:00:21,450 --> 01:00:27,600
That's it. No other choices. Ultrasound not available. And how does it feel?

504
01:00:27,610 --> 01:00:31,410
What is the risk tradeoff like? How does the clinician look at that risk tradeoff?

505
01:00:32,400 --> 01:00:39,480
The look at that tradeoff. Really difficult because it's hard to send somebody home.

506
01:00:41,290 --> 01:00:46,599
When you don't know. So this this question of like, when do we do imaging studies?

507
01:00:46,600 --> 01:00:56,170
When do we do tests? Even if that test is probably not going to change what we already believe, that I don't want to be wrong about it.

508
01:00:56,830 --> 01:01:03,880
That contributes a lot to the overtesting and overutilization of screening in certainly in our medical system.

509
01:01:05,300 --> 01:01:10,040
Because we overweight on an expected value basis,

510
01:01:10,460 --> 01:01:16,640
we overweight not being wrong and we underweight the costs of those tests costs

511
01:01:16,640 --> 01:01:21,410
both financially and frankly in terms of downstream risks from radiation exposure,

512
01:01:21,410 --> 01:01:28,760
etc. So when you tell people, hey, yes, I know you're in pain.

513
01:01:30,280 --> 01:01:36,400
Well, we're not going to take you to the are. That's its own very difficult risk communication situation.

514
01:01:40,580 --> 01:01:43,920
Time for one more. Uh oh, yeah.

515
01:01:43,940 --> 01:01:52,310
I got to hit this one. Uh, Joshua, we were talking about false positives.

516
01:01:53,260 --> 01:01:58,270
And that is another experience of risk that we have to talk about today.

517
01:01:59,590 --> 01:02:03,940
Yeah. So when I was 15, I had a false positive for cystic fibrosis.

518
01:02:03,970 --> 01:02:09,970
I was a progressive terminal lung condition, which is not fun to be diagnosed with.

519
01:02:09,970 --> 01:02:16,720
And so I went then had the gold standard test, which is I always had lung issues like pneumonia.

520
01:02:16,720 --> 01:02:21,810
And I think the doctor really just originally schedule the test was like, oh, just kind of double check thing.

521
01:02:21,820 --> 01:02:25,510
And so first of all, chloride test inconclusive or another.

522
01:02:25,720 --> 01:02:29,110
All right, cool. Go back a second. One comes back positive.

523
01:02:29,590 --> 01:02:34,270
The doctor is reasonably sure that cystic fibrosis first can be pamphlets.

524
01:02:34,900 --> 01:02:43,059
Start looking into getting them like there's different treatment options or pretty much just things that can delay negative outcomes.

525
01:02:43,060 --> 01:02:53,350
And so I remember thinking I'm 15 at the time, the letter I was writing, roughly 35 was the life expectancy for someone with fibrosis.

526
01:02:53,350 --> 01:02:56,110
So I was like, All right, I've lived half my life.

527
01:02:56,200 --> 01:03:03,309
And that was pretty devastating at the time, and I didn't really even thought about my own mortality much in death and all that kind of stuff.

528
01:03:03,310 --> 01:03:05,740
And so that really kind of messed me up for a bit.

529
01:03:05,740 --> 01:03:14,469
And fortunately, the doctor, unbeknownst to me, had ordered some kind of either alternative test or alternate look at the second results.

530
01:03:14,470 --> 01:03:19,900
And a couple of weeks later I was told, oh, no test came back, you don't have cystic fibrosis.

531
01:03:19,900 --> 01:03:23,979
And so. I can totally see in his end.

532
01:03:23,980 --> 01:03:28,600
Well, it's like, okay, based on the symptoms that I presented on and my condition.

533
01:03:29,140 --> 01:03:31,270
Oh, yeah. Just try this test. Make sure.

534
01:03:31,270 --> 01:03:36,970
And eventually, like, I mean, there might have been some false positives on the way, but it got to the right stuff and the test was there.

535
01:03:37,240 --> 01:03:42,190
But from my experience of the event, I literally had a trauma response.

536
01:03:42,190 --> 01:03:44,980
It kind of blocked a memory that was unavailable for about a year or so,

537
01:03:45,370 --> 01:03:49,120
and it just kind of really messed me up for a bit and a lot of stress and stuff.

538
01:03:49,120 --> 01:03:55,030
And so it's just kind of the I'm sure the medical doctor analytically was doing all the right decisions.

539
01:03:55,060 --> 01:04:00,549
However, my experience and the communication of the risk was not very good.

540
01:04:00,550 --> 01:04:05,710
And so kind of the dichotomy of that wasn't it? And so a few things I want to highlight here.

541
01:04:05,800 --> 01:04:11,240
One, you've already said this, but let me reinforce it. Those three weeks mess you up.

542
01:04:11,960 --> 01:04:15,590
I talk about a real trauma experience. That is trauma.

543
01:04:18,660 --> 01:04:25,590
And that is something that is always on the table when we talk about changing someone from I am fine to I am not fine,

544
01:04:26,070 --> 01:04:29,380
even though physically your symptoms were not changing in those moments.

545
01:04:29,400 --> 01:04:32,730
It was knowledge. But it was challenging.

546
01:04:33,930 --> 01:04:40,080
To. I really appreciate the way you're sort of framing this from the doctor standpoint.

547
01:04:41,190 --> 01:04:49,890
Yeah, there were reasons why they do what they did. Yeah, they did follow up and hopefully ended up at the correct biological diagnosis.

548
01:04:49,900 --> 01:04:55,380
So in that sense. The process did what it needed to do.

549
01:04:56,780 --> 01:05:01,150
And what I think is important about your story is that doesn't mean it wasn't costly.

550
01:05:01,160 --> 01:05:11,360
That doesn't mean it didn't have an impact on you. Another component of this is.

551
01:05:13,830 --> 01:05:20,100
You know, I don't want to overstate it, but I want to understatement that that phrasing of, you know, I've lived for half my life.

552
01:05:24,000 --> 01:05:31,100
Probabilities are just probabilities. Even that is not actually accurate in the sense that some people who have cystic fibrosis die much earlier.

553
01:05:31,140 --> 01:05:33,360
Some people have cystic fibrosis last much longer.

554
01:05:33,870 --> 01:05:43,320
It's not like because the life expectancy is set, is is on average a certain time, somebody's going to go to their 35th birthday and they die.

555
01:05:43,350 --> 01:05:49,170
That's not the way this works. What you're really talking about is a knowledge that.

556
01:05:51,000 --> 01:05:58,110
Those probabilities have fundamentally shifted. They are much more likely, they are much earlier, etc. And that's fundamentally changing.

557
01:05:58,920 --> 01:06:05,820
Not just am I going to be healthy, but priority is what you choose to do in life, etc.

558
01:06:09,630 --> 01:06:11,310
Now your case is extreme.

559
01:06:11,340 --> 01:06:17,430
When we talk about diagnoses like cystic fibrosis or other kinds of terminal conditions, that's obviously on the extreme end of this.

560
01:06:19,520 --> 01:06:26,900
But let's pause for a moment and talk about the likelihood that somebody actually only framed it in Utah.

561
01:06:27,560 --> 01:06:32,450
The likelihood that you at some point in time in your life.

562
01:06:33,480 --> 01:06:41,010
As we go through all of the tests that we do on as part of regular medicine will experience a false positive.

563
01:06:43,980 --> 01:06:48,930
It's not small. And now.

564
01:06:50,120 --> 01:06:54,290
Think about this, I'll use the example of mammography because it's a good example.

565
01:06:54,290 --> 01:07:01,670
It's by no means the only example. How many mammograms is a woman likely to do if they follow the appropriate guidelines?

566
01:07:02,350 --> 01:07:08,089
Okay. You're going to start at depending upon shared decision making, somewhere between 40 and 50,

567
01:07:08,090 --> 01:07:11,970
certainly by 50, you're going to be doing mammograms every two years.

568
01:07:11,990 --> 01:07:18,470
Usually, I think some people will do them even more frequently than that. But we're looking at a minimum of something like.

569
01:07:19,890 --> 01:07:24,240
12 to 15 mammogram over the course of a woman's life, possibly more.

570
01:07:25,210 --> 01:07:28,510
Each one of those has a chance of kicking back at false positive.

571
01:07:29,110 --> 01:07:33,650
Those probabilities are cumulative. And if you do.

572
01:07:35,050 --> 01:07:39,730
You're going to have a three weeks like what Joshua did.

573
01:07:41,450 --> 01:07:45,139
Where you're going to go back and have a second mammogram or maybe you're

574
01:07:45,140 --> 01:07:48,350
going to have a second mammogram and then you're going to have a biopsy done.

575
01:07:48,350 --> 01:07:52,670
And only after that needle is inserted are you going to find out that, no, this isn't cancer.

576
01:07:53,030 --> 01:07:59,700
And in the interim, you're going to believe. You might have a chance.

577
01:08:03,020 --> 01:08:09,980
This is another part of the cost of the screening regimens that we put in place to make our lives.

578
01:08:11,440 --> 01:08:15,700
More likely to be law and more likely to be cancer free.

579
01:08:17,680 --> 01:08:22,900
And yet it is part of the human cost of the risk management that we do as a society.

580
01:08:26,130 --> 01:08:31,020
The evidence about what happens when someone experiences a false positive is pretty clear.

581
01:08:32,380 --> 01:08:40,270
Likelihood of returning for your next mammogram drops rather significantly because people go, I don't want to go through that again.

582
01:08:43,980 --> 01:08:51,900
So here's the one. Here's the piece that I'm going to that's really ethically difficult to wrestle with.

583
01:08:53,630 --> 01:09:01,670
Imagine, Joshua, what would have happened had they never told you about the result from the positive test until they had run the next one?

584
01:09:02,240 --> 01:09:15,590
I think about that. And yet that violates so much of our principles of transparency and right to own access to your medical records,

585
01:09:15,590 --> 01:09:25,100
etc. And yet your life would have been much better in an important way had you not been exposed to that information.

586
01:09:25,940 --> 01:09:27,710
There's no easy solution to that one,

587
01:09:28,520 --> 01:09:34,040
but it's something that I think we all have to wrestle with as we think about what is the impact of presenting somebody with risk information,

588
01:09:34,340 --> 01:09:39,840
especially information that says. This might be the case and.

589
01:09:41,280 --> 01:09:50,580
We have a newborn screening test run on every single birth in the country, and there are false positives that kick out of that a daily basis.

590
01:09:51,920 --> 01:09:57,170
I've seen some of the stories of people who experience. Does that mean we stopped doing newborn screening?

591
01:09:58,070 --> 01:10:04,250
No, but but this is a both a difficult day and an important one,

592
01:10:04,250 --> 01:10:10,700
because there's so much complications in terms of this question of when is providing the information Fed, when, when does it help?

593
01:10:11,690 --> 01:10:16,610
When does it harm? And how do we wrestle with that population level truth?

594
01:10:18,000 --> 01:10:23,370
There are really good reasons to do a screening. There are really good reasons to do these follow up tests that your doctor ran.

595
01:10:23,370 --> 01:10:30,090
There are really good reasons to expose people to knowledge about their risk factors.

596
01:10:31,940 --> 01:10:36,590
Yes. All right. We got about 10 minutes left.

597
01:10:36,740 --> 01:10:44,030
Take about five of them. Talk at your table. Think about this question of the individual versus the population and the role of statistics.

598
01:10:44,540 --> 01:10:48,710
What are statistics helpful from the individual standpoint and what are they not?

599
01:10:48,950 --> 01:10:56,510
They clearly are valuable at the population level. We make good policies based upon statistics, but when we translate them down to the individual.

600
01:10:58,030 --> 01:11:05,820
Complicated. Just take a few minutes and talk about that one.

601
01:11:07,590 --> 01:11:21,950
On one level that I recently, you know, all of our research studies assist our clients on average.

602
01:11:22,770 --> 01:11:27,690
And so he doesn't know where they're going to fall.

603
01:11:27,920 --> 01:11:57,540
And they maybe it's really hard to translate a lot of what my field of health care is not in relation to the ones who have it yourself.

604
01:12:01,010 --> 01:12:09,330
I mean, it's obviously a different experience to be able to sit down.

605
01:12:09,900 --> 01:12:14,650
It's hard to think about.

606
01:12:15,640 --> 01:12:19,130
I like. I know.

607
01:12:21,620 --> 01:12:38,900
Oh, yes. So at this point, though, that that's that's a huge problem right now.

608
01:12:38,970 --> 01:12:51,870
That's terrible. But I think that I don't think that's the part of the story.

609
01:12:52,920 --> 01:13:11,159
I do not have any idea how why I might be able to withstand.

610
01:13:11,160 --> 01:13:20,430
So that's why I like let's be clear at this point,

611
01:13:21,240 --> 01:13:46,890
we're providing a ridiculously I think we're taking something different people that when make them feel

612
01:13:46,920 --> 01:14:08,790
that like even it's sort of like someone it's not like kind of like I am just going to be very helpful.

613
01:14:12,400 --> 01:14:34,130
So I have to say like the first part and also like yeah,

614
01:14:34,580 --> 01:15:02,910
I tried in the process for something like that because I think the one where the crux of the matter is very much so.

615
01:15:04,170 --> 01:15:11,350
Yeah, yeah, yeah, yeah.

616
01:15:12,030 --> 01:15:19,260
I think it must be about, you know, it's like, all right.

617
01:15:20,560 --> 01:15:30,090
But easily continue this conversation for not just the rest of the class, but because I want to do a quick.

618
01:15:31,250 --> 01:15:36,950
Full of any thoughts that came up. And then I have one last to in a story I want to share with you to wrap up this section.

619
01:15:37,990 --> 01:15:43,820
I think that really came up. That struck you. So why not? When do statistics feel most relevant to the individual?

620
01:15:44,760 --> 01:15:53,930
Yeah. Like if you have some kind of control over the situation, how big a statistic might be helpful, but it's sort of like you have no control.

621
01:15:54,350 --> 01:15:56,840
I mean, my example was like I lost my sense of starvation.

622
01:15:57,140 --> 01:16:01,940
I have COVID and like having the statistics about like when I might get it back weren't really helpful

623
01:16:01,940 --> 01:16:06,560
because I had no control over it or there's a choice of having a statistic might be more helpful.

624
01:16:07,100 --> 01:16:11,330
Well, I'll give one essential caveat to your example,

625
01:16:11,360 --> 01:16:21,680
which is while the statistics of how fast someone might get their senses back on COVID, do not tell you what will happen to you.

626
01:16:22,670 --> 01:16:27,080
They can sometimes be useful to tell you that your experience is not unusual.

627
01:16:28,010 --> 01:16:35,020
So if what you hear is, hey, it might take weeks or months for either your senses to come back and it's been two weeks,

628
01:16:35,420 --> 01:16:43,340
you are now no longer feeling like, Oh my gosh, this proves you're life, and maybe it may be that it calibrates you.

629
01:16:43,340 --> 01:16:48,380
And so there is some degree that we share individual statistics, not because it's a chance for people's questions about what will happen,

630
01:16:48,920 --> 01:16:54,709
but it will help them know whether their experiences are in line with what has happened,

631
01:16:54,710 --> 01:16:59,660
with others, with pop, you know, where do they fall in the distribution? So that is an important piece of this.

632
01:16:59,720 --> 01:17:06,400
Sometimes the other things that came out that people want to share, actually, that's a good lead in to where I'm going to go to wrap up today.

633
01:17:06,410 --> 01:17:13,790
But yes, I think we kind of talked about like kind of when they're not really there or when they're over emphasized,

634
01:17:13,790 --> 01:17:17,689
like was the example where like every day we got something new about the same thing.

635
01:17:17,690 --> 01:17:23,629
And then you have President Trump telling it, telling people one thing, and then like the news, trying to tell you something else.

636
01:17:23,630 --> 01:17:26,870
And almost like the statistics, didn't it?

637
01:17:26,870 --> 01:17:29,600
Almost like they lost their value because you're like, okay, what's right? What's wrong?

638
01:17:29,820 --> 01:17:35,450
Like, so right or wrong isn't even necessarily the right right metric here.

639
01:17:35,460 --> 01:17:39,350
Like, they just you're representing a thing, but you don't necessarily know what to do with.

640
01:17:39,380 --> 01:17:46,130
My example of this is I get the daily emails from the New York Times telling me what the COVID case counts in Washington County are.

641
01:17:47,140 --> 01:17:52,270
And what I have come to realize is that I pay absolutely no attention to the absolute level because

642
01:17:52,270 --> 01:17:56,590
the only thing that I'm picking up is whether it's going up or down in the last week or so.

643
01:17:56,620 --> 01:17:58,569
That's it. That's all that I'm potentially getting,

644
01:17:58,570 --> 01:18:04,899
and that's all that may be useful from it because I don't know what to think about 100 cases is that a lot

645
01:18:04,900 --> 01:18:11,890
of like it just tells me that it exists and that's a limitation of the value of those statistics for me.

646
01:18:13,330 --> 01:18:14,739
Yeah, I'm kind of going after that.

647
01:18:14,740 --> 01:18:21,070
We talked about like the way statistics are presented can really determine the relevant seems like a person or not.

648
01:18:21,230 --> 01:18:25,360
Yeah. Hold that thought. We're going to like spend weeks on it in about three weeks.

649
01:18:25,360 --> 01:18:29,140
So. Yes, and let me cut that discussion about that.

650
01:18:29,830 --> 01:18:38,170
All right. Let me wrap this up, both yesterday's and today's discussion with a little story of another of my own health issues.

651
01:18:40,090 --> 01:18:45,580
Another one of the things that shaped my interest in this topic was even before my transplant,

652
01:18:46,900 --> 01:18:51,250
my spouse and I went through multiple years of infertility.

653
01:18:52,300 --> 01:18:57,130
A risk that is very common in the population and not often talked about.

654
01:18:58,360 --> 01:19:01,599
The statistics that I've seen are something on the order of one in six couples

655
01:19:01,600 --> 01:19:04,190
who are attempting to get pregnant will experience some form of killing.

656
01:19:05,910 --> 01:19:10,260
But I want to share with you a moment that I think captures both this analytical versus

657
01:19:10,260 --> 01:19:17,700
experiential and also the experience of risk to moment in the midst of our treatment journey.

658
01:19:18,420 --> 01:19:26,940
By the way, I'll tell you the ending. I have two kids after in-vitro fertilization, so it turned out ultimately well, but this is before them.

659
01:19:27,510 --> 01:19:31,170
And we were going through a procedure known as intrauterine insemination.

660
01:19:33,640 --> 01:19:38,910
Basically trying to address the possibility of the sperm ward actually getting to the egg.

661
01:19:38,920 --> 01:19:44,620
So you mean you essentially injected directly, but not into an individual egg?

662
01:19:44,620 --> 01:19:53,890
Just into the woman and. My spouse was going through fertility medications to promote ovulation, etc.

663
01:19:54,790 --> 01:20:01,060
Now, the key thing here is that conception is probabilistic, even in a perfectly healthy person.

664
01:20:01,360 --> 01:20:07,240
Everything is great. Conception is fine. Well, less than 50% chance in a given cycle.

665
01:20:07,480 --> 01:20:11,170
I mean, we can have our estimates all use 25% just to make this easy.

666
01:20:12,400 --> 01:20:16,080
So. We did this trial.

667
01:20:16,140 --> 01:20:19,860
We went through. She took the medications. We had a procedure done.

668
01:20:20,190 --> 01:20:25,600
We wait two weeks. We redo it.

669
01:20:26,670 --> 01:20:31,650
Another round of the medications, another rounds of the tests, another round of getting up early in the morning to go do things.

670
01:20:31,890 --> 01:20:35,560
Another round of waiting. If you a.

671
01:20:36,730 --> 01:20:46,080
And we did a third time in which once your medications we do all the tests we travel to and we get our hopes up.

672
01:20:46,320 --> 01:20:50,720
We imagine the possibility. You. And she was right.

673
01:20:50,840 --> 01:20:58,790
And I remember the day that we found out that third psycho wasn't pregnant because my analytical brain was doing the math.

674
01:21:00,000 --> 01:21:04,409
Okay. 25% chance. That means there's a 75% chance on any given situation.

675
01:21:04,410 --> 01:21:08,030
It won't be pregnant. No, 75% race or so.

676
01:21:08,040 --> 01:21:14,880
Third power subtracted from one that works out to something like a 40% chance that this is occurring just purely by chance.

677
01:21:15,840 --> 01:21:23,160
We've only done this three times. Obviously, we need to keep going because there is there's plenty of opportunity for this to work.

678
01:21:24,200 --> 01:21:31,330
And. My experiential brain had lived through each of those cycles and the hopes and the desires.

679
01:21:31,510 --> 01:21:34,750
And I was absolutely, completely convinced it would never work.

680
01:21:35,920 --> 01:21:44,440
At the same old literally at the same moment, I'm sitting here doing the math in my head and believing and grieving the fact that it would never work.

681
01:21:44,950 --> 01:21:49,630
And I study this stuff because it's not that I don't it's not that I'm not an expert in this.

682
01:21:50,020 --> 01:21:56,850
But I lived that duality in that moment. That's risk.

683
01:21:57,990 --> 01:22:04,260
We all are both of these things and we all live the experience of having that probability either manifest or not.

684
01:22:04,770 --> 01:22:09,600
And that's what I'm going to leave you with today. So think about what the experience of risk is like in your lives.

685
01:22:10,170 --> 01:22:19,829
And for some time, if you have questions about the assignment, we feel free to reach out to you and then shift more into the numbers.

686
01:22:19,830 --> 01:22:27,630
Space starting. Know.

687
01:22:30,950 --> 01:22:36,320
Come back later.

688
01:22:39,440 --> 01:22:48,790
You'll see. Over. He's like, a little more like.

689
01:22:55,660 --> 01:23:00,360
When we come back.

690
01:23:03,040 --> 01:23:14,990
Thank you for making love again. I'm happy to meet with her about my post, about you as my supervisor.

691
01:23:15,010 --> 01:23:24,080
And I want you to actually see her help her flow.

692
01:23:25,530 --> 01:23:33,780
Listen, I've always thought that, yes, I do have a shirt, I will wear them.

693
01:23:35,820 --> 01:23:53,880
But for whatever reason, I discovered that I feel like I have not had the passion in the conference or elsewhere for nine years.

694
01:23:57,920 --> 01:24:09,930
I do. I notice that every year I do have other thoughts on the world, and that's why I wasn't waiting to say that.

695
01:24:09,930 --> 01:24:15,070
I'm like, I need to wait another class. Oh, you got something in your attention.

696
01:24:15,120 --> 01:24:18,640
Okay, we'll get out. I'm sorry. No, no, no, not really.

697
01:24:20,140 --> 01:24:24,790
And it's often just empty. So I haven't thought about that.

698
01:24:25,120 --> 01:24:28,630
I will get out of the way. Yes.

699
01:24:29,170 --> 01:24:32,440
Yes. This is between like.

700
01:24:32,680 --> 01:24:36,999
Oh, I think there's a word count is up for each paragraph.

701
01:24:37,000 --> 01:24:41,650
Or is that like for the musings or for the assignment? The assignment is due Monday.

702
01:24:41,800 --> 01:24:45,490
I forget what I marked. This is in your description to your name.

703
01:24:45,490 --> 01:24:52,130
Is that a screenshot like the total document report? And let me see what I wrote and then I will answer that.

704
01:24:55,720 --> 01:24:57,918
That's to me as an example. So.

