1
00:00:02,200 --> 00:00:05,720
You know. Roots.

2
00:00:14,360 --> 00:00:25,769
Soon we come down to the very core of the class we we're watching online or you to be is of the things you need to be doing.

3
00:00:25,770 --> 00:00:30,840
But this is very subdued.

4
00:00:32,340 --> 00:00:37,890
It was so quiet walking in today. What did I miss, this extra thing?

5
00:00:41,770 --> 00:00:49,850
Okay. All right. So let's move into the sort of final stretch here.

6
00:00:49,870 --> 00:00:58,630
We're going to be talking about sort of causal inference and in sort of time during in time to event settings.

7
00:00:59,530 --> 00:01:06,130
So we'll start out a little bit with mediation, analysis and survival data.

8
00:01:07,360 --> 00:01:12,790
And we're going to sort of look at three different approaches to this accelerated figure, the time models,

9
00:01:12,790 --> 00:01:20,560
which are typically parametric models, proportional hazards models, which are the personal hazard models.

10
00:01:20,680 --> 00:01:27,489
So this sort of treatise, both of which we discussed briefly in our review of survival analysis and finally about the

11
00:01:27,490 --> 00:01:33,670
use of inverse probability weights and the survival Mel setting to do the mediation analysis.

12
00:01:34,870 --> 00:01:38,800
So, okay.

13
00:01:40,880 --> 00:01:49,130
So. So for accelerated filter time models, we're going to start with our usual linear model for a mediator.

14
00:01:50,090 --> 00:01:55,969
So we have a mediator that we assume is linear,

15
00:01:55,970 --> 00:02:04,240
and it's been so there's just a little bump for treatment level A versus a prime Alpha

16
00:02:04,250 --> 00:02:12,200
one and then a set of other predictors involving X that are associated with a mediator.

17
00:02:14,450 --> 00:02:20,210
And then for the now for the outcome, we're going to use this this log of time model.

18
00:02:21,470 --> 00:02:32,720
So basically, this can be thought of as various forms if if this error term is normally distributed, this is a log normal model.

19
00:02:33,800 --> 00:02:43,010
If this is a extreme value function and this becomes a label model, so have the mechanism.

20
00:02:43,550 --> 00:02:57,940
So we have our usual very similar setup that we, we looked at in our sort of non time to event settings having an effect for treatment and

21
00:02:57,950 --> 00:03:01,760
effect for the mediator and then not allowing possibly for a treatment mediator interaction.

22
00:03:02,660 --> 00:03:06,500
And we have all of our same sequential nor ability assumptions in place.

23
00:03:12,860 --> 00:03:18,110
So then we measure our natural, direct effect.

24
00:03:19,430 --> 00:03:24,620
Now we're going to think about ratios since we're on this long scale.

25
00:03:25,460 --> 00:03:38,810
So a Luc can think of if it's linear in the log function, it's going to be multiplicative in the original scale.

26
00:03:39,830 --> 00:03:44,720
And if you're looking at additions and you're multiplying things together, and if you look at subtraction, you're dividing things.

27
00:03:45,830 --> 00:03:58,010
So, so again, a direct effect that our mediator hang out or whatever, control the treatment or exposure is.

28
00:03:58,670 --> 00:04:02,840
And then we change between treatment and control for the actual exposure.

29
00:04:04,130 --> 00:04:13,700
Condition X the whole way through. Because in order to get these sequential insurability assumptions in place right,

30
00:04:13,770 --> 00:04:19,370
we typically want to need to condition X and even a phase randomized that we still

31
00:04:19,370 --> 00:04:26,570
have the issue about the Mediator Outcome Association not necessarily be independent.

32
00:04:27,350 --> 00:04:31,730
So we try to condition on that to make that assumption better. Okay.

33
00:04:31,970 --> 00:04:37,129
So basically to compute this, we do it to make an additional assumption,

34
00:04:37,130 --> 00:04:44,850
which is that it is probably distributed and as we'll see in a minute, that basically becomes a log, minimal exponential.

35
00:04:45,590 --> 00:04:51,739
And so we have a somewhat more complicated structure here because we essentially end up with

36
00:04:51,740 --> 00:04:57,800
a little bit piece of the log in the distribution that doesn't that doesn't get raised.

37
00:04:59,750 --> 00:05:13,520
So and I'm looking at the general form right here could be any value, but if this is one, then the least these two are equal simplifies slightly.

38
00:05:15,080 --> 00:05:18,260
Okay. So to get this.

39
00:05:23,810 --> 00:05:33,470
Going to go over and games we went before, but it's a little bit different situation.

40
00:05:35,260 --> 00:05:49,090
Live here anymore. Again, we're thinking about fashion and some valuable acts of.

41
00:05:51,570 --> 00:05:57,790
The best spirit is conditioning.

42
00:06:02,940 --> 00:06:20,930
Him. And so.

43
00:06:22,940 --> 00:06:26,840
It's in our expectation conditions on and they still are.

44
00:06:27,560 --> 00:06:31,940
And then we want to think about the expectation of them fixing things at a star.

45
00:06:31,940 --> 00:06:37,530
So, you know, the next phase there. So.

46
00:06:39,620 --> 00:06:56,900
Get. A little clunky about using this to keep an eye on what the condition of the second step or what gravity.

47
00:07:15,070 --> 00:07:23,840
The simplest and. And this is basically based with the fact that.

48
00:07:28,560 --> 00:07:33,650
Services potential outcomes independent of and they start next.

49
00:07:48,110 --> 00:08:16,100
The crop in. And well here, since we assumed to be an independent, very frequent site, it is now more mediators independent of treatment.

50
00:08:19,610 --> 00:08:30,120
These are all very but assumptions. We are independent.

51
00:08:30,120 --> 00:08:37,000
The media has. So put this out a little more detail.

52
00:08:37,720 --> 00:08:42,130
When I went through this in the middle of your case, you got to this point here.

53
00:08:42,610 --> 00:08:48,000
Go back and look through. Okay.

54
00:08:49,410 --> 00:09:12,250
So. So now I've got this separate failed time model.

55
00:09:13,780 --> 00:09:47,940
So basically now. Right.

56
00:09:49,160 --> 00:09:57,330
So I'm just. Just go back here.

57
00:10:00,140 --> 00:10:10,740
Right. The safety model.

58
00:10:21,920 --> 00:10:25,670
Is there also a bit of extra? Uh, yes.

59
00:11:10,670 --> 00:11:15,489
Okay. So I'm going to get what is an expectation condition, a bunch of stuff.

60
00:11:15,490 --> 00:11:20,500
So expected values as people sort of have.

61
00:11:28,460 --> 00:11:50,340
If you don't know. And. So.

62
00:11:52,690 --> 00:12:00,230
It's also going to be independent. University independent Arizona.

63
00:13:02,930 --> 00:13:11,360
So now I have to deal with these expectations and am so.

64
00:13:51,290 --> 00:13:55,310
You factor out maybe two in my bed three days.

65
00:13:59,090 --> 00:14:02,809
Then I expect the value of the yen will be soon.

66
00:14:02,810 --> 00:14:07,580
It is really distributed. If you do that transformation, then it becomes a lot more.

67
00:14:08,780 --> 00:14:17,180
And you might remember the name of a wonderful variable. It's basically you.

68
00:15:01,480 --> 00:15:04,630
Plus the specter here where it comes to various.

69
00:15:20,840 --> 00:15:24,400
It's got good times for me. The Senators Square.

70
00:16:00,120 --> 00:16:12,440
Question. The idea like normal comes from something that is right.

71
00:16:13,780 --> 00:16:46,040
We are making those. Everybody was starting to is.

72
00:16:59,440 --> 00:17:06,080
And know what? Under.

73
00:17:22,850 --> 00:17:30,500
So. That's a direct effect.

74
00:17:38,280 --> 00:17:41,750
Yes, sir.

75
00:17:51,280 --> 00:17:58,089
Somewhat messy thing from the bottom here and it's going to come back up here to replace you need a star.

76
00:17:58,090 --> 00:18:20,570
And then the Terminator. I never did kind of take this out, but it's not going to matter because he's going to get cancer.

77
00:18:25,010 --> 00:19:12,980
It's. So what's clear is the variances and.

78
00:19:19,310 --> 00:19:34,010
Original skin. And in the denominator the place on my is for these stars for things associated.

79
00:19:53,340 --> 00:20:27,870
So I went to write and then three or three or four years or so since then, thankfully it goes away.

80
00:20:27,870 --> 00:20:43,230
So we have to model here, folks. It doesn't matter what the form of the epsilon is, as long as as long as it's still structured.

81
00:20:44,960 --> 00:20:51,050
And so, you know, together then.

82
00:20:55,920 --> 00:21:11,430
One. Eventually Dave Isay started it and then got.

83
00:22:11,150 --> 00:22:32,930
So this kind of break this piece off here. This obviously is going to be.

84
00:23:08,650 --> 00:23:16,600
Right. Just. Division rival Magicians Guild.

85
00:23:29,720 --> 00:23:34,760
What an excellent square. He expanded his.

86
00:24:11,620 --> 00:24:11,900
Which.

87
00:24:49,390 --> 00:25:06,170
It seems Apple is going to factor out the game as a star in the square, dancing star square to get a few minutes of experience and bring it up here.

88
00:27:13,860 --> 00:27:18,020
You know, they don't want to lose this.

89
00:27:19,990 --> 00:27:30,320
That's right. So that's how we should be.

90
00:27:34,660 --> 00:27:37,760
This system increased drastically.

91
00:27:37,780 --> 00:27:52,520
This. I was going to cancel here.

92
00:28:15,230 --> 00:29:08,710
The school. Oh.

93
00:29:09,400 --> 00:29:13,060
Because it's very important that they're respecting the citizens.

94
00:29:14,470 --> 00:29:17,680
So that was their.

95
00:29:19,390 --> 00:29:45,680
So. So.

96
00:29:46,960 --> 00:29:53,450
Is it better to square?

97
00:30:07,350 --> 00:30:34,980
It's a story. So you start.

98
00:30:53,290 --> 00:30:57,650
So here's when I started. Zero one.

99
00:30:59,050 --> 00:31:10,770
So. Obviously there's no interaction to an area where we sympathize with this.

100
00:31:12,540 --> 00:31:18,399
I just knew that they were one way of getting us.

101
00:31:18,400 --> 00:31:29,270
To where? Correct? Yes. And otherwise, I have to worry about two pieces, girls.

102
00:31:33,550 --> 00:31:37,200
The exponentially more than the expectations.

103
00:31:58,840 --> 00:32:01,960
Thank you so much for.

104
00:32:04,270 --> 00:32:41,380
Yes, it. That will cut this piece.

105
00:32:49,890 --> 00:32:54,510
When I just factored out my biggest mistake.

106
00:32:54,510 --> 00:32:58,500
The square foot here. Three eight, nine, six, four.

107
00:33:00,570 --> 00:33:04,010
This. That second story begins with.

108
00:33:09,520 --> 00:33:22,620
Nielsen. A lot of this you can pull out of the Vanderbilt text.

109
00:33:22,650 --> 00:33:30,150
I'm sort of just trying to highlight pieces and also fill in some spot, some blanks because they didn't do all the algebra.

110
00:33:37,030 --> 00:33:43,760
So. As an undergraduate, I took a class on history of science,

111
00:33:44,570 --> 00:33:50,090
and one of your assignments was to take a page from Newton's Principia, where he said, This follows from this.

112
00:33:51,480 --> 00:33:55,310
They asked you to show it. It took about two pages of derivations.

113
00:33:55,900 --> 00:33:58,100
It's apparently if you're Isaac Newton, you could do it in your head.

114
00:34:00,980 --> 00:34:07,850
So like Tableau, Andrew is known as Newton, but he's a really smart guy, so he didn't put all that in there.

115
00:34:09,530 --> 00:34:21,920
So, okay, so for the natural, indirect effect, a little less gruesome.

116
00:34:27,130 --> 00:35:08,110
Stefan FATSIS. Never hold a.

117
00:35:13,020 --> 00:35:22,430
It seems to me your value. Going to.

118
00:36:04,870 --> 00:36:16,290
It's. Now I'm going to face a new year and a star.

119
00:36:25,340 --> 00:36:51,560
Phases, it just becomes. Trickle down.

120
00:37:32,480 --> 00:37:36,440
So the little simpler stuff disappears.

121
00:37:39,510 --> 00:37:45,150
But. It's.

122
00:38:02,930 --> 00:38:07,970
Within both alpha not to also pieces.

123
00:38:09,140 --> 00:38:19,960
I just got this part. And if he has one of these star zero.

124
00:38:21,430 --> 00:38:26,740
And basically, I just want this baby to.

125
00:38:28,550 --> 00:39:00,900
This. Being thrown out for one. So.

126
00:39:05,030 --> 00:39:09,080
I won't go through the details, basically with a binary mediator.

127
00:39:14,440 --> 00:39:18,010
It's both.

128
00:39:19,480 --> 00:39:23,380
So where we have a binary immediate or in a time two event outcome,

129
00:39:25,570 --> 00:39:33,160
we get our same results we get from linear media, except we kind of let the expectation of M give an X.

130
00:39:36,160 --> 00:39:43,570
And so, again, this kind of denominators and these long odds.

131
00:39:47,520 --> 00:39:51,160
A new mayor is going to fix so.

132
00:39:57,370 --> 00:40:02,470
Beta beta one times this piece here, they won and he started zero.

133
00:40:10,630 --> 00:40:15,010
And unfortunately, because this is a one plus function, we can't just cancel all of these things.

134
00:40:20,000 --> 00:40:33,310
But. So the variance estimators match a lot of those derived in class energy using the delta method.

135
00:40:35,500 --> 00:40:43,540
The difference is that, well, first of all, just a reminder, we're going to fit these using an accelerated period of time model.

136
00:40:43,540 --> 00:40:47,950
So like a label model to estimate the betas here,

137
00:40:49,630 --> 00:40:59,290
right from our observed data and of course our usual linear model for for em to get estimates of beta alpha.

138
00:41:01,690 --> 00:41:09,700
And then of course our covariance matrix would be determined by the variance covariance matrix of the FFT model for the linear logistic model.

139
00:41:10,210 --> 00:41:13,240
So. Very similar.

140
00:41:18,660 --> 00:41:28,770
Okay. So with personal hazard models.

141
00:41:30,710 --> 00:41:39,130
If. The basement has a small we can approximate these direct and indirect effects natural,

142
00:41:39,130 --> 00:41:43,060
direct, natural and effects using the same formulas as for the NFT model.

143
00:41:44,080 --> 00:41:49,900
But we're going to define the direct indirect effects as a ratio of hazards within ratio of expected times to event.

144
00:41:50,710 --> 00:41:53,830
And we'll see in a minute that's actually somewhat controversial.

145
00:41:55,030 --> 00:42:01,300
But I'm going to real this does derive this so I just could use it.

146
00:42:07,160 --> 00:42:11,990
And so if we think about now the hazard.

147
00:42:14,490 --> 00:42:26,130
So the sort of instantaneous risk of event. And under this potential outcome model with a and that may star a star and may star.

148
00:42:28,100 --> 00:42:35,690
Then we get something that looks basically identical to what we had before.

149
00:42:40,490 --> 00:42:46,850
And basically the reason we can get this is that we get we can show that again,

150
00:42:46,850 --> 00:42:51,020
as long as the baseline hazard is not too high to the risk at any point in time,

151
00:42:51,020 --> 00:42:55,970
as part of instantaneous risk is fairly low, then we can approximate this hazard.

152
00:42:57,140 --> 00:43:09,620
So looks very much like. Are expected time two events under the NFT model so.

153
00:43:14,160 --> 00:44:01,149
So that. All right.

154
00:44:01,150 --> 00:44:05,410
So our definition basically is a PDF.

155
00:44:09,220 --> 00:44:14,650
At the time of writing my one minus for survival.

156
00:44:27,110 --> 00:44:41,560
So. So we're going to work this out.

157
00:44:42,780 --> 00:44:59,370
Use the same game or condition. The values.

158
00:45:18,110 --> 00:45:31,820
So under my usual affordability assumptions, if you just keep conditions of any extended.

159
00:45:47,490 --> 00:45:55,640
So my people from the disproportionate hazards model. It was actually imagining this.

160
00:46:05,240 --> 00:46:25,220
It's. I have this baseline hazard which is purely a function of t w appropriate set to zero.

161
00:46:47,470 --> 00:47:57,800
In. Since I've been ranked, this effort has been a cancer survival function.

162
00:48:00,200 --> 00:48:05,740
The treatments. So what do you do for another smile?

163
00:48:09,790 --> 00:48:18,340
Survival rate out. Over this time, it seemed as if he's here to.

164
00:48:25,100 --> 00:48:59,960
So. So you play the same game.

165
00:49:07,650 --> 00:50:02,520
Survival side. So we put this together and we're here.

166
00:50:57,050 --> 00:51:05,030
So this approximation is clearly capturing a small.

167
00:51:22,200 --> 00:51:27,720
So this essentially becomes a constant period, very close to one that small.

168
00:51:29,010 --> 00:51:33,690
So if you just drop it out. So.

169
00:52:50,530 --> 00:52:54,780
Well. This doesn't appear out here.

170
00:53:07,800 --> 00:53:11,140
So basically this entire piece down here, expensive.

171
00:53:19,310 --> 00:53:23,980
I see this as a moment to make this. The Fusion.

172
00:53:26,220 --> 00:53:33,090
Expect the expectation to. So I'm just writing this with a smile here.

173
00:53:34,990 --> 00:53:58,640
Oh, no, I think they'll call him. Something.

174
00:54:09,010 --> 00:54:12,549
And then just work this out.

175
00:54:12,550 --> 00:54:21,850
And I did before the previous piece. Right.

176
00:54:22,490 --> 00:55:09,340
Normal. So one has to be squared in two to say three, three square.

177
00:55:23,220 --> 00:55:37,360
Yeah. So this whole part.

178
00:55:46,580 --> 00:55:50,730
Here. So you have that.

179
00:55:51,850 --> 00:55:58,290
I mean, we just go back to our previous derivations to work out through direct indirect effect because it's exactly the same thing.

180
00:55:59,700 --> 00:56:09,230
So now I have this. Has her turn, but that's a constant with respect to M-A and X.

181
00:56:10,490 --> 00:56:14,470
So that just cancels. I get back to this parts here.

182
00:56:30,030 --> 00:56:38,250
You can estimate write offs for my linear model from my betas, from my Cox proportional hazard model.

183
00:56:41,320 --> 00:56:50,170
And plug in I and if I have a binary mediator, basically identical results.

184
00:56:51,130 --> 00:56:58,540
Now, of course, an estimate into the proportion hazards model. So and it should mention a little bit this discussion, I mean,

185
00:56:58,540 --> 00:57:05,049
the advantage of proportional hazards model is that it you don't have to make any

186
00:57:05,050 --> 00:57:10,240
assumptions about the distribution of T except that it has proportional hazards assumption.

187
00:57:11,200 --> 00:57:19,360
Sometimes I think that's a little bit of the math chasing the reality, but but it is a really nice feature of it.

188
00:57:19,380 --> 00:57:22,090
And, and it's, I think one reason why it's become so popular,

189
00:57:22,990 --> 00:57:32,320
but one certainly can test for distributional assumptions in time event models just like you can in other models.

190
00:57:32,620 --> 00:57:40,690
I think the censoring pieces of is part of that also because censoring does it do some issues about testing distributional assumptions.

191
00:57:41,290 --> 00:57:50,260
So the sensitivity to those distributions, of course can be stronger presence of censoring.

192
00:57:50,890 --> 00:57:53,490
So the personalized model has that advantage.

193
00:57:53,710 --> 00:57:59,800
You can also test proportional hazards assumption, as we mentioned briefly and we'll come back to a little bit.

194
00:58:00,280 --> 00:58:04,900
You can also look at the failure to personalize it. Something doesn't mean K as the model simply means,

195
00:58:05,380 --> 00:58:12,430
but you have to interpret the hazard non proportionally by putting in interaction terms between the axes at the time itself.

196
00:58:13,630 --> 00:58:21,120
So you can you can, you can sort of relax that assumption using those kinds of interactions.

197
00:58:21,130 --> 00:58:25,760
It makes the estimation a bit trickier, but in discrete time to them model it's less so.

198
00:58:27,010 --> 00:58:38,750
So okay. So measures of mediation rate in particular, this proportion mediated can be computed as an logistic model case.

199
00:58:40,130 --> 00:58:43,310
So everything is kind of falls out the same way.

200
00:58:49,590 --> 00:59:01,270
All right. So it's a little bit of math today with algebra. Questions at this point.

201
00:59:18,010 --> 00:59:21,129
So an alternative to this two stage model. I said outcome is binary.

202
00:59:21,130 --> 00:59:23,020
I don't think I really meant that at the mediators,

203
00:59:23,020 --> 00:59:31,930
binary or low dimensional categorical variable is to use a weighted approach and it's a little bit of a funky thing

204
00:59:33,010 --> 00:59:40,480
and I'm not going to get into the details of the math because it's just too complicated for my time from the class.

205
00:59:41,890 --> 00:59:52,000
But the basic trick is you create a duplicate dataset and can content concatenated onto the original data set and you take a variable a star,

206
00:59:52,900 --> 00:59:57,070
you set it equal to A for the original data set and then one minus eight for the duplicated data.

207
00:59:58,030 --> 01:00:04,390
So every time you had a subject assigned to treatment, they get assigned to control and vice versa.

208
01:00:07,270 --> 01:00:13,000
And you then compute the following weights estimated using logistic regression.

209
01:00:14,140 --> 01:00:21,630
So the probability of. Treatment assignment given X, right?

210
01:00:21,640 --> 01:00:27,250
If we're not assuming right, we're using our Xs to enforce randomization, respect for treatment.

211
01:00:27,640 --> 01:00:37,900
So the usual game there and then the probability the mediator according to the course, we're assuming the mediator is typically binary given.

212
01:00:41,300 --> 01:00:49,850
A star is equal to A versus A is equal to A. So whatever the the sort of value of a under this concatenated dataset is.

213
01:00:50,780 --> 01:00:55,220
So in the content, any data set, a star is equal to a. So this thing is just equal to one.

214
01:00:55,880 --> 01:01:03,800
So our weights are just the usual weights for sort of trying to recreate balance in the,

215
01:01:03,800 --> 01:01:12,950
in the assignment and then in the duplicated data, we then multiply by basically the probability of the mediator being in the opposite,

216
01:01:17,960 --> 01:01:23,720
given that media is the opposite, given sorry, the probability of the media, given the treatment,

217
01:01:23,720 --> 01:01:27,410
it's on the opposite value of what it actually was in the original dataset.

218
01:01:29,180 --> 01:01:39,590
And you then fed proportional hazards model where you plug in both A and a star, nothing else.

219
01:01:39,980 --> 01:01:51,090
Right. Using the weight the off with the the attempt to adjust for condition x create randomization.

220
01:01:52,760 --> 01:01:56,270
And of course, this usual baseline has a.

221
01:01:58,820 --> 01:02:04,070
Basically this sort of separates out the natural, direct effect of the natural indirect effect.

222
01:02:05,300 --> 01:02:13,430
So either the cap or one is a natural, direct effect, and you have to capture the corresponding natural indirect effect.

223
01:02:14,870 --> 01:02:21,470
And getting too much of the details, the basically the logic on this is that prior to the natural, direct effect,

224
01:02:22,970 --> 01:02:30,410
we are we are holding the mediator constantly flipping the treatment and then the indirect effect the other way around.

225
01:02:31,310 --> 01:02:35,200
And that is essentially what this extra weight piece does per capita.

226
01:02:36,410 --> 01:02:40,250
And then capital. And this keeps us in the direct effect setting.

227
01:02:41,510 --> 01:02:46,490
So standard errors in this pretty messy except. So bootstrapping is the standard for this.

228
01:02:48,750 --> 01:02:56,640
So if we went back and we talked about this sort of weighted approach to structural to marginal structural models,

229
01:02:59,040 --> 01:03:04,500
and then there's this somewhat technical development of the estimated equation based on the duplication of the dataset.

230
01:03:05,640 --> 01:03:08,730
So again, I want to get through it here,

231
01:03:08,730 --> 01:03:19,980
but this is an alternative way to estimating direct and indirect effects that just as in the model structural model approach,

232
01:03:19,980 --> 01:03:26,040
we could use weights or we could use models. So this is the same thing here, except in the time to event setting.

233
01:03:37,970 --> 01:03:42,590
All right. So we went to our last little piece here before an example.

234
01:03:46,280 --> 01:03:51,080
And so this issue of hazard ratios and causal inference context is a little controversial.

235
01:03:52,550 --> 01:03:56,750
So even though the hazard Vandewalle text does describe mediation through hazard ratios,

236
01:03:57,860 --> 01:04:03,170
Hernan another big player in this causal material argued against their use for causal inference for two reasons.

237
01:04:04,460 --> 01:04:11,840
One is the portion of hazard ratio may not be constant, and averaging over this change might damage the causal interpretation of the hazard ratio,

238
01:04:12,710 --> 01:04:22,430
since essentially you're sort of trying to get this marginal idea and if you just

239
01:04:22,430 --> 01:04:28,340
sort of condition X and don't worry about the fact that X and T maybe interacting,

240
01:04:28,580 --> 01:04:36,020
then this this interpretation may fail. A more important issue is that the change in the risk set required to estimate the

241
01:04:36,020 --> 01:04:40,640
hazard ratio given point in time does not account for the counterfactual survival risk.

242
01:04:43,660 --> 01:04:50,740
So the first issue basically you can allow for non proportional hazards, right?

243
01:04:50,770 --> 01:04:53,979
So this basically means interactions between T and cover.

244
01:04:53,980 --> 01:04:58,660
It's X. So everything here now would become essentially conditional on T as well.

245
01:04:58,690 --> 01:05:07,269
So whatever particular time you're looking at, but you could still get the same kind of direct indirect effect estimates.

246
01:05:07,270 --> 01:05:10,870
They would just now only be associated with a given point in time,

247
01:05:10,870 --> 01:05:18,100
which makes sense because of the hazard ratio and the portion of the the hazard ratio itself is not constant over time,

248
01:05:18,730 --> 01:05:22,480
so you've got to account for that. The second issue is a little trickier.

249
01:05:24,190 --> 01:05:30,849
So sort of try to maybe give an example this work out the math in this, but ran out of time.

250
01:05:30,850 --> 01:05:33,880
So I'll just sort of repeat the sort of conceptual idea here.

251
01:05:34,750 --> 01:05:39,250
So imagine we have a situation where exposure kills all the high risk individuals by some time.

252
01:05:39,250 --> 01:05:44,050
T has no effects on the others. So the time you get the time t plus one.

253
01:05:45,250 --> 01:05:52,420
The exposed survivors are all low risk individuals. The unexposed survivors are a mixture of high risk and low risk individuals.

254
01:05:53,560 --> 01:05:59,470
The result a hazard ratio T plus one may be less than one, even though the treatment is not beneficial for any individual.

255
01:05:59,710 --> 01:06:10,390
Right. So the the unexposed so or I should say the exposure is not beneficial for any individual.

256
01:06:11,410 --> 01:06:16,030
So I'm sorry. He's a weird exposure and treatment here.

257
01:06:16,040 --> 01:06:29,829
We mean the same thing. I think initially I used the word treatment and I thought, that doesn't look good, killing off everybody to treatment.

258
01:06:29,830 --> 01:06:34,480
So it's much more exposure. But this is an idea here.

259
01:06:41,250 --> 01:06:47,850
All right. So I have to think through this a little bit here, and I've seen this a bunch of times, so.

260
01:06:48,510 --> 01:06:51,270
So our exposure basically is not beneficial.

261
01:06:52,740 --> 01:07:04,530
But by the time we get to some later point in time here, then those are exposed are all sort of low risk individuals,

262
01:07:04,890 --> 01:07:07,530
maybe unexposed or a mixture of high and low risk individuals.

263
01:07:07,530 --> 01:07:17,520
So if we just look and see what happens between time T and plus one, the group that's been exposed may have a lower failure rate.

264
01:07:19,050 --> 01:07:22,620
But if you were to counterfactual, followed an individual over time,

265
01:07:23,730 --> 01:07:30,629
exposed and unexposed, you'd see they would tend to die earlier for switching to failure.

266
01:07:30,630 --> 01:07:39,150
In earlier we talked about survival, I should mention it's obvious, but sometimes during medical situations it actually does literally refer to death.

267
01:07:39,150 --> 01:07:44,639
It could also be like the end of being non-diabetic or having some health condition,

268
01:07:44,640 --> 01:07:48,360
a chronic health condition appear that's kind of absorbing, right?

269
01:07:48,360 --> 01:07:51,540
So you're not in that state that you are. So that can also be a time.

270
01:07:53,730 --> 01:07:58,070
So so you know,

271
01:07:58,080 --> 01:08:06,120
even though so you'll notice that if you follow individuals this sort of death or switch to event or event occurring may tend to occur.

272
01:08:06,150 --> 01:08:09,810
You're always in exposed group for you to look at the counterfactuals.

273
01:08:10,320 --> 01:08:21,330
When you actually look the observed data, you've got this sort of of sometimes called survivorship bias.

274
01:08:22,900 --> 01:08:28,420
So and the problem is that we're we're conditioning our post-treatment variable, right?

275
01:08:28,990 --> 01:08:33,220
This whole issue right now, essentially the time itself becomes a sort of mediator.

276
01:08:34,030 --> 01:08:38,350
Right. You're being alive at time piece what you conditioned on to escalate this risk.

277
01:08:39,580 --> 01:08:42,670
So and it doesn't really matter. The treatments randomized. Right.

278
01:08:43,420 --> 01:08:46,540
Still don't have this issue. So.

279
01:08:48,610 --> 01:08:54,850
So her now suggestion was to focus on survival curves, compute counterfactual survival curve misdemeanors.

280
01:08:55,840 --> 01:08:59,139
So go through the details here in a second. But basically,

281
01:08:59,140 --> 01:09:04,690
the idea is you're going to sort of estimate what would happen if everybody in the population

282
01:09:05,470 --> 01:09:11,110
did not have the exposure to the treatment and if everybody had exposure to treatment.

283
01:09:11,120 --> 01:09:14,980
And you're going to look at the probability of survival in any given point in time.

284
01:09:15,400 --> 01:09:19,210
So then you really are comparing sort of apples to apples at any point in time.

285
01:09:20,080 --> 01:09:25,270
So you can look at the survival rate if nobody been exposed to versus if everybody had been exposed.

286
01:09:26,920 --> 01:09:32,320
So and they sort of suggest doing this using the discrete hazard times model.

287
01:09:34,870 --> 01:09:39,100
A few minutes, do people need a review on that? Should I just punch forward?

288
01:09:40,400 --> 01:09:44,930
All right. So. So the Street has a Times model, you might recall.

289
01:09:44,930 --> 01:09:56,780
Remember where we sort of we slice up time into chunks and we look at the probability of surviving at a particular for a particular period of time.

290
01:09:57,920 --> 01:10:09,260
And those those can index by T and then we have the sort of baseline hazard becomes basically a bunch of dummy variables for each time.

291
01:10:09,260 --> 01:10:13,339
T Or this could be something that's like a spline or something a bit more structured.

292
01:10:13,340 --> 01:10:20,540
But the most general case that looks like a partial hazard or a proportional odds model in this case we just put in dummy variables.

293
01:10:21,350 --> 01:10:31,040
We then have an effect, right, for exposure treatment, and then we can do similar much coverage or you can try to play here.

294
01:10:32,150 --> 01:10:41,809
So. Now, once we fit that model,

295
01:10:41,810 --> 01:10:50,780
we can go back and multiply each predicted value the time to estimate survival at time t to basically

296
01:10:50,780 --> 01:10:55,010
get conditional or adjusted survival curves under the condition of exposure and no exposure.

297
01:10:56,480 --> 01:11:11,360
So. So basically the probability of failing in the teeth time interval is the probability of failing t given treatment or exposure and covered sex.

298
01:11:12,020 --> 01:11:21,259
Is that same probability conditional having survived up through the time t minus one times it probably to survive the time t

299
01:11:21,260 --> 01:11:29,180
minus one given your time t minus two all the way down to the probability surviving the first year of what we consider right.

300
01:11:29,180 --> 01:11:33,589
And so you remember this from your history hazard stuff basically is the probability of

301
01:11:33,590 --> 01:11:39,470
failure at time t times the probability of surviving it all the previous time points.

302
01:11:40,670 --> 01:11:43,850
Right, which just becomes a factor here.

303
01:11:43,850 --> 01:11:56,160
I guess I could put parentheses down there, but. So this is the predicted probability of survival or predicted probably a failure given the conflict.

304
01:11:58,640 --> 01:12:05,870
So basically we predicted prior approval of survival to time t for each subject

305
01:12:05,870 --> 01:12:10,930
in our both exposure and non exposure regardless of the subject's exposures.

306
01:12:10,970 --> 01:12:23,300
Actual exposure status. Right. So we fit our time to event model with the estimate, the exposure and then exposure over time variables here.

307
01:12:24,500 --> 01:12:30,200
So of course each time at each for each variable K, things might affect that.

308
01:12:31,220 --> 01:12:41,360
So, so basically I have my alpha time t plus x one transpose b2x when I'm not exposed, treated.

309
01:12:42,320 --> 01:12:47,150
And then the same thing here. But now I add in the component of being exposed or treated.

310
01:12:49,540 --> 01:12:53,000
So and then I just average those.

311
01:12:54,690 --> 01:12:59,800
I can get an estimate this marginal survival risk survival rate at time.

312
01:13:00,370 --> 01:13:04,090
A failure rate essentially survival failure at 20.

313
01:13:08,280 --> 01:13:16,550
So and I can bring in full time very hazard ratios by adding product terms that can exposure and follow up.

314
01:13:16,560 --> 01:13:22,440
So essentially when I go to do this, this part of the modeling here, I have an interaction.

315
01:13:27,260 --> 01:13:38,510
Between X and D. And as well as between Jackson,

316
01:13:39,440 --> 01:13:47,480
Andy and then Beck and bootstrap is probably the best way to deal with variance estimation

317
01:13:48,500 --> 01:13:52,040
when quick as you don't want to recap you propensity score summary sample data.

318
01:13:52,250 --> 01:13:59,330
Right. So you just attach propensity score to the particular observation and we sample that.

319
01:14:10,430 --> 01:14:13,790
So it's great if we have a randomized trial setting.

320
01:14:14,930 --> 01:14:23,160
If we don't have that and we can play our usual old game of benefit scores in inverse probability weights to create estimates

321
01:14:23,180 --> 01:14:27,680
of the probability of survival and the survival functions that are essentially randomized with respect to observe covariance.

322
01:14:29,420 --> 01:14:42,950
So. Basically I'm just fitter like Aussie model exposure or treatment given x and creator awaits.

323
01:14:44,880 --> 01:14:53,560
Right. And then whether they're actually treater exposed, treated or not exposed or not.

324
01:14:54,670 --> 01:15:00,610
And then we just use weighted S2 meters. And then other nice thing about the screen time event models is really using weights.

325
01:15:00,640 --> 01:15:03,640
Could you just just generalized in your model? Right.

326
01:15:03,640 --> 01:15:11,470
So you can just choose the survey packages which typically nowadays deal with generalizing your models and that's that.

327
01:15:13,530 --> 01:15:23,630
Okay. So I think for diving into the sample, I will stop here and we'll pick that up Wednesday.

328
01:15:23,660 --> 01:15:29,050
Any any questions before we wrap up? Okay.

329
01:15:30,240 --> 01:15:37,040
So I have office hours today and keep an eye out.

330
01:15:37,050 --> 01:15:42,270
I'm trying to finish up what will be the last set of class notes, trying to decide where I want to push things out.

331
01:15:43,320 --> 01:15:48,450
But they'll be posted at some point and we will get to them Wednesday.

332
01:15:48,450 --> 01:15:53,400
So, you know, before then. And I guess that's.

