1
00:00:00,030 --> 00:00:05,219
Ah. Yes. Suggests that they would just sit quietly for the rest of the semester.

2
00:00:05,220 --> 00:00:10,440
We have homework for you next Monday. When would homework five be healed?

3
00:00:11,340 --> 00:00:16,840
It's December 17th. Some assignments. So you have one more homework to determine.

4
00:00:18,900 --> 00:00:25,710
Again, there will be homework six. But that will be the the sample exam from lot previous year.

5
00:00:25,780 --> 00:00:30,540
Okay. So you don't need to cover anything but. Yes, good question.

6
00:00:38,300 --> 00:00:48,780
Any other questions? If not, let's talk about this whole song process.

7
00:00:49,230 --> 00:01:13,260
So, of course. So in the previous week, we talked about setting for some process, including the marginal distributions of the member rhythm variable,

8
00:01:13,260 --> 00:01:20,340
including the interval time distribution and a conditional distribution of the right times.

9
00:01:21,720 --> 00:01:24,740
Last time we start seeing a little bit like Malawians,

10
00:01:24,750 --> 00:01:30,690
if we change the conditions like in the polling perspective and if we do the

11
00:01:30,690 --> 00:01:34,800
thinning of a pull song process or do some polling on the plus on process.

12
00:01:35,370 --> 00:01:40,170
So one of the things we did for some polling of the for some process, we did change.

13
00:01:40,290 --> 00:01:48,590
So we find that there's a resulting process with respect to each individual type of event is no longer possible.

14
00:01:48,840 --> 00:01:54,210
So but it's closely related to the Poisson process.

15
00:01:54,630 --> 00:02:06,510
So for the next probably two lectures, we're going to see if we change the definition of standard Poisson process.

16
00:02:07,080 --> 00:02:12,270
More specifically, relax some of the assumptions, what going to happen, we can look at it.

17
00:02:12,540 --> 00:02:16,620
So this is a in general called generalization of Poisson process.

18
00:02:17,130 --> 00:02:22,470
So the first thing we're going to see today is not homogeneous Poisson process.

19
00:02:39,150 --> 00:02:47,400
So homogeneity, hydrogenated use of law and all kinds of the areas of statistics for.

20
00:02:49,250 --> 00:03:00,250
For statistical. For stochastic processes. The homogeneous or the heterogeneous usually refers to the time or in this time heterogeneous.

21
00:03:00,270 --> 00:03:05,670
So in this case, is essentially the kernel of the Markoff process.

22
00:03:06,060 --> 00:03:09,090
Well, it is that later on you will know.

23
00:03:09,530 --> 00:03:23,040
And so that means we change one of or other ways, generalize one of the assumptions in the center Poisson process, but keep the other parts intact.

24
00:03:23,160 --> 00:03:30,960
So let's take a look what I mean by that. So to define a non homogeneous Poisson process, we follow the same.

25
00:03:34,470 --> 00:03:38,129
The same approach, like we defined the full song process, right?

26
00:03:38,130 --> 00:03:45,690
So we can achieve the different assumptions and that so in this case I only

27
00:03:45,720 --> 00:03:53,520
have of the A is the non homogeneous Poisson process is a counting process.

28
00:03:53,880 --> 00:04:01,320
And then with that we naturally have an 000 people notation here.

29
00:04:01,980 --> 00:04:06,580
We're going to use the same thing that you call it.

30
00:04:09,390 --> 00:04:25,260
We still going to have independent increment, meaning so independent increment assumption.

31
00:04:25,260 --> 00:04:34,330
So simply put, if you have two non overlapping time intervals, the event occurred in these two unknown overlapping intervals.

32
00:04:34,350 --> 00:04:37,409
Going to be independent. Not right.

33
00:04:37,410 --> 00:04:43,110
So that's true for any non overlapping integral.

34
00:04:43,410 --> 00:04:51,530
So general way we use as this sort of adjacency interval, this interval versus this interval, but they don't have to be adjacent.

35
00:04:51,690 --> 00:04:56,200
Right, as long as they are not overlapping.

36
00:04:56,220 --> 00:04:59,879
And if they do overlapping though you know,

37
00:04:59,880 --> 00:05:08,610
that doesn't satisfy the the condition for independent increment that the reason they're they have to

38
00:05:08,610 --> 00:05:16,890
be dependent on the reason because they share the same amount of the time that information is shared.

39
00:05:17,730 --> 00:05:22,350
So independent increment is intuitive.

40
00:05:22,470 --> 00:05:30,480
What I mean that's very intuitive for this is last time I said this is stronger than Markov property.

41
00:05:30,480 --> 00:05:35,520
And then when we talk about Markov process, we can go back and revisit this, this condition.

42
00:05:35,700 --> 00:05:39,329
But independent increment indeed implies.

43
00:05:39,330 --> 00:05:42,960
So is it because it's stronger? So that implies the Markov from the actual.

44
00:05:45,670 --> 00:05:47,540
Holes in the whole thing.

45
00:05:47,560 --> 00:05:59,709
So if we have a the so for standard Poisson process where you have stationary increments, meaning the increments of the well,

46
00:05:59,710 --> 00:06:07,300
the number of events occurring within the interval only depends on the interval length and.

47
00:06:08,310 --> 00:06:12,090
On the other hand, it doesn't depend on where the interval is.

48
00:06:12,960 --> 00:06:25,190
On that condition no longer true. This is not a homogeneous Poisson process, so put into a markov process point of view.

49
00:06:25,210 --> 00:06:28,230
So that means the transition kernel is time dependent.

50
00:06:29,160 --> 00:06:38,910
You don't need to know that at this point. But so they're the homogeneous two time homogeneous transition kernel versus so that well,

51
00:06:38,970 --> 00:06:44,820
that's exactly where the name come from is called a non homogeneous Poisson process

52
00:06:44,820 --> 00:06:51,330
because the underlying Markov process is no longer a homogeneous Markov process.

53
00:06:51,560 --> 00:06:57,570
Okay. So we don't have a stationary increment assumption for another homogeneous process process.

54
00:06:59,130 --> 00:07:05,610
And with that, there are some need to be adjustment to define the number of random variables.

55
00:07:05,660 --> 00:07:17,430
Right. So the way we define member random variables in the center Poisson process is defined as an h, h chosen zero.

56
00:07:19,740 --> 00:07:26,330
So this is no longer. So for multiple reasons, this this.

57
00:07:26,340 --> 00:07:40,950
We cannot use it in exactly the same way because there is no stationary increment, only reason and h you only write an h -0.

58
00:07:41,700 --> 00:07:53,820
So this is unchanged, but this random variable, it doesn't have the same distribution as a seed plus h minus, right?

59
00:07:54,060 --> 00:08:05,090
So if you change the anchor point from zero to t, you still get the time interval as small as H, but because you don't have the.

60
00:08:05,220 --> 00:08:15,840
Well, I'm pointing to something that doesn't exist. So the because you don't have the stationary increment, so you cannot say an H here it's the same.

61
00:08:15,840 --> 00:08:27,180
So NH minus and zero, which is just an H is not the same as a T plus h -90 for something.

62
00:08:27,600 --> 00:08:33,479
Right. I can get this because I have a zero equal to zero.

63
00:08:33,480 --> 00:08:40,500
So it didn't happen. H so, so you have to accommodate this complexity.

64
00:08:40,980 --> 00:08:45,360
There is then, but the, the idea would be the same.

65
00:08:45,900 --> 00:09:02,800
But you cannot say something like this. We cannot define in general instead of an H, you cannot define until plus H minus three.

66
00:09:03,210 --> 00:09:06,260
So that's interval with one h.

67
00:09:07,680 --> 00:09:14,040
But is also unheard of. H goes in there but is also unheard of at the time point t.

68
00:09:14,610 --> 00:09:24,959
So the point is this we can define the behavior in this more interval, but that behavior going to be depends on in general depending on t.

69
00:09:24,960 --> 00:09:29,310
So that will also be a function of T in general.

70
00:09:29,340 --> 00:09:33,890
So. But the for the same sort of approach.

71
00:09:33,950 --> 00:09:48,290
What we can do is the probability and try to define this the increment in this small time interval and plus h minus and.

72
00:09:56,460 --> 00:10:08,820
Let's say we are equal to two points. Well, we can still say this one is a wage.

73
00:10:10,080 --> 00:10:20,670
But just so with a small probability being the function representing this, a probability of approaching zero faster than the linear function.

74
00:10:21,100 --> 00:10:25,590
Oh, right. And we need another.

75
00:10:25,900 --> 00:10:35,220
Remember, if we trying to define this, this random goal when you defined the whole distribution, but with all h notation,

76
00:10:35,340 --> 00:10:45,430
you need to define either equal to zero or equal to one, and then add that all the other numbers squared over equal to two.

77
00:10:45,450 --> 00:10:54,570
So this way defines individually. If you're if this is obtained a number where are equal to two that also fall into the category of always.

78
00:10:55,410 --> 00:11:03,900
All right. So the D here you can use you find the zero event.

79
00:11:08,760 --> 00:11:20,250
All right. So it's going to still be a linear function, but it's not going to be the service the same as in the plus on process as a one minus.

80
00:11:20,580 --> 00:11:27,330
So if it was on process, we minus lambda, which is constant multiplied by the H, that's the interval.

81
00:11:28,080 --> 00:11:35,220
In this case, the longest time. It depends on the anchor time t.

82
00:11:43,970 --> 00:11:50,520
Okay. So that's really the difference. And then I have explained the motivation why you need a lambda key.

83
00:11:50,620 --> 00:11:57,069
So in general this probability will be a function of T because we don't have stationary distribution.

84
00:11:57,070 --> 00:12:07,809
So this is sort of a consequence to the lambda t here is reflect the probability

85
00:12:07,810 --> 00:12:12,520
even for the small interval going to be highly dependent on time itself.

86
00:12:13,330 --> 00:12:23,020
But overall he has the the the mark up of the benefits has a similar set up as the full song.

87
00:12:23,710 --> 00:12:28,720
So you get in five from C and D, what is the probability?

88
00:12:34,000 --> 00:12:47,500
All right. So from C plus the implies what is the probability and he wants also H minus and indicates.

89
00:12:48,270 --> 00:12:51,740
Equals one. Right. So that's easy to calculate the right.

90
00:12:51,750 --> 00:12:57,660
So you add up C and D, so you get one minus along the T cross H plus oh H.

91
00:12:58,380 --> 00:13:03,480
I thought this is the only the complement event. So one minus spot value, you get that.

92
00:13:04,020 --> 00:13:16,920
So I'm going to argue this one, this line of T times h that's sort of a fuzzy math for dealing with those H functions,

93
00:13:19,560 --> 00:13:23,530
but you don't need to explicitly put this one into the designation.

94
00:13:23,670 --> 00:13:27,299
It's just the implication from C and D. All right.

95
00:13:27,300 --> 00:13:32,760
So this perfectly defines a non homogeneous Poisson process so explicitly.

96
00:13:32,760 --> 00:13:41,790
If you compare it to the standard, there is no stationary increment assumption and then this accordingly C and D.

97
00:13:42,840 --> 00:13:54,750
Well, actually just be the person rate, but I think your parameter that's important parameter becomes highly dependent.

98
00:13:55,950 --> 00:14:09,840
Okay. Any questions? So this is a what we call that generalization y because you could add more thing to it, right?

99
00:14:09,900 --> 00:14:13,350
So the generalization versus specialization, right.

100
00:14:13,350 --> 00:14:19,170
So the person will be a special lies the non homogeneous process.

101
00:14:19,410 --> 00:14:25,620
If you add in more assumptions in this case, what assumption is that you're probably.

102
00:14:25,920 --> 00:14:34,219
Well you need to add um, in the a station or increment and then well the consequence of that is that a

103
00:14:34,220 --> 00:14:39,750
lot of the T is time independent so long that he becomes a constant so that.

104
00:14:47,690 --> 00:14:54,710
Then this implies so that the nuns homogeneous process becomes a pull song process.

105
00:14:55,430 --> 00:15:00,920
We'll see if the other connections later on. So.

106
00:15:06,380 --> 00:15:11,720
So with this, we could do the similar things as we did before.

107
00:15:14,120 --> 00:15:24,110
So if we find this now homogeneous force on processes, we can ask the question, what is the marginal distribution?

108
00:15:27,170 --> 00:15:37,240
So this is one marginal distribution of benefit.

109
00:15:40,790 --> 00:15:47,630
All right. Again, the question is, we suspect a single random variable and it's a member of this.

110
00:15:50,390 --> 00:15:56,390
Well, you could calculate this or the easy way to reformulate this problem.

111
00:15:56,810 --> 00:16:02,660
What you could do is really ask the question with respect to the increment.

112
00:16:04,160 --> 00:16:07,700
Because this one is an T -0.

113
00:16:07,730 --> 00:16:12,290
Right. So if you if you know an T -0, you know, in T.

114
00:16:12,590 --> 00:16:21,290
But in general, the question we can generalize this question. And we calculate and see that minus.

115
00:16:23,060 --> 00:16:32,450
Right. We just don't require ask to be as small or as goes to zero for general.

116
00:16:32,750 --> 00:16:41,180
So if we know this, then we know cause you just take the equal to zero, then you get this.

117
00:16:44,360 --> 00:16:51,830
So this one is or we cannot tackle today trying to solve the problem for T plus s.

118
00:16:52,730 --> 00:16:58,580
Well, I think we can have the conclusion upfront and then just try to prove that's the case.

119
00:16:59,060 --> 00:17:04,340
So the answer for that is T.

120
00:17:05,680 --> 00:17:18,220
Plus us -90. So this is exactly the event occurred in this interval from T to T plus s with the interval on being s right.

121
00:17:20,440 --> 00:17:23,589
So the answer says this is a poor song.

122
00:17:23,590 --> 00:17:43,860
Random variable. Not surprising with the poor song mean, which is the key parameter s across T minus s and that's all right.

123
00:17:43,900 --> 00:17:51,130
I haven't written what am is, but this is going to be from this function.

124
00:17:51,910 --> 00:18:01,720
So we're asking has this define us integral zero as the why do you want?

125
00:18:03,460 --> 00:18:10,000
Okay, so you see some similarity between this and some form of cosine process to be.

126
00:18:11,470 --> 00:18:22,000
So if you have this definition for the, the mean function with respect to time so this and as plus T so that's a twice.

127
00:18:28,000 --> 00:18:31,060
It's just an integral from us to us.

128
00:18:31,120 --> 00:18:42,100
Plus, he loved the why or the right.

129
00:18:42,110 --> 00:18:54,050
So if you have this much function. So this is always integrated from time zero to we are destination time then the difference right.

130
00:18:54,070 --> 00:18:57,460
So just look at this as a practice of.

131
00:19:00,570 --> 00:19:04,530
You know, this definite integration integral.

132
00:19:04,540 --> 00:19:11,850
So you have the the value of your value is plus t minus the value, evaluate the assets and then that's it.

133
00:19:12,840 --> 00:19:18,870
So graphically, that makes more sense why this is some of the answers you would expect.

134
00:19:19,560 --> 00:19:23,550
So here is why. So what this says.

135
00:19:26,450 --> 00:19:51,100
If you're interested in the the random increment, the interval from 50 to 2 parsecs, then so we have a function which is trying to help.

136
00:19:51,790 --> 00:19:58,130
All right. So the lambda for the, for some cases a constant for these is not.

137
00:19:58,160 --> 00:20:03,020
So let's say there is a curve. Pretty dramatic curve here.

138
00:20:04,100 --> 00:20:07,550
And if we're interested, a from the s to.

139
00:20:08,980 --> 00:20:14,770
S plus t the interval and its t then.

140
00:20:16,120 --> 00:20:22,719
So the conclusion says there is a person run the variable and then the mean of that was not run.

141
00:20:22,720 --> 00:20:25,900
The variable is really the area under the curve.

142
00:20:28,260 --> 00:20:37,940
Right. So now.

143
00:20:39,760 --> 00:20:44,330
And I do compute the area under the curve. You have to use the integral.

144
00:20:44,840 --> 00:20:50,510
Right. Pretty straightforward. And this is again why for some, it's a special case of that.

145
00:20:51,140 --> 00:20:55,220
If you have a standard Poisson process, the Lambda is constant.

146
00:20:56,960 --> 00:21:01,780
Right. So I don't have a different color of fog.

147
00:21:01,790 --> 00:21:05,810
So what do I do?

148
00:21:05,860 --> 00:21:10,450
This. Let's. Let's just draw the. A different one.

149
00:21:12,150 --> 00:21:15,660
So for the standard song process, this argument still applies.

150
00:21:17,550 --> 00:21:21,900
It's a special case of that so that the lambda is a constant.

151
00:21:22,650 --> 00:21:28,950
And now we know from S plus T to sorry from T plus size to T.

152
00:21:32,840 --> 00:21:40,740
As as the continue by the same rule well beyond the area under the curve.

153
00:21:40,980 --> 00:21:46,620
But this is trivial to calculate. You don't need the integral in the to do the integral to calculate.

154
00:21:47,070 --> 00:21:51,060
This is just the rectangle. And then the area is one of the types.

155
00:21:51,810 --> 00:22:00,990
Right. So the this is a and then the rate is constant, the lambda, which is the height.

156
00:22:01,860 --> 00:22:08,160
So a lot of the times t well this is again that's expected if lambda is constant.

157
00:22:08,460 --> 00:22:14,130
This convert to standard force out run the variable and then the area under the

158
00:22:14,130 --> 00:22:20,640
curve instead of that complicated integral becomes just lambda times the right.

159
00:22:20,880 --> 00:22:29,580
So this is a special all this is a generalization and then this is a special case.

160
00:22:32,120 --> 00:22:37,190
Makes sense. All right.

161
00:22:37,370 --> 00:22:41,870
So. So we supposed to prove this?

162
00:22:43,340 --> 00:22:46,460
That's true. And then the way we doing it.

163
00:22:46,820 --> 00:22:52,580
So we could actually start doing the same thing as we did for the Poisson process.

164
00:22:53,170 --> 00:23:03,740
Right. So we figure out what is, for example, what is the distribution, the probability, and T plus, s minus and T equal to zero.

165
00:23:04,700 --> 00:23:08,029
Right. And then we first figure out that.

166
00:23:08,030 --> 00:23:14,990
And then we build upon for the only other way to figure out what's the probability.

167
00:23:16,010 --> 00:23:25,070
Again, this is this random variable, is this great.

168
00:23:27,920 --> 00:23:35,719
So we need to figure out the probability mass function for each value with zero, one, two, three and four, so on, so forth.

169
00:23:35,720 --> 00:23:39,680
That's all of the possible values and then find the corresponding functional form.

170
00:23:40,760 --> 00:23:50,180
So that's what exactly what we did for the Poisson process, the marginal distribution of the run, random variables in the pull out process.

171
00:23:50,360 --> 00:24:02,810
But for, you know, it's for the fun of it or just for a different type of approach, we can use something similar to probability generation function.

172
00:24:03,020 --> 00:24:09,050
Just find them all in one at the same time, same stroke.

173
00:24:09,530 --> 00:24:21,620
So in the sake of the idea is you can have all these different values that run the variable and take it into a sequence and then do that.

174
00:24:22,280 --> 00:24:26,209
You correspond that sequence into a function.

175
00:24:26,210 --> 00:24:33,810
So that's exactly moment generating function. Probability generating function or characteristic generating function.

176
00:24:33,830 --> 00:24:38,750
Those are the ideas. So you do a simple derivation for the generating function.

177
00:24:38,750 --> 00:24:42,470
You recover all these probability mass functions, right?

178
00:24:42,610 --> 00:24:50,780
So, so we're going to do the same, but we don't want to do the boring thing, so we do something relatively new.

179
00:24:50,870 --> 00:24:57,170
So this this time is being called plus transformation.

180
00:25:06,620 --> 00:25:23,920
Which is exact. Well, it's very, very similar to normal general function, but so GST is a large class transformation for the distribution of X.

181
00:25:24,260 --> 00:25:30,410
That's then around the variable is basically the Mormon generating function.

182
00:25:31,040 --> 00:25:44,120
Take the value negativity. So that's the expected value E negativity to X, okay, 4 to 3, 3 to 0.

183
00:25:50,000 --> 00:25:54,530
So is there is no negative sign this becomes a generating moment generating function.

184
00:25:55,100 --> 00:26:01,460
Right. So you could actually working with a moment generating function, there will be the same.

185
00:26:01,730 --> 00:26:09,130
But as I said, I think there is no particularly advantage to use one way or the other.

186
00:26:09,140 --> 00:26:18,860
So this is an opportunity to introduce something existing in history and with a name, especially the.

187
00:26:21,830 --> 00:26:30,740
In some way, I think I suspect I don't know the the fact I think moment generating function must be inspired by a lot plus transformation.

188
00:26:34,310 --> 00:26:43,590
But the idea remain the same. Right. So you have this compact, the representation of the distribution, right?

189
00:26:43,610 --> 00:26:49,760
So you can recover each of these and the probability mass function if you want.

190
00:26:50,120 --> 00:26:52,100
And you should know how to do it, by the way.

191
00:26:54,380 --> 00:27:06,290
But instead of dealing with in finite terms, your where just need to deal with this single function that actually correspond to the,

192
00:27:06,970 --> 00:27:12,740
you know, finite terms or probability you've got probably equal to zero one, two, so on and so forth.

193
00:27:13,100 --> 00:27:21,290
So that's the convenience. So if we figure out the key and then we can figure out the underlying distribution.

194
00:27:21,800 --> 00:27:26,390
So the question here is the target guess is going to be a Poisson random variable.

195
00:27:26,750 --> 00:27:31,700
So what is? The last transformation of a person random variable.

196
00:27:33,850 --> 00:27:45,830
All right. Here. So a lot plus of this formalization.

197
00:27:56,700 --> 00:28:02,300
X person. All right.

198
00:28:02,310 --> 00:28:09,420
So just by the definition that she acts t the transformation says this one has to be.

199
00:28:09,720 --> 00:28:15,360
So instead of the expected value negative piece.

200
00:28:15,360 --> 00:28:29,090
And now we just take that for. For all the plausible values of the persona the viable can take that will be capable of zero to infinity.

201
00:28:31,280 --> 00:28:35,600
The the value is e negative t to the k.

202
00:28:37,010 --> 00:28:41,450
As each travel it we have and then we just need to multiply by the probability.

203
00:28:41,750 --> 00:28:49,130
Right. So the probability acts equal then that's the definition of it.

204
00:28:49,940 --> 00:28:56,210
So you calculate this expectation of this function and then the series batteries that way.

205
00:28:59,330 --> 00:29:00,200
They're pretty simple.

206
00:29:00,200 --> 00:29:13,410
Math behind this is all related to right now the probability of mass function for x equal to which you should be familiar with yet.

207
00:29:16,720 --> 00:29:26,730
And then the other thing is you cannot deal with this series of E to the negative, okay?

208
00:29:26,730 --> 00:29:32,560
K that you could also get a analytic solution.

209
00:29:33,160 --> 00:29:36,640
So this one is tricky. So we have e to the negative.

210
00:29:37,660 --> 00:29:44,170
So you have an exponential function on the exponent of a exponential function.

211
00:29:44,290 --> 00:29:52,860
All right. So it's negative lambda. So this one, at the end of the day, it's exponential function lambda.

212
00:29:54,390 --> 00:29:58,710
E to the 90 Nike T minus one.

213
00:29:59,520 --> 00:30:03,180
All right. So this is the form we're looking for.

214
00:30:04,140 --> 00:30:09,420
So you want to assert something is up for some random variable.

215
00:30:10,290 --> 00:30:14,670
We know the lambda is going to be here. This is can be factories rise.

216
00:30:15,150 --> 00:30:23,100
And then within the parentheses, you should always have the E to the negative T minus one for the.

217
00:30:26,710 --> 00:30:35,140
This is really not important, but it's just showing you there are different ways we can, you know,

218
00:30:35,230 --> 00:30:44,170
find the old the probability match function for certain to run the variables in a single in the in.

219
00:30:48,190 --> 00:30:52,980
You just one at first. Okay.

220
00:30:53,070 --> 00:30:57,780
So we hide that a little bit because we want to compare our result to this to

221
00:30:57,780 --> 00:31:03,210
be able to show that this one isn't this important and that we go back to.

222
00:31:04,320 --> 00:31:16,590
Set up the equation and try to solve for us any questions so far.

223
00:31:21,900 --> 00:31:27,540
So this is the second time we're dealing with trying to do this problem.

224
00:31:27,540 --> 00:31:37,620
The first time we're trying to figure out that we'll solve this in the standard post process and figure out what the distribution is.

225
00:31:39,300 --> 00:31:44,710
In this case, we need a few. Notations.

226
00:31:45,070 --> 00:31:56,680
So this is an ass. So this one is notation going to be a bit more complicated than the Poisson case because the anchor point matters.

227
00:31:57,050 --> 00:32:00,800
There's no longer the station or increment.

228
00:32:00,850 --> 00:32:08,000
So the anchor point matters. So this one, we use this use this as a defined anchor point.

229
00:32:08,020 --> 00:32:12,900
So this is actually this.

230
00:32:21,180 --> 00:32:31,590
So they're going to be. Confusing things in the notation because unfortunately we use.

231
00:32:37,140 --> 00:32:43,300
But different things. Okay. So so this is this is the anchor point here.

232
00:32:43,840 --> 00:32:51,610
The other thing is, if we do the class transformation, we're going to.

233
00:32:54,390 --> 00:33:11,130
So to me, so this is a function of in that case, the T or the T of different in that one is t is just.

234
00:33:12,440 --> 00:33:18,799
It's not the time here that he is the time. And so we have to change the life loss transformation.

235
00:33:18,800 --> 00:33:27,250
Instead of using heat, we use meal here. And then the the variable we're interested is down here and.

236
00:33:32,950 --> 00:33:36,490
So this one is an expected value.

237
00:33:37,480 --> 00:33:40,890
Just a definition. You and us.

238
00:33:44,260 --> 00:33:48,510
And then. Two of.

239
00:33:51,370 --> 00:33:58,670
Sorry. So the back for this. So for the ease of my own writing.

240
00:33:58,690 --> 00:34:07,960
I'm going to call this publishing job. I know it's confusing, but bear with me.

241
00:34:08,140 --> 00:34:15,340
At least I explain. Right. So the so the meal will be a remain the same during the derivation.

242
00:34:15,350 --> 00:34:19,300
So the t is a point of interest. So this is T.

243
00:34:19,840 --> 00:34:23,380
But don't look at that. Look at me here.

244
00:34:28,150 --> 00:34:32,140
And then there will be a s plus.

245
00:34:42,180 --> 00:34:46,750
So as you age you.

246
00:34:47,670 --> 00:34:51,070
All right. So this is the same idea.

247
00:34:51,090 --> 00:34:57,360
So what is the most important thing here? The most important thing here is our set up.

248
00:34:58,290 --> 00:35:05,850
Our overall strategy still follows this so-called growth forward equation.

249
00:35:06,270 --> 00:35:21,659
So you look at a time window from zero to as and then to as plus T, right?

250
00:35:21,660 --> 00:35:34,590
So now is where trying to figure out this part of the thing and then we kind of look forward to as plus t points estimates.

251
00:35:35,640 --> 00:35:40,920
Las Vegas. So the ACA is just an anchor point and it's actually not important.

252
00:35:41,490 --> 00:35:46,290
The important thing is you have these two segments.

253
00:35:46,740 --> 00:35:53,100
One is the Beat segment from zero to ASP plus T, and then the other one is the small segment.

254
00:35:53,400 --> 00:35:56,070
You look forward just a little bit.

255
00:35:56,460 --> 00:36:06,590
The reason of doing that is because we know the behavior, the random behavior within the small window that's given by the definition.

256
00:36:06,600 --> 00:36:14,100
So we so we still keep this overall. So we're interested in the anchor point as the T.

257
00:36:14,220 --> 00:36:19,100
So that's compared to this random variable, which is look a little bit older.

258
00:36:20,400 --> 00:36:34,530
So that's the important thing, right? Plus H and that by this notation we're going to call this G sausage.

259
00:36:36,270 --> 00:36:42,569
Essentially, this is just trying to capture the most important part and then basically say, oh,

260
00:36:42,570 --> 00:36:52,710
the other things are within this function, like the parameters doing our reasoning going to be kept constant like the anchor point as.

261
00:36:55,050 --> 00:37:00,480
The view here for the for the last transformation.

262
00:37:00,690 --> 00:37:15,650
All right. So this notation are important. Notation is the most difficult thing you're ever tried to write a paper.

263
00:37:22,160 --> 00:37:25,970
There's some sort of a contradiction between different connections.

264
00:37:26,990 --> 00:37:33,920
You will figure out that when you actually write down things. All right.

265
00:37:34,100 --> 00:37:41,479
With that. So. So the idea of that forward equation,

266
00:37:41,480 --> 00:37:57,760
the core macro forward equation is trying to relate the anti PI to relate this random variable to an acid

267
00:37:57,850 --> 00:38:07,400
plus because we know the behavior of this process in the small window and the increment in the small window.

268
00:38:07,730 --> 00:38:14,510
So we can set up some different equations and then we can turn that differential equations into differential equations.

269
00:38:15,290 --> 00:38:19,100
Finally, by solving the differential equation, we get what we want.

270
00:38:19,460 --> 00:38:23,540
So that's the idea. That's really the very simple idea.

271
00:38:23,540 --> 00:38:30,079
There's nothing fancy about this. It's almost all these continuous, random, stochastic process.

272
00:38:30,080 --> 00:38:37,500
Follow this this type of the idea. Later on, we say there is a different way to set up this type of the equation.

273
00:38:37,500 --> 00:38:42,890
That's called a backwards equation. But for now, we just focus on the forward equation.

274
00:38:43,040 --> 00:38:57,060
Okay. All right. So to do that, let's take a look at the equivalent representation of this of this random variable, which is Laplace transformation.

275
00:38:57,100 --> 00:39:00,380
So as we said, we're going to call this T plus H.

276
00:39:02,480 --> 00:39:07,730
There is no meal. There is no S. It's all hidden from us for now.

277
00:39:07,960 --> 00:39:20,050
But so this one is expected value of negative mirror.

278
00:39:20,330 --> 00:39:27,390
And as you do it once h this is just the definition again.

279
00:39:29,930 --> 00:39:38,240
So what we're going to do is relay this to ask t so we could easily do that by.

280
00:39:42,490 --> 00:39:45,880
Recently and as he.

281
00:40:03,490 --> 00:40:13,600
So if that makes sense. So we've just artificially created the increment, right by subtract subtraction last year and then add this back.

282
00:40:14,050 --> 00:40:18,580
So now you have an iced tea at the end?

283
00:40:18,910 --> 00:40:34,140
Well, I'd be. So this is as this is as plus t as plus the key plus h.

284
00:40:35,370 --> 00:40:40,320
So h. I mean this here. Right.

285
00:40:40,330 --> 00:40:46,810
So we we put so this is about a increment in there because we know the distribution.

286
00:40:47,260 --> 00:40:57,310
This is what we don't like that. So what we get here is expected value e to the U.

287
00:40:58,720 --> 00:41:06,280
S t because this is a exponential function.

288
00:41:06,310 --> 00:41:12,750
So within this. Multiply by.

289
00:41:39,730 --> 00:41:43,540
Right. So because of the exponential function, I can separate this two terms.

290
00:41:43,540 --> 00:41:47,620
Basically factor all the the. Unless you are.

291
00:41:53,910 --> 00:41:57,120
All right. I think that achieved the goal.

292
00:41:57,450 --> 00:42:02,440
So the other thing is now we have the iced tea.

293
00:42:02,460 --> 00:42:08,190
So so this is related to what happens in from zero.

294
00:42:08,520 --> 00:42:13,290
Right. So this is the anchor point is a zero to S plus T.

295
00:42:13,290 --> 00:42:20,459
So that's the total increments or the counting of the count of the event occurred between zero and

296
00:42:20,460 --> 00:42:28,680
that S plus T and then this increment s plus T plus or minus X plus t is this interval will happen,

297
00:42:28,860 --> 00:42:38,670
right? So the number of events occur in this and then obviously they are not overlapping because of the independent increment.

298
00:42:38,790 --> 00:42:48,370
So those two random variables, these and these are independent and then we can factor that out from the expectation.

299
00:42:49,380 --> 00:43:01,410
So what we're going to get is expected value E and s T and then times because of independence, we can do this generally.

300
00:43:01,410 --> 00:43:21,830
You can't. Expected value, meaning as you plus h minus this by the way this is again the.

301
00:43:25,720 --> 00:43:28,840
It's just the different notation, but the same thing.

302
00:43:30,280 --> 00:43:36,700
Right. That's clear. So this is important that you need to invoke improvement here.

303
00:43:39,350 --> 00:43:46,730
All right. I want to keep this, but, um, I want you to have that on your note, hopefully.

304
00:43:49,250 --> 00:43:56,060
So the first term is just G of T, that's the first term.

305
00:43:58,160 --> 00:44:07,870
And then the second term starts with.

306
00:44:08,990 --> 00:44:35,270
So this is geography. You multiply by the expected you as h minus as, all right, so that's how far we got.

307
00:44:35,870 --> 00:44:44,270
Um, but the good thing is now we just need to deal with this difference in the small window,

308
00:44:44,630 --> 00:44:51,600
and now we can actually expand those right by conditioning on what the actual values are.

309
00:44:51,740 --> 00:44:55,250
Meaning we can calculate the expected value.

310
00:44:55,700 --> 00:45:05,540
Um, in this. So, so let's just focus on con you.

311
00:45:10,250 --> 00:45:15,700
Nice to meet me. So this one.

312
00:45:17,560 --> 00:45:24,460
Just enumerate all possible values this can take. So this is a new kind of zero.

313
00:45:24,520 --> 00:45:32,319
So what is the probability that no event occurs during this small window check?

314
00:45:32,320 --> 00:45:46,450
The definition is going to be one minus along the Assam, plus T times h.

315
00:45:49,330 --> 00:46:03,720
Possible h. So if it's take zero value then you are looking for the small window from as a plus T So

316
00:46:04,310 --> 00:46:14,820
I can just point this as well this option as plus h the window size h1h goes to zero.

317
00:46:15,420 --> 00:46:24,569
This zero event occurs is must be one minus the anchor point is s plus t multiply by age also h.

318
00:46:24,570 --> 00:46:44,350
So that's one. You know, this one, I tell you, is as close to times, age plus old age, and then you can start writing for old.

319
00:46:44,800 --> 00:46:51,450
This the value taking us on the taken is two, three, four.

320
00:46:51,810 --> 00:46:55,810
All of those are old age, right? When they don't add up.

321
00:46:55,830 --> 00:47:00,209
They still age. So I'm just saying e to the negative new here.

322
00:47:00,210 --> 00:47:05,850
New is positive. And so it's a constant.

323
00:47:06,120 --> 00:47:13,410
What's your spec to you here? So everything else is just right in that comparison.

324
00:47:13,920 --> 00:47:25,930
So it looks of complicated to write the expectation, but we can take advantage of the the small window definition, right?

325
00:47:25,950 --> 00:47:31,290
So your only thing is to retain all these zero one race of them.

326
00:47:31,440 --> 00:47:35,040
O h and then that falls.

327
00:47:37,030 --> 00:47:43,959
Giving you this particular form. And then all the old age, for all the old age function,

328
00:47:43,960 --> 00:47:50,380
multiply by a constant oh the multiply by constant you can further absorb into this

329
00:47:50,980 --> 00:48:06,280
oh h and then finally write this way to the infinity into the muc probability.

330
00:48:07,130 --> 00:48:16,180
Um, it's mostly a plus h minus and he equals k.

331
00:48:18,580 --> 00:48:28,340
So this whole thing because of these are considered, you know, h okay.

332
00:48:29,170 --> 00:48:36,200
Just for the complete. All right.

333
00:48:36,290 --> 00:48:40,210
So you can combine you can further combine all the functions.

334
00:48:42,260 --> 00:48:48,740
And so eventually it gives you.

335
00:48:59,060 --> 00:49:05,440
Equals one minus along the plus t h.

336
00:49:17,750 --> 00:49:22,880
I come from the first term this e to the zero term again there's.

337
00:49:30,800 --> 00:49:35,060
So this is not long the times as. See, it's just a function.

338
00:49:39,740 --> 00:49:45,760
All right. So this one equals what?

339
00:49:46,330 --> 00:49:49,390
This one? According to our notation, this is a G.

340
00:49:54,400 --> 00:50:02,610
This is just the expected value of that new.

341
00:50:06,000 --> 00:50:22,590
And once H minus and that's we need to plug this back into that g t equation we have

342
00:50:23,130 --> 00:50:31,840
so we have g t plus h equals g of T and then multiplied by this expected value.

343
00:50:31,860 --> 00:50:36,350
Right. And then we just need to rewrite this one minus one.

344
00:50:36,400 --> 00:50:46,470
But that's plus t h e to you must be h.

345
00:50:47,340 --> 00:50:51,750
And then you could write the whole thing as a wage.

346
00:50:52,780 --> 00:50:59,220
Right. Again, this g of t is going to be found, this positive number multiplied by always.

347
00:51:00,780 --> 00:51:09,400
So that's a. Yeah.

348
00:51:10,510 --> 00:51:13,930
All right. So this is the key equation.

349
00:51:13,940 --> 00:51:19,090
The difference does the difference in equations we get from the definition of the problem.

350
00:51:20,290 --> 00:51:32,890
It's actually nothing fancy. The only thing is it's tedious in the way you have to consider all of these, you know, all of these notations.

351
00:51:33,280 --> 00:51:37,030
But it's really very simple thing to do.

352
00:51:39,430 --> 00:51:43,050
I mean, you know, the bookkeeping is tedious for sure.

353
00:51:44,230 --> 00:51:54,639
But once you have this equation, you realize this the left hand side is a G plus T H on the right hand side, it's a g t, so you can make a difference.

354
00:51:54,640 --> 00:52:04,210
Form a, make make of the make it like a derivative.

355
00:52:04,690 --> 00:52:14,080
Please look at the formal derivative in the sun's g t divided by h, right?

356
00:52:14,740 --> 00:52:31,510
So on the left hand side you get g t t right.

357
00:52:34,720 --> 00:52:42,580
So if your so those are algebra and that was o h divided by h.

358
00:52:43,750 --> 00:52:50,570
So what I did is move this term to the left and then collect all the terms on the number on the right,

359
00:52:50,590 --> 00:52:57,550
the remaining terms on the right hand side on separate from the O, h and then dividing both sides by H.

360
00:52:59,260 --> 00:53:06,670
All right. Up to this point is pretty straightforward. And the last thing to do is take a limit left h goes to zero.

361
00:53:09,100 --> 00:53:18,520
And then you can do that. So you're got to get g t prime equals.

362
00:53:21,180 --> 00:53:24,960
Long the t.

363
00:53:26,640 --> 00:53:33,540
E to the new ordinance one. So this is the differential equation.

364
00:53:35,090 --> 00:53:46,890
We got. We're solving.

365
00:53:47,130 --> 00:53:54,500
With respect to T, right. So T is the interval length from as plus tea.

366
00:53:58,530 --> 00:54:04,650
Yeah. So that's not did not that working. So there is a s s plus T.

367
00:54:05,670 --> 00:54:09,180
So this is how far away from your anchor point that's.

368
00:54:14,900 --> 00:54:25,700
Consider the lambda is known at least two for every value of t, so this is still a easy sort of differential equation to solve.

369
00:54:26,280 --> 00:54:29,390
And you see, you might need to say how to solve it.

370
00:54:37,540 --> 00:54:51,110
Oh, I'm sorry. I think I made a mistake here. So this is a prime private device like sorry equals this.

371
00:54:51,150 --> 00:54:55,450
Otherwise, there is a cheeky function on the right hand side.

372
00:54:56,490 --> 00:55:02,370
If you take limit and then divide by 20 on both side, you get this.

373
00:55:02,820 --> 00:55:12,700
So the reason to write in this form, that should remind you if you take the derivative of log GTD.

374
00:55:13,020 --> 00:55:16,230
So those are positive for sure. So you can take a log.

375
00:55:16,440 --> 00:55:23,340
So you could take log. This one equals one over time, right?

376
00:55:24,480 --> 00:55:34,080
So to make it this form, so, you know, this right left hand side is it's a it's a derivative of the long of g.

377
00:55:43,660 --> 00:56:06,880
Okay. Next of all, solving you don't need to know how to solve this, but of what?

378
00:56:07,450 --> 00:56:14,040
So the other way is this one is a dialog party.

379
00:56:15,880 --> 00:56:20,080
So you can integrate that from zero to a T on the left hand side.

380
00:56:20,080 --> 00:56:34,810
On the right hand side, you can as the DP and then there is a constant X minus one.

381
00:56:35,440 --> 00:56:41,110
We just get to that. All right. So so you already see some of the things emerge from this.

382
00:56:42,610 --> 00:56:56,680
At the end of the day, you get G and S plus T involves the exponential function.

383
00:57:02,030 --> 00:57:08,630
Zero to the mom. That's why you lie.

384
00:57:09,470 --> 00:57:12,650
So this whole integral you cannot get rid of.

385
00:57:13,850 --> 00:57:17,749
I want us to be consistent.

386
00:57:17,750 --> 00:57:21,680
So this isn't the key. But I change. This would be why this doesn't change anything.

387
00:57:24,210 --> 00:57:27,510
So this whole thing multiplied by.

388
00:57:34,950 --> 00:57:38,680
All right. I think that's the end of these.

389
00:57:39,600 --> 00:57:51,329
Right. So the only point is just compare this lackluster transformation to the ones we previously written for the person.

390
00:57:51,330 --> 00:57:59,790
Random variable. Right. So just remember now, instead of a T, we have a meal here, the meal corresponding to T here.

391
00:58:00,180 --> 00:58:05,250
So you see this part, that means the whole thing is a person random variable.

392
00:58:05,670 --> 00:58:12,540
And then by connecting the functional form.

393
00:58:12,990 --> 00:58:15,240
Now you know this is a poor song.

394
00:58:17,010 --> 00:58:28,980
And then the poor song, meaning parameter or the plus rate parameter lambda is indeed that this is this pretty complicated.

395
00:58:35,040 --> 00:58:38,849
So. So this is a zero to t okay. So let me right this way.

396
00:58:38,850 --> 00:58:46,679
So that's lambda as was y the UI, right?

397
00:58:46,680 --> 00:58:49,560
So this is also the same as possible.

398
00:58:50,940 --> 00:59:08,220
So you can change the starting point as, as the lambda y can be y so those are the same right thinking about the curves on the area under the curve.

399
00:59:08,400 --> 00:59:15,360
So if you do zero to t so you're just changing the region of the integration, right?

400
00:59:16,500 --> 00:59:26,250
So you can do. So you're kind of representing this in two different forms if it's a zero 30 and you just calculating the aria on the curve here.

401
00:59:26,730 --> 00:59:32,070
So you count this as anchor point zero, or you could using the, um.

402
00:59:33,580 --> 00:59:40,240
Absolutely zero. And then just calculate the bigger area, subtract the ones that's overlapping.

403
00:59:43,030 --> 00:59:48,010
Okay. Nothing really fancy going on here.

404
00:59:48,220 --> 01:00:05,710
So the key idea is still what we could achieve by setting off the base for the creation of the for the friends equation.

405
01:00:06,010 --> 01:00:11,140
And now we can get the forward differential equation. In this case, we can solve for it.

406
01:00:19,420 --> 01:00:29,420
A homework function is to think about the entire arrival time distribution thing.

407
01:00:29,470 --> 01:00:34,780
So now, with no time to define this process,

408
01:00:35,230 --> 01:00:45,309
we know the the random increment from S plus T 20 follows of course on distribution and

409
01:00:45,310 --> 01:00:53,050
then suppose on me mean this actually area under the curve defined by the re function.

410
01:00:54,640 --> 01:01:04,870
So this is a really clever. And then the question is can you think about, you know, just like what we did for the standard Poisson process,

411
01:01:05,230 --> 01:01:10,330
what is the interval of time between the first divided between the second or third?

412
01:01:11,170 --> 01:01:15,070
Are they still independent right interval time?

413
01:01:15,460 --> 01:01:19,260
Are they still in the right?

414
01:01:19,270 --> 01:01:22,840
What's your intuition? Are they going to still going to be independent?

415
01:01:30,590 --> 01:01:34,650
Are they going to be IED? Unlikely.

416
01:01:36,100 --> 01:01:39,810
The rate is changing, so it cannot be so. In that case, the.

417
01:01:40,330 --> 01:01:44,140
Um. Yeah. They are still going to be independent.

418
01:01:44,680 --> 01:01:50,899
So it's still. Well, I mean, you at the end of the day, I think in a few weeks you're will know all of these.

419
01:01:50,900 --> 01:01:58,959
Some are called process have at least the the ones we we have the Markov properties built

420
01:01:58,960 --> 01:02:07,420
in they all have independent exponential distribution for the inter arriving in time,

421
01:02:07,810 --> 01:02:11,230
but usually those inter arrival time are rate dependent.

422
01:02:11,770 --> 01:02:17,490
In this case the re this time even this time variant.

423
01:02:17,560 --> 01:02:27,860
So. So that gives you no longer give you the distribution, but still you can simulate those.

424
01:02:28,130 --> 01:02:33,320
But it's your job when you get back and then trying to figure out what is the.

425
01:02:36,840 --> 01:02:40,770
What is the, um, the interactive time distribution.

426
01:02:42,540 --> 01:02:47,190
Okay. So, well, the other thing we could do is we could, uh.

427
01:02:48,000 --> 01:02:51,900
So now this is a poor song. Now, homogeneous for song process.

428
01:02:52,500 --> 01:03:04,230
Another sort of a homework problem. That's the last thing you do when you get back is to revisit some poorly.

429
01:03:08,400 --> 01:03:24,270
Of course. So so last time we did this for a different.

430
01:03:24,390 --> 01:03:29,340
So somehow the old person processes the events has subtypes.

431
01:03:29,790 --> 01:03:39,660
Right. So in the thinking of the Poisson process, the subtype classification is the environment is respect to time.

432
01:03:39,870 --> 01:03:45,860
So you have a fixed classification probabilities with respect to all possible events.

433
01:03:45,870 --> 01:03:49,270
And then all of those events are mutually exclusive.

434
01:03:49,320 --> 01:04:00,630
The types of events are mutually exclusive. Now, the sum of a person process says that classification probabilities are on time dependent.

435
01:04:01,030 --> 01:04:08,580
It's now that you have a and then what we said is we didn't really say, what is that?

436
01:04:08,930 --> 01:04:14,250
What is the the nature of the process for each SAP event?

437
01:04:14,820 --> 01:04:21,120
I think now it's up to you to show on each of the stop event 90.

438
01:04:25,050 --> 01:04:32,630
So the overall events are still Poisson. But if you look at the thing they induced on.

439
01:04:33,920 --> 01:04:38,360
So casting process for each event once.

440
01:04:41,390 --> 01:04:51,800
So what are those stochastic process? Obviously these should be connect to the non homogeneous person and then you should be able to prove it.

441
01:04:52,160 --> 01:04:57,260
The way to prove it is not really derive those Laplace transformations.

442
01:04:57,320 --> 01:05:09,170
It's really checking the definition. Okay.

443
01:05:09,530 --> 01:05:14,950
So we still have time.

444
01:05:14,960 --> 01:05:31,640
Let's talk about this. So this is, you know, so this is one general generalization of all songs process favorite movie.

445
01:05:39,340 --> 01:05:48,390
By removing stationary increments.

446
01:05:59,170 --> 01:06:13,180
Similarly, there is another type of force on event process that's called conditional on itself the process.

447
01:06:18,940 --> 01:06:27,510
So in this case, we will keep the stationary increment intact.

448
01:06:27,520 --> 01:06:31,900
Well, sort of intact, but trying to remove.

449
01:06:31,960 --> 01:06:40,960
So let's define that conditional force some process and then zero zero.

450
01:06:43,180 --> 01:06:56,050
Yancey So this is stationary. So if we leave a stationary increment there.

451
01:06:57,430 --> 01:07:02,930
But trying to relax. On the independent increment.

452
01:07:04,250 --> 01:07:12,500
Okay. So this is not really a concept that related to much about probability theory, but this kind of the concept,

453
01:07:12,500 --> 01:07:19,760
what we're going to do is related to the concept of how you approach a random variable versus a constant.

454
01:07:20,720 --> 01:07:31,190
Okay. So in this case, we can invalidate the make the this stationary increment.

455
01:07:32,120 --> 01:07:42,230
We can relax. Let's say that stationary increment assumption a little bit by saying the lump,

456
01:07:42,800 --> 01:07:54,050
the rate of the lambda is no longer a constant, but it come from the sample distribution by, say, a comma distribution.

457
01:07:55,670 --> 01:08:01,950
Right. So this is a rather a statistical concept that rather than saying I'm thinking about if you're.

458
01:08:01,970 --> 01:08:06,020
So in this case, this is a called a conditional Poisson process.

459
01:08:06,740 --> 01:08:07,220
Okay.

460
01:08:07,970 --> 01:08:23,000
We don't we no longer have a process which the Lambda is a view that as a constant is that every time we're trying to simulate the Poisson process,

461
01:08:23,420 --> 01:08:32,070
we're going to draw the line from a distribution. So if you saw a Bayesian, that's pretty a natural thing to do, right?

462
01:08:32,100 --> 01:08:36,479
Everything is random. Even though it's a it's a it's a parameter.

463
01:08:36,480 --> 01:08:40,170
You don't know that you're thinking about. You're drawing from some distribution.

464
01:08:40,770 --> 01:08:50,280
Now, if you draw the lambda from a distribution and then I hope I wish you would, you can think about those conditions.

465
01:08:50,580 --> 01:08:58,530
Lambda Coming from a distribution and taking into account the fact that Lambda is a random variable now.

466
01:09:02,090 --> 01:09:06,260
Do we still have four, of course, on process.

467
01:09:06,260 --> 01:09:09,590
Do we still have independent increment?

468
01:09:11,420 --> 01:09:14,510
Right. Um. The correct answer is not.

469
01:09:14,900 --> 01:09:18,710
Um, so this is called a conditional pause on process.

470
01:09:19,070 --> 01:09:23,959
So what it does is, is that of a six alarm claim.

471
01:09:23,960 --> 01:09:29,980
It's a constant. Every time I simulate this process, I'm gonna draw the lambda.

472
01:09:30,170 --> 01:09:34,900
And then conditional on that. I have a00.

473
01:09:34,910 --> 01:09:44,870
I have independent conditional on the lockdown and I have a stationary increment and then I have a rest of the the definition for the Poisson process.

474
01:09:45,230 --> 01:09:55,460
However, the independent increment becomes conditional independent of.

475
01:10:01,090 --> 01:10:26,240
And. So this is the second part of if you can change this, then this is still you know, it's a derivative of a Poisson process.

476
01:10:26,250 --> 01:10:34,680
Instead of saying Columbus fixed, I draw the number from the, you know, the point of view of synthesis.

477
01:10:34,980 --> 01:10:45,270
If you consider the randomness of lambda, then you don't have independent increment anymore.

478
01:10:45,600 --> 01:10:51,370
Why is that? What is the reason they are no longer independent?

479
01:10:54,460 --> 01:10:59,410
So mathematically, to argue for something as independent is not necessarily easy.

480
01:10:59,590 --> 01:11:06,100
But intuitively our view of something is independent is very easy if they share information on something unknown.

481
01:11:07,330 --> 01:11:12,010
So if you know how to intervals, they share the information about lambda.

482
01:11:12,700 --> 01:11:17,100
And in most cases lambda is constant and that's public knowledge.

483
01:11:17,120 --> 01:11:20,770
So there's no information if there's something as a constant.

484
01:11:21,040 --> 01:11:24,640
But if Lambda is a random, it's very different.

485
01:11:25,120 --> 01:11:30,940
So you can estimate Lambda thinking about the more integrals you know and the more knowledge you know about the.

486
01:11:31,990 --> 01:11:39,129
So. So this is no longer, you know, the overall process.

487
01:11:39,130 --> 01:11:42,280
If you're adding some polling step on the lambda,

488
01:11:42,370 --> 01:11:52,059
this whole process is no longer standard for some process because there is a obvious violation of the independence increment condition.

489
01:11:52,060 --> 01:11:58,600
But still, the process is not hard. Actually, you should treat all of these Poisson processes in practice.

490
01:11:59,110 --> 01:12:04,419
You know, if you are trying to apply a person process to a practical question,

491
01:12:04,420 --> 01:12:11,940
you should treat those RS conditional plus on process because the lambda is usually among the few or I mean know that you know,

492
01:12:11,980 --> 01:12:17,380
for you the inference problem you probably don't know anything about and you need to estimate from the data.

493
01:12:17,740 --> 01:12:23,500
So this point of view is important only if you know the lambda, you are independent.

494
01:12:23,530 --> 01:12:25,930
If you don't and there is not.

495
01:12:27,220 --> 01:12:34,540
The other interesting point probably we don't have time for today is we're going to see if you look at the overall process,

496
01:12:34,540 --> 01:12:41,020
meaning when you consider the randomness of the lambda,

497
01:12:41,540 --> 01:12:49,330
you still have this stationary increment that's looking from the point of view of conditional pause on process.

498
01:12:49,900 --> 01:13:02,020
Do we still have the stationary increment intact if it's defined in such a way as to suspend or pull some conditional on the optics drawing from this,

499
01:13:02,500 --> 01:13:07,420
and then the conclusion is true. You still have stationary increment, but.

500
01:13:09,290 --> 01:13:13,160
We'll talk about that next time. So next Monday we will.

501
01:13:14,450 --> 01:13:25,670
Talking about generalizations building stochastic process on call pulse plus on process although personas very simple why you add more things into it,

502
01:13:26,000 --> 01:13:37,790
it can be very, very complicated. As a matter of fact, if you have you know, there are some multiple versions of stochastic processes in the compass,

503
01:13:38,220 --> 01:13:43,090
you feel nervous, stochastic processing from IUI.

504
01:13:43,220 --> 01:13:51,210
So this operation, this research will deal with this for some process for very difficult problem.

505
01:13:51,390 --> 01:13:56,660
The next time we get the snapshot on the edge of that title.

506
01:13:58,260 --> 01:14:01,810
Let's see if you have this.

507
01:14:01,850 --> 01:14:10,520
Get your exam paper and get you ready.

