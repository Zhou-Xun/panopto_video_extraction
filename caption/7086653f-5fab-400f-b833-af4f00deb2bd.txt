1
00:00:17,440 --> 00:00:21,820
Okay. Let's get started with this story.

2
00:00:24,370 --> 00:00:38,140
Okay. Um. So just to set expectations, though, there is, uh.

3
00:00:39,940 --> 00:00:49,049
Uh. There's a midterm assignment due this Wednesday night.

4
00:00:49,050 --> 00:01:00,450
I actually do not realize I am I over overlook that the Wednesday was during the break so I

5
00:01:00,450 --> 00:01:07,230
probably should have given the deadline to Tuesday but I'm not going to change it because,

6
00:01:07,590 --> 00:01:11,610
you know, some some of some of you might have relied upon it.

7
00:01:12,300 --> 00:01:17,220
But, uh, yeah. So deadline is Wednesday night.

8
00:01:17,220 --> 00:01:22,050
But hey, it's better if you finish.

9
00:01:22,290 --> 00:01:28,409
I mean, I don't I don't want to be I don't want to mean that you have to work during the holiday break.

10
00:01:28,410 --> 00:01:31,450
So that was not my message.

11
00:01:31,450 --> 00:01:38,660
You, you know, you know, try to try to finish by Tuesday night and that'll be that.

12
00:01:38,810 --> 00:01:52,350
That would have been my expectation. Okay. So and there will be no Wednesday, Wednesday lecture, obviously, next season next week.

13
00:01:52,350 --> 00:01:56,520
So we have this lecture and next Monday.

14
00:01:57,240 --> 00:02:00,899
And after that we we probably have a few more lectures.

15
00:02:00,900 --> 00:02:09,510
So it's not a lot of lectures left given the amount of lectures available, uh, among lecture material available.

16
00:02:09,720 --> 00:02:18,240
So I'm going to speed up a little bit to make sure that I uncover interesting content.

17
00:02:20,080 --> 00:02:27,969
Uh, so I understand that both Jesse's office hours and my office hour is on Tuesdays, so it's not ideal.

18
00:02:27,970 --> 00:02:32,950
So I'm going to move my office hour to Monday four from next week.

19
00:02:33,580 --> 00:02:36,280
So I'm going to make the announcement.

20
00:02:36,280 --> 00:02:47,769
But you're going to expect the 5 to 6 534 630 on Monday for my office hour and just as of this hour as we move to Tuesday.

21
00:02:47,770 --> 00:02:56,740
So I guess that that will diversify a little bit in terms of the availability of a chair size.

22
00:02:57,010 --> 00:03:01,839
If you need more assistance from us, let us know.

23
00:03:01,840 --> 00:03:04,959
But midterm is like a takeover exam.

24
00:03:04,960 --> 00:03:10,510
So, you know, we have a limitation about how much help we can provide.

25
00:03:10,510 --> 00:03:15,370
So we're going to give a very general idea of what what's important about it.

26
00:03:15,370 --> 00:03:20,860
We're not going to give you a specific help with a specific code, the modifying code and so on.

27
00:03:21,550 --> 00:03:27,340
But the general theme is that you will really need to handle very small numbers efficiently.

28
00:03:27,970 --> 00:03:31,750
So you're going to have to deal with a lot on the floor, increase an issue.

29
00:03:32,020 --> 00:03:42,099
And that's that's probably you know, many of you already realized and there are other complicated issue in terms of like

30
00:03:42,100 --> 00:03:50,320
parameters in properly for using using this optimum function for someone with a problem.

31
00:03:50,800 --> 00:03:54,490
But you basically need to figure out the details.

32
00:03:55,300 --> 00:04:03,760
Yeah. Any other questions regarding the, uh, regarding midterm project or final project,

33
00:04:04,600 --> 00:04:08,620
I think are you I gave you all the comments about the final project.

34
00:04:08,620 --> 00:04:18,800
I did, I believe. But if you have any other question regarding the comments, feel free to contact.

35
00:04:19,410 --> 00:04:24,340
Contact me or just say, uh, okay.

36
00:04:25,690 --> 00:04:34,060
And if you given the comment, if you think that, oh, I really should keep totally changing my topic, that that's okay, just discuss with me.

37
00:04:34,210 --> 00:04:38,020
Okay. Uh, okay.

38
00:04:38,140 --> 00:04:43,990
So that's, uh, that's a, I think that's the, that's what I wanted to say.

39
00:04:44,200 --> 00:04:47,530
So Lecture 13 should be very quick.

40
00:04:47,680 --> 00:04:50,890
I guess it could take less than 30 minutes.

41
00:04:51,520 --> 00:04:55,900
Um, so let's, let's get started.

42
00:04:56,110 --> 00:04:59,319
Okay. So we covered the first slide already,

43
00:04:59,320 --> 00:05:10,990
but basically Bootstrap was introduced in 1979 and it has been very useful in, uh, in many areas of the parameters.

44
00:05:11,380 --> 00:05:15,730
Many of this is not quite like Monte, the traditional Monte Carlo method,

45
00:05:16,150 --> 00:05:26,290
but this is a remote Monte Carlo method and it's a useful to help estimating parameters and confidence levels and so on in general.

46
00:05:27,280 --> 00:05:38,830
So one thing I didn't cover in the last lecture is that, uh, what is the difference between a non parametric bootstrap in parametric bootstrap?

47
00:05:39,220 --> 00:05:52,050
But can anyone explain? So how many people use a pushchair?

48
00:05:52,070 --> 00:05:57,270
I guess not many, but just anyone use it and some people use it.

49
00:05:58,070 --> 00:06:02,209
It's good. Okay. So yeah, no promoting bus service.

50
00:06:02,210 --> 00:06:10,610
Basically, you're not making any parametric assumption in the data and you use only observe data for performing the bootstrapping.

51
00:06:11,360 --> 00:06:18,370
Parametric bootstrap is that you estimate the parameter from the observed data first and use simple the.

52
00:06:19,730 --> 00:06:27,230
So obviously that parameter may be incorrect, but if you estimate the timing and generate the random sample from the parameter,

53
00:06:27,680 --> 00:06:32,680
then you don't have a risk of observing the same value again and again.

54
00:06:32,690 --> 00:06:37,240
Again, you can reduce that and reduce that risk.

55
00:06:37,250 --> 00:06:42,290
So that that was the basic difference between the general and the bootstrap sampling.

56
00:06:42,620 --> 00:06:47,770
We're going to only talk about the first non parametric bootstrap, but this idea,

57
00:06:47,960 --> 00:06:56,750
this all the basic coding can be easily expand into the parametric bootstrap.

58
00:06:57,140 --> 00:07:02,600
Okay. So let's talk about resampling.

59
00:07:02,600 --> 00:07:07,610
So let's say you have a different sample that are observed from a distribution

60
00:07:07,850 --> 00:07:17,209
with the CDF of F of X and let's say you're selecting a random sample from X,

61
00:07:17,210 --> 00:07:22,160
then uh, you have an different sample.

62
00:07:22,160 --> 00:07:28,790
So the CDF doesn't really matter and you're just to have one over and a probability

63
00:07:29,660 --> 00:07:34,790
that your selected sample is a particular sample that is labeled as X or Y.

64
00:07:35,210 --> 00:07:37,160
If there are all different samples. Right.

65
00:07:38,600 --> 00:07:49,759
So, uh, resampling is a very simple procedure that um, instead of permitting the data which actually is guaranteed to have one counter,

66
00:07:49,760 --> 00:07:56,440
which I'm going to resemble the data, which means that I'm going to select them with replacement.

67
00:07:56,630 --> 00:08:09,290
Okay. So that, that, that's all about the resembling so the random variable x, x or Y star is ahead and uniformly distributed in this in this set.

68
00:08:09,650 --> 00:08:14,299
Okay. So this might be useful,

69
00:08:14,300 --> 00:08:21,620
especially when you have a relatively large number of observations because of chance of sampling the same same thing twice

70
00:08:21,620 --> 00:08:30,529
is a relatively small so general bootstrapping method is that if you have a data as a permit over interest in data,

71
00:08:30,530 --> 00:08:34,069
Halley's estimate or good estimate is always a function.

72
00:08:34,070 --> 00:08:41,870
So theta head is not a value is a function that takes your value as a theta.

73
00:08:42,290 --> 00:08:51,349
Theta is input and it gives output. So in a the possible estimate of the distribution, theta can be obtained this way.

74
00:08:51,350 --> 00:09:03,050
So generate bootstrap replicate for each of them basically exactly sampling and different sample but the with replacement.

75
00:09:03,200 --> 00:09:15,350
Okay so the if they they could be permutations sometimes by some sample can be sampled twice so it's not going to be always the same.

76
00:09:15,830 --> 00:09:23,620
So you're going to have a different set of sets of samples and you can use a beat the replicate

77
00:09:23,630 --> 00:09:30,440
data B from the bootstrap samples and that's it to represent the data of eight ahead of B,

78
00:09:30,440 --> 00:09:37,100
which means that I'm using the sum of the replicates as input and I'm get get the getting the estimate.

79
00:09:37,190 --> 00:09:48,320
Okay. So you have well, if you have a capital B different, different number of bootstrapping, you have us estimate of data in different ways.

80
00:09:49,160 --> 00:09:53,150
So the bootstrap estimate of CDF of F,

81
00:09:53,510 --> 00:10:00,290
F of theta is basically empirical distribution of these F of data head because you can get a

82
00:10:00,830 --> 00:10:08,209
you can get a distribution of your estimate if you can get a random bootstrap of your sample.

83
00:10:08,210 --> 00:10:16,160
So I mean, this one is probably work better with a pragmatic bootstrap if you're interested if you're interested in getting the full CDF.

84
00:10:16,820 --> 00:10:20,990
But just assuming you have a large number of samples,

85
00:10:20,990 --> 00:10:28,240
this should also work with the non parametric tab where you don't have to make any assumption about this mission.

86
00:10:28,630 --> 00:10:42,610
Okay. So we're going to talk about very so with this class is not really talking about the theory of global stability and just how you can.

87
00:10:43,090 --> 00:10:49,750
The purpose is to show how you can actually implement the was trapping with the article.

88
00:10:49,820 --> 00:10:54,850
So it's not it's not that challenging but it'll be good to know.

89
00:10:55,510 --> 00:11:01,750
So bootstrap estimate of let's say you're estimating standard errors for your parameters,

90
00:11:02,410 --> 00:11:07,690
then you can estimate the standard error your bootstrap replicates by.

91
00:11:08,170 --> 00:11:14,079
I have, you know, you have bunch of different bootstrap based estimates so you can get the standard

92
00:11:14,080 --> 00:11:19,149
error by calculating the standard error for the oldest estimate examples.

93
00:11:19,150 --> 00:11:23,530
And that's a bootstrap based estimate of your standard error.

94
00:11:23,650 --> 00:11:31,060
Okay. So this is not guaranteed to be identical to your standard error of your parameter.

95
00:11:31,210 --> 00:11:35,980
There can be a lot of cases that puts bootstrap based estimate or is is under

96
00:11:35,980 --> 00:11:44,260
estimation of the standard error or overestimation depending on the how you know,

97
00:11:44,440 --> 00:11:48,280
how good your the original observed data is.

98
00:11:49,330 --> 00:11:55,030
But this is definitely one way to calculate the standard error of your estimate,

99
00:11:55,030 --> 00:12:02,290
because otherwise you have a just single estimate, you have a single data, so you have only a single estimate sometimes.

100
00:12:02,560 --> 00:12:09,270
So you have I just want you to know, you know, there's only one observation, so there's nothing else I can do.

101
00:12:09,970 --> 00:12:13,120
So can I try to get a standard? Okay.

102
00:12:13,960 --> 00:12:18,070
Oh, well, with an equal one, you cannot. But if you wanted to try,

103
00:12:18,550 --> 00:12:30,190
what's suggested is that you take the random resampling of your data and try to re estimate your parameter and try to get the how variable they are.

104
00:12:30,820 --> 00:12:36,190
So that could be one way you can you can do the similar thing with a bias.

105
00:12:36,760 --> 00:12:40,480
If you have only one estimation, it's just the one value.

106
00:12:41,200 --> 00:12:53,470
It's hard to get the bias, which is the expected value of your estimate or your expected value estimate compared to the true value.

107
00:12:55,180 --> 00:13:05,709
So you can again, what you want is that you want to get the mean of your estimate from estimate,

108
00:13:05,710 --> 00:13:12,640
but you have only a single sample so you can pretend to you get a multiple sample by using bootstrapping.

109
00:13:14,080 --> 00:13:18,280
Yeah, you can use a parametric bootstrapping which which may be more robust.

110
00:13:18,850 --> 00:13:29,560
If you don't have parameter parametric bootstrapping method, then you can just use a non parametric bootstrapping to assess the bias in this way.

111
00:13:30,310 --> 00:13:36,940
Obviously this bias, this bias can be biased by biases, estimate can be biased by your actual sample.

112
00:13:36,940 --> 00:13:46,540
So if you your random you don't have enough number of sample your sample could your even though the your parameter is not biased,

113
00:13:46,690 --> 00:13:53,229
your data could be biased, then that could that could generate the biased estimate and it'll give you a bias.

114
00:13:53,230 --> 00:14:01,150
So then, you know, that doesn't mean that the, your estimate is the estimate has a problem,

115
00:14:01,600 --> 00:14:05,860
but those could happen if you have only single data to re sample from.

116
00:14:05,860 --> 00:14:11,650
So there is a limitation. But this is a this is better than nothing.

117
00:14:12,220 --> 00:14:19,370
Many people argue that that they wouldn't see when you have just a single set of observation, you can do this good.

118
00:14:20,320 --> 00:14:28,240
So basically what you do is you get this mean, which is just a mean of all your estimate.

119
00:14:28,420 --> 00:14:40,000
And if you know the if you have the estimated value from the observed sample in this case because you don't have the the parameters.

120
00:14:40,600 --> 00:14:49,330
So you use the difference between the full dataset versus full.

121
00:14:49,670 --> 00:14:57,070
So so this is the original dataset. You, you get the estimate using original data and you get the re simple data.

122
00:14:57,430 --> 00:15:01,210
And if your estimate has a bias, then it's good.

123
00:15:01,240 --> 00:15:10,569
It's going to give the estimated that are that are greater or smaller compared to the estimate that are compared to using your full sample,

124
00:15:10,570 --> 00:15:15,910
then that's that's what you can do. So same thing for the confidence level.

125
00:15:15,910 --> 00:15:22,030
So if you have you if you have an estimate of a confidence intervals.

126
00:15:23,950 --> 00:15:29,650
So if you're if you have an estimate and if you wanted to get the confidence, the value of your estimate.

127
00:15:30,330 --> 00:15:33,389
Then what you can do is that pretty much similar thing.

128
00:15:33,390 --> 00:15:42,520
You try to get the bootstrap replicate of your estimates by generating the uh, yeah.

129
00:15:43,080 --> 00:15:47,370
Generated bootstrap replicates and calculate estimate or estimate.

130
00:15:47,670 --> 00:15:51,239
Then you can get the distribution of your replicates.

131
00:15:51,240 --> 00:15:56,510
Then you, you know, whatever confidence interval level, if the alpha is a point of five,

132
00:15:57,540 --> 00:16:05,730
take the 2.5 at 95.9, 97.5 percentile and try to use them as your confidence level.

133
00:16:06,390 --> 00:16:10,770
Otherwise, you know it depending on what the alpha value is.

134
00:16:10,770 --> 00:16:19,050
You can just get that out at get that empirical distribution as your best guess of your confidence interval.

135
00:16:19,770 --> 00:16:28,830
And obviously, this is again not the best way, but this is one way to guess what your confidence interval might be.

136
00:16:29,010 --> 00:16:36,780
Okay. So, uh, this method is a super simple actually just, you know, denied the super,

137
00:16:37,380 --> 00:16:43,920
did it whatever way was bootstrapping bootstrap samples and tried to get the standard error bias in interval.

138
00:16:44,400 --> 00:16:56,190
And if you actually know the I, if you actually formally learn about the theory of bootstrapping,

139
00:16:56,190 --> 00:17:02,220
there's a lot of interesting things that you can prove that even though this looks like a very heuristic,

140
00:17:02,730 --> 00:17:10,049
there's a very nice theory about under certain assumptions, this bootstrap based estimate is actually very,

141
00:17:10,050 --> 00:17:19,490
very useful and have very good properties, too, to guarantee that these these estimates are very useful.

142
00:17:19,500 --> 00:17:25,620
So that's why people are using bootstrapping a lot and we're not getting to that theory.

143
00:17:25,620 --> 00:17:33,360
But in terms of in terms of implementing bootstrapping, I'm just saying that this is a relatively very straightforward thing to do.

144
00:17:33,600 --> 00:17:40,819
Okay. So, uh, so here's the example.

145
00:17:40,820 --> 00:17:50,690
We're going to try it today. So, uh, we are going to generate a random sample from bivariate normal distribution.

146
00:17:50,990 --> 00:17:58,729
Okay. Then what you can do is that you have the pairs of the normal free samples and you can calculate the

147
00:17:58,730 --> 00:18:07,100
correlation coefficient between those two random samples and you can get a correlation coefficient from,

148
00:18:07,100 --> 00:18:16,730
from those samples. But the correlation coefficient is not always straightforward to, you know, analyze like.

149
00:18:17,090 --> 00:18:26,150
So when you have a correlation coefficient, how do I know like what is the confidence level, how you know, what is what is the standard error?

150
00:18:26,210 --> 00:18:32,750
My correlation coefficient. Those are usually, you know, a little bit trickier than other statistics.

151
00:18:32,930 --> 00:18:41,569
So under certain assumptions you can get the analytical, uh, estimate of these correlation coefficient.

152
00:18:41,570 --> 00:18:47,059
By here we're going to say that we are going to estimate the bias in standard

153
00:18:47,060 --> 00:18:50,570
errors and the confidence about for this correlation coefficient using bootstrap.

154
00:18:50,870 --> 00:18:55,760
Okay, so let's try the hands of session.

155
00:18:56,000 --> 00:19:03,440
Okay. So almost the end of the lecture already. So, uh.

156
00:19:07,070 --> 00:19:11,240
So let's look at the setting of the problem.

157
00:19:12,440 --> 00:19:20,929
Okay, so, uh, we're gonna just make a wall all in one function that does that.

158
00:19:20,930 --> 00:19:31,790
Calculate the bias and stand out that are and confused about at the same time given a number of bootstrap replicates.

159
00:19:32,030 --> 00:19:38,030
Okay. So we're going to make a function that takes the three three parameters.

160
00:19:38,090 --> 00:19:41,270
What is the observed sample?

161
00:19:41,270 --> 00:19:51,440
So this is non parametric bootstrap. So here you have a set of observer samples and B is a size of your bootstrap replicates.

162
00:19:51,800 --> 00:19:59,060
Bootstrap, sorry. Okay. And estimate R is a function so estimate of your parameter.

163
00:19:59,060 --> 00:20:02,210
So this is returning any scalar value.

164
00:20:02,840 --> 00:20:08,620
And in this case, in this example, we're going to do the correlation coefficient and then you can use any kind of

165
00:20:08,630 --> 00:20:13,030
different estimate or you just need to that this estimate or need to take this,

166
00:20:13,590 --> 00:20:23,030
this data as a function is don't add the sorry data as a, as an argument and return a single value.

167
00:20:23,510 --> 00:20:28,999
But what we are going to do is we're just not going to not only just use this data,

168
00:20:29,000 --> 00:20:37,100
we're going to use a very sample version of this data as an input and get a different sort of estimate for each of the replicates.

169
00:20:37,580 --> 00:20:41,680
And using the set of replicates, we're going to do the bootstrap simplicity.

170
00:20:41,750 --> 00:20:53,780
So that's what we're going to do. So what we do is we're estimating the estimating the parameter date using the full data first.

171
00:20:53,870 --> 00:20:57,650
So this is just a typical estimate or default estimate you're going to have,

172
00:20:58,970 --> 00:21:09,340
but we're going to also run this estimate are multiple times using function called replicate.

173
00:21:09,560 --> 00:21:15,320
Okay. So replicate is a is a function that you can just run the same.

174
00:21:18,820 --> 00:21:25,870
So. So you're going to run the same estimate or multiple times.

175
00:21:25,870 --> 00:21:31,030
But you're running. You are running this run.

176
00:21:31,180 --> 00:21:34,899
Running this the same estimate of function. Be different times.

177
00:21:34,900 --> 00:21:49,380
And how how do you do it. So you are running this using the so you are using this data observe data as input.

178
00:21:49,600 --> 00:22:04,149
Okay, but whenever you take the input, this one if you see, okay, uh, this is the, uh, so it's a, it's a taking.

179
00:22:04,150 --> 00:22:15,160
So this one is basically taking the, the random sampling, uh, random sampling of your sample.

180
00:22:15,370 --> 00:22:25,659
Okay. So one one to do the number of replicate the of sample size and you're trying to sample one through n is a with the replacement.

181
00:22:25,660 --> 00:22:34,540
So that will basically give you a indices of the what, uh, the which sample you want to select.

182
00:22:34,540 --> 00:22:42,670
And each time it's selecting a different sets of the samples and it's going to run this function here.

183
00:22:42,790 --> 00:22:46,930
Okay. So this is a percent based estimate here.

184
00:22:47,620 --> 00:22:56,830
And so then you are going to have a basically have run this estimate or beat P different times and have a different that estimate.

185
00:22:57,820 --> 00:23:03,280
And you can estimate the bias using the mean value of these replicates,

186
00:23:03,430 --> 00:23:11,680
the replicated estimate estimates from the replicates and take the difference with the to the product.

187
00:23:11,980 --> 00:23:17,260
Well in this case is a is an estimate or a full data estimate from the full data.

188
00:23:18,040 --> 00:23:23,979
You can also just simply calculate the standard deviation. So this is the same you can just use as the function.

189
00:23:23,980 --> 00:23:33,100
Because if you look at the original formula for calculating a C, it's the same exactly same as a calculating the sample standard deviation.

190
00:23:33,100 --> 00:23:37,030
So that's what it does. If you wanted to do this,

191
00:23:37,180 --> 00:23:46,030
the confusion about what you can do is that you can take the full vector and try to calculate the quantile so there's a quantile function.

192
00:23:46,030 --> 00:23:52,479
So each of them may be a little bit of work if you wanted to implement from scratch.

193
00:23:52,480 --> 00:23:57,490
But these are all of this function is relatively very simple to implement.

194
00:23:59,200 --> 00:24:11,230
And you can get a reasonable estimate of of these bias and standard that are in the and the confidence intervals.

195
00:24:12,400 --> 00:24:19,560
Okay. So as I said, we're going to abide by very normal distribution to try the simulation.

196
00:24:19,600 --> 00:24:26,379
We're going to use only 20 samples here and use a 0.5 as a default correlation.

197
00:24:26,380 --> 00:24:33,520
And the for first variable has a set standard deviation of one second.

198
00:24:34,720 --> 00:24:40,450
The Y has a standard deviation of two just to make it a slightly more interesting.

199
00:24:40,900 --> 00:24:49,360
And this is the, I use the fullest decomposition to uh, to just simulate the by very normal.

200
00:24:49,360 --> 00:24:55,299
But you don't have to this is a simple by in normal so you can use other way but decomposition.

201
00:24:55,300 --> 00:25:02,320
We already learned it, so we just used it. And what kind of estimate should I use?

202
00:25:02,320 --> 00:25:05,510
Well, you're using correlation coefficient. How hard it could be.

203
00:25:05,510 --> 00:25:11,709
You just see what a function correlation function basically that takes the calculate the covariance

204
00:25:11,710 --> 00:25:18,220
and divide divided by the equivalent divided by the marginal variances for each of them in take.

205
00:25:19,270 --> 00:25:23,739
And I take a square root of them and that's, that's what the correlation coefficient should be.

206
00:25:23,740 --> 00:25:26,740
So then this should be very straightforward.

207
00:25:27,940 --> 00:25:34,360
Now you can ask, you know, how, how this bootstrap based inference works out.

208
00:25:34,360 --> 00:25:46,270
So we're going to use 20 samples in a row, a point five using the default parameter and we can generate 20,000 different bootstraps.

209
00:25:46,450 --> 00:25:53,230
Okay. And this is what a correlation coefficient looks like when you when you allow the re sampling.

210
00:25:54,070 --> 00:26:08,889
So this one basically as you see the true quotient coefficient should be 0.5 and looks like actually it does, it does seem to be centered around 2.5.

211
00:26:08,890 --> 00:26:18,250
So this this sort of makes sense in a in if you see the actual estimate was a point for a three here and.

212
00:26:21,470 --> 00:26:36,140
So this is a bias and this is a center that ah, and this was the, uh, this was the conversation about, so how, how well these estimates work.

213
00:26:36,200 --> 00:26:40,409
So obviously this one was calculated only just a pair of samples.

214
00:26:40,410 --> 00:26:45,080
So just a single sample. So this may not be a very good estimate.

215
00:26:45,080 --> 00:26:50,420
So we can try to estimate how this how well this works.

216
00:26:51,140 --> 00:26:54,920
By actually now we're doing the same thing using the replicate function.

217
00:26:55,340 --> 00:26:56,209
We're using this.

218
00:26:56,210 --> 00:27:08,020
But now this time we are using this estimate or at college an estimate are using the independently randomly sampled 20, 20 pairs of pairs of X and Y.

219
00:27:08,570 --> 00:27:15,290
Now we're really getting the real confidence level for these samples because of where

220
00:27:15,290 --> 00:27:20,810
we're making 20,000 different replicates from the from the actual distribution.

221
00:27:21,920 --> 00:27:28,850
So and if you look at the distribution, if you compare that the distribution looks surprisingly similar to each other.

222
00:27:28,850 --> 00:27:37,309
And that's probably the benefit of the the all the nice theory about the bootstrapping method, but with a certain assumption,

223
00:27:37,310 --> 00:27:40,590
even if you only have just 20 samples, you know,

224
00:27:40,670 --> 00:27:48,500
magically those 20 samples have a lot of information to reconstruct the confidence about pretty nicely.

225
00:27:49,310 --> 00:27:57,560
One caveat is that if you probably I would guess that if you change, I cannot show which one was better or not.

226
00:27:57,560 --> 00:28:01,100
But if you I mean, if your sample is not that great.

227
00:28:01,100 --> 00:28:04,280
So in this case, the distribution looks very different.

228
00:28:04,280 --> 00:28:09,259
So if you did that, it's probably going to be slightly different.

229
00:28:09,260 --> 00:28:12,680
So I you know, you may see some differences here.

230
00:28:12,680 --> 00:28:20,059
So I the the samples I showed you with some specificity, it was better than the other.

231
00:28:20,060 --> 00:28:29,720
So you there are differences based on the you know how how good representative of your buscemi's from the distribution.

232
00:28:30,170 --> 00:28:35,780
But nevertheless this was a relatively well and that's this is how you perform the

233
00:28:35,780 --> 00:28:40,459
bootstrapping so this is a really just a lesson of how you perform bootstrapping.

234
00:28:40,460 --> 00:28:49,340
So this is very short lecture. So it's show this lecture indeed among all the lectures that we have with you.

235
00:28:50,360 --> 00:28:54,620
So that's all I have. And I took 30 minutes. Any questions?

236
00:28:57,450 --> 00:29:04,250
Okay. So let's move on to lecture 16.

237
00:29:04,940 --> 00:29:07,900
So sorry for going back and forth, but just to,

238
00:29:08,490 --> 00:29:18,560
to just give some overview of what the journey we have where so far we talked about a precision issue and the

239
00:29:19,110 --> 00:29:26,659
interpolation and those things and talked about also the divide and conquer language in the in the beginning.

240
00:29:26,660 --> 00:29:37,850
Right. So and we'll move on to the optimization, numerical optimization and the Monte Carlo method.

241
00:29:38,930 --> 00:29:42,110
And while we doing the Monte Carlo method,

242
00:29:42,110 --> 00:29:48,920
I switch it back to the EMR wisdom and I see our analysis RCP just to cover those

243
00:29:49,550 --> 00:29:55,280
project related topics and where we went back to finish the Monte Carlo algorithm.

244
00:29:55,280 --> 00:30:01,490
So it's a little bit hectic, but those are all connected in my opinion.

245
00:30:01,880 --> 00:30:07,970
And this dynamic programing is actually doesn't have any connection with all these prior things necessarily.

246
00:30:08,630 --> 00:30:12,080
It's the most closely close related to the divide and conquer region.

247
00:30:12,080 --> 00:30:18,590
We started the valley in the beginning. Okay, so you can forget about all the intermediate thing.

248
00:30:18,590 --> 00:30:24,590
Just you need to remind us of the divide and conquer algorithm a little bit, which is a probably a little bit of challenge.

249
00:30:26,810 --> 00:30:36,049
But I think dynamic programing is one of the useful techniques that you may want to learn beyond the divide and conquer algorithms.

250
00:30:36,050 --> 00:30:43,070
And so also good, good exercise. This is very useful skills, but also good intellectual exercise as well.

251
00:30:44,660 --> 00:30:50,280
So just to recap, we had divide and conquer by me.

252
00:30:50,580 --> 00:30:55,490
I learned and using the three examples are power only problem.

253
00:30:56,120 --> 00:31:02,960
And we also look at the merge sword and we did also homework as well related to that and now is a by section.

254
00:31:03,590 --> 00:31:12,079
Okay. So these algorithms divide a problem into smaller pieces and a disjoint to solve problems until they become trivial.

255
00:31:12,080 --> 00:31:16,880
So that's the basic idea. So I'm going to assume that, you know,

256
00:31:17,450 --> 00:31:23,629
small the smallest problem was already solved and I'm going to define how to combine the solution from the smaller problems.

257
00:31:23,630 --> 00:31:36,890
So that's basically the idea. Again, so well, so let's try to use this divide and conquer algorithm for solving Fibonacci number.

258
00:31:37,730 --> 00:31:40,850
Okay. Well, one or two numbers are super simple.

259
00:31:41,090 --> 00:31:45,260
I don't think we need to divide the algorithm by why now?

260
00:31:46,010 --> 00:31:52,129
Let's try. So this is the Fibonacci number.

261
00:31:52,130 --> 00:31:57,800
How do you generate the Fibonacci numbers? Okay, so you have an equal zero zero and equal one.

262
00:31:57,800 --> 00:32:03,920
Equal one. And if N is greater than one representative one number in this way.

263
00:32:03,920 --> 00:32:11,300
Right. So, uh, well, I.

264
00:32:11,900 --> 00:32:23,240
I don't know why we need to do the recursive way, but if you wanted to use the recursive implementation for wise with its numbers, you can do that.

265
00:32:23,550 --> 00:32:29,840
Okay, well, basically, you recursion needs a terminating condition.

266
00:32:30,220 --> 00:32:39,220
Okay. So if a is a less than two, okay, then I'm going to return 000 or one.

267
00:32:39,230 --> 00:32:45,260
It's going to return to zero or one directly. Otherwise, I'm going to use these.

268
00:32:45,380 --> 00:32:53,360
If you were to function to calculate the function of Z minus one and the most to date and that's it.

269
00:32:53,720 --> 00:32:59,270
So should work. Okay. Do you see any problem with this implementation?

270
00:33:06,000 --> 00:33:10,350
No one has objections, so let's see if it works or not.

271
00:33:19,440 --> 00:33:22,910
Uh. Well, it takes a lot. Okay.

272
00:33:23,750 --> 00:33:26,930
So let's let's look at the previous number.

273
00:33:26,930 --> 00:33:31,010
Ten. Well, ten. Is this right?

274
00:33:32,270 --> 00:33:36,410
Uh, 55. Uh.

275
00:33:39,540 --> 00:33:42,900
Interesting. Why is that?

276
00:33:48,130 --> 00:33:58,150
Maybe. Maybe. Let me see if one or two number five is 501, two, three, five.

277
00:33:58,390 --> 00:34:02,950
Okay. Maybe. Maybe. Right. Okay. 55. I did not know there was a 55.

278
00:34:04,060 --> 00:34:08,980
Okay. So look at the Fibonacci number 30 and worked.

279
00:34:09,750 --> 00:34:12,870
It took 1.3 seconds. Hmm.

280
00:34:14,080 --> 00:34:18,910
Okay. So. Well, this is a little slower than I expected.

281
00:34:18,940 --> 00:34:23,440
Why is that interesting? As calculate the Fibonacci number 35.

282
00:34:24,760 --> 00:34:31,090
Wow. This takes a really long time. Why? Why does it take such a long time?

283
00:34:32,790 --> 00:34:41,570
In the same way. Wow. This calculated probably right number, but this took like 14 seconds.

284
00:34:42,140 --> 00:34:45,200
Know how hard this can be? Why why is taking so long?

285
00:34:45,390 --> 00:34:54,500
So if you look at the mathematical representation of the mathematical definition of female number, this is exactly same.

286
00:34:54,890 --> 00:34:58,700
Right? So that is inductive definition.

287
00:34:58,700 --> 00:35:03,290
We're just using it. I don't see any problem. But why does it take so long?

288
00:35:04,910 --> 00:35:09,260
So that is a question and trying to ask.

289
00:35:14,830 --> 00:35:22,360
So we're trying to calculate the Fibonacci number of N, but why does it take so long?

290
00:35:24,130 --> 00:35:27,250
So let's try to analyze a little. Okay.

291
00:35:28,150 --> 00:35:32,470
So, uh, well, let's look at just this.

292
00:35:32,560 --> 00:35:43,750
Okay. We are calculating the F of n. The function says that you need to calculate the f, f minus one and F of minus two to calculate.

293
00:35:43,750 --> 00:35:50,230
Therefore, by minus one, you need to calculate forward minus two and f of my st calculator this and this.

294
00:35:50,590 --> 00:35:55,210
So this sort of looks like a tree country when you, when you try to calculate it.

295
00:35:56,750 --> 00:36:02,590
Uh, so it's calculating all this way. So this is exactly how the Fibonacci function is working.

296
00:36:03,260 --> 00:36:09,960
Uh, just if you illustrate this, your problem now, what kind of problem they see.

297
00:36:11,940 --> 00:36:15,140
It's doing some calculations that has been done before,

298
00:36:16,260 --> 00:36:24,570
which which part of my history and for their mastery over my history is gradually running the same function twice.

299
00:36:24,750 --> 00:36:29,580
Yeah, exactly. This one and this one, they're running the same function twice.

300
00:36:29,870 --> 00:36:39,209
Okay. You don't have to. And the the time complex of running these is almost exponential because of that,

301
00:36:39,210 --> 00:36:46,170
because it's culture, the end and the height of trees are probably, you know, roughly end.

302
00:36:46,470 --> 00:36:52,770
Right. So it's basically due to the end time complexity if you look at the size of the tree.

303
00:36:54,660 --> 00:36:58,350
So that's what is happening. Okay.

304
00:36:58,800 --> 00:37:08,400
When you calculate so time complexity of adding, this is simply just you're you're doing the exponential calculation.

305
00:37:08,880 --> 00:37:14,790
Okay. So well, in fact, the time complexity is actually actually Fibonacci number.

306
00:37:14,790 --> 00:37:21,140
Exactly. You can you can prove that because of, you know, this this the interest.

307
00:37:21,330 --> 00:37:25,440
The interesting fact is that this is recursive time complexity.

308
00:37:25,440 --> 00:37:29,190
I would say with time complex representation itself is, if you will, this number.

309
00:37:29,550 --> 00:37:36,240
Right. So the so because because of the this formula is if you want this number, this is if you want a simple.

310
00:37:37,770 --> 00:37:40,860
Okay. So how do we avoid it?

311
00:37:40,860 --> 00:37:44,220
How how we can make it more efficient. Oh, sorry.

312
00:37:45,150 --> 00:37:51,150
How we can make it more efficient. Well, once you calculate it.

313
00:37:51,210 --> 00:37:58,650
So the sequence of it is, is that you you call this, you call this, you call this.

314
00:37:58,680 --> 00:38:04,350
Right. And calculate that. And if f a minus one was calculated.

315
00:38:05,120 --> 00:38:08,160
And then you don't need to recalculate, right?

316
00:38:08,280 --> 00:38:10,020
You just need to save it somewhere.

317
00:38:10,620 --> 00:38:21,150
And when you when this was called, instead of calling it again, if you use we use the same store, the value that'll solve the problem.

318
00:38:21,660 --> 00:38:31,710
Okay. So, well, if I didn't use recursion, some would say, oh, you know,

319
00:38:32,490 --> 00:38:37,620
unless you are really big fan of recursion, if someone says, oh, can you implement the pivots number?

320
00:38:38,070 --> 00:38:40,320
I don't think you're going to try this way first.

321
00:38:40,320 --> 00:38:49,340
Many of you, if you became a very big fan of the record, then you might you might do that by the many of that.

322
00:38:49,350 --> 00:38:52,830
Many of you probably just start right away this way. Okay.

323
00:38:54,180 --> 00:39:00,170
So I'm going to make an array and you know, for first element, if you want to.

324
00:39:00,300 --> 00:39:04,830
Well, if you want to, number of one equals one to equal one.

325
00:39:05,050 --> 00:39:12,500
Okay. So then three to you after I'm going to use this just loop and what is the time complexity.

326
00:39:12,900 --> 00:39:21,530
Complexity of this are going to. It's linear.

327
00:39:21,620 --> 00:39:26,059
Yeah. To just a single loop. Right. So, no, no complicated part.

328
00:39:26,060 --> 00:39:31,710
There's no tree here, right? So how how how hot?

329
00:39:31,730 --> 00:39:40,570
How fast is this? Oh, it's a it's a point over 7 seconds and this is 0 seconds, right?

330
00:39:40,580 --> 00:39:43,969
I mean, I don't think a zero is a correct, but this is really, really fast.

331
00:39:43,970 --> 00:39:48,410
Right. So what's the lesson here?

332
00:39:48,880 --> 00:39:59,840
Okay. So the lesson here is that divide and conquer would be sometimes very slow if you use it unwisely.

333
00:40:00,800 --> 00:40:11,630
Okay. The heart y y is that divide and conquer is supposed to make things simpler and faster, but in a more sort of basic sorting over it much faster.

334
00:40:12,290 --> 00:40:17,480
Well, in this case, it is not, because it's just a doing a lot of redundant calculation.

335
00:40:17,630 --> 00:40:20,780
And if you're using the wasting the computing time.

336
00:40:22,100 --> 00:40:37,550
Okay. So. Well, y y does that so is is it possible that you can, you know, make the divide and conquer algorithm to be always useful?

337
00:40:37,770 --> 00:40:42,890
Okay. So that's the starting motivation of the thinking about this dynamic programing.

338
00:40:44,480 --> 00:40:47,160
So when, when you do this, when you think about this,

339
00:40:47,160 --> 00:40:55,100
people view in this number example each of F of in will be we used to calculate the this f of n plus one and f up and plus two.

340
00:40:55,250 --> 00:40:55,550
Okay.

341
00:40:56,090 --> 00:41:08,690
So if you instead of so you're going to instead of evaluating this twice, you know, I want to evaluate the ones and store them for the later use.

342
00:41:09,530 --> 00:41:22,160
That means that you need to now store the result into certain space and find out a way to reuse the value when you have to recalculate.

343
00:41:22,670 --> 00:41:30,380
Okay. So that's the key idea in the people in the non non redundant of G number calculation.

344
00:41:31,130 --> 00:41:34,580
And also that's the key idea for the dynamic programing. Okay.

345
00:41:36,770 --> 00:41:44,480
So when you say something is a dynamic programing. Dynamic programing is a.

346
00:41:47,380 --> 00:41:51,280
This is a problem that can be divided into sub problems.

347
00:41:51,280 --> 00:41:54,750
So that's similar with divide and conquer.

348
00:41:55,540 --> 00:42:03,249
But the main difference with the divide and conquer bar and diner programing, when you divide in divide and conquer,

349
00:42:03,250 --> 00:42:07,960
when you divide a problem into sub problems, those problems are independent problems.

350
00:42:08,170 --> 00:42:17,630
Okay, let's think about the more you sort your your dividing them into two pieces and you're you need to sort each of them separately.

351
00:42:17,860 --> 00:42:27,490
So there is no redundancy. But in the Fibonacci numbers you are calculating the F of pn twice each of them F of a minus two twice.

352
00:42:27,610 --> 00:42:32,860
So you are calculating some overlapping sub problems.

353
00:42:33,010 --> 00:42:35,440
Okay. So some problems share some problems.

354
00:42:35,740 --> 00:42:44,110
So that's the structure you need to recognize to see whether you need to use just the dividing configuration or dynamic programing.

355
00:42:44,230 --> 00:42:59,030
Okay. So compared to the divide and conquer, then the differences that you need to solve some sort of problem once in a you save is Easter.

356
00:42:59,310 --> 00:43:07,209
Okay. So this is really like divide and conquer goes on with some more information, but people are coding, calling.

357
00:43:07,210 --> 00:43:13,570
This is a dynamic programing and Y and it's a very silly region.

358
00:43:13,570 --> 00:43:17,080
So some sort of the dynamic problem was a very cool word.

359
00:43:17,770 --> 00:43:22,690
So there's no real reason to use this as a call it dynamic programing.

360
00:43:23,200 --> 00:43:37,150
Okay. So, so this is, you know, you know, so what what's probably more appropriate for the the word for timer program is a smart recursion.

361
00:43:37,280 --> 00:43:48,399
Right. So you're using recursion, but you're adding some smartness there so that you avoid avoid recalculating some of these things.

362
00:43:48,400 --> 00:43:55,240
So I just like to call it column is a smart recursion or you know the you know so

363
00:43:55,450 --> 00:44:00,879
because this is really recursive way to solve it but we'll get to that later.

364
00:44:00,880 --> 00:44:06,420
But actually to implement that, I mean, you don't really have to use a recording all the time depending on the date.

365
00:44:06,430 --> 00:44:10,020
A problem structure sometimes is easier to implement as a loop.

366
00:44:10,030 --> 00:44:21,309
So we get we can get there. Okay. So this dynamic programing is really, really useful in many cases.

367
00:44:21,310 --> 00:44:28,600
So and in I'm working in the genomics and genetics, there's a lot of use cases of dynamic programing.

368
00:44:29,200 --> 00:44:32,049
I'm pretty sure that in other application it does that too.

369
00:44:32,050 --> 00:44:41,260
So when you if you're using Google Map, you probably use Google maybe using some of the dynamic probiotic edge and very popular.

370
00:44:41,260 --> 00:44:49,060
I William calls the Dijkstra algorithm, which is the shortest pathfinding algorithm between the source and destination.

371
00:44:49,420 --> 00:44:59,319
Okay. So that that dynamic problem often converts a problem that looks like a exponential problem, but it can become a polynomial problem.

372
00:44:59,320 --> 00:45:06,430
So that, that's a very nice feature of dynamic programing and DNA sequence alignment.

373
00:45:06,430 --> 00:45:15,339
If you have a lot of DNA sequences in online, then there was a big problem with the human genome sequence and you have a lot of fragments of genome

374
00:45:15,340 --> 00:45:20,350
you don't know where to place and you need to align them with some other sequences in the DNA.

375
00:45:20,890 --> 00:45:28,510
This has been very helpful and there's a lot of interesting algorithm just based off this dynamic programing formulation.

376
00:45:28,900 --> 00:45:32,559
I developed a lot of time hidden Markov models.

377
00:45:32,560 --> 00:45:46,750
Some of you may already know in genetics you used a lot and in the in the if you use stochastic process or those those are auditable so that H.M.

378
00:45:46,750 --> 00:45:56,950
is related there to and this he remarkably used a lot in machine learning a lot of heatmap of models are used in behind the scene as well could.

379
00:45:59,120 --> 00:46:07,129
So. And. Oh, yeah, I forgot to mention message in passing language, which is actually probably useful for European friends.

380
00:46:07,130 --> 00:46:12,880
And you probably some of you may know that as well, but that's also a good.

381
00:46:14,210 --> 00:46:17,960
So what is the steps of dynamic programing. Okay.

382
00:46:18,650 --> 00:46:26,180
Well it character. So first step is that you need to characterize the structure of optimal solution.

383
00:46:26,270 --> 00:46:27,830
Why is that? What is optimal solution?

384
00:46:27,840 --> 00:46:37,520
You think about it and define your problem in a recursive way without worrying about overlapping problem being overlapping.

385
00:46:38,660 --> 00:46:49,430
And now you calculate the value of a solution in a bottom of question and construct the optimal solution from from this computed information.

386
00:46:50,690 --> 00:46:54,860
Make sure that your store the value so that you avoid the recalculation.

387
00:46:55,180 --> 00:47:00,770
Okay, so those are the steps of dynamic programing. So this may be very abstract.

388
00:47:00,770 --> 00:47:02,450
Why? Why do we have to do this right?

389
00:47:02,780 --> 00:47:15,060
So that this is a this is kind of similar principle way to divide and conquer, because you you also need to think about bottom up.

390
00:47:15,080 --> 00:47:25,190
Right. So or in in other way, you just assume that all the sub problem was solved and you focus on the solving the larger problem,

391
00:47:25,190 --> 00:47:34,150
assuming that the smaller problem was solved. So the example we're going to talk about today is a manhattan tourist problem.

392
00:47:34,530 --> 00:47:38,500
Okay. So you have a green a path.

393
00:47:38,510 --> 00:47:43,190
So this is similar to the shortest path organism. It's a simple, simplified version.

394
00:47:44,630 --> 00:47:53,480
So you have a all non-negative cause between the between each of these junctions.

395
00:47:53,840 --> 00:47:59,210
And what I what I want to do is I want to go from here to here.

396
00:47:59,390 --> 00:48:02,450
Okay. And Manhattan is a very busy city.

397
00:48:02,450 --> 00:48:05,839
So this cost changes a lot of a lot of time.

398
00:48:05,840 --> 00:48:11,389
But this is a snapshot of certain, certain, uh, time.

399
00:48:11,390 --> 00:48:14,650
And, you know, I'll assume that this, this snapshot doesn't change.

400
00:48:14,720 --> 00:48:21,260
So you have a specific cost for crossing certain edges.

401
00:48:21,530 --> 00:48:26,030
Okay. So what is optimal path going from here to there?

402
00:48:26,960 --> 00:48:32,810
Can you do that by do that by your hand or will you just mentally, mentally figure it out?

403
00:48:40,160 --> 00:48:55,270
So let's say these are minutes. How many minutes does it take? If you think about this, this is a lot of path.

404
00:48:55,510 --> 00:49:04,930
Do you know how many paths you can steer? What are the total number path?

405
00:49:05,180 --> 00:49:17,490
Six or one problem. Come on.

406
00:49:17,500 --> 00:49:31,100
What a total path. Which is what? You need to you need to make eight different moves to to reach to the to the bottom.

407
00:49:31,430 --> 00:49:36,499
Right. What four types of movies? Horizontal for four types of movies are vertical.

408
00:49:36,500 --> 00:49:44,600
So H is four, right? So that's the total number of move you need to make.

409
00:49:44,840 --> 00:49:52,190
So that's a lot of passes basically. Then problem becomes really large if you think about the larger network.

410
00:49:52,670 --> 00:50:03,220
Okay, so one possible solution you can think about is, you know, just, you know, I'm going to choose random me.

411
00:50:03,470 --> 00:50:12,920
Okay, that's one way to choose. So if you, if you choose random path, maybe you can reach in 32.

412
00:50:12,990 --> 00:50:16,520
Okay, so 30 minutes, not bad. Okay.

413
00:50:17,630 --> 00:50:26,690
Okay. So, well, I actually so this this is a well, let's start with this.

414
00:50:26,750 --> 00:50:36,110
Okay. So I didn't make a slide for this, but one, one immediate thought that might come to your head.

415
00:50:36,320 --> 00:50:44,020
So when you don't know the optimal solution, most of you want to go from here to here, right?

416
00:50:44,090 --> 00:50:50,419
Because oh, this is called greedy solution is just a short I just look at the problem choices.

417
00:50:50,420 --> 00:50:54,610
Just just write right after right before me and oh, this it.

418
00:50:55,040 --> 00:51:03,649
This one is shorter than this. So I'm going to go, go here. Then you need to have a pay for, you know, both equally, equally bad choices.

419
00:51:03,650 --> 00:51:07,400
Almost equally bad choices. Right. So is now that takes us 7 minutes.

420
00:51:08,030 --> 00:51:13,430
Right. And this goes like 14, right.

421
00:51:14,240 --> 00:51:17,660
So 22. Right. Sorry.

422
00:51:18,140 --> 00:51:35,360
So this seven, you need to go here, right? So 11, 12, 13 and 13 and 22 and 29.

423
00:51:35,360 --> 00:51:38,970
So it's better than this, right? Okay.

424
00:51:39,050 --> 00:51:43,700
But you can also get the 29 solution in different way because in this case,

425
00:51:43,700 --> 00:51:50,150
if you see it once you are here, going here to here takes takes nine, right.

426
00:51:50,900 --> 00:51:54,559
And another another seven. So take the 16 here.

427
00:51:54,560 --> 00:52:00,200
But if you go here, take 15. So there are if you make a choices,

428
00:52:00,230 --> 00:52:09,110
there are cases that you are making a non optimal anonymous my choices and this is actually the optimal solution 21 minutes.

429
00:52:10,130 --> 00:52:13,310
Okay think and how do I get here?

430
00:52:13,550 --> 00:52:17,000
So that's the question. How do I get here?

431
00:52:17,450 --> 00:52:25,969
Okay, think about it. Okay. So so obviously brute force algorithm is that you're going to enumerate all the puzzle

432
00:52:25,970 --> 00:52:29,720
passes and calculate the cost of each of a positive pass and pick the best one.

433
00:52:29,840 --> 00:52:39,410
Right. So that time complexity might be possible for this problem because H is for but the number of possible pairs are will

434
00:52:41,120 --> 00:52:49,670
dramatically increase almost super x equals two exponential growth if you and the end of are in and of c are similar.

435
00:52:50,180 --> 00:52:55,009
So this is probably not a very good algorithm.

436
00:52:55,010 --> 00:53:01,970
So let's let's go back to here. Okay, so, well, maybe let's not bias you, so let's try to think about this.

437
00:53:02,150 --> 00:53:04,250
Okay? So this is the problem, you see.

438
00:53:04,490 --> 00:53:13,160
Okay, I don't you know that there is there is a so there's the answer you can just look at from the next slides.

439
00:53:13,160 --> 00:53:20,420
But I want you to just think about this problem a little bit. I'll give it 2 minutes and think about.

440
00:53:20,420 --> 00:53:23,110
So this is not again, this is not a divide and conquer.

441
00:53:23,210 --> 00:53:36,890
Agree them, but think as a divide and conquer and see the yeah, formulate the problem as a combining to solve problems and how you going to do it.

442
00:53:36,890 --> 00:55:37,490
So think about it. Okay.

443
00:55:37,790 --> 00:55:46,180
So, uh, so the key of the key idea here is that when you so when,

444
00:55:46,880 --> 00:55:54,140
whenever you think of a specific place, you want it to calculate the optimal, optimal cost.

445
00:55:54,140 --> 00:55:58,760
Let's say you're trying to find the optimum cost here or here anywhere.

446
00:55:59,360 --> 00:56:05,690
Okay. Only focused on the one that are right, right above or right.

447
00:56:07,130 --> 00:56:12,830
Right on the left. So right. Just the immediately previous.

448
00:56:13,040 --> 00:56:19,369
No. Okay. And, you know, a lot of wisdom is a lot of pretending here.

449
00:56:19,370 --> 00:56:24,380
So I'm going to pretend all the problem before then.

450
00:56:25,190 --> 00:56:28,580
I know the ultimate solution. Okay.

451
00:56:30,190 --> 00:56:49,010
Okay, then what you have is that you've, you have, you know, because of h c of we, uh, let's say all of hc0 of h and all of we.

452
00:56:54,840 --> 00:57:00,030
And unless they see a sea of age and see a week.

453
00:57:00,630 --> 00:57:07,410
And so old age means that because I'm not I'm assuming that I know the ultimate solution.

454
00:57:08,070 --> 00:57:12,780
So this is all the more cost to until wanting to reach here.

455
00:57:13,710 --> 00:57:15,510
This is the more cost to reach here.

456
00:57:16,410 --> 00:57:27,000
And sea of age is a cost to cost from traveling from here to here, she agree, is a cost cost traveling from here to here.

457
00:57:27,410 --> 00:57:32,130
Okay. So what we need to decide is that to reach here.

458
00:57:32,490 --> 00:57:35,800
Should I move? Is this way better?

459
00:57:35,820 --> 00:57:47,160
Would you say that? That's all I need to decide. So what you need to do is see we propagate or we always this one.

460
00:57:47,710 --> 00:57:53,820
Okay, so this will be the this can be a new cost if you decide to move from here.

461
00:57:54,780 --> 00:58:00,390
And this will be the new costs. It's possible age will be the new cost.

462
00:58:00,810 --> 00:58:10,140
If you decide to move here and just compare which one is smaller and whichever smaller will win, it's that simple.

463
00:58:17,250 --> 00:58:20,610
So that's the algorithm that is described here.

464
00:58:21,300 --> 00:58:26,400
It looks a little bit more complicated. But think about a focus on this one.

465
00:58:28,320 --> 00:58:33,630
Okay. So we assume the C of art.

466
00:58:33,810 --> 00:58:37,740
So C is a matrix that contains that stores the ultimate cost.

467
00:58:38,040 --> 00:58:43,020
And I assume that everything before in C is computed.

468
00:58:43,350 --> 00:58:51,810
Okay. Already computed. And we're just trying to decide which one is better path.

469
00:58:52,120 --> 00:58:58,320
Okay. And well, then what are all these?

470
00:58:58,350 --> 00:59:03,180
Well, if you are in the edge, if you are the puppet, there is nobody can move.

471
00:59:03,420 --> 00:59:07,110
You can only make it. You can only make a horizontal move.

472
00:59:07,110 --> 00:59:11,220
So if R equals zero. Only horizontal move is possible.

473
00:59:11,490 --> 00:59:14,620
If C only vertical move is possible. Okay.

474
00:59:14,940 --> 00:59:21,120
So in this case, you don't have a choice. Okay. So if it's a very beginning, you know, start with zero.

475
00:59:21,450 --> 00:59:31,050
Okay. So you can recursively define this problem as a in this way.

476
00:59:31,260 --> 00:59:34,830
Okay. And this is important.

477
00:59:35,850 --> 00:59:39,300
Once you once you evaluate this, it must be stored.

478
00:59:39,870 --> 00:59:42,959
And to avoid the redundant, redundant computation.

479
00:59:42,960 --> 00:59:46,890
Otherwise, is it going to repeat the same computation again and again?

480
00:59:49,800 --> 00:59:55,770
Okay. So this is like smart recursion, but the dynamic, dynamic programing structure,

481
00:59:55,770 --> 00:59:59,700
basically, I just say quotation dynamic because this is not really dynamic.

482
01:00:00,810 --> 01:00:06,860
Okay. Well, if you do this, what is the time complex?

483
01:00:07,010 --> 01:00:14,540
It is time. Policy may be very hard to analyze, but this is actually simple because what it what it all takes is that for each of them,

484
01:00:14,810 --> 01:00:20,690
you just make the one decision, right? So these are compared to values and then everything is computed.

485
01:00:20,990 --> 01:00:29,200
So everything is linear, just constant time to calculate, fill in each of the cell and there's only, you know, number of limit,

486
01:00:29,270 --> 01:00:34,610
the number of rows and number of columns and number of all times the number of column is actually the time complexity.

487
01:00:34,850 --> 01:00:46,600
You need to fill this in. So like if you want to search, if you don't pre compute, you're going to get the same value again, again, again.

488
01:00:46,600 --> 01:00:54,400
So it'll be super exponential. But that's not how how you implement this.

489
01:00:54,410 --> 01:01:06,430
Okay. So well let's, let's not worry about this reconstructing first and try to try to implementing the algorithm first.

490
01:01:06,610 --> 01:01:11,060
I don't want to confuse you. First.

491
01:01:11,240 --> 01:01:24,200
Okay, so. So as you see here, this is not implemented as a recursive arboretum.

492
01:01:24,790 --> 01:01:32,360
Okay. The region is that is just hard to make up some function recursion because it doesn't allow to store something in local.

493
01:01:33,080 --> 01:01:39,080
That's one reason. But you could you could use a global assignment. But the other reason is that a lot of cases,

494
01:01:39,080 --> 01:01:45,650
dynamic program is better to implement a loop because it's a very obvious to which one to calculate the first.

495
01:01:45,960 --> 01:01:55,340
And it's not if you have a very complicated graph, maybe recursive formulation sometimes helps, but many of the cases in dynamic programing,

496
01:01:55,790 --> 01:02:03,309
it's very clear that you just calculate something, you know, as long as you're calculating, you can you can go from horizontally or vertically.

497
01:02:03,310 --> 01:02:09,590
It doesn't matter. But as long as you calculate everything before the calculating the next, that's fine.

498
01:02:09,590 --> 01:02:13,220
So we're going to just use you simple move to fill these cells.

499
01:02:13,490 --> 01:02:25,910
Okay. So what do we do? So this is a little bit, uh, a little bit hard to understand in text that you need to compare with visually.

500
01:02:26,570 --> 01:02:38,810
So if you have any different end rows and columns, then you have DN times and minus one matrix for horizontal move cost.

501
01:02:39,800 --> 01:02:44,250
And you have this matrix, the vertical move, cause the region is this.

502
01:02:44,270 --> 01:02:52,129
So if you see because of the, the, the cost is stored between the edges.

503
01:02:52,130 --> 01:02:59,209
So this is actually the horizontal cost is a five by four matrix vertical plus is four by four by five matrix.

504
01:02:59,210 --> 01:03:00,860
So that's how we going to store.

505
01:03:02,690 --> 01:03:11,570
So and this part is just the number of calculating the number of rows and columns and make sure that the dimension is correct.

506
01:03:12,530 --> 01:03:24,430
And after that, okay, so I'm going to ignore this optimal part first because I just wanted to make sure that the you well,

507
01:03:25,540 --> 01:03:30,290
but why don't I copied because I don't want to I don't want to confuse you.

508
01:03:30,380 --> 01:03:37,300
So let's not worry about to move this to move is not essential part now.

509
01:03:37,310 --> 01:03:40,400
So let's just get rid of this.

510
01:03:40,730 --> 01:03:47,070
Everything. Optimal. I'm going to just remove things and.

511
01:03:47,420 --> 01:03:53,780
Oh, sorry. Well, I guess, yeah.

512
01:03:55,220 --> 01:03:59,370
Okay, so I'm going to just move on.

513
01:04:00,900 --> 01:04:05,900
Okay. So so this is this is a core part.

514
01:04:06,200 --> 01:04:13,970
So then what you have is the when one is the first row in the first column to store zero.

515
01:04:15,080 --> 01:04:21,830
So if it's the first column, first of all, but not a first column, then I can only move horizontally.

516
01:04:21,830 --> 01:04:31,470
So the horizontal cos only if it's the first column, not a first row, then the only political move is possible.

517
01:04:31,490 --> 01:04:39,440
So add the vertical otherwise. So in this case, this, this is a case where both are equal, greater one and JS greater than one.

518
01:04:40,700 --> 01:04:45,710
Then this is a new horizontal cause. This is a new vertical cost.

519
01:04:45,890 --> 01:04:53,240
So exactly this one. So this one and this one, you need to compare them to see which one is greater.

520
01:04:53,870 --> 01:04:58,490
And we are going to store the one that is smaller.

521
01:04:58,640 --> 01:05:04,760
Okay. So let me try that and use the example.

522
01:05:04,760 --> 01:05:10,490
This is exactly the same number that we had in the slide.

523
01:05:10,910 --> 01:05:15,260
Okay. So it's the same same cost cause the matrix we had.

524
01:05:15,920 --> 01:05:24,230
And if you print this out, then you're going to see that the optimal cost is a 21 here.

525
01:05:24,500 --> 01:05:34,130
Okay. So this is a 21 is optimal cost to reach to to the end here and but it also store optimal cost to reach to any of the previous node.

526
01:05:34,730 --> 01:05:37,820
And that's what this algorithm is doing.

527
01:05:40,070 --> 01:05:46,310
Any questions so far? Okay.

528
01:05:47,690 --> 01:05:50,570
Now, let's talk about the backtracking. Okay.

529
01:05:51,620 --> 01:06:01,270
Well, this is cool to know that, you know, your cost is 21, but it's not very useful if you don't know how to go.

530
01:06:01,280 --> 01:06:10,880
What is the path? Right. What is your path? The story we have is basically this problem is a backtracking problem.

531
01:06:11,240 --> 01:06:20,719
Okay. When you when you do the when you find a maze, oftentimes it's easier to find from the back to the from the beginning a the of same.

532
01:06:20,720 --> 01:06:24,830
So here we already know the optimal path here.

533
01:06:24,940 --> 01:06:33,050
It's a. So here what you need to know is that instead of starting from you do not know when you when you run your way,

534
01:06:33,070 --> 01:06:43,700
you do not know what's the optimum passing your future. But when you look back, you always can remember what your ultimate optimal choice was.

535
01:06:43,700 --> 01:06:50,900
So I already calculated compare between two numbers and decided this way is better.

536
01:06:51,110 --> 01:06:57,140
So if I remember that o to reach to reach to this node, you need to move horizontally.

537
01:06:57,740 --> 01:07:02,960
To reach this node, you need to move logically if you remember this path.

538
01:07:03,230 --> 01:07:11,000
Okay. Decisions. Then you can just reconstruct the path by going from the end to the beginning and a backtrack.

539
01:07:11,300 --> 01:07:15,650
Okay. So that that's how you do it?

540
01:07:15,950 --> 01:07:20,870
Well, actually, I still in the same same same problem.

541
01:07:20,870 --> 01:07:35,570
Right. So now this one are for for each of each over the non non starting node I store zero or one zero means that my optimal move is horizontal move.

542
01:07:35,780 --> 01:07:40,520
Okay. So in this case, there is only political move possible. So you just remember horizontal move.

543
01:07:41,420 --> 01:07:44,630
In this case, vertical if is one.

544
01:07:44,660 --> 01:07:54,410
This means that political move was optimal. Okay. And when you have possible choices, if vertical move was smaller,

545
01:07:54,410 --> 01:08:00,889
then I got to store the political move as optimal pairs and for the horizontal movies.

546
01:08:00,890 --> 01:08:10,700
Or can I pass? Okay. Here. Okay. Then if you run it again, well, run it again.

547
01:08:10,880 --> 01:08:16,790
You're going to have you're going to have this information.

548
01:08:17,000 --> 01:08:23,060
Okay. So well, now you can conceptually see.

549
01:08:23,300 --> 01:08:30,230
Okay, you can conceptually see that, oh, to reach here, I need to make a horizontal move.

550
01:08:30,230 --> 01:08:33,230
So this is what digital move. Vertical, more.

551
01:08:33,230 --> 01:08:37,070
Vertical, more. Vertical, more. Vertical, more. In terms of what? In terms of digital move.

552
01:08:37,070 --> 01:08:43,580
So you can visually reconstruct the optimal path by having this.

553
01:08:44,210 --> 01:08:51,590
But how do I actually get the least of the node to it so that that requires some additional programing.

554
01:08:52,760 --> 01:08:58,220
So this is the function to do the backtracking.

555
01:08:58,580 --> 01:09:01,390
Okay. So I'm using data frame here.

556
01:09:01,400 --> 01:09:11,990
So well, if you have M node in so many m rows and and columns, the number of move you need is m plus and minus one.

557
01:09:11,990 --> 01:09:16,580
Right. So that's the total number of moves you need.

558
01:09:17,390 --> 01:09:23,330
So here I'm going to make the.

559
01:09:24,230 --> 01:09:27,260
So this is just storing dataframe that's drawing column.

560
01:09:27,830 --> 01:09:32,600
So in this case, because it's backtracking, it is storing the value from the back.

561
01:09:32,750 --> 01:09:40,880
So at the end, I'm, I am storing what the X and Y so low roi am column index and what the cost was.

562
01:09:41,150 --> 01:09:46,129
Okay. And then, then that that should be enough.

563
01:09:46,130 --> 01:09:51,470
Like because I stored the wrote rows and columns is very clear that the what the move should be.

564
01:09:51,470 --> 01:09:59,900
So if my move was one if a vertical move I'm, I'm moving x I'm, I'm moving the row row indices.

565
01:10:00,080 --> 01:10:03,500
Otherwise I'm moving the column indices. So that's what, that's what it does.

566
01:10:04,700 --> 01:10:10,910
So if you do that and you have optimal course, an optimal move, if you provide this function,

567
01:10:11,270 --> 01:10:16,820
then it's going to show that, oh, this is your starting point, this is the end and this is your path.

568
01:10:16,910 --> 01:10:20,080
So it does reconstruct this.

569
01:10:20,090 --> 01:10:29,180
This is obviously not a special algorithm, but you sometimes need this kind of utility function to make your output interpretable to the to the users.

570
01:10:32,220 --> 01:10:39,900
Any questions so far? And this is how you interpret.

571
01:10:40,800 --> 01:10:47,340
So input. And so this is a wholesale cost and this is actual cost.

572
01:10:47,760 --> 01:10:51,090
You see that this is just adding to the cost here.

573
01:10:51,780 --> 01:10:55,290
And after that is the particular cost. So I'm just visualizing the optimal pass here.

574
01:10:56,580 --> 01:11:03,809
And so so that I can, you know, explain how to do the backtracking from the back to back to the beginning.

575
01:11:03,810 --> 01:11:09,750
But I already explained in the column screen, so I don't think I have to do it again.

576
01:11:12,630 --> 01:11:17,670
So as I said, dynamic programing, I would call as a spokesman because.

577
01:11:17,670 --> 01:11:21,840
Yeah, okay, so it has a recording and without repetition.

578
01:11:21,840 --> 01:11:27,579
So formulate the problem recursively, but I'll build a solution to your recurrence from the bottom up.

579
01:11:27,580 --> 01:11:32,700
But allowing the sub problem to be overlapping and resolve to be stored.

580
01:11:32,880 --> 01:11:37,890
Huh? Okay. So yeah.

581
01:11:37,890 --> 01:11:41,340
So the problem is kind of interesting.

582
01:11:41,340 --> 01:11:44,970
You start with recursion, but it's actually not just the recursion.

583
01:11:45,750 --> 01:11:52,020
And the problem looks like actually when you try to implement, it's like filling in table basically.

584
01:11:52,530 --> 01:11:56,969
But it's all the what's important part is the idea about the filling in table.

585
01:11:56,970 --> 01:12:04,940
So how do you actually formulate the problem recursively so that it becomes a polynomial problem,

586
01:12:04,950 --> 01:12:09,390
polynomial complexity problem, and that's what, what it is.

587
01:12:09,540 --> 01:12:17,460
Okay, um, I think I have some time to talk about this minimum distance problem.

588
01:12:18,520 --> 01:12:21,329
I don't think I can go into the implementation,

589
01:12:21,330 --> 01:12:28,980
but these are connected problems so we can finish some of it and focus on the hidden Markov model in the next lecture.

590
01:12:30,810 --> 01:12:35,280
So minimum edit distance problem.

591
01:12:35,640 --> 01:12:48,600
Okay, so edit distances, basically, you know, the minimum number of insertion, deletion and substitution required to transform one word to another.

592
01:12:49,140 --> 01:12:49,830
So for example,

593
01:12:49,830 --> 01:13:04,800
if you want to transform for to money it in these are four edits here so here one one sub one substitution another substitution insertion.

594
01:13:05,010 --> 01:13:15,380
And on the substitution right. So how do how do I calculate the minimum edit distance and how do I find this?

595
01:13:19,160 --> 01:13:27,440
This path is an interesting problem, so I don't know if you guys have played the word letter by any chance.

596
01:13:27,650 --> 01:13:29,480
So I am.

597
01:13:30,770 --> 01:13:40,339
You know, when my kids were younger, I was, you know, playing what word letter, basically just starting with one word and changing to another word.

598
01:13:40,340 --> 01:13:44,390
And, you know, make one word, one word change at a time.

599
01:13:45,410 --> 01:13:49,280
So, you know, this is kind of same similar problem.

600
01:13:49,490 --> 01:13:56,389
Okay. So, yeah, you can actually think about the network of words in this way.

601
01:13:56,390 --> 01:14:02,330
And it's a kind of interesting problem from that perspective, but you know that that's going too far.

602
01:14:02,340 --> 01:14:05,780
So we're just talking about that it is that problem now.

603
01:14:05,990 --> 01:14:12,950
Okay. So so this is basically aligning two words, okay.

604
01:14:13,460 --> 01:14:20,090
And decide which one is the best alignment between two words for each of the letter.

605
01:14:20,510 --> 01:14:24,319
And sometimes you need to tolerate mismatches here.

606
01:14:24,320 --> 01:14:29,690
You need to pay for the mismatch mismatch cost here and here and here.

607
01:14:31,370 --> 01:14:40,010
Always a mandatory if your line this way, one one deletion, one insertion, another insertion and some substitution required.

608
01:14:40,730 --> 01:14:45,500
But that can be aligned pretty well and you can show that this is optimal alignment.

609
01:14:47,750 --> 01:14:58,790
So this is a very related problem to the DNA sequence alignment or other a multiple sequence alignment kind of problem that is these days.

610
01:15:01,040 --> 01:15:06,170
Yeah, natural language processing is using kind of similar structure oftentimes.

611
01:15:06,320 --> 01:15:09,710
So this is interesting examples. Okay.

612
01:15:11,360 --> 01:15:15,530
So maybe you can ask questions.

613
01:15:15,650 --> 01:15:21,560
Is this is this alignment giving the optimal edit distance or are there better alignment?

614
01:15:21,770 --> 01:15:28,309
So you can you can come up with a different way to line it and argue that, oh, this is this is better than the other.

615
01:15:28,310 --> 01:15:34,010
Right? So how do we solve this problem?

616
01:15:35,090 --> 01:15:39,500
Okay. How do we come up with this alignment?

617
01:15:42,470 --> 01:15:47,750
I'll give you one minute I before I show the show how to do it with nine in the program.

618
01:15:51,950 --> 01:15:58,840
When you when you enter this new, interesting problem, I really think it's valuable to think about the problem at least a little bit,

619
01:15:59,410 --> 01:16:03,520
to try to come up with your own way before seeing the answer.

620
01:16:09,890 --> 01:16:46,310
The hint is that it's very similar to the minute, the first problem. Uh oh.

621
01:16:48,430 --> 01:17:09,220
So this is how you do it? So you a lot you arrange one word in the top as a as a column, one word in the bottom as a row, and start with empty letter.

622
01:17:09,480 --> 01:17:23,070
I'll explain why you need to start from here. I started with the empty letter and tried to align them very similar way to the at for this problem.

623
01:17:23,820 --> 01:17:30,000
But in this case, this going horizontal means that you are adding one.

624
01:17:32,880 --> 01:17:39,420
So this going going this way, you are adding one letter and deleting one.

625
01:17:39,690 --> 01:17:44,610
And this is adding one letter compared to the to the to the top one.

626
01:17:44,610 --> 01:17:50,759
To the left one. And if you going to that, you have a way to go to diagonals.

627
01:17:50,760 --> 01:17:55,469
So this one this one is a fully connected graph is showing only the possible ways.

628
01:17:55,470 --> 01:18:03,660
But there is this all possible way you can go horizontally, vertically or diagonally diagonally going means that.

629
01:18:04,200 --> 01:18:08,270
So if you if you have something like this, it's going horizontally.

630
01:18:08,280 --> 01:18:11,970
If you have something like this, this is going diagonally.

631
01:18:12,600 --> 01:18:15,959
Matches diagonally mismatch is also going back diagonally.

632
01:18:15,960 --> 01:18:19,950
This is going vertically. So that's how this was visualized.

633
01:18:20,550 --> 01:18:24,960
And the numbers here represent the number of mismatches.

634
01:18:25,500 --> 01:18:33,479
So at a distance, if we go this way and the region Y is one, the reason why there is a some error, it doesn't appear,

635
01:18:33,480 --> 01:18:38,250
is because it's actually this was constructed using dynamic programing and only,

636
01:18:38,970 --> 01:18:44,160
you know the one that was that is possible to backtrack what was showing.

637
01:18:44,160 --> 01:18:52,560
So yeah, but but the all the, all the diagonal and the horizontal vertical pass shouldn't exist in the photograph.

638
01:18:54,270 --> 01:19:01,139
So you can take this on and try to figure out why this would work.

639
01:19:01,140 --> 01:19:07,050
And then we can together figure it out. Show that together to show that this actually works.

640
01:19:08,250 --> 01:19:11,370
Okay. And see you next Monday.

