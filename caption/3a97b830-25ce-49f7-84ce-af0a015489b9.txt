1
00:00:01,500 --> 00:00:04,920
You know, steady. Steady. You don't want me to do risky things.

2
00:00:05,340 --> 00:00:08,580
You would do it yourself. Yeah, I do.

3
00:00:08,640 --> 00:00:11,650
You can also just text me a list of things. Right? Write.

4
00:00:12,660 --> 00:00:23,860
And that's what I was about to like. Yeah, I know, because I didn't really get it.

5
00:00:25,110 --> 00:00:31,350
It wasn't all that was always going to be going out.

6
00:00:33,040 --> 00:00:48,960
So the challenges of the Los Angeles, downtown and back with the people and I wanted to make sure that a lot of those experiences that I have,

7
00:00:50,630 --> 00:00:55,190
because I do not like my opinion or not.

8
00:00:55,770 --> 00:00:59,080
Are you saying it's not going to happen? This is not like.

9
00:01:00,750 --> 00:01:06,390
All right. Let's get started. Even though we are maybe a third of the class.

10
00:01:07,260 --> 00:01:12,090
So reminders your homework is due Thursday.

11
00:01:13,230 --> 00:01:20,660
So today I have office hours, 3 to 4. That's the last official office hour to ask question.

12
00:01:20,670 --> 00:01:24,270
If you have other questions, email the GSI phone or myself.

13
00:01:25,110 --> 00:01:29,790
And then your test, your first test on phase one and phase two concepts is next Tuesday.

14
00:01:29,790 --> 00:01:33,390
So it's a week from today. We'll be in this room.

15
00:01:33,570 --> 00:01:40,980
You'll have the entire class to take it. You can have one eight and a half, 511 front and back of whatever you want on it.

16
00:01:41,430 --> 00:01:44,910
It can be tiniest, tiniest printed, whatever you want.

17
00:01:45,840 --> 00:01:53,550
I don't I don't really care what's on it. You don't need you won't be able to use your laptop or tablet or anything and you don't need a calculator.

18
00:01:53,880 --> 00:02:04,470
So just can cancel whatever your health insurance rating interest or first thing that you want to write with is in your paper.

19
00:02:05,010 --> 00:02:08,549
I don't collect those so I don't I really don't care.

20
00:02:08,550 --> 00:02:12,629
What's on is whatever makes you feel more comfortable taking the test and then

21
00:02:12,630 --> 00:02:18,870
you can keep it for your reference or throw it out or whatever you want. This test is just on phase one of phase two.

22
00:02:18,870 --> 00:02:24,359
It's multiple choice and short answer. There is a practice test on here.

23
00:02:24,360 --> 00:02:29,670
So if you go under answer keys, you'll see there's a practice test and the key.

24
00:02:29,730 --> 00:02:42,150
So I suggest that's a good way to practice. Like I said, the objectives from every lecture are like your study guide and the whole everywhere.

25
00:02:42,150 --> 00:02:55,950
Questions are similar to the multiple choice questions minus requiring any type of calculator and any questions about the test or homework.

26
00:02:55,950 --> 00:02:59,160
Yeah. So just to clarify, practice test one is for this one. Practice test.

27
00:03:00,210 --> 00:03:03,840
That's right. Yeah, practice. So the second test will be on phase three.

28
00:03:04,650 --> 00:03:08,820
It's not cumulative. There's no final exam. Remember, you have your projects.

29
00:03:09,780 --> 00:03:12,930
So the phase three test would be before Thanksgiving.

30
00:03:13,770 --> 00:03:20,820
The not yeah. Practice two is for that one. Any other questions?

31
00:03:25,260 --> 00:03:33,730
All right. So we're going to finish the last lecture, then we're going to move to so we're going to finish talking about Bayesian phase two designs.

32
00:03:34,120 --> 00:03:37,389
Then we're going to move to talking about randomized phase two designs,

33
00:03:37,390 --> 00:03:44,890
and then we're going to go to the exercises which are really comparing the assignment to stage to a Bayesian design.

34
00:03:44,890 --> 00:03:50,050
But I want to keep that for laughs, because if we run out of time, I want to finish all of phase two today.

35
00:03:50,380 --> 00:03:55,630
And so if we run out of time, you can do that on your own. All right.

36
00:03:55,630 --> 00:04:00,970
So we were talking about we're still in the phase two space, right?

37
00:04:00,970 --> 00:04:07,930
Our interest is in safety, but now more efficacy in terms of is this drug that we took forward from phase one,

38
00:04:08,230 --> 00:04:13,330
does it look like it's actually beneficial? And so first, we talked about single arm trials.

39
00:04:13,330 --> 00:04:20,559
There is no control group and we assume that we know the historical control rates and that we just enroll everybody

40
00:04:20,560 --> 00:04:27,520
on the treatment and they go through and we see if they hit of response rate that we deem successful or not.

41
00:04:28,030 --> 00:04:35,859
Then we said, well, we can make decisions earlier so we could stop that that one arm early based on some

42
00:04:35,860 --> 00:04:40,510
information on a limited number of patients and see that it's actually not useful.

43
00:04:40,930 --> 00:04:47,409
And so we talked about these two stage designs and so that's like assignment two stage design and there was

44
00:04:47,410 --> 00:04:52,180
optimal and there is minimax and then there is an admissible design which is somewhere between the two.

45
00:04:53,710 --> 00:05:00,130
Now we're changing gears, still single arm, but now we're going into the Bayesian framework.

46
00:05:00,130 --> 00:05:04,150
So those were really based on frequentist statistics and our outcome was still binary,

47
00:05:04,150 --> 00:05:07,990
although not the binary outcome from the first of one phase one trial.

48
00:05:07,990 --> 00:05:12,190
Right? That's DLT or not phase two. It's did you respond or not.

49
00:05:12,850 --> 00:05:18,370
So that was the assignment to stage is based on frequentist statistics a one sided hypothesis test.

50
00:05:19,030 --> 00:05:22,570
The Bayesian design is a one arm trial.

51
00:05:22,870 --> 00:05:25,209
We're now we're in the Bayesian framework and we're going to say, well,

52
00:05:25,210 --> 00:05:31,570
we can stop at any point, not just at that specific number that Simon said we should look at.

53
00:05:31,600 --> 00:05:31,839
Right.

54
00:05:31,840 --> 00:05:40,240
But at any point, we could stop if the probability of response isn't looking so good, or we could stop if the probability response is looking so good.

55
00:05:40,660 --> 00:05:47,920
Right. Like I said, we don't usually stop for a vaccine phase two, but we could if we feel like it's really important to get the drugs market faster.

56
00:05:49,540 --> 00:05:55,420
So we went over a little bit more about Bayesian design, which was essentially a review of what we already talked about.

57
00:05:55,600 --> 00:06:04,239
Phase one, we talked about the serum, but what's great about the vision design is that we can allow for early stopping as soon as we see it.

58
00:06:04,240 --> 00:06:11,950
So remember, there is a poll everywhere question that said how many actual like what's a sample size in assignment to stage design?

59
00:06:11,950 --> 00:06:15,009
It's either N1, right, or it's the end.

60
00:06:15,010 --> 00:06:23,380
It's that first allowable sample size, which in Queens design was 14 or seven and the words the total end.

61
00:06:23,680 --> 00:06:30,790
Now in the Bayesian design, we could actually stop at any end. So at any and up to a max sample size, we could make that decision to stop.

62
00:06:31,690 --> 00:06:36,370
So why don't we do this all the time? Because the Bayesian in the Bayesian framework,

63
00:06:36,370 --> 00:06:44,080
many things are computationally intensive and it requires like real time data and real time feedback in order to make that decision.

64
00:06:44,470 --> 00:06:49,780
And because that's more intensive than having these set rules, it's at times it's not often done.

65
00:06:51,100 --> 00:06:59,920
There's also some issues in terms of we require prior distributions for Bayesian analysis and there are some there's some subjectivity to that.

66
00:07:00,700 --> 00:07:07,090
Of course, we can test across a range of priors, however, because we choose a priori and has a certain weight,

67
00:07:07,390 --> 00:07:13,990
some people are worried about how influential that could be. Okay, so we have our phase two data.

68
00:07:13,990 --> 00:07:17,500
Again, our outcome is binary. So it's did the patient respond?

69
00:07:17,500 --> 00:07:21,399
Or there can be phase two trials where the outcome is not binary.

70
00:07:21,400 --> 00:07:29,710
So there could be phase two trials where the outcome survival or the outcomes continuous, but we're focusing on binary outcomes.

71
00:07:30,130 --> 00:07:34,750
So our likelihood here is that of the binomial distribution, right?

72
00:07:34,750 --> 00:07:45,459
We have our parameter of interest gamma, we have the number of responses that we see and we can say we can update this after every patient.

73
00:07:45,460 --> 00:07:52,030
And so that's the subscript is saying, okay, after patient K, what is the likelihood of the data?

74
00:07:52,330 --> 00:07:56,980
And so after Patient K, how many responses have there been and how many non responses have there been?

75
00:07:57,670 --> 00:08:00,610
And so the question is what do we use for pi of gamma?

76
00:08:00,730 --> 00:08:06,219
When I say pi of gamma, I'm saying what do we use for the prior distribution of that parameter of interest?

77
00:08:06,220 --> 00:08:12,940
Gamma, that response rate, right? That's what we're really interested in, the response rate of our treatment.

78
00:08:14,140 --> 00:08:22,450
And so we said that, well, whenever we have a binomial variable of interest, we use a beta distribution for its prior.

79
00:08:22,880 --> 00:08:27,320
And the beta distribution density looks as such and it's mean.

80
00:08:27,470 --> 00:08:35,690
So the beta distribution is dependent upon two values a one and a two will call and a means A1 over A1 plus A2.

81
00:08:35,780 --> 00:08:39,859
And so we can think about this that we have prior information about our response rate.

82
00:08:39,860 --> 00:08:46,159
So we want to set A1 over A1 plus A2 to be the expected response rate of a treatment.

83
00:08:46,160 --> 00:08:49,730
And or we'll see how we have to deal with that control.

84
00:08:50,480 --> 00:08:53,240
And then the variance is a such which isn't quite as important.

85
00:08:53,570 --> 00:08:59,320
But what we also know is that A1 plus A2 is the effective sample size of that prior distribution

86
00:08:59,330 --> 00:09:06,320
or how much weight we're putting on this this guess of the expected response rate.

87
00:09:07,640 --> 00:09:14,180
And so if we combine a beta prior with a binomial likelihood, we get a beta posterior distribution.

88
00:09:14,510 --> 00:09:16,160
And so it's very easy to work with it.

89
00:09:16,220 --> 00:09:28,250
So we went through so we discussed that and we went through sort of visualizing the amount of weight we're putting on our, our information.

90
00:09:28,250 --> 00:09:33,260
And so we see that if A1 plus A2 is small, it's almost a uniform distribution.

91
00:09:33,560 --> 00:09:37,250
And so it's saying what we think the mean is like .33.

92
00:09:37,580 --> 00:09:42,680
However, we really don't put a lot of weight on that. Whereas if A1 plus A2 is really large.

93
00:09:42,920 --> 00:09:48,139
Now all of a sudden we're saying, okay, the mean is 0.33. And I really believe that I'm putting a lot of weight on that.

94
00:09:48,140 --> 00:09:53,870
And that's here. I'm putting 45 patients worth of data on that expectation.

95
00:09:54,410 --> 00:09:59,959
And in phase two, where we're going to probably accrue somewhere between like 30 to 100 participants,

96
00:09:59,960 --> 00:10:02,930
that's a fair amount of information about replacing on it, right?

97
00:10:02,930 --> 00:10:08,450
If it's 45, whereas if we put three amount about three people worth of information stock.

98
00:10:10,430 --> 00:10:19,220
Okay. So here's how this Bayesian phase two design works. We're going to enroll patients until the stopping rule is satisfied and after patients.

99
00:10:19,550 --> 00:10:25,010
So after every single patient or after maybe it's just like we kind of have like a burden period.

100
00:10:25,010 --> 00:10:31,310
So we maybe say we want to roll 5 to 10 first and then after those patients we could start estimating this probability.

101
00:10:32,330 --> 00:10:39,889
If we see that the probability that our response rate is greater than some control response rate of Delta, right?

102
00:10:39,890 --> 00:10:48,260
We want our response rate for this new treatment to be greater than some standard of care or placebo by some amount.

103
00:10:48,830 --> 00:10:50,629
Given the number of responses in the trial,

104
00:10:50,630 --> 00:11:00,260
we could stop and say we stop because either we've reached some threshold that this probability is so low that our treatment is going to be effective,

105
00:11:00,260 --> 00:11:06,950
that we should stop the trial or we get out this upper threshold, this pie of you, which says this probability is so high,

106
00:11:06,950 --> 00:11:11,299
there's no point in getting anybody else on it because we already know this is really going to be successful.

107
00:11:11,300 --> 00:11:14,510
We should move forward. So Delta's fixed.

108
00:11:14,510 --> 00:11:17,209
Delta doesn't change throughout the trial, right?

109
00:11:17,210 --> 00:11:22,940
We have to specify this ahead of time that we want to see say that we expect the standard of care to have

110
00:11:22,940 --> 00:11:30,110
like a 30% response rate and that we only find this treatment beneficial to move forward into phase three.

111
00:11:30,110 --> 00:11:37,070
If we see a 60% rate, delta would be 0.3 and that wouldn't change after K patients.

112
00:11:39,210 --> 00:11:48,300
So the key idea here is that remember in Simon two stage design, we put we say that we absolutely know the standard of care response rate, right?

113
00:11:48,300 --> 00:11:51,300
If it's a one arm, we absolutely say that it's okay.

114
00:11:51,300 --> 00:11:53,580
It's 30%. There's no variation in that.

115
00:11:54,270 --> 00:12:01,710
In the Bayesian framework, we can say, well, we're pretty sure that the standard of care is 30%, but we put a distribution on it.

116
00:12:01,950 --> 00:12:08,040
And depending upon the weight of that distribution, right, we can either be really sure about it or we could be not so sure.

117
00:12:09,060 --> 00:12:18,030
Now, usually we put a lot of weight on the distribution of the expected value of that that P zero,

118
00:12:18,090 --> 00:12:21,840
because we assume that we have really good data about that.

119
00:12:21,990 --> 00:12:28,500
We're not collecting data in here, right? So we're not going to increase our precision around that estimate in this trial.

120
00:12:28,800 --> 00:12:32,730
And so usually we say we pretty much know that we'll have a pretty strong distribution around it.

121
00:12:36,300 --> 00:12:41,850
Okay. So this is this all and Simon Pepper, if you see on the website to read it.

122
00:12:43,190 --> 00:12:47,390
Okay. So our first decision is what does and what prior are we going to put on this?

123
00:12:47,900 --> 00:12:53,960
That should be a lowercase gamma just went to uppercase, which is our response rate of interest.

124
00:12:54,230 --> 00:13:01,730
So remember that the size of our of our if we're using a beta distribution, the size of A1 plus A2 is very important.

125
00:13:01,730 --> 00:13:16,940
So we went through this such that if we have ten participants and we've seen nine responses as our prior was A1 equals point five and A2 equals 4.5,

126
00:13:16,940 --> 00:13:25,700
right? There'll be five patients worth of data. And we're saying that we believe that the response rate is 10%, 0.5 over point five plus 4.5.

127
00:13:26,240 --> 00:13:30,500
Right? So we say with five patients worth of data, we think the response rate is 10%.

128
00:13:30,500 --> 00:13:34,010
We've actually seen a 90% response rate in the first ten patients.

129
00:13:34,430 --> 00:13:45,920
If we combine our prior with our observed data, right, we get the probability that the response rate is greater than or equal to 0.3 a 69%.

130
00:13:46,520 --> 00:13:48,050
Right. That's relatively high.

131
00:13:48,560 --> 00:13:55,910
We had about half the we put half the amount of weight on the prior and then we had ten patients and we saw a very high response rate.

132
00:13:57,010 --> 00:14:07,149
If however I change that A1 to A2 in my prior to say the prior x right are expected, what we're expecting in the response rate is 10%.

133
00:14:07,150 --> 00:14:10,750
But I'm putting 50 patients worth of data on it and now I have accrued ten.

134
00:14:11,020 --> 00:14:14,080
You can imagine that prior is going to take over. Right.

135
00:14:14,350 --> 00:14:19,569
And so now when I look at the probability that the response rate is greater than 0.3, it's much lower.

136
00:14:19,570 --> 00:14:32,080
It's 11.4%, even though we saw a 90% response rate, because I put so much emphasis on my prior, it's very unlikely that it's the posterior saying.

137
00:14:32,080 --> 00:14:37,990
It's very unlikely that the response rate is greater than point three because it's putting a lot of emphasis on that prior distribution.

138
00:14:38,650 --> 00:14:47,799
So as you can see, right, we probably don't want to assume a prior so strong that it would overtake our estimates and we would

139
00:14:47,800 --> 00:14:52,810
never make these decisions or we wouldn't really be putting enough emphasis on our actual data.

140
00:14:52,990 --> 00:14:58,900
So it's very important. So we have to put it prior on our R Oh, yes, sir.

141
00:14:59,020 --> 00:15:06,339
So yes. So when we divide plier, that's like 50 work of patient.

142
00:15:06,340 --> 00:15:13,299
But does it matter how much they're going to pay one and how much of the key to it only

143
00:15:13,300 --> 00:15:18,970
matters in terms of that your A1 over A1 plus a two is equal to your expected response rate.

144
00:15:19,630 --> 00:15:24,400
So you if you change those around, you wouldn't get to expect a response rate of 10%.

145
00:15:24,400 --> 00:15:30,959
Right. So it would definitely change your posterior estimate. Okay.

146
00:15:30,960 --> 00:15:34,980
So you have to figure out what's your prior honor, your variable of interest,

147
00:15:34,980 --> 00:15:39,750
that response rate that you're going to see of the treatment in the trial.

148
00:15:39,750 --> 00:15:47,010
Then you also have to put prior on the standard of care or historical control response rate that we call P zero.

149
00:15:48,690 --> 00:15:58,110
And so. What we really want is that we have a good estimate of zero because we've seen this

150
00:15:58,110 --> 00:16:02,640
treatment in a very similar population to which we're going to apply the new treatments.

151
00:16:03,000 --> 00:16:06,120
And so we have a really good idea. However, that's not always the case.

152
00:16:06,480 --> 00:16:11,510
So when you're putting a weight on zero, right, you want it to be very strong.

153
00:16:11,520 --> 00:16:22,260
If you have the case that it's a relatively current control cohort that matches the inclusion criteria that you would have in phase two.

154
00:16:22,800 --> 00:16:29,670
Right. And and look at the inclusion criteria that you would have in phase three as well.

155
00:16:30,360 --> 00:16:32,339
If those things are not the case,

156
00:16:32,340 --> 00:16:42,300
if it's a pretty old cohort that you're looking at for this response rate and or it's a very heterogeneous or somewhat different patient population.

157
00:16:42,510 --> 00:16:44,530
You don't want to put that much weight on it, right?

158
00:16:44,560 --> 00:16:55,830
You want your prior to be a little bit more diffuse or not a one plus two to be so high so that it's not it's not super.

159
00:16:55,950 --> 00:17:04,829
You're not saying like, I really know this well, usually we have a pretty informative primer on this and we think that we have

160
00:17:04,830 --> 00:17:11,320
this relatively well known because if we were to do a frequencies version right,

161
00:17:11,340 --> 00:17:19,470
we would assume that we absolutely do it. And so usually in the vision framework, we do put a lot of weight on our prior distribution for zero.

162
00:17:21,250 --> 00:17:26,020
Okay. So then we have to figure out how do we choose Delta? That's not P zero plus Delta.

163
00:17:26,350 --> 00:17:29,470
That's that extra amount that we want to see our treatment response rate.

164
00:17:30,370 --> 00:17:32,020
And that's really something that's.

165
00:17:34,370 --> 00:17:39,650
Not, it says tuning parameters here, but it's not so much a tuning parameter as something that should be guided by the science.

166
00:17:40,010 --> 00:17:47,990
Right. The clinicians should say, well, in this disease area, with the treatments that are available,

167
00:17:48,080 --> 00:17:55,370
we really need to see that the treatment is at least 20% more effective than the standard of care, or 30% or 40%.

168
00:17:56,570 --> 00:18:02,930
It's usually not as low as 10% or 15% because those would make that would make the sample size just infeasible for phase two.

169
00:18:02,930 --> 00:18:09,590
So it's usually a pretty large amount, although actually we have 5% or 15% here.

170
00:18:09,950 --> 00:18:15,770
That's kind of low. It could be that low, but that's going to require somewhat of a high sample size.

171
00:18:16,400 --> 00:18:25,879
It could also be higher like 20%, 30%. The pi l in the pi you these are the thresholds for stopping early, right?

172
00:18:25,880 --> 00:18:35,210
So the pi l is the lower bound threshold that says that if the probability that this new treatment is really much better than the control is,

173
00:18:35,300 --> 00:18:40,040
if it's going to be if that probability super low that we should stop.

174
00:18:40,970 --> 00:18:46,879
Right. And then pi you is this upper bound threshold that says if the probability that

175
00:18:46,880 --> 00:18:53,630
our treatment is really much better than the control is high and is really high,

176
00:18:53,660 --> 00:18:56,750
then we should stop because we see that there's efficacy.

177
00:18:57,170 --> 00:19:01,430
So we usually set these thresholds. So Pi l is usually quite low.

178
00:19:01,760 --> 00:19:06,170
That means that we're not going to stop that often. Right. And unless it's truly, truly, really bad.

179
00:19:07,640 --> 00:19:15,590
But if it really is bad, then we would stop. And then similarly, we're not going to stop that often for advocacy unless it's truly much better.

180
00:19:15,590 --> 00:19:23,060
But we set those thresholds relatively on the conservative side to make sure that and phase two are weeding out really bad ones.

181
00:19:23,810 --> 00:19:28,490
But we're not going to give up on treatments that we could see that are effective in Phase three.

182
00:19:33,710 --> 00:19:41,630
Okay. So and then like those pi l in the pi you they can be somewhat tuned to when you run simulations to see

183
00:19:41,630 --> 00:19:46,310
how often are you stopping under different scenarios and you can tweak them a little bit to say like,

184
00:19:46,310 --> 00:19:51,860
I want to stop more or I don't want to stop as much. And so those can be a little bit more of tuning parameters then.

185
00:19:52,870 --> 00:20:03,700
Then Delta, of course, here. So while we're in the Bayesian framework, we're still trying to show that we're controlling type one air and power,

186
00:20:04,120 --> 00:20:10,419
because if we're trying to do this for a new drug, the FDA always wants to see you type one error and power.

187
00:20:10,420 --> 00:20:14,020
So you have to define these even in the Bayesian framework.

188
00:20:15,570 --> 00:20:20,310
Okay. So let's see an example. So here's a design for newly diagnosed prostate cancer.

189
00:20:21,270 --> 00:20:28,040
The treatment is a surgical procedure, and they're trying to decrease the burden of what's called circulating tumor cells.

190
00:20:28,050 --> 00:20:29,990
So that's the fact that you have cancer.

191
00:20:30,210 --> 00:20:37,530
And then there's some of that cancer that is circulating within your bloodstream and that could ultimately lead to metastatic disease.

192
00:20:39,220 --> 00:20:50,020
Response here is going to mean that you have less than five circulating tumor cells per seven and a half years of collected blood after surgery.

193
00:20:52,240 --> 00:20:55,420
And the historical comparison is no surgery.

194
00:20:57,670 --> 00:21:08,170
So for our response rate of interest, well, we could give it a better distribution with a one of 2.8 and a two of 1.2.

195
00:21:08,440 --> 00:21:13,610
And so this gives the expected response rate of surgery about 70%.

196
00:21:13,700 --> 00:21:16,239
Right. We're expecting a relatively high response rate,

197
00:21:16,240 --> 00:21:23,950
meaning that we see less than five ctcs after surgery and we have a pretty low amount of weight on that.

198
00:21:23,950 --> 00:21:33,790
Right. The eight one plus two is four. And so if you look at this distribution down here, right, we have a lot of mass.

199
00:21:34,210 --> 00:21:40,240
Hi. Like right in between here. Right. So the mean is 0.7, but it's very spread.

200
00:21:40,660 --> 00:21:46,000
And so we're saying, you know, we're hoping we hope that it's as good as 70%, but we're going to let the data talk for us.

201
00:21:46,030 --> 00:21:57,880
Right. Whereas here our p zero for our control or if they don't have surgery, we believe that the expected response rate would be 40%.

202
00:21:58,150 --> 00:22:04,510
And we're going to put a lot of weight on that. Right. So the A1 plus A2 is 400.

203
00:22:04,510 --> 00:22:06,280
We have 120 and 180.

204
00:22:07,060 --> 00:22:14,480
And so you can see right in this distribution, we're saying we really believe that this is the response rate if they didn't get surgery.

205
00:22:14,500 --> 00:22:17,510
There's a little wiggle room, but we're pretty sure about it.

206
00:22:18,910 --> 00:22:24,580
And then we're going to specify our lower threshold value pi l as 0.02.

207
00:22:25,000 --> 00:22:30,819
So we're going to say that we could stop the trial after patient k is the probability that our

208
00:22:30,820 --> 00:22:37,899
response rate is greater than or equal to P zero plus point three given the number of responses,

209
00:22:37,900 --> 00:22:46,590
if that's less than 0.02, meaning that right the probability that we see that this treatment is doing much better than the sterile coach,

210
00:22:46,960 --> 00:22:56,170
the standard of care is really, really low. Then we're going to stop and then we're going to set the sample size max sample size at 36 patients.

211
00:22:56,170 --> 00:23:04,330
So how do we decide that in the same in two stage design, the sample size is a bit more connected to that hypothesis test.

212
00:23:04,810 --> 00:23:13,480
Remember, we have the hypothesis test of whether P is greater than P, not in our Bayesian design, just like in the serum.

213
00:23:13,510 --> 00:23:20,889
This is something that's more user specified and then we test B how good that sample

214
00:23:20,890 --> 00:23:24,700
size is or how adequate we think that sample size is by looking at simulations.

215
00:23:25,240 --> 00:23:34,840
And so 36 is something that we probably think is crucial in terms of the amount of time that we would do this and the patient's available.

216
00:23:34,840 --> 00:23:42,790
It's also maybe we would look at the sample size for assignment two stage and we could sort of start from there and perhaps try.

217
00:23:43,850 --> 00:23:54,500
Little bit fewer of patients. Okay. So let me show you this stimulus, this simulation of incoming data.

218
00:23:55,040 --> 00:24:02,719
Okay. So here we're going to we have those to the representation of the standard care

219
00:24:02,720 --> 00:24:06,740
response rate and the representation of our prior on the expected response rates.

220
00:24:07,190 --> 00:24:10,640
And up here, can you read that? It's pretty small.

221
00:24:11,450 --> 00:24:19,840
Can we make it bigger? Yeah. That's doing a little better.

222
00:24:20,560 --> 00:24:30,910
Okay. So we want to look at this up here. So this is our K is the number of responses at given that we have K patients accrued in our trial.

223
00:24:31,150 --> 00:24:35,290
So it's going to say the number of responses out of the total individuals in the trial.

224
00:24:35,560 --> 00:24:42,940
And then we're looking at the probability that our new treatment response rate is greater than P, not plus point three.

225
00:24:43,000 --> 00:24:46,060
Given those number of responses. We're going to see what that is.

226
00:24:46,090 --> 00:24:47,950
So, for example, if we just start,

227
00:24:48,040 --> 00:24:57,520
we have nobody based on the prior the probability that our expected response rate is greater than peanut plus point zero is .56.

228
00:24:57,750 --> 00:25:02,020
Okay. So this is just given the prior information. This is how we set it up.

229
00:25:02,020 --> 00:25:08,230
And now we're going to see once we enroll patients in whether they respond or not, how that probability changes.

230
00:25:12,140 --> 00:25:15,920
And you can see the distribution. You can see we're getting a lot of responses.

231
00:25:16,430 --> 00:25:26,389
And so that distribution, the posterior distribution of the let me stop there, the posterior distribution of the response rate for that new treatment.

232
00:25:26,390 --> 00:25:31,250
Right. It's getting more and more L-shaped and getting more and more.

233
00:25:32,390 --> 00:25:35,780
Close to that. That's right.

234
00:25:36,050 --> 00:25:40,400
It's centered over the expected mean, which is quite high because we're seeing a lot of responses.

235
00:25:40,400 --> 00:25:43,940
So we've seen 19 responses out of 24 individuals.

236
00:25:43,940 --> 00:25:50,090
And we see that the probability that our expect a response rate is greater than peanut plus point three is quite high point 83.

237
00:25:50,330 --> 00:25:58,880
Remember, we only had a stopping rule for this is that this probability was super low, was less than .02, that we'd stop the trial.

238
00:25:59,180 --> 00:26:06,110
We're not even close to that. Right? That would mean that our distribution would be like way over there.

239
00:26:06,140 --> 00:26:14,420
Right. But we're not seeing that. So we're enrolling up to that 36 participants.

240
00:26:16,330 --> 00:26:21,540
So we stopped. Oh, we did stop. I got to go back.

241
00:26:23,630 --> 00:26:27,020
No. There you go.

242
00:26:27,590 --> 00:26:30,979
So at the end of the trial, right, here's the data that we had.

243
00:26:30,980 --> 00:26:36,680
We had 26 out of the 36, 26 responses out of 36 total patients.

244
00:26:37,280 --> 00:26:42,889
And we get the probability that our response rate is greater than the standard of care.

245
00:26:42,890 --> 00:26:47,390
Plus point three is about 62%. Right?

246
00:26:47,390 --> 00:26:51,800
So we didn't stop the trial. We went all the way. And then we basically have to decide, right.

247
00:26:51,860 --> 00:26:55,340
Is that good enough to move forward with this treatment?

248
00:27:04,250 --> 00:27:10,430
Okay. Alternate. So we could also add an additional stopping rule.

249
00:27:10,430 --> 00:27:16,940
So that stopping rule is only stopping for futility right now is only stopping if the treatment is really not effective.

250
00:27:17,270 --> 00:27:22,640
We could also add an additional stopping rule that says phase two is really concerned with safety as well.

251
00:27:23,060 --> 00:27:28,820
So I, I want to stop if I see that there is a lot of toxic events.

252
00:27:28,820 --> 00:27:33,350
And so in that case, we need to have a prior distribution of the expected toxicity rates.

253
00:27:33,860 --> 00:27:37,969
And so here we might have. So this is a gamut to use of this.

254
00:27:37,970 --> 00:27:46,340
Is there the toxicity rates T for toxicity we might give it a prior distribution of beta with 0.4 and 3.6.

255
00:27:46,820 --> 00:27:57,320
So right we have 0.4 over four, 10% toxicity expected with a relatively low number effective sample size.

256
00:27:57,650 --> 00:28:00,890
Right, because that information is probably from our phase one trials.

257
00:28:01,250 --> 00:28:05,660
And we don't have we don't feel like we have a lot of precision around that estimate, most likely.

258
00:28:06,950 --> 00:28:16,460
So now we could say we also want to stop the trial if the probability that the toxicity events is less than point ten is is low.

259
00:28:16,490 --> 00:28:23,480
So if if it's likely that we're actually seeing a lot of toxicity or more than 10% toxicity, then we want to stop the trial.

260
00:28:23,960 --> 00:28:29,630
Right. And so this sets up an additional stopping rule that says we could stop because it's not effective.

261
00:28:29,630 --> 00:28:36,650
We could also stop because it's too toxic and we can use those together with the prior distribution,

262
00:28:36,650 --> 00:28:41,030
set the accumulating data to decide whether we stop the trial or we continue.

263
00:28:42,810 --> 00:28:53,760
And what we can see with these vision designs in phase two are we have a we specify the sample size and we have these prior distributions, right?

264
00:28:53,820 --> 00:29:00,870
We can actually kind of like the MTI go through the possibilities and calculate the probabilities that we would stop for

265
00:29:00,870 --> 00:29:11,129
efficacy or stop for futility or stop due to toxicity based on the number of evaluable patients and the number of events,

266
00:29:11,130 --> 00:29:16,110
the number of toxic events, toxicity events, or the number of responses, right?

267
00:29:16,140 --> 00:29:25,290
And so we can actually get these nice pre-populated information rules that we could say,

268
00:29:25,290 --> 00:29:34,019
all right, well, if we had 15 patients and we saw that there were four, four responses, right?

269
00:29:34,020 --> 00:29:38,580
This is actually outside the acceptable efficacy range. So we'd have to stop for efficacy.

270
00:29:39,210 --> 00:29:48,720
Similarly, we could say if we had 15 individuals enrolled and we saw four toxic events, we could continue.

271
00:29:48,720 --> 00:29:57,330
It's not too toxic, right? So we're making decisions based on the number of responses for efficacy and the number of toxic events for toxicity.

272
00:30:01,860 --> 00:30:06,489
So this is just showing we can go through that with different scenarios.

273
00:30:06,490 --> 00:30:12,270
So given different true proportions of toxicity and true proportions of response rates.

274
00:30:12,660 --> 00:30:18,090
Right, we can see when we'd actually stop the trial versus when we'd continue or declare efficacy.

275
00:30:18,690 --> 00:30:21,450
So that's just something that you would want to run through prior to the trial,

276
00:30:21,480 --> 00:30:28,050
actually going to make sure that you've chosen that pile you write appropriately and you're making good decisions.

277
00:30:31,070 --> 00:30:44,870
Now, even if the design is Bayesian, often the end assessment or the end result is based on a frequentist, but some frequentist rules.

278
00:30:44,870 --> 00:30:49,099
And so, like I said, we, the FDA, especially for any drug that's going to be approved,

279
00:30:49,100 --> 00:30:56,000
needs to see that the type one error is controlled and the power is as expected.

280
00:30:56,330 --> 00:31:02,960
And so you'd simulate this trial and you can tune the stopping rules or you can tune the pi, l or PIU,

281
00:31:03,260 --> 00:31:11,840
or that probability of toxicity that you allow for based on making sure that you control your type one error

282
00:31:12,050 --> 00:31:18,290
and have enough power to find an efficacious treatment under scenarios where they're truly efficacious,

283
00:31:18,290 --> 00:31:23,240
under scenarios where it's too toxic. Right? You try all these different scenarios, just like the CRM,

284
00:31:23,990 --> 00:31:29,270
and then you see that you have these operating characteristics maintained and that's

285
00:31:29,270 --> 00:31:32,750
the trial that you would then move forward to actually accruing real patients.

286
00:31:32,760 --> 00:31:37,400
So you do all of this invasion design, you always do all this upfront work.

287
00:31:37,610 --> 00:31:43,249
You try to imagine all the different scenarios that it could occur, that you've chosen the right parameters, you have good priors.

288
00:31:43,250 --> 00:31:48,200
They're not overly informative if they're for the accruing data to speak to you.

289
00:31:48,530 --> 00:31:52,370
Right, and you feel like you're controlling type one error and you're maintaining your power.

290
00:31:54,380 --> 00:31:58,040
Okay. So the question here is this.

291
00:31:58,670 --> 00:32:08,000
These two thresholds, Pi, L and PIU is pi l a futility stopping rule or an efficacy stopping rule?

292
00:32:34,060 --> 00:32:45,960
Try to get a few more responses. Okay?

293
00:32:46,050 --> 00:32:51,300
Yes, right. It's a futility stopping rule at Wpials, the lower bound for which you need to see.

294
00:32:51,660 --> 00:32:58,820
If you see such low evidence of your treatment being efficacious, you should stop the drug.

295
00:33:00,530 --> 00:33:03,710
Hi. You, on the other hand, would be advocacy stopping more.

296
00:33:04,990 --> 00:33:18,219
You're going to get more. More experience with the Bayesian design in the exercises, which we'll do after we talk about randomized trials.

297
00:33:18,220 --> 00:33:27,430
But are there any questions? Yes. Look at these and why we choose Delta, not just incorporate that into like, hey, you pile.

298
00:33:31,180 --> 00:33:38,260
So don't. Okay, so, like, why wouldn't you just have the probability of gamma greater than zero?

299
00:33:44,560 --> 00:33:45,040
So I.

300
00:33:45,310 --> 00:33:54,610
So if you did that right, then you would just be saying, what's the probability that is this is better, but it could be like 1% better or 2% better.

301
00:33:54,730 --> 00:33:58,270
Right. In terms of response rate, if you didn't choose that delta to be higher,

302
00:33:58,750 --> 00:34:01,900
in which case you probably wouldn't want to move forward into phase through

303
00:34:02,290 --> 00:34:07,089
phase three if it's only slightly better so that if you left out the Delta,

304
00:34:07,090 --> 00:34:11,469
it would be a way to be more conservative in terms of moving forward to phase three.

305
00:34:11,470 --> 00:34:15,520
Right, or not less conservative, you would often move far to phase three.

306
00:34:16,420 --> 00:34:23,320
Choosing the Delta allows you to be a little bit more conservative and say, I really only want to move forward if it looks.

307
00:34:24,650 --> 00:34:28,990
Some clinical amount better than this than zero.

308
00:34:30,200 --> 00:34:39,250
So, I mean, I guess if there's an area where like there's really no other treatments and any amount of better efficacy would be useful,

309
00:34:39,260 --> 00:34:49,700
you could potentially have still some zero. Or you might want to make like pie.

310
00:34:51,320 --> 00:34:55,110
If you stopped early for efficacy, for example, you'd want that like 99%, right?

311
00:34:55,130 --> 00:34:58,880
Like, really high. So it could be super low.

312
00:34:58,880 --> 00:35:07,820
But usually we choose it so that it's always a little bit more peanut like control and no treatment or just the standard treatment either.

313
00:35:08,360 --> 00:35:13,520
So yeah, usually in most areas there's a standard of care already.

314
00:35:14,420 --> 00:35:21,590
However, if this is like a new disease or a very specific disease in terms of like precision medicine,

315
00:35:21,590 --> 00:35:29,770
now we're targeting and we don't know in this area what would be or there's nothing that's been used or we don't know,

316
00:35:29,780 --> 00:35:35,270
then it could be placebo, but oftentimes standard of care where it could be either depends on the setting.

317
00:35:37,120 --> 00:35:41,400
Good questions. Any other question? Okay.

318
00:35:43,080 --> 00:35:50,549
So we'll get to the lecture that exercises that actually tries to get you to implement some of these things in AR.

319
00:35:50,550 --> 00:36:00,720
But first, let's talk about randomized phase two trials. This is a pretty short lecture so that we've talked all about so far.

320
00:36:00,720 --> 00:36:04,830
It is having one single arm, one new treatment arm in phase two.

321
00:36:05,160 --> 00:36:10,049
However, there are also randomized designs. Also just I think I've noted this,

322
00:36:10,050 --> 00:36:16,680
but like we talk about specific designs in phase one and specific designs and phase two and we'll talk about some specific designs in phase three.

323
00:36:16,680 --> 00:36:23,880
But that doesn't mean they're all the designs, right? If I wanted to tell you about all the designs in all these phases, this would be a year course.

324
00:36:24,300 --> 00:36:28,740
And so because we have one semester, we just hit on some of the big ones.

325
00:36:28,740 --> 00:36:35,190
But just know that there are a lot of other designs that exist out there in phase one, in phase two that we're not talking about.

326
00:36:35,190 --> 00:36:41,640
But hopefully giving you this background is allowing you to get to that literature, read it a little bit easier than had you not had this.

327
00:36:43,080 --> 00:36:45,989
So we talked about a few of the single arm designs.

328
00:36:45,990 --> 00:36:51,900
Now we're going to go into well, we could run a randomized phase two design and we'll talk about why we would do that.

329
00:36:53,040 --> 00:36:58,020
And then what are some ethical and statistical perspectives of randomization?

330
00:36:58,650 --> 00:37:00,809
We'll just give a glimpse into randomization,

331
00:37:00,810 --> 00:37:08,550
so we'll spend a whole lecture on or part of a whole lecture when we talk about phase three on randomization and the different types of randomization.

332
00:37:09,090 --> 00:37:15,540
But we'll get a little glimpse that like I think most people think, oh, there's only one way to randomize is just flip a coin and be randomize.

333
00:37:15,840 --> 00:37:18,090
However, there's lots of different ways to randomize.

334
00:37:18,090 --> 00:37:24,240
So we'll just talk about simple block randomization today and talk more about other types of randomization in Phase three.

335
00:37:24,750 --> 00:37:26,520
And then we'll look at some case studies.

336
00:37:28,110 --> 00:37:38,810
So the advantages of randomization, hopefully you've learned these from epidemiology class or some design class, but they eliminate bias due to both.

337
00:37:39,780 --> 00:37:47,670
So either the patient or the physician or other things happening where if you self-select your treatment or the patient,

338
00:37:47,760 --> 00:37:52,680
the physician selects the treatment for you. Right? There's probably reasons for why that's happening.

339
00:37:52,920 --> 00:38:00,120
And with randomization, we take it the way those reasons are, we say you're equally likely or you have this probability of getting this treatment.

340
00:38:00,120 --> 00:38:08,220
And we can actually we know that probability, it's known, it's measurable, we can't get it wrong, but right, we don't have to model it.

341
00:38:08,430 --> 00:38:12,719
So we're eliminating bias. We're averaging out the bias due to unknown factors.

342
00:38:12,720 --> 00:38:21,990
So we have all these are all different, but hopefully with randomization on average the groups will be similar and.

343
00:38:24,530 --> 00:38:27,260
We especially want to make sure that the groups are similar.

344
00:38:27,620 --> 00:38:33,560
If there are specific risk factors or factors that are associated with the outcome of interest.

345
00:38:33,650 --> 00:38:38,389
So we'll talk more about that in phase three. But if our outcome is, say,

346
00:38:38,390 --> 00:38:47,060
some score on a depression test and there are specific factors that we know from like observational data or previous trials that say these factors,

347
00:38:47,060 --> 00:38:55,160
I don't know, age, whatever are associated with depression, we would want to make sure, especially that our groups are balanced across those factors.

348
00:38:57,110 --> 00:39:02,510
Why would we not want to randomize? Like, why do we have single arm phase two trials while they're simpler?

349
00:39:02,540 --> 00:39:08,060
Right. Once we start randomizing, it requires equipoise.

350
00:39:08,450 --> 00:39:13,819
Right. So at the beginning of a trial, we have to say that, well, I don't know if A or B is better,

351
00:39:13,820 --> 00:39:17,360
and so I feel comfortable randomizing individuals to these treatments.

352
00:39:17,810 --> 00:39:21,530
And so sometimes it's really difficult to justify that equipoise.

353
00:39:21,560 --> 00:39:31,910
So, for example, lung transplant has actually never been tested in a randomized clinical trial because once people started doing lung transplants,

354
00:39:31,910 --> 00:39:37,970
they didn't feel like it was ethical to not do a lung transplant in that population who would potentially need it.

355
00:39:38,810 --> 00:39:47,360
And so we can only really do randomization when we feel like there is some level of equipoise between the treatments considered.

356
00:39:48,870 --> 00:39:54,690
Once we start randomizing, right, we're going to require the sample size of a control group or of the other group.

357
00:39:55,080 --> 00:39:59,790
And so that's going to require more time, more people, more money.

358
00:40:00,180 --> 00:40:05,160
And so sometimes it's easy to say, I just want to get everybody on the new treatment.

359
00:40:05,190 --> 00:40:12,270
I'm going to say that I know the historical control rate because that way I don't have to spend the money on all the patients accruing to that arm,

360
00:40:14,070 --> 00:40:20,129
especially if the design, if this trial is going to be run by one center, if it's investigator initiated at, say,

361
00:40:20,130 --> 00:40:26,130
University of Michigan, there might not be the sample size to have a full control arm.

362
00:40:26,490 --> 00:40:29,940
So the options are go multicenter.

363
00:40:30,690 --> 00:40:34,979
Or if you feel like you have a really good idea about your control arm.

364
00:40:34,980 --> 00:40:39,059
Right. You could run a single arm study. You shouldn't make that decision just based on the facts.

365
00:40:39,060 --> 00:40:47,400
Well, I can't get enough people right. You should make sure that you've decided that your control rate is actually an acceptable one.

366
00:40:48,480 --> 00:40:55,799
Okay. And then like with randomization, so there's an administrative or logistical burden in terms of you have to make sure that

367
00:40:55,800 --> 00:41:00,420
you're working with whoever is distributing the treatments if the trial is also blinded,

368
00:41:00,420 --> 00:41:07,050
meaning that the either the patient and or the clinician or both don't know what the treatment is,

369
00:41:07,350 --> 00:41:13,500
there is a lot that goes into trying to make these treatments look the same and then labeled the same and somebody has to keep track of it.

370
00:41:13,690 --> 00:41:23,160
All right. So there's a lot of extra work that goes with that. So the question is, should phase two trials randomize?

371
00:41:23,790 --> 00:41:31,560
Right. So we've talked a lot about single arm trials, but there's a lot of questioning about should phase two trials randomized if you haven't.

372
00:41:32,010 --> 00:41:44,100
There's one paper in particular in the readings that I suggest you read for this to talk about phase two and randomization so specifically.

373
00:41:49,790 --> 00:41:56,749
So either either this Manjrekar and Sergeant Pepper, I think is good or the Sergeant and Taylor Pepper,

374
00:41:56,750 --> 00:42:00,739
they both kind of discuss reasons why you may or may not randomize.

375
00:42:00,740 --> 00:42:05,120
And so I, I know that they put a lot of readings up here, and I know they probably don't do them.

376
00:42:05,120 --> 00:42:12,710
But I do suggest that you look at that you look at these to give you better information about randomized phase two designs.

377
00:42:18,480 --> 00:42:25,590
So remember that Peter Doherty says that phase two is both assessing safety and activity and also feasibility.

378
00:42:25,590 --> 00:42:31,530
So in terms of the feasibility, getting a better idea of whether you could actually run a phase three trial.

379
00:42:31,770 --> 00:42:35,160
Right. And the phase three trials are almost always randomized.

380
00:42:35,580 --> 00:42:38,640
You get a better idea doing that if you try the randomization in phase two.

381
00:42:40,120 --> 00:42:47,290
So before I don't actually know how this works for everyone to see if you can figure it out.

382
00:42:47,350 --> 00:42:52,750
You can't really read this. It says there are multiple experimental therapies currently being tested.

383
00:42:53,290 --> 00:42:59,839
See if you can rank these questions. I don't know if you can do this on your phone as easily.

384
00:42:59,840 --> 00:43:04,760
I guess you probably does the same thing as a computer. So it doesn't the exact rank doesn't matter.

385
00:43:04,760 --> 00:43:10,910
But just see like what rises to the top of why you would want to randomize versus not randomizing.

386
00:43:32,790 --> 00:43:47,530
Here, I can see. There is no right answer.

387
00:43:50,500 --> 00:44:15,120
And. Right these questions.

388
00:44:15,160 --> 00:44:20,870
So we'll take a look in a second. Like, does the experimental therapy work at all or does experimental therapy work better than zero care?

389
00:44:21,220 --> 00:44:24,390
Right. Both those questions can be answered without randomization. Right.

390
00:44:24,960 --> 00:44:32,700
That's what we do in single arm studies. But perhaps you can answer them maybe better in randomized studies.

391
00:44:32,700 --> 00:44:36,930
Right? So does experimental therapy work better than standard of care?

392
00:44:36,960 --> 00:44:40,370
A lot of we write this first, right? We actually answer this in single arm studies.

393
00:44:40,380 --> 00:44:42,720
We assume that we know the standard of care response rate,

394
00:44:43,260 --> 00:44:47,820
but we might get a better estimate of that standard care response rate from a randomized study.

395
00:44:48,120 --> 00:44:50,130
Right. Similarly, for this one,

396
00:44:51,660 --> 00:44:58,950
I think there is a lot of reason why you'd want to do a randomized study if there are multiple experimental therapies in the pipeline.

397
00:44:58,950 --> 00:45:05,040
And you're asking which one should you move forward with? You would randomize across those experimental studies, right?

398
00:45:05,370 --> 00:45:11,340
And then move forward with the one that looks the most promising. And we'll see an example of a randomized phase two trial like that.

399
00:45:12,120 --> 00:45:14,300
Should a comparative trial be conducted later? Right.

400
00:45:14,340 --> 00:45:23,460
That's kind of like the the feasibility question of like, are we able to run this in a smaller sample that we could actually do this later?

401
00:45:24,360 --> 00:45:30,419
And this one, too, especially if we're trying to really figure out what the subpopulation is that you'd want

402
00:45:30,420 --> 00:45:35,069
to use the experimental therapy and you'd want to randomize across multiple subpopulations.

403
00:45:35,070 --> 00:45:37,530
Right, and then move forward with the one that looks most promising.

404
00:45:37,800 --> 00:45:44,390
So I personally would probably rank what you all ranked third and fifth as one and two, and then the other is lower.

405
00:45:45,270 --> 00:45:48,569
Certainly all of these questions are useful for running phase two trials.

406
00:45:48,570 --> 00:45:54,840
Right. But but the ones you all ranked, one and two, are most of you ranked one or two or highest.

407
00:45:55,770 --> 00:46:02,430
They we can do that with our single arm studies. We don't have to have randomization, but perhaps we get better data with randomization.

408
00:46:04,500 --> 00:46:13,110
Okay. So in terms of like the logistical perspective of do we randomize there is well, how many eligible patients are there?

409
00:46:13,110 --> 00:46:19,889
Are there enough for multiple groups? Right. If you don't have enough patients, for example, in rare diseases, you might not be randomizing.

410
00:46:19,890 --> 00:46:24,940
And that's actually the case that rare disease trials more often than non riders,

411
00:46:25,020 --> 00:46:33,090
these trials do not randomize because there's just not the population to pull from how many eligible patients can be enrolled,

412
00:46:33,270 --> 00:46:41,549
which is obviously connected to how many exist out there. But then also in terms of consent and then how many patients can we afford to enroll?

413
00:46:41,550 --> 00:46:45,640
So what are our resources here? Now, again, you shouldn't necessarily.

414
00:46:45,660 --> 00:46:49,590
Well, so how many eligible patients there are definitely going it's going to be very

415
00:46:49,590 --> 00:46:55,920
informative and to the design chosen but the the and so is resources but

416
00:46:56,250 --> 00:46:59,639
potentially you could try to get more resources if you feel the need that that

417
00:46:59,640 --> 00:47:05,100
randomized study is really important in terms of the ethical perspective.

418
00:47:05,100 --> 00:47:06,870
This is where that equipoise comes in.

419
00:47:07,290 --> 00:47:17,609
So do the clinicians feel like it's ethical to randomize patients and would a patient accept randomization in a trial like this?

420
00:47:17,610 --> 00:47:21,329
Right. If you say that you're going to run this trial or are going to randomize between A and B,

421
00:47:21,330 --> 00:47:25,890
if you actually go to the patients and try to enroll them, and they said, no, thank you, I do not want to be randomized.

422
00:47:26,160 --> 00:47:34,200
Right? You don't have a useful trial. So you need to make sure that the patients would agree to be randomized.

423
00:47:36,520 --> 00:47:41,860
There might also be some ethical perspective in terms of what's the disease prognosis

424
00:47:41,860 --> 00:47:47,980
for the patients and what's the potential for a large experimental treatment effect.

425
00:47:48,010 --> 00:47:53,830
So this might just figure out is it worth randomization or is it not?

426
00:47:56,590 --> 00:48:02,020
Then randomizing from a statistical perspective. So remember that the pipeline operating characteristics,

427
00:48:02,020 --> 00:48:10,000
those odds that we have a truly good treatment right from going from phase one to phase two to phase three,

428
00:48:10,480 --> 00:48:15,820
the odds of a true positive are the probability that is truly worthwhile.

429
00:48:15,820 --> 00:48:23,560
Right? Related to this theta is the power and this alpha is the type one error in each of the phase one, phase two and phase three.

430
00:48:24,250 --> 00:48:33,910
And so even if this error and phase two, like we've taken the wrong treatment forward,

431
00:48:34,120 --> 00:48:40,269
we're still increasing the odds of finding a good treatment going through phase one of phase two of phase three.

432
00:48:40,270 --> 00:48:47,440
So in that case, you might say, well, so what if my historical control rate isn't that great, right?

433
00:48:47,440 --> 00:48:49,120
So what if I have some error in that?

434
00:48:49,450 --> 00:48:55,120
If I put everybody on my treatment, I feel like I'm still getting good enough data to make a decision to move forward.

435
00:48:57,160 --> 00:49:04,719
So there's some reason why, you know, maybe not having the best estimate is still okay.

436
00:49:04,720 --> 00:49:10,150
I'm still going to somewhat whittle down the effective treatments and move forward with effective ones.

437
00:49:10,480 --> 00:49:14,290
On the alternative side, you might say, well, I'll get more bang for my buck, right?

438
00:49:14,290 --> 00:49:20,529
I'm more likely to get those really worthwhile treatments if I have better estimates or lower

439
00:49:20,530 --> 00:49:26,770
error in terms of those probability of the control response for the control rate moving forward.

440
00:49:32,660 --> 00:49:40,459
And as we've said, these one hour trials make this implicit assumption that the historical control rate is correctly described,

441
00:49:40,460 --> 00:49:44,090
at least in a frequentist setting. Right. In a Bayesian setting.

442
00:49:44,090 --> 00:49:50,240
We might have some some distribution around it, but because we assume that we know that.

443
00:49:50,450 --> 00:49:54,679
Right. We don't require so many people because we don't need that historical arm.

444
00:49:54,680 --> 00:49:57,680
We just say that we know that. And so we're not collecting data on it.

445
00:49:58,640 --> 00:50:05,690
However, we're assuming that that p not or that historical control rate or standard of cure rate is right.

446
00:50:06,110 --> 00:50:11,210
So like we said, we we say that it's in the same population as we later tested.

447
00:50:11,420 --> 00:50:18,499
It's recent. So like they've had the same other types of treatments or similar backgrounds, right?

448
00:50:18,500 --> 00:50:24,620
And that might all be wrong. So often the historical control rate comes from like, really?

449
00:50:26,020 --> 00:50:34,210
Long ago data that just isn't representative of the current landscape of the medical options for these patients.

450
00:50:34,660 --> 00:50:44,620
And so unless you can actually get that from like the most recent trial done or a very recent natural history study data or some cohort study data,

451
00:50:44,920 --> 00:50:48,730
it might be a really bad estimate of the natural response rate.

452
00:50:48,970 --> 00:50:52,330
And so you might be setting it to low when it should have been higher. Right.

453
00:50:52,330 --> 00:50:53,770
And then you wouldn't.

454
00:50:54,250 --> 00:51:00,250
You might see a difference and move forward to something that's ultimately not actually that much better than what the patients had.

455
00:51:01,830 --> 00:51:06,510
Okay. So let's look at some examples. So.

456
00:51:07,830 --> 00:51:18,810
The this is an example from 2016 and hepatitis B, this is kind of like a combination of phase one, phase two.

457
00:51:19,230 --> 00:51:27,030
So they had three different doses of this yeast vaccine, essentially,

458
00:51:27,030 --> 00:51:34,800
or yeast treatments, and they're using healthy volunteers to see how how useful it was.

459
00:51:35,160 --> 00:51:43,350
I think actually this. I think what happened in the Phase One study is they all looked safe, but they still weren't sure what to move forward with.

460
00:51:43,350 --> 00:51:47,400
So they decided in phase two to take all three of these doses forward.

461
00:51:49,320 --> 00:51:56,820
So in phase two, they enrolled chronic hepatitis B patients whose disease was already responding to some oral antiviral therapy.

462
00:51:57,240 --> 00:52:00,630
And so they use they randomized across four groups.

463
00:52:01,020 --> 00:52:04,080
So they had just the oral antiviral therapy.

464
00:52:04,110 --> 00:52:10,140
Then they had the oral antiviral therapy, plus these three different doses of this yeast treatment.

465
00:52:11,850 --> 00:52:15,720
And so they actually randomized one to 2 to 2. So this one or two to 2 to 2.

466
00:52:16,020 --> 00:52:23,790
This is something that you see in randomized trials. Where there is a control involved is that they say, okay, well, we need control data.

467
00:52:24,090 --> 00:52:28,320
However, we know that patients are going to be less excited about not getting the new treatment,

468
00:52:28,710 --> 00:52:32,280
so I'll increase the randomization probability to the treatment groups.

469
00:52:32,760 --> 00:52:40,080
So this is sort of that way in trying to balance the well, I need concurrent data, but I want patients to come and enroll.

470
00:52:40,140 --> 00:52:43,500
So maybe more will do that if they feel like there is a much higher chance of getting treatment.

471
00:52:44,040 --> 00:52:49,439
And then you're right. If you have three treatment arms and double the probability for each treatment arm, then the control.

472
00:52:49,440 --> 00:52:51,300
There's a much higher rate. Right.

473
00:52:51,370 --> 00:53:01,020
It's it's relatively it's not very high probability that you get the placebo or the standard OAB alone versus anything else.

474
00:53:02,190 --> 00:53:08,160
They use something called block randomization. And so I want to talk about what that means.

475
00:53:08,490 --> 00:53:16,040
So we're used a simple randomization flip a coin, right? You get A or you get B in the case where it's equal.

476
00:53:16,050 --> 00:53:18,629
So if we were just doing a B right, you'd flip that coin.

477
00:53:18,630 --> 00:53:29,040
If it's 1 to 2, right, you'd have the probability of getting a and than twice that probability of getting B's right in block randomization.

478
00:53:29,640 --> 00:53:38,010
What we can say is that, all right, if I just keep flipping a coin, there is a possibility that that randomization is unbalanced.

479
00:53:38,490 --> 00:53:40,670
Right. Especially in smaller sample sizes.

480
00:53:40,710 --> 00:53:48,360
I could actually get only three people on a and seven people on on B when I should have gotten five and five.

481
00:53:48,660 --> 00:53:55,860
So block randomization is a way in terms of ensuring balance or better ensuring balance between the treatment groups.

482
00:53:56,190 --> 00:54:03,690
And what that means is I'm going to treat blocks. Usually they're somewhat smaller and within that block.

483
00:54:03,690 --> 00:54:10,080
So for a block of four, for example, I'm going to ensure that two people have a and two people have B in a block of four.

484
00:54:10,440 --> 00:54:12,960
But there are lots of different ways that they could get randomized, right?

485
00:54:12,970 --> 00:54:23,460
So if I had two treatments and I have blocks of size four, right, it could be that the block looks like a B or B, B or B, a, right.

486
00:54:23,670 --> 00:54:28,319
So I don't actually I can't tell which treatment is next in this block because I don't

487
00:54:28,320 --> 00:54:33,900
know which out of these five possible randomization is in the block that somebody is.

488
00:54:34,200 --> 00:54:40,319
Okay. So the point is that we want to not if we just said we have a block of four and it's always a B, right.

489
00:54:40,320 --> 00:54:44,010
The clinician would start realizing, oh, this next patient's going to get A,

490
00:54:44,070 --> 00:54:49,049
the next patient is going to get B, and then they could start creating some bias.

491
00:54:49,050 --> 00:54:53,490
Could they say, I don't want you to go on this trial next. Just wait till the next next one comes, right?

492
00:54:53,910 --> 00:55:01,530
So this block randomization where we can have all these different combinations of the two treatments where there's two A's and two B's,

493
00:55:01,740 --> 00:55:08,460
allows for some randomness involved so that we don't know which block we're in or what the next treatment's going to be.

494
00:55:09,390 --> 00:55:12,870
So what happens is that we say we're doing block randomization, we have two treatments.

495
00:55:12,870 --> 00:55:14,849
We have blocks of size four, right?

496
00:55:14,850 --> 00:55:24,329
We generate as many blocks as we need for the total number of individuals, usually more because we sometimes lose people.

497
00:55:24,330 --> 00:55:32,370
So for example, we might say that we're accruing 20 people. So we'll get at least five blocks, right?

498
00:55:32,370 --> 00:55:35,490
Of these groups of four, usually more.

499
00:55:36,030 --> 00:55:44,429
And then as an individual comes in, right, we say, okay, this individual, let's say that the first block is AB, right?

500
00:55:44,430 --> 00:55:49,890
The first individual gets a, the next individual comes in, they get a, the next one gets B and the next one gets B,

501
00:55:50,220 --> 00:55:54,600
then I'm now I'm insured that there's balance in these first four patients.

502
00:55:54,930 --> 00:55:59,069
Now the fifth patient comes in. Right. I might actually have that block again.

503
00:55:59,070 --> 00:56:03,270
I might have one of these other blocks because the randomization within the block could be whatever.

504
00:56:03,270 --> 00:56:09,629
But as long as it's balance, okay. And so now I'm assigning my next patient to say this is the next block.

505
00:56:09,630 --> 00:56:16,340
B that B so the block, whatever, whatever block comes up, it's not in this order, right?

506
00:56:16,350 --> 00:56:20,339
So it's like random in that group before or how A and B was randomized,

507
00:56:20,340 --> 00:56:30,660
but at least it's balanced in every block of floor so that I can ensure that after every four individuals I have balance between the two groups.

508
00:56:30,960 --> 00:56:36,870
Now they had block size 14 because they have four groups and one, two.

509
00:56:36,990 --> 00:56:43,920
You two, two, two, two randomization. So the block actually has to be as big as 14 to ensure that we have the one,

510
00:56:43,920 --> 00:56:48,660
two, two, two, two, two, two equally balanced among those, those treatments.

511
00:56:50,940 --> 00:56:58,409
If you just have to treat men's and equal randomization, right, you have to have blocks of size of two of at least two.

512
00:56:58,410 --> 00:57:06,000
Right. Two, four, six, eight, whatever to ensure equal randomization between those.

513
00:57:06,900 --> 00:57:14,640
Okay. So that's two ways of doing randomization. So the block randomization is primarily just to ensure balance with smaller sample sizes.

514
00:57:15,150 --> 00:57:20,280
We'll talk a little bit more about other types of randomization when we get to phase three, when we have large sample sizes.

515
00:57:21,670 --> 00:57:26,200
Okay. So they did that block randomization, their primary efficacy endpoints.

516
00:57:26,470 --> 00:57:33,250
So this is their like their response is actually a continuous variable.

517
00:57:33,250 --> 00:57:39,220
It's the mean change in the serum hepatitis B surface antigen from baseline to week four.

518
00:57:40,000 --> 00:57:49,329
And they said that they need 25 patients in the oral antiviral therapy only group and then 50, right.

519
00:57:49,330 --> 00:57:54,820
Twice as many of those in each one of these new dose level of the treatment groups.

520
00:57:57,850 --> 00:58:03,250
They assume that the change from baseline to week 24 in the standard group is 0.12,

521
00:58:03,370 --> 00:58:11,770
and they want to detect a difference of at least 0.15 units of this of control, of this surface antigen.

522
00:58:13,570 --> 00:58:17,170
And then because they're going to compare control to each treatment group, right,

523
00:58:17,170 --> 00:58:23,560
control to the small, the low use dose group, the control to the moderate and the control to the high.

524
00:58:24,040 --> 00:58:27,580
They're going to control their type one error by doing a bonferroni adjustment.

525
00:58:27,940 --> 00:58:30,729
So they're going to say, we're really interested in doing these three comparisons.

526
00:58:30,730 --> 00:58:40,129
So I will divide my type one error divides and we'll talk about how they get the sample size more when we talk about phase three trials.

527
00:58:40,130 --> 00:58:48,700
So don't worry about where they got that 25 from now. But you can just assume that it's from a hypothesis test or a continuous outcome.

528
00:58:49,150 --> 00:58:53,800
With this type one error of 0.16, it was likely one sided.

529
00:58:56,250 --> 00:59:05,970
So we haven't learned these formulas yet. But this is the formula that we ultimately use where this R is the randomization allocation ratio.

530
00:59:06,330 --> 00:59:11,100
So the fact that it's not balanced, it's 1 to 2 to 2 to 2 that's going to affect this.

531
00:59:12,210 --> 00:59:16,080
This Z is a critical value depending upon the type one error.

532
00:59:16,440 --> 00:59:22,020
This Z is the critical value depending upon the required power.

533
00:59:22,410 --> 00:59:29,730
And then we have Delta. So that's that amount of difference that we need to see between the standard of care and the new treatment.

534
00:59:30,030 --> 00:59:35,400
And sigma is the variance of that, or sigma as the standard deviation of that, which I put right here.

535
00:59:37,240 --> 00:59:42,760
And so we get for ALM a that we need like 23 patients they get 25 assuming a

536
00:59:42,760 --> 00:59:47,170
little bit of dropout and then we need twice that amount for the other arms.

537
00:59:47,560 --> 00:59:51,940
So again, don't worry about where that came from. We'll talk a lot more about sample size when we get to phase three.

538
00:59:52,690 --> 01:00:02,469
So here are the results. So they have this into the oral into fire antiretroviral treatment here and then they

539
01:00:02,470 --> 01:00:08,080
have the that standard of care plus these three dose levels of the new treatment.

540
01:00:08,530 --> 01:00:15,220
And they treated 27 on the standard of care and then about 50 on the other arms.

541
01:00:15,310 --> 01:00:22,719
I think this little star is they accidentally gave two units to somebody who was assigned to 50 units.

542
01:00:22,720 --> 01:00:27,490
So this is a little bit higher. And so they they included it in here.

543
01:00:28,890 --> 01:00:33,030
So their main outcome remember was week 24.

544
01:00:33,150 --> 01:00:42,330
The mean change from baseline. And so you can see here that for the standard group it was -0.019.

545
01:00:42,800 --> 01:00:48,420
Remember, they actually thought it was going to be 0.12. So they're close, but not quite.

546
01:00:49,290 --> 01:00:53,400
And then everybody wasn't. Didn't contribute data.

547
01:00:53,430 --> 01:00:56,669
So this happens when people are lost to follow up.

548
01:00:56,670 --> 01:01:03,330
They drop out or they take away their consent. But 47, 48, 49 people had data at 24 weeks.

549
01:01:03,720 --> 01:01:11,880
And you can see here that the mean difference. Between the treatment group and the control group.

550
01:01:12,120 --> 01:01:15,900
Right. Is basically nothing for the small dose.

551
01:01:16,650 --> 01:01:24,719
Still basically nothing for the median dose, medium dose, and slightly higher from the for the large dose.

552
01:01:24,720 --> 01:01:28,680
But if we look at the P values, none of them are close to significant.

553
01:01:29,730 --> 01:01:33,959
We can see that if we look at Big 12, there's a little bit of difference.

554
01:01:33,960 --> 01:01:37,110
And at week 48, there's a little bit of a difference.

555
01:01:37,110 --> 01:01:45,990
And if you think about if you compare these differences across time, you might say that perhaps this like high dose is.

556
01:01:47,280 --> 01:01:56,340
Trending towards being effective the longer it's given, but it's not significant in terms of what they were hoping to find.

557
01:01:58,240 --> 01:02:04,420
So they didn't establish really a dose efficacy relationship,

558
01:02:04,420 --> 01:02:09,450
although in some sense it did look like the highest dose would have been the most effective,

559
01:02:09,460 --> 01:02:11,830
but there didn't look like there was a difference between low and medium.

560
01:02:13,060 --> 01:02:21,610
It was they didn't see a lot of safety issues and they didn't see any clinically or statistically significant differences.

561
01:02:22,360 --> 01:02:29,020
So I don't think none of these were continued on to to be looked at.

562
01:02:30,880 --> 01:02:34,260
Okay. So so that's one example of a randomized trial, right?

563
01:02:34,270 --> 01:02:39,549
There are these different doses. They weren't sure what to move forward with. So they looked at all of them and compared.

564
01:02:39,550 --> 01:02:42,760
So here's another one. This is for psoriasis.

565
01:02:43,090 --> 01:02:48,610
And they're looking at us. They're looking at appointment, I think, actually.

566
01:02:49,180 --> 01:02:54,750
Yeah, but we'll see that a foam treatment had been approved already.

567
01:02:54,760 --> 01:03:00,120
So here's something that you should always look for when you're critically thinking about papers.

568
01:03:00,880 --> 01:03:10,030
Often in like one of the corners or on the website of the paper you're going to see when the paper was submitted or received that to that journal,

569
01:03:10,510 --> 01:03:14,680
when the paper was accepted and when the paper was published.

570
01:03:15,070 --> 01:03:22,180
And usually you see quite a big chunk of time between received and accepted, because that's when it undergoes the peer review process.

571
01:03:22,210 --> 01:03:30,850
Right. Somehow this was accepted the same day it was received, which is somewhat alarming right now.

572
01:03:30,850 --> 01:03:39,090
There is the possibility these days that they say, like, you know, you submit to JAMA and they say, like, we we don't want to publish your paper.

573
01:03:39,100 --> 01:03:43,250
However, if you submit this to JAMA Open, you know, we could consider it there.

574
01:03:43,270 --> 01:03:51,670
Usually it still undergoes a different review, but perhaps, you know, it got reviewed and then they thought it was good enough to accept.

575
01:03:51,940 --> 01:03:57,490
But usually this is a a sign that like peer review wasn't well done.

576
01:03:59,830 --> 01:04:06,070
And then it's not clear why it took so long to publish online, but we would have liked to see a bigger chunk here.

577
01:04:07,570 --> 01:04:12,720
Okay, so this one. So obviously you can tell I don't have critiques about this one, but it's good to see.

578
01:04:12,730 --> 01:04:17,830
Right. So this is a there was a phase three study that for in psoriasis,

579
01:04:17,830 --> 01:04:26,680
they showed that this aerosol foam was efficacious compared to a placebo foam in terms of treating psoriasis.

580
01:04:27,220 --> 01:04:31,240
Now, this trial is saying, okay, so the foam is efficacious.

581
01:04:31,240 --> 01:04:36,060
However, we actually know that ointments are better at treatment treating things.

582
01:04:37,300 --> 01:04:44,430
But, you know, we know that people don't always use ointments because they're sticky and they're inconvenient.

583
01:04:44,440 --> 01:04:48,400
However, if it's much better than the foam, maybe it should be on the market, too.

584
01:04:48,520 --> 01:04:48,880
Right.

585
01:04:49,240 --> 01:05:03,820
And so they say here we're going to run a phase two trial where we have a placebo ointment and a placebo foam and then the foam and then an ointment.

586
01:05:04,450 --> 01:05:08,319
Now, if we think about this, right, so there are multiple arms and they're saying, well, which one?

587
01:05:08,320 --> 01:05:13,660
We want to compare these to the placebos. We want to move forward with the ointment for the foam.

588
01:05:14,050 --> 01:05:18,670
Now, there is already a phase three trial saying that the foam was better than a placebo.

589
01:05:18,670 --> 01:05:22,030
So why do they include the placebo foam? Right.

590
01:05:22,030 --> 01:05:25,240
Is not clear to me. If I were a patient, I would say absolutely not.

591
01:05:25,360 --> 01:05:29,019
Right. Like, I am not going on this trial. I know that the foam is better.

592
01:05:29,020 --> 01:05:33,220
Why are you giving me nothing? No foam, right? Like four tents. All right, I don't want that.

593
01:05:34,750 --> 01:05:40,480
Obviously, you would know because it's it was blinded, but still, you probably wouldn't want to participate in this.

594
01:05:41,620 --> 01:05:44,620
They said, well, you know, maybe we'll try to get more people in.

595
01:05:44,620 --> 01:05:54,099
It will randomized 3 to 3 to 1 to 1 so that you're three times more likely to get the real foam than the placebo foam

596
01:05:54,100 --> 01:06:00,130
and you're three times more likely to get the effective or hopefully effective ointment than to not affect equipment.

597
01:06:01,090 --> 01:06:05,110
But still, this design is somebody should have said, oh, what are we doing?

598
01:06:05,800 --> 01:06:09,640
Right, maybe this maybe they started this design before the Phase three data came out.

599
01:06:09,640 --> 01:06:13,750
That's the only thing I could think of why this design would be appropriate.

600
01:06:14,770 --> 01:06:17,739
However, that design should have been modified as soon as the phase three.

601
01:06:17,740 --> 01:06:22,810
Even if it was ongoing, there should have been an amendment and modified design as soon as the phase three results are out.

602
01:06:23,770 --> 01:06:29,830
Okay. So their end point is the proportion of patients who achieve treatment success at week four.

603
01:06:30,100 --> 01:06:33,220
And this is based on a physician's global assessment scale.

604
01:06:33,910 --> 01:06:38,950
And so they said that they needed 427 patients, 141.

605
01:06:38,950 --> 01:06:50,380
This is the actual number they had 140 135 on the foam and ointment that actually likely worked versus 49 and 51 on the placebos.

606
01:06:50,710 --> 01:06:55,450
They gave absolutely no justification for the sample size and the sample size is quite large.

607
01:06:56,260 --> 01:07:03,050
So the 50 is. Relatively in Rome of of phase three, but then because they required three times as much.

608
01:07:03,450 --> 01:07:12,330
Right. It's just a very, very large phase two study. And as you can see, they probably were aiming for 150, but they didn't get data on all of that.

609
01:07:12,600 --> 01:07:17,820
Anyway, there should always be information about why a sample size was chosen and it was not given here.

610
01:07:18,480 --> 01:07:27,180
So here's their results. And they have bar plots of at week two, one, two and four, and they're interested in four.

611
01:07:27,630 --> 01:07:34,030
And you can see that they're pointing out that the aerosol foam was better than the ointment and that was there.

612
01:07:34,050 --> 01:07:39,690
It was significantly better. They do not point out that both were significantly better than placebo.

613
01:07:39,720 --> 01:07:42,930
So why did they why have these placebo groups?

614
01:07:42,930 --> 01:07:50,280
Right. Is very confusing. Their entire discussion focuses on the comparison between the foam in the ointment.

615
01:07:50,490 --> 01:07:54,680
They do not talk about those placebo groups at all.

616
01:07:54,690 --> 01:07:59,190
And so, again, why did they enroll patients? Why do they spend money and patients?

617
01:08:00,000 --> 01:08:06,360
More importantly, why did patients get these things that we know don't work right when we're not even going to think about that comparison?

618
01:08:09,660 --> 01:08:17,040
They didn't justify their sample size, and it's just really hard to figure out why this trial was done.

619
01:08:17,650 --> 01:08:23,040
And so this is kind of an example of what another example of what not to do with what to be concerned about.

620
01:08:23,310 --> 01:08:31,260
And if you were a reviewer, a peer, reviewers of this, things that you would point out, like, you know, we see that this trial happened.

621
01:08:31,260 --> 01:08:35,790
Why are you enrolling people that controlled how did you get the sample size that needs to be included in the paper?

622
01:08:37,260 --> 01:08:42,090
Okay. Here's the last example for a randomized phase three.

623
01:08:42,240 --> 01:08:45,560
I mean, phase two. This is again from 2016.

624
01:08:45,570 --> 01:08:57,750
It's for metastatic esophageal cancer. And they're trying to figure out which one of these treatments do they have?

625
01:08:57,750 --> 01:09:04,680
Three potential treatments that they would add to this kind of standard of care to move forward.

626
01:09:04,690 --> 01:09:07,769
So they're saying we likely need this combination chemotherapy,

627
01:09:07,770 --> 01:09:15,780
but we don't know which new chemotherapy we should add to the standard chemotherapy is going to provide a better response rate.

628
01:09:17,660 --> 01:09:21,770
So they randomize equally between three arms.

629
01:09:22,100 --> 01:09:31,340
So they all have that cetuximab and then randomly they equally our patients are equally randomized across these three.

630
01:09:31,370 --> 01:09:37,399
The addition of these three other treatments. The primary endpoint is tumor response rates.

631
01:09:37,400 --> 01:09:42,320
So that's the proportion of individuals receiving either complete or partial response,

632
01:09:42,320 --> 01:09:48,800
meaning that their treat, their tumor has completely gone away and or it has shrunk a little bit.

633
01:09:50,030 --> 01:09:51,859
So here's interesting, right?

634
01:09:51,860 --> 01:09:59,720
So what we saw before in the other is that they randomize across these three arms and then or they randomize across four arms and both of those.

635
01:09:59,900 --> 01:10:03,560
And there was some control groups that they were comparing the new treatment to control.

636
01:10:03,950 --> 01:10:10,670
In this case, we're going to randomize across three active treatments and we're actually going to use single arm

637
01:10:11,450 --> 01:10:17,450
study designs for each of these three treatments and compare it to a known historical control rate.

638
01:10:17,930 --> 01:10:21,050
So that control rate of cetuximab alone.

639
01:10:21,620 --> 01:10:26,749
So here, instead of having an active control group or randomize across three treatments and doing a

640
01:10:26,750 --> 01:10:32,990
Simon two stage design in each one of these arms and comparing to a known control group.

641
01:10:34,130 --> 01:10:40,940
So they set up a Simon two stage design within each treatment arm where they said that the control response rate would be 25%.

642
01:10:41,270 --> 01:10:44,720
And they only want to move forward with the treatment if they see a 40% or better.

643
01:10:45,170 --> 01:10:54,549
So this is kind of like a. If there are multiple treatments and you want to figure out what's the best one to move forward with, right?

644
01:10:54,550 --> 01:10:59,950
You can run this kind of design and then say, I only want to move forward into phase three with whatever treatment.

645
01:11:00,580 --> 01:11:04,510
But we passed the Simon to stage or whatever treatment looks most promising.

646
01:11:04,810 --> 01:11:11,700
So there are different kinds of like ranking and estimation designs or this option, which is just saying, you know,

647
01:11:11,710 --> 01:11:14,440
I want to instead of doing these all individually,

648
01:11:14,440 --> 01:11:21,370
let's just do it all together and see which ones pass the Simon to stage to move forward with selection design.

649
01:11:21,700 --> 01:11:24,730
So they randomly assigned 245 patients.

650
01:11:25,180 --> 01:11:37,510
There was about 80 on each treatment arm and then they only had response data on 200 of them, or about 60 to 70 of them per treatment arm.

651
01:11:38,770 --> 01:11:44,350
They didn't have enough details in this article alone to figure out where that sample size came from.

652
01:11:44,680 --> 01:11:54,010
However, if we look at the Simon two stage design, considering P zero 25 and P 1.4 and a 5% type one error and 80% power,

653
01:11:54,370 --> 01:12:03,010
we can see that the optimal design requires 71 patients and a minimax design requires 60, so they're probably set up.

654
01:12:04,120 --> 01:12:10,179
You know, either the optimal or minimax design and then said they would accrue marks they expected to lose patients.

655
01:12:10,180 --> 01:12:15,490
So most likely here patients are possibly dying before they're able to see response.

656
01:12:16,330 --> 01:12:21,069
They could also be just lost to follow up, but hence they they increased the sample size to 80,

657
01:12:21,070 --> 01:12:25,959
knowing that they wouldn't be able to collect the response data on everybody. Okay.

658
01:12:25,960 --> 01:12:31,000
So here's what they saw. So you can see only very few patients actually had complete response.

659
01:12:31,030 --> 01:12:40,360
A lot of patients had partial response and their primary endpoint was the combination of complete and partial response.

660
01:12:40,990 --> 01:12:57,069
And so their overall response rate that this LRR is the 37 plus one over the total number of 63, so it's 60%, 45% and 53% for all of these.

661
01:12:57,070 --> 01:13:05,170
You can see that they didn't stop at the first stage. Right, because we have 70 patients, not somewhere like 20 or 50.

662
01:13:08,230 --> 01:13:14,380
They then showed so often in for cancer studies, the phase two endpoint is binary,

663
01:13:14,530 --> 01:13:18,010
but what we're really interested in is actually a survival type endpoint.

664
01:13:18,370 --> 01:13:21,490
And so you'll still follow these patients and collect the survival data,

665
01:13:22,090 --> 01:13:28,540
but it often takes too long to use survival as overall outcome that would be used in a Phase three trial.

666
01:13:28,540 --> 01:13:34,870
But they show you they collect this data and they show it to you, and you can see these survival curves are really overlapping.

667
01:13:36,520 --> 01:13:48,550
It looks like this ICC is maybe worse than ECF or full foxy, but once you get to like even 15 months, right, they're all the same.

668
01:13:49,030 --> 01:13:53,230
However, they did all perform better than. The.

669
01:13:55,410 --> 01:14:02,130
Then what was expected from the standard of care. So what they did, they determined was that.

670
01:14:04,990 --> 01:14:12,190
They said that the CFC led the group followed by FOLFOX, followed by ICC.

671
01:14:12,580 --> 01:14:16,780
Overall survival seemed promising for not the ICC.

672
01:14:19,970 --> 01:14:22,730
And there was. And so essentially,

673
01:14:22,730 --> 01:14:29,450
they could have decided to move forward with all of these treatments or with just the two that looked best in terms of their survival,

674
01:14:29,660 --> 01:14:34,430
at least the initial survival. I think what ended up happening was that.

675
01:14:38,660 --> 01:14:44,389
That Cetuximab ended up not being the standard of care anymore.

676
01:14:44,390 --> 01:14:48,230
And so they didn't end up going forward with any of those options in the phase three rule.

677
01:14:49,550 --> 01:14:53,570
Okay. So randomized phase two study is generally random.

678
01:14:53,720 --> 01:14:58,490
There's really it's really difficult to argue against randomization being better statistically.

679
01:14:58,940 --> 01:15:04,429
Right. Statistically, there are clear advantages to randomize you balance between groups.

680
01:15:04,430 --> 01:15:13,940
You get really good concurrent estimates of control, but there is a fair amount of logistical and ethical reasons to argue against randomization.

681
01:15:16,490 --> 01:15:26,390
However, we don't want to do phase two designs that are basically small ish or close to the same size as Phase three.

682
01:15:26,840 --> 01:15:30,649
Right? We want to make sure that if we're randomizing,

683
01:15:30,650 --> 01:15:39,680
it's because we need a better estimate of the control rate or it's because we have, you know, we're able to do this.

684
01:15:39,680 --> 01:15:44,420
And we didn't believe that we had a good control rate and historical control rate.

685
01:15:44,720 --> 01:15:48,890
So we're not doing it just to say that like, oh, this is close to phase three.

686
01:15:48,890 --> 01:15:51,170
Maybe we can make this decision at this point.

687
01:15:52,130 --> 01:15:58,550
So really the randomized phase two design is most highly motivated by the fact of meeting a concurrent control group,

688
01:15:59,390 --> 01:16:03,410
but it's often limited due to resources and ethics.

689
01:16:05,210 --> 01:16:10,380
Okay, so I run out of time. We didn't get to the. The exercise.

690
01:16:10,390 --> 01:16:18,940
So what I would suggest is that there is this there is these slides about exercise,

691
01:16:18,940 --> 01:16:26,320
and they're essentially just taking you through conducting and finding differences between the Simon two stage design and the Asian design.

692
01:16:26,680 --> 01:16:34,690
So I would suggest that you do this, but I will also spend about 10 to 15 minutes on Thursday going through it very quickly,

693
01:16:34,990 --> 01:16:41,230
through the answers and everything, so that you make sure that you have all this information and that you've done it for the test.

694
01:16:41,420 --> 01:16:46,510
Okay, so ask any questions. I'll also go through it on Thursday.

695
01:16:46,810 --> 01:16:50,530
Otherwise, I'm office hours today. You can ask about the test. You can ask about your homework.

696
01:16:50,980 --> 01:16:56,410
You will post homework three answers basically immediately after class on Thursday.

697
01:16:56,710 --> 01:17:00,070
So if you turn it in late, you're holding up your whole class.

698
01:17:00,190 --> 01:17:07,180
So make sure you get it in on time before the start of the class so that you all get into the study from how it's used.

699
01:17:15,200 --> 01:17:48,670
It's just something that's going to be like for you to see what kind of things that you think that you need to feel,

700
01:17:51,020 --> 01:17:56,950
all of the things that you would like.

701
01:17:57,880 --> 01:18:05,100
Do you want to go any other place to do?

702
01:18:06,400 --> 01:18:20,090
It's like a big test.

703
01:18:21,640 --> 01:18:29,170
I'm sorry to maybe not improve their losses.

704
01:18:29,930 --> 01:18:33,280
I don't really want to have anything worse.

705
01:18:35,860 --> 01:18:51,550
You know, my back is funny because you're not allowed to say, you know, why don't you ask any questions?

706
01:18:52,690 --> 01:18:56,680
So there's corporatization lot. There's random block recognition for you.

707
01:18:56,700 --> 01:19:04,920
Yeah, yeah, yeah. Because like a black box at the right time.

708
01:19:05,170 --> 01:19:14,470
Yeah. Right. So we actually see something below.

709
01:19:16,240 --> 01:19:27,820
So it's not like I said, power to me.

710
01:19:27,850 --> 01:19:33,790
One minus one. Yeah, exactly. Crappy aspects of how we usually think about it.

711
01:19:33,880 --> 01:19:38,860
I mean, I thought, oh my God, he did not get my.

712
01:19:38,970 --> 01:19:43,000
But maybe it was like a difference of like. Because I know, I know.

713
01:19:43,990 --> 01:19:53,210
But maybe it's funny. You should come out because in your class you are saying that I had to know.

714
01:19:53,440 --> 01:19:59,160
So I assume you are not allowed.

715
01:20:04,420 --> 01:20:10,239
But anyway, that's a fact. So much. But I just wanted to make sure that I could go.

716
01:20:10,240 --> 01:20:13,450
Oh, no, we went to I got five shoulders off.

717
01:20:13,450 --> 01:20:15,270
I would just say it's a one plus.

718
01:20:15,350 --> 01:20:29,230
It's more like either and it was it's a solid place to use like a like a so it's right and say like in later in the fight is like a blindfold.

719
01:20:29,730 --> 01:20:33,440
And other times it's like, yeah, yeah, yeah.

720
01:20:34,270 --> 01:20:38,410
So I'm just very confused by that because you are seeing those labels,

721
01:20:38,620 --> 01:20:43,809
which is big on a scale that you're right, it's a PG, it's you're right, it's poorly worded.

722
01:20:43,810 --> 01:20:48,219
It should just say, can you use the injured, your values of one, two, three, four.

723
01:20:48,220 --> 01:20:57,310
Oh yeah, yeah, yeah. Because I in your class, I, I did not tell it outside, but I listened to the recording and I just yeah, I function.

724
01:20:57,310 --> 01:21:02,110
It's about big on the page. So yes, when I went through the some of those lectures,

725
01:21:02,110 --> 01:21:07,120
there is a lot of confusion between those labels and then I try to make it clear, but I never change that.

726
01:21:07,120 --> 01:21:10,389
So it should have just said as told. Okay. Okay. That will make sense to me.

727
01:21:10,390 --> 01:21:18,790
And then maybe the last question is about the the last example you are saying because you are saying the last example,

728
01:21:18,790 --> 01:21:22,299
they are you are saying that they they both do the animation.

729
01:21:22,300 --> 01:21:27,520
But the day after that in this area that they do, they get us them on to a strange two.

730
01:21:27,520 --> 01:21:35,440
Right. So what I'm considering is if all they just want to use a random motion to make sure like all the people have the almost have the

731
01:21:35,440 --> 01:21:43,809
same car it's balanced so that the we all like the I mean they have like one control group and a three experimental groups so

732
01:21:43,810 --> 01:21:50,680
that back of the they want to make sure that that yeah so the reason so there wasn't a control group right I was this you know one

733
01:21:50,680 --> 01:21:57,340
across all those three Simon to stage the reason why they use randomization there is because then they can within one protocol,

734
01:21:57,370 --> 01:22:06,500
one trial essentially conduct three different trials all within the same with similar patient population because yeah, yeah, yeah.

735
01:22:06,680 --> 01:22:12,850
Just one one. So, so because they just attack like from Michael and we just combined that.

736
01:22:13,150 --> 01:22:13,570
That's right.

737
01:22:13,630 --> 01:22:20,680
They just combine like three so advantageous I mean zeros combined advantages of randomization randomization and also less than to a straight.

738
01:22:20,740 --> 01:22:31,710
Yes, you're right. So they want to make sure like every every, like every experimental treatment of the you have the same population properties.

739
01:22:31,770 --> 01:22:40,590
Yeah, yeah, yeah, exactly. Yeah. But the why, why do they do that or why you like make or create take on all these like, oh no, I didn't.

740
01:22:40,600 --> 01:22:44,950
I shouldn't I didn't mean to critique that at all. It was a totally fine example.

741
01:22:44,950 --> 01:22:48,910
I was trying to show the difference between that versus when they actually have a control.

742
01:22:49,180 --> 01:22:53,889
So in that one, they wanted them to be balanced across and they felt like they had a good enough historical control rate, right?

743
01:22:53,890 --> 01:22:56,950
So they could do the assignment stage and the other ones.

744
01:22:57,250 --> 01:23:01,239
They had always had a control group because I guess they decided that. But the I mean, the bigger they are,

745
01:23:01,240 --> 01:23:08,860
maybe their problem is that if once the balanced among these four three groups they control historical

746
01:23:08,860 --> 01:23:13,990
control rate is like a for overall population which may know to be up with that that's true.

747
01:23:14,220 --> 01:23:18,060
Yeah they could still have the same issue of yeah yeah yeah yeah, yeah.

748
01:23:18,070 --> 01:23:24,410
That's all the question. Yeah, yeah, yeah. So you're just waiting for him?

749
01:23:24,470 --> 01:23:32,670
Yeah. Know there's been a lot of [INAUDIBLE].

750
01:23:32,690 --> 01:23:42,590
What? I was. What? We should keep an eye on account of the surgery.

751
01:23:43,670 --> 01:23:45,710
Have you found on your blog site.

