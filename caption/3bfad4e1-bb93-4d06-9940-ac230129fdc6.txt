1
00:00:00,176 --> 00:00:07,176
Welcome to Part Two of the session on information bias, in which we will discuss the various types of information bias.

2
00:00:07,176 --> 00:00:16,176
As a brief outline, we will talk about the forms of exposure identification bias and outcome identification bias that I introduced in part one,

3
00:00:16,176 --> 00:00:25,176
and then I will give a brief definition of two common types of information bias that occur in our species and ecological studies.

4
00:00:25,176 --> 00:00:29,176
Recall bias is a form of exposure, identification bias,

5
00:00:29,176 --> 00:00:35,176
which is probably the most common type of information bias that you will encounter and hear referred

6
00:00:35,176 --> 00:00:44,176
to in the literature and essentially recall bias is simply an accurate recall of past exposures.

7
00:00:44,176 --> 00:00:53,176
We simply call this recall error when inaccurate recall of past exposures is non differential with respect to the outcome status.

8
00:00:53,176 --> 00:01:02,176
But please note that this recall error will lead to bias in our affect estimates.

9
00:01:02,176 --> 00:01:07,176
And this becomes recall bias when the outcome groups such as cases versus controls in

10
00:01:07,176 --> 00:01:14,176
a case control study systematically recall their past exposures in different ways.

11
00:01:14,176 --> 00:01:19,176
As you can imagine, this is a more common problem in case control studies,

12
00:01:19,176 --> 00:01:28,176
but it can occur in cohort studies if exposures are ever assessed prior to outcome status or if individual's

13
00:01:28,176 --> 00:01:34,176
future outcome status might affect their recall or reporting of exposures for whatever reason.

14
00:01:34,176 --> 00:01:43,176
And again, knowing what we know about the case control study design where sampling happens on the basis of outcome status,

15
00:01:43,176 --> 00:01:53,176
we know that this is a problem in case control studies because in this study, design exposures are assessed after the outcome has occurred.

16
00:01:53,176 --> 00:01:55,176
Here's an example of recall bias.

17
00:01:55,176 --> 00:02:03,176
Weinstock et al collected data on tanning ability, which was self reported by study participants in the Nurses Health Study,

18
00:02:03,176 --> 00:02:12,176
which is a cohort study of nurses in the United States. They collected this data at the study baseline and then after the occurrence of

19
00:02:12,176 --> 00:02:18,176
melanoma in the cohort participants and what they found was that the nurses

20
00:02:18,176 --> 00:02:24,176
health study participants who eventually developed melanoma tended to overreport

21
00:02:24,176 --> 00:02:28,176
having a low tanning ability when they were asked about their tanning ability

22
00:02:28,176 --> 00:02:35,176
after their diagnosis of melanoma. And this was an over-report compared to what they had said at the baseline

23
00:02:35,176 --> 00:02:40,176
interviews before they knew that they were going to be diagnosed with melanoma.

24
00:02:40,176 --> 00:02:46,176
So this is a clear example of where having a particular diagnostic status might lead people

25
00:02:46,176 --> 00:02:52,176
to overreport experiencing exposures that are known to be associated with that outcome.

26
00:02:52,176 --> 00:02:59,176
And this difference in response over time was not seen in the controls who did not develop melanoma.

27
00:02:59,176 --> 00:03:03,176
There are several strategies that we can use to prevent or reduce recall bias.

28
00:03:03,176 --> 00:03:09,176
One is to assess the exposure by using objective data collected or recorded prior to disease onset,

29
00:03:09,176 --> 00:03:13,176
such as medical records, employment records or residential histories.

30
00:03:13,176 --> 00:03:20,176
Another strategy in case control studies is to use a control group that might have similar recall to the case group under study.

31
00:03:20,176 --> 00:03:24,176
And so typically this would be another group with a different disease outcome

32
00:03:24,176 --> 00:03:29,176
who may also have a similar likelihood of having ruminated on past exposures.

33
00:03:29,176 --> 00:03:33,176
However, please note that both of these methods may induce selection bias.

34
00:03:33,176 --> 00:03:35,176
So with respect to using a different control group,

35
00:03:35,176 --> 00:03:44,176
we know that using a control group that has a different disease outcome might not represent the source population from which our cases arose.

36
00:03:44,176 --> 00:03:51,176
Which, of course, would induce selection bias and then assessing exposure, using data from other means might induce selection bias.

37
00:03:51,176 --> 00:04:00,176
If it makes us use a different control group that where we have access to these data because they might not always be easy to access.

38
00:04:00,176 --> 00:04:08,176
Another type of exposure identification bias, which I didn't mentioned earlier, but which definitely happens is response bias on surveys.

39
00:04:08,176 --> 00:04:16,176
And so there are many ways in which this can happen. Individuals can alter their response or behavior because they are part of a study.

40
00:04:16,176 --> 00:04:26,176
There can be bias towards responding to certain points on a scale such as scale extremes, where individuals may tend to give just ones and fives.

41
00:04:26,176 --> 00:04:31,176
This can also happen where there's a bias towards giving responses in the middle of a scale.

42
00:04:31,176 --> 00:04:37,176
So on a one five scale, this would be a lot of threes. And I think it really depends on what the scale is trying to measure.

43
00:04:37,176 --> 00:04:43,176
There can also be a social desirability bias on surveys where individuals may not like to

44
00:04:43,176 --> 00:04:51,176
report exposures or behaviors that might be stigmatized or perceived to be non normative.

45
00:04:51,176 --> 00:05:00,176
Another form of information bias is interview bias, and this is a form of exposure, identification, bias.

46
00:05:00,176 --> 00:05:05,176
This can happen when in-person or telephone interviews are conducted with study participants.

47
00:05:05,176 --> 00:05:15,176
And when the interviewer has knowledge of the outcome and thus asks additional clarifying or probing questions about exposures.

48
00:05:15,176 --> 00:05:20,176
And this would happen when this these clarifying or probing questions are given differentially

49
00:05:20,176 --> 00:05:30,176
according to the participant's outcome, status and simple ways to reduce interviewer bias are to have really robust interviewer training with defined,

50
00:05:30,176 --> 00:05:40,176
defined protocols for interviewing to minimize systematic differences in the ways in which the interviews are conducted across outcome groups.

51
00:05:40,176 --> 00:05:45,176
Another way to reduce this type of bias is to blind the interviewers to outcome status,

52
00:05:45,176 --> 00:05:50,176
although this can actually be difficult to do in practice if interviewers are also

53
00:05:50,176 --> 00:05:56,176
assessing outcome status at the time in which they are conducting the interviews.

54
00:05:56,176 --> 00:06:03,176
OK, so moving on to forms of outcome, identification bias, the first one here is respondent bias.

55
00:06:03,176 --> 00:06:08,176
This is relatively straightforward and can occur when the outcome is self reported by study participants.

56
00:06:08,176 --> 00:06:14,176
So in an example where a survey is administered and it doesn't really matter what the study design is here,

57
00:06:14,176 --> 00:06:19,176
let's say we're doing a survey assessing migraine headache episodes and it's hard to know

58
00:06:19,176 --> 00:06:25,176
whether self reported migraines truly represents migraines or just a severe headache.

59
00:06:25,176 --> 00:06:33,176
And so, ideally, wherever possible, we want to confirm information given by participants using objective means, such as hospital records.

60
00:06:33,176 --> 00:06:38,176
One example of a way to achieve this when you're limited to survey data or self

61
00:06:38,176 --> 00:06:42,176
reported data would be to ask better questions or ask additional questions.

62
00:06:42,176 --> 00:06:50,176
So in this migraine example, we could ask questions about additional migraines, symptoms such as presence of aura, nausea or fatigue.

63
00:06:50,176 --> 00:06:55,176
So in this case, the bias is really attributed to the participant in the way that we define it.

64
00:06:55,176 --> 00:07:02,176
But to be honest, it's a result of not asking the right questions or of a poor survey design.

65
00:07:02,176 --> 00:07:06,176
Another form of outcome identification bias is observer bias.

66
00:07:06,176 --> 00:07:14,176
And so this happens when the interviewer or other observer is assigning outcome status to these study participants and their

67
00:07:14,176 --> 00:07:21,176
decision of whether the outcome is present in a given participant is affected by the knowledge of that person's exposure.

68
00:07:21,176 --> 00:07:30,176
So as an example, a pathologist may be more likely to give a diagnosis of alcoholic cirrhosis if they know that the patient was an alcoholic.

69
00:07:30,176 --> 00:07:35,176
I'll note here that this is similar to diagnostic bias, if anyone is familiar with that.

70
00:07:35,176 --> 00:07:42,176
But I'll note that it occurs with patients who are already enrolled in a study and it doesn't affect their selection into the study.

71
00:07:42,176 --> 00:07:49,176
Strategies to prevent or reduce observer bias include masking observers to the exposure status or

72
00:07:49,176 --> 00:07:58,176
using multiple observers and checking agreement on the outcome assessment across the observers.

73
00:07:58,176 --> 00:08:05,176
Very briefly, I want to give a couple of definitions on information bias in RCTs as well as ecologic studies.

74
00:08:05,176 --> 00:08:12,176
When observer bias happens in RCTs. It is referred to as performance bias and it is a bias that can arise due to knowledge

75
00:08:12,176 --> 00:08:17,176
of the allocated interventions by the participants and the personnel during the study.

76
00:08:17,176 --> 00:08:24,176
We deal with this bias through blinding, as discussed in the Intervention Trials section.

77
00:08:24,176 --> 00:08:33,176
Information bias can occur in ecological studies. And recall that ecologic studies have the potential for substantial bias in effect estimation,

78
00:08:33,176 --> 00:08:42,176
which occurs when we commit the ecological fallacy, which is making causal inferences about individual level effects on the basis of group data.

79
00:08:42,176 --> 00:08:48,176
I just want to note here, and this is really purely for semantic reasons, because you may encounter this in the literature,

80
00:08:48,176 --> 00:08:54,176
the ecological fallacy is also referred to as aggregation bias and can be thought of as a type of information bias,

81
00:08:54,176 --> 00:09:05,176
if what we really wanted to assess was individual level exposure measures, but all we have available is group level data.

82
00:09:05,176 --> 00:09:10,176
And a couple of summary points now to remember the assessment of whether misclassification

83
00:09:10,176 --> 00:09:15,176
has occurred is subjective, because there is often no way to go back and obtain the truth.

84
00:09:15,176 --> 00:09:19,176
We have to make judgments about the presence and extent of misclassification

85
00:09:19,176 --> 00:09:24,176
based on our knowledge at hand and our knowledge of how a study was conducted.

86
00:09:24,176 --> 00:09:28,176
And basically, we have to remember that no study data are perfect.

87
00:09:28,176 --> 00:09:34,176
We measure exposures and outcomes and covariates as a way of trying to get at the truth.

88
00:09:34,176 --> 00:09:42,176
But our measures never really represent the truth. And there is always some amount of misclassification in every epidemiological study.

89
00:09:42,176 --> 00:09:47,176
We use our common sense on our epidemiological sense to examine the nature

90
00:09:47,176 --> 00:09:52,176
and magnitude of misclassification that might have occurred in a given study.

91
00:09:52,176 --> 00:09:59,176
Basic questions that you can ask yourself when assessing misclassification bias and studies are based on the data collection methods.

92
00:09:59,176 --> 00:10:07,176
What study elements may have been misclassified? And is misclassification likely to be differential or non differential?

93
00:10:07,176 --> 00:10:13,176
And then what is the expected impact of misclassification on the study results?

94
00:10:13,176 --> 00:10:20,176
So in summary, information bias arises from how information is collected from participants in the study.

95
00:10:20,176 --> 00:10:28,176
And this misclassification may be non differential or differential with respect to the outcome or exposures of interest.

96
00:10:28,176 --> 00:10:34,176
That's it for Part Two. The next is Part Three, identifying and correcting for misclassification.

97
00:10:34,176 --> 00:10:41,002
We will go over this in the live Zoom lecture on Thursday, October 15th, from ten thirty to twelve o'clock Eastern Time.

