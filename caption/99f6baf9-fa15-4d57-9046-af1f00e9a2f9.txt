1
00:00:09,670 --> 00:00:13,570
When I was growing up, my mom used to always say to me, nothing is perfect.

2
00:00:13,990 --> 00:00:18,400
And that is true for the data that we use in our epidemiology studies as well.

3
00:00:19,300 --> 00:00:20,770
In this particular video,

4
00:00:20,770 --> 00:00:29,800
what I'm going to be talking about is when our errors are similar between our groups that we're comparing resulting in non differential error

5
00:00:30,190 --> 00:00:39,760
and the impacts on our associations that we observe or the information bias that we can introduce due to non differential misclassification.

6
00:00:41,380 --> 00:00:48,490
So specifically, I'm going to talk about and describe common causes of non differential information bias.

7
00:00:48,880 --> 00:00:56,320
We're also going to be predicting the impacts of non differential information biased on observed associations.

8
00:00:58,190 --> 00:01:03,320
Non differential error usually occurs simply because you have an imprecise test.

9
00:01:03,920 --> 00:01:09,170
For example, we might have some outcome like blood pressure where there's somewhat arbitrary cutoff

10
00:01:09,170 --> 00:01:14,720
point above which a person with or without exposure will both be classified as disease,

11
00:01:15,170 --> 00:01:18,560
even though the cut point may itself not be exactly correct.

12
00:01:19,490 --> 00:01:24,020
Similarly, there may be some measure like manual readings of blood pressure.

13
00:01:24,320 --> 00:01:28,400
That's correct, on average, but it's measured with error among all people.

14
00:01:29,720 --> 00:01:35,450
Each of these scenarios, along with others like them, will introduce non differential measurement error.

15
00:01:36,350 --> 00:01:43,220
The question that I try and answer in this video is how much does that error matter to our associations of interest?

16
00:01:44,860 --> 00:01:46,750
To look at this question in detail.

17
00:01:47,050 --> 00:01:55,060
We'll use this example of data from a case control study that was investigating the association between exposures to tetrachloride,

18
00:01:55,060 --> 00:02:02,500
ethylene or PC e, which is a chemical used in metal decreasing and dry cleaning with breast cancer.

19
00:02:03,370 --> 00:02:09,969
Now, due to poor control practices, PCI has been a common contaminant in drinking water and there have been concerns

20
00:02:09,970 --> 00:02:13,840
that it may result in an increased risk of cancer among those who are exposed.

21
00:02:14,710 --> 00:02:18,370
Here you can see that if we estimate the odds ratio,

22
00:02:18,640 --> 00:02:26,050
we see that people with breast cancer have a two and a half times higher odds of exposure to PCI than those without breast cancer.

23
00:02:26,440 --> 00:02:32,350
And the risk of breast cancer among those with exposure is 70% higher than those without exposure.

24
00:02:34,120 --> 00:02:41,170
Now let's imagine that our exposure measure has 100% sensitivity and an 80% specificity.

25
00:02:41,890 --> 00:02:46,270
What this means is that all of the people with exposure are correctly classified,

26
00:02:46,750 --> 00:02:52,060
but 20% of those who are without exposure are misclassified as being exposed.

27
00:02:52,900 --> 00:03:00,790
This results in a movement of 20% of the people from cell C and D in our table to our cells A and B.

28
00:03:01,390 --> 00:03:10,030
Now, because the error is non differential, we see that the movement of people occurring happens in both the cases and the controls.

29
00:03:11,800 --> 00:03:14,500
Taking our observed and misclassified data,

30
00:03:14,500 --> 00:03:24,010
we can now estimate the odds and risk ratios that we would expect to observe given the reported sensitivity and specificity of our test.

31
00:03:24,670 --> 00:03:35,650
This is shown at the bottom of this slide. You'll notice that both the odds ratios and the risk ratios are smaller than the true odds and risk ratios.

32
00:03:36,610 --> 00:03:40,300
They're also closer to the null association of one.

33
00:03:41,110 --> 00:03:47,919
In other words, non differential misclassification of the exposure due to lowered specificity in this

34
00:03:47,920 --> 00:03:53,710
particular example makes our observed associations closer to no association at all.

35
00:03:55,330 --> 00:04:01,210
Now let's take this scenario where we have perfect classification of our unexposed population.

36
00:04:01,300 --> 00:04:08,800
In other words, our specificity is 100%. But there's misclassification of the exposed population due to a lowered sensitivity.

37
00:04:09,610 --> 00:04:16,959
For this scenario, we see the following observations and also find that the information bias shifts our

38
00:04:16,960 --> 00:04:22,810
observed associations towards the null or basically seeing no associations at all.

39
00:04:24,700 --> 00:04:30,820
So why is it that non differential exposure error always seems to bias our results towards the null?

40
00:04:31,750 --> 00:04:31,989
Well,

41
00:04:31,990 --> 00:04:40,720
imagine that I have this group of exposed individuals here represented as spheres and a group of unexposed individuals here represented as cubes.

42
00:04:41,500 --> 00:04:45,880
If our exposure was a necessary and sufficient cause of our outcome,

43
00:04:46,240 --> 00:04:54,760
then you might imagine that all of the exposed people would become ill, whereas none of those without exposure would become ill.

44
00:04:55,360 --> 00:05:02,050
This is illustrated by all of this fear as having the color as opposed to the cubes, basically being hollow cubes.

45
00:05:03,100 --> 00:05:07,840
Of course, in the real world we don't have everyone nicely separated into groups.

46
00:05:08,290 --> 00:05:12,490
Rather, all of the spheres and cubes are mixed up together in the full population,

47
00:05:12,910 --> 00:05:18,560
and we as epidemiologists, need to be able to sort out who is exposed and who is not.

48
00:05:20,290 --> 00:05:23,320
If I have a good classifier for exposure,

49
00:05:23,650 --> 00:05:30,280
I'm going to put all of the spheres back into an exposed bag and all of the cubes back into my unexposed bag.

50
00:05:30,910 --> 00:05:35,500
This will maintain the strong relationship that I will observe between exposure and outcome.

51
00:05:36,340 --> 00:05:40,630
However, if I have a very poor classifier for exposure,

52
00:05:41,050 --> 00:05:49,210
I now lose my ability to distinguish between the groups such that when I sort my spheres and cubes back into my exposed and unexposed bags,

53
00:05:49,570 --> 00:05:52,840
I've effectively randomly assigned people into those bags.

54
00:05:53,380 --> 00:05:57,910
This makes the two populations much more similar with respect to the distribution of the outcome,

55
00:05:58,360 --> 00:06:07,570
and I wind them biasing any true association between my exposure and my outcome towards no association or in epidemiologic speak.

56
00:06:07,840 --> 00:06:14,350
We bias it towards the null. Now, one important thing I want you to note here is that while I showed you an example

57
00:06:14,350 --> 00:06:18,610
of the impacts of information bias on an exposure that causes more disease,

58
00:06:19,090 --> 00:06:27,309
the same type of bias will occur towards the null, even if an exposure is protective again, because effectively,

59
00:06:27,310 --> 00:06:33,220
by not being able to classify my exposure correctly, I'm just sort of jumbling up those two bags.

60
00:06:35,000 --> 00:06:44,750
So just to summarize, we've now seen that lowering of a sensitivity and specificity in our exposure measure biases our observed associations

61
00:06:44,750 --> 00:06:51,200
towards one or basically makes it look more like there's no association at all between our exposure and our outcome.

62
00:06:52,850 --> 00:06:57,610
Now what happens if I start to look at misclassifying my outcome here?

63
00:06:57,620 --> 00:07:01,310
What I'm showing you is an 80% specificity of the outcome,

64
00:07:01,700 --> 00:07:07,340
meaning that I'm incorrectly identifying some of my healthy individuals as having breast cancer,

65
00:07:07,820 --> 00:07:11,640
but I'm doing the same among the exposed and the unexposed.

66
00:07:12,500 --> 00:07:15,319
The sensitivity, in contrast, is 100%.

67
00:07:15,320 --> 00:07:23,090
So no healthy individuals are being misclassified as ill like before with a non differential misclassification of an exposure.

68
00:07:23,540 --> 00:07:31,729
The observed odds ratio and risk ratio with my misclassification are both biased towards the null and

69
00:07:31,730 --> 00:07:37,670
therefore more likely to indicate that there's no association at all between the exposure and the outcome.

70
00:07:39,380 --> 00:07:48,560
Now here's where it starts to get a little bit interesting. In this scenario, we now have 80% sensitivity, but 100% specificity.

71
00:07:49,100 --> 00:07:56,750
In other words, now we're shifting our individuals from our A cell to the B cell and the C cell to the cell, but not the other way.

72
00:07:57,740 --> 00:08:04,250
In this situation, we observe a lower odds ratio that is biased towards the null just as before.

73
00:08:04,820 --> 00:08:09,320
But interestingly, you see that the risk ratio is unaffected.

74
00:08:11,140 --> 00:08:14,140
It's pretty cool, right? So what's happening?

75
00:08:14,590 --> 00:08:21,610
Well, because we have an equal fraction of people being misclassified among the exposed and the unexposed groups.

76
00:08:22,270 --> 00:08:29,340
The errors in the numerators of our equation with respect to who has disease and who doesn't are canceling out.

77
00:08:29,650 --> 00:08:40,840
Also, because we're just shifting people from the left to the right cells, the total number of people who are exposed and unexposed stays the same.

78
00:08:41,110 --> 00:08:48,130
As a result, our risk ratio is identical under non differential misclassification of our outcome.

79
00:08:49,810 --> 00:08:53,590
So now let's use that information to fill out our table a little bit more.

80
00:08:54,130 --> 00:09:01,900
What we see is that low specificity and low sensitivity biases are odds ratios towards the null,

81
00:09:02,590 --> 00:09:06,460
low specificity biases, our risk ratio towards the null.

82
00:09:06,970 --> 00:09:11,050
But low sensitivity does not bias the risk ratio.

