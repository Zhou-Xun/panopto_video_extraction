1
00:00:02,630 --> 00:00:11,300
So if you recall in slides seven and eight of this module of Module D,

2
00:00:12,080 --> 00:00:23,530
we introduced sequential and partial testing using extra sum of squares principle.

3
00:00:23,540 --> 00:00:28,490
If you if you recall, let's go back and just take a quick peek.

4
00:00:28,640 --> 00:00:44,540
So we introduced the concept of sequential and partial sums of squares and the kind of leading into the concept of sequential partial testing.

5
00:00:44,540 --> 00:00:50,209
And we used extra sum of squares principle to construct those different sums of squares.

6
00:00:50,210 --> 00:00:59,630
So we are going to take it from here and now develop fully the concept of sequential and partial testing.

7
00:01:00,410 --> 00:01:11,080
So let's in general kind of talk about when when is one appropriate over versus the other.

8
00:01:11,090 --> 00:01:22,910
So there are certain situations that could indicate strictly either doing a sequential or a partial test.

9
00:01:24,020 --> 00:01:37,580
And basically the when the sequential testing applies over the partial or vice versa really depends on the aims of the investigator,

10
00:01:38,900 --> 00:01:44,120
but sometimes helpful in the nature of the model that we are considering.

11
00:01:45,260 --> 00:01:50,190
So let's take, for example, the following model Y are equal to be done.

12
00:01:52,360 --> 00:02:08,210
B+ be the one x say one plus 2xi do plus B that we say three plus three Epsilon II, which is the random error or noise and the concept of partial.

13
00:02:08,220 --> 00:02:22,130
This is basically what we have been talking about generally in the context of multiple linear regression, which is B, which is an adjusted analysis.

14
00:02:22,460 --> 00:02:29,870
So in this particular model, the partial tests would assess the following types of question.

15
00:02:30,260 --> 00:02:35,420
So let's a question. One is, does X one contribute to the model?

16
00:02:36,500 --> 00:02:42,409
So explain the variation in the outcome. Given that explained, x three are already in the model.

17
00:02:42,410 --> 00:02:45,559
So like you do, each will be read at a time.

18
00:02:45,560 --> 00:02:53,000
And the inference is basically a given that the other covariates are already in the model.

19
00:02:53,420 --> 00:02:59,930
Does this specific covariance explain any part of the variation?

20
00:03:01,100 --> 00:03:15,860
Question two for x two we are asking does x2 contribute to the model when already given that x1 and x two are already in the model?

21
00:03:15,860 --> 00:03:29,089
So partial testing essentially is talking about the test for a certain full body and even all the other two variants in the model are already here.

22
00:03:29,090 --> 00:03:32,660
So it's adjusted for the other 4 minutes in the model.

23
00:03:34,850 --> 00:03:38,540
So that's partial testing.

24
00:03:39,200 --> 00:03:49,250
And for some more formally, you can ride this partial tests for X1, x2,

25
00:03:49,430 --> 00:03:59,480
etc. using again the general F and applying the principle of extra sums of squares.

26
00:03:59,600 --> 00:04:05,060
So here is what the partial test for X1 would look like.

27
00:04:05,840 --> 00:04:16,340
So the F statistic would be based on the x2, a sum of squares due to be torn between is the coefficient attached to x1.

28
00:04:17,030 --> 00:04:21,470
Given that better not better do better three are already in the model,

29
00:04:22,310 --> 00:04:32,510
so this is the extra sum of squares due to weight go on given better not beta to beta three are already in the model.

30
00:04:32,510 --> 00:04:45,549
And once again remember just to remind you, the beta not the coefficient of for the intercept is always there in the model on the null hypothesis.

31
00:04:45,550 --> 00:04:54,530
So always in model under the null hypothesis.

32
00:05:00,410 --> 00:05:03,860
Okay. And what do we have in the denominator?

33
00:05:03,860 --> 00:05:07,910
In the denominator, we have sigma hat squared.

34
00:05:08,540 --> 00:05:16,429
So the sigma squared is the MSE from the full model or the bigger model?

35
00:05:16,430 --> 00:05:19,310
The larger model under each one.

36
00:05:21,530 --> 00:05:29,540
Just as you can write the F in terms of the parameters, you can also write the F in terms of the covariance in the model.

37
00:05:29,540 --> 00:05:35,989
And in in this case, the way you write it would be f is the extra sum of squares.

38
00:05:35,990 --> 00:05:41,290
In the numerator you have the extra sum of squares contributed by x1.

39
00:05:42,680 --> 00:05:51,889
Given that the x 23 are already in the model and the denominator is once again sigma hat squared.

40
00:05:51,890 --> 00:05:57,440
So this would have an F distribution. The degrees of freedom, one and minus four y one.

41
00:05:58,300 --> 00:06:07,070
No, not because there is one strip out any curve that is in the full model, in the bigger model.

42
00:06:07,070 --> 00:06:13,370
And that extra strip is coming from X1. And what about the denominator?

43
00:06:13,370 --> 00:06:23,960
Degrees of freedom in minus four? Because I have expanded to x covidiots I have bitterness of B and minus b b is equal to four.

44
00:06:25,310 --> 00:06:32,120
Similarly for x2 we have F is the extra sum of squares contributed by beta two.

45
00:06:32,120 --> 00:06:38,359
Given beta not be drawn beta three are already in the model divided by sigma hat

46
00:06:38,360 --> 00:06:42,829
squared and equivalently can write because the extra sum of words due to x2,

47
00:06:42,830 --> 00:06:52,459
given x1 and x3 are already in the model and this has an and the ratio of this to sigma had

48
00:06:52,460 --> 00:06:56,510
squared as an empty solution once again with degrees of freedom one and then minus four.

49
00:06:56,870 --> 00:07:05,110
So just once again, to sort of summarize, as you can see from both these expressions that we can express to sum up,

50
00:07:05,120 --> 00:07:10,580
spread out in terms of either the parameters or the corresponding covariance, that's number one.

51
00:07:11,090 --> 00:07:17,030
So this is in terms of the parameters, this form and.

52
00:07:19,950 --> 00:07:27,200
And this form is in terms of the covariance. Okay.

53
00:07:28,750 --> 00:07:42,590
And the Intercept Beta note is always included after the particle bar sign, meaning that they do not is always in the model under the null hypothesis.

54
00:07:42,610 --> 00:07:52,409
Therefore, when we are writing out explicitly in terms of the covariates, we don't include that that beta,

55
00:07:52,410 --> 00:07:58,180
not because it's really part of the design matrix that has the column of ones, right?

56
00:07:58,510 --> 00:08:08,739
So if we use the code, we need to express the extra sum of squared, then we don't kind of write the bottom ones, but as,

57
00:08:08,740 --> 00:08:20,110
as part of the extra small squares expression and the denominator is always the estimate of Sigma Square in the full model, in the bigger model.

58
00:08:20,980 --> 00:08:25,510
Okay, what's a few more points?

59
00:08:26,140 --> 00:08:39,280
So with the partial tests, we could assess not only could be assess a single core body or the impact of a single core,

60
00:08:39,280 --> 00:08:48,940
but we could also assess the importance of a subset of overlays, given that a second subset of covariance is already in the model.

61
00:08:49,810 --> 00:09:04,300
For example, here, if we are interested in asking whether x two or three, either of these are important predictors of Y adjusting for x one,

62
00:09:04,660 --> 00:09:13,660
then essentially the null hypothesis that we are interested in testing is the null that beta two equal to beta three equal to

63
00:09:13,660 --> 00:09:27,820
zero versus here the alternative is what that either beta two is it not equal to zero or beta three is not equal to zero.

64
00:09:33,400 --> 00:09:37,210
Okay. So this is the alternative.

65
00:09:37,990 --> 00:09:42,510
And what is the extra sum of squares to test for this goal?

66
00:09:42,510 --> 00:09:52,540
We need subset. So remember here under the null, my model will look like under the null beta to beta three equal to zero.

67
00:09:52,870 --> 00:10:03,640
So my model is reduced to y equal to beta, not plus between X5 one and under the alternative.

68
00:10:05,230 --> 00:10:13,750
It's basically this full model here. So how many extra parameters do I have in the bigger model?

69
00:10:14,320 --> 00:10:19,660
Two by responding to better two and beta three are the coefficients for x2 any scheme.

70
00:10:20,200 --> 00:10:32,560
So here applying the extra sum of squares principle, then the numerator of this f statistic is the extra sum of squares due to x2 or its three.

71
00:10:34,060 --> 00:10:38,950
Given that x1 was already in the model.

72
00:10:40,300 --> 00:10:46,720
Yes. And adjusted for the degrees of freedom corresponding to this extra sum.

73
00:10:46,720 --> 00:10:55,680
Of course the degrees of freedom is the number of extra parameters and that is equal to two corresponding to the coefficients for x2 in extreme.

74
00:10:56,110 --> 00:10:58,540
And in the denominator I have sigma hat squared.

75
00:10:58,540 --> 00:11:05,920
So the the this f statistic would have an F distribution with degrees of freedom to and in minus four.

76
00:11:07,210 --> 00:11:11,700
Okay. So we can do covariate subset tests.

77
00:11:11,710 --> 00:11:16,980
Yes. Previously we had tested for.

78
00:11:22,390 --> 00:11:27,580
You can use it. This one. Can we use the teachers for.

79
00:11:27,580 --> 00:11:39,729
Absolutely we can. Yes. So the question was, can we use the details for the single corporate or should desks and the answer these.

80
00:11:39,730 --> 00:11:47,650
Yes. Why? Because, again, remember, the posture desks are and this is based on the system of work.

81
00:11:47,710 --> 00:11:55,750
But we saw that and as we want go through them at one end and minus two degrees of

82
00:11:55,750 --> 00:11:59,799
freedom is equal to the square of working within minus three degrees of freedom.

83
00:11:59,800 --> 00:12:05,290
So the answer is yes, we can do this test using that need desk as well.

84
00:12:06,340 --> 00:12:16,930
Led the point of this slide was to show that that you can actually use that general formulation to carry out all these

85
00:12:16,930 --> 00:12:23,860
different kinds of tests that can elicit the same equal value does that only accepts it as a benefit overall that.

86
00:12:25,360 --> 00:12:29,290
Okay, any other questions? Yes. So.

87
00:12:30,210 --> 00:12:35,910
The first real test for some sort of coherence, justice for the American family.

88
00:12:36,480 --> 00:12:40,620
Either of them, we don't know. But the fact that. Yes, we don't know.

89
00:12:40,620 --> 00:12:46,020
We know that they are more important than food or not.

90
00:12:46,440 --> 00:12:52,560
Okay. So we would reject the null hypothesis if either it is zero.

91
00:12:55,500 --> 00:13:03,290
Maybe as a follow up question to what you ask and when combining the question you asked.

92
00:13:04,110 --> 00:13:08,370
So for the full weight subset, this, let me just go to that slide.

93
00:13:14,590 --> 00:13:17,990
So here is the corporate subsidies.

94
00:13:18,010 --> 00:13:24,700
We are interested in testing out either x two or three important predictors of Y after adjusting for x one.

95
00:13:24,970 --> 00:13:31,570
And I just showed you that using the extra frame of square principle, again, you can control connected with degrees of freedom.

96
00:13:32,110 --> 00:13:36,460
Do it in minus four. So now the question is, can you put test here?

97
00:13:38,920 --> 00:13:42,010
Yes. You cannot do a test here.

98
00:13:43,750 --> 00:13:48,040
Everybody everybody agree on that for a seamless video,

99
00:13:48,040 --> 00:13:59,040
if you could do it to death because of the equivalence of F.A. Square and but for a for a full body, it's upsetting.

100
00:13:59,670 --> 00:14:03,219
You cannot digest. So that is, again,

101
00:14:03,220 --> 00:14:15,690
the power or sort of the importance of this general framework to show that using this general framework and using the extra sum of first principle,

102
00:14:15,700 --> 00:14:21,810
you can actually do this big is kind of this under the unified framework.

103
00:14:23,440 --> 00:14:34,540
Okay. Now, here is sort of an applied example.

104
00:14:35,170 --> 00:14:44,380
Suppose my response is systolic blood pressure and the covariates are age, weight and height.

105
00:14:45,370 --> 00:14:56,469
So I have a model. Is BP for the I individual is I can write it as B Dunham plus beta e times age plus

106
00:14:56,470 --> 00:15:06,040
beta w times v plus beta h times height plus epsilon ii and the random error.

107
00:15:07,630 --> 00:15:12,150
All the coordinates are of approximately equal interest.

108
00:15:12,160 --> 00:15:21,230
So in other words, there is no inherent ordering regarding the importance of the variables there,

109
00:15:22,090 --> 00:15:28,720
either the importance of variables or ease of data collection, or by design.

110
00:15:29,650 --> 00:15:38,200
Basically, all these coordinates here are of equal interest, and there is no inherent ordering of importance.

111
00:15:40,450 --> 00:15:48,280
Some of them interested in testing importance of each covariate adjusted for the others, and no particular order of the test is obvious.

112
00:15:48,400 --> 00:15:57,430
So in this example, a set of partial tests is going to be very appropriate and actually is the default.

113
00:15:58,690 --> 00:16:07,810
So you would do like, you know, a partial test of the effect of age on systolic blood pressure adjusting for width and height,

114
00:16:08,140 --> 00:16:12,880
a partial test of weight on systolic blood pressure adjusting for age and height.

115
00:16:13,420 --> 00:16:21,480
And lastly, partial test of the effect of height on systolic blood pressure adjusting for aid and weight.

116
00:16:22,810 --> 00:16:29,770
So we can do these three tests and there is no particular order of importance.

117
00:16:30,730 --> 00:16:38,570
So we will do three partial discs here, and each of these tests would look like this.

118
00:16:40,210 --> 00:16:50,020
And so the partial test for each would be like the null hypothesis is that beta is equal to zero versus the alternative two sided alternative.

119
00:16:50,020 --> 00:16:52,240
That beta is not equal to zero.

120
00:16:54,520 --> 00:17:08,320
So we would consider an F test or equivalently a D test, and the F test would look like this extra sum of squares due to beta e,

121
00:17:09,160 --> 00:17:20,800
there'd be days that is the coefficient for each given beta, not beta w, beta h, but already in the model divided by Sigma Square.

122
00:17:22,670 --> 00:17:27,010
And this has an F distribution with degrees of freedom one and then minus four.

123
00:17:28,390 --> 00:17:35,530
The four corresponds to the three coefficients for each height and weight, and the fourth one being the intercept.

124
00:17:36,580 --> 00:17:42,010
You can equivalently do a t test there.

125
00:17:43,270 --> 00:17:55,680
And we just talked about this where the T statistic is the point estimate of beta e divided by the standard error off b de hat.

126
00:17:55,690 --> 00:17:59,020
So this has a D distribution within minus four degrees of freedom.

127
00:17:59,590 --> 00:18:09,730
And because of the equivalence of 40 square and an F with one and the of degrees of freedom, then the alternative is two sided.

128
00:18:10,090 --> 00:18:23,320
We could actually do either an F test, partial F test or a D test, and we could repeat the same procedure for both weight and height.

129
00:18:25,350 --> 00:18:41,100
Okay. So so that's going to be the sort of the default for partial testing in, you know, MLR might be what about subset of covariates.

130
00:18:41,100 --> 00:18:46,020
So we could assist the association between systolic blood pressure and a subset of covidiots.

131
00:18:46,090 --> 00:18:54,120
Yes. So. Well in the previous slide.

132
00:18:58,270 --> 00:19:05,850
Better to make it. Christmas aims to. Okay.

133
00:19:06,310 --> 00:19:09,370
So this is the alternative.

134
00:19:10,830 --> 00:19:13,870
Oh, that. Is that it? Yeah.

135
00:19:14,740 --> 00:19:19,890
So it's the H1. Okay.

136
00:19:20,190 --> 00:19:34,560
So now if we wanted to do this, the association between systolic blood pressure and body metrics, so height and weight adjusted for it.

137
00:19:34,710 --> 00:19:39,510
So here I'm talking about the orbiting subset.

138
00:19:40,440 --> 00:19:51,929
So the null hypothesis is that the body mass measures are not associated with BP after accounting for age versus the alternative,

139
00:19:51,930 --> 00:20:00,150
that there is an association between the body mass metrics and the A.P. after controlling for age.

140
00:20:00,270 --> 00:20:11,160
So if I did formally in terms of the coefficients of the model, then basically here is the null meta w we will do beta eight equal to zero.

141
00:20:12,570 --> 00:20:25,530
So in other words, the model just reduces to SBP equal to beta, not plus beta eight times age plus epsilon under the null hypothesis.

142
00:20:25,950 --> 00:20:39,060
And the alternative is that like beta w not equal to zero or beta age not equal to zero or both would be zero.

143
00:20:41,860 --> 00:20:44,140
Okay. So that's the alternative.

144
00:20:44,470 --> 00:20:57,430
So now again, using the exact same principle of extra sum of squares, the f statistic is the extra sum of squares due to beta.

145
00:20:57,430 --> 00:21:06,100
WB got a new bit beta zero and beta E, but all of the wanted A.

146
00:21:06,130 --> 00:21:11,860
Now in the numerator I have the extra sum of squares divided by two.

147
00:21:11,860 --> 00:21:17,050
The two corresponds to the two extra barometers I can read.

148
00:21:17,970 --> 00:21:21,190
We now live in the model that already has it,

149
00:21:22,150 --> 00:21:30,940
and the denominator of this statistic has the our familiar sigma squared or the

150
00:21:31,720 --> 00:21:37,450
mean square letter from the full model of the model under the alternative.

151
00:21:38,410 --> 00:21:45,790
So again, this is an F distribution with degrees of freedom to an and minus four and voila, I'm done.

152
00:21:48,640 --> 00:21:58,870
Okay. So these are all typical settings for when a partial test would be applied.

153
00:21:59,950 --> 00:22:03,400
Now, let's talk about sequential testing now.

154
00:22:03,940 --> 00:22:16,060
Sequential testing. There are some situations that lend quite naturally and easily in the sequential testing.

155
00:22:17,860 --> 00:22:22,120
And the best example of this is a polynomial regression.

156
00:22:23,710 --> 00:22:27,280
A polynomial regression is a regression.

157
00:22:27,580 --> 00:22:37,960
It's like a multiple linear regression framework, but you have a single core reading it, but you all add different order.

158
00:22:38,290 --> 00:22:51,819
And so that will be it. So let's say here I have my responses serum cholesterol and the whole plate is body mass index B and I'm

159
00:22:51,820 --> 00:23:02,230
interested in a model like pseudo cholesterol as a function of the linear body mass index of quadratic body,

160
00:23:02,380 --> 00:23:05,890
the body mass index of 40 cubic and a quarter.

161
00:23:06,040 --> 00:23:26,770
So I have it c I for the it subject in the study is equal to beta not plus beta one times b i b i is the linear term corresponding to body mass index.

162
00:23:30,250 --> 00:23:38,080
Then I have plus beta to be squared. So this is the quadratic in BMI.

163
00:23:39,580 --> 00:23:43,930
Then I have plus beta three times VII q.

164
00:23:44,050 --> 00:23:48,530
So this is cubic DA, I mean, BMI.

165
00:23:48,550 --> 00:23:55,210
And then lastly, I have beta four times VII to the power four.

166
00:23:55,420 --> 00:24:04,660
So a petite DA, I mean, BMI plus I have the random error.

167
00:24:06,760 --> 00:24:15,820
Okay. So the polynomial regression is a is a very natural setting for sequential testing because

168
00:24:16,540 --> 00:24:25,740
you have to test the lower order times first before testing for the higher order times.

169
00:24:26,650 --> 00:24:33,340
And in polynomial regression, the goal is to balance model fit with interpretation and parsimony.

170
00:24:33,790 --> 00:24:39,670
In other words, like, do I need a quadratic term when I already have a linear term in the model?

171
00:24:39,790 --> 00:24:46,430
Why do we get for 40 cubic done when I already have a linear inequality done in the model?

172
00:24:46,450 --> 00:24:52,570
So do I need higher order terms when I already have the law order in the model?

173
00:24:52,630 --> 00:24:57,550
So you're trying to balance model fate with interpretation and possible.

174
00:24:58,420 --> 00:25:04,660
So here, as you can see in this model and this is an example of polynomial regression.

175
00:25:12,350 --> 00:25:21,140
And as you can see in this context, a partial test would not be appropriate.

176
00:25:21,620 --> 00:25:26,360
So what would be the interpretation of a partial test of BW equal to zero?

177
00:25:27,230 --> 00:25:38,960
Basically what it would say, kind of in plain English, the interpretation would be, is there a quadratic effect of body mass index on cholesterol?

178
00:25:39,650 --> 00:25:46,070
Given that I already have the linear and the cubic and the 40 dance in the morning

179
00:25:47,150 --> 00:25:53,360
so that the partial test actually would not be appropriate here because as I said,

180
00:25:53,930 --> 00:26:05,089
you know, in a polynomial regression, typically you would have to test the lower order terms first before examining the higher order terms.

181
00:26:05,090 --> 00:26:11,149
And the higher order terms should not be tested unless the lower order terms are significant.

182
00:26:11,150 --> 00:26:22,730
So in this context, a partial test would not be appropriate, and a sequential test is something that falls very naturally in this framework.

183
00:26:23,330 --> 00:26:55,870
Question. No.

184
00:26:56,110 --> 00:26:59,780
So that why the why we're fighting this war.

185
00:27:00,410 --> 00:27:03,480
That question I haven't answered.

186
00:27:03,500 --> 00:27:13,729
And of course, that question would be assessed based on, again, looking at the pattern of the scatterplot between Y index and so on.

187
00:27:13,730 --> 00:27:19,070
Because often times you can look at the scatterplot between Y an X and see the shape

188
00:27:19,070 --> 00:27:27,830
of the scatter and decide whether polynomial terms are going to make a difference.

189
00:27:28,100 --> 00:27:32,750
So we haven't really assessed why we're going to fit this model.

190
00:27:33,080 --> 00:27:43,790
But imagine if you had a situation where you are actually seeing in the scatter there, maybe like there's a kind of U-shaped back there.

191
00:27:43,940 --> 00:27:50,570
I mean, not exactly. You look like, you know, sort of or there is kind of a S-shaped pattern.

192
00:27:50,990 --> 00:28:02,330
So those are all exploratory analysis graph things that could help you in deciding as to whether you need to add to what you've done and so on.

193
00:28:03,110 --> 00:28:07,160
So that part is kind of precedes this model thinking.

194
00:28:07,190 --> 00:28:20,240
But at this point we are seeing that if this was a model of under consideration, then I think clearly here partial testing wouldn't be appropriate.

195
00:28:20,270 --> 00:28:24,650
What would lend more easily to interpretation is a sequential test.

196
00:28:44,650 --> 00:28:49,330
Yes. Whether there's a Libyan relationship between the core belief and the outcome.

197
00:28:49,840 --> 00:28:57,990
And then, you know, once once you kind of add the height of distance sequentially.

198
00:28:58,750 --> 00:29:04,450
So that's why you pass this, the lower number of people going into a higher order market.

199
00:29:06,220 --> 00:29:12,460
So that's both from the from the point of view of interpretation as well as parsimony.

200
00:29:13,750 --> 00:29:18,850
Okay. So this is a very natural setting for sequential testing.

201
00:29:19,360 --> 00:29:26,650
Here would be the sequence of tests that we would construct under this kind of scenario.

202
00:29:27,040 --> 00:29:35,080
So the first one that we are going to test does, as you mentioned, is is the linear effect of BMI.

203
00:29:35,560 --> 00:29:44,080
No. Is is that significant or does that explain serum cholesterol?

204
00:29:44,470 --> 00:29:50,740
So the null hypothesis is that beta one equal to zero versus alternative beta one, not equal to zero.

205
00:29:51,280 --> 00:30:00,870
And once again, we can construct an F test using extra sum of squares, but now we are using the sequential extra sum of squares.

206
00:30:00,870 --> 00:30:13,509
So we are saying some of squares due to beta one given we only had beta not in the model divided by sigma had squared and beta the name distribution,

207
00:30:13,510 --> 00:30:23,620
big one and in minus p degrees of freedom. If we did the null hypothesis, then only we go to the next test.

208
00:30:25,120 --> 00:30:30,130
Otherwise we stop. So this is basically called the stopping rule.

209
00:30:32,140 --> 00:30:34,330
And this is essentially, you know,

210
00:30:34,330 --> 00:30:44,200
the point that I was trying to make is that you see potentially after you build the model from lower and higher order terms,

211
00:30:44,670 --> 00:30:51,910
you know, at this point, let's table this sigma squared.

212
00:30:51,920 --> 00:31:01,580
What is this? Let's table this for now and we'll come back to it.

213
00:31:10,380 --> 00:31:13,440
And you know why? Why I'm mentioning this.

214
00:31:16,560 --> 00:31:20,630
So one, maybe, maybe lips.

215
00:31:21,480 --> 00:31:34,889
So the way I have defined the statistic, the general F for this sequential test, the sigma hat,

216
00:31:34,890 --> 00:31:40,100
I know the nod is between equal to zero versus the alternative is because more people are visible.

217
00:31:41,850 --> 00:31:49,379
So anybody wants to offer thoughts on what this sigma hat square should be.

218
00:31:49,380 --> 00:31:58,290
Should it be that MSP from the full body,

219
00:31:58,290 --> 00:32:07,139
meaning that I had better not be one to be dark you better be careful corresponding responding to

220
00:32:07,140 --> 00:32:20,430
the intercept linear quadratic in regard for dance or BMI or according to the way I developed this,

221
00:32:20,730 --> 00:32:31,530
if this this sigma had square food B and the MSE from the model B, you know, I have the alternative,

222
00:32:31,680 --> 00:32:36,930
which in this case is the model with a really big up and we get one, correct.

223
00:32:39,510 --> 00:32:46,590
Did everybody get this question? Why am I making a big deal out of it?

224
00:32:47,670 --> 00:32:50,489
Because all in all, I have been telling you lately the denominator,

225
00:32:50,490 --> 00:32:57,959
what you have is the MSE from the full body, meaning the model or the larger model.

226
00:32:57,960 --> 00:33:02,490
The model under each form. In this case, the model under each one.

227
00:33:02,670 --> 00:33:07,950
Because we are not going to be there one because I'm doing a sequential this.

228
00:33:10,630 --> 00:33:21,220
So should should seek my expert with the embassy from that podium or should it be the ABC from the late fall market,

229
00:33:21,730 --> 00:33:25,160
which as you know began on weekend one would definitely be there to up.

230
00:33:26,530 --> 00:33:30,580
So let's table this question for now. We'll come back to it.

231
00:33:31,360 --> 00:33:38,139
Now, let's do the. And so if we needed the null hypothesis here, then we go to the next test.

232
00:33:38,140 --> 00:33:43,090
And what is the next is? The next test is that bigger is equal to zero.

233
00:33:43,810 --> 00:33:47,890
So beta two is the coefficient corresponding to the quadratic done.

234
00:33:49,930 --> 00:33:54,400
That is zero versus the alternative. That beta two is not equal to zero.

235
00:33:55,150 --> 00:34:05,200
So the F first, the sequential F for this would be the extra sum of words due to greater to given beta naught.

236
00:34:05,200 --> 00:34:15,290
And we are already in the model given the intercept and the linear B images are already in the model divided by sigma head squared.

237
00:34:15,310 --> 00:34:21,040
Once again, we are going to come back and ask what the Sigma had square should be.

238
00:34:21,040 --> 00:34:26,469
Should it be the MSE from the model under the alternative here,

239
00:34:26,470 --> 00:34:31,570
which would be better not be the one beta two or should it be the sigma hot squared from

240
00:34:31,570 --> 00:34:37,510
the really big full model because beta not beta one beta do better through beta four.

241
00:34:39,070 --> 00:34:45,430
Nevertheless, this will have an error distribution with degrees of freedom, one and minus five.

242
00:34:48,310 --> 00:34:58,270
So if each note is rejected, then once again you go to the next test, otherwise you stop, etc.

243
00:34:59,470 --> 00:35:04,720
Okay, so, so that's the sequential sequence of test.

244
00:35:04,900 --> 00:35:11,560
Then you can further do a test of the cubic and the quantity terms.

245
00:35:11,620 --> 00:35:20,560
So you know, you kind of continue this P for our student cholesterol and BMI polynomial model.

246
00:35:21,820 --> 00:35:35,230
Continuing this way, suppose I want to test the null hypothesis that the second order model fits well, meaning that I only have the I and VI squared.

247
00:35:38,430 --> 00:35:41,740
What is the alternative? The tall order turns unnecessary.

248
00:35:41,760 --> 00:35:46,230
So like I need the cubic and the 40 tons also in the model.

249
00:35:47,070 --> 00:35:54,840
So more formally then what am I interested in testing that beta three is equal to beta for equal to zero.

250
00:35:54,840 --> 00:36:08,400
The coefficients associated with the cubic and 40 tons of zero versus the alternative that either or or both.

251
00:36:09,390 --> 00:36:14,520
The positions beta three and beta four are different from zero.

252
00:36:15,120 --> 00:36:18,120
So again, using the extra sum of principle,

253
00:36:19,500 --> 00:36:28,139
the extra sum of squares associated with B BMI Cube and BMI is for the bar for given that the linear and

254
00:36:28,140 --> 00:36:35,190
quadratic terms are already in the model divided by the two corresponding to the two extra parameters,

255
00:36:35,790 --> 00:36:42,000
and in the denominator I have sigma hat squared. This is an F distribution with degrees of freedom, two and n minus five.

256
00:36:42,420 --> 00:36:46,770
And basically I am, I'm done right.

257
00:36:46,770 --> 00:36:49,610
I can construct the sequential test.

258
00:36:49,620 --> 00:36:59,850
So the empirical, the cubic coefficient is beta three and beautiful is the question corresponding to the four determined BMI.

259
00:37:01,920 --> 00:37:09,959
Okay, so all good so far. Now we have to resolve what the sigma head squared is, but before that,

260
00:37:09,960 --> 00:37:18,720
a few other sort of general points and I mentioned that partial testing is going to

261
00:37:18,720 --> 00:37:31,530
be the default in any MLA setting and only in certain situations in certain settings.

262
00:37:31,530 --> 00:37:40,110
And the polynomial regression is one very natural setting where the sequential testing would be indicated.

263
00:37:40,560 --> 00:37:50,700
There may be other situations where sequential testing is indicated, when the full variance being considered are somehow ordered.

264
00:37:50,970 --> 00:38:01,470
Inherently they're ordered either by ease of interpretation, by perceived accuracy,

265
00:38:01,470 --> 00:38:07,800
by how easy or difficult it is to clean those many books and so on.

266
00:38:08,520 --> 00:38:17,370
So these are some situations or some considerations when the sequence should be appropriate,

267
00:38:17,370 --> 00:38:26,279
but generally bottom of this thing is that before and in your homework you will work on a problem like this,

268
00:38:26,280 --> 00:38:34,110
that the sequential testing may be appropriate by either of, you know, data collection.

269
00:38:36,690 --> 00:38:47,459
But the bottom line is the order of the variables or the order in which the variables enter the model makes a huge difference in between,

270
00:38:47,460 --> 00:38:51,930
you know, partial testing and sequential testing.

271
00:38:51,930 --> 00:38:55,020
Partial testing assumes that there is no ordering.

272
00:38:58,320 --> 00:39:04,560
So now let's resolve the issue of Sigmund Freud, which one could use.

273
00:39:06,330 --> 00:39:14,819
The idea is this Suppose you had a response y and the covariance are x1 x2x3x4x5.

274
00:39:14,820 --> 00:39:38,280
So I have five covariates let's. Consider this statistic the f is testing for the coefficients associated with x2 and it's three and equal to zero.

275
00:39:38,430 --> 00:39:46,050
They go to equal weight. That's equal to 0% alternative that either one or both are different from zero.

276
00:39:46,500 --> 00:39:56,309
So the partial F, so the sequential F would be essentially the extra sum of squares due to better to beta three,

277
00:39:56,310 --> 00:40:03,710
given beta one and which are not are already in the model divided by two for those two extra parameters.

278
00:40:04,500 --> 00:40:07,980
And the denominator is sigma hat square root.

279
00:40:08,070 --> 00:40:17,219
See, my head squared is computed based on the full model, meaning the model that contains all the five orbit.

280
00:40:17,220 --> 00:40:33,300
It's X1 needs to be x for x five. Although this test, this sequential test has got like is not testing anything about export and X5.

281
00:40:34,650 --> 00:40:38,850
I want to make sure that everybody understands what the issue is.

282
00:40:38,850 --> 00:40:50,730
So the the null hypothesis here is that beta two equal two beta three equal to zero versus the alternative is that.

283
00:40:54,440 --> 00:41:04,400
It's not h not meaning that either one or both of better do better three are different from zero.

284
00:41:06,830 --> 00:41:12,500
And because it is a sequential test and I'm entering the variables like you just said,

285
00:41:12,500 --> 00:41:16,670
then it's one, then it's two directly the next for the next five.

286
00:41:17,150 --> 00:41:29,590
So in this test, when I'm constructing the extra sum of squares sequentially to sum, of course it's for an S five and not in the picture at all.

287
00:41:32,420 --> 00:41:40,969
Yet in the denominator, the sigma squared is computed based on the really full model,

288
00:41:40,970 --> 00:41:50,420
the big model out there that contains exponents 2x2845 so it's 4x5 are also being part of the full model.

289
00:41:50,450 --> 00:42:00,440
Note that under the alternative here for the sequential test x 14 x five are not part of the model.

290
00:42:03,030 --> 00:42:12,269
Okay. So this F will have an F distribution with degrees of freedom to and in minus six because I'm

291
00:42:12,270 --> 00:42:18,989
computing sigma hat square based on the model that has all the files we need to send the intercept.

292
00:42:18,990 --> 00:42:20,940
So I have six parameters there.

293
00:42:23,060 --> 00:42:36,320
Another alternative of this sequential F and in some textbooks, you will see that the statistic would be defined as the denote.

294
00:42:36,350 --> 00:42:40,040
The numerator will be the same as this.

295
00:42:46,060 --> 00:42:54,940
However, the denominator would be the SSD from the model under the alternative.

296
00:42:55,540 --> 00:43:04,060
And the alternative here only includes beta, not beta one, beta two and beta three.

297
00:43:04,420 --> 00:43:13,840
So it would be the denominator. The denominator would be based on the SCC from the model with only those four parameters.

298
00:43:14,620 --> 00:43:24,579
So you divide it by minus four and you get the issue of these two quantities as

299
00:43:24,580 --> 00:43:29,410
an if distributed random variable with degrees of freedom to and in minus four.

300
00:43:29,680 --> 00:43:37,910
So in other words, the sigma square of the sigma hat squared in the denominator is estimated to be

301
00:43:37,960 --> 00:43:44,230
based on a model with only the four idiots x1 x to extend and the Intersect.

302
00:43:45,460 --> 00:43:49,600
So do you see the difference between this F and that star statistic?

303
00:43:50,050 --> 00:43:55,990
The numerator of these two statistics are the same, but the denominators are different.

304
00:43:55,990 --> 00:44:06,040
The denominators are different because of which and which model is being used to estimate that mse.

305
00:44:07,990 --> 00:44:11,020
To calculate them if you are to estimate the sigma squared.

306
00:44:13,390 --> 00:44:16,840
So that's the question we tabled for later.

307
00:44:17,260 --> 00:44:24,580
And here are sort of, you know, kind of what is going on.

308
00:44:25,300 --> 00:44:36,459
So the denominator when we are using the the F star statistic or in other words,

309
00:44:36,460 --> 00:44:47,170
when you are when we are using the denominator as the C from the model under H1 with only X1, x2, x3 as the covariance.

310
00:44:47,800 --> 00:44:56,050
This has a very nice interpretation because it's kind of like percent reduction in C adjusted by degrees of freedom.

311
00:44:57,010 --> 00:45:15,520
However, what happens is we end up and that's the kind of default in in most software, we end up using the top version of the F statistic.

312
00:45:16,210 --> 00:45:27,880
So we use a we end up using this F statistic where the denominator is computed based on the really full model,

313
00:45:27,880 --> 00:45:31,870
which also has X for the next five included.

314
00:45:32,380 --> 00:45:46,060
And the reason for that is this. So what happens is when you all meet globally, it's from a model, it positively biases that MSE.

315
00:45:46,330 --> 00:45:55,719
So if you if you only covariates then you know the estimate of estimated for MSE if you take

316
00:45:55,720 --> 00:46:04,030
the expectation of that in general it would be larger than the true unknown sigma squared.

317
00:46:04,030 --> 00:46:07,300
So that is a positive bias if you only over years.

318
00:46:08,290 --> 00:46:13,510
On the other hand, if you include extra idiots in the model.

319
00:46:14,140 --> 00:46:19,420
In other words, if there's overfitting, then usually that does not bias sigma heads.

320
00:46:19,430 --> 00:46:22,660
But all it does is it adds more noise.

321
00:46:23,530 --> 00:46:26,710
It makes the sigma hat square more noisy.

322
00:46:28,150 --> 00:46:39,370
So we end up using this top version, this F statistic, because the idea is, well, you know what,

323
00:46:39,790 --> 00:46:46,630
we are okay compromising on the precision a little bit, but we want to minimize bias.

324
00:46:48,160 --> 00:46:56,440
So we end up using the MSE from the really full model because the really full model has extrapolated.

325
00:46:56,440 --> 00:47:07,170
It's perhaps it will only meet the Sigma Square squared a bit more noisy, but it does the it will not bias sigma heads.

326
00:47:07,180 --> 00:47:12,940
But on the other hand, if you use the smaller model or the model under each one,

327
00:47:13,450 --> 00:47:21,490
then possibly we are all meeting some covariance and that might positively bias by sigma have square.

328
00:47:21,500 --> 00:47:32,500
So that's the rational and that's why we say, okay, we are okay to compromise on the precision a little bit, but we want to really minimize bias.

329
00:47:32,500 --> 00:47:40,000
So we end up using the our version of the F statistic in sequential testing as opposed

330
00:47:40,000 --> 00:47:47,380
to the F start and this is the default in board are the annual function in SAS.

331
00:47:49,000 --> 00:47:58,150
Okay. So both our function, ANOVA and SAS use our version of the F statistic in the sequential testing as opposed to a star.

332
00:47:58,810 --> 00:48:09,310
So that's the sort of reason why we end up using what we do, which is use the.

333
00:48:10,880 --> 00:48:22,953
It's statistical. Okay. So I'm going to pause here and we will take a break and we will come back at.

334
00:48:26,862 --> 00:48:34,622
So I have a Bible study where I'm looking at the role of each,

335
00:48:34,902 --> 00:48:41,202
which is measured in days and birthweight measured in ounces as predictors of

336
00:48:41,802 --> 00:48:49,992
infant systolic blood pressure as BP measured in millimeters of mortality.

337
00:48:50,202 --> 00:48:55,452
So this is a very simple example, but we're going to like, you know,

338
00:48:55,452 --> 00:49:06,912
sort of use this concept of extra sum of squares to construct different kinds of deaths, both in the partial and sequential setting.

339
00:49:09,072 --> 00:49:19,842
So the first question that I ask is estimate the crude unadjusted effect of Bartlet on SBP.

340
00:49:24,882 --> 00:49:30,072
And is the effect significant? So basically, this is a simple linear regression model, right?

341
00:49:30,582 --> 00:49:36,242
I am fitting SBP as a function of what we're doing.

342
00:49:37,962 --> 00:49:52,541
This gives me the crude effect of birthweight and here are sort of the results for the model fitting the coefficient for and the

343
00:49:52,542 --> 00:50:08,652
crude coefficient for birthweight is .1573 with the standard input of .28 5at statistic of 1.839 with the p value of born 0872.

344
00:50:08,952 --> 00:50:15,822
Okay. So one of thing that I would like to point your attention to is the residual standard error.

345
00:50:16,722 --> 00:50:24,672
So in other words, this is the square root of MSE 6.213 on 14 degrees of freedom.

346
00:50:25,902 --> 00:50:34,302
Okay. So this is the crude term effect of birthweight on systolic blood pressure.

347
00:50:35,142 --> 00:50:42,612
No, I'm saying like estimate the effect of birth weight on systolic blood pressure adjusted for age.

348
00:50:43,122 --> 00:50:44,912
So this is what am I asking?

349
00:50:44,922 --> 00:50:56,322
I'm asking you to give me a multiple linear regression model of SBP on age and systolic blood pressure of age and birthweight.

350
00:50:56,832 --> 00:51:01,332
And give me the effect of birth weight adjusted for age.

351
00:51:01,812 --> 00:51:06,342
So based on this MLR model.

352
00:51:07,122 --> 00:51:12,642
So here this is an MLR model as opposed to an SLR model.

353
00:51:12,702 --> 00:51:16,782
In the previous slide here, I was fitting an SLR model.

354
00:51:20,142 --> 00:51:39,072
The beta had for birth weight based on the SLR model was .157 and the beta half for birth weight from.

355
00:51:42,722 --> 00:51:48,752
The MLR model is now a .125.

356
00:51:52,482 --> 00:52:00,972
With the standard rate of 0.03, the statistic of 3.65 and a P value of A or two nine.

357
00:52:03,012 --> 00:52:08,742
So just, you know, kind of mark these statistics.

358
00:52:10,122 --> 00:52:20,622
So as we can see that the adjusted effect of pot paid on systolic blood pressure is significant at the point of five level,

359
00:52:20,622 --> 00:52:24,042
whereas the crude effect was no.

360
00:52:25,812 --> 00:52:35,772
Okay, so hold that thought for a few seconds, then we'll come back and see why that may be the case.

361
00:52:37,602 --> 00:52:45,432
Now, the next bar, the next question I ask is estimate the correlation between birth weight and it.

362
00:52:45,672 --> 00:52:49,272
So remember what we need are both covariates in the model.

363
00:52:50,022 --> 00:53:00,762
So I'm asking are these two of variants that I am including in the model to predict systolic blood pressure?

364
00:53:01,542 --> 00:53:05,892
Is there a correlation between these two and keep the correlation is significant.

365
00:53:07,092 --> 00:53:13,962
So this is basically a computer person split up woman correlation between birth weight and we

366
00:53:14,802 --> 00:53:29,082
both fit and age and Sam both base estimate of the Pearson correlation coefficient is .1068.

367
00:53:34,802 --> 00:53:43,441
And based on these statistics, I guess the null hypothesis,

368
00:53:43,442 --> 00:53:49,592
whether the population correlation is zero versus the alternative, that it's different from zero.

369
00:53:49,922 --> 00:53:54,452
And I end up not predicting the null hypothesis.

370
00:53:54,452 --> 00:54:06,271
The P value is .69 and basically the the conclusion is that there is there isn't a significant you know,

371
00:54:06,272 --> 00:54:15,332
there's no evidence to say that the population or correlation between age and birth weight is different from zero.

372
00:54:16,442 --> 00:54:22,472
So it is statistically non-significant. Yes. So you have a question and I think I know what the system is.

373
00:54:46,702 --> 00:54:55,492
Yeah. So that's why I said when I summarized those two modules, I said, Just hold that thought and we will come back to it.

374
00:54:59,272 --> 00:55:05,162
So the answer to your question is in the next slide, but since you asked it, let me just put it back.

375
00:55:05,482 --> 00:55:09,772
So let me. Okay, so what the summary from those first two models,

376
00:55:10,372 --> 00:55:24,112
the of the crude model based on the SLR and the crude estimate based on the SLR and the adjusted estimate based on the MLA from the SLR model,

377
00:55:25,042 --> 00:55:28,372
the effect of perfect was not significant. Correct.

378
00:55:29,632 --> 00:55:40,552
And from the MLR model, the effect of market was significant after adjusting for weight testing for each.

379
00:55:41,962 --> 00:55:45,412
Yes, everybody like we saw that. Okay.

380
00:55:45,482 --> 00:55:48,922
Now coming back, why did I care?

381
00:55:49,222 --> 00:55:56,601
What was the point that I wanted you to estimate the correlation between the covariates and see if that was significant.

382
00:55:56,602 --> 00:56:02,482
So now let me point your attention to these two numbers that they highlighted.

383
00:56:02,932 --> 00:56:06,292
So the crude estimate is point one, five, seven.

384
00:56:08,522 --> 00:56:13,292
Okay. And the adjusted estimate is point 1 to 5.

385
00:56:16,162 --> 00:56:24,512
If you compare these two. Just just let's focus on the point estimates.

386
00:56:24,512 --> 00:56:30,332
If you compare this to from the simple and the multiple linear regression models.

387
00:56:31,442 --> 00:56:35,522
Are these estimates really much different?

388
00:56:42,242 --> 00:56:45,872
But this is two or three months. Different standard years.

389
00:56:46,352 --> 00:56:51,422
Yeah. No, don't talk about the standard. That's why I said let's just focus on the point estimate.

390
00:56:52,352 --> 00:56:55,722
I know where you are leading. And in fact, that's what I'm going to have to.

391
00:56:55,802 --> 00:57:02,282
But let's answer this question first. So up at the point, estimates much different.

392
00:57:03,312 --> 00:57:06,452
No. Can I come back to the question.

393
00:57:06,812 --> 00:57:13,052
So as we saw that it and Berkeley those two Bob it's.

394
00:57:15,642 --> 00:57:19,122
You really don't have a significant motivation.

395
00:57:20,622 --> 00:57:25,542
I mean, other words, he did not want in tweeting.

396
00:57:26,352 --> 00:57:32,842
So I have Google Vineyards that I'm putting them all together.

397
00:57:33,432 --> 00:57:36,702
But those covidiots are not all related.

398
00:57:40,742 --> 00:57:57,952
So adding it to a model that had bought me already and given that Asian market are not calling it,

399
00:57:58,322 --> 00:58:07,142
would that change the estimate of corporate much from a simple innovation of your money to the market.

400
00:58:09,012 --> 00:58:14,622
No. That's why. That's why I was kind of letting you do that then, sir.

401
00:58:15,252 --> 00:58:20,672
But that is why I looked at the coalition. Okay.

402
00:58:21,042 --> 00:58:24,212
So basically, that's what is going on.

403
00:58:24,222 --> 00:58:31,632
Then the covariates, even birthweight, are not significantly correlated.

404
00:58:32,532 --> 00:58:41,292
So here is here was the question that we were coming to compare the simple and multiple linear regression estimates for bodyweight.

405
00:58:41,292 --> 00:58:45,371
Are they really any different y. So basically here is this.

406
00:58:45,372 --> 00:58:55,181
The crude estimate from the SLR model was tell me what what it was .15, what was it, 1.57.

407
00:58:55,182 --> 00:59:06,282
Right. And the adjusted estimate from the MLR model was 1.1 to 6.

408
00:59:06,282 --> 00:59:10,242
Correct. They're really not much different.

409
00:59:15,242 --> 00:59:28,112
And the reason is that he and Bartlett are not.

410
00:59:31,482 --> 00:59:33,552
Or significantly for elected.

411
00:59:36,812 --> 00:59:51,812
Actually the point estimate for the correlation is only point one, so they're not strongly correlated, and that's the reason.

412
00:59:54,092 --> 01:00:02,552
But now coming to the next part, what is the main reason?

413
01:00:03,002 --> 01:00:13,831
What do you think is the reason that based on the SLA model, Bartlett was non-significant, but based on the MLR model,

414
01:00:13,832 --> 01:00:21,482
when we adjusted for each Bartlet was a significant predictor of systolic blood pressure.

415
01:00:22,652 --> 01:00:26,492
We saw that the point estimates are not much different.

416
01:00:26,612 --> 01:00:31,262
So what is going on here? And basically where you were going.

417
01:00:32,432 --> 01:00:35,692
So I'll let you complete. Honestly, that wasn't very interesting.

418
01:00:35,732 --> 01:00:40,921
I was going to say if I first I was going to say that there's massive overlap with the standards,

419
01:00:40,922 --> 01:00:45,242
but the standard error in the second was a lot lower than the first. That's what. Yeah.

420
01:00:45,692 --> 01:00:50,972
So let's so let's just maybe like derived up in a table that might be.

421
01:00:51,212 --> 01:00:57,241
So I'm just going to call it sort of the model fit statistics.

422
01:00:57,242 --> 01:01:04,022
So here is say my SLR model and here is my MLR model.

423
01:01:06,572 --> 01:01:15,232
So I have beta had four birthweight, then I have a sigma happy.

424
01:01:16,622 --> 01:01:19,712
Then I have the standard error of beta her.

425
01:01:23,752 --> 01:01:28,372
And I have the statistics. I'm going to list all of these things.

426
01:01:29,002 --> 01:01:36,502
So as you just told me from the SLR model, it's point one, 5 to 7 from the MLR model is point 1 to 6.

427
01:01:37,402 --> 01:01:45,522
So quite similar, but maybe like roughly like.

428
01:01:47,032 --> 01:02:00,502
And I'm going to have another column here. So this is the percent difference between the MLA and SLR model.

429
01:02:13,432 --> 01:02:20,272
So the coefficients spawned estimates of kind of similar.

430
01:02:25,862 --> 01:02:31,982
What about Sigma hat? Does anybody want to go back and tell me from the output?

431
01:02:31,982 --> 01:02:40,692
Sigma hat from the SLR model was. 6.21.

432
01:02:41,862 --> 01:02:50,922
Yes. What about the MLR model? Go back and look at the residual MSE 2.47.

433
01:02:51,762 --> 01:03:07,592
2.48. Yes. So the stigma had as a becomes much smaller, it's almost like a 60% decrease.

434
01:03:13,912 --> 01:03:17,692
Did you find the right quantities from the output?

435
01:03:17,692 --> 01:03:21,822
Everybody. Okay. What about the standard errors?

436
01:03:22,552 --> 01:03:29,782
The standard error of beta hack from the SLR model was .085.

437
01:03:37,782 --> 01:03:43,212
.285 from the MLR model.

438
01:03:44,532 --> 01:04:02,752
It's point all three. So once again, roughly about a 60% decrease.

439
01:04:08,672 --> 01:04:23,252
What about the that statistic 1.84 from the seller model 3.6 from the MLR model almost like 98% increase.

440
01:04:27,962 --> 01:04:29,742
So do you see what's going on?

441
01:04:30,632 --> 01:04:43,972
The beat the head for McQuaid from the SLA and their Miller models are kind of similar, maybe like less than you know, about 15% decrease if at all.

442
01:04:44,492 --> 01:04:57,992
But one estimates are quite similar. However, the Sigma had got a lot smaller in the MLR model.

443
01:05:01,202 --> 01:05:09,452
Which in turn made the standard dated of beta had a mark which basically depends on that.

444
01:05:09,452 --> 01:05:13,712
MSI also got much smaller in the MLA model.

445
01:05:15,842 --> 01:05:22,292
And so the beta, the point estimate, which is in the numerator of the P statistic remains about the same,

446
01:05:22,832 --> 01:05:30,062
but the standard error becomes much smaller in the MLA model than the SLR model.

447
01:05:30,062 --> 01:05:33,632
And the standard error is what is in the denominator of the D statistic.

448
01:05:33,642 --> 01:05:39,422
So as a result, what happened in the MLA model? That P statistic got much bigger.

449
01:05:46,452 --> 01:05:54,222
You see what's going on. So that is why that in the pool model, the effect of what we did was not significant.

450
01:05:54,222 --> 01:05:59,502
But in the adjusted model, it is significant.

451
01:06:22,332 --> 01:06:36,852
Just adding age to. I'm not sure I got your question.

452
01:06:36,862 --> 01:06:41,422
So. So there are two things going on here. Even Barkley does not want to get there.

453
01:06:42,682 --> 01:06:55,612
Yes. Right. So. So. So basically what it is, it is not taking away much of the mediation that part of it explains.

454
01:06:56,872 --> 01:07:00,842
However, we are giving Egypt ends up in the unwanted.

455
01:07:01,282 --> 01:07:05,922
So it's it's actually contributing to extending some part of the mediation.

456
01:07:05,932 --> 01:07:13,492
So it's taking a part of the it's claiming a part of the mediation one even if it is more.

457
01:07:17,982 --> 01:07:28,182
Yeah, yeah, yeah. Sorry. Not that even into small in that sense what I'm saying that likability me related to part two because.

458
01:07:32,242 --> 01:07:37,072
Given that. Yeah.

459
01:07:37,372 --> 01:07:48,462
The difference between what I see. We the.

460
01:07:48,812 --> 01:07:52,372
You mean the sea mark going from a 6.1 to a 2.40?

461
01:07:52,402 --> 01:07:56,012
Yeah, because it is explaining. It is explaining.

462
01:07:56,012 --> 01:08:05,872
Like if you add multiple billions in the model, it will, you know, explain more and more of the variability in Y.

463
01:08:05,882 --> 01:08:22,472
So the is will get previews and. Maybe it's because it has sigma had limits in its calculation.

464
01:08:22,482 --> 01:08:32,962
The standard it gets use. Of the things that.

465
01:08:35,432 --> 01:08:42,732
I'm looking at, I'm comparing the standard internal data Fed going from the PWC to the actors.

466
01:08:53,212 --> 01:08:56,602
What is the standard bearer of that has?

467
01:09:00,832 --> 01:09:04,912
But is it just that I'm not even because segments there.

468
01:09:08,632 --> 01:09:16,431
So it's the variants. Remember we calculated the variants of beta, had variants of beta had three sigma squared times six.

469
01:09:16,432 --> 01:09:27,241
Prime symbols. Correct. So you feel when you are looking at the standard bearer of beta hair, which is the square root of that.

470
01:09:27,242 --> 01:09:31,502
So it's basically ce mark times.

471
01:09:32,822 --> 01:09:37,192
The diagonal elements of base brightness inversely fixed.

472
01:09:39,722 --> 01:09:43,632
So see, what I have is a part of the standard sort of.

473
01:09:48,062 --> 01:09:55,891
Yeah. Yeah, yeah. So you'd be dying from the flu, who the adjusted is.

474
01:09:55,892 --> 01:10:14,752
But he's only three questions. Yeah.

475
01:10:14,782 --> 01:10:18,612
I do like this. Like, let me help me understand.

476
01:10:18,622 --> 01:10:22,762
Like, where do you work? Where your.

477
01:10:25,202 --> 01:10:31,652
Confusion is like with everything, so it is only fixed in time.

478
01:10:32,912 --> 01:10:36,172
The point this student, as you saw, did not change months.

479
01:10:37,412 --> 01:10:40,712
Right. But it does seem to have changed.

480
01:10:43,392 --> 01:10:46,942
Meaning that we may see teams from the pool that just didn't it.

481
01:10:47,562 --> 01:10:55,571
So you can see like tens the billions of get ahead or the standard a little bit that also

482
01:10:55,572 --> 01:11:03,332
changes because the standard is going to be the head has seemed to have been its formula.

483
01:11:23,232 --> 01:11:29,552
Does this does that clarify? So business as.

484
01:11:43,142 --> 01:11:50,372
Yeah. Yeah. Because if you go back if you go back here, here is the MLR model.

485
01:11:57,552 --> 01:12:04,842
Here is the MLR model, so it doesn't show the SSR total.

486
01:12:05,232 --> 01:12:10,152
But you can look at this residual standard error. It's 2.47.

487
01:12:12,042 --> 01:12:27,792
If you add these three up in the MLR model, it's 53.4, five plus .125 plus one 5.80 versus in the M in the SLR model.

488
01:12:27,792 --> 01:12:32,922
So it's 53 plus roughly about six, right?

489
01:12:33,822 --> 01:12:44,772
So 59. And in the SLR model, it's 69 plus .157, something like 71.

490
01:12:46,482 --> 01:12:50,082
So 71 versus 59.

491
01:12:52,632 --> 01:12:56,081
It's this why is fixed doesn't depend on the model.

492
01:12:56,082 --> 01:13:08,202
So what happens to excess E it says C is much smaller in the MLR model compared to the SLR model.

493
01:13:16,472 --> 01:13:25,452
And what happens to this model and make predictor look significant media predictor appears in the.

494
01:13:29,212 --> 01:13:36,132
You just keep having. Yes, it would have to uncork because otherwise you start cutting.

495
01:13:36,162 --> 01:13:39,732
Yes. Otherwise you start talking. So and so the. Yes.

496
01:13:39,732 --> 01:13:49,842
Thank you. So basically what is happening here, the kind of the interesting thing here, because age and Berkeley are not related.

497
01:13:50,172 --> 01:14:03,252
So it's not like what we what they're explaining in the MLR model is, loosely speaking, that big contribution it's not quacking of.

498
01:14:03,462 --> 01:14:08,142
And really nice to see that. I like that phrase. It's not saying yes.

499
01:14:08,142 --> 01:14:25,202
It's not copying it from the other particular. Reduce the.

500
01:14:35,952 --> 01:14:40,872
What is the sigma? It used to see.

501
01:14:44,902 --> 01:14:47,872
Again. I mean, the fallacy is what is the U.S.?

502
01:14:52,082 --> 01:14:59,042
And remember, in the context of like this sequentially, like here, this thing we said, like we need to add more, more vineyards.

503
01:14:59,492 --> 01:15:05,042
It doesn't buy us much, but maybe kind of makes it a bit more noisy.

504
01:15:05,052 --> 01:15:10,172
On the other hand, you can have, you know, lesser for vineyards than what is needed.

505
01:15:10,652 --> 01:15:17,652
We actually bias the seed model. But basically we did a signal.

506
01:15:21,222 --> 01:15:32,512
Supreme. If you have proof, you convince anyone to positively bias the estimated four seamless.

507
01:15:48,602 --> 01:15:56,372
Okay. So now the question that you are asking is we are getting into the credibility of model selection.

508
01:15:57,032 --> 01:16:03,652
Like where do I make you a question is more like where do we stop adding more and more videos?

509
01:16:03,662 --> 01:16:05,842
So what is the point at which?

510
01:16:06,182 --> 01:16:14,732
And that is that is basically not based on really the Constitution of sigma, but that is based on many different considerations.

511
01:16:14,732 --> 01:16:18,392
And parsimony comes into play.

512
01:16:19,232 --> 01:16:23,881
Interpretation comes into play. Adding another cool video.

513
01:16:23,882 --> 01:16:29,632
Does it improve the the the fact of the Sigma Hackney security.

514
01:16:30,722 --> 01:16:36,722
All of these things come into play and it's not just one statistic that you can look at.

515
01:16:37,172 --> 01:16:46,382
It's a, you know, kind of a funny illumination of many things and so forth that unfortunately you have to wait.

516
01:16:47,132 --> 01:16:55,832
We will get to that that question. But it's not just one thing that you can focus on and be done.

517
01:16:57,262 --> 01:17:00,741
Okay. Any other questions?

518
01:17:00,742 --> 01:17:03,912
Thank you for all the all the other discussion.

519
01:17:03,922 --> 01:17:07,182
I hope everyone benefited.

520
01:17:07,192 --> 01:17:18,312
Yes. It could be.

521
01:17:19,812 --> 01:17:26,742
It could be. And most likely likely if it was that bought with an agent pretty highly equally gifted.

522
01:17:27,612 --> 01:17:31,032
And, you know, it is still significant.

523
01:17:31,032 --> 01:17:36,962
So it is taking away even more from the ground.

524
01:17:37,142 --> 01:17:42,702
Is this why you explain so then?

525
01:17:43,032 --> 01:17:55,342
Yes. Here is the reason why this is happening is precisely that's why I wanted to show you the politician that it's not keeping away.

526
01:18:02,392 --> 01:18:06,682
Okay. Good discussion.

527
01:18:07,042 --> 01:18:10,372
Thank you. So now let's look at.

528
01:18:15,062 --> 01:18:18,212
So basically that's why the statistic got much bigger.

529
01:18:18,542 --> 01:18:21,722
Now we are going to compute the sequential sum of squares.

530
01:18:21,992 --> 01:18:25,082
These are also known as the type one sum of squares.

531
01:18:25,892 --> 01:18:36,422
And here, the way I am fitting this model is basically remembering sequential sum of squares ordered is important.

532
01:18:37,382 --> 01:18:43,082
How I am entering or in which order I'm entering, the variables becomes important.

533
01:18:43,412 --> 01:18:50,522
So Berkeley is entered first and then it is entered in the model.

534
01:18:51,272 --> 01:19:01,952
So here is basically the first model, but with extra sum of squares due to what was given only or not was in the model.

535
01:19:02,612 --> 01:19:08,402
And I have this type one sum of squares here.

536
01:19:09,002 --> 01:19:17,792
Next I fit it extra sum of squares due to its given intercept and Bert, which was in the model.

537
01:19:18,062 --> 01:19:30,932
So here is that second model. So this is the first model and this is the second model because of the way that I am inputting the COVIDIOTS.

538
01:19:33,362 --> 01:19:39,882
Okay. So now then just to show that the order matters.

539
01:19:42,662 --> 01:19:51,842
Now I reverse the order of it and it so now it enters first and Bert with and second.

540
01:19:53,852 --> 01:20:01,562
So what about the the first model is like it is entered first.

541
01:20:01,562 --> 01:20:09,992
So the extra sum of squares due to age, given what it was in the model I started given, only the intercept was in the model.

542
01:20:10,532 --> 01:20:16,202
And the second model is when Eden Bert we are both fitted,

543
01:20:16,202 --> 01:20:23,912
but the extra sum of for Bert with the extra sum of squares due to God when given in the second age but in the model.

544
01:20:24,962 --> 01:20:28,831
So do you see how the order matters?

545
01:20:28,832 --> 01:20:37,622
Because here the extra sum of squares due to birthweight is 82.22.

546
01:20:38,192 --> 01:20:43,232
In this model, what about the extra sum of squares for birthweight?

547
01:20:44,462 --> 01:20:51,572
In this model where it was entered first, it's one 30.54.

548
01:20:52,262 --> 01:21:02,642
So the sequential sum of squares or the type ensemble squares will depend on in which order the covariance entered the model.

549
01:21:06,752 --> 01:21:11,592
Numerically verified that same SS and y uses f rather than f star.

550
01:21:11,612 --> 01:21:23,542
I'm just going to leave it up to you because you know, it's essentially just using the MSE from the full model.

551
01:21:23,552 --> 01:21:31,082
Now here the full model is essentially the model that has both worked with an edge.

552
01:21:33,002 --> 01:21:41,792
And you can see that the sequential, even though the sequential test will use the sequential sample squared,

553
01:21:42,212 --> 01:21:48,842
but the denominator sigma hat split will always use the MSE from the full model.

554
01:21:49,352 --> 01:21:52,562
So again, this is more of a verification.

555
01:21:53,162 --> 01:21:56,302
Now I'm going to compute the partial sum of Square.

556
01:21:56,312 --> 01:22:02,312
These are also referred to as type three sum of squared in SAS.

557
01:22:02,672 --> 01:22:12,482
If you are if some of you are using says that this is kind of assess the terminology for the

558
01:22:12,482 --> 01:22:22,532
sequential and partial somewhat spurts and remembering partial sum of squares order doesn't matter.

559
01:22:30,702 --> 01:22:43,601
Okay. So basically this 82.22 corresponds to the extra sum of squared is due to birthweight, given the intercept and age.

560
01:22:43,602 --> 01:22:52,542
But already in the model, the four 60.5 is the extra sum of squares due to age, given the intercept in birthweight but already in the model.

561
01:22:52,542 --> 01:22:55,992
So that's the interpretation.

562
01:22:56,292 --> 01:23:03,371
And it doesn't matter in which order you are incorporating this now using the extra sum of squares.

563
01:23:03,372 --> 01:23:10,452
Calculate how much would R-squared increase if it is added to a model that already contains birthweight?

564
01:23:10,812 --> 01:23:15,072
So I'm just going to sort of and I did here.

565
01:23:15,552 --> 01:23:23,892
So our square from a model with age and birthweight is what by definition this is the SSR

566
01:23:24,642 --> 01:23:37,781
from the model with age birth weight given only the intercept was pair divided by the SS.

567
01:23:37,782 --> 01:23:49,272
Why is this? Why does not depend on the model? It's basically fixed so I can write this as is this are.

568
01:23:53,242 --> 01:24:00,142
From a model that has birthweight given only beta not was there.

569
01:24:00,592 --> 01:24:18,052
So the sequential model fitting plus SSR from a model with each given beta node and birthweight was there.

570
01:24:26,972 --> 01:24:30,152
Divided by its white.

571
01:24:32,962 --> 01:24:37,492
So these are you know what? I have these sequential sums of squares.

572
01:24:47,312 --> 01:24:53,312
What is this first one BP says are burping given only beta,

573
01:24:53,312 --> 01:25:03,361
not birds in the model divided by yes is why this is the square from the unadjusted model the crude model simple linear

574
01:25:03,362 --> 01:25:19,082
regression model with birthweight plus this part is the gaining R squared by adding age from adding age to the model.

575
01:25:27,952 --> 01:25:36,232
So you can I'm going to go to the next slide and write this.

576
01:25:36,712 --> 01:25:40,132
You can see that.

577
01:25:40,132 --> 01:25:43,222
What is this quantity?

578
01:25:43,222 --> 01:25:55,671
What is the gaining R squared or what is the extra sum of squared due to age, given birth weight and beaten up already in the model?

579
01:25:55,672 --> 01:26:12,052
This is the fall 60.5. So the gain in our squared is then four 60.5 divided by the is this y which is if you add this to a plus the error,

580
01:26:12,532 --> 01:26:19,942
then you get 674, 60 plus one, 30 plus 79.

581
01:26:20,812 --> 01:26:30,052
So this is roughly equal 2.6 C So the gain in our expert is roughly 68%.

582
01:26:32,512 --> 01:26:36,832
And we can compute this basically using the sequential sums of squares.

583
01:26:37,382 --> 01:26:46,972
Another way of confirming this is essentially go back to the model that has the MLA model and the SLR model.

584
01:26:49,372 --> 01:27:05,362
So the R squared from the MLA model, from the SLR model was .19 and the R squared from the MLA model was 4.88.

585
01:27:06,742 --> 01:27:12,832
And the MLA model is the one where we added H on top of a birthweight.

586
01:27:13,342 --> 01:27:15,202
So what is the difference then?

587
01:27:15,892 --> 01:27:32,032
The difference is essentially point the D minus .19 and this is the output from MLA and this is the R squared from the SLR.

588
01:27:35,792 --> 01:27:39,002
And the difference is .68.

589
01:27:42,612 --> 01:27:52,602
Look up using the extra sum of squares test whether birth weight is associated with systolic blood pressure and not accounting for age.

590
01:27:53,232 --> 01:28:01,202
So basically I'm asking about like, you know, can you do a sequential test where um,

591
01:28:02,142 --> 01:28:08,292
enter BW before in the model and then age and we fitted a model like that.

592
01:28:08,922 --> 01:28:20,572
If you recall in the, in this slide here, there I have BWT birth weight entered first in the model and then age.

593
01:28:20,982 --> 01:28:30,732
So this one 30.54 in the model corresponds to the extra sum of squares due to birth weight given

594
01:28:30,732 --> 01:28:37,752
only beta not was in the model because birth weight is entered first in the sequential order.

595
01:28:38,502 --> 01:28:41,892
So then now what do I have?

596
01:28:43,422 --> 01:28:55,842
So this one 30.57 is the extra sum of squares corresponding to birth weight, not accounting for age.

597
01:28:56,202 --> 01:29:01,722
And based on this sum of squares, I can construct a sequential effect.

598
01:29:02,292 --> 01:29:09,761
That statistic has value 21.23 with a p value of less than one or one.

599
01:29:09,762 --> 01:29:25,972
So it is significant. However, note that this test result is different from the model,

600
01:29:25,972 --> 01:29:35,722
that SLR model that we had fitted where we only bought it because in that Islam model, the point estimate, as we have been talking about, is 1.5.

601
01:29:36,262 --> 01:29:51,262
And with the standard error of 1 to 8 and a B value of .287, not significant based on the T test, the D and the F are equivalent in this setting.

602
01:29:52,252 --> 01:29:58,222
So it's not because of, you know, using two different tests, but what is the reason for the difference?

603
01:29:58,582 --> 01:30:02,462
The reason for the difference is once again, the estimate of sigma.

604
01:30:05,092 --> 01:30:08,421
Okay. So it's in the SLR model.

605
01:30:08,422 --> 01:30:16,642
We're using the larger estimate of Sigma hat, but as in the MLR model, even in the sequential testing framework,

606
01:30:17,002 --> 01:30:26,642
remember the denominator sigma hat is based on the MSE from the full model we bought but we dummy so that's what is going on.

607
01:30:27,832 --> 01:30:34,522
Are discussing the output standard output sequential or partial.

608
01:30:42,852 --> 01:30:48,982
They are partial because remember, the default is.

609
01:30:51,502 --> 01:30:54,522
Partial for answers.

610
01:30:54,982 --> 01:31:04,342
And you can also verify this from the not only the point estimates, but also the sum of squares.

611
01:31:07,132 --> 01:31:13,612
So I think I think I'm going to stop here.

612
01:31:13,882 --> 01:31:22,132
I mean, so the standard default is partial tests,

613
01:31:22,132 --> 01:31:31,431
but you can get the sequential sums of words and conduct sequential tests by in in whatever software you are using,

614
01:31:31,432 --> 01:31:35,542
but by paying attention to the order in which you entered the variables.

615
01:31:36,262 --> 01:31:47,362
So I think that's so that's it. That wraps up this example and module G and other questions.

616
01:31:49,172 --> 01:31:56,202
Yes, true. So. It involves the residual status for 30 days.

617
01:31:56,272 --> 01:32:04,092
Yeah. Yeah. Yeah. The I mean, the output issue, the residual standard error for the MSE, the squared effect.

618
01:32:07,392 --> 01:32:15,462
Either for the death of their best mate feeds the spirit of the rest of us.

619
01:32:19,722 --> 01:32:30,012
Okay, so we didn't get a chance to go into more detail about this, but let's start from there on Thursday.

620
01:32:31,692 --> 01:32:35,162
Thank you. At.

621
01:32:39,132 --> 01:32:39,392
Some.

