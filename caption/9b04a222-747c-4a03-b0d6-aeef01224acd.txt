1
00:00:00,780 --> 00:00:10,820
You think so, which is go back then.

2
00:00:10,830 --> 00:00:16,480
But I think you're going to be able to say good bye.

3
00:00:16,710 --> 00:00:17,650
I noticed your class.

4
00:00:20,440 --> 00:00:37,390
You know, I was like, you know, like in an open letter now's time to get ready, because I mentioned it the other day, and you're like, Oh, I know.

5
00:00:37,910 --> 00:01:07,210
All right. Yeah, I'm so that when I was like, yeah, like when I look at your organization professors,

6
00:01:07,530 --> 00:01:37,440
sometimes I think of the do it yourself bias and how do you know if I should have obviously came in for the Technical Institute?

7
00:01:42,090 --> 00:01:52,340
I just. Yeah, no problem.

8
00:01:56,220 --> 00:02:02,640
Congratulations. We can predict that better next year.

9
00:02:03,180 --> 00:02:16,710
Yeah, I mean, I read that, but as we all know, whatever, you know.

10
00:02:16,800 --> 00:02:21,140
I know. I just think. I think what's going to end up happening that semester where we're.

11
00:02:21,720 --> 00:02:25,830
But we have to be here. Right.

12
00:02:30,150 --> 00:02:35,020
You're just going to go for it. So it's one thing.

13
00:02:36,690 --> 00:02:51,090
I think what's interesting is and I don't think it's like I remember studying accents.

14
00:02:51,110 --> 00:02:57,180
We have something every day. I think a class this time I'm going to see them for now.

15
00:02:57,350 --> 00:03:03,090
There is one of them.

16
00:03:04,740 --> 00:03:42,060
Yeah, I was kind of like I was hoping to outside in the morning and then they came and took a closer look at you.

17
00:03:42,640 --> 00:03:49,500
And I just feel like I'm.

18
00:03:59,050 --> 00:04:07,140
It's quite true that we're. It's true.

19
00:04:07,260 --> 00:04:15,270
And we may have more people strap on. That's right. Yes, it's certainly.

20
00:04:24,550 --> 00:04:28,630
That's what I said. Ready? Let me start the night.

21
00:04:33,490 --> 00:04:49,450
You. It's going to spend the next 4 hours, but there's no downside.

22
00:04:49,940 --> 00:05:17,270
It's just it's like I said, I could just start watching the show.

23
00:05:17,800 --> 00:05:36,590
All right. So we are continuing our discussion, which is and I want to start you thinking about the next assignment coming up.

24
00:05:38,140 --> 00:05:41,860
We will spend Thursday really deconstructing the students.

25
00:05:42,130 --> 00:05:47,680
We will have great examples to read and listen to one during class after Thursday.

26
00:05:47,710 --> 00:05:58,540
So like really get into the meet on Thursday. But for the moment, I do want to sort of set the stage for what are they doing for the next assignment?

27
00:05:59,680 --> 00:06:02,200
What I'm asking you to do is to imagine that.

28
00:06:03,450 --> 00:06:17,069
You are the first frontline health responder briefing the media on an outbreak of an unfamiliar infectious disease in an outbreak,

29
00:06:17,070 --> 00:06:20,910
specifically, two cases of Middle Eastern Respiratory Syndrome.

30
00:06:24,230 --> 00:06:29,900
You have to situate this in the current moment, like we have a pandemic going on.

31
00:06:29,900 --> 00:06:33,560
So you're only talking about something that's not COVID and it's cold.

32
00:06:35,990 --> 00:06:46,400
But imagine that you are as you're doing the five minute introduction space speech, letting people know that these cases exist.

33
00:06:48,680 --> 00:06:53,630
Think about what your goals are. Think about what I'm going to talk about today in terms of the dilemmas.

34
00:06:56,840 --> 00:07:06,300
The Irish, as it says in the syllabus, I'm giving you a few specific pieces of information, but a lot of leeway to make up what the story is.

35
00:07:06,320 --> 00:07:14,200
Beyond that, and this is, again, not a health education assignment.

36
00:07:14,900 --> 00:07:18,650
I am not asking you to do lots of research on this particular disease.

37
00:07:18,770 --> 00:07:24,960
That's not the point. Here's some basic information you can get, and that's fine.

38
00:07:25,950 --> 00:07:29,800
But do not go down the pathway of thinking, like with the test result.

39
00:07:29,830 --> 00:07:35,730
Don't go down the path of thinking. If your job is is to educate, educate people about this disease in great detail.

40
00:07:36,570 --> 00:07:44,640
Your task is to communicate in that first crisis moment, meet the needs of your audience,

41
00:07:46,380 --> 00:07:51,450
help them know what they think, what they should feel responsible.

42
00:07:52,680 --> 00:07:59,700
Get into that in much more detail on Thursday. But the idea that people make up this assignment more than anything else is that they

43
00:08:00,240 --> 00:08:03,569
start to learn more and more and they turn it into a health education assignment.

44
00:08:03,570 --> 00:08:13,190
And that is that is a dangerous path because it's not about the information as much as it is about performing people lives.

45
00:08:14,100 --> 00:08:15,990
That's what I want us to be thinking about today.

46
00:08:19,290 --> 00:08:28,470
I also want to acknowledge that we are once again talking about crisis in a moment when there is a real crisis.

47
00:08:30,000 --> 00:08:37,830
I don't know how much you guys have followed the news, but yesterday they were two different universities in this country,

48
00:08:38,190 --> 00:08:44,880
which had major deaths of students, one at a shooting incident at the University of Virginia and one in eight.

49
00:08:44,970 --> 00:08:52,310
I don't even think they know what had happened with four students at the University of Georgia.

50
00:08:52,680 --> 00:08:58,590
Yeah, that's what I've been hearing enough on the news reports, but I don't think anybody really knows what's what what it is.

51
00:09:01,170 --> 00:09:04,260
But either way, we're on a university campus.

52
00:09:05,010 --> 00:09:10,800
We are students. There is an element of crisis component to this moment.

53
00:09:11,760 --> 00:09:18,540
And so part of what I want you guys to think about today is, you know what?

54
00:09:18,540 --> 00:09:23,420
You know, nothing has happened here at the moment that.

55
00:09:24,380 --> 00:09:34,070
But it could. And imagine that, you know, those college campuses, how would that play out?

56
00:09:36,740 --> 00:09:39,740
What would you expect to learn?

57
00:09:39,920 --> 00:09:44,450
When would you learn and how would you expect to learn it? What would you be feeling like?

58
00:09:44,470 --> 00:09:49,850
Let's unpack those kinds of reactions, because that's what this is about.

59
00:09:51,020 --> 00:09:55,900
It's being ready to respond to those kinds of moments. For example.

60
00:09:57,780 --> 00:10:02,670
Because they did not know where the shooter was initially.

61
00:10:03,570 --> 00:10:12,300
Virginia was under lockdown for something like 12 hours. If that were to happen here, how would you expect to know that?

62
00:10:15,030 --> 00:10:18,299
We have something, I would hope, on the University of Michigan alert system,

63
00:10:18,300 --> 00:10:24,180
which I've signed up for, and stuff on your email, get stuff on your telephone, your phones, etc.

64
00:10:26,490 --> 00:10:32,090
How much detail would you expect to get from that? And if you could give everything from.

65
00:10:33,600 --> 00:10:39,690
We have a lockdown period. End of conversation to details about what they knew.

66
00:10:41,040 --> 00:10:47,580
Speculation about what they thought might be the case. So this is where the speculation versus not speculation thing comes into play.

67
00:10:47,610 --> 00:10:52,170
Real quickly. You just fill it up?

68
00:10:52,230 --> 00:10:57,969
What would you want? That kind of a situation where to have yeah that's kind of breaking it apart like

69
00:10:57,970 --> 00:11:02,310
an active versus like a after the fact situation or like an active situation.

70
00:11:02,320 --> 00:11:05,650
Definitely. You want a there's something happening.

71
00:11:05,800 --> 00:11:08,230
What kind of matters is a fire or an active shooter?

72
00:11:08,720 --> 00:11:14,230
I kind of just want to region, I would say I mean, it's depends on the size of your university, but I mean,

73
00:11:14,620 --> 00:11:21,260
I'd say we're big enough so you can tell like, oh, it's North Campus or it's like maybe the east part of campus or, you know, so like kind of rock.

74
00:11:21,280 --> 00:11:27,370
So a sense of is this, yeah, you know, when you have a campus is large both in terms of number of people and physical environment.

75
00:11:27,370 --> 00:11:31,780
Is this, you know, something that's happening several miles away might still be on campus.

76
00:11:32,380 --> 00:11:38,770
So location does have some relevance to determining, oh, is this a I need to change what I'm doing right now?

77
00:11:38,770 --> 00:11:42,700
Or this is like, hey, maybe I should head that direction right now kind of situation.

78
00:11:44,300 --> 00:11:51,230
What else. So the active and I don't want to use the phrase an active shooter to capture that as the only thing.

79
00:11:51,230 --> 00:11:57,360
But the idea of is it happening now versus it has happened and I need to be aware of it distinctly.

80
00:11:57,370 --> 00:12:05,959
You, I think is really important. Yeah. When I was an undergrad, we had like a lockdown because there was supposedly an active shooter.

81
00:12:05,960 --> 00:12:11,150
And so we were getting all the text message alerts and there was a lot of speculation.

82
00:12:11,450 --> 00:12:14,720
And I think that was like the worst thing that could have happened.

83
00:12:14,750 --> 00:12:18,409
Like they kept saying, like, there's shots fired in this building and all this stuff.

84
00:12:18,410 --> 00:12:20,810
And then like when everything came to be two days later,

85
00:12:21,080 --> 00:12:27,770
it was like a small team at the best dispute that happened on campus and like, nothing was related to, like what they said.

86
00:12:28,100 --> 00:12:31,579
And like, it just led to like a ton of fear of everybody.

87
00:12:31,580 --> 00:12:38,000
Like, so I think sometimes that like speculation can be especially in like a really heightened situation like that,

88
00:12:38,000 --> 00:12:41,360
like it creates a lot of fear and like that's counterproductive.

89
00:12:42,050 --> 00:12:51,880
So we play the counterfactual here. Let's imagine they hadn't said anything about shooting and instead it had turned out to be a shooting incident.

90
00:12:54,110 --> 00:12:59,240
How would you then feel like? The problem here is that in a space of uncertainty, you don't know what's true.

91
00:12:59,750 --> 00:13:03,409
They don't know it's true. And the question here becomes which which?

92
00:13:03,410 --> 00:13:07,190
And basically what Sandman's raising is the question of which side do we want to error?

93
00:13:07,670 --> 00:13:13,810
Do we want to err on the side of speculating, potentially overstating what's going to happen versus not?

94
00:13:14,480 --> 00:13:22,070
Yeah, I'm not necessarily saying salmon's always right, but this is the dilemma that he's trying to raise because as you know, the end product was.

95
00:13:23,890 --> 00:13:27,280
Some degree of loss of trust. We knew it wasn't what was actually.

96
00:13:27,580 --> 00:13:31,600
You know, you found out that what actually occurred was a much smaller and much less important thing.

97
00:13:32,830 --> 00:13:35,920
Antimatter balancing isn't an important thing, to be clear about that.

98
00:13:36,940 --> 00:13:43,040
But it isn't a mass shooting event. But the flip side is also would be good.

99
00:13:43,440 --> 00:13:50,070
Yeah, I guess my point to that is like I think there's like a role in speculating, but I think like they took it way too far.

100
00:13:50,090 --> 00:13:53,540
I think that's like a tendency for people who are like there's one thing to say,

101
00:13:53,540 --> 00:13:59,449
like active shooter beyond lockdown and then like telling people that there's like shots fired in buildings,

102
00:13:59,450 --> 00:14:02,720
like when there's no confirmation of that. Like, that was very traumatizing.

103
00:14:03,520 --> 00:14:10,950
One second. I want to I want to say one more time, do you remember the exact wording that was used when this draft?

104
00:14:11,240 --> 00:14:18,260
Was it there is an active shooter? Is it was it there are reports of an active shooter.

105
00:14:18,740 --> 00:14:22,040
Was it we believe there may be an active shooter.

106
00:14:23,000 --> 00:14:25,760
Those three statements are not the same thing.

107
00:14:26,510 --> 00:14:35,659
Yeah, I think the university said that they had confirmed an active shooter and that they had said reports of shots being fired in these buildings.

108
00:14:35,660 --> 00:14:42,080
So slightly different. But but I wanted to raise this because this is a really critical distinction.

109
00:14:42,080 --> 00:14:50,840
Like if you speculate, your choice matters because if you say this is true and it's not that one very bad outcome.

110
00:14:50,840 --> 00:14:59,899
But if you say we at at the moment what we believe is X, do you leave the door open that you're wrong and they may not have done that?

111
00:14:59,900 --> 00:15:06,500
And that's a problem in this kind of a time. I was going to argue kind of what you were making the counterfactual of, like,

112
00:15:07,130 --> 00:15:16,459
it's actually better to be wrong most of the time because people are going to overreact and that's going to limit the math of maximum possible damage.

113
00:15:16,460 --> 00:15:23,480
Whereas if you didn't take overreaction, the worst possible case is you knew and you didn't do anything.

114
00:15:23,750 --> 00:15:30,080
And that's going to be so incredibly damaging that it's worth saying overprotective every single time.

115
00:15:30,350 --> 00:15:36,800
And that might have little that little hint that you're going to take to prevent the VC hit is is a better,

116
00:15:37,580 --> 00:15:44,660
strictly speaking, trade off in the long run. So yeah, I'm going to be annoyingly pushing back on everybody's perspective today.

117
00:15:47,160 --> 00:15:58,110
There is the boy who cried wolf problems. Everything becomes big if everything is massively overstated in people work.

118
00:15:59,670 --> 00:16:11,040
And that is its own form of problem. So I at least have some degree of hesitation about saying always, you know, go big, even if there's,

119
00:16:11,250 --> 00:16:16,980
you know, basically always frame things in terms of the worst possible speculation because of that risk.

120
00:16:17,370 --> 00:16:23,790
But I also very much go to the you know, you don't want to frame an event.

121
00:16:25,780 --> 00:16:32,970
And artificially turn it into something which it is not just because you don't know.

122
00:16:33,900 --> 00:16:41,250
Which is why one of the key things I'm trying to emphasize here is there is what is the way you're portraying an event?

123
00:16:41,700 --> 00:16:46,050
Is this an active shooter or an event? Is this. We've heard noises that sounded like shots, etc.

124
00:16:46,650 --> 00:16:56,030
And then there is the certainty or hesitation language on the issue.

125
00:16:56,850 --> 00:17:00,570
And one of the things that Sam makes a huge point about it really is.

126
00:17:01,690 --> 00:17:08,160
Never say you're certain about stuff, so you're hopeful. You can be hopeful all you want.

127
00:17:08,640 --> 00:17:12,480
We can be hopeful that COVID would go away in two weeks. Didn't happen.

128
00:17:12,870 --> 00:17:19,310
But I can hope for that. We can hope that these reports are wrong, that there is a shooting of that.

129
00:17:19,320 --> 00:17:26,630
But that's what we're hearing right now. That's a different kind of thing than saying there is.

130
00:17:30,100 --> 00:17:36,970
Now my question. So for example, when you send out a text alert that we believe there's an active shooter.

131
00:17:38,490 --> 00:17:45,370
Different people are different. How would you know so?

132
00:17:46,990 --> 00:17:50,650
The problem here is you don't know the truth.

133
00:17:51,550 --> 00:17:57,430
You can't change that in a crisis. We do not know what the truth is.

134
00:17:59,110 --> 00:18:01,900
So the question becomes, what is our goal in that moment?

135
00:18:02,350 --> 00:18:10,780
If our goal is do not approach this space because we believe there is something happening at this location on campus.

136
00:18:11,830 --> 00:18:16,420
That you can be as explicit about that as you want to be like. There's no problem about that.

137
00:18:16,420 --> 00:18:20,050
You could be right or wrong, but that's what your instruction is to the community.

138
00:18:22,540 --> 00:18:33,160
If. And this is where there's a tension between reporting what happens and instructing people about what to do about it.

139
00:18:37,290 --> 00:18:46,310
If what you know is. You are hearing reports of something occurring that was just reported.

140
00:18:49,600 --> 00:19:03,080
And that's. Somebody wrote about a something that happened, not a few of them that had a campus where there was sort of an overlap.

141
00:19:03,230 --> 00:19:06,920
One round and then another event happened. So people as you.

142
00:19:07,170 --> 00:19:10,130
Yes. Tell what you were talking about because this is relevant to this question.

143
00:19:11,060 --> 00:19:21,200
So the first event that happened, it was very final there was walking across campus carrying what was perceived to be a pressure cooker.

144
00:19:21,830 --> 00:19:24,950
And so people thought that it was like a pressure cooker bombs.

145
00:19:25,640 --> 00:19:29,390
So the university was sending out really neat text messages.

146
00:19:29,390 --> 00:19:32,990
So I was actually getting all the information through GroupMe and text.

147
00:19:33,050 --> 00:19:39,210
And obviously Snapchat was the way to go because I was like traced to where the person was going through campus,

148
00:19:39,350 --> 00:19:42,320
people updating when they saw this person walking through.

149
00:19:42,740 --> 00:19:51,510
So if you were to avoid it ended up being that the student had a rice cooker and literally was just making rice for trials in the library.

150
00:19:51,530 --> 00:19:58,610
So we only got word from the university after the police arrived on the scene and everything was fine.

151
00:19:59,450 --> 00:20:02,870
So then people were very upset that they didn't know from the university.

152
00:20:03,980 --> 00:20:07,610
So then another incident happened where there was a bear on campus.

153
00:20:08,630 --> 00:20:15,290
And so the university said, Hey, there's a bear on this area of campus going towards downtown with area.

154
00:20:15,290 --> 00:20:18,310
But instead students thought that was like school thing.

155
00:20:18,320 --> 00:20:27,030
So they started going towards the bear as like were getting like donuts and throwing, throwing up at the bear and like went towards the ninja.

156
00:20:27,050 --> 00:20:34,310
So then there it was like loose. So the reason why I wanted to make sure to bring up that story is this.

157
00:20:35,680 --> 00:20:38,980
This question of when you share information about what is occurring.

158
00:20:40,220 --> 00:20:43,850
People may behave towards it in ways that were not aligned with what you wanted.

159
00:20:43,870 --> 00:20:46,880
Like even if they were saying, don't go towards the bear.

160
00:20:47,660 --> 00:20:51,510
What happened to people went towards the bear. If I. Exactly a smart idea.

161
00:20:53,870 --> 00:21:00,330
And similarly, especially when you face situations with lots of uncertainty depending upon how it is framed.

162
00:21:00,740 --> 00:21:06,730
There may be some people who will believe, Oh, wait, I need to find out more about this.

163
00:21:06,740 --> 00:21:09,860
Let's go, let's go. Look, let's see, etc.

164
00:21:11,930 --> 00:21:16,370
Now, I think that's less likely if the event we're talking about is an active shooter.

165
00:21:16,700 --> 00:21:21,229
But I certainly think that there are plenty of other kinds of crisis events where,

166
00:21:21,230 --> 00:21:25,220
depending upon how it's framed, somebody might go, Oh, wait, let's go see what's happening.

167
00:21:25,670 --> 00:21:32,470
And then that might actually be a danger. So one of the key principles here is.

168
00:21:33,710 --> 00:21:37,490
Are you giving people clear guidance as to what you believe they should be doing?

169
00:21:40,070 --> 00:21:48,950
If you're in a physical threat, that might be. Yourself down, putting in it place or evacuating a building or avoiding a particular location.

170
00:21:49,850 --> 00:21:54,710
We're talking about a health threat. We're talking about.

171
00:21:56,430 --> 00:21:59,980
Should you be going someplace or when should you not be going someplace?

172
00:22:00,000 --> 00:22:04,380
How should you be taking care of yourself? What should you be doing, etc.?

173
00:22:05,070 --> 00:22:11,100
And those action steps are a key piece of this response.

174
00:22:11,100 --> 00:22:14,100
If you don't know what to do, then people may go, Well, okay,

175
00:22:14,640 --> 00:22:19,020
maybe I should be not going to work when that's not actually what the recommendation would be, etc.

176
00:22:23,940 --> 00:22:26,640
But again, I want to reiterate something I said at the beginning.

177
00:22:27,120 --> 00:22:31,700
There's a big difference between saying this is what you should do and giving people a.

178
00:22:33,390 --> 00:22:44,210
History lesson of everything you know about that situation. Instructions does not equal fully informing people of everything about that situation.

179
00:22:45,470 --> 00:22:51,680
Instructions are instructions and being clear about why you're asking people to do that is also really good.

180
00:22:52,040 --> 00:22:55,909
Like just telling people, Hey, you should do this is different than say, Hey,

181
00:22:55,910 --> 00:23:02,180
you should do this because bears tend to go towards people with food and that might be really threatening type of thing.

182
00:23:04,020 --> 00:23:07,580
Which honestly we talk about wild animals.

183
00:23:07,590 --> 00:23:15,780
I've been fascinated by the ongoing saga of people getting hurt by bison in Yellowstone

184
00:23:17,220 --> 00:23:24,870
because they go to get selfies with the bison and then get trampled on or hit or etc.

185
00:23:24,870 --> 00:23:32,940
And this is happens on an ongoing like every year there's cases of this and it's another one of these things where you could say,

186
00:23:33,090 --> 00:23:36,239
don't approach the bison and people don't necessarily listen,

187
00:23:36,240 --> 00:23:42,990
but if you say don't approach the bison because if you get close to them, they tend to charge you, maybe they'll be more likely to listen to that.

188
00:23:43,800 --> 00:23:50,520
Probably not. But. But we can try. So.

189
00:23:54,660 --> 00:24:03,120
I started. I asked you guys to read this more recent article about over communication related to COVID.

190
00:24:03,630 --> 00:24:06,690
Today is one of these days where we can't completely dump COVID to the end of this

191
00:24:06,690 --> 00:24:10,830
course because COVID is so woven into our discussions of crisis communication.

192
00:24:11,550 --> 00:24:19,800
I do want to first tick off a couple of things from that article and then touch base with like four or five of you talked about specific

193
00:24:19,800 --> 00:24:27,570
aspects of how COVID unfolded for you and how there was crisis communications that either worked well or poorly related to that.

194
00:24:28,440 --> 00:24:32,490
I've noticed that if we put these two readings together.

195
00:24:34,300 --> 00:24:44,980
What are some of the stand and principles that this idea of over communication embodies is at least a few of those that seem to align with that.

196
00:24:47,300 --> 00:24:53,030
Yeah. I mean, I'd say one or two kind of secrecy and speculation versus refusal to speculate.

197
00:24:53,030 --> 00:25:00,020
So he's encouraging speculation and encouraging speculation by encouraging really talking about what might happen.

198
00:25:01,040 --> 00:25:04,670
What else? There's one or two more I can think of.

199
00:25:08,110 --> 00:25:13,500
I believe that being the warming versus being reassuring. Yeah. So there's definitely an alarming component to this.

200
00:25:15,770 --> 00:25:20,120
Especially in the sense of, like, planning for apathy. Like, that is a good thing.

201
00:25:20,130 --> 00:25:22,850
We're going to give you more information because we're going to assume you're not going

202
00:25:22,850 --> 00:25:26,720
to necessarily engage with this unless we really push some other information out.

203
00:25:33,340 --> 00:25:40,170
That's an example where the concern was, we're not going to take this seriously enough.

204
00:25:40,180 --> 00:25:47,530
We're not going to be. Engaged with all of the actions that we could potentially take to limit the threat of climate.

205
00:25:49,970 --> 00:25:56,210
But notice the tension between. Decentralization and decentralization.

206
00:26:00,250 --> 00:26:03,880
COVID starts it. Everything has to come from one place.

207
00:26:06,130 --> 00:26:10,450
We've talked about how universities are not exactly the speediest people to communicate about anything.

208
00:26:11,650 --> 00:26:18,730
So this played out like we saw this happen in the context of COVID on multiple fronts.

209
00:26:20,380 --> 00:26:24,330
One of our. Yeah.

210
00:26:24,430 --> 00:26:29,110
You were talking about the beginning of the quarantining and the way in which that played out.

211
00:26:29,410 --> 00:26:35,590
I mean, there were faults in terms of what was physically done and let's put those aside, but really focus on the communication piece.

212
00:26:35,740 --> 00:26:44,379
Yeah. So I started grad school in fall 2020 and so that was like the first return to emphasis during the pandemic.

213
00:26:44,380 --> 00:26:50,740
And the school had sort of set up this quarantine zone for students who tested positive.

214
00:26:50,740 --> 00:26:56,670
And I don't know. I mean, probably some people remember this, but there were tiktoks that were posted where students were saying like,

215
00:26:56,710 --> 00:27:04,720
there's cockroaches in this apartment, like some food here or bedding. Supportive housing is terrible and put together like not in a healthy way.

216
00:27:05,140 --> 00:27:13,360
And in response to that stuff going viral, the university basically was just completely denying everything that was happening like and sort of,

217
00:27:13,620 --> 00:27:16,420
you know, acknowledging what had happened and apologizing. They just were like.

218
00:27:17,430 --> 00:27:23,430
Students are provided with supplies and just kept kind of coming from this very professional cold place.

219
00:27:23,880 --> 00:27:28,260
And this was also during the strike and everything. And so there was just a lot of distrust.

220
00:27:29,460 --> 00:27:33,270
The we did backwards because of how poorly they were responding to that.

221
00:27:33,690 --> 00:27:42,020
Yeah. I mean, I remember in particular in the sense that it's I'm reading between the lines here,

222
00:27:42,030 --> 00:27:49,500
I don't know what actually happened, but what I had the sense of the higher ups didn't believe the reports.

223
00:27:50,310 --> 00:27:53,100
And so they were like, well, we provide supplies, we do this.

224
00:27:53,530 --> 00:27:57,090
And the people who actually knew that they were true were not actually empowered to say anything.

225
00:27:59,070 --> 00:28:06,600
And so that mismatch between the levels of hierarchy meant that the response was, as you describe it, very sort of like, well, this is what we do.

226
00:28:06,600 --> 00:28:13,860
We provide this, we provide that. And it took a long time before sort of acknowledgment of problems filtered into the communications.

227
00:28:14,610 --> 00:28:22,740
And and there was a tone of, yes, this is not okay and we're going to try to fix it in whatever way they can.

228
00:28:22,770 --> 00:28:25,210
That's putting aside the question of why did that happen in the first place.

229
00:28:26,610 --> 00:28:35,540
I mean, crisis responses are rarely clean and nice, but whether you're talking about an evacuation,

230
00:28:35,550 --> 00:28:40,410
whether you're talking about quarantining, etc., like there's always physical problems and manage a crisis context.

231
00:28:40,790 --> 00:28:44,010
The question I want to raise, though, is when that's going to be the case.

232
00:28:44,370 --> 00:28:48,030
Things are not going to be okay. How do you talk about it?

233
00:28:48,040 --> 00:28:56,550
How do you deal with that, etc.? And the contrast that several of you raise the Tylenol case like imagine had the university said,

234
00:28:56,940 --> 00:29:02,309
you're right, this is completely unacceptable, we absolutely need to do this is going to be really hard.

235
00:29:02,310 --> 00:29:04,680
I don't know if we're going to be able to do X, Y and Z.

236
00:29:05,160 --> 00:29:10,380
You know, we're all struggling with whatever is going on, but here's what we're going to try to achieve.

237
00:29:10,920 --> 00:29:14,940
It would have felt a lot to get noticed.

238
00:29:15,030 --> 00:29:20,820
It's not. Just what the truth of the situation is.

239
00:29:21,210 --> 00:29:28,680
It's acknowledging the emotions students are feeling, the feeling of wrongness, etc., and depressing that feeling.

240
00:29:28,680 --> 00:29:32,250
Because if you didn't address that feeling, you're not actually speaking to the person in that moment as far.

241
00:29:38,310 --> 00:29:43,040
Related to that, you were talking about similar kinds of stuff.

242
00:29:44,100 --> 00:29:50,010
When do universities admit things aren't going well? I'm trying to remember the specific details you were talking about in your music.

243
00:29:53,750 --> 00:30:05,870
Yeah. So basically I was talking about just like like you're talking about like a graduate

244
00:30:05,870 --> 00:30:12,770
student employees and like how the university kind of caters their message to.

245
00:30:14,270 --> 00:30:20,900
The graduate students versus the undergrads. And just how like especially like during the strikes and everything,

246
00:30:21,860 --> 00:30:27,500
when conditions like working conditions were bad and it was like a health safety and they weren't like,

247
00:30:27,830 --> 00:30:32,930
you know, like how does an institution that like relies on like.

248
00:30:33,950 --> 00:30:37,220
Profiting off of students and exploiting them to some extent.

249
00:30:37,250 --> 00:30:46,060
How do they admit to these mistakes? There is this hierarchy, especially in a time of crisis, when safety is like keeping that standard of care.

250
00:30:46,070 --> 00:30:55,490
It's like what's most important. So I want to take the specific example you're taking for free up here and expand it even a little bit larger.

251
00:30:55,490 --> 00:30:58,100
Because while you can certainly talk about this in the context of students,

252
00:30:58,820 --> 00:31:05,330
there were similar layers of conversation about the faculty around who was expected to be onsite teaching,

253
00:31:05,330 --> 00:31:13,250
who was allowed to teach remotely, under what circumstances people could make choices about their workplace and how all of them,

254
00:31:13,580 --> 00:31:18,760
at every level of the institutions there were questions of. Values.

255
00:31:20,070 --> 00:31:26,970
In the sense that there were real trade offs. But as a university, we value having classes.

256
00:31:27,150 --> 00:31:30,300
We value the fact that there are benefits to being in person.

257
00:31:30,690 --> 00:31:35,700
We value public safety. We value people not getting to see those values.

258
00:31:35,700 --> 00:31:38,940
God directly in conflict are many, many layers.

259
00:31:43,200 --> 00:31:51,540
And so the question you raised, which is really important, is, okay, so you're in a moment where it is not obvious what to do.

260
00:31:51,540 --> 00:31:54,239
Like some people, no matter almost no matter what you choose,

261
00:31:54,240 --> 00:32:00,240
some people are probably going to be better off and happier and other people are going to be less well-off and worse.

262
00:32:02,080 --> 00:32:06,130
And that's the reality of the situation. So now what?

263
00:32:06,760 --> 00:32:08,380
How do you talk about that?

264
00:32:09,250 --> 00:32:18,730
And one of the things I really appreciate about that sentence perspective is that one of his dilemmas is around this idea of sharing the dilemmas.

265
00:32:20,740 --> 00:32:27,550
Only when there is a trade off is that the left isn't necessarily the right choice.

266
00:32:28,640 --> 00:32:34,250
But in those moments, I want the university or another institution to say things like, Look.

267
00:32:36,120 --> 00:32:42,000
We all value coming together to teach our classes, being a community together.

268
00:32:42,030 --> 00:32:45,870
We also all value limiting exposure.

269
00:32:46,320 --> 00:32:53,670
We also value having people being able to have different situations when they may be facing particular health risks.

270
00:32:53,820 --> 00:33:00,810
Again, it's a broad forum. We're talking about everything from kids to older adults to compromised people or whatever,

271
00:33:02,670 --> 00:33:07,950
and then be able to say the thing which almost, almost never gets said, which is that these things are in conflict.

272
00:33:08,280 --> 00:33:11,310
We can't actually do all of these things equally, but.

273
00:33:15,660 --> 00:33:21,150
Stanley's argument, I tend to believe it is that even if.

274
00:33:23,090 --> 00:33:28,819
Policy or instructions are not what you want, even if you are the person in some sense being harmed.

275
00:33:28,820 --> 00:33:36,520
But if you were here that the issue was actually raised easier for you to accept,

276
00:33:36,770 --> 00:33:40,700
then if it feels like it was just enclosed with no knowledge of what was going to happen to you.

277
00:33:42,480 --> 00:33:49,310
So if and I will take my personal story, which is a minuscule piece of this, but like at the moment when.

278
00:33:51,260 --> 00:33:58,160
You then said to the faculty, you know. Here is what we will allow you to choose.

279
00:33:58,210 --> 00:34:06,670
Here is what we will not allow you to choose in terms of your teaching. I was able to then step back from that and say, okay.

280
00:34:08,430 --> 00:34:14,040
I know you're at least trying to wrestle with this and you're trying to figure out what the right balance is for each of us.

281
00:34:14,640 --> 00:34:21,510
And if the answer is that I need to be one of the people who comes into class, even though that might put me at risk,

282
00:34:21,510 --> 00:34:27,120
and even though I have parents who are in their 80 is and if they got COVID before they were vaccinated, that was going to be a really bad thing.

283
00:34:28,980 --> 00:34:34,400
I can at least hear some degree of empathy to my dilemma in your consideration of this beloved.

284
00:34:37,530 --> 00:34:41,200
But often what happens, happens, right, is that people don't share that.

285
00:34:41,230 --> 00:34:44,390
They just simply say. Here's what we're going to do.

286
00:34:45,490 --> 00:34:48,010
I don't hear why I don't hear that dilemma coming.

287
00:34:49,290 --> 00:35:02,790
So on Thursday, I'm going to have you play the play for you guys, a recording of a press briefing from the CDC back in 2009.

288
00:35:04,360 --> 00:35:09,910
Oklahoma influenza. And one of the things that I want you to pick up when you hear that recording

289
00:35:10,690 --> 00:35:16,210
is the way in which the CDC director specifically talks about the levels.

290
00:35:17,590 --> 00:35:20,680
He will raise. We could have done this. We could have done this.

291
00:35:20,680 --> 00:35:23,589
But we felt that the only right choice was to go ahead and do this,

292
00:35:23,590 --> 00:35:31,090
even though etc. really explicitly bringing the dilemma that they faced in their choice into the communication.

293
00:35:32,320 --> 00:35:36,610
Which we don't always do. That's why I've kept that one. Is a really nice example.

294
00:35:45,440 --> 00:35:53,300
Some more while we're talking about COVID. Emily, we were talking about your experience in contract tracing.

295
00:35:54,680 --> 00:36:01,310
All right. So I was a contact tracer for the L.A. County Department of Public Health in New York.

296
00:36:01,790 --> 00:36:08,030
And so we were given these really long, like, scripts to say, like throughout our interview while we were collecting information.

297
00:36:08,690 --> 00:36:13,730
And at the end, you would say, like, oh, like, do you have any. Sorry.

298
00:36:13,910 --> 00:36:18,890
And so I remember getting asked a couple of questions like, Oh, do you believe COVID is real?

299
00:36:19,510 --> 00:36:25,989
I like questions like, Oh, one particular person was like, Oh, I don't see the bodies coming out of the hospital.

300
00:36:25,990 --> 00:36:31,760
Like, Do you think it's fear? And like, as someone who's not like a medical professional or a government official,

301
00:36:31,760 --> 00:36:37,700
I didn't want to say the wrong information, but at the same time, I didn't want them to think, Oh yeah, like it's not real.

302
00:36:38,000 --> 00:36:40,940
I feel like the whole interview process that we went through.

303
00:36:41,600 --> 00:36:47,419
So there is just moments where like it's just like having to go through that long interview because you're asking a lot of questions.

304
00:36:47,420 --> 00:36:50,750
You're asking where they are and who they've been in contact with, what are their symptoms.

305
00:36:51,230 --> 00:36:54,890
And sometimes, like, they don't even know how to describe their symptoms or what to say.

306
00:36:54,900 --> 00:36:59,960
So like trying to be empathetic, but also like having to do your job.

307
00:37:00,130 --> 00:37:03,650
Yep. Just something that I thought about a lot. Or reading the principles.

308
00:37:05,170 --> 00:37:07,360
So I have two things I want to say as positive.

309
00:37:07,420 --> 00:37:18,280
One was, I noticed that part of your challenge is that you can't equip somebody with every possible response that you would need.

310
00:37:18,850 --> 00:37:23,530
You were given volumes of scripts, lots of detailed responses to the common question.

311
00:37:23,950 --> 00:37:30,940
You still had to respond in the moment to certain types of things that weren't anticipated because you can't plan for everything.

312
00:37:31,960 --> 00:37:42,400
You have to be able to have that adaptability to some degree, which is why it's different to write a speech where you get to say exactly what you say,

313
00:37:42,610 --> 00:37:47,350
and that's it, versus to do a Q&A where you have to have that dynamic.

314
00:37:47,500 --> 00:37:50,650
You have to be able to respond in the moment, no matter what it is that gets thrown at you.

315
00:37:52,570 --> 00:37:56,230
The other thing is I want to share something with you guys. I don't think I've talked about it in this class.

316
00:37:58,600 --> 00:38:02,710
One of the harder skills, but I think one of the more important skills is this.

317
00:38:04,270 --> 00:38:08,110
Communicate in the moment. Respond to the thing that you didn't anticipate.

318
00:38:09,860 --> 00:38:13,970
It's why I practice improv.

319
00:38:15,140 --> 00:38:23,900
That specific skill is why I do improv. And I think it was a month ago, maybe two months ago,

320
00:38:24,590 --> 00:38:31,370
there was an article published in the in JAMA of the American Medical Association about a improv

321
00:38:31,550 --> 00:38:40,430
based training approach to help community health workers respond in the moment to vaccine hesitancy.

322
00:38:42,360 --> 00:38:51,299
How much that they take is basically to have a script that dynamic, much like what Emily is talking about here,

323
00:38:51,300 --> 00:38:57,060
like a very specific look, I'm going to give you some information and then there's a scripted response, etc.

324
00:38:57,930 --> 00:39:02,190
But at any point, the workers can basically interrupt the scene.

325
00:39:03,090 --> 00:39:09,100
And literally step into playing. The person in your role,

326
00:39:09,100 --> 00:39:16,130
the person who's trying to respond to these community people's questions and basically trying out over and over again in different ways.

327
00:39:16,150 --> 00:39:19,630
Well, what if I said it this way? Well, what if I responded to? Is it real with.

328
00:39:20,200 --> 00:39:25,870
Yes, it's definitely real. But if I responded to it differently to give them essentially a practice environment,

329
00:39:26,920 --> 00:39:31,780
then they get to learn how to respond to things that they wouldn't otherwise have in their script.

330
00:39:34,930 --> 00:39:37,770
It's a skill. I don't know how to describe it.

331
00:39:38,020 --> 00:39:43,450
One of the dangers in these kinds of situations is that people fall back to I can only tell you what's in my script,

332
00:39:45,400 --> 00:39:49,360
and that's just as much of a trust busting kind of experience as anything else.

333
00:39:49,360 --> 00:39:54,460
Because then I can tell you are reading from the script and not actually being human.

334
00:39:54,810 --> 00:40:00,459
It's not actually responding to me in that moment. So part of what we have to think about when we're thinking about crises,

335
00:40:00,460 --> 00:40:05,110
especially when we get out of sort of one too many communications but 1 to 1 communication.

336
00:40:06,360 --> 00:40:11,340
It's how do we build that confidence to be able to respond in those moments?

337
00:40:11,960 --> 00:40:16,800
That's actually to give you the skill you needed in those calls because you were going to get it no matter what.

338
00:40:16,890 --> 00:40:20,220
What happened? Yeah.

339
00:40:22,140 --> 00:40:28,740
So I just kind of want to promote like one of the talks about in the article,

340
00:40:29,250 --> 00:40:34,350
what's the democracy of individual control versus like expert decision making?

341
00:40:34,380 --> 00:40:40,950
Yeah. So especially like going back to like COVID response in colleges and in general,

342
00:40:40,950 --> 00:40:52,700
like when you have an audience that might make like counterintuitive health your decisions, how do you kind of like balance that out?

343
00:40:52,830 --> 00:41:02,490
Because like democracy, to what extent like do you do you consider every opinion and factor that in or like because I like,

344
00:41:02,940 --> 00:41:07,650
I think the whole thing where like you're being very transparent about the decision making makes sense.

345
00:41:08,220 --> 00:41:12,450
But I guess like in those more difficult situations where you have an audience that

346
00:41:12,450 --> 00:41:17,910
maybe is not as cooperative or they have like very counterintuitive instincts,

347
00:41:18,870 --> 00:41:23,670
how do you. Yeah, so first of all, let's just acknowledge this is hard.

348
00:41:24,540 --> 00:41:31,860
Like I can give you what how I would try to respond and how I think Sandman's principles can be embody.

349
00:41:32,130 --> 00:41:36,030
And you're going to say, Yeah, but that might not work, and I'm going to agree with you. It might not work.

350
00:41:36,030 --> 00:41:39,540
And in fact, it probably won't work. But that doesn't mean that we don't try the best we can.

351
00:41:41,790 --> 00:41:47,780
So one key principle I think is I think something I brought up.

352
00:41:50,070 --> 00:41:53,250
So people come to the same conclusions that you've already come to.

353
00:41:55,070 --> 00:42:02,870
Like if you have already come to the conclusion that, wow, and I'll just take mask wearing as an example,

354
00:42:02,870 --> 00:42:10,550
that wearing mask can't hurt and it might help and that the more that we do that, maybe that we can slow the spread of this disease down.

355
00:42:11,690 --> 00:42:17,749
Simply saying to people wear masks is not at all the same thing as saying to people what I just said.

356
00:42:17,750 --> 00:42:22,460
Like, you know, maybe it will help if you're worried about this.

357
00:42:23,270 --> 00:42:28,730
And but if it does, it has the possibility of doing this and this and here's why this might make sense, etc.

358
00:42:29,210 --> 00:42:37,130
So this is why we're going to encourage everybody to wear. Could somebody turn around and say, Yeah, I don't believe you?

359
00:42:37,130 --> 00:42:52,420
Of course I could. But the democratization in my mind is basically an approach that is about empowering individuals to act on their own interest,

360
00:42:53,200 --> 00:42:57,710
to help them when they understand. The truth of the situation.

361
00:42:58,250 --> 00:43:05,870
Most people, most of the time will make decisions that are reasonably rational in that context.

362
00:43:07,640 --> 00:43:11,060
Oh, it's I don't want to minimize that. But most of the time.

363
00:43:11,570 --> 00:43:19,400
And we. Where we break down is when we think that, oh, well, we can avoid those.

364
00:43:19,700 --> 00:43:26,029
The small fraction of problems of the people who want to do that by giving some really clear centralized messages.

365
00:43:26,030 --> 00:43:33,110
And we fail to understand how how often that breaks down because that teachers are too late or they're too restricted or whatever.

366
00:43:34,130 --> 00:43:43,940
That's my. Is that when you democratize the process, when you spread the information out, when you share the underlying reasoning,

367
00:43:43,940 --> 00:43:50,360
etc., you increase the chance that somebody is going to go, Oh, I guess that makes sense.

368
00:43:50,360 --> 00:43:53,450
So and then we're off and running in a productive direction.

369
00:43:55,100 --> 00:43:59,719
It's a great question. And I think the democratization idea is in some sense,

370
00:43:59,720 --> 00:44:13,430
one of the harder one example brings up for exactly the reasons you describe it, stepping a little bit out of the public space.

371
00:44:15,350 --> 00:44:20,270
I want to go back to you and talk about because you raised in your musing what happened with Fizzle.

372
00:44:20,660 --> 00:44:26,730
Yeah. So I was like talking about like this dilemma of like the transparency versus the process.

373
00:44:26,750 --> 00:44:30,690
I don't know exactly what he said, but yeah,

374
00:44:30,690 --> 00:44:36,110
I was thinking about like last year when the Regents found out about sexual misconduct with President Schlissel at

375
00:44:36,110 --> 00:44:43,729
the university and how they decided to remove and how they ended up releasing all of his emails as part of that,

376
00:44:43,730 --> 00:44:49,690
which I didn't really talk too much online using, which I think like some of the emails were definitely distracting from the issue.

377
00:44:49,700 --> 00:44:56,600
But I did think overall like the transparency was really refreshing from a university, I think from some of the conversations we had.

378
00:44:57,210 --> 00:44:59,450
Universities don't tend to be the most transparent,

379
00:44:59,720 --> 00:45:09,210
especially given University of Michigan history with sexual misconduct and sexual assault and hiding those types of ongoings on campus.

380
00:45:09,230 --> 00:45:11,450
So that's kind of what I talked about.

381
00:45:11,720 --> 00:45:21,740
What's so I mean, I think the thing from from certainly the contrast from the way previous issues had been managed was noticeable.

382
00:45:23,270 --> 00:45:32,870
The contrast that I want to set up here is, you know, had the emails not been released, what would we have thought?

383
00:45:33,140 --> 00:45:36,940
What would the experience have? Um. Yeah.

384
00:45:37,510 --> 00:45:41,570
Um, I was also here during that time, and I think, like, from the outside, like.

385
00:45:42,710 --> 00:45:49,310
From my other people's perspective, you don't go here. Yeah, it was more like I didn't understand that, but because I thought that went too.

386
00:45:49,730 --> 00:45:58,430
But from people who weren't here, it was more like I received kind of like a joke, like it did not come off well.

387
00:45:58,910 --> 00:46:06,920
And like they took it more of like a laughing matter. They like, made me make jokes and like, it wasn't as serious as it needed to be.

388
00:46:08,300 --> 00:46:15,590
So I was like 5050 and like people from the outside didn't go to school here, didn't take it very well.

389
00:46:15,590 --> 00:46:21,440
And they like disregarded conditions. And I'm glad you raised this because it reminds us that there are multiple lives here.

390
00:46:21,710 --> 00:46:28,670
Like the implication of those release of material was different for those of us within the university community who had previous.

391
00:46:28,670 --> 00:46:34,440
Especially those of us who had experienced previous. The experience is a misconduct in the way.

392
00:46:34,440 --> 00:46:37,820
The university has not been very transparent in terms of discussing notes.

393
00:46:38,970 --> 00:46:44,340
And it also has this sort of like why are they sharing this silly email kind of thing?

394
00:46:45,060 --> 00:46:53,220
The job component that you're describing. And honestly, had the university said, you know, we know that this is.

395
00:46:54,420 --> 00:46:57,899
Unusual to share these, but the interest of transparency, we're going to do so.

396
00:46:57,900 --> 00:47:02,490
That might have actually been a little bit better because then at least we can clear why they're bothering to do it.

397
00:47:03,300 --> 00:47:11,550
Yeah. Yeah. I was also here during what happened last year and I felt it was unnecessary.

398
00:47:11,610 --> 00:47:23,040
Like, I don't know, there's like a it was like a transparency for transparency sake, not transparency for like any actual, like, substantive reason.

399
00:47:23,370 --> 00:47:29,919
I think we would have all gotten like. The gist of what had happened if all of the emails weren't released.

400
00:47:29,920 --> 00:47:40,499
But instead of I don't know, at least like. I know the select group for my program, my my graduate program is like just making fun of everything.

401
00:47:40,500 --> 00:47:44,910
And it took away like the seriousness. It felt like it took away the seriousness of the situation.

402
00:47:45,000 --> 00:47:49,950
I wanted to raise this one because I think this is a good one where my personal perspective.

403
00:47:51,690 --> 00:48:04,290
Is somewhat conflicted. I, I see the value of transparency and I also see the joke and silliness component about what ended up being disclosed.

404
00:48:05,130 --> 00:48:09,690
I also know that, you know, you have the following set of alternatives.

405
00:48:10,080 --> 00:48:16,229
You can disclose nothing, you can disclose everything, you can disclose some things, but not other things.

406
00:48:16,230 --> 00:48:20,969
And then you have to ask the question, Well, who got to decide what's being disclosed and what's not being disclosed?

407
00:48:20,970 --> 00:48:28,290
And how how much trust do you have in that space? None of these positions are perfectly defensible.

408
00:48:28,920 --> 00:48:39,610
All of them have weaknesses. My point here and valid point is not that the right choice is always transparency.

409
00:48:40,540 --> 00:48:45,040
One can make a reasonably strong argument that too much was disclosed in that case.

410
00:48:47,490 --> 00:48:50,490
But Sam, it argues, is you ought to ask the question every time.

411
00:48:52,060 --> 00:48:55,300
You want to ask yourself, why am I not disclosing this?

412
00:48:57,100 --> 00:49:00,700
It's not that there's never an answer, but you always have to ask that question.

413
00:49:00,740 --> 00:49:08,500
Yeah. Just to play devil's advocate for a minute. If they had chosen not to disclose it, there's a legitimate possibility it would have gotten leaked,

414
00:49:08,500 --> 00:49:11,649
which is significantly worse than the organization itself.

415
00:49:11,650 --> 00:49:19,570
Just providing the info also true. So I think about like these meta and all the things that have happened there recently and like.

416
00:49:20,670 --> 00:49:25,049
They just they have been so much worse off because they didn't provide any

417
00:49:25,050 --> 00:49:28,440
info about what was going on and that information is going to get out anyway.

418
00:49:29,100 --> 00:49:32,140
So why wouldn't you just disclose it in the first place? Right.

419
00:49:32,190 --> 00:49:35,760
And this is the organizational dilemma that is at the heart of all of this.

420
00:49:35,940 --> 00:49:41,730
I'll go here and then you get to it from sort of a different dimension to disclosing it.

421
00:49:42,060 --> 00:49:45,070
Like it sort of separates the university from his actions.

422
00:49:45,870 --> 00:49:49,589
So it's like, just so you know, he had nothing to do with this. Look at his emails.

423
00:49:49,590 --> 00:49:55,160
It was his choice to do this with his own time and what a horrible person he's gone.

424
00:49:55,860 --> 00:50:00,240
Let's resume our reputation and that framing.

425
00:50:01,930 --> 00:50:08,500
Intentionally creates. A focus on the individual as opposed to the system.

426
00:50:10,060 --> 00:50:21,280
And in many contexts, there are a systematic factors that create or amplify crises that lead to them, etc., that, you know, this is marketing.

427
00:50:21,340 --> 00:50:21,940
Let's be honest.

428
00:50:21,940 --> 00:50:27,910
I mean, it is marketing from the university's perspective or from any organization's perspective, the way in which you handle these crises.

429
00:50:28,640 --> 00:50:32,080
What I want to make sure we get to is the what are the consequences of each pathway?

430
00:50:32,780 --> 00:50:36,429
Yeah. Yeah. As I say, just to your devil's advocate,

431
00:50:36,430 --> 00:50:44,160
that I don't think that there is necessarily an expectation under those circumstances that the emails have been released.

432
00:50:44,170 --> 00:50:50,440
So like even if they had somehow been hacked and released on itself, I don't think it would have been like a Oh my God,

433
00:50:50,440 --> 00:50:54,400
I can't believe the university didn't disclose these emails because I don't think they were like.

434
00:50:56,610 --> 00:50:57,599
I mean, they were damaging,

435
00:50:57,600 --> 00:51:04,469
but they weren't like incredibly damaging to show that the university was hiding something because like they were his personal because I mean,

436
00:51:04,470 --> 00:51:08,070
of course on the university server but it wasn't like it would have never I don't think would

437
00:51:08,070 --> 00:51:12,389
have been necessarily damaging to the university that they hadn't even ever thought of that.

438
00:51:12,390 --> 00:51:21,410
But I'll let you go first. I mean, are the emails like they're like or when they're public, like someone could request to access this?

439
00:51:21,540 --> 00:51:26,310
I thought they were just sort of the property of their university business.

440
00:51:26,430 --> 00:51:32,850
It's not even like leaking, like because they're public university emails, they're accessible.

441
00:51:32,980 --> 00:51:34,080
So I don't think they would,

442
00:51:34,350 --> 00:51:43,530
but I don't think someone publicly releasing them afterwards would have been like damaging to the university not to have shown them first.

443
00:51:43,860 --> 00:51:51,620
Yeah, I think there's like the conscious like time to like, I don't know how long like that's all like how long it was.

444
00:51:51,630 --> 00:51:55,260
I'd been going like, can't they like see what's going?

445
00:51:56,570 --> 00:52:00,450
Well, so we could go down this radical limit.

446
00:52:00,470 --> 00:52:08,720
I'm going to put a wrap on this covers this particular topic. But the reason I say this, the timing aspect, like you've had it for like like years.

447
00:52:09,260 --> 00:52:17,120
So the key question, of course, is there's a difference between is it possible for this to have been noticed versus is somebody actually

448
00:52:17,120 --> 00:52:23,419
paying attention and noticing this type of thing in lots of situations in which information may be available,

449
00:52:23,420 --> 00:52:26,480
but that doesn't necessarily guarantee that somebody knows that it exists.

450
00:52:27,560 --> 00:52:32,450
The last point I want to make, just to sort of close the loop, is the distinction that Ariel is bringing up as important.

451
00:52:37,200 --> 00:52:42,240
Each of us can take a look at those particular emails and make a judgment about.

452
00:52:43,300 --> 00:52:47,410
How much of a responsibility was there to disclose this piece of information?

453
00:52:52,080 --> 00:52:58,710
If. The answer is it's not that big of a deal.

454
00:52:59,580 --> 00:53:04,470
Then maybe that's a justification for not necessarily going down the path of disclosing.

455
00:53:06,110 --> 00:53:12,110
But let's notice that the danger here from the organization standpoint from trusting is not symmetrical.

456
00:53:13,760 --> 00:53:23,030
That give whatever this piece of information is, is something that you would feel outrage that it was not disclosed and is not disclosed.

457
00:53:23,300 --> 00:53:31,760
Then there is all kinds of consequences to that. If it turns out it is something you didn't really need to know that and it is disclosed.

458
00:53:32,270 --> 00:53:34,120
Salman's argument is, yeah.

459
00:53:34,130 --> 00:53:40,340
The amount of outrage you get in those kinds of situations is rarely at the same level as you would have on the other side.

460
00:53:40,820 --> 00:53:44,870
And so to think about that as we make these charges, yeah, last comment here.

461
00:53:45,290 --> 00:53:48,860
I think of it very similar to the Joe Paterno situation at Penn State.

462
00:53:49,020 --> 00:53:55,159
Yeah. There. The information was known and they did not disclose it,

463
00:53:55,160 --> 00:54:01,250
and it became infinitely worse for everyone involved because there was no disclosure of information.

464
00:54:01,730 --> 00:54:09,320
And those stories are the ones in many ways that crisis communication are most designed to prevent situations in which.

465
00:54:10,440 --> 00:54:17,010
Had disclosure occurred, the pathway of how everybody would have felt was radically different than what actually played out.

466
00:54:20,460 --> 00:54:24,910
Couple more examples. Just note that keep going on this idea.

467
00:54:27,460 --> 00:54:32,750
I got one big compensation I make sure we have. Luke,

468
00:54:33,700 --> 00:54:39,279
you were talking about the way in which pop manufacturers talk about health issues

469
00:54:39,280 --> 00:54:43,630
with their with their products and how this parallels to this for their interest.

470
00:54:43,840 --> 00:54:51,760
They got what it was last night. We have received reports that in this case, it wasn't actually specifically my insulin pump,

471
00:54:51,760 --> 00:54:59,430
but it was the device that used to send information to the company saying that we had received reports of this,

472
00:54:59,650 --> 00:55:08,979
that when charging that you have an overheating in the device caught on fire at the end, saying that very small amount of reports.

473
00:55:08,980 --> 00:55:16,840
But please be cautious. And we point this out in general that they sometimes are really early phone, even a small number.

474
00:55:17,200 --> 00:55:23,620
And subsequently when they know actually the numbers that are impacted in terms of the actual boxes,

475
00:55:23,620 --> 00:55:30,190
then you can get more specific and say, okay, this doesn't apply to me, but I still would rather happen to be sending it out very early.

476
00:55:30,200 --> 00:55:37,779
So, you know, to be cautious, even if in the end it's going to end up being something that was sold in another country.

477
00:55:37,780 --> 00:55:42,190
And it clearly has no impact. But better to know it's a possibility.

478
00:55:43,450 --> 00:55:47,200
I get mad afterwards about I didn't say anything and this did.

479
00:55:47,200 --> 00:55:54,850
In fact, we woke up in the middle of the night, this instant feeling, and needed to be in hospital.

480
00:55:55,000 --> 00:55:59,829
Yes. And you know, the reason why this is a nice contrast is I don't think at least I wouldn't

481
00:55:59,830 --> 00:56:04,180
think there's a lot of amount of argument about your device bursting in flames.

482
00:56:04,540 --> 00:56:08,990
Meeting the standard of this needs to be disclosed like that.

483
00:56:09,000 --> 00:56:16,180
That's that's clearly a threat at the level of why the heck didn't you tell me this becomes fairly straightforward.

484
00:56:18,560 --> 00:56:28,670
So where I want to go from here is thinking about how do we manifest this?

485
00:56:30,200 --> 00:56:34,730
How do we do this in practice? I guess this is about dilemmas.

486
00:56:35,810 --> 00:56:39,200
We can disagree about what the right choice would be in one situation versus another.

487
00:56:39,980 --> 00:56:46,430
Salmon's arguing. Hey, we ought to think about this stuff. We ought to strive to be more speculative, more humane, etc.

488
00:56:47,570 --> 00:56:52,430
Sydney, you raised the question I wanted to talk about towards the end of the day,

489
00:56:52,430 --> 00:56:58,310
which is, okay, so we're getting all of these advisors to do certain types of things.

490
00:56:59,290 --> 00:57:02,800
We're not necessarily all equal in our ability to do those things.

491
00:57:04,770 --> 00:57:09,930
Yeah. Um, yeah, I was sort of talking about how, like.

492
00:57:11,940 --> 00:57:19,030
The advice that we get may not be like what everyone is like given the same respect necessarily from like

493
00:57:19,050 --> 00:57:25,220
the audience and how that can impact how you might choose to deliver something or what you choose to say.

494
00:57:25,230 --> 00:57:34,500
And so specifically, um, I guess overall like thinking about taking into consideration like discrimination and biases and stigma that exist in

495
00:57:34,500 --> 00:57:42,750
our society and like the example of like professionalism versus being human was like the specific one I talked about.

496
00:57:44,550 --> 00:57:49,520
The chairman gave like specific examples of like three different women who

497
00:57:49,650 --> 00:57:53,850
are like acting government officials in like their responses and just sort of

498
00:57:53,850 --> 00:58:01,980
thinking about like why they may have felt might have felt like they needed to act more professional to like gain more respect to be present that way.

499
00:58:02,390 --> 00:58:07,200
Um, and it reminds me of like this interview I watched with Doris Burke, who is like,

500
00:58:07,500 --> 00:58:13,170
very distinguished and like famous, um, like sports analyst and announcer for like NBA games,

501
00:58:13,410 --> 00:58:21,479
like college basketball that announces like a lot of, like, men's basketball games and it's very like criticized compared to like male announcers.

502
00:58:21,480 --> 00:58:28,170
And she was kind of saying, you know, like, yeah, when I, ah, like when people are listening to a male announcer, they're just listening to the game.

503
00:58:28,170 --> 00:58:32,399
But when they're listening to me, they're like waiting for me to make a mistake, listening for an error.

504
00:58:32,400 --> 00:58:36,750
And so just like the scrutiny that she's like under just by, like, you know,

505
00:58:36,750 --> 00:58:43,050
her gender and like considering people's like different identities, that impacts how their message is received.

506
00:58:43,230 --> 00:58:48,030
Yeah, every time we have this day, I want to make sure that we always come back to this question of particularly,

507
00:58:48,030 --> 00:58:57,360
as you said, the professionalism versus showing emotion dimension that talks about has to at least raise the question of.

508
00:58:58,780 --> 00:59:04,780
How does that play out differently for each of us, given who we are,

509
00:59:04,780 --> 00:59:09,700
given the identities that we project out to the audiences we may be interacting with?

510
00:59:11,970 --> 00:59:16,570
Is it different? I think the answer is probably yes for sure.

511
00:59:17,340 --> 00:59:21,600
And I will pick on individual people here just because they're their public figures.

512
00:59:22,500 --> 00:59:27,250
Is it different? Were there to be a. You know, this isn't going to happen.

513
00:59:27,580 --> 00:59:31,420
If there were there to be a horrible event in Michigan.

514
00:59:32,740 --> 00:59:40,030
Is it different for President Biden to express emotion about that exact person's suffering with her?

515
00:59:43,110 --> 00:59:51,440
And if it is. What is the right pathway for each of them to do?

516
00:59:52,610 --> 00:59:57,290
I mean, we can all sort of say, well, I hope we can all say it shouldn't be that way, but it is.

517
00:59:58,190 --> 01:00:01,850
So from the perspective of how do we respond?

518
01:00:02,210 --> 01:00:09,890
Given who we are in a situation? How do we think about what would you be willing to do?

519
01:00:09,890 --> 01:00:17,300
What would I be willing to do? At least we may we will be in these situations at some point in time.

520
01:00:17,330 --> 01:00:21,030
So we have to make those choices. How do you want to feel?

521
01:00:21,660 --> 01:00:26,340
Are you saying I wouldn't ever feel comfortable expressing emotion?

522
01:00:26,790 --> 01:00:31,739
Is there a way to be in the middle ground? I don't know how to. I just want this to be a discussion.

523
01:00:31,740 --> 01:00:35,850
I don't have a clear point here so much as just to raise the issue that this is complicated.

524
01:00:36,390 --> 01:00:39,780
There is not one size fits all. It fits all answer as to how to.

525
01:00:42,460 --> 01:00:47,330
Navigate the dilemma of professionalism and emotion given the society we.

526
01:00:50,450 --> 01:00:58,840
I thought. You repeat the question?

527
01:01:00,620 --> 01:01:07,400
If you were a boil down to this, how much emotion would you show if you were in that situation?

528
01:01:08,390 --> 01:01:13,700
Situation of what was the situation again? A crisis, a mass shooting in Grand Rapids.

529
01:01:17,290 --> 01:01:25,060
I well, I think for some reason I think back to President Obama when he dealt with the Sandy Hook health crisis.

530
01:01:25,180 --> 01:01:31,150
I think it was like a really defining moment. Presidency, something that never really has happened before.

531
01:01:32,200 --> 01:01:35,440
He did handle it with so much. You know, it was really emotional.

532
01:01:35,920 --> 01:01:41,980
And if he had it, I mean, he just would have been totally criticized for that.

533
01:01:42,070 --> 01:01:45,190
So, you know, it depends on the situation for sure.

534
01:01:45,200 --> 01:01:56,410
I mean, you don't want to be overemotional about something that's not super tragic or whatever, but you need to match the situation.

535
01:01:57,510 --> 01:02:03,870
I guess what I'm raising is the question of what does match look like and is it the same for each of us?

536
01:02:04,080 --> 01:02:10,889
Yeah. Yeah. I think like in some of those situations, like just from my perspective as a woman, like it's very gendered.

537
01:02:10,890 --> 01:02:16,490
And like I think like if I had like a violent and showed emotions, people would think I'm like that strong enough to handle the situation.

538
01:02:16,500 --> 01:02:23,460
Like even just like my prior experiences, like being in residency as a female, like in surgery, which is like a very male dominated field.

539
01:02:23,470 --> 01:02:25,920
Like if you show emotion, they're like, get out.

540
01:02:26,190 --> 01:02:33,419
And like, men have like the ability in that setting to, like, really just be able to be empathetic in a way that,

541
01:02:33,420 --> 01:02:37,350
like, I was very much like told not to me and like socialized not to be.

542
01:02:37,830 --> 01:02:43,420
So I think that that's like one piece of the puzzle. Yeah.

543
01:02:43,580 --> 01:02:52,290
I think with that, I think we have a tendency of praising men who show emotion more than praising like feeling like women who show emotion.

544
01:02:52,320 --> 01:02:57,790
So, like, I agree with President Obama's speech, it's like he got so much, like, praise for being emotional.

545
01:02:57,800 --> 01:03:03,500
And I feel like like his wife being emotional would not have had the same amount of praise as you got.

546
01:03:05,570 --> 01:03:10,790
I mean, I think it's pertinent in this. I mean, we're not fully convinced, control, exactly.

547
01:03:10,790 --> 01:03:16,150
When we display emotions. I mean, something impacts us when we're the crisis communicator more than others.

548
01:03:16,160 --> 01:03:21,230
I mean, obviously, some might say they can restrain yourself to some extent, but oftentimes it's more an organic kind of thing.

549
01:03:22,460 --> 01:03:22,670
Yeah.

550
01:03:22,670 --> 01:03:34,879
I mean, I do want to be clear that what segment is really pushing against is the belief that communicators should actively suppress their emotions,

551
01:03:34,880 --> 01:03:43,580
their feelings, that what it means to be a professional, a leader or a communicator is a persona that does not have those emotions.

552
01:03:43,610 --> 01:03:52,400
Obviously, both situations vary and people vary in terms of what is genuine for them, but.

553
01:03:53,810 --> 01:03:59,480
And again, I'm raising this as a question like each of us are going to make choices when we're in these situations and we're going to make.

554
01:04:00,810 --> 01:04:02,160
We may be right, we may be wrong.

555
01:04:02,250 --> 01:04:12,810
His argument is just don't blindly adopt the belief that because you're in this situation, I have to be like straight faced, no emotion.

556
01:04:15,510 --> 01:04:21,890
I'm certainly well aware that I make different choices. Depends on the approach to all of this.

557
01:04:21,930 --> 01:04:28,980
Wondering, for example, during a shooting event, the police officers are fired if he or she able to handle it.

558
01:04:29,340 --> 01:04:36,080
On the other hand, there can be true risk making occurs when talking about complying or I can face suspension.

559
01:04:36,090 --> 01:04:40,440
But the other person more astute, better modeling.

560
01:04:40,530 --> 01:04:48,390
So I would argue no, because I think that regardless of what your role is, if you're in the crisis, you are being affected.

561
01:04:48,810 --> 01:04:55,740
Whether you're just simply describing what the plan is or you are the one who is intentionally trying to be empathetic with your audience,

562
01:04:56,400 --> 01:05:00,150
if you hide your feelings, you are not being true to that.

563
01:05:00,150 --> 01:05:03,420
Almost. You're not being genuine. Now.

564
01:05:06,350 --> 01:05:10,270
How that plays out, Mike. Excellent.

565
01:05:10,700 --> 01:05:16,940
So as you guys have gotten used to, I have these random snap snapshots of examples that pop up.

566
01:05:17,420 --> 01:05:27,350
The one that pops to my mind right now is I was scrolling through yesterday news and I saw the video of yes,

567
01:05:27,350 --> 01:05:37,640
it was the police chief in Virginia who learned that the suspect was in custody while in the middle of doing his briefing.

568
01:05:40,010 --> 01:05:48,300
And there was you see this moment of pausing and it's not like he's crying.

569
01:05:48,380 --> 01:05:52,580
But you you can tell that this he is affected by that moment.

570
01:05:53,600 --> 01:05:58,790
And he says something like, So we've just learned that this suspect is in custody.

571
01:06:02,610 --> 01:06:05,730
Thank goodness for this. Obviously, this is a big relief.

572
01:06:05,740 --> 01:06:12,270
Like he didn't just rattle off the words. There was clearly a moment where he was gathering himself to say something.

573
01:06:13,710 --> 01:06:15,840
That's all it was. It wasn't more than that.

574
01:06:15,840 --> 01:06:22,710
But I knew that he was effective in that moment, and that was important had he just sort of, like, rattled it off like a newscaster.

575
01:06:24,210 --> 01:06:29,550
Having learned it literally in that moment, I would have been like I would have felt wrong.

576
01:06:30,610 --> 01:06:35,730
So that's I think, the example of what comes to my mind. Like, I don't think it's necessarily sweet.

577
01:06:36,480 --> 01:06:44,700
You may spend more time or less time on that, but if you just are a wall of of no emotion, that's not real.

578
01:06:45,620 --> 01:06:52,500
How do those kind of situation? So.

579
01:06:57,980 --> 01:07:01,710
Just to wrap up this idea if you want to. Yeah, I.

580
01:07:01,750 --> 01:07:04,840
I was just like I was thinking, I mean, I know what you just heard.

581
01:07:04,910 --> 01:07:09,770
Obama said he focused on, like with Hurricane Sandy before national disasters as well.

582
01:07:10,670 --> 01:07:15,649
Like, I feel like with like what I think I know and I believe that everyone should be showing emotion.

583
01:07:15,650 --> 01:07:20,720
These speeches. I think it's like a hallmark of a good politician is being able to empathize the people you represent.

584
01:07:21,650 --> 01:07:26,059
I think for like it really breaks down as when you become less articulate about your message.

585
01:07:26,060 --> 01:07:30,990
We use like more like almost like an attacking language.

586
01:07:31,010 --> 01:07:35,059
Like if they start like it was because of this group or this group, I'm blaming this.

587
01:07:35,060 --> 01:07:39,650
It's like, well, I think like Focus on coming together is like these sort of scenarios.

588
01:07:41,120 --> 01:07:52,340
So such like lose the focus of your message. So. I'm going to agree with you and try and shape it into something that I think gives us clearer advice.

589
01:07:52,940 --> 01:07:57,550
If the emotion you're feeling is. Grief.

590
01:07:59,180 --> 01:08:08,660
That's normal. We can be grieving of whatever the crisis is that the harm that has occurred is the emotion that you are manifesting is anger.

591
01:08:12,320 --> 01:08:16,730
It's not that I don't understand where that comes from, but it feels like it's going off of the message in that moment.

592
01:08:18,830 --> 01:08:24,080
And that is a key distinction in these kinds of contexts. Like I can feel.

593
01:08:29,280 --> 01:08:32,759
I can feel grief no matter what the crisis is. Someone has been hurt.

594
01:08:32,760 --> 01:08:43,170
This is bad. I am affected by this. Anger has a purpose, and sometimes that purpose may be constructive and sometimes that purpose may be destructive.

595
01:08:43,680 --> 01:08:47,759
But either way, it's its own message. And then I start to get out of it.

596
01:08:47,760 --> 01:08:58,470
Why are you going? Why are you going down that pathway, etc.? I'm not saying that there aren't times in which leadership in crises isn't.

597
01:08:59,960 --> 01:09:04,320
It doesn't have an anchor component to it where we leverage the emotion that we're

598
01:09:04,320 --> 01:09:08,430
feeling to motivate people to take the actions that need to be taken in that situation.

599
01:09:11,190 --> 01:09:16,730
But it's much more sort of like I'm manipulating you and we have to be honest about what that occurrence.

600
01:09:19,280 --> 01:09:25,160
Just before I wrap up and send us to our small groups to discuss this, these dilemmas I don't want to.

601
01:09:26,540 --> 01:09:31,880
I want to come back to the point about that Cindy was raising about our individual differences.

602
01:09:32,030 --> 01:09:36,979
I know. Not just from my knowledge in teaching this class,

603
01:09:36,980 --> 01:09:47,450
but from my lived personal experience that I have an enormous amount of leeway in how emotional I can be and how vulnerable I can be,

604
01:09:47,450 --> 01:09:55,090
etc., because I can pull it back any time I want. Not everyone has that privilege.

605
01:09:56,930 --> 01:10:05,390
And I fully want to try to understand and respect the differences and the choices that we each must make because of who we are.

606
01:10:06,340 --> 01:10:14,320
And how the society treats us. That said, my goal for today is not to say you should always pursue a particular behavior.

607
01:10:15,880 --> 01:10:22,990
I really want to emphasize Sandman's argument that the goal here is not to say you should always speculate or you should always be emotional,

608
01:10:23,440 --> 01:10:25,690
or you should always democratize the process.

609
01:10:26,230 --> 01:10:35,050
It's that you ought to always ask the question of yourself and to make how you respond to these kinds of situations intentional.

610
01:10:37,280 --> 01:10:42,169
Salman is fully willing to believe there are times in which the right choices,

611
01:10:42,170 --> 01:10:47,120
that there has to be one speaker and that maybe in that moment they have to prioritize getting

612
01:10:47,120 --> 01:10:50,840
their message across more so than they have to be about reflecting their own emotions.

613
01:10:51,230 --> 01:10:54,440
He will accept that, but you better know that you're doing that.

614
01:10:56,260 --> 01:10:59,630
So I simply leave you with this? Yeah.

615
01:10:59,880 --> 01:11:02,930
At some point in time in your life, you're going to be in one of these situations.

616
01:11:02,940 --> 01:11:07,290
I certainly already have. I hope you'll remember today.

617
01:11:07,980 --> 01:11:12,090
I hope you'll remember these questions in that moment, because I hope.

618
01:11:12,870 --> 01:11:20,040
I think certainly my experience is that it was even more enormously helpful to me to go a whole week.

619
01:11:20,990 --> 01:11:22,549
Right. I can think about that.

620
01:11:22,550 --> 01:11:28,970
I can make a choice about that, etc. It gave me a lot more confidence about how to respond in those moments than I thought I would have.

621
01:11:29,450 --> 01:11:41,750
Yeah. Do you feel like because some of them are like paradoxical that like if you're operating under a lot of that,

622
01:11:41,810 --> 01:11:46,070
like other people around, you are going like you're like, always push back.

623
01:11:47,330 --> 01:11:51,080
What a wonderful transition to the question I want you to be wrestling with in your small group.

624
01:11:52,730 --> 01:11:57,020
Always know. Sometimes, yes.

625
01:11:59,600 --> 01:12:09,890
It's a knee jerk reaction to the quick unconscious reactions that most people in crisis assessment describes are to clamp down on,

626
01:12:09,900 --> 01:12:14,570
be secretive, not speculate, not show emotion, etc.

627
01:12:16,940 --> 01:12:24,829
Part of what I hope you will do in your careers is to be the voice of San men and say, Yeah, but we might get some benefit if we did this.

628
01:12:24,830 --> 01:12:29,450
Yeah, but it might be better if we did that, etc. We get some pushback sometimes yes.

629
01:12:29,450 --> 01:12:34,230
Sometimes no. But again, my purpose here is to raise the question.

630
01:12:34,270 --> 01:12:36,180
It's not necessarily to say that you always have to win.

631
01:12:38,020 --> 01:12:45,610
So what I want you to do for the last few minutes is not from here is ten different dilemmas as you

632
01:12:45,610 --> 01:12:55,390
take the popular small groups about which of them seem most difficult to do spontaneous raising.

633
01:12:55,810 --> 01:12:59,950
And some of them are more difficult, either personally difficult or organizationally difficult.

634
01:13:00,970 --> 01:13:06,890
And some of them are going to feel more important if we think about what our goals are in crisis.

635
01:13:06,890 --> 01:13:12,760
And of course, there's been a little bit of time talking through which of these feel most difficult and which feel most important.

636
01:13:24,940 --> 01:13:33,100
I said, I'm so sorry.

637
01:13:36,660 --> 01:13:40,170
I think it's a good idea.

638
01:13:46,530 --> 01:13:55,860
I want to reassure the situation.

639
01:13:58,390 --> 01:14:21,930
Obviously, it's a hard sometimes to win The New York Times with 30 seconds, but it's not as bad as it's going to be.

640
01:14:27,840 --> 01:14:51,520
So we're going to make certain information on speculation.

641
01:14:51,630 --> 01:15:16,620
So I think it is important that people in situations like that, something that has been around for a while, this has been going through.

642
01:15:18,440 --> 01:15:35,070
And I think that I think about I had to do this like I had to do it because we didn't have anywhere near where I thought it would be,

643
01:15:35,160 --> 01:15:46,700
given that I had no time to do that, then some of them are pretty much done.

644
01:15:46,710 --> 01:15:53,550
I don't know what I'm thinking. And so I was like, I talk about it.

645
01:15:54,030 --> 01:16:03,690
I think I did a lot of like a very straightforward and certainly very emotional.

646
01:16:09,180 --> 01:16:18,590
And I think that's what I thought it was like.

647
01:16:18,600 --> 01:16:22,040
Well, what if what if we just didn't work?

648
01:16:22,080 --> 01:16:51,570
So what if we just keep on trying to figure out what happened to the other problem earlier on?

649
01:16:58,830 --> 01:17:23,670
It is, yeah, I think I mean, everyone needs to be shut down or something like that.

650
01:17:23,820 --> 01:18:10,990
So one place where people are like, Oh my goodness, it was weird, but like because I didn't feel like that you don't have to go out there.

651
01:18:11,810 --> 01:18:17,350
And I think that's a fact is for.

652
01:18:17,430 --> 01:18:28,680
Moment to wrap up for today. I want to share with you guys before we wrap up my answer as to what I think is the most important.

653
01:18:29,200 --> 01:18:32,700
It's not that any of these are not important. I think all of them are really interesting.

654
01:18:34,350 --> 01:18:38,880
But there's one piece of this article that has affected me more than anything else.

655
01:18:40,290 --> 01:18:47,850
That's I do not call that feeling safe.

656
01:18:48,700 --> 01:18:53,740
However, I do not call a chemical safe ever.

657
01:18:53,750 --> 01:18:57,240
However, I do not call it procedure safe.

658
01:18:57,780 --> 01:19:01,980
However, I will call things the most safe thing we know how to do.

659
01:19:02,010 --> 01:19:08,030
I will say that we've tested them. I will say that we are safer than not doing them.

660
01:19:08,340 --> 01:19:13,320
I will do all kinds of modifiers, but I will not call something safe.

661
01:19:14,280 --> 01:19:18,240
And I really work at this one because I think salmon's really right.

662
01:19:19,260 --> 01:19:23,580
The right question people have to ask is how safe is somebody?

663
01:19:23,970 --> 01:19:30,000
And we can engage in that conversation any time. We are the experts in that kind of question.

664
01:19:30,670 --> 01:19:36,000
But when we find the truth, we turn it into this dichotomous safe or not safe.

665
01:19:36,720 --> 01:19:38,040
We take that away from people,

666
01:19:39,210 --> 01:19:46,800
really powerful ideas that unfortunately is often woven into the way much of public health communication talks about risk.

667
01:19:48,000 --> 01:19:53,970
So before we leave, I just wanted to share this one because this is probably the thing that's affected me the most for reading this article.

668
01:19:55,110 --> 01:20:01,349
All right. So as I mentioned at the beginning of class, we'll spend Thursday's class going through lots and lots of speech,

669
01:20:01,350 --> 01:20:06,420
examples of practical examples to help you set up for the assignment that's due on Monday.

670
01:20:07,680 --> 01:20:15,360
Take a look at it. It's a fairly simple scenario. Two cases of relief from Respiratory Syndrome in Ann Arbor.

671
01:20:16,320 --> 01:20:22,680
Specific things. Just a couple of specific facts that I give you and then I give you a lot of flexibility

672
01:20:22,680 --> 01:20:27,630
to set the stage for anything else in whatever way you want to talk about that.

673
01:20:28,620 --> 01:20:51,449
All right. You know, it's not like I'm working and I can't talk about two and I don't know how this happened,

674
01:20:51,450 --> 01:21:00,090
but I know it's nothing to be apologetic, not defensive.

675
01:21:03,960 --> 01:21:08,180
Yeah, I'm at a loss.

676
01:21:08,920 --> 01:21:12,030
Yeah, well, I hope that in the future.

677
01:21:12,030 --> 01:21:16,500
In the future, I know you're not the only person who said that.

678
01:21:18,240 --> 01:21:28,800
She was like, Oh, my God, oh, my God.

679
01:21:30,430 --> 01:21:35,430
So I think the other thing that I ran into is when I had to do mine, I wasn't expecting it.

680
01:21:35,970 --> 01:21:40,500
I, my head coach, literally got pulled into coaching and he was like, All right, you're in charge.

681
01:21:40,710 --> 01:21:51,080
You have to tell these kids what's going on. And I was like, I yeah, enforce.

682
01:21:51,150 --> 01:22:07,370
The next day I was going to walk through the front door and I went through the 77 year I have to regulate in your business.

683
01:22:08,290 --> 01:22:24,370
You know, that was a difference in your testimony from 200 and grand old house was never about me.

684
01:22:24,670 --> 01:22:35,399
I mean, I hate how my hair looks after and sometimes I just wonder what happened.

685
01:22:35,400 --> 01:22:39,900
And reality is there is like you here when it's really short, it doesn't matter.

686
01:22:39,940 --> 01:22:52,500
So like, my name is just one of the things that I do and it's just such a basic thing and using it improperly because they will leave it up to you.

687
01:22:52,830 --> 01:22:57,270
It's really important. What do you want to train clinicians for?

688
01:22:57,300 --> 01:23:01,470
I have to do this. All right. Yeah, whatever it is.

689
01:23:01,470 --> 01:23:12,370
Because it seems to me that from the glory days, though, there were eventually get to it maybe ten or something like that.

690
01:23:12,580 --> 01:23:16,710
You know, I'm sitting here going, you know, you're just going to have to tell grandma deal with that because.

691
01:23:17,270 --> 01:23:23,990
Everything else is going to flow from there. I love your company.

692
01:23:25,490 --> 01:23:30,360
Yeah, I was looking for them.

693
01:23:31,430 --> 01:23:32,839
I was wondering where you'd been,

694
01:23:32,840 --> 01:23:45,500
but I figured something like that is something I got to know in this particular episode with the bad news corporations and all kinds of stuff.

695
01:23:46,580 --> 01:23:49,790
Oh, that. I thought you have a fascinating sample.

696
01:23:50,270 --> 01:23:54,110
I said it would be something I did or somebody else's.

697
01:23:56,210 --> 01:24:03,830
Anyway, it's pretty good to see you. Yeah. I mean, I'm sorry that I made you listen to the lecture that.

