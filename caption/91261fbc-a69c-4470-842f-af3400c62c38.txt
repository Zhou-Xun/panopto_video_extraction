1
00:00:03,460 --> 00:00:10,230
The exam will be just as well for the exam your exam paper in your mailbox later today.

2
00:00:11,670 --> 00:00:21,730
We are going to move on to the mailbox around 1 p.m. or you just have to relax later on and then post a resolution as well.

3
00:00:21,780 --> 00:00:31,710
Cameras that after you got an exam paper, please go through your exam paper and see if you have any questions or any grading.

4
00:00:32,490 --> 00:00:38,309
And then we are not going to talk about the exam today because you you will have the exam paper.

5
00:00:38,310 --> 00:00:41,970
But we are going to talk to you about the exam next Tuesday.

6
00:00:42,300 --> 00:00:50,520
Once you got it, we were back. It was you have a chance to review them and also to check out the solution.

7
00:00:50,760 --> 00:00:58,140
We want proof and we'll have a little bit more about the exam and also some questions, some answers on next Tuesday.

8
00:00:58,910 --> 00:01:07,100
And yeah, that's next week.

9
00:01:07,230 --> 00:01:13,799
So today we are going to continue the discussion about not what might happen.

10
00:01:13,800 --> 00:01:23,610
We are running all this testing, so maybe we should get a very quick memory because it has been one week and the whole week

11
00:01:23,610 --> 00:01:34,650
since the last time we have since since the last last Thursday we talked about this.

12
00:01:36,330 --> 00:01:43,889
So here we in introduce some calls have a recall to some square but you can forget about that concept for a minute.

13
00:01:43,890 --> 00:01:54,960
Let's take a look at what we are trying to achieve here in this whole mode is one of the mode of achieving the goal is to develop

14
00:01:55,740 --> 00:02:06,720
or to look at the test within a more general framework so that we can use our test to test different types of hypotheses.

15
00:02:07,590 --> 00:02:14,850
So really are rational. Well, we are going to see that later in this night, are going to see that many questions they can be formulated,

16
00:02:15,120 --> 00:02:23,969
as has been the hypothesis that certain subsets of beta work in regression you have about happiness balance.

17
00:02:23,970 --> 00:02:30,720
Right. So many problem can be formulated as testing if a subset of these beta are equal to zero.

18
00:02:31,890 --> 00:02:41,580
And later to see many examples. And it turns out that for such a hypothesis A has been whether are some of basal abilities are equal to zero.

19
00:02:42,960 --> 00:02:50,340
The impasse can be used to have some hypotheses. And then there is a unique unified framework and this is what we are trying to achieve here.

20
00:02:50,460 --> 00:02:59,970
We're trying to look at our test, how we use after some test, you know, such hypotheses and and the one yes.

21
00:03:00,130 --> 00:03:03,540
Those before or after solution. And that we're going to see examples.

22
00:03:04,080 --> 00:03:08,140
So that's not the, you know, the future of the world.

23
00:03:08,150 --> 00:03:14,910
We're going to model regime now in column two so far, well, we talk about our past.

24
00:03:16,590 --> 00:03:36,909
We have to use our house to test. To test this hypothesis, testing whether one arm to beat on, one arm to beat up minus one.

25
00:03:36,910 --> 00:03:45,040
So other than to intercept whether all the other betas are simultaneous equal to zero versus at least one is not anything.

26
00:03:45,370 --> 00:03:49,720
That's the meter case we are looking we have been looking at, but we use our test.

27
00:03:50,980 --> 00:03:52,430
But it turns out that, you know,

28
00:03:52,710 --> 00:04:01,450
we can use our pass to test a variety of different hypotheses of of similar for similar structure, but not exactly this.

29
00:04:01,930 --> 00:04:05,259
For example, we can use our test while we have seen this as well.

30
00:04:05,260 --> 00:04:18,309
We can use our pass to test whether a single beta is equal using you know that we introduce the so called sum of not introduced last time,

31
00:04:18,310 --> 00:04:22,840
but we have been talking about all of some of the squares and of the idea, well,

32
00:04:22,840 --> 00:04:28,870
maybe it's worthwhile to go after knowing what we are trying to achieve in the end.

33
00:04:29,260 --> 00:04:34,930
Now let's look at we talk about the major idea behind this impasse.

34
00:04:35,440 --> 00:04:43,120
The idea is that suppose we are testing whether this particular subset of beta are equal to zero or not.

35
00:04:44,050 --> 00:04:51,700
Now you compare the models with this betas in the model and the model that went out of this made us.

36
00:04:51,820 --> 00:04:56,889
In other words, you force this balance to be equal to zero. You remove them from the model as well.

37
00:04:56,890 --> 00:05:00,070
The models that have this data as in the model that do not have this mass.

38
00:05:00,370 --> 00:05:04,749
And so one model is larger. The models that have this betas is a larger model.

39
00:05:04,750 --> 00:05:11,620
The model that does not have this betas is a smaller model we call a restricted model where we do its models from the time about later.

40
00:05:12,010 --> 00:05:17,530
But the idea is to compare those two models, to compare the sum of squares of these two models.

41
00:05:18,130 --> 00:05:25,360
So if the larger model gives you a much higher sum of squares, measures almost square or much smaller error or somewhat square,

42
00:05:26,170 --> 00:05:29,530
then we tend to say, well, the larger model is good, is better.

43
00:05:30,250 --> 00:05:34,960
But if the sample squares, they are very similar, they're very close between those two models.

44
00:05:35,640 --> 00:05:39,850
That means while adding this betas, they do not give you any improvement.

45
00:05:40,180 --> 00:05:44,350
So then we tend to say, Oh really the larger model does not benefit us.

46
00:05:44,620 --> 00:05:50,080
So we probably will just stick to the smaller model. And that's the, the fundamental idea.

47
00:05:50,110 --> 00:05:55,120
So that's based on that idea, we need to look at the sum of squares for these two models.

48
00:05:55,120 --> 00:05:59,979
You have to compare the sample squirrel models and we'll compare some squares.

49
00:05:59,980 --> 00:06:06,280
We can either compare the sum of regressions on the square or there isn't one square there equivalent.

50
00:06:06,280 --> 00:06:12,910
Because what we saw to the total sum of the square, which as it was your view of the data, then the photos on the square is next.

51
00:06:13,450 --> 00:06:16,810
So we can look at look at either a regression ensemble square or errors.

52
00:06:17,440 --> 00:06:22,860
So that's that's the main focus of this course of this model.

53
00:06:22,870 --> 00:06:28,609
So we're going to look at how much change when we graduate on the square.

54
00:06:28,610 --> 00:06:31,840
It is for permission to the error rates.

55
00:06:33,400 --> 00:06:40,550
So this change in the error in the sum was where we call it, we call to action some more squares, right?

56
00:06:40,610 --> 00:06:43,540
So that is when you look at a larger model,

57
00:06:43,540 --> 00:06:53,800
how much increase do the regression sample squares or how much reduction is is for the errors on the squares?

58
00:06:54,010 --> 00:07:00,760
So this is called extracellular space. And then we look at one, one example, right?

59
00:07:00,760 --> 00:07:13,600
So we looked at an example where we have we have partitioned the X into two components and corresponding the beta in the two components as well.

60
00:07:13,600 --> 00:07:20,760
So we have a smaller model that has only beta one and we have a larger model that has both beta ones and balance.

61
00:07:22,360 --> 00:07:30,740
And then while we use this as an example to sort of to illustrate this notation, this is the so-called called for some one square or change,

62
00:07:31,030 --> 00:07:40,240
change or some square and for some a square, this notation, one of those this relation means is, well, given that beta one is already in the model.

63
00:07:40,840 --> 00:07:48,820
So now we're given the first of all given sorry, not given the first model, but if even the beta one is already in the model,

64
00:07:49,210 --> 00:07:56,620
we look at how much, how much change we have in terms of the sample square.

65
00:07:56,890 --> 00:08:07,030
This change can either be calculated by looking at the difference in the regression sample square or the difference in error is almost square.

66
00:08:07,810 --> 00:08:09,600
The difference in regression is almost there.

67
00:08:09,620 --> 00:08:20,350
Now, of course, the larger model with more comparison, for better so remarkable as to have a larger rewrite.

68
00:08:20,410 --> 00:08:25,840
It's almost half because the number model. Well, of course it doesn't really hurt.

69
00:08:26,270 --> 00:08:30,370
If you have. Well, let's forget about the high dimensional case that we've just done for this course.

70
00:08:30,980 --> 00:08:37,340
Give you include one covariate. But even if it doesn't, it's not related to the response by including it.

71
00:08:37,550 --> 00:08:48,050
It doesn't hurt the model. But if you remove it, if if it does, it has to the Y if you do not include about covariate, then your model is incorrect.

72
00:08:48,260 --> 00:08:54,110
Is right. So. So in including Merkel, marriage doesn't hurt the model.

73
00:08:54,500 --> 00:09:03,559
Right. So it will increase the Radisson a square. So here we look at how much we wrote a sample square change by comparing this one to the

74
00:09:03,560 --> 00:09:11,260
smaller law restrictive restraining order that did not does not have an extreme of similarity.

75
00:09:11,360 --> 00:09:22,159
Or equivalently, we can look at the error square by adding this to by adding beta and true into the model that it has been a one how

76
00:09:22,160 --> 00:09:29,960
much emotion we have in terms of errors almost because adding more covariates will reduce that interest almost square.

77
00:09:31,730 --> 00:09:36,500
Or this is just what this notation means. I'm very happy to give an update on what.

78
00:09:39,520 --> 00:09:47,260
And this. Then we look at a for example, we really look at the so-called parties almost with the parties almost where it is.

79
00:09:47,740 --> 00:09:53,860
Now we have Hillary Clinton. In other case, we have three sets of basically subnational events.

80
00:09:54,130 --> 00:10:04,720
So we have a one, two or three. And the partial sum of square that is to look at that is to look at the change matches.

81
00:10:04,840 --> 00:10:11,079
And it is almost square when adding any of these beaters into the model or to

82
00:10:11,080 --> 00:10:16,630
have the other food greatest is right where the other two subsets of calories.

83
00:10:16,960 --> 00:10:20,110
This is the so-called partial sum of square.

84
00:10:20,920 --> 00:10:26,830
And then we look at the so-called sequential troubles where this equation is almost clear.

85
00:10:27,320 --> 00:10:31,650
If you look at the change in sum of square sequentially, though,

86
00:10:31,780 --> 00:10:42,580
you will also you first you look at how much some square changed when you add the X1 into the model that the model has only intersect.

87
00:10:43,210 --> 00:10:50,890
And then how much while that based on the model that has already been resolved and X1 there, how much extra squared,

88
00:10:50,950 --> 00:11:02,220
how much changing sum of square if you add extra in the model and then you look out of whole lot of R2 has X1 and adds to that,

89
00:11:02,260 --> 00:11:09,069
you see how much change in the sum of the square if you add at three in the model as we look at this

90
00:11:09,070 --> 00:11:16,630
equation that's that's the so-called equation of the square and a both are have practical meanings.

91
00:11:17,080 --> 00:11:22,630
So later we will talk more about particle sum of square.

92
00:11:22,640 --> 00:11:27,840
But here I think we can very quickly give us examples.

93
00:11:27,870 --> 00:11:33,939
What are some secret examples where we can we use square someone's word, for example,

94
00:11:33,940 --> 00:11:38,620
when we do the models, when we try to add polynomial terms in the model.

95
00:11:38,770 --> 00:11:45,879
Let's say you want to add a new thing that you know the response y depends on the say axes.

96
00:11:45,880 --> 00:11:54,310
H Not necessarily just if you had an edge, some kind of a square if cube, but a way you build the model.

97
00:11:54,310 --> 00:12:01,150
We like to try to see explore a little bit to see whether it does because a big

98
00:12:01,150 --> 00:12:06,940
square and a Q and value add page and a square and you see also in the model.

99
00:12:07,360 --> 00:12:17,260
And so that's that's when a similar model square is playing for and that's just one example for the other pieces.

100
00:12:20,050 --> 00:12:28,440
Okay. And then well this, this, this slide here, this is just showing you could do by using some of some examples.

101
00:12:28,440 --> 00:12:41,649
Just so again, what, how these notation work. So for example, here this this guy, the speaker one given below zero,

102
00:12:41,650 --> 00:12:48,400
this simply means that we look at the the reversal of square when we include both intercept and x one.

103
00:12:49,270 --> 00:12:56,700
How much how much difference is there between this guy and the model that has only intercept?

104
00:12:57,010 --> 00:13:04,180
And that's what this conditional beta one is means.

105
00:13:04,840 --> 00:13:12,729
So this is again, it's just notation, again, to get familiar with the notation so that that is where we stop less time adding

106
00:13:12,730 --> 00:13:27,720
questions before we move on of and then we are going to pass on some new,

107
00:13:28,240 --> 00:13:36,910
new material. So the first cause that we're looking at today, that is the so called nasty politics it has to the models of.

108
00:13:39,970 --> 00:13:47,590
Maybe why? It's a lot easier if first look at one example rather than talking about that low cost himself.

109
00:13:48,130 --> 00:13:58,480
So if we look at like these three models of the three model, let's say we have three blocks of X, the X, Y and Z three.

110
00:13:59,620 --> 00:14:04,210
And then if we look at the three models, we see that this model is a simplest,

111
00:14:04,540 --> 00:14:12,670
it only has an X one and this model has of well, slightly more complex as both X1 and x three.

112
00:14:13,180 --> 00:14:18,280
And this model is the most complex. It has all the three blocks of x.

113
00:14:18,670 --> 00:14:23,860
If you look at the three models, then the X,

114
00:14:23,860 --> 00:14:32,500
the cobra is usually goes model for a subset of the covariates used in this model and then are a subset of the comparisons in this one.

115
00:14:32,860 --> 00:14:42,759
This is what we mean by nasty models. So you have the areas of smaller model, very complete subset of the B of another model.

116
00:14:42,760 --> 00:14:50,350
So that we say that these two models, the nasty versus the second the case, if you look at of this example here,

117
00:14:50,350 --> 00:14:58,180
the simpler model, it has x1x4 in it, but the larger model has x1x2 and three.

118
00:14:58,390 --> 00:15:04,420
You can see that a three is not a second model, but as four is not in the first one.

119
00:15:04,720 --> 00:15:10,840
So these two models, they are not nested, they have not overlapping covariates.

120
00:15:11,140 --> 00:15:16,240
So this is not nested model. So this is what we call nested models.

121
00:15:16,240 --> 00:15:22,120
The models are nested if they if they use the same variables for the same variables.

122
00:15:22,120 --> 00:15:26,030
But one model stays for at least one additional parameter to ask me.

123
00:15:29,170 --> 00:15:36,190
And the motto with more parameters that that is what we call the for more for larger more.

124
00:15:36,850 --> 00:15:48,100
Different people have different ways of columnist for the word murder model and the model that has has less parameters.

125
00:15:48,610 --> 00:15:55,870
So fewer coverage, less parameters. That is the so-called restraint model where we reduce model or some smaller model.

126
00:15:59,170 --> 00:16:06,760
Of course, when we have I mean, here we have more parameters, but it means we have fewer restrictions on the parameters.

127
00:16:06,760 --> 00:16:17,900
Because. Because. Now we have the example here so we can use this to make use of these examples.

128
00:16:20,230 --> 00:16:28,160
So if we compare this model and this model the first and second, rather than this is the like the so-called larger model.

129
00:16:28,180 --> 00:16:33,010
This is a smaller, more restrictive model or a reduced model.

130
00:16:33,820 --> 00:16:39,850
And sometimes I tend to not say like for model, because if you look at the three models,

131
00:16:39,850 --> 00:16:45,100
I mean that if you if you just focus on the first and the second oh, sorry, the second and third.

132
00:16:45,490 --> 00:16:52,600
And this is actually not a full model in the sense that it it's not included as three referenced.

133
00:16:52,600 --> 00:17:00,690
There are also three to consider. But anyway, I mean, the concepts they are not like we do not have to, you know,

134
00:17:00,700 --> 00:17:06,580
think of those terms like a full model, 3D model in terms of mathematics, because they are not.

135
00:17:07,220 --> 00:17:16,090
They're not super rigorous mathematical definitions, just in terminology that we use to to distinguish a smaller amount of smaller model.

136
00:17:16,360 --> 00:17:21,250
But in this case, if we compare this four models, then the seven the model here,

137
00:17:21,260 --> 00:17:27,550
the similar model, that is by forcing beta two and a beta three equal to zero.

138
00:17:28,060 --> 00:17:32,720
Right? If you force this equal to zero, this equal to zero, then you get the maximum.

139
00:17:34,150 --> 00:17:39,670
So that's why we we say that the smaller model, second model or the restricted model,

140
00:17:40,840 --> 00:17:46,120
it has more restriction on the parameters because you're forcing those parameters to be equal to zero.

141
00:17:46,480 --> 00:17:53,900
So that's what it means here. So for example, with the last parameters that normal,

142
00:17:53,900 --> 00:17:59,080
that has more restrictions on the parameters because you are forcing some parameters to be equal to zero.

143
00:17:59,860 --> 00:18:05,690
So that the formula, the larger model allows more profit and fewer restrictions on the.

144
00:18:09,100 --> 00:18:14,320
Okay. So this is what we mean by, you know, by nasty morals.

145
00:18:16,210 --> 00:18:22,220
You. And then for hypothesizing.

146
00:18:22,220 --> 00:18:29,840
Now, let's take a look at the different forums. We'll have all the testing that we will be focusing on in this module and not only in this module.

147
00:18:29,840 --> 00:18:33,830
I mean, this is a different hypothesis,

148
00:18:34,460 --> 00:18:40,460
but I think that you guys on holiday are going to see we're formulating our own hypotheses

149
00:18:40,460 --> 00:18:46,430
in our forums in your research where we read papers because when we run linear regression,

150
00:18:46,430 --> 00:18:50,360
it's very common, but not necessarily linear regression, but generally linear regression as well.

151
00:18:50,360 --> 00:18:54,950
I mean, there is many, many problem can be formulated as.

152
00:18:56,680 --> 00:19:00,639
Some people have a hypothesis. So let's say we are we have this model.

153
00:19:00,640 --> 00:19:10,110
We have three covariates, right? One, two, three. And then there are different hypotheses we might be interested in testing.

154
00:19:10,810 --> 00:19:17,650
There is a so-called overload hazard. We have seen this is testing whether this three way oh, these three betas,

155
00:19:18,430 --> 00:19:26,650
they are simultaneously equal to zero inverse is that at least one of the experiments is not equal to zero.

156
00:19:27,700 --> 00:19:29,930
This is the case of this.

157
00:19:30,010 --> 00:19:42,010
This is to assess the overall fit of this model, to see whether this three covariates, like all the various other considerations over all,

158
00:19:42,010 --> 00:19:50,680
whether they have any power in explaining the variation in Y is an overall assessment of the model.

159
00:19:52,090 --> 00:19:57,040
So whether any of these covariates indeed has a strong association with Y.

160
00:19:57,310 --> 00:20:04,240
So that's what this hypothesis is testing. And the second case is the single covariates.

161
00:20:04,630 --> 00:20:12,220
We have seen this as well. So let's say our interest is in beta two alone, or it adds to what we think of as true or not.

162
00:20:12,610 --> 00:20:21,740
Let's say x two is H. So for example, we were just interested in seeing that whether age has a significant effect of of passion.

163
00:20:22,900 --> 00:20:30,700
But if we were to see that after adjusting for the lesson for gender and a four for race, let's say for example.

164
00:20:30,700 --> 00:20:34,149
Right. So, so, so in this case,

165
00:20:34,150 --> 00:20:44,590
the main focus is the effect of x two and then are test of whether it's true is equal to zero versus x two is not equal to zero.

166
00:20:46,210 --> 00:20:50,080
Of course adjusting for the other two, whereas x one and x three.

167
00:20:51,130 --> 00:20:54,640
So this is another scenario that is commonly seen,

168
00:20:54,730 --> 00:21:03,330
that is to test a single payer and a lot of other cases where we want to test a subset of the three.

169
00:21:03,370 --> 00:21:13,120
So here, for example, we might be interested in testing whether beta tools and a beta three are simultaneously equal to zero, not a beta.

170
00:21:13,530 --> 00:21:21,900
So we are less we. While we are less interested in beta one, we are casting whether these two are simultaneously given two.

171
00:21:22,540 --> 00:21:31,179
That's another commonly seen scenario. But this is the case where you can you can imagine that many other situations are similar to this.

172
00:21:31,180 --> 00:21:41,660
You could test whether beta one, beta two are simultaneously equal to zero or whether beta one beta three are simultaneous equal to zero versus,

173
00:21:41,740 --> 00:21:45,040
you know, at least at least here in this case,

174
00:21:46,120 --> 00:21:53,020
you're testing whether beta two or three there are some versus at least one of these two is not even zero.

175
00:21:54,450 --> 00:22:02,340
Right. This is the. I'm trying to think of a.

176
00:22:05,230 --> 00:22:09,360
Thinking of the very simple example to illustrate.

177
00:22:09,460 --> 00:22:19,810
So for example, if, for example, let's say let's against here is age and let's say maybe I'll.

178
00:22:38,120 --> 00:22:41,240
But this is one you just made out.

179
00:22:41,330 --> 00:22:49,880
This example, let's say you're interested in such a model building, such a model for studying the low blood pressure, white blood pressure.

180
00:22:50,810 --> 00:22:54,500
And you have age and it's a square in a model.

181
00:22:55,610 --> 00:23:06,650
And your interest is to see whether age has a significant effect or association or whether blood pressure depends on age significantly.

182
00:23:07,280 --> 00:23:14,730
And then. One very natural hypothesis to test is to test whether beta two and a beta three US continue.

183
00:23:17,130 --> 00:23:24,570
So that's a case where you might be interested in testing such a hypothesis versus and is one of these is not a.

184
00:23:26,470 --> 00:23:32,170
Of course, there are many, many other horrible situations, but this is just one example Trump illustrates.

185
00:23:33,700 --> 00:23:41,410
So you can imagine that if you have Vancouverites available, and then you can, depending on your interest,

186
00:23:41,440 --> 00:23:50,860
depending on the investigators interest, depending on the sentiment question of interest, you have many people's hypotheses.

187
00:23:51,340 --> 00:23:56,990
They're all inside for like casting a subset, whether a subset of voter are able to.

188
00:23:58,330 --> 00:24:01,330
So that that is the focus on this model.

189
00:24:01,330 --> 00:24:08,650
We are trying to develop and test like a more unified a framework and test to test all these hypotheses.

190
00:24:09,130 --> 00:24:15,190
It turns out that the F statistic for comparing two nasty tomatoes.

191
00:24:15,460 --> 00:24:21,460
So if you look at if you look at all these hypotheses, you look at all these hypotheses,

192
00:24:23,410 --> 00:24:29,440
the models specified under a novel is is intermodal space, but other alternative hypotheses.

193
00:24:29,950 --> 00:24:39,130
These are nasty to models because under normal, this is in a sense that, you know, the corresponding virus are equal to zero zero.

194
00:24:39,820 --> 00:24:44,830
These models are not. Well, this is these these are the smaller models are the industry models,

195
00:24:46,060 --> 00:24:52,000
whereas the models under the corresponding order, the corresponding alternative hypothesis.

196
00:24:52,950 --> 00:24:59,950
This says that while these say that at least some betas are not equal to zero, at least one beta is not.

197
00:25:01,060 --> 00:25:05,640
So these are more larger models or less restrictive model.

198
00:25:06,040 --> 00:25:11,709
If you just consider this model, this is the so-called full on result that underlie why this is.

199
00:25:11,710 --> 00:25:14,920
You have a smaller order to see the model on an alternative.

200
00:25:15,550 --> 00:25:19,000
You have a larger or less restrictive of the following.

201
00:25:19,630 --> 00:25:26,220
And now you're comparing the model unreliability versus the model under alternative or alternative.

202
00:25:28,090 --> 00:25:37,120
And these two models, they are nested. They're nested because you're not losing all the data as are equal to zero or sometimes are equal to zero.

203
00:25:37,480 --> 00:25:40,600
But Alternative says that at least one of those beta is not equal to zero.

204
00:25:40,870 --> 00:25:47,500
So they are nested. And for this nested for testing, this novel versus alternative.

205
00:25:48,590 --> 00:25:58,730
Once we realized that now here we are comparing to nested models, then we are able to apply the so-called well,

206
00:25:58,780 --> 00:26:04,240
we are able to construct the F statistic to compare adding to nested models.

207
00:26:06,440 --> 00:26:11,780
And in the form of the statistic is, well, it's very similar to before.

208
00:26:11,810 --> 00:26:15,500
So it's the change in terms of some squares.

209
00:26:16,720 --> 00:26:23,740
Divided by is corresponding to our freedom and then dividing by what means sum of squares.

210
00:26:24,550 --> 00:26:32,100
People outside the means were error. Now let's take a look at a one by one item.

211
00:26:32,220 --> 00:26:36,960
So this SARS here. This is the change in some squares.

212
00:26:37,440 --> 00:26:39,180
This this change, as we mentioned.

213
00:26:39,420 --> 00:26:46,860
You can either look at the change in the arrows, almost mirrors or the change in the regression of squares there in colon.

214
00:26:46,860 --> 00:26:50,690
Because actually, to sum to the total sum, there's.

215
00:26:51,710 --> 00:26:59,450
So you are comparing two models, the model under age now and the model older alternative.

216
00:27:00,080 --> 00:27:11,540
Right. And of older age now we have the reduced model or the receiving under age one, we have a formal larger one.

217
00:27:12,230 --> 00:27:16,040
And about the smaller model of course has larger error.

218
00:27:17,210 --> 00:27:22,580
The smaller one has an alternative because the smaller model has has fewer covariance, right?

219
00:27:22,580 --> 00:27:31,729
So so but it has larger ever larger model has smaller error and or on the other of the other way.

220
00:27:31,730 --> 00:27:39,320
So in other words, so the larger model because it has more covariance, so it has larger regression.

221
00:27:39,320 --> 00:27:44,360
So more squares and a smaller motor has smaller versions, almost squares.

222
00:27:46,110 --> 00:27:52,150
So either way, by either looking out of the air is almost where we're getting somewhat where you are able to calculate the difference.

223
00:27:52,170 --> 00:27:58,120
What extra someone's watching is. Obviously that is what we have here, these estimates.

224
00:27:59,700 --> 00:28:09,960
And then divided by your freedom. The your freedom is simply the number of parameters casting in analysis.

225
00:28:10,590 --> 00:28:21,660
So in other words, for your freedom, you just need to count how many parameters, how many business, your analysis SAS that are equal to zero.

226
00:28:22,800 --> 00:28:30,959
Like in this case, like these three cases. This is not how others assess that all these three betas are equal to zero than that your freedom

227
00:28:30,960 --> 00:28:36,690
is equal to threatened because you are forcing the three made us equal zero on our novelists.

228
00:28:37,720 --> 00:28:41,260
And the size of the case, liability is equal to zero.

229
00:28:41,530 --> 00:28:46,600
So you are only allowed in beta first. Beta two you will not, but this is only first beta two user.

230
00:28:46,960 --> 00:28:51,280
So the people are freedom of this and for some a square, that's just one.

231
00:28:51,980 --> 00:28:56,770
And in the third case now beta three are equal to zero.

232
00:28:56,980 --> 00:29:03,520
In this case, that your freedom is equal to the two because you know how well it says that two of these spaces are equal to zero.

233
00:29:04,000 --> 00:29:12,760
So this, to your freedom is just the number of parameters tested in a novel is it's okay.

234
00:29:15,160 --> 00:29:19,150
And then the denominator here, this means square error.

235
00:29:20,510 --> 00:29:26,900
This is the assemblage of C1 squared based on H1 model.

236
00:29:26,930 --> 00:29:29,360
This is very important. We have to keep this in mind.

237
00:29:29,360 --> 00:29:36,190
So that's why we have a subsequent here and that's a new one because we are looking at two models, right?

238
00:29:36,280 --> 00:29:42,680
A smaller amount and larger model. And if for either model, for both models, we are able to calculate the useful out.

239
00:29:43,310 --> 00:29:46,550
Once you have a model, you can count on the new square, have a corresponding slack.

240
00:29:47,060 --> 00:29:52,910
So when we you know what, we do have this new square, we have to be very careful and very clear,

241
00:29:52,910 --> 00:29:58,430
which is very useful to have a look at this and the be a square error here.

242
00:29:58,940 --> 00:30:07,220
This is the mean square error for the larger model for the model only 35 offices in the world.

243
00:30:10,760 --> 00:30:20,830
So that is. What I am saying is how the F statistic is constructed and is photos and evidence filtered later in the show?

244
00:30:20,860 --> 00:30:26,380
Why was slow evidence fusion unreliable? This is what this is under nonsense.

245
00:30:27,340 --> 00:30:31,310
It involves an evidence fusion, the D-word, freedom.

246
00:30:31,330 --> 00:30:42,250
While the new numerator, the growth rate is here is just the number of batteries that you specified to be equal to zero hundred dollars.

247
00:30:43,150 --> 00:30:51,510
And the denominator of you are afraid of that is the number of parameters here.

248
00:30:52,500 --> 00:30:55,530
I'm sorry.

249
00:31:01,220 --> 00:31:12,050
Oh. Just trying to find a good way to express this is this is this is.

250
00:31:14,480 --> 00:31:22,760
And minus the number of. So maybe we will skip this for now.

251
00:31:22,780 --> 00:31:26,970
Let's just make it clear later, because we will make it clearer later.

252
00:31:27,210 --> 00:31:35,040
So this D freedom here, this is not the degree or freedom of the error.

253
00:31:35,040 --> 00:31:39,700
Some square under the not the.

254
00:31:41,100 --> 00:31:49,260
So this is guys this is that maybe this is the D where freedom of as.

255
00:31:51,960 --> 00:32:00,390
It's just a tragedy this week a record that of the the for the ABC one this viewer

256
00:32:00,390 --> 00:32:06,630
freedom is equal to N minus P right so here is the number crunchers in the formal.

257
00:32:10,390 --> 00:32:19,170
And we will come back to this later on the leader level to make super clear because we are going to see examples I think of.

258
00:32:20,020 --> 00:32:25,050
Then it will be really clear what this is about.

259
00:32:25,240 --> 00:32:32,760
For now is just just remember, keep in mind that this is a big working class one and I see one in the denominator.

260
00:32:38,630 --> 00:32:44,540
Okay. So this is the so if you look at this statistic, again, this is very intuitive.

261
00:32:47,510 --> 00:32:50,630
This is how we should interpret this AB statistic.

262
00:32:50,990 --> 00:33:01,370
So while F statistic is used to test the age now versus alternative, another way to test this,

263
00:33:01,370 --> 00:33:08,899
to compare this is to look at how much at square change some of that square from comparing

264
00:33:08,900 --> 00:33:13,670
model non model to the alternative model because you are comparing this to models.

265
00:33:13,670 --> 00:33:21,200
So you just compare how much change the sample square is of course replaced by the normalized by the corresponding period.

266
00:33:21,200 --> 00:33:28,790
When you compare that change in some sample square to the total being somewhat square or something.

267
00:33:29,090 --> 00:33:36,710
So the total errors almost square. This is we call that this is error result squared divided by its corresponding divorce rate on a normalized basis.

268
00:33:37,610 --> 00:33:47,150
So essentially this F statistic is comparing how much change you've seen in terms of some square compared to the total error or somewhat square.

269
00:33:47,690 --> 00:33:54,260
If the change is relatively large, then that means these two models, they are quite different.

270
00:33:55,040 --> 00:33:59,060
Now you will reject the novel. This is if the trend is small,

271
00:33:59,480 --> 00:34:08,660
then we think that these two models are not so different than the model that we we will not have exactly the model under my policies.

272
00:34:08,870 --> 00:34:13,910
So that's the intuition behind the F statistic. It just compared the change.

273
00:34:14,290 --> 00:34:21,559
Just look at the change in terms of some square eye to see whether that's large enough for a large enough lab.

274
00:34:21,560 --> 00:34:30,850
That is by comparing it to the error, little errors on the square of that we will in the end will have F distribution matched.

275
00:34:31,280 --> 00:34:33,799
Okay. So now let's take a look at a few examples.

276
00:34:33,800 --> 00:34:44,420
I think it will help a lot to understand better than, you know, this very abstract construction of a F statistic.

277
00:34:44,960 --> 00:34:50,870
Okay, so look at the case where we have to X and then correspondingly we have two data.

278
00:34:51,740 --> 00:35:01,729
So this is the model. The model can be read an sx1, beta one plus Acts two, beta two plus Armstrong and beta one.

279
00:35:01,730 --> 00:35:12,650
Here is pure dimensional beta two is p two dimensional and in total while we have P and that's what this example is.

280
00:35:13,190 --> 00:35:22,370
And let's say we are interested in testing whether beta two is equal to zero, you know, versus beta two is not inclusive.

281
00:35:24,080 --> 00:35:28,610
So we're testing whether this, this one should be included in a model.

282
00:35:30,470 --> 00:35:38,120
And the way to test this hypothesis well is to construct an F statistic.

283
00:35:38,840 --> 00:35:41,989
Now, the error statistic is constrained in this way.

284
00:35:41,990 --> 00:35:54,190
So this some square. This is the change of some square by comparing the model like this is the answer for some we are,

285
00:35:54,730 --> 00:35:59,440
but adding actually into the model that already has X1.

286
00:36:00,490 --> 00:36:10,240
And that's what this knowledge means. So this is SS are out to veto one minus SS arms.

287
00:36:10,550 --> 00:36:13,540
They don't want to look at the difference,

288
00:36:13,750 --> 00:36:22,239
the change or the increase in terms of the regressions on the square by any actual improvement over the House of X.

289
00:36:22,240 --> 00:36:28,310
What? To the other words, compare the model that we've of this.

290
00:36:29,370 --> 00:36:38,690
To the model that would last, and I see how much the samples were changed and then divided by his car's volume.

291
00:36:38,710 --> 00:36:46,410
You are free to list your freedom. Here is just the number parameters that are going to test each order of abilities.

292
00:36:47,050 --> 00:36:56,290
That's P2. So we're able to assess that the beta two is a zero actor will be the two has P2 variants.

293
00:36:56,850 --> 00:37:10,620
So that was what the direct freedom here. And then the denominator of this is, well, MSI for alternative model, among other alternative policies.

294
00:37:11,400 --> 00:37:17,910
So and is the more freedom, as we have seen many times,

295
00:37:18,180 --> 00:37:25,440
is do our freedom is at minus P and because for the full model for for this larger law this is the model under

296
00:37:25,830 --> 00:37:33,230
alternative others it's just this is a longer model for a longer model that you are afraid of before the.

297
00:37:33,240 --> 00:37:38,220
And I see that. Yeah. Minus P minus the total model in the model.

298
00:37:39,120 --> 00:37:45,030
So that's, that's the degree of freedom associated with this single happy single square.

299
00:37:45,450 --> 00:37:51,050
And that's what we were from here. The denominator you're afraid of.

300
00:37:51,510 --> 00:37:53,060
So this is what the outcome of.

301
00:37:53,550 --> 00:38:02,040
So here, I mean, in a slide and we never I mean, well, sometimes we didn't make this explicit, but this this fusion follow this.

302
00:38:02,340 --> 00:38:09,900
This is always under liabilities. So assuming I have a this is is true was F who follows evidence fusion.

303
00:38:16,980 --> 00:38:27,450
Okay. Any questions so far? Okay.

304
00:38:27,510 --> 00:38:32,130
That's an example. Now let's take a look at another example. You'll see a bunch of examples.

305
00:38:32,910 --> 00:38:44,100
Another example is now here we have of we are writing this this Y in terms of intercept and all the other covariance.

306
00:38:45,360 --> 00:38:50,429
So we have P minus one community. So in total we have PBS plus this intercept.

307
00:38:50,430 --> 00:38:56,040
So we have paid us and we will do pass whether all these betas are equal to zero.

308
00:38:56,040 --> 00:39:02,610
We have seen this. This is but now this is just written in terms of matrix, in terms of actors, image, major matrix.

309
00:39:04,830 --> 00:39:12,600
So we're interested in terms of whether this whole back from Beta one is equal to zero versus well,

310
00:39:12,660 --> 00:39:16,760
this is not a zero by four, which means at least one component is not equal to this.

311
00:39:17,640 --> 00:39:26,130
And again, we are casting well here. We can draw out statistic this is not change in error sum in sum of square.

312
00:39:27,360 --> 00:39:37,830
When we add this X into the model that has only intercept where we compare the model without all these covariates.

313
00:39:38,190 --> 00:39:42,870
Oh sorry. We compare the model that have all these covariates versus a model that.

314
00:39:43,850 --> 00:39:51,130
All right. We compare our model while on not this is we have a model that does not have any obvious covariance.

315
00:39:51,370 --> 00:39:58,280
That's a smaller model. We compare that model with the moto under alternative that I have that has all these cameras included.

316
00:39:59,100 --> 00:40:07,829
So we see how how much change in terms of the sample squared and divided, what standardized were normalized by the car.

317
00:40:07,830 --> 00:40:19,680
But what does not is how many parameters you are you have on other models that is p minus one and then divided by single one square.

318
00:40:19,710 --> 00:40:25,260
This is actually under alternative model under the larger model and is the driver.

319
00:40:25,260 --> 00:40:31,780
Freedom is again minus P. So.

320
00:40:33,550 --> 00:40:39,640
And this this gas that that is exactly the same as we've seen before.

321
00:40:40,300 --> 00:40:46,870
This is because this now what this is put to task, whether all these betas are simultaneously equal to zero.

322
00:40:47,500 --> 00:40:51,940
So okay.

323
00:40:51,940 --> 00:40:59,650
So that is another example. And then the third example here, so we are interested in testing.

324
00:41:00,010 --> 00:41:05,710
Now we have two blocks of of X, two blocks of X.

325
00:41:05,830 --> 00:41:13,110
And we are interested in testing whether the first block this beta one is equal to.

326
00:41:13,120 --> 00:41:18,640
There is a zero backtrack has another and this is a zero back and this dimension is p one.

327
00:41:21,530 --> 00:41:28,280
In this case, if we put no heaters out in the actual well, we simply write it as X to a star.

328
00:41:28,310 --> 00:41:30,200
This is just location for convenience.

329
00:41:30,560 --> 00:41:39,950
So we've put an intercept events to together and a similar we put a beta zero and a beta two together and then the F statistic values.

330
00:41:40,430 --> 00:41:44,210
Well, the change is somehow square or the result square.

331
00:41:46,140 --> 00:41:53,379
Well, we had. Well, we know that because we're testing beta one you see to zero.

332
00:41:53,380 --> 00:42:03,520
So well we add X one into the model computer well into the model that already has the intercept and adds to.

333
00:42:04,860 --> 00:42:07,410
We see how much someone's got to change.

334
00:42:07,830 --> 00:42:17,129
Right and standardized by its corresponding to our freedom one which again is the number of parameters of the first to be equal to zero on or not.

335
00:42:17,130 --> 00:42:24,990
But this is as people divided by you square off on the second square.

336
00:42:25,470 --> 00:42:29,520
Under our alternative policies, yens and minus freedom of reading.

337
00:42:31,830 --> 00:42:37,320
So this is another example of how the statistic is constructed.

338
00:42:38,160 --> 00:42:45,910
Okay. And then one more example. So if we look at the single Colvera test.

339
00:42:47,460 --> 00:42:53,520
So here I say that we have x one and that's 2x1 is just a screen, just one there.

340
00:42:53,880 --> 00:43:05,850
I'm not about but as two is maybe a block of covariance and we are interested in testing whether this particular beta one is equal to zero or not.

341
00:43:05,910 --> 00:43:09,270
So this is just testing a single beta one in the or not.

342
00:43:10,140 --> 00:43:14,640
In this case, the average statistic is the change in some of the square.

343
00:43:15,270 --> 00:43:25,679
Well, we add x one this particular x one into the model that already has all the other covariates in the bottom right of the model that

344
00:43:25,680 --> 00:43:34,120
it already has all the other queries and we see how much someone's aware of increases and then divided by the bigger freedom.

345
00:43:34,140 --> 00:43:40,500
But here we need an explicit writing because we earth is just equal to 100 odd.

346
00:43:40,650 --> 00:43:45,270
So you're just testing one data. So but still, I mean,

347
00:43:45,270 --> 00:43:50,459
we need to be very clear that there is a degree of freedom divided on the part of the

348
00:43:50,460 --> 00:43:57,110
numerator and that here we have seen one square hatching that you are afraid of is image.

349
00:43:59,240 --> 00:44:05,210
So this is the absolute stick. Now, this recall out of this statistic is actually equal to t square.

350
00:44:05,760 --> 00:44:09,230
And so testing for a for a single covariate, for a single beta.

351
00:44:09,500 --> 00:44:18,300
And we can now t test and and test the equivalent of a recall that he has is constrained by it in this way.

352
00:44:18,380 --> 00:44:26,600
So we look at an estimate divided by this center area, and this one follows a tedious fusion with freedom or freedom.

353
00:44:27,170 --> 00:44:33,170
But we know that the square of T is actually equal to a less F with fewer freedoms.

354
00:44:33,520 --> 00:44:43,999
One. Okay. So the key, this fusion can be used to test both one sided and two side.

355
00:44:44,000 --> 00:44:48,130
You have others so that can be used to test such alternative.

356
00:44:48,620 --> 00:44:54,230
Of course not, because is always the same. This has not been a100 but alternative.

357
00:44:54,770 --> 00:45:02,030
Well, it could be based on one not able to zero within a one larger than zero or better one smaller than zero or

358
00:45:02,030 --> 00:45:10,040
the tedious where can be used to test a few studies that can be used to test any of these three hypotheses,

359
00:45:10,910 --> 00:45:18,340
whereas the evidence during can only be used. To pass the will to site hypotheses.

360
00:45:18,710 --> 00:45:24,650
Well, again, we haven't explained this. The reason is that the F is equal to the squirrel.

361
00:45:25,580 --> 00:45:29,660
Now it has two tails. So. So it's symmetric about zero.

362
00:45:29,820 --> 00:45:37,040
So? So he asked. What else? So that's why you can use T to test whether you know that the price is turning into orbit.

363
00:45:37,040 --> 00:45:44,899
It's more than zero. But once you're square, you've got to have this fusion then where a square and then that both the plan to

364
00:45:44,900 --> 00:45:50,420
tail and ride help of the tedious fusion just become right here after solution.

365
00:45:50,840 --> 00:45:58,010
So. So that's why the evidence fusion can only be used to test a two sided hypothesis.

366
00:45:58,790 --> 00:46:04,190
That is to test, you know, being a10 versus beta one, not even zero.

367
00:46:06,320 --> 00:46:12,410
So that's a sort of limitation of or go back and test compared to the test.

368
00:46:17,800 --> 00:46:27,230
Okay. Any questions so far? Okay.

369
00:46:28,490 --> 00:46:31,410
So when we tried to carry out this task.

370
00:46:31,460 --> 00:46:40,550
So now again, consider like this is sort of a general way of writing about this is we look at the general general, the general public is.

371
00:46:40,550 --> 00:46:47,090
And so we are casting whether this beta two is equal to zero versus beta two is not not a not a zero back.

372
00:46:48,050 --> 00:46:53,510
And we need to compute this F statistic, which is what evolve this.

373
00:46:54,320 --> 00:47:04,760
And for a sample squared divided by the degree of freedom and divided by the stock and in principle we could actually fit the two models.

374
00:47:04,790 --> 00:47:08,930
Well, in order to calculate in this recall, two models. One model.

375
00:47:09,350 --> 00:47:15,710
That is the full model. This is this is not you know, this is the model on alternative.

376
00:47:16,190 --> 00:47:26,120
This is the former and this is the model under we now have well, this is this is the reduced model, which is essentially 3D model.

377
00:47:28,460 --> 00:47:38,460
So so one way to carry out of this task is to say to both models on all cover, all of those two models.

378
00:47:38,840 --> 00:47:46,490
And then, of course, you can catch which assets are for both models and you can get as I c for both models.

379
00:47:47,390 --> 00:47:52,700
But then you can look at either the change in as a C or the change it has its

380
00:47:52,700 --> 00:47:59,480
arm that gives you the little extra sample squares by comparing instruments.

381
00:48:00,150 --> 00:48:06,650
And again, you can easily find that you are afraid of an event because you think of the model attributes.

382
00:48:06,650 --> 00:48:14,720
So you can easily get the square error so that once you get only three terms, you can construct out.

383
00:48:14,990 --> 00:48:18,890
So those people can have sort of steep. That's one way, right?

384
00:48:20,810 --> 00:48:30,910
But of course, I mean, it's not really. But in practice, we do not have to.

385
00:48:30,910 --> 00:48:35,230
I mean, if you are given the task like this, you do not have to express faith.

386
00:48:35,260 --> 00:48:38,000
This tomorrow's a good run or recess.

387
00:48:38,520 --> 00:48:48,220
I mean, you will be able to get out of the results almost directly, but maybe sometimes involve slight a calculation, but almost magnitude.

388
00:48:49,330 --> 00:48:54,640
We're able to get a result from the outputs of the outputs, essentially.

389
00:48:55,700 --> 00:49:00,470
Essentially they are based on this are based on feeding this model were based on comparing this to models.

390
00:49:05,190 --> 00:49:09,270
Okay. And then let's try to.

391
00:49:15,050 --> 00:49:23,920
Okay. So here in Alaska, we're going to try to argue and argue why this F statistic.

392
00:49:23,920 --> 00:49:26,920
It follows an artist, fusion, other novelists.

393
00:49:27,490 --> 00:49:31,870
And we able to argue that based on the knowledge we have so far.

394
00:49:32,710 --> 00:49:37,270
But in order to do that. That's right. Errors in terms of the matrices.

395
00:49:37,660 --> 00:49:44,800
Matrices in matters. This adjective similar because even though it involves formatting for me involve you know.

396
00:49:45,940 --> 00:49:51,400
Yeah f chi square it is going to happen. And so it's easier to write everything in terms of matrices.

397
00:49:51,700 --> 00:50:00,120
So the SC the errors are more square. We have already written it as a cognitive work in this.

398
00:50:00,430 --> 00:50:08,620
So from module five, I don't have to tell you exactly.

399
00:50:08,800 --> 00:50:19,490
But anyway, so there there was a module as we wrote and as I see as our correcting for and while that's actually what this is the error,

400
00:50:19,510 --> 00:50:30,220
what we can call both x1x2 in the model. So this had a matrix, this h that is what is based on the whole these are matrix acts.

401
00:50:31,810 --> 00:50:39,820
But if you look at errors, all squares for beta one or for only for the model that only has x one,

402
00:50:40,930 --> 00:50:45,549
then of course it's going to have a konrardy form as well because again,

403
00:50:45,550 --> 00:50:48,670
this is a sum of squared error solving squared, so it's going to have more than four.

404
00:50:49,210 --> 00:50:56,830
The only difference is that now for the Hat, a matrix is different because this model only includes one.

405
00:50:56,830 --> 00:51:06,310
So the Had a matrix is only based on X1. That image was still has the same exact the same structure as this, but it's just a based on x one.

406
00:51:10,120 --> 00:51:21,910
So then if you look at the sum of square, the change of the sum of square, that is what is needed here when we calculate the F statistic.

407
00:51:23,510 --> 00:51:30,979
So if you look out of the channel of some square that is, you know, some square for the 3D model.

408
00:51:30,980 --> 00:51:37,970
What is the area on the square of the former that is the Arizona square?

409
00:51:38,600 --> 00:51:42,220
Well, we have Rita. Just Rita. Does it expressed both in Colorado?

410
00:51:42,320 --> 00:51:48,920
Of course. So it's just that this 194 minus, this one over, we have H-1 here, an edge here.

411
00:51:49,790 --> 00:51:59,030
And then because noticing that here we have y transpose to the lab y transposed to land and y on the right and y on the right.

412
00:51:59,210 --> 00:52:03,590
So we can pull this y transpose in y in the middle.

413
00:52:03,590 --> 00:52:08,300
We have a minus H1 that minus this I minus H.

414
00:52:10,160 --> 00:52:19,500
I. And then we are in a council, so we have H minus H one.

415
00:52:21,560 --> 00:52:28,080
So in other words, we have read have this extra sample square as a quadratic form as well.

416
00:52:28,100 --> 00:52:34,160
So it is also organic form and then.

417
00:52:37,230 --> 00:52:40,780
Okay. And then. Okay.

418
00:52:41,370 --> 00:52:49,760
So the F statistic, this is some square divided by the geography, divided by the sigma at end of.

419
00:52:52,320 --> 00:52:58,770
And while the sigma has square, this is Argentina as a city divided by is corresponding to our freedom.

420
00:52:58,800 --> 00:53:04,870
And this is just how C++ squares is defined, where MSA is defined as i c divided by eight.

421
00:53:05,490 --> 00:53:10,500
And then we have we just have expressed this as this corner four.

422
00:53:11,640 --> 00:53:16,260
And this one is already formed. This is from module F.

423
00:53:18,750 --> 00:53:27,000
So in other words, we see now that a canvas that is the Cameroonian mass this already four divided by is corresponding to our freedom.

424
00:53:27,390 --> 00:53:30,660
And in this area four divided by is corresponding to our freedom.

425
00:53:32,700 --> 00:53:38,040
So then in the maps, we'll take a break.

426
00:53:38,040 --> 00:53:42,300
But and that's what we are going to do is to show that growth already.

427
00:53:42,990 --> 00:53:47,040
For us, we follow Chi Square as usual and we are independent.

428
00:53:48,960 --> 00:53:51,960
And then of course we have a square divided by Chi Square.

429
00:53:52,470 --> 00:53:58,050
And if the square of the Independent, then this absolute is the we'll follow in this field.

430
00:53:58,950 --> 00:54:01,270
And so that's what we're going to do next.

431
00:54:01,290 --> 00:54:12,779
But we are let's take a five minute break, because this is all there's a lot of things that you need to be covered in the staff.

432
00:54:12,780 --> 00:54:18,671
As little as five minute break should not be shown to be strange reflections on a short term.

433
00:54:28,537 --> 00:54:39,007
And I think we need to cover the rest of the materials hopefully by the end of this, like, okay.

434
00:54:39,277 --> 00:54:45,457
So as we mentioned, now we want to argue that you will discuss that as follows.

435
00:54:45,467 --> 00:54:48,907
ET was using alternate realities in order to do that.

436
00:54:49,837 --> 00:54:56,417
We first what we look at, if we divide the topic both top and bottom by the same square.

437
00:54:56,737 --> 00:54:59,937
Right. And then we've got let's not share the statistic.

438
00:55:00,757 --> 00:55:08,407
And then if we are able to argue that in the COB here divided by the sequence where it follows cause word is version,

439
00:55:09,067 --> 00:55:12,637
and if the bottom the denominator follows because of our decision.

440
00:55:13,057 --> 00:55:22,117
And if we are able to argue that the numerator and denominator are enhanced, then we then have to follow the story.

441
00:55:22,307 --> 00:55:25,777
Now, that's the three things that we need to argue next.

442
00:55:27,457 --> 00:55:34,357
So this this large as the sketch of the crew and let's go over this together.

443
00:55:36,217 --> 00:55:39,527
So for the for the denominator.

444
00:55:39,547 --> 00:55:47,947
So one thing. Okay. So one thing is that we want to show this ball or chi square that has been divided as soon as we're all chi square.

445
00:55:48,247 --> 00:55:53,677
And we have shown this in module F. If you go back to one module F, you will you will definitely see this.

446
00:55:53,917 --> 00:55:56,947
So this one follow chi square exposure. So this is already done.

447
00:55:57,367 --> 00:56:01,237
Okay. This is so that means that this is done.

448
00:56:03,037 --> 00:56:07,357
This is done. Okay. And then let's focus on this part.

449
00:56:07,537 --> 00:56:15,307
Right. This part for Chi Square distribution. And this part is already a form of the matrix in the middle.

450
00:56:15,307 --> 00:56:26,766
That's H minus H once. And first we see that H minus H one is symmetric and important and it's symmetric.

451
00:56:26,767 --> 00:56:31,897
It's very easy to see because both H and H one. There are some that have had a matrix how matrix is heading.

452
00:56:32,377 --> 00:56:35,877
So the difference is symmetric is item code.

453
00:56:35,887 --> 00:56:39,397
And it's also very easy to see because let's just do a calculation.

454
00:56:39,727 --> 00:56:44,947
So we just calculated the square of this matrix and is equal to that.

455
00:56:44,947 --> 00:56:48,267
If you separate the square, it becomes a square plus.

456
00:56:48,307 --> 00:56:53,467
It was square the minus two times the plus product.

457
00:56:55,557 --> 00:57:00,027
And then because hey, she and each one both are had emergencies.

458
00:57:00,507 --> 00:57:04,377
So then the square and a square there just equal to age.

459
00:57:04,587 --> 00:57:07,587
And each one because they are both are.

460
00:57:07,587 --> 00:57:18,707
I don't know it. And then for this guy now here we're just explicit writing out this one matrix.

461
00:57:19,877 --> 00:57:29,417
It's one kind of matrix. It's just inwardness. And then by noticing that age times X1 is equal to X1.

462
00:57:29,867 --> 00:57:34,767
So here by now, I think we should be quite familiar with some of the results we have.

463
00:57:34,797 --> 00:57:39,017
We have used this sort of resource quite a few times.

464
00:57:40,547 --> 00:57:51,127
So. This is because h x is equal to x by the definition of h age matrix.

465
00:57:51,297 --> 00:57:59,997
Age X is equal to x and x1 is just a subset of x so that h times x one is equal to x one.

466
00:58:01,957 --> 00:58:09,937
And if any type of X1 is equal to X1, then that means, well, for this matrix, there's this whole thing.

467
00:58:10,087 --> 00:58:17,617
If you just look at this product first, this gives us X1, it was, this gives us X1.

468
00:58:17,877 --> 00:58:22,747
But this whole thing becomes the same as X1 comes to rest.

469
00:58:23,507 --> 00:58:28,077
Now, this is precisely what each one is one that matrix H1 is.

470
00:58:28,417 --> 00:58:31,987
So in other words, this whole thing, this is just a H1 matrix.

471
00:58:34,247 --> 00:58:42,347
Okay. I'll. So this isn't usual matrix.

472
00:58:42,377 --> 00:58:49,067
Then the plus H1, the minus two H1. So we have then you have this H minus H1.

473
00:58:49,727 --> 00:58:53,927
So this actually shows that the square of it is just equal to yourself.

474
00:58:54,497 --> 00:59:07,177
So this shows that H minus H1. This is I don't know that this is just purely algebra showing that it is on.

475
00:59:07,217 --> 00:59:14,447
And then for our component, we know that the rank is equal to increase the rank.

476
00:59:14,597 --> 00:59:23,777
The difference is it will create a little difference. And also, we know that trivial difference is the difference of the of the two visits.

477
00:59:24,797 --> 00:59:30,017
So for an appropriate matrix, we know the entries is equal to this dimension.

478
00:59:30,537 --> 00:59:35,687
Sorry, sorry. No division. We have calculated the trace of h like in module.

479
00:59:36,287 --> 00:59:51,047
Module F is equal to P, the number of column of x and then the similarly the trace of h one that is P one that is the column of x1.

480
00:59:51,347 --> 00:59:59,877
That is our matrix x1. And then the differences is that the difference is that the measured max to.

481
01:00:01,667 --> 01:00:04,937
So that's the wreck of the item. Golden Matrix.

482
01:00:08,617 --> 01:00:16,146
And then we. Okay. So the reason what we are actually using is here is this one.

483
01:00:16,147 --> 01:00:20,947
So maybe this is the reason we are trying to use right here.

484
01:00:20,947 --> 01:00:30,097
We have already for. We have a lot of work and we are trying to assure that of this because of our distribution.

485
01:00:30,817 --> 01:00:39,317
And while here, a lot of people are fed up, we just calculated now is it not central square with the Central D parameter equal to this?

486
01:00:39,367 --> 01:00:53,307
Now, let's calculate this this prompter number, you know, so probably the parameter is equal to nil, which is an exponential y transpose times.

487
01:00:53,317 --> 01:00:56,647
Here is view and then the matrix in the middle.

488
01:00:59,567 --> 01:01:03,197
An older null hypothesis. Well.

489
01:01:03,257 --> 01:01:06,667
Well, this has been a tool is equal to zero.

490
01:01:07,387 --> 01:01:11,317
Now under not hypothesis. Now theta two is equal to zero.

491
01:01:12,307 --> 01:01:22,687
The entire region of Y. So under this, this implies that a stage of y is equal to just x1 times speed of one.

492
01:01:24,887 --> 01:01:28,487
Because X too is equal to zero or below two is equal to zero.

493
01:01:29,777 --> 01:01:35,597
Right? A model is recall that a model is the model we are looking at.

494
01:01:38,157 --> 01:01:41,187
The model we're looking at is x one.

495
01:01:41,877 --> 01:01:45,537
That's 2x1 being one plus. And so they're two plus hours.

496
01:01:46,407 --> 01:01:52,137
But on arrival, this is there not. Wilson says that theta two is equal to zero.

497
01:01:53,127 --> 01:02:00,687
So between zero zero alternate uses. Now, of course while under novelists examination is just x one has been almost.

498
01:02:02,087 --> 01:02:07,437
So that's why we have here. We have. Israeli agents.

499
01:02:07,477 --> 01:02:16,357
Explain to me what under the auspices that if we replace the despised x one better one replace those by x one better one.

500
01:02:17,757 --> 01:02:21,597
And then we see this is equal to zero. The reason is that, okay,

501
01:02:21,597 --> 01:02:29,006
so if we focus on the product of this because this is matrix part it so matrix

502
01:02:29,007 --> 01:02:33,687
multiplication so we can actually arbitrarily combine the order of the different measures.

503
01:02:33,687 --> 01:02:38,027
It's when we travel with the product, then we look at this first.

504
01:02:39,267 --> 01:02:43,767
This gives us hx1 minus h1x1.

505
01:02:46,247 --> 01:02:51,537
Right. And then each times x1 is X1.

506
01:02:52,987 --> 01:03:02,497
And each one times x one is also x one. So this gives us to do it again using the property of the had a matrix.

507
01:03:06,547 --> 01:03:15,096
And so evolution. Or then of course, once you have a zero factor like for matrix multiplication that everything well then then fine.

508
01:03:15,097 --> 01:03:19,867
And finally when you get to zero. Right.

509
01:03:20,167 --> 01:03:24,717
So. So you are the worst about the nursing program, true or not?

510
01:03:24,757 --> 01:03:28,867
Well, this is. Is equal to zero. Is equal to zero.

511
01:03:29,827 --> 01:03:36,487
So if we put all these things together and then if we use this result.

512
01:03:38,857 --> 01:03:43,537
So here if asymmetric and I had a loaded with around a P,

513
01:03:44,527 --> 01:03:54,547
then this quadratic form follow chi square would be working with a p and A with Nasser I would have round around and we just show that,

514
01:03:54,817 --> 01:03:58,027
you know, our pay matrix now is H minus H one.

515
01:03:58,537 --> 01:04:04,777
We just show that H minus H one that is symmetric and important and a rank is equal to P2.

516
01:04:06,457 --> 01:04:11,947
And so this should follow chi square just fusion with the word freedom p p2.

517
01:04:13,557 --> 01:04:18,597
A member we just saw is equal to zero. So.

518
01:04:19,347 --> 01:04:30,297
So then by making use of this result, we should show the first, you know, the first, the first result here.

519
01:04:31,927 --> 01:04:36,757
And so this guy follows for his own uninformed view on housework.

520
01:04:36,997 --> 01:04:44,437
And it would be. And of course here we need to keep in mind this is our problem is it's.

521
01:04:47,807 --> 01:04:52,847
So we have shoulders. So even next, we need to show that, you know,

522
01:04:53,057 --> 01:04:58,517
the numerator and denominator they are independent to cut square does usually are invalid

523
01:05:00,227 --> 01:05:06,497
in order to show they are independent again we are using for making use of the the result.

524
01:05:06,707 --> 01:05:14,927
So two quadratic forms are independent. If the matrix is in the middle A and B if the product is a zero matrix.

525
01:05:16,247 --> 01:05:23,357
So in other words, we just need to show that the matrix in the middle age, minus H1 and minus H.

526
01:05:25,777 --> 01:05:35,497
All of the product is equal to zero. And again, this is just in some areas where I saw the product is equal to.

527
01:05:35,617 --> 01:05:47,977
Now, if you separate the product. So I've got to multiply this by age and then multiply this by its sheet as well.

528
01:05:48,277 --> 01:05:54,547
So then I have I'm sorry. I'm going to multiply, but I don't know, do you want to do this?

529
01:05:54,817 --> 01:06:00,247
And then I will go to minus H multiplied by by the second difference.

530
01:06:00,847 --> 01:06:08,887
So not only multiplied by those that is age minus H1, the minus this age multiplied by the s that is minus.

531
01:06:08,887 --> 01:06:13,637
H square once. H times h one. Okay.

532
01:06:14,117 --> 01:06:18,317
And then again, because h h is either potent.

533
01:06:18,497 --> 01:06:24,677
So H Square is equal to H. Right.

534
01:06:24,687 --> 01:06:29,487
And about age. Age one is equal to age one.

535
01:06:29,847 --> 01:06:33,337
That that is precisely what we have shown.

536
01:06:33,357 --> 01:06:41,067
So this this age here times this age, one is equal to age one.

537
01:06:44,427 --> 01:06:51,737
That. So. So in the end.

538
01:06:51,747 --> 01:06:58,077
But then we have, you know, the end line as H council minus H one plus one cancels.

539
01:06:58,087 --> 01:07:03,417
So yeah, we have a zero matrix. Okay.

540
01:07:03,687 --> 01:07:09,777
So this shows that eight times B is a zero matrix, then it shows that of the true cognitive force.

541
01:07:09,777 --> 01:07:18,567
We are independent, so that means we have trawled the sky before that.

542
01:07:18,807 --> 01:07:27,297
So with all the three facts. The F should follow and evidence fusion.

543
01:07:29,227 --> 01:07:37,337
Okay. So. Under the three.

544
01:07:47,067 --> 01:07:52,127
F follow f this vision was key to your freedom.

545
01:07:52,427 --> 01:07:56,847
Your mind is. Again, we have to be very, very clear.

546
01:07:56,847 --> 01:08:02,457
This is under novelists. So assuming hypothesis is true.

547
01:08:03,197 --> 01:08:11,797
F We'll follow after inspiration. Okay.

548
01:08:11,797 --> 01:08:19,626
So I know that we went over the algebra, you know, the arguments of these three things very quickly.

549
01:08:19,627 --> 01:08:22,987
So. So it's.

550
01:08:24,767 --> 01:08:28,827
It's okay if you have questions or.

551
01:08:29,647 --> 01:08:34,297
Yeah. But first, let me ask, are there any questions about this algebra?

552
01:08:42,457 --> 01:08:50,467
I think so because of the time restriction, we do not have time to really to get him to like a very,

553
01:08:50,467 --> 01:08:53,526
very detailed calculation of the all these things.

554
01:08:53,527 --> 01:08:59,867
But these are algebra. I think if after like lecture, if you spend 15, 20 minutes trying to go over.

555
01:09:00,277 --> 01:09:04,237
So we went over the major the major staffs later completions.

556
01:09:04,657 --> 01:09:16,267
So every likely to spend like ten or 15 minutes, try to follow all the steps, you should be able to get a very clear picture why all these are true.

557
01:09:17,587 --> 01:09:21,727
All of these still work if you include beta zero in the model.

558
01:09:23,867 --> 01:09:31,157
Oh. Well, first of all, the answer is definitely yes.

559
01:09:31,247 --> 01:09:36,917
So all this should definitely work, if we can call it better.

560
01:09:37,577 --> 01:09:48,497
But I was hesitant because I was thinking because I see all these actually, although we didn't make it explicit.

561
01:09:48,497 --> 01:09:55,367
But all these ads really do include Britain's been, as it were.

562
01:09:55,367 --> 01:09:59,147
Here we were we didn't really expect to talk about Benazir.

563
01:09:59,927 --> 01:10:05,447
Right. Well, there are two reasons. One reason is that you are we do not care that much about babies.

564
01:10:06,437 --> 01:10:14,827
So Benazir is intercept opium. You know what we care are the effects of some certain covariates like age.

565
01:10:14,837 --> 01:10:22,207
Gender is a coherent intercept is something that we we want to include all of them all including including the auto,

566
01:10:22,577 --> 01:10:27,677
you know, to improve the performance of the loan. But we really do believe that India's having a zero.

567
01:10:28,577 --> 01:10:32,747
You know, there is an intercept. So we need to include it in the model to improve the performance.

568
01:10:33,347 --> 01:10:37,697
However, rarely do we care about, you know, what exactly being a zero is.

569
01:10:38,547 --> 01:10:42,437
And that's one reason that we didn't explicitly talk about zero.

570
01:10:43,007 --> 01:10:50,867
So another reason here is that if you look at the formulation of the model here,

571
01:10:50,867 --> 01:10:58,677
all you could actually consider beta zero is implicitly historically to look at it.

572
01:10:58,727 --> 01:11:04,417
So we didn't make a you call to consider, you know, X1 inclusion of the first column as as the constant.

573
01:11:04,427 --> 01:11:09,377
I got my column once then automatically that has been a zero will conclude about interest.

574
01:11:10,267 --> 01:11:14,197
And so that's another reason why we do not have to expose title.

575
01:11:14,977 --> 01:11:19,227
But the whole thing definitely works. If you if you consider it.

576
01:11:26,437 --> 01:11:37,897
Okay. Any other questions? Okay.

577
01:11:39,617 --> 01:11:44,057
So then. Let's take a look at.

578
01:11:45,287 --> 01:11:51,707
Okay. So that is some algebra. So again, the algebra is important,

579
01:11:51,707 --> 01:11:59,087
but we do not want to spend too much time in it using our life time to go through like a very, very detailed calculation.

580
01:11:59,627 --> 01:12:11,717
So it becomes details. So I think it's a better use of leisure time to look at ideas and the sending of different concepts and the results.

581
01:12:12,767 --> 01:12:16,487
So we talk about a sequential versus partial casting.

582
01:12:18,827 --> 01:12:26,327
So now let's take a look at like when you look at how do we determine welfare tomorrow?

583
01:12:26,357 --> 01:12:30,947
How do we determine whether we should see tomorrow in a sequential way work or carried out a

584
01:12:30,957 --> 01:12:36,767
squirrel kind of thing where part of casting and this is largely based on the scientific interest.

585
01:12:37,337 --> 01:12:48,587
So there is no unique or general rule of saying that you have to consider a square pass first or you have to consider a partial past first.

586
01:12:48,897 --> 01:12:53,117
And so it is largely driven by the single question on the interest.

587
01:12:54,197 --> 01:13:05,657
It also depends on the aim of the investigator. Right now, if we consider such a model that has three X on the partial, that's.

588
01:13:08,007 --> 01:13:17,666
Irma pass. But you must hopefully have all our archives that try to answer all the questions in the following form.

589
01:13:17,667 --> 01:13:23,077
So does x one contribute to the model or implementation?

590
01:13:23,097 --> 01:13:26,757
Y Given that both as two and three already in the model,

591
01:13:26,907 --> 01:13:36,027
and that's what a partial hypothesis is that has whether you know this covariate x1 really add.

592
01:13:37,187 --> 01:13:46,307
Any really improved explanation will try to explain that there isn't one compared to a model that already has the other two commitments.

593
01:13:46,997 --> 01:13:55,177
This is a partial, partial testing and a similar you can allow you can ask the question for whether it's true.

594
01:13:56,237 --> 01:14:05,067
Explain the variation why compared to a model that has already already has x one and three in a model and similar age,

595
01:14:05,417 --> 01:14:11,417
you can have three and then compare for a model that already has excellent actually in the model.

596
01:14:11,687 --> 01:14:20,147
So this is the first test. So to answer the question whether one particular covariate or one particular subset of covariates,

597
01:14:20,537 --> 01:14:28,667
whether that helps explain their reason why if we have already included the other sets of subsets of covariates,

598
01:14:30,257 --> 01:14:38,147
and if our partial tests or x ones, we actually compare.

599
01:14:41,607 --> 01:14:44,787
4x1, but so does Dick.

600
01:14:45,267 --> 01:14:55,947
As we look out to the X for some of the square by adding x one in the model that already has the intercept and the other two callbacks.

601
01:14:56,697 --> 01:15:01,977
And if you want the right edge, but not in terms of beta, but in terms of the covariates,

602
01:15:02,427 --> 01:15:11,667
then it's the address of one square away at x one in the model similar to the model that R2 has x two and X3.

603
01:15:12,447 --> 01:15:16,256
So here while you run in terms of the covariates, you are two.

604
01:15:16,257 --> 01:15:24,566
We do not need to make it explicit back to the intercept. The way we're right in terms of beta you are that we make the intercept explicit so model

605
01:15:24,567 --> 01:15:31,367
has intercept but when you have covariates usually we well I mean we do not have to add a,

606
01:15:31,377 --> 01:15:38,576
for example, a causal one here. So there is no need to do that.

607
01:15:38,577 --> 01:15:43,857
I mean by by writing this request to think about this model that Ana has intercept.

608
01:15:46,377 --> 01:15:50,247
Okay. And this one it follow is to follow evidence fusion.

609
01:15:50,727 --> 01:15:57,477
So the numerator your freedom equal to one. The reason is that we have just added additional data into the mode.

610
01:15:58,157 --> 01:16:02,837
So that's that's why it the girlfriend is equal to one end of the denominator.

611
01:16:02,837 --> 01:16:06,047
Do our freedom on that is how many.

612
01:16:06,047 --> 01:16:10,936
Well yeah. Minus P feeding is how many paid us in total you're not full.

613
01:16:10,937 --> 01:16:22,217
But in this case if you look at the model we're looking at, it has one, two, three, four babies has four betas, so p014.

614
01:16:23,087 --> 01:16:26,177
And that's why here we have minus four.

615
01:16:26,957 --> 01:16:31,007
This is generous being this piece number of betas.

616
01:16:34,517 --> 01:16:38,987
So this is 4x1 and then 4x24x2.

617
01:16:39,527 --> 01:16:46,727
It is similar i so the sum of squares when you add x two in the model that I've heard, it has x one and x three.

618
01:16:48,947 --> 01:16:59,237
You can write it again in terms of the betas for in terms of clearance and it follows the same you have this fusion under novelist's it's.

619
01:17:05,127 --> 01:17:17,337
Okay. And then here the denominator, the CMA square is CMOs where they're using this is always the least squared error under the larger one.

620
01:17:17,967 --> 01:17:20,487
Under the phone you can see my square.

621
01:17:20,877 --> 01:17:31,227
It's always is always the Sigma Square have based on this larger argument or in other words, the more or under 35 of the six.

622
01:17:34,057 --> 01:17:39,146
But this is this is very important. So this is this is very important.

623
01:17:39,147 --> 01:17:46,017
So this seems where the denominator is always the estimate, as estimates were in the full model.

624
01:17:47,847 --> 01:17:52,167
Because here we do have motive for supermodel murder motive.

625
01:17:52,587 --> 01:17:57,167
So we have to keep in mind the sea must wear here. This is not the sequence we're asking.

626
01:17:57,177 --> 01:18:06,887
Is this seamless work for. Okay.

627
01:18:07,307 --> 01:18:14,057
And another example of the protest is to look at the weather from the previous examples.

628
01:18:14,057 --> 01:18:19,006
They were about a single a single quarter X and of course,

629
01:18:19,007 --> 01:18:27,197
in the part of parts can look at multiple X, for example, still using the previous inversion example.

630
01:18:27,197 --> 01:18:39,137
So that's a modal test whether a 2 to 3 are simultaneously equal to zero or this is to look at the change in some of the squares.

631
01:18:39,467 --> 01:18:45,767
Well, we've got a fourth x2x3 into the model that already has x one.

632
01:18:47,087 --> 01:19:00,917
And of course, the intercept of in this case in this case, notice that here we have two is expensive so divided by the of freedom of the numerator.

633
01:19:01,277 --> 01:19:09,647
That is true because here we are forecasting and our listeners might have some idea this two bits are simultaneously equals zero.

634
01:19:10,187 --> 01:19:17,147
So that's right here. The numerator is repeat this is equal to two divided by two cannot be not major.

635
01:19:17,477 --> 01:19:25,817
Again, this is sigma how to square this is the estimate is to see them squared under the alternative model under the full one.

636
01:19:29,437 --> 01:19:36,006
And so now it follows our distributions. Now the numerator due to our freedom is to give.

637
01:19:36,007 --> 01:19:40,847
Because here we have to bait us under this list.

638
01:19:40,927 --> 01:19:46,647
That is, to beat us are equal to zero. And a numerator and denominator to work me down.

639
01:19:47,487 --> 01:19:52,017
So yes, it was p or p is the total number of betas in the full model.

640
01:19:52,977 --> 01:20:03,427
It is four. Okay.

641
01:20:04,627 --> 01:20:12,367
And this is a partial test. And now let's look at take a look at one example.

642
01:20:18,707 --> 01:20:27,317
We are one example of this. So let's say that we are the response why is systolic blood pressure?

643
01:20:28,747 --> 01:20:32,167
Right end of the coverage. We have aid, we have way, we have height.

644
01:20:33,787 --> 01:20:40,987
And the model is the full model where the model increase is actually what we want to see.

645
01:20:41,467 --> 01:20:50,557
The model that has that includes all the three covariates and let's say that all queries are of equal interest.

646
01:20:50,887 --> 01:21:00,516
So, so we will have to make assessment of the effect of, or association between SBP and all of these covariates.

647
01:21:00,517 --> 01:21:05,917
There is no emphasis on any of these covariates on the importance.

648
01:21:07,177 --> 01:21:15,127
And we all recognize the importance of each covariate address for the others, and there is no particular order of task.

649
01:21:15,937 --> 01:21:20,947
So in this case, we need to carry out the so called turtlenecks,

650
01:21:21,667 --> 01:21:26,496
particular because there is we are clear that there is no particular order on

651
01:21:26,497 --> 01:21:35,707
the test is obvious because they are of equal importance of equal interest.

652
01:21:37,027 --> 01:21:50,107
So to carry out the partial test, let's say for age, no, for age we are interested in testing whether you have a is equal to zero or not.

653
01:21:52,077 --> 01:21:58,317
And so and because we're casting a single beta in this case the beta corresponding to age.

654
01:21:58,677 --> 01:22:06,357
So we can use either in our test or a key test because here we're looking at a two sided alternative.

655
01:22:06,657 --> 01:22:14,307
So P and F, they are equivalent. So we can we can use either avatars to repeat has so far f past.

656
01:22:14,427 --> 01:22:26,187
But I have a statistic that is a change in sum of squares what we had age into the model that already has the intercept the weight spindle height.

657
01:22:27,237 --> 01:22:32,847
And we look at this trend of some square. And then, of course, there is a divided by the divorce rate of one.

658
01:22:32,967 --> 01:22:39,097
But we permitted the one has these because here we are casting the single beta.

659
01:22:39,177 --> 01:22:48,597
Well, that single data is equal to zero or not. And the denominator that is the sigma that is that I see the estimate of Sigma Square.

660
01:22:48,917 --> 01:22:53,907
Under alternative model, the model includes all these three scenarios.

661
01:22:55,437 --> 01:23:07,107
So that is the F said institute. Of all those F with one, your freedom and minus four degree freedom were on your freedom and the key exclusions.

662
01:23:08,067 --> 01:23:09,477
Those are lattice that has D.

663
01:23:09,777 --> 01:23:21,327
It calculates the ratio between the estimate beta hat and its center error and is follow t dispersion with the minus p your freedom.

664
01:23:23,757 --> 01:23:32,837
Okay so these two tasks they are they equivalent, right because F is equal to physically and then you can.

665
01:23:32,847 --> 01:23:38,027
Well, this is just an example for H. And you can, of course.

666
01:23:39,707 --> 01:23:47,267
I've carried out similar tests for hypothesis, you know, for, you know, for for weight and for height.

667
01:23:52,177 --> 01:24:01,336
Well, let's think about it now. We are interested in not being a single body, but we are interested in testing the association due to SBP.

668
01:24:01,337 --> 01:24:07,247
This is the white rhinos response SBP and a subset of covariance adjusted for others.

669
01:24:08,507 --> 01:24:19,727
So for example, we could assess contribution of voting mass by metrics because body mass metrics that wage and a height weight in height,

670
01:24:19,817 --> 01:24:25,937
these are both relating to two volumes. These are both bonus metrics.

671
01:24:26,957 --> 01:24:34,937
So in other words, we want to test whether the collisions for weight and the coefficient for height,

672
01:24:34,997 --> 01:24:44,687
whether these two are simultaneous is equal to zero. So whether the body mass metrics have a strong association with that SBP within the space.

673
01:24:45,947 --> 01:24:48,647
So if this is the scientific question of the interest,

674
01:24:48,827 --> 01:24:55,487
so again here I want to emphasize that the hypothesis how to formulate the hypothesis or what have others who are testing.

675
01:24:56,817 --> 01:25:00,207
I always driven by the scientific question of interest. Now,

676
01:25:00,217 --> 01:25:06,956
it's not like it's not a short of the title called The Club of Hypotheses like others

677
01:25:06,957 --> 01:25:11,367
is how the formula hypothesis should be driven by somebody who has an interest.

678
01:25:11,377 --> 01:25:16,766
Let's say the question of introduce to test to assess the contribution of this Votomatic

679
01:25:16,767 --> 01:25:22,797
metrics and because in this example we have to sort magic's weight and height.

680
01:25:23,187 --> 01:25:35,307
So that is then that leads to the hypothesis that the beta waves and the beta a sort of been a beta height and beta weight,

681
01:25:36,057 --> 01:25:41,727
both are equal to zero versus that at least one of these is not equal to zero.

682
01:25:44,427 --> 01:25:52,237
So to test this hypothesis. Well, again, we look here, we need to construct the statistic.

683
01:25:52,567 --> 01:26:03,607
So it's the change in some of squares. But any way in the into a model that has the intercept and h intercept and h,

684
01:26:04,117 --> 01:26:09,157
you see the change in sample square divided by the corresponding to your freedom,

685
01:26:09,457 --> 01:26:16,356
which is equal to two, because we have to balance our on analysis and of the Sigma Square hand.

686
01:26:16,357 --> 01:26:21,217
Again, this is a sigma squared under the alternative model format.

687
01:26:21,637 --> 01:26:24,637
So on a full order we have four betas.

688
01:26:24,967 --> 01:26:28,157
So that's why here we have come on this for you.

689
01:26:28,197 --> 01:26:38,287
Operator. So this is another example showing that you are able to construct an F statistic

690
01:26:39,067 --> 01:26:46,377
to test a hypothesis always is in a for not a subset of beta are equal crucial.

691
01:26:50,937 --> 01:27:01,467
Okay. Any questions about the partial tests? Okay.

692
01:27:01,887 --> 01:27:05,487
And then let's take a look at some examples about a sequential testing.

693
01:27:06,987 --> 01:27:10,827
So in certain settings, we will actually carry out hypothesis.

694
01:27:11,867 --> 01:27:21,347
In a sequence. In a sequence. And this is a particularly helpful example, very illustrative of the polynomial regression.

695
01:27:23,357 --> 01:27:29,867
For polynomial regression, we have to balance the model fit with interpolation and parsimony.

696
01:27:29,867 --> 01:27:33,287
So this is not only true for one, another one generally is true.

697
01:27:33,497 --> 01:27:36,677
So this comes to the tool, well,

698
01:27:36,677 --> 01:27:44,717
we need to make a balance strike a balance between the interpretation of the whole and the the complexity of the model for parsimony on the market.

699
01:27:45,137 --> 01:27:57,827
So on one hand, we want the model to be complex enough to explain the power of the mechanisms and all the cars behind our data.

700
01:27:58,677 --> 01:28:05,157
On the other hand, we do not want the model to be too complex so that we cannot we do not know how to.

701
01:28:05,787 --> 01:28:09,627
We do not know how to interpret the model. I would still want to have an interpretation.

702
01:28:10,137 --> 01:28:17,157
One of the things that is one of the general, if that is what an association between AVP and the NRA is, for example.

703
01:28:17,457 --> 01:28:24,117
So we do want to have interpretation. So in order to have intervention, we do not want the model to be too complex.

704
01:28:24,957 --> 01:28:31,467
So in other words, we want to keep the sort of personal view of this in a model.

705
01:28:32,937 --> 01:28:44,217
So this is actually about one particular example, is that when we feed a model that we where we are trying to include a polygon in terms in a model.

706
01:28:45,007 --> 01:28:49,407
Right. So if you have reasons to believe that, you know,

707
01:28:49,437 --> 01:28:57,087
the dependance of here in this case does a serum cholesterol Helicobacter this is a BMI body mass index does that mean.

708
01:28:57,357 --> 01:29:08,006
So if you have strong reasons to believe that you know the dependance or the association of serum cholesterol on the BMI is

709
01:29:08,007 --> 01:29:16,677
not a simple linear is why depends on polynomial terms high order terms of BMI then you can definitely build such a model.

710
01:29:17,757 --> 01:29:26,637
However, what would be with such a model? We need to be careful because on the other hand, we want to be able to interpret this model, right?

711
01:29:27,327 --> 01:29:32,037
So for second model year, we want to build it in a sequential way.

712
01:29:33,117 --> 01:29:37,617
So in other words, we do not want to have a model that has no lower order term,

713
01:29:37,617 --> 01:29:42,597
but suddenly we include first, for example, the first power of the BMR.

714
01:29:43,047 --> 01:29:45,357
And this model is really hard to interpret.

715
01:29:46,057 --> 01:29:55,377
So if you have a model that only has BMI, linear term and a fourth make under term five reboot of such a model, it's quite unnatural.

716
01:29:56,037 --> 01:29:58,377
So a more natural way is okay.

717
01:29:58,377 --> 01:30:07,707
So I'm going to first look how this model has BMI alone, and then I'm going to look at what are you add already before returning the model.

718
01:30:08,877 --> 01:30:12,326
And if my model well says that I need a Conrado term,

719
01:30:12,327 --> 01:30:19,737
then I will see whether I need a Cuban to add to this equation rather than suddenly at a higher order term,

720
01:30:20,127 --> 01:30:24,207
make up of a BMI without the lower undetermined amount.

721
01:30:25,677 --> 01:30:29,127
So this is the example we want to carry out this hypothesis sequentially.

722
01:30:32,037 --> 01:30:38,516
So here the particle has this is like for polynomial regression, we will have a higher order.

723
01:30:38,517 --> 01:30:48,687
Terms were found not to be tested in less lower order terms or less significant in our earlier included in the model.

724
01:30:51,407 --> 01:30:54,677
So in this example, we will cast this sequentially.

725
01:30:56,087 --> 01:30:59,777
So first, we're going to look at a beta one.

726
01:31:00,977 --> 01:31:07,667
You know, one is linear. This is the first the first of all, we're not a linear.

727
01:31:08,507 --> 01:31:12,497
We're we're testing when a beta one is equal to zero or not.

728
01:31:13,217 --> 01:31:18,797
We're passing that by comparing it to the bottom that has no BMI included.

729
01:31:18,827 --> 01:31:23,057
So in other words, we're looking at the change of some square.

730
01:31:23,567 --> 01:31:27,047
By adding a BMI into a model that has only intercept.

731
01:31:29,247 --> 01:31:33,447
And we are testing whether that's significant.

732
01:31:37,797 --> 01:31:42,657
So that's that's the first well, that's the first step of this sequence.

733
01:31:42,987 --> 01:31:47,607
The I'll come back to the similar sort of. But but for now, let's just focus on the numerator, the sum of square.

734
01:31:48,507 --> 01:31:56,537
Now, if h zero is rejected, that means, well, beta one is never going to differ from zero.

735
01:31:56,857 --> 01:32:00,927
That means we should include beta one in the mode.

736
01:32:01,167 --> 01:32:05,157
We should include first order remaining alone.

737
01:32:05,697 --> 01:32:11,757
Now we move ahead. We move forward and past whether beta two is equal to zero or not.

738
01:32:13,077 --> 01:32:19,137
And then what? What it means is where it has a now whether beta two is equal to zero or not.

739
01:32:19,917 --> 01:32:24,387
And this sample square we're looking at is the change of some square.

740
01:32:24,417 --> 01:32:34,587
Let's use this whole square by adding a little square in the model that has already included numerous app and the beta one.

741
01:32:36,207 --> 01:32:46,197
And then we look at this change of some square and that of we look at whether we reject of this or not.

742
01:32:46,467 --> 01:32:51,687
So even if zero is rejected, that means this hypothesis is retracted.

743
01:32:52,227 --> 01:32:58,107
That means. Well, we should include squaring the model as well.

744
01:32:59,847 --> 01:33:07,767
And then we move forward. It has a backward level two to test whether beta three is equal to zero.

745
01:33:09,207 --> 01:33:18,327
Now, suppose that out of this step of this step, after this side of the step, suppose that we failed to reject monopolizes,

746
01:33:19,797 --> 01:33:26,867
that it means, well, we do not have strong evidence showing that beta zero is not able to do so.

747
01:33:26,877 --> 01:33:36,507
In other words. Now this square turned small, but the association between FC and the square term is not insignificant.

748
01:33:37,617 --> 01:33:47,477
Then we will stop here. We will not move forward anymore because without including this square, we will not fuller goal go forward.

749
01:33:47,547 --> 01:33:53,847
So we'll just stop here. So this is not like building a model in a sequential way.

750
01:33:53,877 --> 01:34:00,067
This is particular while this is a particularly good example. So it's a long order.

751
01:34:00,087 --> 01:34:03,357
So we only include higher order scenarios.

752
01:34:03,687 --> 01:34:08,067
After we include a short order.

753
01:34:09,387 --> 01:34:14,427
Now let's talk about the CMA square in the denominator.

754
01:34:17,247 --> 01:34:29,487
Here we have a sequence of models. You have a model that has only B, only B, and then you have a model that has both B and a B squared.

755
01:34:30,387 --> 01:34:40,277
And then you have a model that has both B about B, B square and A, B, Q and A, then you have a model that has all this form in a model.

756
01:34:40,287 --> 01:34:45,086
So we have a, a sequence of one, two, three, four models, right?

757
01:34:45,087 --> 01:34:51,867
At least four models. So we have a sequence of four models or maybe five model that has only an intercept.

758
01:34:52,107 --> 01:34:56,607
So we have a sequence of models and each model has a seamless width.

759
01:34:56,727 --> 01:35:02,957
You can, you can, you can estimate MSE for each model as long as you see the model estimate seamlessly.

760
01:35:04,287 --> 01:35:12,627
And for this sequence of models, we need to be very clear that this Sigma Square hat used here,

761
01:35:12,627 --> 01:35:17,607
local forecast, the hosting that is the Sigma Square for the largest amount,

762
01:35:18,657 --> 01:35:22,827
your four largest models that you have in mind in this case,

763
01:35:24,027 --> 01:35:30,387
this is the model that you have in mind and you want to see sequence from the start of this moment.

764
01:35:31,227 --> 01:35:37,227
In this case, then the total number of betas nest one, two, three, four, five, that's five meters.

765
01:35:38,847 --> 01:35:45,357
So while we calculate the CMA square, this, you must wear a hat.

766
01:35:45,417 --> 01:35:48,777
This again, this is not Sigma Square hat.

767
01:35:48,777 --> 01:35:52,137
Owner of a full moon. Our full model, we have five plans.

768
01:35:52,647 --> 01:35:57,267
So that's why here we have. Yeah. Minus five on the can understand.

769
01:35:59,367 --> 01:36:06,707
Okay. So this may seem a little bit strange, but it is not so.

770
01:36:07,557 --> 01:36:13,607
If again, if we go back to the essential idea behind the F test, the F test,

771
01:36:13,697 --> 01:36:19,697
the fundamental idea is to compare two models, a smaller model and a larger model.

772
01:36:21,267 --> 01:36:22,577
Another way to compare it,

773
01:36:22,607 --> 01:36:29,807
to look at the change in terms of summer square or to look at the sample square of these two models or changed of some square.

774
01:36:30,947 --> 01:36:39,496
And we look when we look at the changing sample square, we have to compare that sample square to the aerosol square in order to say,

775
01:36:39,497 --> 01:36:43,487
well, whether that shade of some square is large enough is big enough.

776
01:36:44,967 --> 01:36:52,887
And in this area on the square now don't we make a comparison to that is always the area some square

777
01:36:52,887 --> 01:37:00,867
for the whole period you compare the change of some square to Arizona square for the full moon.

778
01:37:00,897 --> 01:37:06,087
In this case, the full model is. Is this mine?

779
01:37:06,977 --> 01:37:11,047
So that's. That's why he having all these videos this semester.

780
01:37:14,427 --> 01:37:18,077
So this is something we take a little attention to.

781
01:37:21,177 --> 01:37:32,877
And then that of the sequential tests can be carried out for for motive or parameter as well.

782
01:37:33,147 --> 01:37:45,297
So for example, let's say we are interested in testing this novel is not a this is such that the second order of the model artist fits the data.

783
01:37:45,327 --> 01:37:57,027
Good enough already gives us a very good fit. So the translation, like the statistical translation of this, of this statement is that beta three,

784
01:37:57,027 --> 01:38:04,257
beta four, or is it because in this model, look at if you believe that, you know,

785
01:38:04,587 --> 01:38:12,627
including the up to the seven terms if you believe match that already gives us a good enough fit to the data,

786
01:38:13,737 --> 01:38:23,487
then we can test whether this the last two betas, whether these two are impossible, right?

787
01:38:23,637 --> 01:38:27,627
So if these two are equal to zero, that means this this model is good enough.

788
01:38:28,527 --> 01:38:40,477
So this is a case where. We'd have to know whether Peter three has been a flaw or simultaneously close in on versus at least one of these is not able.

789
01:38:41,527 --> 01:38:46,957
And in this case we compare we look out of the chain of some square for adding, you know,

790
01:38:47,437 --> 01:38:56,077
be killed at ab2 power four into the model that already has intercept and b b squared.

791
01:38:56,227 --> 01:39:06,217
We don't get how much of that some one square change. Again, we look at the change of some square compared to the error and some square on the floor.

792
01:39:09,167 --> 01:39:14,657
And of course, here we need to divide it by two because the novel is is this will reinforce.

793
01:39:17,597 --> 01:39:26,567
And that if I will chi square evidence fusion with shooting heart rate up in the numerator and minus five people every major.

794
01:39:31,727 --> 01:39:39,567
All of. Yes.

795
01:39:42,237 --> 01:39:46,347
Yeah. So let's sequential testing now here.

796
01:39:46,347 --> 01:39:49,617
We have to have some test, partial testing here, sequential testing.

797
01:39:50,007 --> 01:39:53,047
So you might wonder like when do we use which?

798
01:39:53,757 --> 01:40:02,127
So it turns out that if you unless you intentionally count SAS or R that A you want to have sequential test.

799
01:40:02,877 --> 01:40:08,427
Otherwise the results output from SAS or are they are partial.

800
01:40:08,757 --> 01:40:17,907
So if you fail tomorrow, let's say if you let's say for example, let's go back to this example here.

801
01:40:17,947 --> 01:40:22,927
I say, oh, this is a typical most of the research once you are given the data, right.

802
01:40:22,947 --> 01:40:32,907
So you you include it in the more or less ever clearer it it turns out that unless you exclude the towel SAS or are not a you like to have sequential.

803
01:40:33,177 --> 01:40:40,227
Otherwise the results the output from sense are all partial based on part of hypothesis.

804
01:40:41,067 --> 01:40:46,377
They are results based on feeding this joint make model of.

805
01:40:46,797 --> 01:40:51,657
So this is by later variable to make this more clear.

806
01:40:51,717 --> 01:40:59,187
But for now I think this is we need to keep in mind that partial testing is the default.

807
01:41:01,007 --> 01:41:02,167
Let's see what you have seen.

808
01:41:02,227 --> 01:41:09,867
Well, you can actually you can definitely carry out a segment of hosting because for sure, not using SAS or any other subject.

809
01:41:10,257 --> 01:41:14,067
But you need to do it. And more explicitly you can tell SAS or aren't explicit.

810
01:41:15,957 --> 01:41:24,297
And also the way to do a sequential testing, if you do it sequentially, then the order of the variables matter.

811
01:41:24,477 --> 01:41:30,537
So later on we'll see an example for like which variables you at first into the model,

812
01:41:30,537 --> 01:41:37,257
you add a cycle into the model, then we have a those task depends on the order of variables you're looking at.

813
01:41:45,217 --> 01:41:51,177
Yeah. Okay. So I think here we see we have two slides before example.

814
01:41:51,487 --> 01:41:55,087
Okay, so let's we have 2 minutes that I think we should have be able to finish this.

815
01:41:55,627 --> 01:41:59,527
This is very important. Well, a subtle but a important point.

816
01:42:01,807 --> 01:42:10,837
So as we mentioned. If we consider now, let's say that we have five covariates.

817
01:42:11,197 --> 01:42:21,287
Five covariates. And let us say that we are interested in testing data to build a theory whether this two are simultaneously equal to zero.

818
01:42:38,087 --> 01:42:44,237
It's easier to exclude rather than so we are has to whether you know this this to our expense and inclusive.

819
01:42:45,927 --> 01:42:51,537
And. Well, if we carried out in a sequential way.

820
01:42:51,747 --> 01:42:58,467
Right. So. So let's say we compare we have this to compare our explanatory to the model that already has intercept.

821
01:42:58,647 --> 01:43:04,107
And that's one. And in this case, we divide it by two because there has to was two properties.

822
01:43:08,377 --> 01:43:15,467
And even if now we are looking at we are comparing like this model like has

823
01:43:15,517 --> 01:43:19,897
we're adding this full coverage to a model that has already has this question.

824
01:43:20,167 --> 01:43:28,327
It seems that so far we didn't really I mean, if you you have to even worry about this tool called errors.

825
01:43:28,707 --> 01:43:39,887
However, however, when we calculate the error, someone squared the error of some square numbers are the errors.

826
01:43:39,967 --> 01:43:49,117
That was where the going on. These were of error. It is still based on the largest model that we are trying to construct is still based on this model.

827
01:43:50,587 --> 01:44:01,177
So this see my how to square the newer field is yeah, minus six because in the learner's model we have six patients among those people among a six.

828
01:44:02,377 --> 01:44:13,896
So see those were how it is calculated based on the formula reason for not in some textbooks apparently the bottom here in our

829
01:44:13,897 --> 01:44:23,557
lecture and in the textbook we are using while we are always using this semester has so much ground because what in some textbooks.

830
01:44:25,537 --> 01:44:27,697
We look at the sum of squares,

831
01:44:29,077 --> 01:44:42,097
we use a star to denote this if they might actually use the sum of squares and aerosol squares for the model that has only theta zero,

832
01:44:42,097 --> 01:44:45,537
beta one, two and obey the three units.

833
01:44:45,607 --> 01:44:56,287
They do not care about the Explorer x five because now again because you are adding x 23, even the borderline has more than one.

834
01:44:56,947 --> 01:45:00,247
So this is some square. It has nothing to do with x score x55.

835
01:45:01,147 --> 01:45:12,547
So sometimes what they might actually use this error example squares and divided by is corresponding to work models for tomorrow's P because you

836
01:45:12,547 --> 01:45:25,687
know you have box for these and this Sigma Square is actually estimating based on the model that has only this three covariance plus an intercept.

837
01:45:27,457 --> 01:45:37,367
Now this is a subtle difference is okay I see that we are already over time so I think we

838
01:45:37,387 --> 01:45:45,397
should you should stop here in Washington because it's taking a few minutes to explain this.

839
01:45:46,387 --> 01:45:57,637
So I think we will start here. And so I think some of you mentioned that, you know, the pillboxes, you know, they probably are there.

840
01:45:57,817 --> 01:46:02,527
So some of you probably didn't find your mailbox there.

841
01:46:03,077 --> 01:46:13,177
Well, if you must say that you didn't find your mailbox because the GSI is either going to accept your object if you do not a cereal box,

842
01:46:13,177 --> 01:46:17,227
you do not have a mailbox there just to send emails to to read.

843
01:46:17,347 --> 01:46:22,357
You want to just be able to schedule a time for you to pick up.

844
01:46:25,297 --> 01:46:25,537
Don't.

