1
00:00:00,330 --> 00:00:12,120
I just got to understand. I think it's because the first ones are starting to make sense for like this is just getting to an all time low.

2
00:00:12,150 --> 00:00:19,260
All right. This one's unusable. 23, 23 people.

3
00:00:19,560 --> 00:00:23,080
All right, everybody, let's come together in 24.

4
00:00:23,100 --> 00:00:26,100
All right, class.

5
00:00:28,560 --> 00:00:32,520
I hope this is just fabric. Yeah, and life.

6
00:00:33,870 --> 00:00:39,840
If we're going to only have 20 some people showing up, that's a bad sign for the next 6 to 7 weeks.

7
00:00:41,820 --> 00:00:45,810
But anyways, no pressure. If you're sick, please don't come.

8
00:00:46,860 --> 00:00:55,740
But if you're not sick, please come. You've got a fall break coming up.

9
00:00:59,840 --> 00:01:07,010
We have been asked by the chair of our committee who is Laura Scott and I'm a member of the DEA committee.

10
00:01:07,340 --> 00:01:14,570
Make this full. That's not what I want and that's not helpful.

11
00:01:16,670 --> 00:01:21,980
So for the last five years, you probably haven't been here for five years unless you're undergrad.

12
00:01:22,940 --> 00:01:29,629
Michigan has been doing what they call the DCI 1.0 diversity, equity and inclusion,

13
00:01:29,630 --> 00:01:36,590
trying to figure out what everybody's doing at the University of Michigan with regard to these three these three topics.

14
00:01:37,720 --> 00:01:42,110
We're now in the process of five years of DEA 2.0.

15
00:01:42,950 --> 00:01:48,440
And the plan now is to try and formulate, I think, some strategies, plans.

16
00:01:49,490 --> 00:01:55,880
Instead of having 200 different activities across the university, maybe trying to scale that back to be a little more productive.

17
00:01:57,020 --> 00:02:02,900
Part of that initiative is every school at the university had to tell the university what they've been trying to do in this area.

18
00:02:03,950 --> 00:02:11,260
And now the School of Public Health has its own DEA 2.0 as part of Michigan's to clean plateau the Wednesday after fall break.

19
00:02:11,270 --> 00:02:13,060
You should have gotten an email about this already.

20
00:02:13,070 --> 00:02:20,629
So the Wednesday after fall break, you're going to be excited to do lots of stuff from 10:00 to 1:00 in the currently room.

21
00:02:20,630 --> 00:02:23,840
We used to call it the Oregon Rule and there was a cool Oregon in there.

22
00:02:25,100 --> 00:02:29,240
There's 3 hours of activities related to diversity, equity and inclusion.

23
00:02:30,290 --> 00:02:35,150
There's a gallery walk. You'll have no idea what that is.

24
00:02:36,080 --> 00:02:42,440
But there's a gallery where from 10 to 11 there is an interactive canvasses, interactive conversation from 11 to noon.

25
00:02:43,160 --> 00:02:46,580
And then there's lunch and a quilt making exercise.

26
00:02:47,680 --> 00:02:51,890
I don't know what that is. If you're at all interested, please go.

27
00:02:53,090 --> 00:02:58,010
I do a lot of work in D.C. I'm more at the university level than in our department or at the school.

28
00:03:00,200 --> 00:03:04,940
It's a monumental task, and I think Michigan is still struggling to figure out what exactly they want to do.

29
00:03:05,330 --> 00:03:09,500
But if you're interested in being connected more with the school but because I think

30
00:03:09,500 --> 00:03:13,430
our department does a really lousy job staying connected with the rest of the school,

31
00:03:14,720 --> 00:03:19,430
they don't necessarily always connect us anyway. But it goes both ways anyways.

32
00:03:19,970 --> 00:03:24,200
Join us if you want. I don't know who attending. I don't know what the department's attending.

33
00:03:25,100 --> 00:03:31,580
But there it is. Please go. If you're at all interested and there's a QR code if you want to register.

34
00:03:33,860 --> 00:03:38,930
I'm trying to stall till 211 when my recorder come back out.

35
00:03:39,620 --> 00:03:46,730
We're spending some time again. This is important, but so it's close that.

36
00:03:47,750 --> 00:03:54,350
So we're midway through the semester. It's fall break coming up, although it probably feels like you're nowhere near that.

37
00:03:56,240 --> 00:04:01,639
And that was live there, mostly listening. I was talking with a couple of folks yesterday.

38
00:04:01,640 --> 00:04:10,640
I was on a meeting. They sit on the government's there's a governance panel that meets with the president and the provost.

39
00:04:10,730 --> 00:04:13,850
And I am one of the 12 people who get to do that.

40
00:04:15,380 --> 00:04:26,210
And we met with another committee at the University of Michigan who was tasked with looking at student experience at the undergraduate level.

41
00:04:26,960 --> 00:04:30,560
That's where the university always seems to start the year with its undergrads before it gets

42
00:04:30,560 --> 00:04:37,610
to its grad students trying to figure out how to make classes a little less intense angst,

43
00:04:37,670 --> 00:04:46,050
anxiety ridden and so forth. And I got some good feedback and I want where I can do this right now.

44
00:04:46,230 --> 00:04:51,840
But it is open and I know it's here somewhere. If you take the time.

45
00:04:52,970 --> 00:04:57,090
And I'm serious. In that panel discussion,

46
00:04:57,090 --> 00:05:04,230
it's very obvious that what faculty think students need and what students think they want from faculty don't line up very well.

47
00:05:05,270 --> 00:05:09,480
That's surprising. So if you want to answer this question as many times as you want.

48
00:05:09,870 --> 00:05:13,320
Again, it's anonymous. I'm not going to go tell Brimmer who said what.

49
00:05:14,520 --> 00:05:16,470
Even though she's on sabbatical, I wouldn't tell her anyway.

50
00:05:16,500 --> 00:05:22,730
But to reduce potential anxiety and or stress regarding my coursework, it doesn't have to be this class.

51
00:05:22,740 --> 00:05:27,630
It can be anywhere. I wish I had. Whatever.

52
00:05:28,500 --> 00:05:32,370
If it's ten things. If it's one thing. Please put those in a survey.

53
00:05:32,370 --> 00:05:36,029
In the survey. At some point. I'll bring this up again after fall break.

54
00:05:36,030 --> 00:05:44,320
We'll talk about it again. I am curious because some of the things that were suggested in that committee meeting, the faculty just hated.

55
00:05:46,950 --> 00:05:50,249
So but if they show up again in the survey, then what?

56
00:05:50,250 --> 00:05:53,820
I have to figure out how we can bridge this.

57
00:05:53,850 --> 00:06:00,820
So, again, please answer that question. It'd be good to know. Grad school is tough.

58
00:06:00,910 --> 00:06:03,940
It should be. It should test you.

59
00:06:04,450 --> 00:06:07,480
It should not kill you. It should not.

60
00:06:08,890 --> 00:06:13,330
And if it is that much of a struggle, then we have to figure out how to not make it that bad.

61
00:06:13,360 --> 00:06:18,610
So anyways, please tell me. And if I get enough feedback, I'll let the department know.

62
00:06:19,540 --> 00:06:21,340
Because we're trying to figure this out, as you know.

63
00:06:21,430 --> 00:06:26,890
We're trying really hard with these large cohorts, trying to figure out how to make this this place better.

64
00:06:27,640 --> 00:06:32,480
And I'm not quite there yet. Calendar.

65
00:06:33,110 --> 00:06:40,770
Speaking of anxiety inducing. So here is the calendar for October site and makes some more changes.

66
00:06:40,800 --> 00:06:44,160
Again, reminder, next Friday, a week from now, we're not here.

67
00:06:44,790 --> 00:06:53,940
I'm at an all day retreat, so there's no class. So you're going to get your fall break on Friday for this class rather than Monday and Tuesday.

68
00:06:55,170 --> 00:07:01,500
That means there's only one thing that you have due to me in October, and that is Homework three, which is due next Wednesday.

69
00:07:01,950 --> 00:07:08,100
I hope everybody has just about done with it. Please don't save it until next Wednesday morning.

70
00:07:10,830 --> 00:07:14,220
Then we're going to start talking about GDP and normal data.

71
00:07:14,820 --> 00:07:19,440
So October looks pretty late and that means November doesn't look so lame.

72
00:07:22,890 --> 00:07:27,180
So I move to homework. Number four, homework for was due a week after fall break.

73
00:07:28,170 --> 00:07:31,170
We're hardly going to get to gee, I forget that I wasn't going to be here on Friday.

74
00:07:31,170 --> 00:07:35,310
So a homework four is now moved to November 2nd.

75
00:07:36,630 --> 00:07:40,350
That means homework number five is moved to the.

76
00:07:40,620 --> 00:07:45,640
Oh, my God, that's the 16th. So two weeks later, homework number five.

77
00:07:46,450 --> 00:07:55,510
Two days later, exam number two is going to open. Exam number two, covers form works three and four, not number five.

78
00:07:57,160 --> 00:08:01,150
It's open on Friday. It goes until Tuesday, then you've got Thanksgiving.

79
00:08:01,690 --> 00:08:09,490
So there's no test. If you do it Friday or over the weekend, you don't have an exam right against Thanksgiving break.

80
00:08:10,650 --> 00:08:16,080
We'll come back from Thanksgiving. And then again, everything goes very, very fast here at the University of Michigan.

81
00:08:17,490 --> 00:08:20,340
We're going to have one more assignment due on the seventh.

82
00:08:21,150 --> 00:08:28,980
And the last day of class was my plan for the final exam to be open again on a Friday and go until Tuesday of exam week.

83
00:08:30,090 --> 00:08:35,550
If things start to get too anxiety filled and stressful, we can recalibrate.

84
00:08:35,960 --> 00:08:39,450
Right. So I don't have to have a homework. Six.

85
00:08:40,080 --> 00:08:43,080
I don't have to have an intensive exam. I have to have something.

86
00:08:44,220 --> 00:08:49,530
We'll figure out what that is. But just keep that in mind that November is going to have a lot more from you.

87
00:08:50,430 --> 00:08:55,559
All right. I do not like November and December here at the University of Michigan because of

88
00:08:55,560 --> 00:08:59,910
these four days right here and the fact that we don't have to have a break right here.

89
00:09:01,140 --> 00:09:04,410
One of the suggestions from the committee that I met with the other day was that

90
00:09:04,410 --> 00:09:07,860
we move the winter semester to start two weeks later than it does right now.

91
00:09:09,020 --> 00:09:13,360
Yes. Yes. Yes. I know.

92
00:09:14,640 --> 00:09:23,580
We could not have shouted louder about how great that idea that everyone seems to like, the idea that we have this really long spring summer.

93
00:09:23,580 --> 00:09:33,440
But it comes at a huge cost, I think. But it's kind of stupid to have spring break in February, so hopefully it won't affect you probably.

94
00:09:33,440 --> 00:09:36,500
And it's going to take Michigan five years to figure out how to make that happen.

95
00:09:36,510 --> 00:09:42,570
But yeah, even one more week would be nice because the two weeks that we have off are like right during the holidays and flights are really expensive.

96
00:09:42,600 --> 00:09:46,350
Oh, I agree. There's so many there's so many positive aspects for all of us.

97
00:09:48,740 --> 00:09:51,920
Yeah. Most of our peers do not do this.

98
00:09:51,980 --> 00:09:57,200
Most European institutions do not do this. And I agree. Nowadays, with flights being so ridiculously expensive.

99
00:09:57,890 --> 00:10:06,350
Here's one more reason why we don't want people flying around New Years just to get back to a university and have classes done in the middle of April.

100
00:10:07,430 --> 00:10:13,040
All right. If I delayed enough guests who spend all their time making sure I would work here on the computer.

101
00:10:13,040 --> 00:10:19,210
But I think. And back her studio?

102
00:10:19,240 --> 00:10:24,069
Yes. I don't have a warning. All right, good. I've done the calendar.

103
00:10:24,070 --> 00:10:32,860
I've done the whole time. Ready? All right. I like to teach through simulations, as you probably have learned by now.

104
00:10:34,240 --> 00:10:42,010
We can put up lots of slides with formulas and things, but questions have come up from you guys, both after lecture and in my office hours.

105
00:10:42,280 --> 00:10:48,250
I got another one yesterday about the homework number three, and we can look at all this bias by assimilating data.

106
00:10:48,970 --> 00:10:58,030
I think I can get a rough idea of what I'm trying to tell you guys when I show you my PowerPoint slides and everything around anyways.

107
00:10:59,680 --> 00:11:05,870
So as I told you, like, I had a file for simulating data from a global standpoint.

108
00:11:05,890 --> 00:11:11,170
So for you to find a correlation structure and you use a multivariate normal distribution to draw a sample,

109
00:11:12,100 --> 00:11:18,790
we're going to do the same thing now, but with random effects. And so a lot of the code looks the same again.

110
00:11:18,790 --> 00:11:25,090
This library capital emphasis is only necessary to use a multivariate normal random sample.

111
00:11:25,720 --> 00:11:29,710
There is no default in our and there's probably some others out there. It's the one I use.

112
00:11:29,920 --> 00:11:32,950
I'm going to start with ten people right now because I want to do some visualization.

113
00:11:33,910 --> 00:11:40,720
This one isn't helpful, but so I've got ten people, five people in one group, five people in the other group.

114
00:11:41,440 --> 00:11:48,880
There's five time points in time is going to be recorded as continuous zero one, two, three, four.

115
00:11:50,570 --> 00:11:56,360
And how we code time is a really interesting aspect of these models that I want to get into.

116
00:11:56,360 --> 00:12:00,290
Eventually there is an intercept.

117
00:12:01,340 --> 00:12:09,750
There is a slope on time. There is a group difference in the intercepts and right now I'm not going to have an interaction.

118
00:12:09,770 --> 00:12:13,490
So the slopes are the same for both groups. Of course, we could change that if we want.

119
00:12:14,940 --> 00:12:20,250
We then want to simulate or draw random effects for each individual.

120
00:12:20,490 --> 00:12:27,480
So there is a variance component. Sigma Square Alpha, which I think I called the theta in my notes.

121
00:12:27,690 --> 00:12:34,860
This is the variance of the random intercepts. This is the variance of the random slopes.

122
00:12:36,660 --> 00:12:42,450
I'm going to have those two variance components have covariance attached to them of negative one so they're negatively correlated.

123
00:12:44,370 --> 00:12:48,090
And then there is the error variance, which I'm just going to code as to right now.

124
00:12:51,250 --> 00:12:57,190
In the notation, there is this D matrix, there's the variance covariance matrix of the random effects.

125
00:12:57,910 --> 00:13:01,060
So again, that's a two by two matrix way of two random effects.

126
00:13:01,690 --> 00:13:05,739
There's a variance for the intercept and the slope, and then there's the covariance term.

127
00:13:05,740 --> 00:13:09,640
And I've just used some code there to make a two by two matrix. So.

128
00:13:11,530 --> 00:13:15,900
Look. The man looks like that.

129
00:13:19,820 --> 00:13:25,340
As I keep saying in class, random effects are another way to induce correlation into data.

130
00:13:26,120 --> 00:13:29,269
Besides a correlation matrix for the errors in.

131
00:13:29,270 --> 00:13:36,920
So let's see what kind of correlation is induced when we have these random effects in the data themselves.

132
00:13:37,940 --> 00:13:44,719
So again, the remember the formula and remember if there is a formula that I've shown you

133
00:13:44,720 --> 00:13:49,879
in the PowerPoint slides that says the variance covariance of a person's values,

134
00:13:49,880 --> 00:13:54,200
why I is z transpose plus r.

135
00:13:55,190 --> 00:13:58,220
So Z is that decision matrix for the random effects.

136
00:13:58,970 --> 00:14:05,870
I have a random slope and a random intercept, so there's a column of ones and then a column of the time values.

137
00:14:09,830 --> 00:14:11,660
There it is. All right. Yeah.

138
00:14:12,170 --> 00:14:21,380
Intercepts and then zero one through for the our matrix we typically assume is a is an identity matrix times sigma squared for the errors.

139
00:14:23,990 --> 00:14:34,340
Right. So that's just an identity times two. And then the formula for Sigma is Z, Z, transpose plus R, and there it is.

140
00:14:35,690 --> 00:14:40,310
I don't really like to look at variance covariance matrices. I like to look at the correlation matrix.

141
00:14:40,880 --> 00:14:45,500
And again, there's a function in R that takes a variance matrix and turns it into a correlation matrix.

142
00:14:46,220 --> 00:14:50,150
CLV To see all our so I've done that here.

143
00:14:51,710 --> 00:14:55,010
And so as I've been saying, if I have a random intercept and a random slope.

144
00:14:56,600 --> 00:15:03,290
That should mimic some sort of air one structure. So, again, you can do this.

145
00:15:04,190 --> 00:15:16,940
I put everything in there. Here's the correlation matrix. And sure enough, there is the correlation the first time points of a correlation,

146
00:15:16,940 --> 00:15:22,400
2.63 and then it decays over time as the two S2 observations get further apart in time.

147
00:15:23,120 --> 00:15:27,200
It is not strictly error one, but it has the sticking structure.

148
00:15:31,420 --> 00:15:36,820
No. This matrix right here is a function of Z.

149
00:15:38,370 --> 00:15:47,490
And Z has the time values in it. So the correlation structure is very sensitive to how you code time and your analysis.

150
00:15:51,090 --> 00:15:54,840
And it decays pretty quickly as time gets larger.

151
00:15:55,170 --> 00:15:58,410
So right now, my time variables are zero, one, two, three and four.

152
00:15:59,280 --> 00:16:04,650
Suppose instead they were zero, two, four, six and eight, right?

153
00:16:04,890 --> 00:16:08,220
Two months, four months. So I decided to model time that way.

154
00:16:11,230 --> 00:16:13,960
So everything else is the same. The Matrix hasn't changed.

155
00:16:15,220 --> 00:16:21,370
The only thing that's changed is the Z matrix design matrix, and that's going to change my correlation structure.

156
00:16:29,970 --> 00:16:35,400
I've doubled the time values and the correlation now has vanished quickly to the

157
00:16:35,400 --> 00:16:38,820
point where there's almost negative correlation for the first and the last time.

158
00:16:39,930 --> 00:16:45,810
So one of the questions I got is, you know, how should I code time when I'm doing the random effects?

159
00:16:46,290 --> 00:16:52,170
Well, just remember that the larger the time values are, the quicker and you're going to have correlation checking in your model.

160
00:16:52,770 --> 00:16:54,810
So think about that when you're trying to fit these models.

161
00:16:55,260 --> 00:17:05,960
If your time variables are months and at zero 12, 24, 36, you might want to change that two years, one, two, three, four, eight.

162
00:17:06,120 --> 00:17:10,740
It's going to be harder to model the correlation unless you really think it drops off that fast.

163
00:17:11,280 --> 00:17:17,580
So it's something to think about now is how you code time in the random effects is not trivial.

164
00:17:19,530 --> 00:17:25,649
You can do just about anything you want. So some of you are fitting a categorical time in your homework assignments.

165
00:17:25,650 --> 00:17:31,950
We talked about whether time should be categorical or fix categorical or continuous in the fixed effects.

166
00:17:33,060 --> 00:17:40,200
You can have categorical fixed time effects and a random slope continuous time computer doesn't care.

167
00:17:40,290 --> 00:17:45,480
Those are just two different things to the computer. But you have to think about what are you saying there?

168
00:17:46,050 --> 00:17:50,640
You're saying that the mean structure, there's a different mean for every time point,

169
00:17:51,720 --> 00:17:56,549
but then you have this correlation and sticking with these actual time values can

170
00:17:56,550 --> 00:18:02,930
just think about what you're doing when you fit those you typically cannot fit.

171
00:18:02,940 --> 00:18:09,450
I'll show you this in my homework assignment. If time is categorical, you can make time categorical for the random effects.

172
00:18:11,040 --> 00:18:18,390
But again, remember, if you have let's say you have 14 points, so you've got three dummy variables,

173
00:18:20,010 --> 00:18:23,730
you're going to fit a random component for every one of those time points.

174
00:18:23,940 --> 00:18:29,370
So that's four of those guys. And then a covariance variance for every pair of those.

175
00:18:30,450 --> 00:18:34,590
That's six more. So you're going to try and fit ten variance components.

176
00:18:34,620 --> 00:18:40,500
The computer is probably going to crash. Right. So you do have to think about how you're going to handle time.

177
00:18:41,520 --> 00:18:45,210
Does not have to be the same in both the random effects and the fixed effects.

178
00:18:46,080 --> 00:18:49,560
Think about what that means in terms of what you're actually fitting to the data.

179
00:18:51,450 --> 00:18:59,340
All right. So timer time is important in how you're going to model correlation if you're going to fit a random slope.

180
00:19:00,300 --> 00:19:05,410
And again, as I said to you guys, you folks. The right term is anymore.

181
00:19:05,420 --> 00:19:09,710
I've just been told that Fox is a bad word. You people.

182
00:19:10,670 --> 00:19:13,680
All right? Let's fit a random intercept.

183
00:19:13,700 --> 00:19:17,060
Let's simulate data with only a random intercept.

184
00:19:17,870 --> 00:19:21,830
Something to get rid of random slopes, and therefore, there can't be a covariance term.

185
00:19:23,180 --> 00:19:28,850
So those are both zero. What does the correlation structure look like now?

186
00:19:35,340 --> 00:19:39,810
Comment about your comment symmetric and what value is off the diagonal.

187
00:19:42,000 --> 00:19:48,100
Who? What is the correlation between any two observations?

188
00:19:54,500 --> 00:19:59,060
Any thoughts? Approximately.

189
00:20:05,900 --> 00:20:19,920
Not even close? No. The correlation should be the variance between individuals six divided by the total variance, which is eight, six plus two.

190
00:20:21,060 --> 00:20:33,600
So the correlation of six over eight, which is point seven, five fingers, that's what the correlation matrix looks like, right?

191
00:20:33,780 --> 00:20:39,120
Compound symmetric. And we know the correlation is the ratio of between divided by total variance.

192
00:20:44,460 --> 00:20:53,430
Again if if the variability between individuals as six and the variance within individuals is 20.

193
00:20:54,840 --> 00:20:58,620
Now we've got six over 26 and that's pretty small.

194
00:20:58,950 --> 00:21:08,100
I should have picked a nicer number. There's a correlation of about 2.236 over 26.

195
00:21:09,120 --> 00:21:18,220
That's pretty close. 23 three Woolsey zero zero.

196
00:21:18,240 --> 00:21:22,470
Go before it. Nope. I don't like those machines.

197
00:21:22,500 --> 00:21:26,640
Let's go back to what we had you. I think this was like two and this was a negative one or something.

198
00:21:27,210 --> 00:21:29,250
Let's go back to the random intercept slope model.

199
00:21:31,410 --> 00:21:38,010
So I'm going to simulate ten individuals, right, with the given fixed effects and the given random effects.

200
00:21:38,730 --> 00:21:46,070
And then I added some new code at the end of this, different from the last simulation, and that is to plot everybody's trajectory.

201
00:21:46,080 --> 00:21:54,100
So I'm going to plot ten trajectories here. So those are the ten individuals right there.

202
00:21:57,210 --> 00:22:05,520
I put the colors there, but you can pretty much see the distinct distinctness there, how different people are from each other.

203
00:22:06,030 --> 00:22:09,900
Each individual's trajectory is distinct from everybody else's trajectory,

204
00:22:11,100 --> 00:22:18,870
and that's because the between subject variability is bigger than the within within each person.

205
00:22:18,900 --> 00:22:22,500
The data are fairly similar among people.

206
00:22:22,710 --> 00:22:27,600
They're very distinct, and that is because the variance of the variance components.

207
00:22:29,130 --> 00:22:38,160
The variance of the random effects. Excuse me. These things are much bigger than this number in magnitude.

208
00:22:38,800 --> 00:22:42,030
Oh, you go, then. This number is.

209
00:22:44,480 --> 00:22:50,240
And if I make them even bigger, let's make this 60 and then 20.

210
00:22:50,270 --> 00:22:58,360
Why not? So now we have huge variation between people and very little variability within the first.

211
00:23:00,540 --> 00:23:06,000
And again, it's just ten people. But again, hopefully what you can see is that I can tell each person it's.

212
00:23:08,990 --> 00:23:19,220
Conversely, if I make this relatively small relative to how big the noise is, what's in a person, what do you think is going to happen?

213
00:23:22,360 --> 00:23:25,600
You get something like this and I can make it even worse.

214
00:23:26,530 --> 00:23:28,720
Maybe that'll be right.

215
00:23:29,950 --> 00:23:39,850
Everybody's observations themselves are bouncing around so much that I can distinctly see each person very well in terms of their trajectories.

216
00:23:40,210 --> 00:23:44,290
And that's because within is so much bigger than between.

217
00:23:44,710 --> 00:23:53,770
The correlation is small. So correlation is measuring how between and within subject variability are going with each other.

218
00:23:54,280 --> 00:24:03,490
Right. So again, I've talked about between and within subject variability and how that spreads people apart or has them overlap.

219
00:24:04,480 --> 00:24:08,290
You can examine that through this code right here and again, see what ten people look like.

220
00:24:12,550 --> 00:24:16,990
Again, I have to really make things smaller, big to to get things really distinct.

221
00:24:17,530 --> 00:24:27,700
So again, even though 20 and six and two and so forth are very distinct from each other and I guess is a pretty distinct beginning,

222
00:24:27,700 --> 00:24:31,240
we can start to shrink that again and see different things.

223
00:24:33,110 --> 00:24:39,530
So that was the next thing I wanted to show everybody here in our is that by simulating data with true,

224
00:24:39,530 --> 00:24:45,350
true random effects, we can see what we're talking about in terms of the slides in PowerPoint.

225
00:24:48,630 --> 00:24:55,860
Right. Smoke. That's. All right.

226
00:24:57,960 --> 00:25:02,160
So this again, is a method to simulate one dataset.

227
00:25:03,480 --> 00:25:08,160
So now I'm going to increase it to 100. I'm going to try and actually fit a random effects model.

228
00:25:08,850 --> 00:25:10,590
So now I'm simulating data.

229
00:25:12,570 --> 00:25:19,950
There is truly a random intercept, truly a random slope, and there is covariance between those two things in the data themselves.

230
00:25:22,170 --> 00:25:29,130
The random intercept has a variance of six and a variance of two for the random slope, so forth.

231
00:25:29,910 --> 00:25:36,900
So I'm going to simulate 100 people, 50 and each group. And I'm going to fit a random intercept model.

232
00:25:38,010 --> 00:25:46,360
The data are truly random intercepts slope. I'm going to wrongly set a random intercept model.

233
00:25:48,340 --> 00:25:53,880
Okay. So 100.

234
00:25:55,470 --> 00:26:04,770
Plus, let's see what happens and cross my fingers that this doesn't take longer than it does on someone to run a thousand simulations,

235
00:26:05,430 --> 00:26:11,820
simulating 100 people with random intercepts and slopes, analyzing each dataset with a random intercept model.

236
00:26:12,540 --> 00:26:17,040
I'm going to save all the beta out solver coefficients. They're standard errors.

237
00:26:17,820 --> 00:26:23,610
I'm going to save the variance of the intercept value that our gives you.

238
00:26:24,540 --> 00:26:33,730
And I'm going to see what happens. What do you think of this while this is running and I have to do a little song and dance?

239
00:26:35,740 --> 00:26:39,130
What's going to happen to the coefficients in the fixed effects part of the model?

240
00:26:42,090 --> 00:26:49,880
Good or bad. I'd be an exam question.

241
00:26:52,860 --> 00:26:57,090
What do what does what does? Ignoring what is getting correlation wrong due to estimation?

242
00:27:00,090 --> 00:27:03,750
Nothing wild. Nothing. We still get unbiased, right?

243
00:27:04,350 --> 00:27:10,500
Getting the correlation structure wrong still leads to unbiased estimates of my coefficients in the mean parameters.

244
00:27:11,370 --> 00:27:15,809
So even though the data are random intercept and slope fitting,

245
00:27:15,810 --> 00:27:21,030
a random intercept model should still give me good estimates of the means of X parameters.

246
00:27:21,600 --> 00:27:26,520
So that concept in glass carries over here if I get the random effect structural.

247
00:27:27,700 --> 00:27:29,140
That's causing the weight matrix.

248
00:27:29,680 --> 00:27:35,740
And we know that the weight matrix still leads to an unbiased estimate of beta, of beta, of the mean of the fixed effects.

249
00:27:38,860 --> 00:27:49,919
And we're almost there. He finishes up.

250
00:27:49,920 --> 00:27:55,370
Relax. I come here. Almost there. All right.

251
00:27:55,380 --> 00:27:59,170
We've run a thousand simulations. So, again, what have I done here?

252
00:27:59,190 --> 00:28:10,590
I have simulated data. I have then asked the computer to set a random intercept model with Remo, and that's the default.

253
00:28:10,950 --> 00:28:17,400
Actually never made that explicit in class. I don't believe that the default in all these programs is to use restricted maximum likelihood.

254
00:28:19,350 --> 00:28:22,620
I'm going to set a no random effects model. I'll show you why in a second.

255
00:28:24,270 --> 00:28:28,790
And then from the random intercept model, I'm going to save all the coefficient estimates.

256
00:28:28,800 --> 00:28:33,150
So there's four of them. Intercept group time in the interaction.

257
00:28:35,290 --> 00:28:40,160
I'm also going to record the standard errors that come out of the model fit.

258
00:28:40,180 --> 00:28:53,110
So those are again, those are model base standard errors. I'm going to keep track of the variance of the random intercept that is estimated each time.

259
00:28:55,480 --> 00:28:58,930
And also record an estimate of sigma squared to the error variance.

260
00:28:59,710 --> 00:29:06,600
And I'm going to put those two things together. And I'm also going to record likelihood ratios, test statistic that I'll get to later.

261
00:29:07,710 --> 00:29:15,600
But what am I interested in? I now have a thousand sets of coefficient estimates for the fixed effects.

262
00:29:15,630 --> 00:29:24,900
I'm going to compare those on average. So averaging across all simulations on average are the coefficient estimates close to the truth.

263
00:29:25,420 --> 00:29:37,590
That's exactly what biases. And again, remember, the coefficients had magnitude of like 25 and five.

264
00:29:38,250 --> 00:29:48,940
So again, I got the correlation structure wrong. But there's very little bias in the coefficient estimates themselves in the fixed index.

265
00:29:48,950 --> 00:29:52,190
So that's what we wanted to see. In fact, it holds true.

266
00:29:55,340 --> 00:30:01,140
Here are the model base standard errors. But let's put this all in a table that'll make it easier.

267
00:30:01,620 --> 00:30:09,600
So again, when we do simulations for things like this, the first thing we get is in every simulation, we get a standard error that's output from our.

268
00:30:11,200 --> 00:30:13,360
On average, are those close to the right answer?

269
00:30:14,850 --> 00:30:21,430
And so what we do then is go back to our coefficient estimates and look at their variability across simulations.

270
00:30:21,450 --> 00:30:25,110
That's the true. We call that the empirical standard error.

271
00:30:25,890 --> 00:30:34,380
So again, model based senator simply says go, go, go, go to the output from our and get the average standard error across the thousand simulations.

272
00:30:34,410 --> 00:30:37,890
Of course I get the variance. Take the average of those and then take a square root.

273
00:30:39,000 --> 00:30:47,370
The actual variability simply says go to the beta sort of every column and take the standard deviation across the thousand simulations.

274
00:30:48,450 --> 00:30:56,790
These two. If my methods are correct, the model based on the empirical should be close to a high degree.

275
00:30:58,590 --> 00:31:04,230
So I put the bias, the standard error from the model in the standard error into the mean that's all in one table.

276
00:31:05,580 --> 00:31:10,890
And recall that all results fixed, all those things.

277
00:31:13,380 --> 00:31:22,020
So again, there's the bias I just showed you. It's very, very good. There is on average with the standard items are from a random intercept model.

278
00:31:23,260 --> 00:31:29,950
First. We got that wrong. The actual variability across the betas is actually very different from that.

279
00:31:31,000 --> 00:31:36,610
And that's because I got the model wrong. So it's the same thing as it was with.

280
00:31:38,260 --> 00:31:42,850
Estimation is fine. Inference is impacted if you don't get the right variance components.

281
00:31:43,750 --> 00:31:48,400
So you could take this random intercept model and you could throw on a sandwich standard error.

282
00:31:49,000 --> 00:31:52,780
The residuals should tell us what's left over. Right.

283
00:31:53,320 --> 00:32:02,230
So again, fitting a random intercept model when there truly is a random slope is going to lead to incorrect inference.

284
00:32:02,380 --> 00:32:16,660
Make sense. The variance is wrong. I also saved the estimate of the random intercept variance.

285
00:32:17,190 --> 00:32:27,020
Again, if we go back to the code. I wanted everyone to have a random intercept such that those random intercepts had us variability of six.

286
00:32:28,730 --> 00:32:40,480
What do you think is actually being estimated from the data? I think the estimate is going to be bigger than our less than six.

287
00:32:50,230 --> 00:32:54,130
Is there more or less variability in the data than a random intercept?

288
00:32:56,880 --> 00:33:03,650
One or more. There's random slopes. There's more noise in the data than I accounted for in my model.

289
00:33:04,310 --> 00:33:10,870
So where do you think that extra variability is going to go? It's going to get thrown into the random intercept.

290
00:33:12,330 --> 00:33:15,630
Right. The Intercept is trying to capture all the between static variability.

291
00:33:15,900 --> 00:33:19,290
Well, there was two parts, the intercepts and the slopes. You got rid of the slopes.

292
00:33:19,290 --> 00:33:23,220
That noise has to go somewhere. It goes into the random intercept variance.

293
00:33:24,780 --> 00:33:29,190
So, again, hopefully that's going to happen here.

294
00:33:30,060 --> 00:33:41,640
It did last night. So again, there's the bias in the variance of the intercepts and the bias and the error variance.

295
00:33:42,180 --> 00:33:49,259
Remember, again, the number was six. So there's huge bias in the random intercept because we didn't accurately account

296
00:33:49,260 --> 00:33:53,130
for all the variability in the data between between individual experience.

297
00:33:55,640 --> 00:34:00,770
In fact, let's look at the random intercept variances across the thousand simulations.

298
00:34:00,770 --> 00:34:06,860
Look at the distribution of those things. Again, it should have a middle of about six.

299
00:34:06,870 --> 00:34:10,100
Six was the truth. We're way off the mark here.

300
00:34:11,190 --> 00:34:15,990
And that's because there's substantial between seven variability due to the swaps that we didn't account for.

301
00:34:16,150 --> 00:34:23,550
Right. So, um, I think the small were set off.

302
00:34:25,440 --> 00:34:31,980
Now let's fit a thousand. I'm going to simulate a thousand data sets again with a random intercept and a random slope.

303
00:34:34,320 --> 00:34:38,010
And I'm truly going to fit the random intercept slope model.

304
00:34:38,580 --> 00:34:42,370
So now my fit. It's the same code.

305
00:34:42,370 --> 00:34:45,760
Except now there's a random intercept and a random slot in the set.

306
00:34:47,240 --> 00:34:52,100
And hopefully what we're going to see now is there is no bias, very little bias.

307
00:34:53,120 --> 00:34:58,849
And in fact, the model based standard errors and the imperative senators are right on top of each other, are pretty close.

308
00:34:58,850 --> 00:35:03,500
They'll be exact the same, but they should be pretty darn close.

309
00:35:06,560 --> 00:35:14,720
And then once that runs. This part where we at 22 three.

310
00:35:17,810 --> 00:35:35,030
330. I still can't do to timetable two different times from class to pick up the football game because it's going to be just your tickets.

311
00:35:35,030 --> 00:35:39,770
No. Oh, don't go to gate two. I can't take students and working too.

312
00:35:39,840 --> 00:35:48,500
So do you want to stop? I get you. I'll be there in all my amazing blue scanning tickets.

313
00:35:48,590 --> 00:35:50,240
So we really had a whole game.

314
00:35:51,200 --> 00:36:03,650
I have to be there at 930, four noon M and then I stayed the entire game and at least half an hour later for 30 bucks, it's a blast.

315
00:36:04,400 --> 00:36:11,450
I love talking to everybody who comes into the gates. It's there is a fascinating, diverse crowd that comes to Michigan football games.

316
00:36:13,350 --> 00:36:18,290
Not so excited about the Michigan State game. That might be a little challenging.

317
00:36:19,430 --> 00:36:24,290
All right. Let's talk about that right there.

318
00:36:24,710 --> 00:36:31,460
You're going to see this maybe now with your data and class, but eventually you may see a warning signs with with random effects models.

319
00:36:33,230 --> 00:36:36,860
It says model failed to converge with blah, blah, blah, blah.

320
00:36:38,780 --> 00:36:43,760
Did you guys have to program iterated weight at least squares in 651?

321
00:36:44,740 --> 00:36:48,750
No. Okay. Back in the days, yes. We needed to write pseudo code.

322
00:36:49,030 --> 00:36:52,660
We didn't have to, actually, for one of the hallmarks we did. You had to write your own algorithm.

323
00:36:52,870 --> 00:36:55,930
Okay. Just the point is, is that it's iterative, right?

324
00:36:56,440 --> 00:37:00,370
There's this iterative process. It's the same thing here. I haven't emphasized that.

325
00:37:00,370 --> 00:37:02,440
But in all these random effects model settings,

326
00:37:02,800 --> 00:37:08,530
there is constant going back and forth between the fixed effects and the random effects and maximizing and so forth.

327
00:37:10,270 --> 00:37:14,680
It often takes a long time and sometimes it crashes.

328
00:37:15,550 --> 00:37:19,890
I just out of severe sorry set up the stuff, but I know you don't remember doing it.

329
00:37:19,900 --> 00:37:27,070
That's okay. The point is, is whenever there is a convergence, you have to worry about what's going on there.

330
00:37:27,760 --> 00:37:36,670
Right. Our gave us our gamey output. So even though the output is there, it's telling you and not too sure about it.

331
00:37:36,970 --> 00:37:45,880
And usually the problem is that the variants are so small that they're right next to zero and zeros on the boundary.

332
00:37:46,600 --> 00:37:52,720
We don't like boundaries. So it's showing you here that probably one of the variance components is very close to zero.

333
00:37:53,410 --> 00:37:56,680
And so things are having a hard time fitting. So just again, keep that in mind.

334
00:37:56,690 --> 00:38:06,490
That's what I'm trying to tell you here. Let's hope now I fit the right model to the data stacks.

335
00:38:09,010 --> 00:38:12,520
So again six to Fox estimates pretty unbiased.

336
00:38:13,220 --> 00:38:18,160
There's what my output on average is telling me the standard errors are and look at that.

337
00:38:19,120 --> 00:38:25,240
They match what the actual variability was across a thousand simulations in the empirical right as they should.

338
00:38:25,360 --> 00:38:29,589
So we've got everything right here. Yeah, that makes sense.

339
00:38:29,590 --> 00:38:37,110
We fit the right model. Showed you all of that.

340
00:38:39,240 --> 00:38:48,660
So let's talk about something newer that again, we're not going to spend a lot of time on, but I think is useful in simulations of controllers.

341
00:38:50,610 --> 00:38:58,320
So I told you on Monday that inference for the various components is tricky.

342
00:38:58,680 --> 00:39:04,709
If you want to test whether or not a variance component is zero or not, you're essentially saying, should that be in the model?

343
00:39:04,710 --> 00:39:08,100
Right. If there's no random slope variance.

344
00:39:09,370 --> 00:39:13,689
Then you're asking whether or not to throw that away because all the random effects are exactly at zero.

345
00:39:13,690 --> 00:39:14,770
There's a spike and zero.

346
00:39:16,410 --> 00:39:23,700
To do those sorts of hypothesis tests violates all the likelihood theory that you've learned because of the fact of the regularity here.

347
00:39:23,700 --> 00:39:28,670
We've got testing on the boundary. Zero is the lower bound for these various components.

348
00:39:28,680 --> 00:39:32,220
And when you're testing at the boundary, things don't work well.

349
00:39:33,510 --> 00:39:37,060
So let's see if we can investigate that.

350
00:39:37,080 --> 00:39:48,870
So of course, I'm going to take out the random covariance, the covariance between the random effect variances.

351
00:39:49,140 --> 00:39:58,410
When I get rid of the random slopes and I'm also going to get rid of the random intercepts, so I am simulating independent data.

352
00:39:58,890 --> 00:40:07,900
Right. There's no there's no various components. There's just noise. Such events.

353
00:40:10,630 --> 00:40:22,690
I am then wrongly going to fit a random intercept and I'm going to look at what the value of the resulting variance parameter is.

354
00:40:24,260 --> 00:40:30,230
So this is generating a null distribution of what that variance component looks like.

355
00:40:31,880 --> 00:40:40,340
So I'm simulating data under the null of no random intercept and then going to ask the computer to estimate a random intercept variance.

356
00:40:40,760 --> 00:40:42,380
And we're going to see what it comes up with.

357
00:40:47,050 --> 00:40:53,440
What I'm also going to do is try and do a hypothesis test like we always do with all of our fixed effects.

358
00:40:54,280 --> 00:41:01,330
So I'm going to set again random error set model wrong to fit a model with no random effects.

359
00:41:01,360 --> 00:41:07,860
That's the right model. Then I want to do a hypothesis test.

360
00:41:07,880 --> 00:41:11,390
So what do we typically do with two models that look nested with each other?

361
00:41:12,510 --> 00:41:17,040
We take a difference in their log likelihoods reduce the likelihood ratio test negative two times the

362
00:41:17,040 --> 00:41:23,430
difference and the degrees of freedom is the difference in the number of parameters in the two models.

363
00:41:23,940 --> 00:41:26,730
And so these two models differ by one variance component.

364
00:41:27,810 --> 00:41:34,650
So we might think that we can compare a model fitting a random intercept and not we could compare

365
00:41:34,650 --> 00:41:39,240
the likelihoods and compare that to a Chi Square distribution with one degree of freedom.

366
00:41:39,870 --> 00:41:43,050
That's what we've learned. What we do in our other regression classes.

367
00:41:43,500 --> 00:41:48,410
So I'm going to compute the likelihood ratio statistic each time again.

368
00:41:48,420 --> 00:41:55,950
Now, I have to be explicit here. That I'm going to get a likelihood when I use maximum likelihood using Rebel now

369
00:41:57,060 --> 00:42:00,900
because we have to use likelihood theory and I'm going to see what happens when again,

370
00:42:00,900 --> 00:42:05,640
when I simulate data that are independent, yet I try to set a random intercept.

371
00:42:06,420 --> 00:42:10,890
And the first thing you're going to see if you go boom, you're going to see lots of warnings.

372
00:42:13,110 --> 00:42:17,510
And what the computer is telling you is I cannot estimate a variance.

373
00:42:17,520 --> 00:42:21,120
It's zero. That's what it means by singular boundaries.

374
00:42:21,120 --> 00:42:25,140
Singular. Our has such wonderful error messages, doesn't it?

375
00:42:25,780 --> 00:42:30,389
That's just dumb. C question mark is singular and if you go to that, it helps you a little bit.

376
00:42:30,390 --> 00:42:37,410
But so every time that's coming up in a simulation, it's, it's coming up with zero for the variance.

377
00:42:39,060 --> 00:42:50,490
When an error doesn't come up, it's fit. So number. So it's going to and again, this is going to take a little bit longer than my other simulations,

378
00:42:50,490 --> 00:42:56,250
because every one of these simulations is going to the last iteration and then it's giving up.

379
00:42:57,540 --> 00:43:02,639
Often you don't need 30 iterations, it converges after three and service simulation runs faster.

380
00:43:02,640 --> 00:43:08,010
So here a lot of these simulations are going to the very last iteration before they get up again.

381
00:43:08,010 --> 00:43:15,470
I could have reset that, but I'm lazy. But I want to show you what happens across a thousand simulations.

382
00:43:16,290 --> 00:43:20,000
I show you what the distribution of all those various components looks like.

383
00:43:20,240 --> 00:43:24,260
And I want to show you the distribution of the likelihood ratio test statistic.

384
00:43:25,190 --> 00:43:27,350
We think it's under the null distribution.

385
00:43:27,620 --> 00:43:33,140
We think that my likelihood ratio tests it to six, have a chi square distribution with one degree of freedom.

386
00:43:33,720 --> 00:43:38,180
And that's the theory. If we believe that theory tells us, it should be.

387
00:43:38,960 --> 00:43:43,190
We know that we have a violation here of the things necessary for that to be true.

388
00:43:45,680 --> 00:43:50,080
For those singular models. Is it still returning the likelihood that you're using?

389
00:43:50,090 --> 00:43:53,510
Yeah, it's returning a likelihood basically from the independence model.

390
00:43:53,510 --> 00:43:59,340
Right, because it sticks in zero. So again, there is an important fact there.

391
00:43:59,820 --> 00:44:04,950
When the variance is exactly zero, we're back to the independence model.

392
00:44:05,550 --> 00:44:10,680
So we're going to take the difference between the Elm model and the Elm model zero.

393
00:44:11,250 --> 00:44:17,130
I just thought that if it wasn't converging, it just might stick in like the last estimate of what the variance would be.

394
00:44:17,760 --> 00:44:22,020
No, I think when it says singular is putting in a zero, it's stuck at zero.

395
00:44:22,710 --> 00:44:28,440
That's a good question. I suppose there could be a case where it fails to converge at something very close to zero.

396
00:44:29,820 --> 00:44:33,090
But we'll look at what the numbers are. All right.

397
00:44:33,450 --> 00:44:37,769
Thousand simulations, again, data under the null of no random effects.

398
00:44:37,770 --> 00:44:42,870
And I try to sit around and intercept it.

399
00:44:46,320 --> 00:44:50,790
All right. So I computed a line of code here over 20 years.

400
00:44:50,810 --> 00:44:55,590
I don't care about the bias and all that kind of stuff. I'm interested in doing inference now on the random effect.

401
00:44:56,100 --> 00:45:00,120
So what I went and I said is, look at all of the random variance intercepts.

402
00:45:00,120 --> 00:45:07,479
Variance estimates from one. Again, for all intents and purposes, you have to the 10th digit.

403
00:45:07,480 --> 00:45:10,540
This thing is zero. I'm going to say it zero.

404
00:45:10,910 --> 00:45:17,890
Right. So I'm trying to tell Ana, you know, some of these things are not exactly zero, but they basically are zero.

405
00:45:18,700 --> 00:45:27,310
So I rounded down to ten digits. Around to ten digits. Anybody have any idea how many of these simulations should have a zero once?

406
00:45:29,160 --> 00:45:35,550
Before I show you some of the computers. I mean, so every simulation I said, tell me whether or not you got a00 for the variance.

407
00:45:36,750 --> 00:45:45,050
Anybody have any idea how many times? All right.

408
00:45:46,260 --> 00:45:52,710
Should be 50%. And again, simulation error, it's 53.5% of simulations.

409
00:45:52,980 --> 00:45:54,720
So 535 out of a thousand.

410
00:45:57,880 --> 00:46:07,030
I told you in the slides that the normal distribution for the likelihood ratio statistic or any statistic has a spike at zero.

411
00:46:07,660 --> 00:46:12,879
And it's a mixture of chi squares, 50% of a chi square zero, which is a spike at zero,

412
00:46:12,880 --> 00:46:17,560
50% and 50% of the time it will follow the normal likelihood theory.

413
00:46:19,000 --> 00:46:24,160
So that's what's happening here. 50% of the time I'm getting exactly zero.

414
00:46:24,550 --> 00:46:27,640
And so this is what happens to the likelihood ratio test statistic.

415
00:46:30,090 --> 00:46:39,990
So when a histogram of the likelihood ratio test statistics only for those where I got a variance component estimate something other than zero.

416
00:46:46,000 --> 00:46:50,950
And again, you may not have all these chi squares down in your brain, but that's very much a case where,

417
00:46:50,950 --> 00:46:58,660
one, I only plotted the 50% of simulations that produced a non-zero estimate.

418
00:46:59,890 --> 00:47:04,900
50% of the time I get a chi square one, 50% of the time I get zero.

419
00:47:06,880 --> 00:47:11,530
So again, as well as simulations, someone went through a lot of work.

420
00:47:11,800 --> 00:47:20,830
And again, this is no proof. But when trying to determine whether or not they should have an intercept in the model or not, random intercepts.

421
00:47:21,880 --> 00:47:27,940
The normal distribution is a mixture of zero chi square degrees of freedom and a one degree 5050 mixture.

422
00:47:28,960 --> 00:47:33,250
And this is what these simulations are trying to show you. So you're less impressed than I am.

423
00:47:33,250 --> 00:47:41,470
But this is again, this is why simulations are nice when the theory is is really, really complicated.

424
00:47:41,770 --> 00:47:48,040
But we do see what's going on here. So and again, it's because we're stuck at the boundary.

425
00:47:48,370 --> 00:47:54,760
These variance components have a boundary that beta beta did not beta was was a real valued thing.

426
00:47:54,910 --> 00:48:08,650
So let me get stuck at the boundary if things go awry. So there's that and something I screwed up on the exam that I thought Rimmel.

427
00:48:08,680 --> 00:48:17,410
I thought Rimmel was used to produce unbiased variance components, but of course I was informed that they produce less biased.

428
00:48:17,530 --> 00:48:23,810
Right? And again, we can assess that in simulations.

429
00:48:24,410 --> 00:48:28,860
So I'm glad it fits. And let's go back to what we have here.

430
00:48:28,880 --> 00:48:38,240
I think we. GROSS So truly, the data have a random intercept and a random slope, and I'm going to fit the right model.

431
00:48:40,810 --> 00:48:48,740
So I'm going to do my run, swim, intercept and slope model. And right now I'm going to set the model with Remo being true.

432
00:48:49,460 --> 00:48:53,120
So I should have saved this from before. I wouldn't have to run on again.

433
00:48:54,690 --> 00:48:57,509
Right. So I'm going to look at the variance component.

434
00:48:57,510 --> 00:49:04,800
So the estimated variance of the intercept, the estimated variance of the slope and the estimated covariance between those two things.

435
00:49:05,940 --> 00:49:14,000
When I use Remo. And I'm going to compare those to the true values and see how much bias there is.

436
00:49:14,630 --> 00:49:19,010
And maybe I don't have to do a thousand simulations. To make my point here, but.

437
00:49:25,450 --> 00:49:33,500
So where are your seats at the football game. You know, nobody's following the student student section.

438
00:49:33,760 --> 00:49:37,120
I thought you had the student. You are the student section. I'm sorry. You said you were healthy.

439
00:49:38,740 --> 00:49:42,650
We said at the very. Do you? We like it up there.

440
00:49:43,570 --> 00:49:46,750
You're safe. Or should I?

441
00:49:46,960 --> 00:49:54,040
Yeah. You can't see the game. Well, I like going down lower.

442
00:49:56,080 --> 00:50:02,260
Okay. Yeah, I've heard that game is fascinating to work with friends, for sure.

443
00:50:02,260 --> 00:50:06,309
It's a lot of fun. There's a lot of energy there and it's a stampede.

444
00:50:06,310 --> 00:50:12,070
I used to have season tickets and my family and I used to go in the student gate because it was closest to where we were going to be.

445
00:50:12,840 --> 00:50:17,950
It was fun. It seems so chaotic to be the student section.

446
00:50:18,230 --> 00:50:21,790
Yeah, that's where you are. It depends on your laptop, where they are. It's very true.

447
00:50:22,030 --> 00:50:29,530
But if you go to a lower for those, that's more much more for the second state's going to be than it was.

448
00:50:29,530 --> 00:50:33,930
That was probably a world in and of itself. Your first let's do.

449
00:50:34,150 --> 00:50:38,080
Oh, all right. What are we doing here?

450
00:50:38,410 --> 00:50:41,760
All right, so we're almost done with a thousand simulations.

451
00:50:41,770 --> 00:50:50,620
I want to look at the bias of the variance components using level two, and then it gets a warning every once in a while.

452
00:50:53,770 --> 00:50:57,490
That's a big deal, right?

453
00:50:58,690 --> 00:51:06,340
So there is the bias bias of the random intercept variance by the random slope variance that are covariance and the error term.

454
00:51:07,330 --> 00:51:11,230
So again, relative to the magnitude of these things, those are those are pretty decent.

455
00:51:12,640 --> 00:51:24,160
So my estimation of what I want to do now is show you what kind of in our classes we teach folks to worry about bias a lot.

456
00:51:24,520 --> 00:51:28,120
I think theoretically it's an important thing.

457
00:51:31,100 --> 00:51:34,550
But in reality, how much bias are we talking about?

458
00:51:35,540 --> 00:51:42,020
So now I am not going to sit I'm going to use maximum likelihood to estimate the variance components rather than rebel.

459
00:51:46,590 --> 00:51:49,680
And again, I want to see what happens to these phone numbers right here.

460
00:51:51,090 --> 00:51:55,980
How much bias are we talking about when we don't use remote versus maximum likelihood?

461
00:51:59,430 --> 00:52:13,500
What else can we talk about? Do they have season ticket packages for faculty so they don't, they don't have specific to faculty.

462
00:52:14,520 --> 00:52:19,380
Uh, you guys weren't here then, but Michigan football got really bad for a while.

463
00:52:20,400 --> 00:52:30,300
Lot and and tickets were not being sold, so they gave faculty a really good deal and that's when I bought them.

464
00:52:31,080 --> 00:52:36,030
That deal is long gone, but, you know, faculty don't get any benefits.

465
00:52:36,810 --> 00:52:41,880
So my sure pitch Rodriguez was our coach for a while.

466
00:52:42,780 --> 00:52:46,230
The younger yes. Weren't too successful.

467
00:52:46,860 --> 00:52:50,999
But anyway, do you know how many faculty you go to the games?

468
00:52:51,000 --> 00:53:00,540
Because I feel like, generally speaking, besides me, I think they might have gone once in a while, but I don't think anybody has season tickets.

469
00:53:00,540 --> 00:53:04,260
They're not cheap. Healthy. I could buy them because they're just not worth it.

470
00:53:04,710 --> 00:53:08,250
I have nothing under 50 bucks to watch. Michigan when 50 something to zero.

471
00:53:09,240 --> 00:53:14,250
That's just that's that's stupid. You can pay over 300 bucks to go to the Michigan State.

472
00:53:14,280 --> 00:53:27,420
I'll bet individual has people here yeah no I'm in my fifties that are either sit at home and my coach until you get old.

473
00:53:29,010 --> 00:53:39,490
All right. It's almost there. All right.

474
00:53:39,500 --> 00:53:45,629
We'll see in seven trouble converging on this. So here are the variance component.

475
00:53:45,630 --> 00:53:54,210
Bias is with Ramble and here is what they are now with with maximum likelihood.

476
00:53:54,780 --> 00:54:00,030
So I can almost get these in the window and here we go.

477
00:54:00,570 --> 00:54:06,000
So it went from point remember remember their actual value is six for the randomness of variance.

478
00:54:06,510 --> 00:54:13,530
So instead of being playing zero six, it's now .16 at a magnitude of six, who really cares?

479
00:54:14,280 --> 00:54:18,089
Right? So there is some bias,

480
00:54:18,090 --> 00:54:23,940
but it isn't like suddenly things are going to come to a screeching halt and you're going to get the wrong answer or a bad answer or a conclusion.

481
00:54:24,390 --> 00:54:30,390
So there is bias using maximum likelihood that again, we're going 100 people.

482
00:54:30,390 --> 00:54:38,170
It's probably worse in a smaller sample of individuals. Again.

483
00:54:38,170 --> 00:54:42,720
I emphasize this before. Uh oh, it's.

484
00:54:42,830 --> 00:54:46,150
Yes. All right. Not done.

485
00:54:47,380 --> 00:54:52,209
Don't start picking up. I want to talk about a couple other things related to homework.

486
00:54:52,210 --> 00:55:04,730
Number three. Art is the second much of that already.

487
00:55:04,730 --> 00:55:07,760
But. Let's get rid of all this noise.

488
00:55:12,980 --> 00:55:19,970
So eventually I'm going to generalize the simulation code to binary and for sun variables,

489
00:55:20,630 --> 00:55:26,840
because we can just change the distribution from normal 2% or four binomial and generate those kind of data as well.

490
00:55:28,190 --> 00:55:40,360
Club sandwich. No, I don't need that today. But if you stop, you're limiting it.

491
00:55:43,860 --> 00:55:55,230
Huh? Why don't you sit on my computer? It just reloads. Now we in the club, both on the doorstep.

492
00:55:59,790 --> 00:56:07,950
Okay. Now that I can use my clout again. Oh, yeah, sure enough.

493
00:56:08,340 --> 00:56:15,810
That's okay. Nope. Project three on that file.

494
00:56:23,320 --> 00:56:27,770
Three. All right. So again, I have the PIP data.

495
00:56:29,240 --> 00:56:34,280
I decided that a random intercept model was sufficient.

496
00:56:42,680 --> 00:56:48,860
There's no random intercept model and try to manage that slope with correlation between them,

497
00:56:49,670 --> 00:56:53,210
as in a model with correlation between the random intercept and slope.

498
00:56:55,370 --> 00:57:01,730
I tried to set a random intercept slope and quadratic in that crashed.

499
00:57:02,510 --> 00:57:09,260
And again, by comparing the season because I decided that random reset was the way to go and we said, That's all right.

500
00:57:16,720 --> 00:57:22,840
So I'm going to try and generalize the idea of random effects to you guys.

501
00:57:24,510 --> 00:57:36,300
So in our data here and many times this will come about in datasets that you encounter if you get observations from different hospitals,

502
00:57:37,140 --> 00:57:40,080
from different schools, from different communities.

503
00:57:41,090 --> 00:57:49,100
We often think that people are in the same group for reasons that make their values more similar than people from different groups.

504
00:57:49,970 --> 00:57:53,629
Kids go to the same school. Maybe they live in the same districts.

505
00:57:53,630 --> 00:57:57,860
They have the same socioeconomic status. Again, all of these latent factors.

506
00:57:59,060 --> 00:58:02,390
So I'm going to set a model here to my data.

507
00:58:03,290 --> 00:58:07,940
Again, I've got three groups, so I'm going to set categorical two dummy variables.

508
00:58:09,050 --> 00:58:16,010
I'm going to fit a slope and a curvature for time, no interaction, and then have a random intercept.

509
00:58:17,190 --> 00:58:22,530
They don't have a random slope. What I have instead here is as vector group.

510
00:58:24,560 --> 00:58:26,240
So again, that's two dummy variables.

511
00:58:26,330 --> 00:58:33,560
So I have a random intercept and then I have a variance component for group two and the variance component for group three.

512
00:58:51,660 --> 00:58:56,130
Here are the random effects. If I did summary of my model, here are the random effects I got.

513
00:58:58,170 --> 00:59:06,230
I got a variance for the random intercept. I got a variance for this thing and I got a variance for this thing.

514
00:59:08,950 --> 00:59:13,720
And then I have a residual. So what have I done here?

515
00:59:16,060 --> 00:59:21,490
This is the variance in group one. This is the between a subject variance and group one.

516
00:59:23,080 --> 00:59:29,500
The variance between subjects and group two is this one plus this one.

517
00:59:31,100 --> 00:59:34,580
The variance between people in group three is this.

518
00:59:35,590 --> 00:59:39,910
Plus that. And then there's a residual.

519
00:59:43,160 --> 00:59:50,690
So now I've allowed for non constant variance among the groups by fitting a random group effect.

520
00:59:53,490 --> 00:59:53,840
Right.

521
00:59:55,850 --> 01:00:11,780
So if I were to show you this table and I asked you which of the three groups have individuals whose correlation is greatest, would you tell me?

522
01:00:19,160 --> 01:00:24,860
One in three. So we want the group.

523
01:00:24,860 --> 01:00:30,600
Remember correlation is a uterus that's going. Correlation is between.

524
01:00:31,710 --> 01:00:32,820
Divided by total.

525
01:00:33,840 --> 01:00:41,820
So for each group you've got to compute with the between variability is divided by the total and I'm not sure I could figure it out right away,

526
01:00:42,690 --> 01:00:48,280
but for group one. For Group one. It's quite 1128.

527
01:00:48,580 --> 01:00:57,520
That's the between the total is 1128 plus two, two, three, three, one.

528
01:00:57,760 --> 01:01:01,320
For the second group, it's 1128 plus 2903.

529
01:01:01,390 --> 01:01:06,670
That's the numerator. That's the between. And the total is those two numbers plus the error.

530
01:01:08,270 --> 01:01:11,989
And then for the third group, it's 1128 plus 1316.

531
01:01:11,990 --> 01:01:17,959
I tested here divided by those two plus the noise and fitting three correlation.

532
01:01:17,960 --> 01:01:23,450
I'm fitting three exchangeable correlation matrices one for group one, one for group two.

533
01:01:23,450 --> 01:01:28,330
One for group three. So we can do lots of things with random effects.

534
01:01:28,350 --> 01:01:36,060
It doesn't just have to be a random intercept in a random time. Often we have random components when we have people coming from different groups.

535
01:01:36,270 --> 01:01:42,780
Again, this is a different kind of grouping. But again, hospitals, schools, classrooms, universities,

536
01:01:43,650 --> 01:01:49,500
whenever you think that you have individuals from different groups that have latent characteristics that might impact things,

537
01:01:50,520 --> 01:01:57,060
that we fit a random effect for those groups to take out that component of variability to try to take out that nice.

538
01:02:00,510 --> 01:02:06,079
One last thing. And this gets back to what I said earlier.

539
01:02:06,080 --> 01:02:09,740
And when somebody asks me about their homework assignment, is this whole idea of categorical time.

540
01:02:10,310 --> 01:02:17,690
So if the time fact in your mean model is categorical, what should I do to model time with random effects?

541
01:02:18,230 --> 01:02:24,980
Should it be categorical? Should it be continuous? And the question is, is can I estimate all the variance components?

542
01:02:25,490 --> 01:02:29,360
And again, in my data, I have a lot of time points.

543
01:02:29,360 --> 01:02:32,720
So I have one, two, three, four, five, six dummy variables.

544
01:02:33,590 --> 01:02:40,190
So I have set a model here in which time is a category of time as category two groups.

545
01:02:41,260 --> 01:02:44,740
No interaction. And only random intercepts.

546
01:02:45,640 --> 01:02:50,590
Right. So that works. This model's a little bit funky, right?

547
01:02:50,920 --> 01:02:59,950
It has categorical time in the machine model, but it has continuous time in the random slope and the random effect.

548
01:03:01,870 --> 01:03:05,430
But it works. I mean fits.

549
01:03:06,730 --> 01:03:10,610
But again, you have to think about what you're sitting here. Right.

550
01:03:11,660 --> 01:03:18,050
You're saying that correlation is decreasing or correlation is decreasing over time through a random slope model?

551
01:03:21,640 --> 01:03:28,660
You might say, well, I really, really like my fixed effects to look like my random effects design matrix.

552
01:03:29,470 --> 01:03:39,070
So if I have categorical time, I'm going to set a random effect for every timepoint relative to the first.

553
01:03:40,600 --> 01:03:44,320
What do you think is going to happen there? I have throw some people in my dataset.

554
01:03:46,850 --> 01:03:50,690
Right. Which says, are you crazy? Right. That doesn't work.

555
01:03:51,680 --> 01:03:55,069
So again, random effects are really hard to estimate.

556
01:03:55,070 --> 01:03:59,870
Variance components are very hard to estimate. You can't do more than a couple.

557
01:04:00,050 --> 01:04:01,370
Even if you want to do more,

558
01:04:02,810 --> 01:04:11,060
I can't tell you how many times I've gotten some really nice longitudinal data and I know I need to have a random slope and it just doesn't converge.

559
01:04:12,830 --> 01:04:15,980
That happens because of variability. You don't have enough observations.

560
01:04:16,640 --> 01:04:27,450
But then I said, Well, oops. I want to use categorical time in the mine model and I see this dip at two.

561
01:04:27,760 --> 01:04:33,720
Again, I'm making this up. I'm not saying this is a smart thing to do, but I'm going to say, well, you know what?

562
01:04:34,050 --> 01:04:41,040
I'm going to use two categories of time. I'm going to have variability before time two, and I'm going to have variability after time.

563
01:04:42,090 --> 01:04:52,620
And so that's what this model says. If I have a random intercept and then I have this as factor for those below two less than or two and above two.

564
01:04:53,660 --> 01:04:57,140
And that model works. They run the converters.

565
01:04:57,160 --> 01:05:08,950
And I'm not saying it's right. It converges. Where the variance components are there.

566
01:05:09,790 --> 01:05:19,630
So again, I got a random intercept variance and then I have this extra variability for the time points after two and then there's a residual.

567
01:05:19,690 --> 01:05:30,700
So three variance components. Again, I can compare Rimmel, I can Perumal, I can compare to ICBC, those sorts of criteria to see which model fits best.

568
01:05:32,110 --> 01:05:36,070
But there's lots of things you can do. They don't always make sense.

569
01:05:37,210 --> 01:05:45,310
So be smart with what you do with these models. Let's set any other questions on number three.

570
01:05:46,360 --> 01:05:53,580
I am not going to see you until it's due. Everybody's got it own done right.

571
01:05:54,900 --> 01:05:58,740
Excellent descriptions of the results with more than just p values.

572
01:06:00,810 --> 01:06:04,890
This came up in my office hours and shoot. I'm actually going to do a little summary of my data here.

573
01:06:06,300 --> 01:06:12,600
I made the statement that just pasting a coefficient table into a report is not probably always the best thing to do.

574
01:06:13,410 --> 01:06:18,240
Sometimes it is. But whenever you have interactions.

575
01:06:19,850 --> 01:06:26,020
The Co-efficient table is probably not your friend. People don't understand peoples.

576
01:06:26,080 --> 01:06:29,650
Many people don't understand what those interaction terms mean.

577
01:06:30,220 --> 01:06:33,570
It's the difference between the slogan for this group in this group, and this is the.

578
01:06:34,420 --> 01:06:37,450
Don't tell me what the difference is. Just tell me what the two slopes are.

579
01:06:38,230 --> 01:06:41,440
This group has a slope from this coefficient. This group has a slope.

580
01:06:41,440 --> 01:06:45,040
That's the sum of those two. Right. Make it easy for me.

581
01:06:45,880 --> 01:06:50,560
I didn't take by statistics. Right. I went to med school and I'm really great at what I do.

582
01:06:51,870 --> 01:06:55,990
Don't make me add numbers. Take differences. Do it for me.

583
01:06:56,010 --> 01:07:00,060
Right. So just think about things like that. Whenever you have group effects.

584
01:07:01,800 --> 01:07:05,640
Right. And I could do it right here with you, with my mail here. I have categorical time here.

585
01:07:06,580 --> 01:07:09,740
Okay, so we're in the time coefficients.

586
01:07:09,750 --> 01:07:12,840
These coefficients right here. So I know.

587
01:07:12,870 --> 01:07:15,170
I know because I've taken a lot of regression classes.

588
01:07:15,180 --> 01:07:24,870
I know that the intercept refers to Time zero and I know that the first aspect your time there is the difference between time zero and time .05.

589
01:07:26,880 --> 01:07:32,310
Well, just tell me what that number is. 8.5. It's four minus point five.

590
01:07:32,760 --> 01:07:37,380
Tell me what the means are. It is time point rather than telling me the differences.

591
01:07:39,120 --> 01:07:42,600
Of course, inference gets mixed up then because you're adding to coefficients.

592
01:07:43,140 --> 01:07:47,430
Great. What's the variance of two correlated things anyway? But just keep that in mind.

593
01:07:49,350 --> 01:07:53,550
Contrasts are not always the best way to express your results.

594
01:07:54,180 --> 01:07:59,370
Let's try to solve the contrast for people. All right.

595
01:07:59,490 --> 01:08:03,840
Quarter after. Enjoy whatever you do on Forex.

596
01:08:04,740 --> 01:08:11,490
Hopefully gets a little bit of work and fun and we'll see you guys on Wednesday and not on Friday.

597
01:08:13,320 --> 01:08:14,550
All right. Good weekend.

