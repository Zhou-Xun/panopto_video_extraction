1
00:00:07,010 --> 00:00:16,700
Okay. So it's going to start out a little bit with a review of.

2
00:00:18,530 --> 00:00:22,250
The final project rubric.

3
00:00:24,260 --> 00:00:28,830
All right, put that. There.

4
00:00:45,190 --> 00:00:52,480
Okay. We'll try that again.

5
00:00:58,470 --> 00:01:08,730
Here we are. Okay. So for those of you embarrassed that we'll be taking 639 next semester in the school, this will then look familiar.

6
00:01:09,300 --> 00:01:12,900
Next semester when you see it again, not quite the same.

7
00:01:13,530 --> 00:01:16,520
So but the basic structure I'm kind of laid out in the same way.

8
00:01:16,650 --> 00:01:23,120
Like to have an introduction, statistical methods, results and conclusion can be your main sections.

9
00:01:23,130 --> 00:01:27,660
If there are some sections or things you think make sense to fiddle with on that, that's fine.

10
00:01:27,660 --> 00:01:32,430
This is like rigid, but you should probably have some basic structure along these lines.

11
00:01:33,750 --> 00:01:40,620
So the introduction should give some explanation of what the issue is or the problem that you're addressing.

12
00:01:41,390 --> 00:01:49,020
If there are specific hypotheses, try and state those as well as you know, cite an existing researcher publications.

13
00:01:50,100 --> 00:01:54,149
And one distinction here is that we've tied to causal inference.

14
00:01:54,150 --> 00:02:01,770
So you should make some connection with that as well in the introduction. And for the methods, make sure you explain what you're what you're doing,

15
00:02:02,880 --> 00:02:08,520
that they're appropriate and you know, have some focus or relationship to the causal inference context.

16
00:02:09,240 --> 00:02:13,110
And, you know, don't, don't go crazy, you know, don't try 100 things.

17
00:02:14,100 --> 00:02:21,299
You may you may do more stuff in your background than you actually in the process of putting together than you do for the for the actual report.

18
00:02:21,300 --> 00:02:24,780
And that's okay. So you don't need to say everything you did it.

19
00:02:24,780 --> 00:02:32,610
There's things that you think or did report what you would, what relates to the results that you're going to be presenting.

20
00:02:33,000 --> 00:02:36,390
And if you're doing like sensitivity analysis or things like that, that's fine. Those should be included.

21
00:02:37,110 --> 00:02:42,390
But but for sort of you don't even necessarily go, go, go crazy on that.

22
00:02:42,540 --> 00:02:48,210
The goal is to try to answer the question, not show off how much you might know.

23
00:02:49,230 --> 00:02:56,880
So then for the results, you know, make sure that you're explaining clearly and interpreting it correctly.

24
00:02:58,170 --> 00:03:01,830
You know, you should have enough plots and tables, but not too many.

25
00:03:03,600 --> 00:03:08,010
So I think you can look and I do we do have some examples I believe are posted up for you

26
00:03:08,200 --> 00:03:12,540
to look at so you can sort of get a sense and they should be easy to read to understand.

27
00:03:12,960 --> 00:03:21,460
Ideally, a plot will plot figure or plot a table should should be somewhat self-contained.

28
00:03:21,690 --> 00:03:28,499
So you can sort of read them that maybe, maybe use a little bit of duplication between what's in the text and what's in the what's in the captions.

29
00:03:28,500 --> 00:03:35,700
And that's fine. So it doesn't obviously, but it can't be completely self-contained.

30
00:03:35,700 --> 00:03:38,309
I mean, it's embedded in this paper and the idea is you read in paper,

31
00:03:38,310 --> 00:03:43,170
but you should be able to look at the plot and not have to refer too much back to the text to understand what's going on.

32
00:03:46,110 --> 00:03:50,579
And then for conclusion, you know, you should, you know, summarize your results and you know,

33
00:03:50,580 --> 00:03:57,420
how that relates to the to the broader question and maybe some of the previous literature, if you were looking at that.

34
00:03:58,530 --> 00:04:03,239
And then, you know, typically there's some discussion of limitations because, you know,

35
00:04:03,240 --> 00:04:08,700
there's no absolute perfect solution to any any sort of non-trivial problem here typically.

36
00:04:09,240 --> 00:04:14,049
And so there may always be, you know, limitations or assumptions and so forth, especially in causal different setting.

37
00:04:14,050 --> 00:04:23,370
You have to make assumptions. So state those in how they in the context of the particular issue, they may be less or more important.

38
00:04:24,720 --> 00:04:27,420
And then finally, if there are sort of other things that you think could have been done,

39
00:04:27,420 --> 00:04:30,900
you just didn't have time or, you know, to try to limit the paper here.

40
00:04:32,070 --> 00:04:36,960
That's that's good to squeeze the least more work down the road.

41
00:04:38,280 --> 00:04:42,180
So I haven't really specifically included quality of writing the rubric.

42
00:04:42,510 --> 00:04:48,570
That's one distinction from the 699. But you know, because I've been trying to make this quite at the 699 level, but,

43
00:04:48,990 --> 00:04:56,980
but it'll be easier to obtain credit for each criterion if the style is correct and the grammar writing are sufficiently clear and so on,

44
00:04:57,270 --> 00:05:01,840
so that I sort of get embedded in there. Okay.

45
00:05:02,940 --> 00:05:07,890
And I guess the other thing, too, is those of you asked for revisions, if you could please get those back to me by Friday.

46
00:05:10,530 --> 00:05:12,840
Any questions about the report at this point?

47
00:05:14,760 --> 00:05:27,930
I talked to a lot of people have talked with me and we've given feedback, you know, so, yes, for the policy tables,

48
00:05:27,930 --> 00:05:34,170
do you think you would like a table one table characteristics or just the results are just specific?

49
00:05:35,250 --> 00:05:37,500
That sort of depends on on the context or what you're doing.

50
00:05:37,500 --> 00:05:45,810
But yeah, so just to be clear, this idea of table one is sort of descriptive statistics for your data that's usually important to put in there.

51
00:05:45,960 --> 00:05:49,260
So that's a good point. Yeah, I'll do that.

52
00:05:49,260 --> 00:05:58,120
It will be good. Okay.

53
00:05:59,500 --> 00:06:07,370
So the questions. All right, then.

54
00:06:09,290 --> 00:06:13,050
Close this up. To.

55
00:06:39,580 --> 00:06:45,340
Okay. So we were having an initial discussion, a section of multiple mediators.

56
00:06:48,550 --> 00:07:01,780
So when there's no sort of mediator interaction, we can we can fairly easily sort of get away with our modeling approach.

57
00:07:03,280 --> 00:07:08,440
But we do have these interactions. Then things can sometimes get a little trickier.

58
00:07:09,580 --> 00:07:19,270
So particular our outcome depends not only on the treatment, the value of the mediator,

59
00:07:20,200 --> 00:07:29,170
and the interactive potential interactions between the mediator and the in the treatment, but as well as within the mediators themselves.

60
00:07:29,380 --> 00:07:33,730
And then coherence as well. So.

61
00:07:35,820 --> 00:07:43,380
Since its end get specs and some of your value gets fixed at the same value for the contrast and the direct and indirect effects.

62
00:07:45,210 --> 00:07:48,630
Controlled or natural in a way. Sorry for the direct effects and the control.

63
00:07:48,630 --> 00:07:53,670
Direct effects are natural direct effects. These interaction terms basically cancel.

64
00:07:54,030 --> 00:07:58,530
So without completely getting back into the weeds here.

65
00:08:10,050 --> 00:08:12,830
I with that here on the program.

66
00:08:20,930 --> 00:08:32,660
So we said we can fix these at some sort of value low in the overall rate and variable demeanors being in and then change.

67
00:08:35,420 --> 00:08:39,860
Treatment and see and sort of under the.

68
00:08:52,190 --> 00:08:58,940
So sort of standard conditions. Very good fidelity to the observed data.

69
00:09:14,070 --> 00:09:18,210
So basically the interaction terms here will cancel.

70
00:09:27,870 --> 00:09:29,310
Right. We're keeping em constant.

71
00:09:30,240 --> 00:09:39,330
So even if we have a bunch of interaction in terms of their first animation on the slide there, they're the same for each of these expectations.

72
00:09:39,360 --> 00:09:57,790
And so we the traffic. So that more work for the and I'm assuming the sort of quality and measures.

73
00:10:06,370 --> 00:10:16,570
So for an actual direct effect, we're not fixing them, but learning to take on its value and control the treatment.

74
00:10:18,070 --> 00:10:32,270
So go back and look at her notes from Chapter eight, basically means if you're looking at these.

75
00:10:38,970 --> 00:10:43,410
So we're going to fix. And again.

76
00:10:47,430 --> 00:10:53,610
We started it now because we're not keeping him constant, but letting a lot of people stay here.

77
00:11:04,320 --> 00:11:11,580
We have to average over this distribution of labor given given next start.

78
00:11:16,230 --> 00:11:26,130
We're hearing complaints. Yes, but we're still good here because, you know, these interactions tend to cancel.

79
00:11:43,410 --> 00:11:47,190
But naturally correct. In fact, it's actually messier.

80
00:11:56,180 --> 00:12:07,790
Now we're going to fix a. But he's the leader.

81
00:12:09,470 --> 00:12:14,450
So you wonder treatment is valuable for.

82
00:12:19,720 --> 00:12:31,390
Do. Now, not all as expected.

83
00:12:31,390 --> 00:12:36,400
Value just arrived in the market, but now we need to average over difference.

84
00:12:41,350 --> 00:12:50,800
You should sort the probabilities as so that people are going to.

85
00:12:56,510 --> 00:12:59,630
So we're basically is now we need a.

86
00:13:02,300 --> 00:13:09,440
Not all. The sterilized product.

87
00:13:19,920 --> 00:13:29,060
Of the multiple years. And they're just kind of stuck on one.

88
00:13:30,560 --> 00:13:34,760
Didn't have to worry about that. But.

89
00:13:43,820 --> 00:13:50,209
Now we're going to have because we essentially have to take the expectation of this.

90
00:13:50,210 --> 00:13:54,920
Right. It's part of that approach. Then we're going to have to look at this difference here.

91
00:13:56,420 --> 00:14:02,160
And so we could potentially find a linear model.

92
00:14:02,180 --> 00:14:07,909
These are continuous stolen pairwise products that can be quickly gone untenable.

93
00:14:07,910 --> 00:14:10,550
If you have even higher interactions, you're going to worry about those.

94
00:14:12,830 --> 00:14:19,700
And more generally, it's difficult to deal with the marginal models and a model for the product at the same time,

95
00:14:20,150 --> 00:14:26,030
because we're going to need both of those when we go to compute these these probabilities.

96
00:14:27,350 --> 00:14:32,240
So there's a little bit of detail on this. I'm not going to push it, but you can take a look at it.

97
00:14:34,400 --> 00:14:40,730
Basically, if you have continuous mediators, you could assume some covariance matrix between the residuals for regression model.

98
00:14:41,630 --> 00:14:47,420
That doesn't depend on an error x. If it does, then you get additional complications.

99
00:14:48,050 --> 00:14:54,950
And so that the multi approach just gets gets a little bit more untenable in this situation.

100
00:14:55,940 --> 00:15:00,799
So but we can go back to our propensity weighting approach, right?

101
00:15:00,800 --> 00:15:10,100
So we can cycle way back to we talked earlier in class the propensity weights as an alternative to regression modeling for.

102
00:15:15,430 --> 00:15:23,080
Poor accounting for the least these distributions under these counterfactuals.

103
00:15:24,970 --> 00:15:31,600
So basically this is going to dispense for the need to worry about his medium or immediate or

104
00:15:31,600 --> 00:15:35,950
mediator interactions and can be applied really regardless of the distribution of the outcome.

105
00:15:36,970 --> 00:15:51,950
So. We're still going to need to model the outcome as a function of the exposures and the mediators.

106
00:15:53,180 --> 00:16:02,480
But once we have that model, we can use the propensity weights to estimate that model rather than plugging in these components.

107
00:16:03,770 --> 00:16:07,100
So we don't get away from our assumptions.

108
00:16:07,460 --> 00:16:11,060
Right. So these aren't confounder exposure, exposure outcomes,

109
00:16:11,990 --> 00:16:17,420
the uncontrolled immediate outcomes and confounder exposure mediators and no

110
00:16:17,420 --> 00:16:21,380
confounders between the mediator and the outcome that are expected by exposure.

111
00:16:21,410 --> 00:16:24,950
All those are still going to be required for these propensity models.

112
00:16:25,130 --> 00:16:31,760
Pretty late estimate to be unbiased for these causal quantities.

113
00:16:38,000 --> 00:16:45,649
So but the basic idea, and I should add it maybe not 100% clear from the from the text,

114
00:16:45,650 --> 00:16:48,980
but you don't have to be in the multiple mediators setting to use these.

115
00:16:49,280 --> 00:16:52,610
You can use these anyway. So it's an alternative.

116
00:16:52,910 --> 00:16:58,550
It's a full alternative. Even with a single mediator, everything going to work out here can be used in the same fashion.

117
00:16:59,720 --> 00:17:03,530
So so we, we,

118
00:17:03,680 --> 00:17:07,999
we basically are going to estimate our three expectations for the national direct and indirect

119
00:17:08,000 --> 00:17:13,580
effects using weights equal to the inverse of the probability being an exposure control group.

120
00:17:13,670 --> 00:17:20,210
So this issue of accounting for the lack of randomization at the exposure treatment level.

121
00:17:27,230 --> 00:17:36,620
Depending whether interest in the counterfactual, immediate or simple exposure. A exposure of a control value conditional on the based on covariance.

122
00:17:40,160 --> 00:17:55,010
So. So essentially we're going to get expectations of each of these potential outcomes.

123
00:17:56,150 --> 00:17:59,650
So. Under treatment.

124
00:18:01,600 --> 00:18:06,749
Under control, of course. Reinforce this later on.

125
00:18:06,750 --> 00:18:13,080
But this is the overall treatment effect, right?

126
00:18:13,230 --> 00:18:18,750
This is the overall mean for why under treatment. Right. Because we let the mediator take whatever value it happens to naturally.

127
00:18:19,590 --> 00:18:22,590
This is the overall effect.

128
00:18:23,370 --> 00:18:30,510
The overall mean for the outcome under control. But the media take control back then for mediation estimation itself.

129
00:18:30,920 --> 00:18:40,890
Right. We've got to look at this distinct where we consider a each outcome under treatment or the mediator takes on this control value.

130
00:18:42,270 --> 00:18:50,550
And essentially each of these can be estimated using our propensity score weights.

131
00:18:51,090 --> 00:18:56,820
So basically, for this first component here, we're going to look at.

132
00:19:00,940 --> 00:19:09,370
The weighted value for Y and the control where the weights are given by the probability of being in the control given covariance

133
00:19:09,850 --> 00:19:16,780
and we're going to use the stabilized weights or he's going to have the overall population in control in the numerator.

134
00:19:18,970 --> 00:19:29,320
So for the treatment group, we're going to look at the weighted mean where the weights are now given by the probability of actually being treated,

135
00:19:29,620 --> 00:19:32,530
given, covariance stabilized.

136
00:19:34,210 --> 00:19:41,800
And finally, for this last one sort of most complex one here, we're still going to wait by the probability of being in the in the control group.

137
00:19:42,340 --> 00:19:52,870
But now we're going to use our model prediction of why, given a and it's observed covariance and X.

138
00:19:54,750 --> 00:20:03,420
So. So, of course, once we have all of these, we can immediately compute our natural, direct and indirect effects.

139
00:20:04,990 --> 00:20:14,140
Right. So for our natural direct effect, we fix the control matrix, the mediator and control value and change the treatment.

140
00:20:14,220 --> 00:20:21,780
So it's this, it's this. And then for our natural indirect effects, we're going to fix the.

141
00:20:26,620 --> 00:20:41,829
Treatment or exposure at the sort of treated or level and then consider the difference between and at the at the mediators taking on their value of

142
00:20:41,830 --> 00:20:51,910
treatment in their evaluate control this this should just boldface these to indicate these can be multiple mediators and so there I missed that so.

143
00:21:04,300 --> 00:21:15,210
So. So just conceptually, we're trying to sort of sort out.

144
00:21:19,190 --> 00:21:27,290
And because we're not, we're allowing them the mediator and the treatment to be the same value here.

145
00:21:27,290 --> 00:21:30,430
We can actually use the observe wise to estimate these. Right.

146
00:21:30,980 --> 00:21:39,730
This is just the good old fashioned propensity score thermometer. Further me under treatment and I mean under control here.

147
00:21:39,730 --> 00:21:49,959
Things are a little a little uglier because we're in this now sort of cross world scenario where we're going to fix that, the treatment level.

148
00:21:49,960 --> 00:21:53,830
But then we're let the media take on mediator, take on its control value.

149
00:21:54,490 --> 00:21:58,390
So I'm just like up here, right?

150
00:21:59,050 --> 00:22:12,130
We're sort of trying to average out over any discrepancies, uh, from, uh, from the treatment assignment given covariance.

151
00:22:12,790 --> 00:22:23,410
But rather than using the observed value, we're going to use the predicted value from our, our, our model.

152
00:22:31,630 --> 00:22:39,580
So we're essentially taking all the observations that are in control and saying what would they have had had they been assigned to treatment?

153
00:22:45,720 --> 00:22:49,440
And then what? Do you end? Enough by the probability of being assigned to patrol.

154
00:22:51,790 --> 00:23:03,670
So essentially, if we if we had a randomized assignment and then looking at their predictive values under under the other arm,

155
00:23:04,030 --> 00:23:09,610
the arm to which they were not assigned the treatment case. Okay.

156
00:23:09,690 --> 00:23:14,570
So from that work.

157
00:24:06,830 --> 00:24:15,890
All right. So just for the notation, I'm going to assume that X and or vector.

158
00:24:26,210 --> 00:24:39,820
Three. Basically the continuous version needs to be replacing these probabilities with their tedious.

159
00:24:46,890 --> 00:24:57,240
So I'm going to work out this one, which is the toughest one for those kinds of stories when.

160
00:25:22,410 --> 00:25:29,219
All right. So. Basically we can go from our defense.

161
00:25:29,220 --> 00:25:41,520
So I would consider how you replace these this with the potential outcome traditionally and then thinks and a store we get.

162
00:25:44,520 --> 00:26:04,200
An average of ten cases. But to go to the potential and the potential outcomes to serve you better just basically one before slide ten four, but also.

163
00:26:06,320 --> 00:26:14,840
Give them. Be. So the next step here.

164
00:26:17,870 --> 00:26:22,510
And borrowing notation from the book explaining that I wanted to change this.

165
00:26:42,990 --> 00:26:51,570
Okay. So I'm bringing down the expectation of supply and demand and you just start getting this.

166
00:26:51,590 --> 00:26:55,319
You should be asking me. But what?

167
00:26:55,320 --> 00:27:01,610
I'm going from here to here. So basically that's.

168
00:27:33,650 --> 00:27:49,130
All right, so this. Sort of think of this traditional distribution fixing at a store is basically the more general distribution of them given a set.

169
00:27:53,790 --> 00:27:58,769
Restricting it to the values or using the base star. So it's a little funky right there.

170
00:27:58,770 --> 00:28:02,940
Basically, if they only store one zero,

171
00:28:03,810 --> 00:28:16,770
then basically every day I'm giving a one an X Times indicator that is one plus the probability that the market probability could be.

172
00:28:19,640 --> 00:28:32,140
Mathematics is the problem. And if I had x x plus probably starting next year, the probability is large.

173
00:28:32,560 --> 00:28:40,750
So the condition is these behaviors form the basis of look at this marginal probability, but only partially.

174
00:28:41,920 --> 00:28:48,340
So that's a little jump here in this nation at the bottom.

175
00:28:49,330 --> 00:28:56,200
So I guess the other thing, too, is that sort of this area is fixed and so whatever.

176
00:28:59,010 --> 00:29:08,330
This. Here is the summation over here and here. So.

177
00:29:30,190 --> 00:29:38,520
So we rank this conditional probability as.

178
00:29:45,100 --> 00:30:04,530
For all probability. Provided by his kids.

179
00:30:04,540 --> 00:30:08,160
Chicago, he may be the next.

180
00:30:09,630 --> 00:30:15,690
So here's the trick.

181
00:30:31,930 --> 00:30:38,440
Right. For his role here. It really is that his national leadership ability to.

182
00:30:47,930 --> 00:30:55,639
Right. So I'm getting an agent here. Then they're going to speak to him and he would probably have a condition.

183
00:30:55,640 --> 00:31:02,640
That's a little. So why is.

184
00:31:04,690 --> 00:31:13,160
That they're bringing this on here. Yeah.

185
00:31:24,670 --> 00:31:51,450
If the multiple sides where the American public backs. Right.

186
00:31:53,160 --> 00:31:56,490
Moreover, in times the conditions of an actual system or marginal.

187
00:31:57,450 --> 00:32:04,020
And so I've been able to pull. The pieces here.

188
00:32:08,160 --> 00:32:22,550
This. So basically this additional probability that we're going to hear next and the market probably has a joint probability.

189
00:32:27,340 --> 00:32:32,010
We're all in the house and the other divided by the.

190
00:32:32,310 --> 00:32:39,060
But. So.

191
00:32:56,340 --> 00:33:10,270
So since then, restricting this to a store and I'm selling over accidentally here and so this is just the overall expectation would.

192
00:33:35,270 --> 00:33:40,160
And so the expectation means that basically going to be taking his wife and having a child over.

193
00:33:46,700 --> 00:34:02,360
The actual. The summation.

194
00:34:05,640 --> 00:34:12,330
It is reliability. This is going to be the expectation that is expected and.

195
00:34:15,230 --> 00:34:23,370
With the entire distribution of vaccine. And then I have this principle here.

196
00:34:45,950 --> 00:34:49,630
So that's how restrictive the cases were able to start.

197
00:34:50,520 --> 00:35:00,290
The problem is able to say is basically we're just looking at a historic day here as well with both ranges,

198
00:35:00,290 --> 00:35:07,430
but only, for example, there has been some sort of occasion.

199
00:35:11,200 --> 00:35:14,380
So. And we can play the same game.

200
00:36:05,790 --> 00:36:11,360
So I think. Yeah.

201
00:36:12,380 --> 00:36:12,630
Yeah.

202
00:36:54,380 --> 00:37:06,810
So I guess there is one less piece I don't know myself, but basically what should be the expectations indicator is just about every main star here.

203
00:37:10,850 --> 00:37:14,720
And so.

204
00:37:20,750 --> 00:37:24,920
So what I want is to make this estimate.

205
00:37:25,040 --> 00:37:38,089
For this estimate is the best way. It's very easy to estimate this, right?

206
00:37:38,090 --> 00:37:44,150
This is just a portion of cases that are under control here.

207
00:37:45,280 --> 00:37:51,589
You know, logistic regression can be a logical thing, although assuming you're looking at projects that are sort of fancier methods,

208
00:37:51,590 --> 00:37:56,569
you can consider more machine learning type methods for this kind of classification.

209
00:37:56,570 --> 00:38:02,360
So that's fine. And then finally, I've got to estimate this for my model for a while.

210
00:38:02,630 --> 00:38:08,920
So I still have a model for argument and an X. I mean, I'm a model for this, too, right?

211
00:38:08,930 --> 00:38:16,190
So there's still models here. Oh, free. And that second model.

212
00:38:16,200 --> 00:38:19,339
Right, could use linear regression for continuous outcomes, logistic regression,

213
00:38:19,340 --> 00:38:23,780
binary outcomes, whatever kind of generalized linear model with the appropriate link function.

214
00:38:23,780 --> 00:38:28,940
If you have some Y that's, you know, either binary or nominally distributed,

215
00:38:29,130 --> 00:38:35,180
obviously you can look at interactions between mediators, between the mediators themselves, right?

216
00:38:35,930 --> 00:38:44,930
So they can be incorporated as suggested by the data. So this does automatically average over the covariance.

217
00:38:45,140 --> 00:38:52,220
So these conditional natural correcting natural indirect effects are so estimable.

218
00:38:54,230 --> 00:39:00,469
And while I've put them here as a vector, it could be, as I mentioned before, it could be scalar, right?

219
00:39:00,470 --> 00:39:06,530
So all the previous results we did that were fully model based could be replaced with these density score type approaches.

220
00:39:07,820 --> 00:39:13,399
So there's nothing magical about element works when you have interactions between mediators that can be used.

221
00:39:13,400 --> 00:39:19,370
But if you get into these more complex models of multiple mediators, it becomes a simpler way of trying to deal with these.

222
00:39:20,360 --> 00:39:31,760
But these interactions. So.

223
00:39:36,850 --> 00:39:41,290
Right. And so I guess we have a couple more questions.

224
00:39:41,290 --> 00:39:47,770
So articulate particularly became a last point that you could use it with a single mediator.

225
00:39:48,520 --> 00:39:51,430
What are some of the advantages of the weighting approach versus the regression approach?

226
00:40:07,810 --> 00:40:13,230
So clearly in the multimedia with me here with the interaction mediations, it's very obvious that really approaches superior.

227
00:40:13,610 --> 00:40:19,060
The simple case is what? What might be sort of the tradeoff.

228
00:40:44,550 --> 00:40:48,160
So when I got this class on Zoom, I can say I have my coffee.

229
00:40:48,170 --> 00:40:52,520
I'm sitting here in the computer, I can wait so I don't have my coffee anymore.

230
00:40:52,520 --> 00:41:00,020
But I can still be. Yes.

231
00:41:00,680 --> 00:41:07,610
Yeah. I mean, I think like for the regression approach, it's maybe a little bit less interpretable, but just in terms of, you know,

232
00:41:07,610 --> 00:41:10,950
you're you're basically going to weighting the expectation by the, you know,

233
00:41:11,000 --> 00:41:16,520
probability of how you're going to be observing the condition and compared to the mediator.

234
00:41:16,520 --> 00:41:19,879
And like what you would expect was to be, I think in regression,

235
00:41:19,880 --> 00:41:27,890
it's a little bit more you've got like multiple steps in the regression, so maybe it's a little bit less clear, at least for me.

236
00:41:28,100 --> 00:41:31,190
Okay. Uh, so.

237
00:41:34,010 --> 00:41:38,420
So. So you said regression approach for both. The first one you meant was the weighting.

238
00:41:38,720 --> 00:41:46,490
Okay. Okay. Okay. So you feel like that sort of multiple models in the in the in the Marley approaches?

239
00:41:47,140 --> 00:41:51,980
You know, that's interesting perspective. So they had some truth here.

240
00:41:54,560 --> 00:42:00,260
So, um, but probably but there's some other, other issues.

241
00:42:00,260 --> 00:42:04,470
I think I also was looking to sort of pick up. Yeah.

242
00:42:04,980 --> 00:42:11,460
Um, the regression approach, you can see sort of the individual effects of each area.

243
00:42:11,580 --> 00:42:15,580
Mm hmm. That's true. That's true.

244
00:42:15,600 --> 00:42:19,980
Particularly if you don't, you know, worry about these interaction pieces, if you don't think that they're relevant.

245
00:42:20,860 --> 00:42:26,940
Um, what's. What's one sort of disadvantage of the winning approach that's pretty common across a lot of wedding approaches?

246
00:42:30,010 --> 00:42:41,930
A potential disadvantage doesn't have to be. I guess you have to.

247
00:42:41,960 --> 00:42:46,280
You have to estimate. You do? I mean, all these. So there's a sort of a moral issue here.

248
00:42:46,280 --> 00:42:50,000
And so some of these machine learning things can be sort of try to deal with part of that.

249
00:42:50,480 --> 00:42:55,310
Obviously, the more fundamental issues that you need the is available to make these assumptions

250
00:42:55,320 --> 00:43:01,490
as something is not so easy to deal with machine learning versus model.

251
00:43:01,640 --> 00:43:09,980
But but yes. So you have model assumptions. But what else can go on with the weights that cause trouble?

252
00:43:16,460 --> 00:43:20,480
When we talked about reading earlier, we talked about like the robustness and variance tradeoffs.

253
00:43:20,600 --> 00:43:25,430
Yeah. So. So that's in the Veterans Trade Office because of.

254
00:43:28,390 --> 00:43:36,400
And what's the variance trade off and why does it happen if you have a more robust estimate and have more variance?

255
00:43:36,640 --> 00:43:41,050
Yes. And the bigger variance is cause because the weights are variable.

256
00:43:41,110 --> 00:43:45,190
Right. So if you have. So some of this gets back to.

257
00:43:47,240 --> 00:43:51,350
To the whole point of this. Kamloops back to the whole issues of.

258
00:44:00,120 --> 00:44:11,610
Support and overlap. So certain covariate patterns have very little possibility of being under treatment or control.

259
00:44:13,890 --> 00:44:17,280
Then these weights are going to be very large in a very a lot.

260
00:44:18,090 --> 00:44:19,800
And so the estimates become quite unstable.

261
00:44:22,170 --> 00:44:32,750
The regression approach avoids that at the cost of essentially doing projecting out from the observed data into the parts,

262
00:44:33,570 --> 00:44:37,290
the parts of the covariance space where there's nobody who's assigned to that tree

263
00:44:37,290 --> 00:44:41,069
birth control but using where they were assigned saying We've got this linear model,

264
00:44:41,070 --> 00:44:42,660
so we're going to stick it up here.

265
00:44:43,620 --> 00:44:57,960
So that is so that leads to more stability at the cost of of potentially being wrong if that that sort of extrapolation is incorrect.

266
00:44:58,950 --> 00:45:06,069
So so of course, I guess there's the bonus of the weights is that when these weights get really unstable,

267
00:45:06,070 --> 00:45:12,330
that's telling you having this issue of, you know, maybe you want to sort of rethink about what you can actually say.

268
00:45:13,380 --> 00:45:18,450
So I basically take only paraphrase is essentially the limitation of regression.

269
00:45:18,460 --> 00:45:25,550
What you're saying is that, you know, it's really just focusing on the data that you have and putting on a kind of rather than the

270
00:45:25,560 --> 00:45:28,920
weight is also considering like I'm here and there might be some variability in kind of,

271
00:45:29,430 --> 00:45:37,860
you know, what we have observed too is that, well, I would say it's more like the the the way the approach gives you a signal that there

272
00:45:37,860 --> 00:45:44,370
are parts of the data that are not well covered in terms of the treatment assignment.

273
00:45:44,760 --> 00:45:50,700
So they're they're sort of parts of the covered space where we can't say much unless we extrapolate, which is what they.

274
00:45:51,760 --> 00:45:53,139
The sort of regression approach.

275
00:45:53,140 --> 00:46:01,810
But that's just general, not only for this particular thing, but just for that, just for good old fashioned, not real mediation.

276
00:46:01,810 --> 00:46:04,630
Just the truth is the cause and effect itself of treatment.

277
00:46:05,020 --> 00:46:13,339
So yeah, in terms of the extrapolation, does that mean that one of these methods is better for if you're into this,

278
00:46:13,340 --> 00:46:18,040
other groups are like more well balanced in terms of your covariance.

279
00:46:18,310 --> 00:46:22,990
Well, if they're more well balanced and probably you won't have so much issue with the weights being unstable.

280
00:46:23,800 --> 00:46:36,400
So but also your regression model while still having probably some modeling assumptions is it's going to be well estimated over that covariance space.

281
00:46:37,000 --> 00:46:41,530
So so there's no that's not necessarily a right answer here.

282
00:46:43,060 --> 00:46:49,510
I think what the weighting does is it gets away from extrapolation at the cost of either saying you have to have a,

283
00:46:50,350 --> 00:46:55,700
you know, I mean, if you have a lot of data, right? So even even the small areas have some data in them.

284
00:46:55,720 --> 00:47:00,010
So the weights may be big, but with enough data, the whole thing kind of stabilizes.

285
00:47:00,880 --> 00:47:09,010
So, so you either need more data or you need to live with the fact that you get a lot of uncertainty from this extrapolation.

286
00:47:11,710 --> 00:47:23,440
Or you say, I'm going to talk about mediation in this reduced covariate space for more generally causal effects in this reduced covariance space.

287
00:47:25,270 --> 00:47:29,530
So those are the things that the weights sort of do, or I throw out the weight approach,

288
00:47:29,530 --> 00:47:35,280
go back to my models and say I'm extrapolating if we make that assumption, this is what we have.

289
00:47:42,640 --> 00:47:51,380
Okay. I think this class question isn't quite correct.

290
00:47:51,920 --> 00:47:56,000
I think what I was trying to ask is what are these weighted sums for the.

291
00:47:59,970 --> 00:48:08,120
I kind of highlighted this before. So this sort of emphasize the point right before we even talked about mediation.

292
00:48:09,260 --> 00:48:44,110
What did this weighted sum represent? Put another way.

293
00:48:44,380 --> 00:48:49,090
I also write this as the the predicted expectation of.

294
00:48:51,410 --> 00:48:54,720
Population proportion trying to find.

295
00:48:58,340 --> 00:49:02,740
I'm not sure I'll come under control. That's right.

296
00:49:02,780 --> 00:49:09,080
So this is just the just this is just the. I would.

297
00:49:53,250 --> 00:50:12,130
One. But.

298
00:50:23,040 --> 00:50:30,300
Right. From our old business analysis especially we from.

299
00:50:39,650 --> 00:50:49,090
Right. So. 50.

300
00:50:53,230 --> 00:51:00,700
So. Right. We're just waiting then by the probability of actually being assigned to whatever treatment they were assigned to.

301
00:51:01,480 --> 00:51:09,730
So. I guess it's another way of saying that.

302
00:51:19,220 --> 00:51:31,520
When we get into separating these. Right.

303
00:51:34,600 --> 00:51:39,510
But. Right.

304
00:51:39,560 --> 00:51:50,710
This sort of. Where we restrict the counterfactuals to simply considering treatment versus control.

305
00:51:52,180 --> 00:52:06,610
That's the same thing as where we let the mediator take on whatever value would take under treatment or under control along with the actual treatment.

306
00:52:06,880 --> 00:52:21,710
Either in treatment. Right.

307
00:52:21,770 --> 00:52:36,200
So. So.

308
00:52:42,760 --> 00:52:55,520
So. So there might be situations where the meat eaters may influence each other causally in addition to the outcome.

309
00:52:57,140 --> 00:53:05,900
That means that for the assumption that basically this potential outcome is independent under a given treatment,

310
00:53:05,900 --> 00:53:10,220
is independent of the mediator, under the other arm is no longer met.

311
00:53:11,390 --> 00:53:17,440
So I guess. Yeah.

312
00:53:18,010 --> 00:53:28,410
Yeah. Over here. So we first started drawing and so mostly two years.

313
00:53:32,990 --> 00:54:11,220
In this picture. So.

314
00:54:14,660 --> 00:54:15,290
We had some.

315
00:54:27,450 --> 00:54:37,290
This idea is going to have multiple parts from the treatment to the outcome and lacking randomization and with randomization we might have.

316
00:54:42,860 --> 00:54:48,770
Confounding between the demeanor and the outcome.

317
00:54:50,060 --> 00:54:54,950
And so that's it. That's why also fixed the arms and possibly the age.

318
00:54:55,050 --> 00:54:58,600
Well we don't have randomized center. So.

319
00:54:59,740 --> 00:55:09,630
But it's of leftists. These folks are independent, so they might have that.

320
00:55:11,800 --> 00:55:19,640
So. So let's say we are going to.

321
00:55:45,950 --> 00:55:50,329
Right. So we're sort of trying to assess. This year.

322
00:55:50,330 --> 00:56:00,450
I'm here. So. So.

323
00:56:16,460 --> 00:56:20,720
So that's essentially the effect. They just go.

324
00:56:24,970 --> 00:56:49,450
So. Basically.

325
00:56:55,260 --> 00:57:05,310
So you have some effect from the treatment that doesn't go through the media as all as well as this piece that kind of goes around to.

326
00:57:06,970 --> 00:57:10,540
So this is the sort of indirect effect.

327
00:57:11,980 --> 00:57:51,220
So the problem here is that. It blocked the state into the White House and.

328
00:58:13,830 --> 00:58:20,970
So we sort of get this cut out for revlon's this fall in direct effect in just trying to progression.

329
00:58:22,260 --> 00:58:25,940
But we know adjust for to.

330
00:59:32,820 --> 00:59:40,110
We've got to just do this. We've got this companion piece left that's going to give from the results about the direct effect.

331
00:59:42,000 --> 00:59:45,240
Can you point out the confounding piece and the model?

332
00:59:45,750 --> 00:59:54,090
So. And then.

333
01:00:05,540 --> 01:00:17,150
So I went to services and found her. But if I was just going to take this piece out, I've got the correct things so we can flip it around either way.

334
01:00:19,720 --> 01:00:24,010
So. So great.

335
01:00:24,020 --> 01:00:30,380
So if I want to transport that, essentially I've got this new record that is here.

336
01:00:30,530 --> 01:00:34,840
Okay, now I've messed up. Andy.

337
01:00:35,360 --> 01:00:39,799
I do it just for family, right? But now I've lost this part.

338
01:00:39,800 --> 01:00:52,940
In fact, it doesn't go to. Slipped my mind to them to.

339
01:01:10,210 --> 01:01:14,500
All right. So the text refers to this as exposure induced confounding.

340
01:01:15,280 --> 01:01:18,850
In nonrandomized studies it's sometimes referred to as confounding by indication.

341
01:01:20,140 --> 01:01:29,650
So. So, again, the problem is if we're using logistic regression, also confounder, we're not treated as a mediator and vice versa.

342
01:01:31,480 --> 01:01:36,110
So. The solution.

343
01:01:37,710 --> 01:01:41,180
Well, okay, here's an example of this. So.

344
01:01:44,140 --> 01:01:55,300
Right. So an example of this, if we sort of go back to our our previous example of adult exposure to poverty, if diabetes,

345
01:01:55,510 --> 01:02:02,890
we were talking about the mediation effect of diabetes, it's possible that poverty might lead to later in life health issues.

346
01:02:03,520 --> 01:02:08,799
So the poverty might be part of both the causal pathway between childhood poverty

347
01:02:08,800 --> 01:02:13,510
and mortality and a confounder between the mediator of diabetes and mortality.

348
01:02:14,770 --> 01:02:17,770
So. In this.

349
01:02:21,050 --> 01:02:24,800
This sample. Poverty.

350
01:02:35,130 --> 01:02:39,840
Survival is just zero one advantage by the moral.

351
01:02:43,650 --> 01:02:46,500
And so this is David.

352
01:02:46,680 --> 01:02:56,999
So I've seen this sort of talk about a few things, actually, and maybe an issue that people feel grapple with that kind of political.

353
01:02:57,000 --> 01:03:02,880
You're right, this one. Sort of her first on this one.

354
01:03:03,450 --> 01:03:07,499
Plus, there will be more that way. But all right.

355
01:03:07,500 --> 01:03:11,520
So we're to we're trying to assess this direct effect of diabetes.

356
01:03:12,480 --> 01:03:23,100
You know, adjusting for poverty. You know, if you're looking at direct, indirect effects together, you're not necessarily getting the indirect effect.

357
01:03:23,460 --> 01:03:28,440
Correct. And if we want to just work on that direct effect.

358
01:03:40,400 --> 01:03:46,670
So another example might be in longitudinal medical studies I worked with recently.

359
01:03:47,190 --> 01:03:51,260
We have nonrandomized treatments over time, so particular case.

360
01:03:51,650 --> 01:03:58,430
So I discovered a generation ago that's true in AIDS as well where there is this sort of

361
01:03:58,430 --> 01:04:03,890
desperate need to kind of get a treatment out to deal with a critical infectious disease.

362
01:04:04,430 --> 01:04:08,960
And so people weren't always like willing to wait for randomized trials and they just kind of threw things out there.

363
01:04:11,450 --> 01:04:15,350
But but if you follow people over time, if treatment changes over time,

364
01:04:15,920 --> 01:04:22,480
then the A of treatment at a given time point might be affected by the ultimate outcome of interest.

365
01:04:22,490 --> 01:04:24,559
So that's a classic example of this.

366
01:04:24,560 --> 01:04:40,459
And some of the early AIDS studies where they were using essentially looking at sort of measures of impact on sort of immune

367
01:04:40,460 --> 01:04:52,670
response that often if you sort of didn't worry about the issues of confounding with with with treatment assignment,

368
01:04:53,060 --> 01:04:59,570
it might look like the treatment was actually very bad because they're sort of giving it the highest doses or because

369
01:04:59,570 --> 01:05:09,290
also there was a limited amount sometimes to the people that had the most severe with the lowest antibody response.

370
01:05:09,980 --> 01:05:14,060
So just a crude analysis was like all these experiments because of who has been given the treatment.

371
01:05:14,180 --> 01:05:22,010
So doing some adjustment before to start. But then if it's sort of measured over time, the treatment changes over time adjusting for those treatments.

372
01:05:22,940 --> 01:05:26,660
Yeah, I ended up doing this issue of sort of blocking this, these indirect effects.

373
01:05:27,500 --> 01:05:32,209
So. So you sort of didn't get them adjusted for it.

374
01:05:32,210 --> 01:05:40,640
You got to sort of try to deal with the fact that that that these sort of intermediate treatments were sort of measures of how severe or how secure.

375
01:05:42,170 --> 01:05:49,159
But you then messed up this sort of the direct effect of the treatment on the outcome or indirectly of treatment outcome.

376
01:05:49,160 --> 01:05:55,340
So actually that was the motivation for some of this very early cousin, but it was Jim Robinson,

377
01:05:55,340 --> 01:06:02,240
his group in the 1980s and 1980s in Harvard AIDS, his research team there.

378
01:06:02,480 --> 01:06:08,680
So so so this is the sort of confounding by treatment indication which.

379
01:06:12,620 --> 01:06:16,699
Okay. So the solution to this is return of the propensity.

380
01:06:16,700 --> 01:06:25,900
Wait. So now we're going to kind of separate our mediators here into the mediator of interest and the mediator we want to absorb into the.

381
01:06:29,500 --> 01:06:45,290
We should say, in direct effect. Think. So this exposure reduced confounding and so.

382
01:06:46,860 --> 01:06:51,100
Before. You know, we can no longer make this assumption. We're going to place this assumption here.

383
01:06:51,120 --> 01:06:57,389
We don't want to make the assumption that that this potential outcome is independent of the media.

384
01:06:57,390 --> 01:07:02,670
We sort of have this echo here, but we're going to assume that once we put once we condition on.

385
01:07:02,670 --> 01:07:18,450
L Right. So if you will, conditioned on our adult poverty, then we can break this association and the potential outcomes in the media are of interest.

386
01:07:19,230 --> 01:07:23,490
So you allow EL to confound him, but assume we don't have any other additional hidden confounding.

387
01:07:24,690 --> 01:07:28,499
So where we can.

388
01:07:28,500 --> 01:07:32,210
Again, sensitivity analysis we talked about could be brought in here.

389
01:07:32,220 --> 01:07:35,820
I'm not going to do that. But but you can imagine that he did a piece in there.

390
01:07:36,780 --> 01:07:40,230
Okay. So so basically interestingly, pretty similar.

391
01:07:41,160 --> 01:07:53,300
We're. We're still going to do this regression of Y on A&M,

392
01:07:54,530 --> 01:08:00,950
but now we're going to use a wake that combines basically potential confounding from the treatment

393
01:08:00,950 --> 01:08:10,640
it's finding itself with this confounding from the sort of intermediate pathway components.

394
01:08:11,660 --> 01:08:24,229
So so basically trying to get this this relating to balance on a and then relating to balance,

395
01:08:24,230 --> 01:08:34,970
I am given a accidental so and then just this numerators just for the stabilization so and so once we have that,

396
01:08:35,870 --> 01:08:47,690
then we just take this regression estimate or this weighted regression estimate here and you plug it in or you have a one gram of three.

397
01:08:52,940 --> 01:09:01,250
So if they're binary, we can estimate these probabilities using logistic regression.

398
01:09:03,930 --> 01:09:07,260
If they're categorical, then we could use more than normal regression.

399
01:09:08,100 --> 01:09:16,470
If they're continuous, we could use PDFs with the appropriate distributional models.

400
01:09:16,590 --> 01:09:19,590
Alternatively, structural need models we could talk about in a bit with it.

401
01:09:20,160 --> 01:09:23,280
For now, we're going to assume that these things are binary.

402
01:09:26,600 --> 01:09:34,190
So. All right. So this is basically what I just said. So this is basically alternative to regression adjustment that allows us to

403
01:09:34,190 --> 01:09:39,019
exclude the exposure to this confounder from the adjustment of the exposure,

404
01:09:39,020 --> 01:09:41,000
but include it for the adjustment for the mediator.

405
01:09:42,710 --> 01:09:53,000
So the first we can try to get a representative sample from a counterfactual population or treatment's randomized,

406
01:09:53,930 --> 01:09:58,819
and the second way provides a representative sample from this counterfactual population.

407
01:09:58,820 --> 01:10:01,100
Randomize the mediator by weighting.

408
01:10:01,100 --> 01:10:06,649
Get to subjects that are less likely to have a give it mediator about in the treatment and exposure induced confounding and

409
01:10:06,650 --> 01:10:11,300
weighting down subjects that are more likely to having given me conditional on the treatment and exposure reduce confounding.

410
01:10:12,350 --> 01:10:15,470
So. So.

411
01:10:17,020 --> 01:10:20,380
The proof for this is kind of similar to what I worked out previously.

412
01:10:23,780 --> 01:11:07,290
You have to trust them. And some where the idea to work.

413
01:11:07,470 --> 01:11:11,190
We need to show that.

414
01:11:38,670 --> 01:11:43,230
The expected value of the potential outcome is the expected value of our observed y.

415
01:11:47,320 --> 01:11:50,350
Divided by the probability of age of an X. The probability of him.

416
01:11:53,820 --> 01:12:18,550
So. Sorry.

417
01:12:37,830 --> 01:13:01,780
We do. First I want to work out potential outcomes as a condition observed expected value finds probability of or.

418
01:13:03,810 --> 01:13:07,020
Sort of. Confounder mediator.

419
01:13:07,260 --> 01:13:11,550
Yes. Given X given the access to x.

420
01:13:12,840 --> 01:13:30,280
So. So just the first simple little step averaging over our distribution of facts.

421
01:13:37,080 --> 01:13:40,400
And, you know, I think.

422
01:13:47,630 --> 01:13:50,940
All right. So I can also finish on a.

423
01:13:56,110 --> 01:14:05,570
I make home my standards. Unconfirmed.

424
01:14:05,840 --> 01:14:14,490
So the explosion, basically. The potential outcome have have.

425
01:15:16,480 --> 01:15:19,690
All right. So I understand now condition further on.

426
01:15:21,520 --> 01:15:25,240
Right. So if the expectation is due to some backup.

427
01:16:09,050 --> 01:16:20,180
So now I think further girlfriend did issue this thumbnail expectation aluminum's potential outcome and which which conditions this.

428
01:16:25,170 --> 01:16:33,510
On. My assumption is. Of Independent.

429
01:16:37,190 --> 01:16:49,290
Yes. Actually the Ministry of Health here instructed.

430
01:16:56,740 --> 01:17:10,890
And then. No, I don't know my data model.

431
01:17:16,590 --> 01:17:25,640
I just consistency. Timetables conditions in some areas, in places that have been.

432
01:17:28,070 --> 01:17:49,140
So that's done. It's a race line by line here.

433
01:17:53,420 --> 01:18:22,650
Here it is. To show that this piece here.

434
01:18:29,410 --> 01:18:53,270
This. Right.

435
01:18:53,360 --> 01:19:01,040
But I need to get to the point. So. All right.

436
01:19:01,040 --> 01:19:06,670
So basically. I'm not going to write this.

437
01:19:12,860 --> 01:19:19,340
As opposed to expectation of why now as a pdf.

438
01:19:30,080 --> 01:19:34,940
Right. So please. This this here.

439
01:19:49,160 --> 01:19:53,120
I know, I hear, but I'm almost done.

440
01:19:59,390 --> 01:20:07,430
So I'm just going to multiply. I actually divide by the same quantity here that's going to let me sort of get out the expectation I really want to.

441
01:20:12,400 --> 01:20:15,490
So this is just basically this.

442
01:20:18,620 --> 01:20:23,860
And given land access and a given access to one.

443
01:20:27,000 --> 01:20:30,590
So now.

444
01:20:32,810 --> 01:21:02,140
Yeah. And so this long series of conditional distributions up here.

445
01:21:18,190 --> 01:21:39,160
Basically just allows the. They think of this as this whole big joint distribution of Y and a y and Allen X.

446
01:21:44,190 --> 01:21:54,060
Yeah. Yeah. You know, they next year and next and.

447
01:21:54,930 --> 01:22:03,160
Right. So this is just this expectation of why they're. And it's come up over the next.

448
01:22:18,140 --> 01:22:23,870
And the denominator states these two conventional distributions two conditional probably one exception.

449
01:22:24,170 --> 01:22:31,820
So. And so during these two weeks and what it means.

450
01:22:36,420 --> 01:22:41,350
The respect to whatever our model based value of Y is gives us our result.

451
01:22:43,290 --> 01:22:48,490
So. All right.

452
01:22:51,030 --> 01:23:08,930
There. We talk about variance estimation here briefly and then go on to an example.

453
01:23:13,020 --> 01:23:23,380
Next week. Office hours tomorrow.

454
01:23:26,590 --> 01:23:30,070
Questions about the notes or the notes or the projects.

455
01:23:31,930 --> 01:23:33,490
Yes. Could rescue.

