1
00:00:29,930 --> 00:00:41,680
Okay. Good morning, everyone.

2
00:00:44,340 --> 00:00:49,380
So let's briefly look at what we had in the last lecture.

3
00:01:01,640 --> 00:01:16,160
So we were mainly busy looking at the general form of discrete random variables we defined.

4
00:01:19,890 --> 00:01:26,160
The the bag and the growth. Let's reiterate this stuff as a definition.

5
00:01:28,320 --> 00:01:34,860
So we had to extend being simple functions.

6
00:01:42,350 --> 00:01:48,700
Uh, and uh, so just the reminder so we called function simple for lack of a better term,

7
00:01:49,270 --> 00:01:55,090
that are non-negative, um, have a discrete and have finite number of values.

8
00:01:55,900 --> 00:02:09,490
We spent quite some time talking about the space of such functions if they share one in the same sigma algebra or the partition key.

9
00:02:11,320 --> 00:02:25,000
So it's based on some values and where it goes from one to M and X and takes.

10
00:02:25,120 --> 00:02:29,920
So then I'm negative. Sam takes.

11
00:02:31,800 --> 00:02:36,600
And is. Yes, I am.

12
00:02:38,120 --> 00:02:42,930
Oh. Some sense, I.

13
00:02:46,390 --> 00:02:50,800
Again from one end. So that's.

14
00:02:53,150 --> 00:02:58,890
So the collection of AI from 1 to 10 is a partition of on me.

15
00:02:58,910 --> 00:03:07,110
The. Not of omega of our right.

16
00:03:12,610 --> 00:03:28,510
Yeah, it's. No.

17
00:03:28,540 --> 00:03:34,070
Actually, it is a petition about the rights. But a special one.

18
00:03:37,250 --> 00:03:40,870
So we partitioned the.

19
00:03:51,780 --> 00:04:01,020
By addressing. SATs.

20
00:04:04,930 --> 00:04:10,570
So. A partition of our.

21
00:04:20,950 --> 00:04:30,000
Right. So we have some I. iPhone one, two and internals.

22
00:04:34,700 --> 00:04:38,180
You are the former politician of it.

23
00:04:43,620 --> 00:04:47,610
Then we define a guy is.

24
00:04:49,160 --> 00:04:53,690
It's minus one. Me, I.

25
00:04:57,690 --> 00:05:02,340
So we have extensive functions and this is a target random variable.

26
00:05:12,960 --> 00:05:20,040
Or a function of on a go. And so and the back integral is an integral over a function of on the go.

27
00:05:21,540 --> 00:05:26,220
So that's why we called it expectations.

28
00:05:27,300 --> 00:05:32,460
And we said that expectation of X.

29
00:05:34,860 --> 00:05:50,230
Defined as a live band in the Gulf. Is a limit.

30
00:05:54,200 --> 00:05:58,540
And those to infinity. Some.

31
00:05:59,260 --> 00:06:03,920
Okay. It's okay.

32
00:06:04,040 --> 00:06:10,320
And. Indicator. Of 80.

33
00:06:12,450 --> 00:06:17,320
Right. Mary Kay. It's so big.

34
00:06:17,340 --> 00:06:28,460
It. And the notations for key of X.

35
00:06:29,710 --> 00:06:37,840
He's in the girl. Now, in this particular case, it's over the fall.

36
00:06:38,590 --> 00:06:46,730
But it could be over. Some subset of it. And would you be?

37
00:06:48,450 --> 00:06:51,870
SDP. Right. We were presented as a limited.

38
00:06:59,980 --> 00:07:05,620
Him to grow things in GDP when.

39
00:07:07,460 --> 00:07:20,770
It's an approximate ex. Convergence two x no, I'm showing convergence from below because it's part of the definition.

40
00:07:21,910 --> 00:07:30,920
So it's in is a sequence. Such that.

41
00:07:32,230 --> 00:07:35,640
And plus one is great able send.

42
00:07:38,520 --> 00:07:56,580
But at the same time it's less than X. Okay.

43
00:07:56,590 --> 00:08:02,260
I just collected what we kind of loosely talked about last time.

44
00:08:03,310 --> 00:08:17,170
Um, so the only addition to what we had in the previous lecture is that I want the monotonic sequence converging to my random variable X from below.

45
00:08:18,740 --> 00:08:21,980
Now everything is non-negative and there.

46
00:08:22,370 --> 00:08:25,400
So if I'm able to build a structure like that.

47
00:08:26,120 --> 00:08:30,100
So this would be called the liberty, the goal of the function x.

48
00:08:31,550 --> 00:08:40,040
Over the field them. Now, there are some gaps to be filled in here.

49
00:08:40,850 --> 00:08:44,900
Namely, there are two questions. So how do we build?

50
00:08:54,180 --> 00:08:59,350
The U.S. and. Converging tracks.

51
00:08:59,890 --> 00:09:11,900
Is it always possible? Then what about?

52
00:09:18,090 --> 00:09:23,770
Arbitrary. Yeah.

53
00:09:24,570 --> 00:09:32,790
So not necessarily. Negative.

54
00:09:38,490 --> 00:09:42,890
Right. So this definition needs some generalization.

55
00:09:45,060 --> 00:09:48,390
Following all these questions that will clarify them.

56
00:09:51,360 --> 00:09:58,500
What else did we do? So we looked at discrete random variables in general.

57
00:10:05,720 --> 00:10:09,620
And we found that we can represent them as.

58
00:10:10,940 --> 00:10:15,230
Um. Sums of some values.

59
00:10:17,900 --> 00:10:30,680
Time's indicators of disjoint sets where X and takes those values k from one to f.

60
00:10:32,790 --> 00:10:42,029
Okay. So when we looked at and an important thing in this definition of an integral so in some

61
00:10:42,030 --> 00:10:48,450
sense in spirit it basically mimics the way we dealt with other types of integrals,

62
00:10:48,450 --> 00:11:01,140
namely Freeman and stilts in calculus where we basically approximated the function of X in the case of the remaining integral.

63
00:11:01,260 --> 00:11:04,530
There were two kinds of approximations from below.

64
00:11:04,530 --> 00:11:10,290
That was the using lower double sums from above using above their sums.

65
00:11:10,710 --> 00:11:23,940
So here the analog of this is kind of a lower there some because we said we won't take the lowest values, so we'll take X and when we approximate X.

66
00:11:25,630 --> 00:11:32,080
With a goal to define the back end of it. We said we'll take the lowest value on a cake.

67
00:11:38,470 --> 00:11:48,900
So vaccinations. So we used.

68
00:11:51,270 --> 00:11:55,220
Yes. And. Defined.

69
00:11:59,750 --> 00:12:04,980
Lowest. News.

70
00:12:07,570 --> 00:12:25,930
X on a case. And this was for the purposes of the back and the girl.

71
00:12:48,640 --> 00:12:53,560
Okay. So we also looked at space as a friend of variables.

72
00:12:56,250 --> 00:13:06,900
And the variables measurable. With respect to the same sigma algebra.

73
00:13:15,550 --> 00:13:24,790
And we said that the sigma algebra would be, in the case of discrete random variables would be the one generated by the sets a key.

74
00:13:27,720 --> 00:13:35,850
Okay. And then the space of these random variables is basically the vector space of their values.

75
00:13:43,220 --> 00:13:47,010
It's one in. It's.

76
00:13:49,350 --> 00:13:52,530
And so this is part of. And.

77
00:13:59,620 --> 00:14:07,350
And from there. So we went to, uh, the space that's defined by those values.

78
00:14:08,420 --> 00:14:11,920
So either star double stars is money.

79
00:14:13,180 --> 00:14:25,660
This. So he's a star.

80
00:14:26,290 --> 00:14:29,580
Double star. With.

81
00:14:31,420 --> 00:14:36,670
Values like these, it defines a space.

82
00:14:42,840 --> 00:14:47,200
And let's call it. Let's call this sigma algebra.

83
00:14:47,260 --> 00:14:50,470
Let's say you know that beautiful. You.

84
00:14:51,700 --> 00:14:58,230
Of random variables. Measurable.

85
00:15:02,770 --> 00:15:18,900
With respect to you. So here is just a summary of what we were trying to get.

86
00:15:20,550 --> 00:15:29,150
So once again, so we defined Libya and integral by partitioning the range of ex.

87
00:15:30,710 --> 00:15:42,560
Instead of the, um, the domain of x we found what that partition of the range and uses on the domain of x,

88
00:15:43,310 --> 00:15:47,300
we defined discrete variables that approximate x.

89
00:15:48,200 --> 00:15:54,980
Um, they're by taking the lowest value on the subsets of this domain.

90
00:15:57,090 --> 00:16:07,980
So in a sense we represented the limbic integral or the expectation of X is an output of that approximation when it becomes better and better.

91
00:16:08,880 --> 00:16:13,770
But we haven't formally considered or looked into those approximations.

92
00:16:13,830 --> 00:16:17,790
Right. So we just assume it's possible to do it like this.

93
00:16:20,620 --> 00:16:27,650
Then we took a somewhat more general view of what's going on, namely that we defined some,

94
00:16:28,690 --> 00:16:36,070
uh, more primitive sigma algebra, a u instead of the one that is linked to X.

95
00:16:37,870 --> 00:16:43,840
And we said that we're looking for an, uh, essentially for, um.

96
00:16:46,090 --> 00:16:52,120
So that's an is an approximation.

97
00:16:58,600 --> 00:17:03,430
So in this part of the space that we defined.

98
00:17:03,480 --> 00:17:11,030
Right. It is an approximation of x and x is generally from a different space.

99
00:17:13,950 --> 00:17:20,149
That belongs to some other. Again.

100
00:17:20,150 --> 00:17:26,030
We're not defining it yet. Somehow this is a functional space.

101
00:17:26,080 --> 00:17:30,370
So space. Function X.

102
00:17:34,870 --> 00:17:43,600
Measurable. With respect to some of the algebra.

103
00:17:47,330 --> 00:17:51,770
If. Okay.

104
00:17:51,920 --> 00:17:58,459
So we're taking kind of a bird's eye view of what's going on when we're defining in the back in the grill.

105
00:17:58,460 --> 00:18:04,370
So we have a space of functions as F so we can think of a more primitive space.

106
00:18:04,370 --> 00:18:16,910
That's part of it. Uh, then in that part we're looking for some kind of an approximation for an element of the s have and we're defining the integral,

107
00:18:17,840 --> 00:18:21,920
uh, based on these approximations when they become finer and final.

108
00:18:23,550 --> 00:18:30,420
Right. Okay. So that leaves yet another question.

109
00:18:30,420 --> 00:18:47,810
So what is if. Or how do we link around the variable to a sigma algebra and we can formally define it like this.

110
00:18:50,000 --> 00:18:56,700
So with sigma algebra. Generated.

111
00:19:00,770 --> 00:19:05,690
And by the random variable, let's say X.

112
00:19:08,410 --> 00:19:11,600
He's. Collection of stats.

113
00:19:20,030 --> 00:19:24,260
It's minus one B when?

114
00:19:25,610 --> 00:19:29,300
B is part of the algebra.

115
00:19:31,330 --> 00:19:34,900
Thinking that this betrayal is linked to the range of X.

116
00:19:40,870 --> 00:19:44,770
Needs to be the range mix.

117
00:19:52,650 --> 00:19:56,730
I'm just filling in the blanks. Right. So we talked for a while about sigma algebra.

118
00:19:57,750 --> 00:20:02,700
Uh, the, we induce, uh, through error and the variable.

119
00:20:03,660 --> 00:20:12,990
So I'm taking a very old sigma algebra in the range of X. I'm looking at the pre images of all those barrels since uh, there are subsets of Omega,

120
00:20:13,380 --> 00:20:18,930
they form another sigma algebra that we call a sigma algebra generated by the random variable.

121
00:20:21,170 --> 00:20:25,220
Okay. So what else what were the other questions?

122
00:20:28,330 --> 00:20:31,389
So what about the arbitrary X?

123
00:20:31,390 --> 00:20:36,080
That's not necessarily. Negative.

124
00:20:38,710 --> 00:20:45,570
Let's see. Okay. So. It's just finished the review of the previous lecture.

125
00:20:46,930 --> 00:20:53,530
Basically introducing new stuff at the same time as I am reviewing the previous lectures.

126
00:20:53,530 --> 00:21:03,340
So what else we did? Um, so we, um, defined what it means when XM converges almost truly to X.

127
00:21:04,360 --> 00:21:14,590
And we will understand. This convergence from X to X is an almost sure one.

128
00:21:16,270 --> 00:21:26,670
So people must truly. Then we did another exercise.

129
00:21:29,170 --> 00:21:33,880
Where we basically introduce the kind of geometry.

130
00:21:35,830 --> 00:21:40,600
So we looked at the linear algebra and how things are defined there and following.

131
00:21:41,740 --> 00:21:47,890
The idea is in the linear algebra. So we defined the scalar product of two random variables x and y.

132
00:21:56,750 --> 00:22:07,040
Right. Using the integral of x times y d on the expectation of x times y.

133
00:22:08,660 --> 00:22:21,260
So once the scalar product is defined so we can equip the space of random variables with a norm that defines the length of it.

134
00:22:21,430 --> 00:22:30,490
Right. So that's the scalar product of X with itself and the square root of that thing.

135
00:22:31,680 --> 00:22:39,130
We noticed that the emerging norm is kind of similar to the one used in functional analysis.

136
00:22:40,660 --> 00:22:46,270
It's probably the most common one there. The L two norm and the defined.

137
00:22:46,270 --> 00:22:55,270
Also the distance between X and Y is the norm of x minus Y, right?

138
00:22:56,790 --> 00:23:07,439
And it's the distance that's the target of that general theory, because once we started talking about approximations,

139
00:23:07,440 --> 00:23:11,620
we can't really talk about them without defining some kind of a distance.

140
00:23:11,620 --> 00:23:14,760
So what does it mean that X and is close to x?

141
00:23:19,290 --> 00:23:23,940
And we'll be looking at best possible approximations later on in the lecture.

142
00:23:24,990 --> 00:23:31,230
So if I have a random variable X and I want to approximate it by any other random variable Y,

143
00:23:32,550 --> 00:23:36,690
starting with discrete ones because this was our main object for now.

144
00:23:37,410 --> 00:23:42,060
So how do we best approximate an arbitrary random variable by a discrete one?

145
00:23:43,110 --> 00:23:46,590
And we'll start with the question of how do we approximate it by a constant.

146
00:23:49,320 --> 00:23:53,400
Okay. So that was the previous lecture.

147
00:23:56,100 --> 00:24:05,220
And I'm simply giving a bunch of definitions associated with the expectation and the back end, the growth.

148
00:24:06,930 --> 00:24:11,130
So the integral, uh, can be over, said E.

149
00:24:12,860 --> 00:24:16,820
Not necessarily over the whole or mega.

150
00:24:20,650 --> 00:24:26,080
So we can do it over a subset of our media. There will be a special notation for it.

151
00:24:27,310 --> 00:24:33,850
I will say that it's an integral x so my column and then E.

152
00:24:34,420 --> 00:24:39,510
So that would be integral over a. Acts of Parliament.

153
00:24:39,610 --> 00:24:42,810
The. DP. I know.

154
00:24:48,420 --> 00:24:53,110
We can also be presented as an integral over the whole long ago, if you want.

155
00:24:54,990 --> 00:24:55,620
But then.

156
00:24:56,460 --> 00:25:06,410
So we'll make we need to make the expression under the integral zero for anything that's outside of the A and we can do it with an indicator.

157
00:25:06,420 --> 00:25:13,770
We. No, that's exploitation.

158
00:25:16,420 --> 00:25:33,900
It's times. So that way we can extend the integrals over arbitrary sets from the sigma algebra that's built on omega.

159
00:25:47,270 --> 00:25:57,590
So what else? We had a question of how do we extend it to integrals over arbitrary functions, not necessarily non-negative ones.

160
00:25:58,820 --> 00:26:06,530
So for that, we define. The X-Class is a maximum.

161
00:26:09,980 --> 00:26:17,290
Between zero and X. It's minus is a maximum.

162
00:26:19,720 --> 00:26:22,960
Between zero and minus six.

163
00:26:25,640 --> 00:26:30,470
So both are non-negative friendly variables.

164
00:26:30,680 --> 00:26:42,200
So the integral is is well defined for them because we just did it and they are non-negative because it's a maximum between zero and something.

165
00:26:42,320 --> 00:26:52,640
Right. And then we know that I can represent x is x plus minus, x minus.

166
00:26:57,190 --> 00:27:02,500
And uh, just a note that the absolute value of X is x plus.

167
00:27:03,680 --> 00:27:08,410
While six minus. Right.

168
00:27:08,540 --> 00:27:11,650
And then the definition is actually to say that.

169
00:27:13,330 --> 00:27:21,670
Um, the, the back end, the growth of acts over the set e acts is arbitrary.

170
00:27:27,630 --> 00:27:38,710
So not necessarily a negative. Right.

171
00:27:38,950 --> 00:27:44,529
So looking at this representation of X in terms of two non-negative random variables,

172
00:27:44,530 --> 00:27:51,310
it's basically straightforward how we define it because the integral is a linear thing.

173
00:27:51,940 --> 00:27:55,390
So we just define that as an integral of X plus a.

174
00:27:56,530 --> 00:28:01,980
That's not negative. Minus the global X, minus T.

175
00:28:03,640 --> 00:28:14,090
It's on someone like a. So in the sequel.

176
00:28:23,040 --> 00:28:33,030
We can. Use non-negative random variables without loss of generality.

177
00:28:43,480 --> 00:28:47,590
When we talk about the properties of the integrals, expectations and so on.

178
00:28:48,280 --> 00:28:59,170
So we will recall that because X is represented as a difference between an arbitrary X as a difference between two non-negative from the variables,

179
00:28:59,280 --> 00:29:11,680
then so the properties proved for non-negative random variables will carry over to x with kind of an almost trivial overhead.

180
00:29:13,790 --> 00:29:27,590
Okay. So one last thing to complete this definition is the question of whether it is always possible to build an approximate sequence.

181
00:29:28,370 --> 00:29:31,460
And this is just the construct, the constructive thing.

182
00:29:32,300 --> 00:29:38,020
So we can call it the theorem. It is always possible.

183
00:29:45,580 --> 00:29:56,110
So build. And from the Virgin, from below to X, where it's simple.

184
00:30:00,500 --> 00:30:09,980
And um, x is not negative, but in view of the previous nodes it will extend to how the tree.

185
00:30:16,410 --> 00:30:19,530
And the proof is just showing how to do it, essentially.

186
00:30:20,380 --> 00:30:27,270
So it's not really a theory admits. Just the algorithm of how to build an approximation.

187
00:30:28,760 --> 00:30:35,760
So let's say we'll start with. So we need to.

188
00:30:36,720 --> 00:30:40,650
So you remember that exam is a simple random variable.

189
00:30:40,650 --> 00:30:44,340
It's discrete, it's based. The starting point is partitioning are.

190
00:30:46,020 --> 00:30:51,150
And the wheel start with the interval zero one.

191
00:30:59,340 --> 00:31:02,720
That's the start of my partitioning. Right.

192
00:31:02,730 --> 00:31:09,710
And, and, and is equal to one then one and is equal to two.

193
00:31:10,370 --> 00:31:19,710
I'll add another interval. So 012 and I will make the partition fine.

194
00:31:19,720 --> 00:31:24,950
I will include the .15 into it. Right.

195
00:31:25,280 --> 00:31:34,330
And then. So I can continue doing this.

196
00:31:35,020 --> 00:31:39,370
So what I'm going to have is the partition with the.

197
00:31:47,250 --> 00:31:57,870
So let's let's do a number of intervals. So M is one to this is number of intervals.

198
00:31:58,920 --> 00:32:04,320
So it's going to be one here. It's going to be four here.

199
00:32:05,530 --> 00:32:11,200
And so on. So yeah, in general.

200
00:32:11,200 --> 00:32:15,820
Two, two and minus one for and.

201
00:32:18,180 --> 00:32:25,820
The way it looks on a picture. Intervals.

202
00:32:25,830 --> 00:32:38,160
So that would be. Intervals in zero one, but then zero once there will be more of them.

203
00:32:39,150 --> 00:32:47,530
So those are total. In the times two and minus one intervals.

204
00:32:54,060 --> 00:32:59,910
0:02 a.m. So that's my position.

205
00:33:00,480 --> 00:33:04,590
So if we look at the picture of how that happens, let's say you have a function.

206
00:33:06,600 --> 00:33:10,380
So that's my ex. Right.

207
00:33:10,630 --> 00:33:17,320
So I have zero one. In civil.

208
00:33:20,270 --> 00:33:24,560
So I have a pre image, you know, two sets.

209
00:33:33,270 --> 00:33:37,830
Where my X value falls into the zero one interval.

210
00:33:38,520 --> 00:33:42,270
Right. And the lowest value will be the lowest end of that interval.

211
00:33:42,270 --> 00:33:57,790
That's zero. Right. And then so I always have in mind that I also have another interval attached to it.

212
00:33:57,790 --> 00:34:02,860
And that's the one to infinity, right everywhere.

213
00:34:05,580 --> 00:34:10,590
And if I follow the same rule because I need to partition the whole R right.

214
00:34:11,190 --> 00:34:18,600
So zero one is just the starting point of that partition and then everything else upwards is is my second interval.

215
00:34:19,100 --> 00:34:24,360
So end if I take the lowest value on that second interval, that would be this one.

216
00:34:24,840 --> 00:34:30,380
So the ensuing approximation is going to look like this, right?

217
00:34:32,870 --> 00:34:41,180
Then if I do it for the second time, so then I will have two intervals.

218
00:34:41,780 --> 00:34:44,899
So 0 to 1 and 1 to 2.

219
00:34:44,900 --> 00:34:50,840
And within them I have another partitioning point and then I still have my functions.

220
00:34:52,370 --> 00:34:59,360
Looks like these and each time I'm taking the lowest value on the tree.

221
00:35:01,400 --> 00:35:06,320
So that would be this one. At the next interval it's going to be this one.

222
00:35:10,530 --> 00:35:22,300
Right. The next interval, it's this one. This one.

223
00:35:25,280 --> 00:35:30,170
And then finally I have this one at the last interval from two to infinity.

224
00:35:31,100 --> 00:35:34,310
So we see visually how the approximation works, right?

225
00:35:35,120 --> 00:35:41,300
So the approximate text from below, um, everything is not negative.

226
00:35:43,130 --> 00:35:46,160
Uh, it is always possible for me to do like that.

227
00:35:46,920 --> 00:35:59,420
Um, and, uh, the final note would be that each next function is going to be a greater equal than the previous function.

228
00:35:59,990 --> 00:36:06,890
So why is there, uh, this exam in any of the intervals?

229
00:36:09,780 --> 00:36:12,810
So let's say this is the interval for partition and.

230
00:36:14,960 --> 00:36:20,000
So X is approximated by the lowest value, which is this one right?

231
00:36:20,900 --> 00:36:31,100
Then for the x and plus one, each such interval will turn into a double.

232
00:36:31,460 --> 00:36:40,880
Right. Because I'm cutting them in half and I will have two values now inside one of them, this one and one of them this one.

233
00:36:41,540 --> 00:36:49,010
Right. So and because in general, the things associated with the second one.

234
00:36:52,760 --> 00:37:00,640
Uh. Great. Uh. And the first one so on some of the partitioning.

235
00:37:04,420 --> 00:37:12,370
So let's let's say the pre image of that was a and the image of these two will be a one and the two.

236
00:37:15,240 --> 00:37:25,709
Union. Right. So it's clear that if I take the lowest value of X on a, uh, it's going to be lower of them in general,

237
00:37:25,710 --> 00:37:41,250
or not higher than if I take the lowest value of X on a one and the lowest value of X on E to two, given that is actually a union of these joint.

238
00:37:42,120 --> 00:37:49,460
Models. Right.

239
00:37:49,470 --> 00:37:53,580
Because this these is minimum of X.

240
00:37:55,430 --> 00:37:58,830
Take over for me.

241
00:37:58,860 --> 00:38:03,230
This from E and this is.

242
00:38:05,140 --> 00:38:11,990
Meaning. Yeah. It's taken over only this one.

243
00:38:12,320 --> 00:38:17,470
This is minimum. It's taken over two.

244
00:38:21,940 --> 00:38:28,150
Right. So if I have a minimum of a larger set and then I'm taking a minimum of a smaller one

245
00:38:29,530 --> 00:38:34,360
than the minimum of a smaller one cannot be larger than the minimum of a larger one.

246
00:38:34,400 --> 00:38:38,950
Right. So this is what works to make it a monotonic sequence.

247
00:38:39,460 --> 00:38:46,060
And then by definition, since I always take the lowest value so I will have X being.

248
00:38:47,630 --> 00:38:53,540
Great. We call them this because we always take.

249
00:38:58,680 --> 00:39:03,220
My mother. Facts. See.

250
00:39:09,910 --> 00:39:12,640
Right. And the final note would be that.

251
00:39:13,420 --> 00:39:23,860
So the difference between like saying an X is going to be a less equal than the size of the interval and there are two.

252
00:39:26,660 --> 00:39:35,760
And minus one. So this will go to zero as in goes to infinity.

253
00:39:37,710 --> 00:39:41,700
So that will be the limit. No difference between Excel and X.

254
00:39:44,670 --> 00:39:56,220
And they and so the zero and we will go to our when and goes to infinity so I will I keep covering the whole.

255
00:39:58,830 --> 00:40:07,860
Range of X with this. And that completes the building of the approximating sequence.

256
00:40:18,670 --> 00:40:33,960
Okay. So what we did, we used a discrete approximation.

257
00:40:35,100 --> 00:40:45,580
Not the best one. Oh, that's.

258
00:40:48,500 --> 00:40:51,560
By extension, taking.

259
00:40:54,270 --> 00:41:00,900
A constant value. And since.

260
00:41:04,500 --> 00:41:12,000
He key? Right. Then we defined expectations using that approximation.

261
00:41:13,080 --> 00:41:21,060
So I want to expand on that device a little bit more and ask the question.

262
00:41:21,600 --> 00:41:35,999
So suppose I have. The function x uh, I made them right and I want to concentrate on some set.

263
00:41:36,000 --> 00:41:42,470
A That's a subset of. So what would be?

264
00:41:48,060 --> 00:42:02,120
The best approximations. It's by a constant.

265
00:42:05,400 --> 00:42:08,850
Let's see. On.

266
00:42:22,480 --> 00:42:31,510
It's a general question, right? So in order to be able to say what's best, so we need to use some kind of a concept of a distance.

267
00:42:32,380 --> 00:42:40,120
And the distance would now be between X and the constant.

268
00:42:42,550 --> 00:42:49,750
And we just alluded to how these distances were defined using functional analysis concepts.

269
00:42:50,410 --> 00:42:56,770
So in our case it's the norm of X minus Y.

270
00:42:57,310 --> 00:43:06,040
Y is now a constant. So that's the norm.

271
00:43:07,650 --> 00:43:14,490
Yes, I see. And this is.

272
00:43:14,710 --> 00:43:27,880
Well, Norm is going to be square and it's defined an X as an expectation of X minus C with itself times X minus C.

273
00:43:27,880 --> 00:43:36,770
So that's an integral. Of X.

274
00:43:38,100 --> 00:43:42,070
Minus C squared deep.

275
00:43:46,260 --> 00:43:58,230
And the integral would be over the set a. Okay.

276
00:43:58,310 --> 00:44:07,470
And the best means. We are trying to minimize this distance.

277
00:44:07,480 --> 00:44:23,450
All the sea. Now you can sense that I'm having actually a quadratic equation here.

278
00:44:36,330 --> 00:44:39,360
So let's spell these things out.

279
00:44:45,450 --> 00:44:52,350
So the integral of E. S minus C squared, the P.

280
00:44:55,710 --> 00:45:01,800
He is well into the square deep.

281
00:45:03,620 --> 00:45:14,570
Minus to see. You want to go over a.

282
00:45:18,900 --> 00:45:23,440
P. Plus.

283
00:45:25,590 --> 00:45:31,410
C squared times. A deep.

284
00:45:36,600 --> 00:45:42,250
Now, this guy, we kind of. See them.

285
00:45:42,280 --> 00:45:59,050
This is your fee. These guys, we see that this is expected to value.

286
00:46:00,510 --> 00:46:08,480
It's a. And this thing does not dependency.

287
00:46:20,890 --> 00:46:25,510
Now, you probably remember high school calculus better than I do.

288
00:46:26,770 --> 00:46:31,150
What? What is this? See, that, uh, minimizes this function?

289
00:46:31,930 --> 00:46:36,010
It's. It's a quadratic one, right? Uh, so it looks like this.

290
00:46:38,790 --> 00:46:45,290
So what's the see that gives it the minimum? I know the answer.

291
00:46:46,860 --> 00:47:02,960
I need to get. So if I remember correctly, if I have a X squared plus B, it's plus C than the minimum is.

292
00:47:03,870 --> 00:47:10,109
The point of minimum is minus V over two A, if I remember correctly.

293
00:47:10,110 --> 00:47:21,930
Is that correct? So then the minus B, so the C gives a minimum to that thing.

294
00:47:23,790 --> 00:47:28,260
A would be. So two times in the row of a.

295
00:47:29,440 --> 00:47:38,860
It's p divided by two times and e is in the global e d.

296
00:47:43,140 --> 00:47:55,650
The two will cancel out. So I have expectation of the x taking over the area e divided by the probability of it.

297
00:47:56,760 --> 00:48:05,170
Does anyone recognize this? This quantity? What is this?

298
00:48:05,590 --> 00:48:09,100
So you can look either at the previous line or the last one.

299
00:48:13,520 --> 00:48:17,660
So that's a conditional expectation of Thanksgiving, right?

300
00:48:17,670 --> 00:48:25,300
Six or one stuff. So here is an interesting twist.

301
00:48:31,560 --> 00:48:34,680
So the best approximation.

302
00:48:39,980 --> 00:48:44,600
Of gaffes by. The constant.

303
00:48:46,590 --> 00:48:53,470
On the set a. Is the conditional expectation.

304
00:49:03,050 --> 00:49:17,020
It's given they. Right and conditional expectation in the sense of 601 is actually a constant right.

305
00:49:18,530 --> 00:49:25,090
With respect to an event. This is an interesting observation.

306
00:49:27,450 --> 00:49:32,190
That. I will continue elaborating on how after the break.

307
00:50:26,300 --> 00:50:29,480
Right. That should be. It should be probability.

308
00:50:29,780 --> 00:50:34,760
That's right. It's my village.

309
00:52:26,450 --> 00:52:31,070
No. So this is just a general form of a discrete random variable.

310
00:52:31,790 --> 00:52:35,820
So if we don't want to mess with the sense. Okay. That fixed?

311
00:52:37,160 --> 00:52:43,250
Right. They have the set of all possible random variables like that is the set of vectors.

312
00:52:43,550 --> 00:53:00,090
Build up their values. X key. So if I fix the AK, I'm basically fixing the sigma algebra generated by a case.

313
00:53:01,040 --> 00:53:06,300
I'm asking the question what are all possible functions that immeasurable that are stacked in that sigma algebra?

314
00:53:07,770 --> 00:53:13,940
And that would solve the general form of them. These are the only three parameter is the value x key.

315
00:53:15,180 --> 00:53:22,530
So if I take a vector space consisting of vectors field with those values.

316
00:53:24,310 --> 00:53:27,810
That every point in that space will define.

317
00:53:28,850 --> 00:53:38,920
Uh. A function from my. Functional surveys of random variables measurable with respect to sigma algebra.

318
00:53:39,940 --> 00:53:43,540
Generated from eight days. I know it's a mouthful, but.

319
00:53:44,840 --> 00:54:01,230
That's why. That's right. What would we.

320
00:54:05,330 --> 00:54:09,840
It's the minimum points. Yeah, that's right. Right.

321
00:54:09,940 --> 00:54:13,230
So. So I'm following the same recipe. Right?

322
00:54:13,650 --> 00:54:17,550
So I'm partitioning this line with intervals, right?

323
00:54:18,210 --> 00:54:23,100
On each such interval. I'm approximating X by the lowest value would be.

324
00:54:23,550 --> 00:54:27,310
And that would be the left hand from that interval. Right.

325
00:54:30,110 --> 00:54:39,140
And I am saying that my approximating uh, extent will just take this value on uh, the privilege of this, right.

326
00:54:39,470 --> 00:54:44,750
And the premium which is these two. Right. And then assuming the constant value.

327
00:54:46,390 --> 00:54:50,350
Both places. Right. Then in the next interval.

328
00:54:50,460 --> 00:54:55,210
So the constant value will be the low end of the of that interval.

329
00:54:55,530 --> 00:54:59,350
And that would be on a different. Brand image.

330
00:55:00,250 --> 00:55:07,030
And so once I'm gone through all of them, I basically covered the whole on the go with that.

331
00:55:07,180 --> 00:57:48,130
Right. Okay.

332
00:57:48,550 --> 00:57:55,570
Shall we continue? Now, this is a pretty general results that were just stated.

333
00:57:56,800 --> 00:58:02,170
Uh, we can look at the reflection of this result in calculus.

334
00:58:09,370 --> 00:58:28,980
Example from, of course. So let's say I'm having the function of X and I am looking at the interval, let's say, from A to B.

335
00:58:31,680 --> 00:58:41,330
And I want to approximate if. By a constant.

336
00:58:44,620 --> 00:58:47,140
See on the internal.

337
00:58:56,900 --> 00:59:07,640
And so you may remember from Calculus, there was a theorem about a mean value of a function or something like that, on average of a function.

338
00:59:07,940 --> 00:59:11,030
Right. When you had, let's say, a function they have.

339
00:59:12,390 --> 00:59:17,010
Uh, on an then tomorrow from A to B by right.

340
00:59:17,010 --> 00:59:21,450
And there was a theorem that you can always find some level C.

341
00:59:23,730 --> 00:59:36,460
That will be an average. In the sense that she's going to be integral from A to B, f of x, the x.

342
00:59:38,370 --> 00:59:49,280
Over the minus T right. I don't remember the exact name of that, uh.

343
00:59:51,080 --> 00:59:55,739
Here and. In calculus.

344
00:59:55,740 --> 01:00:00,990
And you can see that this is a special case of what we just consider because.

345
01:00:01,350 --> 01:00:09,780
Well. A special case of.

346
01:00:13,740 --> 01:00:17,819
This statement above. What is it?

347
01:00:17,820 --> 01:00:32,810
Three stars now? He is laying.

348
01:00:37,040 --> 01:00:43,260
On his number. From our.

349
01:00:48,670 --> 01:00:54,410
Then what happens? This particular case of the integral and exclusive.

350
01:00:54,430 --> 01:01:05,510
Right. So on they go with these x.

351
01:01:08,830 --> 01:01:17,690
This Aframax. So he can see that with these specifications.

352
01:01:18,530 --> 01:01:27,200
So the mean the value theorem from calculus is actually a special case of what we just considered.

353
01:01:28,570 --> 01:01:41,140
Okay. So. And you may already sense that what I'm trying to approach with this type of observation is a definition of conditional expectation.

354
01:01:42,430 --> 01:01:49,600
Right. Because we're just, uh, linked, even in a very primitive case, uh, example,

355
01:01:50,080 --> 01:02:02,170
we linked the concept of approximating around the variable by a discrete one with the concept of a conditional expectation.

356
01:02:02,650 --> 01:02:12,190
Right. And this allows us to actually generalize the conditional expectation as we know it from 601 into a more general one.

357
01:02:12,520 --> 01:02:16,840
Right. So this one right here is the six of one concept.

358
01:02:16,990 --> 01:02:24,790
Right. And what we're looking at this is essentially, uh, a random variable that's a constant on some set.

359
01:02:26,190 --> 01:02:30,260
We are asking the question of what happens outside of that set.

360
01:02:32,020 --> 01:02:35,840
I'm. Let's do that.

361
01:02:36,890 --> 01:02:50,740
And I will do that in the general situation where I have an arbitrary, discrete, random variable sucks and that's some of the K from one.

362
01:02:50,750 --> 01:02:53,900
So and it's K.

363
01:02:58,540 --> 01:03:01,930
Times indicator sets a key.

364
01:03:03,860 --> 01:03:07,310
They go right. Yeah.

365
01:03:07,520 --> 01:03:10,760
They have some arbitrary acts their.

366
01:03:12,350 --> 01:03:22,880
Right. So if, uh, what, what our previous assertions mean is that if I focus on.

367
01:03:25,300 --> 01:03:30,800
And one of the sets. One specific.

368
01:03:36,570 --> 01:03:45,000
They're the best value. Of X key approximate.

369
01:03:52,470 --> 01:04:02,100
It's on this specific set. AKE is the expected value of X given that he came.

370
01:04:09,390 --> 01:04:15,240
Right. Then if I want to approximate X for you on the.

371
01:04:17,300 --> 01:04:32,430
Take our betrayal. Now this guy is sure to fall into one of a case because because of the construction case,

372
01:04:32,430 --> 01:04:36,720
a petition of the omega omega is an element of the capital omega.

373
01:04:41,400 --> 01:04:45,600
Then it falls into.

374
01:04:48,670 --> 01:05:00,350
One specific. Okay.

375
01:05:01,900 --> 01:05:18,760
Right. And if X and a bombing is to approximate x, then I can say that it's an ego based approximating x.

376
01:05:27,930 --> 01:05:40,560
Yes, actually, this. So it's equal to expected the value of the x given e one.

377
01:05:41,160 --> 01:05:55,020
If this happens to be inside a one and so on, it's expected value of x given e and we this part of t m.

378
01:06:02,630 --> 01:06:06,290
Right. I'm just now taking any arbitrary omega.

379
01:06:06,950 --> 01:06:17,389
It falls into one of the sets a uh that I know the best value to approximate my function X within that

380
01:06:17,390 --> 01:06:24,470
specific set where Onaga happens to fall is a constant that's given by a conditional expectation.

381
01:06:25,070 --> 01:06:32,870
And for each of the sets a uh, this constant will be a different one, um, given by the conditional expectation.

382
01:06:34,130 --> 01:06:44,060
So that allows me to summarize that X and for me the best approximating.

383
01:06:51,380 --> 01:06:55,720
Yes. For any Orlando.

384
01:06:59,060 --> 01:07:02,240
By a discreet.

385
01:07:06,080 --> 01:07:11,840
Random variable taking values, taking constant values on those sets.

386
01:07:21,220 --> 01:07:24,820
So this is actually some.

387
01:07:26,240 --> 01:07:32,210
Okay from one to an additional expectation of X given the UK.

388
01:07:34,040 --> 01:07:37,640
Times indicator a key.

389
01:07:44,630 --> 01:07:52,880
So unlike the accent that we used for the lib back integral, we actually took a convenient approximation that was not the best one.

390
01:07:52,880 --> 01:08:04,670
We just approximated by the lowest value in a case that was enough to define the integral because we are making the partitioning finer and finer.

391
01:08:04,940 --> 01:08:09,740
Essentially erased the sub optimality of our.

392
01:08:12,570 --> 01:08:16,290
Approximations. But if we ask the question of what would be the best one?

393
01:08:16,410 --> 01:08:22,860
It's written like this. Now, if you pay attention to what kind of animal this expression is.

394
01:08:23,160 --> 01:08:35,750
So this is a discrete, random variable. Right.

395
01:08:35,930 --> 01:08:43,460
And later on. We will define.

396
01:08:47,340 --> 01:08:57,640
Conditional expectation. This is a random variable that's part of the functional space, right?

397
01:08:58,300 --> 01:09:04,630
Yes. You where you is a sigma algebra generated by a case.

398
01:09:14,270 --> 01:09:18,800
So we'll define conditional expectation of X given you.

399
01:09:22,980 --> 01:09:29,310
So in this particular case, it will be equal to this expression.

400
01:09:33,090 --> 01:09:39,270
And as such it will be around the variable that best approximates ex in some sense.

401
01:09:40,650 --> 01:09:44,730
Right. So there's such.

402
01:09:48,430 --> 01:09:51,850
The conditional expectation of X giving you.

403
01:09:54,720 --> 01:10:04,590
In this context. Is the best.

404
01:10:07,490 --> 01:10:12,930
Approximation. It's by.

405
01:10:14,910 --> 01:10:19,980
And that's part of the. Functional.

406
01:10:21,130 --> 01:10:29,920
By the space of all the variables measurable with respect to this specific more primitive sigma algebra than the one generated by x.

407
01:10:35,380 --> 01:10:40,330
Now there's a geometric analogy. So you are actually, uh.

408
01:10:40,720 --> 01:10:45,640
There's a link, all right? There's a meaning to a geometric meaning to approximations.

409
01:10:46,850 --> 01:10:52,760
So let's say I have a more general space and I will roughly think of it as a space.

410
01:10:55,660 --> 01:10:59,400
Or functions measurable to the sigma algebra have.

411
01:10:59,680 --> 01:11:02,740
But I am using scaling mapping that plate.

412
01:11:04,210 --> 01:11:07,360
I have some more primitive space, let's say line.

413
01:11:09,470 --> 01:11:19,010
And this is the analog of space of functions measurable with respect to a more primitive sigma algebra,

414
01:11:19,010 --> 01:11:22,430
a new and that's in our example is a discrete one.

415
01:11:25,230 --> 01:11:30,660
Okay. I have an element X, uh, from the space of.

416
01:11:33,150 --> 01:11:42,100
All random variables measurable with respect to the Sigma algebra F and I'm thinking of F as a sigma generated by X.

417
01:11:42,390 --> 01:11:46,770
We just gave a definition some time ago for what the thing is, right?

418
01:11:49,710 --> 01:11:54,210
So that's just a collection of old images on burial sets in the range of X.

419
01:11:56,240 --> 01:12:03,920
Okay. So and the question is and let's say the distance is also mapped to the distance of the plane.

420
01:12:05,510 --> 01:12:15,350
So you would be able to show me the point as you that approximates as the best way of minimizes the distance from X to.

421
01:12:17,230 --> 01:12:22,210
So let's say if I take a random variable Z from s u.

422
01:12:22,360 --> 01:12:26,110
So the distance between X and Z will be right here.

423
01:12:31,160 --> 01:12:35,660
And if I'm looking for a point that minimizes that distance, where would it be?

424
01:12:36,740 --> 01:12:42,950
So it would be right here. Right. This would be the point.

425
01:12:42,950 --> 01:12:47,760
Why? The minimizes.

426
01:12:57,130 --> 01:13:03,140
The distance. Between X, Y and Z.

427
01:13:04,280 --> 01:13:09,120
While Ozzy is. You.

428
01:13:14,220 --> 01:13:20,010
And such y represents. So in the geometric sense it's a projection.

429
01:13:31,090 --> 01:13:34,130
And I that's. Yes, you.

430
01:13:42,510 --> 01:13:47,850
So when we characterize when we finally define the conditional expectations in general,

431
01:13:48,360 --> 01:13:55,020
so they will be random variables are generally more primitive than the original random variable.

432
01:13:57,920 --> 01:14:02,510
So why would the conditional expectation of.

433
01:14:03,620 --> 01:14:27,330
It's given you. So in general, conditional expectations will be over sigma algebra.

434
01:14:27,960 --> 01:14:34,380
So if there is a random variable in the conditioning, it's understood as.

435
01:14:37,360 --> 01:14:42,150
The Sigma algebra. So this is understood as the.

436
01:14:43,490 --> 01:14:49,230
Of course, given. You?

437
01:14:49,740 --> 01:14:54,180
Where you. Is this sigma algebra generated by Z?

438
01:14:57,960 --> 01:15:06,470
And because as you is basically a collection of all sigma of all random variables measurable with respect to you.

439
01:15:06,480 --> 01:15:12,110
So this is the same thing as. This segment algebra generated by Y.

440
01:15:12,400 --> 01:15:15,560
When you read the variable in that line, for that matter.

441
01:15:17,480 --> 01:15:21,890
So additional stations will be defined as such.

442
01:15:34,000 --> 01:15:42,270
And that projection interpretation actually visualizes the properties that we want to use to characterize conditional expectations.

443
01:15:42,280 --> 01:15:48,790
Right. So there's also the analogy property, right, that X minus Y.

444
01:15:49,450 --> 01:16:00,940
So if you think of them as vectors, which is the right analogy, it will be orthogonal to any Z in this new right to to the space of such function Z.

445
01:16:03,550 --> 01:16:09,280
Right. It's also minimizes the distance and so on and so forth.

446
01:16:10,190 --> 01:16:13,870
And if if I'm already if my ex is already.

447
01:16:17,530 --> 01:16:26,920
In this you. They know what it's going to be a year of X with you.

448
01:16:29,120 --> 01:16:33,590
So can anybody tell me using this analogy?

449
01:16:34,970 --> 01:16:40,700
So if my ex is already on that line, then my projection is X itself, right?

450
01:16:42,990 --> 01:16:53,830
And the distance will be zero. So that's going to be an X. So in other words, effects is measurable.

451
01:16:53,830 --> 01:16:59,380
With respect to you, the conditional expectation of X given you will be x itself.

452
01:17:00,940 --> 01:17:08,500
So that's another property that we will prove for conditional expectations and there will be more properties and so on.

453
01:17:10,320 --> 01:17:19,260
Okay. I think this is it for today, and I'll be more formal in the next lecture introducing the conditional expectation.

