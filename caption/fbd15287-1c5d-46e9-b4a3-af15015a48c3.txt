1
00:00:00,810 --> 00:00:12,150
And I'm thinking, oh, my God.

2
00:00:14,570 --> 00:00:18,140
Hi. Hello.

3
00:00:19,050 --> 00:00:22,690
Welcome to our second love. So great news.

4
00:00:22,710 --> 00:00:26,790
This love is not as long as the last one. Those days.

5
00:00:27,660 --> 00:00:33,240
So today, today, actually today and next week, we are going to cover homework number two.

6
00:00:33,660 --> 00:00:37,590
So I don't know if you already look at how much fun homework number two.

7
00:00:37,600 --> 00:00:45,330
We uploaded a load it uploaded it today on ABC on Sunday, October to October the second.

8
00:00:46,080 --> 00:00:53,790
There are three problems today. After today, you're going to be able to do completely the first one, which I think is the longest one.

9
00:00:54,150 --> 00:00:57,980
And then for next week, we will cover the other two problems.

10
00:00:57,990 --> 00:01:05,820
Okay? Okay. So if you haven't, so please, all of the homework is already uploaded, income by assignment, so on and so forth.

11
00:01:06,120 --> 00:01:11,949
And remember that every. That's everything for the loft.

12
00:01:11,950 --> 00:01:17,260
It's also uploaded on campus. So please download the source code or our code and follow me.

13
00:01:18,340 --> 00:01:21,570
Okay. So the outlook for today, it's covered.

14
00:01:21,680 --> 00:01:27,280
Problem lot in homework too. So basically.

15
00:01:29,450 --> 00:01:39,300
Yeah, I think there are four problems within problem one, we are going to do A, B and C and then D, it's like an interpretation problem.

16
00:01:39,320 --> 00:01:43,040
So it's nothing about coding, it's just interpret whatever. We just see.

17
00:01:44,210 --> 00:01:52,640
We're going to start with statistics. So first of all, just a reminder, what's it called by statistics?

18
00:01:52,760 --> 00:02:00,079
So let's say we have to make two methods to test that can be either positive or negative.

19
00:02:00,080 --> 00:02:08,659
And we just want to create a measure of the agreement of those two test that's Zic5 is so the couple is two perspectives.

20
00:02:08,660 --> 00:02:14,570
I'm myself the amount of agreement between two tests. So we have to construct a two y2 table like this.

21
00:02:14,840 --> 00:02:18,760
So this could be because number one you there are like.

22
00:02:20,140 --> 00:02:26,920
Samples people in them like you got here place I'm on of people for make of them

23
00:02:27,190 --> 00:02:32,889
number one who were positive and then for ultimatum number two who were positive.

24
00:02:32,890 --> 00:02:39,220
And this is number. This is value based and so on. And so far creating like the two by two table of the two different methods.

25
00:02:40,870 --> 00:02:47,170
And then what we are interested in like, you know, are these two tests healers or not.

26
00:02:47,500 --> 00:02:51,489
So for example, if you are like doing COVID 19 testing that you can test,

27
00:02:51,490 --> 00:02:59,200
we just wanted to see what's the level of agreement between the different type of tests that we have you don't like to do.

28
00:02:59,200 --> 00:03:03,430
So we'll we will need two important values.

29
00:03:03,910 --> 00:03:09,040
The first one actually one important value are it's okay,

30
00:03:09,040 --> 00:03:18,189
which is this statistic and it's measure B zero minus B E over one minus B where this B zero or not,

31
00:03:18,190 --> 00:03:26,799
it's the percentage of people, the percentage of people or the proportion of subjects for which the methods agree.

32
00:03:26,800 --> 00:03:33,520
So it will be a plus D divided by the total number of people in these cases.

33
00:03:33,520 --> 00:03:42,790
N and then B, which is the proportion, proportion of subjects for which the method would agree entirely by chance.

34
00:03:42,970 --> 00:03:44,620
And this is definitely number three.

35
00:03:44,950 --> 00:03:52,310
Once we've calculated those two values based on these two were two table, we can create t cap statistics just comparing this.

36
00:03:53,860 --> 00:03:58,190
Okay. So how do we do this first?

37
00:03:58,600 --> 00:04:09,100
How do we interpret mea culpa, so to speak? It's a number that can be any value in the real life if it is negative.

38
00:04:09,460 --> 00:04:17,140
I think lovely. Less than zero. We would say that there's support for agreement, which means that the two tests give very,

39
00:04:17,140 --> 00:04:24,790
very different results between zero, implying to a slight agreement between point one and 43.

40
00:04:24,790 --> 00:04:31,030
Agreement point 41 and six, moderate point 6180 substantial agreement.

41
00:04:31,330 --> 00:04:35,020
And then anything above 80, it's almost perfect agreement.

42
00:04:36,550 --> 00:04:40,390
Okay. So. For example.

43
00:04:41,590 --> 00:04:51,400
Oh, let's say there are two methods that are commonly used to test for diabetes, an oral glucose tolerance test, and a standard blood test.

44
00:04:51,760 --> 00:04:58,190
We want to use the cup as statistics test in order to determine if the to make the progression.

45
00:04:59,680 --> 00:05:11,820
Okay. As you all know, we can do this by either creating this table by other by other thinking we have match subjects or not.

46
00:05:12,090 --> 00:05:13,440
We have had it both ways.

47
00:05:13,440 --> 00:05:20,490
So, for example, in this case, we are going to use a 1 to 1 matching and then later on in the presentation where when I use a different method.

48
00:05:21,120 --> 00:05:26,280
So for example, we have only tried to table these meals at these 135.

49
00:05:26,640 --> 00:05:37,080
Is that using the sun drop test, they were negative for diabetes and also using the oral glucose says those same people,

50
00:05:37,080 --> 00:05:41,160
125 were also negative for diabetes. For diabetes.

51
00:05:42,070 --> 00:05:48,900
Okay. So based on these data said, we're going to work our entire way through the lab.

52
00:05:49,920 --> 00:05:57,450
So how do we compute? Because statistics in source, we need to create our to open tables.

53
00:05:57,450 --> 00:06:09,269
So we use the data we have for variable for variables, whether the early test was positive or negative for the blood test,

54
00:06:09,270 --> 00:06:13,890
what was positive, positive or negative and the value of the cell.

55
00:06:14,190 --> 00:06:20,070
So as you can see here, I'm imputing 3114 six on 135,

56
00:06:20,460 --> 00:06:27,630
which are literally just the values of the two way to tell you to where you table, say one, six, 14 and 135.

57
00:06:29,040 --> 00:06:34,139
Okay. Once I create my table, then to you pick up my statistics.

58
00:06:34,140 --> 00:06:36,930
We just use appropriate as you would do operating.

59
00:06:36,940 --> 00:06:45,300
Have to wait for a table for all our test lines, blood test and we collect that these is using these common average.

60
00:06:45,420 --> 00:06:49,230
Okay so but these are very that will be your cup statistic.

61
00:06:54,210 --> 00:07:01,650
Yes. Oh. So if you run this code, you would have to tables.

62
00:07:02,100 --> 00:07:12,180
The first one is, yes, the value of the corpus. But they say this summer error of such estimate on the 95 concert for the 95% confidence interval,

63
00:07:12,720 --> 00:07:18,060
and then another one testing whether that proper statistic is zero or not.

64
00:07:19,020 --> 00:07:29,010
Okay. So if we go to the first table, the estimate is 0.68, which means if we go back according to our table,

65
00:07:29,280 --> 00:07:37,800
0.6 to 8.3, I think it follows two, a substantial agreement category that will be one.

66
00:07:38,040 --> 00:07:45,570
Our first conclusion I don't want to second conclusion of this is like with a passive statistic,

67
00:07:45,960 --> 00:07:52,050
you can take a look at the confidence interval and realize we don't have a zero here or go directly

68
00:07:52,050 --> 00:07:58,350
to the test and then use the p value to conclude that the corpus statistic is different than zero.

69
00:07:58,440 --> 00:08:01,770
Correct. We have enough evidence to reject a new hypothesis.

70
00:08:02,730 --> 00:08:09,870
Okay. Yes.

71
00:08:10,710 --> 00:08:19,500
If we run these lines of code subs, we would also have the maximum hours.

72
00:08:20,320 --> 00:08:32,100
Yes, this is a chi square test. So again, just we have the coursework value of the test, the degrees of freedom and more importantly, the p value.

73
00:08:32,100 --> 00:08:38,280
And based on the p value we can agree we got compared to the alpha level, usually 5%.

74
00:08:38,280 --> 00:08:42,510
And whether we reject or do not reject the null hypothesis.

75
00:08:44,150 --> 00:08:48,170
Okay. Now, if we want to do this on our.

76
00:08:51,620 --> 00:08:59,390
First of all, just create the data set to create an asset, never to create a much a matrix of that matrix.

77
00:08:59,450 --> 00:09:07,540
It's going to look something like. It's going to look something like this.

78
00:09:07,540 --> 00:09:11,440
So positive, negative, positive and negative.

79
00:09:11,920 --> 00:09:23,230
So is the two by two table and then by row, 316 14 on 135.

80
00:09:23,560 --> 00:09:27,880
So we are creating this table as a matrix in our.

81
00:09:28,390 --> 00:09:31,810
The first thing I do is just equal to the third.

82
00:09:31,810 --> 00:09:36,220
So I have 31, six, 49, 135 times was in office here.

83
00:09:37,210 --> 00:09:43,600
I said any called equal to two like let our know that I'm creating a two by two table.

84
00:09:44,260 --> 00:09:52,150
So if I input four values is going to you know and number of columns columns equal to will give me up to what you table

85
00:09:52,630 --> 00:10:01,060
and then my row equals row would mean that whenever r it's reading those numbers is going to fill all of the rows first.

86
00:10:01,360 --> 00:10:04,970
So 31 six will be 21 6/1 row.

87
00:10:04,990 --> 00:10:08,650
There's no more space. So then 49 135.

88
00:10:08,980 --> 00:10:12,700
How do I know there is no more space? Space? Because there are only two columns.

89
00:10:12,700 --> 00:10:16,160
Because here I said the parameters were only two columns.

90
00:10:16,210 --> 00:10:20,080
Those I think that's that's just one way to create it.

91
00:10:21,130 --> 00:10:24,810
Okay, I'm going here. I'm just creating the labels.

92
00:10:25,180 --> 00:10:31,660
So when you look at the look of the Matrix, it will have a positive, negative, positive, negative.

93
00:10:32,230 --> 00:10:35,680
This is completely optional, but it's easier to understand.

94
00:10:35,830 --> 00:10:39,040
I just love the labels as well. Okay.

95
00:10:42,460 --> 00:10:47,140
And then to create a statistic, we're going to use the cyber.

96
00:10:48,180 --> 00:10:55,560
So you sell packages the librarian brings the library into the art into the are a script that you're working on.

97
00:10:55,980 --> 00:11:01,900
I'm going to create all of the statistics. Confidence interval tests.

98
00:11:02,280 --> 00:11:06,080
Just use the function. Kind of couple that.

99
00:11:06,120 --> 00:11:11,249
Whatever it is. The name of your matrix here, that will be the matrix.

100
00:11:11,250 --> 00:11:14,370
Are you going to pass a separate method for this function?

101
00:11:14,700 --> 00:11:19,410
Okay. This name is the name of the matrix you created here.

102
00:11:22,050 --> 00:11:36,420
Okay. And then if you run this. So if we run this, this is how you're to write your table should look like in art.

103
00:11:36,990 --> 00:11:40,620
And then, oh, this should be the output.

104
00:11:42,030 --> 00:11:48,130
Of that function. Oh.

105
00:11:54,320 --> 00:12:00,470
Yes. This is not the only in art. This is not the only way to obtain the cut by statistics.

106
00:12:00,770 --> 00:12:04,490
There are different libraries that we can use.

107
00:12:04,520 --> 00:12:11,090
I know for a fact that some of you have used this at the library so we can also use this epi tool library.

108
00:12:12,470 --> 00:12:17,400
So if we use. Yes.

109
00:12:17,760 --> 00:12:28,530
So if we use Epic, if we use these library ie, are there some other function to compute the corpus that they think it should be the same?

110
00:12:28,920 --> 00:12:33,090
The only difference is that the data sets should look something different.

111
00:12:33,390 --> 00:12:44,130
So if you're working with R and you decide to compute the cut by statistic using this psych library,

112
00:12:44,490 --> 00:12:52,740
then you're the data said that you pass also parameter to the function should look something like a to way to take.

113
00:12:53,310 --> 00:13:01,020
However, if you decide to use these libraries, I are on to compute the corpus of this thing.

114
00:13:01,410 --> 00:13:03,690
So we find it should give you the same result.

115
00:13:04,080 --> 00:13:11,100
The only difference is that the thing that you possibly on it that looks something different is not going to be up to y to table in this case.

116
00:13:11,730 --> 00:13:16,740
In this case, it should be. It looks something like this.

117
00:13:18,310 --> 00:13:50,020
Hmm. So if you are using this library, you will need to create a dataset that looks something like this.

118
00:13:50,230 --> 00:13:55,240
First, I have one. I have 186 observations y.

119
00:13:55,720 --> 00:14:00,910
And that's just because y 86 is the total number of subjects that I have in my pool.

120
00:14:01,510 --> 00:14:09,730
And then so, for example, I know 21 people were positive using the two different best.

121
00:14:10,030 --> 00:14:15,040
So that would mean that in my dataset, the first 51 individuals.

122
00:14:16,320 --> 00:14:23,450
Will have one or all test on one glucose test, one, one, one, so on and so forth.

123
00:14:24,780 --> 00:14:33,420
31 lines look the same. And then, for example, at the end, I know that there are 135 who are negative from negative.

124
00:14:33,900 --> 00:14:39,420
So the last 100 I'm pretty five rows should be like ciaran's zero.

125
00:14:40,110 --> 00:14:44,910
That's kind of the data. The difference again, you can use whatever you want.

126
00:14:45,270 --> 00:14:51,720
This is just like multiple functions to compute the same capacity played by statistics.

127
00:14:51,750 --> 00:14:56,760
The only difference is that you need to pay attention to is the type of data they receive.

128
00:14:57,030 --> 00:15:01,560
The first one receives a two by two table. The second one receives a table something like this.

129
00:15:02,100 --> 00:15:07,310
If you already constructed a two by two table, it's easy to go into this long format.

130
00:15:07,680 --> 00:15:12,920
The way to convert data into this long format is just use the function expand table.

131
00:15:13,320 --> 00:15:16,620
That will do it for you. Okay. Buzzati.

132
00:15:17,610 --> 00:15:23,330
Any questions so far? Oh.

133
00:15:25,090 --> 00:15:30,459
Oh. I had it here. So I look something like this. And we can compute the capacity, the capacities.

134
00:15:30,460 --> 00:15:34,570
These are the types just based on the p value associated with it.

135
00:15:35,050 --> 00:15:45,760
This is statistics. Okay. In our how do we compute the monthly Mars test?

136
00:15:46,720 --> 00:15:51,790
So in size we just use brow prep and that's are we need to do two things.

137
00:15:52,120 --> 00:16:04,530
First, run the couple statistic, then run our 95% confidence interval, you know the value of the p value faces.

138
00:16:04,540 --> 00:16:08,740
But I think we need to create the McNamara's test.

139
00:16:09,070 --> 00:16:18,640
So it's a computer based art. We need a library art component, and then there's a function memory test and that's it.

140
00:16:18,970 --> 00:16:22,870
Okay. So Insource Fred would do it for you,

141
00:16:23,740 --> 00:16:28,750
would give you the three results as we are looking for the capacity six the

142
00:16:28,750 --> 00:16:34,150
95% confidence interval of the estimate and then the McNamara's test in art,

143
00:16:34,420 --> 00:16:36,760
you need to do those things separately.

144
00:16:36,970 --> 00:16:45,440
So one library for the capacity think another library for the 95% confidence interval under another library for the maximum assessed.

145
00:16:45,940 --> 00:16:51,080
Okay. Questions so far. Okay.

146
00:16:53,130 --> 00:16:58,260
All right. And then finally.

147
00:16:58,920 --> 00:17:10,190
So we did all of this because we are we looked for the measurement of agreement between those those two tests.

148
00:17:10,200 --> 00:17:15,750
But we can also ask for something different, for example, for an odds ratio of that table.

149
00:17:15,990 --> 00:17:19,740
I mean, at the end, it's a two way to table, so we should be able to do that.

150
00:17:19,740 --> 00:17:27,330
It's just like a different definition of the odds ratio in this case, because we are having to test instead of like that, somebody the true.

151
00:17:28,080 --> 00:17:38,660
Okay. So the question of interesting index here would be something like what is the odds ratio for diagnosing diabetics,

152
00:17:38,940 --> 00:17:44,010
comparing the oral glucose test and your standard blood test?

153
00:17:44,280 --> 00:17:50,879
So instead of the normal odds ratio, when we compare like treatment versus control group here,

154
00:17:50,880 --> 00:17:58,020
I have one bias on the other, but I still want the odds ratio of comparing those to test for diagnosing diabetes.

155
00:17:58,260 --> 00:17:59,490
So that's our question.

156
00:18:00,120 --> 00:18:11,610
Are we can think of diabetes, diabetes like being positive, like having diabetes as the outcome and each test as the predictors of such outcome.

157
00:18:13,280 --> 00:18:17,790
And again, what we want to do now is we've got to wait to table the test.

158
00:18:17,800 --> 00:18:29,400
We want to find the appropriate odds ratio, estimate the 95% confidence interval of that odds ratio, the two sided P value and then just are complete.

159
00:18:30,470 --> 00:18:37,890
Okay, so how do we do that? And then here I would need a little bit allocation of.

160
00:18:39,290 --> 00:18:43,310
The tornado table that we have, we can divide these two by two.

161
00:18:43,340 --> 00:18:54,410
Table two, four tables one for actually in the 188 tables categorized into four categories.

162
00:18:54,680 --> 00:19:02,670
So the first category will be. A standard blood test positive and oral glucose test positive.

163
00:19:03,030 --> 00:19:07,019
I would have 31 tables like that. Why 31 tables?

164
00:19:07,020 --> 00:19:11,760
Because these are cells. 31 and I can construct again.

165
00:19:12,150 --> 00:19:18,210
This is positive or negative. Diabetes. So this will be like my outcome in this case.

166
00:19:21,490 --> 00:19:29,380
And then in the columns I have the two predictors which B which will be the results of each of the test.

167
00:19:29,770 --> 00:19:35,440
So this first table would be okay if I focus only on these 31 people.

168
00:19:35,740 --> 00:19:44,380
For these 31 people, they the half positive side I go up test I'm positive process.

169
00:19:44,770 --> 00:19:53,650
So for that those 31 people, I have one for positive one for oral glucose test because that's positive for me.

170
00:19:53,950 --> 00:19:59,890
And then one thing based on their test and then in their line of positive because they are both positive.

171
00:20:00,280 --> 00:20:07,970
Does that make sense? And then the other cable, I would have six tables that looks like this.

172
00:20:08,390 --> 00:20:12,920
So again, you remember that kind of the outcome, whether they have diabetes or not.

173
00:20:13,310 --> 00:20:17,930
I'm here. I have the do or the tests.

174
00:20:18,350 --> 00:20:23,570
So, for example, for these six people, for the sun blood test, they do not have.

175
00:20:23,930 --> 00:20:27,980
Yes. If I, I, I did the a sample blood test for them.

176
00:20:28,280 --> 00:20:35,450
I didn't. And they don't have diabetes. So I found the blood test means that for those six people.

177
00:20:36,860 --> 00:20:40,880
Yeah. Some of the blood test for those six people, they are false.

178
00:20:41,180 --> 00:20:44,900
They are. And then negative. I'm sorry. I was reading it wrong.

179
00:20:44,930 --> 00:20:52,760
I was like, What? Okay, I'm sorry. Again, for these six people, the blood test, the standard blood test is negative.

180
00:20:53,150 --> 00:20:58,400
So the second table, just imagine I have six tables like this.

181
00:20:58,760 --> 00:21:02,600
The exam, the blood test. We have a one here because they are negative.

182
00:21:03,950 --> 00:21:08,420
And then they got positive for the glucose test.

183
00:21:08,720 --> 00:21:13,970
So for the person who says they are positive for someone here, does that make sense?

184
00:21:15,070 --> 00:21:27,550
And so on and so forth with the other numbers. So, for example, if we do this 135, it would mean that I have 135 tables that look like this.

185
00:21:27,940 --> 00:21:32,620
So for these 135 people, the sometimes blood test is negative.

186
00:21:33,040 --> 00:21:38,170
So if someone blood tests negative, I'm going to put out one wonder because it's negative.

187
00:21:38,590 --> 00:21:43,690
And then for these last 105 people, the oral glucose test is alternative.

188
00:21:44,650 --> 00:21:49,420
So of course, this photo negative. So I'm going to put that one on everything else in the table.

189
00:21:49,420 --> 00:21:55,300
It's a zero. Does that make sense? MORALES Okay.

190
00:21:56,500 --> 00:22:06,730
So if I think instead of having these two I do table, I have all of these tables like this we can create all odds ratio.

191
00:22:12,620 --> 00:22:18,609
So. I'm creating.

192
00:22:18,610 --> 00:22:21,990
I mean, they just said this is source code and the new data set.

193
00:22:22,000 --> 00:22:30,670
I have four variables. The result for our test is standard test, how many people they have and wait.

194
00:22:30,940 --> 00:22:35,260
Wait is equal to one just to make sure we are using all of the data lines.

195
00:22:36,070 --> 00:22:40,480
So this is just creating the input of the stable.

196
00:22:46,200 --> 00:22:49,860
Right. That's just the input of the two by two table that I have between the two best.

197
00:22:53,440 --> 00:23:01,690
All right. And then what I'm doing in this code is just creating all of these.

198
00:23:07,580 --> 00:23:15,319
Fables like here. Okay. So. Okay, first first of all, you thought I'm just going to create a two by two table.

199
00:23:15,320 --> 00:23:18,500
So just four lines, one for each of the cells.

200
00:23:18,890 --> 00:23:21,980
And then we do a little more complicated.

201
00:23:24,640 --> 00:23:31,780
The procedure, I'm going to create my create all of those other like simplified tables of only 120.

202
00:23:32,320 --> 00:23:42,000
But the zip code that I have here. Okay. And then finally, after doing that, I just ran a graph frac.

203
00:23:42,490 --> 00:23:48,880
Notice that when I'm running the prop frac, the data that I've been for is this second data file.

204
00:23:49,060 --> 00:23:52,930
Its data diabetes tool is not a two by two table.

205
00:23:53,200 --> 00:23:56,109
Because I have to think of these odds differently,

206
00:23:56,110 --> 00:24:00,070
because it's not the same old ratio of like treatment, I'm going to tell you, because we have to test.

207
00:24:00,460 --> 00:24:04,060
So just make sure that you're in the data that your input.

208
00:24:04,240 --> 00:24:10,360
It would be this second dataset that's creating all of those 186 different to my your.

209
00:24:11,500 --> 00:24:16,210
And then just you know, create that table by adding criteria response.

210
00:24:16,480 --> 00:24:26,740
Everything is just because here I created 186 table and then just wait by the way so like I can have the odds ratio and then here.

211
00:24:29,060 --> 00:24:32,930
The. Amanda Hazel estate.

212
00:24:36,110 --> 00:24:41,690
Any questions so far of like, the logic behind it makes sense.

213
00:24:44,410 --> 00:24:50,710
More or less make sense. Okay. So once we do that, it's onto Hazel.

214
00:24:50,730 --> 00:25:00,850
So we already cover these last week. We have one, one table that covers the faces that we sing on with you.

215
00:25:00,850 --> 00:25:06,580
All of you. And then another one for the odds ratio on the 95% confidence interval.

216
00:25:06,610 --> 00:25:10,780
Okay. I just want you to know that. Just do the exercise.

217
00:25:10,930 --> 00:25:14,800
These ulcerations that you have here. Single point for tool.

218
00:25:15,100 --> 00:25:21,490
It's completely different than taking these two right to table and creating the odds ratio of these.

219
00:25:21,700 --> 00:25:24,730
Okay. Because that's definitely not what we are doing.

220
00:25:25,480 --> 00:25:33,860
Makes sense, but makes sense to you. Okay. Just Oh, and that will be homework.

221
00:25:34,140 --> 00:25:38,400
Question one see, how do we do this in our nights?

222
00:25:38,400 --> 00:25:41,820
A little bit easier, I guess, because we can work with vectors.

223
00:25:42,510 --> 00:25:47,880
We still have the 186 tables like we did, as we did before.

224
00:25:48,750 --> 00:25:52,200
It's just a way that we input this data in something a little bit different.

225
00:25:52,500 --> 00:26:05,000
So for the sake of remember that our labeling is these will be A, B, C and D, okay?

226
00:26:05,670 --> 00:26:13,470
These will be A, B, C and D, E, C and D and so on and so forth.

227
00:26:13,890 --> 00:26:17,370
So what we are doing in R, it's creating vectors.

228
00:26:17,550 --> 00:26:22,410
So the first vector will include all of the values of the ace of I.

229
00:26:23,010 --> 00:26:28,140
And then the second vector was create all of the values of the of EI and so on and so forth.

230
00:26:28,470 --> 00:26:32,820
So very similar to what we would like in the homework as I was you yesterday.

231
00:26:33,180 --> 00:26:38,669
So for example, 48 I, I have 37 people.

232
00:26:38,670 --> 00:26:43,049
Y 37 is just because I mean, I'm going to input all of these data.

233
00:26:43,050 --> 00:26:56,460
So for just for eight, I would have 31 ones and then followed by six, the ones followed by 14 zeros followed by so 135 zeros.

234
00:26:56,700 --> 00:27:00,390
So that's the same as doing that seven one.

235
00:27:00,600 --> 00:27:08,880
Why? Just because, you know, six and 31 on 149 zeros on four B's exactly the same.

236
00:27:09,210 --> 00:27:21,930
So first for B, I would have 30 116 zeros, 14 ones and 135 zeros and so on and so forth.

237
00:27:23,160 --> 00:27:27,420
And then once you create these a vectors for AB CND,

238
00:27:28,230 --> 00:27:41,130
we can use the library method for as you reading this homework to create the amount of space LSD so just past the ABC only and then rerun that line.

239
00:27:42,330 --> 00:27:52,770
You would have the estimate on the confidence interval of such estimate make sense questions so far.

240
00:27:55,780 --> 00:28:01,110
Okay. Good. And then the last question in homework.

241
00:28:01,120 --> 00:28:08,740
The last question in homework to problem, one would be like to create a paragraph summarizing our results.

242
00:28:09,280 --> 00:28:16,450
So in this case, remember that we have to test on glucose first from the standard tests for diabetes.

243
00:28:16,810 --> 00:28:19,300
And the odds ratio was 0.42.

244
00:28:19,630 --> 00:28:33,550
So something like this, the odds ratio estimate is the value that we have 0.42 with a 95% confidence interval of between 0.16 and one point you like.

245
00:28:34,090 --> 00:28:37,120
The kind of squared pass statistic is 3.2.

246
00:28:37,390 --> 00:28:45,010
This is the month. Okay, so a statistic with one degree of freedom and the corresponding p value is the value of the month.

247
00:28:45,010 --> 00:28:52,390
Okay. So therefore there is marginal evidence that the odds of that marginal.

248
00:28:52,540 --> 00:28:55,090
Why didn't use marginal evidence here?

249
00:28:55,480 --> 00:29:05,170
Because remember that normally our threshold for a rejected null hypothesis will be 5%, but this is very close to 5%.

250
00:29:05,410 --> 00:29:08,170
That's why here we use like marginal evidence.

251
00:29:09,100 --> 00:29:17,950
So therefore there is marginal evidence that the odds ratio of diagnosing diabetes via the oral glucose test is lower.

252
00:29:18,400 --> 00:29:32,830
Also noting via the standard this when they do tests, these agree on them like formally since that P-value it's greater greater than 5%.

253
00:29:33,250 --> 00:29:44,470
We would say we fail to reject the null hypothesis at a 5% significance level and not conclude that there is a significant difference.

254
00:29:44,950 --> 00:29:56,340
Does that make sense? Questions so far.

255
00:30:01,530 --> 00:30:07,380
Okay. So that's everything you need for problem one of the homework.

256
00:30:08,280 --> 00:30:13,020
So you're going to just go ahead and start doing it. If you have questions, please feel free to ask me.

