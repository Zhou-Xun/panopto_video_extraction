1
00:00:09,020 --> 00:00:17,360
Now, of course, against all of our best efforts, there are times at which we get things wrong and we do introduce selection bias into our studies.

2
00:00:18,110 --> 00:00:24,349
So what do we do? Well, there's actually a couple of ways that we can try and recover our information and still

3
00:00:24,350 --> 00:00:28,940
get an accurate estimate of our exposure outcome relationship in the true population.

4
00:00:29,870 --> 00:00:33,770
In the next few slides, I'm going to talk you through three of our main techniques.

5
00:00:34,400 --> 00:00:37,760
One is predicting the impact of the selection bias.

6
00:00:38,300 --> 00:00:40,130
The second one is stratification.

7
00:00:40,400 --> 00:00:48,020
And finally, we'll talk about this notion of creating pseudo populations with which we can study the exposure outcome relationships.

8
00:00:49,280 --> 00:00:57,560
Now predicting the impact of selection bias is a very simplistic but often effective approach, and it's one that's very frequently done.

9
00:00:58,520 --> 00:01:07,010
So you may recall that the goal in any sampling strategy is to get the same fraction of the full population in your study,

10
00:01:07,280 --> 00:01:17,070
regardless of their exposure and their disease status. If we're able to do that successfully, then we have no selection bias introduced here.

11
00:01:17,090 --> 00:01:26,390
However, we show you a case where people who are both exposed and with disease were far less likely to participate or be followed over time.

12
00:01:27,260 --> 00:01:35,690
As you recall from a previous lecture, by losing so many people in a cell, a or those with exposure and with our outcome,

13
00:01:36,200 --> 00:01:45,440
our observed association in our sample population is going to be much smaller than what is expected from the full population.

14
00:01:46,250 --> 00:01:52,340
When this happens, we can put a sentence in a discussion section that basically says this.

15
00:01:52,340 --> 00:01:59,690
You know, we found such and such an association, but we would expect to see a larger association if only we hadn't lost people.

16
00:02:00,790 --> 00:02:05,290
Most of the time, it's hard to really estimate the magnitude of that bias.

17
00:02:05,290 --> 00:02:13,810
However, unless we're able to know what the sampling frequency was and sell A versus the other cells as a result,

18
00:02:14,170 --> 00:02:18,900
you know, it is something, but it's often not all that fulfilling to just put in a paper.

19
00:02:18,910 --> 00:02:25,840
Well, we think we might have some selection bias. And if we did, you know, we would expect to see this impact on our association.

20
00:02:26,900 --> 00:02:36,650
Another approach that we can do to estimate associations in the true population with more accuracy is to use stratification.

21
00:02:37,130 --> 00:02:43,820
In effect, what we're trying to do is adjust our models for some other factor in order to get the correct answers.

22
00:02:44,900 --> 00:02:51,950
So let's take, for example, the scenario that we had previously where we were interested in pesticide use and prostate cancer.

23
00:02:52,520 --> 00:02:57,590
And there was selection bias because people who use pesticide were both more likely to participate.

24
00:02:57,950 --> 00:03:02,510
And those people with a family history of prostate cancer were also more likely to participate.

25
00:03:03,410 --> 00:03:12,170
As a result, by conditioning on the collider of participation, we introduced a backdoor path and therefore introduce selection bias.

26
00:03:12,710 --> 00:03:19,400
Now, one of the ways that we can remove this bias and close the backdoor path is by conditioning on family history.

27
00:03:20,330 --> 00:03:23,270
Conceptually, you can see it here in the data.

28
00:03:23,450 --> 00:03:30,380
This conditioning on family history will block that factor path, but you can also understand it intuitively.

29
00:03:30,980 --> 00:03:36,920
So if you think about just looking at those people who have a family history of disease,

30
00:03:37,490 --> 00:03:43,819
we would no longer expect that there would be any variation in somebody whose underlying risk

31
00:03:43,820 --> 00:03:49,370
for an outcome due to genetic predisposition based on if they were exposed or unexposed.

32
00:03:50,240 --> 00:03:55,470
Similarly, we'd have the same thing among those who had no genetic predisposition.

33
00:03:55,730 --> 00:03:59,299
Once you've stratified to people who have no genetic predisposition,

34
00:03:59,300 --> 00:04:05,510
there's really no association between risk of disease and family history and your exposure status.

35
00:04:07,210 --> 00:04:13,030
A final strategy that can sometimes be employed is something that's called inverse probability weighting.

36
00:04:13,750 --> 00:04:20,110
Now, this tends to be a more advanced technique, but I just want you to understand the concept of this particular approach.

37
00:04:20,980 --> 00:04:25,270
The idea was inverse probability weighting is to create a pseudo population of

38
00:04:25,270 --> 00:04:30,190
what would be expected to be seen if everyone was observed for the full study.

39
00:04:31,030 --> 00:04:35,829
Now, the way that we do this is we effectively update the data from individuals who are

40
00:04:35,830 --> 00:04:41,680
observed throughout the whole study in order to reflect others who are similar to them,

41
00:04:42,070 --> 00:04:45,940
but who did not get sampled for the full duration of the study.

42
00:04:47,050 --> 00:04:54,910
In this way, observed, individuals are counting in our two by two tables and in our analysis not only for themselves,

43
00:04:55,150 --> 00:04:59,860
but also for others who are not sampled but have similar characteristics to themselves.

44
00:05:01,620 --> 00:05:10,110
The extent to which a person's information is updated in our analysis is related to the inverse of the probability that they were retained in a study.

45
00:05:10,590 --> 00:05:20,220
This is why it's called inverse probability weighting. So let's take, for example, there were ten men, each of whom were aged 60 to 65 years of age.

46
00:05:20,670 --> 00:05:23,970
They were all exposed and they all had a family history of cancer.

47
00:05:24,600 --> 00:05:29,130
But only two of those ten men remained in the study until the end of follow up.

48
00:05:30,270 --> 00:05:32,099
In our pseudo population,

49
00:05:32,100 --> 00:05:42,390
we could update each of these two individuals who were followed for the full duration to stand and to represent each five people in their analysis.

50
00:05:42,960 --> 00:05:48,120
They represent themselves plus four other people, each of whom were lost to follow up.

51
00:05:49,460 --> 00:05:56,290
Now, I just wanted to briefly show you a nice example of this approach of inverse probability weighting in the literature.

52
00:05:56,860 --> 00:05:59,920
This is a study that was conducted by my friend Jennifer Weave,

53
00:06:00,250 --> 00:06:08,320
where she was interested in understanding whether or not smoking was a risk factor for dementia and more rapid cognitive decline in later life.

54
00:06:09,220 --> 00:06:15,250
Importantly, smoking causes people to get cardiovascular disease and be at higher risk of death.

55
00:06:15,460 --> 00:06:19,930
Therefore, they are less likely to be followed over time. Similarly,

56
00:06:19,930 --> 00:06:25,329
people who are experiencing cognitive decline in later life and dementia really

57
00:06:25,330 --> 00:06:30,430
are no longer able to continue participating in a study for health reasons.

58
00:06:31,510 --> 00:06:38,320
What this translates to in the full study is that if you look only among those people that you observe,

59
00:06:38,680 --> 00:06:45,400
the smokers who are retained in the study are often those who had the least amount of cognitive decline.

60
00:06:45,640 --> 00:06:51,550
Out of all of the smokers that are in the full population, because they're the ones who continued to show up,

61
00:06:52,600 --> 00:06:59,020
this makes it seem as if smoking is less harmful on cognition than it actually is.

62
00:06:59,710 --> 00:07:03,940
In fact, this is exactly what the researchers saw in their study.

63
00:07:04,630 --> 00:07:10,870
If you look at the unweighted population, which is a population that has not been adjusted for selection bias,

64
00:07:11,230 --> 00:07:16,720
what you see is that smoking only reduces cognition by about point one points.

65
00:07:17,620 --> 00:07:26,410
However, once you move to this weighted analysis, which is the pseudo population or that one that they're trying to take into account selection bias,

66
00:07:27,010 --> 00:07:32,410
they now saw that smoking was associated with a point to smaller cognition.

67
00:07:33,340 --> 00:07:41,530
This suggests that selection bias, due to loss to follow up, underestimated their results in the true population by almost 100%.

68
00:07:42,690 --> 00:07:47,579
I just wanted to wrap up and conclude by saying that when we are planning a study,

69
00:07:47,580 --> 00:07:56,430
it's critically important to think about how we retain and recruit subjects in a way so that we minimize selection bias in our designs.

70
00:07:57,000 --> 00:08:06,270
If we do, however, find that there's evidence of selection bias in our study, all is not lost, and there are possible ways to adjust our associations,

71
00:08:06,510 --> 00:08:14,970
especially if we understand the reasons for missing this, or if our population has sufficient information to infer the findings of those who are lost.

