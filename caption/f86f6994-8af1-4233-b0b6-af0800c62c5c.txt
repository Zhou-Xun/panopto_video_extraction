1
00:00:03,160 --> 00:00:08,220
Okay. And another thing is about the office hour.

2
00:00:08,230 --> 00:00:14,680
I think I'm assuming after the send out announcement over the weekend, it's slow.

3
00:00:16,120 --> 00:00:22,580
She's going to switch office hour with weijia numbers whom something is going office hour on Thursday and 3030.

4
00:00:22,630 --> 00:00:29,200
Her office Ouija is going to have a bizarre to the floor on Monday but we are actually

5
00:00:29,200 --> 00:00:38,170
now trying to reserve to make the announcement later on after we know really for sure.

6
00:00:39,640 --> 00:00:43,480
Oh looks obvious are cosmetic so it's still jewelry.

7
00:00:44,830 --> 00:00:50,690
But we got on of that once we know that long.

8
00:00:51,340 --> 00:01:03,700
Another thing is about the homework. So the homework zero will be posted today probably around noon and is due next Tuesday.

9
00:01:03,820 --> 00:01:10,150
So all the subsequent homeworks will be posted on Tuesday and then do what we do later.

10
00:01:10,840 --> 00:01:20,800
That's Tuesday, midnight. So and also you want to start looking at homework, not waiting until next Tuesday.

11
00:01:21,010 --> 00:01:29,910
So this is maybe the first one maybe is relatively straightforward, but still, you know what the start Irving is now waiting for lot.

12
00:01:34,370 --> 00:01:38,270
Look now continue our factor.

13
00:01:38,450 --> 00:01:45,790
So starting from that last loss to the last Thursday.

14
00:01:46,620 --> 00:01:54,350
All right. Not exactly. So we started to look at some basic statistics.

15
00:01:54,930 --> 00:01:59,460
So we looked at the Ladies Foundation, the Veterans Ladies Foundation.

16
00:02:00,480 --> 00:02:05,640
It's wild that the course, the fees that Asian is the center of the disclosure.

17
00:02:05,760 --> 00:02:10,740
We have little children. We are not the centers. That's one of the Asian means.

18
00:02:10,910 --> 00:02:13,810
So the mean or the average syndrome, obviously,

19
00:02:14,220 --> 00:02:20,760
and the various matter is how scratch the data is how much information there is in the in the disclosure.

20
00:02:21,150 --> 00:02:29,090
So these are two super important analyzes of a dispute examination and awareness.

21
00:02:30,960 --> 00:02:38,810
And now we talk about the covariance. Covariance is actually the quality that matters, the associations between two little girls.

22
00:02:40,380 --> 00:02:51,210
We have X and Y covariance. You know, the covariance measures, the how strongly these X and Y, they're linearly associated.

23
00:02:51,250 --> 00:02:58,980
And so here I really want to emphasize this idea of inclusion, because this is what covariance matters.

24
00:02:59,620 --> 00:03:02,830
It doesn't matter other type of association and matter,

25
00:03:02,860 --> 00:03:13,950
the strength of the decision between these intervals to run narratives of an event because covariance is not a scale involved.

26
00:03:14,220 --> 00:03:25,300
So if you change the change of the unit of the variable, then the corresponding value as the magnitude of the various covariance also change.

27
00:03:25,320 --> 00:03:28,650
This is not desirable in practice.

28
00:03:28,950 --> 00:03:35,850
So then we talk about a causal correlation. The correlation is sort of a standardized or normalized covariance,

29
00:03:36,300 --> 00:03:44,280
so that this correlation is always between negative one and one with negative one means a perfect linear,

30
00:03:44,670 --> 00:03:50,850
systematic linear association positive one meaning a perfect party, linear association.

31
00:03:51,210 --> 00:03:57,930
And typically the correlation is somewhere between somewhere in the middle between negative one one.

32
00:04:00,750 --> 00:04:06,540
So of equal to zero means that there is no need or association at all.

33
00:04:07,980 --> 00:04:11,130
And now we talk about the rules of covariance.

34
00:04:11,550 --> 00:04:15,510
And last time I actually talk about very quickly talk about this example.

35
00:04:15,780 --> 00:04:21,180
So I got some questions after the lecture. Now, let's really talk about this.

36
00:04:22,180 --> 00:04:25,480
And so. Here.

37
00:04:25,530 --> 00:04:29,670
This is an example. Try to illustrate this.

38
00:04:30,150 --> 00:04:40,110
So vocabularies, as we measure the covariance matters, the linear strength of linear relationship, linear association beat interim variables.

39
00:04:41,610 --> 00:04:46,260
So to run the variables they are independent in any manner is a very strong condition.

40
00:04:46,910 --> 00:04:51,480
But independence means that the 12 variables has nothing to do, had nothing to do with time.

41
00:04:53,370 --> 00:04:57,120
They are completely independent. One one has nothing to do with this on that.

42
00:04:57,630 --> 00:05:01,120
That's what I knows. It's uncorrelated.

43
00:05:01,680 --> 00:05:07,200
This is sort of matters. The linear association is a linear association.

44
00:05:07,950 --> 00:05:16,860
So anyone does that implies if we're not really variable or independent implies they are uncorrelated, but the other direction is not correct.

45
00:05:17,490 --> 00:05:22,260
We can take a look at a this is a is a good illustration.

46
00:05:23,520 --> 00:05:26,530
So suppose this is the unit circle, right?

47
00:05:26,560 --> 00:05:33,180
And if you take points, first of all, this circle doesn't matter how many.

48
00:05:33,510 --> 00:05:43,799
Hey, let's think of this many points from this. And in that if you calculate the correlation, we're clear as a corporation of these points,

49
00:05:43,800 --> 00:05:49,930
you will see that the correlation is exactly equal to zero. I'm sorry.

50
00:05:52,120 --> 00:05:58,330
So if you probably if you take it, take them, you are going to be a little bit careful.

51
00:05:58,660 --> 00:06:01,629
You can see the table. I'm like unequally spaced probably.

52
00:06:01,630 --> 00:06:10,570
You'll see you'll see some correlation for this finite point but let's say you take you know you take equal is based on his so.

53
00:06:16,790 --> 00:06:26,499
Let's say you take these many points, they are equal is based on the yearly circle and that if you calculate the covariance or correlation,

54
00:06:26,500 --> 00:06:33,190
you will see that that's exactly equal to zero because there is no linear association at all for the points you take.

55
00:06:33,670 --> 00:06:37,270
However, they are definitely not independent and you guys,

56
00:06:37,270 --> 00:06:44,860
they fall on the on the circle because x that implies that the Y value the square in some of

57
00:06:44,860 --> 00:06:49,780
the square is equal to one because all of these data points they fall beside Union Circle.

58
00:06:50,350 --> 00:06:57,290
So this is a good example. I was just trying to use this to illustrate that in manners and in unrelated, they're not the same thing.

59
00:07:00,700 --> 00:07:05,469
Okay, so that's covariance. So any questions so far?

60
00:07:05,470 --> 00:07:15,670
That's where we stopped in our muscle. Okay.

61
00:07:16,780 --> 00:07:22,240
So then about there. Well, there are certain rules about Olive Aarons.

62
00:07:22,280 --> 00:07:29,049
Natalie a couple of years. Let me and not only this class, but generally speaking, all of us subsidies.

63
00:07:29,050 --> 00:07:34,210
Of course, it's your whole take. These are some facts or some rules that will cause the news.

64
00:07:35,300 --> 00:07:43,310
So one is the bearers of the sun, the virus of the sun, a bunch of rubber animals.

65
00:07:43,790 --> 00:07:51,330
Now, this is well, the bearers is actually the bearers of a rule of law.

66
00:07:51,350 --> 00:07:55,160
If you consider this whole thing, let's say if you give a name, you call it a Z.

67
00:07:55,700 --> 00:08:02,820
Then this is the adjective, the covariance of. This is actually the clearance of Z and A Z yourself.

68
00:08:03,110 --> 00:08:20,090
So it's equal to. And then, if you recall, the one property of the Cobras.

69
00:08:22,240 --> 00:08:24,040
We're excited that we are using this one.

70
00:08:24,040 --> 00:08:33,130
But this one is just for you know, it's just for a sum of, well, a little over here, a side, an argument of the covariance.

71
00:08:34,180 --> 00:08:40,450
So in a sense, the covariance, a sequel to this covariance plus this covariance, and this can be easily shown.

72
00:08:40,830 --> 00:08:43,959
I mean, if you are interested or maybe you have already done this.

73
00:08:43,960 --> 00:08:49,360
So this can be easily shown by just referring to the definition of covariance.

74
00:08:49,540 --> 00:08:56,470
This is the definition of covariance. So you can very easily show all these properties here by going back to the definition of covariance.

75
00:08:58,120 --> 00:09:08,140
But anyway, so if we apply this property of the covariance, the now of course there's a slight generalization of that because here we have some.

76
00:09:10,750 --> 00:09:12,729
For both arguments of covariance.

77
00:09:12,730 --> 00:09:21,550
But if you apply that that rule repeatedly, you will see that this Congress is actually equal to, you know, this double.

78
00:09:22,830 --> 00:09:33,990
Double submission submission for I and a submission for J and the covariance between each of y i and wages.

79
00:09:35,320 --> 00:09:41,380
This is just a repeat application, repeated application of that of this role, of the coherence.

80
00:09:44,570 --> 00:09:52,570
And then once we got for this double summation here, now this is over and over.

81
00:09:52,850 --> 00:10:01,820
Of course, we can separate that. That was our measure into. Well, if we look at the term that is equal to G, when is equal to J,

82
00:10:01,850 --> 00:10:09,070
this covariance becomes the variance of either Y or YJ found naturally because we would have a case there I assume.

83
00:10:09,100 --> 00:10:20,690
Object. So. So definitely this double summation has these terms that these terms are the terms that that i's are equal to the eye is equal to J.

84
00:10:21,020 --> 00:10:34,760
So we have these guys and then what is left is what is left for established measure is the the terms that j is not able to y.

85
00:10:35,900 --> 00:10:41,500
Right down to then we well, we just keep the corresponding covariance.

86
00:10:44,880 --> 00:10:53,730
Okay. So this is how how how do we Jenner is being how do we, Calvin, are the bearers of the song?

87
00:10:53,730 --> 00:10:58,320
And then if you want to write it, read it further.

88
00:10:58,650 --> 00:11:07,460
Well, this is completely unnecessary. But look here it is not able to I because Jay and I they are they symmetry brothers.

89
00:11:07,470 --> 00:11:10,560
They are the the role they play. They are symmetric.

90
00:11:10,560 --> 00:11:13,710
So then you can write it as two times.

91
00:11:14,430 --> 00:11:17,480
Jay is now Jay is smaller than I. So there is a table here.

92
00:11:17,520 --> 00:11:26,310
This should be at minus one. So this is just mathematically it's also equal to this.

93
00:11:28,590 --> 00:11:39,360
But but the the main point is that when you consider the variance of the sup essentially equal to the some of the variance plus,

94
00:11:40,290 --> 00:11:43,860
you know, the some of the covariance of all the pairs.

95
00:11:51,330 --> 00:12:00,600
Okay. So that's how we calculate the variance of the sun from general when all the y ies are mutually independent.

96
00:12:00,720 --> 00:12:09,060
Yeah, independence is a very strong condition. But if they are all independent and in this course we are going to see that

97
00:12:10,350 --> 00:12:14,730
indeed this is a assumption that is commonly made in the coming days and weeks.

98
00:12:14,970 --> 00:12:18,580
That is to assume data points from different individuals.

99
00:12:18,600 --> 00:12:27,320
They are independent. Of course, later in other forces, some forces are going to relax this assumption by, at least in his words.

100
00:12:27,330 --> 00:12:31,890
We consider that the data point from different individuals, they are all independent.

101
00:12:32,910 --> 00:12:42,000
So when what they need of they are independent. Then if you look at this covariance here inside of the second summation.

102
00:12:43,430 --> 00:12:50,329
Because they are independent now. Of course they are uncorrelated and then the covariance is equal to zero for any.

103
00:12:50,330 --> 00:12:53,390
I am not equal to J right for any j, not even y.

104
00:12:54,140 --> 00:12:59,810
And then then the second term disappear because these are all equal to zero.

105
00:12:59,990 --> 00:13:05,690
All the terms are equal to zero. So what is left is this variance of the sun.

106
00:13:06,410 --> 00:13:10,580
And so this actually is what we have here.

107
00:13:12,200 --> 00:13:16,280
This is when all the white eyes, they're mutually independent.

108
00:13:18,890 --> 00:13:23,000
But you need to keep in mind that this is this is true only when they are independent.

109
00:13:23,090 --> 00:13:31,610
So the variance of the sum is equal to the sum of the various while they are abandoned or they are uncorrelated,

110
00:13:31,610 --> 00:13:36,440
or if they're uncorrelated, that it means the convergence of all the covariance are also equal to zero.

111
00:13:37,490 --> 00:13:45,140
But generally, I mean, what is the host you see already? We we are about four data points from the individual.

112
00:13:45,180 --> 00:13:50,360
We are assuming they are mutually independent. So the variance of some is equal to the sum of appearance.

113
00:13:50,540 --> 00:13:57,560
A generous figure. This is not true. Any questions?

114
00:14:04,210 --> 00:14:11,890
Okay. So now we talk about different qualities of the report that characterize the database fusion.

115
00:14:11,890 --> 00:14:15,760
I mean, the variance, the covariance, the correlation.

116
00:14:16,030 --> 00:14:22,640
And also we look at the certain rules about these different carriers, but how do we estimate?

117
00:14:22,870 --> 00:14:26,310
So the thing is that while we never know the truth, right.

118
00:14:26,350 --> 00:14:36,340
So if I if I of like is the hostess, if I ask you what is the distribution of age in the population, for example?

119
00:14:36,520 --> 00:14:44,410
And we never know the true age distribution. For example, if I asked you what is the expansion of age in the population like?

120
00:14:44,860 --> 00:14:47,979
We don't know. Right? So we don't know exactly about it. What is the variance?

121
00:14:47,980 --> 00:14:55,900
We don't know what is that true of a covariance between age and and A.S. adolescent allocation?

122
00:14:55,900 --> 00:15:04,270
Like what is the true association of what we can then give the kind of data to estimate these different quantities.

123
00:15:04,420 --> 00:15:11,980
And that's how like what as major we can construct how do we how do we construct estimate hours for this for this different quality.

124
00:15:12,130 --> 00:15:21,520
So first, let's take a look at of the mean. So again, the fundamental idea is not only for further estimation on these few quality,

125
00:15:21,520 --> 00:15:25,060
but generally speaking, this is I think we mentioned this probably once.

126
00:15:27,070 --> 00:15:30,670
So this that is what we are interested in is usually the population.

127
00:15:31,000 --> 00:15:35,410
What is the mean of the population living as an Asian or the average?

128
00:15:35,680 --> 00:15:39,920
What is the variance of what is the true association between, you know,

129
00:15:39,940 --> 00:15:45,190
this particular disease that is the risk of having this disease and a bunch of other covariates.

130
00:15:45,790 --> 00:15:50,110
So we don't know these. The true value of this quality is in population.

131
00:15:50,650 --> 00:15:57,490
But what we can do is while we collect data, we receive a small sample from the population and it looks like data.

132
00:15:57,910 --> 00:16:03,520
And then based on the data, we try to estimate all these qualities that are interesting.

133
00:16:04,000 --> 00:16:11,290
And here let's take a look at let's let's start from the simple qualities like first, let's take a look at a mean.

134
00:16:12,880 --> 00:16:17,290
Now for the mean. Once we have the data, let's say this is our data.

135
00:16:17,770 --> 00:16:23,620
So from the IDI, IDI means they are independent and I live with this building.

136
00:16:39,780 --> 00:16:43,920
So this is the typical assumption we make in many courses.

137
00:16:45,270 --> 00:16:48,770
So we have a run of sample of 40 hours.

138
00:16:48,790 --> 00:16:58,499
We have a simple random sample. So we have anybody that I don't have this really random variables and with 2 million new entries,

139
00:16:58,500 --> 00:17:01,380
Sigma Square, but we don't know the exact value of each.

140
00:17:01,470 --> 00:17:08,190
So we want to clear data and estimate them so the model can be estimated by the symbol average.

141
00:17:08,310 --> 00:17:14,880
That is very natural, very intuitive and we use wide bar to be put in out of the mean.

142
00:17:15,690 --> 00:17:24,750
And for this as a measure of the mean, well, we can calculate the expansion that is foundation because we know that you is a linear operator.

143
00:17:25,260 --> 00:17:33,900
So the expansion of the sample average is equal to the sample average of the expansion, which is the.

144
00:17:34,290 --> 00:17:39,540
Yeah. Because of the expansion linear operator. So then there is value in each.

145
00:17:39,570 --> 00:17:42,360
Why is we want they would tell you a sample average,

146
00:17:42,360 --> 00:17:49,970
you still get a new one so we can see that the expansion of the sample mean is equal to that true but I know we

147
00:17:50,200 --> 00:18:00,030
right so and the variance of the same what we well this is actually equal to the variance of the sample average.

148
00:18:02,770 --> 00:18:05,770
And then you can apply the rules of the virus.

149
00:18:06,130 --> 00:18:14,110
And here you have a constant you move it outside and that it becomes this whether we're in square an event because

150
00:18:14,110 --> 00:18:22,260
we have independence or the wise are independent so that the sun as the bearers of the sun become the sum of yeah.

151
00:18:22,300 --> 00:18:26,470
So that's the sum of these appearances.

152
00:18:27,370 --> 00:18:32,370
And then because the white eyes, they have the same distribution. So the variance on each one eye is,

153
00:18:33,400 --> 00:18:39,709
is seamless with their whole the same so that you take sun like in a sample

154
00:18:39,710 --> 00:18:45,610
within a single square and then you can cancel with this one one again here.

155
00:18:45,610 --> 00:18:50,530
So finally we are be able to see you will receive y squared over here.

156
00:18:50,960 --> 00:18:59,140
And this this is a straightforward application of the rules of awareness.

157
00:18:59,710 --> 00:19:09,070
So by applying that we can see that awareness of the mean is equal to the true errors divided by the total sample size.

158
00:19:12,730 --> 00:19:15,910
This is very simple. The assumption of the myth.

159
00:19:16,510 --> 00:19:22,230
So what about the bears and cobras? Not for the virus.

160
00:19:23,030 --> 00:19:25,730
We have this as major.

161
00:19:29,730 --> 00:19:44,370
Recall that the virus is equal to why climates that is and why aware that that's how very of how various is defined mathematically we never

162
00:19:44,430 --> 00:19:59,070
estimate this there is this expectation we estimated by assemble average here and this is estimated by this simple average and this expectations.

163
00:20:01,540 --> 00:20:05,919
Well, not here first. Suppose we know this is manager.

164
00:20:05,920 --> 00:20:10,000
I suppose the foundation mean he's not. Well, cognitions mean he's not.

165
00:20:10,090 --> 00:20:12,700
So while this quality is not. So, we just need to.

166
00:20:12,740 --> 00:20:19,870
When we estimate of errors, we just need to estimate of this expectation that that is replaced by by this somehow average.

167
00:20:23,760 --> 00:20:34,600
But a lot of the population is I know that we replaced this expectation by this similar average bar is also a simple average of the.

168
00:20:38,100 --> 00:20:45,840
But this is a of a general way of a very general way of estimating unknown quantity.

169
00:20:45,850 --> 00:20:49,810
So you just replace things foundation by sample average.

170
00:20:50,260 --> 00:21:01,720
So that that gives you a good aspect in the end. But, but notice that here, I mean, we replace this one number in five, one over and minus one.

171
00:21:03,720 --> 00:21:11,610
Well, this you can't interpret this. I mean, here you can interpret this in two ways.

172
00:21:12,090 --> 00:21:17,100
One way is that now because the mean is are unknown.

173
00:21:17,370 --> 00:21:22,620
So we have to estimate this is very wide by the sample average by white bar.

174
00:21:23,010 --> 00:21:27,270
Right. That's that's what we did. So we replaced this is that is not why I buy White Bar.

175
00:21:27,870 --> 00:21:30,080
So that means we actually, you know,

176
00:21:30,130 --> 00:21:37,980
sacrifice one degree of freedom as sort of the more freedom that does cause out later on to use this more and more often.

177
00:21:38,520 --> 00:21:43,070
So that's why we replace we need to replace this. We we need to adjust for that fact.

178
00:21:43,110 --> 00:21:47,270
So that's like clearly replaced by in n by minus one.

179
00:21:47,280 --> 00:21:50,970
That's one. One way to look at this.

180
00:21:51,300 --> 00:21:56,640
Another way, which I think is maybe simpler at this point, is that.

181
00:22:03,440 --> 00:22:13,430
Is that by replacing in by a minus one here is that area of sigma have square that's equal to the true but unknown quantity.

182
00:22:14,210 --> 00:22:25,400
So but without without this adjustment I mean, you have you have against you have probably, you know, minus one over five sea lions square.

183
00:22:28,820 --> 00:22:35,240
Right. So, Barbara, by making this adjustment, you have this exactly equal to this.

184
00:22:38,630 --> 00:22:44,480
So that's the estimation of the various replaced things valuation by several average.

185
00:22:47,120 --> 00:23:01,099
And then estimate her coverage. So now suppose we have these I.D. parents I.D. Paris and the cameras is by

186
00:23:01,100 --> 00:23:08,899
definition of cameras is equal to a foundation of Y minus these values and y times.

187
00:23:08,900 --> 00:23:15,740
X minus x foundation on the x. RADDATZ How Congress is defined.

188
00:23:17,040 --> 00:23:23,430
And then again, when we asked maybe these we replace these foundation by simple average.

189
00:23:23,820 --> 00:23:27,630
So this expanded in here. We replace it by some average.

190
00:23:27,670 --> 00:23:32,430
That's why BARR And this is rather a year we replaced by simple average.

191
00:23:32,430 --> 00:23:41,620
That's as far. And then this strategy here, we're replacing it by, you know, this sort of assemble average.

192
00:23:41,620 --> 00:23:46,260
But again, you know, we make this adjustment in minus one.

193
00:23:46,270 --> 00:23:52,120
This is based on similar consideration as well.

194
00:23:52,120 --> 00:23:55,330
We estimated that the bear has really published these unknown.

195
00:23:55,360 --> 00:24:01,150
So because we have to lose lending more freedom when we estimate at the Y bar and X bar.

196
00:24:03,940 --> 00:24:05,650
So but one in a while here.

197
00:24:06,530 --> 00:24:14,559
I mean, generally speaking, I mean, in this course, we will pay some attention to this difference that we use in working on this one denominator.

198
00:24:14,560 --> 00:24:18,340
I and that's a that's sort of a, a big thing linear regression.

199
00:24:18,760 --> 00:24:25,909
But every year we take a look at are the causes and really there's not a big if you guys within

200
00:24:25,910 --> 00:24:35,080
this is large in these 3050 100 for example and minus one really there's no real difference.

201
00:24:35,830 --> 00:24:40,190
So but in this course, we will we will we will still pay attention to this difference.

202
00:24:40,190 --> 00:24:48,190
So here here, because of the issues of funding or freedom, we were used and one this one, that's how we estimated the covariance.

203
00:24:48,790 --> 00:24:56,240
Then the correlation, of course, is just equal to. The estimate of the covariance divided by.

204
00:24:57,520 --> 00:25:02,790
But. As month.

205
00:25:06,980 --> 00:25:13,580
The scoring of that, as made up various wide times, described them as new of X.

206
00:25:18,320 --> 00:25:21,790
Okay. Any questions so far?

207
00:25:33,330 --> 00:25:44,010
Okay. And then we're going to take a look at some like four very important decisions, very, very important decisions for linear regression models.

208
00:25:45,780 --> 00:25:51,270
And later, throughout the course, we are going to actually rely heavily on this for four distributions.

209
00:25:51,710 --> 00:25:58,830
And when we talk about different studies, different methods in different aspects of linear regression.

210
00:25:59,190 --> 00:26:03,089
So this discussions are normal as usual cause of our distribution,

211
00:26:03,090 --> 00:26:10,380
cuz s distribution and all of these distributions should be generated based on normal distribution.

212
00:26:10,530 --> 00:26:16,590
So once you have learned this, you can generate all these D for four different solutions or the other three disclosure.

213
00:26:16,650 --> 00:26:20,580
Let's take a look at what they are and how they are related.

214
00:26:21,780 --> 00:26:32,010
So more with the solution. I believe everybody now has some exposure to normal distribution.

215
00:26:32,290 --> 00:26:42,480
So this is one of the most widely seen dispersion in modeling statistics, body science for almost all scientific areas.

216
00:26:42,510 --> 00:26:46,830
This is this is most fundamental distribution.

217
00:26:48,420 --> 00:26:51,720
So normal distribution, the density is given by.

218
00:26:52,770 --> 00:26:55,620
This is the mean. This is the variance. The normal thing.

219
00:26:55,630 --> 00:27:04,840
I mean, the end of the atlas and was you know what are the mean virus are that this is the density and PDF normal exclusion.

220
00:27:05,400 --> 00:27:11,930
And this is what a normal distribution looks like. What generally wall.

221
00:27:17,880 --> 00:27:20,930
And this is what a normal business would look like.

222
00:27:20,960 --> 00:27:28,100
So so is the metric about is mean end of the year is equal to see my salary.

223
00:27:28,520 --> 00:27:31,640
This is why I write.

224
00:27:35,950 --> 00:27:42,310
And the normal diffusion well was new as mean and seen much more as there is.

225
00:27:42,700 --> 00:27:49,750
Then if we take samples from done with this fusion, let's say you take repeated the sample example from all of this fusion.

226
00:27:50,230 --> 00:27:54,100
Take a thousand data points, for example, maybe, maybe 10,000 points.

227
00:27:54,730 --> 00:28:03,860
And then if you take many data points, you will see that roughly two thirds of two thirds of these data points were for, let's say, here now.

228
00:28:03,890 --> 00:28:12,310
So here is is a new minus one center revision and here is new plus Western division.

229
00:28:12,580 --> 00:28:16,060
And here is the new minus true center deviation.

230
00:28:16,300 --> 00:28:19,210
And if you have this new plus two standard deviation.

231
00:28:22,310 --> 00:28:31,430
So if you take many, many coins from normal distribution, you will see that roughly two thirds of the data points will fall between you know,

232
00:28:31,550 --> 00:28:35,030
you might as well start your division in the middle plus one division.

233
00:28:35,630 --> 00:28:45,740
So in other words, the area here under this shaded area, this is roughly one points, about two thirds of the whole area.

234
00:28:45,740 --> 00:28:48,889
Other is curved. That's equal to one because this is a PDF.

235
00:28:48,890 --> 00:28:57,140
So the area on the left figure that's even one. So the shading area here between minus my interview crossing and that's that's two thirds.

236
00:28:58,010 --> 00:29:06,770
And again, roughly 95% of the data points will fall between mil minus two sigma and a plus two sigma.

237
00:29:09,800 --> 00:29:20,210
So in other words, if you look at this shaded area, the whole thing of the city, that's roughly 95%, 4.95.

238
00:29:20,750 --> 00:29:30,540
And again. About 99% of the data points to a fault between new minus three sigma and the plus.

239
00:29:33,500 --> 00:29:42,480
This is one way to try to interpret the norm of this usually symmetric.

240
00:29:43,100 --> 00:29:52,410
And then if you look at a different like different division from the from the middle England, roughly,

241
00:29:52,430 --> 00:29:57,709
we know how many points fall between the middle was one less central division

242
00:29:57,710 --> 00:30:02,570
away from the median two center division and three center divisions away from.

243
00:30:05,360 --> 00:30:10,040
So that's normal as usual. And then linear combinations of normals are also normal.

244
00:30:10,040 --> 00:30:20,210
So if y if follow a normal distribution and if we look at this linear accommodation, then it also follow normal.

245
00:30:20,600 --> 00:30:25,169
So the foundation of this now, because this is linear,

246
00:30:25,170 --> 00:30:33,230
our return so is equal to this and of the virus on this is eight times is where it has a Y it's.

247
00:30:36,170 --> 00:30:42,350
That's just based on the rule of the veterans. And also we have centralize the Y.

248
00:30:42,350 --> 00:30:48,530
So if y I follow the a normal server with me new and a my square of errors

249
00:30:49,130 --> 00:30:55,460
that if we subtract y me and divide of the difference by the center division.

250
00:30:55,820 --> 00:31:00,500
This is so-called centralization with normalization of another variable.

251
00:31:01,190 --> 00:31:05,060
And then this Z follows a standard normal distribution.

252
00:31:05,750 --> 00:31:14,600
So this transformation here is just corresponds to, you know, we shift that while we shake the PDF of Y,

253
00:31:14,840 --> 00:31:22,310
which is center to zero, and then we either squeeze it or stretch it a little bit so that it has variance equal to one.

254
00:31:23,000 --> 00:31:26,330
So this that is what this transformation does.

255
00:31:33,370 --> 00:31:37,870
So that's normal distribution. Any questions?

256
00:31:44,210 --> 00:31:49,460
Okay. So once we have normal distribution, then we can generate the so called a customer distribution.

257
00:31:51,660 --> 00:31:59,070
Because word is fusion we use this notation customer is usually the parameter is the result of your freedom.

258
00:31:59,610 --> 00:32:02,910
So this is a positive integer. We'll see. Whatever means.

259
00:32:04,150 --> 00:32:09,049
Oh, well, maybe we can take a look at how it's generated so easy.

260
00:32:09,050 --> 00:32:10,480
See, I follow standard. Normal.

261
00:32:11,800 --> 00:32:20,020
Then if we take the square of Z, then we will have a course square and run an error with what they were afraid of with one degree of freedom.

262
00:32:21,460 --> 00:32:31,690
But if we have multiple, let's say we have in the Z, there are independent and all those follow center normal distribution.

263
00:32:32,500 --> 00:32:40,330
And then if we take some of the squares of this VI, then we will have a Chi Square distribution.

264
00:32:40,510 --> 00:32:46,590
Now, with in degree freedom, this is how many z icr your sum.

265
00:32:47,410 --> 00:32:54,340
So we are summing up in the squares that we have here now.

266
00:32:55,900 --> 00:33:00,510
So this is how square distribution is generated.

267
00:33:00,520 --> 00:33:07,860
It's computer generated from normal distribution, a bunch of center normal rows, variables that are independent of the earth.

268
00:33:08,240 --> 00:33:12,880
And while here, two things are important. One is these have to be independent.

269
00:33:14,350 --> 00:33:17,870
And also you have to be centered normal running animals.

270
00:33:18,790 --> 00:33:24,340
So and then for at least in evaluation, the long running variables even simply take a sum of squares.

271
00:33:25,090 --> 00:33:37,389
You will get the Chi Square distribution. So then this generous speaking, this your freedom here, this, this is this represent just how many standard,

272
00:33:37,390 --> 00:33:41,020
normal, independent, central, normal run variables are taking up.

273
00:33:42,190 --> 00:33:48,610
And then you see that Asian of course, squared I run an error mode is equal to its degree of freedom.

274
00:33:50,260 --> 00:33:59,170
Now, of course, because. Because the customer is generated by taking the sum of the squares of of their bills.

275
00:33:59,490 --> 00:34:03,180
So ants can only take part in balance.

276
00:34:06,690 --> 00:34:11,640
And generally speaking, this is what a crossword distribution the PDF looks like.

277
00:34:12,060 --> 00:34:22,500
So it looks like something like this. This is Chi Square distribution.

278
00:34:22,650 --> 00:34:26,910
So we can see that we can easily, very easily generate Chi Square distribution.

279
00:34:27,510 --> 00:34:33,900
If you generate a general rule, the variables that follow customers, which once we have normal, the distribution of the animals.

280
00:34:37,110 --> 00:34:42,479
And another important decision is the so-called T distribution that can be

281
00:34:42,480 --> 00:34:47,910
generated after we reach out to the normal and chi square among the variables.

282
00:34:48,780 --> 00:34:58,680
Suppose we have. A standard normal run the variable Z and also we have a course where the variable S square.

283
00:35:00,200 --> 00:35:07,850
And Z as they are independent. Again, basically, if anyone knows, it's very, very important to ask whether they are independent.

284
00:35:09,050 --> 00:35:15,620
And then if you look at this rather variable, this is Z divided by.

285
00:35:18,050 --> 00:35:28,190
This is also. I don't know which which way is easier, but you can also consider it in this way.

286
00:35:28,200 --> 00:35:41,360
So. It's the divided by the square root of the cause, scoring a veritable best square divided by its all the more afraid of.

287
00:35:44,880 --> 00:35:48,540
So then that follows a distribution that we call a transfusion.

288
00:35:49,620 --> 00:35:58,050
And transfusion that we were afraid of is equal to the growth rate, on the cost burden, on the variable that it's used to generate.

289
00:35:58,330 --> 00:36:11,870
If you. So you can see that once we have a normal rhythm and because we're in the miracle that we can very easily generate the team as usual.

290
00:36:12,870 --> 00:36:16,600
And tennis fusion. It's actually.

291
00:36:24,130 --> 00:36:27,360
It's symmetric about zero. Okay.

292
00:36:29,620 --> 00:36:36,470
And it looks very similar to the you know, to the new normal, a standard normal pdaf.

293
00:36:37,030 --> 00:36:43,710
But the difference is that it has a heavier tail. So this this this one is t distributed.

294
00:36:44,110 --> 00:36:48,760
And in this one here, this is this instead of normal fusion.

295
00:36:49,060 --> 00:36:54,820
So it has a heavier hill than the you know, this fusion.

296
00:37:00,150 --> 00:37:05,720
Well, a degree of freedom is large. Then there's essentially no difference.

297
00:37:05,840 --> 00:37:11,090
So if the degree you're afraid of goes to infinity, that t just becomes so normal, that narrow.

298
00:37:12,710 --> 00:37:18,230
So the difference is only when you TS is finite is also one that the growth rate on is small.

299
00:37:18,890 --> 00:37:21,230
And then there there there is the difference.

300
00:37:21,920 --> 00:37:29,210
Now for do you are afraid of learning that learned at 30 keys while tedious version closer resemble the standard one.

301
00:37:30,000 --> 00:37:40,070
There's going to be no point of distinguishing between experience with their logical freedom and of extending normal distribution.

302
00:37:42,230 --> 00:37:51,530
But in this course, you will rely heavily on key distribution to later talk about making inference that I have on key distribution.

303
00:37:54,780 --> 00:38:01,950
Okay. That's tedious decision. Another very important decision, the so-called F distribution.

304
00:38:03,600 --> 00:38:13,770
And this fusion can be generated if you have two chi square rhythm variables x one square follow chi square and that's two square.

305
00:38:13,920 --> 00:38:22,080
Follow Chi Square with two direct freedom to evenly rhythm and these two have to be independent.

306
00:38:22,440 --> 00:38:28,950
You can see that when we generate the chi square, the key and evidence usually require all of these to be random.

307
00:38:30,090 --> 00:38:39,540
So if there are any. But then we look at s one square divided by is only for freedom and x to a square are divided based on the operator.

308
00:38:39,930 --> 00:38:44,520
And we look at the ratio, then the corresponding distribution.

309
00:38:44,520 --> 00:38:52,829
We call it f this fusion. Well, Cabinet's building has two parameters for freedom.

310
00:38:52,830 --> 00:39:01,629
One, integral freedom to. And by definition, of course, the app is used in only data.

311
00:39:01,630 --> 00:39:05,440
Policy matters because costs were the honorable gentleman paying party knowledge.

312
00:39:05,680 --> 00:39:08,650
Now, of course, the original content policy battles.

313
00:39:10,430 --> 00:39:20,450
And then for for for tedious version, it was simply Taylor Square on the cheek that was the arch after this fusion.

314
00:39:20,900 --> 00:39:26,480
Here with Wendy we're afraid up here. But then the second to be more freedom is equal to more freedom.

315
00:39:27,020 --> 00:39:32,120
The reason is that he used to actually record that he's actually divided by this.

316
00:39:34,000 --> 00:39:41,140
And if we take the square of the teeth, we will look at this square, divided by square, divided by exterior freedom.

317
00:39:42,730 --> 00:39:46,630
And this is where we know it follows chi square with one bigger freedom.

318
00:39:47,470 --> 00:39:53,300
And this one follow chi square with. This many dwarfism.

319
00:39:53,720 --> 00:40:01,400
So that by definition this this one should follow this whole thing should follow after exposure without the numerator has let me reiterate.

320
00:40:01,400 --> 00:40:04,720
I mean denominator has so much freedom.

321
00:40:07,790 --> 00:40:17,300
So in other words, now latitudes fusion and AB this fusion they are connected so that we can where we do have an.

322
00:40:24,530 --> 00:40:30,970
Okay. These are four very important decisions in statistics in Boston, especially, Nina.

323
00:40:31,330 --> 00:40:32,409
I mean, these decisions,

324
00:40:32,410 --> 00:40:41,140
they are an inspiration and key decision and they become less important when we move on to generalized models and other courses.

325
00:40:41,410 --> 00:40:45,140
But they play a fundamental role in linear regression models.

326
00:40:45,160 --> 00:40:48,220
And later, we're going to see how they can be applied.

327
00:40:49,120 --> 00:40:54,250
But then all these decisions are related. As normal as futurism was, you know, how to generate a normal distribution,

328
00:40:54,610 --> 00:40:59,590
how we are going to run the variables, then you should be able to generate all these different distributions.

329
00:41:04,020 --> 00:41:14,390
Any questions? Just. Okay.

330
00:41:14,490 --> 00:41:24,840
If there's no question, then we are on to a while. This is the end of the module a where we do want people to see.

331
00:41:38,050 --> 00:41:41,970
Okay. You might be our focus is going to be our symbol interaction.

332
00:41:42,370 --> 00:41:48,100
So in module eight, what we did was we look at the overall picture while they're doing this for us,

333
00:41:49,060 --> 00:41:58,030
the different aspects of linear regression models for searching for a model, be ready to take a deep dove into the first linear regression model.

334
00:41:58,030 --> 00:42:02,080
We are able to look at sorry symbol linear regression model with one covariate.

335
00:42:03,530 --> 00:42:10,939
We're going to look at it, interpretation of the parameters, how to estimate those parameters and the properties of asymmetric.

336
00:42:10,940 --> 00:42:17,690
So we rely heavily on the so-called least square assumption and then we look at an estimation of various

337
00:42:18,710 --> 00:42:27,170
and if we want to read a textbook one of these based on chapters one and two from the textbook.

338
00:42:30,840 --> 00:42:42,390
So this is what a simple linear regression model is. So it has it has just one covariate, a single covariate.

339
00:42:42,930 --> 00:42:45,120
And this is why it's called a simple linear regression.

340
00:42:46,380 --> 00:42:54,070
And here why is what we call the response variable one of the all time values for the dependent variable.

341
00:42:54,090 --> 00:43:04,020
So different people have different names for this, but they all mean the same thing depending on which area people come from.

342
00:43:04,770 --> 00:43:14,160
Okay. So why is the response variable and and the X is the culture for covariate or predictor or people were intimate of the animals.

343
00:43:15,870 --> 00:43:20,130
And in this work, we will consider the X values to be fixed.

344
00:43:20,220 --> 00:43:23,820
I later want to talk a little bit more about this.

345
00:43:23,970 --> 00:43:27,780
So s they are not random X on fixed values.

346
00:43:29,010 --> 00:43:34,860
And then we have this to ration parameters that will has been a zero and beta one.

347
00:43:35,130 --> 00:43:39,720
These are the so called a regression coefficient and the beta zero.

348
00:43:39,720 --> 00:43:44,700
Here is the intercept. What is the slope?

349
00:43:46,170 --> 00:43:52,020
And these videos in regression, we consider this betas are fixed numbers.

350
00:43:53,670 --> 00:44:02,100
We don't know what their variant values are. And so that's that's why we are we try to estimate them using the data, but they are fixed.

351
00:44:02,640 --> 00:44:07,290
They are unknown. And they are you can you can just do a truncated one.

352
00:44:07,530 --> 00:44:10,860
Think of these as fixed numbers face. But I know numbers.

353
00:44:11,040 --> 00:44:14,340
And we are trying to estimate this intercept and slope.

354
00:44:16,460 --> 00:44:23,210
And then we have the absolute the so-called error of this error as well to characterize, you know,

355
00:44:23,240 --> 00:44:31,600
the difference among individuals that have the same enzyme that, let's say X is H, right?

356
00:44:31,610 --> 00:44:38,150
So make things concrete, let's say X is H and why is a blood pressure missing?

357
00:44:38,900 --> 00:44:47,270
And then so this model assumes that a blood pressure depends on age in a linear in a linear way.

358
00:44:47,540 --> 00:44:55,850
Right. So this may be a two know travel approximation, but let's say that we are using those to model blood pressure.

359
00:44:56,660 --> 00:45:05,960
And then what this model says is that on average, the people at a same age, they will have on average the same blood pressure.

360
00:45:06,500 --> 00:45:11,780
But of course, I mean, if you look at even people who have different age, they will definitely have different blood pressure.

361
00:45:12,380 --> 00:45:19,820
So that assumes characterized by Eric. So knowing that, you know, that these are individuals building differences.

362
00:45:20,810 --> 00:45:25,580
So this error actually is used to categorize attachment.

363
00:45:26,030 --> 00:45:30,560
So these are the different components of simple linear regression model.

364
00:45:30,980 --> 00:45:40,320
Again, our goal is to collect data. By collecting data, that means we collect values of x and y, y es.

365
00:45:40,320 --> 00:45:49,650
Our response axes are covariance, so we take sample from the population, let's say a while with a sample size again as again is equal to a thousand.

366
00:45:50,130 --> 00:45:54,450
And then we for this a thousand individuals matter their age.

367
00:45:55,980 --> 00:45:59,160
And then this is the information we have, this is the data we have.

368
00:45:59,490 --> 00:46:08,040
And then based on data, we're trying to estimate the spread of zero and the beta one because beta one represents,

369
00:46:08,610 --> 00:46:15,000
you know, how in fact of age but project price or association between these two.

370
00:46:15,630 --> 00:46:19,590
So that's all simple in your regression model.

371
00:46:22,260 --> 00:46:28,680
Now the linear model, the linear linearity actually refers to that.

372
00:46:29,250 --> 00:46:40,250
The mean of Y, given X is linear in the right and in beta, not necessarily in the comparative x.

373
00:46:41,850 --> 00:46:49,500
So for example, if you look at all of these examples of the three examples here, these are all linear regression models we can.

374
00:46:50,070 --> 00:46:54,150
So these are just based on different transformation of the covariate.

375
00:46:56,280 --> 00:47:04,250
We just transferred over a little bit, but we are still fed to the same linear measurement linear in terms of this dataset.

376
00:47:05,320 --> 00:47:14,390
So these are all linear regression models. On the other hand, these are not linear regression models.

377
00:47:14,750 --> 00:47:21,590
So because if you look at their dependance on data, they are not linear dependance on all these factors.

378
00:47:22,020 --> 00:47:27,650
So there is a measure exponential function. So these are not linear models.

379
00:47:28,610 --> 00:47:36,170
So in this class, when we talk about linear regression models, what we deal with is examples like these.

380
00:47:36,800 --> 00:47:44,300
So we don't care that much whether I mean the covariance, whether you make transformation or not.

381
00:47:44,310 --> 00:47:48,110
Because even if you make a transformation, I could simply call this Z.

382
00:47:48,110 --> 00:47:53,360
I rescue Ava DuVernay. So I, for example, I pass the data to you.

383
00:47:53,370 --> 00:48:01,490
I, I don't even tell you. Z is equal to Z squared minus the gravity file a z and a you.

384
00:48:02,810 --> 00:48:06,870
And then you can do that freedom model in a second line.

385
00:48:06,890 --> 00:48:15,690
So it's still a crash model. Any questions so far?

386
00:48:23,150 --> 00:48:26,690
Now for linear regression model, there are certain assumptions.

387
00:48:31,150 --> 00:48:38,799
So here this smart ass listening to some assignment and call this and this this like her slides to try to

388
00:48:38,800 --> 00:48:45,730
separate assumptions for assumptions some assumptions for inference which I mean which which which is okay,

389
00:48:45,730 --> 00:48:52,250
but, but it's actually has some capacity to that to the coverage like let's take a look at.

390
00:48:52,250 --> 00:48:56,020
And so first let's take a look out of assumptions for estimation.

391
00:48:58,980 --> 00:49:01,950
Now for for for estimation.

392
00:49:01,950 --> 00:49:12,269
That means if we only if we are only interested in estimating beta zero in a beta one, our goal is just as made known about inference.

393
00:49:12,270 --> 00:49:17,610
We will later rule. And how about inference? But let's say now our goal is just to estimation, as it were, in beta one.

394
00:49:18,590 --> 00:49:25,910
And again, these are the assumptions that are needed in order to estimate, problem, estimate better, zero and a better one.

395
00:49:26,930 --> 00:49:33,410
So one assumption is that the error term follow some distribution.

396
00:49:34,090 --> 00:49:39,770
You know, we are not asking you to follow normal distribution. It's not necessary to assume you're following us.

397
00:49:40,250 --> 00:49:48,920
We're simply saying it follows some distribution. The disorder has mean zero and a virus equal to seems clear.

398
00:49:50,630 --> 00:49:56,660
That's one assumption. Another assumption is that these are individuals.

399
00:49:58,310 --> 00:50:02,680
The error terms, they are uncorrelated. So if you look out on the covariance,

400
00:50:03,740 --> 00:50:12,410
if Macquarie are is a true absolute I have some Jake the covariance is equal to zero for I not equal to J for different individuals.

401
00:50:12,800 --> 00:50:17,410
The covariance is equal to zero. So these are uncorrelated.

402
00:50:17,420 --> 00:50:21,740
But as we know, that uncorrelated doesn't mean imbalance.

403
00:50:21,930 --> 00:50:28,940
So here we are not assuming environments. So for estimation, I mean, it's another to assume imbalance.

404
00:50:32,960 --> 00:50:38,540
So these are, you know, assumptions that we make when we just care about estimation.

405
00:50:39,630 --> 00:50:44,960
We just care about estimation. But later, when we talk about inference making you first,

406
00:50:44,990 --> 00:50:51,410
that means we are constrained to accommodate the scenarios we are combining all those testing,

407
00:50:52,030 --> 00:50:57,110
both concepts that we are able to make them more clear later in later lectures.

408
00:50:59,140 --> 00:51:05,910
Now we are going to assume that this absolute I they follow the idea the imbalance

409
00:51:05,920 --> 00:51:11,260
I think is really they follow normal discussion with me and they see my script.

410
00:51:11,620 --> 00:51:21,280
And indeed, I think if you ask most people what we are like, what are my options for obviously most people will,

411
00:51:21,550 --> 00:51:29,170
without seeing a model, would directly say while there in terms of normal discussion with what can you do in a single square?

412
00:51:30,010 --> 00:51:34,460
So but here, I mean, this is like a slight surprise.

413
00:51:34,570 --> 00:51:43,120
These assumptions now for estimation, actually, we can we can make a set of less restrictive assumptions.

414
00:51:43,750 --> 00:51:52,870
But generally speaking, I mean, for either model because for a linear regression model, we do care about how long this has and do care about place.

415
00:51:53,290 --> 00:52:02,550
So the idea that the most fundamental assumption that's actually assuming the error follows normal distribution mean,

416
00:52:03,300 --> 00:52:07,660
mean, zero there and see my square and I'm assuming they are independent.

417
00:52:08,920 --> 00:52:21,350
Okay. Okay. So let's take a seven minute break and we will come back you.

418
00:52:30,620 --> 00:52:38,750
And if we if we just look at these tools, assumptions, assuming that absent follow some exclusion,

419
00:52:39,560 --> 00:52:47,660
not necessarily normal means zero in a C must work and we are uncorrelated error terms aren't related.

420
00:52:48,170 --> 00:52:51,510
Then if you.

421
00:52:51,600 --> 00:52:59,970
Look at the exact reason why given X because the error terms appear in the examination, the error is equal to zero as we assumed.

422
00:53:00,330 --> 00:53:11,930
So indeed it has this been here for the last year or depending on a bit of zero and the have one end of the virus here.

423
00:53:11,940 --> 00:53:25,180
The virus is just equal to the virus of Y because we call the event that we call that what is equal to zero plus beta one has lost everything

424
00:53:25,500 --> 00:53:36,240
and so that the virus of Y because this is it has a fixed number so the variance of y is equal to the variance of absolute sigma squared.

425
00:53:37,380 --> 00:53:44,460
So does not depend on that does not depend on x, y and the y y they are uncorrelated.

426
00:53:45,060 --> 00:53:51,060
So in other words, these are, you know, some implications based on this two assumptions.

427
00:53:52,590 --> 00:53:56,399
But again, here I want to point out that really, I mean, for linear regression,

428
00:53:56,400 --> 00:54:01,170
it's it's you are if people do not separate this such assumptions for estimation

429
00:54:01,170 --> 00:54:07,110
assumption for inference although I mean mathematically they may be different.

430
00:54:07,230 --> 00:54:17,160
But really this is if you ask people what what assumptions are behind linear regression, most likely people will say,

431
00:54:17,160 --> 00:54:23,130
oh, you are assuming the median have a term follow girls would mean zero and we are assuming square.

432
00:54:23,460 --> 00:54:28,500
Now that's usually what we are going to look at for for on the next slide.

433
00:54:29,040 --> 00:54:35,850
So this is for a full list of the assumptions that we make for linear right behind your lecture model.

434
00:54:35,850 --> 00:54:43,049
This is for estimation and inference. So generally speaking, if you ask people what assumptions are made are behind regression model,

435
00:54:43,050 --> 00:54:46,170
these are the assumptions behind the interaction model.

436
00:54:47,490 --> 00:54:55,020
And here you can actually this probably help help a little bit to remember these assumptions.

437
00:54:56,820 --> 00:55:00,959
So the first is the linearity, right? Of course, linear regression model.

438
00:55:00,960 --> 00:55:09,090
We assume that the Y depends on depends on the parameters, the parameters in a linear fashion.

439
00:55:09,270 --> 00:55:10,890
Right. This is the so-called linear.

440
00:55:11,610 --> 00:55:18,870
And for linear regression model, of course, we assume this model is craggy as specified because otherwise, I mean, we can't do anything further.

441
00:55:19,290 --> 00:55:23,110
So here, while assumption that the meaning of all of these, Craig,

442
00:55:23,110 --> 00:55:29,789
the space facts or indeed the dependance of Y, all x is can be can be modeled in this way.

443
00:55:29,790 --> 00:55:33,720
This is a crank model. So this is one assumption.

444
00:55:33,840 --> 00:55:37,840
The linearity assumption. And another assumption is that.

445
00:55:38,790 --> 00:55:42,510
The error terms for different individuals. They are independent.

446
00:55:43,110 --> 00:55:51,900
So we are seeing in the same data as you cocktails, ads that are content in a thousand individuals.

447
00:55:52,380 --> 00:55:56,610
So this assumption says that in these of individuals, there are error terms.

448
00:55:56,610 --> 00:56:05,820
They're all embedded, mutually independent. And then, of course, amidst the responses, they're are also mutually independent.

449
00:56:08,190 --> 00:56:13,379
And another assumption is that the error term followed normal distribution would

450
00:56:13,380 --> 00:56:19,980
mean zero and embarrass sigma squared and the same as square does not depend on X5.

451
00:56:20,580 --> 00:56:30,389
So this is a constant veterans actually is this this is true for for every individual it doesn't matter what X5 out of their individual

452
00:56:30,390 --> 00:56:41,760
house so this this is a of veterans and it was we assume the of of errors of course that y I given x Y now it followed normal distribution.

453
00:56:42,120 --> 00:56:49,310
Would this mean this mean which is actually that this is not a component of here.

454
00:56:49,330 --> 00:56:53,640
Right? This means the variance is just equal to similar square.

455
00:56:53,970 --> 00:56:58,900
The variance does not change with excited about it.

456
00:56:58,930 --> 00:57:05,740
So it's been we have a constant variance. That's actually sorry, but that's actually the last assumption.

457
00:57:05,750 --> 00:57:10,130
So that the virus is always a constant.

458
00:57:10,340 --> 00:57:14,930
It does not vary for different individuals. This is the so-called equal variance assumption.

459
00:57:17,620 --> 00:57:24,640
These are the. You know about the fundamental assumptions we make behind linear regression model.

460
00:57:26,260 --> 00:57:31,389
So again, we assume linearity. That is to say that already in your model is practice.

461
00:57:31,390 --> 00:57:40,330
This might result in need of a relationship is greater as a linear model and a size only the error terms their their environment.

462
00:57:40,390 --> 00:57:49,000
The different individuals that are independent in the dataset and you already this is you are the one this is satisfied.

463
00:57:50,200 --> 00:58:01,600
If we assume our data, their idea, their independent distribution, and then we assume the normality, okay, so that it stands for normality result,

464
00:58:02,020 --> 00:58:08,940
we assume that absolute return followed normal distribution with mean zero is very similar square and of then

465
00:58:08,950 --> 00:58:15,460
the last one they use has four equal equal variance things out of that veterans for different individuals,

466
00:58:15,460 --> 00:58:25,330
they are all the same they're equal to see my script and this I stands for in abundance and with this L stands for narrative.

467
00:58:25,570 --> 00:58:33,190
So this this is the first options behind the linear regression models.

468
00:58:35,370 --> 00:58:41,600
Any questions? Yes.

469
00:58:42,080 --> 00:58:47,330
It's just the middle to the errors.

470
00:58:47,990 --> 00:58:53,430
I'd normally zero sigma squared. Is that sufficient for all of these?

471
00:58:53,450 --> 00:58:59,490
Because if you say. It. There is a normal distribution with means zero.

472
00:58:59,490 --> 00:59:07,950
Does that imply that the model is correctly or do you need both separately of.

473
00:59:10,040 --> 00:59:13,880
So okay, so these four assumptions, they are there.

474
00:59:13,910 --> 00:59:19,160
There are separate assumptions. One assumption does not imply no redundancy.

475
00:59:19,610 --> 00:59:23,809
No, there is no there is no redundancy. So, yeah.

476
00:59:23,810 --> 00:59:33,240
So for linear regression models, indeed, we have to make all these assumptions about what I have said.

477
00:59:33,290 --> 00:59:44,800
We have to but but these are not the made us behind linear regression models and the these are assumptions they are mutually exclusive.

478
00:59:44,810 --> 00:59:48,970
So one does not imply the idea for example, that's a linear, right?

479
00:59:48,980 --> 00:59:56,270
So this is about the model, the structure of the model. So from linearity model, narrative does not imply an abundance of their return.

480
00:59:56,660 --> 01:00:00,140
It does doesn't imply that error followed luminous solution.

481
01:00:00,530 --> 01:00:03,530
It doesn't imply, you know, the constant is balance.

482
01:00:03,870 --> 01:00:07,790
It's sorry, numbers is constant resolver.

483
01:00:08,030 --> 01:00:12,290
The one assumption here does not imply the other assumptions are yeah.

484
01:00:12,380 --> 01:00:23,600
So these assumptions are are are the ones that are probably most widely used the assumptions behind intersection models.

485
01:00:27,120 --> 01:00:37,900
Okay. Any other questions? Okay.

486
01:00:39,100 --> 01:00:43,900
And then here's a linear regression model here.

487
01:00:43,990 --> 01:00:48,190
Throughout this course, we will consider the called a fixed design.

488
01:00:51,280 --> 01:00:59,460
This means that this x rs they are treated as fixed constants rather than other variables.

489
01:00:59,470 --> 01:01:02,770
I mean, for linear regression model, there are two ways of doing this.

490
01:01:02,860 --> 01:01:06,850
This is just one of one one view that we take in this course.

491
01:01:07,240 --> 01:01:10,960
So we assume this exercise there. There are concerns there.

492
01:01:11,200 --> 01:01:18,910
There are not really variables. So we can think of this while this is more a from a experimental design perspective.

493
01:01:21,000 --> 01:01:25,330
So you can think of the kind of data in this particular way.

494
01:01:25,350 --> 01:01:34,650
So let's say you want to study the association between.

495
01:01:37,030 --> 01:01:45,260
Just as BP and let's say here I'm making of an example, let's say an oxygen level, right?

496
01:01:45,260 --> 01:01:50,089
And then for education, location for simplicity, let's consider we have two categories.

497
01:01:50,090 --> 01:01:56,300
One is people without a college degree and a wide people with some college education or maybe higher.

498
01:01:57,080 --> 01:02:05,750
So then when you have data, we designed the experiment where you have data, you can think of this as, first,

499
01:02:05,840 --> 01:02:14,750
I'm going to look how people with not a college degree and I am going to sample, you know, let's say 500 individuals from that particular category.

500
01:02:14,960 --> 01:02:20,120
And I'll go to a matter their blood pressure. Blood pressure.

501
01:02:21,650 --> 01:02:26,180
I'm going about their their blood pressure. And then I'm going to focus on the other category.

502
01:02:26,180 --> 01:02:29,120
Let me go with some college degree or higher,

503
01:02:29,510 --> 01:02:35,330
and then I'm going to sample another or let's say some 100 individuals and I'm going to matter their blood pressure.

504
01:02:35,780 --> 01:02:40,330
So in this case, the X has only two fixed values, right?

505
01:02:40,430 --> 01:02:50,090
That's either is without a college degree or with some college degree and a four for either group of individuals and their x value is fixed,

506
01:02:50,820 --> 01:02:55,490
there is no random at all. So this is what we call a fixed design.

507
01:02:55,490 --> 01:03:05,150
So the x i's are treated, treated as fixed conflicts and then we sample Y, you know, within each level of X.

508
01:03:05,660 --> 01:03:10,670
So this is the so-called fixed design from a experimental design perspective.

509
01:03:12,510 --> 01:03:16,120
But but nowadays, when people take samples, I mean,

510
01:03:16,130 --> 01:03:21,350
oftentimes people do not follow such a design or we will just directly take a sample from the population,

511
01:03:21,830 --> 01:03:24,529
and then we will look at a thousand individuals, for example,

512
01:03:24,530 --> 01:03:29,950
and then we will look at what are their blood pressure is, what are their education level is, right?

513
01:03:30,020 --> 01:03:39,390
So the allocation level is not. So we do not take a sample within people who without a college degree and a within people who have some color degree.

514
01:03:39,980 --> 01:03:48,920
So so in the second case, if we directly take a thousand individuals in the matter, there was an X in that case,

515
01:03:48,920 --> 01:03:54,500
X can be treated as as random as well because we do not know that that's it beforehand.

516
01:03:55,910 --> 01:04:00,529
But here in this course we will follow the fixed design proceeding.

517
01:04:00,530 --> 01:04:04,310
So the x rays, they are treated as fixed.

518
01:04:05,480 --> 01:04:11,120
It really doesn't matter too much. All our, you know, all the subsequent topics.

519
01:04:11,420 --> 01:04:15,070
Well, although there is some difference. But, but let's not worry about.

520
01:04:15,590 --> 01:04:22,040
So in reality, this exercise may be random, especially when x, r is continuous.

521
01:04:22,490 --> 01:04:31,880
So for example, let's say let's say instead of allocation, let's say while in this case, let's say we study the.

522
01:04:35,920 --> 01:04:42,070
They found her body weight on black thought passion and what it weighs matter as a continuous variable.

523
01:04:42,640 --> 01:04:47,200
So in this case, it's hard to think of this body weight as a fixed value.

524
01:04:47,560 --> 01:04:56,330
So. So it's more natural to begin to assemble from this collision and then matter of people's blood pressure and body weight along the way.

525
01:04:56,330 --> 01:05:01,920
You can actually the various types of weight when we measure body weight, I mean, naturally, there is there is some method of error.

526
01:05:02,040 --> 01:05:09,670
So the scale yields, I mean, it's very it's not probably kind of calibrated or I mean,

527
01:05:09,960 --> 01:05:12,850
but for the same person, the body weight as of [INAUDIBLE] of it.

528
01:05:13,120 --> 01:05:19,130
So whether you whether it is matter before a meal or after a meal or whether it's a matter

529
01:05:19,150 --> 01:05:24,600
before exercise or after exercise or no matter in the morning or in the late evening.

530
01:05:24,610 --> 01:05:31,240
So the body weight also changes throughout the day. So there is some randomness in the body weight.

531
01:05:32,080 --> 01:05:37,450
So in this case, it's hard to say that this exercise, they are fixed values.

532
01:05:38,650 --> 01:05:49,660
But anyway, so all in this course and we will again, we will take the perspective that this exercise, there are six constants.

533
01:05:49,660 --> 01:05:53,440
So we do not worry about the run of this index.

534
01:05:53,860 --> 01:05:58,510
So what have we learned? What what we studied is the relevant is in white.

535
01:05:58,540 --> 01:06:06,700
So once we are given x values. So once we are given the average level or once we are given the body weights.

536
01:06:06,970 --> 01:06:17,530
So that means the X is fixed. And then we look at the relevant is in the Y in the response that's done so that if we take this course attributes

537
01:06:17,710 --> 01:06:23,290
also the collisional personality for the rationale look at the development of linear regression model.

538
01:06:23,300 --> 01:06:32,350
You see that indeed the linear regression model was developed under such a perspective,

539
01:06:33,280 --> 01:06:38,680
but it is just later that you know, it realized that we really don't remember.

540
01:06:40,330 --> 01:06:45,220
Well, f can be treated as rhythm as well and also sometimes X has to be treated as random.

541
01:06:45,580 --> 01:06:51,820
But again, that's not a worry for that. Let's just consider X to be fixed factors in this course.

542
01:06:52,780 --> 01:06:57,530
Fixed values. Okay.

543
01:06:58,850 --> 01:07:07,730
So the. So for the model, I mean, the model components, we this is actually the one assumption we make.

544
01:07:07,910 --> 01:07:12,980
We assume that the Y depends on X in such a linear fashion.

545
01:07:14,180 --> 01:07:18,470
I mean, here I'm loosely speaking because here, of course, you can make a transformation of X.

546
01:07:19,220 --> 01:07:26,930
So solidarity again is in terms of this parameter beta, but linear regression model, specify the model like this.

547
01:07:27,050 --> 01:07:38,960
So there is V a relationship between between Y and and the status and then the error term is actually equal to one minus than the mean.

548
01:07:41,980 --> 01:07:49,060
So in order to determine this, our goal is absolutely to determine this line, to determine the association between one and two acts.

549
01:07:49,270 --> 01:07:58,010
That is to determine the rate of 001. So a line is has been determined by two numbers, right by intercept and slope.

550
01:07:58,850 --> 01:08:01,729
So, you know, we're a speed of zero, you know, one using our vision.

551
01:08:01,730 --> 01:08:09,590
And these are the qualities that we are trying to estimate and also tool to make inference later.

552
01:08:11,130 --> 01:08:14,600
All. So the.

553
01:08:15,720 --> 01:08:25,170
If we want to make a plunge, let's say this is not the line that the beta zero plus beta beta zero plus beta one x.

554
01:08:25,200 --> 01:08:33,680
This is love. We are interesting and we are trying to estimate the beta zero animator one and here this is represents Brazil.

555
01:08:34,170 --> 01:08:41,990
That's the intercept. And another big one is actually, you know, calculating the slope.

556
01:08:43,990 --> 01:08:47,090
So this is, let's say, the change in X.

557
01:08:48,200 --> 01:09:00,150
This is the change. In a separation of why rather than a small can be calculated by as a racial between this to and the racial

558
01:09:01,900 --> 01:09:11,810
the in the in the expansion of y divided by the change in x that if you sustain the slope of this result,

559
01:09:11,900 --> 01:09:23,340
in other words, the beta one, the slope is actually the explanation of why at one particular value of acts and another particular

560
01:09:23,340 --> 01:09:32,340
value of X and then divided by the change in X that that is one of the slope represents.

561
01:09:36,210 --> 01:09:42,350
That is assuming that the change in the mean of one per unit of change for one year,

562
01:09:42,360 --> 01:09:51,840
an increase in X and a beta zero and beta zero is actually that that it is that when X is equal to zero.

563
01:09:52,230 --> 01:09:57,280
So that is the mean Y would mean yes.

564
01:09:57,410 --> 01:10:03,240
So if Y is weight and axes h that needs to be weighed for individual H equal to zero.

565
01:10:03,660 --> 01:10:07,860
This may or may not make sense. Later, we're going to talk about the interpretation of beta zero.

566
01:10:08,220 --> 01:10:19,710
So when x acts equal to zero may or may not be meaningful in the meaningful scenario, but I'm going to for now, a while.

567
01:10:19,800 --> 01:10:24,900
But not even the beta zero is the expected one when x is equal to zero.

568
01:10:32,470 --> 01:10:36,160
Okay. So now this is a more concrete example.

569
01:10:36,280 --> 01:10:42,490
Suppose we have two subjects that differ by one unit in x.

570
01:10:43,120 --> 01:10:47,500
So let's say X is h axes h measured in years.

571
01:10:47,520 --> 01:10:54,220
Let's see. And then if we look at the two, two, two people.

572
01:10:54,310 --> 01:11:02,950
Well, and they differ in age by way unit by one year, let's say one has one is seven years old, another one is six years old.

573
01:11:03,340 --> 01:11:06,830
And then we look out of there. What about the exciting the one.

574
01:11:07,810 --> 01:11:12,460
And for seven years old is equal to this and a four, six years old is equal to less.

575
01:11:13,790 --> 01:11:22,190
And another difference if we if we look at the difference of this two, that's, of course, gives us a better one.

576
01:11:22,610 --> 01:11:25,720
And that's the mean that's an interpretation being a one.

577
01:11:25,730 --> 01:11:41,780
So that is the change in the meaning of Y for y, you're the change in X and the linearity assumption actually means that,

578
01:11:42,050 --> 01:11:49,910
well, you could actually look out changed from 6 to 7 or you could look at a change from from from 9 to 10.

579
01:11:50,480 --> 01:11:55,310
So if x one equal to ten x two equal to nine, a change of y unit,

580
01:11:55,370 --> 01:12:00,410
you will get exactly the same interpretation of beta one if you look at the difference.

581
01:12:00,920 --> 01:12:06,409
So in other words, a minority assumption means that this change is actually constant.

582
01:12:06,410 --> 01:12:15,590
So for every unit shaded next, the mean difference is constant is always this beta was gonna matter, which started looking at.

583
01:12:16,160 --> 01:12:21,060
So as long as the change is the same, you have the same change in me.

584
01:12:21,670 --> 01:12:27,860
And that's just based on the modal structure, based on the model assumed.

585
01:12:32,670 --> 01:12:50,070
Okay. Any questions? Sorry. Well.

586
01:12:53,710 --> 01:13:01,990
Okay. So another thing that we need to pay attention to is that the radical visions, the beta zero, beta one, they are skill dependent.

587
01:13:02,260 --> 01:13:06,160
So they depends on how X is measured.

588
01:13:08,170 --> 01:13:11,979
Say why are equal to zero must be greater.

589
01:13:11,980 --> 01:13:16,690
One must absolutely. And so let's say X is h.

590
01:13:18,820 --> 01:13:24,740
A four page word. Let's say X is is is is is weight.

591
01:13:26,640 --> 01:13:34,040
Excuse which one is patronizing and the interpretation of beta zero and beta one.

592
01:13:34,100 --> 01:13:41,729
Also like the absolute value, the magnitude depends on how it's on how well his matter will matter.

593
01:13:41,730 --> 01:13:46,020
Weighed in pound and will matter weight in cure rats.

594
01:13:46,380 --> 01:13:51,220
You will definitely get a different. As deeper matters for Beowulf.

595
01:13:52,250 --> 01:14:06,330
So if if if you divide a page by if you divide away by ten, then the better one should be multiplied by ten, corresponding to the same the question.

596
01:14:07,550 --> 01:14:11,690
So in other words, a zero beta one. We are not skill invalid.

597
01:14:12,800 --> 01:14:20,250
So they depends on the interpretation. Depends on what a unit you use, no matter is x interval.

598
01:14:23,380 --> 01:14:29,340
And a bigger one. They categorize the association between one.

599
01:14:29,350 --> 01:14:34,770
That's the strength of the association. So it reflects the magnitude of the association.

600
01:14:37,600 --> 01:14:46,479
So from this perspective then our interest is mainly in beta one because beta one market

601
01:14:46,480 --> 01:14:52,120
quantifies the strength of association in quantifies the how wide it has on acts.

602
01:14:52,630 --> 01:15:04,180
How how how does the change in X effects then a change in Y and this is most most of the time this is the sign of a question of interest.

603
01:15:04,720 --> 01:15:09,850
So we are more interested in beta one than beta zero, generally speaking.

604
01:15:11,920 --> 01:15:22,090
Again because speed of light qualifies the effect of x, y or z association due to y index of all the other head.

605
01:15:22,180 --> 01:15:26,830
Although I am a beta zero, generally speaking is not as important as beta one,

606
01:15:27,100 --> 01:15:31,060
but still we will need to have a meaningful interpretation of principle.

607
01:15:31,180 --> 01:15:36,610
So we will have to interpret both beta zero and a beta one because the R model.

608
01:15:41,950 --> 01:15:45,310
Now let's take a look at the one example.

609
01:15:45,610 --> 01:15:48,940
To interpret the below zero beta one.

610
01:15:49,660 --> 01:15:52,670
So let's say y one is the CEO.

611
01:15:52,840 --> 01:16:04,480
Lastly, the response is serum cholesterol and is measured in MGP alum mg per deciliter.

612
01:16:05,830 --> 01:16:15,430
So this is how y standard. Yes. Is this is how like a blood pressure and this matter is unit and that cheese or.

613
01:16:15,430 --> 01:16:30,120
Mm. Liquor. And so and we assume this linear regression model, we assume that the serum cholesterol depends on systolic blood pressure which you just.

614
01:16:31,160 --> 01:16:35,750
About whether this model significantly whether that's a solid model or not.

615
01:16:36,260 --> 01:16:39,320
Let's for now let's not worry too much about that.

616
01:16:39,590 --> 01:16:46,720
I mean, this this is standard the oversimplified model. But we are using it as a your station of interpretation as well.

617
01:16:47,370 --> 01:16:57,800
So linear regression model, of course, in many scenarios, it's it's too simple, but oftentimes it's a good approximation.

618
01:16:57,960 --> 01:17:03,290
In this case, is is definitely oversimplification of much of the scientific problem.

619
01:17:03,980 --> 01:17:10,860
But we are just using that tool to illustrate to to discuss the interpretation.

620
01:17:10,880 --> 01:17:22,220
So in this case, the beta one represents the mean difference in y y is the zero cholesterol.

621
01:17:22,610 --> 01:17:27,950
The mean difference in what per one unit higher in SBP.

622
01:17:28,380 --> 01:17:34,760
And so if you increase SBP by one unit, if you increase X by one unit.

623
01:17:35,800 --> 01:17:43,030
Then on average, on average, the mean of one will increase by one unit.

624
01:17:43,790 --> 01:17:46,930
And that's how we interpret this. Based on what?

625
01:17:49,310 --> 01:17:55,220
And here one important thing is that this is the change in the meaning of why so.

626
01:18:01,040 --> 01:18:09,620
Because the model this model implies that why given and that's equal to zero because of a one and study.

627
01:18:10,280 --> 01:18:13,700
And so so for one you're increasing X.

628
01:18:13,700 --> 01:18:18,950
We are going to see that in the mean of Y, it's going to increase by 31.

629
01:18:19,580 --> 01:18:26,030
So that's the that's the interpretation of theta one and beta zero.

630
01:18:28,550 --> 01:18:34,170
Below zero that is well x is equal to zero results where x is equal to zero.

631
01:18:34,190 --> 01:18:37,730
Now this term disappears and what is left is below zero.

632
01:18:37,910 --> 01:18:50,300
So that is the interpretation of zero. One zero is the mean is fast y or mean zero control for patients with SBP equal to zero.

633
01:18:50,570 --> 01:18:54,980
That means done x equals zero for the patients with SBP equal to zero.

634
01:18:56,380 --> 01:19:06,230
All but of course I mean what scientifically doesn't make sense right so all to have SBP equal to zero right so so this interpretation of beta zero

635
01:19:06,230 --> 01:19:15,680
that doesn't really make sense and we will see that actually this is not uncommon in linear regression models because a linear regression model,

636
01:19:15,680 --> 01:19:26,299
the beta zero is interpreted. It represents the mean of Y when x is equal to zero, but against but s equal to zero all the time.

637
01:19:26,300 --> 01:19:30,440
She really doesn't make sense from your point of view.

638
01:19:30,950 --> 01:19:41,090
So just like in this example. So in this case, the beta zero, the interpretation scientifically doesn't make too much sense.

639
01:19:43,480 --> 01:19:47,289
But we do have ways to deal with that little problem.

640
01:19:47,290 --> 01:19:54,160
Talk about ways to know to avoid to avoid a central problem.

641
01:19:55,180 --> 01:20:08,120
Now let's take a look at another example. This is the study of forgotten males aged between 20 to 39.

642
01:20:08,510 --> 01:20:12,260
So let's say we want to study how their body weighs.

643
01:20:12,410 --> 01:20:18,680
Depends on their age, right? Yeah. Let's say we focus on such a linear regression model.

644
01:20:20,060 --> 01:20:25,460
And in this case, while beta one, again, beta one is the mean change in y.

645
01:20:25,860 --> 01:20:37,640
Now why is bodyweight so a matter of kg missing an event mentioned in weight per one unit change for one you increase in x.

646
01:20:39,030 --> 01:20:46,110
An ax is measured in years. So per one unit increase in accidental deaths per one year increase in age.

647
01:20:47,300 --> 01:20:56,940
But that's the interpretation of beta one. At zero that is here again the never been a zero.

648
01:20:57,210 --> 01:21:06,150
That is at the X are equal to zero because only one x equals zero now that there's this term disappear.

649
01:21:06,150 --> 01:21:16,920
So then the interpretation of beta zero is actually the the mean body wage and the mean of y.

650
01:21:18,220 --> 01:21:24,810
When? Age is equal to zero, right?

651
01:21:26,110 --> 01:21:29,740
So what age is equal to zero while this saying. Well, in this case.

652
01:21:30,820 --> 01:21:35,990
Well, I guess is probably near some sense like an hour before newborns.

653
01:21:36,010 --> 01:21:42,440
Right. So a newborn baby is probably given the zero then the mean wait for even that.

654
01:21:42,460 --> 01:21:45,700
I mean, is this still a little bit strange? Because here we are.

655
01:21:45,940 --> 01:21:50,680
The studies focus on people with age 25 to 39.

656
01:21:50,770 --> 01:21:53,170
Right. Well, we interpret it as being a zero.

657
01:21:53,470 --> 01:22:03,280
Now we are not we have to interpret that when it is equal to zero, which is actually quite different from the age range we are looking at.

658
01:22:03,640 --> 01:22:12,640
So again, in this case, the interpretation of this data zero, although I mean scientifically it seems to make sense to talk about age zero.

659
01:22:13,120 --> 01:22:16,930
However, is still quite strange for this particular statement.

660
01:22:18,370 --> 01:22:27,040
So I the stats that I'm supposed to extrapolate outside of your your range of X, is that what we're doing here?

661
01:22:27,250 --> 01:22:32,880
Yeah, that's a great point. And we are going to actually talk about that in the next slide of extrapolation.

662
01:22:33,210 --> 01:22:39,340
And that's that's a great point. That's actually the reason behind this strange interpretation.

663
01:22:42,490 --> 01:22:49,799
Any other questions? Okay.

664
01:22:49,800 --> 01:22:55,020
So these are the interpretations of data zero and data one in this particular example.

665
01:22:55,050 --> 01:22:57,930
Oh, now we are moving to explanation. Okay.

666
01:22:58,400 --> 01:23:11,010
So but if you look at this example here, what we are doing is that we are interpreting at a particular age value.

667
01:23:12,240 --> 01:23:20,130
That is when outside, you know, the age range of X range and that is a moment for our cognitive data.

668
01:23:20,400 --> 01:23:26,010
So we've got a data for people aged between 20 and 39, but we are interpreting age in zero.

669
01:23:26,370 --> 01:23:32,130
This is the so called extrapolation in regression models.

670
01:23:34,290 --> 01:23:37,320
So here is a graphical illustration.

671
01:23:38,250 --> 01:23:49,890
So let's say that now here this this is the range, but range that in our observed data and in this observed data,

672
01:23:49,950 --> 01:23:56,160
while you can see that the linear regression model described the data pretty well and there's there

673
01:23:56,160 --> 01:24:02,250
is a clear increasing trend as probably again can be well-described by linear regression model.

674
01:24:02,640 --> 01:24:09,840
However, there may be another range that has some disparity, does not hold anymore.

675
01:24:10,590 --> 01:24:14,040
And over time, you know what is quite a natural maturation.

676
01:24:14,310 --> 01:24:23,910
But if you imagine as to the age and gender and why we thought it weight as low as as you

677
01:24:24,480 --> 01:24:32,010
got from you know from from from young kids to announce that the body weight is increasing,

678
01:24:32,010 --> 01:24:37,950
the speed of age probably going to always decrease. However, if we only got data from this range,

679
01:24:39,330 --> 01:24:47,699
then we will never actually see this trend over here and that it becomes dangerous to actually to interpret,

680
01:24:47,700 --> 01:24:56,280
like based on this observation here, to try to interpret what would happen here, because we had no observation from that age range.

681
01:24:57,330 --> 01:25:02,890
So this is the so-called extrapolation, and this is actually exactly what we did here.

682
01:25:02,910 --> 01:25:09,660
So our data. Only adult males aged between 20 and 39.

683
01:25:10,320 --> 01:25:21,810
However, what we interpret below zero, we as we interpret on average people zero, which is way outside our end stage as our X range.

684
01:25:23,550 --> 01:25:26,790
So this is not a good practice.

685
01:25:32,470 --> 01:25:37,960
So in other words, well, in practice we should try to avoid extrapolation.

686
01:25:38,590 --> 01:25:42,850
What if we are observed data? If the x range is between this,

687
01:25:43,720 --> 01:25:52,810
then what we try to make statements were either make probation or make other statements about what they had about the individuals with x values.

688
01:25:52,990 --> 01:25:57,279
That is way outside this range. Now, we should we should be very,

689
01:25:57,280 --> 01:26:07,150
very we do not really have information to make any prediction in the region outside the typical X values that we see.

690
01:26:11,060 --> 01:26:14,600
So this is not a saying that we cannot make a prediction.

691
01:26:14,790 --> 01:26:18,070
So but it's just that we have to be very, very careful.

692
01:26:18,080 --> 01:26:23,420
So, for example, in another example, let's say we just observe data points from here.

693
01:26:24,740 --> 01:26:30,020
And then if we have an individual coming from here making a prediction,

694
01:26:30,020 --> 01:26:35,930
what seems to be actually we seem to be able to make quite a reasonable prediction as so because

695
01:26:36,230 --> 01:26:40,910
the trend actually does not change from from this particular region through this region.

696
01:26:41,360 --> 01:26:46,429
However, the trend has to change when we move to a different region.

697
01:26:46,430 --> 01:27:00,130
So this is this is why we have to be very careful when we try to make predictions and outside the range of them.

698
01:27:00,230 --> 01:27:10,910
Well, as we mentioned, so the interpretation of beta zero, that is actually while we interpreted the one X at X equals zero.

699
01:27:11,210 --> 01:27:19,250
And this may or may not make sense. And oftentimes it doesn't make sense in general for almost a liberal point of view.

700
01:27:19,700 --> 01:27:26,750
So do we have a way of actually revenue? We have a way of avoiding this to avoid this.

701
01:27:26,990 --> 01:27:38,270
The answer is definitely yes. So we can take on the next maybe the following very simple procedure to to avoid in this strange patient zero.

702
01:27:39,080 --> 01:27:45,280
So the way is to simply send your. Nicole got rid of them in the accident.

703
01:27:46,960 --> 01:27:52,660
So if we. Well, as far as the sample, every drug excise X is age.

704
01:27:52,780 --> 01:27:56,350
That X bar is simply the average age in the dataset.

705
01:27:57,280 --> 01:28:00,940
And then we simply redefine the covered manner.

706
01:28:02,500 --> 01:28:07,120
We really view it as X minus the sample average.

707
01:28:08,110 --> 01:28:11,289
Okay. So in other words, we are we are we are shifting.

708
01:28:11,290 --> 01:28:16,960
We are we are seen during the coverage at the average at an average age.

709
01:28:17,890 --> 01:28:21,430
So after the redefining this exercise start,

710
01:28:22,420 --> 01:28:29,559
then if we just forget about let's say let's let's pretend that if we didn't even know the existence of this X,

711
01:28:29,560 --> 01:28:33,930
Y, we were just given us a we were just given this x y star in our dataset.

712
01:28:34,330 --> 01:28:40,360
So you can't beat us out if we only see this Y and Z sort of.

713
01:28:40,570 --> 01:28:50,080
And then of course we could have such a model. So Y given excite starts and let's see what happens in this case.

714
01:28:51,760 --> 01:28:56,950
So this is equal to beta zero star plus beta one star.

715
01:28:59,320 --> 01:29:05,740
I'm exercise x y star is equal to x on minus x bar and then plus m supply.

716
01:29:06,040 --> 01:29:11,560
So. Right.

717
01:29:11,620 --> 01:29:26,970
And then. I can combine this two terms.

718
01:29:34,570 --> 01:29:41,870
I did my best two terms. So if we compare I mean, this is linear regression model.

719
01:29:42,000 --> 01:29:48,980
I mean, this this is. If I compare this to the original to the original linear regression model,

720
01:29:50,570 --> 01:29:55,700
then for this two linear regression model to be the same, then the radical version must be the same.

721
01:29:56,330 --> 01:30:02,750
And so the other words, and this guy must be equal to beta zero and this guy must be equal to beta one.

722
01:30:05,850 --> 01:30:10,650
And also this guy in our air attorneys is just an absolute I.

723
01:30:14,370 --> 01:30:21,340
So in other words. Not a beta star zero.

724
01:30:21,490 --> 01:30:29,319
The new interceptor is absolutely equal to the called intercept has been a

725
01:30:29,320 --> 01:30:40,890
lot of start and spot and the new slope is just equal to afford slope slope.

726
01:30:41,300 --> 01:30:47,410
So this change of variable from x to exercise star doesn't really change the slope at all.

727
01:30:47,470 --> 01:30:52,700
The slope will be the same. So then of course this is equal to.

728
01:30:55,510 --> 01:31:01,700
It was this. Now this is the relationship between these two models.

729
01:31:01,760 --> 01:31:11,210
After I made this change, the variable, after essentially the cold areas so central to the covariance will not change.

730
01:31:12,420 --> 01:31:19,950
But on the slope at home. So it will keep the same salt, but it will change the intercept.

731
01:31:21,210 --> 01:31:30,810
Which is the intercept so graphically. Well this is we going to look the illustrate it immediately so.

732
01:31:35,450 --> 01:31:40,340
This is agency. This is blood pressure poisoning.

733
01:31:41,030 --> 01:31:52,310
And let's say here we have this is the line we are now describing, the association between black Asian age.

734
01:31:52,790 --> 01:31:56,640
And so our data actually occurs here.

735
01:31:56,660 --> 01:32:00,140
So this is, let's say, 29 to 1. This is 20 to 39.

736
01:32:07,120 --> 01:32:10,510
32, 22, 39.

737
01:32:12,730 --> 01:32:17,050
So we look for record data within this range.

738
01:32:19,120 --> 01:32:22,250
And again, this is beyond zero. This is the intercept.

739
01:32:22,500 --> 01:32:33,650
That is when H is equal to zero. And this is the average age redness in the middle.

740
01:32:33,660 --> 01:32:38,690
This is X bar. This is the average age. Let's say.

741
01:32:38,770 --> 01:32:42,539
Well, let's try to make this a little bit more concrete.

742
01:32:42,540 --> 01:32:47,430
Let's say average age and make you have a number. I say average age is equal to 30.

743
01:32:48,050 --> 01:32:55,860
I'm making this up and making this transformation.

744
01:33:02,350 --> 01:33:05,870
So this is age and this is a the start, right?

745
01:33:05,890 --> 01:33:15,640
This is exercise start. So after making this transformation, that means we actually subtract the mean age from each individual's age.

746
01:33:16,510 --> 01:33:22,449
Then here we have zero. And here we have negative while starting from negative ten.

747
01:33:22,450 --> 01:33:28,360
Right. 21 to 30, plus negative ten, and then 39 -39.

748
01:33:29,200 --> 01:33:34,270
So then. We are actually looking.

749
01:33:36,930 --> 01:33:42,810
Along the same line, but we are actually shifting the Y axis to the right.

750
01:33:47,400 --> 01:33:59,190
That's what I mean by the effect of making this transformation or thinking this y, even x, x, y star does that.

751
01:33:59,520 --> 01:34:10,919
So we're shifting the y axis, you know, a little bit, but not to the center of the range, not to X far, far.

752
01:34:10,920 --> 01:34:19,890
So that here, you know, the way the star starts from there is between negative ten and nine.

753
01:34:24,570 --> 01:34:28,470
I'm sorry. This is still the same line.

754
01:34:28,950 --> 01:34:34,570
Still the same line. It's. Is still the same.

755
01:34:34,930 --> 01:34:39,070
So this now, this intercept here now is beta zero.

756
01:34:39,500 --> 01:34:43,920
Star, this is the new intercept. This is part of zero star.

757
01:34:44,690 --> 01:34:50,249
This has been a new star. No.

758
01:34:50,250 --> 01:35:01,170
The interpretation below zero star is well is the mean blood pressure value one and the star is equal to zero.

759
01:35:03,690 --> 01:35:08,250
That is what age is at 30?

760
01:35:09,030 --> 01:35:12,450
Well, age is actually the single average age is at 30.

761
01:35:13,170 --> 01:35:22,470
And this actually now make lots of sense because we didn't want to talk about people with age at 30, which is the sample average within our sample.

762
01:35:23,580 --> 01:35:29,700
And then this this interpretation of beta zero star in this model.

763
01:35:31,250 --> 01:35:40,310
If you look at this model here, this interpretation of this bit of zero star, that is 1xy star equal to 04x are x i star zero.

764
01:35:40,340 --> 01:35:48,560
That to me is the original age that is at the center of the of the symbol that is the symbol average that is 30 years old.

765
01:35:50,480 --> 01:35:58,490
So the other is beta zero star. That is the mean SBP mean blood pressure for people at 30 years old.

766
01:36:00,960 --> 01:36:03,390
Now this makes a lot of sense.

767
01:36:03,960 --> 01:36:11,070
So this is a very quick waste addressing the problem that, you know, the interpretation ignores and does not make sense.

768
01:36:11,400 --> 01:36:15,840
We simply send her the covariate center.

769
01:36:15,840 --> 01:36:25,020
The covariate at the center of the covariate represents a shift in a shift of the wife of the Y axis.

770
01:36:25,530 --> 01:36:38,160
So we are shifting the y axis to the location to location where X is equal to its central average and then the corresponding intercept.

771
01:36:38,510 --> 01:36:43,230
So makes sense. It goes chained to a slope is still exactly the same line.

772
01:36:43,920 --> 01:36:47,820
So this like this one over here in narrative, we never change this line.

773
01:36:48,330 --> 01:36:52,740
What we did, it was simply shooting this y axis to the right.

774
01:36:52,890 --> 01:36:57,330
Now to that, we look to the middle of H range.

775
01:37:05,040 --> 01:37:08,420
Any questions about this symbol of transformation?

776
01:37:09,260 --> 01:37:13,070
Yes. When we do this, we need to worry about it.

777
01:37:13,190 --> 01:37:21,110
We actually have a sample where the atoms are uniformly distributed across the range.

778
01:37:22,640 --> 01:37:27,090
Well, no, we do not need to worry too much about that.

779
01:37:27,690 --> 01:37:36,830
So whether X is uniformly distributed or normally distributed or other, a lot of it, it doesn't matter much.

780
01:37:37,190 --> 01:37:41,360
What we did here was we just look at where the central X is.

781
01:37:41,930 --> 01:37:50,729
And because that's a part of that, that's that's a kind of that we can we can we can mathematically we can shift the y axis to anywhere.

782
01:37:50,730 --> 01:37:54,530
Right. If you imagine this this this plot of here, this plot here.

783
01:37:55,580 --> 01:38:00,320
So mathematically, we're going to shift this y axis to anywhere without changing this line.

784
01:38:00,680 --> 01:38:04,490
So mathematically, it doesn't change the association between y x at all.

785
01:38:04,700 --> 01:38:05,660
It doesn't change the slope.

786
01:38:06,350 --> 01:38:17,370
But it now what we are doing is we are just shifting the y axis to a place where it makes sense when we talk about x equals zero.

787
01:38:18,050 --> 01:38:22,550
So guess what? It doesn't depend on that is usually it is distributed to somewhere.

788
01:38:23,060 --> 01:38:31,610
But like if we have samples on one side of the mean and then on the other side of the mean for the X values that we're going to see in the middle,

789
01:38:31,610 --> 01:38:43,370
where within the line. Oh, and it's a no that that's, that's totally fine because I mean because if you think about let's consider a stream case.

790
01:38:44,060 --> 01:38:52,550
We built the data so we never expected for a continuous x but data will never contain the sample average.

791
01:38:53,000 --> 01:39:01,880
But let's say we we sample let's take an H this as a example we sample people from age between 20 and 30.

792
01:39:02,250 --> 01:39:10,670
But let's say that in our dataset, if we never got an individual with 8 to 30, there's no individual with a 30 in our data set.

793
01:39:11,270 --> 01:39:15,980
But now we are actually shifting this y axis to age 30, which is totally fine.

794
01:39:16,760 --> 01:39:21,780
And so because because while you 25 continuous run variables, there's,

795
01:39:22,070 --> 01:39:30,630
there's almost zero probability of having an exact battle of like having an individual with an exact value as the same amount.

796
01:39:31,160 --> 01:39:36,920
That means that if you relax that a little bit of them, then enemies within the neighborhood,

797
01:39:36,920 --> 01:39:42,530
your average age and there's no individual people, which is totally fine.

798
01:39:47,630 --> 01:40:03,620
Okay. Any other questions? Okay.

799
01:40:03,650 --> 01:40:16,500
So then, okay, so with this centering of the, of the verb, now we can interpret the beta zero in a more meaningful way.

800
01:40:16,520 --> 01:40:23,660
So in the original model, we call that in the reason model where we have age, we have to interpret the speed of zero.

801
01:40:24,830 --> 01:40:31,360
Now age equal to zero improves it so that while this one does not really I mean,

802
01:40:31,640 --> 01:40:40,640
it's kind of strange interpreting and using however with our revised model nothing depends on this beta one star sorry the

803
01:40:40,640 --> 01:40:54,560
beta zero star that is at its highest star equal to zero for x a star is equal to x are a star is equal to x by minus x bar,

804
01:40:54,590 --> 01:41:02,749
right? So that means that is the value. What gets by is equal to export and this makes sense.

805
01:41:02,750 --> 01:41:06,770
So now the interpretation of beta zero star that is the mean wage.

806
01:41:06,950 --> 01:41:14,600
The mean response for individuals was h is at an average who has an average h.

807
01:41:16,850 --> 01:41:25,130
So this avoids some difficulties and some strange interpretations of that intercept.

808
01:41:29,870 --> 01:41:34,529
Okay. I think we are. Almost at time.

809
01:41:34,530 --> 01:41:38,940
So any questions? I think we ought to start maybe just some hearings in the next month.

810
01:41:39,180 --> 01:41:51,740
But any questions before we feel good about all the homework and homework zero will be posting around to you.

811
01:41:51,810 --> 01:41:56,760
All of that is due next Tuesday. On Tuesday.

812
01:41:59,320 --> 01:42:05,400
We got him. Obviously a long trying. I'm.

