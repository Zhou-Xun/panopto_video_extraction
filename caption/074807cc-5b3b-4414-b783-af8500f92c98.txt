1
00:00:06,720 --> 00:00:12,750
Yeah. Although it, it does show the screen, but I'm not sure. Yeah.

2
00:00:12,750 --> 00:00:17,130
Let's try it out this time, just like this and see how it goes.

3
00:00:17,460 --> 00:00:22,160
If done work, well, then I'll see if I can use that to record.

4
00:00:22,170 --> 00:00:25,620
But anyway, let's listen to the track. Okay.

5
00:00:25,860 --> 00:00:33,760
So. If you recall what we are doing.

6
00:00:34,660 --> 00:00:44,080
Well, again, please forgive my handwriting especially very heavily is not going to read well, but hopefully it doesn't diminish.

7
00:00:45,760 --> 00:00:55,180
Hopefully it's not too bad. So we are actually looking at a so called M that's defined as.

8
00:00:56,520 --> 00:01:00,020
Maximizing. Objective function.

9
00:01:00,520 --> 00:01:03,890
Q In theta. Q Actually depends on all the data.

10
00:01:04,640 --> 00:01:09,560
On the travel data. We construct this. Q Impact theta and we maximized this.

11
00:01:09,560 --> 00:01:18,920
That's the theta had it in and theta zero, which is kind of the true value, is actually.

12
00:01:21,160 --> 00:01:27,200
The Maximizer of the so-called Q zero theta and this Q there Q zero theta.

13
00:01:27,220 --> 00:01:31,450
You can think of this. Q zero. Say that theta as the limit.

14
00:01:34,680 --> 00:01:47,549
As in goes to infinity q in action thena and or if you want to emphasize is the probable limit, then probably limit when you can pull the pin in.

15
00:01:47,550 --> 00:01:56,520
The problem is simply the nose is the problem that Erskine Bowles infinity and then our goal is actually or what we did.

16
00:02:01,070 --> 00:02:08,470
We showed that theta had converted probably to theta zero, as in ghostwritten.

17
00:02:09,320 --> 00:02:13,790
That's what we did last time. And of course, this is subject to conditions.

18
00:02:14,240 --> 00:02:17,660
And one of the ones we wrote on that on that going over there.

19
00:02:18,140 --> 00:02:22,130
So those four conditions, they are very, very important.

20
00:02:22,190 --> 00:02:27,860
The reason that that I chose to write on that one, I hope that we can keep it at that point for a while.

21
00:02:28,910 --> 00:02:31,910
So if you recall the few, you know, the four conditions.

22
00:02:32,420 --> 00:02:37,070
The first condition is identification, probability of the parameter theta zero.

23
00:02:37,500 --> 00:02:42,440
Well, of course, the zero has to be identified in order for us to estimate.

24
00:02:43,430 --> 00:02:47,270
The second one is the parameter space needs to be compact.

25
00:02:48,140 --> 00:02:54,480
Right. And the third one is that this Q zero theta needs to be continuous.

26
00:02:54,770 --> 00:03:02,480
And this is a very weak requirement, actually. So it doesn't even require no part of the assembled finite sample.

27
00:03:02,750 --> 00:03:05,750
This of the advantage to be continuous but a unit. Of course,

28
00:03:05,750 --> 00:03:10,879
the functions that we consider the continuous bottom of the theory to solve is very

29
00:03:10,880 --> 00:03:16,460
general in the sense that it only requires this q zero theta to be continuous.

30
00:03:17,060 --> 00:03:24,080
This is there we see this is a very weak condition because the Q zero theta is actually the limit of.

31
00:03:24,110 --> 00:03:27,380
Q Yeah, patch theta.

32
00:03:28,010 --> 00:03:35,840
And by taking a limited URI to smooth things out, the more information you collect, the more smooth the smoother becomes.

33
00:03:36,200 --> 00:03:39,530
So it only requires the Q in Syracuse zero.

34
00:03:40,280 --> 00:03:45,410
So we can do this. And this is a very neat computer. So we do cover a lot of cases.

35
00:03:47,000 --> 00:03:53,180
For example, in this course, we are not going to talk about it at all.

36
00:03:53,300 --> 00:03:59,070
And this is not like as widely used in Boston.

37
00:03:59,070 --> 00:04:01,880
It is as, for example, DNA, Joanne.

38
00:04:02,180 --> 00:04:09,790
So but one example is the part so called upon how I'm sure that some of you probably have seen or have heard of the so called, oh, no reaction.

39
00:04:10,550 --> 00:04:13,879
So it's given for me to write a new register model.

40
00:04:13,880 --> 00:04:15,530
That is that is not why given back.

41
00:04:15,530 --> 00:04:24,520
So the mean of X, mean of Y, given x, but vulnerable in the models and the quantile, even quantile like the meaning of the decision.

42
00:04:24,560 --> 00:04:27,660
Why Y given X or the first or now one third part?

43
00:04:28,190 --> 00:04:33,320
So what our reason? It turns out that this updated version.

44
00:04:34,080 --> 00:04:38,190
So the finance. I'm okay. Is this a discrete function? It's not a continuous.

45
00:04:38,670 --> 00:04:41,010
However, the limited function,

46
00:04:41,010 --> 00:04:47,250
the limited boundaries is continuous because then the inventory is sort of taking the operation when people are limited.

47
00:04:47,630 --> 00:04:49,620
So taking these matters has become continuous.

48
00:04:50,010 --> 00:04:57,450
So the theorem from 1.1 that we cover can still be applied to show that can help us make major is consistent.

49
00:04:58,230 --> 00:05:00,780
But that's not a we don't need to worry too much about it.

50
00:05:00,780 --> 00:05:06,270
I just the reason I want to talk about this is to point out that this theorem itself is very general.

51
00:05:07,800 --> 00:05:14,830
So the third condition then is the so-called universe, convergence universe.

52
00:05:15,060 --> 00:05:21,720
Like the sheer number this Q in theta convert is to put the Q zero theta uniform.

53
00:05:23,630 --> 00:05:33,160
So that's what we did last time. Um, and now let's take a look at these poor conditions one by one, because we want to have a better, um,

54
00:05:33,410 --> 00:05:41,030
a better idea of what these conditions are and how they are connected to some of the examples that we are familiar with,

55
00:05:41,030 --> 00:05:46,760
like the, for example, the likes of BlackLivesMatter. So we see our one one that was very general.

56
00:05:47,000 --> 00:05:54,850
It is kind of abstract as well. So we want to connect that theorem and also before conditions to some problem,

57
00:05:54,860 --> 00:05:59,510
to some examples that we are familiar with the expansion of a maximum life in the last major.

58
00:05:59,930 --> 00:06:03,290
So now let's try to do that.

59
00:06:03,710 --> 00:06:06,950
So let's first look at the added information pollution.

60
00:06:11,870 --> 00:06:39,560
Right. And here going drive and look at the ammo and we are going to.

61
00:06:41,820 --> 00:06:44,970
Oh. See how.

62
00:06:46,050 --> 00:06:49,510
We? How do we establish an identification even for now?

63
00:06:50,400 --> 00:06:54,900
So for me, you have this example if the following conditions are satisfied.

64
00:06:55,230 --> 00:06:58,560
So if theta zero is identified.

65
00:07:03,240 --> 00:07:04,260
In the sense that.

66
00:07:24,790 --> 00:07:34,910
So first of all, theta zero is identified in a sense that if theta is not equal to zero, then the probability density is a different probably.

67
00:07:35,800 --> 00:07:39,910
And this is very a very natural and basic requirement.

68
00:07:40,360 --> 00:07:44,710
So, for example, if you think of normal distributed normal density, you generated a normal density.

69
00:07:45,790 --> 00:07:50,020
Then of course to normal the solution would differ means there are different normal distribution.

70
00:07:50,840 --> 00:07:55,650
So this is a very natural and reasonable requirement parameter.

71
00:07:56,680 --> 00:08:01,150
It is so thin a zero is identified and a suddenly if.

72
00:08:22,460 --> 00:08:32,200
And certainly if your density function centers advise that if you inhale reliable the density to the absolute value and they look out of reach,

73
00:08:32,210 --> 00:08:36,080
that even extreme is finite for any parameter theta.

74
00:08:37,220 --> 00:08:45,620
And this is also what is a fairly easy to track condition because it only

75
00:08:45,620 --> 00:08:50,230
relies on the probably density you are considering only relying on this theory.

76
00:08:50,810 --> 00:08:56,660
If you are considering normal distribution, dangerous text, you catalog normal density.

77
00:08:56,660 --> 00:09:05,030
These are absolute value, these are innumerable. So if you have exponential, you can keep track of collision particles.

78
00:09:05,030 --> 00:09:08,780
And so this collision is purely.

79
00:09:10,600 --> 00:09:14,620
Analysis and real analysis. There is nothing statistics involved here.

80
00:09:14,620 --> 00:09:20,920
It's simply says that you are so dazzling if you take one absolute value that is illegal.

81
00:09:22,750 --> 00:09:30,410
So even under this tool conditions. Then cue zero theta.

82
00:09:31,620 --> 00:09:35,070
Which in this case is the foundation of luck.

83
00:09:37,820 --> 00:09:42,870
The density. That has a unique maximum.

84
00:09:53,760 --> 00:09:57,070
Of state as you have to.

85
00:09:57,910 --> 00:10:03,250
So this shows that under this two conditions, fairly straightforward conditions.

86
00:10:05,030 --> 00:10:12,800
This cue zero zero, at least for the MCU case, it does have a unique maximum efficacy.

87
00:10:13,460 --> 00:10:20,870
So it shows that an occasional lesion for sale important one more one value case here exclusive for now

88
00:10:20,940 --> 00:10:28,099
you probably already know that is but I want to one up so here we are I mean we didn't make any threes,

89
00:10:28,100 --> 00:10:38,179
but we are assuming that the eyes we are indeed following this distortion right so we crack

90
00:10:38,180 --> 00:10:42,559
data from this disproving the data are generally from this description with true value zero.

91
00:10:42,560 --> 00:10:49,370
We are trying to estimate this true that of thin air zero in this example in a sense that under this

92
00:10:49,370 --> 00:10:57,499
two conditions this Q zero theta indeed has a unique maximal at zero so that there's probably as well.

93
00:10:57,500 --> 00:11:00,740
But we are able to talk about estimate.

94
00:11:03,910 --> 00:11:07,640
So this is the. This is a result.

95
00:11:07,700 --> 00:11:14,750
Okay, so now let's try to prove this from another new case.

96
00:11:16,970 --> 00:11:22,100
The prove is quite straightforward. So this is from Genesis Inequality.

97
00:11:53,800 --> 00:12:05,410
So from Genesis equality now for any non constant random variable not positive variable y that is positive for not only you run the variable one.

98
00:12:06,910 --> 00:12:31,389
Justice and equality assess that. Assassination of the this is because love life is love is a campaign focus of

99
00:12:31,390 --> 00:12:37,990
lives that function so presently essentials instead of a connect function.

100
00:12:37,990 --> 00:12:44,350
The class function applied to these ideas and why it's less than excited to learn about this function.

101
00:12:46,430 --> 00:12:51,490
Okay, here the class function is active like. And this is just.

102
00:12:51,910 --> 00:12:57,490
Now, if we just take why to me this particular run the variable.

103
00:13:08,930 --> 00:13:17,390
Then why'd you find it? By the ratio of this to dozens? Not for any fixed theta is not equal to zero.

104
00:13:19,730 --> 00:13:34,940
And then. Let's look at the difference between Nostradamus.

105
00:13:42,750 --> 00:13:46,200
And now we want to show that the difference is always that,

106
00:13:46,650 --> 00:13:51,430
because what we are trying to show is that 3 to 0 is the unique maximizer of this two zero.

107
00:13:51,510 --> 00:13:54,879
If we are able to show that difference is always positive for anything.

108
00:13:54,880 --> 00:14:01,590
They are not able to do that message in a shower. So so now let's try to argue that this difference is always policy.

109
00:14:05,480 --> 00:14:09,110
And the difference is always positive because.

110
00:14:14,130 --> 00:14:20,440
Recall that aq0 is defined, while q zero in this case is equal to the original log f.

111
00:14:20,820 --> 00:14:25,920
Now, the reason why I mean, here again, I only did that like one detail.

112
00:14:26,400 --> 00:14:30,809
So Q zero is equal to the exaggeration. Of log.

113
00:14:30,810 --> 00:14:34,890
AB The reason is that recall that the employee is defined.

114
00:14:35,220 --> 00:14:39,330
Peter Hatch is. Maybe I just wanted to point.

115
00:14:39,570 --> 00:14:48,080
So the Q in Hatch is defined as the symbol average and block the higher freedom.

116
00:14:51,060 --> 00:14:59,640
That's the Q impact feed a function of the this is the central average of la la la la la la la la la la la la la.

117
00:14:59,850 --> 00:15:10,680
And we maximize during that. That's the and so of course, then the limit of this cue in half theta is if you take the limit of this,

118
00:15:11,100 --> 00:15:16,860
then for any fixator pilot Roche number that to convert is to this cute zero theta.

119
00:15:17,100 --> 00:15:20,560
And that's the reason why this gives you a thing that you study salvation a lot.

120
00:15:20,610 --> 00:15:32,610
Yeah. Here. This is one piece of detail we didn't make explicit, but anyway, so now we are clear that the Q zero theta is the operation of luck.

121
00:15:32,790 --> 00:15:39,130
Yeah. And then we just. Calculate this to value.

122
00:15:40,810 --> 00:15:53,470
It turns out this true value is equal to an active lock, and that's fairly easy to see because y is defined in this way.

123
00:15:54,400 --> 00:16:02,170
And it's very that it's very easy to see that the difference between gives you 0000000 theta is equal to this.

124
00:16:02,740 --> 00:16:14,080
And then if we apply the genesis inequality. Its larger than that.

125
00:16:14,100 --> 00:16:18,910
You block about one. Okay.

126
00:16:19,870 --> 00:16:26,070
And then. Again because why is defined as this.

127
00:16:26,160 --> 00:16:36,540
So now let's that is then these categories was any world any of y times the density of Z and then so is negative log.

128
00:16:37,530 --> 00:16:46,320
Now let's write of the examination as anyone that any world of y while in this case y is actually and z.

129
00:16:50,760 --> 00:16:55,850
The. Theta divided by zero.

130
00:16:55,980 --> 00:16:59,730
That's that's one. Right. And now we want to couple of things that, you know,

131
00:16:59,730 --> 00:17:07,010
why why is this is a functional essentially this function is integral actually under the density of these.

132
00:17:07,020 --> 00:17:10,960
So what is the you know that is generated from this that's.

133
00:17:19,790 --> 00:17:25,179
And that this council with thus. So what?

134
00:17:25,180 --> 00:17:32,380
His lab is just in the world of Abu Zubaydah. But for anything to have these feet on his desk.

135
00:17:32,950 --> 00:17:38,040
So the in Iraq, of course, is equal to. And so, like one that is equal to.

136
00:17:38,860 --> 00:17:48,730
So finally, this is people who. So if you look at what we have done, we have shown that.

137
00:17:48,820 --> 00:17:54,880
Q. Q zero theta zero minus. Q zero theta is always larger than zero.

138
00:17:56,830 --> 00:18:10,900
That's actually the better finish the. So it just shows that, well, if we go back to this example, let's try to see what are the implications.

139
00:18:11,070 --> 00:18:13,600
The reason is that now for me,

140
00:18:13,610 --> 00:18:21,499
which is the case that we are very familiar with and also which is the case that is probably the most widely considered as motoring.

141
00:18:21,500 --> 00:18:32,360
So those things. So for me, the ID is actually implied by this two conditions over here and the beautiful conditions are very straightforward.

142
00:18:32,870 --> 00:18:36,590
So it doesn't involve complicated statistics. So there you go.

143
00:18:37,490 --> 00:18:41,990
So he's just saying that the disease, if 2% are values are different, the disease are different.

144
00:18:43,090 --> 00:18:50,240
This is one requirement. Another one is that of the density function. If you take luck, then the value of that is integral.

145
00:18:50,570 --> 00:19:00,080
So you calculate saturation. So it's fine. So as long as we have this tool conditions, then we have that.

146
00:19:00,080 --> 00:19:04,130
If you zero has that unique, maximize your freedom zero.

147
00:19:04,310 --> 00:19:09,350
So let's let these ID the visual field one one is the host.

148
00:19:11,240 --> 00:19:19,410
So that's the ID condition under the model in case any questions about this example.

149
00:19:25,990 --> 00:19:29,920
Okay. And then let's look at another while.

150
00:19:29,920 --> 00:19:36,940
The second provision of the 1.1 that's the contract is that we we say that we require the parameter space to be compact.

151
00:20:30,160 --> 00:20:31,690
The companies condition.

152
00:20:31,840 --> 00:20:44,710
This is some condition that lots of people do not like, but lots of people actually make this assumption when trying to establish direct results.

153
00:20:45,160 --> 00:20:52,660
The reason that people do not many who do not like this commission is that combined is well under your dream space,

154
00:20:52,990 --> 00:21:03,820
which is that the people that this is that we will most worry about the winners face it it means that their space is closed, is bondage.

155
00:21:05,050 --> 00:21:10,330
So that means, well, if you think of it in terms of three dimensional space and actually having an immediate state,

156
00:21:10,330 --> 00:21:17,740
that means there is a maybe a big, very big bulk or sphere that spans your country.

157
00:21:18,040 --> 00:21:23,380
So that means that it requires there be more that's.

158
00:21:25,080 --> 00:21:29,570
I think the reality of, of course, this is this seems to be quite reasonable.

159
00:21:29,600 --> 00:21:31,730
I mean, if we've been a regression model, for example,

160
00:21:32,270 --> 00:21:39,530
there is no untypical and there is no reason to believe the random coalitions they are like about absolute values in the scale of meetings,

161
00:21:39,530 --> 00:21:45,950
for example, or meetings. So during a while, you know, we would tend to think about the parameter values.

162
00:21:45,950 --> 00:21:50,240
They are finite values. They are not large original values.

163
00:21:51,410 --> 00:21:59,480
However, when we try to establish surgical theory, credibility from general theory, we cannot rely on that.

164
00:21:59,570 --> 00:22:06,740
I mean, mathematically, there is no reason for us to think that the parameter matters is it would be bounded by, you know, for example, one medium.

165
00:22:07,280 --> 00:22:10,820
So why, why, why? Why do you think that that must be the case?

166
00:22:11,450 --> 00:22:17,810
So this is the reason why I to try to establish general theory or when people try to establish their general theory,

167
00:22:18,350 --> 00:22:24,110
this condition is critical because it requires you to specify, to know beforehand.

168
00:22:24,230 --> 00:22:32,360
Even before solving the problem, you'll know that there is a higher bound on the primary and a you know, one of them is in part.

169
00:22:32,810 --> 00:22:41,750
So however, on the other hand, this is a commonly seen admission that by people, if you read the papers,

170
00:22:41,750 --> 00:22:49,490
you will see that I don't want to put a percentage, but you will see that there are large proportion of papers.

171
00:22:49,920 --> 00:22:57,350
If you read the appendix, you will see how, what conditions they make, what assumptions they will see people make this assumption.

172
00:22:57,800 --> 00:23:04,850
The reason is that this can simplify things a lot and without in this assumption, sometimes we cannot proceed.

173
00:23:05,000 --> 00:23:07,070
We cannot really establish anything.

174
00:23:07,550 --> 00:23:16,010
So that's the reason why this is not although lots of people do not like this, but the people still make this anyway.

175
00:23:17,330 --> 00:23:24,920
Okay. So however, in some special cases we are able to drop this condition, work this assumption.

176
00:23:24,920 --> 00:24:28,140
We will look at one such example. So it was a federal case.

177
00:24:28,160 --> 00:24:37,400
We are able to drop this so-called companions commission. That is the case when the function Q in Q and have data is contained.

178
00:24:39,310 --> 00:24:41,410
If you recall what a computer function looks like,

179
00:24:41,620 --> 00:24:52,330
a computer function looks like something while someone like this needs it is while there seems bothered or or it looks like this.

180
00:24:52,510 --> 00:24:56,950
There doesn't have to be. I mean, this lemon doesn't have to go down.

181
00:24:57,040 --> 00:25:01,030
It doesn't actually go down. But. But I looked like this. So if you.

182
00:25:02,810 --> 00:25:10,760
But let's consider this case. So if there is a case, then we're able to drop this company as it is.

183
00:25:10,940 --> 00:25:19,250
The reason is that this community actually prevents this function from tuning up as food moves away from zero.

184
00:25:20,140 --> 00:25:26,050
Now. So.

185
00:25:29,470 --> 00:25:39,250
Well, the reason that we in this case we're able to travel companions is that now, even if there is no boundary for the parameter space, I hope so.

186
00:25:39,270 --> 00:25:44,650
Now, without a companion, of course there no boundary at all. Let's a real life boundary.

187
00:25:45,370 --> 00:25:52,930
But because the objective agents can help. So if the theta value get to a three get really I mean,

188
00:25:53,500 --> 00:26:03,610
going to infinity or positive infinity but because the function itself cannot go up and towards like when theta becomes limited.

189
00:26:04,180 --> 00:26:11,230
So if well in that case then the objective function still has a, you know, sort of maximizer in the middle.

190
00:26:11,590 --> 00:26:19,810
And again, we are able to draw this compound that's not intuitive or geometric or intuitive explanation behind this.

191
00:26:22,660 --> 00:26:25,420
Now, let's take a look at a formal result of the.

192
00:26:27,610 --> 00:26:36,130
So you might wonder that why do we consider this special case arise all the contribute how common it is to have all of that a function that is okay.

193
00:26:36,610 --> 00:26:40,300
It turns out that these square objects you can,

194
00:26:40,390 --> 00:26:49,000
if you consider this square functionally square of that function is again and later what we talk about lasso and

195
00:26:49,000 --> 00:26:56,680
adaptive muscle and we are going to show that lasso as major or adaptive muscle as nature is is consistent.

196
00:26:57,800 --> 00:27:00,880
And that resound as we rely on this, you know,

197
00:27:00,920 --> 00:27:08,980
we will find it so that we do not need to worry about the compactness of the outdoor space so that your parameter space can be,

198
00:27:08,990 --> 00:27:15,380
you know, the whole real space or more of a high dimensional, multi-dimensional, your medium space.

199
00:27:15,830 --> 00:27:19,430
You do not need to specify that on it, but let's worry about that later.

200
00:27:20,570 --> 00:27:25,270
So in other words, indeed, and this is Elysium.

201
00:27:25,280 --> 00:27:33,440
There is a very wide of this in case that is so as a meter for these square as measured that we can apply this out.

202
00:28:22,110 --> 00:28:26,600
So first condition is do what is the same as their 1.1.

203
00:28:26,610 --> 00:28:34,320
So you zero theta is unique and maximize and after zero again we cannot drop this.

204
00:28:36,330 --> 00:28:48,590
And secondly the. Peter zero is inside is in the interior of the parameter space where the parameter space is.

205
00:28:51,800 --> 00:28:53,450
The premier space at its climax.

206
00:28:55,280 --> 00:29:05,120
Premier space is collapsed on the campus and the space does doesn't really put any value on the private space for some of the real life.

207
00:29:05,510 --> 00:29:11,260
These are exact. But it has to become.

208
00:29:12,070 --> 00:29:15,970
Well, that's so parameter space is comebacks and.

209
00:29:19,500 --> 00:29:27,960
Q in theta is. So this collisions.

210
00:29:36,060 --> 00:29:45,610
There's the companion addition. So if it helps, you could just try to imagine geometrically where you have the real life as well,

211
00:29:45,630 --> 00:30:00,310
and her space and then your Q and A hand is just a great function in real life and it just just you just stuff it so that helps.

212
00:30:00,330 --> 00:30:06,030
You might actually think, well, think of surgery example right so the whole real life of her face.

213
00:30:06,360 --> 00:30:12,490
Well now Q and had theta sutra she. Okay.

214
00:30:12,500 --> 00:30:16,610
So this is the second condition. Then the third condition is that.

215
00:30:37,770 --> 00:30:40,410
Q in hack murders to kill was zero.

216
00:30:40,870 --> 00:30:49,889
But now this convergence is slightly weaker while it's a pipeline weaker than the one we saw in 1.1 because it fell 1.1.

217
00:30:49,890 --> 00:31:00,330
The convergence was uniform convergence. And here we just require that it all done convergences is Cornwall convergence.

218
00:31:00,330 --> 00:31:11,000
Convergence. Right. So polarized convergence means that for any fixed theta for anything theta then this Q and have theta convert is from zero.

219
00:31:12,620 --> 00:31:24,570
So the for a uniform convergence but it means that but not sure how about from this the difference between point like and you.

220
00:31:25,040 --> 00:31:29,310
So the point of convergence is that you look at theta one by one, right?

221
00:31:29,480 --> 00:31:34,460
And in fact theta then as you go through infinity, as a sample size becomes large.

222
00:31:34,700 --> 00:31:40,429
Look Q and happy that in terms of here becomes very close by to the sample size.

223
00:31:40,430 --> 00:31:43,610
N could vary I mean for different theta.

224
00:31:43,610 --> 00:31:54,230
So for example for theta one, you might require an to be one meaning for say a m pattern and say that zero theta you have to be very close,

225
00:31:54,980 --> 00:32:05,270
but for a theta to z might require sample size to be one B in our work if you have beta and Q close, right.

226
00:32:06,800 --> 00:32:11,660
So this symbol size requirement has a different set of values.

227
00:32:11,660 --> 00:32:18,380
You are looking at the uniform convergence. It it means that doesn't matter doesn't matter which theta you're looking at.

228
00:32:18,750 --> 00:32:26,420
You give me an arbitrary theta so then I can find a similar size X for example, one D, right?

229
00:32:26,420 --> 00:32:37,610
So this sample size one body doesn't matter what you're looking at, then the Q in that theta and acute zero theta close uniform force.

230
00:32:38,240 --> 00:32:47,310
So that's the difference between uniform convergence and poor and what the merge to pull out card is weaker than uniform colors.

231
00:32:47,690 --> 00:32:54,320
It turns out that when we have connectivity, this assumption, this universal convergence, is not required anymore.

232
00:32:54,350 --> 00:32:59,690
We just need one, one convergence. So under the three conditions.

233
00:33:35,820 --> 00:33:39,870
Yes. What is WPA then? Oh, this is.

234
00:33:41,700 --> 00:33:53,390
With a probability of 31. We'll probably approach you.

235
00:33:53,420 --> 00:33:56,690
Why not? Well, the reason.

236
00:33:56,840 --> 00:34:00,590
Well, here we may. Just a month later, we're gonna see that at least for the.

237
00:34:00,590 --> 00:34:10,700
For the first chapter, we're going to use this a lot of if we say that an event violates first, let's consider the case.

238
00:34:10,700 --> 00:34:15,050
I'll find out. I'm okay. Let's not worry about it. Let's consider it where it's not finite.

239
00:34:15,410 --> 00:34:19,459
So we say that an event occurs with a probability.

240
00:34:19,460 --> 00:34:23,900
One event, a for example, occurs with probably the one that means.

241
00:34:35,810 --> 00:34:39,830
Well, mathematically, it means that the probability that if a event occurs,

242
00:34:40,250 --> 00:34:45,770
the probability is equal than what would be by by event a occurring would probably one.

243
00:34:46,310 --> 00:34:52,160
But now, because we are considering as Nordics, we are considering the case where a sample size goes with the food.

244
00:34:52,580 --> 00:34:57,260
So that's why here is probably the approach you want. So that means this.

245
00:34:58,490 --> 00:35:05,450
This then essentially means that as the sample size goes to infinity, this probability becomes one.

246
00:35:13,590 --> 00:35:24,660
So then if we look at the statement, what it means is that then as in goes to invent the probability that the had it exists is equal to one.

247
00:35:24,690 --> 00:35:28,680
So in other words, we do not need to worry about the case. We are theta and may not exist.

248
00:35:29,050 --> 00:35:37,260
Let's say that it has to exist. The property that him this is this is what some of our calls infinity becomes like.

249
00:35:37,890 --> 00:35:43,330
And then this as major as will convert is probably so is consistent.

250
00:35:45,520 --> 00:35:50,320
So here we are not going to prove this result because the proof is quite involved.

251
00:35:50,410 --> 00:35:55,360
I don't think we had the time. One thing is for interpretation farmers.

252
00:35:56,200 --> 00:36:05,950
We don't get approvals without permission. But again, I want to emphasize the the idea behind this result.

253
00:36:06,070 --> 00:36:13,660
So because later on, we are going to apply this result for the reversal and adapted muscle paste to show consistency.

254
00:36:15,510 --> 00:36:24,900
So again, this result is quite a useful in a sense that it does require a compact, proper space anymore.

255
00:36:26,250 --> 00:36:31,170
This is nice because if you think about linear regression model,

256
00:36:31,260 --> 00:36:43,590
because the muscle and the muscle originally proposed or at least a square in square meter, the thing of the linear regression model in 650.

257
00:36:45,390 --> 00:36:53,490
Of course, this reviews didn't really pop too much about the theoretical results, but if you look at the theoretical results,

258
00:36:53,490 --> 00:37:01,950
the linear regression model, those results, they didn't require the parameter space to be compact.

259
00:37:02,730 --> 00:37:04,740
So for leaner leisure to look at of,

260
00:37:04,770 --> 00:37:15,270
I thought it was out there to combat this assumption and which is nice because it's really first for such a simple regression model,

261
00:37:15,270 --> 00:37:28,460
a linear regression model. There does seem to be a particular reason to require the provider to be funded by a finite, finite number.

262
00:37:28,470 --> 00:37:39,180
Right? So of then, of course, then when people try to generalize the result or try to establish a result for a sole and adapted result,

263
00:37:39,180 --> 00:37:45,030
it will be nice to have to keep that generality without applying the categories phase to be bounded.

264
00:37:45,480 --> 00:37:48,660
And indeed, then this was this 1.1 crime.

265
00:37:49,020 --> 00:37:57,690
This actually allows that. So. And because of that, if I could.

266
00:38:00,720 --> 00:38:08,160
Okay. So that's this result. The, um, the compactness.

267
00:38:11,170 --> 00:38:18,810
So any questions before we move on to the next? Okay.

268
00:38:19,260 --> 00:38:48,360
Now let's look at the uniform convergence. We're going to look at this this two together.

269
00:38:48,360 --> 00:38:57,810
So the universal converters and the community addition or community piece that are the two zero theta part of the function.

270
00:39:00,960 --> 00:39:07,110
The Universal Hammer murders. This is a quite challenging assumption to check for the good state,

271
00:39:09,600 --> 00:39:18,300
or at least is probably the most involved assumption among those four for theorem 1.1.

272
00:39:19,650 --> 00:39:24,630
And here, welcome. While there are different ways of establishing uniform convergence.

273
00:39:25,350 --> 00:39:29,760
But in this course, we're able to focus on one one.

274
00:39:30,540 --> 00:39:34,340
One way that is done through the uniform. Last number.

275
00:40:15,920 --> 00:40:21,200
The uniform number can be used to establish exclusions.

276
00:40:21,800 --> 00:40:26,370
Now, before we talk about uniform, we love that number. That's what we call what we love.

277
00:40:26,370 --> 00:40:32,660
Last number is we love what number says that if you have I.D. data.

278
00:40:33,350 --> 00:40:38,090
So video, this is just a recall.

279
00:40:38,960 --> 00:40:44,870
We collect that, right? So if we have the eye ID data.

280
00:40:49,850 --> 00:40:56,240
Follows Undisputed for some description then.

281
00:40:57,630 --> 00:41:06,380
The sample average. Of the commodities in probability to the South Asian.

282
00:41:10,000 --> 00:41:15,400
That's what a number is, because you assemble every various police station.

283
00:41:16,420 --> 00:41:23,730
That's why we have I.D. data. But now we're talking about a more advanced version of love.

284
00:41:23,740 --> 00:41:27,880
About love lost number. That's the uniform of the glove.

285
00:41:28,450 --> 00:41:31,570
Let's take a look at what we've assessed.

286
00:41:48,750 --> 00:41:53,270
So let a note. Possibly a matrix of function.

287
00:41:53,300 --> 00:42:02,690
This is just to keep the result, general. So you can imagine this eight to be the matrix, right?

288
00:42:02,740 --> 00:42:08,030
Each each element of this matrix is a function of the data Z and the property.

289
00:42:17,940 --> 00:42:21,339
And for. A let's say.

290
00:42:21,340 --> 00:42:28,260
Well, I, I use a, you know, a matrix with elements.

291
00:42:28,780 --> 00:42:34,390
Hey. Lenore, we consider.

292
00:42:39,720 --> 00:42:44,190
When we talk about the normal, this matrix, this is the norm that we are talking about.

293
00:42:44,700 --> 00:42:47,790
So it's the square root of the sum of square of all elements.

294
00:42:50,730 --> 00:42:59,100
I'm serious. And then. This lava.

295
00:42:59,110 --> 00:43:24,130
This is the uniform lot of life on. So we first look at the data as the eyes are so invalid.

296
00:43:24,170 --> 00:43:31,190
I don't know what's good, but this is a fairly third way to use the assumption.

297
00:43:31,880 --> 00:43:35,180
And also theta is the parameter space is compound.

298
00:45:09,970 --> 00:45:13,960
Okay. Under the three conditions. Now, let's take a look at the conditions in one.

299
00:45:14,240 --> 00:45:18,670
So the first one is SGI. The data are in. This is very easy to understand.

300
00:45:19,000 --> 00:45:22,750
The same as as the parameter space is combat also very easy to understand.

301
00:45:23,260 --> 00:45:32,660
The third one says that now you have a bunch. It may be a matrix of actions, but anyway, so it is a function of the data in a theater.

302
00:45:33,110 --> 00:45:37,970
This function is continuous at each theater with a probability one.

303
00:45:38,630 --> 00:45:45,380
So here I mean with probably one. This is just to make the result more general come more cases.

304
00:45:46,670 --> 00:45:55,070
For most of the problems that we see in the statistics are this is not a problem because the function that we consider you are there continuous.

305
00:45:55,790 --> 00:45:59,240
But there are some s matrices, statistics.

306
00:46:00,770 --> 00:46:08,060
Sometimes, for example, again called our regression. Those estimate about this function may not be continuous everywhere.

307
00:46:08,180 --> 00:46:12,890
Maybe it is continuous at one one particular.

308
00:46:14,300 --> 00:46:17,570
Of course. I'm sorry. So it is continuous with probability one.

309
00:46:17,570 --> 00:46:25,220
But if you look at a particular x value object. But anyway, so let's not worry too much about this about this one here.

310
00:46:25,700 --> 00:46:33,800
So we have a obviously that is continuous can use this function in favor of reducing theta with a probability one.

311
00:46:34,280 --> 00:46:38,150
And also there exist a so-called dominant function,

312
00:46:38,630 --> 00:46:47,240
dominant function in a sense that this function does not depend on that there is a function of Z only a Z along such that.

313
00:46:48,520 --> 00:46:58,030
And it dominates. There's a Z theta function dominant in the sense that the norm is less than or equal to just the opposite for anything.

314
00:46:59,620 --> 00:47:06,970
And also this Z is a good word. So that means sorry, it's less than 50.

315
00:47:08,230 --> 00:48:09,640
So under these three conditions, then. Okay.

316
00:48:09,720 --> 00:48:12,810
Under the three conditions, then we have a final result.

317
00:48:12,840 --> 00:48:19,170
The first result is that maybe when we look at this, this is the major, major one.

318
00:48:19,950 --> 00:48:27,950
The second here, if you look at those results, this results as that rather simple average of this, a function as a function player.

319
00:48:28,320 --> 00:48:35,210
The symbol average actually converges to the excitation, which is sort of love, large number.

320
00:48:35,250 --> 00:48:38,730
I love the number of sets that the assembly every converters looks at Asia.

321
00:48:40,460 --> 00:48:48,780
But here, this convergence is unique in a sense that a firm like Superman or Theta, you have the convergence probably.

322
00:48:50,010 --> 00:48:53,040
So this is why it's called the uniform large number.

323
00:48:54,330 --> 00:49:01,170
So this if and then while the second part of the reason is that this limiting function, these values are observed.

324
00:49:01,200 --> 00:49:05,610
Now, of course, this becomes a function law. So this adds to the convenience.

325
00:49:05,880 --> 00:49:09,210
Of course, then it's a theta signal.

326
00:49:09,780 --> 00:49:15,359
So if we look at this without this result again, for now,

327
00:49:15,360 --> 00:49:23,459
I can give a kind of a abstract and relatively general explanation of the usefulness of this.

328
00:49:23,460 --> 00:49:26,100
The major log on to see examples where we will propose.

329
00:49:27,810 --> 00:49:39,570
So the reason that this result is useful is because think about the what we have learned in 656, 51, 53, probably in other courses.

330
00:49:40,590 --> 00:49:50,990
When you look at the different majors, you are asked Major, you are to involve both data and in the present theta.

331
00:49:52,630 --> 00:50:03,160
And in. But because of that, the technical number is not a sufficient adult because that number only says that often a function of

332
00:50:03,160 --> 00:50:10,660
the data z you have to convert into the sample average convert instrumentation but many as meters,

333
00:50:10,660 --> 00:50:16,200
many, many qualities we look at. They are both the function of the data and the function of the pantry.

334
00:50:17,320 --> 00:50:24,160
So for those qualities that if we want to argue that assemble average convergence means that easier than the

335
00:50:24,460 --> 00:50:32,310
collection of last number does not apply and more or it applies only if you look at it think about right.

336
00:50:33,010 --> 00:50:40,900
However I mean this result allows you to generate that so in can sense that even if now you are looking at a function as a function theta,

337
00:50:41,440 --> 00:50:49,570
you still have a convergence probability and a convergence is actually uniform in the prime position.

338
00:50:50,080 --> 00:50:59,680
So this is a very horrible for and later I want to use this but of course there are conditions, there are assumptions behind this, right.

339
00:50:59,680 --> 00:51:05,710
So that these three conditions make sure that the host.

340
00:51:09,430 --> 00:51:14,110
Okay. And this reason we are not going to show the true this result of either.

341
00:51:14,260 --> 00:51:19,780
And these we want to see the application and the vision of this example.

342
00:51:20,620 --> 00:51:23,800
Now let's take a look at another major result.

343
00:51:25,330 --> 00:51:31,120
So so far what we have done is we have looked at the general theory.

344
00:51:31,250 --> 00:51:35,350
General theory I feel one on one about the consistency of atmosphere.

345
00:51:36,070 --> 00:51:39,580
And also we talk about the four conditions.

346
00:51:39,980 --> 00:51:44,290
We look at those four conditions. Again, the identification.

347
00:51:44,560 --> 00:51:47,590
The compound is of the parameter phase, the continuity.

348
00:51:47,860 --> 00:51:54,510
And then any new idea of the of the of any function and the uniform convergence of the.

349
00:51:55,510 --> 00:52:01,210
Now, let's try to apply this result to the now in case it is the third one.

350
00:52:01,270 --> 00:52:06,780
One way is a better general reduction in general holds for any assignment.

351
00:52:07,510 --> 00:52:11,350
But now let's take a look at how that leaves out what that result is.

352
00:52:11,890 --> 00:52:15,120
Now there is a max like a fascinator.

353
00:52:52,290 --> 00:53:02,569
And this result is important. In two ways.

354
00:53:02,570 --> 00:53:10,310
One way is that, of course, I now use one of the most widely used escalator ambassadors or any statistics.

355
00:53:10,490 --> 00:53:14,809
So it's very it's crucial to know like under what conditions.

356
00:53:14,810 --> 00:53:18,250
And I'll use six and a seven.

357
00:53:18,390 --> 00:53:23,210
Suddenly we actually learn in six, six, oh two.

358
00:53:23,640 --> 00:53:33,500
Right? Back then we talk about oh and I'll use consistent value has it as not only as a normal decision, but we never formally prove that result.

359
00:53:34,130 --> 00:53:42,650
So here now we are this result of formally while this is a formal result showing that it and I use this.

360
00:53:43,280 --> 00:53:50,630
So now suppose that again the data I've followed this is version and then if.

361
00:53:57,080 --> 00:55:55,970
But under the following conditions. Okay so this is it gives the conditions under which I'm I'll use consistent.

362
00:55:56,310 --> 00:56:02,850
Now take a look at those conditions. So the first commission sort of guarantees that I don't know.

363
00:56:03,180 --> 00:56:08,700
I don't know the ability of identification of the parameter. I think it's a very simple requirement.

364
00:56:09,120 --> 00:56:14,520
It requires that the proper values are different then the densities are different.

365
00:56:15,070 --> 00:56:19,889
And this is actually true part of all of the description that we have seen.

366
00:56:19,890 --> 00:56:23,890
Right. So, for example, for normal useful manual poisoning, for whatever reason,

367
00:56:23,910 --> 00:56:28,040
anything you can think of with a different primary becomes a different decision.

368
00:56:29,520 --> 00:56:32,990
So. And secondly, the primaries phase is combat.

369
00:56:34,240 --> 00:56:38,680
And thirdly, the lock on the density function is continuous in theater.

370
00:56:39,250 --> 00:56:45,970
It's clear that each theater will probably be one. This is also true believe true for the densities that we have.

371
00:56:46,720 --> 00:56:50,260
But for example, normal is financial and is moving.

372
00:56:50,260 --> 00:56:54,130
I think all there are continue there does this are continues after theater.

373
00:56:55,740 --> 00:57:09,170
And lastly, while this is more of a, you know, analytical analysis for new analysis or calculus confusion, so look,

374
00:57:09,180 --> 00:57:17,160
f it would take long and you take an absolute value look at a subgroup and they use validation is less often and this is sort of.

375
00:57:19,730 --> 00:57:27,090
This. While this isn't from here, there exists a dominant function here.

376
00:57:27,100 --> 00:57:32,190
Here you can while you can consider this this supreme law.

377
00:57:32,490 --> 00:57:38,130
You can consider the supreme of the absolute value block as sort of the dominant function.

378
00:57:38,370 --> 00:57:41,250
So I think that it is less definitive.

379
00:57:42,360 --> 00:57:51,920
But anyway, this is also purely analysis assumption, but a real analysis assumption has nothing to do with scarcity.

380
00:57:51,960 --> 00:57:57,550
Once you have the density wasn't in by your multiplicity in terms of for example,

381
00:57:57,550 --> 00:58:08,190
oh my data on woman this program I did a discussion then think this this checking this just become a real analysis technique the real problem.

382
00:58:08,790 --> 00:58:17,670
So under this four conditions and let's see now these four conditions are very straightforward to understand under this condition.

383
00:58:18,660 --> 00:58:29,549
Now this and I'll use consistent as evidence and the proof here amended by this this omission is not because it is too complicated,

384
00:58:29,550 --> 00:58:36,660
but it is because it's simply abrogation of 1.1 or just checking because because for example,

385
00:58:36,660 --> 00:58:42,830
I mean the identity commission kind of use the example 1.11. to argue that.

386
00:58:44,190 --> 00:58:48,390
So this 1.2 is sort of just application of this 1.1.

387
00:58:50,010 --> 00:58:57,570
Okay. So now it's clear that the consistency of emoji is implied by this word conditions.

388
00:58:58,060 --> 00:59:01,800
Now I want to point out that if you read a different textbooks,

389
00:59:03,180 --> 00:59:08,480
you see that the confusion and now you may be established under different set of conditions here.

390
00:59:08,490 --> 00:59:13,620
I mean, we use this several conditions, but in some other one person,

391
00:59:13,980 --> 00:59:24,360
this melody about the coverage of the book chapter neue in the next chapter, the different textbooks.

392
00:59:25,620 --> 00:59:34,800
People may prove this consistency using different conditions, which is quite natural or not.

393
00:59:35,370 --> 00:59:39,270
I mean, this, this word conditions are sufficient, but they are not necessary.

394
00:59:39,870 --> 00:59:45,120
Some of these some of them, they are negative and all of them are necessary.

395
00:59:46,650 --> 00:59:53,550
But these four conditions, they are quite straightforward to understand and also quite natural.

396
00:59:55,770 --> 01:00:02,490
Okay, so that's the persistence. So any questions because that's your next topic.

397
01:00:07,680 --> 01:00:14,340
Okay. So that's consistency. Now, the next thing we're going to look at is it's not even normality.

398
01:00:26,320 --> 01:00:33,670
Here are these two are paired together when we tried to establish the properties of an escalator.

399
01:00:33,670 --> 01:00:40,059
So as I if you tried to ask me something you space that model you propose a new ask later.

400
01:00:40,060 --> 01:00:46,570
You're trying to study the property of that later. Typically, if you rely on a lot of sympathy or increase out of the property,

401
01:00:46,570 --> 01:00:50,410
typically you will to establish consistency and thus modulate the knowledge.

402
01:00:51,370 --> 01:00:55,420
So consistency means that at least the way your sample sizes look,

403
01:00:55,660 --> 01:01:02,860
at least the way you collect more and more information about your estimate of become closer, closer to the truth, that eventually becomes the truth.

404
01:01:03,340 --> 01:01:10,340
So in the sense that there is no. At least there is no systematic discrepancy between the last meter and the truth.

405
01:01:11,060 --> 01:01:14,520
When when your information becomes. When you have more dramatic.

406
01:01:14,840 --> 01:01:25,160
Lot more dramatic. So when you have consistency, of course, then consistency is that is a very natural property to talk to us for.

407
01:01:26,930 --> 01:01:35,659
But once you establish consistency. Another thing is to look at it as an analogy, because once you have a consistency,

408
01:01:35,660 --> 01:01:42,590
then what matters is the property of the house maker in the local neighborhood of the client,

409
01:01:42,830 --> 01:01:47,780
because the real parameter of your estimate is going to fall a local neighborhood of that of the.

410
01:01:48,920 --> 01:01:57,350
And then you want to see how is what is this rootedness so that you can make inference and construct a reasonable and reliable assessment.

411
01:01:58,370 --> 01:02:04,850
So that's the reason why, after establishing consistent theory, people who have studied the study in analogy.

412
01:02:07,280 --> 01:02:18,320
So a small analogy is a sort of a local like is a property where we look at a local neighborhood, a zero, and we look at how the estimate behaves.

413
01:02:21,110 --> 01:02:29,540
So here are what to do before we look at the general steps it takes to establish a semblance of normality.

414
01:02:30,030 --> 01:02:42,800
Now let's take a look at the idea for for the case of Mali as the AU and I use a very familiar way that I hear to start with and I.

415
01:04:09,780 --> 01:04:19,469
So well. First, let's consider the case where not long after is the impressionable and if there is debatable

416
01:04:19,470 --> 01:04:25,770
and also that the theta hat the estimate or actually is inside the parameter space.

417
01:04:26,640 --> 01:04:31,680
Now in this case because theta had maximize the log likelihood,

418
01:04:32,670 --> 01:04:37,950
then of course it is satisfied the status in the equation which which means that if we take

419
01:04:37,950 --> 01:04:43,469
the log likelihood or worse that that's the score function by six more square function.

420
01:04:43,470 --> 01:04:48,000
Right. So then the theta have a solve the score equation.

421
01:04:48,570 --> 01:04:54,510
So that satisfies that. But energy energy equals it.

422
01:05:46,260 --> 01:05:55,110
Now let's further assume that lock up is twice continuously differentiable, so which means that a cycle already exists and also continuous.

423
01:05:55,770 --> 01:06:03,480
So basically it's smooth. It's a nice function. Then we can apply the so-called metal theorem to this score function.

424
01:06:04,540 --> 01:06:09,840
You can recall what a new battle theorem is. Reveal a theorem.

425
01:06:12,680 --> 01:06:20,870
So that for a faction. Yeah. Or maybe I would just do a soundtrack for function G and X.

426
01:06:23,670 --> 01:06:30,720
The miners at a value at zero then is as an equal to g d rarity.

427
01:06:41,910 --> 01:06:48,890
Times the difference we didn't that's an issue where this at Tudor this is some value between X and x2.

428
01:06:49,050 --> 01:06:52,260
So that's why he's called me out of zero energy prime, he said.

429
01:06:53,670 --> 01:07:00,510
So now let's apply the value theorem to this score, to this score function.

430
01:07:07,760 --> 01:07:11,000
So I'm going now. Let's call the score function as the G function.

431
01:07:15,750 --> 01:07:20,100
So then if you go to the store now evaluate, you've had a zero.

432
01:07:22,270 --> 01:07:29,980
That, plus the diversity of the score now, which becomes the second order of your livelihood.

433
01:08:00,290 --> 01:08:05,149
All right. So here this is sort of a g prime example.

434
01:08:05,150 --> 01:08:18,560
So this is the 700 unit where the majority of the score was that in order to evaluate you here, I emphasize evaluating at a feeder bar in a bar.

435
01:08:18,860 --> 01:08:32,210
So for me, this is. And this is going to be about this is some battle between feet ahead and feelings of pride.

436
01:08:32,220 --> 01:08:38,800
But we have a feeling. Now, of course on the firm calculus.

437
01:08:39,280 --> 01:08:51,880
Now the remainder theorem for multivariate function, modular or modular by the level of theorem does not exist.

438
01:08:52,030 --> 01:08:54,140
But here, what do we mean by that?

439
01:08:54,250 --> 01:09:04,239
You can apply this to each component of the exact value function and then just the thing to have to do as a barrier for each component.

440
01:09:04,240 --> 01:09:08,290
But that's less some technical details. Let's not worry too much about that.

441
01:09:08,950 --> 01:09:12,580
But there's a bar somewhere between thing. I haven't seen a zero.

442
01:09:19,550 --> 01:09:23,090
And once we got it here, now we are going to.

443
01:09:25,670 --> 01:09:30,530
Now we are able to solve for the year at -0.

444
01:09:32,270 --> 01:09:36,920
Maybe our first out of this bizarre theater had a minor offensive.

445
01:09:37,940 --> 01:09:41,390
And then. This is equal to 90.

446
01:09:51,950 --> 01:09:55,760
The inverse of this comes.

447
01:10:08,820 --> 01:10:16,190
How does that sound? This is nothing but a simply, you know, solving for a half -0.

448
01:10:17,480 --> 01:10:23,630
Now, with this one I'm going to do now is I'm going to modify both sides by square number in.

449
01:10:24,970 --> 01:10:33,460
So on the left hand side. Then I had this squared on the end and this the reason I highlighted this becomes a very familiar form for us.

450
01:10:33,700 --> 01:10:39,880
So. So in six or two. And the other course is where you establish a smart in reality.

451
01:10:40,070 --> 01:10:45,370
Typically it is this guy converts to some form of exclusion.

452
01:10:47,690 --> 01:10:52,370
So then. Then on the right hand side, I also multiply by square.

453
01:10:52,520 --> 01:10:56,080
And so here I have of.

454
01:11:05,440 --> 01:11:10,080
Okay. And then now because we are almost as time.

455
01:11:10,090 --> 01:11:19,510
So let me just briefly explain the idea and then next like I have or do you have so you can look at this guy over here.

456
01:11:20,470 --> 01:11:24,670
This is a sample, average sample average of the second order of your.

457
01:11:25,950 --> 01:11:32,729
Now based on last last number were the week uniform week long last number we know that assemble

458
01:11:32,730 --> 01:11:37,620
average should have converged with a citation right so this guy then we will converting

459
01:11:37,620 --> 01:11:46,439
probability to some matrix police violation of the 700 route where the hash images and

460
01:11:46,440 --> 01:11:53,880
the this guy if you look at this guy over here and this guy if you consider simply what.

461
01:11:55,900 --> 01:11:59,720
Don't be like that.

462
01:12:00,400 --> 01:12:06,910
If you simply consider this whole thing as a random variable, indeed it is right now we will consider the whole thing as a running variable.

463
01:12:07,180 --> 01:12:11,770
Then this is nothing but you know the one over scored in the summation.

464
01:12:12,250 --> 01:12:16,329
Some random error and this random variable has inspiration.

465
01:12:16,330 --> 01:12:22,000
Zero because of because this is a score function actually so score that the original log likelihood.

466
01:12:23,560 --> 01:12:27,960
So then based on a central limit theorem this guy will convert in this filter.

467
01:12:28,240 --> 01:12:33,750
Who wants to convert Columbus Fusion. So.

468
01:12:34,740 --> 01:12:38,790
In other words, this one will convert in probability to a matrix,

469
01:12:39,330 --> 01:12:45,600
and this one will convert in this fusion one based on central interference to some normal this fusion.

470
01:12:46,650 --> 01:12:55,830
And then you have the paradox of this true that based on selected here we know that the product will convert to a normal this fusion.

471
01:12:57,480 --> 01:13:04,440
So you have a factor that converts to a constant and you have a run, a variable converting distortion.

472
01:13:04,950 --> 01:13:08,910
Then the product is written as the product of this to.

473
01:13:10,360 --> 01:13:12,340
Which means that in the end,

474
01:13:13,120 --> 01:13:22,240
this is going to enhance the difference at the feet of how to buy and sell zero oil converting and distribution to a normal platform of this fusion.

475
01:13:22,720 --> 01:13:28,240
And this will establish the study of the distinction of fascinating thing to happen.

476
01:13:29,410 --> 01:13:33,850
So this is what we are going to do in our next lecture.

477
01:13:34,150 --> 01:13:37,150
So we will stop here today.

478
01:13:39,520 --> 01:13:43,180
I do not think that using the protagonist, Mike Decker, running on the board.

479
01:13:43,690 --> 01:13:47,140
Okay. That's way too that I will be using the correct.

