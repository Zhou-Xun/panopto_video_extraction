1
00:00:01,020 --> 00:00:04,800
Yeah. Yeah, exactly. Yeah.

2
00:00:06,210 --> 00:00:21,540
So we get everybody drunk and it's kind of it's only nine right now because the last one in, like, that's.

3
00:00:25,530 --> 00:00:28,990
It's really strange.

4
00:00:32,040 --> 00:00:35,430
Oh, well, okay. So I have met a version.

5
00:00:35,460 --> 00:00:40,320
It's 10,000. Yeah, it's a long, long track.

6
00:00:41,790 --> 00:00:48,730
So now you're not. You're not going to like the person I said to.

7
00:00:48,750 --> 00:01:05,100
And you've seen this tape, and I thought it was just because I don't.

8
00:01:09,820 --> 00:01:15,130
And you're going to find some, you know, really, really good information about it.

9
00:01:19,800 --> 00:01:33,280
You can see both type of symptoms and the sign up sheet going around sign up for that is towards the end.

10
00:01:33,280 --> 00:01:44,230
So should if anyone wants to come and get you afterwards, come to my office at 1030 and say hello or whatever you want to ask about the seminar.

11
00:01:44,590 --> 00:01:50,799
I guess I encourage questions as we go along here. Yes. Summer is a new system professor in the department.

12
00:01:50,800 --> 00:01:54,670
Just got her Ph.D. maybe weeks, many months ago.

13
00:01:56,150 --> 00:01:59,320
And so she's going to the University of Minnesota.

14
00:01:59,770 --> 00:02:03,220
So it's kind of riveting. Thanks.

15
00:02:03,820 --> 00:02:06,670
Yeah. Thanks for coming out. I know it's a little chilly out there.

16
00:02:06,670 --> 00:02:13,780
I struggle with getting out of bed this morning, but yeah, thanks for being here and hopefully you take something away from this.

17
00:02:13,780 --> 00:02:17,250
And if you don't, that's fine too. Be honored to be talking about.

18
00:02:17,270 --> 00:02:25,839
It's actually like my dissertation work, so I finished my dissertation in May and if you went to my I don't know if anybody

19
00:02:25,840 --> 00:02:29,650
here besides Jeremy went to my job talk like a year ago when I was interviewing.

20
00:02:29,920 --> 00:02:39,010
It's going to be like a little bit of an overlap. I hate to say I haven't made too much progress on this stuff since then, but yeah,

21
00:02:41,590 --> 00:02:48,400
so I feel like we've been talking a lot about prostate cancer in this series, but I'm going to talk about it again today.

22
00:02:49,030 --> 00:02:55,479
Hopefully not too much overlap between what you learned here today and what we've talked about before.

23
00:02:55,480 --> 00:02:59,170
But yeah, prostate cancer is like a leading cancer in this country.

24
00:03:00,070 --> 00:03:05,110
About 268,000 new cases of prostate cancer will be diagnosed this year.

25
00:03:06,340 --> 00:03:10,959
And prostate cancer is has better survival.

26
00:03:10,960 --> 00:03:16,270
So only around like 30,000 people with prostate cancer in 2022.

27
00:03:18,460 --> 00:03:25,510
So early detection has been very good for the death rate of prostate cancer.

28
00:03:26,140 --> 00:03:32,049
So and when you buy that is the risk of dying from prostate cancer has decreased

29
00:03:32,050 --> 00:03:40,120
about like 50% from the mid 1990s to the mid 20 tens due to improved treatment.

30
00:03:40,120 --> 00:03:46,960
And then this early detection from PSA testing, which is like a screening test for prostate cancer.

31
00:03:47,650 --> 00:03:57,820
So that's really good. However, despite this reduction in mortality due to the early screening that became really popular,

32
00:03:58,450 --> 00:04:09,850
there's increasing evidence that PSA testing was causing undue harm and burden through like overdiagnosis and overtreatment, actually.

33
00:04:10,120 --> 00:04:16,240
So it turns out that PSA has a pretty low predictive value.

34
00:04:17,980 --> 00:04:25,570
So like this little graphic over here just shows, you know, you can have a PSA and it doesn't necessarily mean that you have cancer.

35
00:04:25,570 --> 00:04:30,549
It could mean like, for example, you have like a utili or you rode a bike.

36
00:04:30,550 --> 00:04:36,130
I don't really know. But yeah, so PSA is like good, but it's not super great.

37
00:04:37,180 --> 00:04:46,960
So as a result, the U.S. Preventative Services Task Force actually like changed their guidelines about PSA screening

38
00:04:47,650 --> 00:04:53,350
and recommend that and stop recommending it as like a screen test for all men to undergo.

39
00:04:54,610 --> 00:05:01,630
And these like changing guidelines sort of cause this like volatility in the incidence of prostate cancer.

40
00:05:02,110 --> 00:05:09,399
So you can see as like the popularity of PSA screening sort of increased.

41
00:05:09,400 --> 00:05:13,780
So did the incidence of cancer because they were finding, you know, clinically,

42
00:05:14,770 --> 00:05:21,100
maybe clinically irrelevant or very small cancers that aren't going to turn into anything aren't going to cause this person to die.

43
00:05:21,580 --> 00:05:29,920
So people were starting to undergo treatment for cancers that they probably didn't need to undergo treatment for, just like an incidence.

44
00:05:30,190 --> 00:05:35,679
And then the guidelines change or the incidence fell. So that's just kind of confusing.

45
00:05:35,680 --> 00:05:43,060
But basically using PSA as a screening tool causes like overdiagnosis, which we want to prevent.

46
00:05:44,770 --> 00:05:54,640
And that's where my collaborators we're sort of looking to do, looking to find a new diagnostic tool that's better than a PSA.

47
00:05:55,600 --> 00:06:00,250
So multi parametric MRI or EMP.

48
00:06:00,280 --> 00:06:09,270
MRI is like a relatively new tool and it's showing like increasingly an important role in the screening or early check.

49
00:06:09,560 --> 00:06:14,120
Prostate cancer. So I don't know a lot about MRI.

50
00:06:14,150 --> 00:06:19,670
I have done one once. It was not fun, but it is less invasive than a biopsy.

51
00:06:19,760 --> 00:06:24,920
If you can imagine that. And what an MRI does, according to Wikipedia, which is how I found this out,

52
00:06:25,550 --> 00:06:32,270
it uses like magnets and radio waves to create detailed images of the soft tissues in your body.

53
00:06:32,990 --> 00:06:39,830
And MRI scans basically just give doctors a very clear picture of the prostate and the surrounding areas.

54
00:06:40,880 --> 00:06:49,130
And it can be used to determine if a man that has an abnormal PSA or maybe symptoms of cancer if they should get a biopsy.

55
00:06:49,340 --> 00:06:58,010
So it's sort of like triaging them before they have to undergo a more serious sort of biopsy for the cancer.

56
00:06:59,960 --> 00:07:05,140
So yeah so MRI MRI's is showing promise as a tool to like do before a biopsy to

57
00:07:05,140 --> 00:07:09,520
prevent then having to go to biopsy who really didn't need to go in the first place.

58
00:07:12,130 --> 00:07:19,690
So what the data looks like, so empty MRI is actually like a combination of several,

59
00:07:19,840 --> 00:07:26,380
several images, which makes it like quite difficult for clinicians to synthesize.

60
00:07:26,920 --> 00:07:33,100
So they have to look at several images together to decide if the person has cancer and where the cancer is located.

61
00:07:34,030 --> 00:07:42,400
So the diagnostic performance is going to be highly dependent on the greater or the reader and their experience in their expertize.

62
00:07:42,880 --> 00:07:55,390
So in order to tackle that whole issue, people have been developing these things called CAD systems, which are computer aided diagnosis systems,

63
00:07:55,960 --> 00:08:05,740
which basically just like take the all of the images and like spit out like one score so they can like better synthesize all that data.

64
00:08:08,260 --> 00:08:11,440
And cat systems like have been fairly successful.

65
00:08:12,640 --> 00:08:24,340
Many of them are not perfect, but our team developed a cat system and what it does is it takes those images on the left, it creates a score.

66
00:08:25,080 --> 00:08:30,250
So like a map of the prostate where like red is like a high probability of cancer.

67
00:08:32,050 --> 00:08:35,620
So it's not a score like a univariate at each voxel.

68
00:08:36,610 --> 00:08:41,380
And that's great. However, our clinicians weren't satisfied with that.

69
00:08:42,280 --> 00:08:45,459
They wanted something more like a picture on the far right.

70
00:08:45,460 --> 00:08:50,560
So, you know, basically teasing out the signal from the noise.

71
00:08:50,770 --> 00:08:55,360
And I'm showing you data here that like it's kind of obvious where the cancer is.

72
00:08:55,360 --> 00:08:57,250
Like there's a big like red area.

73
00:08:57,940 --> 00:09:04,059
Like it's very kind of clear that there's a large lesion on the left hand side of the prostate, but not all the data.

74
00:09:04,060 --> 00:09:12,940
Is this pretty? In fact, like most of the data has a very noisy signal sort of in the in the healthy region.

75
00:09:13,600 --> 00:09:22,239
So our clinicians were like, okay, this is helpful. But we kind of like need something more because we want to like automate this process.

76
00:09:22,240 --> 00:09:26,440
So they want like a map of, like where they should do the biopsy essentially.

77
00:09:27,610 --> 00:09:32,769
So like that's what my project focuses on is taking like that score and turning

78
00:09:32,770 --> 00:09:40,030
it into like a partition of the prostate or like a boundary detection method.

79
00:09:41,100 --> 00:09:47,160
And feel free to like raise your hand if you have questions. I'm kind of going fast, but there's a lot to talk about.

80
00:09:48,150 --> 00:09:56,160
So another thing we wanted to do was like really mimic what a pathologists outline of a tumor would be.

81
00:09:56,160 --> 00:09:57,970
So in figure A,

82
00:09:57,990 --> 00:10:08,490
you actually have a tissue sample from a prostate that was removed via surgery for somebody who underwent surgery as a treatment for prostate cancer.

83
00:10:08,670 --> 00:10:12,390
So and then what happens is the prostate gets sliced up,

84
00:10:12,630 --> 00:10:18,360
it goes to the pathologist and they actually like look at it and they draw a circle around the cancer.

85
00:10:18,720 --> 00:10:25,410
And obviously, like, we can't just take everybody's prostate out when they have cancer to see where the cancer is.

86
00:10:25,410 --> 00:10:28,170
We want to automate this using the imaging data.

87
00:10:28,410 --> 00:10:36,810
So we really want to like mimic those pathologist annotations as closely as possible using only the imaging data.

88
00:10:37,350 --> 00:10:42,600
And this just shows how we can kind of map the pathologist drawings onto the images.

89
00:10:43,470 --> 00:10:48,510
And this will serve as our gold standard for our data analysis.

90
00:10:49,630 --> 00:10:54,420
Yeah, like that just shows you like, the shape we're trying to mimic, which is like a closed boundary.

91
00:10:55,530 --> 00:11:03,390
It's kind of smooth. Kind of rough. Yeah, we're really just trying to produce this with the imaging alone.

92
00:11:05,440 --> 00:11:09,390
Yeah. And spatial.

93
00:11:09,970 --> 00:11:13,120
Yeah. So this one slice, is it like three dimensional?

94
00:11:13,510 --> 00:11:18,670
Yeah. So you can imagine. So I just showed one slice. But you can imagine that this was actually 3D data.

95
00:11:19,630 --> 00:11:25,270
And so when the prostate is removed, it gets sliced up until, like 10 to 12 slices.

96
00:11:25,960 --> 00:11:34,990
And they actually have these annotations for each slice. And we also have like imaging data also in slices.

97
00:11:35,260 --> 00:11:44,170
And the slices don't exactly line up because you can imagine, like when that process is removed from the body, actually changes shape quite a bit.

98
00:11:44,740 --> 00:11:52,660
So we do the best that we can to match up the imaging data with the pathology data for the purposes of,

99
00:11:54,010 --> 00:11:57,310
you know, being able to tell if our method is working.

100
00:11:58,120 --> 00:12:04,990
But yes, it is like 3D data, and I'm going to be talking about it in the context of 2D and then 3D later.

101
00:12:06,370 --> 00:12:17,290
Yeah. Okay. So if anybody is familiar with like spatial statistics, that's exciting because I love spatial statistics.

102
00:12:17,890 --> 00:12:23,260
But basically our data exhibit this like positive spatial autocorrelation,

103
00:12:23,260 --> 00:12:29,410
which just means that like voxels that are near each other tend to have like similar scores,

104
00:12:30,520 --> 00:12:33,270
which like makes sense biologically that, you know,

105
00:12:33,280 --> 00:12:38,500
two cells in your prostate that are close together or if one is cancer, the other one's probably cancer too.

106
00:12:40,240 --> 00:12:47,290
And if you just kind of ignore that spatial autocorrelation, it can lead to a lot of problems.

107
00:12:47,290 --> 00:12:52,060
And there's all kinds of papers talking about what happens when you ignore spatial autocorrelation.

108
00:12:52,360 --> 00:12:55,960
This one I cited here is very widely known.

109
00:12:57,970 --> 00:13:02,260
Yeah. And it talks about MRI, which is a completely different thing from what we're talking about.

110
00:13:02,260 --> 00:13:09,190
But it's still. Yeah, if you're ever encountering spatial data, don't ignore the spatial aspect.

111
00:13:09,190 --> 00:13:19,209
You could run into really big problems. So, I mean, talking about how we handle that, so we use a Gaussian process to model our data,

112
00:13:19,210 --> 00:13:24,610
which just means that I mean, it's basically a fancy name for like a multivariate normal distribution.

113
00:13:26,320 --> 00:13:34,690
So don't want that scare you. So basically we have Y, which is like our score and we observe it at a bunch of voxels or locations.

114
00:13:34,690 --> 00:13:38,860
S And then we just like use this linear model very easy, very simple.

115
00:13:40,120 --> 00:13:43,810
And here we don't even have like covariance x transpose.

116
00:13:44,230 --> 00:13:53,170
We just have like a mean beta. So you can just ignore the X, but this is like a more general how you would apply this in any spatial context.

117
00:13:54,850 --> 00:14:04,500
So here we actually have two error terms. The W is the spatial error, and then the epsilon is like the independent random error that you want have.

118
00:14:06,130 --> 00:14:12,610
And then we can just like do some tricks, marginalize over the WS and get this expression for the likelihood,

119
00:14:13,630 --> 00:14:17,320
which is, just like I said, a normal distribution with a big.

120
00:14:18,340 --> 00:14:26,400
Covariance matrix here, which has two components, the spatial and the independent random error.

121
00:14:27,880 --> 00:14:39,860
Yeah. And then usually what we do in a gas Gaussian process is we assume some very simple function for creating the H matrix.

122
00:14:40,930 --> 00:14:48,550
So we'll make this assumption that H just depends on the distance between two points.

123
00:14:49,600 --> 00:14:54,030
And then there's some, it's some function of them. And you can pick there's different ones.

124
00:14:54,670 --> 00:14:58,000
There's like exponential return. Have fun with it.

125
00:14:58,720 --> 00:15:03,190
Exponential is the easiest one. So that's what everybody uses. It's just like one parameter, I think.

126
00:15:03,820 --> 00:15:09,610
So that's it we're going to use to. So yeah, like I said, we want to estimate this,

127
00:15:10,780 --> 00:15:19,030
which is the pathologists annotation in the booklet in black and I've just like mapped that onto the imaging data.

128
00:15:21,360 --> 00:15:27,300
And we want to estimate it by something like this. So this is actually like what my method like spits out.

129
00:15:28,260 --> 00:15:29,879
It spits out this boundary in black.

130
00:15:29,880 --> 00:15:36,870
And then we actually also get a credible band because we're working in the Bayesian framework, which is really cool,

131
00:15:36,870 --> 00:15:44,159
and our clinician clinicians really like this much better than just the the heatmap alone because it shows,

132
00:15:44,160 --> 00:15:47,520
you know, like where they should do the biopsy.

133
00:15:48,450 --> 00:15:55,320
So we say target the biopsy like in this, inside this boundary, the cardinal bands are like kind of just for fun.

134
00:15:56,430 --> 00:16:02,970
But we have some interesting ways to capture uncertainty in other ways, and I'll talk about that in a second.

135
00:16:03,360 --> 00:16:07,020
But I talked about the the boundary estimation first.

136
00:16:08,970 --> 00:16:17,160
So the black line that you see, we want it to be smooth and close to mimic like what a tumor would actually look like.

137
00:16:18,030 --> 00:16:23,700
So that just like translates to to requirements of of some function.

138
00:16:24,390 --> 00:16:35,910
It's got to be periodic with respect to like the angle and it's it should be differentiable so it makes it smooth, so satisfying.

139
00:16:35,910 --> 00:16:44,070
Those two things we have like sign cosine functions which are like the most obvious thing and then something called periodic baselines,

140
00:16:44,490 --> 00:16:52,440
which also works. But why? But yeah, there's, there's two ways always these the first one because it's the most obvious.

141
00:16:53,130 --> 00:17:02,010
So this figure just shows like how like a linear combination of basis functions and model like any arbitrary curve X by x prime.

142
00:17:03,690 --> 00:17:10,870
Yeah. So that's kind of what we want to do. And this is just like the mathematical representation of what I just said, if you're into that.

143
00:17:12,100 --> 00:17:21,400
So basically to estimate any given boundary, we just have to estimate a bunch of betas, which is just a bunch of parameters.

144
00:17:22,180 --> 00:17:25,690
And the number of parameters is changes with K.

145
00:17:25,930 --> 00:17:35,440
So we just like set K to some number. I think we use cable's five, which generates like 11 betas for each boundary.

146
00:17:36,370 --> 00:17:43,480
So it's a lot, but not too bad. And basically if you, if you increase K, you can like have a more wiggly boundary.

147
00:17:44,050 --> 00:17:53,590
If you decrease k like if you. If you like, set K to zero, you would just have a circle with radius theta zero.

148
00:17:55,510 --> 00:18:05,020
Yeah. And that's just kind of to say, like, you can choose gay however you want and you could imagine like different like disease mapping.

149
00:18:05,020 --> 00:18:10,100
You could probably use those to find like disease hotspots and you could just use a circle, but yeah.

150
00:18:11,200 --> 00:18:17,020
Oh, also. So everything I've showed you so far has had like one lesion in it.

151
00:18:17,290 --> 00:18:25,090
But you can imagine that somebody has two cancerous lesions in their prostate or zero cancerous lesions in their prostate,

152
00:18:25,810 --> 00:18:28,090
and we want to be able to estimate that, too.

153
00:18:29,230 --> 00:18:37,720
So we have to use this framework called reversible jump, M.S., M.S. because the number of things that we're.

154
00:18:38,760 --> 00:18:42,360
The number of boundaries that we're estimating is unknown.

155
00:18:44,220 --> 00:18:48,510
And we we don't want to assume that we know the number of boundaries like a priori.

156
00:18:48,540 --> 00:18:57,059
So we're just going to include that as another parameter in our M.S., M.C. And I'll talk more about that.

157
00:18:57,060 --> 00:19:04,450
But basically, if you can imagine, like several iterations where we're basically guessing, you know,

158
00:19:04,530 --> 00:19:14,669
where the cancer is like an iteration time, we may have this guess that there's like one small lesion down here, but then jump to iteration.

159
00:19:14,670 --> 00:19:21,510
153. I made these numbers up, obviously. Maybe at this point we're guessing that there's three different lesions.

160
00:19:22,020 --> 00:19:30,420
So we're going to be like in our parameter space, like jumping around is the guy who invented this method, the reversible jump.

161
00:19:31,560 --> 00:19:36,390
I found this quote on Google in somebody else's slides where they talked about Peter Green,

162
00:19:36,810 --> 00:19:41,190
but I don't know if he actually said it, but I think it's funny. So yeah.

163
00:19:43,020 --> 00:19:47,430
Yeah, we're in a Bayesian framework, so if you're not familiar,

164
00:19:48,270 --> 00:19:57,929
you should check it out because Bayes is really cool because you can basically do whatever you want and it allows like a lot of flexibility,

165
00:19:57,930 --> 00:20:04,620
but that's beside the point. So we have our posterior, which is basically just the likelihood times the prior.

166
00:20:04,890 --> 00:20:10,200
This is a lot of math, but just to show that the posterior is actually like a joint posterior.

167
00:20:10,920 --> 00:20:16,470
So the big Phi, that's just all the parameters for the boundaries and stuff that we have to estimate.

168
00:20:16,680 --> 00:20:21,570
And then M's the number of lesions that we're also trying to estimate.

169
00:20:21,810 --> 00:20:27,000
So you can see that the, the number of parameters is dependent on em.

170
00:20:27,180 --> 00:20:31,110
So the more boundaries that we have, the more parameters that we have to estimate.

171
00:20:32,730 --> 00:20:40,490
So that's why we got to use that reversal jump. Um, and here's where we incorporate the spatial component, our data.

172
00:20:40,500 --> 00:20:45,120
I'm using Z here. I changed it up. So I'm sorry about that. But Z is now Y is now a C.

173
00:20:46,410 --> 00:20:54,510
And so we basically just assume that each back was in each boundary and the healthy sort of outer region,

174
00:20:55,140 --> 00:21:01,590
we assume those are all independent nor multivariate normal distributions or Gaussian processes, processes.

175
00:21:02,970 --> 00:21:07,560
And then the sigma, this is where the spatial sort of correlation is going to be.

176
00:21:08,880 --> 00:21:16,740
And then we have this prior, which is the reason we love Bayesian, is we can just specify whatever prior we want and.

177
00:21:17,940 --> 00:21:22,030
Nobody will be mad at us. I'm trying to talk about that now. Okay.

178
00:21:22,050 --> 00:21:25,410
This is a lot of notation, so I really apologize. It's early.

179
00:21:25,800 --> 00:21:30,060
It's a lot. So feel free to just ignore me for a while while I talk about this.

180
00:21:30,070 --> 00:21:34,710
But if you're interested, we have some, like, cool priors that.

181
00:21:35,650 --> 00:21:38,950
Well, I think they're cool because they're very, like, oddly specific.

182
00:21:39,520 --> 00:21:44,079
And I'll talk about why so. Well, M is not M is just a uniform.

183
00:21:44,080 --> 00:21:53,230
So this is the number of of boundaries that we have. And then we can just specify some minimum value, usually zero, because it is possible that,

184
00:21:53,420 --> 00:21:57,190
you know, a patient has no cancer and then some maximum value.

185
00:21:57,610 --> 00:22:03,610
I think we use like M equals ten for the maximum possible, you know, cancerous lesions that somebody could have,

186
00:22:03,970 --> 00:22:09,580
which seemed conservative because I only saw I only ever saw like examples where there were like four.

187
00:22:09,610 --> 00:22:21,490
So we just have a conservative guess for this. But um, yeah, you can do whatever you want and then the beta and the centroid are here, so.

188
00:22:23,500 --> 00:22:31,629
This is like a lot. I know. But basically all we're doing here is we're slapping on this indicator function,

189
00:22:31,630 --> 00:22:36,160
which just prevents, like, boundaries from overlapping in the iteration.

190
00:22:36,490 --> 00:22:39,549
And it's this kind of weird mathematical notation.

191
00:22:39,550 --> 00:22:46,300
But all we're saying is, if we propose two boundaries that are overlapping with each other,

192
00:22:47,980 --> 00:22:52,700
we're just going to basically set weight that at zero probability.

193
00:22:53,200 --> 00:23:04,120
So it gets rejected every time in the CMC and RB does sort of have a normal zero one distribution,

194
00:23:04,900 --> 00:23:13,120
except this is like the intercept beta zero and we're going to set a zero to the radius of

195
00:23:13,120 --> 00:23:20,410
the image space because that kind of controls like the overall size of the boundaries and.

196
00:23:21,770 --> 00:23:32,890
Yeah. Everything else is pretty straightforward. Oh, here, we're going to set the means of the Gaussian processes.

197
00:23:33,380 --> 00:23:38,870
The means should be higher in the cancerous areas.

198
00:23:39,440 --> 00:23:47,450
So we, like, do this thing with the half normal distribution forcing those means to be larger than the means of the healthy region.

199
00:23:48,020 --> 00:23:55,580
And that's based on, you know, what that heat map looks like where the the cancerous regions have like a higher score.

200
00:23:56,180 --> 00:24:01,880
So we're just forcing them to find those areas. And then all of the variance priors are.

201
00:24:03,310 --> 00:24:08,880
Just really basic. So it's nothing to talk about. Okay.

202
00:24:09,240 --> 00:24:10,719
So yeah, I getting it.

203
00:24:10,720 --> 00:24:18,160
So like with three regions when you have like each region has its own mean is like four means and then they have two variances within the region.

204
00:24:18,170 --> 00:24:25,090
Yeah, yeah. Yeah. So we're assuming that each region is independent with its own Gaussian process.

205
00:24:25,390 --> 00:24:29,650
So it's own mean its own, you know, spatial covariance.

206
00:24:30,940 --> 00:24:34,260
And that sort of also allows us to say, um.

207
00:24:35,980 --> 00:24:45,310
Have some sort of measure of how confident we are about certain lesions, like certain lesions will have a very high mean a very high score.

208
00:24:45,520 --> 00:24:53,180
In other ones, they may have a distinct sort of distribution from the healthy tissue, but the score is slightly less.

209
00:24:53,190 --> 00:25:00,400
So we can report those means, which is like one way that we can talk about like the uncertainty of our estimates.

210
00:25:02,080 --> 00:25:05,080
But yes. Okay.

211
00:25:05,090 --> 00:25:10,010
So talked about reversible job. So these are what the actual jumps look like.

212
00:25:10,010 --> 00:25:20,390
We have four types of jumps in our CMC. So as we're like iterating along, we can propose a birth or death of a boundary.

213
00:25:21,620 --> 00:25:31,310
So when you propose a birth and you propose this new boundary somewhere in your image space with a distinct Gaussian process,

214
00:25:32,360 --> 00:25:39,019
and analogously you have the death step or jump where you're getting rid of a boundary.

215
00:25:39,020 --> 00:25:45,230
And then all the data that was inside here is now assumed to be part of the healthy region of the data.

216
00:25:46,250 --> 00:25:55,070
And then we have these split and merge steps which just take one boundary and split it or take two boundaries and merge them together.

217
00:25:55,970 --> 00:26:02,660
The merge is a little weird because just the way I set it up so like any boundaries and merge

218
00:26:02,660 --> 00:26:12,680
together so would actually like force all of the healthy data to be inside now which is interesting,

219
00:26:12,680 --> 00:26:16,760
but I didn't know a better way. So yeah.

220
00:26:17,030 --> 00:26:23,090
So if you have just one boundary, I didn't want to overwhelm you with like three boundaries moving around.

221
00:26:24,800 --> 00:26:30,410
So through the CMC we're basically just changing the boundary a little bit,

222
00:26:30,410 --> 00:26:38,360
proposing that move and if the likelihood is higher, we're going to accept it.

223
00:26:39,290 --> 00:26:47,899
So this boundary here is trying to find the area with the higher mean, with different covariance structure.

224
00:26:47,900 --> 00:26:54,560
This is simulated data. Obviously nobody has a tumor that's square shaped, so that would be crazy.

225
00:26:54,950 --> 00:27:01,190
So this is simulated data and just like what the boundary does as it iterates.

226
00:27:01,400 --> 00:27:12,620
So we start it just a guess with this big circle and then it slowly like moves around and the centroid the way that the centroid moves is,

227
00:27:12,620 --> 00:27:13,730
is interesting.

228
00:27:14,030 --> 00:27:24,530
So we don't like sample the centroid and CMC, we just force it to be the geometric mean of the data of the locations within the boundary.

229
00:27:24,830 --> 00:27:31,670
So the centroid sort of updates as the boundary stretches out, the centroid will shift and then we'll back off.

230
00:27:32,060 --> 00:27:36,140
But that's the whole thing. But yeah, that's how it moves around, so it's fun to watch.

231
00:27:36,710 --> 00:27:41,390
I did spend like three years of my PhD just watching this.

232
00:27:43,130 --> 00:27:47,750
Yeah, so it was a good time. Oh yeah.

233
00:27:47,750 --> 00:27:53,329
So I forgot to mention that computationally this is very hard because we have pretty

234
00:27:53,330 --> 00:27:59,390
dense spatial correlation matrices and we have a fairly high amount of data.

235
00:28:00,380 --> 00:28:06,820
So there's all kinds of strategies that people have proposed to deal with, you know, speeding up your MCI.

236
00:28:06,860 --> 00:28:18,230
MCI, I did not create any of these, I'm just using them and I encourage you if you have a slow mo CMC there are lots of things you could do.

237
00:28:19,160 --> 00:28:24,830
So I used blocking which is so we have so many parameters, we have so many boundaries, so many parameters.

238
00:28:25,070 --> 00:28:31,910
So if you block them together and sample them as a block, it's obviously faster than sampling them one at a time.

239
00:28:33,980 --> 00:28:43,730
Also, we use adaptive proposal densities, so for each block you can imagine that a block of parameters may be correlated,

240
00:28:44,630 --> 00:28:47,450
especially the way that we've blocked them. We've blocked boundaries together.

241
00:28:48,890 --> 00:29:00,020
So these adaptive proposal densities allow the allow you to learn the correlation between your parameters, sort of as you're iterating through.

242
00:29:00,560 --> 00:29:05,900
So that's really cool. And we also use some likelihood approximations.

243
00:29:06,560 --> 00:29:15,980
So I showed you our likelihood with this the covariance matrix with B that showed you H and how we use a function to find that.

244
00:29:16,400 --> 00:29:21,230
So that will give you like a very dense big covariance matrix.

245
00:29:22,610 --> 00:29:25,999
So obviously that's going to be very hard to take.

246
00:29:26,000 --> 00:29:30,980
The inverse and determinant of it will be very slow, very costly.

247
00:29:31,610 --> 00:29:39,019
So tapering basically just takes everything off of the diagonal and puts it to zero.

248
00:29:39,020 --> 00:29:46,340
Not everything, but take some of the. The Matrix and basically pushes it to zero so it's faster to invert.

249
00:29:46,670 --> 00:29:54,910
And the assumption there is just that two locations that are further away from each other are not going to be correlated.

250
00:29:54,920 --> 00:29:59,420
So we'll just assume that the correlation is sort of like. Close together.

251
00:30:01,470 --> 00:30:06,030
Yeah, it's an approximation, but it seems like an assumption, at least in our case.

252
00:30:06,600 --> 00:30:08,460
But there's a lot of other things you can do to.

253
00:30:10,300 --> 00:30:18,100
And I've Googled a lot of them and these are the ones that were easy to implement in the CMC, so that's the ones we used.

254
00:30:19,510 --> 00:30:24,180
Okay, so how long does it take to look at them?

255
00:30:24,700 --> 00:30:29,040
The amount of time is dependent on the number of boundaries that you're going to estimate.

256
00:30:29,050 --> 00:30:36,070
So if you have data that has like five cancerous lesions, it's going to take a lot longer than if you have data with nothing.

257
00:30:36,820 --> 00:30:40,360
Because in the case where you have none, there's no boundaries to estimate.

258
00:30:40,960 --> 00:30:45,820
And boundaries will pop up in the MSI as it's going through, but there's just less of them, so there's less parameters.

259
00:30:47,620 --> 00:30:56,730
So in the case where there's just like one lesion. Like 30 minutes or less in the case where there's, you know,

260
00:30:56,790 --> 00:31:02,480
several it can take a few hours and that's with all of the approximations I just talked about.

261
00:31:02,490 --> 00:31:16,530
So yeah. Yes, it can be slow but it was it was okay enough for our collaborators in radiology at so that's good.

262
00:31:17,400 --> 00:31:20,820
That's who I'm trying to make happy.

263
00:31:21,210 --> 00:31:25,680
So you can imagine at the end of all of this.

264
00:31:27,600 --> 00:31:35,069
M.S., M.S., you have all these iterations and they all have like a different number of boundaries.

265
00:31:35,070 --> 00:31:39,510
They all look different. So we need some way of summarizing these together.

266
00:31:41,100 --> 00:31:51,630
So what we'll do basically is assume that boundaries that are sort of in the same location are the same lesion.

267
00:31:52,650 --> 00:31:57,090
So a boundary may die and then be reborn.

268
00:31:58,140 --> 00:32:03,150
And we're going to assume that that is the same as that which makes sense.

269
00:32:04,380 --> 00:32:07,770
So you basically just find these boundary groups.

270
00:32:07,860 --> 00:32:12,570
So in this situation, we have three boundary groups blue, yellow and red.

271
00:32:13,350 --> 00:32:16,350
And for each one, we can compute like an average boundary.

272
00:32:16,560 --> 00:32:20,510
Incredible band. Yeah.

273
00:32:20,600 --> 00:32:25,249
There's some math that goes along with that, but it's not bad. Yeah.

274
00:32:25,250 --> 00:32:35,840
So talk about different types of uncertainty so we can imagine the lesion uncertainty and there's actually like two components to this.

275
00:32:36,080 --> 00:32:42,500
So I was just talking about we have this score like the average score for each boundary

276
00:32:42,890 --> 00:32:50,180
and then we also have the proportion of CMC samples which contain that boundary.

277
00:32:51,560 --> 00:33:01,840
So if we have like 10,000 CMC iterations and a boundary popped up one time, then we can kind of imagine that we're not certain that there is cancer.

278
00:33:01,850 --> 00:33:05,270
They were pretty uncertain or pretty certain that there's not cancer there.

279
00:33:05,420 --> 00:33:10,490
But if a boundary is in every single CMC iteration,

280
00:33:10,700 --> 00:33:17,750
then we're pretty certain that there's something going on in that area and that's different from the healthy region of data.

281
00:33:18,050 --> 00:33:19,700
So that's like lesion uncertainty.

282
00:33:19,970 --> 00:33:28,370
Now we also have the boundary uncertainty, which is those point wise, like credible bands that we can generate for each boundary.

283
00:33:28,370 --> 00:33:32,900
So there's all kinds of ways we can be uncertain, which is fine.

284
00:33:34,340 --> 00:33:43,850
So this is like what the lesion uncertainty could look like. So on the left, we have the the data derived from the imaging parameters.

285
00:33:44,180 --> 00:33:52,460
So you can see at the top, like this is an example of a data set that does not have very strong signal to noise ratio.

286
00:33:53,000 --> 00:33:59,450
And this is actually pretty common in our data. So the ground truth is from the pathologist annotations.

287
00:34:01,430 --> 00:34:16,310
So basically our lesion uncertainty is counting the proportion of time that we think there's a unique sort of Gaussian process in this area.

288
00:34:17,810 --> 00:34:23,360
So we're very certain that there's something going on here, and we are right about that.

289
00:34:24,230 --> 00:34:29,870
And we're a little bit less certain that there's something going on down in this corner,

290
00:34:31,190 --> 00:34:37,610
and there actually truly is something going on in that corner. But we also think that there might be something going on at the top and there's not.

291
00:34:38,270 --> 00:34:41,760
So this is just a way for us to present, you know,

292
00:34:41,840 --> 00:34:50,360
where maybe like the biopsy should be targeted for like pretty sure that there's something here, maybe something here.

293
00:34:51,170 --> 00:34:57,920
And that's actually very helpful for our team of clinicians when they're trying to.

294
00:35:00,150 --> 00:35:03,660
Target the biopsies. So they really like this, which is great.

295
00:35:04,830 --> 00:35:09,090
So on the left, that's what they say. So is this red, which is like bad?

296
00:35:09,570 --> 00:35:14,950
Yeah, blue and yellow. I mean, is that different degree of badness or is it like blue and yellow?

297
00:35:14,970 --> 00:35:21,000
Just not bad? Yeah. Well, so everyone's like data comes out to be different, but these scores are.

298
00:35:21,690 --> 00:35:28,379
So how will you generate the scores is like a I think they're cross validated across like 30 or 40

299
00:35:28,380 --> 00:35:37,980
patients and they generate this like univariate data based on four or five imaging parameters.

300
00:35:38,340 --> 00:35:41,880
So yeah, like red means that.

301
00:35:43,080 --> 00:35:46,080
There's a high like certainty that there's cancer there.

302
00:35:47,640 --> 00:35:54,390
And blue is like a very low probability that there's cancer there based on the cross validated model.

303
00:35:56,640 --> 00:35:59,880
And that's using its reign on this like ground truth data.

304
00:36:00,690 --> 00:36:06,780
So that's how we generate this. But we're trying to skip obviously skip this.

305
00:36:07,560 --> 00:36:12,810
This ground truth is from the pathologists from the excised prostates.

306
00:36:13,560 --> 00:36:19,050
So, yeah, we're trying to go from this data to to over here size regression.

307
00:36:19,710 --> 00:36:25,630
So yeah, red bad. So that's the bottom line of the program, right?

308
00:36:25,650 --> 00:36:32,040
You got the little, little green things we would like to have as the left is just yellow.

309
00:36:33,020 --> 00:36:36,469
So now it's. Yeah, yeah, it's just. It's neighbors, right?

310
00:36:36,470 --> 00:36:49,100
It's just bigger. Yeah. Yeah. So you can see, like, there's a pretty obvious lesion in the left side of this prostate, which is truly there.

311
00:36:50,210 --> 00:36:53,260
And then there's these. I don't know. Three other ones.

312
00:36:53,270 --> 00:36:57,040
I guess you can count this as one lesion. And then there's this mine.

313
00:36:57,050 --> 00:37:02,120
I don't know if that's actually true, but that's there. So, yeah.

314
00:37:02,120 --> 00:37:06,979
So the data doesn't always like capture those lesions.

315
00:37:06,980 --> 00:37:10,760
Well, and it could be that these ones I don't have this information on this slide,

316
00:37:10,760 --> 00:37:14,720
but it could be that these ones are like low grade and this one's like a higher grade.

317
00:37:15,470 --> 00:37:18,920
So that's something that we can, you know, get estimates of.

318
00:37:19,700 --> 00:37:26,929
We obviously have this these two lesions estimated fairly well.

319
00:37:26,930 --> 00:37:31,999
And then we also have this one and we're we're only like 25% of the time.

320
00:37:32,000 --> 00:37:37,700
This one is showing up in our M.S., IMC, so we're not very certain that there's something here, but there actually was.

321
00:37:38,510 --> 00:37:44,780
And then we also have we think that there's something going on over here and there's not.

322
00:37:44,780 --> 00:37:45,950
So we're actually wrong about that.

323
00:37:45,950 --> 00:37:54,470
But that's I mean, you can see like why we have that guess here in the data, there's like a very sharp change right here between the.

324
00:37:55,850 --> 00:38:02,250
For some reason, some something's going on there. But yeah, the data, it has a lot of noise and it's, it's not always great.

325
00:38:02,260 --> 00:38:05,680
So that's what we're trying to work around. That makes sense.

326
00:38:09,430 --> 00:38:13,660
Yeah. So this is again, just showing the boundary, like the credible bands that you've already seen.

327
00:38:16,100 --> 00:38:19,910
Okay. Now I'm going to talk about the 3-D, which I think is way cooler.

328
00:38:20,180 --> 00:38:25,910
So if you were asleep for all that time to wake up, this should be more interesting.

329
00:38:26,870 --> 00:38:34,250
So, yeah, what Jeremy is talking about is you can imagine that I've just been showing you slices of imaging data,

330
00:38:35,480 --> 00:38:40,460
but in reality, somebody's imaging data is a 3D set of data.

331
00:38:41,750 --> 00:38:48,980
So we're going to because this it starts we get really computationally intense with this size of data.

332
00:38:50,240 --> 00:38:56,210
We're going to just assume that there's a single lesion and remove that reversible jump component to save time.

333
00:38:56,690 --> 00:39:06,230
And this was so I could graduate. So, yeah, if you're trying to the finish line, just make a bunch of terrible assumptions and keep going.

334
00:39:08,060 --> 00:39:12,740
Yeah, theoretically, it's a beautiful extension to the 2D.

335
00:39:12,950 --> 00:39:16,250
It's just that computationally it's not fun to deal with.

336
00:39:17,690 --> 00:39:23,450
So the boundary that I showed you before, it looks very similar.

337
00:39:24,380 --> 00:39:29,720
All we've done here is our betas are now functions of an angle.

338
00:39:30,320 --> 00:39:34,090
Instead of just being a coefficient, it's now function.

339
00:39:34,590 --> 00:39:41,850
So two angles here. And it can't just be any function.

340
00:39:44,820 --> 00:39:51,930
I thought it would be an easy extension, but it turns out that this guy named John figured out this expansion.

341
00:39:52,890 --> 00:40:02,160
So you have to use these specific theta functions to ensure that the polls are continuous and they like a touch.

342
00:40:02,160 --> 00:40:07,040
And it's not just like weird and wonky at the polls. So we'll just do that.

343
00:40:07,050 --> 00:40:10,830
We'll copy what his work and cite him. Thank you.

344
00:40:11,340 --> 00:40:24,480
And okay. So what I've done here is simulated a bunch of possible lesions, shapes to see what that boundary function could do.

345
00:40:26,130 --> 00:40:29,520
And this is what they look like there.

346
00:40:29,670 --> 00:40:33,410
I don't know why the plotting software that I use, like, makes them look bubbly.

347
00:40:34,080 --> 00:40:38,010
Just ignore that. Plotting 3D is.

348
00:40:39,320 --> 00:40:44,480
I mean, it's harder than it looks. But, yeah, I found all these fun shapes.

349
00:40:44,780 --> 00:40:54,470
Obviously, a cancerous lesion will never be like an x, but I thought it would be fun to try to estimate that.

350
00:40:56,090 --> 00:41:03,410
So these are like the estimated boundary services that we estimate for some simulated Gaussian process data.

351
00:41:04,550 --> 00:41:08,330
So yeah, they're like some of them are better than others.

352
00:41:09,020 --> 00:41:12,110
So this like egg shaped is like pretty easy to estimate.

353
00:41:13,070 --> 00:41:20,450
Anything with a sharp angle is not so good, but it's fun to look at nonetheless.

354
00:41:22,490 --> 00:41:26,000
So yeah, that's exciting. And this would be really cool to look at.

355
00:41:26,000 --> 00:41:34,610
You know, if you're a clinician and radiology and you're trying to locate or estimate what somebody has cancerous lesion looks like.

356
00:41:36,020 --> 00:41:44,960
They were pretty excited about this. So and then I told them, you'll have to wait like a week to get your results, which so, you know, pros and cons.

357
00:41:45,810 --> 00:41:50,720
So, yeah, this is really hard to visualize. I tried really hard to make this like.

358
00:41:51,790 --> 00:41:55,270
Something that you could see, but I wasn't very successful.

359
00:41:55,480 --> 00:41:59,590
But these are like the credible you have credible surfaces now. It's in a credible bands.

360
00:42:00,700 --> 00:42:03,429
So you can see that there's like three different shades of gray.

361
00:42:03,430 --> 00:42:10,060
You're showing the credible surface, which is not particularly fun to look at, but we can do it.

362
00:42:11,650 --> 00:42:19,210
Yeah, like I said, it's computationally very difficult now because we've just increased our size of the data by ten.

363
00:42:20,620 --> 00:42:28,360
And you know, before we were assuming that like one slice was correlated, spatially correlated,

364
00:42:28,960 --> 00:42:32,860
but now you can imagine that they're spatial correlation going this way and this way.

365
00:42:33,880 --> 00:42:37,750
There's no reason that a voxel should only be correlated with things in one slice.

366
00:42:37,750 --> 00:42:42,250
It could be correlated with slices of time and then front.

367
00:42:43,690 --> 00:42:48,400
So yes, the spatial covariance matrix has just completely blown up in size.

368
00:42:50,050 --> 00:42:57,670
And so what I did to graduate was I asked this question, what if we just drop the spatial component of the model?

369
00:42:59,410 --> 00:43:09,490
And yeah, it's not my proudest moment, but I was trying to graduate, so I didn't do that because I couldn't wait years for the CMC to run.

370
00:43:11,050 --> 00:43:20,950
And basically what I found was if there's a very strong signal, then dropping the spatial component of the model is is not too bad.

371
00:43:22,720 --> 00:43:26,440
So when the data shows like a very obvious lesion,

372
00:43:27,310 --> 00:43:42,280
we can just assume the data are independent and you won't lose out on your sensitivity if there's a weak signal, if the spatial model is way better.

373
00:43:43,330 --> 00:43:51,340
So what I did is I just looked at data where the signal was very strong and I ignored all the rest.

374
00:43:52,300 --> 00:43:56,170
And that's how I graduated on time. And that's what I'll show you here.

375
00:43:56,470 --> 00:43:59,830
So this top part is our data.

376
00:44:00,100 --> 00:44:05,110
So these are all this like things from one person's prostate imaging data.

377
00:44:06,130 --> 00:44:14,980
We also have these slices from the so they underwent surgery, prostate was removed and then sliced up.

378
00:44:16,090 --> 00:44:21,490
The slices are not the same slices as here, but I've tried to line them up as best as I could.

379
00:44:22,450 --> 00:44:32,470
And you can kind of see that there's the pathologist has identified in each slice this one lesion in the corner.

380
00:44:32,750 --> 00:44:43,209
I think I've you've seen this data before but in the context of two D and this is our partitioning result which

381
00:44:43,210 --> 00:44:50,380
does know very fairly well but we've made that big assumption that the data is not spatially correlated.

382
00:44:50,380 --> 00:44:54,190
So it's okay and this is fine.

383
00:44:55,570 --> 00:45:06,130
You can generate these like three d maps of the lesion which the clinicians get really excited about showing them this boundary.

384
00:45:06,310 --> 00:45:11,350
And there's like a little weird, wonky bit here where the, the boundary goes outside and then comes back in.

385
00:45:11,350 --> 00:45:15,070
So ignore that. Oh yeah.

386
00:45:15,130 --> 00:45:19,270
And so that's like pretty much it. I'll get I save time for questions.

387
00:45:19,510 --> 00:45:28,000
And if you're interested in doing a spatial analysis, there are so many good resources for you and these are actually links.

388
00:45:28,150 --> 00:45:32,110
So if you look on the canvas, you can click on these.

389
00:45:33,820 --> 00:45:40,540
Any paper by this guy is good. Look for his name if you want to apply any spatial methods.

390
00:45:41,650 --> 00:45:47,410
And this is my email. If you're doing spatial work and you run into problems, you can email me.

391
00:45:47,890 --> 00:45:53,050
I'll get really excited. Yeah. If anybody has questions, I'm happy to take them now.

392
00:46:00,570 --> 00:46:06,150
Right. So I'm curious, did you compare like the 2D versus the 3D?

393
00:46:06,360 --> 00:46:11,040
Like you gain a lot by looking at 3D. Yeah. So that's something I wanted to do and didn't get to.

394
00:46:11,910 --> 00:46:23,190
So you can imagine that you could just apply that 2D method like ten times in parallel and that would be like a lot faster than doing the 3D version.

395
00:46:25,330 --> 00:46:33,940
The problem with that is, is less it's more like theoretically a problem because you could have a lesion in one

396
00:46:33,940 --> 00:46:42,819
slice and no lesion here and they might not line up very well and also eat theoretically.

397
00:46:42,820 --> 00:46:49,870
And I haven't tested this, but theoretically there's more information to gain from looking at all the data together.

398
00:46:51,980 --> 00:47:00,530
You know, like a maybe a false positive that shows up in one slice, would look like nothing in the slices right next to it.

399
00:47:01,130 --> 00:47:06,690
So that when, you know, you're less likely to flag it as a false positive, theoretically.

400
00:47:07,990 --> 00:47:11,360
Yeah. I mean, you could just supply it. That was our first idea.

401
00:47:11,360 --> 00:47:16,860
And then I was like, That's not fun. I think that would be a middle ground between, like, the independence, right?

402
00:47:16,880 --> 00:47:19,250
Yeah, I'm getting that defense slice. Yeah.

403
00:47:19,490 --> 00:47:26,240
And like, there are there are things that you could do which like all of the things I talked about, like the tapering,

404
00:47:26,240 --> 00:47:33,080
like you could do that in a more extreme way, but then leave tapered so much that it's like, what?

405
00:47:33,590 --> 00:47:38,629
You might as well just be assuming independence. But, yeah, it's tough.

406
00:47:38,630 --> 00:47:51,110
And there's, there's like these things though. And MGP is nearest neighbor Gaussian process, which is a way of modeling the the Gaussian process data.

407
00:47:51,800 --> 00:47:55,250
And this is like proven to be very, very fast and very, very good.

408
00:47:55,910 --> 00:48:06,740
And what it does is it assumes that each location is just correlated, like with its neighbors, which is a, you know, like.

409
00:48:07,670 --> 00:48:09,500
A pretty good assumption in practice.

410
00:48:10,280 --> 00:48:22,550
But the problem is for us, we can't really use it because the neighbor the neighbor structure would change as the boundary moves.

411
00:48:22,790 --> 00:48:30,320
So if a voxel is now in a boundary that it wasn't before, it's its set of neighbors are different.

412
00:48:30,620 --> 00:48:38,990
So having to update the the set of neighbors every time is so computationally intensive that it makes this method not fast anymore.

413
00:48:40,010 --> 00:48:41,990
So that was like a very disappointing finding.

414
00:48:42,000 --> 00:48:50,920
But yeah, if you're ever using or have Gaussian process data and you can apply this, definitely do that.

415
00:48:50,930 --> 00:48:57,710
It's very fast and good. Yeah, that was like a very roundabout answer to your question.

416
00:48:58,520 --> 00:49:03,170
So so then the neighbors need to be updated because you don't want to have them within and outside the boundary or.

417
00:49:03,740 --> 00:49:07,070
Yeah. So because we're assuming that that the.

418
00:49:08,080 --> 00:49:14,230
They're independent regions with their own means and covariance structures.

419
00:49:15,790 --> 00:49:20,740
Instead of neighbors is like restricted to be in the boundary that it's in.

420
00:49:21,340 --> 00:49:29,030
And so every time you update the boundary, you have to update the neighbor, the list of possible neighbors, which, you know,

421
00:49:29,050 --> 00:49:36,820
if you're not doing that, you just generate your neighbors list one time at the beginning and then you let it run.

422
00:49:37,150 --> 00:49:41,030
But. Yeah. Science research.

423
00:49:43,650 --> 00:49:49,890
And any other questions. Yeah.

424
00:49:50,250 --> 00:49:57,630
And really matter if each patient could have different prostate size or structure.

425
00:49:58,800 --> 00:49:59,024
Yes.

