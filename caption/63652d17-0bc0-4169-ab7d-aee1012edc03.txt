1
00:05:33,000 --> 00:05:48,000
Hello! Good morning. Everyone let's get started because people are through calling in So today we first review the the qu from like lecture 9 together.

2
00:05:48,000 --> 00:05:56,000
Okay, this is the quiz about symbol in your regression.

3
00:05:56,000 --> 00:06:05,000
Question number one any about the gate? Are you studying the relation between physical and the electoral growth of primary school children?

4
00:06:05,000 --> 00:06:08,000
Age, one to grade, one to 6 at each grade level.

5
00:06:08,000 --> 00:06:21,000
She knows that a correlation between the height of the children, the size of the vocabulary 0 students in the school the correlation is likely to be which of the following can draw a picture this: is the exact We talked to a going

6
00:06:21,000 --> 00:06:45,000
cloud. So any of you you say something about it.

7
00:06:45,000 --> 00:06:52,000
You would be positively correlated, because you tend to increase your height as you increase your grade level.

8
00:06:52,000 --> 00:07:00,000
And typically how did you increase your grade level you'll increase your intellectual growth?

9
00:07:00,000 --> 00:07:05,000
So that will be a positive correlation perfect. Thank you, Bar very much, Sarah.

10
00:07:05,000 --> 00:07:12,000
Exactly right, even though they say here the correlation between hide and the side of vocabulary.

11
00:07:12,000 --> 00:07:15,000
Within each grade is 0. I don't want you to pull different grapes together.

12
00:07:15,000 --> 00:07:22,000
The great serve as a controlling factor. to give you this correlation, which is positive, that is strongly positive.

13
00:07:22,000 --> 00:07:32,000
After this quiz i'll have to show you some example I find online about similar kind of a correlation which I feel really fine to look at. I might make you to rethink about your understanding of correlation.

14
00:07:32,000 --> 00:07:42,000
And politician, and other things what's the number 2 Yeah, Professor Joe. For some reason I also selected the the positive option.

15
00:07:42,000 --> 00:07:47,000
But it told me that I was wrong, and the right answer was cannot be determined.

16
00:07:47,000 --> 00:07:53,000
I know what went wrong with com boss. but oh, really,

17
00:07:53,000 --> 00:08:02,000
Yeah, Yeah. So that happened for sure. yeah, we kind of we kind of maybe something was all because I scored like 6%.

18
00:08:02,000 --> 00:08:10,000
On the whole, the whole quiz this time. time. Okay,

19
00:08:10,000 --> 00:08:18,000
So. yeah, Sorry they'll hear that so yeah how about we take a note of this and go back to look cause we have your route.

20
00:08:18,000 --> 00:08:25,000
Call to see what's going on anybody else run into the same situation.

21
00:08:25,000 --> 00:08:32,000
Me, too, I did the same thing. This is fine, that is strange.

22
00:08:32,000 --> 00:08:36,000
Yeah, I have positive defense time, and it said it was wrong.

23
00:08:36,000 --> 00:08:42,000
And then I I went back, and I kind of thought about it, and out of the answers.

24
00:08:42,000 --> 00:08:47,000
I chose negative, and it said it was correct the second time.

25
00:08:47,000 --> 00:08:57,000
Oh, okay, Sorry i'll hear that so let me see if is a ta here.

26
00:08:57,000 --> 00:09:06,000
Yes, yeah. could you take a note of we can go back actually look at their walk, or to see what what are you talking with?

27
00:09:06,000 --> 00:09:11,000
I'm in the system exactly not behaving itself all of that for that.

28
00:09:11,000 --> 00:09:15,000
Yeah, if if anybody else got the same issue feel free to live up, so we'll double check.

29
00:09:15,000 --> 00:09:20,000
But yeah from my side so far I don't see any problem.

30
00:09:20,000 --> 00:09:24,000
I'll i'll double check i'll make sure you're not in school.

31
00:09:24,000 --> 00:09:30,000
You you you deserve. Thank you for letting me letting us know.

32
00:09:30,000 --> 00:09:40,000
Okay, Question 2. which of the following statements Reflect how a State regression line computing.

33
00:09:40,000 --> 00:09:52,000
So choose every response you believe to be correct. alright, Maybe we just you know, this supposed to be a multiple toy.

34
00:09:52,000 --> 00:09:59,000
Let's that's the goal robot the sum of square squared error is as small as possible.

35
00:09:59,000 --> 00:10:08,000
Anybody think this is right or wrong.

36
00:10:08,000 --> 00:10:14,000
I'd say that's correct thank you that's the definition of the D Square.

37
00:10:14,000 --> 00:10:27,000
Remember we we do this so called the least square method which minimize the Thomas Square. of all the arrow, the arrows between the predicted value and observe the value, and then the sum of apple error as small as possible so that will

38
00:10:27,000 --> 00:10:34,000
be false. The first one is correct, the second line is incorrect, because if I minimize the square error in the meantime you're not ready, and then minus the absolute error, right?

39
00:10:34,000 --> 00:10:42,000
So it's Yeah, you could actually you know you you wonder why do we have to do the square, or not the sum of absolute error?

40
00:10:42,000 --> 00:10:47,000
There are many reasons why don't the reason being a squared. I already turned out to be mathematically easier Vd. but not the absolute error.

41
00:10:47,000 --> 00:10:55,000
It's actually fathers with all Take a computer the square error actually has a closed form solution, as I showed earlier. Right? That's what people did.

42
00:10:55,000 --> 00:10:59,000
The leaf car was anybody 300 years ago, and they have no computer to minimize the absolute area.

43
00:10:59,000 --> 00:11:08,000
You need to come during right the algorithm. But there is a regression, and that's called leave absolute error kind of thing, you know.

44
00:11:08,000 --> 00:11:13,000
Lisa's least absolute deviant regression so there's a different kind of regression.

45
00:11:13,000 --> 00:11:17,000
You minimize the other type of error. they have different properties. You can imagine.

46
00:11:17,000 --> 00:11:26,000
If you sum if you minimize the sum of apps to error, it's actually more robust because you know for your square Arab, you know the outer becomes even online.

47
00:11:26,000 --> 00:11:35,000
Right. So it's actually a more sensitive to all that So the sum of absolute error actually has some from benefits being robbed and other things.

48
00:11:35,000 --> 00:11:39,000
But for for the thing we learned minimize the Thomas Square in the Arrow, the 13.

49
00:11:39,000 --> 00:11:43,000
The line goes through more points than any other possible straight line.

50
00:11:43,000 --> 00:11:55,000
Anyone want to say something about it by them I think that's false because it actually doesn't have have to go through a handy of the point exactly absolutely right.

51
00:11:55,000 --> 00:12:00,000
The the line. doesn't have to go to any as last you have 3 more points right.

52
00:12:00,000 --> 00:12:08,000
If you want to have 2 points of port the line would just go through that to a point, a video regression line with 2 data points, sort of the filling right?

53
00:12:08,000 --> 00:12:13,000
So as far as i'm more than 3 point the line doesn't have to go to any point but you may actually by chance go through some point.

54
00:12:13,000 --> 00:12:17,000
But there's no guarantee of anything the last one.

55
00:12:17,000 --> 00:12:20,000
The same number points are below and above the regression line.

56
00:12:20,000 --> 00:12:29,000
Anyone think this right along

57
00:12:29,000 --> 00:12:37,000
That's false Yeah, I can talk to you You can imagine right

58
00:12:37,000 --> 00:12:43,000
There should be points on both sides of the line right because when you're trying to minimize the sum of squares.

59
00:12:43,000 --> 00:12:46,000
If all the points are line on 1 one side of the line, you should lower the line right?

60
00:12:46,000 --> 00:12:53,000
So eventually there should be point on both sides of line. But the number of points do not have a mind map mash right?

61
00:12:53,000 --> 00:12:59,000
You could have a 1 point above, but which is very far, which balance all all the remaining points below.

62
00:12:59,000 --> 00:13:04,000
So the demo point above the below the line doesn't have to be the same.

63
00:13:04,000 --> 00:13:07,000
So essentially, if you minimize one metric, you cannot minimize the other Right?

64
00:13:07,000 --> 00:13:10,000
So here the metric is the sum of square error and that's it.

65
00:13:10,000 --> 00:13:16,000
Nothing else is guaranteed so I know that's that's kind of tricky because I say it is. I mean the problem.

66
00:13:16,000 --> 00:13:20,000
Say it's a multiple choice, but turn out to be a single toys, or some of you might dial yourself.

67
00:13:20,000 --> 00:13:26,000
Am I tweeting the right thing? But yeah, that make it unnecessarily hard.

68
00:13:26,000 --> 00:13:38,000
Maybe, but you know that's basically a test of your knowledge and any questions so far

69
00:13:38,000 --> 00:13:48,000
Okay. So the the third figure, this is a little Yeah, whatever you can. You can zoom in right the page to see this.

70
00:13:48,000 --> 00:13:52,000
Let me zoom in

71
00:13:52,000 --> 00:14:02,000
Okay, hold this help. This figure shows the the Gdp per capita of each country.

72
00:14:02,000 --> 00:14:07,000
Where there's this is the life expectancy in you in our country.

73
00:14:07,000 --> 00:14:13,000
I don't know which year the data was taken Nevertheless, you know they show the country.

74
00:14:13,000 --> 00:14:18,000
I think. you see that this is pretty interesting.

75
00:14:18,000 --> 00:14:21,000
Gather plot. it's still fundamentally it's guidelines.

76
00:14:21,000 --> 00:14:31,000
But somehow they overlay other information. Bombho, the caller of the country shows which content than they are from right, and the the size of the country shows the population.

77
00:14:31,000 --> 00:14:38,000
Ivd. So the basic over the other kind of categorical and confused variable on top of Canada plan.

78
00:14:38,000 --> 00:14:42,000
That's why you want to show you know 3 or more variable in one plot.

79
00:14:42,000 --> 00:14:46,000
This is what you can do, you know, you make the plus part of to read, but make it more information, then, right?

80
00:14:46,000 --> 00:14:51,000
So it's a pros and count i'll probably do so.

81
00:14:51,000 --> 00:14:58,000
Let's. But our point is to speed the regression so you can even know the size of the country. and the the caller of the country. right?

82
00:14:58,000 --> 00:15:01,000
Just think about this is a scatterplot. So number one.

83
00:15:01,000 --> 00:15:06,000
This is again malibu, Twice, if a regression line worth it.

84
00:15:06,000 --> 00:15:10,000
To this data the slope of the fitted regression line would be positive.

85
00:15:10,000 --> 00:15:17,000
Anyone thinks this is correct or wrong.

86
00:15:17,000 --> 00:15:26,000
I said that that was true. The slope appears to be positive in this Thanks so much, Star. there's obviously a positive plan, right?

87
00:15:26,000 --> 00:15:34,000
The slope if you fit. I know if you can see my miles let me let me draw a little bit right.

88
00:15:34,000 --> 00:15:42,000
Can I draw a line, so I would bet you know if you feed the regression.

89
00:15:42,000 --> 00:15:46,000
I would somewhat look like this. It it won't be perfect but that's about it.

90
00:15:46,000 --> 00:15:53,000
Would you? Would you go back and the second if the regression line we're paid to these data, United States would have a negative review.

91
00:15:53,000 --> 00:15:57,000
You first need to figure out what where the United States is.

92
00:15:57,000 --> 00:16:00,000
And then they got the definition of residual right.

93
00:16:00,000 --> 00:16:03,000
The residual is defined as if you think about it.

94
00:16:03,000 --> 00:16:11,000
You know what we learn? Pop is the the residual would be observed, the fly minus the predicted Y.

95
00:16:11,000 --> 00:16:15,000
So points lie below the the line will have a negative residue point.

96
00:16:15,000 --> 00:16:25,000
5 above the line will have a positive review. So so residue is simply the the estimated error.

97
00:16:25,000 --> 00:16:29,000
Right. So the United States would have a negative result. This is crack.

98
00:16:29,000 --> 00:16:35,000
This is correct? are the questions so far? Oh, actually, that move it?

99
00:16:35,000 --> 00:16:38,000
Yeah, I move the figure, the line actually stay the same. The third one.

100
00:16:38,000 --> 00:16:44,000
There is a strong, positive association between the countries in home level and the health of this citizen.

101
00:16:44,000 --> 00:16:49,000
I guess that depend on what you mean by Clon.

102
00:16:49,000 --> 00:17:00,000
But from this video it seems like there is a relatively strong association right with the bad.

103
00:17:00,000 --> 00:17:09,000
If you calculate the correlation is probably 0 point 8 or something like that party. I don't know the true number, unless it's written somewhere in the pig figure.

104
00:17:09,000 --> 00:17:20,000
It's very easy, I don't see the number but but I would say, this is correct.

105
00:17:20,000 --> 00:17:25,000
Finally the house of a country's citizen will improve by increasing the income level of the country.

106
00:17:25,000 --> 00:17:31,000
Anyone with Lancaster this one. You cannot make this conclusion from the data.

107
00:17:31,000 --> 00:17:35,000
I I I

108
00:17:35,000 --> 00:17:39,000
I I I don't know how many times for should I repeat this until you're a board.

109
00:17:39,000 --> 00:17:45,000
But is the correlation right? So this this sentence implied foundation?

110
00:17:45,000 --> 00:17:50,000
Good totally be true, but we can and i'll draw the conclusion from figure.

111
00:17:50,000 --> 00:18:00,000
Yeah. any question, so far.

112
00:18:00,000 --> 00:18:05,000
If you ride into issues with the online quiz, you know. let us know.

113
00:18:05,000 --> 00:18:15,000
You can let us know right now during the break or send us an email will double check what you got in there

114
00:18:15,000 --> 00:18:24,000
Yeah, but you know I know you. You have 2 files of this quiz right the first time they give you a wrong answer, and then that may you, which was the 1 1.

115
00:18:24,000 --> 00:18:27,000
Unfortunately, we are not going to see that. what happened right?

116
00:18:27,000 --> 00:18:34,000
So, or if that happened to you, you probably need to let us know what happened, and we will correct your score for you.

117
00:18:34,000 --> 00:18:47,000
But honestly, unless you're taking it for credit it doesn't really matter as long as you know the vine answer. You know what know the right knowledge that should be good enough right So today.

118
00:18:47,000 --> 00:18:51,000
The answer is how you today is the correct answer. No matter what you got from yesterday.

119
00:18:51,000 --> 00:19:01,000
If you, if you take it for credit right and definitely let us know we'll correct the the score for you question 4.

120
00:19:01,000 --> 00:19:08,000
This figure below show data collecting on 21 subjects examining the association between age and actor type.

121
00:19:08,000 --> 00:19:15,000
The yellow line is the finite regression line. Select all the following conclusions that can be reached from the figure.

122
00:19:15,000 --> 00:19:19,000
This is similar right number. This is again audible Toy number one.

123
00:19:19,000 --> 00:19:24,000
The slope of the 30 regression line positive I you know I Guess it's clear right.

124
00:19:24,000 --> 00:19:26,000
It's trending up work right so it is a positive.

125
00:19:26,000 --> 00:19:34,000
So this is correct. if the point with the largest age and largest hours of exercise per week circle in the figure.

126
00:19:34,000 --> 00:19:51,000
This point Here, or remove let's say take this point out the slope of the repeated regret line would decrease anybody agree with this for disagree

127
00:19:51,000 --> 00:20:01,000
I do agree, because the outlier there is pulling the the on the line sort of upwards, so I think it would decrease the slope.

128
00:20:01,000 --> 00:20:12,000
Yup: perfect. Yeah, you're absolutely right the all wire has a stronger impact on other points on your feet. the the the lines trended off because the point is here right?

129
00:20:12,000 --> 00:20:18,000
Otherwise, you know you have the line where flat and this will have a big residue and a lot.

130
00:20:18,000 --> 00:20:24,000
You know the regression doesn't favor that right so the line put a the the point for the line upwards.

131
00:20:24,000 --> 00:20:27,000
They could remove it. the line will blob. Actually, I would.

132
00:20:27,000 --> 00:20:34,000
I would, if you remove this point. I would think the remaining points are sort of uncorrelated, so the line would be almost black.

133
00:20:34,000 --> 00:20:45,000
That's my good. These are the correct so the third one. The 50 line does not appear correct, because there are more points below the line than above the line.

134
00:20:45,000 --> 00:20:52,000
We just talk about this right? It never meant to have the same number of points above and below the line.

135
00:20:52,000 --> 00:21:03,000
So this is not valid. We can already. see what are the lines correct or not, by counting the number points above and below the line, and especially if there's a olive all right.

136
00:21:03,000 --> 00:21:11,000
All, I will have more weight the other point. so this single point will balance our several points, that below the line which make it unbiased.

137
00:21:11,000 --> 00:21:18,000
Finally, if the point was the largest 8 and largest hour of access, I probably, except in the figure, this one were removed.

138
00:21:18,000 --> 00:21:21,000
The coalition between age and exercise is nearly 0 this again.

139
00:21:21,000 --> 00:21:24,000
You know it's hard to stay for sure but if you take out this point.

140
00:21:24,000 --> 00:21:33,000
I would see the remaining point. Do not really show us clear positive or negative trends, right as we use ipidel.

141
00:21:33,000 --> 00:21:38,000
Don't see that so the which means the car is and will be close to 0.

142
00:21:38,000 --> 00:21:40,000
Remember the correlation and the flow. They are proportional.

143
00:21:40,000 --> 00:21:45,000
They always have the same time, so the correlation is close with 0.

144
00:21:45,000 --> 00:21:54,000
I hope it will be close to 0. So this one is actually Oh, this here, just say the correlation will be in here.

145
00:21:54,000 --> 00:22:10,000
Okay. any questions for the quiz, any common

146
00:22:10,000 --> 00:22:17,000
Okay, that's cool. So I yes, they are scourging you know, preparing for the for the lecture today.

147
00:22:17,000 --> 00:22:26,000
I was searching online, I find it very funny interesting website is called what's going on.

148
00:22:26,000 --> 00:22:31,000
He was opening

149
00:22:31,000 --> 00:22:39,000
Hold on a second

150
00:22:39,000 --> 00:22:43,000
Yeah, I I just open it with another browser so let me drag it here.

151
00:22:43,000 --> 00:22:52,000
I don't know why this probably doesn't allow it beyond what I can understand.

152
00:22:52,000 --> 00:22:59,000
But, nevertheless, let me show you. So you can see the year right?

153
00:22:59,000 --> 00:23:06,000
The same website. I don't know why the other browser doesn't show It's called a serious correlation.

154
00:23:06,000 --> 00:23:09,000
So you send your spears. Correlation means that things are highly correlated.

155
00:23:09,000 --> 00:23:16,000
But for no good reason. So basically they shouldn't be But They they're just are okay, and you can go down the list.

156
00:23:16,000 --> 00:23:22,000
It's very funny, you know they just I don't know what how they find all this it's kind of a spirit correlation.

157
00:23:22,000 --> 00:23:35,000
But it's kind of funny. For example, us spending on time, space, and technology correlated with suicide by handing triangulation and a suffocation partition is 99.7 9%, and our you

158
00:23:35,000 --> 00:23:41,000
know, too, Bra. And you just see the you know, the yearly data from 90, 99 to 2,000, another 9.

159
00:23:41,000 --> 00:23:47,000
Right. Basically, there are 2 time series, and they are highly correlated.

160
00:23:47,000 --> 00:23:50,000
Comparative to have no real reason to be. Carl.

161
00:23:50,000 --> 00:23:57,000
It is high, right? So if you compute the pivotal, it would be super significant, because the correlation is follow high.

162
00:23:57,000 --> 00:24:03,000
But just one no reason. And similarly, this is not so high.

163
00:24:03,000 --> 00:24:11,000
The correlation is only 66% is moderate, but the number of people who, drawn by falling into pool and the fumes Nicolas cage appeared in.

164
00:24:11,000 --> 00:24:17,000
You know I I talk about people drowning versus ice cream sales, right? you know.

165
00:24:17,000 --> 00:24:20,000
Those will be correlated if you look at pizza note, but not a yearly change.

166
00:24:20,000 --> 00:24:25,000
But this is a few Nicholas Page, a purity which make no sense to be part of it.

167
00:24:25,000 --> 00:24:35,000
Here. Similarly, the next one is per capita cheese consumption for the number of people who died by becoming tango in their batch sheet, which makes no tends to be part.

168
00:24:35,000 --> 00:24:43,000
I think. Hey, man, hi! they didn't say this is a joke, and they also have a data sort.

169
00:24:43,000 --> 00:24:47,000
So I I tend to believe these are real data, right? And there are tons of example like this.

170
00:24:47,000 --> 00:24:52,000
Basically 2 seemingly totally irrelevable, but somehow the highly correlated.

171
00:24:52,000 --> 00:24:58,000
So this is again, you know. read you to think about correlation and causation.

172
00:24:58,000 --> 00:25:11,000
So apparently these 2 are not calling. each other and this is unlike the case with, you know, drowning and ice cream, where, although those 2 we know are shouldn't be related. but we know the season is driving them right we know we

173
00:25:11,000 --> 00:25:22,000
can see all the confounding factors. right but this is the case. We couldn't even have no idea what the Kentucky fighter could be so.

174
00:25:22,000 --> 00:25:33,000
The The truth is that you could think about millions of variable, and then compare parallelized correlation by chance. Some of them will just be highly correlated.

175
00:25:33,000 --> 00:25:45,000
So if I can, and then you'll pick those ones or maybe they are really confounded by something you never thought about, or you know they are down the road right sound factor can turn up another 2, and 3 down the road.

176
00:25:45,000 --> 00:25:50,000
You know, In the end of fact, this too, variable and it's too far away, you know.

177
00:25:50,000 --> 00:25:56,000
There's a call, though. paragraph you know is it so cute that you couldn't even figure it out.

178
00:25:56,000 --> 00:26:09,000
So there are many different reason explanation, but in the end. The table message that correlation doesn't think compilation right. You could have 2 variable, highly correlated, but nothing to do each other.

179
00:26:09,000 --> 00:26:16,000
So this go back to the case, you know. What if I replace one variable with smoking the other one with a lung cancer?

180
00:26:16,000 --> 00:26:20,000
We know they are also correlated, or we replace one with Co.

181
00:26:20,000 --> 00:26:23,000
2 right mentioned the other one with the global temperature they're also high recording Right?

182
00:26:23,000 --> 00:26:32,000
What makeup. think those are true but these are not true right that's That's why there's handless argument I overweight.

183
00:26:32,000 --> 00:26:43,000
Whether those how much you know reliable those conclusions are upon the fundamental bottleneck is that we cannot do experiment. and this is only a division of data.

184
00:26:43,000 --> 00:26:51,000
Any thoughts, any

185
00:26:51,000 --> 00:26:56,000
Yeah, at first, when I find it, though sorry, interesting, make me think more.

186
00:26:56,000 --> 00:27:00,000
Think again any time. I think I know things when I look at this kind of stuff right? I was like.

187
00:27:00,000 --> 00:27:13,000
Oh, maybe I don't really know everything

188
00:27:13,000 --> 00:27:28,000
Okay, that's all let me go back

189
00:27:28,000 --> 00:27:32,000
So yesterday we were on lecture 10. We just started multiple linear aggression today.

190
00:27:32,000 --> 00:27:40,000
Elizabeth finish it.

191
00:27:40,000 --> 00:27:50,000
By the way, let me look at this it's 2 exercises, and the quick, I believe they won't be due into Friday.

192
00:27:50,000 --> 00:27:57,000
So this one is still on Friday. this might be one that's surprising right.

193
00:27:57,000 --> 00:28:04,000
Both the quiz and the project, or do on friday so that's the last one you need to do.

194
00:28:04,000 --> 00:28:15,000
So it's not due tomorrow do on friday and Then the very last electronologist regression will not have anything needed to be some matter, because we'll do that in in the last day. and after that it's fun I

195
00:28:15,000 --> 00:28:21,000
don't want you to do anything over the weekend but you can that definitely work on those it's all available here.

196
00:28:21,000 --> 00:28:25,000
But just you don't need to find that so multiple in your regression.

197
00:28:25,000 --> 00:28:37,000
We talk about our time is the extension of simple regression by including more if one of 3 or dependent, or independent or exposure whatever covariance in your model, right?

198
00:28:37,000 --> 00:28:41,000
So basically, we still keep one Y. But now we have multiple ad which could be confounding each other.

199
00:28:41,000 --> 00:28:46,000
And we need to figure it out right here. The example we use are the 3 variables.

200
00:28:46,000 --> 00:28:49,000
I just have the example, the male suicide rate as the outcome.

201
00:28:49,000 --> 00:28:57,000
Our ownership and the female suit our rate as though, as the explanatory variable, I would say they're not really closure.

202
00:28:57,000 --> 00:29:01,000
So, and there are many other variable. We might be listening right.

203
00:29:01,000 --> 00:29:08,000
Keep in mind. So essentially for simplicity, we have this 3 variable right.

204
00:29:08,000 --> 00:29:12,000
We also study the relationship between 2. By the third variable could be confounding them.

205
00:29:12,000 --> 00:29:19,000
You many different ways, right? and then modeling your regression that let me put this right.

206
00:29:19,000 --> 00:29:27,000
So take when the data is observational it is right there's no way you can get all of it.

207
00:29:27,000 --> 00:29:34,000
Margaret regression. Just give you a tool to Look at the related among 3, variable at the same time, but it still doesn't tell you which one is the cause.

208
00:29:34,000 --> 00:29:45,000
We try the consequence. Maybe none of the is right. So what which one is the cause which one potentially the consequences all up to your own explanation up to your on the funding. environment.

209
00:29:45,000 --> 00:29:54,000
So you basic, I'm saying, multiple integration cannot give you the arrow in this kind of ground, the arrow come from your knowledge.

210
00:29:54,000 --> 00:29:59,000
Okay. So essentially, we talk about we put the multiple in your regression here.

211
00:29:59,000 --> 00:30:03,000
Y equals alpha plus beta, one x one plus beta 2 x 2 plus t arrow.

212
00:30:03,000 --> 00:30:10,000
In this case we put why the male suits our rate, and the other acts as the paramolers shame.

213
00:30:10,000 --> 00:30:12,000
A team of 3, but we did it just because we did.

214
00:30:12,000 --> 00:30:15,000
You could do any other way right, you could put some variable as y.

215
00:30:15,000 --> 00:30:20,000
The other error would act depend on. You know what you think should be the outcome.

216
00:30:20,000 --> 00:30:25,000
Nevertheless, in this case, even the the 2 access, we think they are not equal.

217
00:30:25,000 --> 00:30:34,000
So we really care about males with our rate, for you know, with our ownership, however, we include females which are read as a potential compounder.

218
00:30:34,000 --> 00:30:43,000
In this case X. one is the make voter of interest like through its contounder, so we can rearrange the terms to still keep x Beta one x one as the flow.

219
00:30:43,000 --> 00:30:52,000
But we absorb X data to act 2 into the intercept, so that now every single data point has a different intercept. Depend on their

220
00:30:52,000 --> 00:31:00,000
X 2 level, and to further illustrate with a bigger assume that's cool with categorical right.

221
00:31:00,000 --> 00:31:06,000
So there are 3 group of states with low, medium, and high female suicide rate.

222
00:31:06,000 --> 00:31:13,000
Then we put the regression line. Each state separately nevertheless let's see that regression line with each they each group separately.

223
00:31:13,000 --> 00:31:23,000
We forced them to have the same flow. They just have different interface, because here they the F beta, one, is non-changing right.

224
00:31:23,000 --> 00:31:29,000
So we still see the same model with 3 groups together, but somehow each group has a different intercept. When we put them together.

225
00:31:29,000 --> 00:31:34,000
You test what we got right, he finally. we split all the States into 3 group.

226
00:31:34,000 --> 00:31:38,000
Each one has a different regression line, all the regression line.

227
00:31:38,000 --> 00:31:42,000
They are parallel to each other because they have the same slope, but they don't have the same inter that interrupt.

228
00:31:42,000 --> 00:31:45,000
Depend on X 2, because act 2 is categorical.

229
00:31:45,000 --> 00:31:48,000
Here we all have 3 inter type values, and then the black line is the original.

230
00:31:48,000 --> 00:31:53,000
He does that. What we see here is that after you include act 2 in the model.

231
00:31:53,000 --> 00:31:57,000
The interface to change in this case the intercept review Right.

232
00:31:57,000 --> 00:32:05,000
The flow gets smaller, basically say that well female suits our way.

233
00:32:05,000 --> 00:32:15,000
It can explain the way some of the variation in the outcome.

234
00:32:15,000 --> 00:32:27,000
We'll reduce the attack of the farm ownership 3,000, you could say from this, from this multiple regression model, you can say female suites are rate.

235
00:32:27,000 --> 00:32:31,000
Could be a container, or at least partial confounder.

236
00:32:31,000 --> 00:32:35,000
What the you back between power, ownership and mail through time rate.

237
00:32:35,000 --> 00:32:41,000
What is the compiler or not? Depend on you on the finding the variable right?

238
00:32:41,000 --> 00:32:50,000
If you think it's, potentially be confounder then this result validate that because you know, after you're putting the female suit our rate, the fact of the the power ownership mails we are raised with

239
00:32:50,000 --> 00:32:55,000
you

240
00:32:55,000 --> 00:32:59,000
So let's compare the 2 model right on the top is when we regret mail.

241
00:32:59,000 --> 00:33:04,000
So we are raised on car ownership. Only on the bottom is when we regret.

242
00:33:04,000 --> 00:33:08,000
Male suits are made on the 2 variables, our ownership and the females resource.

243
00:33:08,000 --> 00:33:23,000
We will compare both right. I talk about this yesterday. but I want to repeat again everything change right. the intercept change the slope for power ownership reduced more than 50% by the p of the t statistics Then arrow

244
00:33:23,000 --> 00:33:27,000
key value the p model doesn't seem to change because that's because the precision is actually changed right?

245
00:33:27,000 --> 00:33:34,000
And then female suicide rate, of course, is new here, and the mean, square error rebuild.

246
00:33:34,000 --> 00:33:39,000
That will always reduce, and then R. squared increase that will always increase.

247
00:33:39,000 --> 00:33:48,000
I also talk about You say the R Square, not only in simple in your direction, means the arm is the correlation between you know X and Y right.

248
00:33:48,000 --> 00:33:51,000
It also means the correlation between Y and the Y hat.

249
00:33:51,000 --> 00:34:00,000
So in the multiple regression Cave R. Square is really the correlation between y and the Y hat squared

250
00:34:00,000 --> 00:34:07,000
There are a few number. There are a lot of numbers on this 2 table, but there are a number which are especially interested in.

251
00:34:07,000 --> 00:34:16,000
For example, this 0 point 3, 2, one, what the flow of our ownership before and then 0 1, 4 4 is the power ownership right now.

252
00:34:16,000 --> 00:34:26,000
So the slope dropped. so basically the station is that by including a third variable that you' of the second variable redo.

253
00:34:26,000 --> 00:34:35,000
So the third variable could be a confoundment and the other number. Now it's a interested this this you know the P.

254
00:34:35,000 --> 00:34:43,000
Value right? It seems like the female suicide rate is significantly associated.

255
00:34:43,000 --> 00:35:06,000
Dot com together with the power ownership so i'll explain later on, any questions so far

256
00:35:06,000 --> 00:35:17,000
So let's not talk about the the whole point of using multiple linear regression is to pull the confounder in your model, trying to see what role they play right, whether in fact, they have So let's not talk about it how do

257
00:35:17,000 --> 00:35:20,000
we really read it right? So after we include the female.

258
00:35:20,000 --> 00:35:25,000
So we are right, right, although the file ownership still has a no cluster, you know.

259
00:35:25,000 --> 00:35:32,000
By no means is is is 0 right? It is still weak, but associated, and also key value is significant.

260
00:35:32,000 --> 00:35:47,000
The Association is still there, just getting weaker so include a third variable doesn't completely eliminate the fact of the second variable by the weekend right association must weaker, which means that the association between our

261
00:35:47,000 --> 00:35:51,000
ownership, and the male suits array may not be as strong as we thought.

262
00:35:51,000 --> 00:35:58,000
If you just look at this. that means, if you you know, just take the the most naive interpretation which may be wrong.

263
00:35:58,000 --> 00:36:01,000
But just from this number you can interpret that per unit.

264
00:36:01,000 --> 00:36:13,000
Remember per unit increase or per unit, decrease in file ownership. You would expect the male switcher will drop by a certain amount by def amount, actually right, 0 point 3 2%.

265
00:36:13,000 --> 00:36:31,000
That's the interpretation of this quote but Now, after including the third variable, that this closed drop, which means the you fact of changing file ownership on the mail suicide rate may not be as big as you thought

266
00:36:31,000 --> 00:36:37,000
Right, and then you find maybe 0 to begin with because if we don't really know anything of a causation.

267
00:36:37,000 --> 00:36:41,000
But just that's just say, you know in a simple case they are causing each other.

268
00:36:41,000 --> 00:36:48,000
What are you packing may not be as Well, as your phone, right but at least that's one implementation

269
00:36:48,000 --> 00:36:51,000
Right, then, that give you a thought. Maybe there you know other thing we have is all about right.

270
00:36:51,000 --> 00:36:57,000
It's basically the it may be more complicated no one knows everything.

271
00:36:57,000 --> 00:37:05,000
That's why no one really knows whether there are other variable when you include the model, things will be changed differently, and whether they are variable.

272
00:37:05,000 --> 00:37:13,000
You never thought about right. So there's no right over one answer. We to interpret this kind of thing in the real setting require a lot more knowledge.

273
00:37:13,000 --> 00:37:21,000
Young the data. So there's no right or wrong number at some point it becomes objective that's why there's an endless argument.

274
00:37:21,000 --> 00:37:27,000
Right. We use observational data for policy change or things like those, right?

275
00:37:27,000 --> 00:37:39,000
Sometimes you can interpret the data both ways and both make fun Unfortunately, you know, that's the reality.

276
00:37:39,000 --> 00:37:46,000
Okay.

277
00:37:46,000 --> 00:37:54,000
Again. there are different terminology. i'm gonna use intro deals right?

278
00:37:54,000 --> 00:37:59,000
So this is a multiple in your gradient, and the £10 confounding right.

279
00:37:59,000 --> 00:38:14,000
I I never really rigorously defined confounding. Because, first of all, i'm not sure i'm I'm not acting, you know, you can call with you for that's why I I look online.

280
00:38:14,000 --> 00:38:18,000
I took this Wikipedia page up, compounding.

281
00:38:18,000 --> 00:38:24,000
I just look at the first sentence right in statistics of calendar, also called confounding variable.

282
00:38:24,000 --> 00:38:33,000
Confounding factor, or, you know, determinant or a lurking variable many different names.

283
00:38:33,000 --> 00:38:37,000
Right is a variable that in influence both the dependent, variable, and independent variable.

284
00:38:37,000 --> 00:38:41,000
But basically these are on the outcome, causing a spirit association.

285
00:38:41,000 --> 00:38:49,000
Okay, confounding is a call, though contact as such and i'll be describing terms of correlation association existing confounders.

286
00:38:49,000 --> 00:38:56,000
It's important quality why part is that 9 5 causation so basically call call it, and doesn't imply causation.

287
00:38:56,000 --> 00:38:59,000
One of the main reasons, because there could be confounding right, at least the reason right.

288
00:38:59,000 --> 00:39:13,000
These depends on the actually one right, maybe x one has nothing to do each other. but they are seemingly correlated because there's a underlying variable causing or associating with both right That's a component But you know

289
00:39:13,000 --> 00:39:19,000
it's more complicated if you really take do the literature of call on your friend, which is beyond my expertise.

290
00:39:19,000 --> 00:39:23,000
I'm not going, you know deeper on this topic just how you know that.

291
00:39:23,000 --> 00:39:31,000
You know, combining me this kind of but there are other terminology statistics.

292
00:39:31,000 --> 00:39:37,000
The one hallmark of compounding dot one is controlling that, you facto confounder.

293
00:39:37,000 --> 00:39:41,000
The exposure has the same impact all values of the component.

294
00:39:41,000 --> 00:39:51,000
So what does that mean? Not I mean, yeah, right. Once we, the female suit are right.

295
00:39:51,000 --> 00:39:59,000
So basically here the female series already only change the intercept, but not as well of.

296
00:39:59,000 --> 00:40:06,000
You know of the the model, if you'll fix female suites are right, Right?

297
00:40:06,000 --> 00:40:13,000
But the The file ownership has the same effect on all that is that the component right?

298
00:40:13,000 --> 00:40:15,000
Basically all the regression on Rl: I think parallel.

299
00:40:15,000 --> 00:40:23,000
But there are cases. this is not which means that the Confounder only change the interaction.

300
00:40:23,000 --> 00:40:28,000
But now the slope of the second variable right? Well, one of you will also change the flow.

301
00:40:28,000 --> 00:40:34,000
Well, yeah, we got something out and that's not called the confnder anymore.

302
00:40:34,000 --> 00:40:37,000
They have a term call that you Fagg modify i'll explain the difference among them.

303
00:40:37,000 --> 00:40:42,000
Right. You know a current problem right in this particular setting right now, right?

304
00:40:42,000 --> 00:40:48,000
Suppose females to be harder to use a confound there, then

305
00:40:48,000 --> 00:40:50,000
Which means that different States will have different intercepts, different data lines.

306
00:40:50,000 --> 00:40:57,000
To begin with, however, the fact of changing for our ownership would be the same.

307
00:40:57,000 --> 00:41:04,000
Each state regardless of their base, One level

308
00:41:04,000 --> 00:41:18,000
Okay, But this is assumption. It may not be true What If actually, even the effect of fire ownership with male suit that rates actually change. when you'll change female suicide.

309
00:41:18,000 --> 00:41:21,000
Right, then. this is beyond the model we are using right now.

310
00:41:21,000 --> 00:41:32,000
We need a new model for that. Okay, in this. In those case, actually, even the slope will change, not only the user, the slope will also depend on X 2.

311
00:41:32,000 --> 00:41:37,000
So the slope for X. one will also depend on x 2 that's a different model is a more complicated model.

312
00:41:37,000 --> 00:41:42,000
In those case regression are no longer parallel let's see what it what it looks like.

313
00:41:42,000 --> 00:41:55,000
So in this case, right here the level of female per So it's our rate modifies the you pack of power ownership rate Mayo file on suite that right Then we say the female follow

314
00:41:55,000 --> 00:42:02,000
suicide rate, and if our own ownership have an interaction, there is an interaction.

315
00:42:02,000 --> 00:42:11,000
Another way to think, to say that is, that a female suitar rate is a stack modifier for for power ownership.

316
00:42:11,000 --> 00:42:15,000
So you fact modifier, or you type modification or interaction.

317
00:42:15,000 --> 00:42:23,000
They just different terminology for the same thing I know it is confusing, because, you know, so it was used by people in different.

318
00:42:23,000 --> 00:42:29,000
That's the point, right? I mean statistician epidemiologists, economists social scientists.

319
00:42:29,000 --> 00:42:32,000
They all use statistics, and somehow time they developed them.

320
00:42:32,000 --> 00:42:37,000
Look in different settings that's Why, use different terminology, and again, that'd be calm.

321
00:42:37,000 --> 00:42:41,000
I don't know a little confusing right but it is the reality.

322
00:42:41,000 --> 00:42:48,000
Well, some people may you I mean as a statistician I tend to use interaction, but for epidemiologists they can use you attack Modifier.

323
00:42:48,000 --> 00:42:54,000
That's actually the same thing. So you essentially the model here in this case, right?

324
00:42:54,000 --> 00:42:58,000
Why equals alpha plus beta, one x one plus beta track.

325
00:42:58,000 --> 00:43:03,000
To this are still the same. but in this new model we add a new term beta, 3 x, one times 2.

326
00:43:03,000 --> 00:43:07,000
So we we put a Mo product. This is just product term.

327
00:43:07,000 --> 00:43:15,000
Are we call the interaction it's just a product term well, this new term in the model.

328
00:43:15,000 --> 00:43:19,000
So what does this new term do? Left rearrange the permanently right?

329
00:43:19,000 --> 00:43:23,000
Remember we can absorb X beta to x 2 into the interse.

330
00:43:23,000 --> 00:43:27,000
That's what we got previously right so our 2 basically intercept depending.

331
00:43:27,000 --> 00:43:37,000
But now look at this. This has a that's one unit but if we run together all the term with x one, we put x one here, the next one.

332
00:43:37,000 --> 00:43:42,000
Now have a slope which is beta one plus beta 3 act 2.

333
00:43:42,000 --> 00:43:56,000
And we call it the Data Act 2. So now, which means that not only the intercept dependencies, even the slope of X one dependent beyond what we had earlier.

334
00:43:56,000 --> 00:44:02,000
This is case, that actually both change the intertap and also the flow and the slope is the effect right?

335
00:44:02,000 --> 00:44:04,000
Which means, when the effect of X one depend on the value.

336
00:44:04,000 --> 00:44:13,000
Act 2, we say x 2 is the attack modifier by one that that is caused by the interaction.

337
00:44:13,000 --> 00:44:16,000
You see this model? The original model was the matching X.

338
00:44:16,000 --> 00:44:21,000
One act 2. Now it is hasty magic, just because we think I find more important.

339
00:44:21,000 --> 00:44:24,000
We could rearrange the same way, so that X.

340
00:44:24,000 --> 00:44:27,000
One become a attack modified by 2 on the other side right?

341
00:44:27,000 --> 00:44:31,000
So whether actually that you talk to modifier is one or x.

342
00:44:31,000 --> 00:44:33,000
One is a back modifier on 2. Really, up to your invitation.

343
00:44:33,000 --> 00:44:43,000
The model is the thing, the model, just including interaction among the 2

344
00:44:43,000 --> 00:44:56,000
Yeah, any questions. So far I know this could be confusing, especially for those who see the first time

345
00:44:56,000 --> 00:45:05,000
Okay, Yeah, this is the equation right now. i'm gonna show the figure for those of you who are, you know more comfortable, seeing the people.

346
00:45:05,000 --> 00:45:16,000
Remember these are what we had before right. This was the model without interaction, where the 3 group have different regression line at the different intercept, but they have the same slope.

347
00:45:16,000 --> 00:45:24,000
This is the knowing tractor model we showed earlier, and this is the interaction model. here.

348
00:45:24,000 --> 00:45:27,000
Both of them will assume Act 2 is categorical.

349
00:45:27,000 --> 00:45:30,000
Therefore we can show 3 lines, right, if can, actually is continuous.

350
00:45:30,000 --> 00:45:34,000
We have to have a line for every single data point i'll be too messy.

351
00:45:34,000 --> 00:45:37,000
I know it's hard to see but let me go back and forth.

352
00:45:37,000 --> 00:45:41,000
See whether you know this or anything. There is a very follow change.

353
00:45:41,000 --> 00:45:50,000
You need particular data set i'm going back and forth I don't know on your screen whether you see the same it will change.

354
00:45:50,000 --> 00:45:55,000
But here, in the no interaction model, the 3 lines are perfectly parallel, you know.

355
00:45:55,000 --> 00:45:58,000
Interaction model. The 3 lines are not parallel anymore.

356
00:45:58,000 --> 00:46:02,000
You see that they seem to be parallel. They are not right, they are separate more.

357
00:46:02,000 --> 00:46:07,000
Here. they are separate. last year this call to data, right? you know another data set.

358
00:46:07,000 --> 00:46:11,000
It could be more, even more unparalleled to each other.

359
00:46:11,000 --> 00:46:16,000
So this is a different model. Now, although you will say this model and this model do not really make that much difference.

360
00:46:16,000 --> 00:46:20,000
Right, the partition would be very similar to Our Square. The everything would be very similar.

361
00:46:20,000 --> 00:46:31,000
Nevertheless, they are different models. The slopes will not be identical between to model

362
00:46:31,000 --> 00:46:43,000
Any questions so far

363
00:46:43,000 --> 00:46:49,000
So this is the regression. we're calculating track the model. You may be. wonder.

364
00:46:49,000 --> 00:46:54,000
How do we fit a model like this? right? there is a product term.

365
00:46:54,000 --> 00:47:00,000
How do you fit the model? It turns out that it's not so hard, so the linear regression models seem to be simple.

366
00:47:00,000 --> 00:47:06,000
It's actually very, very powerful in the sense that you can actually include nonlinear term.

367
00:47:06,000 --> 00:47:19,000
It's called a linear regression model. But you can actually include nonlinear prompting that the truth is that here we have a product That's one time back 2 You can drop. you Could you can just call this X 3. right?

368
00:47:19,000 --> 00:47:22,000
You can compute X one. Remember, you have a raw data sheet.

369
00:47:22,000 --> 00:47:25,000
Right the first column X. I find the second column.

370
00:47:25,000 --> 00:47:31,000
Act 2. you can just compute the third column to be at one time tax 2 and the card X 3.

371
00:47:31,000 --> 00:47:37,000
Then through the math. It doesn't you know the the software doesn't really care whether they are one contact to already another variable.

372
00:47:37,000 --> 00:47:45,000
They just treat it as a third variable, and they will get everything out right if you replace this by Act 3, this just a multiple in your vager model.

373
00:47:45,000 --> 00:47:51,000
Similar, you can actually add more terms. like X, one square log x, one you can add arbitrary functions.

374
00:47:51,000 --> 00:47:54,000
X, one x, 2, x, 3, or whatever in the linear regression model.

375
00:47:54,000 --> 00:48:05,000
He will always pay this using the same program. Okay, So the linear brand model is more powerful than it appears.

376
00:48:05,000 --> 00:48:08,000
So you need case. we don't even need to do it much.

377
00:48:08,000 --> 00:48:12,000
The software will basically pay the model. Now, because we are including the third term, right?

378
00:48:12,000 --> 00:48:18,000
We have 4 lines, Right? So the first one is, hey, the intercept; the second one is P.

379
00:48:18,000 --> 00:48:24,000
One the flow total ownership. the third one is B 2, the slope for female. so we are right now.

380
00:48:24,000 --> 00:48:28,000
I have a third, which is B 3. We just has domain for Beta.

381
00:48:28,000 --> 00:48:37,000
3 is the interaction term, and just like before, when you add a new term in your model, everything changed the previous slope.

382
00:48:37,000 --> 00:48:42,000
The previous intercept the P previous p-value. Also the mean square arrow always go down.

383
00:48:42,000 --> 00:48:53,000
The hard score always go on that's just the nature right you can add any terminal model. they always reduce the audience by error.

384
00:48:53,000 --> 00:49:01,000
They always Well, technically, that is not true. The mean, square arrow, you know.

385
00:49:01,000 --> 00:49:07,000
Let me put this way right. The total sum of squirts will always reduce, because, you know, you had a new term right line.

386
00:49:07,000 --> 00:49:16,000
Feed the data a little better. but the mean square hour is the total sum of squared, divided by the degree of freedom. It's n minus the number of parameters.

387
00:49:16,000 --> 00:49:22,000
Right when you had a new terminal model. The number of parameter also increased that one. so the denominator also decreased by one.

388
00:49:22,000 --> 00:49:26,000
So these actually the musical error i'm not sure you know may I create?

389
00:49:26,000 --> 00:49:37,000
Go up a little bit, maybe, but our Square always belong, because adding a new variable always help you explain more variation.

390
00:49:37,000 --> 00:49:43,000
Even just a tiny bill. So looking at Our Square may not be the only way or the best way to come back.

391
00:49:43,000 --> 00:49:51,000
Different models. i'll talk about how to compare the model Stay there, you know, looking at myself.

392
00:49:51,000 --> 00:49:57,000
May not be very informative or revealing, but we want to really come to model.

393
00:49:57,000 --> 00:50:05,000
Later on. Okay, it's hard but well so let's now talk about model selection.

394
00:50:05,000 --> 00:50:16,000
So far we have step 3 models, right model. One is only with X, one model. 2 is with X, 2 model 3 is with x, 2, and also interactions between X, one x, 2 with 53 model.

395
00:50:16,000 --> 00:50:22,000
You have fifth like a a 100 different models, if you want.

396
00:50:22,000 --> 00:50:26,000
But in the end, which model do you pick to make the final interpretation?

397
00:50:26,000 --> 00:50:35,000
Because each model will give you a different intersect. You need to pick a model to making the rotation.

398
00:50:35,000 --> 00:50:40,000
So one thing I want to say here is a very famous saying by a by a famous presentation.

399
00:50:40,000 --> 00:50:53,000
George Box t 5, which is absolutely correct cause all all those are Well, what's on my useful which means don't try to find the model.

400
00:50:53,000 --> 00:50:59,000
There is no D model. Every model make a lot of function which in reality probably is not true.

401
00:50:59,000 --> 00:51:03,000
So all all those are wrong models can only be approximation of the reality.

402
00:51:03,000 --> 00:51:06,000
They can never be the be the full characterization of reality.

403
00:51:06,000 --> 00:51:14,000
So when we say statistical Models right we're same model like this, which is part of a different way, you'll say physical models right like newton's.

404
00:51:14,000 --> 00:51:24,000
Equation. Those are probably true, really true, right. But the 2 models are never fully reflecting the reality.

405
00:51:24,000 --> 00:51:30,000
So we just use model. To study this. we think there should be 2 different variable, but none of them fully, really characterize the relationship.

406
00:51:30,000 --> 00:51:34,000
We just find one way, we think, are closely resembled.

407
00:51:34,000 --> 00:51:42,000
The reality help us to end up on the real world alright But now we it's pretty believe your model is the true model. Other people might pay.

408
00:51:42,000 --> 00:51:48,000
Take a different model number, the last. All models are wrong, but some are useful, Right?

409
00:51:48,000 --> 00:51:51,000
So some model model. Some of those are more used for the other model.

410
00:51:51,000 --> 00:51:57,000
They want to pick the the back model that we can. we can think of right.

411
00:51:57,000 --> 00:52:00,000
So the best is quote unquote there's no bad model.

412
00:52:00,000 --> 00:52:10,000
But we want to pick the best one we can pick that's a that definition of the best you how do we pick

413
00:52:10,000 --> 00:52:19,000
So in this case it's not so hard in general picking model picking the bat model models that actually is very hard.

414
00:52:19,000 --> 00:52:23,000
It's very subjective, and there are many different quiet area.

415
00:52:23,000 --> 00:52:36,000
Sometimes they give you different conclusion but in this particular case it's not so hard because these 3 models have a special, probably in the sense are there nested within each other.

416
00:52:36,000 --> 00:52:44,000
The first model is connected within the second model. and further second model is that it within the third model.

417
00:52:44,000 --> 00:52:50,000
By Napa I mean the first model is the special case of the second model in the second model.

418
00:52:50,000 --> 00:52:56,000
If you, if you fix X theta 2 equals 0, then the second model reduces the first model.

419
00:52:56,000 --> 00:53:00,000
Similar to right in the third model. If you fix Beta 3 3 0.

420
00:53:00,000 --> 00:53:04,000
Then the second model, then the third model will become the second model.

421
00:53:04,000 --> 00:53:06,000
If you fix both of them to be 0, then the term will become the first one.

422
00:53:06,000 --> 00:53:10,000
Okay. So essentially, this Th: the first model is a special case, a second model, anything.

423
00:53:10,000 --> 00:53:13,000
The first model. Can you look straight? The second model also can?

424
00:53:13,000 --> 00:53:18,000
And can you let train more so in this particular nasty case?

425
00:53:18,000 --> 00:53:22,000
Picking model is not so hard still there's some subject in it there.

426
00:53:22,000 --> 00:53:26,000
But it's not so hard because in this case model one is connected with the model.

427
00:53:26,000 --> 00:53:34,000
2 models who is nothing with the model pre but in this case. There's one way to pick the model. just look at the p-value.

428
00:53:34,000 --> 00:53:46,000
Remember you can never look at r square because all square always go up you don't help you, but the pivot will tell you a little more.

429
00:53:46,000 --> 00:53:50,000
I'll talk about that. but when the 2 mother are nonetheless, they become harder.

430
00:53:50,000 --> 00:53:58,000
Pivotal do not already tell you much, and there are other approach to peak model, and there are more than one post like archive information criterion, aic.

431
00:53:58,000 --> 00:54:08,000
There are basic information can be I see there are many other like follow selection backwards. collection, all subsequent last, you know, there's just so many ways for picking models when they're nonetheless, and some of

432
00:54:08,000 --> 00:54:14,000
the time they give you a different answer. what is that active research area. There's no perfect answer to it.

433
00:54:14,000 --> 00:54:19,000
I'm not going there that rabbit hole right now, just telling you right.

434
00:54:19,000 --> 00:54:23,000
Models that actually is this is a hop it's a hard problem.

435
00:54:23,000 --> 00:54:34,000
I mean it's not the case what we can do with that. Think about our model one, the model who model 2 will reduce another one, or you can say, collapse to model. one.

436
00:54:34,000 --> 00:54:44,000
If Beta 2 is 0. if Beta, 2 is 0 model, 2 will be equivalent to model one, and we can run a have a tough beta 2.

437
00:54:44,000 --> 00:54:50,000
So the novel is a beta to e 0. The alternative beta 2 is not 0 under the No.

438
00:54:50,000 --> 00:54:56,000
You beta too easier than mother to eat, actually, just the same as model one and everything I was equal.

439
00:54:56,000 --> 00:55:11,000
We would prefer a simpler model. Right? The Beta 2 is not 0, which means model 2 is really better than by the one to pay the data, which means that to compare models one more one or 2.

440
00:55:11,000 --> 00:55:19,000
We also need to look at Model 2 and look at the p-value which corresponds to the new variable added model.

441
00:55:19,000 --> 00:55:27,000
I did the model Facebook model 2. And this variable, this key value is significant, which means this beta 2, right?

442
00:55:27,000 --> 00:55:30,000
This is the s make for beta 2 right P. 2.

443
00:55:30,000 --> 00:55:39,000
This pivot means that beta 2 is unlikely to be 0, which means model.

444
00:55:39,000 --> 00:55:44,000
2 probably make more sense that model one, because model, one assume state or 2.

445
00:55:44,000 --> 00:55:53,000
Is there. But you know there are evidence against that assumption like in this case, based on this P value itself.

446
00:55:53,000 --> 00:55:57,000
We can reject H. Not so you bet that to be 0.

447
00:55:57,000 --> 00:56:02,000
Therefore we prefer model to versus model one so that's one way to pick a monastery model.

448
00:56:02,000 --> 00:56:11,000
It's not the only way, but this way I think it a little community

449
00:56:11,000 --> 00:56:18,000
Any questions so far

450
00:56:18,000 --> 00:56:25,000
Okay, yeah, I mean, the reality is more complicated than you thought right?

451
00:56:25,000 --> 00:56:28,000
Because, now we have 2 models model one model, 2. By your reality.

452
00:56:28,000 --> 00:56:33,000
You may have 10 variables, and even for that the model you can build many.

453
00:56:33,000 --> 00:56:40,000
Do you add? for example, you have 10 variables right you can you can't imagine you can add them one by one.

454
00:56:40,000 --> 00:56:51,000
But then which one do you add for they're like yeah common is how real top you can add 10 variable year model right on a pivot actually depend on the sequence.

455
00:56:51,000 --> 00:56:58,000
You add variable. For example, if you add variable tool in the model first, so you add variable 3. then variable to you, will not be thinking everything.

456
00:56:58,000 --> 00:57:03,000
But you've had a variable 3 first right I was variable 2 the normal 2 in numbers.

457
00:57:03,000 --> 00:57:12,000
So you depend on the sequence. So in reality it's still hard. because you have to pick the particular sequence to add variable one by one email, model, and that's why they are so called forward selection.

458
00:57:12,000 --> 00:57:17,000
I saw, you know, or their backward selection, where you you put first. put all the variable in the model.

459
00:57:17,000 --> 00:57:21,000
There gradually remove those or nothing, but you know none of them.

460
00:57:21,000 --> 00:57:27,000
It guarantees you to get one single answer. They actually give you different answers.

461
00:57:27,000 --> 00:57:30,000
So the the problem is still much more complicated. in this case.

462
00:57:30,000 --> 00:57:37,000
I think we all God conveys that model to His better than other one.

463
00:57:37,000 --> 00:57:50,000
Okay as similar, we can compare Model 2 versus model 3, because when beta 3, which is the coefficient of the slope for the interaction term is 0, the model 3 will reduce to model 2 in this particular case the

464
00:57:50,000 --> 00:58:03,000
p-value is for the interaction term is insignificant, which means there's no evidence showing there is a really the interaction terminus at all.

465
00:58:03,000 --> 00:58:08,000
So everything else equal. We prefer a simpler model that's called the

466
00:58:08,000 --> 00:58:16,000
What's that called ever go that's called outcomes razor, or something like that?

467
00:58:16,000 --> 00:58:20,000
Right. so everything else equal you'll try to make fuel assumption right? Hi!

468
00:58:20,000 --> 00:58:26,000
I mean, because there's not enough evidence showing are you talking Tom is nonzero.

469
00:58:26,000 --> 00:58:43,000
We just don't include it in this case we we comfortably think model 2 is better than both model one and model 3

470
00:58:43,000 --> 00:58:48,000
So in this case, you know, we remove the interacting term because they don't think that user that's also reflected here.

471
00:58:48,000 --> 00:58:55,000
Right see included, the interacting term you know the model of don't really change much, right?

472
00:58:55,000 --> 00:59:03,000
So why bother pretty much. Got the same model fit, same pretty much the same flow, pretty much the same R.

473
00:59:03,000 --> 00:59:06,000
Square pretty much in the same means where our reporting in the same everything.

474
00:59:06,000 --> 00:59:10,000
Then why bother include the third term? make a model more complicated? right?

475
00:59:10,000 --> 00:59:14,000
Actually I didn't mention but the interaction term is very hard to interpret.

476
00:59:14,000 --> 00:59:21,000
Just don't bother right go go back here that's the single one, and also the the slope of the interaction term is very tiny.

477
00:59:21,000 --> 00:59:27,000
By the change it means where error and r square, although there is a change, is very fine.

478
00:59:27,000 --> 00:59:36,000
So just don't bother include them where are we

479
00:59:36,000 --> 00:59:49,000
Okay, However, you know the decision of we decide to prefer model to over model 3, but over model one and the model to all of 3 are purely based on t value.

480
00:59:49,000 --> 01:00:05,000
But we know the P. by not always correct. Are there a top final type of error sometimes would make type to error just because lack of power, which means by no means our decision is correct.

481
01:00:05,000 --> 01:00:14,000
Okay, we could just have it. You know, we failed to detect the interacting term because our sample that is too small.

482
01:00:14,000 --> 01:00:20,000
How are you keep? out? Is helpful But don't count on it for making all your decisions right?

483
01:00:20,000 --> 01:00:28,000
If you know a variable, I mean the whole reason you include the variable in your model is because you think it could be a confounder.

484
01:00:28,000 --> 01:00:46,000
If you know a variable from your knowledge, very likely to be a confounder, you'd like to including the model, no matter what the pivotal hand. for example, when you'll study smoking or lung cancer you definitely want to

485
01:00:46,000 --> 01:00:51,000
you include age in the model, Because, you know, age has a new background.

486
01:00:51,000 --> 01:00:58,000
Cancer, any cancer right? So regard for ages, you know, has a significant value or not.

487
01:00:58,000 --> 01:01:04,000
You always want to include, because you know it's a typical problem compounder.

488
01:01:04,000 --> 01:01:12,000
So sometimes the the knowledge of all the variables on top prompt the a few value, right?

489
01:01:12,000 --> 01:01:14,000
You don't want to look at your value alone. so in the end, you know things become subjective again, right?

490
01:01:14,000 --> 01:01:27,000
I know we all want to it's like unify the approach Everybody agree on like mechanically, that's that's just not how things works, unfortunately, or approximately right.

491
01:01:27,000 --> 01:01:31,000
You think they're supposed to be cutting them you know people like me all all the job right?

492
01:01:31,000 --> 01:01:35,000
So a lot of subjective is going on in the model.

493
01:01:35,000 --> 01:01:50,000
So there's no point arguing you know one model is better than the other, because people different people might have different meaning

494
01:01:50,000 --> 01:02:03,000
And one more file I would take up right Okay, so previously, when we compare 2 model, both with one variable.

495
01:02:03,000 --> 01:02:07,000
Only if you still recall. Yet today we compare this to.

496
01:02:07,000 --> 01:02:15,000
We favor the second one, because our square is larger. But I just mentioned right.

497
01:02:15,000 --> 01:02:28,000
Will you compare 2 connected models. this to the r squared It's not so useful because in that the model the Arts Bar is always larger for the larger model.

498
01:02:28,000 --> 01:02:35,000
Let's go back

499
01:02:35,000 --> 01:02:38,000
So ours can be useful by the hyper limitations.

500
01:02:38,000 --> 01:02:48,000
Right in that. The models are always increased the way you increase the new environment. In your model regard the variable is really useful or just a totally random noise variable.

501
01:02:48,000 --> 01:02:52,000
They always increase our square. You know the difference. Just the amount of arts are that increase right?

502
01:02:52,000 --> 01:03:05,000
If you increase the if you include the positive you're out of the noise in arable, the art part increase the tiny bit right? so the pivot is more useful than the hardware idea

503
01:03:05,000 --> 01:03:10,000
Okay. Alright, let me take a break for 10 min.

504
01:03:10,000 --> 01:03:40,000
I will continue to lecture after break

505
01:13:07,000 --> 01:13:13,000
Okay, that's continue so here we were talking about R.

506
01:13:13,000 --> 01:13:22,000
Square could be useful. When we compare different models, well be aware that they are not perfectly you know you.

507
01:13:22,000 --> 01:13:31,000
The informative. In some cases, when we compare like nasty models, our Square always increased, so it's less useful in those settings.

508
01:13:31,000 --> 01:13:36,000
For example, i'm just taking the r square from the 3 models here, right?

509
01:13:36,000 --> 01:13:43,000
The model one was only for our ownership. The Osboro was 7 o 9 0 point 7, all 9, you know.

510
01:13:43,000 --> 01:13:47,000
Model. 2 will include female, 3 sorry rate r squared increase from 0 point 9, 3, 2.

511
01:13:47,000 --> 01:13:56,000
There's a big job, remember, r square is the square of the correlation between the predictive value and the absorbed value. Y.

512
01:13:56,000 --> 01:14:02,000
So. a higher R square is a higher correlation between the predictive observer, which means the model predicts all compatible.

513
01:14:02,000 --> 01:14:06,000
It turns out that will not increase the variable regardless if you' not useful.

514
01:14:06,000 --> 01:14:17,000
You always improve the prediction. a little bit right you model 3 we're, including traction term ds bar becomes 0 point 9, 3, 4, just a tiny bit increase, but still increase.

515
01:14:17,000 --> 01:14:25,000
That's awful consistent with the fact that i'm, all too, you know you create a very useful variable.

516
01:14:25,000 --> 01:14:34,000
Therefore you you help him. Improvement, you know, on a prediction very much from all 3 includes, includes a not so useful, variable, therefore only healthy prediction.

517
01:14:34,000 --> 01:14:43,000
A little bit right, but ours are always increased. So in this case we actually pick the model 2, which has a intermediaries.

518
01:14:43,000 --> 01:14:53,000
Were not available. So people are already aware of this, and they also develop some other alternative version of elsewhere to adjust the hardware.

519
01:14:53,000 --> 01:14:58,000
Basically they try to reduce the hardware where you have more and more variable in the model through account for this fact, right?

520
01:14:58,000 --> 01:15:02,000
And that's adjusting our square will be one way to help you.

521
01:15:02,000 --> 01:15:09,000
You know, select a model, but just like many other way of selecting model. right? there are aic bacc just the hardware.

522
01:15:09,000 --> 01:15:22,000
So there's just so many criteria and they don't always give you the same model, so that make it hard, right, cause you use one right here. you can keep this model you use the other part here to help peek the other model so in the

523
01:15:22,000 --> 01:15:28,000
end he's very very subjective which model okay don't rely on any single metric.

524
01:15:28,000 --> 01:15:37,000
It's not gonna be universally Oh, applicable

525
01:15:37,000 --> 01:15:40,000
Now let's move on. I think we have done with model selection right?

526
01:15:40,000 --> 01:15:44,000
There are some useful metrics, but you know Indiana is a more more of a art than science.

527
01:15:44,000 --> 01:15:52,000
And now let's move on model interpretation. So we already talk about this right in simple in your regression model.

528
01:15:52,000 --> 01:15:59,000
We have a we have a interest. we have a slope and the model look like this. right?

529
01:15:59,000 --> 01:16:14,000
We know the intercept is the predictive value. Why, when you let x equals 0, which may, it may not, be practically meaningful, depend on whether 0 is in the range of your data or not right?

530
01:16:14,000 --> 01:16:27,000
Nevertheless. the slope is always useful, because the slow represents the difference in predicted why will increase x by one unit right in this case, if you access, you know 20%?

531
01:16:27,000 --> 01:16:34,000
No, we got predicted. Why, you've access 21% of the why then, the difference in the predic?

532
01:16:34,000 --> 01:16:40,000
Why is the smoke right? The slope is always very, very useful.

533
01:16:40,000 --> 01:16:44,000
Are the top on this right? so the slope is the

534
01:16:44,000 --> 01:16:52,000
The change in predicted Y. When you change x by one, if I change, I mean either increase or decrease right.

535
01:16:52,000 --> 01:16:57,000
If the slope is partner, which means the changing political, why go in the same direction as a changing X.

536
01:16:57,000 --> 01:17:06,000
If the slope is negative, which means the changing pretty good Wikipedia in the other direction, Hi regardless. right?

537
01:17:06,000 --> 01:17:18,000
So again, go ahead. Every unit increasing has the expected. value of y we've increased by the amount equal to. the So which means how, if you increase x by 10 units Exactly.

538
01:17:18,000 --> 01:17:24,000
Why? by 10% points. Then you would expect why to decrease by 10?

539
01:17:24,000 --> 01:17:33,000
Because here the slope. Oh, yeah, if you decrease access by 10 unit, then the Y will.

540
01:17:33,000 --> 01:17:46,000
The expected y will decrease, by 10 times. the slope so it's all proportional that means it's That's why we call it a linear model, because everything is this linear it's proportional

541
01:17:46,000 --> 01:17:55,000
Yeah goes back. If you assume the relationship between X and Y is not lead, How do you do with that?

542
01:17:55,000 --> 01:18:01,000
There are a few approaches, Lonnie. you can do a transformation.

543
01:18:01,000 --> 01:18:13,000
So you assume, y goes as the square of x that you'll, just you can take square of that. so you can take square root of the Y before you'll see them all or log or exponential, or any function right you have some idea

544
01:18:13,000 --> 01:18:17,000
in what kind of function you are filling you can take the transformation to make them.

545
01:18:17,000 --> 01:18:28,000
Linear and if you really don't know what kind of function you you validate back, you can actually put things like the supplies. I mean, this is go beyond the course.

546
01:18:28,000 --> 01:18:34,000
200, Basically, what i'm saying, you put different curves in the model and let them model figure out what exactly function you want to pick.

547
01:18:34,000 --> 01:18:40,000
Usually they use, you know, cubic lines that's cubic spines.

548
01:18:40,000 --> 01:18:47,000
So there are cases, but not what we know. the some disease, or some some events like car accidents.

549
01:18:47,000 --> 01:18:54,000
Right they go. They don't go linearly with age. Remember the the the car accident rate is a yield.

550
01:18:54,000 --> 01:19:03,000
Shake curve with age by for very young or very old people. The accident rate is higher than the mid age Cool, alright.

551
01:19:03,000 --> 01:19:08,000
So it's that minority. So what do you do right you could use a quadratic function approximate right?

552
01:19:08,000 --> 01:19:13,000
You basically include both the linear term you of age and the quadratic form.

553
01:19:13,000 --> 01:19:19,000
Eventually, I'm saying, you Include X. and X. squared both in the model.

554
01:19:19,000 --> 01:19:25,000
Then that will feed any quadratic function. I will, you know, automatically figure out it usually curve for you.

555
01:19:25,000 --> 01:19:36,000
But right so, including a square term, or even a cubic terminal model, will allow you to fit almost, and and any curve you like

556
01:19:36,000 --> 01:19:43,000
We're not changing much of the the linear question you know So now let's move on right.

557
01:19:43,000 --> 01:19:46,000
So what will be the interpretation of the intercept the slope?

558
01:19:46,000 --> 01:19:51,000
What we have multiple new regression. I remember we have audibly directed.

559
01:19:51,000 --> 01:19:58,000
Here we have one inner side. We have 2 slopes

560
01:19:58,000 --> 01:20:02,000
So let me ask you, what is the intercept in the multiple interaction model?

561
01:20:02,000 --> 01:20:32,000
What does the interests, I mean should be a simple, general, right-hand side. simple. You know, anymore. Anybody want to try to interpret the interse having the monitoring model

562
01:20:53,000 --> 01:21:02,000
Okay, So you use the same idea right in this equation, which is the multiple integration equation.

563
01:21:02,000 --> 01:21:10,000
If you left both X one X 2 to be 0 Then the why? predicted Why, we'll send you the email.

564
01:21:10,000 --> 01:21:15,000
So you've both x one that's where there will be 2 terminal call. remains right.

565
01:21:15,000 --> 01:21:25,000
So the intercept in the multiple university model is the predictive value of all the variable. if all the variable is not only one for all of them.

566
01:21:25,000 --> 01:21:36,000
Again, not particular by that particular combination may not be practically meaningful, because that particular combination may not lie in the middle of your data, and may not be even practically possible right.

567
01:21:36,000 --> 01:21:43,000
But now, with the last that's the integrity of the user side, That's why interest up is this you know sometimes useful, but not always useful.

568
01:21:43,000 --> 01:21:48,000
What the slope is always useful so let's now move on to the slope.

569
01:21:48,000 --> 01:21:56,000
The slope in the multiple regression model is a little harder to being target.

570
01:21:56,000 --> 01:22:00,000
But we have to do it because that's that's the most important thing.

571
01:22:00,000 --> 01:22:03,000
So let's plug in 2 2 numbers right x one and x 2.

572
01:22:03,000 --> 01:22:09,000
Let's take 2 random numbers and plug in when we have Xy was 15% x 2 plus 2.

573
01:22:09,000 --> 01:22:15,000
We plug in here? and then the predict, Why is this number?

574
01:22:15,000 --> 01:22:25,000
And then when we increase X one by one unit here the unit is percentage, That's why 0 point 1 6 actually for the 16 here.

575
01:22:25,000 --> 01:22:30,000
Okay, if we put in the increase X one by one unit.

576
01:22:30,000 --> 01:22:35,000
Oh, I guess I should have written x* they're always me the fix.

577
01:22:35,000 --> 01:22:41,000
Act 2, and we got another particular one. You see the predicted why you increase.

578
01:22:41,000 --> 01:22:45,000
And just look at this 2 number The amount that particular wide increase will increase. X.

579
01:22:45,000 --> 01:22:56,000
One by one unit, while fixing has 2 unchanged, is the slope

580
01:22:56,000 --> 01:23:02,000
Hi sounds good. So question in the chat It seems like there's a typo on the slide.

581
01:23:02,000 --> 01:23:09,000
There is. yeah, you have to write this there's stephanie of High Paul. distribute that this should be this number.

582
01:23:09,000 --> 01:23:15,000
Right. Yeah, Thank you. Pull out me all, did it? Yeah, this should be 1 point, 1, 3, 5.

583
01:23:15,000 --> 01:23:24,000
Nevertheless, you know. Yeah. you know the the conclusions the whole

584
01:23:24,000 --> 01:23:29,000
Yeah, the change in the predictable way, why turnout will be the need.

585
01:23:29,000 --> 01:23:41,000
This up here, so that So the intercept in a module in your record model has almost the same interpretation as the sampling aggression model, except with one condition.

586
01:23:41,000 --> 01:23:49,000
Okay? So which means that

587
01:23:49,000 --> 01:24:02,000
This right i'm really percentage, for increasing part ownership the expected rate of male suicide will increase by a month equal to equal to the slope.

588
01:24:02,000 --> 01:24:08,000
And then this, this: they are new amongst states that have the same level.

589
01:24:08,000 --> 01:24:16,000
Females Reset. this is the private interpretation in general.

590
01:24:16,000 --> 01:24:23,000
You could say the interface for a particular variable means, we will increase that variable Y one unit.

591
01:24:23,000 --> 01:24:36,000
Thanks. And why will equal to that intersect comma, assuming all other variable are fixed because you could have x, 3, x, 4 x 5. right?

592
01:24:36,000 --> 01:24:50,000
So, assuming all how the variable are fixed, we could say, keeping all other variable, constant, or you can say, controlling for all other variables, no matter how you say it, that has to be there right because this difference only makes sense where you fixed.

593
01:24:50,000 --> 01:24:59,000
The other variable unchanged. This number could be 2 could be 3 could be any number doesn't matter, but the key is that they should not change right.

594
01:24:59,000 --> 01:25:05,000
So this number means will increase, for our ownership you would expect widely increased by this amount.

595
01:25:05,000 --> 01:25:15,000
If females would have it doesn't change and this line for me is that if you increase email suicide rate, then the male suicide rate will increase by this amount, if you assume our ownership doesn't change

596
01:25:15,000 --> 01:25:22,000
right, so every number is assuming. All other variables do not change

597
01:25:22,000 --> 01:25:39,000
Similarly, you know I didn't talk about this for this key value Remember, he's testing this particular beta 0 now, and that is assuming all other Beta could be helpful.

598
01:25:39,000 --> 01:25:44,000
So when that has this data, I don't really care about other people automated could be nonzero.

599
01:25:44,000 --> 01:25:50,000
So this pivotal means marginal right, we would have all other variable in the model.

600
01:25:50,000 --> 01:25:57,000
Is this matter ofable still contributing anything additional so that's the conditional sort of a key line.

601
01:25:57,000 --> 01:26:07,000
It's not marginal key. about it now you could think about marginal Cuba is this variable to this variable to do is why, regardless of all the variable that's not the case, this pivot

602
01:26:07,000 --> 01:26:09,000
means, you know, with all other variable already in the model.

603
01:26:09,000 --> 01:26:18,000
Already. nonzero. Is this paid off 0 or not it's conditional all the way in the model.

604
01:26:18,000 --> 01:26:20,000
So the slope and the key value is all you know.

605
01:26:20,000 --> 01:26:26,000
Depending on other slope, and the key line

606
01:26:26,000 --> 01:26:34,000
Alright, so essentially you just add this send us to the patient and that'll be it right, you know, controlling for the level.

607
01:26:34,000 --> 01:26:53,000
All other variables. any questions, so far

608
01:26:53,000 --> 01:26:59,000
Okay, Now let's move on talk about after repeat the model.

609
01:26:59,000 --> 01:27:03,000
How do we You bother it, or diagonal What?

610
01:27:03,000 --> 01:27:10,000
How, how how good the model fitting is. But remember, all models are well, but somewhat useful.

611
01:27:10,000 --> 01:27:14,000
We do want to pick a model which apparently doesn't feed the data right?

612
01:27:14,000 --> 01:27:21,000
Each model has its own assumptions. Those are assumptions are not, are never perfectly correct parties.

613
01:27:21,000 --> 01:27:29,000
We shouldn't pay the model when the assumption is obviously well.

614
01:27:29,000 --> 01:27:34,000
In those cases, you know, the results are not just very meaningful where you cannot force them.

615
01:27:34,000 --> 01:27:39,000
Model to the data. You need to say the model. naturally, if the name right.

616
01:27:39,000 --> 01:27:46,000
So it turns out that this simple and the multiple in your regret rely on 3 assumptions.

617
01:27:46,000 --> 01:27:51,000
They're not all equal. Some of the assumption are more crucial than others.

618
01:27:51,000 --> 01:28:01,000
Okay, i'll explain them. The first assumption meaning the arrow are normally distributed, which means 0 that's the normality assumption.

619
01:28:01,000 --> 01:28:07,000
Remember y equals alpha plus beta one x one plus beta plus 2 plus the error.

620
01:28:07,000 --> 01:28:19,000
Right. So there's a random error so the assumption is that the random error is normal, and that's the assumption underlying all the pieces that we use t statistic to do the test but those are based on this

621
01:28:19,000 --> 01:28:29,000
assumption. It turns out that this is something is not so crucial because the T statistics do, host.

622
01:28:29,000 --> 01:28:36,000
As long as you have large, sample size that's what I don't even feel. Nevertheless, right if you are.

623
01:28:36,000 --> 01:28:47,000
If your arrow is highly skilled. this may not be the best model you want to use, because you know you'll be sensitive to our that's all.

624
01:28:47,000 --> 01:29:03,000
But in most cases we don't worry too much about the normalality as long as it's reasonable why not so strongly queue to be fine and second one, the arrow are normally distributed with a variance

625
01:29:03,000 --> 01:29:11,000
that is unrelated to which means not only is normal, but also at the moment with the same, the same standard deviation.

626
01:29:11,000 --> 01:29:16,000
So basically different data points should have the same level of noise.

627
01:29:16,000 --> 01:29:27,000
You cannot have One data part has a bigger noise than the other.

628
01:29:27,000 --> 01:29:45,000
It turns out that the second assumption is more important than the first assumption, but still is not. I would say critical in a sense that if you really have data which are, you know not constantly doesn't they don't have confidence, I think

629
01:29:45,000 --> 01:29:50,000
he's the digital term that's that's called the hydroscope that's necessity.

630
01:29:50,000 --> 01:29:56,000
It's a very long term I didn't put it here because it's very, you know, just just terminology.

631
01:29:56,000 --> 01:30:02,000
If your data really you know They'll probably have different variants are you still fit? I'm.

632
01:30:02,000 --> 01:30:18,000
Using this model, you lose power. Okay, if if the data has different variable, you assume they have the same water, you lose power, which means that you have lower chance of finding association, but it's unlikely.

633
01:30:18,000 --> 01:30:27,000
That you you play your type one out Okay, so you're not going to make a big, false binding is more likely you just lose your power.

634
01:30:27,000 --> 01:30:36,000
So It's bad but it's not that bad right So there are matters to deal with this Hydro, this discussedasticity issue right?

635
01:30:36,000 --> 01:30:40,000
You could use those models which are beyond what we learn.

636
01:30:40,000 --> 01:30:43,000
This cost

637
01:30:43,000 --> 01:30:54,000
But the third assumption is really crucial. The third assumption means that the regretment model completely explain the true associated.

638
01:30:54,000 --> 01:31:00,000
Why has with each X variable means that the linearity right?

639
01:31:00,000 --> 01:31:03,000
Remember y equals alpha plus beta one x one plus beta, 2 x 2. right?

640
01:31:03,000 --> 01:31:12,000
Basically say, Why is linear in X one and x 2 and that's the fundamental thing you're modeling the relationship is an excellent right.

641
01:31:12,000 --> 01:31:17,000
If that relationship is wrong, just like you know when you use peers that's all correlation.

642
01:31:17,000 --> 01:31:23,000
But when X and y are not linearly associated, number is nothing right.

643
01:31:23,000 --> 01:31:28,000
You gotta slope out of it. or what if the slope is not even there? right? you know.

644
01:31:28,000 --> 01:31:32,000
Why is a quadratic function? How do you even define the slope by the slope?

645
01:31:32,000 --> 01:31:39,000
Is is changing regarding was different value events. so which means in those case the model is automatically wrong.

646
01:31:39,000 --> 01:31:44,000
You just sure that, using the first place? now, you will say, what do I do?

647
01:31:44,000 --> 01:31:50,000
I talk about that right. If y has a different relationship with that, you should do transformation before you fit the model, or you could.

648
01:31:50,000 --> 01:32:04,000
You could include nonlinear terms in your mom, right? If you include the X square term in your model, then that can explain any quadratic rate, it should be doing that

649
01:32:04,000 --> 01:32:07,000
And then how do we assess all these 3 assumptions?

650
01:32:07,000 --> 01:32:15,000
Right. after we feed the model, we could actually have a few tools. It's called a model diagnosis.

651
01:32:15,000 --> 01:32:23,000
If you use physical software, you can have the software to spit all those those speakers and one of the useful to very useful tool.

652
01:32:23,000 --> 01:32:28,000
Yes, 2 do this talk about the residual part. So what we do is after a feed.

653
01:32:28,000 --> 01:32:40,000
The model, We'll? look at you might be thanks you know so, Justin, why don't we just plot the raw data? you scatterpa, and then see the line right?

654
01:32:40,000 --> 01:32:46,000
The truth is that you cannot. You can only do a scatterp with excellent Why, you have 5 different acts.

655
01:32:46,000 --> 01:32:55,000
You can not even do this kind of part right that's Why, we make a different kind of off right. It still scatter plot.

656
01:32:55,000 --> 01:32:59,000
But we pick the 2 variable that we want to apply right.

657
01:32:59,000 --> 01:33:04,000
You can pause one against every single x. Oh, you cannot plot the Y against all the x.

658
01:33:04,000 --> 01:33:13,000
Yeah. So in this case, after a few months, we have the Y from the data. we also have the Y hat, which is the predictive one, have the freedom model.

659
01:33:13,000 --> 01:33:20,000
We have both, then we can imagine the residual, which is, Yeah, I have remember.

660
01:33:20,000 --> 01:33:23,000
Ei is the error. Yeah, I had it's the estimate of error.

661
01:33:23,000 --> 01:33:28,000
We call the residual Yeah, I have it's basically a y minus y.

662
01:33:28,000 --> 01:33:39,000
I have, we can't compute this I have remember the 2 of some The first 2 assumption basic saying that the error should be normal, distributed with mean 0, and the conference.

663
01:33:39,000 --> 01:33:47,000
We never know the arrow, because those are unobserved. Well, we know the good estimate on our which is a museum.

664
01:33:47,000 --> 01:33:56,000
If the arrow is normally distributed with mean 0 and the cost of errors, then the residual should also be, and we can follow the regime.

665
01:33:56,000 --> 01:33:59,000
Not only are we gonna make a pistol ground of the residual, even better.

666
01:33:59,000 --> 01:34:07,000
We can follow residual against some other variable

667
01:34:07,000 --> 01:34:16,000
So what we do last using vulnerable Okay, here we kind of assess the knowledge of the residual by making a histogram.

668
01:34:16,000 --> 01:34:24,000
The residual. Then that's piece of ram should Have a center call to 0 should be symmetric shape around 0.

669
01:34:24,000 --> 01:34:35,000
Alright, let's take this simple integration fit and gather residual and make a hitogram out of the resume.

670
01:34:35,000 --> 01:34:40,000
You see that it's not too bad right there our couple of data points as high residual.

671
01:34:40,000 --> 01:34:49,000
But overall it's not too bad is a little skill like I thought.

672
01:34:49,000 --> 01:34:53,000
No no matter assumption. it's not so crucial because essentially material.

673
01:34:53,000 --> 01:34:59,000
Here we have a sample size of like a 50 by the sample size Depends on a number of variables.

674
01:34:59,000 --> 01:35:05,000
Right when you have 2 variable in your model, as samples of 50 is like is sufficient.

675
01:35:05,000 --> 01:35:08,000
Well, we have 10 variable in the model something that's 50 will be small.

676
01:35:08,000 --> 01:35:18,000
There are some rule of time. How many what's the sample size you should collect right to do a formal power analysis. But that require you to collect a lot of information about the effect size of all our ability?

677
01:35:18,000 --> 01:35:21,000
On anything Right? Oh, the rule of problem is, every variable.

678
01:35:21,000 --> 01:35:33,000
We include the model. You need to increase your samples about 10 to 20, so you have 10 variable in your model. I would say you have a sample size of 200 to the reasonably confident that you know sometimes not too, small right

679
01:35:33,000 --> 01:35:46,000
right now. this model has, like a 2 or 3 variables, so we have some of the other 50, which is probably fine

680
01:35:46,000 --> 01:35:50,000
So it turns out that the 3 data points with high residual are the 3 data points here.

681
01:35:50,000 --> 01:35:57,000
We know that available of all are in the first place right there. you know roughly on the margin of being all wires.

682
01:35:57,000 --> 01:36:07,000
I don't think there are you fact you know Cuba. We have 50 data points and given these 3 points life sort of in the middle range of the acts, and also their residual is not crazy.

683
01:36:07,000 --> 01:36:13,000
Big. Personally, I don't think they have a big impact are you feel suspect they are.

684
01:36:13,000 --> 01:36:18,000
They have a big impact. What you can do is that you have kick them out one by one or altogether.

685
01:36:18,000 --> 01:36:22,000
Let's see whether the p value of whether the slope of either does have change along.

686
01:36:22,000 --> 01:36:33,000
I thought they will that's one way to assure yourself that your model is not driven by how liars alright turns out.

687
01:36:33,000 --> 01:36:37,000
You can also look at their nevada our result on New Mexico.

688
01:36:37,000 --> 01:36:52,000
I don't know why they have a you know high male suicide rate, given mid range of fire ownership. It's interesting to figure that out, but at least for this particular model of feeling i'm not worried about them.

689
01:36:52,000 --> 01:36:57,000
Oh, you they are sort of like here right I don't know you can see my mom if they are way online.

690
01:36:57,000 --> 01:37:02,000
Then i'll be worried give them the place they were they are i'm not.

691
01:37:02,000 --> 01:37:14,000
Oh, you could! You could easily chat right by removing them and refuse the model here

692
01:37:14,000 --> 01:37:18,000
So many of the students. I teach this course war about residuals.

693
01:37:18,000 --> 01:37:24,000
I worry about our lives more than I do my my message was always right.

694
01:37:24,000 --> 01:37:28,000
If you worry about something, you can try to remove them to see what your conclusion change right.

695
01:37:28,000 --> 01:37:41,000
If your conclusion doesn't change which is typically the case then there's nothing to be worry about. You just don't want your conclusion to be totally driven by a few data points. and That's of course, not good but most

696
01:37:41,000 --> 01:37:55,000
of the time. it's not like that the model or model both that you would imagine actually any questions so far

697
01:37:55,000 --> 01:38:00,000
I mean there will be cases right you can't imagine you you pay the data.

698
01:38:00,000 --> 01:38:03,000
You feed them model with your data, you gotta keep out of 0 Point 5.

699
01:38:03,000 --> 01:38:09,000
One i'll kick off my data point Now i've got a pivot of 0 point 4 9.

700
01:38:09,000 --> 01:38:16,000
I would be very present. This result because I don't trust the 0 point 4 9, right?

701
01:38:16,000 --> 01:38:21,000
Because you got your point for that just because you'll kick call a data point myself.

702
01:38:21,000 --> 01:38:27,000
Maybe Google back, but this whole pockets make it very suspicious.

703
01:38:27,000 --> 01:38:38,000
Multiple passing right. All of this right. so you know after you learn the course after this course I have to do many exercise. I think you got a feeling what kind of practice is fine.

704
01:38:38,000 --> 01:38:52,000
What kind of practice is dangerous. there's no clear top Oh, you just caught up behind

705
01:38:52,000 --> 01:38:56,000
Okay, so you could do a residual call like that.

706
01:38:56,000 --> 01:39:05,000
You have to do more. Remember, we assume conference we haven't tracked that yet, right?

707
01:39:05,000 --> 01:39:09,000
How do we know they have constant variance? We just check the normal model assumption.

708
01:39:09,000 --> 01:39:23,000
One. How do we check constant variance? We can actually plot the feeding value or the residue either way

709
01:39:23,000 --> 01:39:27,000
Oh, guess each of the variable or even repeated value.

710
01:39:27,000 --> 01:39:31,000
So. if the constant variance hold, then there should be no visual pattern in the plot.

711
01:39:31,000 --> 01:39:41,000
What do I mean by that, and look at it right? So these are the part of the scalar part of the Fiddie via, which is the white hat versus the reason?

712
01:39:41,000 --> 01:39:58,000
If the residual has constant variance, which means it should scatter around the horizontal line of 0 up or down with no clear pattern, the residual should be random, half a down, with no clear problem

713
01:39:58,000 --> 01:40:05,000
I in this particular part we see that it is mostly the case except a couple of outers right again.

714
01:40:05,000 --> 01:40:13,000
I'll let her show up on every call like this

715
01:40:13,000 --> 01:40:16,000
Okay, i'm not personally i'm not glorious.

716
01:40:16,000 --> 01:40:22,000
This means the cost of variance. Assumption is roughly okay.

717
01:40:22,000 --> 01:40:40,000
When it is not okay, let me show you a case when it is not okay.

718
01:40:40,000 --> 01:40:48,000
So if the regional plot right, look like this. This is a y hat.

719
01:40:48,000 --> 01:40:58,000
Is this: You know, Ei, how this is 0, right? So a good one will be like, you know, the one on the right except for the online.

720
01:40:58,000 --> 01:41:09,000
Well, you have a resume, a P. look like this

721
01:41:09,000 --> 01:41:14,000
Right, You signed up the variance of the residual increase with a variable y.

722
01:41:14,000 --> 01:41:21,000
That means the costumes are constant. Variance or something is just one right.

723
01:41:21,000 --> 01:41:25,000
In this case you can still feed the model. Actually, your bottle of it is still unbiased.

724
01:41:25,000 --> 01:41:40,000
Somehow. but you lose a lot of power, so we'd be a lot better to to take care of this and some single way of taking care of this is to some so called the virus stabilizes so very stabilizing

725
01:41:40,000 --> 01:41:43,000
transformation. Exactly. If I try to take the square root of y, take the log of y.

726
01:41:43,000 --> 01:41:51,000
There are many of those to stabilize the variance and that now way you'll get a better i'm out with it.

727
01:41:51,000 --> 01:42:01,000
But you know that will change your invitation right? So you may or may not want to do that, or you could feed the model like this, but not with simple in your regression, but with some more sophisticated version.

728
01:42:01,000 --> 01:42:19,000
There are, there are way for fit model like this, which is beyond this course, because I, you know from the polypendic, and see whether things are good on that

729
01:42:19,000 --> 01:42:27,000
Okay, and the finally, we we assess the third of employees in linearity.

730
01:42:27,000 --> 01:42:32,000
Right, we assume. Why is linear in every single app? Actually, the assumption is more than that.

731
01:42:32,000 --> 01:42:37,000
The why is linear in jointly in order X. But you cannot really assess that.

732
01:42:37,000 --> 01:42:42,000
So you can only assess why marginal, you was okay.

733
01:42:42,000 --> 01:42:55,000
So how do we look at it? Similarly, we can make a plot of the residual against every single pass

734
01:42:55,000 --> 01:43:04,000
If y it's joyfully linear and everything will act which means the model will explain most of the relationship.

735
01:43:04,000 --> 01:43:16,000
Did you act via and all that? The model, we explained away all of them, which means, I only think remaining half of the model fit is the residual and the residual self is just random noise right?

736
01:43:16,000 --> 01:43:26,000
Which means again, you should not see any pattern Does might be cool

737
01:43:26,000 --> 01:43:31,000
This is a again not so bad one, right, you know. live along the all eyes.

738
01:43:31,000 --> 01:43:37,000
This is a pretty good one.

739
01:43:37,000 --> 01:43:42,000
Well, what is a bad part? The backpack is when you'll see a pattern out of this kind of pop.

740
01:43:42,000 --> 01:43:51,000
What kind of hot I don't have an example here I mean draw from it.

741
01:43:51,000 --> 01:43:59,000
You can so who's out on you if y

742
01:43:59,000 --> 01:44:07,000
If Y was originally like nonlinear with that

743
01:44:07,000 --> 01:44:17,000
But you still feel the linear linear regression. What you will find is that residual will show that lot nonlinear nice.

744
01:44:17,000 --> 01:44:29,000
The reason your cloud may look like this

745
01:44:29,000 --> 01:44:35,000
So essentially, you see, the residual will be parted for a certain range of that will be negative for other rank of act.

746
01:44:35,000 --> 01:44:41,000
I just see this kind of thing

747
01:44:41,000 --> 01:44:46,000
So i'm the same

748
01:44:46,000 --> 01:44:50,000
This this sort of a diagnostic plot. They are useful, right?

749
01:44:50,000 --> 01:45:01,000
They can help you capture when the model fitting is insufficient, or things like those. But they don't guarantee the model feeding is good. it's possible that your model is not good Yeah, and by the dog

750
01:45:01,000 --> 01:45:08,000
and those top of the show that because each time you only plot one variable, you cannot pull all 5 together, Right?

751
01:45:08,000 --> 01:45:15,000
Maybe jointly. The model is bad, but look at it by variable each time you don't see it

752
01:45:15,000 --> 01:45:22,000
But the other hand is how if the diagnostic part shows something weird, then the model definitely is weird.

753
01:45:22,000 --> 01:45:28,000
Okay, so it's a useful not the tool but it doesn't guarantee.

754
01:45:28,000 --> 01:45:32,000
I'm always good

755
01:45:32,000 --> 01:45:43,000
Okay. So the overall conclusion of this model of feeling is that for our part of all, we conclude that none of the assumptions appear to be violated. Right?

756
01:45:43,000 --> 01:45:48,000
None of the diagnostic paths show. strong. Highland indicated the assumption, violation, right?

757
01:45:48,000 --> 01:45:56,000
All the concurrently, the eyeball right subjective, and you can never prove that assumption or not live in.

758
01:45:56,000 --> 01:46:05,000
I just fail to find anything weird again. And finally, there are 3 States up here to not a feed the model. Very well, right.

759
01:46:05,000 --> 01:46:10,000
Maybe you can try to the model, or maybe you just kick all the 3 States to see whether things change.

760
01:46:10,000 --> 01:46:17,000
I thought they will personally, i'm not worried about the 3 States in this particular model.

761
01:46:17,000 --> 01:46:35,000
Finally, you know, we have extended single single in your graph model for a multiple in your graph model for your include one variable.

762
01:46:35,000 --> 01:46:41,000
As a confounder, to include 2 variable as an effect modifier bye.

763
01:46:41,000 --> 01:46:49,000
And we can. This is not a limitation. We actually include more than 2, one or 3.

764
01:46:49,000 --> 01:46:56,000
Okay. But the problem is that i'll make the model very complicated and hardly interpreted. right.

765
01:46:56,000 --> 01:47:11,000
You have to strike about it. You want to find the smallest model which characterize or explain what models the data rhythmically.

766
01:47:11,000 --> 01:47:14,000
Well right, capture the main trend main variation in the data.

767
01:47:14,000 --> 01:47:17,000
Oh, you don't wanna be overfitting overfitting my whole opinion.

768
01:47:17,000 --> 01:47:21,000
We mean. the model is over the complicated Wait a week, I mean the model.

769
01:47:21,000 --> 01:47:30,000
Explain the data perfectly that's the sign of being overfitting

770
01:47:30,000 --> 01:47:36,000
Bye, whether you're overfitting or not depends on how many variable you are you have, and how many data points you have right.

771
01:47:36,000 --> 01:47:51,000
If your data points is small compared to the number of variables, then you run into the risk of overpaying

772
01:47:51,000 --> 01:47:54,000
And there there are ways to trying to. qualify.

773
01:47:54,000 --> 01:48:03,000
Now, you know, over 30. This is beyond the force here but you know if if you're like, I said, give you a number based on the rule of pump right?

774
01:48:03,000 --> 01:48:07,000
The number of Oh, you can Sample size is like 10 or 20 times your number of variables.

775
01:48:07,000 --> 01:48:12,000
They are most be okay. but if you, while at that room be careful.

776
01:48:12,000 --> 01:48:17,000
It might be over

777
01:48:17,000 --> 01:48:27,000
And if again, if you assume a variable is really useful here based on knowledge, whether it has a p value or not doesn't matter, you should always include them all.

778
01:48:27,000 --> 01:48:31,000
Okay, there, there may be many relationship. you feel variable of the variable interest.

779
01:48:31,000 --> 01:48:38,000
Right. So, for example, if X is high, why is not all of these 8 right?

780
01:48:38,000 --> 01:48:44,000
Just look at X on y. You might find them. how do you associate it? Hi!

781
01:48:44,000 --> 01:48:53,000
They correlated, so you might think, Oh, Polar people will have higher math school, or will you include aging it?

782
01:48:53,000 --> 01:49:00,000
You might see the association goes away right. The relationship between X and Y is equal to very complicated.

783
01:49:00,000 --> 01:49:06,000
One simple case could be, Z is driving both x and Y that call the spurious correlation.

784
01:49:06,000 --> 01:49:09,000
If you have one that could be more than that right Z could be driving.

785
01:49:09,000 --> 01:49:12,000
Live acts would be partially driving wide or not, as Z.

786
01:49:12,000 --> 01:49:17,000
Could be correlated with that for unknown reason I there could be something else.

787
01:49:17,000 --> 01:49:21,000
You're missing like w you would you know driving both sides of Z. right?

788
01:49:21,000 --> 01:49:28,000
So there could be a very, very complicated hub. And even this path, even if you have a graph like this, is called a call or graph right.

789
01:49:28,000 --> 01:49:36,000
It may be a simplification of the real world, because in real world. You could have both a causes B and B causes A.

790
01:49:36,000 --> 01:49:45,000
Because i've cycles right really hard to teach them all

791
01:49:45,000 --> 01:49:56,000
For example, low income and mental health issue. but they are definitely associated.

792
01:49:56,000 --> 01:50:03,000
There are definitely, you know, related, either direct or indirectly.

793
01:50:03,000 --> 01:50:06,000
You could imagine they form a cycle. I will have loaning comedy tend to have.

794
01:50:06,000 --> 01:50:17,000
I don't have the usual Vice versa but it's really hard for Tesla, which one is the cause it's on point

795
01:50:17,000 --> 01:50:24,000
So you know real world is much more common. Yeah, finally i'm gonna go back to a shower example.

796
01:50:24,000 --> 01:50:28,000
You know, the compounding can show up in many different forms. Right?

797
01:50:28,000 --> 01:50:31,000
We have talked about many different form, but let's talk about one final.

798
01:50:31,000 --> 01:50:40,000
I hope it's final example. it's nava enough So this is the so-called very famous thing since paradox.

799
01:50:40,000 --> 01:50:47,000
So suppose we collect data from 2 hospitals. so cost with A and B, and then we see.

800
01:50:47,000 --> 01:50:53,000
Come, you know, during a period of time. Hospital, hey? For 2,100 patients hospital.

801
01:50:53,000 --> 01:50:58,000
These are 800 patients, and with the hominid diet in each hospital communism live.

802
01:50:58,000 --> 01:51:06,000
And the visit the number. So these are real data, supposedly we we put them into a 2 by 2 table Bye.

803
01:51:06,000 --> 01:51:11,000
I'm missing the third column as the marginal songs Are you know what i'm in?

804
01:51:11,000 --> 01:51:17,000
So the question is, the which hospital is bad or safer.

805
01:51:17,000 --> 01:51:23,000
You see that in hospital a it saw 2,100 patients, and among them $63.

806
01:51:23,000 --> 01:51:31,000
So the death rate is 3%. they higher than me. and Hospital B is 2%.

807
01:51:31,000 --> 01:51:39,000
Just from this data you might be hospital a safer. The hospital be

808
01:51:39,000 --> 01:51:48,000
Not just by itself. everything else equal that's what you should conclude

809
01:51:48,000 --> 01:52:01,000
However, if you collect a third variable application, you break it down into patients with good condition and patients with poor condition.

810
01:52:01,000 --> 01:52:07,000
Now you have 2 stop tables right so this is a hobby i'll be a and B.

811
01:52:07,000 --> 01:52:16,000
So you see that if you add up the 2 soft table here, you actually got a previous table that was 6 P.

812
01:52:16,000 --> 01:52:20,000
57 equals 63 that's the number we had earlier.

813
01:52:20,000 --> 01:52:23,000
So this is just a breakdown when you collect the new variable.

814
01:52:23,000 --> 01:52:32,000
What's so surprising is that if you look at each group now, hospital, hey?

815
01:52:32,000 --> 01:52:41,000
It's actually let's say that hospital so here 6 out of 608 out of 600 hospital.

816
01:52:41,000 --> 01:52:49,000
B. No hospital, hey? Actually this, say for the hospital B, which is opposite right here in good in good condition.

817
01:52:49,000 --> 01:52:57,000
Pages hospital a safer in poor condition. patients. You can do the math hospital a again safer, but we will put them together.

818
01:52:57,000 --> 01:53:03,000
The hospital. Ai trees. Possibly so. this this time, you know.

819
01:53:03,000 --> 01:53:06,000
Previously we had, when you had a third variable right.

820
01:53:06,000 --> 01:53:18,000
Your conclusion is either way weakened, or disappear it's weakened in the in the firearm case it's disappeared. in the you know school case, you know what vocabulary and the high case right are these the case

821
01:53:18,000 --> 01:53:21,000
when you add a third variable You'll conclude it not only is up here.

822
01:53:21,000 --> 01:53:28,000
But although, actually flip the sign before you'll collect this data, you will see hospital, hey?

823
01:53:28,000 --> 01:53:32,000
Is let's say. but after you see this day hey?

824
01:53:32,000 --> 01:53:36,000
It's actually safe for both kind of patients so so what's going on. and that's because this is a compounder.

825
01:53:36,000 --> 01:53:45,000
Not only a conf follower it's actually one of the common. I don't even know how to call right the only reason for this.

826
01:53:45,000 --> 01:53:51,000
Now this is so surprising that people call it the same since paradox apparently find my Simpson.

827
01:53:51,000 --> 01:53:54,000
It's almost like a power, though but there's nothing paradoxic.

828
01:53:54,000 --> 01:54:03,000
The only reason for this happening is because if you look at a number poor condition, patients tend to go to pass hospital to 8 and hospital B.

829
01:54:03,000 --> 01:54:07,000
So hospital ac more port condition patents that's Why, I put the gather.

830
01:54:07,000 --> 01:54:18,000
There are more of that from hospital A so basically patience which hospital to go to is associated with their condition, and also socially with with that.

831
01:54:18,000 --> 01:54:22,000
So there's a confounding going on but without you collect this data.

832
01:54:22,000 --> 01:54:30,000
You can never really realize that that's the case

833
01:54:30,000 --> 01:54:35,000
So is this conclusion: That hospital be safer, correct, right or wrong, apparently here is correct.

834
01:54:35,000 --> 01:54:44,000
But here it is one, However, once that photo you think you got the truth.

835
01:54:44,000 --> 01:54:56,000
Now what if there's a fourth variable you didn't think about I mean flip your conclusion again

836
01:54:56,000 --> 01:55:03,000
So the scary part of this and founding argument is that you don't know what you're going to know right.

837
01:55:03,000 --> 01:55:08,000
There always could be some component you have a thought about I'll give you another thought about you never collect the data.

838
01:55:08,000 --> 01:55:16,000
You've never really see the truth

839
01:55:16,000 --> 01:55:28,000
Okay, So that's this is just another way of looking at this particular part, because this is a continuous part, and this is the you know, binary table, but they they mean the same thing right in this case.

840
01:55:28,000 --> 01:55:31,000
Remember we'll put all the data together it's positively correlated.

841
01:55:31,000 --> 01:55:34,000
When you look at every single subgroup it's actually negative, right?

842
01:55:34,000 --> 01:55:41,000
If you don't know the group indicator you never really review the truth.

843
01:55:41,000 --> 01:55:50,000
That's the same thing it's just why is binary wise, continuous.

844
01:55:50,000 --> 01:56:16,000
So any question.

845
01:56:16,000 --> 01:56:23,000
You know That's Why, when that will try to study exposure and outcome, always think about all the possible compounder you could imagine.

846
01:56:23,000 --> 01:56:44,000
And try to collect those information bye because with all that it's not going to be plus our size while study

847
01:56:44,000 --> 01:56:48,000
And knows the physical analysis and rescue from a design.

848
01:56:48,000 --> 01:56:54,000
But you know the environmental design without thoroughly think about all the compilers right?

849
01:56:54,000 --> 01:57:00,000
If you never collect the data, there's no thought edition can I figured that off because you just don't have data, right?

850
01:57:00,000 --> 01:57:06,000
Okay, if there's no question let's move on so we again.

851
01:57:06,000 --> 01:57:11,000
We have 2 exercise 10, am 10 b today we're gonna do 10 B.

852
01:57:11,000 --> 01:57:34,000
But this won't be due until friday. morning also the pulse actor quiz is due on friday morning, so you don't have to turn it anything today, so let's open 10 B.

853
01:57:34,000 --> 01:57:45,000
So 10 B basically do this far on data set right to do is table 2 bigger, a bigger 2 and no paper, one table, 2, and so on, so forth.

854
01:57:45,000 --> 01:57:49,000
As so today we let's try to finish handb but if we could have finished. That's fine.

855
01:57:49,000 --> 01:57:57,000
We have tomorrow on this and Let's go back right So my name is Kirby's. here.

856
01:57:57,000 --> 01:58:12,000
The data is here and there's some spreadsheet which i'll go through very quickly

857
01:58:12,000 --> 01:58:23,000
So this spreadsheet, again, is, for multiple in your regression is rather limited right to for you to really do. My own integration is better to use this little software this way just for demonstration.

858
01:58:23,000 --> 01:58:28,000
Purpose. Nevertheless, it works right. So the data is 3 column Y. X, one x 2.

859
01:58:28,000 --> 01:58:40,000
We'll food in the data. It will fit 2 models one with both marble, while with both variable and the interaction term give you the intercept slow.

860
01:58:40,000 --> 01:58:44,000
The key value. standard error R Square: Yeah. means grab right?

861
01:58:44,000 --> 01:58:47,000
You might be wondering if I just want to feed a single in your regime model.

862
01:58:47,000 --> 01:58:52,000
How do I do it? They should use this pressure from yesterday.

863
01:58:52,000 --> 01:58:57,000
So this might fit this to model, We trust sufficient for our purpose for this active sign.

864
01:58:57,000 --> 01:59:01,000
But you know your real data analysis. You would like to use this to the software, which can do a lot more.

865
01:59:01,000 --> 01:59:14,000
Right? Okay, Any question before we go to the great hard rooms

866
01:59:14,000 --> 01:59:23,000
So there is a break upcoming so i'll give 25 min, pop last break again. 35 min.

867
01:59:23,000 --> 01:59:28,000
Now feel free to take a break any time, so we gotta see at 11 and use the rest of time.

868
01:59:28,000 --> 01:59:42,000
We will review on this exercise. If there was no question i'm gonna send you into the breakout room 35 min, and that include the 10 min break. See?

869
01:59:42,000 --> 02:00:12,000
You soon.

870
02:10:22,000 --> 02:10:35,000
Professor Ellen. Yes, I I just wanna let you know that tomorrow some there might be a couple of students in the Oral Health Science program. I will.

871
02:10:35,000 --> 02:10:40,000
I think it should be all of them PHD. students.

872
02:10:40,000 --> 02:10:50,000
Who will have to miss class cause. this is the last week for one of our classes, and our professor is

873
02:10:50,000 --> 02:10:56,000
Usually we only have a class on tuesday at like one o'clock.

874
02:10:56,000 --> 02:11:01,000
So it works perfectly with our schedule but since this is the last week.

875
02:11:01,000 --> 02:11:05,000
He's doing 2 lectures we've already had our first one yesterday.

876
02:11:05,000 --> 02:11:12,000
Our second one is tomorrow, but he's julia in the morning during by the set Yeah.

877
02:11:12,000 --> 02:11:15,000
No, no more. it's no luck thanks for letting me know if you you know.

878
02:11:15,000 --> 02:11:21,000
Somehow I can get on list of the students with free my Gs: I can get a list of students so we can mark it up.

879
02:11:21,000 --> 02:11:29,000
Yeah, I I I think I sent you an email with the list of all the students that are gonna be gone tomorrow.

880
02:11:29,000 --> 02:11:33,000
Alright, i'll also be gone tomorrow as well cause I'm. A.

881
02:11:33,000 --> 02:11:37,000
In the program, but on the PHD side of things. Cool: Yeah.

882
02:11:37,000 --> 02:11:42,000
Yeah, we will. as long as we have an email. we will take care of that.

883
02:11:42,000 --> 02:12:12,000
Okay, See? Awesome. Thank you.

884
02:35:51,000 --> 02:35:59,000
Okay, that's continue welcome back yeah for the oral health size students.

885
02:35:59,000 --> 02:36:02,000
I will. We have already got an email we'll take a note

886
02:36:02,000 --> 02:36:11,000
Just watch the recording of the lecture tomorrow, and the exercise Won't be due on Friday morning.

887
02:36:11,000 --> 02:36:17,000
So should be okay if you'll turn it out Well, see and that's the a very last final alright.

888
02:36:17,000 --> 02:36:23,000
Let's continue with project can be it is on this farm.

889
02:36:23,000 --> 02:36:34,000
So first the table, 2 is also in the spreadsheet and then let's go over figure one.

890
02:36:34,000 --> 02:36:51,000
Let's go there

891
02:36:51,000 --> 02:37:02,000
The speaker. And this tells us the number of average number of provisions in 3 different a year 3 different groups.

892
02:37:02,000 --> 02:37:05,000
Actually it's not 3 different this is the bottom tennessee topics.

893
02:37:05,000 --> 02:37:11,000
There's an office these days across a period of 15 25 years.

894
02:37:11,000 --> 02:37:19,000
Okay, And then imagine you have data points corresponding to the top 10 States, all 50 States and Bottom 10 States.

895
02:37:19,000 --> 02:37:23,000
If you were to fill the regression line through each the 3 side of points.

896
02:37:23,000 --> 02:37:30,000
Right. what? What would be your interceptive value for each line let's come back here.

897
02:37:30,000 --> 02:37:42,000
So what's your guess? I guess you know when you talk about intersect?

898
02:37:42,000 --> 02:37:47,000
Right you have to stretch it all the way to 0, which is almost impossible.

899
02:37:47,000 --> 02:37:53,000
Let's just assume this is the 0 and you know the first year, second year, and this is the like a 25 year.

900
02:37:53,000 --> 02:38:01,000
So So the intercept that way will simply be the readouts.

901
02:38:01,000 --> 02:38:06,000
All this access? right? So that will be this about you know 7.

902
02:38:06,000 --> 02:38:27,000
If this is about like 17, is this is about 38, I would say, Anybody got the answer

903
02:38:27,000 --> 02:38:44,000
Okay, The second question, right? So if the slopes of free line were 0 point 9, 8, 0 point, 0, 7 and 0 point 2 8 which ones which

904
02:38:44,000 --> 02:38:51,000
So you'll see this is probably the most flat line so probably has the lowest.

905
02:38:51,000 --> 02:39:01,000
So this one probably has the 0 point 0. 8 it's fine The intermediate slope is about 0 point 2 8. This ball is a 0 point, 9, 8 right to see that.

906
02:39:01,000 --> 02:39:07,000
How do you really look at slow? You see, across a span of like 25 years.

907
02:39:07,000 --> 02:39:13,000
If this number increased by about 25, So the phone will be one.

908
02:39:13,000 --> 02:39:31,000
So that's correspond to the 3.9 8 any questions So far these are pretty straightforward.

909
02:39:31,000 --> 02:39:38,000
Okay, The third question might be a little trickier. so which of the third line would have the smallest R square?

910
02:39:38,000 --> 02:39:53,000
Why, i'm sorry and almost will try this

911
02:39:53,000 --> 02:40:01,000
We've got the the bottom 10 states would have the

912
02:40:01,000 --> 02:40:08,000
So smallest are because they also have the smallest slope.

913
02:40:08,000 --> 02:40:16,000
Yup, thank you, is a good point. Anybody has a different opinion.

914
02:40:16,000 --> 02:40:23,000
I feel like it's a talk to but i'm not sure.

915
02:40:23,000 --> 02:40:33,000
Why do you think that way because well that's the only way we're looking at off if his dates and the more of the Baltimore today?

916
02:40:33,000 --> 02:40:39,000
It's more like just online, and the they base smaller Msc.

917
02:40:39,000 --> 02:40:47,000
That that's the bureau But there is I feel like if you put it up line here to the top 10 States.

918
02:40:47,000 --> 02:40:53,000
So there are more coins below our app rather than they're close to the line.

919
02:40:53,000 --> 02:40:58,000
Yeah. And because yeah, So the ask where the eyes, not the slope.

920
02:40:58,000 --> 02:41:03,000
So I I didn't I didn't take the smoking into consideration.

921
02:41:03,000 --> 02:41:09,000
You're saying they are more scattered right yeah thank you any other comments?

922
02:41:09,000 --> 02:41:18,000
Yeah, I agree with 16. I put that because

923
02:41:18,000 --> 02:41:25,000
R. squared the worst. The model seats, the data. Oh, I think these applies for the top 10 States.

924
02:41:25,000 --> 02:41:29,000
Yeah, I think you actually you both make very good point. right?

925
02:41:29,000 --> 02:41:34,000
So the top 10 State Seems like they are sort of a scattered along right?

926
02:41:34,000 --> 02:41:42,000
So a a straight line will not fit it very Well, so that's gonna be too high on the other hand.

927
02:41:42,000 --> 02:41:46,000
Remember when when the slope is 0, the r will be 0.

928
02:41:46,000 --> 02:41:52,000
Right. So you believe the the points perfectly lie on flat line are will still be 0.

929
02:41:52,000 --> 02:41:57,000
So that all argument also part of the bottom times thing so honestly I don't know.

930
02:41:57,000 --> 02:42:00,000
We're trying to lowest our car we had to fit the data to know it.

931
02:42:00,000 --> 02:42:13,000
Hello, do we have the data? Probably not right we probably don't have the data here, so no one really knows until we feed the data.

932
02:42:13,000 --> 02:42:15,000
But I I think if both of you may very good point.

933
02:42:15,000 --> 02:42:25,000
These are the pretty challenging case. Any question, any comments

934
02:42:25,000 --> 02:42:33,000
Yeah, I think the slopes are in. their sets are pretty obvious, but our Square is not so obvious in these 3 cases.

935
02:42:33,000 --> 02:42:42,000
Could you? Why, the top 10 would also have the local fishing again.

936
02:42:42,000 --> 02:42:48,000
Sorry. Yeah, the R square is just R. and then square. right is a correlation.

937
02:42:48,000 --> 02:42:52,000
So. and also the R Square explains how well street life is.

938
02:42:52,000 --> 02:42:59,000
The data. You see how this is. The The data do not really fall on a straight line that closely. right?

939
02:42:59,000 --> 02:43:06,000
So if you go straight line through, it probably looks something like this, right?

940
02:43:06,000 --> 02:43:19,000
So there's a These are the amount of residents So the ars war won't be sorry I will be raising nobody good.

941
02:43:19,000 --> 02:43:22,000
But you know just from these, I think the R. may be point 8.

942
02:43:22,000 --> 02:43:29,000
5, or something in our square will be point 7 fish it's not close to one.

943
02:43:29,000 --> 02:43:35,000
And the yeah, the other. you know this Here the line seems to feed the data a little better.

944
02:43:35,000 --> 02:43:40,000
But, on the other hand, you know the line become flat or flatter.

945
02:43:40,000 --> 02:43:46,000
Yeah. I. When the slope becomes 0, there are also becomes 0.

946
02:43:46,000 --> 02:43:51,000
So I I obviously I Don't know which one is the hierarchy.

947
02:43:51,000 --> 02:44:01,000
Thank you. No, Mars. Any other questions.

948
02:44:01,000 --> 02:44:05,000
So for this one, Can we, technically, then, are you either?

949
02:44:05,000 --> 02:44:12,000
Or in that case well, you could argue either. Well, but if you have the data you can fit, and you, you will know the true end.

950
02:44:12,000 --> 02:44:21,000
Okay, this. is not an argument We just try to guess what the arts part really is. I I guess I don't have the data here, so otherwise i'll be interested.

951
02:44:21,000 --> 02:44:29,000
How are you guys? not? We have the data of table.

952
02:44:29,000 --> 02:44:37,000
2. Oh, we don't know means the thing is that the same data, no right?

953
02:44:37,000 --> 02:44:41,000
No, we don't have the data for this vegas so unfortunately we cannot figure out the truth.

954
02:44:41,000 --> 02:44:48,000
But there is a truth. My guess is that maybe the hardware for the bottom space are lower, because they're flat.

955
02:44:48,000 --> 02:45:02,000
But not just my guess. Okay. I I think the key one is that I understand the behavior of our Square Why is not the data you can use it to go?

956
02:45:02,000 --> 02:45:17,000
Alright. question number 2. Examine figure 2. Now, You imagine the author has fit the line for the data points for Stan your ground law and found the service 0 point 7, 8 include that the number of standard one law increased by 7 8

957
02:45:17,000 --> 02:45:33,000
per year. let's go to bigger 2 so basically saying, there reading the data for this standard from wrong walk here, right?

958
02:45:33,000 --> 02:45:40,000
So if you fit in your regression model probably got a line like this, I don't know.

959
02:45:40,000 --> 02:45:50,000
Yeah, And then say the slope is 0 point 8, 7, 4, and the invitation will be that every year the number of laws increased by 78, a 0 point, 7, 8.

960
02:45:50,000 --> 02:46:04,000
How do you take that interpretation? Anyone I think this conqueror is not reliable, because also we'll look at this this, this this figure.

961
02:46:04,000 --> 02:46:12,000
You can see that the relationship of why variable is not purely linear with all X values.

962
02:46:12,000 --> 02:46:20,000
But it's kind of like there is a dividing coin at the year 22,005.

963
02:46:20,000 --> 02:46:27,000
So I think the variability of the rather do it's not constant for all the X value.

964
02:46:27,000 --> 02:46:32,000
So the quick. So I think this is not very reliable.

965
02:46:32,000 --> 02:46:40,000
Thank you very much. Yeah, I agree with you. you could still say, on average, every year you increase by 0 point 7 4.

966
02:46:40,000 --> 02:46:47,000
But the reality is that if you look at it right, So there are 2 Prs.

967
02:46:47,000 --> 02:47:02,000
There is a period almost never change with flat and there's a period that increase sort of a quite a bit right So on average, Hello, it's 0 point 7, 8 but it doesn't reflect the reality.

968
02:47:02,000 --> 02:47:11,000
It's like when you make you know some from a shortcase, together with some talk, is if it's not for half of the cost.

969
02:47:11,000 --> 02:47:15,000
You'll say the average high right which is not very representative. the same thing here.

970
02:47:15,000 --> 02:47:23,000
So essentially the linear assumption is not, very well, established by the data.

971
02:47:23,000 --> 02:47:27,000
Therefore, linear regression model is not a good reflection of the data.

972
02:47:27,000 --> 02:47:39,000
I mean comments, questions.

973
02:47:39,000 --> 02:47:47,000
Okay, next One.

974
02:47:47,000 --> 02:48:00,000
In table 2. The author chose to examine the difference in for all provisions from 90 91

975
02:48:00,000 --> 02:48:08,000
One is 16 is that it's simple in your graph model the number of file in law in 2,016 versus the number of final law, and you know, 91.

976
02:48:08,000 --> 02:48:13,000
Their association between these 2 values. Provide a evidence for your answer alright.

977
02:48:13,000 --> 02:48:36,000
That's go find the data set I haven't done all the things that yet, and let me dial the data set

978
02:48:36,000 --> 02:48:45,000
So we need to use the number of 2,016 as the

979
02:48:45,000 --> 02:48:56,000
That's why the number of 91 as acts right is the number of 91.

980
02:48:56,000 --> 02:49:21,000
Sorry should be this, too right Oh, that's the population that's not what we should use the last 2 column so 16 as the why, and that 91 as the x Let me copy it, and then go to the same holy your aggression

981
02:49:21,000 --> 02:49:29,000
Packard, we should actually be the I believe a simple linear requirement here, right?

982
02:49:29,000 --> 02:49:34,000
So we should use another spreadsheet last week.

983
02:49:34,000 --> 02:49:53,000
We just call here and go to the spreadsheet, including your regression

984
02:49:53,000 --> 02:50:01,000
I know it pays the data here so 16 as the why 91 as the X.

985
02:50:01,000 --> 02:50:08,000
And this is what you should get and so you've got a r reasonably good R.

986
02:50:08,000 --> 02:50:15,000
Square, originally good, positive, slow. right? So also ports. You look at the spread.

987
02:50:15,000 --> 02:50:27,000
Look at the data, right and highly significant p value So the question is that there are association between these 2 values.

988
02:50:27,000 --> 02:50:34,000
Hi! what's your what's your conclusion

989
02:50:34,000 --> 02:50:41,000
You come here? Is there Association? Well, apparently, yes, right. Yeah.

990
02:50:41,000 --> 02:50:50,000
Yup are pretty strong. you have a key value of How do you think in the time I think that's all what you need to say right on you can look at so.

991
02:50:50,000 --> 02:51:06,000
Yes, right strong, or relation r equals 0 point 8, 5, or you could say r square equals.

992
02:51:06,000 --> 02:51:32,000
I forgot 0 point 7, 3 0 point 7 3 by and p that's not 0 point 0 0 one right So there's association very small between us too positive strong positive association.

993
02:51:32,000 --> 02:51:46,000
Now repeat, Question 3 separately for states with less than 25 on provision in 91 states, with one on 5, 25 provision, he's, playing, which resolue with a lot of report.

994
02:51:46,000 --> 02:51:58,000
So we do here is that there's another column which is

995
02:51:58,000 --> 02:52:06,000
Which is, you know, to 91 here, right? So So what we do with that we need to fit 2 simple linear regression models.

996
02:52:06,000 --> 02:52:15,000
Yeah. and the stratified by the number of provision you know, small, large in 91.

997
02:52:15,000 --> 02:52:20,000
So the way to do it is, you know you select this.

998
02:52:20,000 --> 02:52:25,000
I thank you. Slack this. go to data. If you have a bad way, let me know.

999
02:52:25,000 --> 02:52:29,000
This is how I would do it like you there and then.

1000
02:52:29,000 --> 02:52:37,000
You pay 0 only that's less than 21 is this one right?

1001
02:52:37,000 --> 02:52:42,000
0 means more than 2025, 91.

1002
02:52:42,000 --> 02:52:48,000
So you take these 2 columns control c you'll but go back here.

1003
02:52:48,000 --> 02:52:54,000
You paste it

1004
02:52:54,000 --> 02:52:59,000
I got it new regression right. The slope is much lower.

1005
02:52:59,000 --> 02:53:07,000
Pivotal in significant. and then, you do another one.

1006
02:53:07,000 --> 02:53:14,000
Go back to the raw data. Now you'll pick the one only basically fit 2 separate linear regression models.

1007
02:53:14,000 --> 02:53:28,000
This might have a lot more data points. Do copy again. you pull back here to paste again.

1008
02:53:28,000 --> 02:53:36,000
Again. you got a much lower r this time i'll second i've been queue about it, but now i'm thinking of it as before.

1009
02:53:36,000 --> 02:53:42,000
So did you guys the same number

1010
02:53:42,000 --> 02:53:47,000
Let me double check

1011
02:53:47,000 --> 02:53:51,000
Yes, I got the same numbers cool. Thank you very much. Same R. values.

1012
02:53:51,000 --> 02:54:01,000
And then the P values as well. Okay, yeah. So the question is, do you prefer which one?

1013
02:54:01,000 --> 02:54:06,000
No, you prefer the the the joint model earlier. Oh, the separate model!

1014
02:54:06,000 --> 02:54:36,000
Play around, and why

1015
02:54:42,000 --> 02:54:50,000
I know this is a pretty tricky question after I don't think there is a, you know, correct answer to it is pretty subjective.

1016
02:54:50,000 --> 02:55:12,000
Are. recall what you're learning calls join one model versus 2 stratified analysis

1017
02:55:12,000 --> 02:55:19,000
So you could look at, you know R. Square you can look at key value includes other things.

1018
02:55:19,000 --> 02:55:33,000
Why don't we to interpret the data is that when you when you separate the analysis, you see that the correlation become lower?

1019
02:55:33,000 --> 02:55:38,000
Right. In fact, the slope also become lower yeah I didn't compare them.

1020
02:55:38,000 --> 02:55:42,000
But if you remember, the original slope was 1.8.

1021
02:55:42,000 --> 02:55:48,000
The slope become lower, the correlation become lower the pivot will become less significant.

1022
02:55:48,000 --> 02:55:51,000
Alright that's also part of because the smallest sample size for each analysis.

1023
02:55:51,000 --> 02:55:57,000
We cannot. okay so much of that an R square, because the r becomes smaller.

1024
02:55:57,000 --> 02:56:02,000
The hardware also becomes smaller, so you could say the first model has a larger R. square.

1025
02:56:02,000 --> 02:56:13,000
Therefore it's a better model. But you could also say that you know the 2 group.

1026
02:56:13,000 --> 02:56:23,000
Actually, essentially, you have 2 States right before, you know, for States, with high number of provisions in 91, the States with globe number provision in 91.

1027
02:56:23,000 --> 02:56:28,000
They have different kind of slopes

1028
02:56:28,000 --> 02:56:39,000
Right so long them together may not be a good idea

1029
02:56:39,000 --> 02:56:44,000
So depending on how we interpret that. So you know, you look at the hardware itself.

1030
02:56:44,000 --> 02:56:48,000
It seems like the drawing model is the data ballot.

1031
02:56:48,000 --> 02:57:01,000
Look at the the changing slopes it's just that there are 2 stop population with which have different sales, and you'll make them together. right?

1032
02:57:01,000 --> 02:57:07,000
So this this by this time it's a little subjective I don't really have a can you answer to that.

1033
02:57:07,000 --> 02:57:14,000
That's the difficult to model selection you can come up with many, many models, and each one you can find some room.

1034
02:57:14,000 --> 02:57:27,000
Yeah supporting them all. So it's very hard to find the model that everybody agreed is the best one

1035
02:57:27,000 --> 02:57:35,000
Any questions, so far.

1036
02:57:35,000 --> 02:57:52,000
Well, any different awesome, different answers.

1037
02:57:52,000 --> 02:57:59,000
Okay, that's not move to number 5 and 5 Now we just instead of feeding 2 separate linear regression, right?

1038
02:57:59,000 --> 02:58:08,000
You see why we do do this practice, you know again again. Now, if you, the multivariate regression line of number of our own, you know.

1039
02:58:08,000 --> 02:58:11,000
Altogether I was the the 3 columns alright.

1040
02:58:11,000 --> 02:58:16,000
So what we do is that we take this data alright.

1041
02:58:16,000 --> 02:58:19,000
We take these, that data would take the 3 columns and all.

1042
02:58:19,000 --> 02:58:26,000
We have to go back to the wrong, like everything

1043
02:58:26,000 --> 02:58:38,000
We take this off 3 columns Yeah, I know we're put in the multiple regression models here, except that we want this 26 to be?

1044
02:58:38,000 --> 02:58:48,000
Why, this would be tax 2. So we, this here, if you could swap them

1045
02:58:48,000 --> 02:59:02,000
So now i'm just doing a lot of slobbing right? So the number of provision in 91 is X, one last, or less than 25 is, you know, like X, 2.

1046
02:59:02,000 --> 02:59:09,000
This number of reasoning fund is 16 is that 3

1047
02:59:09,000 --> 02:59:16,000
This is what you should. Yeah, I remember. I cannot make a cloth here anymore, because I cannot pot.

1048
02:59:16,000 --> 02:59:27,000
We have 2 access. so you only have this 2 side of this

1049
02:59:27,000 --> 02:59:34,000
Okay, So you see a dollar thing right so for example there's an interaction term.

1050
02:59:34,000 --> 02:59:42,000
Now, with this P. value and R. square increase a little bit here, but very tiny, mean, square error also increase the time to be.

1051
02:59:42,000 --> 02:59:47,000
This is what I have all right, having one variable will reduce your total sales worse.

1052
02:59:47,000 --> 02:59:53,000
But you also increase one degree of freedom. So the mean square error could go up a tiny bit.

1053
02:59:53,000 --> 03:00:00,000
Not much. And you see that the intercept change a little bit.

1054
03:00:00,000 --> 03:00:05,000
The slow change a little bit. i'm here to here as Well, right now the number always change.

1055
03:00:05,000 --> 03:00:15,000
So be careful what you want to look at. So the question here Yes, I have to repeat the model. Right?

1056
03:00:15,000 --> 03:00:30,000
Not quite this approach. grace up separate regression model for states with less than 25 States that for space was more than 25 States.

1057
03:00:30,000 --> 03:00:42,000
So remember this this is a very interesting approach Well, if that i'm audible to integrate and model with a binary right terrible, because bonding around. I'll only take a 2 values.

1058
03:00:42,000 --> 03:00:51,000
Right. you can think about. I that's 2 is 0 or X. 2 is one. They actually you can separate your patient into 2.

1059
03:00:51,000 --> 03:00:56,000
Let me write a little bit. I believe many of you have already figured out right.

1060
03:00:56,000 --> 03:01:07,000
So here the multiple in regression is y equals how far plus beta one x one plus beta 2 x 2. No, you can't use added.

1061
03:01:07,000 --> 03:01:14,000
If so, it doesn't matter. So because here x 2 only take a value of, and what right?

1062
03:01:14,000 --> 03:01:21,000
So we can simplify perhaps 2 is 0. What we have is y equals alpha plus beta, one x one.

1063
03:01:21,000 --> 03:01:29,000
If x 2 is one why equals alpha plus pay the tool plus beta one x one.

1064
03:01:29,000 --> 03:01:39,000
Remember that's. the trick we're using costs right So essentially we have 2 group of subjects depend on X 2, and they have the same slope.

1065
03:01:39,000 --> 03:01:46,000
Oh, they have different interaction. So these are Donald Street, though.

1066
03:01:46,000 --> 03:01:57,000
So essentially what we have was. If you come, look at the number here minus, you know, and this thing right sorry.

1067
03:01:57,000 --> 03:02:02,000
I just overlooked already wipe them out.

1068
03:02:02,000 --> 03:02:10,000
So essentially we have 2 models right for x 2 equals 0, which is the remember, actually means less than 25 right?

1069
03:02:10,000 --> 03:02:21,000
That's the basically greater than 25 right right the 91 provision greater than 25 operator on you call.

1070
03:02:21,000 --> 03:02:36,000
Okay, I don't know, then, 25 in this group with y opposed the inter intersect, which is

1071
03:02:36,000 --> 03:02:52,000
Sorry which this number 33 right so that's the intercept that'll be 33 boss 1 point o 5. Thanks.

1072
03:02:52,000 --> 03:03:03,000
So X. One is the number of provisions in 91 in the X 2 equals one group which is 90.

1073
03:03:03,000 --> 03:03:08,000
91 provision last 1, 25. we have Y.

1074
03:03:08,000 --> 03:03:15,000
Post. This time will be 33, plus

1075
03:03:15,000 --> 03:03:21,000
The slope of this thing. Mine is 28, point 6, 5.

1076
03:03:21,000 --> 03:03:31,000
So basically mine is 28.6 5 let's take them all that'll be 4 point, 4 cost 1 point or 5 x one.

1077
03:03:31,000 --> 03:03:39,000
So essentially feeding a multiple in your regression model with a binary Oh, very, is the equivalent.

1078
03:03:39,000 --> 03:03:50,000
Yeah, feeding this 2 model, but you force some slope to be the same, but they have different intersect

1079
03:03:50,000 --> 03:03:58,000
Any questions so far

1080
03:03:58,000 --> 03:04:11,000
Can you explain where? to 4.4 came from? again? Oh, this 4.4, 32 minus 28 that's where now let me write it again.

1081
03:04:11,000 --> 03:04:27,000
This is a plus b, one x one equals this. This is a plus b 2 plus b, one excellent.

1082
03:04:27,000 --> 03:04:33,000
So those are the numbers

1083
03:04:33,000 --> 03:04:41,000
Any other question.

1084
03:04:41,000 --> 03:04:47,000
So the question number 2 is that here we have 2 model for the tube rule.

1085
03:04:47,000 --> 03:05:03,000
Previously. we'll also Have a tool model for the Google remember so what's the difference?

1086
03:05:03,000 --> 03:05:11,000
Anyone can answer

1087
03:05:11,000 --> 03:05:16,000
So now we have 2 regression lines right for the full group.

1088
03:05:16,000 --> 03:05:17,000
We. we also have 2 regret and life on the Google.

1089
03:05:17,000 --> 03:05:44,000
The difference

1090
03:05:44,000 --> 03:05:48,000
Okay, So so let's let's look at it right Okay, numbers.

1091
03:05:48,000 --> 03:05:53,000
So previously. These are the for the greater group right we have this too.

1092
03:05:53,000 --> 03:06:02,000
That's right i'm done right so previously right for the X 2 equals one group.

1093
03:06:02,000 --> 03:06:09,000
We have y equals 2.5, 5 boss, 1 point, 2 x one.

1094
03:06:09,000 --> 03:06:17,000
Well the

1095
03:06:17,000 --> 03:06:27,000
For the actual equal 0 group. We have y equals let's go back

1096
03:06:27,000 --> 03:06:37,000
Where do I have? Oh, this is not the same thing

1097
03:06:37,000 --> 03:06:45,000
Alright bye hold on, cannot.

1098
03:06:45,000 --> 03:06:52,000
Oh, I cannot, I cannot do it. So I had to. go back, recover the data here.

1099
03:06:52,000 --> 03:07:03,000
I always need That's Why, see it again

1100
03:07:03,000 --> 03:07:08,000
So you got 41 and 0 point 8, 5. Okay, for the other group.

1101
03:07:08,000 --> 03:07:15,000
Sorry. So now he calls 41 wow, 0 point 8, 5 X.

1102
03:07:15,000 --> 03:07:21,000
One. You see, these 2 regression lie are not the same right left.

1103
03:07:21,000 --> 03:07:26,000
That equals 4.4, that's 1 point Oh, 5 next month.

1104
03:07:26,000 --> 03:07:28,000
This to regret my heart similar, but not the same right.

1105
03:07:28,000 --> 03:07:32,000
For example, this one is 41 plus 0 point, 8, 5 x one.

1106
03:07:32,000 --> 03:07:38,000
This one is 33, plus 1.0 5, and this one is 2.5, 5, plus 1 point, 2 x.

1107
03:07:38,000 --> 03:07:44,000
One isn't, 4.4 plus one one though 1.0 5. right?

1108
03:07:44,000 --> 03:07:47,000
So these are similar, but not the same regression line so they are different.

1109
03:07:47,000 --> 03:08:01,000
But what's driving this difference

1110
03:08:01,000 --> 03:08:09,000
Is it the size of the sample? Nope. hey? Yeah, not quite. Yeah.

1111
03:08:09,000 --> 03:08:12,000
I mean they have the same. They work on the same data right here.

1112
03:08:12,000 --> 03:08:16,000
You you paid them separate here. Freedom jointly yeah they're not quite the same.

1113
03:08:16,000 --> 03:08:23,000
But oh, the main main difference, I would say, here is that you know these are these 2 regression line.

1114
03:08:23,000 --> 03:08:27,000
They have different interests, but they have the same slope.

1115
03:08:27,000 --> 03:08:47,000
Here they have different industry, but they have this difference flow so when your forced them to have the same slope you end up with different lines, although similar. I saw the difference that you know same versus different slopes, So that's the main

1116
03:08:47,000 --> 03:09:00,000
difference. Okay. So now let's look at the other one we haven't even talked about which is interaction model.

1117
03:09:00,000 --> 03:09:04,000
So what is interactive model is really, Do we let me play a little bit right?

1118
03:09:04,000 --> 03:09:08,000
This. this whole exercise is trying to understand different model and their equivalence in the interaction model.

1119
03:09:08,000 --> 03:09:19,000
On the right hand side We have why people hey? plus b one x one plus e 2 x 2 plus B, 3 x one times x 2, remember.

1120
03:09:19,000 --> 03:09:37,000
That's the amount. and now we can rearrange it, remember, because a plus b, 2 x 2 well v one plus b, 3, x 2 x one.

1121
03:09:37,000 --> 03:09:42,000
We just rearrange them all that's what we're learning cost Now, because B.

1122
03:09:42,000 --> 03:09:48,000
And 2 is is binary right? X. 2 will be either 0 1.

1123
03:09:48,000 --> 03:09:53,000
Now we have further simplified X with 0 you just plug in you've got a y equals, hey?

1124
03:09:53,000 --> 03:10:04,000
Plus b one x one that's what you call if access one you got y equals a plus b 2 plus v one plus p.

1125
03:10:04,000 --> 03:10:13,000
3 X. one. So this also give you 2 regression lines. Now for the last slide are different, because you have the interaction there.

1126
03:10:13,000 --> 03:10:27,000
And more importantly, these 2 lines doesn't have the same slow right? this additional interaction term give you one degree of freedom. so like you don't have the same have the same slope anymore.

1127
03:10:27,000 --> 03:10:41,000
Let's see what we got from this okay we have to Remember these numbers and this equations, and unfortunately, I have to wipe them out, because you know, if I switch back they overlap play on how price know where you can see well.

1128
03:10:41,000 --> 03:10:53,000
suppose you remember the equations, and then for the interaction model we have, you know, when X 44, 0 we have Why?

1129
03:10:53,000 --> 03:11:02,000
Because we don't remember hey? b x one and in this case we just come back here.

1130
03:11:02,000 --> 03:11:13,000
This is a * 41 off. This is V. one right

1131
03:11:13,000 --> 03:11:34,000
0 point 8 5 that's what right in the interactive model X 2, if you still remember what I just rolled equals one which is equivalent, saying y equals how no a plus B You want you know I forgot hi plusby

1132
03:11:34,000 --> 03:11:43,000
pool. Well, v one plus B 3 x one that equals one let's try it down right.

1133
03:11:43,000 --> 03:11:54,000
41 plus. this is V. 2 miners 38.6 that's what you got right.

1134
03:11:54,000 --> 03:12:04,000
Well, i'm done 0 point 8 5 8 plus you don't want 3, 4 x one.

1135
03:12:04,000 --> 03:12:12,000
Now you both want, because we're gonna do the month hard for me.

1136
03:12:12,000 --> 03:12:21,000
2.4 plus 1 point ball, 1 point cool x one.

1137
03:12:21,000 --> 03:12:29,000
This is, you know, accuracy, you know, precision loss is about 2.5.

1138
03:12:29,000 --> 03:12:44,000
Okay, So that's the other model. So this is the equivalent to separate regression model from the interaction model where you have different slope.

1139
03:12:44,000 --> 03:12:48,000
What I want to point out is that supply, and you are not so.

1140
03:12:48,000 --> 03:12:57,000
Quality. You see, this tool model are essentially the same from the 2 separate regression. model, right?

1141
03:12:57,000 --> 03:13:02,000
2, point 5, to 4 that's just a that's just a population, you know, accuracy usual.

1142
03:13:02,000 --> 03:13:18,000
They actually are the same model You right? Then people So remember, we showed that equivalence between 2 sample tasks and a linear regression when when we use the linear regression on an indicator, variable right?

1143
03:13:18,000 --> 03:13:23,000
There are equivalent. Same thing here if you'll add 4 is binary.

1144
03:13:23,000 --> 03:13:30,000
The feeding an interaction model here. This actually is binary.

1145
03:13:30,000 --> 03:13:36,000
The impact model here is equivalent to fit to separate sample in your right model.

1146
03:13:36,000 --> 03:13:41,000
Because you have 2 group they got. They got a different intersection.

1147
03:13:41,000 --> 03:13:44,000
Interaction got the same. They got different interaction. intercept.

1148
03:13:44,000 --> 03:13:54,000
They got different. So and the reason you got the same is because in both model you'll have the same number of parameters right here.

1149
03:13:54,000 --> 03:14:00,000
You have a V. one V. 2 v. 3 so you got 4 parameters, about 4 degree of freedom in the other molecules.

1150
03:14:00,000 --> 03:14:04,000
It's 2 separate, simple integration, each one has their own A and B.

1151
03:14:04,000 --> 03:14:09,000
So you also have 4 parameter this one is not equivalent, because I don't have 3 problems.

1152
03:14:09,000 --> 03:14:14,000
So basically, you've paid 4 parameter to your data you are now with the same model.

1153
03:14:14,000 --> 03:14:23,000
So feeding what i'm saying, feeding this one this one is actually equivalent to 2 separate simple in your question.

1154
03:14:23,000 --> 03:14:32,000
So now the question can be formulated actually to compare this one to 2 simple in your regression

1155
03:14:32,000 --> 03:14:38,000
War is the equivalent for comparison for this one.

1156
03:14:38,000 --> 03:14:43,000
You could this one, The right hand side is equivalent to simple new regression.

1157
03:14:43,000 --> 03:14:47,000
In this case we can actually make the decision, because these are net and models.

1158
03:14:47,000 --> 03:14:52,000
We just need to look at the key value of the interaction term, which is insignificant.

1159
03:14:52,000 --> 03:14:59,000
This harm, probably not necessary, which is also reflected by the fact that the R.

1160
03:14:59,000 --> 03:15:04,000
Squared change, very tiny right adding additional term doesn't help you to explain.

1161
03:15:04,000 --> 03:15:18,000
Much variation in the y which means it's probably don't need the actual term, which means this model probably is sufficient.

1162
03:15:18,000 --> 03:15:30,000
Okay, that's all i'm trying to say right So from all of this you see the interaction term as of C value great on a 0 point.

1163
03:15:30,000 --> 03:15:44,000
5 bye probably not necessary, which means you know the non interaction model.

1164
03:15:44,000 --> 03:15:57,000
It's sufficient, but that's my conclusion on the other hand, here we know the interaction model is equivalent to the 2.

1165
03:15:57,000 --> 03:16:07,000
It's not great same whole universe right the model

1166
03:16:07,000 --> 03:16:18,000
Excuse me well that's the sort of argument I know It's a long long way out here, right I just wanted to show you you know.

1167
03:16:18,000 --> 03:16:23,000
There they're there. There are things you know to do with this kind of modeling scheme, and some of all of us equivalent.

1168
03:16:23,000 --> 03:16:38,000
Some are not back to look at the right number to make the decision

1169
03:16:38,000 --> 03:16:52,000
Right? A question.

1170
03:16:52,000 --> 03:16:57,000
Okay, let's move on. So now we have we have a different question.

1171
03:16:57,000 --> 03:17:08,000
Right. We would like to know if there is association with the number of iron law provision in 2016, with the protection of voters of those given to Donald Trump in 2,016.

1172
03:17:08,000 --> 03:17:16,000
What's your conclusion

1173
03:17:16,000 --> 03:17:22,000
That's a try to find a data the data was here.

1174
03:17:22,000 --> 03:17:28,000
We have to go back to the to the full data, So we use 2,016.

1175
03:17:28,000 --> 03:17:32,000
But now we use the this is the portfolio. right?

1176
03:17:32,000 --> 03:17:46,000
So we take this one. let's let's take this 2016 cool sample in your graph, and please here and take the support of fall.

1177
03:17:46,000 --> 03:17:53,000
Put it back here

1178
03:17:53,000 --> 03:18:02,000
I have to drag this to review the number right So There is a negative association, and there is a significant key value.

1179
03:18:02,000 --> 03:18:07,000
There's a negative slope. if you Look at it the figure right?

1180
03:18:07,000 --> 03:18:18,000
There is a negative trend

1181
03:18:18,000 --> 03:18:24,000
So anyone want to tell us i'll do you read this model? Okay, do you think it's a good video?

1182
03:18:24,000 --> 03:18:48,000
Now

1183
03:18:48,000 --> 03:18:53,000
I think it's a good fit Pearson is I mean so.

1184
03:18:53,000 --> 03:19:06,000
This is a negative correlation. But it's actually It's going in point 5 or it's great. It's more negative than negative point 5 Okay, it's hard to say because it's only

1185
03:19:06,000 --> 03:19:13,000
negative point 6. So it's kind of yeah almost in the middle thank you.

1186
03:19:13,000 --> 03:19:21,000
Any other calls,

1187
03:19:21,000 --> 03:19:29,000
No significant there, too. So I mean, I guess that would support me saying that yeah, I would.

1188
03:19:29,000 --> 03:19:34,000
I would trust it. Yeah, there are many number we can look at.

1189
03:19:34,000 --> 03:19:40,000
Thank you both for your colleagues right. The pivot is highly significant, and the the correlation is reasonable, Right?

1190
03:19:40,000 --> 03:19:47,000
Moderate our Square not so high so just from this number there's nothing wrong.

1191
03:19:47,000 --> 03:19:52,000
Seems to be a reasonable model, or from the plot.

1192
03:19:52,000 --> 03:20:02,000
I would argue. You know they are not really linear. I just ski this sort of a curve for the majority of day.

1193
03:20:02,000 --> 03:20:08,000
Now with similar one outlier off the curve. Right?

1194
03:20:08,000 --> 03:20:14,000
So. if I say there is a negative association, and some of the States may may not agree.

1195
03:20:14,000 --> 03:20:31,000
Some of the States do not all of the time that Well, yeah, that's so really, really subjective right depending on what you look at

1196
03:20:31,000 --> 03:20:35,000
Right. It seems like there are some States with high support, right?

1197
03:20:35,000 --> 03:20:40,000
They have a long number for some States with intermediate support.

1198
03:20:40,000 --> 03:20:44,000
They have a high-level number right and then there's a one All right here.

1199
03:20:44,000 --> 03:20:48,000
I don't know what's the effect of this one state

1200
03:20:48,000 --> 03:20:57,000
This is probably I don't know is that dc or something so our line

1201
03:20:57,000 --> 03:21:01,000
So yeah, let's move on for the sake of time and expand the model.

1202
03:21:01,000 --> 03:21:06,000
You'll 15 question 6 to adjust whether the number fire on law less than 25.

1203
03:21:06,000 --> 03:21:13,000
Do you prefer this model or a while setting question 6 right so let's do it.

1204
03:21:13,000 --> 03:21:26,000
So what we do is how we use the multiple we put Here, take this data and go to the multiple in your regression in here.

1205
03:21:26,000 --> 03:21:38,000
Okay, I guess what I would do. I simply take the tall column. I'm putting the first column here. That should be sufficient.

1206
03:21:38,000 --> 03:21:44,000
Let me drag this

1207
03:21:44,000 --> 03:21:52,000
This is what you got so compare with a previous fit this time we don't have a plot, but you see the hard square is way much higher.

1208
03:21:52,000 --> 03:22:08,000
Not before right previous Osbourne was point 3 point 3, 6, 7, and now it's point 7 7.

1209
03:22:08,000 --> 03:22:19,000
So you increase the law. but that does that by myself. doesn't say much because arts are always increased by the look at this right when we add a X 2 in the model act.

1210
03:22:19,000 --> 03:22:25,000
2 is highly significant. Are you in the interaction term is not so we probably don't need a second model.

1211
03:22:25,000 --> 03:22:33,000
But this model seems like who'd be a much better fit than I know previous model

1212
03:22:33,000 --> 03:22:48,000
We don't have the we do not have the curve i'll have the plot. but essentially we are feeding, you know, 2 separate model for states with a low number of laws, and the States with high number law and make them have the

1213
03:22:48,000 --> 03:23:00,000
same slow. Would that be the data much bad? So the same idea, I think this can be stuff a model in your regression model. everything else equal.

1214
03:23:00,000 --> 03:23:07,000
This model is scattered, and a simple in your very mind, honey.

1215
03:23:07,000 --> 03:23:12,000
Off.

1216
03:23:12,000 --> 03:23:25,000
So you start out right here. right? So our square increases from 3.3, 6, 2, 0 point 7 something I forgot.

1217
03:23:25,000 --> 03:23:40,000
Have a name. key value for X 2 that's not point Oh, one. All of this shows that multiple you know the the module in your record model.

1218
03:23:40,000 --> 03:23:53,000
This 5 or 9,

1219
03:23:53,000 --> 03:24:06,000
Any question there's one yeah okay, any question

1220
03:24:06,000 --> 03:24:12,000
Alright. so it is time now to finish the day, so no need to turn in anything.

1221
03:24:12,000 --> 03:24:24,000
But if you want, please feel free to turn in and there's also a quiz, both of you on Friday morning tomorrow we're gonna continue with 18, and then we move on to the very last lecture and there's no

1222
03:24:24,000 --> 03:24:27,000
homework to be deal by the very last lecture.

1223
03:24:27,000 --> 03:24:30,000
So this is the very last assignment you need to summit.

1224
03:24:30,000 --> 03:24:37,000
And thank you very much. I will have a office hour in 10 min at another zoom link.

1225
03:24:37,000 --> 03:24:42,000
So. yeah, you can find my Zoom meeting I don't have a instructor tap on on have us.

1226
03:24:42,000 --> 03:24:53,000
You have a question. you can find me there otherwise have a great rest of your day.

