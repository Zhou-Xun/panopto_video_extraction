1
00:00:00,060 --> 00:00:07,220
That's crazy. I'm so happy.

2
00:00:08,910 --> 00:00:13,890
All right, wonderful. Let's jump back in here and thank you, folks, for your help with the Panopto information.

3
00:00:14,070 --> 00:00:20,400
I also actually have this on the announcement that I want to make a plug for student drop hours are on Zoom on Fridays.

4
00:00:20,430 --> 00:00:28,440
I would love it if you came and join me there. Feel free to ask questions related of course, assignments or your own personal research.

5
00:00:28,440 --> 00:00:34,680
We can brainstorm together. It's a great opportunity just to practice, practice coding.

6
00:00:35,700 --> 00:00:42,720
Okay. Does anybody have anything they want to point out from that last segment where we were exploring a variable?

7
00:00:45,340 --> 00:00:50,920
Otherwise we are going to generate a whole bunch of data sets all at once so that we can join on together.

8
00:00:52,360 --> 00:00:56,750
Right. You can see here there's a whole array of data set.

9
00:00:56,760 --> 00:01:00,110
So we will get planning and practice joining data sets. All right.

10
00:01:00,110 --> 00:01:03,320
So the next one, so we have our demographics data.

11
00:01:03,970 --> 00:01:07,430
The next one around Poland is blood cell count data.

12
00:01:07,790 --> 00:01:10,880
So our research question for this class, we're going to see our.

13
00:01:12,270 --> 00:01:19,380
Levels of metals associated with how many immune cells people have in their in their bloodstream.

14
00:01:19,440 --> 00:01:25,400
So that's going to be what we're testing. You're going to notice these are all coming from the most recent wave of enhanced.

15
00:01:25,650 --> 00:01:29,430
And we can tell that because they all have the suffix at the end of the dataset with a jag.

16
00:01:29,820 --> 00:01:38,160
Okay, so let's pull on the CDC dataset and if you want, you can go to the enhanced website and check to see whether you expect to be in here first.

17
00:01:38,730 --> 00:01:41,060
But I'm just going to kind of fly through this initially.

18
00:01:41,680 --> 00:01:48,610
What I have is a complete blood count dataset, pop up in our global environment and check it out.

19
00:01:53,310 --> 00:02:02,010
All right. So we've got a blood count, that complete blood count data so that it has 8366 observations on 22 variables.

20
00:02:02,610 --> 00:02:05,820
What do you know that says we have the same number of people in both of these data sets?

21
00:02:07,240 --> 00:02:12,610
Now it's pretty common. Maybe not everybody consented to a blood draw or something like this.

22
00:02:12,790 --> 00:02:17,380
So oftentimes we have this issue where if we have multiple data sets, are not always on the same people.

23
00:02:17,560 --> 00:02:21,520
So this is going to set us up to have to make some decisions when we're doing the joining.

24
00:02:24,500 --> 00:02:28,399
Another day to settle down. There will be some of those metals levels.

25
00:02:28,400 --> 00:02:34,880
So here I'll download the ion data. I'm calling that f e, that's the chemical name for Ion.

26
00:02:35,190 --> 00:02:44,410
We think this has 6400 observations. I'll download some arxan data.

27
00:02:45,720 --> 00:02:54,200
Blood and cadmium data. And then I'll download some quote me and put me in as a biomarker for cigaret smoke exposure which might be a.

28
00:02:55,850 --> 00:02:59,620
Confounder in some of these research questions. All right.

29
00:02:59,630 --> 00:03:04,540
These deals that some of them are huge, right? What do we have across all of these things?

30
00:03:04,570 --> 00:03:09,590
We have four variables, 22 variables, 16 variables, five or 46 variables.

31
00:03:09,910 --> 00:03:13,750
That's kind of a lot for us to keep track of all the time. These variable names are.

32
00:03:15,300 --> 00:03:18,960
Uh, and I'm kind of in code. They're kind of confusing.

33
00:03:19,470 --> 00:03:25,170
So what function can we use to grab on to certain variable names that we want to keep?

34
00:03:25,590 --> 00:03:32,970
So if we don't want to keep all of the variables, what's a function that we can use that we saw in the slides for grabbing columns?

35
00:03:46,310 --> 00:03:55,760
Yeah. So there's two functions or kind of a similar deal once called select to grab columns and once called filter to grab rows.

36
00:03:56,390 --> 00:04:01,610
So first we'll try to grab just certain columns. So we'll use the select function first.

37
00:04:02,690 --> 00:04:06,500
All right, so let's just grab the rows we want. So are the columns, right?

38
00:04:07,160 --> 00:04:16,610
All right. So we've decided, based on studying the data dictionary, based on coming up with our research question,

39
00:04:16,610 --> 00:04:23,420
probably based on drawing a dag of our analytic plan of like how conceptually we think these things are going.

40
00:04:24,140 --> 00:04:27,810
But these are the variables we want going forward. Okay.

41
00:04:28,030 --> 00:04:31,780
So I'm just going to grab some of these to make them more manageable.

42
00:04:32,080 --> 00:04:36,370
All right. So what I'm taking is this. I'm starting with the demographics data that.

43
00:04:37,460 --> 00:04:42,530
I'm piping it into the select function and then I'm selecting a bunch of variables I like.

44
00:04:43,040 --> 00:04:47,870
You noticed that halfway through the line I can put a hash tag and give some code to myself.

45
00:04:48,200 --> 00:04:53,570
So anything after the hash tag, these are just notes to myself to help me better remember which variable is which.

46
00:04:54,140 --> 00:05:02,570
And you notice each variable, I end up with a comma and then I specify the next variable when I'm done with the select function I and the parentheses.

47
00:05:04,840 --> 00:05:09,700
I'm also going to rename one of the variables because we saw that that gender variable is actually talking about sex.

48
00:05:09,700 --> 00:05:18,309
So I'm here, I'm just renaming it, and then I am assigning that as a new name.

49
00:05:18,310 --> 00:05:22,510
I'm calling this my demographics that I've selected. You can call it whatever you want.

50
00:05:22,810 --> 00:05:26,050
All right. So I'm just grabbing portions of this dataset.

51
00:05:26,260 --> 00:05:31,260
And so now I'm expecting a new dataset to pop up over here called Demographic Selector.

52
00:05:31,570 --> 00:05:39,820
And how many variables are expected to have. 123456789 variables.

53
00:05:40,810 --> 00:05:45,970
How many rows do you expect it to have? Same as before.

54
00:05:46,000 --> 00:05:49,230
We're not messing with that. So we're going in. We've got what do we expect?

55
00:05:49,240 --> 00:05:56,890
And then let's see what we get. And if they match, you notice I can when I want to run a code that spans a whole bunch of rows.

56
00:05:57,370 --> 00:06:04,030
All I have to do is I can put my cursor anywhere I want and I can do that keystroke of control, enter or command enter.

57
00:06:04,570 --> 00:06:07,780
That'll run the entire thing. It's able to find the beginning in the end.

58
00:06:08,170 --> 00:06:13,840
Or if you want, you could, you could like highlight the whole thing and then click run.

59
00:06:14,380 --> 00:06:21,890
You've got options for how you want to do this. So I see a new data set pop up.

60
00:06:21,900 --> 00:06:24,930
What do you see? How many rows and columns are in this new dataset?

61
00:06:24,930 --> 00:06:38,719
The suburbs select the dataset. First it's telling us the number grows and nicely what we expected.

62
00:06:38,720 --> 00:06:45,410
We've got the same number of roses before and then we see that we successfully selected only down to nine columns.

63
00:06:45,410 --> 00:06:51,220
So we've gone from 46 columns down to nine columns. So this is matching our expectations.

64
00:06:51,440 --> 00:06:55,389
If we ever want to click on it, we can we can see what those look like and see.

65
00:06:55,390 --> 00:07:05,860
Okay. These are actually the variables that we are checking out. I'm going to do the same thing for those other datasets.

66
00:07:05,860 --> 00:07:10,329
I'm going to grab just the variables we want. So the Complete Blood Count dataset has 22 variables.

67
00:07:10,330 --> 00:07:22,470
I'm going to take it down to very few. I'm going to do the same thing with iron ratings.

68
00:07:23,100 --> 00:07:26,190
I'm just going to run through this a little bit more quickly. But you can see.

69
00:07:28,510 --> 00:07:33,220
One variable hopefully you'll see is in common. I'm selecting for every single dataset.

70
00:07:33,550 --> 00:07:39,220
Can anyone tell me what that is? What variable do you notice that I keep selecting over and over again from every dataset?

71
00:07:40,490 --> 00:07:44,810
Ivan. Yeah, the C10 variable. So that's our ID variable.

72
00:07:44,990 --> 00:07:50,300
This is to set ourselves up for success because when we do a joint or a merge, we need to have something in common.

73
00:07:51,170 --> 00:07:58,190
So I'm making sure, even though I'm selecting just the iron measure I want, I'm always keeping that participant identifier as well.

74
00:08:00,790 --> 00:08:05,140
Or something like that. I'd love to grab that coat and grab that.

75
00:08:05,170 --> 00:08:13,090
Okay. So now we have a whole bunch of these smaller selected data sets so that when we join up together, hopefully it won't be as unwieldy.

76
00:08:14,530 --> 00:08:21,870
All right. All right.

77
00:08:23,190 --> 00:08:29,770
We're going to do a series of drawings now. And we're going to do them pairwise.

78
00:08:29,780 --> 00:08:35,870
So we're going to bring together two data sets at a time. The first thing that I'm going to bring together is the demographics on.

79
00:08:36,860 --> 00:08:44,060
Now I bring together the CBC and I tell it what variable I want to enjoy it by if I want to join it by the second variable.

80
00:08:44,750 --> 00:08:49,729
And then I'm going to assign out a new object here. I'm just calling demographics underscore CBC.

81
00:08:49,730 --> 00:08:56,330
So I remember which two variables have already been joined. So I'm expecting these to be stuck side by side.

82
00:08:59,030 --> 00:09:02,950
All right. Let's see what that looks like. Let's explore that a little bit.

83
00:09:05,690 --> 00:09:10,640
So we see that the variables that are on the left hand side of our dataset are all these demographics.

84
00:09:11,800 --> 00:09:16,450
And then as we start to get to the right hand side, here's those blood variables.

85
00:09:17,020 --> 00:09:20,920
These are a bunch of blood cells. So you notice that it kind of does it in the order.

86
00:09:20,930 --> 00:09:22,620
So we gave it the demographics first.

87
00:09:22,630 --> 00:09:28,960
So whatever we get at first was on the left and whatever we give it second it goes on the right and they just basically get stuck together.

88
00:09:30,570 --> 00:09:35,760
If somebody was not in the second data set, we got missing values for them.

89
00:09:37,270 --> 00:09:42,549
So you can see that all people who were in the earlier data set and instead of being

90
00:09:42,550 --> 00:09:46,060
excluded in the joint dataset because we want to still keep everybody together,

91
00:09:46,660 --> 00:09:52,000
we're getting a whole bunch of missing. Okay. So it still has the dimensions of the larger dataset.

92
00:09:54,160 --> 00:09:59,080
Next time I'm merged, another thing together, I'm going to now start with the.

93
00:10:00,120 --> 00:10:03,300
Product of that last one follows the demographics and we see it.

94
00:10:03,600 --> 00:10:06,760
And I'm going to stick to the right hand side of the stick.

95
00:10:06,780 --> 00:10:14,240
The Ion Dataset Merchant by Sega. So where did that iron show up?

96
00:10:14,510 --> 00:10:20,780
The iron value came all the way on the right hand side. And now we've got even more missing values showing up for anybody who missed that.

97
00:10:21,960 --> 00:10:28,090
Study published. We can do it again to add arsenic to the right hand side.

98
00:10:31,100 --> 00:10:35,120
One came out all the way on the right hand side here. Arsenic has a ton more missing.

99
00:10:39,960 --> 00:10:45,560
Next, the cadmium led. And then there just one.

100
00:10:47,180 --> 00:10:50,749
A trip that I issued that I ran to the colony.

101
00:10:50,750 --> 00:10:55,310
And they decide this is even with a data set that is like as nice and.

102
00:10:56,360 --> 00:10:59,450
Relatively clean, as I say, to set the.

103
00:11:01,600 --> 00:11:09,639
Label of the second variable encoding was not compatible with the label for a second.

104
00:11:09,640 --> 00:11:16,360
For every other data thought somebody must have had a typo in there. So the merge was failing because the guys didn't match.

105
00:11:16,900 --> 00:11:21,310
So I'm just removing those labels so that everybody matches and we can stick together.

106
00:11:23,320 --> 00:11:28,480
So here I'm just stripping the label off of that variable, not the whole thing, just that.

107
00:11:28,490 --> 00:11:32,020
But then I'm bringing it together. And once I brought everything together, I'm just.

108
00:11:32,020 --> 00:11:35,560
I'm just calling our names dataset and we've got, got a structure for it.

109
00:11:36,400 --> 00:11:39,820
So this is our whole drawing dataset.

110
00:11:40,390 --> 00:11:47,620
You notice this has the number of participants that our biggest group that was our demographics dataset.

111
00:11:48,580 --> 00:11:51,580
And now we have just the 18 variables that are of interest.

112
00:11:51,580 --> 00:11:53,860
So the demographics variables we selected.

113
00:11:54,640 --> 00:12:04,120
Then there's a few blood variables, then there's the iron variable arsenic, cadmium, lead, and then the coat name for smoking.

114
00:12:04,930 --> 00:12:11,230
So we've stitched together all of our variables one at a time and made this whole larger dataset.

115
00:12:13,100 --> 00:12:17,959
Generally when I do this, this will take you know, you'll end up spending entire workday,

116
00:12:17,960 --> 00:12:24,590
probably doing all these joints and doing this kind of like meticulous quality control along every step of the way.

117
00:12:25,610 --> 00:12:29,210
But let's just pause for a second and see how folks are doing here.

118
00:12:43,590 --> 00:12:49,230
Can anyone think of a scenario in your research where you would want to merge or join datasets together?

119
00:12:50,280 --> 00:12:59,690
Why? When might this come up for you? See if we can have some actual examples to make those more concrete.

120
00:13:17,380 --> 00:13:21,230
Yeah, I'm thinking about. Yeah.

121
00:13:21,330 --> 00:13:30,690
This is the new parent data. So I if you've got one observation ahead of time and later another want to see how it changes.

122
00:13:31,110 --> 00:13:34,470
Oh, that's a great point. Yeah. Right.

123
00:13:34,900 --> 00:13:41,350
So if we have like multiple, like a longitudinal data format for six months on a graph, so maybe merge because I want to visit two months.

124
00:13:43,620 --> 00:13:48,480
This is one of our comments. Such an opening object that we.

125
00:13:49,580 --> 00:13:53,210
Something you may. It certainly is true in my work and you may encounter it too.

126
00:13:53,930 --> 00:14:02,300
This type of data management takes so much more time and care, almost that running the regression model that you're building up to.

127
00:14:02,900 --> 00:14:08,750
So that data analysis that like you've been so excited to run that model,

128
00:14:09,650 --> 00:14:16,670
sometimes there's like weeks of this type of data coming up for parents that will get you to a stage where you're ready to be able to do that.

129
00:14:17,840 --> 00:14:20,900
So, yeah, just just go in with that expectation that this is,

130
00:14:21,560 --> 00:14:27,620
this is a careful job and you want to have it done right so that you can interpret your results.

131
00:14:29,420 --> 00:14:37,999
All right, let's transition back to our slides and we'll talk about how we might want to take some of the variables that are provided to us,

132
00:14:38,000 --> 00:14:42,050
but then also make new ones that might be more useful for our research questions.

133
00:14:49,980 --> 00:14:56,820
All right. So our goal in this next session will be to talk about how we can create new variables in our from some existing variables.

134
00:15:01,100 --> 00:15:07,580
So can anybody brainstorm sample of this? Like, why might you want to make a new variable to make it more health relevant to you?

135
00:15:08,030 --> 00:15:13,550
Can anybody think of either based on some of these variables we read in here or in your own work?

136
00:15:13,850 --> 00:15:17,660
Why might you want to make a new variable? Why might this come up for you?

137
00:15:23,300 --> 00:15:32,480
Yeah. Over the summer, they were trying to combine, like five different variables into one and make it a variable.

138
00:15:32,960 --> 00:15:38,300
So you add up the score of variables you variable.

139
00:15:40,440 --> 00:15:44,540
I'm also going to hit a variable or summary variable from other constructs.

140
00:15:45,630 --> 00:15:46,320
That's very common.

141
00:15:46,440 --> 00:15:55,170
I do that in our work with cognition, so we might have a cognitive test for someone's spatial memory, some short term memory, some executive function.

142
00:15:55,380 --> 00:16:00,270
All right. You're saying you got score on each of those tests and now we want your overall score.

143
00:16:00,930 --> 00:16:03,960
So we might have some kind of formula for how to bring us together.

144
00:16:05,510 --> 00:16:09,950
Can anybody else think of any other reason you might want to create a new variable?

145
00:16:14,000 --> 00:16:20,140
Please. I mean, if you wanted to use that to get the VMA, I'm sure.

146
00:16:21,860 --> 00:16:28,760
Yeah. So if you have like two measurements, for example, height and weight and you want to combine them in some kind of construct like BMI.

147
00:16:29,360 --> 00:16:32,660
Absolutely. Other times, I like to make more variables.

148
00:16:32,930 --> 00:16:41,000
For example, maybe a variable is like continuous, but there's a clinically meaningful cut point.

149
00:16:41,390 --> 00:16:44,270
So I want to know, are people high or are they low?

150
00:16:44,900 --> 00:16:51,910
So sometimes I want to take a continuous variable and chop it up as a pieces so that I can interpret it better or vice versa.

151
00:16:51,920 --> 00:17:00,260
Sometimes I want to take categories and turn them into like an ordinal or a level variable so that I can compare them across each other.

152
00:17:00,920 --> 00:17:06,649
So we'll practice all these different approaches and you may brainstorm on your own some

153
00:17:06,650 --> 00:17:11,479
that come up for you that might be important based on what you're most curious about,

154
00:17:11,480 --> 00:17:19,470
what your research questions are. So it could be common for us to want to convert between our two categories.

155
00:17:19,480 --> 00:17:22,560
So if we have those kind of clinical plot points I was talking about,

156
00:17:23,340 --> 00:17:27,960
sometimes we want to combine multiple numeric things into some kind of total score.

157
00:17:28,410 --> 00:17:33,030
And regardless of what type of variable we want, usually we want to add them to our data.

158
00:17:33,330 --> 00:17:37,470
So we don't want them floating off as a separate vector.

159
00:17:37,800 --> 00:17:41,190
Usually we want to stitch it to our dataframe and make it a new variable.

160
00:17:45,320 --> 00:17:48,950
One of the useful ways from doing this, particularly for making those cup points,

161
00:17:49,280 --> 00:17:57,080
is to use conditional statements which basically, like, if this condition is true, then do this outcome.

162
00:17:57,740 --> 00:18:01,960
So a useful function for this, an R is called the effects function,

163
00:18:03,350 --> 00:18:10,790
and so we specify some action to do if this is true and a second action to do if that statement is false.

164
00:18:12,620 --> 00:18:16,370
So, for example, for this class.

165
00:18:17,400 --> 00:18:23,940
If your score is greater than or equal to 70, you'll be in the category of pass health.

166
00:18:24,000 --> 00:18:29,640
If that's not true, you'll be in the category of fit. And nobody has ever failed this class before.

167
00:18:29,670 --> 00:18:36,450
We will all be in this first category. So what this is saying there is essentially within the Phelps function,

168
00:18:36,750 --> 00:18:43,260
there's you notice there's two commas which sets apart like three spaces for information.

169
00:18:43,590 --> 00:18:51,000
So if a first space of information is true, if this first condition is true, do this.

170
00:18:51,450 --> 00:18:57,030
This is the action you do. Else if that first condition is not true, this is the action.

171
00:18:57,120 --> 00:19:03,930
The third action you do. Okay. And then what we're doing in this case is we're assigning this as a new object.

172
00:19:07,130 --> 00:19:11,390
For this. I always want a check my work too. I want to see what I expect, what I get through the match.

173
00:19:12,080 --> 00:19:16,790
You could inadvertently put all the missing people in one category that you might not mean to.

174
00:19:17,270 --> 00:19:23,810
So I always want to have an expectation going in and I want to check to make sure what I actually got here.

175
00:19:23,820 --> 00:19:32,340
If I put people in the right category to. There is a ten year extension of this if we want.

176
00:19:32,430 --> 00:19:36,420
That's useful if we want to extend that for multiple conditions.

177
00:19:37,020 --> 00:19:40,950
So it's kind of it's possible with efforts to do more than those two conditions.

178
00:19:41,490 --> 00:19:50,940
But it's. It's kind of tricky. There's a tiny first version of a function called Case one that's going to allow us greater flexibility.

179
00:19:50,940 --> 00:19:54,390
So if we want to use many more points or many more conditions.

180
00:19:55,320 --> 00:19:59,550
So this is going to follow the same structure. So if this is true, do this.

181
00:20:00,390 --> 00:20:03,480
And you notice these are linked with instead of a comma.

182
00:20:03,750 --> 00:20:06,870
Now they're linked with a tilde, this kind of squiggly line.

183
00:20:07,350 --> 00:20:11,970
So if this condition is true, do this action on this other side.

184
00:20:13,450 --> 00:20:19,059
This is very easy to string many of them together. So this is actually for another class I have.

185
00:20:19,060 --> 00:20:25,570
This is how I do the grading. So if the score meets this criteria, assign this value.

186
00:20:26,140 --> 00:20:33,580
And then after the column, I can specify another criteria. So if the score is greater than 80 and less than 90, assign this value.

187
00:20:33,940 --> 00:20:37,870
And then after the comma, I can do another criteria. On and on and on.

188
00:20:38,080 --> 00:20:47,560
So this case, one function is useful because after the commas we can separate, you know, an infinite number of cut points for ourselves if we need to.

189
00:20:48,520 --> 00:20:51,520
And then similarly, as before, we can assign that as a new object.

190
00:20:56,890 --> 00:20:59,890
And I was thinking, how often do and data cleaning is?

191
00:21:00,490 --> 00:21:07,450
I want to make factor levels, factor variables. So these are variables that have discrete values that are possible.

192
00:21:07,450 --> 00:21:12,310
Those values could be 1 to 3 or they could be ABC or they could be names or something like this.

193
00:21:12,850 --> 00:21:16,809
But this is essentially the most equivalent to like a categorical variable

194
00:21:16,810 --> 00:21:20,830
in epidemiology where there people are able to be and in certain categories.

195
00:21:22,470 --> 00:21:26,400
Oftentimes when we're doing a regression model or we're doing a comparison,

196
00:21:27,960 --> 00:21:32,070
you always want to or generally we want to compare a relative to one of those groups.

197
00:21:32,820 --> 00:21:37,320
So you want to, as the analyst, be in charge of which one of those groups is the reference.

198
00:21:37,740 --> 00:21:43,770
Otherwise, R by default is going to pick the your reference group just alphabetically.

199
00:21:44,280 --> 00:21:47,160
And I'm like by chance you what you intended.

200
00:21:47,990 --> 00:21:54,450
But, but a lot of times the group we want to be our reference group, you know might not be alphabetically first.

201
00:21:54,450 --> 00:22:00,239
You know, maybe we're comparing a cross university, University of Michigan to be the reference group,

202
00:22:00,240 --> 00:22:05,070
you know, and that might not come out by default because that's kind of on the alpha.

203
00:22:05,520 --> 00:22:10,229
So here we would pick what reference group we want and there's a function we can

204
00:22:10,230 --> 00:22:15,330
use re level where we specify which level we want to be the reference category.

205
00:22:16,340 --> 00:22:19,970
This may feel kind of early to be doing this in our analysis,

206
00:22:20,420 --> 00:22:27,170
but really we're trying to set ourselves up so that when we're doing regression modeling with categorical or dummy variables,

207
00:22:27,320 --> 00:22:45,920
we will be all set to go. Sometimes we want to split our numeric variables up into categories and we don't necessarily know what the cut points are,

208
00:22:45,920 --> 00:22:54,680
but we know how many groups we want it to be. So there's these two functions cut interval and cut numbers that are really useful.

209
00:22:56,390 --> 00:23:07,070
So here I'm cutting my age vector into five groups that have an equal age range between them.

210
00:23:08,000 --> 00:23:14,150
So if you want to compare people at higher ages, some middle ages to lower ages, you can do it that way.

211
00:23:16,190 --> 00:23:23,540
Or we can use cut number to make a certain number of drops with approximately equal number of participants.

212
00:23:24,140 --> 00:23:25,480
So you might have different reasons.

213
00:23:25,490 --> 00:23:35,270
Maybe you want B, the groups have equal number of age years between them, or here maybe you want equal number of participants in each of those groups.

214
00:23:35,480 --> 00:23:43,310
And these are different analytic choices you might make based on your goals for modeling going forward.

215
00:23:47,920 --> 00:23:56,579
Here's the example of folks who were describing before. Sometimes we want to use calculator functions to combine variables.

216
00:23:56,580 --> 00:23:57,360
So in this case,

217
00:23:58,350 --> 00:24:08,100
this is saying within the enhanced object I want to take weight in kilograms and divide it by height in meters squared to create a BMI variable.

218
00:24:08,520 --> 00:24:14,130
Or maybe I want to take score one and score two and add them together for a total score.

219
00:24:14,730 --> 00:24:23,580
So we're kind of using those operators, the plus, the division, the power.

220
00:24:24,120 --> 00:24:30,120
So we're combining some of the skills we learned in our very first week of this class to now apply it not just the numbers,

221
00:24:30,120 --> 00:24:38,230
but we're applying it to variable names. So far, we've been making these variables.

222
00:24:38,330 --> 00:24:41,790
They're just floating. These are new objects. We're making these objects.

223
00:24:41,800 --> 00:24:45,100
They're just floating around in our global environment.

224
00:24:45,910 --> 00:24:49,210
If we want to actually stitch them to our dataset, there's one more step.

225
00:24:52,840 --> 00:24:57,550
So we're going to use a function called mutate to stitch it to our dataset.

226
00:24:58,390 --> 00:25:03,070
All right. So this will take our current variable, which is in our dataset,

227
00:25:03,310 --> 00:25:09,100
and create a new variable built on that variable that's stitched to the right hand side of the dataset.

228
00:25:09,880 --> 00:25:13,210
So here I'm saying mutate whatever the name of the data frame is.

229
00:25:13,960 --> 00:25:19,450
And I say, here's this new variable I want you to make from the old variable, and this will add that variable.

230
00:25:19,450 --> 00:25:23,200
It will no longer be floating separate in the environment.

231
00:25:23,380 --> 00:25:30,150
Now it's going to be stuck to the dataset. I could do that with a pipe if I want.

232
00:25:30,150 --> 00:25:38,280
So I want to pipe the data for him into the mutate function and specify that new variable there and I'll sign as variable on our new day of Saturday.

233
00:25:42,240 --> 00:25:50,880
Mutates useful because we can make a whole bunch of variables at once, whether it's a way of wrapping all of this in together.

234
00:25:51,030 --> 00:25:57,910
So here are three variables that we we made on prior slides.

235
00:25:58,230 --> 00:26:02,100
And let's start with the mutate function. Let's see how they can all be created at once.

236
00:26:03,150 --> 00:26:07,800
All right. So I'm taking that hands object and piping it into the mutate.

237
00:26:08,790 --> 00:26:12,599
And now I'm saying, okay, make a me a new make me a new variable.

238
00:26:12,600 --> 00:26:17,360
I'm calling BMI. And how I want you to build that is by taking the weight.

239
00:26:17,430 --> 00:26:22,620
Kilograms variable divided by the height and meter square. And then comma.

240
00:26:23,250 --> 00:26:25,560
I also want a new variable called Age Group.

241
00:26:26,340 --> 00:26:32,670
Here's how you build that age, your variable, and you cut the interval age into five groups and then comma.

242
00:26:32,700 --> 00:26:38,670
Here's a new variable. I want a variable called result and I want that to be built with this case one score.

243
00:26:39,420 --> 00:26:46,229
So when those criteria for passing or failing is met. So you notice in each one of these, all within them, you take function.

244
00:26:46,230 --> 00:26:51,870
So this new target function got opened up over here. It hasn't even closed out until over here.

245
00:26:52,740 --> 00:26:58,830
So this function is huge right now. There's three different variables being created within that one function.

246
00:26:59,400 --> 00:27:05,370
So in this way, it's helpful. It's allowing us to make a whole bunch of variables at once.

247
00:27:06,150 --> 00:27:09,870
And then I'm assigning that as a new data set that's going to be the same as this old one,

248
00:27:10,620 --> 00:27:14,429
and it's going to have three new columns on the right hand side. For these three new columns.

249
00:27:14,430 --> 00:27:18,499
We just don't. All right.

250
00:27:18,500 --> 00:27:21,710
So here's this recap of this journey we were just talking about.

251
00:27:22,010 --> 00:27:28,130
So it's very, very common in our public health data to make new variables using existing variables.

252
00:27:28,220 --> 00:27:34,340
We make these a time out there guided by recommendations from our clinical colleagues.

253
00:27:34,580 --> 00:27:42,380
They're guided by your reading in the literature. You can get more out of data sets when you make more complex variables from them.

254
00:27:43,070 --> 00:27:50,870
So some of the helpful functions to help you do this. We're going to use case one to help us with conditional statements.

255
00:27:50,890 --> 00:27:58,580
So if this is true, then do this. You use cut interval to help break up numeric data into categories.

256
00:27:59,180 --> 00:28:02,960
We'll use some of those calculator operators to combine numeric variables.

257
00:28:04,410 --> 00:28:10,050
And then to bring it all together, we'll use mutate to add those new variables to the existing dataset.

258
00:28:11,160 --> 00:28:12,059
And across all of these,

259
00:28:12,060 --> 00:28:20,760
we're going a logic check to make sure what we expect to happen is what is actually we're observing that in the in the results there.

260
00:28:21,630 --> 00:28:24,780
So let's pause a second. What are your thoughts about this?

261
00:28:25,140 --> 00:28:30,810
Anybody have any examples of variables that they could apply these functions to?

262
00:28:31,020 --> 00:28:41,660
Any questions, comments? All right.

263
00:28:45,470 --> 00:28:50,540
Well, as one of my old mentors used to say, let's get to the data so we can click back in here.

264
00:28:50,570 --> 00:28:58,950
We're going to rejoin Project two. I'm going to click back into my project to.

265
00:29:07,560 --> 00:29:12,840
Okay. All right. So we left off. For me, it's summer.

266
00:29:12,840 --> 00:29:18,000
I'm colorblind to 80. It might be different for you based on how many notes you're taking along the way.

267
00:29:18,630 --> 00:29:27,220
But really, where we are together. Is at a coach and that's all about creating a new continuous variable from other continuous variables.

268
00:29:27,460 --> 00:29:35,320
If you ever want to like navigate quickly through this, there's an outline button and you can see all of the different titles of.

269
00:29:36,940 --> 00:29:43,680
Topics we've been working through. So there's one way to put that out of the way for now, just so we have more space to do.

270
00:29:46,150 --> 00:29:48,850
All right. So we're going to start making some variables.

271
00:29:48,850 --> 00:29:53,139
Our main dataset that we're going to build all of our variables off is the one I'm calling enhanced.

272
00:29:53,140 --> 00:29:59,740
So this is the one that's already gone through joining this as currently before we start, this has 18 variables.

273
00:30:00,430 --> 00:30:05,259
We're going to start adding some more and we'll see where they get added to. All right.

274
00:30:05,260 --> 00:30:10,450
So one variable I want to make is one recommended by our clinician colleagues.

275
00:30:10,840 --> 00:30:14,080
This is something called the neutrophil lymphocyte ratio.

276
00:30:14,620 --> 00:30:25,270
So this is taking a variable that counts the number of neutrophils, which are a type of cell in your bloodstream.

277
00:30:25,390 --> 00:30:29,620
There are grass sites that are like the first responders, your infection.

278
00:30:30,610 --> 00:30:34,239
And then we're going to divide it by the number of lymphocytes.

279
00:30:34,240 --> 00:30:43,299
Lymphocytes includes like all of your B cells and T cells and other other types of blood cells.

280
00:30:43,300 --> 00:30:47,080
So we were looking at the fraction of these two. All right.

281
00:30:47,080 --> 00:30:52,240
So we're going to take the neutrophils variable and divide it by the lymphocytes variable.

282
00:30:52,810 --> 00:30:57,820
And I'm assigning that as a new name. I'm calling and I look for neutrophil lymphocyte ratio.

283
00:30:59,080 --> 00:31:04,810
So where are you expecting this neutrophil lymphocyte ratio variable to appear?

284
00:31:04,930 --> 00:31:14,680
Where are you expecting that to show up? Is there going to be a new object or is it going to show up?

285
00:31:14,700 --> 00:31:22,810
What are we assigning? Ask. They're going to do very well, right?

286
00:31:23,170 --> 00:31:28,600
Yes. We're going to rewrite the old engine's data set and we're going to keep all the other variables the same.

287
00:31:28,840 --> 00:31:31,899
And we're going to make this it's going to show up and we're expecting it to

288
00:31:31,900 --> 00:31:37,540
show up on the far right side so I can put my cursor anywhere around here, hit control, enter and we'll see what happens.

289
00:31:37,990 --> 00:31:42,550
So we run that on the engines. That gets upset. And I have 19 variables.

290
00:31:43,610 --> 00:31:48,710
Let's check that out. I look like. We see on the far right hand side.

291
00:31:49,400 --> 00:31:53,810
Now we have a new variable called MLR and it looks to be continuous.

292
00:31:55,040 --> 00:32:00,260
And let's do a little bit more diagnostics so we can here.

293
00:32:00,680 --> 00:32:03,880
Now, I'm pulling together some of the functions we used before.

294
00:32:04,550 --> 00:32:11,210
I'm saying let's look in the names object with select just some of the relevant variables I want.

295
00:32:11,240 --> 00:32:16,850
So I want the IV variable, the neutrophil variable, the lymphocyte ratio, and the new variable we make.

296
00:32:17,360 --> 00:32:23,149
And I want to look at just the top of it, just the head of it. All right.

297
00:32:23,150 --> 00:32:28,389
So here now we've made this output table. Had posed just the first six rows.

298
00:32:28,390 --> 00:32:31,990
So there's the first six rows and then here's our is variable.

299
00:32:33,430 --> 00:32:36,580
Here's our regional variable, our lymphocyte variable in our analyzer.

300
00:32:36,940 --> 00:32:41,170
So what happens if if our neutrophils and lymphocytes were missing?

301
00:32:42,100 --> 00:32:45,160
You notice that our ratio is still missing. That's good.

302
00:32:45,820 --> 00:32:49,360
We don't want to invent data and just on eyeball.

303
00:32:49,690 --> 00:32:57,820
Does this make sense? If if a value was 3.2 here, a value of 3.5, does it make sense that our ratio is slightly less than one?

304
00:32:58,890 --> 00:33:04,910
Yeah. So we can kind of logic check that out. If our value is 4.2 and 3.4, does that make sense?

305
00:33:04,920 --> 00:33:07,050
And this is slightly greater than one. Okay.

306
00:33:07,320 --> 00:33:15,330
So I'll just kind of like look this at look these things up side by side to make sure that nothing really bizarro is happening there.

307
00:33:18,820 --> 00:33:28,320
So this is an example of if we want to use operators like to combine things in our example with adding two scores together,

308
00:33:28,360 --> 00:33:32,110
something like this, and we can use the mutate to put it as a new variable.

309
00:33:34,390 --> 00:33:43,390
Another way we might want to do is create categories from a continuous variable based on some clinical points.

310
00:33:43,720 --> 00:33:55,810
So let's say we talk to our clinicians and we learned that if a person has iron levels below 60, then they are considered low iron status.

311
00:33:56,200 --> 00:34:02,080
So before we even make this variable, let's double check and see how many people we expect to be in each of these groups.

312
00:34:05,140 --> 00:34:09,430
So here I'm saying add up how many people are in this group of iin?

313
00:34:09,430 --> 00:34:13,030
Less than 60. Don't talk about the missing data.

314
00:34:13,150 --> 00:34:21,250
We'll have a whole thing about missing data very soon. But so what this is telling us is that 1300 people in our dataset have low iron levels.

315
00:34:22,470 --> 00:34:29,030
Then I'm going to ask how many people have normal levels? Here's the Cup points that our collaborators told us.

316
00:34:29,040 --> 00:34:35,649
And then lastly, I'll ask for how many people at higher levels. So again, I haven't made a new variable yet.

317
00:34:35,650 --> 00:34:39,330
I'm just setting my expectations beforehand. Okay.

318
00:34:39,460 --> 00:34:42,970
So I'm only expecting 143 people to have high grade levels.

319
00:34:43,270 --> 00:34:47,080
All right. So now I've got a baseline idea of what I expect.

320
00:34:47,590 --> 00:34:52,329
Now I'm ready to make a variable. All right. So, all right.

321
00:34:52,330 --> 00:34:57,730
I'm using the mutate function to make a new variable. I'm calling that new variable iron status.

322
00:34:58,570 --> 00:35:02,290
Could anybody talk me through what is happening in this case? One function.

323
00:35:02,920 --> 00:35:06,350
Okay, so what are we. What are we performing here?

324
00:35:06,370 --> 00:35:10,540
What are the conditions we're setting? And what kind of values are we assigning them?

325
00:35:12,970 --> 00:35:24,750
See if we can talk our way through it together. You have a phrase you're creating a of categorical variable for different types of studies.

326
00:35:24,840 --> 00:35:27,990
Mm hmm. And based on, I guess, the clinical parameters.

327
00:35:29,730 --> 00:35:37,050
Exactly. Those fabulously said. So we're taking this original variable for I think it stands for lab measure of iron.

328
00:35:38,160 --> 00:35:43,200
And we're saying whenever that lab ion a lab measure of ion value is less than 60,

329
00:35:43,530 --> 00:35:48,360
let's assign this now to be a category, this category I'm calling deficient.

330
00:35:48,990 --> 00:35:52,290
So we're starting with a continuous numeric variable.

331
00:35:52,650 --> 00:35:56,580
And I'm putting I'm Ben on it saying that's a deficient category one.

332
00:35:56,580 --> 00:36:05,460
After the comma, I can specify another category. So I'm saying if your ion is greater than 170, then you get assigned to the category of excessive.

333
00:36:06,470 --> 00:36:09,470
And I have a new category down here. What? Who?

334
00:36:09,590 --> 00:36:17,750
The most new category? I've got two criteria. And how am I indicating to our that I want somebody to fit both criteria?

335
00:36:21,410 --> 00:36:23,270
Yeah. I'm using the emphasis on that. And.

336
00:36:24,320 --> 00:36:29,660
So this in this way, if you want to do good scripts, you can make people fit a whole bunch of criteria together.

337
00:36:30,290 --> 00:36:36,560
So this is saying somebody has iron greater than or equal to 60 and they have either less than or equal to 170.

338
00:36:37,760 --> 00:36:43,940
Because you can string together more arms if you want to. There's also a symbol if you wanted, or that's a vertical bar.

339
00:36:44,060 --> 00:36:48,590
If that was applicable in your selection, we have our normal category.

340
00:36:49,160 --> 00:36:53,540
And then here I'm stringing together another mutate statement where I'm saying,

341
00:36:53,540 --> 00:36:58,850
take that iron that is variable and make sure we set our reference level to be the deficient group.

342
00:36:59,430 --> 00:37:03,290
Okay. So this is just an example of how you can plan ahead.

343
00:37:03,320 --> 00:37:09,980
So for all of our plots, we're going to always be comparing to the decision group, if you want to correct me on this.

344
00:37:10,910 --> 00:37:16,260
See, what do we get and we see in the table I reference group,

345
00:37:16,260 --> 00:37:21,620
this gets listed first and these are the number of participants in each of the groups that we were expecting.

346
00:37:21,630 --> 00:37:25,190
So our high iron group, we only had one 4442.

347
00:37:25,730 --> 00:37:33,710
So we see that we were actually able to make these categories and we made the right number of people in each category that we were expecting.

348
00:37:34,430 --> 00:37:42,620
We can check the structure of this new variable we made. And we see that, okay, this is now a fracture variable and it has three levels.

349
00:37:42,620 --> 00:37:45,740
Here is the levels and here are the first few observations.

350
00:37:46,470 --> 00:37:50,970
All right. So I don't just, like, jump in and make a variable and then walk away.

351
00:37:51,390 --> 00:37:56,060
You can see, like, I build up to it. So I see what do I expect before I make the variable?

352
00:37:56,100 --> 00:38:00,140
I try the variable and then I double check to make sure it works in the way I thought.

353
00:38:06,840 --> 00:38:12,720
Sometimes you don't exactly know what points you want, so you just want to tell R Here's how many groups I want.

354
00:38:13,710 --> 00:38:21,930
So here I'm saying take that hands dataset, type it into the mutate function and make me a new variable I'm calling age groups.

355
00:38:22,800 --> 00:38:29,790
And what I want you to do is cut the existing age variable into five groups of equal number of years between the.

356
00:38:32,980 --> 00:38:41,060
And so here I'm checking the frequencies of those. We can see our first age group is ages 0 to 16.

357
00:38:41,600 --> 00:38:46,340
There's 3200 people in that low age group. Now we have age 16 to 32.

358
00:38:46,430 --> 00:38:51,320
There's 1500 people. This middle age group are 1300.

359
00:38:51,500 --> 00:38:55,040
And then in our oldest age groups, 60, 48, 5000 people.

360
00:38:55,280 --> 00:38:59,900
Would you say there's an even spread of people in our dataset across all ages?

361
00:39:01,390 --> 00:39:07,900
Now. All right. We've got a lot of people in the younger age group, so they've kind of overrepresented children in our dataset.

362
00:39:08,860 --> 00:39:14,110
So in that case, if we would rather for our modeling purposes or any other reason,

363
00:39:14,320 --> 00:39:23,560
if we want to have approximately equal number of people in each group, we could use the number function.

364
00:39:23,830 --> 00:39:27,370
And now we have approximately equal number of people in each group.

365
00:39:27,610 --> 00:39:31,600
But the number of years each group spans are unequal.

366
00:39:32,010 --> 00:39:36,809
Okay. In the last few minutes of class.

367
00:39:36,810 --> 00:39:41,879
Let's do this. Check your understanding. Where we try to take serum protein,

368
00:39:41,880 --> 00:39:52,530
which is one of the variables in our dataset and try to take it from a continuous variable into a categorical variable.

369
00:39:53,340 --> 00:40:01,200
So if your coating levels are greater than ten, we can infer that that person is in a smoking category.

370
00:40:01,200 --> 00:40:06,030
And if their colony values are less than or equal to ten, let's put them in the nonsmoking category.

371
00:40:06,790 --> 00:40:15,720
So let's see if we can make smoking variable from colony and figure out how how we can do this using code.

372
00:40:22,340 --> 00:41:14,660
These new. We have.

373
00:41:20,490 --> 00:41:41,899
Yeah. All right.

374
00:41:41,900 --> 00:41:49,340
So here's one way I might set my expectations. So I got to ask how many people are greater than ten and how many are less than or equal to ten?

375
00:41:50,090 --> 00:41:55,250
So I can see if I run those together. Here's how many people expect to be in each of those groups.

376
00:41:56,420 --> 00:42:01,220
Does anybody have any ideas? How would you approach us? How are you going to actually make those groups on your dataset?

377
00:42:04,650 --> 00:42:07,050
What kind of function are people interested in using?

378
00:42:09,030 --> 00:42:19,560
Sure, we could use case one so we can assign those to the enhanced data set and type that in there.

379
00:42:24,550 --> 00:42:29,830
All right. And then we can mutate and use the kiswa.

380
00:42:31,470 --> 00:42:35,880
And what do you want to call this new variable? Sure.

381
00:42:38,040 --> 00:42:41,250
Yeah. Let's just do a check of above.

382
00:42:44,330 --> 00:42:48,860
So where to go? Smoking. On that score.

383
00:42:48,860 --> 00:42:54,550
It's got us. Equals and then we'll say the case run function.

384
00:42:55,150 --> 00:43:04,480
And what are the criteria? What's the first criteria? What to do if the common levels are greater than ten?

385
00:43:06,630 --> 00:43:09,840
Then. Tilda Or you can call that smoking.

386
00:43:11,470 --> 00:43:20,590
And then to set a second criteria over X mean if the values are less than or equal to ten.

387
00:43:21,310 --> 00:43:32,340
We can set that value to nonsmoking. Tick that out and then run a table to see what we got.

388
00:43:38,710 --> 00:43:49,690
You can't match what we expected before. So we've got 1255 people in the smoking category and 50, 100 people in the non smoking category.

389
00:43:58,680 --> 00:44:01,889
Just a reminder, we've got unsaved code up here.

390
00:44:01,890 --> 00:44:04,830
It's in red. There's an asterisk to save our code.

391
00:44:04,830 --> 00:44:14,610
We can click a floppy disk or hit command control s and then wonder what I want to show us at the very bottom and scroll past the next code chunk.

392
00:44:17,440 --> 00:44:20,860
To this very. And we're going to save the data set. All right.

393
00:44:21,130 --> 00:44:25,230
So if we want, we can write it as a C SD to share it with our collaborators.

394
00:44:25,230 --> 00:44:28,830
So write that and use data. See that out to see us.

395
00:44:28,840 --> 00:44:40,810
We want to show up in our files folder if we want to save it as a R file and save it as the RBA, that'll show up in our lower right hand corner.

396
00:44:41,320 --> 00:44:50,470
Okay. If we render this, we put this file and it'll run the entire code all together as and create a report or a product.

397
00:44:52,660 --> 00:44:59,080
Right. So that is going to wrap up our data management section.

398
00:44:59,080 --> 00:45:06,700
And you have a homework assignment on data management that's going to ask you to read on a new enhanced dataset,

399
00:45:06,850 --> 00:45:10,390
merge it, and then create some of these new variables.

400
00:45:10,900 --> 00:45:14,620
Use case when use interval to create some new variables.

401
00:45:14,620 --> 00:45:17,769
So you got to practice each of these steps. This is going to be challenging.

402
00:45:17,770 --> 00:45:20,800
Please use the discussion board to help each other out.

403
00:45:21,710 --> 00:45:31,750
So so we can practice. This is very practical, very practical and useful steps and you'll be ready to do this on your own dataset.

404
00:45:32,590 --> 00:45:38,140
So thank you everyone for attention. I'm going to turn off the recording and I think we might have a new class coming on this.

