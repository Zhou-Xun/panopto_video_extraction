1
00:00:00,720 --> 00:00:09,750
I don't know how I got here long enough to start a research firm.

2
00:00:09,780 --> 00:00:26,880
I'm just doing my job. And I don't know if this position and that honorable office is wrapped up at the moment.

3
00:00:26,960 --> 00:00:31,110
Well, I'm pretty sure you're not. It's not good.

4
00:00:31,200 --> 00:00:34,690
All right. You can have another chance to grab candy on your way out, too.

5
00:00:34,950 --> 00:00:41,589
Don't leave me with this staff. So, expecting a lot of these my office hours.

6
00:00:41,590 --> 00:00:47,399
If you didn't see I sent an announcement. I changed my office hours today, election day, which hopefully all of you are aware.

7
00:00:47,400 --> 00:00:54,150
And if you're able to vote, you did or will vote. But because of that, there's no public school.

8
00:00:54,150 --> 00:00:58,210
And so I sent my kids, my oldest, to something called Kids Zone.

9
00:00:58,410 --> 00:01:02,580
But unfortunately it ends I for so I got to go pick her up.

10
00:01:02,760 --> 00:01:07,470
So I had to go to my office hours earlier so I could leave and get out.

11
00:01:10,530 --> 00:01:14,729
Otherwise you have one more homework. It's due next week.

12
00:01:14,730 --> 00:01:20,430
Or when is due? Thursday. Thursday. If you want to do next week goes by me.

13
00:01:20,430 --> 00:01:24,880
I don't care. It's your choice. If there is a heavy vote, just send me an email and I will.

14
00:01:24,900 --> 00:01:29,100
I don't. It doesn't matter. Yeah. Do you? Who wants to move it to next Tuesday or Thursday?

15
00:01:31,710 --> 00:01:37,610
Who was it to stay Thursday? Nobody want to hear it.

16
00:01:37,800 --> 00:01:44,280
Let's make it. Oh, I'll make sure it's updated on grade scope.

17
00:01:45,300 --> 00:01:51,960
But I think, you know.

18
00:01:52,350 --> 00:02:00,450
So it wasn't 17th. It's okay, we'll make it do the case.

19
00:02:00,450 --> 00:02:11,930
It was oh yeah, we'll make it do the 15th. Okay. So week from now into this and then I'll make sure I update updated.

20
00:02:13,000 --> 00:02:16,460
So it's time for a quick question about that.

21
00:02:17,640 --> 00:02:25,400
Yeah. Okay. I think it's part C is asking like for which lead indication something.

22
00:02:25,680 --> 00:02:28,860
Yeah. I didn't think there were like different types of indications.

23
00:02:28,860 --> 00:02:41,280
I wasn't sure what that meant. So I believe in this article it calls things, um, yeah.

24
00:02:41,280 --> 00:02:45,870
So you see how it calls things like lead indications and all indications.

25
00:02:46,110 --> 00:02:50,070
Yeah. And then.

26
00:02:56,240 --> 00:03:00,070
This is by disease for all indications. Right.

27
00:03:00,080 --> 00:03:04,870
You should be able to. One of them asks about a me about this.

28
00:03:04,870 --> 00:03:08,319
I might do. One of them does not say disease indication.

29
00:03:08,320 --> 00:03:12,460
Is that the one. Now, is there one that asks if you give indication to.

30
00:03:13,450 --> 00:03:25,239
I think there is a different one that. First, which lead indication was the proportion of drugs entering phase one study?

31
00:03:25,240 --> 00:03:33,040
That is, are they asking more like compared across the different studies definition to meet indications?

32
00:03:49,230 --> 00:04:11,380
So. New York is I'm asking you about like in here.

33
00:04:11,410 --> 00:04:15,940
Right. All indication is biologics and EMS lead indications.

34
00:04:18,540 --> 00:04:21,810
So, like, separated by the drug class. Oh, no. Here we go.

35
00:04:21,970 --> 00:04:33,440
You're right. Read indications. Other infectious respiratory autoimmune underground oncology neurology cardiovascular disease divided by year.

36
00:04:33,940 --> 00:04:40,510
Under this lead indications that. Right?

37
00:04:40,810 --> 00:04:46,900
Yup. Okay. So Hallmark, will we do Tuesday office hours or earlier today?

38
00:04:47,170 --> 00:04:52,810
Do you have any other questions? And you can't make office hours. You can go to Fong's on Friday or you can send me an email.

39
00:04:54,440 --> 00:04:57,590
All right. Any other anything else?

40
00:04:57,620 --> 00:05:01,760
Not necessarily homework related. Okay.

41
00:05:01,850 --> 00:05:07,150
So hopefully so today. And it's also definitely going to go into solid Thursday's lecture.

42
00:05:07,280 --> 00:05:13,640
This one's pretty long. We're going to talk about trial monitoring and more adaptive features and clinical trials.

43
00:05:14,420 --> 00:05:21,410
And I hope that if you that you read that set of clinical trials, commentaries or editorials.

44
00:05:22,160 --> 00:05:30,010
It was the if you go on campus. And you look at today, it's the second set of readings.

45
00:05:31,000 --> 00:05:39,170
I just reread it myself because I've read it many times, but not more recently where you go, right?

46
00:05:39,280 --> 00:05:43,000
It's this one. It's this reading, this adaptive design in clinical trials.

47
00:05:43,570 --> 00:05:51,520
It is like 26 total pages, but each, I don't know, there are six or seven commentaries in there and I just find it very interesting.

48
00:05:51,520 --> 00:05:57,040
And myself, I was sort of like, yes, you know, when you read it, you're like, Yeah,

49
00:05:57,410 --> 00:06:01,720
and adaptive designs are terrible and you're like, Well, actually, that sounds pretty good.

50
00:06:01,990 --> 00:06:05,620
Oh, no, it's really bad, right? You kind of go back and forth. They're very convincing.

51
00:06:06,430 --> 00:06:13,569
And so it pulls in the ethics that we talked about originally and then also really talking about statistics and what is the goal,

52
00:06:13,570 --> 00:06:15,010
what are we trying to optimize?

53
00:06:15,850 --> 00:06:25,929
And so I think it's a really nice set of articles that are easy to read and also really combine a lot of what you're learning,

54
00:06:25,930 --> 00:06:27,520
not only in this class, but otherwise.

55
00:06:27,520 --> 00:06:35,200
And so again, I just find it to be a really useful set of articles that I suggest that you if you don't read a lot of things that you do read that.

56
00:06:37,080 --> 00:06:43,590
So the goals are that we're going to define what is an adaptive component will mean different types of adaptations.

57
00:06:43,920 --> 00:06:48,780
We're going to spend a fair amount of the time talking about group sequential design or interim analysis,

58
00:06:48,780 --> 00:06:57,749
and in particular talking about two specific types of boundaries, the O'Brien Fleming boundaries and the Pocock boundaries.

59
00:06:57,750 --> 00:07:03,210
And then we'll talk about how those can be more flexible or general in the alpha spending methods.

60
00:07:03,780 --> 00:07:07,139
And that will move on to a little discussion about the response, adaptive randomization.

61
00:07:07,140 --> 00:07:11,640
And that's really what all of those clinical trials, editorials or commentaries are about.

62
00:07:12,270 --> 00:07:14,819
They call them outcome adaptive randomization,

63
00:07:14,820 --> 00:07:23,580
but a lot of people call it R response adaptive randomization and then just try to conclude with some advantages and disadvantages.

64
00:07:23,580 --> 00:07:31,020
Although as I was reading, it's mostly concludes with disadvantages, but do not be to pull them on direction.

65
00:07:31,020 --> 00:07:33,149
They are both ways. Okay,

66
00:07:33,150 --> 00:07:44,520
so on the top is what usual clinical trial design or maybe not usual standard clinical traditional clinical trial design looks

67
00:07:44,520 --> 00:07:53,040
like is that we design the trial ahead of time and then we everything that we set forward and we conduct and nothing changes,

68
00:07:53,250 --> 00:07:58,860
right? Unless there is like some massive catastrophe in the data safety monitoring board shuts it down.

69
00:07:58,860 --> 00:08:04,050
But like otherwise, everything goes as as we had planned it and we analyze the data.

70
00:08:04,620 --> 00:08:08,700
Alternatively, there is the adaptive design of which we've already talked a little bit about.

71
00:08:08,740 --> 00:08:17,069
We've actually already talked about two adaptive designs, one being the continual reassessment method or also the tight scrum right,

72
00:08:17,070 --> 00:08:22,140
and other being Simon's two stage design, where we set forward the design,

73
00:08:22,500 --> 00:08:28,530
however we've pre-specified specific adaptations we can make when we start to accrue data.

74
00:08:28,950 --> 00:08:36,690
And so we can look at the data, review it and adapt based on our pre-specified rules with the accumulated data.

75
00:08:37,050 --> 00:08:41,910
And we can potentially do this multiple times throughout the trial and then analyze the data later.

76
00:08:43,380 --> 00:08:47,160
So adaptive designs, is this like massive umbrella term?

77
00:08:47,550 --> 00:08:54,930
A lot of people, maybe you all, and especially outside of statisticians, when they hear the word adaptive,

78
00:08:54,930 --> 00:08:59,579
they automatically think response, adaptive randomization or outcome adaptive randomization.

79
00:08:59,580 --> 00:09:06,989
What all those articles are about, however, it is not just that it is this massive again umbrella term that really just talks

80
00:09:06,990 --> 00:09:13,020
about looking at the data and changing things in the trial based on the data.

81
00:09:13,320 --> 00:09:20,910
However, those things all do need to be specified so that we're not undermining the integrity or validity of the trial.

82
00:09:21,240 --> 00:09:25,620
So it's not like we can just say, okay, well, we wrote the trial this way and we started,

83
00:09:25,620 --> 00:09:28,979
and then we decide to look at the data and change some things. You can't do that, right?

84
00:09:28,980 --> 00:09:34,080
That's that is adaptive, but it's not good adaptive and it's not ethical.

85
00:09:34,080 --> 00:09:35,220
It's not something you can do.

86
00:09:35,520 --> 00:09:44,159
But what you can say is that here's our trial design, and we've specified ahead of time that we're going to review the data at these points.

87
00:09:44,160 --> 00:09:50,340
And based on what we see in the data, we're going to use that information in this way to change potentially change things about the trial.

88
00:09:51,120 --> 00:09:59,759
So we talked about adaptive dose finding like in the continual re assessment method where we see did the previous person have a DLT or not?

89
00:09:59,760 --> 00:10:04,740
Yes or no. We can use that information, update our model and decides what's the next dose to give.

90
00:10:05,790 --> 00:10:11,700
We also somewhat talks about the same treatment, adaptive allocation when we talked about randomization.

91
00:10:12,120 --> 00:10:19,140
So there is a minimization method where we could use where we can use people's covariates.

92
00:10:19,680 --> 00:10:27,749
And once somebody comes into the trial, we can say, okay, well, how many people with those covariates right are on this side?

93
00:10:27,750 --> 00:10:33,630
How many are on the side? And we can adjust with treatment assignment is to ensure balance across the treatments.

94
00:10:35,430 --> 00:10:37,589
Then there's the response, adaptive allocation.

95
00:10:37,590 --> 00:10:43,139
So that's this response, adaptive randomization where we can look at the data and see, well, how are you actually doing?

96
00:10:43,140 --> 00:10:46,320
What's the outcome, how have you responded or not? Have you failed or not?

97
00:10:46,650 --> 00:10:51,000
And then adjust the probabilities so that more people go on the better performing treatment.

98
00:10:52,470 --> 00:10:59,310
And there's also adaptive sequential testing or group sequential design such that we can say we want to look

99
00:10:59,310 --> 00:11:04,200
at the data at some point in time and decide if we can stop for futility or for a success rate like this.

100
00:11:04,320 --> 00:11:08,940
SIMON Two stage design. So these are four main types of ADAPT adaptations.

101
00:11:08,940 --> 00:11:11,040
However, there are even more than this.

102
00:11:11,040 --> 00:11:18,120
There are lots of ways in which we can look at the data, use it and make changes to the trial based on what it is.

103
00:11:19,110 --> 00:11:23,880
So we can also potentially refine the sample size and in most cases,

104
00:11:24,780 --> 00:11:28,770
really all cases if you refine the sample, size it so that you can make it larger.

105
00:11:29,280 --> 00:11:33,749
So you could start the trial with some idea, the sample size.

106
00:11:33,750 --> 00:11:39,660
However, you might not have really good pilot data. And so then you look at the data and you say, Oh, actually, I really got that wrong.

107
00:11:39,720 --> 00:11:44,220
The variances this, you know, is more and so therefore, we're going to need this many people.

108
00:11:45,330 --> 00:11:51,330
You can abandon treatments or doses or say you have multiple arms instead of stopping for futility.

109
00:11:51,330 --> 00:11:57,450
If you had two treatments right, you could stop that one arm and continue the trial with the other ones.

110
00:11:58,770 --> 00:12:02,880
You can change allocation ratio of the patients to the trials arms for.

111
00:12:04,730 --> 00:12:08,210
Response after randomization or potentially for some other reason.

112
00:12:09,110 --> 00:12:14,630
You can also have what we call enrichment design. So you could start potentially with like all comers to your trial.

113
00:12:14,990 --> 00:12:20,540
Then you can see what are the subsets of groups who are actually doing best on treatment or specific treatments.

114
00:12:20,960 --> 00:12:26,900
And then you can change who you're allocating to treatment and or.

115
00:12:28,110 --> 00:12:34,410
Further define your eligibility criteria to all treatments based on who's doing better.

116
00:12:34,420 --> 00:12:40,410
So you're changing the potential eligibility criteria and enriching the sample of those in the trial.

117
00:12:41,040 --> 00:12:49,290
And then, of course, you could stop the whole trial for to say, okay, and compare the treatments and this one's definitely better, let's stop.

118
00:12:49,290 --> 00:12:53,729
Or, Hey, compare the treatments and the there looks like there's no difference.

119
00:12:53,730 --> 00:12:57,540
We're not going to find that this that the treatments superior we can stop the whole trial.

120
00:13:01,480 --> 00:13:10,680
It's there's the potential. So adaptive designs came about because there are potential advantages such that, you know,

121
00:13:10,740 --> 00:13:15,510
it seems like it would be advantageous to put more patients on better performing

122
00:13:15,510 --> 00:13:19,830
treatments or to put less patients on worst performing treatments so that,

123
00:13:19,950 --> 00:13:24,570
you know, you're not recruiting to not well performing treatments.

124
00:13:25,230 --> 00:13:29,700
Or you could stop that whole treatment arm early and not put patients on that treatment arm.

125
00:13:32,160 --> 00:13:41,340
There is the potential that on average, right when you think about the Simon to stage designs, remember that expected sample size on average,

126
00:13:41,340 --> 00:13:48,900
that expected sample size could be smaller than the total sample size required to go throughout the full trial because you can make early decisions.

127
00:13:49,330 --> 00:13:57,150
So there is the ability that these trials could be smaller, shorter, because you make decisions earlier.

128
00:13:59,570 --> 00:14:03,889
And of course, we never really want an underpowered trial. We don't want to waste resources.

129
00:14:03,890 --> 00:14:07,910
So if there is the possibility that we can do things more efficiently, we would like to do so.

130
00:14:11,240 --> 00:14:15,889
There's also a lot of the reason why we do a tight CRM or CRM design is because

131
00:14:15,890 --> 00:14:20,540
we can actually get more information about this full dose response curve,

132
00:14:20,870 --> 00:14:28,430
right? The dose toxicity curve. We can do that faster by allowing to see more people across that full curve than if we

133
00:14:29,570 --> 00:14:35,930
used equal allocation or had some other way to get to that or to do the dose finding.

134
00:14:37,910 --> 00:14:44,890
It sounds beneficial if we can identify the patient population who is most likely to benefit from the treatment.

135
00:14:44,900 --> 00:14:48,980
Right. If we can do that within the trial, it sounds like we're really helping those in the trial.

136
00:14:50,090 --> 00:14:57,409
And so it could be useful because we could then put more patients on the treatments performing better.

137
00:14:57,410 --> 00:15:02,480
Right. We can potentially have more precision about that treatment effects because we have more patients on it.

138
00:15:03,350 --> 00:15:12,620
And so the having estimates with greater precision reduces our uncertainty and it can better it can show us which really is the better treatment.

139
00:15:13,430 --> 00:15:20,180
And then just similar to what we said before, that if we can actually stop early or make these changes early or do something else early, right,

140
00:15:20,180 --> 00:15:25,700
then we can potentially reach that conclusion earlier and get it out to the broader

141
00:15:25,700 --> 00:15:29,900
public and actually start treating more patients with that treatment faster.

142
00:15:30,230 --> 00:15:34,940
So there are right at the end, I'm going to end kind of more with the disadvantages.

143
00:15:34,940 --> 00:15:41,749
But remember, come back to these first slides which are saying the potential advantages of different adaptations.

144
00:15:41,750 --> 00:15:47,510
And this is not just response, adaptive randomization, this is across lots of different adaptations,

145
00:15:47,510 --> 00:15:53,960
what the appeal is and what are potential advantages of adaptations.

146
00:15:55,460 --> 00:16:01,010
So this is from an article that has an overview of adaptive designs,

147
00:16:01,400 --> 00:16:09,530
and they give they also give the citations to actual trials in practice which have used these types of adaptations.

148
00:16:10,940 --> 00:16:14,900
And so you can see, right, we've already talked about the continual assessment method.

149
00:16:15,140 --> 00:16:18,770
We're going to talk today about group sequential design.

150
00:16:19,010 --> 00:16:22,820
We're not going to spend any time talking about sample size estimation,

151
00:16:23,090 --> 00:16:32,120
but that's the fact that you could increase your sample size by recalculating your your power sample size based on the accrued information.

152
00:16:32,540 --> 00:16:40,370
We also want to talk about multi arm multi-stage designs, except for those are referenced in the set of clinical trials articles.

153
00:16:41,000 --> 00:16:48,050
So you can learn more about those. But essentially, right is having instead of just like treatment versus control,

154
00:16:48,170 --> 00:16:51,740
you can have some standard of care and multiple treatments or multiple doses.

155
00:16:52,010 --> 00:16:58,720
And so you could have the potential to drop arms or make other decisions with these multiple arms.

156
00:16:59,150 --> 00:17:04,160
Population enrichment is that fact that we can narrow down to those who are doing better?

157
00:17:04,160 --> 00:17:05,570
We're not going to talk more about that.

158
00:17:06,050 --> 00:17:15,920
There's also a bunch of biomarker adaptive designs, and those are, again, also somewhat referred to in the set of clinical trials papers.

159
00:17:16,280 --> 00:17:26,629
But this is where you can incorporate information about biomarkers or signatures from people into the design and then response,

160
00:17:26,630 --> 00:17:33,860
adaptive randomization. This is what we will also talk about and what is primarily the focus of the clinical trials design.

161
00:17:34,220 --> 00:17:40,129
And then there is adaptive dose ranging and then seamless designs and two groups are talking about a seamless phase one,

162
00:17:40,130 --> 00:17:44,810
phase two designs for the projects. So you'll learn more about those when we get to the projects.

163
00:17:45,110 --> 00:17:50,660
So again, these are that is a type of adaptive design.

164
00:17:51,620 --> 00:17:55,100
Okay. So we'll focus on group sequential and adaptive randomization today.

165
00:17:55,400 --> 00:17:59,240
But again, just know that these are not the only types of adaptations.

166
00:17:59,570 --> 00:18:05,300
There are a lot of adaptations that can occur in a trial, and these are just two types.

167
00:18:07,800 --> 00:18:11,520
This is also pulled from that article just to show you that.

168
00:18:13,250 --> 00:18:19,490
We often have the balanced randomization, right? We have fixed randomization and usually it's also balance 1 to 1.

169
00:18:19,820 --> 00:18:25,639
And we saw previously that it's often 1 to 1 or balanced because that increases the

170
00:18:25,640 --> 00:18:30,500
precision or optimizes the precision or efficiency of the treatment effect estimates.

171
00:18:31,490 --> 00:18:38,899
Now, in a fixed design, we're going to have unbiased treatment effect estimates and we'll have the correct

172
00:18:38,900 --> 00:18:43,610
coverage of our confidence intervals as well as a well calibrated p value.

173
00:18:44,120 --> 00:18:48,920
If we start using any type of adaptive design, that may not be the case.

174
00:18:49,190 --> 00:18:51,560
And so you'll see in those articles, right?

175
00:18:51,590 --> 00:19:00,470
A lot of the many of the arguments against adaptations are the potential biases which can occur from the adaptations.

176
00:19:00,800 --> 00:19:07,460
So it is possible that once you start adapting the design, you may now have a biased treatment effect estimate.

177
00:19:07,790 --> 00:19:14,599
However, there's a solution in which you can try to decrease for right, adjust appropriately,

178
00:19:14,600 --> 00:19:19,850
adjust for the bias so that you could still potentially end up with an unbiased estimate.

179
00:19:20,450 --> 00:19:23,990
It's possible that with an adaptive design, your confidence intervals,

180
00:19:24,950 --> 00:19:29,390
if they're computed without considering the adaptation, they will have the incorrect coverage.

181
00:19:29,810 --> 00:19:36,530
However, if you are accounting for the fact that you've used these adaptations, right, you can get the correct coverage.

182
00:19:37,660 --> 00:19:43,200
And then again, if you have bias and you have a lack of precision, right.

183
00:19:43,210 --> 00:19:47,260
Your P values may not be correct either. And so, again,

184
00:19:47,260 --> 00:19:55,180
you have to make sure that you're accounting for these adaptations and you've accounted for the potential that if you are looking at the data,

185
00:19:55,360 --> 00:19:58,900
you're type one error could be inflated. And so we'll see that again later.

186
00:20:01,210 --> 00:20:06,760
All right. So the first type of adaptations that we're focusing on are what we're calling trial monitoring,

187
00:20:06,760 --> 00:20:10,850
or it really falls under what's called group sequential design or interim analysis.

188
00:20:10,870 --> 00:20:14,620
All of these things are like the same thing synonyms, trial monitoring.

189
00:20:14,830 --> 00:20:21,610
Although trial monitoring is more broad because it can include general non statistical safety monitoring.

190
00:20:22,240 --> 00:20:28,900
But we're going to focus on it in the case of the looking at the data group, sequential making, interim analyzes.

191
00:20:30,850 --> 00:20:38,110
So as we introduced this, when we talked about phase two, two stage designs, the Simon two stage design, we said, well,

192
00:20:38,110 --> 00:20:46,730
it makes sense that you could stop the trial early if it looks like there's evidence that none of the treatments right.

193
00:20:46,780 --> 00:20:50,500
Or the treatment of interest is not actually going to be effective.

194
00:20:50,950 --> 00:20:57,189
And so if there's strong evidence for no difference, then why have more patients come into the trial,

195
00:20:57,190 --> 00:21:03,640
spend more resources, or expose more patients to potential risk if it's not actually effective?

196
00:21:07,410 --> 00:21:12,479
And also, perhaps if there's early evidence that there's a massive treatment effect.

197
00:21:12,480 --> 00:21:19,920
Right. It might be useful to stop the trial for efficacy and to try to get that treatment out to more patients.

198
00:21:19,920 --> 00:21:28,200
So if early evidence is promising, it may be useful to either stop or to change allocation based on the accumulated data.

199
00:21:29,500 --> 00:21:32,590
However, we need to go back and we always need to think about the ethics.

200
00:21:32,590 --> 00:21:40,420
And so that first article and the set of clinical trial articles are by Hanging Kimmelman, who are actually medical ethicists.

201
00:21:41,140 --> 00:21:49,450
They're also quantitative and statistical. But it's nice to pull it back to our original, you know, lectures one and two, which you probably like.

202
00:21:49,450 --> 00:21:52,690
Why did I sign up for this class? This is nothing to do with stats.

203
00:21:53,010 --> 00:21:56,760
Right. We always have to keep ethics in mind when we're talking about clinical trials.

204
00:21:57,280 --> 00:22:01,179
And this is also one of the, you know, talking about one of those questions,

205
00:22:01,180 --> 00:22:06,850
which is on your first test, the individual versus collective collective ethics issues.

206
00:22:07,270 --> 00:22:14,970
So we should never randomized to or continue to treat patients with this treatment that's been established as inferior.

207
00:22:14,980 --> 00:22:18,640
Right. That's talking about the individual ethics of the people treated in the trial.

208
00:22:19,360 --> 00:22:26,169
However, we also need to consider the collective ethics that we need to get good estimates here so that we have a real,

209
00:22:26,170 --> 00:22:31,570
real robust evidence of what we would treat most patients with.

210
00:22:31,580 --> 00:22:35,300
So we need evidence sufficient enough to change clinical practice.

211
00:22:35,310 --> 00:22:40,330
So we're trying to both balance this individual ethics of the treat the patients in the trial with the

212
00:22:40,330 --> 00:22:44,740
fact that we need answers so that we can have the best treatment for all of those outside of the trial.

213
00:22:46,140 --> 00:22:50,620
And interim analysis are saying, okay, well, we want to, you know,

214
00:22:50,700 --> 00:22:55,590
potentially treat those in the trial with the best, but we also want to make sure that we're not.

215
00:22:56,660 --> 00:23:01,550
Using up these resources if it's not going to do, you know, have greater good effects.

216
00:23:03,530 --> 00:23:07,700
And, of course, everything costs something, right? There are these resources.

217
00:23:07,700 --> 00:23:14,930
And so we have to balance all of this within real life of the cost it is to pay for and run these trials.

218
00:23:17,450 --> 00:23:26,600
So we potentially want to end the trial early or terminate the trial early if there are really huge safety concerns.

219
00:23:26,630 --> 00:23:36,140
Right. So there's often always safety monitoring going on by the Data Safety Monitoring Board and or just the general investigators of the trial,

220
00:23:36,200 --> 00:23:41,900
making sure that they're looking at these serious adverse events. And if there are too many, then the trial is stopped.

221
00:23:43,370 --> 00:23:51,980
If we see this dramatic beneficial effect, it would be best to stop the trial so that we're not enrolling patients on the inferior treatment,

222
00:23:52,310 --> 00:23:56,120
and we can get that treatment out to everyone faster.

223
00:23:56,750 --> 00:24:03,920
If it's clear at some point that we're not going to find or it's very low likelihood

224
00:24:03,920 --> 00:24:07,489
of finding that there's this difference between the treatments involved. Right.

225
00:24:07,490 --> 00:24:12,110
Why would we again spend this money on the trial? We could just end it early.

226
00:24:13,370 --> 00:24:20,150
And if there somehow becomes some logistic or data quality problems, like so much data is missing,

227
00:24:20,990 --> 00:24:24,350
or we figure out that it was measured incorrectly or whatever, right?

228
00:24:24,650 --> 00:24:29,360
That if there's no way to correct the problem, then we likely shouldn't continue.

229
00:24:32,200 --> 00:24:36,850
However, before we stop right, we have a lot of things that we need to consider.

230
00:24:37,270 --> 00:24:43,080
So we have to consider the fact that we never have information instantaneously.

231
00:24:43,090 --> 00:24:46,000
Even with all the technology that we have these days,

232
00:24:46,840 --> 00:24:52,900
people are late in coming to appointments that they're supposed to go, though they're late filling in surveys.

233
00:24:53,290 --> 00:24:58,840
We're backed up in terms of the research assistants pulling this data.

234
00:24:59,200 --> 00:25:04,629
And so there is often this delay in terms of like where we think we are in the trial

235
00:25:04,630 --> 00:25:08,560
with the actual amount of data or crewing the data that we need to make that decision.

236
00:25:09,640 --> 00:25:18,130
So we need to make sure that we're updating the follow up for everyone that we have before we look at the data and stop it.

237
00:25:19,360 --> 00:25:24,159
There could be potential differences in the baseline factors rate and some covariates.

238
00:25:24,160 --> 00:25:29,290
We try to have these balanced across treatments but say we're early in the trial

239
00:25:29,650 --> 00:25:36,640
or say there was some randomization that we use that didn't balance it very well.

240
00:25:37,540 --> 00:25:43,570
Somehow these baseline differences could be making the difference that we're seeing, not actually the treatment.

241
00:25:43,660 --> 00:25:48,580
Right? So we have to make sure that we're attributing the effects to the right issue.

242
00:25:48,610 --> 00:25:52,750
Right. It's actually the treatment that's causing this or is it actually just this imbalance?

243
00:25:54,550 --> 00:26:04,320
We have to make sure that the response, the outcome is hopefully assessed, unbiased, early, and if the treatment is not blinded, right?

244
00:26:04,390 --> 00:26:07,900
If we don't have this double blind where the assessors know the treatments,

245
00:26:07,900 --> 00:26:13,270
they could potentially, potentially be inducing bias into the response assessments,

246
00:26:13,420 --> 00:26:19,390
which could again rate the effects or the difference that we're seeing could be due to this bias, not actually due to the treatments.

247
00:26:19,780 --> 00:26:24,970
So we want to be really careful that we're attributing the effects correctly before we stop the trial.

248
00:26:26,620 --> 00:26:33,060
Missing data always has an impact. If you haven't taken a missing data class, I highly suggest it.

249
00:26:33,070 --> 00:26:37,899
We never have complete data and yet in all of our classes we pretend like we do right.

250
00:26:37,900 --> 00:26:41,229
You learn as if we have complete data, but we never do.

251
00:26:41,230 --> 00:26:46,720
And so inevitably, in anything that you do as a statistician, you need to know how to deal with missing data.

252
00:26:47,110 --> 00:26:53,530
And so we can pretend like it doesn't exist to really talk about the the underlying theory of everything.

253
00:26:53,530 --> 00:27:01,479
But in practice it does exist and we need to account for it. So outside of like maybe pilot studies, which are small studies,

254
00:27:01,480 --> 00:27:07,720
just trying to assess feasibility where you could probably ignore it and or it's saying something about the feasibility of the design.

255
00:27:08,110 --> 00:27:13,030
Right? We need to account for this missing data in some way. And then of course,

256
00:27:13,300 --> 00:27:20,650
we talked a little bit about compliance in terms of when you look at the intent to treat analysis versus per protocol

257
00:27:20,650 --> 00:27:28,120
analysis versus that as treated analysis and how if patients are going to not take what they're supposed to take,

258
00:27:28,420 --> 00:27:32,770
how that could potentially bias the results as well. And so right,

259
00:27:32,770 --> 00:27:39,040
if we just look at the data as is at some point in time and then decide to

260
00:27:39,040 --> 00:27:43,690
make a decision without considering all of these potential issues with bias,

261
00:27:44,020 --> 00:27:52,960
we could very much be making a wrong decision. Right, which would not be useful for the ultimate answer of whether this treatment is is good or not.

262
00:27:53,410 --> 00:28:01,420
And so you can see that while we could see resources, we have to make sure we're doing that in the right setting and that we've consider these biases.

263
00:28:02,410 --> 00:28:05,649
Okay. There is also a bunch of other ones. Right?

264
00:28:05,650 --> 00:28:10,660
So what about what other patients, what other treatments patients are taking that could be affecting the outcome?

265
00:28:12,010 --> 00:28:13,870
There could be potential side effects.

266
00:28:14,230 --> 00:28:21,280
There's we want to make sure that there is consistency of response across subgroups and various outcome measures.

267
00:28:22,300 --> 00:28:24,400
If we have multiple centers involved,

268
00:28:24,400 --> 00:28:32,760
we want to make sure that there is consistency across all the centers or fidelity of the interventions across all the centers.

269
00:28:35,590 --> 00:28:43,600
We if there are other similar trials that have occurred, we want to look at those and get any more insight about what's happening with ours.

270
00:28:44,950 --> 00:28:49,509
And again, we just need to ensure that what we decide.

271
00:28:49,510 --> 00:28:53,079
Right is certainly going to impact what's happening with that treatment.

272
00:28:53,080 --> 00:28:54,970
We could be stopping that treatment completely.

273
00:28:55,300 --> 00:29:01,810
And so we want to make sure that if we do that, that we feel very secure in our decision and doing that.

274
00:29:04,200 --> 00:29:14,939
Okay. So this is the one slide about like essentially sample size estimation, which is like a decision to extend a trial because it would be saying,

275
00:29:14,940 --> 00:29:18,210
well, we had the sample size, but now we want to actually increase it.

276
00:29:18,570 --> 00:29:23,960
And if that's the case, if there is sample size estimation, it should be done early in the trial.

277
00:29:23,970 --> 00:29:31,440
So you don't want to wait until you've gotten like two thirds of the the trial population or the trial sample and then said,

278
00:29:31,440 --> 00:29:36,300
oh, actually, let's let's recalculate the sample size and extend this because it looks like.

279
00:29:36,690 --> 00:29:37,889
Right, if that's what it is,

280
00:29:37,890 --> 00:29:43,470
it looks like you waited so long and then you looked at the data and you didn't like it and you thought maybe if we get more, it'll be better.

281
00:29:44,010 --> 00:29:51,940
But if at the beginning of the trial you say we're going to do this like relatively early, we just need a better estimate of these effects, right?

282
00:29:51,990 --> 00:29:58,470
Then we can increase the size that's much more justifiable and.

283
00:30:01,400 --> 00:30:05,470
Just seems not like your even if you preplanned it that late.

284
00:30:05,550 --> 00:30:09,320
Right. It just seems like you are waiting to try to hold on to something.

285
00:30:18,650 --> 00:30:29,720
Okay. So adjustments can either be made to the specific sample size saying we need more people, or if it's like a time to event and point,

286
00:30:30,080 --> 00:30:37,490
you might potentially actually just for a binary endpoint, you might just need more time to see that event occur.

287
00:30:37,730 --> 00:30:44,120
So you could either increase the number of people and or the amount of time your trial is ongoing to see that outcome.

288
00:30:44,120 --> 00:30:50,620
But again, this should be done as early as possible. Okay.

289
00:30:50,620 --> 00:30:57,489
So now we're going to. Talk about interim the specific interim analysis.

290
00:30:57,490 --> 00:31:04,030
And again, there are these two types. One are the preplanned statistical analyzes, and then one is the safety analyzes,

291
00:31:04,030 --> 00:31:07,960
which are going on in the background by the Data Safety Monitoring Board.

292
00:31:08,290 --> 00:31:14,500
So the Data Safety Monitoring Board is a group of independent investigators outside of the trial.

293
00:31:15,310 --> 00:31:22,090
It's usually a statistician, clinician and other sort of scientists who are familiar with that area,

294
00:31:23,050 --> 00:31:31,470
and they review the data from the trial as it's ongoing at regular periods of time.

295
00:31:31,480 --> 00:31:36,880
So usually they're like biannual. They might be more often if the trial is going really fast.

296
00:31:37,030 --> 00:31:44,589
I'm on several data safety monitoring boards and what happens is that we get together and usually the investigator for

297
00:31:44,590 --> 00:31:51,640
the primary investigator or maybe the primary statistician from that trial come present data and then they leave.

298
00:31:51,820 --> 00:31:57,860
And the DSM-V talks about like, okay, you know, are there any issues here?

299
00:31:57,880 --> 00:32:05,020
Does it look like we need to that there are issues with safety in particular, anything like that,

300
00:32:05,020 --> 00:32:11,070
just to make sure that the patients in the trial are good, that things are still okay, right.

301
00:32:11,080 --> 00:32:14,770
That the ethics are still sound and the patients in the trial are safe.

302
00:32:15,160 --> 00:32:17,620
There's also often before the investigators leave,

303
00:32:17,620 --> 00:32:22,959
there's a discussion if the investigators are like we're having a lot of trouble accruing patients, that's like the primary issue I see.

304
00:32:22,960 --> 00:32:27,880
And most of my data safety monitoring boards are that the investigators say we were not getting

305
00:32:27,880 --> 00:32:33,580
patients were way below sample size were suggestions and so the DSM but you can also help in that case.

306
00:32:34,720 --> 00:32:37,620
Okay but that's like all we're talking about, the DSM-V.

307
00:32:38,320 --> 00:32:45,219
We're going to spend most of our time talking about these pre-planned statistical analyzes of the interim interim analysis.

308
00:32:45,220 --> 00:32:49,060
And you'll remember that we already discussed this with Simmons to Sage.

309
00:32:49,060 --> 00:32:56,620
So we said in Simon's to Sage, we get some N1 amount of patients, we look at the data, we look at the response rate.

310
00:32:56,620 --> 00:33:03,549
If it is passed, some critical response rate or we saw some critical number of responders will continue into stage two.

311
00:33:03,550 --> 00:33:05,290
And if it's not, we stop the trial.

312
00:33:06,540 --> 00:33:16,019
That was, remember, one arm in phase two and we only allowed one internal look and essentially right to full analysis.

313
00:33:16,020 --> 00:33:19,020
If we went on, we looked at the first stage and then we looked in the second.

314
00:33:20,280 --> 00:33:28,049
And at that point we talked a little bit about in the Bayesian setting where we could decide to stop for futility or efficacy.

315
00:33:28,050 --> 00:33:31,430
But for Simon's to stage, we only stop for futility, right?

316
00:33:31,440 --> 00:33:36,360
We either stopped because we didn't have enough responses or we continued we wouldn't stop for efficacy.

317
00:33:36,870 --> 00:33:43,919
So we're going to change it up here where we can in interim analyzes potentially, right, stop for efficacy or futility.

318
00:33:43,920 --> 00:33:47,610
We'll consider two arms. We could consider more, but we won't.

319
00:33:47,610 --> 00:33:54,360
In this case, we'll just consider two and we can consider any number of interim analyzes or looks at the data.

320
00:33:56,030 --> 00:34:08,120
So the group, the the term group sequential methods is really the main term for how we can do these interim analyzes in clinical trials.

321
00:34:08,480 --> 00:34:14,510
And there are going to be rules for stopping a study early, either for success or for failure.

322
00:34:15,350 --> 00:34:17,570
And we'll call the times that we look at the data,

323
00:34:17,810 --> 00:34:27,650
the interim analysis times we can monitor or look at the data sequentially at some finite number of times.

324
00:34:27,650 --> 00:34:29,570
This could either be based on calendar.

325
00:34:29,570 --> 00:34:37,490
So like every four months we look at the data or most often it's actually based on number of individuals in the trial.

326
00:34:38,030 --> 00:34:47,389
So like after we've recruited 45 and after we've recruited 90 and we get this new accumulated data,

327
00:34:47,390 --> 00:34:53,450
we look at the we look at it, and then based upon our pre-specified decision rules, we can make changes.

328
00:34:55,110 --> 00:35:02,890
Okay. But you can imagine, right, that we look at the data after say say we want to accrue like 700 patients.

329
00:35:03,250 --> 00:35:06,780
We look at it after 50 patients. We look at it after 100 patients.

330
00:35:06,790 --> 00:35:13,600
We look at it after 150 after 200. Right now, all of a sudden, we're like analyzing the data multiple times.

331
00:35:13,930 --> 00:35:21,940
Right. So this is a classic multiple comparisons problem, especially because I'm looking at data which is not independent.

332
00:35:22,030 --> 00:35:25,990
Right. The first 50 are included in the 100 as included in the 150.

333
00:35:27,280 --> 00:35:31,210
And so our type one error is going to be inflated.

334
00:35:32,620 --> 00:35:38,620
In fact, at each monitoring time, a test statistic is computed, it looks right at the first look.

335
00:35:38,620 --> 00:35:44,640
We have our 5% type one error, but at the second look that errors inflated to 8.3%.

336
00:35:44,650 --> 00:35:52,330
Third look, 10.7%. Right? If we had 100 looks, we'd inflate our type one error to 27.4%.

337
00:35:52,750 --> 00:36:02,469
Now, it'd be unusual to have 100 looks unless we have continuous monitoring such that every patient we look at the data,

338
00:36:02,470 --> 00:36:10,000
like in that case, you're right. But it would be unusual to say like, oh, we're going to have 1000 patients and look after every ten.

339
00:36:10,270 --> 00:36:15,460
We'd either have some smaller number usually or continuous updates.

340
00:36:17,030 --> 00:36:28,269
Okay. Right. So you can imagine here, this is this is a representation of if we looked at the data at every point, right,

341
00:36:28,270 --> 00:36:35,649
where you can say, but we can imagine that the interim analysis would happen like end to end three and four in patients.

342
00:36:35,650 --> 00:36:41,690
But we can see this, right, like Brownian motion of if we made this decision after everyone agrees,

343
00:36:42,370 --> 00:36:46,329
this is the z value of comparing the two treatments.

344
00:36:46,330 --> 00:36:50,380
Right? Say we have to treatment and we are comparing them after every person.

345
00:36:50,830 --> 00:36:55,840
Right. The Z value is sort of oscillating based on the data that's incoming.

346
00:36:56,170 --> 00:37:03,040
And you can see that if we use the same critical V Z value for like a type one error of 5%,

347
00:37:03,460 --> 00:37:08,920
right at 310 patients, we crossed that line and we would actually decide potentially to stop that trial.

348
00:37:09,400 --> 00:37:15,310
Right. But if you look, if we were able to actually keep running the trial, we would have seen that that went back down.

349
00:37:15,580 --> 00:37:22,000
So it was just this like blip in the data, right, where we saw a false positive or a false negative.

350
00:37:22,570 --> 00:37:28,670
Whereas what we really need to do is account for the fact that we're making these decisions over time.

351
00:37:28,670 --> 00:37:35,020
We're inflating the type one error. And so we really need to use essentially, right, like higher critical values to say,

352
00:37:35,170 --> 00:37:40,389
I don't actually want to stop there because if I keep going, that's not a good representation of the data.

353
00:37:40,390 --> 00:37:44,320
And so I'm going to need to account for that in my analysis.

354
00:37:46,810 --> 00:37:52,600
And so the question is, how do we figure out what those critical values are or how do we figure out what

355
00:37:52,600 --> 00:37:57,730
those alphas are that we should be comparing to each look so that it's not just 5%?

356
00:37:59,290 --> 00:38:03,480
So we want to allow for the rejection of our null hypothesis during the trial.

357
00:38:03,520 --> 00:38:05,980
The null hypothesis here. Imagine we have two arms,

358
00:38:06,220 --> 00:38:13,180
right A versus B and aren't all hypothesis is that say the response rate for A is the same as the response rate for B or the mean

359
00:38:13,180 --> 00:38:23,319
outcome for A is same as the mean outcome for week we are and patients in the treatment arm a and patients in treatment arm.

360
00:38:23,320 --> 00:38:29,560
We will assume equal allocation here and that we want to conduct K analyzes.

361
00:38:30,490 --> 00:38:36,700
So at every look we have some fraction of patients, right?

362
00:38:36,700 --> 00:38:44,950
So this is like look, M right we have M patients which is take the total number of A patients and divide by K.

363
00:38:44,950 --> 00:38:48,640
So that's assuming we have uniform accrual of patients across the trial.

364
00:38:48,670 --> 00:38:49,060
Right.

365
00:38:49,390 --> 00:38:59,650
So like at this time, we have the total number who will ever be in a divided by the number of looks because they have accrued uniformly over time.

366
00:39:00,580 --> 00:39:05,500
So we could look here where we have patients in both arm, two patients in both,

367
00:39:05,500 --> 00:39:15,129
arm three etc. until we get up to the end of the trial, which is K or just an A and and B, okay.

368
00:39:15,130 --> 00:39:19,660
So we'll assume here that it's that our outcome is continuously distributed.

369
00:39:19,660 --> 00:39:23,500
So we have a mean outcome for treatment, a mean outcome from treatment.

370
00:39:23,500 --> 00:39:27,700
B, they have the same variance of sigma squared. Here's our null hypothesis.

371
00:39:27,700 --> 00:39:31,419
Our alternative hypothesis is that there are some difference in these trials.

372
00:39:31,420 --> 00:39:34,150
We'll call it a difference in these treatments. We'll call it Delta.

373
00:39:34,750 --> 00:39:45,520
And so at each analysis, right, we can construct our test statistic, Z, which is just the difference in the the the estimated means.

374
00:39:45,520 --> 00:39:51,610
Right. So these are just the estimated means over there, their variance and it's the same.

375
00:39:51,610 --> 00:39:59,559
So it's not that complicated. Right. So the question is how big should our critical Z value be to reject the null at our time?

376
00:39:59,560 --> 00:40:05,260
K So in order to do that, we actually have to look out ahead and say, well,

377
00:40:05,350 --> 00:40:11,169
I'm using the Z one, but if I'm making K analyzes, I could be using K Z's, right?

378
00:40:11,170 --> 00:40:16,090
So I actually need to construct the joint distribution of all my critical value uses.

379
00:40:16,780 --> 00:40:24,520
So I have to take into account, right, that I could be making all of these decisions are using all of these critical values.

380
00:40:24,970 --> 00:40:31,660
And so I can figure out, well, what's my expected value of any one of these Z variables?

381
00:40:32,020 --> 00:40:37,089
And this is actually the square root of some information, right?

382
00:40:37,090 --> 00:40:46,600
We can we call this this I k the square root of the information times delta this ik is this two sigma squared over to the negative one.

383
00:40:46,600 --> 00:40:49,719
Right. This is some level of information that I have at each.

384
00:40:49,720 --> 00:40:52,930
Look, it depends on the number of patients at that time.

385
00:40:53,200 --> 00:40:57,489
Right. And the precision or the the variance of the treatment effect estimate.

386
00:40:57,490 --> 00:41:01,660
So it's telling me something about the information I have about the treatment,

387
00:41:02,950 --> 00:41:07,060
and then I need to calculate my covariance between any two of these statistics.

388
00:41:07,390 --> 00:41:12,760
Right. And so that's the square root of the information for one over the information of the other,

389
00:41:13,120 --> 00:41:16,390
which actually ends up being the square root of K prime over K.

390
00:41:16,570 --> 00:41:19,870
And so K remember is the what? Look, I'm not okay.

391
00:41:22,870 --> 00:41:31,510
And so my joint distribution under the null is determined essentially all by this relative amount of information that I have at that time point.

392
00:41:33,370 --> 00:41:43,210
So I need to figure out, right, if I'm going to do these, get these K looks and I have this potential joint distribution of all of the Z's.

393
00:41:43,600 --> 00:41:45,009
Right. I need to figure out, well,

394
00:41:45,010 --> 00:41:55,930
what are the actual type one errors that I can use so that at the end I made sure that I haven't made more than a 5% type one error.

395
00:41:56,350 --> 00:42:02,350
Right. So I can make I'm going to need to make smaller type one errors throughout, right.

396
00:42:02,350 --> 00:42:08,680
So that I over all of these decisions, I'm not going to inflate my type one error.

397
00:42:09,430 --> 00:42:19,389
So I have to figure out, well, if I have this, if I can make decisions right, my first decision would be, well, I will stop the trial, right?

398
00:42:19,390 --> 00:42:26,440
If my critical value is greater than some level of type one error.

399
00:42:26,440 --> 00:42:30,340
Right. Or some some level of this critical value.

400
00:42:31,870 --> 00:42:38,050
But if I if I don't stop there. Right. So this would say I stop at the first look if I don't stop there.

401
00:42:38,110 --> 00:42:43,630
Right. I didn't pass that threshold. Then I could stop at the second look if I pass the threshold.

402
00:42:44,080 --> 00:42:48,300
But if I don't stop at the second threshold, right. I move on and then I could stop.

403
00:42:48,310 --> 00:42:53,740
So this is this cumulative sum of how often I'm making a choice, right?

404
00:42:53,740 --> 00:42:56,530
And the cumulative sum of how often I could make an error.

405
00:42:56,860 --> 00:43:04,980
And I need to make sure that the amount of the amount of error that I make over the full trial is my alpha level that I want to secure.

406
00:43:04,990 --> 00:43:15,250
Right? If I want 5% type one error across the full trial, then I need to ensure that over all of these decisions, I'm not going over that alpha level.

407
00:43:16,630 --> 00:43:21,460
So I'm accounting for the fact that I could stop first or I didn't stop first and I saw the second,

408
00:43:21,550 --> 00:43:24,850
or I didn't stop first or second, but I stopped third, right?

409
00:43:24,850 --> 00:43:27,490
All the way up to the key number of analysis.

410
00:43:29,260 --> 00:43:39,190
So the group sequential approach, right, is that I can stop and reject my null at the first analysis if I find that my value is high enough.

411
00:43:39,790 --> 00:43:45,790
If I don't, then I move on to the second analysis and I could stop there if my value is high enough,

412
00:43:45,850 --> 00:43:52,510
etc. etc. and I maintain my type one error by ensuring that I at all.

413
00:43:52,810 --> 00:43:59,320
If I cumulatively add this up, I'm not over stepping I type one error that I wanted to have for the full trial.

414
00:44:01,480 --> 00:44:05,410
So. Right.

415
00:44:05,430 --> 00:44:11,190
Notice that we've actually we have this covariance between our Z statistics, right?

416
00:44:11,190 --> 00:44:14,640
Because of the fact that our data is an independent. Right?

417
00:44:15,030 --> 00:44:22,560
We have g accumulating data. And so the first 50 are involved in the second right in the hundred and 150.

418
00:44:22,650 --> 00:44:30,210
So we have the covariance. And so we want to note that later when we actually figure out what these alphas are.

419
00:44:30,750 --> 00:44:31,040
Okay.

420
00:44:31,050 --> 00:44:39,510
So once I have the once I figured out how I need to maintain, you know, I'll figure out some way in which I can calculate my total type one error.

421
00:44:39,870 --> 00:44:46,649
Now I've got to figure out, well, what are these critical values? And so there are lots of ways in which we can calculate these critical values.

422
00:44:46,650 --> 00:44:56,020
But the two most common are the Pocock and O'Brien Fleming thresholds or tests.

423
00:44:56,070 --> 00:44:59,800
So the Pocock test came out in 1977.

424
00:45:00,000 --> 00:45:06,390
Pocock said, okay, well I can calculate, right, I got this joint distribution, I can figure out what my overall type one error is.

425
00:45:06,690 --> 00:45:11,759
And so I just want to be simple and kind of similar to like a bonferroni adjustment.

426
00:45:11,760 --> 00:45:20,160
Just say like, you know, well, if I've got five looks, I want to use the same alpha level or the same critical Z value at each look.

427
00:45:20,820 --> 00:45:28,500
Okay. And so the test that each time is going to be of the same size without that same critical value two years later.

428
00:45:28,800 --> 00:45:33,540
Right. Thus the O'Brien Fleming came out and said, Well, I can do better, right?

429
00:45:33,540 --> 00:45:38,460
Or we can do differently than that. Actually, given we know how to calculate this.

430
00:45:38,610 --> 00:45:41,770
Right. Maybe we don't want these to be equal.

431
00:45:41,850 --> 00:45:47,549
We actually only want to stop upfront if we have huge evidence to stop and we

432
00:45:47,550 --> 00:45:53,459
want to have a very similar type one error at the end to our threshold level.

433
00:45:53,460 --> 00:45:59,550
So like we actually want these these critical values to be decreasing or the alpha levels to be

434
00:45:59,550 --> 00:46:04,110
decreasing or the critical values to be decreasing so that alpha levels are increasing over time.

435
00:46:04,440 --> 00:46:11,250
So, for example, we want like if we look at the data, we would only want to declare success if the P values like super small.

436
00:46:12,260 --> 00:46:19,040
At first, and as we were accumulating data, then we'd allow that p value, right, that alpha level to go up a little bit.

437
00:46:19,040 --> 00:46:23,930
And so at the last point, we actually want an alpha level that's close to like the 5%.

438
00:46:24,290 --> 00:46:27,710
I'll show you with real numbers what that looks like. Right.

439
00:46:27,720 --> 00:46:34,010
And in order to calculate any of these K alphas, we have to have that joint distribution.

440
00:46:35,000 --> 00:46:40,219
And so say that we just had to looks up the data, right?

441
00:46:40,220 --> 00:46:47,660
We have our Z one and our Z two where we can get our expected value of Z one and our variance of Z one,

442
00:46:48,020 --> 00:46:52,970
assuming that we have normally distributed data.

443
00:46:53,720 --> 00:47:03,560
And so we can calculate the covariance for Z one and Z two for the part of the this is part of the covariance, right?

444
00:47:03,560 --> 00:47:08,000
So that we can actually get the covariance of Z one, NC two, which is just one of the square root of two.

445
00:47:08,000 --> 00:47:13,129
And so we can actually write out this joint distribution of Z one and Z two, right?

446
00:47:13,130 --> 00:47:22,550
Just for the two values. Our two looks are true critical values and we'll see that we have our expected R means for Z one and Z two.

447
00:47:22,550 --> 00:47:29,240
Right? And then the variance covariance matrix, which is showing these are like standard normal right with covariance one over square root of two.

448
00:47:30,020 --> 00:47:34,520
And so now I can figure out if I could make two decisions.

449
00:47:34,520 --> 00:47:43,100
One is you write one at a line and on a time. Two, I need to make sure that this overall cumulative amount of type one error

450
00:47:43,400 --> 00:47:48,920
right is equal to my overall amount of alpha that I want to hold in my trial.

451
00:47:48,920 --> 00:47:59,450
So if that's 5% and make sure that it Z at Z one and Z two or time one and type two, then I'm going to cumulatively add up to .05.

452
00:48:00,680 --> 00:48:09,800
So Pocock boundary says, okay, here's your right, here's your cumulative amount of type one error spent.

453
00:48:10,250 --> 00:48:16,580
So I can actually figure out what my critical values are based on this integral.

454
00:48:17,480 --> 00:48:18,700
And so I come up,

455
00:48:18,750 --> 00:48:29,570
you usually have to do some numerical integration and come up with what see is when Alphas .05 or you want a 5% trial level type one error.

456
00:48:29,900 --> 00:48:36,620
And so that comes out to say that I would reject at time one and at time two if my p

457
00:48:36,620 --> 00:48:43,099
value of the difference between treatment and treatment B is less than 0.029 now.

458
00:48:43,100 --> 00:48:48,200
Right. If we applied a bonferroni correction, that would be what what would that p value be?

459
00:48:49,940 --> 00:48:53,090
Oh yeah. .025. But it's higher.

460
00:48:53,120 --> 00:49:00,649
Why is it higher? Because the data is not independent.

461
00:49:00,650 --> 00:49:09,020
Remember Bonferroni corrections assume that your data is independent, and that's why the Bonferroni correction is always conservative, right?

462
00:49:09,440 --> 00:49:15,650
It's actually making the P-value less than it needs to be if your data is not truly independent.

463
00:49:15,920 --> 00:49:23,660
And in here we clearly don't have independent data over making a decision on 50 patients and then 100 patients of which that 50 are included in both.

464
00:49:24,170 --> 00:49:28,950
And so we've accounted for that when we calculated the covariance, right?

465
00:49:29,000 --> 00:49:32,390
We actually know that that's not zero, that this is not independent data.

466
00:49:32,900 --> 00:49:40,010
And so our P-value is 0.029. So at each look, I look at 50 patients, I look at 100 patients.

467
00:49:40,280 --> 00:49:54,290
And if the comparison of my of my groups right if that's if I a Z value is greater than 2.178 or my P value is less than 0.029.

468
00:49:54,290 --> 00:49:58,370
I can say that I can stop the trial. Right. Or that I have found differences.

469
00:49:59,810 --> 00:50:08,150
Now, the O'Brien Fleming boundary says, well, okay, but then, you know, you're you're really decreasing.

470
00:50:08,300 --> 00:50:13,070
You're type one error. You're having to find this pretty big difference at both time points.

471
00:50:13,400 --> 00:50:19,820
What if early on we say we would only stop the trial if we say big difference, right?

472
00:50:19,820 --> 00:50:25,910
But later, we actually could have type one error very close to if we just made one decision.

473
00:50:26,150 --> 00:50:32,450
Right. But overall keeping type one error 2.05 and so they he constructed a different

474
00:50:33,260 --> 00:50:38,540
integral to solve to find these critical values such that you can see here.

475
00:50:38,540 --> 00:50:40,250
Right which differs are these.

476
00:50:41,550 --> 00:50:47,470
These bones here instead of being see the negative see they're actually square root of to see the negative two square root of two.

477
00:50:48,230 --> 00:50:55,650
And doing so what happens is that at look one, you have a huge a bigger critical value 2.796.

478
00:50:56,220 --> 00:51:01,950
But right and remember we're kind of relating these are critical as use or relating this to like 1.96, right.

479
00:51:01,950 --> 00:51:07,290
The 5% type one, the two sided 5% type one error, critical value.

480
00:51:07,740 --> 00:51:15,300
Right. So it's going to be really big difference. Look one, but then it look to it's 1.977 that's really close to 1.96.

481
00:51:15,720 --> 00:51:17,760
And so it says, well, at the first look,

482
00:51:17,760 --> 00:51:24,930
you would reject nor you could stop the trial or say you find this difference if there is this massive difference.

483
00:51:24,930 --> 00:51:28,950
Right? Like if you see this really big difference, your p value is super small than stock.

484
00:51:29,370 --> 00:51:35,580
Otherwise we're actually going to spend most of our alpha, most of our type one error at the second look or at the end of the trial.

485
00:51:36,270 --> 00:51:43,919
So. O'Brien Fleming is going to allow us to make at the end, right, use most of the type one error that we would have had.

486
00:51:43,920 --> 00:51:48,360
We only looked once but allow us to make interim decisions if we see huge differences.

487
00:51:48,720 --> 00:51:55,290
Pocock is going to say at any point, right, if I see a, you know, a pretty good difference, I can stop.

488
00:51:57,750 --> 00:52:01,170
So that was just for if there are two interim looks, right.

489
00:52:01,170 --> 00:52:06,230
But if there are three, four, five, ten, 15, 20.

490
00:52:06,270 --> 00:52:14,190
These are the the, the like p value bounds or the type one error bounds for the Po Kok method, right?

491
00:52:14,190 --> 00:52:21,270
They're always the same. So if there are four looks, then at any time if your p values less than .018, you would stop.

492
00:52:21,630 --> 00:52:27,570
Right? If there are ten logs, your p value has to be less than .010 620 looks right.

493
00:52:27,580 --> 00:52:34,170
It has to be really, really small. And so as the data becomes available, you compute the test statistic.

494
00:52:34,350 --> 00:52:43,230
If you see that you have a test statistic that the p value is smaller than its critical value, then you can stop.

495
00:52:45,350 --> 00:52:51,260
This is all for 5% tip on error of. Obviously if you're type one or smaller right these are all going to be even smaller.

496
00:52:52,110 --> 00:53:00,769
But on the other side, right, the O'Brien Fleming method, again, every time you look at the data,

497
00:53:00,770 --> 00:53:04,879
you calculate your test statistic, but now you compare it to a new critical value.

498
00:53:04,880 --> 00:53:12,740
At each look, it's not the same, it changes. And so if you have one test, right, the critical value is 1.96.

499
00:53:12,740 --> 00:53:18,890
If you have two, the second test would be at 1.98 if you have three.

500
00:53:19,100 --> 00:53:23,870
Right. So this is saying at the third, the third test, what's the critical value?

501
00:53:24,440 --> 00:53:33,680
And so you can see that as you have more tests, your critical value goes up higher from 1.96, but it's still really close to 1.96.

502
00:53:33,920 --> 00:53:40,190
So that that end decision is really similar to if you just had one look at the data,

503
00:53:42,170 --> 00:53:45,979
here's a maybe a better illustration of comparing these two methods.

504
00:53:45,980 --> 00:53:49,700
So this is across five potential looks at the data, right?

505
00:53:49,700 --> 00:53:57,200
And the flat lines are using the Pocock boundary because it says that you keep that same critical value or the same P

506
00:53:57,200 --> 00:54:05,959
value throughout all the now all of the interim looks right and the the solid lines are the O'Brien Fleming boundaries,

507
00:54:05,960 --> 00:54:10,700
which say you actually have to have a high critical value at first and then at the end,

508
00:54:11,480 --> 00:54:17,540
right, your critical value decreases and is closer to like that 1.96 at the end.

509
00:54:17,870 --> 00:54:25,370
And in fact, right here are your like p values or type one errors that you can have at each look.

510
00:54:25,370 --> 00:54:33,649
So po cop across the board is that 0.016 essentially and O'Brien Fleming is like unless there is some

511
00:54:33,650 --> 00:54:38,420
like incredibly massive difference at first right you're not going to make that decision to stop.

512
00:54:38,870 --> 00:54:44,780
But at the end you just have to have a difference where your p values less than .0413.

513
00:54:45,410 --> 00:54:52,910
Right. And if you add these up right, they don't exactly equal .05.

514
00:54:52,910 --> 00:54:56,899
But that's because they're based on that joint distribution. Right, which includes the covariance.

515
00:54:56,900 --> 00:55:01,640
And so that's why you're not just going to see that it's it's just across the board point of five.

516
00:55:04,750 --> 00:55:13,840
Okay. So considering if we want to use interim analysis, if we decide to do that right, we need to plan that ahead of time.

517
00:55:14,200 --> 00:55:17,430
So we need to go into the trial knowing that we're going to look at the data.

518
00:55:18,160 --> 00:55:23,920
And in doing so, that's going to change, likely potentially change our sample size.

519
00:55:24,460 --> 00:55:30,760
So if we look at the data key times, right, do you think would increase the sample size,

520
00:55:30,790 --> 00:55:36,310
decrease the sample size or be the same as if we just analyzed the data at the end or didn't look at the data?

521
00:55:36,550 --> 00:55:43,330
So who thinks that would increase the sample size? Who thinks it would decrease the sample size.

522
00:55:45,930 --> 00:55:50,370
Who thinks that would the sample size would be the same whether you make interim analysis or not.

523
00:55:51,340 --> 00:55:55,770
Okay. Who's not thinking or doesn't understand the question? Most of you.

524
00:55:56,120 --> 00:55:59,340
Oh, maybe owners did it right. Or you just don't want to be wrong. I don't know.

525
00:56:00,390 --> 00:56:05,400
So the question is like, if we're going to do the interim analyzes, we have to count for it ahead of time.

526
00:56:06,070 --> 00:56:13,080
If what's the sample size difference between doing an interim analysis or including interim analysis versus not including them?

527
00:56:16,050 --> 00:56:23,670
So in fact. Right. If we're going to look at the data and we're trying to maintain this overall type one error,

528
00:56:24,030 --> 00:56:29,010
then if we add interim analysis, we actually increase the maximum sample size.

529
00:56:29,250 --> 00:56:34,070
Remember, this is like the like Simon two stage, right?

530
00:56:34,080 --> 00:56:43,680
If we have two stages, if we get to the end of that second stage, we actually require more patients than had we just had one single hour trial.

531
00:56:43,710 --> 00:56:48,720
However, the expected value of the sample size is lower because we could stop sometimes.

532
00:56:49,530 --> 00:56:56,460
So the expected value of the sample size when you have key interim analysis could be smaller.

533
00:56:56,760 --> 00:57:02,880
But the actual total number right of the trial, if you get all the way through,

534
00:57:03,090 --> 00:57:06,870
is going to be larger when you include interim analysis than if you do not.

535
00:57:10,770 --> 00:57:18,059
So the way that we usually calculate the sample size for a trial where we have this interim analysis is we calculate the sample sizes.

536
00:57:18,060 --> 00:57:19,889
If we don't have the interim analysis,

537
00:57:19,890 --> 00:57:27,420
and then we apply this what we call inflation factor based on the boundary that we're using and the number of analyzes that we have.

538
00:57:28,350 --> 00:57:32,760
And in fact, this you can't calculate these inflation factors by hand.

539
00:57:32,790 --> 00:57:38,970
Don't try. This is something that you have to do using like using a computer.

540
00:57:39,750 --> 00:57:40,770
But essentially, right.

541
00:57:40,770 --> 00:57:50,770
You can use the your like to sample t test powered t test for this standardized effect size of whatever based on your type one error,

542
00:57:50,790 --> 00:57:59,279
5%, your power of 80%. And then if you say, I'm going to do two interim analysis using the boundaries, right,

543
00:57:59,280 --> 00:58:05,640
then I take that sample size and I multiply it by 1.11, and that's now the total sample size I need for my trial.

544
00:58:06,390 --> 00:58:13,410
Now it's possible, right? I stop at interim analysis one so that my expected sample size could be smaller, but if I go all the way,

545
00:58:13,410 --> 00:58:17,070
it's actually going to be larger than if I didn't include the interim analysis.

546
00:58:20,310 --> 00:58:25,080
So if you are going to remember that for sample size at all.

547
00:58:25,140 --> 00:58:32,400
Right, the type one error, the power, the variability of the outcome, the effect size or the differences between the treatments.

548
00:58:32,700 --> 00:58:41,010
Right. Those affect the sample size. Now, if we include interim analysis, the number of interim analysis and the rule,

549
00:58:41,160 --> 00:58:45,480
the boundary that we're going to use are going to impact the sample size.

550
00:58:47,370 --> 00:58:53,430
And so we can find the total sample size, either by a numerical integration or by simulation.

551
00:58:53,880 --> 00:58:59,040
Right. If we're not like in this little table right here, you can figure it out.

552
00:59:01,980 --> 00:59:04,590
So here's just an example. We want 80% power.

553
00:59:04,590 --> 00:59:16,260
See, in effect, size, really small one like 1/16, we have 5% total trial type one error than our sample size would be 337 per arm.

554
00:59:16,740 --> 00:59:20,390
So this is just kind of putting this information in power not to test.

555
00:59:20,410 --> 00:59:33,719
Okay. Now if I use a Pocock boundary for five interim analyzes, then my inflation factor is 1.23.

556
00:59:33,720 --> 00:59:38,400
So if I go down here, I have 5% type one error 80% power five.

557
00:59:38,400 --> 00:59:41,520
In term analysis, there is my 1.23.

558
00:59:42,540 --> 00:59:47,850
And so now I actually need 1.2, three times 337 patients per arm.

559
00:59:48,060 --> 00:59:50,969
And if I am looking at each time point right,

560
00:59:50,970 --> 00:59:58,290
I can divide by five at each time point I need 83 patients per arm per timepoint that I'm looking at the data.

561
00:59:59,520 --> 01:00:02,910
If I use the O'Brien Fleming inflation factor, it's actually smaller.

562
01:00:04,080 --> 01:00:14,760
And so at this point, I need 1.03 times obsessed to say 337 write total patients in arm a and in fact every time I look at the data,

563
01:00:14,760 --> 01:00:18,510
I mean 69 patients per arm per analysis.

564
01:00:21,820 --> 01:00:24,850
So the folk rock boundaries, because they're the same at every look, right?

565
01:00:24,850 --> 01:00:35,620
They're simple, they're they're simpler and they're relatively aggressive in regards to stopping early, meaning that we're more likely to stop early.

566
01:00:35,620 --> 01:00:40,500
Right. Because those key values early are larger than if you compare to O'Brien some.

567
01:00:42,190 --> 01:00:51,160
The disadvantages are that as you can see here. Right, the inflation factors for Pocock versus O'Brien funding are much higher.

568
01:00:51,610 --> 01:00:57,400
So if you use the Pocock boundaries, you're going to require a higher total sample size.

569
01:00:57,730 --> 01:01:02,020
You're expected sample size might be smaller because you might be more likely to stop.

570
01:01:02,470 --> 01:01:13,000
However, your total sample size is going to be larger because you're using that that aggressive critical value.

571
01:01:14,680 --> 01:01:26,950
Though. Brian Fleming boundaries. The advantages are that that end critical value is very similar to if you didn't include the the interim analysis.

572
01:01:27,160 --> 01:01:35,709
So your final critical values close to your critical value with a fixed sample design and it's more powerful than the Pocock design,

573
01:01:35,710 --> 01:01:40,810
meaning, right, that inflation factor was smaller. You need less sample size, however,

574
01:01:40,810 --> 01:01:49,900
you're much less likely to stop early because you had those really tiny P values right that you had to see early on.

575
01:01:50,740 --> 01:01:55,970
If you have many stops. And so there's going to be a larger expected sample size, right?

576
01:01:55,990 --> 01:02:02,139
This is kind of reminiscent of the difference between the MINIMAX and the optimal diamond stage two design.

577
01:02:02,140 --> 01:02:08,140
And see how we can build upon that right now is just doing that more times in

578
01:02:08,710 --> 01:02:13,240
continuous values as opposed to the binary outcomes in those phase two designs.

579
01:02:15,280 --> 01:02:19,899
Okay. So once somebody does something and presents a way to make decisions,

580
01:02:19,900 --> 01:02:24,580
then everybody doing their Bialystok statistical dissertation is like, I can improve it.

581
01:02:24,790 --> 01:02:28,120
And so that's exactly what happened here is. COX And here we go.

582
01:02:28,300 --> 01:02:30,250
O'BRIEN Fleming said, no, this is better.

583
01:02:30,490 --> 01:02:34,930
And then all of a sudden, everybody kept coming out with, like, different alternative ways to look at these boundaries.

584
01:02:34,960 --> 01:02:44,380
So there are other ones. There's one series, there's a little keno which actually came out before Pocock, and there are others and others and others.

585
01:02:44,980 --> 01:02:48,490
I'd say Pocock, O'Brien, Fleming, Lange and see how disinhibited people are.

586
01:02:48,490 --> 01:02:55,600
The most commonly used boundaries beyond what I'll talk about next is just like alpha, flexible alpha spending.

587
01:02:56,680 --> 01:03:00,040
And basically what's happening is there's just a different tradeoff between when

588
01:03:00,040 --> 01:03:03,640
you can make early decisions and when you what your P value is at the end,

589
01:03:03,700 --> 01:03:13,569
right? They're just different ways in weighting. How aggressive you want to be in stopping the trials in all of these can be

590
01:03:13,570 --> 01:03:17,350
implemented in this just design package or at least could be lecture it and check it.

591
01:03:17,350 --> 01:03:24,880
Now that they seem so often, the O'Brien Fleming boundaries are actually most commonly used, at least in cancer,

592
01:03:25,420 --> 01:03:33,070
because usually it's quite undesirable to stop early and we would only really want to stop early if we feel like there's this massive signal.

593
01:03:33,400 --> 01:03:37,870
And that's because. Right. The data early is not that reliable.

594
01:03:37,870 --> 01:03:41,949
And also we've put all of these resources, time everything into the trial moving forward.

595
01:03:41,950 --> 01:03:45,790
We'd love to see it move forward and.

596
01:03:46,970 --> 01:03:52,090
So usually there's not as much excitement about stopping early for futility.

597
01:03:52,130 --> 01:03:55,370
We want to go through, although obviously we don't want to waste patience.

598
01:03:55,730 --> 01:03:59,780
We only want to stop early if there's this massive signal that we should.

599
01:04:01,790 --> 01:04:04,850
One of the books that I recommended for this class is by cooks and mats,

600
01:04:05,030 --> 01:04:10,460
and if you're really interested in group sequential design and terminologies, you can access that book.

601
01:04:10,550 --> 01:04:18,050
So you can go on a syllabus, click on the link, it goes to the library, and this might be based on the version of the book,

602
01:04:18,050 --> 01:04:21,890
perhaps the wrong one, but they have a full chapter dedicated to group sequential design.

603
01:04:22,190 --> 01:04:27,049
So if you want to read more, that's a very good resource for it. Okay.

604
01:04:27,050 --> 01:04:37,879
So here's an example in real life of interim analysis, this was from a large randomized trial and this was one of the first.

605
01:04:37,880 --> 01:04:42,770
So this is kind of old, but this is one of the first trials that implemented group sequential design.

606
01:04:42,770 --> 01:04:45,830
So it was the beta blocker, heart attack, not attached trial.

607
01:04:46,940 --> 01:04:54,710
It was looking at the effectiveness of beta blocker, beta blocker, drug and reducing mortality in patients who had recently suffered a heart attack.

608
01:04:55,040 --> 01:04:58,460
And so they wanted a two sided type one error of 5%.

609
01:04:58,700 --> 01:05:04,609
They wanted 90% power. They wanted to see a 20% reduction in three or mortality.

610
01:05:04,610 --> 01:05:09,469
If the patients were using the beta blocker versus not their target.

611
01:05:09,470 --> 01:05:14,420
Total sample size was 4000 and their endpoint is actually overall survival.

612
01:05:14,420 --> 01:05:22,460
So we ended up not talking about survival data, but right instead of just looking at did you die or not?

613
01:05:22,820 --> 01:05:26,090
Right. That might take too long to actually see in this clinical trial.

614
01:05:26,300 --> 01:05:29,600
They're looking at the time to death and so they can capture everybody who

615
01:05:29,600 --> 01:05:32,810
did die or who didn't die and the amount of time that they were in the trial.

616
01:05:33,500 --> 01:05:39,170
And so you can imagine that sample size has to be large because you'd only see so many events over.

617
01:05:41,130 --> 01:05:44,820
Three. Three years or four years or five years. Okay.

618
01:05:44,850 --> 01:05:48,920
So they said they were going to use group sequential design using O'Brian Fleming boundaries.

619
01:05:48,930 --> 01:05:55,830
They would have seven time points in which they could decide to stop the trial and they actually based theirs on calendar time.

620
01:05:56,940 --> 01:06:03,960
So every six months they would look at the data and in order to use this calendar time,

621
01:06:04,320 --> 01:06:11,520
they were assuming that there was like uniform accrual and they had uniform information between analyzes

622
01:06:11,520 --> 01:06:16,740
so that the same amount of patients were essentially coming in every six months looking at the data.

623
01:06:17,970 --> 01:06:22,290
Okay. So here's what actually happened. There's a super old right in the late seventies.

624
01:06:23,820 --> 01:06:34,710
They and May 1979, they were able to first look at the data and they saw this is the beta blocker versus the placebo.

625
01:06:36,060 --> 01:06:42,630
They saw 22 deaths in the beta blocker, 34 in the placebo.

626
01:06:42,960 --> 01:06:46,440
That was like 13% of information at that point.

627
01:06:47,190 --> 01:06:56,010
This was their critical value, right, with the O'Brien Fleming, that there had to be greater than 5.46 and their actual Z value was 1.6.

628
01:06:56,250 --> 01:07:00,580
Right. So here is their boundary that they have to cross. And here's the actual comparison.

629
01:07:00,810 --> 01:07:03,930
And you can see that they're nowhere near. So they couldn't stop.

630
01:07:03,930 --> 01:07:06,450
They had to keep going. Right. They're not seeing a big difference here.

631
01:07:06,450 --> 01:07:12,570
Even though there are more deaths in placebo by numbers, are less people total and placebo.

632
01:07:12,660 --> 01:07:20,990
There's not being enough difference. Okay. So they move on. Second analysis. Here they have to see a critical value larger than 3.86 to stop.

633
01:07:21,000 --> 01:07:26,110
They actually have a critical value of 2.24. They go on to the next analysis three.

634
01:07:26,790 --> 01:07:32,580
They have to see a critical value of 3.15. Right. The critical values are getting lower because we're using O'Brien, Fleming.

635
01:07:33,000 --> 01:07:36,990
They see 2.37. It's not passed here. They have to move on.

636
01:07:37,450 --> 01:07:40,799
Okay. We're getting closer to our critical value right now.

637
01:07:40,800 --> 01:07:45,480
The critical values, 2.73, we see we calculate Z as 2.3.

638
01:07:45,690 --> 01:07:50,090
We can't stop. We move on. Our critical value is 2.44.

639
01:07:50,100 --> 01:07:53,700
We're so close at 2.34, but we're not over, so we can't stop.

640
01:07:54,120 --> 01:07:57,900
So we move on to the the sixth time point.

641
01:07:57,990 --> 01:08:04,620
Looking at the data and now our critical values 2.23, we actually find our z value is 2.82.

642
01:08:04,620 --> 01:08:08,190
We've crossed our boundary. We got to stop our trial early.

643
01:08:08,640 --> 01:08:12,270
So we haven't quite gotten to the total 4000 patients.

644
01:08:12,270 --> 01:08:20,040
Right, really close. But we actually decide early that we can stop the trial and that it looks like this beta blocker is

645
01:08:20,040 --> 01:08:28,270
effective where there are less deaths in the beta blocker arm than there are in the placebo arm loops.

646
01:08:28,360 --> 01:08:30,500
So that they were able to conclude right.

647
01:08:30,690 --> 01:08:39,630
A little bit early without going the next six months that they could stop the trial and start to get this treatment approved for more patients to get.

648
01:08:42,760 --> 01:08:48,610
Okay. So that was those those boundaries of Brian Fleming pro-cop, right.

649
01:08:48,610 --> 01:08:53,260
We were talking about them in terms of these statistics, normal normally distributed data.

650
01:08:54,460 --> 01:09:02,890
If we have binary response data or time to event response data or normal data where we don't know the variance.

651
01:09:03,130 --> 01:09:10,180
Right. We can actually we would use t statistics. And so as each of these statistics write, all of those under large samples,

652
01:09:10,180 --> 01:09:15,430
we can actually go ahead and use our large sample, normal approximations and use these same P values.

653
01:09:15,790 --> 01:09:22,809
So if you would be applying these to large samples right over depending upon the number of treatment

654
01:09:22,810 --> 01:09:28,660
arms for right like even large samples in the binary is like over 20 sometimes right over 40 over 100.

655
01:09:29,110 --> 01:09:34,689
Right? You can use these large normal approximations so that these boundaries don't have to change

656
01:09:34,690 --> 01:09:38,680
if you have large samples by the type or the distribution of the data that you have.

657
01:09:40,600 --> 01:09:45,610
But the difference is that the information is measured a little bit differently.

658
01:09:45,610 --> 01:09:48,880
If your data is normal, your information is based on the actual number of patients.

659
01:09:49,390 --> 01:09:54,730
If you have a binary event based or survival write event based outcome.

660
01:09:55,060 --> 01:09:59,440
Now your information is based on the number of events, not the total number of patients.

661
01:10:02,060 --> 01:10:10,660
Okay. So again, right, there are lots of different boundaries and wagon series and others that we can we can work,

662
01:10:10,680 --> 01:10:18,530
we can maybe improve the Pocock and O'Brien Fleming and then comes along land and Davis and they say,

663
01:10:18,530 --> 01:10:21,080
well, we can actually make this like super flexible.

664
01:10:21,710 --> 01:10:33,830
We can say that we don't actually need to necessarily know the total number of or the exact timing or total number of analyzes that we're going to do.

665
01:10:34,610 --> 01:10:40,940
And we can decide as we move along how much of our type one error we want to spend at each look.

666
01:10:41,630 --> 01:10:51,820
And so sometimes it's just really inconvenient to specify the number of interim analysis in advance or the exact timing that will occur.

667
01:10:51,860 --> 01:10:57,170
And so land of that said, we'll create these type on error spending functions that are super flexible.

668
01:10:57,620 --> 01:11:02,630
And as we accumulate data, we can decide how much type one error we want to spend.

669
01:11:03,170 --> 01:11:09,470
So rather than defining we stopping boundaries at these critical values that satisfy this.

670
01:11:12,340 --> 01:11:20,380
This sort of function, right? The cumulative amount of stopping has to add up to the alpha total alpha level.

671
01:11:21,370 --> 01:11:30,819
We're actually going to choose an increasing alpha function and define our critical values to satisfy the fact that,

672
01:11:30,820 --> 01:11:35,380
well, at this time, right, my alpha can be whatever I want it to be.

673
01:11:35,680 --> 01:11:41,049
And as I move on, I just need to know that if I'm going to save my alpha right,

674
01:11:41,050 --> 01:11:46,990
I have to subtract off the alpha R2 used and so that I would only have this remaining alpha left.

675
01:11:49,090 --> 01:11:55,329
And so my timing of my interim analysis are flexible and then number of interim analysis are flexible.

676
01:11:55,330 --> 01:12:01,390
However, right. I'm going to I'm essentially deciding how much type one error I'm spending at each one of these.

677
01:12:04,240 --> 01:12:13,959
So if I let the c k denote my test statistic where here this 0 to 1 is like this t here is like my information.

678
01:12:13,960 --> 01:12:17,320
So if it's zero, nobody's in trial, right? No events.

679
01:12:17,320 --> 01:12:24,700
And if it's one, everybody is in the trial. There's the total sample size or total number of events have occurred.

680
01:12:25,120 --> 01:12:31,570
Right. If I'm going to make some interim analysis, then the timing or the information is going to be somewhere in between there.

681
01:12:32,320 --> 01:12:37,030
And so I can choose my critical value so that when a null is true,

682
01:12:37,120 --> 01:12:46,360
the probability that I reject the null hypothesis right is based on some amount of alpha that I feel like I can spend at this time on.

683
01:12:47,170 --> 01:12:55,480
And if I continue to move on right now, I have to say, well, I, I moved on and I spent that much alpha.

684
01:12:55,750 --> 01:13:00,430
So now I have right such amount of alpha left and so I can kind of do that as I move on.

685
01:13:00,430 --> 01:13:04,270
So I kind of have to have some idea of how many interim analysis I'm going to do, right?

686
01:13:04,270 --> 01:13:08,560
Like you can't go blindly into it because I can't just say alpha.

687
01:13:08,770 --> 01:13:11,890
Alpha T one is 5%, right? Then I got nowhere to go.

688
01:13:13,690 --> 01:13:17,590
But I have some flexibility in what I decide that level is.

689
01:13:18,640 --> 01:13:25,299
And so I can I can choose these critical values either by numerical integration simulation or a good software package.

690
01:13:25,300 --> 01:13:30,550
This isn't something you can solve for by hand. This isn't something I can ask you to like solve for right here.

691
01:13:32,950 --> 01:13:41,589
But essentially I'm going to make decisions based on the amount of information that I have and if I have a normally distributed outcome,

692
01:13:41,590 --> 01:13:47,710
that amount of information relates to the sample size. If I have a binary or time to have an outcome that relates to the number of events,

693
01:13:48,190 --> 01:13:53,349
and then I'm going to relate my Type one error to be spent at each interim analysis

694
01:13:53,350 --> 01:13:59,080
to this total proportion of information so that if I am making decisions up front,

695
01:13:59,110 --> 01:14:02,740
right, I have little information, I probably don't want to spend a lot of alpha.

696
01:14:03,280 --> 01:14:09,100
And as I go forward and my information accumulates, then I probably want to spend more my alpha at that point.

697
01:14:11,050 --> 01:14:19,510
So if we can actually write, this is like a more generic framework that we can fit Pocock and O'Brien flooding into,

698
01:14:19,510 --> 01:14:26,980
so you can figure out what the alpha spending functions are for the focus boundaries and for the O'Brien Fleming boundaries.

699
01:14:27,370 --> 01:14:34,330
And in fact the Pocock style spending function is such.

700
01:14:34,810 --> 01:14:40,480
So it's the type one error times natural log of one plus E minus one times the amount of information.

701
01:14:40,960 --> 01:14:48,130
Right. And for O'Brien Fleming, we get this two minus two of the cumulative normal alpha over two over the square root of information.

702
01:14:49,510 --> 01:14:57,130
And so these are just different ways in which you can calculate those boundaries under this framework of the flexible alpha function.

703
01:14:57,520 --> 01:15:00,729
But we can create other types of alpha functions, right?

704
01:15:00,730 --> 01:15:06,620
So that we get other boundaries here. Okay.

705
01:15:06,920 --> 01:15:14,090
So it seems like, right, these utility boundaries are useful because you can potentially have a lower expected sample size.

706
01:15:14,090 --> 01:15:20,780
Right. All the arguments for under the same and two stage for why would be useful are here.

707
01:15:21,350 --> 01:15:27,079
Now why might not be useful and that's you know similar arguments to Simon to

708
01:15:27,080 --> 01:15:31,640
stage as well is that this is going to favor therapies with immediate benefit,

709
01:15:32,960 --> 01:15:34,640
but delayed effects could be missed.

710
01:15:34,640 --> 01:15:43,630
So if right we don't actually see the effect of the therapy for a long time, kind of like the difference between zero and type zero, right?

711
01:15:43,820 --> 01:15:47,600
Or if we're going to make decisions right now at this time, we might miss.

712
01:15:47,600 --> 01:15:50,660
Well, what's actually the outcome like three months later. Right.

713
01:15:50,960 --> 01:16:00,950
And so if we we are prioritizing immediate benefits and losing out on any type of delayed benefit on treatment,

714
01:16:03,740 --> 01:16:10,550
any trial that stops due to small observed effect sizes could potentially miss these long term effects.

715
01:16:10,910 --> 01:16:14,479
And so there are some examples of therapies with late benefit.

716
01:16:14,480 --> 01:16:18,620
So if you you can like Google, you know, disadvantages of futility,

717
01:16:18,620 --> 01:16:23,270
stopping balance or group sequential design, you can actually find more about these specifically.

718
01:16:24,440 --> 01:16:31,640
But like immunotherapy was a big thing that came on the scene in cancer in the last little over a decade.

719
01:16:32,000 --> 01:16:38,840
And those actually are treatments. Immunotherapies generally take a long time and even the cancer usually gets worse.

720
01:16:39,140 --> 01:16:41,890
And then all of a sudden somehow, right.

721
01:16:41,900 --> 01:16:47,600
It's like now trained your immune system to get on, fight the cancer, but it takes quite a long time to get there.

722
01:16:47,840 --> 01:16:53,390
And so if you try to use group sequential design, you probably would have said, Oh, this treatment sucks, stop this trial.

723
01:16:53,630 --> 01:16:58,220
Whereas had you just waited, you could have seen that there was actually an effect.

724
01:17:01,520 --> 01:17:07,460
This is not ideal for trials where there's a learning curve that can impact the outcomes of somehow the intervention being applied.

725
01:17:07,790 --> 01:17:12,769
Right. If it takes a while for clinicians and not not the investigators,

726
01:17:12,770 --> 01:17:16,190
whoever is giving the intervention, if it takes them a while to figure out how to do this.

727
01:17:16,190 --> 01:17:23,450
Well, right, then you shouldn't do this because obviously you're not doing well in the beginning.

728
01:17:23,450 --> 01:17:31,190
And so you can see that there's no difference. Stop the trial or see that right and make the wrong decision.

729
01:17:35,570 --> 01:17:38,710
It's possible to overlook treatment effects in important subgroups.

730
01:17:39,280 --> 01:17:45,040
So you might say, well, total, right? Looking across everybody, this treatment looks terrible.

731
01:17:45,040 --> 01:17:45,999
Let's stop the trial.

732
01:17:46,000 --> 01:17:51,250
But actually, if you went and if you accumulated more data, you would have seen that there are certain subgroups for which it is really helpful.

733
01:17:51,250 --> 01:17:59,260
And you won't have enough data if you stop the trial early to do that. And so decisions to stop for futility must be made with really great care.

734
01:17:59,650 --> 01:18:06,250
And like I said, often those who are invested in the trial, right, those are the investigators, the people who design the trial.

735
01:18:06,250 --> 01:18:08,770
They don't want to separately, they want to see the whole thing happen.

736
01:18:09,100 --> 01:18:14,020
So if we're going to input these stopping downs are likely to be highly conservative upfront.

737
01:18:15,580 --> 01:18:23,889
Okay, so we'll stop there for today. We will finish the adaptive features on Thursday, which again,

738
01:18:23,890 --> 01:18:28,360
if you haven't read the clinical trials article, that's what we're really talking about on Thursday.

739
01:18:28,360 --> 01:18:34,120
So please do so take candy as you leave and I'll update.

740
01:18:34,240 --> 01:18:59,790
So your question to say not Thursday, Tuesday for the podcast boundaries, as I said on Twitter.

741
01:19:01,060 --> 01:19:08,900
So I don't think so. Okay.

742
01:19:10,360 --> 01:19:13,540
Yeah, that was like modeling this morning. It was great.

743
01:19:13,540 --> 01:19:26,229
And all of her like several of them, apparently not I but maybe that would be just the.

744
01:19:26,230 --> 01:19:31,960
How do you keep that? You can't play span of time.

745
01:19:32,690 --> 01:19:38,900
Oh, oh, oh.

746
01:19:38,970 --> 01:19:49,180
Your mother said it's not so you to see my life.

747
01:19:49,180 --> 01:19:57,090
And I don't really know what they're like.

748
01:19:57,130 --> 01:20:04,240
I don't know. I don't remember what it looks like.

749
01:20:04,420 --> 01:20:15,309
It's sort of. Yeah. Oh, we need to get a total lecture on the tape.

750
01:20:15,310 --> 01:20:21,130
Candles, you know, I just. I'm just go for it. So whatever you don't say we're going to go out and.

751
01:20:21,190 --> 01:20:36,670
Well, I got to, you know, judging by can the think or how much they were a new option and what you're saying the same topic.

752
01:20:36,850 --> 01:20:48,970
Yeah. 000000008.

753
01:20:49,100 --> 01:20:55,140
Are they taking it so far?

754
01:20:57,430 --> 01:21:07,560
So I've always like I think they have you want to take this value, you can take it because I'm just going to put it in the camera.

755
01:21:07,570 --> 01:21:25,840
I really don't think you should do it now when people to take 33 I think you know what do you do if there's a

756
01:21:25,840 --> 01:21:39,940
like sandwiched between several weeks I have today so I was just really I don't know if I would rather be like,

757
01:21:40,450 --> 01:21:43,740
oh, that's a great company. That makes a great comment.

758
01:21:44,020 --> 01:21:51,300
But what do you do between now and then? I'll wait to hang out with you.

759
01:21:51,670 --> 01:22:03,030
I'm going to the bridge. The bridge problem, I think.

760
01:22:04,540 --> 01:22:07,270
Pretty high school. Yeah.

