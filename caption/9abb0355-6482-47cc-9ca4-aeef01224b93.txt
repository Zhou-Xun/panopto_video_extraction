1
00:00:01,470 --> 00:00:09,280
Like when you're like in the thick of it all, I'm like, they're trying to say, Listen, I don't want to do that.

2
00:00:09,640 --> 00:00:34,440
So I did my best comes from anywhere between to make I sometimes you feel like you know that like I just feel like I'm like I don't know.

3
00:00:35,390 --> 00:00:41,250
I have never heard of people that you made a difference.

4
00:00:41,970 --> 00:00:51,060
We definitely did something that we hit a threshold.

5
00:00:51,060 --> 00:00:54,930
Then it was like, I going to have a rental.

6
00:00:54,930 --> 00:01:06,610
And it's nice that you want to hear all these things like that, like snowstorm and like driving in.

7
00:01:06,950 --> 00:01:13,190
You still have there been everything went through Denver.

8
00:01:13,570 --> 00:01:17,940
That's who I'm going to think about.

9
00:01:17,940 --> 00:01:37,710
Yeah. So one after another just has responsibilities and it should be more extra whiteboards.

10
00:01:38,550 --> 00:01:42,030
Yeah. Yeah, just in time.

11
00:01:43,890 --> 00:01:49,350
Let me see what I'd like you to work or not.

12
00:01:51,230 --> 00:02:05,820
And I was like, okay, I know here.

13
00:02:09,870 --> 00:03:00,580
It's just it's just keep trying to keep your personality out.

14
00:03:00,960 --> 00:03:06,480
And that's why she's got you.

15
00:03:07,010 --> 00:03:22,860
You know, it's Ellen because you're from.

16
00:03:25,130 --> 00:03:30,000
Because it's options.

17
00:03:30,930 --> 00:03:39,560
It like. Professor.

18
00:03:40,590 --> 00:03:56,640
How many times in this class? I'm earlier, but I feel like I could do the things you like holding a lots of different levels.

19
00:03:58,170 --> 00:04:02,640
What can I do to really change it significantly?

20
00:04:04,110 --> 00:04:27,989
We've got a little thing between states and certain types of ideas to sort of figure out how to connect with people and everybody to do well.

21
00:04:27,990 --> 00:04:38,250
And to take a simple example. I noticed that one of the main problems that I had to keep driving in people is it's

22
00:04:38,250 --> 00:04:41,610
hard to get people motivated to vaccinate for something they've never seen before.

23
00:04:42,810 --> 00:04:49,770
The generational shift is that infectious disease could be something that was you know,

24
00:04:49,770 --> 00:04:55,430
that was not part of the lived experience of people my age or something.

25
00:04:55,440 --> 00:05:00,510
That was until probably not seems like quality.

26
00:05:01,590 --> 00:05:12,749
Yeah. I mean, like my father was in the Middle Ages, like my father who had gotten polio.

27
00:05:12,750 --> 00:05:24,430
Yeah. People who had gotten used to that lived experience of these things being in society was, you know, growing up but not part of my.

28
00:05:24,680 --> 00:05:30,540
And I just, you know, the only thing that I got from I was the chicken pox vaccine.

29
00:05:30,540 --> 00:05:39,749
Yeah. And I think it's really salient to how sort of the assumption was where, of course,

30
00:05:39,750 --> 00:05:47,260
we could just do it because it's kind of infectious diseases aren't actually a thing that, you know, get cold out there.

31
00:05:47,260 --> 00:05:57,450
Right. And I remember I was like, oh, no, no, I'm not.

32
00:05:57,470 --> 00:06:16,830
Oh, I don't know if someone actually speaks of the pattern that pulls out one of the old iron lung out of that part of the basement and rolled it out.

33
00:06:17,490 --> 00:06:22,120
And he had a shot of something that was obviously about the subject of your time.

34
00:06:22,350 --> 00:06:29,680
And it said he was his first wife and everything is like, the [INAUDIBLE] is this?

35
00:06:30,160 --> 00:06:37,979
Oh, we haven't seen that. No, I. I just think that's that's the one thing I didn't really say.

36
00:06:37,980 --> 00:06:43,190
I didn't like a lot when I listened to that. But it's just a gathering experience.

37
00:06:43,200 --> 00:06:48,210
And you talk about and what is your mental model for people?

38
00:06:52,200 --> 00:07:11,519
No, you're right. So, you know, you're kind of super once again, very curious, which is why the vaccine was so you next week.

39
00:07:11,520 --> 00:07:17,100
But I know it's pretty contagious, too.

40
00:07:17,300 --> 00:07:21,360
Yes. It's not measles, but it's pretty contagious. Now, I can get somebody.

41
00:07:21,690 --> 00:07:30,300
I mean, I think I'll be here and I'll take it off until somebody will have to explain it.

42
00:07:30,820 --> 00:07:34,800
He used to be that parents would say that are kids. No, you can't. Yeah.

43
00:07:34,880 --> 00:07:44,380
What do you think about you know, we're like, yeah, I'll go to school and feel that we would change what we do.

44
00:07:44,380 --> 00:07:53,090
Is one of that. Yeah, but how does that generalize?

45
00:07:53,400 --> 00:07:57,740
So that point, how does that compare to spring break?

46
00:08:00,020 --> 00:08:06,000
Well, nothing. I mean, you'd like to think that we would learn about this, but I don't really know that we will.

47
00:08:06,750 --> 00:08:20,720
We'd have the sense of how that clearly is transferable, our responsibility and the like,

48
00:08:20,730 --> 00:08:28,500
just, you know, well, either government or working with it for a private war.

49
00:08:29,550 --> 00:08:34,920
And that's why we wanted to see what that's like.

50
00:08:35,140 --> 00:08:39,960
Our biggest cognitive weakness is like we're like the only species capable of advanced thinking,

51
00:08:39,970 --> 00:08:44,890
but at the same time, we don't like advanced thinking. Yeah, there's a phrase that I don't subscribe to this course.

52
00:08:44,890 --> 00:08:53,510
When we talk about the internet or something like that, you can all be worried about it.

53
00:08:53,620 --> 00:08:57,610
So here we are. You're not going to worry about that.

54
00:08:58,180 --> 00:09:04,740
So it becomes a human prioritization, not so much just intelligence.

55
00:09:05,260 --> 00:09:12,840
I really think that people are worried about how bad they're not going to pay attention to the diseases like we're compared to other people.

56
00:09:13,240 --> 00:09:20,970
This is a useful and I'm sorry, I'm distracted by talking about political foods to everybody.

57
00:09:23,530 --> 00:09:31,209
Obviously, this is our last class. I will sort of reserve a little bit of time towards the end to talk more globally about the class.

58
00:09:31,210 --> 00:09:34,660
But I want to start by just checking in with you about the last assignment.

59
00:09:35,230 --> 00:09:43,240
I've talked with a couple of people about stuff and what am I looking for, etc., but are there any questions?

60
00:09:44,880 --> 00:09:48,180
So you're wondering about sort of like what to emphasize or not emphasize?

61
00:09:51,350 --> 00:09:56,320
I haven't even thought about it yet. All right.

62
00:09:56,410 --> 00:10:02,080
So here's a few pieces of guidance. One.

63
00:10:07,080 --> 00:10:10,720
So anyway, I want to hear sort of, oh,

64
00:10:10,870 --> 00:10:17,470
people's risk perceptions might influence what they might think about the label, like not be concrete and specific.

65
00:10:18,190 --> 00:10:22,390
If the label says X, what do you think people will feel?

66
00:10:23,200 --> 00:10:26,380
Will this make them afraid of what does not make them afraid? Will they ignore it?

67
00:10:26,980 --> 00:10:30,190
Will they not ignore it? I think concreteness matters here.

68
00:10:31,480 --> 00:10:36,310
I'm looking for this paper to show me what you've learned in this course.

69
00:10:36,490 --> 00:10:42,250
It's less about what you answer is and more about show all the connections.

70
00:10:43,000 --> 00:10:54,190
Because like with COVID, we will think about our exit strategy for many different aspects of this course are going to be relevant.

71
00:10:55,120 --> 00:10:59,260
Our cognition, cognitive thoughts, analytical thoughts, the experiences.

72
00:10:59,590 --> 00:11:07,050
There are mental models. There are issues of trust. There are issues of of uncertainty.

73
00:11:08,710 --> 00:11:16,330
There are issues of overloading people with too much information or not enough information, like connecting the dots for me.

74
00:11:17,050 --> 00:11:28,960
That's what this paper is about. If the law requires particular types of labeling.

75
00:11:30,580 --> 00:11:36,550
If you believe that they are. Could be better labels.

76
00:11:37,720 --> 00:11:45,120
You are. It is in scope for you to say, well, so the current labels are doing X, but what we really want is labels that do Y.

77
00:11:45,130 --> 00:11:50,920
So we ought to have labels that look like this or that do look at things like a in scope.

78
00:11:50,920 --> 00:11:58,290
The idea of. It's not just a question of are there labels, but what's on the label?

79
00:12:00,730 --> 00:12:07,720
So if you want to say the label should be bigger or smaller, ready to include more information or specific types of information or whatever.

80
00:12:08,230 --> 00:12:13,670
Feel free. You've lost.

81
00:12:13,970 --> 00:12:17,690
The other part of the paper is about. A general.

82
00:12:17,690 --> 00:12:22,010
Three levels or three levels. You must take a stand.

83
00:12:22,670 --> 00:12:28,610
That is one of the clear lines here. You can't just sort of say, well, us take a stand.

84
00:12:29,150 --> 00:12:32,930
Should these be allowed? Should they be prohibited, etc.

85
00:12:39,430 --> 00:12:43,890
Acknowledge. The opposite side of your argument.

86
00:12:44,520 --> 00:12:50,040
So there are going to be arguments that say, hey, maybe we should.

87
00:12:50,160 --> 00:12:54,480
I'm just making this up. If you want to argue, hey, we should allow this particular type of labor.

88
00:12:55,500 --> 00:13:00,000
My guess is you can come up with reasonable arguments from this chorus about problems with doing that.

89
00:13:00,630 --> 00:13:05,160
Acknowledge those. I don't want you to give me only one side of the argument.

90
00:13:05,190 --> 00:13:11,190
I want you to show me that you understand both sides of the argument and then take a stand and then say,

91
00:13:11,280 --> 00:13:14,310
know in that I think this is the better way to go, etc.

92
00:13:15,450 --> 00:13:23,070
But again, I'm grading this not on. Research about GMO or bioengineered products.

93
00:13:23,840 --> 00:13:33,600
Grading this based upon your ability to show the logic that you've learned things in this course about how this communications will change.

94
00:13:33,600 --> 00:13:39,360
People will change production, producers will change how we interact with risk.

95
00:13:40,200 --> 00:13:53,900
And so just more connections you can make, the better. And I'll leave you with this.

96
00:13:53,910 --> 00:14:01,820
One of the reasons why I have this assignment at the end is how I think.

97
00:14:01,960 --> 00:14:05,460
So it was asking me how long, how many times every time I taught this course.

98
00:14:05,460 --> 00:14:10,710
I think this is either my 12th or 13 flight. I've taught this course early on.

99
00:14:11,250 --> 00:14:17,190
I remember going through almost this entire course and all the different things that

100
00:14:17,190 --> 00:14:21,239
we've been covering and then having some discussions with people around Thanksgiving.

101
00:14:21,240 --> 00:14:32,480
Around how? They were absolutely [INAUDIBLE] bent on prohibiting GMO food products because obviously this was a big danger to people.

102
00:14:33,080 --> 00:14:38,870
And I was stuck struck by the sense of mismatch between all the knowledge I know that they had just been

103
00:14:38,870 --> 00:14:44,450
talking about in the class and what seemed to be a very binary perspective about that particular issue.

104
00:14:45,290 --> 00:14:52,040
So the purpose behind this is to, again, to help you think through the nuances, bring all the pieces together,

105
00:14:52,970 --> 00:15:03,710
and to also remind you that there are relatively few risks out there that are truly binary, that are truly, like absolute, you know, horrific things.

106
00:15:04,130 --> 00:15:08,170
And of course, we're going to do everything we can about them or things that are said.

107
00:15:08,240 --> 00:15:16,100
You know, we don't have to worry about that. We can just ignore it. This whole course is about not just recognizing nuance, but communicating to us.

108
00:15:16,940 --> 00:15:22,040
And one of the things that we want to talk about today is how we do that.

109
00:15:23,660 --> 00:15:26,720
You know, some of you mused about the question of, you know, well,

110
00:15:27,170 --> 00:15:33,649
can we really be that kind of nuanced communicators or do we need to be more clear and directive when we're talking about it?

111
00:15:33,650 --> 00:15:37,370
And yeah, we ought to have we don't have that conversation. So.

112
00:15:38,960 --> 00:15:42,530
If something comes up as you start working on the paper, please feel free to reach out to me.

113
00:15:45,340 --> 00:15:54,790
This should be fairly straightforward. Like there's nothing in here about giving you a number of different links to news articles

114
00:15:54,790 --> 00:15:58,680
and other articles that should give you some food for thought to build on for the assignment.

115
00:15:58,690 --> 00:16:04,770
But if you're looking for if you're struggling. All right.

116
00:16:06,240 --> 00:16:15,420
So. COVID. Two years ago when I taught this course.

117
00:16:16,520 --> 00:16:22,060
It was a really interesting experience. Like an immersive.

118
00:16:22,270 --> 00:16:29,770
I mean, it's like, you know, you talk about like immersive language learning where you go to a country and you have to talk and live in the language.

119
00:16:30,930 --> 00:16:39,570
That was what teaching this course was in the fall of 2020. Every single day was an immersive experience in in risk.

120
00:16:41,280 --> 00:16:47,940
We're a couple of years removed from that now, and that's one of the things we have to talk about, like we are not where we were two years ago.

121
00:16:49,560 --> 00:16:56,070
But what I want to do today more than anything else is it is like I'm talking about with the paper, connect all the dots,

122
00:16:56,070 --> 00:17:03,130
like let's make as many connections to different parts of this course as we can and then sort of take stock of it.

123
00:17:03,150 --> 00:17:09,750
Where are we? What what have we learned about from the experience of COVID that we want to hold on to moving forward?

124
00:17:11,300 --> 00:17:25,320
To get us started. Emily, you were talking in your music about shifting guidelines and the problems that we've had in many contexts,

125
00:17:25,320 --> 00:17:30,990
and COVID about people, public health, saying X and then saying Y and then saying Z.

126
00:17:31,740 --> 00:17:34,950
That seems like a good place to start this conversation.

127
00:17:36,350 --> 00:17:43,489
Yeah. I don't really remember much of what I said. I just remember talking about how there's a lot of pushback when there is shifting guidelines.

128
00:17:43,490 --> 00:17:48,530
And that kind of led to people saying, oh, well, because they're changing and already they're not.

129
00:17:49,100 --> 00:17:59,600
You don't really know, so why should we trust them? And that kind of led it to be politicized and divided just cause, it seems, is caused by mayhem.

130
00:18:00,260 --> 00:18:01,820
So there's no question it caused more mayhem.

131
00:18:02,330 --> 00:18:09,470
A key thing that I want to bring out that you just mentioned is there is the fact that that guideline is changing.

132
00:18:10,040 --> 00:18:12,530
And then there's the implication we take from that.

133
00:18:13,430 --> 00:18:18,860
You're suggesting and I think there's good arguments to believe it, that part of what people took was not.

134
00:18:20,710 --> 00:18:29,120
That the science was evolving. But that scientists or public health had didn't feel like that we were shooting blind,

135
00:18:29,120 --> 00:18:33,100
that there was no knowledge, and perhaps that that affected people's trust.

136
00:18:34,990 --> 00:18:46,240
What are some of the specific situations where the guidelines change and evolved when they switched from the ten days to five days for quarantine?

137
00:18:46,390 --> 00:18:53,590
That's one at the very beginning when they said, you don't need to switch anything, you should wear a mask.

138
00:18:53,660 --> 00:18:54,850
Yeah. So that's another one.

139
00:18:56,030 --> 00:19:01,820
Other ones that pop up, things that we used to think we were supposed to do or now we're not supposed to do or vice versa.

140
00:19:04,070 --> 00:19:07,880
Yeah. Like, uh, washing off your groceries.

141
00:19:08,090 --> 00:19:13,850
Yeah. So there was that brief sort of like, I don't know, it was like a three week window, and all of a sudden it's viral,

142
00:19:13,850 --> 00:19:21,080
like, oh, you had a washer person, and they were like, Oh, you don't have to like your groceries now. Oh, I will note, just for a contrast.

143
00:19:22,840 --> 00:19:29,590
Part of why we stepped away from those contact provision emphasis was because

144
00:19:29,590 --> 00:19:33,669
we started to figure out that COVID was not being transmitted through like,

145
00:19:33,670 --> 00:19:36,040
I touch this of you, touch this type of transmission.

146
00:19:36,850 --> 00:19:45,219
Notice that right now this is increasing level of conversation around those kinds of things washing your hands,

147
00:19:45,220 --> 00:19:49,720
washing surfaces, etc. But it's not about COVID, it's about RSV, and it's about flu.

148
00:19:51,980 --> 00:19:56,240
So again, this is a mental model piece where. As we.

149
00:19:56,410 --> 00:20:03,430
It's not that that came from nowhere. There are plenty of infectious diseases where contact transmission is a major source of issues.

150
00:20:04,440 --> 00:20:09,060
What we happened to do was sort of to assume that it was going to be like that and then we had to walk it back again.

151
00:20:09,360 --> 00:20:14,270
Turns out not true. Other things that changed.

152
00:20:18,330 --> 00:20:21,360
Yeah. Like what type of masks are acceptable?

153
00:20:21,690 --> 00:20:26,519
Like. Yeah. So let's talk about the. The acceptable mask.

154
00:20:26,520 --> 00:20:32,910
The question. I know, Audrey, you were talking about this in your musings.

155
00:20:32,920 --> 00:20:38,470
Like, what's an appropriate mask to be wearing? Anything you want to add from when you were thinking about that?

156
00:20:38,820 --> 00:20:44,020
Because originally I wore a cloth mask and then all of a sudden it was like, Oh, it's useless if you don't have like a ten,

157
00:20:44,100 --> 00:20:49,930
95 and 95, but those weren't available, so it was like an all or nothing type of thing.

158
00:20:49,970 --> 00:20:55,160
Yeah. When really it wasn't right. So there was the no mask.

159
00:20:55,370 --> 00:20:58,420
Then there was. You make a mask out of anything.

160
00:20:58,430 --> 00:21:01,940
I remember of watching the video of the surgeon general holding a T-shirt.

161
00:21:03,760 --> 00:21:06,969
Making a mask out of that. Then there was the oh.

162
00:21:06,970 --> 00:21:14,670
Cloth masks are useless. Now we're sort of I don't know where we are.

163
00:21:15,960 --> 00:21:22,200
Like, clearly, there's some sense of mass as having value, as being general, but there certainly are.

164
00:21:23,480 --> 00:21:32,900
Situations in which cloth masks are not counted as sufficient protection in hospital environments and so that like gradations are being put them.

165
00:21:36,130 --> 00:21:41,470
So certainly one of the things that I've started realizing is that I wear different masks in different situations.

166
00:21:43,240 --> 00:21:47,120
And I'm not sure whether I actually have any rational justification for that.

167
00:21:47,140 --> 00:21:50,530
I just somehow feel like, well, if I'm going to be here, then I ought to have a good Basque.

168
00:21:50,530 --> 00:21:58,210
And if only here, then yeah, I'll just wear whatever I've got. But that's a reflection of this ever evolving guidance.

169
00:21:58,250 --> 00:22:02,920
Like each person is left to sort of sort out what they feel comfortable with or not,

170
00:22:02,920 --> 00:22:07,000
because there is no clear answer to You must be here, you must have this fear, etc.

171
00:22:09,200 --> 00:22:15,270
Any other stuff that's changed over time? Yeah.

172
00:22:15,930 --> 00:22:21,420
I think it's more of like public health, except like wearing a mask as before.

173
00:22:21,810 --> 00:22:27,910
I remember in my undergrad I studied law on the court in California and I'm originally from China.

174
00:22:27,930 --> 00:22:36,839
Satellite in Asia I think is pretty common too. Whereas if just if you want to wear a mask, there's no particular reason that you might be like,

175
00:22:36,840 --> 00:22:40,860
you know, wear makeup today or you didn't look good today. You can just wear a mask to cover it up.

176
00:22:41,340 --> 00:22:49,710
But during the allergy pollen season, I wear a mask to prevent myself or for exposure for pollens.

177
00:22:50,190 --> 00:22:59,180
And my classmates in my class are thinking that I have a disease that is transmittable and asking me like, Are you okay?

178
00:22:59,230 --> 00:23:04,950
You need to go to the hospital. And that, I do think, is a societal change,

179
00:23:05,220 --> 00:23:16,379
like what used to be notable and sort of make assumptions about why it is you're wearing a mask has evolved into a I expect almost

180
00:23:16,380 --> 00:23:23,370
anywhere I go that I will see some people wearing masks and other people not wearing masks and that I don't necessarily know why.

181
00:23:27,010 --> 00:23:32,980
So that's an interesting sort of shift in our societal level of risk perception, how we interpret that behavior.

182
00:23:34,700 --> 00:23:39,470
Any other changes? Yeah, I think there's a lot of changing around testing.

183
00:23:39,890 --> 00:23:43,219
Oh, yeah, yeah, yeah. So let's.

184
00:23:43,220 --> 00:23:47,150
Let's lay out the sequence here. First, we had no tests.

185
00:23:48,780 --> 00:23:52,430
Then we had PCR tests.

186
00:23:53,180 --> 00:24:06,530
So if you wanted to get test, you drove and you went to the clinic or you were I rather impressed with the whole drive through testing thing.

187
00:24:08,510 --> 00:24:14,630
Oh, and I also throw this one in here because it's not that it's changing the risk, but it's certainly changed in the lived experience.

188
00:24:14,960 --> 00:24:23,390
Like the shift from the only way you get tested is by sticking a swab up your nose to spit in a vial and you're done.

189
00:24:23,930 --> 00:24:27,230
Wow. That was a big shift, certainly for those of us with kids.

190
00:24:27,260 --> 00:24:35,930
That was a big shift. I remember trying to get, you know, so that was one off now that we got the home tests.

191
00:24:37,960 --> 00:24:51,840
So let me just pause for a second. What is your sense right now of how valuable or not, how accurate or not the home tests are?

192
00:24:54,320 --> 00:24:57,980
How do you think they should be used at this point in time, given what we know?

193
00:25:01,080 --> 00:25:07,350
Because there was a stage in which it was like, well, of course you're going to do a test every time you want to go out to a club kind of thing.

194
00:25:07,890 --> 00:25:17,670
And that kind of faded away. I think when you're super symptomatic, maybe those tests could be sensitive enough to detect COVID.

195
00:25:17,670 --> 00:25:23,590
But if you're asymptomatic, in my experience, they're not accurate.

196
00:25:23,610 --> 00:25:28,080
So you really want to know if you're asymptomatic, you should probably get a PCR.

197
00:25:28,590 --> 00:25:31,680
So that suggests the use are basically confirmation.

198
00:25:31,770 --> 00:25:36,390
I'm already symptomatic, so I'll use it to confirm, hey, I've got COVID and not flu kind of thing.

199
00:25:36,780 --> 00:25:39,390
But that's your question here. Do you trust it enough?

200
00:25:40,020 --> 00:25:45,600
If you don't trust it enough so that you believe is the negative, then why are you taking it in the first place?

201
00:25:46,670 --> 00:25:51,560
Yeah. So I work at one of the COVID testing centers at the university,

202
00:25:51,830 --> 00:25:58,370
and we recommend at home rapid kits to people who have tested positive in the last 90 days,

203
00:25:59,480 --> 00:26:05,299
because a lot of the times they can't get a PCR because it would potentially pick up

204
00:26:05,300 --> 00:26:10,910
the remaining COVID infections and then they would be recommended to isolate again.

205
00:26:11,330 --> 00:26:16,900
So a lot of people are looking for their time period, full use of.

206
00:26:18,740 --> 00:26:21,200
And how do you think people respond to this?

207
00:26:22,430 --> 00:26:30,950
Sometimes people are upset because they want like that because I think some of the pictures are more accurate.

208
00:26:33,500 --> 00:26:41,720
But I think a lot of the time people are just happy to have something like walk away with like any sort of test and they feel better.

209
00:26:42,260 --> 00:26:47,840
Now notice that you're looking at a population who is coming for testing.

210
00:26:48,680 --> 00:27:01,520
So we've already narrowed the scope here to a group of people who mindset is I want to know as distinct from a test as a screening mechanism,

211
00:27:01,520 --> 00:27:07,050
test as a you have to do this before you can go to the theater kind of thing.

212
00:27:07,070 --> 00:27:13,320
I remember that stage. When my youngest went off to camp,

213
00:27:13,320 --> 00:27:19,980
they had to get a PCR test within 72 hours from the time they showed up for the camp or else they weren't going to be allowed in.

214
00:27:21,210 --> 00:27:25,990
And that's a mindset that. You have it?

215
00:27:26,980 --> 00:27:30,220
I don't know. It feels like we've moved a little bit away from that of.

216
00:27:31,430 --> 00:27:39,870
But again, that's another one of the evolutions here. By the way, let's also remind ourselves of the of you keep talking about changes over time.

217
00:27:39,890 --> 00:27:47,600
Think back to the very beginning of the class and that two factor structure where one of the factors is known versus unknown,

218
00:27:48,650 --> 00:27:53,209
like we have slid down from unknown into known two.

219
00:27:53,210 --> 00:27:56,390
I'm sick of this two. Are we still talking about COVID?

220
00:27:57,230 --> 00:28:05,030
But it's not the virus. We know everything about COVID, but on a psychological standpoint, I'm I'm done.

221
00:28:05,270 --> 00:28:11,870
But we've had so much information, so much part of our lives, it's hard to feel a lot of strong emotions about it,

222
00:28:12,170 --> 00:28:17,120
just simply because of the cumulative exposure that's another part of the COVID experience is.

223
00:28:18,240 --> 00:28:24,240
After two and a half years of this, almost three years now, we're well past any novelty.

224
00:28:27,770 --> 00:28:32,230
All right. So that's one that's a couple of different pieces.

225
00:28:34,960 --> 00:28:42,230
What else do I want to make sure I'll touch upon here? Well, let's talk at least a little bit about.

226
00:28:44,360 --> 00:28:51,379
The politicization, and not that I want to go down the pathway of the American society and we can talk about this more globally.

227
00:28:51,380 --> 00:28:54,950
But there is a key piece of this that is.

228
00:28:56,400 --> 00:29:04,410
About the tension between scientific information and that cultural perspective, that worldview perspective.

229
00:29:05,340 --> 00:29:09,580
And we certainly saw it play out in a few places. So where did it come up?

230
00:29:11,000 --> 00:29:18,380
Most obviously for you guys. Where do you see that sort of cultural bias, that worldview bias coming into play about strongly?

231
00:29:20,390 --> 00:29:31,400
Yeah. Like how we guidelines kind of affected people's perception of their like.

232
00:29:32,410 --> 00:29:38,350
Individual, right? Yeah. So snapping us back a couple of years to lock down.

233
00:29:39,520 --> 00:29:44,889
That's certainly one of the places that seemed most salient to me. I think the theory here is straightforward.

234
00:29:44,890 --> 00:29:49,870
You've got an infectious disease. At that point, we didn't have vaccination, a very good control mechanism.

235
00:29:50,110 --> 00:29:53,380
What do you do? You lock people down to limit transmission.

236
00:29:53,530 --> 00:29:58,150
We've known how to do this for centuries. What's the tradeoff?

237
00:29:59,410 --> 00:30:07,420
Reducing disease burden of the population versus massive impacts on the economy, on learning, on jobs, on socialization, etc.

238
00:30:08,620 --> 00:30:13,640
So that tradeoff. Everybody saw the trailer.

239
00:30:13,730 --> 00:30:16,520
It's not like anybody was, like, surprised by this.

240
00:30:17,180 --> 00:30:26,900
But some people oriented towards the collectivist value of let's protect society, protect each other, and we're willing to absorb those costs.

241
00:30:27,140 --> 00:30:31,880
Other people were, like much more individualistic, aligns with much more.

242
00:30:32,890 --> 00:30:36,850
Flight. You can't deprive me of my right to do my the things that I want to do.

243
00:30:36,880 --> 00:30:49,150
You're destroying my business, etc. And a willingness to accept the idea that there would be health costs in order to preserve that autonomy.

244
00:30:50,690 --> 00:30:52,730
Well, maybe some people.

245
00:30:53,030 --> 00:31:04,310
I don't want to say we did, but certainly there were statements made pretty bluntly about, you know, so some people saying, you know,

246
00:31:04,850 --> 00:31:10,940
we're just going to have to absorb, expect a certain number of people are going to die in order to continue to have, you know, our economy.

247
00:31:13,620 --> 00:31:20,890
And whether you fundamentally disagree with that or not, it is a reflection of that worldview they have.

248
00:31:20,910 --> 00:31:26,100
It's not that they're not understanding, it's the values that are being placed on these different outcomes.

249
00:31:29,430 --> 00:31:36,719
Yeah, I think one of the challenges too is like my timing in terms like election year of like we're midway because

250
00:31:36,720 --> 00:31:41,280
like then there was just like people out there like putting this narrative that it's like an entire hoax.

251
00:31:41,400 --> 00:31:46,830
Yeah. Um, which I thought was, like, really interesting, particularly working in the hospital and like,

252
00:31:47,220 --> 00:31:55,170
having people like ICU nurses who are catering for COVID patients all day and firmly believe that COVID was a hoax.

253
00:31:56,700 --> 00:32:04,770
And I think that was, like, just mind boggling to me. So it's worth reminding ourselves of.

254
00:32:07,510 --> 00:32:16,290
Fretless. I remember early on in the course I talked about the affect.

255
00:32:16,330 --> 00:32:23,110
Interesting the idea that perceptions of risks and perceptions of benefits are just way off against each other,

256
00:32:23,110 --> 00:32:25,180
but it didn't really related to each other.

257
00:32:25,900 --> 00:32:34,750
And that we assume for the most part inaccurately that things that have higher benefits have low risks and vice versa.

258
00:32:36,130 --> 00:32:40,030
So when we start talking about denial.

259
00:32:41,200 --> 00:32:47,409
What always comes to my mind is the question of is that a denial of the risk or is that just a perception

260
00:32:47,410 --> 00:32:54,370
of such massive benefits that they're completely unwilling to engage in the idea that the risk exists?

261
00:32:55,960 --> 00:33:00,520
And we can look at this from an economic standpoint, you can look at it from a social standpoint.

262
00:33:00,520 --> 00:33:12,040
If you fundamentally have an affinity for a particular candidate from their perspective and their perspective is hope, it is a hoax.

263
00:33:12,700 --> 00:33:18,980
It can be very hard for you to. Knowledge the risk because it comes at such a cost on the other side.

264
00:33:19,790 --> 00:33:28,250
I think we saw that in a variety of places. So that's one that's another component to this whole mess.

265
00:33:30,440 --> 00:33:33,680
While we're talking about 20, 20 and early stages of COVID.

266
00:33:35,390 --> 00:33:38,510
Lots of you mused about stuff related to crisis communications.

267
00:33:40,700 --> 00:33:44,030
And yes, I think it is pretty straight forward to acknowledge that.

268
00:33:45,590 --> 00:33:51,139
There was a fundamental disconnect between the fact that we had these guidance for how to do crisis

269
00:33:51,140 --> 00:33:57,380
communications and what actually was done at most levels of the U.S. government about crisis communications.

270
00:33:58,850 --> 00:34:09,169
So that's that's certainly one take away. But I also want to remind us of the connections to some of the things that we were talking about

271
00:34:09,170 --> 00:34:14,210
in September and October when we were talking more about data and we're talking about a crisis.

272
00:34:14,960 --> 00:34:18,770
So let's talk about the data communications, of course.

273
00:34:21,220 --> 00:34:23,980
What have we what have we seen from data communications?

274
00:34:25,190 --> 00:34:31,370
But we may not be paying attention to now, but at least for some period of time was a big part of what was being communicated.

275
00:34:31,790 --> 00:34:44,150
Yeah. Flattening the curve at what exactly was the curve that needed to be flat was COVID cases per 100,000.

276
00:34:44,990 --> 00:34:49,950
Right. So case counts. Try to take yourself back.

277
00:34:49,950 --> 00:34:56,880
Remember how much of the news was? Then say I got three cases of Italian found in Michigan type of stuff.

278
00:34:58,180 --> 00:35:03,690
We left out three cases. All the cases is what happened in this class started like, who cares?

279
00:35:04,210 --> 00:35:10,810
But at that point in time, it was national news when there were three identified cases in a particular state.

280
00:35:14,410 --> 00:35:17,209
Then we got to the point of tracking this over time.

281
00:35:17,210 --> 00:35:22,930
And so we started to move towards this idea of, Oh, look, it's accelerating up, we've got to flatten the curve.

282
00:35:23,500 --> 00:35:30,480
And that language of trying to leverage the data pattern as motivating people to take it seriously.

283
00:35:32,190 --> 00:35:40,830
I will also just flag. One of things you brought up was the idea of rates per rates per 100,000 rates per million, whatever.

284
00:35:41,580 --> 00:35:45,270
What are the more subtle data problems of COVID was?

285
00:35:45,270 --> 00:35:50,730
Initially, what we had was just numbers, but there had been 42 cases.

286
00:35:52,090 --> 00:36:00,000
So obviously 42 cases in California is different than 42 cases in North Dakota given population.

287
00:36:00,510 --> 00:36:09,120
And so there was a fairly blinded shift in the in the communications around COVID rates from absolute count into rates.

288
00:36:11,460 --> 00:36:15,610
And you can go back and look at what The New York Times was reporting or other news outlets was reporting,

289
00:36:15,610 --> 00:36:21,670
and they sort of like woke up to the fact that they needed to stop talking about absolute rates and start talking about rates per whatever.

290
00:36:22,420 --> 00:36:28,800
And that the data. I mean. New York Times, Johns Hopkins University.

291
00:36:28,880 --> 00:36:36,960
Like, there are websites that have been running continuously for two and a half years that were hugely important in terms of sources of data.

292
00:36:38,040 --> 00:36:43,259
That was a fascinating development. I don't think I've ever seen anything like that in public health communications before.

293
00:36:43,260 --> 00:36:52,860
Calvin Ham. You know, the idea of the New York Times coronavirus map being a easily recognizable reference.

294
00:36:54,050 --> 00:36:57,880
Yeah. I think also with um, like some of the changes, like the frequency of communication,

295
00:36:57,890 --> 00:37:02,850
like my undergrad universities, the email is like every Friday with like how many cases there was like that.

296
00:37:03,290 --> 00:37:08,120
And I don't think like any universities like do that anymore, but their sales cases are just not.

297
00:37:08,360 --> 00:37:17,810
So it's interesting you bring this up. I long ago subscribed to the New York Times daily newsletter about covered counts.

298
00:37:18,890 --> 00:37:25,310
And it was really valuable to me over the past couple of years watching them go up and down and thinking of the patterns,

299
00:37:25,310 --> 00:37:29,000
etc. And over the past couple of months I have found myself.

300
00:37:30,360 --> 00:37:33,580
Disconnected from my daily email like.

301
00:37:33,660 --> 00:37:40,020
Yeah. Okay. There's a number like, uh. Like. Something about that data no longer feels useful to me.

302
00:37:41,100 --> 00:37:46,950
Um, I think it's because I don't trust that number anymore.

303
00:37:47,670 --> 00:37:54,719
With the advent of home testing, I no longer confident that these daily case counts are actually representing the paranoia of.

304
00:37:54,720 --> 00:37:58,500
Of. Volume of cases in a given location.

305
00:37:58,830 --> 00:38:02,190
Although I will say it was interesting to note that right after Thanksgiving,

306
00:38:02,730 --> 00:38:07,830
the statistics for Washtenaw County spiked and it just started to come back down.

307
00:38:09,020 --> 00:38:18,730
Yeah. I get the hospital update. And they give you still give you the breakdown of who's sick and who's in the ICU.

308
00:38:18,760 --> 00:38:25,390
Basically, an ICU number is the only one I pay attention to because I think that's just more concerning.

309
00:38:26,380 --> 00:38:31,570
Well, at the current moment, it's certainly more concerning because we know it's not just COVID that's driving that number,

310
00:38:31,580 --> 00:38:35,890
but we've got RSV cases, we've got flu cases, etc.

311
00:38:37,480 --> 00:38:41,290
But yeah, I mean, I remember. I remember when.

312
00:38:41,300 --> 00:38:44,720
So because I have a dry appointment in internal medicine,

313
00:38:44,720 --> 00:38:52,940
I got flagged on the all department emails when the first big wave of COVID hit and they were like

314
00:38:53,480 --> 00:39:01,430
that far away at Michigan Medicine from setting up a field hospital in the athletic department.

315
00:39:02,210 --> 00:39:05,960
Field, field, just like, you know,

316
00:39:07,310 --> 00:39:14,570
like they had already wired it for electricity and they were pretty damn close to opening it before it finally took it down.

317
00:39:17,230 --> 00:39:19,540
But you're right, that kind of data has a different role.

318
00:39:20,770 --> 00:39:28,890
It's less about tracking in that context, what's happening in society and more about tracking about, okay, so what do we have to do for operations?

319
00:39:28,900 --> 00:39:35,290
And so that's another piece of data. Yes. You know, I think something about the like New York Times dashboard that's interesting in my experience,

320
00:39:35,290 --> 00:39:39,189
is that I used to talk over it, but now I feel like I have more experiential knowledge.

321
00:39:39,190 --> 00:39:42,909
So I'm like, it's the holidays, you know, I'm going to be more careful.

322
00:39:42,910 --> 00:39:49,420
Like, I know people are congregating indoors and I saw what happened last year and that feels like that gives me

323
00:39:49,420 --> 00:39:55,800
enough like that experiential knowledge helps me decision make more than like a New York Times COVID dashboard.

324
00:39:55,810 --> 00:40:00,790
So that's a great point and it's a really useful one as we think about the value of this course.

325
00:40:02,050 --> 00:40:07,959
When we don't have experience, we have to fall back on analytical knowledge, on the data,

326
00:40:07,960 --> 00:40:13,900
on the instructions that we're given, etc., which is poor and it's imperfect and people read a different way.

327
00:40:14,830 --> 00:40:16,450
How do like you I mean, at this point,

328
00:40:17,470 --> 00:40:23,590
I'm not going to change what I do that much based upon data because I already feel like I have a sense as to what where the risk is,

329
00:40:23,590 --> 00:40:27,790
how to manage that risk, what I'm willing to do, what I'm not willing to do, etc.

330
00:40:27,800 --> 00:40:35,200
Our experience with risk has given us that lived knowledge that.

331
00:40:36,480 --> 00:40:43,650
Ways is more than analytical communications, which goes back to the larger point of low and behold,

332
00:40:46,410 --> 00:40:49,739
there are lots of situations in which risk communication is not necessarily going

333
00:40:49,740 --> 00:40:54,600
to be very effective in changing behavior because people already have knowledge,

334
00:40:54,600 --> 00:40:56,220
they have lived experience, etc.

335
00:40:57,450 --> 00:41:05,330
If what you want to do is to change habituated behavior, throwing more numbers at people is not necessarily going to be an effective way to do that.

336
00:41:06,870 --> 00:41:15,959
Yeah. I think one of the other interesting things that the data about COVID has done is often times make people more cognizant of other

337
00:41:15,960 --> 00:41:22,890
sorts of data in terms of I think it's how many people now actually watch flu data a lot more than you would have before COVID,

338
00:41:22,890 --> 00:41:26,310
because there's that sense of more significance of,

339
00:41:26,310 --> 00:41:30,540
oh, what if even influenza, which we're so used to dealing with,

340
00:41:30,720 --> 00:41:35,520
does turn into a big situation like the other day when you maybe some other

341
00:41:35,520 --> 00:41:40,229
people thought that Michigan was still in the green for some reason in flu,

342
00:41:40,230 --> 00:41:44,150
it was like, Oh, look, we're doing good. Yeah.

343
00:41:45,730 --> 00:41:51,580
And it's interesting for certainly for me to see those markers of, you know, compared to some other states,

344
00:41:51,580 --> 00:41:58,240
Michigan is not having as bad of a time in terms of infectious diseases, in terms of COVID, in terms of RSV, etc.

345
00:41:58,570 --> 00:42:04,540
And at the same time, I know that the hospital over there is full of full to the bursting point.

346
00:42:07,910 --> 00:42:18,050
Earlier this week, one of my friends who was in internal medicine said they had 68 patients waiting for a bed in the emergency department.

347
00:42:20,240 --> 00:42:28,730
68 patients takes this bath, and that's a reflection of the prevailing rates of disease.

348
00:42:31,490 --> 00:42:36,900
All right. A few more things I want to hit. Oh, yeah.

349
00:42:36,950 --> 00:42:42,420
Let's talk about the vaccine. Then take us back in time.

350
00:42:43,770 --> 00:42:46,830
First of all, no vaccine. Yikes. What do we do?

351
00:42:46,860 --> 00:42:52,470
We want to get the vaccine here as quickly as possible. All of that sort of like how fast can this thing be developed?

352
00:42:52,770 --> 00:42:59,070
Stuff and the tension that that brought up within us about, do I trust this?

353
00:42:59,100 --> 00:43:05,040
Is it safe? Are we being experimented on, etc. from the novel?

354
00:43:06,500 --> 00:43:15,739
Of getting a vaccine that fast. I think this is a really important thing because it shifted from like, oh,

355
00:43:15,740 --> 00:43:19,640
we have to get a vaccine really fast to like, whoa, that was developed really fast.

356
00:43:19,650 --> 00:43:27,730
And I really believe that they did a terrible job communicating of, Hey, we've actually been working on this technology for ten years.

357
00:43:28,070 --> 00:43:35,360
It didn't just happen in the last nine months. Well, and so there's the technology piece, but there's also the.

358
00:43:37,330 --> 00:43:45,040
Transparency, please. So what I really wish would have happened was greater discussion of.

359
00:43:46,590 --> 00:43:51,540
Here are the things we're doing. Here's the type of testing we're doing.

360
00:43:51,550 --> 00:43:53,560
Here's what happened next. Here's what happened next.

361
00:43:53,560 --> 00:44:01,030
It's telling that story because the fact is, we are there were things that were speeded up you could never read,

362
00:44:01,030 --> 00:44:04,059
like, okay, so we already had done lots of this development work.

363
00:44:04,060 --> 00:44:09,100
So we're able to take this technique which we have been working on before now and apply it here.

364
00:44:09,820 --> 00:44:20,020
But also there was in many contexts essentially cutting out of it within this strain of burden as opposed to cutting out of relevant science.

365
00:44:21,160 --> 00:44:26,080
My favorite example of this, which is an unfortunate example, but it's a really good one,

366
00:44:27,370 --> 00:44:32,980
I talked with you guys about the Australian vaccine, I think I have.

367
00:44:33,050 --> 00:44:41,170
Okay. So flash back to the time when there was no vaccine and there were lots of different vaccines in development.

368
00:44:41,500 --> 00:44:46,149
I mean, now we sort of have to use Pfizer or Moderna. Most of the other stuff, at least in the U.S.,

369
00:44:46,150 --> 00:44:52,299
we don't spend much time talking about the fact that everybody it was a race like lots of different companies,

370
00:44:52,300 --> 00:45:03,520
lots of different groups were trying to develop vaccines, including a kind of group based at the University of Queensland in Australia developing

371
00:45:03,520 --> 00:45:07,900
a they were sort of the only group in Australia for you to develop a COVID vaccine.

372
00:45:09,240 --> 00:45:15,240
And one of the things that they did in Australia because of the sort of speed question.

373
00:45:16,200 --> 00:45:20,240
Normally, what would you do? You develop a vaccine and then you put it through trials.

374
00:45:20,580 --> 00:45:23,790
And then after you prove that it's safe and you prove that it's effective,

375
00:45:23,790 --> 00:45:30,570
then and only then do you commit yourself to producing it and you buy it and you spend all the money to develop it.

376
00:45:31,380 --> 00:45:35,880
And the Australian Government understandably said we don't have time to do that.

377
00:45:36,210 --> 00:45:39,840
And they committed to making it before the trials were done.

378
00:45:43,640 --> 00:45:49,730
And the sad story of that COVID vaccine is that it was.

379
00:45:50,690 --> 00:46:00,850
Unlike the Pfizer and Moderna ones using our revenue and our Emiratis, it was more like the Johnson Johnson vaccine.

380
00:46:00,860 --> 00:46:05,870
It was using a more traditional delivery pathway.

381
00:46:07,690 --> 00:46:09,990
When you do that, you have to attach it.

382
00:46:10,620 --> 00:46:20,609
You have to attach sort of the genetic code associated with whatever it is you want your immune system to react to, to something else to.

383
00:46:20,610 --> 00:46:23,850
And I'm going to put you to the science here, but the gist you'll get.

384
00:46:24,980 --> 00:46:35,120
And they made the choice. To attach the relevant genetic material essentially to a.

385
00:46:38,350 --> 00:46:41,560
A virus similar to HIV.

386
00:46:43,780 --> 00:46:52,000
It was very effective Ikaria, and it provoked strong immune responses to COVID 19 vaccination and COVID 19 antibodies.

387
00:46:52,480 --> 00:47:02,630
It looked great. Except when they ran people in the trial, people who got the vaccine started testing positive for HIV.

388
00:47:03,720 --> 00:47:12,570
Even though they didn't have HIV because the genetic material was there, which would have totally messed up all kinds of things.

389
00:47:13,110 --> 00:47:17,940
And so they killed that entire line of vaccine development.

390
00:47:18,390 --> 00:47:25,630
And the Australian government. I think it was something like threw away.

391
00:47:26,920 --> 00:47:36,040
5000 gallons of vaccine that had already been developed in several tens of millions of dollars of investment, just essentially dumped it.

392
00:47:37,470 --> 00:47:40,860
That was the attempt to move fast. But it's a different kind of thing.

393
00:47:40,860 --> 00:47:45,899
Like when they talk about that case in Australia, they're like and the system worked like,

394
00:47:45,900 --> 00:47:52,890
we didn't give this to anybody outside of the trial we went through, we did all of the testing, etc. The cost was financial.

395
00:47:53,940 --> 00:48:01,710
It was not about safe. But that's an example of like we could have had a much better conversation about.

396
00:48:02,950 --> 00:48:09,450
All the things that were already being done about safety. But what was basically left was, here's our vaccine game.

397
00:48:09,610 --> 00:48:12,860
Don't you want to get it? And that wasn't enough.

398
00:48:17,500 --> 00:48:27,590
What else did I want to make sure that I had to do? You know.

399
00:48:27,700 --> 00:48:31,420
Let's go there. Trust.

400
00:48:34,880 --> 00:48:40,280
My lack of trust from what's unfolded in terms of culture.

401
00:48:42,450 --> 00:48:47,120
You certainly are talking about lack of trust in the CDC in a way that we were not three years ago.

402
00:48:50,180 --> 00:48:57,960
We have. Questions about government response and future pandemics.

403
00:49:00,720 --> 00:49:05,870
So a couple of you explicitly raised this and several of you sort of touched upon that a different way.

404
00:49:06,990 --> 00:49:10,230
Where we go from here. We are here. We are in tow.

405
00:49:10,410 --> 00:49:14,130
We're about to be in 2023. I hope it is part of our history.

406
00:49:15,930 --> 00:49:24,330
If we are representing public health and medicine and desiring people to want to hear our communications moving forward.

407
00:49:26,430 --> 00:49:34,960
What do we do? Any thoughts? And this could be with regards to specific populations or just more generally.

408
00:49:44,540 --> 00:49:52,849
Everybody's like, I don't know how I can just say that like I get one major positive came out of it is that it made a lot

409
00:49:52,850 --> 00:49:59,350
of people in the general public across the board just pay attention like public health s like things.

410
00:49:59,350 --> 00:50:04,399
So because like one of the readings talked about how like the CDC is funding was kind of gutted in the

411
00:50:04,400 --> 00:50:09,740
last presidency and I was actually part of the problem that our being able to address the COVID concerns.

412
00:50:11,660 --> 00:50:18,260
I think just that like kind of the advocacy part of it is just trying to make sure that we're actually more well equipped for the next time.

413
00:50:19,390 --> 00:50:24,290
So. Yes. I'll add two pieces.

414
00:50:24,290 --> 00:50:31,580
One regarding of public health funding definitely predates the Trump administration, although it was certainly worsened during that.

415
00:50:31,970 --> 00:50:42,560
If you look at the historical trends, they go back. I mean, you can remember in the speech that I gave the H1N1 CDC briefing,

416
00:50:42,950 --> 00:50:49,280
the CDC director mentions the cuts to public health that it occurred in the 2008 2009 recession.

417
00:50:50,390 --> 00:50:56,200
Those issues had been prevalent even before that, although I do agree with you, like we have responded to some degree.

418
00:50:57,860 --> 00:51:02,580
The other thing I'll say is. I have some degree of worry.

419
00:51:03,870 --> 00:51:10,269
That that will continue. As coverage moves from the thing that we are immersed in,

420
00:51:10,270 --> 00:51:17,589
that we are thinking about all the time to this thing that we sort of just are done with the funding.

421
00:51:17,590 --> 00:51:23,480
The motivation for funding may go away, too. And so a good question is, have we learned some lessons?

422
00:51:23,500 --> 00:51:27,220
Are there things that will be kept permanently and well funded moving forward,

423
00:51:27,730 --> 00:51:31,290
or are we just going to sort of spike up in funding and then spike back there?

424
00:51:32,020 --> 00:51:36,200
I certainly hope not, but we have to acknowledge that. So.

425
00:51:36,200 --> 00:51:39,530
Yeah, that's one. One thing that did certainly evolve.

426
00:51:39,560 --> 00:51:42,740
What else? Like, how do we think about support? You know,

427
00:51:43,370 --> 00:51:48,560
are there lessons that we can take from the mess that was the roll out of COVID

428
00:51:49,070 --> 00:51:54,980
response that we can change moving forward that might help trust the next time.

429
00:52:02,750 --> 00:52:09,620
So I would say like maybe communication, like consistent or not.

430
00:52:11,620 --> 00:52:15,400
But even if they might, two different sources. Having different information.

431
00:52:15,800 --> 00:52:22,350
Like being more like. I'm on way. I'm not hearing one thing from one thing,

432
00:52:22,350 --> 00:52:28,680
one group of people and hearing another thing and not being able to follow which one, not what you actually should do.

433
00:52:29,580 --> 00:52:32,309
There's so many different opinions on what should be done.

434
00:52:32,310 --> 00:52:36,990
Like you should go get these, the queen, or you should know the basically what you should be drinking it like.

435
00:52:36,990 --> 00:52:41,639
It was just so many different avenues of where to go and who to believe that.

436
00:52:41,640 --> 00:52:46,800
I don't think people. I think people just like leaving what they thought because there were so many other opinions.

437
00:52:46,980 --> 00:52:52,020
So in an alternative world, which we did not live through.

438
00:52:54,290 --> 00:53:04,220
I might have wished that the CDC could have stepped into that role right at the start and said,

439
00:53:04,520 --> 00:53:07,520
you're going to hear a lot of things, a lot of people are going to have an opinion.

440
00:53:08,270 --> 00:53:16,220
But what we're going to try and do is to be first and be here and be the central gathering point of information.

441
00:53:17,210 --> 00:53:20,450
And it's going to have to change because obviously things are going to change.

442
00:53:21,410 --> 00:53:28,490
But to sort of give that anchor point of saying, you know, look here first, we didn't get that.

443
00:53:28,700 --> 00:53:34,250
And as a result, once there were so many different perspectives being talked about, it's difficult to then pull people back.

444
00:53:35,480 --> 00:53:41,300
But this is part of the motivation for that. Be first, be credible kind of mindset from the these materials.

445
00:53:41,450 --> 00:53:44,839
It's not just that you have to be part of the conversation,

446
00:53:44,840 --> 00:53:50,720
but because you're creating that anchor point of where do people where will people turn when they don't know who to believe?

447
00:53:55,120 --> 00:54:00,320
And. We can try and play that role moving forward.

448
00:54:00,890 --> 00:54:06,320
How likely we will be able to succeed depends in part on politics, depends in part upon our state of knowledge.

449
00:54:07,160 --> 00:54:09,650
But one of the things I hope you take away from this course is.

450
00:54:10,630 --> 00:54:17,500
When there are these moments, just how important it is to be there, to be available to say,

451
00:54:17,500 --> 00:54:21,010
I am going to try to play this role because people may then turn to you.

452
00:54:21,490 --> 00:54:23,980
And by the way, I don't just mean this for public health officials.

453
00:54:24,460 --> 00:54:33,580
I mean this for each of us individually, in our social networks, in all in the places that we have influence.

454
00:54:34,150 --> 00:54:39,970
Because there will always be, from this point forward in your lives, people who will turn to you and say, hey, you're in public health.

455
00:54:40,300 --> 00:54:50,730
What do you say? And you, I hope, will take ownership of that role, because even if all you do is say,

456
00:54:50,730 --> 00:54:55,680
I don't know what, let me go to the place that you trust to get that information.

457
00:54:55,680 --> 00:54:59,550
You will be a difference in the information that's out there in the community.

458
00:55:03,150 --> 00:55:10,710
So yeah, that's one piece. Another piece that I think is that I have taken away from it is a realization of how much?

459
00:55:14,760 --> 00:55:17,899
We can talk about. Miscommunication.

460
00:55:17,900 --> 00:55:23,870
We can talk about communication at the society level, but how much of it is at the door to door level?

461
00:55:25,390 --> 00:55:29,740
And that individual personal connection between, you know,

462
00:55:29,740 --> 00:55:34,899
the person in your community and you on that particular topic, whether it's a health care provider,

463
00:55:34,900 --> 00:55:41,320
whether it's your peers, you know, the person who does your hair or whether you're a religious leader,

464
00:55:41,890 --> 00:55:51,040
that each of those people have a role to play in this context. Certainly, if we think about the COVID 19 vaccine rollout, where it worked.

465
00:55:52,560 --> 00:55:59,850
Best where the locations where that kind of community level engagement was present and people

466
00:55:59,850 --> 00:56:04,350
were willing to meet people where they were and have the conversations needed to be had.

467
00:56:06,780 --> 00:56:10,740
One other thing I do think we take away from it is the value of that kind of community based work.

468
00:56:19,310 --> 00:56:30,720
I will say one other thing about trust before I let go of that one. Public health doesn't like to make mistakes.

469
00:56:32,560 --> 00:56:43,300
But I think we have to. I think the next time we can't just go in and assume the people are going to trust us.

470
00:56:43,310 --> 00:56:51,950
We have to acknowledge that the last time wasn't so great and then all of that and move forward because the.

471
00:56:54,690 --> 00:56:57,750
In him in much the same sense of talking about uncertainty.

472
00:56:59,400 --> 00:57:01,650
I think if the next time we come up with.

473
00:57:03,020 --> 00:57:08,010
You know, some infectious diseases in which we're trying to track case counts, that we don't know how serious it is.

474
00:57:08,610 --> 00:57:14,700
If we acknowledge, hey, this was really hard back when we were talking about COVID 19 and here's what we're going to try and do,

475
00:57:15,000 --> 00:57:18,460
but we know it's going to be hard. That may be able to help.

476
00:57:21,010 --> 00:57:29,130
And just like Salman says in terms of being. Human in terms of acknowledging uncertainty, in terms of speculation,

477
00:57:29,610 --> 00:57:33,780
I think being willing to acknowledge the uncertainty of of most of what we do when we're

478
00:57:33,780 --> 00:57:39,360
talking about risk is is probably key to reengaging people and building their trust in us.

479
00:57:46,540 --> 00:57:51,630
All right. The last thing I want to say about COVID. Xena.

480
00:57:53,320 --> 00:57:55,809
You read something in your music that I thought was interesting.

481
00:57:55,810 --> 00:58:02,470
You talked about I forget who it was you're referring to, but the desire for a forceful, forward communication.

482
00:58:03,040 --> 00:58:07,240
Oh, yes. Like one of The New York Times opinion pieces.

483
00:58:07,900 --> 00:58:11,700
She let me just put up so I don't know.

484
00:58:11,710 --> 00:58:19,270
But. Like she was critiquing the CDC's response within their own framework.

485
00:58:19,280 --> 00:58:21,290
And then at the end she said something like.

486
00:58:25,220 --> 00:58:33,470
Like crises, she says a pandemic requires a forceful, quick, clear and unified response from public health authorities.

487
00:58:33,470 --> 00:58:39,740
And I think I was just reflecting on how, like, maybe at the beginning of the course, I wouldn't have really batted inside that wording.

488
00:58:39,740 --> 00:58:46,520
And then like I think thinking about the context of like the Sandeman dilemmas, I was kind of taken aback by the word forceful.

489
00:58:46,790 --> 00:58:50,570
So what does forceful mean to you? What do you think she's trying to communicate?

490
00:58:50,960 --> 00:58:56,990
I think I don't know. Like exactly like I think that's why I was like, what does that actually look like and what does that mean?

491
00:58:59,170 --> 00:59:03,380
Like does that mean that there is like more like police surveillance of, like, activity?

492
00:59:03,390 --> 00:59:08,400
Like, I don't know what that means exactly, but, like, it kind of just is concerning.

493
00:59:10,810 --> 00:59:16,180
I'll tell you what my reaction is. Not that I have any personal inside of.

494
00:59:18,730 --> 00:59:23,080
One aspect of it, I think is the first idea. Like, we can't just.

495
00:59:24,690 --> 00:59:29,749
Be active in communicating. We need to be proactive. We need to put ourselves out there, be part of the conversation.

496
00:59:29,750 --> 00:59:41,220
And so that part doesn't bother me. Forceful often, though, has overtones of paternalism, of directness of.

497
00:59:41,510 --> 00:59:49,070
I would tell you what to believe or what to do as distinct from I'm going to empower you to understand and make individual choices.

498
00:59:49,580 --> 00:59:54,320
And that part, I do have a problem. I think we've learned a lot about how that kind of.

499
00:59:56,260 --> 01:00:03,130
Directive approach, especially in the context of uncertainty, runs into significant problems.

500
01:00:03,370 --> 01:00:06,680
So. I agree.

501
01:00:07,220 --> 01:00:13,930
That's a good thing to take away and wrestle with it like. For the next thing and there will always be a next thing.

502
01:00:14,500 --> 01:00:18,850
How do we what does it mean for us to be proactive?

503
01:00:19,910 --> 01:00:24,770
And where do we need to be acknowledging the fact that not everybody is going to agree with us?

504
01:00:29,630 --> 01:00:32,690
Yeah. Said just the word forceful.

505
01:00:32,690 --> 01:00:35,600
Yeah. Like, kind of strikes me as almost being authoritarian. Yeah.

506
01:00:35,780 --> 01:00:43,820
Like that they you there should be like one central idea or person figurehead that kind of, like, paints the picture for you.

507
01:00:45,260 --> 01:00:53,329
Yeah, like, I have a huge problem with that, with that word. But I think like, but, but some people associate that with like a quicker response time.

508
01:00:53,330 --> 01:00:58,760
I think that that's like what they're trying to go for is that if you if you could just in one sense,

509
01:00:59,180 --> 01:01:05,000
you know, if we if we delegated communication to that large bureaucracy, stuff doesn't move fast.

510
01:01:05,120 --> 01:01:15,340
And we had this conversation about U of M before, like the. Disseminated authority does not lead to clear or quick communication.

511
01:01:16,540 --> 01:01:22,300
So I mean let's bring up how she was 4G authoritarian.

512
01:01:26,340 --> 01:01:33,750
Like people have very varying responses to the role that he has ultimately played in the in our perspectives about this pandemic.

513
01:01:36,070 --> 01:01:41,979
And part of that is what role he could play in a context in which it was pretty

514
01:01:41,980 --> 01:01:45,340
clear that there was information that was being suppressed is one context.

515
01:01:45,340 --> 01:01:50,470
And what role he has been playing in the situation since the turn over in the political leadership is different.

516
01:01:51,340 --> 01:01:51,870
But either way,

517
01:01:51,910 --> 01:02:01,920
like the fact that we have the fact that I can say one word 4G and every one of you know who's who I mean and why I'm talking about it is interesting.

518
01:02:03,240 --> 01:02:12,030
We had one human being running, you know, being a major source of our information around in a global pandemic.

519
01:02:14,440 --> 01:02:18,970
As opposed to a system in which many different sources or many different government

520
01:02:19,210 --> 01:02:24,820
spokespeople were given equal kind of respect or trust or value in the communication process.

521
01:02:26,910 --> 01:02:31,780
I have lots of mixed feelings about this. Yeah, that's a good question.

522
01:02:33,270 --> 01:02:42,499
Or am I in time? Okay. So the only other thing I really want to bring up in the context of COVID, which we've touched upon a little bit,

523
01:02:42,500 --> 01:02:52,730
but it's worth making sure that we build a connection with mental models. What was our mental model of COVID when we first?

524
01:02:53,900 --> 01:02:58,190
Heard about it. We didn't know. Maybe we could get it by touching something.

525
01:02:58,190 --> 01:03:02,090
Maybe we could only get it if somebody coughed at our face, etc.

526
01:03:02,360 --> 01:03:09,470
So there's been at least one shift in mental models from the contact transmission to the airborne transmission.

527
01:03:14,590 --> 01:03:19,450
Key mental model idea. How far away are the social distance?

528
01:03:21,870 --> 01:03:27,530
Six feet. Six feet. That's a piece of mental model.

529
01:03:28,460 --> 01:03:34,370
Are you safer indoors or out? So outdoors. Outdoors.

530
01:03:35,030 --> 01:03:40,909
I'm just I'm aware of how much my consciousness of my indoors and my outdoors is.

531
01:03:40,910 --> 01:03:45,800
That window open is the window not open is fundamentally different now than it was three years ago.

532
01:03:46,700 --> 01:03:53,450
Like, I take off my mask the moment I walk outside because I feel safer.

533
01:03:53,690 --> 01:04:00,180
And my mental model of transmission is really salient to environment now in a way that it never was before.

534
01:04:00,200 --> 01:04:06,580
The colder. And there are problems with people's different mental models.

535
01:04:10,380 --> 01:04:13,560
You know, we had mental models about maps, our masks about protecting.

536
01:04:13,560 --> 01:04:20,340
You were protected by the other person. It's both.

537
01:04:20,370 --> 01:04:23,460
But think back to the original communications around masks.

538
01:04:23,790 --> 01:04:28,620
Much of them was not about individual protection. It was about community to prevent the community spread.

539
01:04:29,610 --> 01:04:36,930
We had, for the most part, at least from my perspective, lost that that vast have fallen back into much more of an individual protection context.

540
01:04:37,470 --> 01:04:47,080
You wear it, you don't wear it. But it's for you, not for somebody else. All of that is mental models, communication.

541
01:04:48,970 --> 01:05:00,680
Like. I'm remembering contexts in which you're like, Well, can I stand next to my friend when we're outside and have a conversation?

542
01:05:00,950 --> 01:05:07,510
Is that safe or not? Type stuff. Which is, again, a mental models piece.

543
01:05:07,570 --> 01:05:12,580
And we were desperate for this. Like, I remember being like, well, okay, I can't be next to you here,

544
01:05:12,580 --> 01:05:18,890
but we can talk if we're like hearing that, like we were making daily decisions about what was within a door.

545
01:05:18,910 --> 01:05:26,280
Not okay to do based upon building a mental model out of the the morass of information that we were being given.

546
01:05:30,090 --> 01:05:36,620
And. Notice how that translated into real world?

547
01:05:37,860 --> 01:05:43,920
Costs and experiences sold. Where are there clear plastic dividers between things?

548
01:05:44,640 --> 01:05:50,700
That's driven off of mental models. How far apart are the tables in your restaurant or the desks at the school?

549
01:05:51,420 --> 01:05:55,800
Like the green dots that are on some of these desks.

550
01:05:57,300 --> 01:06:04,540
We're an attempt at one point in time to say, you can sit here, you can't sit here, or to establish the social distancing spacing.

551
01:06:08,200 --> 01:06:13,600
All of which was driven off of somebodys mental model of what was going to be sufficiently safe versus not.

552
01:06:16,540 --> 01:06:24,850
The fact that we're even talking about things like. How much air circulation is in a building.

553
01:06:27,140 --> 01:06:33,110
It's actually an interesting shift. Like, I've never thought about air circulation as being something driving a lot of infectious risk.

554
01:06:33,620 --> 01:06:36,620
And now I actually have real thoughts about,

555
01:06:37,610 --> 01:06:45,620
you know is my fan on and how is it safer or not safer here when we're sitting in this room and the windows are closed versus the windows are open.

556
01:06:47,890 --> 01:06:52,840
That's more mental model peace, which we may or may not take away from this moving forward.

557
01:06:52,840 --> 01:06:55,360
But it's part of the experience that we got.

558
01:06:55,660 --> 01:07:02,290
We spent a lot of time figuring out what should my mental model of When am I safe and when am I not look like?

559
01:07:06,240 --> 01:07:11,780
All right. Of. But you can go back to we can keep going on this.

560
01:07:12,230 --> 01:07:16,850
But the where I wanted to end up and Sarah is not here today.

561
01:07:17,270 --> 01:07:22,240
She had to miss this last class. But I think she put in her music, which I think is a good place to end this discussion.

562
01:07:22,250 --> 01:07:29,100
Is this. Where are we now?

563
01:07:30,520 --> 01:07:33,220
A lot of people stopped wearing masks in different contexts.

564
01:07:35,480 --> 01:07:41,940
Much of the societal changes in terms of physical, you know, we're allowed to do are not allowed to do it.

565
01:07:41,940 --> 01:07:45,050
But back to what we used to do before COVID.

566
01:07:47,690 --> 01:07:50,870
What is permanent or are we back to square one?

567
01:07:51,550 --> 01:07:55,880
Like, is the world different now because of the experiences we've had?

568
01:07:56,390 --> 01:07:57,500
And if so, in what way?

569
01:07:57,500 --> 01:08:02,570
What do you think is actually going to stick for the next five years or ten years in terms of the way in which we think about infectious disease?

570
01:08:04,250 --> 01:08:06,739
Or let's be honest,

571
01:08:06,740 --> 01:08:13,790
if we think that there are some things that have just gone back to where we were and that there's no permanent change lost on that to go,

572
01:08:13,970 --> 01:08:24,530
where do you think we are at this point? I think there's a lot more diligence that still exists about being sick.

573
01:08:25,200 --> 01:08:28,079
There's an understanding that you probably shouldn't come to class and go to work.

574
01:08:28,080 --> 01:08:32,190
And I know that's not like sweepingly acceptable, but that's a lot more acceptable now.

575
01:08:32,190 --> 01:08:34,400
And I live with five people and like if someone,

576
01:08:34,420 --> 01:08:40,770
someone will text if they have like a sore throat and mask and go get a COVID test, and it's kind of just like no questions asked.

577
01:08:41,040 --> 01:08:43,799
Yeah, that's a good one. I like that. I do think you're right.

578
01:08:43,800 --> 01:08:50,590
I think there is an a greater awareness of if you're sick, you stay home on both the individual side and organizations.

579
01:08:50,650 --> 01:08:54,780
Like tolerance for somebody being working from home, etc. is different.

580
01:08:55,460 --> 01:09:05,610
Um, and things like the idea that we should be paying attention to our health and not just like,

581
01:09:05,610 --> 01:09:09,600
oh, I'll just, I got to be there anyway, so I don't care if I'm calling on everybody.

582
01:09:10,500 --> 01:09:21,390
Speaking of which, did I see something about Jenna Ortega being having COVID while she was filming the dance scene?

583
01:09:23,670 --> 01:09:27,470
Like they found out right after the scene that she tested positive. She knew that she tested.

584
01:09:27,480 --> 01:09:33,060
They didn't get the results until after scene was filmed. Okay. So just giving her medicine like what?

585
01:09:33,120 --> 01:09:37,260
Every day. But the reason I bring it up is notice our outrage.

586
01:09:37,500 --> 01:09:40,410
Notice the sort of emotional response to. Wait a second.

587
01:09:40,800 --> 01:09:46,440
There was a thing here that I don't think anybody would have reacted to the same way had it been occurring pre-COVID.

588
01:09:47,160 --> 01:09:54,210
So that's that's I think that's an example of sort of the kind of societal perspective about what is okay or not okay to do in shifting social norms.

589
01:09:54,960 --> 01:09:59,370
Yes, I was going to say, I mean, I can't speak for the population as a whole because obviously,

590
01:09:59,370 --> 01:10:03,580
like, I'm a very different case than the general population that we all live in.

591
01:10:03,780 --> 01:10:10,140
Yeah, I'm like, I don't think I will ever go on an airplane or go to a concert again without wearing a mask,

592
01:10:10,150 --> 01:10:17,310
like be around a close proximity to a bunch of random strangers and not wear a mask like I don't think I'll ever go back.

593
01:10:17,490 --> 01:10:20,880
Yeah, cause I just. You don't know, you have no idea what's out there.

594
01:10:20,890 --> 01:10:23,969
And as you know, as you were bringing up earlier,

595
01:10:23,970 --> 01:10:29,820
like we now have a society where having someone wear a mask is not quite so like, whoa, what's going on?

596
01:10:30,300 --> 01:10:37,290
It's more, Oh, okay, you're wearing a mask. And that creates the opportunity for individual choice.

597
01:10:37,290 --> 01:10:42,840
A The same kind of thing that you're talking about. I'm, by the way, very much similar to you. I don't think I'm ever going to play like that yet.

598
01:10:43,710 --> 01:10:52,200
So he doesn't sound like a someone. I became a see and I during COVID and then I'm working as a tech now at the hospital.

599
01:10:52,890 --> 01:10:57,180
And sometimes I joke around with like the older people who are like and working in health care for a while.

600
01:10:57,180 --> 01:11:02,190
I'm like, How do you ever do this without a mask? I cannot imagine doing this job without a mask.

601
01:11:02,190 --> 01:11:07,410
And most people that I talk to say like, I don't see myself ever taking it off like at work again.

602
01:11:08,400 --> 01:11:16,400
It's a different mental model, a perception of an environment, a context as now being worth protecting yourself against.

603
01:11:16,410 --> 01:11:21,930
And you have a pathway to do that. Fact, I wasn't even just not nervous.

604
01:11:21,930 --> 01:11:23,339
It just was like a pure prevention method.

605
01:11:23,340 --> 01:11:30,569
But also it wasn't like, I guess like me personally, when I'm symptomatic with anything I would if I have to go out somewhere,

606
01:11:30,570 --> 01:11:33,330
I would rather wear a mask cause I don't want to give it to someone else.

607
01:11:33,340 --> 01:11:41,060
Like I like I think that that has become much more culturally accepted now and like in the United States, whereas like other regions of the world,

608
01:11:41,070 --> 01:11:48,809
it was such a for a long time and like, ah, I guess like what Andrew just said about like, like going on a plane.

609
01:11:48,810 --> 01:11:49,150
Like, yeah,

610
01:11:49,170 --> 01:11:55,499
like I really can't imagine going on a plane without wearing a mask at this point in time just because I had to sit next to someone I don't know.

611
01:11:55,500 --> 01:11:59,370
And it's like a particularly symptomatic with pretty much anything.

612
01:11:59,370 --> 01:12:09,629
I would just I'll say one of the things that has changed for me is the idea that I don't just have to get

613
01:12:09,630 --> 01:12:17,400
sick part of the year but haven't navigated a whole winter season and basically not got sick through it all.

614
01:12:18,300 --> 01:12:25,680
I remember coming out of it and that's that and like, Oh, I don't actually have to be sick every other week or something like that.

615
01:12:26,160 --> 01:12:30,990
There is another alternative which has changed my perspective about health,

616
01:12:32,520 --> 01:12:37,470
the personal benefit of that, but also the potential to to limit spread of.

617
01:12:38,520 --> 01:12:43,500
Other things that come up. Are you thinking about the future? Yeah.

618
01:12:44,490 --> 01:12:49,320
Like virtual options. Yeah. For better or for worse.

619
01:12:49,330 --> 01:12:56,530
Yeah. I certainly think differently about travel.

620
01:12:57,130 --> 01:13:00,820
I do. I have to go someplace. Or can I just use somebody?

621
01:13:01,930 --> 01:13:09,669
The fact that we use Zoom as a verb. I mean, it's like Kleenex, like.

622
01:13:09,670 --> 01:13:14,380
And we've got just the brand name to. To a universal term.

623
01:13:17,640 --> 01:13:20,219
But yeah, that's another thing that's that's different.

624
01:13:20,220 --> 01:13:28,820
And I mean, all of us like the fact that I'm not supposed to bring myself into the office for faculty meetings.

625
01:13:28,840 --> 01:13:35,520
Like. Really? Yeah.

626
01:13:36,000 --> 01:13:39,120
Do you think there's going to be an increase or have you seen an increase in like people

627
01:13:39,120 --> 01:13:43,050
entering like MPH programs like more people are interested in public health now.

628
01:13:45,810 --> 01:13:56,000
That is a complicated question. I fear.

629
01:13:57,400 --> 01:14:01,480
That what we're going to see is a lot of what we've seen is a short term sort of.

630
01:14:03,110 --> 01:14:08,190
Awareness Spike, but. It is also uncovered.

631
01:14:09,750 --> 01:14:13,230
Some of the flaws in the public health career pathway.

632
01:14:15,120 --> 01:14:21,370
I don't want to impress you, but it is it is still.

633
01:14:21,540 --> 01:14:30,620
The challenges of COVID and all of the public health crises that we are facing are a mixed emotional bag, let's just put it that way.

634
01:14:30,630 --> 01:14:34,440
Like, yeah, they're big, they're important, and we might rise to meet them.

635
01:14:34,440 --> 01:14:38,820
We also our firsthand knowledge of some of the limitations of what can be done.

636
01:14:39,990 --> 01:14:45,299
I don't know. I hope that the as Max was talking about earlier,

637
01:14:45,300 --> 01:14:51,390
that what we will bring up is a greater financial commitment to greater societal commitment to prevention,

638
01:14:51,390 --> 01:14:57,570
to public health issues, etc., and that that will support a larger public health workforce moving forward.

639
01:14:58,590 --> 01:15:02,879
I don't know if I'm just kind of on that subject.

640
01:15:02,880 --> 01:15:08,670
So I, I mean, a piece that's coming on the perspective. I know, but my roommate is a class representative.

641
01:15:08,670 --> 01:15:13,590
And I know you heard from one of the administrators for Lester's cohort, you know,

642
01:15:13,710 --> 01:15:17,310
admitting students last spring and such on the applications were actually down.

643
01:15:17,860 --> 01:15:23,099
But the applications have been it's in those complicated patterns, let's just put it that way.

644
01:15:23,100 --> 01:15:28,140
And I'm admissions chair, so I see them very, very personally. It's hard to unpack.

645
01:15:29,280 --> 01:15:35,309
The motivational side from the financial side, from the booming economy.

646
01:15:35,310 --> 01:15:37,500
So you have lots of options side.

647
01:15:38,730 --> 01:15:46,470
So again, I don't know how to I think there's too much packaging at this current moment to really have a clear sense, at least from my perspective.

648
01:15:47,910 --> 01:15:51,450
Now, on that note, I would also say that like in general across the country,

649
01:15:51,450 --> 01:15:58,829
admissions and like all underground and everything is down and especially at like expensive or elite institution.

650
01:15:58,830 --> 01:16:01,170
But you're seeing more people go to like state schools and community college.

651
01:16:01,200 --> 01:16:07,020
Well, the demographic shifts I mean, this is a total tangent, which I will say 30 seconds on and then get off of.

652
01:16:08,400 --> 01:16:18,959
Academia is facing a demographic list. The birth rates show that there are going to be vastly fewer people certainly getting into undergrad,

653
01:16:18,960 --> 01:16:22,560
and then that's going to cascade into graduate school over the course of the next decade.

654
01:16:22,560 --> 01:16:26,639
And everybody knows it's coming and nobody knows what to do about it. That my second point.

655
01:16:26,640 --> 01:16:34,140
Sorry, that like I unfortunately don't think that there is really going to be much change like public health infrastructure,

656
01:16:34,140 --> 01:16:37,410
like just working at like a local health department over the summer,

657
01:16:37,410 --> 01:16:43,739
like they were just like mass layoffs because all the CDC funding for COVID is just like gone now.

658
01:16:43,740 --> 01:16:52,559
And I just don't see that there is like this continued investment and there's still like a lot of expectations to be doing a lot of this COVID work,

659
01:16:52,560 --> 01:16:56,880
which is not a part of the initial role of the health department before 2020.

660
01:16:57,690 --> 01:17:01,049
And yet now we're taking away all the additional staff, all the additional funding,

661
01:17:01,050 --> 01:17:03,960
and then telling everyone to go back to like normal operations plus COVID.

662
01:17:04,650 --> 01:17:11,730
So I feel like it's kind of a challenge and unfortunately I don't see it being more positive after this.

663
01:17:12,540 --> 01:17:19,259
I have mixed feelings. I think there are ways in which we may eventually sort of like it will dip down and then people will go, okay, that's not good.

664
01:17:19,260 --> 01:17:22,320
And then maybe. But we're not. This is politics.

665
01:17:23,190 --> 01:17:28,830
Quick thought. Yeah, I was just going to say I would be wary of that because I think there will be a lot of private investment in it.

666
01:17:29,190 --> 01:17:36,990
Like I think you've seen an explosion of this idea of corporate wellness, which I think will make up for some of that in some regards.

667
01:17:37,680 --> 01:17:44,669
Well, there's certainly very broad shifts in terms of expectations of who is doing what in both very negative ways,

668
01:17:44,670 --> 01:17:48,660
like piling on on top onto local health departments is certainly part of it.

669
01:17:48,930 --> 01:17:53,710
I also agree that there are certain ways in which. Some types of public health.

670
01:17:54,010 --> 01:18:00,070
Certainly risk management work has been shifted for better and for worse, into the private sector.

671
01:18:00,400 --> 01:18:05,170
Like insurance. Yeah, that's one. All the leveling stuff.

672
01:18:05,410 --> 01:18:11,860
Like we were having more conversations about sort of like voluntary industry labeling as being something.

673
01:18:11,950 --> 01:18:16,870
Anyway, we're running out of time, so I just want to take the last few minutes to sort of pull this all together.

674
01:18:19,870 --> 01:18:29,830
This is a smorgasbord of topics, this course. We started by talking about perceptions and the idea that you have that all of us are always.

675
01:18:30,850 --> 01:18:39,459
Analytical people trying to use our rational brains and thinking about stuff and these animalistic, emotional,

676
01:18:39,460 --> 01:18:46,360
experientially driven perceptions of, you know, that are the same thing as the is there a tiger by the watering hole?

677
01:18:47,680 --> 01:18:53,700
You know, was it did I get a ticket the last time I drove? Did I get sick the last time I got a shot in me kind of stuff?

678
01:18:55,440 --> 01:18:58,830
That's not different. People are different things that everybody has both.

679
01:19:01,600 --> 01:19:09,310
One of the big lessons of this course that I hope you take away is that giving people the number is not the end of the story.

680
01:19:11,110 --> 01:19:14,590
Contextualize it. Think about the value ability.

681
01:19:14,620 --> 01:19:21,760
Think about what am I comparing this against? Recognize that most people aren't particularly numerate.

682
01:19:22,630 --> 01:19:27,100
They need you to do the math for them. They need you to limit the number of numbers they have to look at, etc.

683
01:19:27,760 --> 01:19:30,999
So this idea which is prevalent in both public health and medicine,

684
01:19:31,000 --> 01:19:38,800
that our job is done when we give you the number is a problem and you now have tools to try and guard against that.

685
01:19:40,460 --> 01:19:45,710
You've gotten a lot from the crisis stuff. I can see that in today's discussion and the way in which you've talked about it.

686
01:19:46,400 --> 01:19:52,129
But don't forget the mental model stuff. Like there's a lot that can be learned by just sort of thinking about what is

687
01:19:52,130 --> 01:19:56,450
that critical insight that will help somebody live their life in a safer way.

688
01:19:56,480 --> 01:20:08,059
For me, with COVID, it was the inside outside idea, the idea that in a space in which the air is going to move a lot,

689
01:20:08,060 --> 01:20:13,490
I didn't need to be worrying it in a space in which I was to be crammed close to somebody and there air wasn't going to be moving.

690
01:20:13,490 --> 01:20:17,720
I did. And what I choose to do has been really influenced by that.

691
01:20:18,050 --> 01:20:21,770
You may have different things that influenced you, but take away that idea.

692
01:20:23,000 --> 01:20:30,500
The part of our purpose is not necessarily to tell you, do this, don't do that, or to tell you your risk is some number.

693
01:20:30,890 --> 01:20:39,430
But to give you the insight to make that connection. And.

694
01:20:41,370 --> 01:20:45,930
And lastly. But.

695
01:20:50,600 --> 01:20:54,260
When you teach a team to drive, which I have now done twice.

696
01:20:55,730 --> 01:21:03,920
One of the things that I try and make sure to bring up is to remind somebody that when you hand them a keys to a car,

697
01:21:03,920 --> 01:21:10,190
you are handing them the keys to a killing machine. There is enormous power.

698
01:21:11,940 --> 01:21:19,080
In a car. It can be used for very good things and it can be extremely dangerous if you are not careful.

699
01:21:20,360 --> 01:21:23,600
I am handing you the keys to a communication car.

700
01:21:25,960 --> 01:21:36,130
I am handing you a tool box that can manipulate people's perceptions, can bias them to motivate them to do whatever you think you want them to do.

701
01:21:38,450 --> 01:21:42,800
Use it well. On the responsibility that comes with this.

702
01:21:43,160 --> 01:21:55,059
This is just as much of an intervention as a drug is. I believe that the tools I'm giving you can be used for really important and good purposes.

703
01:21:55,060 --> 01:22:00,670
And I trust if your goals are the fact that you are here and your engagement in this course.

704
01:22:00,970 --> 01:22:05,799
But don't forget that ethical responsibility I said once earlier in this course,

705
01:22:05,800 --> 01:22:11,380
and I mean, I can make anybody afraid of a number or relieved by it without changing it.

706
01:22:12,680 --> 01:22:15,620
And I remember that every day when I work on risk communication.

707
01:22:16,550 --> 01:22:23,540
So take what you can from this, and I hope you find it valuable wherever you go in your career.

708
01:22:24,440 --> 01:22:28,550
And if, as you progress, you find things that you're like, Oh, this is really interesting,

709
01:22:28,970 --> 01:22:32,450
feel free to shoot me the email and drop me a line and say, Hey, take a look at this.

710
01:22:32,450 --> 01:22:37,310
Is this cool or have you believe they did this? Those are just as valuable to me, by the way.

711
01:22:37,400 --> 01:22:44,560
So feel free to send it my way. And otherwise, I will look forward to seeing your papers next week.

712
01:22:44,570 --> 01:22:46,640
I hope you have a good break. Stay safe.

713
01:22:47,540 --> 01:22:53,500
Thanks for sharing much of those courses dependent upon your willingness to share your personal stories or perspectives.

714
01:22:54,360 --> 01:23:16,610
I've enjoyed it and I hope you answered. And now I'm like, I don't know.

715
01:23:16,640 --> 01:23:24,850
The first time I was like, Yeah, we're in the front office, and I didn't think I was like The end.

716
01:23:25,430 --> 01:23:34,880
That was like, I don't want to bother. And I was like, Yeah, I just know that I was hired.

717
01:23:35,260 --> 01:23:54,580
Maybe I was like, Oh, I, it was time and I don't look like I said, okay, well, I know it's a white elephant, don't want to think about it,

718
01:23:54,690 --> 01:24:12,050
but I just thought it would be like pointing out what's a few things that I guess would be a profession for sure.

719
01:24:12,510 --> 01:24:17,600
Exactly. Okay. Yeah.

720
01:24:20,060 --> 01:24:24,560
Well, I think it's like.

721
01:24:26,100 --> 01:24:42,310
Yeah, yeah. I mean, I feel another time sleeping and honestly, it's like you start working on,

722
01:24:42,510 --> 01:24:47,909
you know, topically, cause they don't get publicity for earrings at all.

723
01:24:47,910 --> 01:24:57,620
Really? Well, they do have a lot of options, but I like, I w I love it, but it's like.

