1
00:00:00,340 --> 00:00:14,290
It's easy there. You know, I really like it because I really do feel like a real person.

2
00:00:15,120 --> 00:00:26,820
So now the teacher is not working. You kind of get that. Make it easier just to get to the bathroom.

3
00:00:28,880 --> 00:00:33,950
Okay. Okay. I'll try and get out of there.

4
00:00:34,310 --> 00:00:37,430
Happy Friday, everybody. We'll go ahead and get started.

5
00:00:38,060 --> 00:00:42,080
I apologize for the the few minute delay I had to get myself situated.

6
00:00:43,250 --> 00:00:53,250
I had put together a couple of PowerPoint slides just for today's class and forgot to put them on Dropbox for myself.

7
00:00:53,810 --> 00:00:57,379
And I also forgot to put them on canvas, not just more to guide me.

8
00:00:57,380 --> 00:01:06,680
And it had a few discussion questions at the end. So I have my like I have a couple of them in the in last week's lecture.

9
00:01:06,680 --> 00:01:15,320
So if we need them, we'll have them for today. But anyway, I wanted to make a couple of quick announcements.

10
00:01:15,650 --> 00:01:19,180
I updated I made like a couple of small updates to the syllabus.

11
00:01:19,190 --> 00:01:24,380
I had mentioned it a couple of weeks ago where just around the timing of the abstract.

12
00:01:24,980 --> 00:01:28,760
I just put some specifics on like due dates for the abstract in the review.

13
00:01:29,660 --> 00:01:37,400
That's not for a while. It's like in November. And then the reviews are due early December, like around the 1st of December.

14
00:01:38,540 --> 00:01:45,409
So those dates are highlighted like any of the changes I made in the syllabus are highlighted in that new version that's on canvas.

15
00:01:45,410 --> 00:01:58,090
So let me know if you have trouble seeing that. Second thing is I posted in the module for today, I posted the feedback form.

16
00:01:59,210 --> 00:02:01,790
And so if you wouldn't mind during today's talks,

17
00:02:02,090 --> 00:02:08,570
downloading that form and just filling out some comments that your peer presenters will find helpful.

18
00:02:09,140 --> 00:02:12,760
And then if you can submit those on the Google form.

19
00:02:12,930 --> 00:02:17,120
Did did any of you did you get the Google form that I shared?

20
00:02:17,150 --> 00:02:20,200
Did it come to your on email? Yeah. So there should be two.

21
00:02:20,200 --> 00:02:25,040
Should there be one for Kristen and one for Layla? Separately. So I'm going to do it.

22
00:02:25,220 --> 00:02:30,680
Last year I did it through canvas and it was a huge pain because of the way the system is set up.

23
00:02:30,680 --> 00:02:38,959
It's really hard for me to like get them off campus and share them. So I think the Google the Google format is going to be a little easier.

24
00:02:38,960 --> 00:02:44,390
So I can take the information from that Google form and share that with each of the presenters.

25
00:02:45,980 --> 00:02:51,860
So anybody cannot get those not get that invite should have come through everybody's email.

26
00:02:52,670 --> 00:02:56,900
Okay, good. A couple other quick things.

27
00:02:57,200 --> 00:03:01,630
I mentioned this talk from Amy. Amy, I don't know how to pronounce her last name.

28
00:03:01,650 --> 00:03:08,330
Q Do you carry the talks about body language and how how our own body language

29
00:03:08,330 --> 00:03:14,690
affects our our own sort of self confidence and in feelings of powerful ness or,

30
00:03:14,900 --> 00:03:20,720
or feelings of not being powerful. It was a really inspiring TEDx talk for me.

31
00:03:21,620 --> 00:03:26,660
And then she also has a book titled Presence, and some information on that is here.

32
00:03:27,320 --> 00:03:36,170
And I also really enjoyed that book because she talks a lot about some interactions she had with with people who were really renowned scientists

33
00:03:36,170 --> 00:03:45,770
in her field and how she let her anxieties about and fears about how they were perceiving her really get in the way of her ability to like,

34
00:03:45,770 --> 00:03:58,130
talk about her science with them. And she gives a lot of really helpful strategies for interacting with people in a way that that promotes confidence.

35
00:03:59,720 --> 00:04:07,340
I think that is all of the announcements I had. So we have two lightning talks today, Lila and Christian.

36
00:04:07,340 --> 00:04:12,370
I don't know which one of you want to go first. Does it matter to you?

37
00:04:12,410 --> 00:04:16,790
Okay. So I'll let one of you if you want to.

38
00:04:18,680 --> 00:04:24,150
All right. So the the PowerPoint talks are just here minimized.

39
00:04:24,870 --> 00:04:27,950
I'll go ahead and let you take over for the talks.

40
00:04:28,910 --> 00:04:32,180
I know we have a little bit of extra time today because there's only two people presenting.

41
00:04:33,350 --> 00:04:39,470
But I will go ahead in the interest of, you know, making sure everybody stays roughly on the time.

42
00:04:40,340 --> 00:04:47,090
I'll set a timer. And when it gets to the four minute mark, I'll just, like raise my hand and not be too distracting.

43
00:04:47,090 --> 00:04:50,569
But just so you know that you have about a minute left and I won't, like,

44
00:04:50,570 --> 00:04:55,700
yell at you and cut you off if you're not right at the five minute mark before you go, like, way over.

45
00:04:56,300 --> 00:05:01,200
Right. Thank you. Yeah, I don't get it. But you didn't get the Google form invite.

46
00:05:01,220 --> 00:05:04,910
Okay. Do anybody else not get it? I think I did.

47
00:05:05,550 --> 00:05:10,640
Okay, I'll share it. I'll share them with you if you want to email me.

48
00:05:11,480 --> 00:05:15,800
And then I'll have a record of who didn't get one. If anybody didn't get it, just email me and I'll.

49
00:05:15,920 --> 00:05:18,980
I'll share the forms through email. Sorry about that.

50
00:05:19,310 --> 00:05:22,370
Yeah, they got rains and land barrels. There's only two.

51
00:05:22,400 --> 00:05:27,940
Yeah, there should be just the two, right? Yeah. The first place to look the other way.

52
00:05:29,650 --> 00:05:34,290
Yeah, the form is on canvas. Oh, yeah.

53
00:05:34,310 --> 00:05:40,730
And keep it down open. Yeah. Let me know. I, I haven't set up a Google form like this before, so that's why I was a little nervous.

54
00:05:41,140 --> 00:05:47,770
I'm sure it works. Thank you. Everyone ready?

55
00:05:50,710 --> 00:05:58,300
Hi, everyone. My name is Layla Land Arrows, and I'm a first year M.S. student here at the University of Michigan School of Public Health.

56
00:05:58,690 --> 00:06:02,559
And today, I'll be sharing with you some of my past research.

57
00:06:02,560 --> 00:06:08,440
I just graduated from Wheaton College with a degree in environmental science and urban studies.

58
00:06:08,920 --> 00:06:13,630
And so I haven't completed any real research yet since I'm just a first year,

59
00:06:14,050 --> 00:06:20,920
but I will be sharing with you instead just some past introductory research that I did during my undergrad experience.

60
00:06:21,370 --> 00:06:28,329
Now, the purpose of this research project was not to discover any new sort of information that could eventually be published,

61
00:06:28,330 --> 00:06:33,850
but it was more of to conduct my own research project from start to finish,

62
00:06:33,850 --> 00:06:40,840
write a paper on it and present on it later to get the whole experience during my undergraduate career.

63
00:06:41,530 --> 00:06:47,050
So the title of my project is called The Elemental Analysis of Urban Road Dust and Nearby Soil.

64
00:06:48,460 --> 00:06:52,240
So road dust contains many natural elements that are found in soil,

65
00:06:52,540 --> 00:06:56,799
but also contains metals and metalloids that are a threat to human health and can

66
00:06:56,800 --> 00:07:02,410
impact cardiovascular and respiratory cause cardiovascular and respiratory disease.

67
00:07:03,070 --> 00:07:08,170
So the dust contains soil, like I said, but also can contain traffic related emissions,

68
00:07:08,170 --> 00:07:16,659
natural nearby industrial source elements, etc., which can really cause a lot of problems, especially though for the urban poor.

69
00:07:16,660 --> 00:07:24,100
So we in college is close to Chicago. And so I lived on the south side of Chicago, which is why I was passionate about this project.

70
00:07:24,460 --> 00:07:27,460
I know that a lot of kids play in the street all the time.

71
00:07:27,580 --> 00:07:30,160
There's a ton of road work all the time in Chicago,

72
00:07:30,460 --> 00:07:36,880
so all those road workers are inhaling the dust constantly, which is why I think this project is significant.

73
00:07:37,030 --> 00:07:40,750
There has been a lot of published work on road dust inhalation in the past,

74
00:07:41,020 --> 00:07:48,850
which is where I got a lot of my ideas for this project and it was able to help make conclusions based off previously published research.

75
00:07:50,110 --> 00:07:57,310
So that main idea of my project was to determine what elements are found in nearby road dust and soil.

76
00:07:58,720 --> 00:08:06,380
So the methods I used were I collected road dust samples manually and through a street sweeper in the weekend area.

77
00:08:07,030 --> 00:08:13,989
I was in collaboration with the city and they were able to share their road dust from the street sweepers itself.

78
00:08:13,990 --> 00:08:18,220
This was really helpful because you get a lot of road dust, you get a large amount.

79
00:08:18,700 --> 00:08:22,210
However, you don't really know exactly where that sample came from.

80
00:08:22,480 --> 00:08:31,080
So pros and cons to that method. I also collected samples manually with just a dustpan and a brush through my research experience.

81
00:08:31,240 --> 00:08:34,990
Research readings. There's no one way to collect road dust.

82
00:08:36,040 --> 00:08:41,530
Some researchers used street sweepers. Some people actually did do the dust and brush method.

83
00:08:41,800 --> 00:08:49,810
People used vacuums. So because of that, I was okay with this variation in sample collection and I also collected soil samples.

84
00:08:50,380 --> 00:08:57,130
This picture here is just a very zoomed in idea of where I collected samples close to the college

85
00:08:57,130 --> 00:09:03,520
with the purple dots being dust collection sites and yellow stars means soil collection sites.

86
00:09:04,840 --> 00:09:14,990
The soil was then dried in the oven at 105 degrees Celsius and then ignited in a muscle furnace at 540 degrees Celsius.

87
00:09:15,010 --> 00:09:21,760
Now, the purpose behind igniting our samples in a muscle furnace is to burn off any remaining carbon in the samples.

88
00:09:22,060 --> 00:09:27,250
So we have a stronger concentration of other elements that are found in our samples.

89
00:09:28,300 --> 00:09:37,060
As for quantitative analysis, the main point behind this project was to learn how to use x ray for x ray fluorescence or x RF analysis.

90
00:09:37,660 --> 00:09:42,310
X ray fluorescence is a method for analyzing elemental composition.

91
00:09:43,120 --> 00:09:50,770
So I do use x, RF and analyze the spectrum that were generated through my sample.

92
00:09:50,780 --> 00:09:59,740
So here's just an example of the peaks that are formed of the elements that are found in my sample that the x ray fluorescence were able to pick up.

93
00:10:00,610 --> 00:10:09,460
So after analysis I was able to just make a quick conclusion about what was found in my limited amount of samples.

94
00:10:09,880 --> 00:10:17,350
On the left we have the overall analysis results, but on the right I performed a principal component analysis,

95
00:10:17,350 --> 00:10:23,379
which means I removed calcium from the data sample. Just because calcium was so large.

96
00:10:23,380 --> 00:10:28,780
It was overwhelmingly the biggest sample in my the biggest element in my samples.

97
00:10:29,080 --> 00:10:34,240
I wanted to see if there was anything else significant. So hence the principal component analysis.

98
00:10:36,470 --> 00:10:47,330
Basically I was able to conclude very introductory that there was other components to the road dust than just natural elements.

99
00:10:47,690 --> 00:10:55,790
Geologically, we do expect there to be calcium, iron, magnesium and silica in road deaths just because it's so close to the earth.

100
00:10:56,210 --> 00:11:02,060
However, since we did see higher amounts of calcium, iron and magnesium specifically,

101
00:11:02,480 --> 00:11:11,180
we can just say that I can make the prediction that this could be because calcium is from tire use on the cars.

102
00:11:11,210 --> 00:11:19,400
Iron can be from car, brake housing and brake pads, and magnesium is significantly found in aggregate based materials.

103
00:11:19,730 --> 00:11:23,389
Now, I can't make this conclusion from just my limited resource research,

104
00:11:23,390 --> 00:11:30,560
but other papers that I based my research off were able to make similar conclusions after their extensive projects.

105
00:11:31,100 --> 00:11:42,270
So thank you. So we have about 5 minutes of the question and answer.

106
00:11:42,540 --> 00:11:45,720
So maybe yes, I may pull back up.

107
00:11:47,310 --> 00:11:55,700
Yeah, interesting presentation. And I was curious, you've said that a few elements, including calcium, were higher than expected.

108
00:11:55,920 --> 00:12:02,940
Yeah, I do. Like. So you collected the sample from a specific location.

109
00:12:03,810 --> 00:12:08,810
You know, I wonder how it compares as compared to other locations, if that has been.

110
00:12:09,300 --> 00:12:13,950
Right. And I'm I was specifically wondering, so I was in the suburbs of Chicago.

111
00:12:13,950 --> 00:12:22,410
I think for future research, it'd be interesting to compare in the actual city of Chicago, since this is where my main concern started from.

112
00:12:22,710 --> 00:12:26,070
So I'm actually not sure how it does compare.

113
00:12:26,460 --> 00:12:30,630
I just know I just remember looking, comparing it to papers, research papers.

114
00:12:30,630 --> 00:12:35,940
That was my main comparison for conclusions that this was a higher amount of calcium.

115
00:12:36,240 --> 00:12:44,820
However, it's also hard geologically because we do expect calcium to be in this earth and then also whether it makes a big difference.

116
00:12:45,090 --> 00:12:50,190
This these samples were collected during the transition season between fall to winter.

117
00:12:50,520 --> 00:12:52,560
So there was more moisture in the ground.

118
00:12:52,920 --> 00:13:00,240
So if these samples were collected right after summer, we would get a better higher dust concentration because there wasn't much runoff then.

119
00:13:01,230 --> 00:13:04,890
So future research ideas. Thanks. Yeah. Yeah.

120
00:13:05,100 --> 00:13:11,999
Good job. Thank you. Can you talk a little bit about how the amounts that you found in the soil translate to,

121
00:13:12,000 --> 00:13:16,800
like, a level that would like how this is attributable to human health concern?

122
00:13:18,000 --> 00:13:21,780
Yes. So I didn't really get into that in this project.

123
00:13:21,780 --> 00:13:26,819
But I think the idea is if we're seeing higher levels of calcium, iron and magnesium,

124
00:13:26,820 --> 00:13:32,180
then that are now, then are naturally found in the natural environment.

125
00:13:32,190 --> 00:13:36,660
That's a concern because that means those chemicals are coming from an outside source.

126
00:13:37,140 --> 00:13:47,760
So as I mentioned earlier, that could be in tires constantly on the ground, producing, leaving calcium elements behind iron and magnesium.

127
00:13:48,030 --> 00:13:54,930
And then those particles do travel down the lungs and are able to create cause disease later on.

128
00:13:55,110 --> 00:14:03,240
Is there a known metric for like, okay, this level is this level in road deaths specifically is like attributable to.

129
00:14:03,510 --> 00:14:07,020
There are but I'm just not that experienced yet. But in my papers.

130
00:14:07,020 --> 00:14:10,650
Yeah. And Dr. Vardaman here, he gets very into this, so.

131
00:14:12,060 --> 00:14:20,430
Yeah. Yes. Do you know why the tail of your spectrograph kind of leaves baseline at the end?

132
00:14:20,460 --> 00:14:29,580
Yeah, good question. So that was, I think the biggest learning experience for me in this project was learning how to analyze my spectra with X.

133
00:14:29,580 --> 00:14:35,430
Or if you want to analyze your spectra, I'm trying to get there to zoom in.

134
00:14:35,910 --> 00:14:39,690
There you go. So there's two ways you analyze your spectra.

135
00:14:39,690 --> 00:14:42,600
You first do it visually, just manually on your own.

136
00:14:43,050 --> 00:14:49,140
Because sometimes when you do it with the fundamental parameters, which is a setting within the software,

137
00:14:49,140 --> 00:14:58,410
which is the setting here, it kind of picks up on extra elements that weren't necessarily strong enough to consider.

138
00:14:58,890 --> 00:15:02,730
So, for example, this tail here, you mentioned this tail,

139
00:15:02,730 --> 00:15:06,900
I'm pretty sure I would have to look at the rest of the graph, but I think this is just noise.

140
00:15:07,380 --> 00:15:15,360
I don't think this is actually an element found, but sometimes like fundamental parameters, I wasn't doing that manually.

141
00:15:15,360 --> 00:15:18,959
They would say this is an element found and I know this is not an element.

142
00:15:18,960 --> 00:15:22,980
This is just noise because this here is a very high concentration of iron.

143
00:15:24,660 --> 00:15:29,320
So good question. Anything else.

144
00:15:31,270 --> 00:16:14,450
Okay. Thank you, everyone. Okay.

145
00:16:17,690 --> 00:16:21,679
All righty. Hello, everyone. My name is Christian Raines.

146
00:16:21,680 --> 00:16:27,799
I am an US master's candidate and today I'll be talking about my previous research experiences.

147
00:16:27,800 --> 00:16:30,830
I'm a first year, so I don't have a specific research project yet,

148
00:16:31,400 --> 00:16:37,940
so I'll talk about my previous experiences there overlap with public health and my future interest for research going forward.

149
00:16:39,650 --> 00:16:45,140
So my undergrad background is in biology and my first experience with research was fieldwork.

150
00:16:45,410 --> 00:16:51,650
I conducted surveys and I did a biological assessment to look at water quality and three different aquatic ecosystems.

151
00:16:52,160 --> 00:16:55,459
So I use fish because they are biological indicator species.

152
00:16:55,460 --> 00:16:59,690
I use fish to determine the overall health of different aquatic ecosystems.

153
00:17:00,290 --> 00:17:07,429
And I didn't work with humans for this project, but it was pretty helpful to really observe the relationship between an organism and the environment

154
00:17:07,430 --> 00:17:11,930
that it's in and the overall health of the environment and the ecosystem or the organism.

155
00:17:13,010 --> 00:17:19,910
And then after that, the most, the next significant research experience I had was working in pharmaceutical research and development.

156
00:17:20,420 --> 00:17:27,229
And the two takeaways I had from this experience was, one, the accessibility of medicine is extremely important,

157
00:17:27,230 --> 00:17:32,719
and I think it's really necessary to make these life changing medications affordable.

158
00:17:32,720 --> 00:17:37,550
So I worked at a pharmaceutical company that prioritized making generics and making affordable medication,

159
00:17:38,150 --> 00:17:43,010
and then also the importance of understanding occupational exposure for certain careers.

160
00:17:43,010 --> 00:17:49,280
People are more likely to be exposed to certain chemical hazards or just they're at a higher risk of these exposures.

161
00:17:49,280 --> 00:17:54,200
And it's necessary to make sure that they're aware of that and they can better protect themselves in these scenarios.

162
00:17:56,060 --> 00:18:01,850
So continuing with the relationship of an organism and the environment and also accessibility,

163
00:18:01,850 --> 00:18:06,050
my research interests going forward are environmental health disparities.

164
00:18:06,500 --> 00:18:12,110
I think it's extremely important to identify and assess or acknowledge these populations that are exposed

165
00:18:12,110 --> 00:18:17,750
to environmental hazards and in an unhealthy environment and disproportionately impacted by these hazards.

166
00:18:18,170 --> 00:18:22,549
It's necessary to recognize why these communities are being disproportionately impacted,

167
00:18:22,550 --> 00:18:26,870
whether it's socioeconomic status, race, gender, disability status,

168
00:18:26,870 --> 00:18:34,490
whatever the factor is, we need to acknowledge that and also find ways to prevent that or avoid these disparities in public health going forward.

169
00:18:35,300 --> 00:18:42,530
And then finding the most appropriate method or approach to address these disparities and make sure that we can make a difference with them.

170
00:18:43,760 --> 00:18:47,240
And then I put an example on here, just one that I think is pretty important.

171
00:18:47,360 --> 00:18:51,050
Vulnerable populations are disproportionately impacted by climate change,

172
00:18:51,470 --> 00:18:56,540
so communities of color or individuals are feeling the effects of climate change

173
00:18:56,540 --> 00:19:00,589
at a disproportionate rate than a lot of other conditions or other communities,

174
00:19:00,590 --> 00:19:05,480
because climate change really exacerbates conditions that are already existing in these populations.

175
00:19:07,430 --> 00:19:10,339
What is the significance of this research? Why does it matter?

176
00:19:10,340 --> 00:19:16,130
Why should people care from the perspective of social justice and with a goal of health equity?

177
00:19:16,490 --> 00:19:22,100
Everyone deserves access to good health in a healthy environment and everyone deserves equal access to that.

178
00:19:22,100 --> 00:19:29,330
Health at increasing the health of an individual leads to a healthier community overall,

179
00:19:29,360 --> 00:19:35,149
which leads to a healthier nation overall and can help to decrease the burden of our health care systems.

180
00:19:35,150 --> 00:19:40,370
And really just help the community be healthier in this research could potentially decrease

181
00:19:40,370 --> 00:19:44,060
the prevalence of these unhealthy environments and these barriers within public health.

182
00:19:46,590 --> 00:19:50,880
Future applications of this research. What can we do with this information once we have it?

183
00:19:51,300 --> 00:19:55,410
I think it will be helpful to identify gaps in our current system or processes.

184
00:19:56,190 --> 00:20:01,260
With research, we can identify areas that need to be studied a little bit more or need more funding.

185
00:20:01,690 --> 00:20:09,270
And example I have is just making health care systems more culturally competent so that they can best serve the communities that they're near.

186
00:20:10,050 --> 00:20:15,300
And then we can also find more efficient ways to educate or protect these vulnerable communities.

187
00:20:15,300 --> 00:20:20,070
If we can identify these disparities and find the populations that are being disproportionately impacted,

188
00:20:20,370 --> 00:20:24,330
we can educate them and help them take the steps they need to protect themselves.

189
00:20:24,990 --> 00:20:27,990
And lastly, an important application is just monitoring.

190
00:20:27,990 --> 00:20:33,090
These health disparities may help to mitigate or eliminate the hazard initially.

191
00:20:33,090 --> 00:20:41,490
So if we can watch the disparities and make plans to mitigate, we could potentially have less exposures over time going forward.

192
00:20:42,240 --> 00:20:47,160
And that's why I think environmental health disparities are a significant part of public health to study.

193
00:20:47,730 --> 00:20:50,820
And I will open it up for questions, comments or feedback.

194
00:20:58,590 --> 00:21:03,720
Do you have a specific area that you want to focus on or that you're specifically passionate about?

195
00:21:04,230 --> 00:21:12,420
I'm incredibly passionate about climate change just because it's such a huge issue and it impacts so many populations and so many levels.

196
00:21:12,750 --> 00:21:15,870
So if I had to choose one, I'd say for sure. Climate change.

197
00:21:16,980 --> 00:21:22,000
Yeah. I was wondering if you could talk a little bit more about your experience as the pharmaceutical company.

198
00:21:22,020 --> 00:21:27,210
Like if there was a particular anecdote or a like it's, you know,

199
00:21:27,540 --> 00:21:33,150
patient experience or something like that that really informed what you're talking about today.

200
00:21:33,330 --> 00:21:36,480
Yeah. So I'll speak just from a personal level.

201
00:21:36,510 --> 00:21:45,930
I worked a lot with solvents and different materials and I essentially had to read the label myself or know what I was working

202
00:21:45,930 --> 00:21:52,049
with to make sure I wasn't exposing myself or I needed to know if I needed extra PPE or if I needed to wear a respirator.

203
00:21:52,050 --> 00:21:55,230
I had to make sure I was reading and finding that out for myself.

204
00:21:55,230 --> 00:22:00,060
I don't know if it's necessarily as clear as it should be in some situations.

205
00:22:00,870 --> 00:22:05,340
And I think that's a big issue overall. And I'll leave it there.

206
00:22:06,240 --> 00:22:11,450
Does that answer? Yeah. Okay. Awesome. But what do you recommend?

207
00:22:11,910 --> 00:22:15,090
And then today, what company? Just period. Yeah, it's in Ohio.

208
00:22:15,090 --> 00:22:20,640
It's called American Region. I'm not sure. What do they what do they specialize in?

209
00:22:20,880 --> 00:22:25,230
So we did injectable solutions and it was generic.

210
00:22:25,230 --> 00:22:30,350
So one of our big products was triamcinolone.

211
00:22:30,360 --> 00:22:37,200
I see tonight. Yeah. So just kind of making injectable solutions and making a generic of already popular.

212
00:22:37,350 --> 00:22:40,889
Yeah, I was doing a products. Yeah, there works.

213
00:22:40,890 --> 00:22:46,620
And he was looking for someone who's got the pharmaceutical background.

214
00:22:47,060 --> 00:22:50,510
So yeah, it was really different from field work.

215
00:22:50,520 --> 00:22:56,640
It was, it was a huge shift actually. But even in both of them, I could see the overlap and importance of public health.

216
00:22:57,150 --> 00:23:09,299
So I think that was pretty cool. While you're talking about climate change made me think of there's a couple of investigators who are working

217
00:23:09,300 --> 00:23:17,130
on the effects of climate change and and heatwaves on cities and the health of people and in the cities.

218
00:23:17,290 --> 00:23:25,470
Yeah. And there's the Michigan Life Stage, Environmental Exposures and Disease Center.

219
00:23:25,680 --> 00:23:30,450
And they have they do a lot of work in that area related to climate change.

220
00:23:31,110 --> 00:23:40,790
And so Emily, it's called Emily. So Emily's scientists might be of interest, might be a good idea for me to talk to them.

221
00:23:40,800 --> 00:23:49,110
So I'll send you that awesome thinking. Also, Dr. Mary O'Neill, she's just had a brand new project and she meets people.

222
00:23:49,170 --> 00:23:57,570
Oh, awesome. Service in Detroit, public housing, place in Detroit, researching energy and quality of life.

223
00:23:57,920 --> 00:24:03,980
Okay. Yeah. Thank you. Yeah. That's it.

224
00:24:05,820 --> 00:24:09,380
Else cool. Thank you. Thank you.

225
00:24:22,440 --> 00:24:26,280
Okay. Yes.

226
00:24:26,280 --> 00:24:37,680
We just have a little bit of time left, so I think that we could, um, I'm gonna pull up the slide deck from last week because I had.

227
00:24:40,600 --> 00:24:52,069
Good discussion questions. I had ones with some initial with some additional ones that I thought were also interesting added on for today.

228
00:24:52,070 --> 00:24:55,190
But we'll table those for another time.

229
00:24:57,250 --> 00:25:00,650
Um, let's start with this one, I guess.

230
00:25:01,920 --> 00:25:11,140
So these are just a couple of kind of case studies slash discussion questions.

231
00:25:11,150 --> 00:25:16,250
These are the types of things you'll probably see in the responsible conduct and research class as well.

232
00:25:17,300 --> 00:25:23,300
And it goes hand in hand with with scientific communication and how you are communicating your data.

233
00:25:24,290 --> 00:25:33,160
And so this is a these are some based on actual, actual cases.

234
00:25:33,170 --> 00:25:40,850
And I can't remember which university has a repository of these case studies, but I pulled from pulled from there.

235
00:25:42,140 --> 00:25:49,150
So you are an ecologist. You and you choose to work on environmental issues because you care deeply about them.

236
00:25:49,160 --> 00:25:56,090
Your research shows that extinction rates are, in fact slower than researchers at Queen, which is fantastic.

237
00:25:56,690 --> 00:26:04,190
But you worry that your data is likely to be misused by logging companies and could support policies that increase deforestation rates.

238
00:26:04,850 --> 00:26:15,230
So the question is, do you present your data at a professional conference suspecting that it will be misused by people whose agenda you abhor?

239
00:26:15,980 --> 00:26:22,340
And so the yeah, so there's like a couple of potential answers you could think, yeah,

240
00:26:22,340 --> 00:26:28,280
scientists need to report whatever findings the data support and should always ignore political issues about how their data will be used.

241
00:26:28,730 --> 00:26:35,030
Or no, research does not take place in a political vacuum and you need to prevent possible misuse of your data.

242
00:26:35,400 --> 00:26:38,970
So does anybody have any thoughts on these?

243
00:26:40,970 --> 00:26:47,629
Um, I tend to agree with yes, uh, not necessarily that limited to this topic,

244
00:26:47,630 --> 00:26:53,209
but we also see a lot of people who have kind of some, you know, project whatever.

245
00:26:53,210 --> 00:26:56,360
And if their findings, I don't know, they tend not to produce it.

246
00:26:56,780 --> 00:27:00,400
Yeah. Like probably it. And then you don't know who has what then what.

247
00:27:00,620 --> 00:27:08,209
Yeah. And so I think like yes people are going to misuse it, they probably misuse it.

248
00:27:08,210 --> 00:27:13,100
But I think as a scientist should be able to counter that with the fact and you should not

249
00:27:13,100 --> 00:27:19,880
hold yourself back similar so that you me like that may be different from the other results.

250
00:27:20,150 --> 00:27:27,440
Yeah, I want to give an example. This is not related to scientific research, but it's in Australia I think.

251
00:27:28,100 --> 00:27:30,620
I don't know if it was last year or last year.

252
00:27:30,620 --> 00:27:36,530
There was an election going on and there are a lot of polls, you know, from different polling companies.

253
00:27:37,160 --> 00:27:44,510
Most of them were talking about this, a specific political party and there was one polling company that was quite opposite.

254
00:27:44,630 --> 00:27:54,950
So but they did not publish it because they thought they were wrong and everybody else was right and the result directly right and everybody else.

255
00:27:54,950 --> 00:27:58,759
But yeah, I think something like that could happen.

256
00:27:58,760 --> 00:28:07,310
I'm not saying that's why you have this particular question, but I tend to agree that scientists, the results, if it is done properly,

257
00:28:07,320 --> 00:28:14,420
you know that building that anything and that this would disclose any like information of whatever conflict of interest

258
00:28:14,870 --> 00:28:26,390
that as long as everything is good I think that yeah yeah I tend to agree and especially you know we as scientists,

259
00:28:26,900 --> 00:28:31,850
most of us do our research using funding that the public is paying for.

260
00:28:32,480 --> 00:28:37,250
If you are funded by a government agency, then that's funded through taxpayer dollars.

261
00:28:37,640 --> 00:28:45,470
And so I always feel an obligation to disseminate my research, whatever whatever the data show,

262
00:28:46,550 --> 00:28:50,960
because the public is paid for that, and we want to be able to share that with the community.

263
00:28:52,250 --> 00:29:04,860
That being said, if if if it's a situation where you feel like it could be misused, you know, I think that there's different ways that you can yeah.

264
00:29:05,180 --> 00:29:12,020
You can address that head on and explain why, you know, I know this could be misused,

265
00:29:12,020 --> 00:29:17,299
but these are the reasons why we still need to be careful about conservation.

266
00:29:17,300 --> 00:29:23,450
And these are the potential risks of, you know, the excessive deforestation and logging that's occurring.

267
00:29:24,170 --> 00:29:33,830
So I think that you can I think holding you're holding this back because you don't want other people to see it is a dangerous sort of premise.

268
00:29:36,200 --> 00:29:39,919
And I don't know if I necessarily agree with this like last bit, you know,

269
00:29:39,920 --> 00:29:43,340
that you should ignore political issues because I think I think you can address them.

270
00:29:43,790 --> 00:29:45,410
You know, you can you can talk about how.

271
00:29:45,570 --> 00:29:53,459
People might interpret this, and that's where the discussion section or your paper comes out or that that's where you,

272
00:29:53,460 --> 00:29:57,800
you know, you address this when you give a talk or you're presenting the poster at a conference or whatever.

273
00:29:57,810 --> 00:30:02,070
So does anybody else have any thoughts on this? Well, sure.

274
00:30:06,010 --> 00:30:10,870
Anybody think that anybody think that they'd be inclined to, like, pull back?

275
00:30:12,750 --> 00:30:17,700
Well, I was actually going to I was thinking what you were talking about, like using the discussion to your advantage and all that.

276
00:30:18,030 --> 00:30:21,810
But I've actually had a good conversation with Neil this morning.

277
00:30:21,930 --> 00:30:27,959
So it's funny that you're bringing this up because he but we were talking about how like the Manhattan Project

278
00:30:27,960 --> 00:30:32,400
and the atomic bomb and all that where people are trying to study really interesting things in physics.

279
00:30:32,400 --> 00:30:40,830
And then, yeah, kind of went the wrong way. So it's just interesting that you the quote that he mentioned was, I don't know.

280
00:30:40,830 --> 00:30:42,270
I just feel like it's very relevant.

281
00:30:42,600 --> 00:30:49,530
So you were saying that like initially the one scientist was saying there must be no barriers to freedom of inquiry,

282
00:30:49,530 --> 00:30:54,270
there is no place for dogma, and science and scientists is free and must be free to ask questions.

283
00:30:56,100 --> 00:31:01,020
And then his quote later on was, Now I've become death the destroyer of Worlds.

284
00:31:01,500 --> 00:31:10,649
It was like really interesting how what an intense and that's yeah that's quote in my mind you know so it's interesting how like we definitely have a

285
00:31:10,650 --> 00:31:16,830
responsibility to think about how our science can be used by a like he probably

286
00:31:16,830 --> 00:31:21,300
wasn't planning to have what he was working on be dropped on an entire city.

287
00:31:21,510 --> 00:31:23,760
Yeah. So yeah, that's kind of tough.

288
00:31:24,810 --> 00:31:37,560
And there's similar, you know, similar questions around things like publishing the sequence of a smallpox virus or of, you know, some pathogen that.

289
00:31:38,790 --> 00:31:45,719
Now, now, in this day of age, you can potentially synthesize in the lab, you know, how much freedom should there be around that?

290
00:31:45,720 --> 00:31:51,930
And that's a very an area with a lot of a lot of controversy and debate.

291
00:31:52,260 --> 00:32:01,050
Um, you know, places where you have so much there, it could be used for nefarious purposes and have such an impact on humanity.

292
00:32:02,610 --> 00:32:07,440
So yeah, and I think there's one other piece that I want to mention about this.

293
00:32:09,120 --> 00:32:17,249
Yeah. And the thing about negative data, I think it's really important and this part of this is not the fault of the researchers.

294
00:32:17,250 --> 00:32:24,390
A lot of it is the journals. It's really hard to get negative data published.

295
00:32:26,010 --> 00:32:30,930
And you almost you have to like find a way to pair it with some positive data.

296
00:32:31,260 --> 00:32:36,569
So you could say we don't see an effect here, but we do see an effect here.

297
00:32:36,570 --> 00:32:39,120
And here's why. The discrepancy is interesting.

298
00:32:39,780 --> 00:32:49,800
But there's a lot of situations where it would be really helpful to know that something didn't work or didn't have an effect on,

299
00:32:49,890 --> 00:32:51,720
you know, your system or whatever.

300
00:32:52,620 --> 00:33:00,900
But you don't you know, you wonder how many researchers are working on this, like simultaneously and getting banging their heads against a wall.

301
00:33:02,460 --> 00:33:12,030
And so I think that, yeah, I don't really have a solution for this, but whenever whatever it's possible, you know,

302
00:33:12,030 --> 00:33:16,049
I think that you can sometimes put a spin on it and, you know,

303
00:33:16,050 --> 00:33:19,500
it might be all negative data that you can put a spin on it in a way that can get it published.

304
00:33:19,500 --> 00:33:26,100
So but I think I'm always in favor of trying to get the data out there in some fashion.

305
00:33:26,580 --> 00:33:33,809
And that's not only for, again, being able to share it with the scientific community, being able to share it with the taxpayers,

306
00:33:33,810 --> 00:33:39,060
but also for your own career as a scientist, a lot of cases,

307
00:33:39,360 --> 00:33:44,849
at least for faculty especially, we have to publish, we have to get publications out there.

308
00:33:44,850 --> 00:33:48,300
And if you have two years of nothing but negative data, you know,

309
00:33:48,330 --> 00:33:55,890
if it puts a damper on your publication record and whatnot, if you're not getting getting that out there somehow.

310
00:33:55,900 --> 00:34:03,510
So yeah, and I'm trying to think if there's one more thing I was going to mention about this.

311
00:34:05,520 --> 00:34:08,970
Anybody else have any thoughts and comments on this?

312
00:34:11,520 --> 00:34:15,450
Cool. Well, we have one one last one.

313
00:34:18,300 --> 00:34:26,070
So there's tension in many science fields between the desire to educate the public on science and related social issues,

314
00:34:26,070 --> 00:34:35,760
and a belief that doing so compromises our objectivity. Some feel that engaging with the public is not an appropriate role for a scientist.

315
00:34:37,820 --> 00:34:41,430
Lose your job.

316
00:34:41,500 --> 00:34:47,190
Yeah. So I think the the the thought is.

317
00:34:47,580 --> 00:34:53,040
So what? Yeah. So what are the potential benefits of scientists engaging with policy issues online

318
00:34:54,450 --> 00:35:01,080
and in in the community for the scientists in the science and society as a whole?

319
00:35:02,160 --> 00:35:11,520
And what are potential drawbacks? And this would be a case where trying to form a distinction between science versus advocacy.

320
00:35:12,450 --> 00:35:18,780
And so science is about finding the truth. Advocacy is about being engaged, being passionate about something.

321
00:35:19,710 --> 00:35:23,340
They're not necessarily they're not necessarily the same thing.

322
00:35:24,570 --> 00:35:28,320
But can scientists do both? So that's the question.

323
00:35:29,430 --> 00:35:34,020
I try really hard when I bring family and friends that are not familiar.

324
00:35:34,450 --> 00:35:40,870
The work that I do to make it very clear when I'm expressing like the results that I found versus what my opinion is,

325
00:35:41,560 --> 00:35:45,160
I say, like, in my opinion, this is what I think it means and what we should do about it.

326
00:35:45,520 --> 00:35:48,280
And I hope that that's enough for them to understand that,

327
00:35:48,280 --> 00:35:54,220
like the way that I interpret it might not be the way that they interpret it or the way that it is applied for policy purposes.

328
00:35:54,460 --> 00:36:00,010
But I'm not an elected official. I can't be the voice of the person that's trying to make the decisions.

329
00:36:00,010 --> 00:36:03,220
So I have to just give like what my scientific opinion is.

330
00:36:03,550 --> 00:36:06,530
And usually they understand that and I appreciate that.

331
00:36:06,530 --> 00:36:11,920
And actually it doesn't get met with as much backlash as someone who's just like, Well, this is what it means.

332
00:36:12,250 --> 00:36:19,090
Yeah. So that's a really good point is to make make a clear distinction between here's what the data says,

333
00:36:19,090 --> 00:36:22,640
here's my interpretation and my opinion, whatever.

334
00:36:22,660 --> 00:36:24,700
That's a that's a good point. Yeah.

335
00:36:24,910 --> 00:36:32,620
I feel like this reminds me of this summer with the Supreme Court versus EPA case when the I don't remember the exact details,

336
00:36:32,620 --> 00:36:39,190
but the Supreme Court basically said they make the rules that EPA can make, enforce the laws like they want to.

337
00:36:39,820 --> 00:36:47,440
So it just kind of goes to show that like there does seem to be a relationship between scientists

338
00:36:47,440 --> 00:36:52,870
and policymakers is because a lot of times policymakers are not the ones doing the science,

339
00:36:52,870 --> 00:36:55,300
engaging with the science, knowing the science.

340
00:36:55,840 --> 00:37:04,420
So the benefits are when they do engage together, we might get better policy created that advocates for both sides well.

341
00:37:04,820 --> 00:37:12,460
But I think the drawbacks of scientists engagement policy issues could potentially be like bias issues,

342
00:37:12,910 --> 00:37:19,750
endorsement problems like similar pain in pay for your research like that kind of ethical problems.

343
00:37:19,750 --> 00:37:25,059
But quick thoughts. Yeah, no, that's really a point.

344
00:37:25,060 --> 00:37:30,500
Did you have any any comments yet? Because you're boiling something now.

345
00:37:30,600 --> 00:37:36,940
Yeah. I think the reason why I reacted like that when that particular sentence was read, in other words,

346
00:37:36,940 --> 00:37:44,200
some people being able to quote I heard a quote once that I really resonated with and it was something on NPR that basically said,

347
00:37:44,200 --> 00:37:49,240
what makes you a scientist is in what you do. It's your ability to explain it to other people.

348
00:37:49,450 --> 00:37:55,779
And I think that's really true. And I think that anybody can say that they're working on this or that.

349
00:37:55,780 --> 00:38:02,399
But unless you can find a way to to explain it to the next person and I'm not talking about the next NSA,

350
00:38:02,400 --> 00:38:09,940
the person who hasn't graduated from high school, I'm talking about just like whoever the next person is, then you're not really finishing the job.

351
00:38:09,940 --> 00:38:12,700
So like, you have to practice at the top of your license,

352
00:38:12,700 --> 00:38:17,920
as we say in health care and like do the most that you can do that's still within your scope.

353
00:38:17,980 --> 00:38:26,290
And so I'm not even talking about necessarily engaging with policy or advocating for anything, but just like to to assume that like,

354
00:38:26,620 --> 00:38:32,980
oh, you can just do the experiment and then pass the rest on like, no, I mean it's part of your job to write the discussion section.

355
00:38:33,160 --> 00:38:37,040
Yeah. And to make that salient. Yeah.

356
00:38:37,040 --> 00:38:42,040
Other people, regardless of what the actual advocacy side is, other people can be the advocate.

357
00:38:42,040 --> 00:38:45,699
That's fine. Yeah. Just have to get that information to them. Yeah.

358
00:38:45,700 --> 00:38:52,749
And I think that's really, um, and I suppose if you take your ego out of the equation, it doesn't matter as much.

359
00:38:52,750 --> 00:39:01,210
But if you are, if you are not going to put yourself out there and, and talk about what you found,

360
00:39:01,960 --> 00:39:09,430
somebody else will put themselves out there and talk about it and maybe take credit for it, you know, and that happens all the time, too.

361
00:39:11,020 --> 00:39:15,219
So sometimes it doesn't bother a lot of people. That would bother me personally.

362
00:39:15,220 --> 00:39:19,090
But yeah, I feel like I don't have a complete thought,

363
00:39:19,090 --> 00:39:27,090
but just some things I'm thinking about that are like maybe from a different perspective than like policy and think you clear,

364
00:39:27,100 --> 00:39:34,690
but engaging with the public and thinking about some of the background and training and having a community based

365
00:39:34,690 --> 00:39:41,319
participatory research where we always talk about like how your science and community based work like doesn't

366
00:39:41,320 --> 00:39:47,350
mean to be objective necessarily because you're working with those communities who are impacted by an issue

367
00:39:47,350 --> 00:39:56,560
and like the objective components of that are like have like a particularly like social and political agenda.

368
00:39:56,980 --> 00:40:03,250
And so you're getting into more of that like social, ecological, environmental, health, science.

369
00:40:03,250 --> 00:40:07,690
We're like the ones of what is like objective is very different.

370
00:40:07,690 --> 00:40:14,140
So I don't really have a full thought about as far as thinking about and also thinking about scientists who

371
00:40:14,650 --> 00:40:23,700
are from a community that are like researching like a health impact in a community that they're from too.

372
00:40:24,130 --> 00:40:33,990
It's like and you're like, what is objectively like my, like your identity is very attached to like a specific goal.

373
00:40:34,410 --> 00:40:40,310
That came out of science. Yeah. Just the different sort of kindred.

374
00:40:40,860 --> 00:40:48,329
And like on the flip side of that, I think that, you know, like my lab looks at cohorts in Puerto Rico.

375
00:40:48,330 --> 00:40:54,930
Like if you're not if you're just doing the science but not participating in any sort

376
00:40:54,930 --> 00:41:00,780
of advocacy or have like that moral justification that always feels ethically wrong.

377
00:41:00,840 --> 00:41:10,590
I think that privileged white people in a union were having them do all these things and you're publishing it,

378
00:41:10,590 --> 00:41:13,830
but you're not doing anything to make it.

379
00:41:14,130 --> 00:41:20,040
It's a Superfund site like you're supposed to be improving your lives at the same time.

380
00:41:20,070 --> 00:41:24,270
So you to be unbiased in that way. Well, that's a really good point.

381
00:41:24,500 --> 00:41:28,440
Good word for your time, which is activism and research.

382
00:41:28,440 --> 00:41:37,680
And just like taking from communities to like publish about like something traumatic in their community but like not actually helping them.

383
00:41:38,070 --> 00:41:42,930
Yeah, you're some great guinea pigs. I'm just going to I'm just gonna put the I'm going to make, you know,

384
00:41:43,500 --> 00:41:46,829
I'm going to get a bunch of funding because this is a really interesting project and I'm

385
00:41:46,830 --> 00:41:51,570
going to get a nice paper and a good journal and then just not do anything about it.

386
00:41:51,750 --> 00:41:56,100
Yeah, that's that would be. That strikes me as that feels wrong to me too.

387
00:41:56,700 --> 00:42:01,380
Yeah. I grew up in a town that was severely impacted by poverty,

388
00:42:01,650 --> 00:42:06,720
and the vast majority of people that live there right now do not even have a high school education.

389
00:42:07,530 --> 00:42:12,329
And so when I sit in these and part meetings with all of these people from my

390
00:42:12,330 --> 00:42:17,910
hometown on like a webinar with all of these big toxicologists or epidemiologists,

391
00:42:18,270 --> 00:42:25,890
it almost feels disgusting with the way that they try to explain things to them because they use all of these big words,

392
00:42:26,190 --> 00:42:31,350
words that I don't even fully comprehend, and they make them feel stupid.

393
00:42:31,920 --> 00:42:35,490
And making people feel stupid is not a way to garner trust.

394
00:42:35,670 --> 00:42:43,110
No. And it's not it's not the way to have people make an informed decision of their health and their safety.

395
00:42:43,650 --> 00:42:49,950
And it really, really upsets me whenever I hear things like this, because I've heard people saying things like this before.

396
00:42:50,280 --> 00:42:53,429
Yeah, I that was me. That could have been me.

397
00:42:53,430 --> 00:42:59,580
I could have been the person without a high school education just as easily as I'm the person I am here right now.

398
00:42:59,610 --> 00:43:05,370
Yeah. And that made a huge difference in how I can make informed decisions for myself.

399
00:43:05,550 --> 00:43:17,400
Yeah. No, that's so, so true. And I actually also grew up in a community that I was one of the only people to make it out of there without,

400
00:43:17,790 --> 00:43:23,460
you know, having children as a teenager or ending up in jail or whatever.

401
00:43:24,270 --> 00:43:32,520
And yeah, it does bother me the way some scientists or elites sort of talk down to people.

402
00:43:33,360 --> 00:43:41,850
And so we do have to find a way to build trust with these communities if we want any sort of credibility, you know, as scientists.

403
00:43:42,690 --> 00:43:47,759
Um, so, yeah, it's really important topics.

404
00:43:47,760 --> 00:43:56,190
I think, you know, with, with elections coming up with, with COVID continuing and, and all of those.

405
00:43:56,190 --> 00:43:59,340
So I thought they were relevant.

406
00:44:00,120 --> 00:44:04,530
Does anybody else have any last comments before we adjourn?

407
00:44:07,290 --> 00:44:10,890
All right. Well, have a great weekend.

408
00:44:12,120 --> 00:44:15,180
Think the games away. Right. It's like in Indiana.

409
00:44:15,540 --> 00:44:22,140
Yeah. Another break. Yeah, that's good. I can, like, leave my house, be stuck in traffic.

410
00:44:22,270 --> 00:44:23,880
I have to, like, look at it.

411
00:44:24,180 --> 00:44:29,580
If I decide where I am and what time I'm going to go to the grocery store or something, I have to, like, look at the football schedule.

412
00:44:30,250 --> 00:44:31,120
Okay, get.

