1
00:00:04,990 --> 00:00:21,610
Okay. I think we can start going through this. So what is an appropriate counterfactual comparison for the effect of vaccination on measles incident?

2
00:00:21,850 --> 00:00:26,500
Some actually present this so it gets bigger, but I think some of you might be kicked out of yourself during it.

3
00:00:28,390 --> 00:00:31,440
Okay. And most of you got this.

4
00:00:31,480 --> 00:00:35,120
So basically, we're following somebody over time, observing if they get the disease,

5
00:00:35,120 --> 00:00:39,370
then go back in time, not vaccinating them and then seeing if they get disease.

6
00:00:40,540 --> 00:00:44,529
So that's counterfactual. And again, counterfactual is literally counter to fact.

7
00:00:44,530 --> 00:00:51,010
It's counter to reality. This is an experimental evidence randomizing individuals.

8
00:00:51,490 --> 00:00:53,900
And that's, you know, a very good level of information.

9
00:00:53,920 --> 00:01:03,220
This is probably like the best the quote, one of the closest things we can do to get close to a counterfactual amount of evidence.

10
00:01:03,580 --> 00:01:06,700
And then these are observational studies.

11
00:01:06,700 --> 00:01:14,520
So observational evidence. Okay.

12
00:01:14,780 --> 00:01:19,850
Do marginal start to our models that come from measured confounders? The answer is no.

13
00:01:19,910 --> 00:01:23,360
Most of you got that next week or in two weeks.

14
00:01:23,360 --> 00:01:26,419
We'll go over how to deal with unmeasured confounders.

15
00:01:26,420 --> 00:01:32,930
But that's a totally different thing. You kind of have to use some sort of bias analysis to actually deal with unmeasured confounders.

16
00:01:37,390 --> 00:01:42,280
Okay. So do causal inference methods estimate per protocol effects or intent to treat effects?

17
00:01:42,550 --> 00:01:48,310
And again, just to kind of rehash this in your brains and intend to treat analysis is where we

18
00:01:48,310 --> 00:01:52,660
look at what was the randomization scheme or were people randomized to receive,

19
00:01:53,440 --> 00:01:57,700
whereas per protocol is where we actually look at like did they adhere to the protocol or not?

20
00:01:59,290 --> 00:02:03,660
So causal inference methods will use that for protocol approach.

21
00:02:05,350 --> 00:02:13,600
And one thing the intend to treat approach is nice in the sense that we actually have their randomization scheme and then we

22
00:02:13,600 --> 00:02:20,230
can kind of deal with all those confounders because they're randomly distributed across the two different exposure groups,

23
00:02:20,920 --> 00:02:22,150
the two different treatment groups.

24
00:02:22,570 --> 00:02:29,320
The problem with intent to treat is that we actually don't know if people adhere to the behavior or not or adhere to the treatment.

25
00:02:30,070 --> 00:02:33,190
And so in causal inference methods, that is what we estimate.

26
00:02:33,250 --> 00:02:40,149
We're not interested in coming up with some like random with some randomization scheme over actually looking at

27
00:02:40,150 --> 00:02:46,210
is what are people's actual behaviors or their actual levels of treatment or whatever the exposure might be.

28
00:02:52,570 --> 00:02:59,440
Okay. So in a marginal structure model, you know, you're in any observational study we're trying to deal with confounding.

29
00:03:00,400 --> 00:03:03,400
So should we include inverse probability weights?

30
00:03:03,400 --> 00:03:10,270
Should we include covariates in the model statement or both? And the answer is just the inverse probability of events.

31
00:03:11,830 --> 00:03:15,670
So that's the difference between marginal structure models and what you've been taught in the past with multivariable

32
00:03:15,670 --> 00:03:21,760
models is for marginal structural models we deal with confounding through these inverse probability weights.

33
00:03:23,530 --> 00:03:27,660
This is a typical thing that we do in a traditional regression model.

34
00:03:27,690 --> 00:03:32,079
Just enter confounders that's covariates and doing them both is kind of like double dipping.

35
00:03:32,080 --> 00:03:38,320
It doesn't it's not necessary. Okay.

36
00:03:38,740 --> 00:03:50,080
So we are developing a marginal structural model and how would we develop the propensity scores in this situation?

37
00:03:54,370 --> 00:03:56,860
And the answer is this one the probability of X given Z.

38
00:03:58,030 --> 00:04:05,310
So for a marginal structural model, we are modeling people's treatment levels, remodeling their exposure levels.

39
00:04:05,320 --> 00:04:09,160
That's what the inverse probability way, that's what the propensity scores are about.

40
00:04:09,550 --> 00:04:17,650
That has to do with their levels of their exposure. So that's why we would do the probability of X given Z.

41
00:04:19,690 --> 00:04:27,070
So we don't do anything. Just so you know, we don't this is one thing that people get wrong is sometimes they want to put the outcome in the model.

42
00:04:28,570 --> 00:04:32,680
We don't do that because like if you look at this causal model, the arrow is in pointing that way.

43
00:04:32,950 --> 00:04:38,050
There's no situation where the arrow goes from Y to X because in that kind of like,

44
00:04:38,890 --> 00:04:45,400
you know, that that's just not what is is is happening causally and temporally.

45
00:04:45,400 --> 00:04:49,059
It's not happening. So we don't need that. Yeah.

46
00:04:49,060 --> 00:04:53,080
And I get, you know, some of the other of you are saying this,

47
00:04:53,080 --> 00:04:57,700
and I think that's just because like maybe in your mind you're not thinking about the marginal structural part of this.

48
00:04:58,000 --> 00:05:05,050
And typically in a model like this, like, of course, where if you outside of a marginal structural model,

49
00:05:05,080 --> 00:05:09,850
we would just be putting in X in the confounders into a multivariable model.

50
00:05:10,480 --> 00:05:14,170
But just recall that a marginal structural model is a two separate approach.

51
00:05:14,560 --> 00:05:22,720
The first step is that we develop propensity scores for the treatment and then we use those as weights in a model for the exposure on the outcome.

52
00:05:24,640 --> 00:05:32,930
Any questions on that? Okay.

53
00:05:35,850 --> 00:05:40,740
I wanted to go to one other thing from the previous class.

54
00:05:44,250 --> 00:05:56,490
We had I had you put together this dag and this is based off of the dag from the reading for last week.

55
00:05:58,020 --> 00:05:59,550
But I kind of made up some of the arrows.

56
00:06:00,120 --> 00:06:08,609
I do want to point out one thing here, which is that race, ethnicity is just included as one of the one of the variables in this analysis.

57
00:06:08,610 --> 00:06:13,770
And of course, race, ethnicity is a very commonly collected variable in our datasets.

58
00:06:14,520 --> 00:06:23,040
So it often is just put in multivariable models or from marginal structural models that will be put into a propensity score.

59
00:06:24,240 --> 00:06:28,470
So many people do that. And of course the the people for the reading last week, the authors did that.

60
00:06:29,790 --> 00:06:40,320
But you know, what we were talking about at the end of class last week in a counterfactual perspective, there's no real way to change somebody's race.

61
00:06:41,430 --> 00:06:46,409
But there are other things related to race that we could change. We could change, you know, racism.

62
00:06:46,410 --> 00:06:53,790
We could change discrimination in education. We could, you know, we could change people's income levels.

63
00:06:53,790 --> 00:06:58,710
We could change potentially even like generational accumulation of wealth.

64
00:06:58,740 --> 00:07:01,710
Those are things that we could make a counterfactual comparison for.

65
00:07:02,040 --> 00:07:05,550
But I guess my my own argument that race, ethnicity is something that we could not.

66
00:07:06,240 --> 00:07:12,540
So it's possible that, you know, the authors just included this variable because it's kind of related to all of those things and,

67
00:07:12,540 --> 00:07:22,079
you know, including measures of like racism or discrimination or structural issues in somebody's life.

68
00:07:22,080 --> 00:07:26,430
Those are harder things to measure. Instead of just asking somebody like, Oh, what's your race?

69
00:07:26,430 --> 00:07:33,360
What's your ethnicity? But I potentially just want you to be cognizant now that you are second year EPI students,

70
00:07:33,840 --> 00:07:38,340
that we should be a bit careful like when we do use race and when we don't use race.

71
00:07:39,960 --> 00:07:46,110
And I think that, you know, in limited datasets, like most datasets that we have access to,

72
00:07:47,250 --> 00:07:52,320
we just probably don't have a lot of the other variables, which are the things that counterfactual we're interested in.

73
00:07:52,710 --> 00:07:57,360
And so instead we have to use race as a proxy. Well, do we have to use it?

74
00:07:57,370 --> 00:08:02,490
Do we not? I think that's something that you should actually have a conversation with in your research group.

75
00:08:04,580 --> 00:08:11,170
Any questions on that? Okay.

76
00:08:11,170 --> 00:08:18,070
So today we are going to be talking about mediation, interaction, but mostly mediation.

77
00:08:22,240 --> 00:08:26,600
So just a brief recap from last time.

78
00:08:26,650 --> 00:08:33,549
Confounding is when we have this third variable, which is an ancestor,

79
00:08:33,550 --> 00:08:40,300
a causal ancestor of both the exposure and the outcome, or it's somewhere along the pathway, but it's not a mediator.

80
00:08:44,370 --> 00:08:53,730
So confounding. I like to think about it also as when the levels of these confounders differs across the exposure groups.

81
00:08:54,570 --> 00:09:05,620
So extraneous factors. That's kind of another word for these confounders or third variables in what we're trying to say here is that, you know,

82
00:09:05,700 --> 00:09:14,160
maybe in an observational study, most of the people who got vaccinated are older, whereas those who didn't get vaccinated were younger.

83
00:09:14,370 --> 00:09:21,060
So then age is a confounder of that relationship because the distribution of age is not equal amongst the different vaccination groups.

84
00:09:28,610 --> 00:09:32,300
Um. Goodness.

85
00:09:32,860 --> 00:09:44,070
So one thing in the past and sometimes I will tell students is sort of like a rule of thumb is there's this 10%.

86
00:09:44,280 --> 00:09:54,090
So you could run a regression model without a confounder and then you could run it with a possible confounder and then you could see,

87
00:09:55,380 --> 00:10:02,490
you know, do your effect estimates, does your odds ratio or does your beta estimate from a linear regression?

88
00:10:02,490 --> 00:10:07,500
Does that change over 10%? And if it does, maybe you say, oh, this is evidence of confounding.

89
00:10:08,520 --> 00:10:11,700
So has it been something that you've kind of heard before?

90
00:10:12,870 --> 00:10:19,140
And I think that's like fine as is just kind of like a rule of thumb or like a bit of evidence.

91
00:10:19,440 --> 00:10:25,620
I think my own thought process is confounding, is more of a theoretical issue rather than a statistical issue.

92
00:10:25,980 --> 00:10:31,680
So if you have a confounder, it should just be included in your model, because that's what we do with confounders,

93
00:10:31,680 --> 00:10:36,750
is we put them in our multivariable regression model and we adjust for them that way,

94
00:10:37,560 --> 00:10:42,150
or we find some other way to deal with them, like through a multi or through a marginal structural model.

95
00:10:43,380 --> 00:10:49,650
But if you like really are hurting for space in your model, potentially,

96
00:10:49,650 --> 00:10:56,010
you could think of removing some variables if they don't change that outcome more than 10%.

97
00:10:56,790 --> 00:11:03,569
It's interesting, though, I did see some other folks argue that maybe 38% is a better number instead of 10%.

98
00:11:03,570 --> 00:11:08,280
So here's an article if you're interested in that and we'll talk about model building more next week.

99
00:11:09,390 --> 00:11:17,670
So just this is a primer for next week. One potential issue is whole linearity.

100
00:11:18,210 --> 00:11:21,900
So linearity is an extreme example of confounding.

101
00:11:22,800 --> 00:11:31,770
So linearity often happens when you have two variables which are so highly correlated that you don't really have many observations in the alpha cells.

102
00:11:32,220 --> 00:11:36,150
So this is an example. You know, it doesn't really matter what the outcome is,

103
00:11:36,540 --> 00:11:43,050
but oftentimes we think of education and income as highly correlated, correlated and maybe even linear.

104
00:11:44,160 --> 00:11:53,580
So say we have around 200 people in a dataset. If about 100 each are in the high income, higher education or low income lower education,

105
00:11:53,580 --> 00:11:58,140
and maybe there's only a couple of people in these, you know, off diagnosed.

106
00:11:58,170 --> 00:12:03,170
That could be a problem. And we could have some issues in estimating our results,

107
00:12:03,180 --> 00:12:09,330
like maybe we run a regression model and we get like really bulky answers or like things that don't make sense.

108
00:12:10,110 --> 00:12:17,040
And that's what happens with Coloniality is that if you include both of these variables in a regression model,

109
00:12:17,040 --> 00:12:20,520
see, that's trying to do this, you might just get really wonky results.

110
00:12:23,250 --> 00:12:30,470
So how do you test for culinary? One thing you can do is a variance inflation factor, but you can only use this with linear regression.

111
00:12:30,480 --> 00:12:37,620
I think there's been some more recent work into trying to do this with logistic regression or other other models,

112
00:12:37,620 --> 00:12:42,270
but for now I think most of the time people will use it for linear regression models.

113
00:12:44,040 --> 00:12:50,490
And what variance inflation factor is basically saying is that if you remove this variable,

114
00:12:50,820 --> 00:12:59,760
how does it affect the variance of the other variable or other variables in the model?

115
00:13:01,560 --> 00:13:04,740
So in this example and again, it doesn't really matter exactly what it is,

116
00:13:04,740 --> 00:13:15,840
but if we move remove this variable gender or if we include it, it will increase the variance in other variables by 1.21 times.

117
00:13:17,880 --> 00:13:22,650
So people use a number of different cutoffs. It could be four, it could be ten.

118
00:13:23,280 --> 00:13:28,050
And basically this is all to say that if you have a really high variance inflation factor,

119
00:13:28,410 --> 00:13:34,290
that might be a sign that that variable is highly linear with another variable in your dataset.

120
00:13:34,740 --> 00:13:42,450
So that could be also reason just to remove a variable from your model is that it's like highly linear or something else.

121
00:13:42,720 --> 00:13:49,770
And if something is highly linear with something else, then maybe if there is confounding that that other variable kind of already accounts for it.

122
00:13:54,440 --> 00:13:59,690
Some other thoughts about culinary. You know, here I have like a data set of, I think a bit over 200 people.

123
00:14:00,410 --> 00:14:06,290
If you added three zeros to this, there is over 200,000 people then Kaliningrad,

124
00:14:06,290 --> 00:14:09,949
you wouldn't be so much of an issue because even though the proportion is the same,

125
00:14:09,950 --> 00:14:14,929
you still have like four or 5000 people in these after signal cells.

126
00:14:14,930 --> 00:14:18,350
So again, that wouldn't be so much of an issue.

127
00:14:18,350 --> 00:14:26,390
But like if you only have 200 people in this probably would be this probably would cause issues with your model.

128
00:14:26,430 --> 00:14:35,270
You might not have convergence. Or another thing that you might see is like odds ratios which have like a bound basically like zero to infinity.

129
00:14:36,680 --> 00:14:40,640
Anything like that is something to kind of be aware of. Maybe linearity is happening.

130
00:14:45,850 --> 00:14:51,249
I really see that. Like there has been some research out of sociology and social epidemiology

131
00:14:51,250 --> 00:14:54,940
which has stated that in some situations you might want to include both terms,

132
00:14:54,940 --> 00:15:01,180
even if they are linear, like education, income, we often just adjust for both, even though they are highly linear.

133
00:15:01,570 --> 00:15:05,390
And the reason for that is that, you know,

134
00:15:05,500 --> 00:15:12,550
they just might that there are certainly related and overlapping concepts that they might be touching on slightly different causal pathways.

135
00:15:17,230 --> 00:15:25,890
Linearity. We also probably care more so if you are trying to estimate like odds ratios or rate ratios or risk differences,

136
00:15:25,900 --> 00:15:31,780
like when you're when you're looking at a strength of association and you're trying to come up with this measure of association,

137
00:15:31,780 --> 00:15:34,179
that's what you're trying to estimate. Then, pulling narratives.

138
00:15:34,180 --> 00:15:40,450
And if you if you're trying to compute like a propensity score or something like that, then culinary, it is probably not so much of an issue.

139
00:15:44,430 --> 00:15:57,990
If you were to do like a two by two table and you'd have cells which were zero, that could be considered a violation of positivity.

140
00:16:00,030 --> 00:16:02,429
That's also a problem with linearity.

141
00:16:02,430 --> 00:16:11,070
If things are super highly linear, then we have a violation of positivity and that is an assumption that we have imposed on French literature.

142
00:16:11,700 --> 00:16:15,689
So what do you mean by positivity? This is just what somebody tweeted about.

143
00:16:15,690 --> 00:16:20,489
I think they put it in different in a good way. I'll let you read this by yourself later.

144
00:16:20,490 --> 00:16:28,500
But in essence, what we are trying to say is that there isn't any one variable which will totally predict another variable.

145
00:16:31,410 --> 00:16:43,770
So like an example might be if we were looking at whether somebody had Medicare or not and what that was their influence on cardiovascular health.

146
00:16:44,250 --> 00:16:52,590
And then we also looked, if they had it like what their age was and how their age was related to cardiovascular health,

147
00:16:53,790 --> 00:17:00,540
because you have to be over 65 to be on Medicare, then there would be a violation of positivity there.

148
00:17:00,540 --> 00:17:07,049
You couldn't include both of these variables in the model just because knowing somebody's age would also make,

149
00:17:07,050 --> 00:17:13,110
you know, whether they had Medicare or not. So that, you know, is is potentially like an intuitive example of that.

150
00:17:15,960 --> 00:17:22,140
Another way of thinking about it is, you know, you had to put together these histograms for the homework.

151
00:17:22,410 --> 00:17:26,310
If everything was clustered at one and zero, that else was a violation of positivity.

152
00:17:26,580 --> 00:17:35,800
So we want things to be like in the middle here. Any questions about that so far?

153
00:17:38,120 --> 00:17:49,870
Okay. So diving into mediation, we first off that a lot of times in this we use Greek letters to kind of explain different associations.

154
00:17:49,870 --> 00:17:56,800
I just have included some here which might be confused amongst each other or which are common things that we use in epidemiology.

155
00:17:57,220 --> 00:18:08,950
Maybe nowadays we're like sort of familiar with this because at least for a while we were using Greek letters to describe new variants of COVID.

156
00:18:08,950 --> 00:18:13,120
But now we've kind of like stopped it on Macron. And I'm also kind of wondering why that's the case.

157
00:18:13,120 --> 00:18:18,520
But, you know, we did have like the Delta variant and things like that.

158
00:18:20,230 --> 00:18:28,810
Okay. So yeah, Alpha Beta Delta over current, I think the ones that will be using today are more so Phi and Theta.

159
00:18:29,830 --> 00:18:34,600
Sometimes people get Phi silence stuff. So I will say that that's like one difference.

160
00:18:34,600 --> 00:18:43,329
But you finally has the connection here. Whereas side is not I suppose we also see these a lot in, you know, sororities and fraternity.

161
00:18:43,330 --> 00:18:48,790
So, you know, maybe you're all familiar with this, but I will say that every year there's always a few students who get confused, and that's okay.

162
00:18:49,270 --> 00:18:55,120
You know, the point of this class is not to learn Greek letters, but if any of these are confusing, just let me know.

163
00:18:56,560 --> 00:19:00,280
Okay. So a mediator again, I think we have an understanding of what this is.

164
00:19:00,280 --> 00:19:03,850
It's something in the course that halfway between the exposure and the outcome.

165
00:19:06,630 --> 00:19:14,580
And we often will label these different arrows with with different Greek letters.

166
00:19:16,620 --> 00:19:22,920
So the total effect is often over interesting epidemiology and see, the vast majority of the time this is what we are interested in.

167
00:19:23,550 --> 00:19:30,930
So the exposure on the outcome, that effect and that effect is so or is five one.

168
00:19:34,520 --> 00:19:38,180
So the total effect is where we do not adjust for any mediator.

169
00:19:38,330 --> 00:19:43,309
We could like we could adjust for confounders and things like that. We're just not showing them in this model.

170
00:19:43,310 --> 00:19:51,600
But exposure and outcome, that's five one. The direct and indirect effect.

171
00:19:51,610 --> 00:19:54,700
Those are in models where we actually do include the mediator.

172
00:19:55,420 --> 00:20:02,530
So the direct effect is in a model of the exposure and the outcome, but also the mediators included in that is theta one.

173
00:20:05,120 --> 00:20:11,060
In that same model, the relationship between the mediator and the outcome would be theta two.

174
00:20:13,430 --> 00:20:18,140
And if you did a separate a third model which just included the exposure as the, you know,

175
00:20:18,170 --> 00:20:23,570
the independent variable, the mediator is the outcome that would be shown by the speed of one.

176
00:20:25,900 --> 00:20:34,750
So, you know, for the homework for this week, I will have you go through different models and have you go see where each of these letters come from.

177
00:20:35,350 --> 00:20:43,810
But there's a few different ways you can think about this. Each if each of the Greek letters represents a different regression model.

178
00:20:44,890 --> 00:20:54,190
So PHI one, this is a model all by itself. Theta one and theta two are in the same model, but they're in a different model and beta one.

179
00:20:55,300 --> 00:21:00,879
But conceptually, we can kind of think about these in a number of different ways, where the PHI one is just the total effect.

180
00:21:00,880 --> 00:21:08,860
That's, you know, the effect of exposure on the outcome regardless of any intermediates, regardless of any mediator.

181
00:21:09,460 --> 00:21:14,110
Whereas the indirect, indirect effect, this is where we are separating out potential mediators.

182
00:21:18,390 --> 00:21:33,450
Okay. So one small group discussion I will have you do is just to talk about when is when is a variable mediator, when is that a confounder?

183
00:21:33,450 --> 00:21:42,540
So just think about like a study you do looking at exposure on mortality is income mediator is the confounder,

184
00:21:42,540 --> 00:21:46,979
does it depend or have you discussed and then Emily,

185
00:21:46,980 --> 00:21:54,420
I feel like you could probably just, you know, find a another group if you are kind of like isolated to everybody else.

186
00:21:54,900 --> 00:22:08,850
Okay. I'll give you just a couple of minutes and we'll come back. Yeah.

187
00:22:26,913 --> 00:22:34,383
Okay. There's a lot of good discount for people to call in a few different groups to see your what, what you came up with.

188
00:22:34,873 --> 00:22:43,173
Um, maybe in the back. The. What do you think about this relationship between education on mortality.

189
00:22:48,003 --> 00:22:51,363
Higher, higher rates and higher.

190
00:22:53,153 --> 00:22:56,812
Hmm. Yeah. I'm all pretty positive.

191
00:22:56,813 --> 00:23:00,803
Like, if you look at another group, don't get fired. What did you think about this?

192
00:23:01,703 --> 00:23:05,873
Anything different or the same as what was just said? We are so big, Jackson.

193
00:23:06,343 --> 00:23:16,573
Well. The person or persons that's causing all of the families.

194
00:23:17,143 --> 00:23:24,453
And the kids like. But if you considering pulling.

195
00:23:26,293 --> 00:23:30,713
How do they come to find out? It's involved with education.

196
00:23:30,713 --> 00:23:35,153
And then also looking at like, are you talking about like education?

197
00:23:35,333 --> 00:23:40,372
And here you had like because also like millennials are the most educated generation.

198
00:23:40,373 --> 00:23:46,213
And so like not just because kids educated automatically depending on the generation and.

199
00:23:49,883 --> 00:23:55,853
Yeah. You're bringing up a really interesting point. Say, like what you're thinking, because it almost seems to me like this Dag is too simple.

200
00:23:55,853 --> 00:23:59,003
We need to add, like, age, and we need to think of other things.

201
00:23:59,273 --> 00:24:03,382
I also like what I think both the groups are bringing up is that we need to think about how these

202
00:24:03,383 --> 00:24:10,883
variables were defined because is this on an individual level or is it on like a family level?

203
00:24:10,893 --> 00:24:18,533
Because clearly the big thing when thinking about like whether the order of things is more like a mediator versus a confounder,

204
00:24:18,833 --> 00:24:22,912
one thing we think about is temporality. So like when did somebody get their education?

205
00:24:22,913 --> 00:24:32,423
When did they get the income? So if you are thinking about your parent's level of education and your own income and how that relates to mortality,

206
00:24:32,423 --> 00:24:36,053
of course, income then would be more of a mediator.

207
00:24:37,283 --> 00:24:43,703
We could also think of like, what is your family levels of of income and then maybe your own level of education,

208
00:24:44,003 --> 00:24:47,573
in which case, you know, the direction might be reversed. So it might be a confounder.

209
00:24:48,713 --> 00:24:51,473
So I don't think there's any one particular answer to this,

210
00:24:51,473 --> 00:24:57,113
but I think what you should be thinking about is I think what was brought up, which is how do you define these variables?

211
00:24:57,113 --> 00:24:58,253
When were they measured?

212
00:24:58,723 --> 00:25:09,503
And another thing which I think was great that you have been thinking about is how does this relate to potentially other variables in the model?

213
00:25:09,503 --> 00:25:16,763
Like maybe there is some effects modification, which we'll be talking about more in a moment where maybe like different generations,

214
00:25:16,763 --> 00:25:21,653
this, this, this, you know, these arrows could show different strings of association.

215
00:25:24,233 --> 00:25:29,273
Okay. So what do we do with mediators? This will be the subject of your homework assignment for today.

216
00:25:30,323 --> 00:25:33,473
If you're just wanting to look at the total effect, then ignore.

217
00:25:34,103 --> 00:25:41,392
You don't need to account for mediators if you don't want to. And I would say most of the time, epidemiology students do not want to.

218
00:25:41,393 --> 00:25:45,053
Most of the time, epidemiology researchers do not want to.

219
00:25:45,563 --> 00:25:51,053
But if you do want to and that, you know, that's something that we can do, then we can use.

220
00:25:52,013 --> 00:26:00,533
There's there's a difference method and there's a product of coefficients method in the that's just these things.

221
00:26:00,543 --> 00:26:04,643
So for the indirect effect, do we measure it through subtraction?

222
00:26:04,643 --> 00:26:08,723
That's the difference method. Audrey Measure it through multiplying two things together.

223
00:26:09,203 --> 00:26:16,163
That is the product of coefficients method. And again, I walk you through this in the homework assignment for this week.

224
00:26:16,463 --> 00:26:23,513
And they most a lot of the times they show similar results. Sometimes if you have ratio measures and especially odds ratios, these won't be the same.

225
00:26:23,963 --> 00:26:29,453
But I think for the homework for today, for this week, I believe we're still dealing with risk differences.

226
00:26:29,453 --> 00:26:33,713
So this equation should still work.

227
00:26:34,703 --> 00:26:36,862
And by here, the equal just means that you could calculate it.

228
00:26:36,863 --> 00:26:47,353
Either way, you don't have to do one way or the other so that a lot of the pioneer, the big pioneers in mediation were Beirne and Kenney.

229
00:26:47,363 --> 00:26:50,273
So you might see them cited a lot in the literature.

230
00:26:50,603 --> 00:26:56,243
If you're wanted to get a p value, which we're not doing for the homework for today, you could do a simple test.

231
00:26:56,423 --> 00:27:02,123
And again, this is just to kind of have these things in mind for you. You can definitely look them up later if it's appropriate for you.

232
00:27:03,113 --> 00:27:11,423
A lot of people in the social sciences like using structural accretion modeling, which is a type of path analysis,

233
00:27:12,653 --> 00:27:19,523
and essentially it kind of looks like a big dag, but they model all of these relationships simultaneously.

234
00:27:21,563 --> 00:27:28,403
Structural equation models aren't something that we talk a lot about in epidemiology, and a lot of epidemiologists just don't like them.

235
00:27:28,403 --> 00:27:32,993
And that's also part of the homework assignment for today is just this brief opinion

236
00:27:32,993 --> 00:27:37,013
piece that Tyler Vanderbilt put together about structural equation modeling,

237
00:27:37,013 --> 00:27:43,403
why he doesn't like it. And that's just one, one set of evidence you may or may not agree with him.

238
00:27:44,273 --> 00:27:48,533
And I will say that there's a lot of people who use structural accretion modeling, and I think that's right.

239
00:27:51,263 --> 00:27:55,433
And then there is this decomposition method. We'll be talking about that later on in class.

240
00:27:56,933 --> 00:28:01,163
Okay. So effect modification, what is this?

241
00:28:02,783 --> 00:28:10,543
Well, first off, any questions about mediators? Okay.

242
00:28:11,173 --> 00:28:16,993
So let's move on to effect modification. For this, we need to be thinking about this strength of association.

243
00:28:17,443 --> 00:28:25,393
And I think people understand what this is based on to make sure we're all at the same place by strength, I mean, like, how big is the number?

244
00:28:25,933 --> 00:28:30,973
So for a risk ratio, something like 2.5 is a stronger association than 1.5.

245
00:28:32,983 --> 00:28:39,783
And then if you if you flip it below one is something like 27 would be a stronger association than point nine, I think.

246
00:28:39,793 --> 00:28:45,253
I think that makes sense for for people. But again, it's mirrored around one for difference measures.

247
00:28:45,253 --> 00:28:52,513
It's mirrored around zero. So like a 60% difference is, of course, bigger than 30% negative.

248
00:28:52,513 --> 00:28:55,843
45% difference is, of course, bigger than any -25%.

249
00:29:00,743 --> 00:29:04,813
So there's different ways of graphically representing effect modifiers.

250
00:29:04,823 --> 00:29:10,943
This is my preferred way is to have an arrow from your effect modifier on to your exposure, an outcome.

251
00:29:11,393 --> 00:29:14,573
Not everyone will agree with this though, and that's totally fine.

252
00:29:14,573 --> 00:29:17,963
I think there's lots of different ways that people might think about doing this.

253
00:29:18,293 --> 00:29:23,363
And this is not like standard dag language, like you can't put this in Dalgety.

254
00:29:25,583 --> 00:29:33,443
So this is just, you know, a way that's commonly done. It's how I do it, but it's not it's not official dag jargon.

255
00:29:35,003 --> 00:29:45,713
But what does is the reason why I like this is basically we're saying the effect modifier influences the the strength of this association.

256
00:29:47,553 --> 00:29:57,453
So there's a number of different scenarios which could happen under effect modification, and I'll give some examples from the vaccination.

257
00:29:59,753 --> 00:30:06,933
So maybe our effect modifier is age or exposure as vaccination or outcome is.

258
00:30:06,953 --> 00:30:08,212
Maybe this is a flu vaccine.

259
00:30:08,213 --> 00:30:20,953
And whether somebody gets gets flu or not, we know that the vaccine is much more protective in younger adults than it is in older individuals.

260
00:30:20,963 --> 00:30:28,493
So generally, you know, older folks will have a poorer immune response to the influenza vaccine than younger individuals.

261
00:30:29,063 --> 00:30:31,253
So that's what this strength of association could mean. You know,

262
00:30:31,253 --> 00:30:39,652
we're stratifying based on age and we're seeing that there's a stronger association between vaccination and immune response for younger ages,

263
00:30:39,653 --> 00:30:42,983
and there's less of a response for older ages.

264
00:30:44,723 --> 00:30:51,323
So again, in this situation, age is an effect modifier of vaccination and the immune response.

265
00:30:54,433 --> 00:30:58,783
We could have a situation where under in certain groups there's no effect.

266
00:30:59,833 --> 00:31:07,722
A vaccination related example for this would be measles vaccination here in the US and in many everyone in every country,

267
00:31:07,723 --> 00:31:11,083
we if we don't vaccinate newborns against measles.

268
00:31:11,983 --> 00:31:19,603
And the reason why is because most newborns will have maternal antibodies towards measles.

269
00:31:19,603 --> 00:31:21,313
So during the third trimester,

270
00:31:22,753 --> 00:31:38,833
the the mother will deliver a certain titer of antibodies towards measles and a number of other infectious diseases to the fetus.

271
00:31:39,313 --> 00:31:44,383
And then when the infant is born for a few months, that individual will have protection.

272
00:31:44,653 --> 00:31:50,533
But that's all to say, that if you tried to vaccinate a newborn against measles, it wouldn't be harmful,

273
00:31:50,533 --> 00:31:59,113
but it just wouldn't do anything because those maternal antibodies would wipe out the vaccine stream before the child would be able to,

274
00:31:59,413 --> 00:32:04,423
you know, develop its own immune response. This is all to say that, you know,

275
00:32:04,753 --> 00:32:13,632
if we're looking at the effect of the measles vaccine in younger in like really young newborn groups, there would be no effect.

276
00:32:13,633 --> 00:32:19,393
And that's just because of the presence of maternal antibodies, whereas there would or hopefully there's an effect in older infants.

277
00:32:25,553 --> 00:32:30,712
Okay. And we could even think about, like a reversal of the arrow.

278
00:32:30,713 --> 00:32:37,163
So it might be protective in some situations. It could be detrimental in other situations for vaccination.

279
00:32:37,733 --> 00:32:41,843
And unfortunate example of this would be dengue vaccination dengvaxia.

280
00:32:43,073 --> 00:32:45,713
This is something that you may have heard half into a few years ago,

281
00:32:47,003 --> 00:32:50,453
but basically dengue is kind of like the flu in that there's a number of different strains

282
00:32:50,453 --> 00:32:57,983
circulating and generally it takes two infections for you to develop really robust immunity.

283
00:32:59,963 --> 00:33:08,213
But what they found was that for individuals who had been previously vaccinated, that dengue,

284
00:33:08,213 --> 00:33:16,973
that who had been previously infected once dengue vaccine was really good because it induced an immune response that was long lasting, that was great.

285
00:33:18,413 --> 00:33:23,563
But for individuals for which Dengvaxia was their first exposure to any dengue antigens,

286
00:33:23,583 --> 00:33:27,563
they had had previously been infected before the vaccine was detrimental.

287
00:33:30,703 --> 00:33:41,923
So again, the effect modifier here is prior infection status, the exposure is dengue and the outcome is severity of disease after dengue vaccination.

288
00:33:44,513 --> 00:33:52,193
Any questions? So there are a number of different words which are used for effect modification.

289
00:33:52,193 --> 00:33:58,763
You might hear things like interaction, you could hear statistical interaction, biological interaction, effect, measure modification.

290
00:33:59,333 --> 00:34:06,683
There are some statisticians and people who are much more brilliant than I am who will distinguish between effect, modification and interaction.

291
00:34:07,013 --> 00:34:11,353
To me, it's not really important on a public health scale.

292
00:34:11,363 --> 00:34:19,192
I think that some of the statistical models might be different if you consider something to be an effect modifier or an interactive.

293
00:34:19,193 --> 00:34:23,333
But I haven't found like a practical example where that matters too much.

294
00:34:24,533 --> 00:34:29,662
I will say that there are some people who have very strong thoughts on whether we

295
00:34:29,663 --> 00:34:34,043
should be measuring interaction on an additive scale or a multiplicative scale.

296
00:34:34,403 --> 00:34:39,283
And that by that I mean, like if we're putting together a multivariable model,

297
00:34:39,293 --> 00:34:44,423
do we want to specify like a risk ratio or do we want to specify a risk difference?

298
00:34:44,693 --> 00:34:51,083
So there is a camp of people who are really pro difference measures, really pro these these additive measures,

299
00:34:52,133 --> 00:34:56,153
and they think that is a better attuned to this idea of biological interaction.

300
00:34:57,323 --> 00:34:59,753
And there are others who don't think it matters too much.

301
00:35:01,883 --> 00:35:07,673
So, you know, I don't think that we need to delve too much into that debate because it's very unsettled.

302
00:35:08,093 --> 00:35:15,863
But one thing that I will mention is that if you want to search for effects modification, you probably will find it.

303
00:35:15,953 --> 00:35:20,843
So along with mediation, if you are not interested in an effect modification for your research study,

304
00:35:21,053 --> 00:35:25,673
do not go looking for it because it gets confusing really quickly.

305
00:35:26,153 --> 00:35:31,523
And sometimes what you can find is that the effect modifier will be significant on an additive scale,

306
00:35:31,553 --> 00:35:35,003
but it will not be significant on a multiplicative scale or vice versa.

307
00:35:35,393 --> 00:35:40,703
And then that gets really confusing. Like, what does it mean that it's significant for like a modest difference, but not for a risk ratio?

308
00:35:41,573 --> 00:35:45,923
So, you know, there's not easy answers to how to resolve those.

309
00:35:46,283 --> 00:35:53,363
But I think one thing that you can do is just to be really purposeful for when you actually are looking for effect modification.

310
00:35:55,253 --> 00:35:58,372
And this is just what I was just saying. So it's scale specific.

311
00:35:58,373 --> 00:36:04,673
So really, when you are looking at effect modification, do you want to emphasize in your methods, of course,

312
00:36:04,673 --> 00:36:13,823
but also in your discussion that you're looking at effect modification on like a multiplicative scale or on a scale?

313
00:36:16,633 --> 00:36:19,783
So interaction is not too difficult to incorporate into your models.

314
00:36:19,813 --> 00:36:27,913
Basically, you include the main effects and then you also include an asterisk in between them.

315
00:36:27,913 --> 00:36:34,632
And I believe this is also the language in our. But please, does anyone know in if it is different than this.

316
00:36:34,633 --> 00:36:49,123
I think it's this is the same. One thing to also think through with this is effective measure modifiers that are symmetrical with exposures.

317
00:36:50,353 --> 00:36:57,613
So statistically, we cannot distinguish what is the exposure and what is the effect modifier because like they're they're exactly the same.

318
00:36:57,613 --> 00:37:01,963
It doesn't matter the order you put these things in, you'll come up with the same model.

319
00:37:06,453 --> 00:37:09,903
Okay. Any questions on interaction terms?

320
00:37:12,433 --> 00:37:15,883
So I will give you your ten minute break now.

321
00:37:15,913 --> 00:37:20,653
Why don't we come back at 155 and we'll do a deeper dive into mediation?

322
00:37:32,888 --> 00:37:41,498
I talked about how you can calculate them just simply by putting together a couple of different regression models estimating this beta and theta,

323
00:37:42,218 --> 00:37:48,338
and then you have an estimate of your indirect effect. I will say that oftentimes with.

324
00:37:50,498 --> 00:37:55,118
With these with a mediation analysis.

325
00:37:55,568 --> 00:37:56,078
I would say,

326
00:37:56,078 --> 00:38:05,498
like the big thing that we are looking to do would be to kind of come up with a measure of the proportion of mediation or the proportion mediated,

327
00:38:06,038 --> 00:38:12,158
which is basically the indirect effects over the total effect.

328
00:38:15,498 --> 00:38:24,437
So that is kind of like the thing that we search for. And if you are doing a mediation analysis, likely this will be part of your results section.

329
00:38:24,438 --> 00:38:35,738
This is percussion. And again, it's the amount of the indirect effect, which is this over the total effect.

330
00:38:37,208 --> 00:38:42,218
And I walk you through it in the homework assignment for today, but I just want to make sure you got that.

331
00:38:43,268 --> 00:38:48,158
And so this is the traditional ways that we estimate the indirect effect,

332
00:38:48,158 --> 00:38:52,358
because that's the first step in getting the proportion mediated is when you find this indirect effect,

333
00:38:53,138 --> 00:39:00,158
we can either do the difference method or the product method, but there are some problems with those.

334
00:39:00,458 --> 00:39:04,508
One is there could be confounding between the mediator and outcome.

335
00:39:05,048 --> 00:39:06,848
So like if you have this here,

336
00:39:07,718 --> 00:39:16,028
how do you deal with like a mediator outcome confounder because there's not like a really a good way of accounting for that in any of these models.

337
00:39:17,108 --> 00:39:21,578
And there could be interaction between the mediator and the exposure.

338
00:39:25,128 --> 00:39:30,438
So those are things that you really can't deal with. And this might not really be an issue.

339
00:39:30,768 --> 00:39:34,428
So if those aren't an issue, then. Like the traditional methods are probably totally fine.

340
00:39:35,058 --> 00:39:41,927
But if those are an issue, then you need to do something different. And we need to start thinking a bit more causally about this.

341
00:39:41,928 --> 00:39:46,368
So, I don't know. About a decade back, Tyler Vanderbilt,

342
00:39:46,398 --> 00:40:00,678
some of his colleagues came up with this decomposition of regression models into the mean effect and the mediation and effect modification.

343
00:40:01,278 --> 00:40:04,278
And so we were going to be talking about the mediator part of that today.

344
00:40:06,288 --> 00:40:11,508
And I'm also going to tell a story of three different people.

345
00:40:13,458 --> 00:40:16,548
I was going to. So I will draw this.

346
00:40:16,548 --> 00:40:23,528
So I will. I mean, there's already a scan from a previous year of this page.

347
00:40:23,538 --> 00:40:28,128
So if you're confused about what I'm drawing, that should already be available for you on campus.

348
00:40:28,548 --> 00:40:34,358
And there is also a recording of me from a couple of years ago just explaining this situation as well.

349
00:40:34,368 --> 00:40:40,158
So if it doesn't make sense right now, you can view the Panopto recordings,

350
00:40:40,158 --> 00:40:48,318
you can view me talking about it a couple of years ago, and I'm also happy to chat with you outside of class about this.

351
00:40:48,528 --> 00:40:59,928
But today we are going to think through like, what do we mean by like counterfactual situations and how those relate to mediation?

352
00:41:00,708 --> 00:41:05,778
I will also say that this is probably one of the more complicated things that we do in the class.

353
00:41:06,498 --> 00:41:12,948
And there are some like big takeaways from this, which I'll get to, but I can understand the nitty gritty can be a bit confusing.

354
00:41:13,158 --> 00:41:18,948
And that's that's totally fine. Don't, don't worry. This isn't immediately apparent to you.

355
00:41:21,048 --> 00:41:25,518
So we are going to be using our example of coffee, high sugar and diabetes.

356
00:41:25,968 --> 00:41:34,098
And so we and we're just going to treat these as binary variables or the commonest one.

357
00:41:34,108 --> 00:41:44,928
So X is coffee and we are going to introduce a mediator and the mediator is a high sugar diet.

358
00:41:46,758 --> 00:41:58,858
And why is diabetes? And for all of these, zero means no and one means yes.

359
00:42:01,558 --> 00:42:05,568
If they weren't able to see this, especially in the back. Okay.

360
00:42:06,888 --> 00:42:14,458
And I'll also try to graphically depict these. So like a no is going to be a circle and a one is going to be filled in.

361
00:42:20,128 --> 00:42:23,948
And what we are trying to emphasize here is that there is a.

362
00:42:28,148 --> 00:42:32,258
A relationship between these and there is a temporal relationship.

363
00:42:35,198 --> 00:42:47,288
Like so. So we think there could be something with coffee consumption which changes people's sugar consumption and then relates to diabetes.

364
00:42:47,288 --> 00:42:53,017
And of course there is the indirect effects going through with sugar levels in your diet.

365
00:42:53,018 --> 00:43:01,778
And then there is the direct effect, which is just the direct effect of coffee on diabetes, not conditioning for sugar.

366
00:43:03,218 --> 00:43:07,718
Does this conceptual model and I'll give some examples of how these things would change, but.

367
00:43:09,288 --> 00:43:13,848
Okay. So let us think about.

368
00:43:14,478 --> 00:43:22,848
So, I mean, I have these three people and there's 12 different scenarios, but just the same three people over and over again we could think of.

369
00:43:23,928 --> 00:43:28,068
This is reality. So maybe this is like what's happening in the real world.

370
00:43:33,138 --> 00:43:37,788
And it could. And again, we have to measure these like temporally over time.

371
00:43:39,198 --> 00:43:46,998
So maybe at the beginning we say that, uh, this person does drink coffee.

372
00:43:48,558 --> 00:43:53,088
They do have a high sugar diet, and they do end up with diabetes.

373
00:43:54,948 --> 00:44:01,668
So graphically, you know, I represent the tide of this as a diet follow through.

374
00:44:02,478 --> 00:44:08,928
And then I filled in diet, and then they eventually get diabetes.

375
00:44:13,048 --> 00:44:17,427
So maybe this is somebody who, you know, they drink coffee, but they don't make it black.

376
00:44:17,428 --> 00:44:24,478
They put a lot of sugar and cream in it so that like their coffee consumption is what changes their sugar consumption.

377
00:44:28,518 --> 00:44:33,828
One thing that I do want to note is so on online, on the thing that I already have scanned,

378
00:44:34,878 --> 00:44:41,568
I think I misrepresented some of the outcomes in terms of like yes or no status,

379
00:44:41,568 --> 00:44:50,057
but I think there's just like one or two examples where I didn't fill in correctly, but I think overall we get this, okay,

380
00:44:50,058 --> 00:44:59,868
so this is the first person we might have, another person who does not drink coffee but still has a high sugar diet.

381
00:45:00,468 --> 00:45:05,028
Maybe they, you know, because they don't have coffee, they need their caffeine.

382
00:45:05,478 --> 00:45:24,318
So they drink a lot of soda instead. And then we could have a third person who drinks coffee but likes it black.

383
00:45:24,328 --> 00:45:30,988
No sugar, no cream. And let's say this person doesn't get diabetes.

384
00:45:45,708 --> 00:45:49,968
So that's just like the simplified example of three different people.

385
00:45:50,118 --> 00:45:58,368
Does that timeline make sense? Okay, what we can do is we can do the counter-factual.

386
00:46:05,018 --> 00:46:08,888
The counterfactual is what I was telling you earlier.

387
00:46:09,158 --> 00:46:13,288
It's it's a it's a timeline. It's a time travel.

388
00:46:13,298 --> 00:46:16,358
We go back in time. We change what happens at the beginning.

389
00:46:16,838 --> 00:46:22,297
So for this, like, all we do is flip their axes. So let's change this person to X equals zero.

390
00:46:22,298 --> 00:46:25,808
This person to x equals one, this person to x equals zero.

391
00:46:27,248 --> 00:46:31,508
And then, you know, I'm just making up what happens. Maybe this person, they don't drink coffee.

392
00:46:31,898 --> 00:46:36,388
So that doesn't that means that they don't have this beverage, which they're constantly adding sugar to.

393
00:46:36,398 --> 00:46:41,228
So they actually have a low sugar diet. Maybe they still end up with diabetes.

394
00:46:42,818 --> 00:46:50,468
You might hear some epidemiological language saying this person is sort of doing this like they're going to get diabetes regardless.

395
00:46:52,148 --> 00:46:59,258
You know, maybe that's not like the most positive thing to talk about how to talk with somebody.

396
00:46:59,258 --> 00:47:06,548
But you do see that. And I'm just going to represent the counterfactual timeline with dots just to say that, you know, it's not.

397
00:47:09,558 --> 00:47:16,118
It's not the same timeline. It's like a different universe than the reality.

398
00:47:18,578 --> 00:47:22,358
And then I'll just fill in, you know, what happens with these other folks.

399
00:47:28,148 --> 00:47:33,858
So maybe for this person, you know, regardless of whether they have coffee or not, maybe they just always drink soda.

400
00:47:34,268 --> 00:47:39,868
So it doesn't really matter. Oh, I'm sorry.

401
00:47:39,878 --> 00:47:48,358
This should be done. But. But maybe they still get diabetes in the end.

402
00:47:50,248 --> 00:48:00,797
Person three. Maybe because they don't drink in again.

403
00:48:00,798 --> 00:48:06,468
They like the coffee black, but maybe if they don't drink coffee, they will have a sugary substance.

404
00:48:06,468 --> 00:48:14,408
So that's why this and this one and this girl, for whatever reason, is so good like this.

405
00:48:27,028 --> 00:48:33,688
Okay. So any questions about these timelines? And again, the counterfactual is just like going back in time to see what happens.

406
00:48:37,158 --> 00:48:40,938
So now is where we get a bit confusing.

407
00:48:43,608 --> 00:48:50,718
Because there's one counterfactual here, but we could also do it sort of in alternate counterfactual.

408
00:48:53,748 --> 00:48:57,258
You could also call it like a counterfactual to the counterfactual.

409
00:49:04,638 --> 00:49:12,638
This one is it starts off the same as the counterfactual. So I'm just going to fill in these first things from what I had above.

410
00:49:37,268 --> 00:49:47,468
So again, these are the exact same timelines, but now is where we get into alternate land and what we do.

411
00:49:50,538 --> 00:49:58,698
Is we change the value of the mediator. And I know what all of you are thinking right now is like, Oh, you just flipped this mediator.

412
00:49:59,178 --> 00:50:04,248
Like, if it's zero, you flip, it's one. Or if it's one, you flip it to zero. That is not what we do.

413
00:50:05,418 --> 00:50:08,477
That is like the inclination of everyone to think that.

414
00:50:08,478 --> 00:50:12,198
But that's not what we do. What we do here.

415
00:50:12,588 --> 00:50:16,338
We set. And.

416
00:50:18,828 --> 00:50:26,988
As if it was one. So the counterfactual here is not that we just directly flip em.

417
00:50:27,378 --> 00:50:32,618
What we do is we go back to the original timeline and see what the value of that is.

418
00:50:41,108 --> 00:50:46,328
So in this one, actually m equals to one.

419
00:50:49,978 --> 00:50:54,468
And that is this failure.

420
00:50:56,188 --> 00:51:05,598
So it's from up here. And it happens in this case that it is the flip of this.

421
00:51:06,438 --> 00:51:17,928
But let's look at the next example where it actually won't be that case. So for this person, we're setting the levels of M as if X equals zero.

422
00:51:21,498 --> 00:51:24,888
And for this person, it's just always going to be.

423
00:51:28,958 --> 00:51:41,958
M equals one. And then for this person, you know, we go up here.

424
00:51:41,968 --> 00:51:51,558
So this is. Setting an as if x equals one.

425
00:51:53,298 --> 00:52:04,708
And that would be. And both here. So which is all to say, like this thing here is the opposite of this.

426
00:52:12,528 --> 00:52:16,698
But we don't directly flip the MBA from what the counterfactual is like.

427
00:52:16,698 --> 00:52:29,448
We actually have to go back to the original timeline. And this is what we call the natural levels of the movie theater.

428
00:52:33,608 --> 00:52:45,538
So I called this like. Natural levels of the mediator, or we might say like natural variation.

429
00:52:53,748 --> 00:53:00,537
But you know this is somebody is. This is somebody's life.

430
00:53:00,538 --> 00:53:09,748
This is their you know, what happens after this is kind of like up to, you know, their own particular circumstances.

431
00:53:10,228 --> 00:53:17,188
So for this person, let's just say that they end up with diabetes.

432
00:53:20,528 --> 00:53:27,998
For this person. They also end up with diabetes.

433
00:53:32,268 --> 00:53:38,988
For this person. They are fortunate that in this timeline they do not interact with diabetes.

434
00:53:47,778 --> 00:53:53,478
Confusions about this at all. I mean, I think it's a very confusing topic.

435
00:53:53,478 --> 00:54:02,328
So it's not designed to make sense. It is designed to make very beautiful mathematical formulas.

436
00:54:02,328 --> 00:54:04,128
And that's why statisticians like this.

437
00:54:04,138 --> 00:54:12,438
But even I was just catching up on things before, while I was preparing for class and I was looking at how people are talking about this and,

438
00:54:12,888 --> 00:54:17,708
you know, how they talk about it in the even in epidemiology journals will be, you know,

439
00:54:17,718 --> 00:54:22,488
lots of equations just because like this, it's hard to put into words, you know,

440
00:54:22,488 --> 00:54:30,767
what does it mean that in the alternate counterfactual we're like taking their exposure from the counterfactual,

441
00:54:30,768 --> 00:54:34,338
but we're taking their mediator from, you know, reality like it.

442
00:54:34,398 --> 00:54:41,908
You know, it's confusing. So if you're thinking about why there's another level,

443
00:54:41,908 --> 00:54:50,848
you're also probably realizing that we can kind of look at a second alternate, second alternative.

444
00:54:53,038 --> 00:55:02,428
So in the second alternative, it's reality for the exits, reality for the exposure variables.

445
00:55:02,908 --> 00:55:08,518
But then it's a counterfactual for the mediator.

446
00:55:10,528 --> 00:55:16,347
So the first thing I would do is just copy down these numbers from the C of x equals one.

447
00:55:16,348 --> 00:55:23,698
X equals zero. X equals one. And then the.

448
00:55:43,188 --> 00:55:48,378
But then we'll set the mediator values based on this counterfactual.

449
00:55:50,678 --> 00:55:53,848
So I'm going to say zero.

450
00:55:53,948 --> 00:55:57,668
And that's just from up here. And of course, one and my one.

451
00:56:02,798 --> 00:56:20,908
The. And again,

452
00:56:21,118 --> 00:56:28,078
we just kind of have to make assumptions about what happens for the rest of their life in I'm

453
00:56:28,078 --> 00:56:33,058
just going to simplify this and say that everyone gets diabetes in this second alternative.

454
00:56:52,588 --> 00:57:03,657
So like a few things that I want to mention besides this, you know, kind of trying to really make a crazy time travel movie is that, you know,

455
00:57:03,658 --> 00:57:13,107
we everything that happens like at this point, of course, it's like dependent on what people's exposures are,

456
00:57:13,108 --> 00:57:15,748
what their coffee is, what their sugar consumption is like.

457
00:57:15,928 --> 00:57:19,678
You know, there's all sorts of other confounders and other things going on in people's lives.

458
00:57:20,128 --> 00:57:24,238
You know, you could have a family history of diabetes, all sorts of other things.

459
00:57:24,238 --> 00:57:32,637
So I like to kind of anecdotally make up stories, you know, like this person is doomed.

460
00:57:32,638 --> 00:57:37,918
They're just going to get diabetes regardless of their levels of coffee and sugar consumption.

461
00:57:38,398 --> 00:57:44,488
But then there are others who kind of flip on and off like this person, you know,

462
00:57:44,488 --> 00:57:49,678
if they drink coffee, that means they don't have other sugary substances, they don't get diabetes.

463
00:57:51,238 --> 00:57:56,458
But if they don't drink coffee than they do drink soda, for instance, then they do get diabetes.

464
00:57:56,758 --> 00:58:04,078
But then the alternate counterfactual relate the levels of the mediator very naturally,

465
00:58:04,948 --> 00:58:09,808
in which case, you know, they start off not drinking any coffee.

466
00:58:09,808 --> 00:58:17,468
They also don't have any soda. They don't have appetite. Yes.

467
00:58:20,418 --> 00:58:29,468
Third. Are you talking about this or rate.

468
00:58:29,988 --> 00:58:34,017
Yeah, let me actually number these rows.

469
00:58:34,018 --> 00:58:50,938
Then I can just, like, make sure that we're talking about them. Okay.

470
00:58:50,958 --> 00:58:58,338
So okay, the value for this one. So we're doing reality up here and double checking my work.

471
00:58:58,788 --> 00:59:06,798
So we start with X equals zero. And then what we do is we take the mediator value from the counterfactual world and in

472
00:59:06,798 --> 00:59:12,648
this one m equals one because in their counterfactual they still keep and of course,

473
00:59:12,648 --> 00:59:19,358
one. So we do allow like, you know, the counterfactual doesn't directly change that.

474
00:59:19,368 --> 00:59:22,218
You know, very again, we use this term naturally,

475
00:59:22,728 --> 00:59:29,988
which would be does that mean I'm not sure but like statistically that's what hear here for years from the counterfactual is not positive.

476
00:59:30,258 --> 00:59:33,438
Yeah. Kurt. Yeah, correct.

477
00:59:33,978 --> 00:59:40,398
And again, that's the thing. Like, I know because I've been in your mindset thinking about this, I think what people think is like,

478
00:59:40,398 --> 00:59:44,598
Oh, in these alternate counterfactuals, all we're doing is we're switching the level of the mediator.

479
00:59:44,838 --> 00:59:48,258
So if it was one before, it's zero now. But that's not what you do.

480
00:59:48,558 --> 00:59:52,638
You just grab the levels of the mediator from either the reality or the counterfactual.

481
00:59:53,028 --> 00:59:58,068
What you don't direct in any of these situations where we're dealing with natural indirect effects,

482
00:59:58,068 --> 01:00:02,238
natural direct effects also get too involved in this idea of like natural.

483
01:00:02,448 --> 01:00:05,468
We are not changing the values of the.

484
01:00:09,318 --> 01:00:13,348
Okay. So what does this mean? You know, this is obviously this is like la la land.

485
01:00:13,368 --> 01:00:16,638
This doesn't happen in reality. Why do we care about this?

486
01:00:17,088 --> 01:00:26,478
We care about this because this is like the thought process behind when we talk about natural, direct and natural indirect effects.

487
01:00:26,488 --> 01:00:36,168
So I'm going to explain what those are. So a natural, direct effect of.

488
01:00:40,178 --> 01:00:45,488
And just to kind of like bring this back to our original chart.

489
01:00:49,438 --> 01:01:00,058
A direct effect is looking at the the effect of the exposure on the outcome when we do control for the mediator.

490
01:01:00,268 --> 01:01:03,658
So it's kind of like outside of that mediated pathway, what's happening?

491
01:01:06,548 --> 01:01:13,028
For this like counterfactual notion of things. What we want to do is we want to.

492
01:01:16,028 --> 01:01:22,058
Counter factually. Observe the difference.

493
01:01:28,968 --> 01:01:35,598
Between X equals zero and x equals one.

494
01:01:40,308 --> 01:01:47,098
When? The mediator.

495
01:01:49,848 --> 01:01:59,118
Is set to be the level, whatever level it might be when X equals zero.

496
01:02:05,718 --> 01:02:12,168
So let us give examples of what that actually means for these three individuals.

497
01:02:17,508 --> 01:02:30,348
So we have. X equals one and we set the mediator as if x equals zero.

498
01:02:33,118 --> 01:02:38,788
And then x equals zero. When we set the mediator as if x equals zero.

499
01:02:52,258 --> 01:02:58,178
Okay. So then it's just kind of like going through these rows to see why we're wherever this is at.

500
01:02:58,198 --> 01:03:03,478
So where is that? So for a person, once it's one of these four choices.

501
01:03:04,018 --> 01:03:09,868
We look to see where is it? Where X equals one and the mediator set as if x equals zero.

502
01:03:11,638 --> 01:03:14,638
So it can't be these original situations.

503
01:03:16,348 --> 01:03:22,978
It has to be this level where we set X to be one.

504
01:03:29,538 --> 01:03:33,168
And then the mediating level is set as if X equals zero.

505
01:03:33,348 --> 01:03:44,568
And so that's the counterfactual right here. Okay.

506
01:03:44,578 --> 01:03:51,898
And then we're X equals zero. This is sort of like the easiest scenario because we're not dealing with any second alternatives.

507
01:03:53,578 --> 01:03:57,537
So we're x equals zero and we're the mediator set as if x equals zero.

508
01:03:57,538 --> 01:04:06,388
That's just ready. And so the natural, direct effect for this person would just be subtracting at least two different levels.

509
01:04:11,068 --> 01:04:16,198
Okay. Wrote to her for observation too.

510
01:04:17,098 --> 01:04:22,348
We're looking at where x equals one and setting the meter as if x equals zero.

511
01:04:26,458 --> 01:04:34,288
So for us that has to be here because X equals one and we're setting the mediator as if x equals zero.

512
01:04:38,058 --> 01:04:43,098
And then we are going to subtract out where x equals zero and setting year of x equals zero.

513
01:04:43,338 --> 01:04:46,518
And that is actually just be.

514
01:04:56,718 --> 01:04:58,488
I'm not going to purposely harm somebody,

515
01:04:58,488 --> 01:05:07,808
but I want you to like think for a few seconds to see if you can find out what's going on with person number three and then we'll come back to it.

516
01:05:29,948 --> 01:05:32,828
You kind of blew it to try to get a better camera for next year.

517
01:05:44,848 --> 01:05:52,198
I'm not going to purposely con somebody, but does anyone want to try to make a guess of what these drugs would be?

518
01:05:59,338 --> 01:06:04,827
Okay. So if we're looking at X equals one, we can, of course close out like where x does not equal one.

519
01:06:04,828 --> 01:06:11,848
So it can't be. These two is going to be has to be where we set the mediator as if x equals zero.

520
01:06:12,568 --> 01:06:16,408
So that can't be here because x is not equal zero. So it has to be here.

521
01:06:16,408 --> 01:06:23,768
So this is row L. And then here would be role as.

522
01:06:28,418 --> 01:06:34,468
Again. That's just because that is where x equals zero. Okay.

523
01:06:34,648 --> 01:06:38,758
So we might then ponder what is the natural indirect effects?

524
01:06:45,378 --> 01:06:50,658
A natural indirect effect is when we fix x equal to be one.

525
01:06:58,418 --> 01:07:01,718
And we compare outcome in outcome. You know why?

526
01:07:07,278 --> 01:07:21,198
When mediator is set as if x equals zero verses as if x equals one.

527
01:07:48,508 --> 01:07:57,718
Okay. So again, we have a situation where we're trying to look at X equals one, where we set the mediator as if X equals one.

528
01:08:01,398 --> 01:08:10,158
And then we have a situation of, you know, we're fixing X equals one, but we set the mediator as if X equals zero.

529
01:08:14,128 --> 01:08:18,868
So I did this for the direct effect where we're looking at changes in X.

530
01:08:22,278 --> 01:08:29,178
We're we're setting the media values to be not necessarily consistent, but under the same counterfactual scenario where X equals zero.

531
01:08:29,778 --> 01:08:35,928
Whereas here we're fixing the levels of x, but we're changing the values then beta.

532
01:08:38,828 --> 01:08:50,558
Okay. So X equals one where the mediator says If X equals one, that means we're living in this, this reality or the first counterfactual.

533
01:08:51,188 --> 01:08:55,178
So four person one x equals one. So that's just row a.

534
01:08:57,838 --> 01:09:02,638
For Person two, we look to see where x equals one that is row e.

535
01:09:06,128 --> 01:09:09,277
And then for person three, we're looking for X equals one.

536
01:09:09,278 --> 01:09:16,868
So that is a C and then we're subtracting out when x equals one where we're setting the mediator as if x equals zero.

537
01:09:17,258 --> 01:09:20,468
So that's where we're looking in this round of the world.

538
01:09:21,998 --> 01:09:28,268
So basically we just have to see where X equals one for each of these individuals.

539
01:09:30,368 --> 01:09:37,598
So for person one, we are looking at the age.

540
01:09:41,468 --> 01:09:47,538
Not rich. It had to be real. So it's X equals one.

541
01:09:52,428 --> 01:10:03,188
Yeah. Sister AJ, sorry. Except the media said this one.

542
01:10:04,208 --> 01:10:09,008
So for a person to we're looking at where X equals one.

543
01:10:09,278 --> 01:10:15,608
But setting the mediator as if x equals zero. So where x equals one for this person.

544
01:10:16,208 --> 01:10:26,138
We're setting the mediator as if x equals zero. So this is row H and then for person three also looking to see where x equals one.

545
01:10:27,008 --> 01:10:32,917
So that has to be down here. And we are looking where the mediator said as if x equals zero.

546
01:10:32,918 --> 01:10:41,238
And again, that goes for right here for the x equals. Okay.

547
01:10:41,478 --> 01:10:53,178
So, you know, that is 30 minutes going over these crazy bonkers timelines and that gets at these natural direct effects and natural indirect effects.

548
01:10:54,948 --> 01:11:03,828
And why do we care so much about this? And so maybe the takeaway, because I understand these timelines can get messy.

549
01:11:04,968 --> 01:11:07,578
The takeaway here is that, you know, first off,

550
01:11:07,578 --> 01:11:14,298
if you're going into an epidemiology PhD and you're going into causal inference, you'll get a lot deeper into this.

551
01:11:15,108 --> 01:11:24,468
But what I would want in epidemiology and student is just to understand that, one, when we're talking about natural variation,

552
01:11:24,978 --> 01:11:30,708
we aren't necessarily directly changing the levels of the good eater, but letting them naturally vary based on levels of X.

553
01:11:31,518 --> 01:11:34,998
But maybe more broadly, like, you know, we're four or five years down the line.

554
01:11:35,388 --> 01:11:38,177
If you read a paper which says something about natural,

555
01:11:38,178 --> 01:11:44,228
direct and indirect effects that serve our thinking about like alternate timelines, including counterfactuals and ultimate of.

556
01:11:51,558 --> 01:11:52,518
Okay. So.

557
01:11:54,818 --> 01:12:03,428
Back in the slides in what I was mentioning earlier, when we're talking about like the cymbal or the Burnin Kenny approach, which is, you know,

558
01:12:03,818 --> 01:12:07,207
the difference method or the product coefficient method,

559
01:12:07,208 --> 01:12:11,198
that's obviously much easier than trying to think through like these alternate timelines and whatnot.

560
01:12:13,058 --> 01:12:21,038
But the problem with those is that they have problems of the media outcome confounding and there could be interaction.

561
01:12:22,118 --> 01:12:27,187
So, you know, the methodologies who came up with these crazy counterfactual timelines realized that

562
01:12:27,188 --> 01:12:33,728
the equations which came out of these crazy timelines were actually very beautiful.

563
01:12:34,238 --> 01:12:37,778
They were able to account for mediator, outcome confounding.

564
01:12:38,258 --> 01:12:45,608
We were able to kind of push away this idea of interaction through like a decomposition analysis.

565
01:12:47,288 --> 01:12:50,108
So basically, like these crazy timelines that I'm talking about,

566
01:12:50,498 --> 01:12:56,918
those are able to directly respond to these limitations of the traditional mediation methods.

567
01:12:58,768 --> 01:13:09,678
But that doesn't make it any easier. You know, these are crazy time travel and like different types of time travel, you know, like multiple timelines.

568
01:13:09,688 --> 01:13:16,858
It is, you know, it's it's it's crazy. But that leads to like what we can what we can estimate.

569
01:13:17,368 --> 01:13:23,488
So let's start with the natural, direct and natural indirect effects. And that's what I was trying to like emphasize to you.

570
01:13:23,488 --> 01:13:32,588
But here's it written and I can kind of restated a natural direct effect is how much our outcome would change if our treatment changed from that,

571
01:13:32,638 --> 01:13:40,498
you know, x equals zero to X equals one. And we kept our mediator at a level where it would be in the absence of exposure.

572
01:13:40,918 --> 01:13:44,128
So let's go back to our coffee diabetes example.

573
01:13:44,878 --> 01:13:58,288
The natural direct effect is just how much would changes in a coffee consumption effect diabetes.

574
01:14:00,728 --> 01:14:12,008
If the levels of the mediator, if you're if your sugar consumption was kept at a level as if you didn't drink coffee.

575
01:14:14,798 --> 01:14:22,478
Again, it's confusing something extent again. So natural direct effect is how much is like what is the direct effect?

576
01:14:22,478 --> 01:14:32,858
What is the effect of coffee consumption on diabetes where your sugar like how much sugar you had your diet?

577
01:14:33,718 --> 01:14:37,328
We kept that at a level as if you did not drink coffee.

578
01:14:38,738 --> 01:14:42,967
So again, for some people, that might mean that they drink a lot of coffee, for they have a lot of sugar.

579
01:14:42,968 --> 01:14:50,078
For some people, it's not that's like an individual behavioral thing, a natural indirect effect.

580
01:14:50,768 --> 01:14:55,898
How much would the outcome change if the exposure were fixed at a level of x equals one?

581
01:14:56,258 --> 01:15:01,388
But the mediator change from the level would be if x equals zero to the level would take effects equals one.

582
01:15:01,868 --> 01:15:11,528
So what does that mean in our example? So how much diabetes would there be if we fixed everyone to be drinking coffee?

583
01:15:13,818 --> 01:15:21,948
But we changed sugar consumption as if people did not drink coffee to if they did drink coffee.

584
01:15:24,788 --> 01:15:26,708
So for some people, that's the same level.

585
01:15:27,098 --> 01:15:34,268
For some people, they are going to have a high sugar diet regardless of, you know, if they if they drink coffee or not.

586
01:15:34,298 --> 01:15:39,127
But for some people, you know, that could change. Okay.

587
01:15:39,128 --> 01:15:47,738
So those are natural, direct, natural and indirect effects. You'll see them in in journal articles probably most of the time that you see them.

588
01:15:47,738 --> 01:15:53,138
People will either try to disguise their interpretation with all sorts of crazy formulas,

589
01:15:53,528 --> 01:15:58,418
or they'll just try to ignore, you know, the radical implications of this,

590
01:15:59,828 --> 01:16:08,168
which is what I do, because it's very hard to explain this using words controlled direct effects are kind of a different way of looking at things.

591
01:16:08,168 --> 01:16:15,068
This is not the time, right approach in control. Your defects are probably what you're thinking about when you're thinking of a direct effect.

592
01:16:15,758 --> 01:16:23,018
A controlled direct effect is how much the outcome would change if we fixed the level of a mediator.

593
01:16:23,648 --> 01:16:30,068
So for there are as many controlled direct effects as there are levels of your mediator.

594
01:16:30,068 --> 01:16:31,178
So think of our example.

595
01:16:31,748 --> 01:16:38,048
We have coffee, diabetes and we have just two levels of sugar consumption are high sugar consumptions, very low sugar consumption.

596
01:16:38,288 --> 01:16:44,107
Again, that's obviously very simplistic. Let's just look at that world with simple what a controlled direct effect is saying.

597
01:16:44,108 --> 01:16:54,097
That is, what is the effect of coffee consumption on diabetes for every for everyone

598
01:16:54,098 --> 01:17:01,688
that would have a high sugar diet or we could do a controlled direct effect.

599
01:17:02,738 --> 01:17:11,858
Looking at what is the effect of coffee on diabetes incidence if we set everyone to have low sugar consumption.

600
01:17:14,108 --> 01:17:19,988
So the thing again with controlled direct effects is there is as many controlled direct effects as there are levels of the mediator.

601
01:17:21,758 --> 01:17:31,148
But, you know, the one thing about controlled direct effects is that they kind of have a policy implication because with control,

602
01:17:31,158 --> 01:17:39,518
direct effects, we could think about like, oh, could we? Maybe we can't intervene on the exposure, but maybe we could intervene on the mediator.

603
01:17:40,028 --> 01:17:44,678
Let me give you another example. Like maybe we are looking at cigaret consumption and lung cancer.

604
01:17:45,428 --> 01:17:54,848
So obviously, you know, the more you smoke, the more you are the higher risk you have for cancer.

605
01:17:55,808 --> 01:17:59,918
Maybe one of the mediators of that is the tar levels in the cigaret.

606
01:18:00,968 --> 01:18:08,588
So what we could do is we could maybe on a policy level, like if we're not wanting to ban cigarets,

607
01:18:08,918 --> 01:18:13,718
maybe what we could do is we could just lower the levels of tar in the cigarets.

608
01:18:16,168 --> 01:18:24,478
So our controlled direct effect then is we could try to to do a study maybe before implementing this policy just to make sure that,

609
01:18:24,508 --> 01:18:36,147
you know, it works. But we could see, we could estimate what would the effect of cigaret consumption be on lung cancer.

610
01:18:36,148 --> 01:18:45,898
If we set the tar levels, we really look like maybe we just are able to like super reduce the tar levels within the cigaret.

611
01:18:52,948 --> 01:18:58,378
Okay. The other thing with this is for natural direct effects.

612
01:18:58,378 --> 01:19:04,348
In natural indirect effects, you can use those to compute a proportion mediated.

613
01:19:06,208 --> 01:19:12,298
So the proportion mediated in this counterfactual example is the natural and direct effect over the total effect.

614
01:19:13,438 --> 01:19:20,518
And this number will often be very similar to the difference method or the product of coefficients method.

615
01:19:22,018 --> 01:19:25,138
So in the homework for the class today,

616
01:19:25,528 --> 01:19:42,058
you will be doing these equations to compute the difference method and the coefficient of products are the product of coefficients method.

617
01:19:42,988 --> 01:19:47,818
You'll be doing those, but I will just give you the output of the counterfactual example.

618
01:19:48,658 --> 01:19:55,168
So that is, you know, hints for people. And this or this week's homework is the last part of the homework.

619
01:19:55,438 --> 01:20:03,988
I give you the output from SAS. You could do this in R, but I'm just giving you the output from SAS and it should be like readily interpretable.

620
01:20:04,288 --> 01:20:07,918
You just you don't need to calculate the proportion mediated.

621
01:20:07,918 --> 01:20:10,318
There already is a proportion in the table.

622
01:20:12,328 --> 01:20:20,397
So just like choose that number where it says percent mediated or proportion mediated, I don't know how they label it, but that's the number you get.

623
01:20:20,398 --> 01:20:26,938
You don't need to calculate like the natural, natural, indirect factor of the total effect there already the the program already this effort.

624
01:20:29,588 --> 01:20:32,888
So the proportion eliminated is where we use the control direct effect.

625
01:20:36,928 --> 01:20:44,548
And you know, the proportion mediate in the profession eliminated the kind of our theoretically they come from this idea of like,

626
01:20:44,548 --> 01:20:51,447
oh, let's let's have a mediator, a mediation model where we are adjusting for a mediator.

627
01:20:51,448 --> 01:20:54,958
And then what is the the proportion which is due to this mediator?

628
01:20:57,598 --> 01:21:02,728
But the reason why we say proportion of eliminated out proportion mediated is oftentimes these numbers are slightly different.

629
01:21:04,438 --> 01:21:08,698
The proportion eliminated is more of like a policy relevant measure.

630
01:21:09,178 --> 01:21:14,428
And here we're looking at, you know, in the secret example,

631
01:21:14,428 --> 01:21:19,498
like how much of that disparity in lung cancer between cigaret smokers and non cigaret smokers,

632
01:21:19,498 --> 01:21:28,468
how much of that could be eliminated if we were to like on a policy level, intervene and remove a certain amount of tar from cigarets?

633
01:21:32,618 --> 01:21:41,318
So I guess another way of thinking about it is because the control direct effect is the effect of the exposure on the outcome that is not mediated.

634
01:21:42,068 --> 01:21:47,588
So it doesn't go through the intermediate and that's and then we're fixing that level.

635
01:21:47,948 --> 01:21:54,488
And so like on a policy level, maybe we like proportional mediator because maybe we are trying to decide between,

636
01:21:54,488 --> 01:22:01,658
you know, removing all of the tar or maybe moving like a bit or, you know, some a tiny amount.

637
01:22:02,028 --> 01:22:07,988
Those are things that we could test for with the proportionality, because, again, the controlled direct effect,

638
01:22:07,988 --> 01:22:15,008
there's as many controlled direct effects as there are levels that are mediated, but per person mediated is more of like a causal inference method.

639
01:22:15,008 --> 01:22:21,548
It's more of like a causally or mechanistically, like how do these variables relate to each other?

640
01:22:22,718 --> 01:22:25,598
So I would say if you're more of a policy person who is per person limited,

641
01:22:25,898 --> 01:22:29,528
or if that's kind of what you're interested in for your paper or your analysis,

642
01:22:29,828 --> 01:22:34,808
perversion mediated is just kind of looking at what is the what are the causal relationships between everything.

643
01:22:37,878 --> 01:22:45,707
Okay. So I know that today is a lot, but so I'll let you go in a moment.

644
01:22:45,708 --> 01:22:51,648
But for the study guide, you know, I don't expect you to like it.

645
01:22:51,678 --> 01:22:59,118
I would never give you timelines and have you kind of can compute with the natural direct effect to naturally direct effect of that's,

646
01:22:59,538 --> 01:23:03,678
you know, beyond what you need to do as students.

647
01:23:05,118 --> 01:23:07,818
But I want you to think conceptually about the difference between per person and limit.

648
01:23:07,818 --> 01:23:16,758
Either proportion mediated again eliminated be more of a policy measure and mediation is kind of thinking more about,

649
01:23:18,168 --> 01:23:22,548
you know, what are the relationships between these variables on more of a theoretical level.

650
01:23:23,658 --> 01:23:28,547
And then, you know, that does relate to control direct effect, a natural direct effect control.

651
01:23:28,548 --> 01:23:34,518
Direct effect is where we fix the level of the mediator. And I think conceptually that's probably what you're thinking happens.

652
01:23:35,148 --> 01:23:41,328
Whereas a natural, direct effect is where we are having both these crazy timelines and trying to pick out,

653
01:23:41,538 --> 01:23:44,028
you know, what happens to the exposure versus the mediator.

654
01:23:44,418 --> 01:23:50,778
And because it's like convoluted to see all these crazy timelines, we just use the word natural variation.

655
01:23:55,388 --> 01:24:02,427
Any questions for me? Okay with that.

656
01:24:02,428 --> 01:24:04,168
I will leave you for today.

657
01:24:04,168 --> 01:24:10,348
Please make sure to if you haven't already signed the entire attendance sheet on your way out and then if you could put your

658
01:24:10,858 --> 01:24:17,788
name tags in with your group placards and then put them on the table up front and I'll stay here if you have any questions.

