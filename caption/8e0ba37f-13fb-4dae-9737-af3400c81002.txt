1
00:00:00,690 --> 00:00:12,239
So the exams have been the grading is complete and the two sides are essentially now tabulating the scores and,

2
00:00:12,240 --> 00:00:15,569
you know, kind of looking into spreadsheets.

3
00:00:15,570 --> 00:00:25,740
And so you will have your exams back this afternoon and they will be put in your mailboxes.

4
00:00:27,630 --> 00:00:34,740
So this is what I would recommend you produce after you get your exams back.

5
00:00:35,190 --> 00:00:42,810
And the solutions will also be posted on canvas this afternoon.

6
00:00:43,260 --> 00:00:52,230
So go to your exam, go to the solutions and see where you may have made mistakes.

7
00:00:52,920 --> 00:01:08,580
And if you have questions like, you know, specific questions related to your exam, feel free to drop me an email on Tuesday when we come back,

8
00:01:08,880 --> 00:01:15,209
because by then you all have had a chance to kind of go through your exams, review the solutions,

9
00:01:15,210 --> 00:01:26,280
and kind of compare the solutions with your specific set of mistakes and have the chance to maybe ask.

10
00:01:28,230 --> 00:01:38,610
So when we come back on Tuesday, we will spend some part of the lecture to talk about some common mistakes.

11
00:01:39,690 --> 00:01:48,749
So we will not talk about, like, things that are already in the solution and things that they may be a few people may have missed.

12
00:01:48,750 --> 00:02:01,950
But this is to allow you to give ample time to sort of go back and review the solutions and and think about where you might have gone wrong.

13
00:02:01,950 --> 00:02:10,350
Is it like a silly mistake to send us and often overlooked, or is it something like a fundamental gap?

14
00:02:12,900 --> 00:02:18,240
And we'll go through that process.

15
00:02:18,240 --> 00:02:22,200
You will go through that process with your self.

16
00:02:22,200 --> 00:02:27,390
And then Tuesday, when we come back, by then you have already looked at it.

17
00:02:28,290 --> 00:02:32,010
Then we will spend some time talking about some common mistakes.

18
00:02:32,400 --> 00:02:36,600
Okay, so that's the plan with the exam.

19
00:02:36,600 --> 00:02:45,210
So you will get your exams back. Do they have any questions?

20
00:02:49,280 --> 00:02:55,570
Any comments? How did the sixth one example.

21
00:02:59,980 --> 00:03:03,030
See. It was easier than I was expecting.

22
00:03:04,200 --> 00:03:27,930
Our expectation. Anybody has any questions either on the material or class admin staff or having the solutions.

23
00:03:29,670 --> 00:03:37,800
I feel like after the first time it's kind of the semester picks up a different kind of face.

24
00:03:40,020 --> 00:03:43,190
So you all might be already feeling that, but.

25
00:03:45,870 --> 00:03:49,800
Okay. No questions. So what? Let's let's do this.

26
00:03:49,830 --> 00:04:08,140
What I'm going to do is. I'm going to. I'm going to sort of pointedly pick up from where we left last Thursday.

27
00:04:11,650 --> 00:04:18,760
This is module DX hypothesis testing, multiple linear regression.

28
00:04:18,760 --> 00:04:36,790
And for again, for folks who were not there on Thursday, we introduced two, but I should say one very important and a very fundamental concept.

29
00:04:36,790 --> 00:04:46,510
And that's the extra somewhat square principle and not just to kind of, you know,

30
00:04:46,780 --> 00:04:52,690
put things into context and maybe and also maybe refresh memory for folks who work there.

31
00:04:54,010 --> 00:05:04,900
So the extra sum of squares basically can be viewed in either of two ways.

32
00:05:06,580 --> 00:05:15,909
It can be viewed as the reduction in the sum of squares error or the increase in the

33
00:05:15,910 --> 00:05:21,880
regression sum of squares when one or more predictor variables are added to the model.

34
00:05:24,640 --> 00:05:37,390
And in a sense, when we add a predictor to a model, the idea is, or the hope is that we explain more of the variability in the, in the,

35
00:05:37,390 --> 00:05:49,870
in the response by regression and the goal and in saving and other, we really use some of the unexplained variation of some of the error.

36
00:05:50,890 --> 00:06:03,310
So that's the idea. And extra sum of squares quantifies how much variability we explain by adding more predictor.

37
00:06:03,310 --> 00:06:09,370
So how much increase in ss r do we have by adding more predictors?

38
00:06:09,370 --> 00:06:13,629
Or alternatively, how much error we reduce?

39
00:06:13,630 --> 00:06:21,030
Or how much of the unexplained variation do we did reduce by adding more predictors?

40
00:06:21,120 --> 00:06:25,570
So that's the fundamental concept of extra sample squares.

41
00:06:26,020 --> 00:06:35,650
And once again, like on Thursday, we sort of we really in terms of the number of slides,

42
00:06:35,950 --> 00:06:43,450
we went up to slide seven of module three, slide eight of module G.

43
00:06:44,140 --> 00:06:49,180
So we kind of stopped here last Thursday.

44
00:06:50,680 --> 00:06:58,000
So, you know, please go back and you know, if you are not there, please go back and listen to the to the audio recording.

45
00:06:58,360 --> 00:07:06,760
But what I want to stress is, although we kind of in terms of the quantity, we went up the Slide eight,

46
00:07:07,090 --> 00:07:16,390
but the most fundamental concept we thought during last Thursday was this principle of extra sample space,

47
00:07:16,450 --> 00:07:28,120
because we are going to now take that extra sum of squares and basically we are going to show that you can

48
00:07:28,120 --> 00:07:39,400
formulate any hypothesis testing in multiple linear regression through the principle of extra samples.

49
00:07:40,840 --> 00:07:49,840
Okay, so that's where we are going to pick up from. We also talked about the concept of partial and sequential sum of squares,

50
00:07:50,230 --> 00:08:02,130
and we also sort of argued that and basically the partial almost versus when you are essentially for each for mediate,

51
00:08:02,140 --> 00:08:11,350
you are assessing the effect of adding that given everything else was in the model and the

52
00:08:11,350 --> 00:08:19,990
sequential sum of squares is where you are adding covariates one at a time or in clusters,

53
00:08:20,770 --> 00:08:27,880
but sequentially. So the order is important in which order you for any convenience that becomes important.

54
00:08:29,230 --> 00:08:40,690
Once again, both the partial and the sequential sample squared can be cast in the framework of extra sum of squares.

55
00:08:41,140 --> 00:08:53,160
And we showed that basically each of these testing frameworks can be sort of framed or tested using the extra sum of questions.

56
00:08:53,170 --> 00:08:57,490
But so that's the most fundamental concept we talked about.

57
00:08:58,000 --> 00:09:05,580
Last Thursday. No, we are going to carry it forward from from here.

58
00:09:06,400 --> 00:09:12,250
And we are going to first talk about nested models.

59
00:09:13,390 --> 00:09:27,130
And then I will convince you that any general hypothesis testing, multiple linear regression can be tested using this extra some of this principle.

60
00:09:27,190 --> 00:09:37,270
So what is what is a nested monitor? What nested model models are nested if they use the same variables and cases,

61
00:09:37,930 --> 00:09:43,210
but one model specifies at least one additional parameter to be estimated.

62
00:09:44,050 --> 00:09:47,200
So in other words, there is a there is a larger model.

63
00:09:47,680 --> 00:10:02,480
And as a special case, you can construct a model which is a sub model of the larger model that fear models are called nested within each other.

64
00:10:02,500 --> 00:10:14,830
So the model that has more parameters or fewer restrictions is on the on the parameters is the flow model.

65
00:10:16,180 --> 00:10:18,730
So the larger model is the full model.

66
00:10:21,250 --> 00:10:29,440
And of course, the definition of full model would change in the context of what you are thinking on what you are testing.

67
00:10:30,550 --> 00:10:37,720
But and the model with more parameters is the, the larger model or the full model.

68
00:10:37,720 --> 00:10:45,160
And the model that has less parameters or more restrictions on the parameters is called the restricted model,

69
00:10:45,160 --> 00:10:48,310
or sometimes also referred to as the reduced model.

70
00:10:52,140 --> 00:11:00,360
And you'll see why it's called reduced or restricted, because the idea is from the full model of the larger model,

71
00:11:01,020 --> 00:11:13,710
you can actually get the restricted or the reduced model by restricting or specifying part of the parameter space.

72
00:11:15,630 --> 00:11:21,840
And a common example is you kind of start off or read some of the pattern, Anderson,

73
00:11:21,840 --> 00:11:30,600
that bigger model zero to get the restricted or the reduced model and the restricted model is said to be nested within the full model.

74
00:11:31,540 --> 00:11:37,560
Okay. So that's the concept of nested models.

75
00:11:37,890 --> 00:11:42,960
So let's look at a couple examples as a special case.

76
00:11:43,170 --> 00:11:50,490
Do multiple linear regression so nested if the covariate setting one is a subset.

77
00:11:53,240 --> 00:12:06,650
Of the Covidiots said of the other. So and the first example, the first set of models is a set of nested models.

78
00:12:08,030 --> 00:12:19,640
So I had the big model. In this case I have y equals 2x1 beta one classics, two beta, two plus three beta, three plus epsilon.

79
00:12:20,060 --> 00:12:32,660
And I have two other models y equal to x, one beta, one plus epsilon and y equal to x one beta, one plus activator, three plus epsilon.

80
00:12:33,050 --> 00:12:41,320
So here in this first set of models, I am I'm arguing that these are a set of nested models.

81
00:12:41,330 --> 00:12:44,389
Why? Look, let's look at this first model.

82
00:12:44,390 --> 00:12:48,500
This is what I'm going to call the this is the largest of the three models.

83
00:12:48,500 --> 00:12:54,830
Right. And this is mindfully model in this context.

84
00:12:55,430 --> 00:13:02,720
Now, as you can see, this second model here is a special case of this full model.

85
00:13:03,140 --> 00:13:13,730
When I have Meade beta two and beta three equal to zero, it would be that when we did see our vectors.

86
00:13:16,230 --> 00:13:25,350
So the second model is a special case of the first model where I have restricted beta two and three to be zero.

87
00:13:27,720 --> 00:13:32,160
So model two is nested within model one. What about model three?

88
00:13:32,190 --> 00:13:42,630
Model three is also nested within model one because I can get model three by stripping beta two equal to zero.

89
00:13:45,780 --> 00:13:54,120
So basically I have a once again model three is a restricted or reduced model

90
00:13:54,720 --> 00:14:00,000
and it is a special case of model one when I've made that an equal to zero.

91
00:14:00,000 --> 00:14:04,800
So these three models make up a set of nested models.

92
00:14:05,430 --> 00:14:09,720
Model two is nested within model one. Model three is nested within level one.

93
00:14:10,650 --> 00:14:16,140
What about the next set in this set of models?

94
00:14:21,820 --> 00:14:32,890
Are these two models nested? Can I get model two as a clearly the first model is the largest or the larger of the two models.

95
00:14:33,340 --> 00:14:43,570
So the fourth model is my full model. But can I get model two as a special case of this fourth model?

96
00:14:46,480 --> 00:14:52,780
No, I cannot. I can meet beta two and beta three equal to zero.

97
00:14:53,410 --> 00:14:55,750
But then I'll only get this part.

98
00:14:56,800 --> 00:15:08,320
But in model two now I'm bringing in some additional four gradients and additional parameters, of course, that are associated with this.

99
00:15:08,320 --> 00:15:19,930
For me it's x4 beta four. So model two cannot be shown as reduced model of from model one.

100
00:15:21,160 --> 00:15:24,460
So these two models are not nested.

101
00:15:29,150 --> 00:15:35,090
Okay. This is the excavator for park and bring in extra.

102
00:15:36,230 --> 00:15:42,260
So these two models are not listed yet.

103
00:15:43,550 --> 00:15:49,380
Oh. What's. Why do I care about nested models?

104
00:15:49,400 --> 00:15:53,540
So what? What do I gain?

105
00:15:54,680 --> 00:16:00,500
Or what am I trying to achieve by sort of talking about these nested models?

106
00:16:01,130 --> 00:16:21,860
And the reason I'm talking about these nested models is I can show that in multiple linear regression, all kinds of hypothesis, be it, you know,

107
00:16:21,860 --> 00:16:27,020
a hypothesis test related to a single framework or that's, you know,

108
00:16:28,610 --> 00:16:36,740
a single coefficient or the overall left test or a test for poverty itself subset.

109
00:16:37,220 --> 00:16:45,650
All of these major types of hypothesis tests can be performed using one single framework,

110
00:16:46,340 --> 00:16:58,760
and then I can construct then the models under the null and the alternative hypotheses as to nested models.

111
00:16:59,930 --> 00:17:15,590
And I can use the principle of extra sum of squares to construct the hypothesis test, to construct that general, if best under any of these scenarios.

112
00:17:16,700 --> 00:17:27,110
Okay. So I'm going to repeat this because this is very really important, you know, and to to get it right conceptually.

113
00:17:27,560 --> 00:17:31,969
So what I am going to show you, this is epsilon.

114
00:17:31,970 --> 00:17:44,540
I what I'm going to show you that big any general multiple linear regression framework.

115
00:17:44,570 --> 00:17:52,670
So here I have a model y are equal to beta now plus 1x7 plus beta to excite two plus because the excite three plus epsilon a random error.

116
00:17:52,680 --> 00:17:59,020
So I have three covariance expanded strictly and the coefficients associated with those are between b.

117
00:17:59,040 --> 00:18:06,180
That will be what I am going to convince you using these two key ideas.

118
00:18:07,040 --> 00:18:18,370
The principle of extra sum of squares. And nested models.

119
00:18:21,780 --> 00:18:23,879
Using these two key ideas,

120
00:18:23,880 --> 00:18:37,710
I'm going to convince you that all major types of hypothesis tests can be performed using a single framework to beat the overall test.

121
00:18:38,100 --> 00:18:44,670
If test that we have been talking about, you know, starting from module E,

122
00:18:46,050 --> 00:18:59,790
where you are simultaneously testing all the parameters equal to zero under the null hypothesis or whether you are doing a single covariant test.

123
00:18:59,880 --> 00:19:06,780
Does the impact of effect of it on systolic blood pressure, is that association significant?

124
00:19:06,810 --> 00:19:16,620
So taking within the framework, taking each albeit one at a time or a conceptually a new idea.

125
00:19:16,620 --> 00:19:22,079
And I think this was the question that had come up like this for corporate subset and we talked

126
00:19:22,080 --> 00:19:36,299
about test for corporate subset in the context of some of the context of a minimum of a scenario.

127
00:19:36,300 --> 00:19:44,070
Let's say when you have sociodemographic variables, you have like physiological variables,

128
00:19:44,070 --> 00:19:53,340
clusters of variables that you would say that, okay, I want to understand the association of the physiologically both on outcome.

129
00:19:54,180 --> 00:19:57,180
I want to answer we talked about age, gender, height,

130
00:19:57,180 --> 00:20:04,590
weight and then income education as different kinds of variables like clusters of building blocks of subsets of over IDs.

131
00:20:05,760 --> 00:20:15,150
So we can also construct test for COVID in subset where we are only looking at a group of or variants or a,

132
00:20:15,570 --> 00:20:22,200
you know, the simultaneous effect of a group of coefficients associated with this covariates.

133
00:20:23,550 --> 00:20:36,810
And that can also be cast in this general framework using the know the ideas of extra sum of squares and nested models.

134
00:20:38,280 --> 00:20:43,800
So let's see, how do how do we do that x statistic?

135
00:20:44,190 --> 00:20:52,220
The general form. For comparing any two nested models.

136
00:20:53,090 --> 00:20:56,840
And the F statistic is going is of this form.

137
00:20:56,960 --> 00:21:06,080
The keyword here is nested models. So the F is the extra sum of squares.

138
00:21:06,260 --> 00:21:10,820
This SS denotes the extra sum of squares.

139
00:21:18,260 --> 00:21:23,150
And again, how do I how do they define the extra sum of growth for Somersworth?

140
00:21:23,780 --> 00:21:33,380
Is the increase in the regression sum of squares going from the smaller model to the long term model?

141
00:21:33,440 --> 00:21:41,060
Or conversely, the decrease in the error sum of squares going from the larger to the smaller model?

142
00:21:41,420 --> 00:21:50,750
Okay, so it's the extra sum of squares divided by the additional number of parameters in the bigger model.

143
00:21:51,770 --> 00:21:59,420
So the model under each one. So that's why I say it's the degree of freedom associated with the extra sum of squares.

144
00:22:03,750 --> 00:22:22,020
And in the numerator I have my friend that I have, you know, my, my sort of long time friend, the MSP.

145
00:22:23,190 --> 00:22:35,129
I have a subscript one here to denote that this is the MSE under the alternative hypothesis, under H1, not H1 is the black term model.

146
00:22:35,130 --> 00:22:37,830
H1 is the full model, H1 is the bigger model.

147
00:22:38,430 --> 00:22:50,459
So this has an F distribution with degrees of freedom equal to the degrees of freedom associated with extra sum

148
00:22:50,460 --> 00:22:59,040
of squares that's in the numerator and the degrees of freedom associated with the error in the bigger model,

149
00:22:59,130 --> 00:23:14,880
the full model. So basically I can show that once again the extra sum of squares and you can think of it either as the increase in the excess

150
00:23:14,880 --> 00:23:22,020
are going from the smaller to the bigger model or the decrease in the SSP going from the bigger to the smaller model.

151
00:23:23,220 --> 00:23:31,020
And when I see the bigger versus smaller the eight, the model under the null each not this is the restricted model, right?

152
00:23:31,020 --> 00:23:40,500
This is the smaller model and the model under H1 is the bigger model.

153
00:23:52,400 --> 00:24:07,820
Yeah. So this is the smaller model has fewer parameters and this is the larger model model and each one has more parameters.

154
00:24:10,940 --> 00:24:16,129
And similarly, you can define the degrees of freedom associated with the extra sum of squares

155
00:24:16,130 --> 00:24:25,100
as the difference in the inner degrees of freedom associated with a going

156
00:24:25,100 --> 00:24:37,370
from the larger to the smaller model or the degrees of freedom associated with SS are going from the smaller to the larger model and MSE subscript.

157
00:24:37,370 --> 00:24:46,880
One in the denominator is basically our estimate of Sigma Square based on the fuller model,

158
00:24:47,120 --> 00:24:50,150
based on the full model and the bigger model, the model of each one.

159
00:24:50,540 --> 00:24:53,630
So this is the general form of the F.

160
00:24:54,950 --> 00:25:05,959
Now let's see, let's kind of go farther and show you the sort of the details of this.

161
00:25:05,960 --> 00:25:15,890
So here is the general form of the F. Suppose I have a double x now.

162
00:25:16,100 --> 00:25:31,190
As we were doing last Thursday, we partitioned the design matrix X into x1 and X2 and I gave this example.

163
00:25:33,680 --> 00:25:37,339
So just let me show you where we talked about.

164
00:25:37,340 --> 00:25:45,890
Okay. So here is the concept of partitioning the design matrix into X, into x1 x2.

165
00:25:46,190 --> 00:25:52,669
So imagine X is age, gender, height, weight, income,

166
00:25:52,670 --> 00:26:02,180
education and sort of a meaningfully partitioning of this X into x1 x2 you can think of

167
00:26:02,480 --> 00:26:10,129
let's collect in X1 the sort of the sociodemographic not not the social demography,

168
00:26:10,130 --> 00:26:14,300
but more about the sort of the physiological variables.

169
00:26:14,570 --> 00:26:29,600
So I have age, gender high generating x1 and then x2 is that I bring in kind of socio economic factors, income, education.

170
00:26:30,170 --> 00:26:35,150
So I'm partitioning this X design matrix into X1 and school.

171
00:26:36,890 --> 00:26:43,880
And now see, I'm interested in different kinds of hypotheses about the effect of,

172
00:26:44,160 --> 00:26:50,480
of age, gender, height, weight, income indication as a different cluster.

173
00:26:50,930 --> 00:27:00,200
And we are going to cast all of those in this general framework of F test using that extra sum of squares principle and nested models.

174
00:27:00,200 --> 00:27:08,540
So just to give you context, this is what partitioning of the design matrix would look like.

175
00:27:09,410 --> 00:27:14,450
So here I have x partitioned into x1 and x2.

176
00:27:15,710 --> 00:27:24,170
X1 is a matrix x2 the matrix. And correspondingly I partition the barometer vector beta.

177
00:27:24,650 --> 00:27:31,160
So beta transpose is beta remember is a column vector.

178
00:27:31,520 --> 00:27:31,940
Right.

179
00:27:34,400 --> 00:27:44,510
So I, I take the transpose and make it into a all vector and correspondingly I partition corresponding to the partitioning on that design matrix.

180
00:27:44,510 --> 00:27:48,440
I partition the barometer vector space as well.

181
00:27:48,950 --> 00:28:04,040
So I have one transpose beta two transpose and beta one is ap1 across one vector and beta to is a P2 growth one vector my x designed matrix.

182
00:28:04,250 --> 00:28:11,330
So if you remember we had like the original framework is X is in gross B.

183
00:28:13,720 --> 00:28:27,580
Okay. So the dimension of the barometer vector now is basically is still P, but now I have partition.

184
00:28:28,060 --> 00:28:33,250
So beta will be one growth, one vector beta two is ap2 growth, one vector.

185
00:28:33,250 --> 00:28:36,580
So I have fees equal to be one plus people.

186
00:28:37,720 --> 00:28:45,040
Okay, so here is my model y equals two x beta plus epsilon and because of the partitioning

187
00:28:45,100 --> 00:28:50,470
in x I can write it as x one be given less x to better two plus epsilon.

188
00:28:51,250 --> 00:28:58,570
So this is my model again and this is the full model.

189
00:28:59,050 --> 00:29:08,800
This is the larger model that basically captures would be the and beta or the covariance, x1 and x2.

190
00:29:09,520 --> 00:29:20,169
Suppose I'm interested in testing the null hypothesis that beta two is zero hint about beta bullets in the context of that example.

191
00:29:20,170 --> 00:29:31,900
Incoming indication. So I want to test that the coefficients associated with the incoming allocation are simultaneously equal to zero.

192
00:29:32,590 --> 00:29:43,569
So what this might be do now might be too is to okay, and I'm interested in testing this against the alternative.

193
00:29:43,570 --> 00:29:47,500
I bought this as a two sided alternative. That will not work.

194
00:29:48,850 --> 00:29:59,140
So can you tell me first under the null, just tell me under the null hypothesis, what would my model be?

195
00:30:00,610 --> 00:30:10,160
What would my born model look like? Exactly.

196
00:30:10,250 --> 00:30:19,520
So under the NOL, my model is y equal to x, one beta, one plus epsilon.

197
00:30:21,780 --> 00:30:25,350
Okay. And what about under the alternative?

198
00:30:27,480 --> 00:30:32,990
It's this model here. Y equals 2x1 beta one plus.

199
00:30:33,000 --> 00:30:37,600
It's better to. Plus see.

200
00:30:49,270 --> 00:30:55,600
Okay. So which one is the bigger model? The model under the alternative?

201
00:30:56,710 --> 00:31:02,050
That's my full model. What about the model number?

202
00:31:02,070 --> 00:31:07,180
Now that has how many less parameters does it have?

203
00:31:09,830 --> 00:31:16,070
He does. How many less parameters does it have compared to the full model?

204
00:31:16,910 --> 00:31:20,450
It has b two less parameters.

205
00:31:23,330 --> 00:31:28,730
Under the. Right. Are these two models nested?

206
00:31:31,520 --> 00:31:44,150
Yes, they are. Because in the bigger model, the model alderman, if I, if I turn off or if I make B2 equal to zero,

207
00:31:44,160 --> 00:31:47,360
if I impose that restriction, then I get the model and then the null.

208
00:31:49,010 --> 00:32:04,160
Okay, so these two models are nested and I can construct that extra sum of squares based on the increase in SSR from these two models,

209
00:32:04,520 --> 00:32:08,420
from going from the smaller model to the bigger model.

210
00:32:10,130 --> 00:32:19,310
So I can write my statistic f as the extra sum of squares due to beta two.

211
00:32:19,310 --> 00:32:22,760
Given beta one was already in the model.

212
00:32:22,910 --> 00:32:36,210
So this is the extra sum of squares. You do better to give in.

213
00:32:37,810 --> 00:32:41,380
Beethoven already was in the market.

214
00:32:51,910 --> 00:33:00,220
Neither would vectors. So in other words, given that age, height, age, gender, height, weight were already in the model,

215
00:33:00,790 --> 00:33:07,510
what is the extra sum of squares attributable to income and education?

216
00:33:08,920 --> 00:33:17,440
How much more does income and education explain the variation in in Y?

217
00:33:17,920 --> 00:33:21,800
Given that I already had age gender height rating them under.

218
00:33:22,540 --> 00:33:30,519
So that's what I'm asking. And divided by the numerator has that extra sum of girls.

219
00:33:30,520 --> 00:33:44,200
Divided by how many extra parameters do I have in the bigger model, or how many limiters lesser capacities do I have in the model and the null?

220
00:33:44,230 --> 00:33:49,380
It's b to the dimension of the beta to vector.

221
00:33:49,780 --> 00:33:56,709
Okay, so that's my numerator and denominator is still that estimate of sigma squared.

222
00:33:56,710 --> 00:34:00,130
That's my mse from the full model.

223
00:34:00,700 --> 00:34:05,890
So is the estimate of sigma squared based on the full model.

224
00:34:06,940 --> 00:34:13,540
And here the free model basically is the model Y equal baseline make a monolithic, debatable plus epsilon.

225
00:34:15,580 --> 00:34:23,560
Okay, so that's. So this is the MSE from the Queen model.

226
00:34:32,170 --> 00:34:40,300
Okay. So no. So this is the general framework.

227
00:34:41,170 --> 00:34:43,610
This is the general form of the FDIC.

228
00:34:44,140 --> 00:34:56,110
What I'm going to show that using this general form, you can actually construct different kinds of test of hypothesis.

229
00:34:58,720 --> 00:35:04,300
So let's do that. So let's first talk about the overall episode.

230
00:35:05,290 --> 00:35:08,710
Remember the our overall test. The overall test is,

231
00:35:09,160 --> 00:35:19,780
is this and is there a significant effect of regression or simultaneously five test the barometers associated with the 4 minutes in the model.

232
00:35:20,200 --> 00:35:25,299
The null hypothesis is that become on equal to BW would be the three data that are not B to

233
00:35:25,300 --> 00:35:31,000
B minus one equal to zero versus the alternative that at least one is different from zero.

234
00:35:31,060 --> 00:35:32,800
So that was the overall level test.

235
00:35:33,640 --> 00:35:45,840
I'm going to cast that same overall leftist into this framework and I'm going to show that you can actually do this overall.

236
00:35:45,850 --> 00:35:51,520
If this is a special case of this, generally, how do I do that?

237
00:35:51,850 --> 00:35:57,100
So my model is Y equal to I have the intercept.

238
00:35:58,150 --> 00:36:03,040
The, the first column of the design matrix is remember the column of ones.

239
00:36:03,100 --> 00:36:10,350
So I have B does not want the column vector one multiplied by that scalar bit or not.

240
00:36:10,690 --> 00:36:17,050
Plus I have extends based one. Now this x does not have the quantum of ones.

241
00:36:17,890 --> 00:36:22,720
It only has the x, the covariance plus epsilon.

242
00:36:23,350 --> 00:36:30,370
I have b minus one covariance. So in all I have B parameters, including the intercept.

243
00:36:31,570 --> 00:36:41,260
Right. Okay. So now I'm going to talk about the overall best.

244
00:36:41,260 --> 00:36:45,070
I'm going to ask it in this framework, general framework.

245
00:36:46,240 --> 00:36:51,070
So in the overall leftist, what am I testing? The null hypothesis is like beta one.

246
00:36:51,550 --> 00:36:59,050
Now I have partitioned my parameter victory to beta, not the intercept and everything else.

247
00:36:59,050 --> 00:37:02,620
Beta one is everything else. Okay.

248
00:37:02,770 --> 00:37:11,650
So I'm interested in testing that. I want people to be like, you know, the third week I want to be test my people components.

249
00:37:12,190 --> 00:37:21,760
That is zero. That is the vector of zeros of dimension B minus one plus one because I have B minus one obedience

250
00:37:22,690 --> 00:37:32,050
versus the alternative that at least some element of that B minus one plus one vector is non-zero.

251
00:37:33,490 --> 00:37:41,650
So I can think about it in the high grade income indication, at least one of those coefficients is non-zero.

252
00:37:43,420 --> 00:37:49,510
So I'm going now again getting convince yourself that the model under the name

253
00:37:49,510 --> 00:37:55,450
and the alternative are nested like because I need to know what is the model.

254
00:37:56,080 --> 00:38:03,010
All the go on, all the coefficients corresponding to gender, height, weight, income, integration drop off.

255
00:38:03,010 --> 00:38:07,090
I'm only left with the model that only has the intercept.

256
00:38:08,920 --> 00:38:11,979
Yes. And what is the model under each one?

257
00:38:11,980 --> 00:38:15,610
The free model. That's the modeling that I have written on the top.

258
00:38:15,970 --> 00:38:17,560
So these two models are nested.

259
00:38:18,910 --> 00:38:27,250
So again, I'm going to apply that extra sum of squares principle to write the error statistic on the new version of the statistic model I have.

260
00:38:27,610 --> 00:38:34,689
This is the extra sum of squares contributed by beta one given beta naught.

261
00:38:34,690 --> 00:38:48,660
The intercept was already in the model and one keeping that B in a sort of stated one when we talked about excess on the square,

262
00:38:48,680 --> 00:39:03,520
the intercept that the peak demand is always, always part of the model on W so the beta not all of this is after this bar sign.

263
00:39:04,720 --> 00:39:11,080
So it's all of this part of the model under each stock and here by default it is.

264
00:39:12,130 --> 00:39:16,810
But even in the general context, you would see that beta not is all we skipped.

265
00:39:16,810 --> 00:39:20,110
We don't know with the non hypothesis.

266
00:39:20,530 --> 00:39:24,370
Okay. So the extra sum of squares is the new one.

267
00:39:24,420 --> 00:39:31,690
Did I have the extra sum of squares contributed by meta one given big enough was already in the model device.

268
00:39:31,730 --> 00:39:39,080
I did buy. How many extra paramedics do I have in the in the bigger model,

269
00:39:39,080 --> 00:39:44,660
in the full model I P minus one extra parameters corresponding to the p minus one covariance, right?

270
00:39:45,800 --> 00:39:50,030
And in the denominator once again my mse from the free model.

271
00:39:54,810 --> 00:40:06,240
So this has no based on the general form of the F has an F distribution with degrees of freedom equal to the new one,

272
00:40:06,300 --> 00:40:16,110
two degrees of freedom, which is B minus one. And the denominator degrees of freedom, which is N minus P and not that.

273
00:40:16,740 --> 00:40:22,260
What is the extra sum of squares? We proved this in slide,

274
00:40:22,320 --> 00:40:34,950
I think three or four of this model that the extra sum of squares attributed to beta one given beta naught was already in the model.

275
00:40:35,400 --> 00:40:46,530
You can write it as the difference in the SS are between the bigger body and the smaller model.

276
00:40:46,530 --> 00:40:53,760
The bigger model here is is this a bit that can be done up in beta one board and

277
00:40:54,090 --> 00:40:59,610
the smaller model is the model under the null hypothesis only has the intercept.

278
00:41:00,300 --> 00:41:07,530
We know that the SS are from the model that has only the intercept is zero.

279
00:41:09,000 --> 00:41:12,570
Right. So basically the it's just sum of squares.

280
00:41:12,600 --> 00:41:25,550
This is zero. So the extra sum of goods is essentially the regression sum of squares from the model that has the intercept and all the port radius,

281
00:41:26,030 --> 00:41:30,860
basically the division of goods from the model with the pool ex.

282
00:41:31,550 --> 00:41:38,900
Therefore it is again my well known like all that all along the way I was constructing.

283
00:41:38,900 --> 00:41:41,820
That is it's the method of what I see.

284
00:41:41,840 --> 00:41:58,730
So as you can see, this general form reduces to msaa but messy and has the same form as as even though s it slr best of beta one zero.

285
00:42:00,250 --> 00:42:03,860
Okay, so that's the overall F test.

286
00:42:04,520 --> 00:42:09,260
What about let's talk about already it's subset tests.

287
00:42:10,130 --> 00:42:21,920
So again, once again, think about aides in their high trade income education and suppose I'm interested in testing, but is there an impact of income?

288
00:42:21,950 --> 00:42:33,350
Any location on outcome given that I have already adjusted or accounted for age, gender, height and weight?

289
00:42:34,160 --> 00:42:37,819
So I'm interested in and I can do vice versa.

290
00:42:37,820 --> 00:42:44,450
I can I can talk about the impact of the physiologic variables in gender, height, weight.

291
00:42:46,580 --> 00:42:56,389
Does it explain additionally some variation in y when I have already adjusted

292
00:42:56,390 --> 00:43:01,250
for or when I've already when I already have income and education in the model?

293
00:43:02,310 --> 00:43:07,880
Okay. So that's what a full body subset test means.

294
00:43:08,510 --> 00:43:18,170
So suppose I'm interested in testing the null hypothesis that beta one is equal to zero versus the alternative.

295
00:43:19,460 --> 00:43:26,150
The two sided alternative that we go on is not equal to zero.

296
00:43:26,780 --> 00:43:38,870
And once again, like before, the dimension of the we are now I'm going to partition the X matrix.

297
00:43:38,870 --> 00:43:47,680
The designed matrix is I have a column of ones, then I have the part of the design matrix that corresponds to a gender.

298
00:43:47,720 --> 00:43:57,800
I think that's my ex money. That's it. And I have x2 as the part of the design, except that has the columns corresponding to income and indication.

299
00:43:59,010 --> 00:44:06,440
So that teleportation the design matrix. So I'm interested in testing that.

300
00:44:07,070 --> 00:44:16,130
And the dimensions of these are basically, you know, the, the first column of ones corresponds to the intercept.

301
00:44:16,940 --> 00:44:25,150
There's a single parameter where the second part of the design matrix has the columns corresponding to age, gender, height, weight.

302
00:44:25,160 --> 00:44:30,320
So it's in cross for matrix.

303
00:44:30,980 --> 00:44:43,340
And the extra matrix B to become an application has basically it's a it's a dimension interesting to the parameter vectors.

304
00:44:43,640 --> 00:44:52,580
The big barometer vector be now is partitioned correspondingly so and it has one element corresponding

305
00:44:52,580 --> 00:44:59,960
to the intercept four corresponding to the beta one bar and two corresponding to the beta two five.

306
00:45:01,100 --> 00:45:06,080
Yes, everybody with me. Okay, so now and together.

307
00:45:06,680 --> 00:45:13,590
So that one plus P, one plus B do makes up my entire that barometer vector.

308
00:45:15,710 --> 00:45:32,810
So now what I'm going to do is I'm going to do a like a kind of a small trigger to write it in terms of do write it as a pair of nested models.

309
00:45:33,230 --> 00:45:44,440
So I'm going to set X to star as the column vector one and it's do why am I doing that.

310
00:45:44,450 --> 00:45:54,529
Because remember as I see that the E the model under each not always keeps the intercept or in other words,

311
00:45:54,530 --> 00:45:58,759
the mean point I'm trying to make is that beta not always stays.

312
00:45:58,760 --> 00:46:07,690
The intercept always stays with the model under it's done since I'm testing the null that beta one equal to zero.

313
00:46:07,700 --> 00:46:15,060
So I have to construct fixed express almost square due to better one given beta two what?

314
00:46:15,120 --> 00:46:17,669
It's already in the model and along big.

315
00:46:17,670 --> 00:46:31,470
BW I also have to improve dataset, so BW Star has both The Intercept and as well as income and gender for income and education.

316
00:46:32,260 --> 00:46:43,580
Okay, so X2 Star is the design matrix where I have the first column as the column of

317
00:46:43,590 --> 00:46:50,250
ones and then I have the columns corresponding to set income and education.

318
00:46:50,910 --> 00:46:56,280
So let's now write the model under the non and the alternative.

319
00:46:57,000 --> 00:47:01,630
So what is the model? Under null? Under null.

320
00:47:03,630 --> 00:47:08,280
I am going to write the model as y equal to.

321
00:47:12,740 --> 00:47:20,810
It's too Star Beta and Star Plus Epsilon.

322
00:47:20,960 --> 00:47:26,140
Can I read that? Yes.

323
00:47:28,910 --> 00:47:32,030
And what about under the alternative?

324
00:47:33,260 --> 00:47:52,500
Under the alternative? The model is y equal to x2 two star beta two star class x one beta one plus epsilon.

325
00:47:58,140 --> 00:48:03,090
Yes. So I'm going to make two points here.

326
00:48:04,050 --> 00:48:10,830
One is that firstly, that these two models.

327
00:48:13,560 --> 00:48:32,510
Unlisted. And the other point that I'm going to make is that or remind you that remember, Bead garnered the intercept.

328
00:48:36,050 --> 00:48:48,200
Always these. With the economic model.

329
00:48:55,960 --> 00:49:00,850
Okay. So now these two models are listed.

330
00:49:00,850 --> 00:49:04,240
So once again, I'm going to apply the extra sum of squares principle.

331
00:49:04,510 --> 00:49:08,830
So what is the statistic now using their two with almost first principle?

332
00:49:08,840 --> 00:49:20,350
So it's that extra sum of squares attributable to better one given better two star was already in the model beta to star now has

333
00:49:20,350 --> 00:49:28,990
the intercept as well as the coefficients for income and gender in what am I say income at the end of income in aggregation.

334
00:49:29,620 --> 00:49:33,579
Okay, divided by P1.

335
00:49:33,580 --> 00:49:46,990
What is B1? B1 is the number of extra parameters in the full model or in other words, it's the dimension of the beta one vector.

336
00:49:49,730 --> 00:49:58,370
That's the numerator and denominator once again is the MSE from the full model or the model under each one.

337
00:49:59,450 --> 00:50:04,250
So these have an F distribution with degrees of freedom, b one and n minus p.

338
00:50:07,010 --> 00:50:12,860
Okay. And once again, recall from that extra sum of squares principle,

339
00:50:13,310 --> 00:50:22,490
the extra sum of squares attributable to beta one given beta two star does already in the model is you can either write it

340
00:50:22,490 --> 00:50:32,240
as SSR of beta one way that the star minus is is set of beta from star because the more difficult to add to the model,

341
00:50:32,240 --> 00:50:35,810
the more of the negotiations on the squares will increase.

342
00:50:36,290 --> 00:50:44,990
So it's the reduction in the regression sum of squares going from the full model to the restricted model.

343
00:50:45,230 --> 00:50:52,370
Or you can conversely think of it is like going from the smaller to the bigger model.

344
00:50:53,030 --> 00:50:59,440
You would sort of end up explaining, you know, less of that.

345
00:50:59,690 --> 00:51:05,030
We would have more unexplained variation in the smaller model compared to the bigger model.

346
00:51:05,390 --> 00:51:24,590
So you can write it as the reduction in SSD going from the model become only bigger to star or to the smaller model to the bigger model.

347
00:51:24,590 --> 00:51:29,780
Because basically on the full model, we test mode beta to start and beta one,

348
00:51:30,160 --> 00:51:35,840
I guess we can write the beta as the increase in SSR or the decrease in SLC.

349
00:51:38,690 --> 00:51:45,860
So that's the poverty subset test. And once again, like as I mentioned, this is the MSE from the full model.

350
00:51:51,410 --> 00:51:58,910
Okay. All good. Now, what about the scene loop already at best.

351
00:52:01,280 --> 00:52:06,170
So remember we talked about testing a symbol for variables.

352
00:52:07,070 --> 00:52:17,690
So is the coefficient associated with a significant is that are adjusted for gender height, weight income education.

353
00:52:19,370 --> 00:52:26,780
Is the coefficient associated for income significant adjusting for age, gender, height, weight and indication?

354
00:52:28,370 --> 00:52:36,950
So again, once again we have the model Y equal to its one vitamin plus x to beta two plus epsilon.

355
00:52:37,340 --> 00:52:44,180
Note now that beta one is a single is a scalar, right?

356
00:52:44,900 --> 00:52:54,200
And everything else I have lumped into the beta two part, including the the the intercept.

357
00:52:55,070 --> 00:53:01,430
So now I'm interested in testing the hypothesis that the signal for present associated with

358
00:53:01,430 --> 00:53:08,210
it that's a beta one is zero versus a two sided alternative that it's not equal to zero.

359
00:53:09,200 --> 00:53:13,100
Once again, under the null, what is the model?

360
00:53:13,790 --> 00:53:17,420
The model is basically under null.

361
00:53:18,500 --> 00:53:24,320
The model is Y equal to X to beta two plus epsilon.

362
00:53:26,600 --> 00:53:35,690
Yes. And under the alternative, the model is equal to x1 beta one less.

363
00:53:35,690 --> 00:53:39,050
It's debatable less epsilon.

364
00:53:39,770 --> 00:53:46,340
This is a number. Not that beta two is a vector, but this is a scalar.

365
00:53:51,440 --> 00:54:02,479
I'm testing for a thing local radio. Okay. So once again, the hub, the model under H1 is the full model.

366
00:54:02,480 --> 00:54:11,030
It's a bigger model. And the model under it'snot is a nested is nested within the model under each one.

367
00:54:11,150 --> 00:54:14,840
In other words, it's a special case, but it's a restricted model.

368
00:54:16,580 --> 00:54:23,150
So, so again, using the extra sum of squares principle for these two nested models,

369
00:54:23,630 --> 00:54:38,750
I can construct that statistic as the extra sum of squares due to fit along or due to attributable to it given gender high income indication.

370
00:54:38,750 --> 00:54:45,470
But already in the model. And note once again that given what is in the model also includes the intercept.

371
00:54:46,190 --> 00:54:50,630
Okay so that divided by sigma one head square.

372
00:54:50,660 --> 00:54:55,340
Now these have an F distribution with degrees of freedom one because I have one

373
00:54:55,340 --> 00:55:01,760
extra parameter in the full model and numerator denominator with them is n minus b.

374
00:55:03,290 --> 00:55:13,849
So we call that the F one and minus p is the square of a p with n minus three degrees of freedom.

375
00:55:13,850 --> 00:55:18,259
B we saw that in the lecture.

376
00:55:18,260 --> 00:55:24,260
To do the homework and distributional F is equal to D squared.

377
00:55:24,260 --> 00:55:30,860
Therefore, a single permitted hypothesis can be also tested using the T distribution.

378
00:55:31,640 --> 00:55:40,400
As you all know, Bitcoin had divided by the standard error bigger one heck of a distribution with ten minus five degrees of freedom.

379
00:55:40,850 --> 00:55:50,809
So using the distribution you could test this single covariant versus the alternative header,

380
00:55:50,810 --> 00:56:00,080
like a two sided or a one sided alternative of bitcoin equal to not equal to zero or bigger one bigger than zero or beta one less than zero.

381
00:56:00,350 --> 00:56:06,920
But with this f test you can only do what one sided test?

382
00:56:08,480 --> 00:56:18,620
So the two sided hypothesis can be tested using either the F based or the T test, but for one sided use only the test.

383
00:56:19,640 --> 00:56:28,130
So so I want to make two points here maybe like and then we will go for a break I want to make.

384
00:56:28,340 --> 00:56:32,370
So the first point that I want to make is no.

385
00:56:37,100 --> 00:56:41,860
Maybe unable to. A question to this if.

386
00:56:49,940 --> 00:56:57,810
Versus. This F.

387
00:57:02,800 --> 00:57:06,100
The first question is, are they the same?

388
00:57:08,530 --> 00:57:18,549
No. Okay. Can you are you both sort of mathematically as well as conceptually?

389
00:57:18,550 --> 00:57:24,310
And I'm more interested in the conceptual answer because mathematically is one is if with degrees of freedom,

390
00:57:24,310 --> 00:57:32,890
one and minus be an order is it could be resolved through to B minus one and then minus what is the possible is like testing the facts of every.

391
00:57:34,100 --> 00:57:38,180
I was just asking. What exactly? Voila.

392
00:57:38,640 --> 00:57:45,900
So everybody with me, conceptually, I want you to understand, these two leftists are very different.

393
00:57:46,620 --> 00:57:53,430
The first one is simultaneous, continuously testing all the coefficients associated with,

394
00:57:54,120 --> 00:57:58,890
you know, the poverty in the model age, gender height, weight in division.

395
00:57:59,460 --> 00:58:05,940
And the second test is this F test is testing only a single core variant at the time.

396
00:58:07,740 --> 00:58:10,740
Yes. Okay. So that's one point.

397
00:58:11,130 --> 00:58:18,090
And then the other question that I can so you know, as I said, that this one, this test,

398
00:58:18,090 --> 00:58:24,060
as we all know, you can do it either through a first or you can do it using a T test.

399
00:58:24,750 --> 00:58:29,950
And with a T test, you can do both two sided as well as one sided alternatives.

400
00:58:31,680 --> 00:58:36,660
I'm going to throw in a question here for the poll really subset test.

401
00:58:38,130 --> 00:58:48,680
So this one. The question is, can you do a tedious.

402
00:59:01,990 --> 00:59:16,750
Can you do, Atticus? Did anybody hear the answer?

403
00:59:19,300 --> 00:59:24,370
So my question was, again, when I am talking about the subsidies, can you do a dentist?

404
00:59:25,540 --> 00:59:31,690
And the answer is no. Because once again, like by comedy, it sucks.

405
00:59:31,870 --> 00:59:43,030
I mean, unless again, the one he has is a scalar, you cannot do a.

406
00:59:45,390 --> 00:59:48,830
Okay. So I'm going to stop here.

407
00:59:48,840 --> 00:59:57,930
We are going to take a break. Sorry it took longer to get a break because I did not want to disrupt the floor.

408
00:59:58,320 --> 01:00:06,540
So let's take a break. Let's come back at 918 and then we will talk about how do we carry out justice?

409
01:00:39,310 --> 01:00:48,870
So. The sequential trend in sequential testing was coming up in the slides.

410
01:00:50,310 --> 01:00:58,140
I think that the system was always that distributor would have one at minus five or ten where we're using Tupperware.

411
01:00:58,230 --> 01:01:05,220
But what about building the mall? She held up a little bit more.

412
01:01:05,780 --> 01:01:09,730
Why is that? Yeah, because we're building it one at a time to the full model.

413
01:01:11,500 --> 01:01:16,220
So, I mean, it's a pretty big naturally, naturally.

414
01:01:16,970 --> 01:01:22,370
And I want you to ask that question. But let's talk about the design life.

415
01:01:22,790 --> 01:01:28,600
So, I mean. I think you the answer.

416
01:01:30,520 --> 01:01:36,340
Conceptually, yes, we have made since the beginning of the you know,

417
01:01:37,240 --> 01:01:44,410
some of the exercises could only make sense that the denominator change will be time.

418
01:01:44,440 --> 01:01:58,150
Yes. But the reason why and even see on something that is has a baby has a logical explanation in terms of the plot.

419
01:02:00,430 --> 01:02:07,660
But the reason why we do that is because, um, and there's a lot,

420
01:02:07,730 --> 01:02:26,440
if you went ahead and say that the estimate of somewhere that as you add if you if you kind of if you add to this the that what actually the proof is,

421
01:02:27,430 --> 01:02:30,550
then basically you can get there by as just.

422
01:02:32,750 --> 01:02:39,729
C++. So. So we all just changed cinemascore and said, yeah, yeah.

423
01:02:39,730 --> 01:02:49,600
And, and if you on the other hand, if you add more than is necessary, then it doesn't bias, it only makes the C plus the cat noise.

424
01:02:50,410 --> 01:03:00,459
So we kind of make a compromise between decision and plus we give a little bit about the position on the position kind of,

425
01:03:00,460 --> 01:03:04,290
you know, so get an unbiased estimate.

426
01:03:05,230 --> 01:03:17,680
And that's why I think the only. It's just that we can make sure it's not like, can we do this afternoon for.

427
01:03:21,510 --> 01:03:25,290
The meeting with the FSB will be.

428
01:03:59,530 --> 01:04:08,770
Just. Well, because that's the decision, people.

429
01:04:10,290 --> 01:04:13,710
So that's a different kind of. This.

430
01:04:16,140 --> 01:04:19,290
But it's. It's going to contrast.

431
01:04:21,240 --> 01:04:28,320
Its combination of small. But you can still guess that he did it.

432
01:04:30,560 --> 01:04:35,380
Basically the framework is stupid and extremely.

433
01:04:36,010 --> 01:04:41,900
Exactly the samples we have. A treatment that has.

434
01:04:42,370 --> 01:04:50,010
And this. Four levels gone full.

435
01:04:51,690 --> 01:04:55,370
Simple. And then you have three daughters of the same jobs.

436
01:04:56,570 --> 01:05:03,560
So you might be interested in pursuing that instead of different kinds of people.

437
01:05:03,980 --> 01:05:13,160
Do you think you can go fast enough, like the Beta Leslie, to pick the speaker whose voices speak at one?

438
01:05:15,470 --> 01:05:27,560
Or you might say, okay, I don't think there's a difference between the the lowest bills and the highest so that it's better for money for.

439
01:05:29,640 --> 01:05:34,130
So to do that cause again, do that.

440
01:09:24,020 --> 01:09:46,770
We're just. Okay.

441
01:09:48,650 --> 01:09:53,530
So. Everybody back.

442
01:10:01,340 --> 01:10:19,129
Okay. So now the question is so I have convinced you by now that basically, you know, tests of all these different kinds like the world,

443
01:10:19,130 --> 01:10:28,280
that there's the Singapore Video Festival, we need subsidies, all of these can be reviewed.

444
01:10:28,280 --> 01:10:45,170
And the general forum for F using the extra thumbnail sketch principle for nested models under the now called connected.

445
01:10:45,950 --> 01:10:50,300
So now the question is how do we actually carry out this test?

446
01:10:52,520 --> 01:10:57,140
Consider this model Y equal to x one beta one plus x two data, two plus epsilon.

447
01:10:57,380 --> 01:11:07,070
The null hypothesis is that they w equal to zero and beta two is a vector of dimension B to growth.

448
01:11:07,070 --> 01:11:12,020
One versus the alternative decided that beta two is not equal to zero.

449
01:11:14,600 --> 01:11:23,990
So we need to compute this f where the numerator is dates to sum of squares due to beta two.

450
01:11:24,470 --> 01:11:31,910
Given beta one was already in the model divided by the number of extra parameters in the full model,

451
01:11:31,910 --> 01:11:36,979
which is p to know all the dimension of the beta two vector.

452
01:11:36,980 --> 01:11:43,460
That's my numerator and denominator is the MSE from the full model.

453
01:11:43,700 --> 01:11:48,380
From the bigger model, the larger model the model under each one.

454
01:11:48,890 --> 01:11:55,130
Okay. So now I could fit the following two nested models.

455
01:11:55,970 --> 01:11:59,480
What is the model under the null? The model and the null?

456
01:11:59,480 --> 01:12:04,880
Is this model here y equal to x1 with the one plus epsilon?

457
01:12:06,230 --> 01:12:16,010
And what is the model under alternative? That's the larger model, the model y equal to x1, beta one plus two, beta two plus epsilon.

458
01:12:17,630 --> 01:12:28,880
These two models are nested and you can easily see that by partitioning the design matrix x into x1,

459
01:12:28,880 --> 01:12:32,750
x2 and corresponding to better make things that we don't want to do.

460
01:12:32,750 --> 01:12:37,760
Well, you know, the model and the null always keeps the intercept.

461
01:12:38,420 --> 01:12:44,840
You can then feed this to nested models and the x2 sample squares.

462
01:12:44,840 --> 01:12:59,120
We said it's basically the reduction in its e or the increase in this are going from the biggest model to the full model.

463
01:12:59,120 --> 01:13:11,210
So what you can do, you actually can mechanistically you can fit these two models, right?

464
01:13:11,540 --> 01:13:15,779
And you're going to take the difference of the size of or the difference in the s.

465
01:13:15,780 --> 01:13:19,580
This is to get the numerator of the gap statistic.

466
01:13:21,930 --> 01:13:26,040
Right. I mean, conceptually, this is this is as easy as it is.

467
01:13:26,210 --> 01:13:39,110
It's a piece of cake. But alternatively, you could also consider the consider the forms of the assessors.

468
01:13:39,490 --> 01:13:43,549
Now, as I say that conceptually, this is very easy to understand.

469
01:13:43,550 --> 01:13:45,590
You are speaking these two nested models.

470
01:13:45,590 --> 01:13:51,080
You are giving the collecting that is this are some diseases from the WHO ones you are taking the difference.

471
01:13:51,740 --> 01:13:53,660
That's what they express. All is.

472
01:13:54,620 --> 01:14:04,310
But one might argue, oh, my gosh, every time I have to do this, this new model is that every time I have to kind of do this operation.

473
01:14:04,760 --> 01:14:09,800
So the and the answer is, well, yes.

474
01:14:10,070 --> 01:14:25,190
And in this day and age, I mean, you know, that that sort of computation really I mean, you know, it's a no brainer, right?

475
01:14:26,150 --> 01:14:31,700
Unless you have many models, large datasets.

476
01:14:33,860 --> 01:14:47,300
But so it's it's not a big deal. But then there is a way where you can I you can kind of bypass fitting actually fitting the these two models.

477
01:14:47,900 --> 01:15:02,540
And you can see that that basically the extra sum of squares could be written in terms of the X's involved.

478
01:15:03,320 --> 01:15:06,470
And you can kind of do the competition in one stroke.

479
01:15:07,160 --> 01:15:13,340
Let's see how. So here is the matrix formulation for the extra sum of square.

480
01:15:14,120 --> 01:15:24,680
So in particular, what is SS e from the full model that has would be the one in beta two.

481
01:15:25,160 --> 01:15:29,600
So this is the larger model, the model under each one.

482
01:15:30,380 --> 01:15:41,060
So you can write it as in matrix formulation and y transpose I minus eight times y.

483
01:15:41,660 --> 01:15:47,360
This should be familiar to you from modeling, right?

484
01:15:48,320 --> 01:15:54,649
So this is the error sum of squares from the full model where it is.

485
01:15:54,650 --> 01:15:58,880
What? The prediction matrix. Okay.

486
01:15:59,150 --> 01:16:04,340
So this is under the model on H1 or full model?

487
01:16:10,940 --> 01:16:16,880
Maybe I will not rotate one because I have each one matrix in the next line.

488
01:16:17,810 --> 01:16:25,370
What is the SSD from the smaller model or the reduced model or the model under none?

489
01:16:26,060 --> 01:16:33,600
So this is the reduced model. The restricted model of the model number?

490
01:16:33,610 --> 01:16:43,230
No. What is the model and the null? The model and the null is y equal to x one beta one plus epsilon.

491
01:16:43,270 --> 01:16:47,890
So the design matrix under the null hypothesis is x one.

492
01:16:49,060 --> 01:16:53,980
So I can write the C from this model as y,

493
01:16:53,980 --> 01:17:03,940
transpose the identity matrix minus h one times y where each one is defined as

494
01:17:04,480 --> 01:17:13,260
x1x1 transpose x one inverse x one transpose and the h matrix is defined as x.

495
01:17:13,270 --> 01:17:17,440
So this is the big design matrix that has both x1 and x2.

496
01:17:17,890 --> 01:17:21,730
So h is x x transpose its Elizabeth X transpose.

497
01:17:23,590 --> 01:17:34,479
Yes. So everybody with me. Therefore, what is the extra sum of squares attributable to beta two?

498
01:17:34,480 --> 01:17:48,100
Given beta one was already in the model. So it's the reduction in assessee going from the smaller model to the bigger model.

499
01:17:49,900 --> 01:17:55,060
So the decrease in is this decrease in what is left unexplained.

500
01:17:55,480 --> 01:18:00,340
The smaller model will have more that is left unexplained.

501
01:18:00,790 --> 01:18:08,440
And the bigger model will explain more of the variation so that the quantity that is less left unexplained is smaller.

502
01:18:08,620 --> 01:18:19,210
So it's the difference in the SCC between the smaller and or the reduced restricted model and the free model.

503
01:18:20,200 --> 01:18:24,160
So is this debate the minus? Is this C between beta two?

504
01:18:24,760 --> 01:18:29,120
Now let's write these expressions for the CSC.

505
01:18:29,140 --> 01:18:40,810
So I have Y transpose identity minus H1 times y minus y, transpose identity minus eight times y.

506
01:18:42,490 --> 01:18:49,570
So just a step of algebra, I can write it as y, transpose h minus H one times y.

507
01:18:50,920 --> 01:18:54,070
So now do you see this extra sum of squares?

508
01:18:56,790 --> 01:19:01,410
Is looks like a quadratic form in e.

509
01:19:02,160 --> 01:19:03,270
In y.

510
01:19:09,390 --> 01:19:19,020
Well, the images from the period we have been using to prove our, like, you know, distributional results, the same matrixes, each minus each one.

511
01:19:21,740 --> 01:19:27,010
Yes. Okay.

512
01:19:27,220 --> 01:19:36,580
So what I'm going to convince you first is that so you can actually instead of instead

513
01:19:36,580 --> 01:19:44,649
of actually fitting the models than the the full model and the reduced model,

514
01:19:44,650 --> 01:19:49,480
taking the difference of the thumbs up squared regression or some of the error,

515
01:19:51,070 --> 01:20:02,950
you can actually compute the extra sum of squares as a quadratic forming up y using this h minus h one matrix.

516
01:20:03,530 --> 01:20:11,560
Okay. So it's, it's, it's sort of again, as I said, in this day and age of computing,

517
01:20:13,350 --> 01:20:18,850
the this difference between fitting or not fitting these models is not a big deal.

518
01:20:18,850 --> 01:20:27,700
It's not a huge deal at all in most cases unless you have many, many, many more models and you have large datasets.

519
01:20:28,420 --> 01:20:32,290
But this saves a little bit of computation time.

520
01:20:34,060 --> 01:20:39,310
Okay. Number one, that's that's that's one point.

521
01:20:39,910 --> 01:20:47,740
But although they said that this saving is probably not a big deal in this day and age of computing.

522
01:20:48,370 --> 01:21:03,279
But a more important point that I want to make is and this form of the extra sum of squares, I will use this form.

523
01:21:03,280 --> 01:21:05,139
I be sure that, you know,

524
01:21:05,140 --> 01:21:19,030
like the fact that I can write the numerator of this general statistic as a quadratic forming y divided by appropriate to use a freed up.

525
01:21:19,030 --> 01:21:25,719
And then in the denominator I have mse I'm going to use this formulation.

526
01:21:25,720 --> 01:21:36,030
You once again prove to you that this indeed has an end distribution, just like we did all through an alternative.

527
01:21:39,250 --> 01:21:44,889
So that's that's the that's the main point.

528
01:21:44,890 --> 01:21:51,160
So that's what I am going to sort of show.

529
01:21:51,760 --> 01:22:07,450
Once again, remember, it is the projection matrix that uses the full design matrix X and each one is a sub part of of

530
01:22:07,450 --> 01:22:17,210
of the x 40 x matrix and each one is defined as x1x1 transpose x one inverse x one transpose.

531
01:22:17,230 --> 01:22:33,010
Okay. So now let's show you how do we know that the F, the general F that I was writing actually follow the F distribution under the name.

532
01:22:35,290 --> 01:22:44,560
So here are basically what I am going to show and I'm going to need.

533
01:22:45,280 --> 01:22:55,059
So the general f looks like on the numerator I have an extra sum of squared attributable to be given to beta two.

534
01:22:55,060 --> 01:23:01,210
Given beta one was already in the model divided by p to and in the denominator I would see my one had squared.

535
01:23:02,440 --> 01:23:08,890
So the denominator is the C from the full model, right?

536
01:23:09,280 --> 01:23:17,920
So I have y transpose I minus eight times Y divided by n minus B, this is my mse.

537
01:23:20,290 --> 01:23:20,680
Okay.

538
01:23:20,950 --> 01:23:30,999
And in the numerator I just showed that the extra sum of squares also you can write it as a quadratic forming y with the E matrix as h minus h one.

539
01:23:31,000 --> 01:23:36,490
So I'm going to write it as Y transpose h minus H1 times y divided by P2.

540
01:23:37,360 --> 01:23:48,940
So it's the ratio of this statistic is that issue off to quadratic form seem y appropriately scaled by the degrees of freedom.

541
01:23:50,110 --> 01:24:02,709
Okay. So what did we do in module D to show that this has an F, this form has an F distribution.

542
01:24:02,710 --> 01:24:18,430
So I'm going to apply the same here and like we did for a C and if this are in my in my in MLA and and apply exactly the same theorem,

543
01:24:18,640 --> 01:24:24,580
everybody remembers the theorem I'm talking about that we used all three module.

544
01:24:25,000 --> 01:24:33,399
To show the distributional properties of this statistic, of this ratio of the appropriately skimmed sums of square.

545
01:24:33,400 --> 01:24:37,690
So I'm going to apply the same theorem.

546
01:24:45,690 --> 01:24:58,690
Like we did. For SSD and ASUS are in module B.

547
01:25:04,560 --> 01:25:08,220
But no, my mistakes.

548
01:25:14,110 --> 01:25:29,169
Any tricks in that Puram. Is what the numerator is.

549
01:25:29,170 --> 01:25:33,070
B is h minus h one.

550
01:25:37,520 --> 01:25:43,040
Yes. So I have to show that the upstairs,

551
01:25:43,040 --> 01:25:48,830
like the new monitor which unspools eight times each one one times y divided by sigma squared

552
01:25:49,190 --> 01:25:55,340
has a chi square distribution with the freedom between the null and the null hypothesis.

553
01:25:55,700 --> 01:26:01,189
The denominator I don't need to do anything I already know from module D and I have proved

554
01:26:01,190 --> 01:26:08,150
in module D that the denominator is all squared with n minus p degrees of freedom.

555
01:26:10,280 --> 01:26:24,559
But what I don't know, or what I need to prove here is that the numerator that the extra sum of squares is independent of the denominator,

556
01:26:24,560 --> 01:26:29,600
the C from the full model. So these are the two things I need to show.

557
01:26:30,110 --> 01:26:34,440
This is already done. Yes.

558
01:26:36,730 --> 01:26:49,990
So now I'm going to apply the theorem like we did for SSR on a C module D Except that now my e netflix in the numerator is h minus h one.

559
01:26:50,860 --> 01:26:59,200
So what do I need to show? Firstly, I need to show that this matrix is important.

560
01:27:04,530 --> 01:27:12,320
And I need to show that the rank of this matrix is equal to beta.

561
01:27:16,830 --> 01:27:25,479
Then that will complete my blow for showing that the numerator or the extra sum of squares

562
01:27:25,480 --> 01:27:34,020
has a case for distribution to show that the extra sum of squares is independent of a.

563
01:27:34,590 --> 01:27:44,580
What do I need to show? I would need to show that each minus H1 times I minus eight is zero.

564
01:27:46,930 --> 01:27:50,310
Okay. So I will also to show this one.

565
01:27:55,120 --> 01:28:00,190
So for this one, I need to show these.

566
01:28:01,780 --> 01:28:06,759
And for this one, I will need to show that each minus.

567
01:28:06,760 --> 01:28:20,030
Each one. Sometimes the denominator, the matrix in the quadratic form is i.e. minus the identity, minus the matrix.

568
01:28:20,030 --> 01:28:23,370
And to show that this is zero. Yes.

569
01:28:27,300 --> 01:28:32,970
We thought one. Oh, yeah.

570
01:28:33,020 --> 01:28:43,190
Yeah. I have to show a significant and important piece. I mean, by my definition, an important matrix is symmetric, so that's why it even updated.

571
01:28:43,200 --> 01:28:53,260
But do it again for symmetric and I didn't put. Okay.

572
01:28:54,070 --> 01:28:57,160
So. So I have to show these.

573
01:28:58,300 --> 01:29:01,810
And then I can just apply the theorem as in module, and I'll be done.

574
01:29:03,730 --> 01:29:08,290
Okay. So how do we know that it follows this distribution little?

575
01:29:08,470 --> 01:29:15,400
Sure. So here is it. So everybody with me, what are my what are the things I need to show?

576
01:29:16,150 --> 01:29:23,200
So let me just first show that a square that asymmetric I.

577
01:29:23,740 --> 01:29:28,390
And so what is what is a square?

578
01:29:29,680 --> 01:29:35,920
A square is h minus eight one nine feet minus eight.

579
01:29:37,630 --> 01:29:42,280
I'm not showing the symmetry sitting separately because it is symmetric.

580
01:29:42,280 --> 01:29:45,430
Each one is symmetric, so it's minus eight symmetric.

581
01:29:45,650 --> 01:29:49,240
Okay. And so what is a square?

582
01:29:49,330 --> 01:30:05,380
A square is equal to eight squared minus eight times C one minus H one times each plus each one square.

583
01:30:09,660 --> 01:30:20,540
Okay. What is a square root square is equal to h.

584
01:30:23,550 --> 01:30:29,210
What is each one? Let let me first show that in the side.

585
01:30:34,740 --> 01:30:48,270
What is each one times each? H1 is x1 x1 transpose x1 inverse.

586
01:30:51,290 --> 01:30:55,930
It's 1.5 correct times.

587
01:30:56,250 --> 01:31:04,280
Each. Eat it.

588
01:31:05,010 --> 01:31:14,880
Say it again. Uh oh.

589
01:31:16,860 --> 01:31:21,510
Yeah, the symmetry doesn't matter. Yeah. So everybody with me.

590
01:31:22,050 --> 01:31:25,770
Okay, so now what do I have?

591
01:31:25,830 --> 01:31:32,580
So it is symmetric, so I can write H as h transpose e.

592
01:31:33,720 --> 01:31:39,270
Yes. Okay. What?

593
01:31:39,720 --> 01:31:43,410
What is it? Swan Brown, Sports Times. It's Transport Canada.

594
01:31:43,410 --> 01:31:46,680
It says each time six months took up the whole thing.

595
01:31:48,170 --> 01:31:51,930
I'm going to just replace and repeat this.

596
01:32:03,010 --> 01:32:07,530
Yes, I'm writing it step, but I'm for space.

597
01:32:07,540 --> 01:32:10,600
I'm just wiping the previous step.

598
01:32:11,170 --> 01:32:16,030
Everybody between what is 8 to 10, 618 is a big extended piece.

599
01:32:17,960 --> 01:32:21,230
It's ten, six. One is it's one.

600
01:32:24,310 --> 01:32:32,240
Okay. So I can write this as. It's one and I read in this.

601
01:32:32,260 --> 01:32:36,580
John's also this. What is this?

602
01:32:39,580 --> 01:32:42,610
This is, by definition, each one.

603
01:32:45,540 --> 01:32:48,840
Yes, by simplicity.

604
01:32:49,740 --> 01:32:53,790
Then each times, each one is also.

605
01:32:58,340 --> 01:33:04,380
Each one. Because age is symmetric.

606
01:33:07,770 --> 01:33:16,920
Each one is symmetric, so each minus one difference of all symmetric matrices is symmetric.

607
01:33:18,660 --> 01:33:23,280
Okay. So now going back.

608
01:33:23,580 --> 01:33:27,930
So this is something that I will do on the side.

609
01:33:28,800 --> 01:33:32,180
Now going back, then what do I have?

610
01:33:32,190 --> 01:33:35,290
It's clear this is a red partnership.

611
01:33:35,310 --> 01:33:38,549
We each minus each one. Yeah, yeah.

612
01:33:38,550 --> 01:33:42,480
I was just at this destroying the middle steps, and then I'm going to come back.

613
01:33:42,480 --> 01:33:45,990
Oh, sorry. No. Did you think I stopped there? No, I did not stop that.

614
01:33:46,230 --> 01:33:51,210
I was drawing the middle steps. Okay, so what is each time?

615
01:33:51,390 --> 01:33:56,310
Each one? It's each one. So I have each minus each one.

616
01:33:57,120 --> 01:34:07,320
What is each one time? Seeds and another. Each one and each one squared is equal to each one because each one itself is quite important.

617
01:34:11,450 --> 01:34:15,890
Okay. So what do I have? H minus h one.

618
01:34:18,530 --> 01:34:24,500
So is equal to E, so h minus h1 is symmetric and either important.

619
01:34:27,520 --> 01:34:37,020
Okay. What about the then gulf? E So asymmetric.

620
01:34:37,030 --> 01:34:55,549
I The importance of the rank of e. Is equal to the decrease of e equal to the crease of h minus h one and it is symmetric.

621
01:34:55,550 --> 01:35:00,050
I've important a20 symmetric ij importance with the trees of each minus.

622
01:35:00,050 --> 01:35:03,770
Trees of each one. Yes.

623
01:35:05,660 --> 01:35:15,730
What is the trees of each. What is the truth of it?

624
01:35:17,090 --> 01:35:21,670
Right. Then go for it. Which is be.

625
01:35:25,860 --> 01:35:33,060
And what is the price of each one? Be one.

626
01:35:34,000 --> 01:35:37,570
Right. So I have B minus B one.

627
01:35:39,130 --> 01:35:50,240
What is B minus b one is equal to. B to. Okay.

628
01:35:51,830 --> 01:35:55,220
So I have shown this spot.

629
01:35:56,630 --> 01:36:07,459
Now, I basically applied the theorem in module B and I have shown that it's the sum of squares divided

630
01:36:07,460 --> 01:36:14,180
by sigma squared under the null hypothesis of the chi square distribution with degrees of freedom.

631
01:36:14,180 --> 01:36:19,790
P two. I still have to show the independence.

632
01:36:22,220 --> 01:36:25,760
Okay. So here it is. Oh, I have it on the slide.

633
01:36:25,770 --> 01:36:31,069
So please make sure that, you know, basically we we worked on this.

634
01:36:31,070 --> 01:36:38,280
Oh, the one other thing that you need to show is the non centrally depend on meter and once again, you know,

635
01:36:38,300 --> 01:36:50,629
use the expression for expected value of Y transport h minus H1 expected value flight under the null hypothesis be equal to zero.

636
01:36:50,630 --> 01:37:03,770
This reduces to zero because once again of the of the fact that the H matrix is the production matrix and we have already showed this part.

637
01:37:04,520 --> 01:37:10,340
Okay. So no, no, we haven't showed this part yet.

638
01:37:11,090 --> 01:37:15,140
So now so this, this completes the proof of the,

639
01:37:17,480 --> 01:37:22,880
the fact that the numerator in the in the general test or the extra sum of squares

640
01:37:23,270 --> 01:37:27,080
divided by three months where the chi square distribution with degrees of freedom b2.

641
01:37:27,530 --> 01:37:33,890
Now, as I said, I have to show that the numerator and denominator are independent.

642
01:37:34,880 --> 01:37:38,960
Correct. So I have to show this part here.

643
01:37:40,100 --> 01:37:49,610
That data sum of squares attributable to make up to given beta one was already in the model is independent of the SSD from the full model.

644
01:37:50,360 --> 01:37:59,689
For that I need to show again I'm applying the theorem in module D, so I have two quadratic turns in y y,

645
01:37:59,690 --> 01:38:13,280
Premier Y and my plan b y and the result that we used in module g b of the pure M that we used in module was basically show that E times B is zero.

646
01:38:14,840 --> 01:38:27,780
So here it is, h minus H1 and what is b b is the matrix associated with the quadratic form in the denominator and that is the identity minus H matrix.

647
01:38:27,800 --> 01:38:32,660
And before this product is of this two matrices is zero.

648
01:38:33,710 --> 01:38:47,180
So let's show that. So H minus H1 times identity minus H is it how do I should zero?

649
01:38:47,180 --> 01:39:08,000
So basically I have and again these are symmetric so I minus two times each minus H1 is h minus H1 minus eight squared plus eight times h one.

650
01:39:09,860 --> 01:39:20,329
So I have h minus H1 minus by the importance of h h squared is equal to H.

651
01:39:20,330 --> 01:39:32,090
So this is I have a minus eight and what is H times h1 we showed that H times H1 is equal to H1

652
01:39:34,100 --> 01:39:40,310
correct because of this result and because of the fact that both H and each one are symmetric.

653
01:39:43,300 --> 01:39:47,200
Okay. So I have each time. So each one is equal to each one.

654
01:39:47,320 --> 01:39:52,299
So what do I have? Each minus each one minus each, plus each one.

655
01:39:52,300 --> 01:39:56,170
So these two cancel out and.

656
01:40:00,870 --> 01:40:07,500
They still cancel. So I have see them. And this part I have shown already.

657
01:40:16,160 --> 01:40:20,060
Okay. So what do I have?

658
01:40:20,360 --> 01:40:34,040
What I have is I have established that using the extra sum of squares principle for two nested models under the null hypothesis,

659
01:40:34,040 --> 01:40:49,010
an alternative hypothesis, the x statistic that I draw, I have proved that the upstairs, the extra sum of square sum has a chi square distribution.

660
01:40:50,180 --> 01:40:54,530
The downstairs of the denominator has a chi square distribution.

661
01:40:54,650 --> 01:41:01,010
And these two, the numerator and denominator are independent.

662
01:41:03,050 --> 01:41:14,810
So applying the pyramid model D, then this statistic has an F distribution with degrees of freedom equal to B2 and minus B.

663
01:41:18,210 --> 01:41:24,690
Well, good. Yes, it has been quite long said.

664
01:41:26,960 --> 01:41:32,860
Why the nonsense reality barometer is zero. So basically look at the non-farm reality barometer.

665
01:41:32,870 --> 01:41:39,140
So it's expected value of white brown spores each minus each one expected value of y, right?

666
01:41:39,410 --> 01:41:48,230
So I have I just plug in X1, transpose video on Sony X1 video and transpose each minus H1, X1, beta one.

667
01:41:48,830 --> 01:41:53,600
Okay. So what is what do I have? I have a maybe I'll write it tier.

668
01:41:53,600 --> 01:42:05,870
I have, I have beta one transpose x1 from I am a x1 beta one.

669
01:42:08,450 --> 01:42:23,780
Yes. And then what is the second part minus beta one transpose x1, prime H1.

670
01:42:27,090 --> 01:42:30,390
Times beat. Go on. Sorry, I'm missing the.

671
01:42:31,620 --> 01:42:35,550
Did I miss anything here? Sorry. It's one week alone.

672
01:42:35,850 --> 01:42:44,990
All right. Yes.

673
01:42:49,400 --> 01:42:53,930
Do you see now? So each one is equal to x one.

674
01:42:54,920 --> 01:42:58,190
Each 1x1 is equal to two. Basically this is zero.

675
01:42:58,760 --> 01:43:09,620
Okay. So that completes the proof that the single representative distribution of degrees of freedom be doing in minus B.

676
01:43:17,560 --> 01:43:28,560
So let me. Actually let me stop here because I think we'll.

677
01:43:34,740 --> 01:43:40,290
Yeah. Okay, let's just. I think we have too many, too many slides.

678
01:43:40,290 --> 01:43:43,800
And this is an important concept. I can kind of rush through this.

679
01:43:44,370 --> 01:43:50,159
So I am going to just sort of set the stage and we are going to stop here.

680
01:43:50,160 --> 01:43:53,310
So the next thing that we are going to talk is bring back.

681
01:43:53,910 --> 01:44:02,730
We talked about sequential versus factual testing. Certain situations indicate strictly either sequential or partial tests alone.

682
01:44:03,930 --> 01:44:09,659
And it sort of depends on the aim of the investigator, but also on the nature of the model under consideration.

683
01:44:09,660 --> 01:44:20,890
So what we will do on Tuesday is will pick up from here and we will sort of discuss more in depth sequential.

684
01:44:22,830 --> 01:44:27,330
Okay. So let's stop here.

685
01:44:27,330 --> 01:44:33,090
Are there any questions? Okay.

686
01:44:34,680 --> 01:44:37,530
Thank you. And have a great weekend.

