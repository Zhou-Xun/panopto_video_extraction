1
00:00:12,390 --> 00:00:17,960
I just didn't. She?

2
00:00:18,210 --> 00:00:22,080
Oh, thank you. Okay. Hello, everybody.

3
00:00:22,100 --> 00:00:25,540
There is a sign in shape circulating.

4
00:00:26,510 --> 00:00:30,050
Please make sure you fill that out before you leave today.

5
00:00:30,920 --> 00:00:36,440
I'm Dr. Lay, and I'll be giving your guest lecture today on human subjects research.

6
00:00:36,440 --> 00:00:42,349
And I'll be. I've heard from Dr. Biedermann that you all don't read before class.

7
00:00:42,350 --> 00:00:50,740
Is that right? I mean, why would he call you out like that?

8
00:00:50,750 --> 00:00:59,630
Well, hopefully you did do some reading because I sent a campus announcement about it, but if not, that's fine, too.

9
00:01:01,440 --> 00:01:06,650
But hopefully, you know, you'll find today's guest lecture useful.

10
00:01:07,760 --> 00:01:11,360
So I am in just. And I'm the John G.

11
00:01:11,360 --> 00:01:15,739
Searle assistant professor in the department. That's my email.

12
00:01:15,740 --> 00:01:24,980
And you can follow me on Twitter if you'd like. I don't take any of my other classes because I mostly teach in the industrial hygiene program.

13
00:01:25,910 --> 00:01:32,870
So what has been my work with human subjects in particular in this department?

14
00:01:32,870 --> 00:01:44,149
I'm actually one of the few people who actually works with humans, live humans, and that's how do human people cells or secondary data using humans.

15
00:01:44,150 --> 00:01:53,330
So I do a lot of community based participatory research, particularly within occupational health disparities in particular.

16
00:01:54,110 --> 00:01:57,709
So one of the populations I focus on are nail salon workers.

17
00:01:57,710 --> 00:02:03,920
So we recently had a article on Michigan Healthy Nail Salon Cooperative featured in Michigan News.

18
00:02:04,280 --> 00:02:08,540
This is the staff at a barbecue salon over on Third Street that we work with.

19
00:02:09,470 --> 00:02:18,830
That's a photo in the corner that I took of Omaha Fire Department while we're doing a training exercise for them on Ebola, the rest are stock photos.

20
00:02:18,830 --> 00:02:29,630
I also work with waste workers, those who work in death care services like crematoriums and funeral homes and then first responder personnel.

21
00:02:31,520 --> 00:02:39,620
So I would argue that working with human subjects is actually quite more difficult than working in a laboratory based setting.

22
00:02:40,430 --> 00:02:45,380
But it also does make your IRP a little bit more complicated.

23
00:02:45,950 --> 00:02:50,750
So I know you all know each other, but I don't hardly know any of you.

24
00:02:51,590 --> 00:02:59,450
So if you could just go around very quickly in the room like your name came up on your program,

25
00:02:59,450 --> 00:03:06,559
and then if you have any experience with human subjects and Arby's, if you don't, you can say, I don't.

26
00:03:06,560 --> 00:03:10,100
And if you do, I'll just very quickly to what extent.

27
00:03:11,270 --> 00:03:17,600
So I'll actually start in the back there, the fact that I'm first here.

28
00:03:23,180 --> 00:03:29,459
Okay. Great. And you first, your. Oh.

29
00:03:29,460 --> 00:03:32,970
How near you and I were?

30
00:03:37,130 --> 00:03:46,790
Okay. We are. I am impressed with.

31
00:03:49,820 --> 00:03:55,500
This time we're not going to football for. Okay.

32
00:03:55,620 --> 00:03:58,830
Sorry. Okay. So you've had experience coming here.

33
00:03:59,010 --> 00:04:02,360
I'm Amber. I'm a second year. Student.

34
00:04:02,380 --> 00:04:05,560
I have not had any any experience in this.

35
00:04:06,480 --> 00:04:10,950
And we're talking about her experience.

36
00:04:12,060 --> 00:04:15,090
I'm not sure. I'm pretty sure I'm a huge.

37
00:04:41,260 --> 00:04:45,150
I just discovered. So I'm working as a journalist.

38
00:04:49,260 --> 00:04:53,160
I work in this project that is going to be.

39
00:04:54,920 --> 00:04:58,780
I have been. David.

40
00:04:58,780 --> 00:05:02,980
I'm first here right now. I used to work with.

41
00:05:04,540 --> 00:05:09,860
Human subjects and bio monitoring research. And I currently work with data.

42
00:05:12,110 --> 00:05:18,320
Okay. I'm Layla. I'm a first year MSC student, and I do not have any human subjects.

43
00:05:19,670 --> 00:05:23,730
Hi. My name is Patricia, and I'm a first year student.

44
00:05:23,960 --> 00:05:36,540
I. And Morgan Forster led.

45
00:05:39,110 --> 00:05:50,120
And I've worked on two different stories about. I Karen a second year.

46
00:06:04,650 --> 00:06:16,530
Okay. Okay. So it sounds like we kind of have like. A third to two thirds that versus like five and have it for those who have it.

47
00:06:16,830 --> 00:06:20,780
Would you like to do human subjects research in the future? Okay.

48
00:06:20,780 --> 00:06:27,230
I see a lot of head shakes and I look back for those who have done human subjects research.

49
00:06:27,240 --> 00:06:37,480
Did you find it enjoyable? Yeah, man, I think it matters more than.

50
00:06:39,400 --> 00:06:42,790
He's doing animal research to learn more about Axl. Okay.

51
00:06:42,870 --> 00:06:49,629
Okay. Pros and cons. Right. So we did have you did have three readings to scam,

52
00:06:49,630 --> 00:06:58,240
if you don't remember how when I'm talking and then you can send forms to look at and you can kind of get for discussion at the end.

53
00:06:59,140 --> 00:07:06,640
This here is just a comic from excuse me where the person obtaining consent says we're concerned

54
00:07:06,640 --> 00:07:10,930
that some of your results may be tainted by the fact that your human subjects are awful.

55
00:07:10,930 --> 00:07:14,620
And they're talking to the researcher and the researcher says, What do you mean?

56
00:07:14,620 --> 00:07:22,269
As they said, several participants in your drug trial were arrested for arson and said side effects can be unpredictable.

57
00:07:22,270 --> 00:07:26,950
And they said they were in the control group. And then in your prisoner's dilemma study,

58
00:07:26,950 --> 00:07:33,850
80% of the participants chose to betray their partners before the experimenter had a chance to tell them about the reward.

59
00:07:34,240 --> 00:07:41,200
Definitely troubling. In one experiment, your subjects repeatedly gave electric shocks to a stranger in another room.

60
00:07:41,200 --> 00:07:43,750
And that's a famous psychological study, by the way.

61
00:07:44,590 --> 00:07:52,120
And then they sent this was a study on moisturizing creams and they said, yeah, they're not sure how they snuck in all that equipment.

62
00:07:53,440 --> 00:07:57,100
So let's start off with some very basic definitions.

63
00:07:57,460 --> 00:08:05,320
So human subjects are living individuals about whom an investigator conducts research on,

64
00:08:05,320 --> 00:08:14,050
either through intervention or interactions with the individual or number to identifiable private information.

65
00:08:14,470 --> 00:08:19,540
So if you, for example, are interested in coded deaths,

66
00:08:19,900 --> 00:08:26,860
looking at specific zip codes to determine socioeconomic status, those people are no longer living.

67
00:08:27,190 --> 00:08:31,810
Right? So that is fair game in terms of that is not considered human subjects research

68
00:08:32,200 --> 00:08:37,720
any secondary or national based data set that you have that is de-identified,

69
00:08:37,990 --> 00:08:44,350
that is not considered human subjects research, a survey, focus groups, semi-structured interviews,

70
00:08:44,650 --> 00:08:54,400
even if you're like a sociologist or ethnographer and you just want to observe people from a distance, you still have to file an IRB for that.

71
00:08:54,730 --> 00:08:58,270
Okay. And the IRB stands for Institutional Review Board.

72
00:08:58,270 --> 00:09:02,200
Every university has their own institutional review board.

73
00:09:02,200 --> 00:09:12,460
So this is essentially a committee that's been formally designated to approve, monitor and review biomedical and behavioral research among humans.

74
00:09:13,570 --> 00:09:26,620
I have been now this is my third Big Ten University that I've worked at, and it has the second most strict and rigorous IAB that I've worked at.

75
00:09:26,620 --> 00:09:33,790
So previously, when I was at the University of Nebraska Medical Center, they did a lot of biomedical research.

76
00:09:33,790 --> 00:09:41,350
And the Buffetts live in Omaha, Nebraska. So a lot of the Buffett Foundation pumps money into the med center for us to do research.

77
00:09:41,710 --> 00:09:48,700
But they look over your protocol with a fine tooth comb, very, very detailed.

78
00:09:48,700 --> 00:09:51,940
So, for example, for my master's capstone,

79
00:09:52,270 --> 00:10:00,580
I did focus groups and interviews with refugees from Bhutan to try to better understand their mental health.

80
00:10:01,270 --> 00:10:08,230
That review took no less than four months and got to the point where I was so granular.

81
00:10:08,560 --> 00:10:21,220
They wanted to know per person what the average cost of me providing water and refreshments were for each person so that it was not coercive.

82
00:10:21,670 --> 00:10:26,890
Okay. At Indiana University, they like literally did not care.

83
00:10:28,720 --> 00:10:33,310
And then here at University of Michigan, it's kind of somewhere in the middle between those two.

84
00:10:34,390 --> 00:10:42,610
Generally, though, when you are doing any research with human subjects, you have to obtain informed consent.

85
00:10:43,000 --> 00:10:49,750
And this is regardless if it's a medical surgical treatment, it doesn't have to be a medication, it doesn't have to be a clinical trial.

86
00:10:50,110 --> 00:10:58,989
Even with a survey, you have to obtain informed consent old school way with paper and physical copy.

87
00:10:58,990 --> 00:11:05,469
Maybe some of you have gone through the process where you've like participated in a psych study for like $30

88
00:11:05,470 --> 00:11:10,720
extra cash and they bring you into a room and you kind of like read through a sheet and sign it saying,

89
00:11:10,750 --> 00:11:14,559
I understand the risks and the benefits nowadays.

90
00:11:14,560 --> 00:11:20,620
A lot of surveys that you see from universities in particular that are for research have informed

91
00:11:20,620 --> 00:11:25,599
consent where the disclosures are at the top of the survey saying the risk and benefits.

92
00:11:25,600 --> 00:11:34,030
And by clicking, I agree to participate. Even though you're not formally signing your name and dating it, that is considered electronic consent.

93
00:11:35,110 --> 00:11:39,160
Okay so vulnerable populations when we think of.

94
00:11:39,470 --> 00:11:42,590
Who might be vulnerable in terms of who we do research with.

95
00:11:43,340 --> 00:11:47,240
I know you have the slides, but like who might some of those be?

96
00:11:48,380 --> 00:11:57,200
Yes, children. Pregnant pregnant women.

97
00:11:58,680 --> 00:12:01,920
Yes. Maybe a little lower socioeconomic status.

98
00:12:02,730 --> 00:12:11,920
Nebulous, but yes. Other thoughts? If there's a language barrier, maybe.

99
00:12:12,040 --> 00:12:17,780
Yeah, potentially. Oh, the elderly, actually.

100
00:12:18,170 --> 00:12:27,920
Okay. So according to most like your peers module and most ethical trainings that you'll go through on human subjects research,

101
00:12:27,920 --> 00:12:34,850
they'll consider pregnant women as a vulnerable population prisoners because they don't have free will.

102
00:12:35,270 --> 00:12:45,830
Right. Minors, children and youth, because they cannot fully consent those who may be had persons with intellectual disabilities.

103
00:12:46,280 --> 00:12:50,540
And then, as we mentioned, refugees, people were English.

104
00:12:50,540 --> 00:12:54,440
Isn't their first language, those of low income?

105
00:12:54,860 --> 00:12:59,900
Those are generally considered, yes. Vulnerable in the public health sense.

106
00:13:00,290 --> 00:13:04,550
But in the IAB eyes, they're not one of these major categories.

107
00:13:04,940 --> 00:13:09,360
So those groups, it totally depends on your protocol.

108
00:13:09,380 --> 00:13:21,200
Right. So just say, for example, you're doing a survey on, I don't know, something super basic like fruit and vegetable consumption.

109
00:13:21,200 --> 00:13:32,300
Right. If you are paying your participants $25 to fill out the survey, if you're giving that to mostly university professors,

110
00:13:32,900 --> 00:13:38,090
I bet most of them wouldn't even think $25 was worth your time to fill out the survey.

111
00:13:38,600 --> 00:13:49,130
Whereas, if you're targeting a low socioeconomic status, predominantly minority community, $25 does make a big difference to them.

112
00:13:49,970 --> 00:13:55,520
So that's not necessarily up to you to worry about, but when you file the RFP,

113
00:13:55,760 --> 00:14:02,720
that's why you have to fill out an excruciating detail what your participant incentives are and who your target population is.

114
00:14:03,020 --> 00:14:09,880
And it's up for the committee to decide. Essentially, they might come back and say, Whoa, whoa, whoa, this is too much.

115
00:14:09,890 --> 00:14:18,360
You need to back down the amount, because some people might feel motivated to, like, fill that out just to get, you know, whatever.

116
00:14:18,710 --> 00:14:22,460
Like when I was a grad student, I would do psych studies all the time.

117
00:14:22,460 --> 00:14:26,930
I've done an MRI. I memorize like what a bunch of rocks look like.

118
00:14:26,930 --> 00:14:29,930
It was like the easiest, like, $50 I ever made, right?

119
00:14:29,930 --> 00:14:41,630
But like you, you come to realize when they think through incentives, don't want to try to bias systematic bias or data collection from the start.

120
00:14:42,890 --> 00:14:46,160
So, for example, my bachelor's degree is in cognitive science.

121
00:14:46,190 --> 00:14:53,630
I'm learning how to choose thrown out, do so as part of what we had to do as psych students and COGS as students.

122
00:14:53,960 --> 00:15:01,370
Part of our participation grade for every class was that we had to participate in X amount of credit hours of psych studies.

123
00:15:01,880 --> 00:15:04,910
That's coercive because that's part of my grade, right?

124
00:15:05,150 --> 00:15:13,160
And now basically all these big psych studies, their study population is primarily healthy, 18 to 22 year olds.

125
00:15:14,060 --> 00:15:19,310
So that systematically biasing in the study for people who speak different languages.

126
00:15:19,700 --> 00:15:27,710
Interestingly, the IAB will ask a lot of Arabs will ask you to see the translated version of your consent forms.

127
00:15:28,430 --> 00:15:34,310
So at Nebraska, for example, they asked for my translated consent forms in Bhutanese,

128
00:15:34,640 --> 00:15:39,950
even though I knew no one in the IAP office could read Bhutanese.

129
00:15:40,400 --> 00:15:46,520
Now, if your population that you're working with does not have appropriate levels of literacy,

130
00:15:47,030 --> 00:15:50,870
they might waive the written consent for verbal consent.

131
00:15:51,140 --> 00:15:56,990
So you can explain to them verbally why you're consenting them, and then they sign off on that,

132
00:15:56,990 --> 00:16:01,580
and that is sufficient, but you have to consent them in like a private room or area.

133
00:16:04,400 --> 00:16:08,790
Little flicker. Yes.

134
00:16:09,270 --> 00:16:12,900
The symbolic of the transcript of what he told him. So.

135
00:16:12,990 --> 00:16:16,709
So. Yes. So the script is what? You'll turn in to the IAB.

136
00:16:16,710 --> 00:16:21,660
So if you're providing verbal consent, you have to turn into the script verbatim,

137
00:16:21,660 --> 00:16:25,950
like what you will say to consent, the persons that you will stick to.

138
00:16:26,490 --> 00:16:31,319
Yes. And then generally you also have to keep a record of everybody you talk to you.

139
00:16:31,320 --> 00:16:34,620
Even if they're de-identified, you give them one, two, three, four,

140
00:16:34,620 --> 00:16:41,640
ABC D if D comes in and says, I don't consent after you explain the risk and the benefits,

141
00:16:42,030 --> 00:16:48,100
then you have to like keep track to say like you did not consent, move on to the next designated person product.

142
00:16:48,420 --> 00:17:01,049
Does that make sense? So just for historical context, in terms of why there are so many protections now for human subjects,

143
00:17:01,050 --> 00:17:11,400
and are these the big one that people think about is in 1947, the Nuremberg Code, and then 64 the Declaration of Helsinki,

144
00:17:12,300 --> 00:17:22,530
where they finally had the first time explicit international guidelines for the Ethical Treatment of Human Subjects and research in response

145
00:17:22,530 --> 00:17:33,120
particularly to the atrocities that happened during World War Two in the internment camps against the Jewish people who were detained.

146
00:17:33,630 --> 00:17:38,970
Then in 62, you have the CAF over amendments to the Food, Drug and Cosmetic Act,

147
00:17:39,300 --> 00:17:46,880
which required drug manufacturers to prove to the FDA the effectiveness of their product before marketing them.

148
00:17:47,310 --> 00:17:53,130
And this was in response to the thalidomide tragedy. Who knows what the letter might tragedy was?

149
00:17:53,850 --> 00:18:00,440
Yes. A medicine given to young women who wanted to try to get pregnant.

150
00:18:00,920 --> 00:18:06,480
And when they got pregnant, those. And ended up having severe deformities.

151
00:18:07,410 --> 00:18:14,070
Close. It was for women who are already pregnant. They gave it to try to treat morning sickness.

152
00:18:15,720 --> 00:18:18,780
It's a known human carcinogen now, so it's a strategy.

153
00:18:18,780 --> 00:18:22,320
And essentially so it did cause severe deformities.

154
00:18:22,680 --> 00:18:27,150
Now, this what these amendments were like, yeah, a step in the right direction.

155
00:18:27,540 --> 00:18:36,119
But I hope you all know the drug and cosmetic industry is still highly unregulated, highly unregulated.

156
00:18:36,120 --> 00:18:39,630
And this is a problem that we deal with when I work with nail salon workers,

157
00:18:40,020 --> 00:18:49,139
because there's so many like trade secrets or proprietary sequins in terms of like scents and colorings and whatever on the marketing labels,

158
00:18:49,140 --> 00:18:52,570
they don't actually have to disclose to you fully what's in there.

159
00:18:52,590 --> 00:18:59,820
So there's this whole thing, there's this whole, you know, this back and forth that there has been about talc in baby powder.

160
00:19:00,210 --> 00:19:06,660
Right. There's also a ton of color in almost every eyeshadow that's on the market there.

161
00:19:06,900 --> 00:19:10,370
And in nail products, there is tons of tile.

162
00:19:10,380 --> 00:19:18,120
You mean acetone, formaldehyde, known human carcinogens, completely unregulated supplements that you might take, right.

163
00:19:18,120 --> 00:19:21,840
Like vitamin A, D, blah, blah, blah. That's not regulated by the FDA.

164
00:19:22,230 --> 00:19:27,540
These like collagen proteins or whatever people are doing now, bone broth.

165
00:19:27,860 --> 00:19:31,860
I think people were drinking chlorophyl for a while, which is like for plants.

166
00:19:32,340 --> 00:19:38,550
It's like a whole the like nutrition, influencer industry, all very unregulated still.

167
00:19:40,350 --> 00:19:50,190
Then in 66, the Beecher article that you read in the New England Journal of Medicine directly resulted in a memorandum establishing I Arby's.

168
00:19:50,580 --> 00:19:53,820
That Beecher article essentially talked about different,

169
00:19:54,360 --> 00:20:05,130
egregious things that have happened in medical research where like one person was in a coma and couldn't consent and they still did research on them.

170
00:20:05,400 --> 00:20:12,930
Some people didn't have full capabilities to consent. One of the studies was babies and babies can't consent, right?

171
00:20:13,560 --> 00:20:14,780
That is 74.

172
00:20:14,790 --> 00:20:22,860
There is the National Research Act, which created the National Commission for the Protection of Human Subjects on Biomedical and Behavioral Research.

173
00:20:23,160 --> 00:20:27,020
And this was in response to the Tuskegee Syphilis Study.

174
00:20:27,080 --> 00:20:31,620
Have you talked about that in your other classes? I see some had not.

175
00:20:32,130 --> 00:20:39,210
Can someone summarize that for me briefly? I found this on the web.

176
00:20:42,630 --> 00:20:48,140
Anyone? Okay.

177
00:20:48,440 --> 00:20:53,420
I'm sorry. What's your name again? Amber. Yes, thank you. Amber. Black men were purposefully.

178
00:20:54,480 --> 00:20:57,930
Infected with syphilis. And they were studied.

179
00:20:58,020 --> 00:21:01,110
They were not given, like, a treatment. So they were just studying the.

180
00:21:01,680 --> 00:21:05,010
How simplistic. Progressives.

181
00:21:06,790 --> 00:21:10,089
Well, yeah, they weren't they weren't given syphilis.

182
00:21:10,090 --> 00:21:18,880
They already had syphilis, but they were withholding treatment to the black men while the white participants got treatment,

183
00:21:19,540 --> 00:21:24,100
and a lot of the participants ended up dying from syphilis, which is totally curable.

184
00:21:24,590 --> 00:21:30,360
Okay. Here. 1979 Belmont Report.

185
00:21:30,360 --> 00:21:34,710
This was the ethical principles and guidelines for the Protection of Human Subjects research.

186
00:21:35,100 --> 00:21:39,660
If you did your peers saying you had to read through the whole Belmont report synopsis.

187
00:21:40,320 --> 00:21:44,250
And then finally, in 91, we have something called the common rule,

188
00:21:44,550 --> 00:21:52,860
which requires each institution engaged in federally supported human subjects research to file assurance or protection for human subjects.

189
00:21:53,370 --> 00:22:01,079
So this is why you, as grad students, when you may participate with some of us faculty on a grant that's funded by the NIH,

190
00:22:01,080 --> 00:22:05,670
CDC, NSF, for example, these are all federally supported.

191
00:22:05,940 --> 00:22:11,969
So you better have an hour before this. Right. But if you apply for funding through a foundation,

192
00:22:11,970 --> 00:22:20,850
they're not necessarily federally supported and may not necessarily require the same level of documentation for human subjects research.

193
00:22:23,380 --> 00:22:29,890
This one here. This was just one of your readings. This is just some historical context of the yellow fever consent form.

194
00:22:29,890 --> 00:22:34,030
So this is the English version in 1900.

195
00:22:35,620 --> 00:22:41,139
So the undersigned understands perfectly well, in the case of the development of yellow fever,

196
00:22:41,140 --> 00:22:47,049
that he endangers his life to a certain extent, but entirely impossible for him to avoid the infection.

197
00:22:47,050 --> 00:22:53,500
During his stay on the island, he prefers to take the chance of contracting it intentionally in the belief that he will

198
00:22:53,500 --> 00:22:57,970
receive from the said permission the greatest care and most skillful medical service.

199
00:22:58,480 --> 00:23:02,350
And they received in the sum of $100 in American gold.

200
00:23:02,590 --> 00:23:07,480
And in the case that his contracting yellow fever during any time during his residence,

201
00:23:07,690 --> 00:23:13,360
he will receive an addition of $100 in American gold upon his recovery.

202
00:23:13,360 --> 00:23:21,730
And in the case of his death, because of the disease, the sum $200 to the person undersigned shall designate at his convenience.

203
00:23:22,630 --> 00:23:28,480
So basically this is saying, okay, you're going to get you're going to have you get yellow fever.

204
00:23:28,930 --> 00:23:32,140
And once you get that, you get 100 bucks, which is a lot. 1900.

205
00:23:32,590 --> 00:23:38,640
And then if you, you know, get that and you, like, recover from it.

206
00:23:38,660 --> 00:23:45,190
Yeah. But in the event that you died from yellow fever, your beneficiary essentially will will get it.

207
00:23:45,820 --> 00:23:52,150
This kind of thing obviously would not fly today, but it's what they had back then.

208
00:23:52,510 --> 00:24:00,010
Okay. I cannot talk about human subjects, though, without bringing up structural racism.

209
00:24:00,280 --> 00:24:05,770
And again, I apologize to King and Mira, who already heard this in my other class.

210
00:24:06,670 --> 00:24:14,680
But there is a huge issue with biomedical ethics, the first big case being Henrietta Lacks.

211
00:24:15,340 --> 00:24:19,570
We all heard of her. Who, besides Ambra, can tell me about her.

212
00:24:24,020 --> 00:24:41,240
Yes. Yes.

213
00:24:41,260 --> 00:24:46,780
Yes. So it's you know, there's a very good book called The Immortal Life of Henrietta Lacks.

214
00:24:46,780 --> 00:24:51,790
And also they made a movie about it, I think, produced by the O network or something, Oprah.

215
00:24:52,480 --> 00:24:57,879
But essentially, like her, cervical cancer cells are considered immortal cells.

216
00:24:57,880 --> 00:25:04,270
And they developed what they call now HeLa cells, where essentially they are like the foundational cells used in cancer research,

217
00:25:04,660 --> 00:25:12,870
used in billions and billions of biomedical research dollars, like have made the biomedical research industry billions of dollars.

218
00:25:12,880 --> 00:25:21,580
They never consented her. She died from cervical cancer anyway, and her family never saw any of the benefits from that.

219
00:25:21,760 --> 00:25:26,230
Okay. Anyone know all about Jay, Mary Marion, The Sims?

220
00:25:27,550 --> 00:25:33,100
Okay, Jay. Marion Sims is considered the father of modern gynecology.

221
00:25:34,750 --> 00:25:40,270
He did a lot of his research on black slaves.

222
00:25:40,660 --> 00:25:45,459
So that's the picture at the top here where they were not consulted, obviously,

223
00:25:45,460 --> 00:25:54,460
because slaves were treated as property rather than human beings and often performed procedures without anesthesia.

224
00:25:55,090 --> 00:26:00,580
So not only, you know, using things like the speculum in performing pap smears,

225
00:26:00,850 --> 00:26:08,679
but even more painful procedures like a colposcopy, which is where they take out tissue from your cervix,

226
00:26:08,680 --> 00:26:16,810
essentially, and a lot of other gynecological procedures without consent, without anesthesia, without treatment, without follow up.

227
00:26:19,060 --> 00:26:29,379
And as a result of these kinds of atrocities, there's no better way to put it, these atrocities that have happened here in the United States.

228
00:26:29,380 --> 00:26:32,580
The Henrietta Lacks thing was at Johns Hopkins University.

229
00:26:32,590 --> 00:26:46,840
Okay. It makes it very difficult for communities of color to see in academic institutions as trusted and reliable sources of information.

230
00:26:47,920 --> 00:26:54,580
And then there is, again, this question of culturally and linguistically appropriate, informed consent.

231
00:26:55,390 --> 00:26:59,800
What we talked about briefly before are the incentives coercive,

232
00:27:00,250 --> 00:27:05,980
and then thinking about the identity intersectionality of people in terms of their gender,

233
00:27:06,310 --> 00:27:12,130
race, ethnicity, income level and then citizenship status as well.

234
00:27:14,650 --> 00:27:21,340
A lot of folks think that they do community based research or ethical research.

235
00:27:21,440 --> 00:27:31,419
They don't actually do that. So a lot of these communities of color, you still kind of like a helicopter research approach where people will come in,

236
00:27:31,420 --> 00:27:35,120
collect their data, do their air sampling, do whatever.

237
00:27:35,560 --> 00:27:40,840
Like a little helicopter dish chopper and collect what they need and then go away.

238
00:27:41,120 --> 00:27:44,770
There's no follow up with the community. There's no incentives for them.

239
00:27:45,130 --> 00:27:51,520
They don't understand what the outcomes were. It's just so they can publish in like whatever high impact journal.

240
00:27:53,560 --> 00:27:57,850
These things still happen, unfortunately.

241
00:27:57,850 --> 00:28:06,490
So this is something that they're trying to be mindful of and cognizant of when looking at protocols for human subjects.

242
00:28:06,730 --> 00:28:13,480
And sometimes, depending on how granular they're getting right for the NIH, for example, they will ask,

243
00:28:13,480 --> 00:28:20,590
we'll break down of how many males versus females who plan to consent from each racial ethnic category.

244
00:28:21,190 --> 00:28:26,500
And if you're excluding certain categories, there better be a good reason why you're excluded.

245
00:28:30,690 --> 00:28:41,820
So just a question for the group. Do you think today, in today's day and age, there are still ethical issues going on in human subjects research?

246
00:28:43,730 --> 00:28:47,030
Yeah. Yeah. Oh, yeah. Oh, yeah.

247
00:28:47,660 --> 00:28:50,660
This is why we now have to have them.

248
00:28:50,930 --> 00:28:55,040
Does anyone have any anecdotes or stories off of the top of their head?

249
00:28:59,710 --> 00:29:00,280
I have one.

250
00:29:02,080 --> 00:29:12,490
I won't say who it is, but there is a researcher at a pretty prominent university that is interested in what's going on in Flint, Michigan.

251
00:29:13,000 --> 00:29:18,220
Right. So in Flint, Michigan, we've had a water crisis since 2014.

252
00:29:19,270 --> 00:29:27,879
Poor infrastructure has led to really bad water, like water that isn't potable for drinking,

253
00:29:27,880 --> 00:29:33,400
let alone bathing in high blood levels due to the pipes leaching lead.

254
00:29:35,210 --> 00:29:44,120
This researcher was testing bone lab in human subjects in Detroit, primarily black.

255
00:29:46,800 --> 00:29:53,390
Decided to use. An X-ray machine bought from Lowe's.

256
00:29:53,690 --> 00:29:59,290
Right. Which is a home improvement store. You're using it on property?

257
00:29:59,300 --> 00:30:02,990
Not it's meant to be used on property. Right? Not humans.

258
00:30:03,530 --> 00:30:07,640
Okay. Didn't didn't mention this to the IAB.

259
00:30:09,140 --> 00:30:12,260
Yeah. He had a he's he's dealing with a huge lawsuit right now.

260
00:30:12,650 --> 00:30:17,660
But, you know, yeah, this kind of stuff happens all the time.

261
00:30:18,680 --> 00:30:28,129
And I think especially when when people, you know, because here in academia, it's very much the whole like publish or perish thing.

262
00:30:28,130 --> 00:30:34,010
People get really desperate to get that that funding to publish that paper.

263
00:30:34,310 --> 00:30:43,310
So sometimes they cut corners and not everybody has had the benefit of being trained in ethical research conduct.

264
00:30:43,910 --> 00:30:47,570
Probably this person thought that was perfectly fine to do.

265
00:30:47,780 --> 00:30:52,670
Right. Didn't think they were doing anything nefarious in particular.

266
00:30:53,930 --> 00:31:02,180
Even when you're doing your human subjects research today, if anything deviates from your protocol,

267
00:31:02,180 --> 00:31:12,140
even just a little bit or there's what we call an adverse event, you're supposed to do your due diligence and report that to the IRP immediately.

268
00:31:13,160 --> 00:31:23,570
I myself have had my hands slapped by the RB because I finished that study on Bhutanese refugees in my master's degree.

269
00:31:23,580 --> 00:31:31,280
I wrote my where I went to get my master's degree and I only had to do an internship, but I still had to write a thesis as an MPH.

270
00:31:31,730 --> 00:31:37,520
So that was like 2 to 4. So I finished writing my thesis, which is like 80 pages,

271
00:31:37,880 --> 00:31:48,050
and then I moved to Indiana to get a new job and I was trying to close out the study because I had gotten my degree and blah,

272
00:31:48,050 --> 00:31:59,210
blah, blah and all that kind of stuff. And so when I contacted the Nebraska IAB, they were like, Where are your consent forms from that study?

273
00:31:59,690 --> 00:32:03,290
And I said, Oh, they're in my apartment here in Indiana.

274
00:32:03,710 --> 00:32:06,380
And they were like, Absolutely not. They were like,

275
00:32:06,380 --> 00:32:18,890
You need to e-mail those to Dr. Johansen in Nebraska immediately via FedEx and then scan us a copy of your FedEx confirmation that you have mailed it.

276
00:32:19,130 --> 00:32:24,200
And then, Dr. Johansen, when you receive Aurora's consent forms, let us know.

277
00:32:24,200 --> 00:32:30,830
And this study was closed. Right. So they are very stringent about those kinds of things.

278
00:32:31,950 --> 00:32:35,910
Yeah. Consenting.

279
00:32:36,270 --> 00:32:39,330
Another example. So I totally depend on the institution. Right.

280
00:32:39,840 --> 00:32:48,180
On how strict they are. But it's like, you know, same thing with plagiarism when in doubt site with your human subjects.

281
00:32:48,180 --> 00:32:52,260
When in doubt, just go ahead and drop a line to the IAB in reporting.

282
00:32:53,310 --> 00:32:57,150
When I was an undergrad at the University of California, San Diego,

283
00:32:57,600 --> 00:33:04,259
I was working in a speech and development lab where we would go essentially solicit outside of

284
00:33:04,260 --> 00:33:10,200
preschools and kindergartens to try to get parents to sign consent forms so their kid could,

285
00:33:10,200 --> 00:33:12,990
like participate in our speech and language study.

286
00:33:13,350 --> 00:33:23,340
And if the parents consented, we would like strap the kid to like a car seat that was just on the ground, and then they would follow a laser.

287
00:33:23,430 --> 00:33:30,120
You know, we would track their eye movements with a laser while they were listening to like different musical tones or speech tones.

288
00:33:31,050 --> 00:33:37,740
And the parents were like really surprisingly chill, about like 21 year olds like,

289
00:33:38,100 --> 00:33:44,700
like cornering them in the parking lot and being like, hey, can we like track your child's eye movement?

290
00:33:44,700 --> 00:33:49,290
And in exchange, they'll get like a little, little toy or a little thing of Play-Doh.

291
00:33:49,290 --> 00:33:54,449
But because it was in La Hoya, which was like a very affluent part of San Diego,

292
00:33:54,450 --> 00:34:00,299
like they were like, okay, for the science, I do not imagine that same thing going very well.

293
00:34:00,300 --> 00:34:09,150
If it was like predominantly like a low income community or folks who don't necessarily trust academic institutions like that.

294
00:34:09,540 --> 00:34:14,460
If I was in preschool and somebody came out to my mom and was like, Let me stop your kid,

295
00:34:15,510 --> 00:34:18,659
do a chair and track their eye movement, she'd be like, Absolutely not.

296
00:34:18,660 --> 00:34:27,240
Okay. So yes, this is still very much an issue today, which is why we have to have such a rigorous process for the IAB.

297
00:34:28,830 --> 00:34:35,430
In practice, the National Institute of Health does require education on a protection of human subjects,

298
00:34:35,430 --> 00:34:42,749
research for all investigators and for any students that you might you already have some experience with.

299
00:34:42,750 --> 00:34:48,360
If you're working with one of the faculty on a protocol that requires human subjects,

300
00:34:48,360 --> 00:34:51,270
they'll probably agree to a protocol you've outlined, your peers,

301
00:34:51,630 --> 00:35:04,650
etc. but they want to make sure that your risks are minimized to the subjects and the risks are reasonable in relation to the anticipated benefits.

302
00:35:04,650 --> 00:35:16,410
And the selection of subjects is equitable. So I'm a survey methodologies and I really do survey research, which is more difficult than people think.

303
00:35:16,710 --> 00:35:24,420
But in terms of the benefits versus the risks for the risks, I still have to say boredom is a risk.

304
00:35:24,660 --> 00:35:32,640
Time loss is a risk. Potentially feeling a mental discomfort from answering uncomfortable questions is a risk.

305
00:35:32,970 --> 00:35:40,260
You have to put all of this in the consent so you can imagine if you're doing something a lot more invasive,

306
00:35:40,260 --> 00:35:42,930
like drawing blood or administering a drug,

307
00:35:43,230 --> 00:35:52,650
you will have to lay those out really clearly and the benefits must outweigh the risks and that the selection of subjects is equitable.

308
00:35:53,520 --> 00:35:59,010
So perhaps in your statistics classes we've talked about convenience sampling.

309
00:35:59,910 --> 00:36:02,430
Some people try to do quota sampling,

310
00:36:03,270 --> 00:36:10,860
but you can't only just like recruit college students because they're the most convenient population and that they're already there.

311
00:36:10,860 --> 00:36:19,830
Right? Or you can't just recruit only white people just because they're easier to access.

312
00:36:20,130 --> 00:36:29,880
Now, if your study is specifically focused on looking at something like perceptions of diabetes among black people,

313
00:36:30,840 --> 00:36:34,139
yeah, that makes sense that you're only recruiting black people. Right.

314
00:36:34,140 --> 00:36:39,660
But you have to explain your exclusion criteria to the IAB.

315
00:36:40,710 --> 00:36:44,640
Okay. I can only talk to this about.

316
00:36:44,640 --> 00:36:52,620
About this in human beings. I don't I don't know what's going on with the mice these days because historically,

317
00:36:52,620 --> 00:37:02,580
a lot of biomedical studies and even toxicology and epigenetic studies use male mice that are severely inbred.

318
00:37:03,720 --> 00:37:09,240
So I find extrapolating that data to human circumstances really tenuous.

319
00:37:10,140 --> 00:37:14,520
But that is for the animal care lecturer, not me.

320
00:37:14,790 --> 00:37:20,760
Okay. So in terms of policies for federal, we do have a couple.

321
00:37:21,450 --> 00:37:27,420
So the FDA, as I mentioned, they have their own institutional review boards for clinical investigators.

322
00:37:27,810 --> 00:37:31,410
The NIH has one as well. The Office for Human Protection's.

323
00:37:31,510 --> 00:37:37,450
Research. And then here at the University of Michigan, we have two separate offices.

324
00:37:37,460 --> 00:37:43,300
One is for clinical trials and one is for behavioral sciences and health sciences research.

325
00:37:44,830 --> 00:37:52,990
Now, if you're having collaborators at multiple sites and you're all doing human subjects research, but like just say,

326
00:37:53,000 --> 00:37:58,000
like, I'm recruiting people out of here at the University of Michigan and Harvard is doing the same thing.

327
00:37:58,000 --> 00:38:07,150
But in Cambridge and like UCLA is doing the same thing, but like in L.A., you would have to file what you call a multi site IAB,

328
00:38:08,020 --> 00:38:16,239
where each site has a designated pi, and the pi ultimately is the person whose shoulders it falls on,

329
00:38:16,240 --> 00:38:19,780
if anything like super ethically egregious happens.

330
00:38:20,110 --> 00:38:26,980
Although everybody who's on the protocol has been tested like, yes, they didn't do all the stuff that you went through on your peers training.

331
00:38:29,950 --> 00:38:33,760
So again, the idea be. So are you.

332
00:38:34,720 --> 00:38:39,750
Are you all too young for this meme? Now just look like two people.

333
00:38:42,060 --> 00:38:46,710
So this is from The Lord of the Rings, the O.G. trilogy.

334
00:38:47,760 --> 00:38:54,959
So, you know, one does not simply submit their project RV for approval five weeks before the due date.

335
00:38:54,960 --> 00:39:00,570
So our reviews take a notoriously long time, even if it's something that is exempt.

336
00:39:01,200 --> 00:39:08,730
For example, like a survey which is very minimal, or you're doing observations or you're maybe looking at ethnographic data,

337
00:39:09,210 --> 00:39:14,550
don't wait until the last minute because sometimes these committees only Minny once in a while.

338
00:39:14,940 --> 00:39:22,110
The reason why my RV at Nebraska took four months is because they only met once every two months, and then that one time they met,

339
00:39:22,110 --> 00:39:28,410
they had issues that they sent back to me to correct, and then I had to wait another two months for them.

340
00:39:30,360 --> 00:39:34,350
I didn't get approved until April and I was supposed to graduate in May.

341
00:39:34,590 --> 00:39:38,730
Okay, so I was like rushing to collect that data.

342
00:39:38,910 --> 00:39:46,920
Thankfully, it was qualitative, right? But don't wait until the last minute, especially if it's clinical trials or anything like that.

343
00:39:47,190 --> 00:39:52,769
It can take up to eight weeks or longer and then they can keep sending you back and forth.

344
00:39:52,770 --> 00:39:58,180
Corrections and clarifications. Okay.

345
00:39:58,330 --> 00:40:06,340
So now we have this case study. I will read you the case study and then we'll do, like little breakout groups.

346
00:40:06,790 --> 00:40:13,269
So Mary's professor gives everyone in the class an assignment to talk with a classmate who's not

347
00:40:13,270 --> 00:40:18,670
in the class about the way their families deal with medical emergencies and chronic illness.

348
00:40:19,360 --> 00:40:22,870
Students should come to class prepared to report on the interviews.

349
00:40:23,290 --> 00:40:30,040
Keep in mind, their presentation should not mention any means to protect the privacy of their classmates.

350
00:40:30,670 --> 00:40:37,270
Mary has some concerns about the assignment with regards to some of the rules pertaining to the use of human subjects in research.

351
00:40:37,810 --> 00:40:40,150
When she raises her concerns with the professor,

352
00:40:40,420 --> 00:40:47,560
he assures her that informal conversations with classmates are not research and therefore not regulation.

353
00:40:47,770 --> 00:40:58,630
So first should be Mary be content with his insurance and contact the interviews to if she still has concerns, where should she turn for advice?

354
00:40:59,650 --> 00:41:05,050
And three Did the professor act properly in giving this assignment to the class?

355
00:41:07,140 --> 00:41:14,850
I'm going to have you just turn to like whoever is closest to you to discuss these three questions,

356
00:41:15,690 --> 00:41:22,920
and then we will regroup when I hear conversations die down or like starting to go on other topics to see what your thoughts are.

357
00:41:23,910 --> 00:41:32,860
Okay, good. I know, but.

358
00:41:38,690 --> 00:41:47,370
Yeah. You know, I don't know.

359
00:41:48,140 --> 00:42:03,410
I feel like you never know what she went through with these X, Y and Z happening and able to kind of in hindsight.

360
00:42:10,760 --> 00:42:18,150
I'm not sure. Three.

361
00:42:21,300 --> 00:42:25,690
Yeah. That's the. Yeah.

362
00:42:26,640 --> 00:42:35,890
Look, I just hope it's a. Definitely been more than 100.

363
00:42:56,200 --> 00:42:59,690
Is that a fair comparison?

364
00:43:00,050 --> 00:43:13,180
Yeah, I. Once you get your optimism right, you'll see that nothing.

365
00:43:19,410 --> 00:43:22,930
I think some of the things that.

366
00:43:25,360 --> 00:43:31,120
I mean, I think I'm a sucker for that.

367
00:43:37,060 --> 00:43:45,100
I think it's a different process to get into this area because I've just seen

368
00:43:46,330 --> 00:43:54,800
some of your eyes look like they're not going to look like these guys for years.

369
00:43:54,820 --> 00:44:00,010
And I don't want platitudes like you want to know what's going on.

370
00:44:02,120 --> 00:44:13,360
And, you know, I hear this and I think, Mr. President, as I said, this was a very good incident with no other country name.

371
00:44:15,720 --> 00:44:23,260
I mean, you deliver the message, what you're saying no one would ever know.

372
00:44:25,700 --> 00:44:33,170
I think you are right. Yeah.

373
00:44:37,490 --> 00:44:44,230
Okay. You know, I don't know if the joint.

374
00:44:46,710 --> 00:44:59,730
So. I look at the electronics and I'm just like the video.

375
00:45:00,170 --> 00:45:03,340
Yes. I found that.

376
00:45:03,530 --> 00:45:12,350
You know, we mentioned you know, I look, I know, you know,

377
00:45:12,600 --> 00:45:21,200
yesterday I wasn't making it and I heard I don't know how to, you know, get around attention.

378
00:45:22,000 --> 00:45:26,910
It's still like the status quo. All right.

379
00:45:29,280 --> 00:45:34,050
Okay. What's the consensus on A?

380
00:45:34,800 --> 00:45:39,060
Should he be content with these assurances? Thumbs up if you think yes.

381
00:45:39,060 --> 00:45:43,770
Thumbs down if no. I see.

382
00:45:43,920 --> 00:45:50,940
I see some partial thumbs, like half bands, which I didn't ask for, but also some thumbs up.

383
00:45:51,390 --> 00:45:56,590
So partial thumbs what? Why? Well, it's not research.

384
00:45:59,320 --> 00:46:06,070
As long as the doesn't is not. Collecting information that the students reveal about the interview.

385
00:46:07,680 --> 00:46:12,350
There's no. Research Center.

386
00:46:12,990 --> 00:46:24,290
Okay. Yes. But also, at the same time, it's like the information of the reports they're going to be presenting no matter how hard you try to make it,

387
00:46:24,290 --> 00:46:28,069
like anonymously, that person is still in your class.

388
00:46:28,070 --> 00:46:33,710
And there are different ways like that people can figure out what information about.

389
00:46:35,020 --> 00:46:39,670
So it's like. It's kind of weird to give this assignment.

390
00:46:39,910 --> 00:46:46,030
Yeah. So it's like the way their families deal with emergencies and chronic illnesses, right?

391
00:46:46,390 --> 00:46:50,290
So they're not necessarily identifying anybody.

392
00:46:50,680 --> 00:46:57,770
So I'm not telling you, like my mom's name or my dad's name, but you still know, like who presented what.

393
00:46:57,790 --> 00:47:05,230
Right. So it's like, you know, one person could be like, oh, yeah, we just go to the doctor like urgent care.

394
00:47:05,500 --> 00:47:09,639
And one person is like, Hey, my parents don't allow me to see the doctor.

395
00:47:09,640 --> 00:47:14,740
They like, you know, closet or something like that. Right. Like that would be prompting concerns.

396
00:47:15,460 --> 00:47:20,530
I would say that from an IAB standpoint, technically, this is not research.

397
00:47:20,950 --> 00:47:30,100
This probably would be a lecture that the professor should not report that will live in the cloud for three months to six months.

398
00:47:30,910 --> 00:47:36,730
But this might be more appropriate where the class has established community guidelines like we do in my other class,

399
00:47:37,060 --> 00:47:46,360
where they assure confidentiality and it's like a contract between the peers and the professor about what's discussed in class stays in class,

400
00:47:46,360 --> 00:47:52,509
but it's not being published anywhere. It's not being used hypothetically for research.

401
00:47:52,510 --> 00:48:00,370
Now where would be a problem if the professor is using this class to anecdotally collect information,

402
00:48:00,370 --> 00:48:07,270
right, and then use that as a sample to as a pilot data for elsewhere.

403
00:48:08,110 --> 00:48:11,260
But we're going to assume the best in the professor.

404
00:48:11,410 --> 00:48:16,400
Okay. Now, Mary still has concerns, though, like this.

405
00:48:16,550 --> 00:48:21,020
You know, the assurance did not assuage her. Who can she talk to?

406
00:48:29,570 --> 00:48:34,100
She is going to go to the club, her classmates, and be like, this is this is next.

407
00:48:34,100 --> 00:48:42,340
And like, what? Yeah. Research is doing.

408
00:48:42,460 --> 00:48:45,820
Research isn't going to do, to be honest.

409
00:48:49,230 --> 00:48:52,340
Ask for advice. Yeah.

410
00:48:52,340 --> 00:48:56,300
That professor, probably. Is it in an interview office?

411
00:48:56,330 --> 00:49:02,239
Yes. Derby office. So every IAB at every university has a general email.

412
00:49:02,240 --> 00:49:04,520
Think ours is like help at IAB.

413
00:49:04,520 --> 00:49:11,870
You mention that, Edu, but also a phone line where somebody who works there is designated to field these kinds of questions,

414
00:49:12,140 --> 00:49:15,620
not just from students, but also participants all over.

415
00:49:15,920 --> 00:49:20,840
So like what? All of my surveys have distributed, this contact information is there.

416
00:49:20,850 --> 00:49:27,580
So just say like I was, I was doing a survey and saliva collection with waste workers at local landfills.

417
00:49:28,010 --> 00:49:29,270
They consented to it.

418
00:49:29,600 --> 00:49:37,560
But after and I give them a copy of their consent afterward, though a week, two weeks later, they're like, actually, I feel really uncomfortable.

419
00:49:37,580 --> 00:49:44,690
What what happened? They can contact the IAB and talk through things and the IAB will determine whether or not

420
00:49:44,990 --> 00:49:50,480
this is a legitimate issue that they will get a claim for and investigate and pursue.

421
00:49:50,900 --> 00:49:54,170
Or if it's not, they'll tell you why it's not. Okay.

422
00:49:55,800 --> 00:50:00,690
Did the professor act appropriately in giving this assignment to the class?

423
00:50:03,990 --> 00:50:07,710
I see some faces. Okay. You just drag your hands. Okay.

424
00:50:08,690 --> 00:50:19,800
What's up? Yeah. I think it's kind of weird to have that assignment go into the class without establishing those community guidelines beforehand.

425
00:50:20,280 --> 00:50:25,730
So I think that's something that Professor should. For sure.

426
00:50:26,180 --> 00:50:29,899
Not at this school, to my knowledge. But when I worked at Indiana University,

427
00:50:29,900 --> 00:50:36,950
there was a blast hot in the pulp in the School of Public Health and Family Dynamics and Bereavement, which is death.

428
00:50:37,670 --> 00:50:41,510
So with that, this kind of conversation be appropriate in that class.

429
00:50:45,000 --> 00:50:50,700
With this kind of conversation be appropriate in chemical hazards?

430
00:50:52,140 --> 00:50:58,260
Probably not. Right. So it again, this is one of the things where it's like it depends on the context of the past,

431
00:50:59,220 --> 00:51:04,080
the purpose that the professor is using this assignment or what rapport the

432
00:51:04,080 --> 00:51:08,130
professor has with the class and then again established community guidelines.

433
00:51:09,890 --> 00:51:12,530
All right. Oh, my gosh. Lucky you.

434
00:51:12,650 --> 00:51:20,060
We didn't even have time to talk about the readings and probably get a deal, so, you know, skim them at your leisure.

435
00:51:20,390 --> 00:51:23,820
But that's all I have for you today. Thank you.

436
00:51:24,500 --> 00:51:25,670
Care? Yeah.

