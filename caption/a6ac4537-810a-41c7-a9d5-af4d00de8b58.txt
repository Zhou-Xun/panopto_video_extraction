1
00:00:11,620 --> 00:00:16,609
Okay. Okay.

2
00:00:16,610 --> 00:00:29,160
Let's get started. So today we're going to just resume from this part.

3
00:00:29,400 --> 00:00:37,290
So we talked about how to generate our packages and this is pretty much all the instruction.

4
00:00:37,290 --> 00:00:46,019
I tried to do the demo last time, something I removed the some file I shouldn't have removed.

5
00:00:46,020 --> 00:00:51,950
So this time I hope that this works better. So so we don't need to look at other slides.

6
00:00:51,960 --> 00:00:55,770
We just need to need to look at to this part.

7
00:00:55,770 --> 00:01:00,660
So let me look at the run our studio again.

8
00:01:03,630 --> 00:01:08,360
I need to change my studio three. This.

9
00:01:15,880 --> 00:01:31,350
Okay. So. It's the working theory to this swoon.

10
00:01:33,470 --> 00:01:46,020
And so. Okay.

11
00:01:47,370 --> 00:01:50,880
So let's do it. Okay.

12
00:01:51,600 --> 00:01:54,960
So, uh, we.

13
00:01:55,230 --> 00:01:58,370
So first step, you need to install these packages.

14
00:01:58,380 --> 00:02:03,750
If you haven't, we have our function ready, so we're gonna do this again, I think.

15
00:02:03,990 --> 00:02:17,969
Package the skeleton. Basically, what you need to do is very simple m this package name, and I think you need to put the code code files.

16
00:02:17,970 --> 00:02:22,150
Right, so. Code files.

17
00:02:23,570 --> 00:02:27,700
Because in this case, it's it's convenient in these directories.

18
00:02:27,700 --> 00:02:33,810
So I'm going to use this. Then this is generated.

19
00:02:33,820 --> 00:02:39,250
So I need to go to go to this directory.

20
00:02:42,810 --> 00:02:51,440
And for the District three and these are the file I need to change the description file a little bit.

21
00:02:51,450 --> 00:02:54,210
I'm just going to check change change a little bit.

22
00:02:54,390 --> 00:03:16,710
Just, just a little bit here and probably not too much this time because I have already shown this and maybe where to say three and this.

23
00:03:17,880 --> 00:03:21,950
I think we need to put the UTF encoding here.

24
00:03:22,740 --> 00:03:26,800
Okay. So. And.

25
00:03:29,000 --> 00:03:34,220
I know he said that they were going to modify this. I'm not going to modify a ton of them.

26
00:03:34,370 --> 00:03:41,179
And I'm going to just actually, I do have a copy of it, which I didn't realize here.

27
00:03:41,180 --> 00:03:53,390
So why don't I just do it this simple way so that I can just replace one file with a prepared file, which which is probably fine here.

28
00:03:53,900 --> 00:04:00,560
Okay. Okay. So then we're going to do this.

29
00:04:00,710 --> 00:04:02,540
So we're going to.

30
00:04:02,900 --> 00:04:13,700
So this step use this step may not be necessary because this is just a saying the license, but we already have the license change it.

31
00:04:13,700 --> 00:04:18,110
So it's probably okay. You don't need to type your name here.

32
00:04:18,120 --> 00:04:23,419
So I think this the syntax has been changed so you don't need to type your name anymore.

33
00:04:23,420 --> 00:04:27,280
So if this part wasn't updated. Okay.

34
00:04:27,440 --> 00:04:31,610
And we're going to delete the namespace file.

35
00:04:31,910 --> 00:04:43,670
Okay. And we're going to delete this and we are going to delete the existing document this documentation just generates by default.

36
00:04:43,670 --> 00:04:47,690
So I'm going to delete this. Okay. Not not the package documentation.

37
00:04:48,530 --> 00:04:53,720
Okay. And then if you do this, I hope this time works.

38
00:04:54,050 --> 00:05:08,470
Okay. And if you uncheck then then it'll say that if there's anything wrong, it'll say it'll give you a warning or no to anything.

39
00:05:08,840 --> 00:05:15,319
If you have an error or warning you might be worried about. If you have a note, it's not that important.

40
00:05:15,320 --> 00:05:20,750
This says that all you need to have some some line that have complete sentences so that

41
00:05:20,750 --> 00:05:26,570
that's a that's that's not breaking change it breaking error so I'm going to ignore it.

42
00:05:27,620 --> 00:05:36,950
So what it says is that if yeah I think the this one, this one doesn't end with the dot or something I think.

43
00:05:37,340 --> 00:05:47,930
Okay. And if you build it so if check, check, this check is okay, if you build it, you should be able to see this file.

44
00:05:48,140 --> 00:05:55,879
Okay. My simple alarm and that that that file should be available here.

45
00:05:55,880 --> 00:06:01,940
So you can obviously now I'm going to my I'm going to go out of these packages.

46
00:06:01,940 --> 00:06:15,350
So go going going to the parent directory and you can say install the packages and save my simple alarm this this file.

47
00:06:15,500 --> 00:06:22,700
Okay. When you when you install a package from the file, you probably already know that you should say that the project problem called the no.

48
00:06:23,000 --> 00:06:27,770
Okay so that that's how you install a package from local file on.

49
00:06:27,770 --> 00:06:37,190
Otherwise it's going to it's going to try to find a package named like this from, from your C++ repository, which is not probably what you want.

50
00:06:37,790 --> 00:06:46,910
So then you know, then then you can probably now say X equals all 100, like 100,

51
00:06:47,990 --> 00:06:56,600
and you can do first simple linear regression in Y in X, and you will get to get the result here.

52
00:06:57,080 --> 00:06:58,980
But when you when you test the packages,

53
00:06:59,030 --> 00:07:09,139
I actually strongly recommend to do something outside of your art studio because your studio can remember that packages already.

54
00:07:09,140 --> 00:07:14,900
So it's it's kind of, you know, if you're installing some independent environment, it doesn't work.

55
00:07:14,900 --> 00:07:23,540
So it'll be better if you try this in completely different environment, like in the server or some, some other computer.

56
00:07:24,650 --> 00:07:29,960
But at least you can do it in the in other instances of our like this.

57
00:07:29,980 --> 00:07:36,410
So you don't have to use our studio. You can use command line and you can say, oh, I'm going to say install packages.

58
00:07:37,010 --> 00:07:44,209
And my simple alarm, you know, the part that T.J. and I report, it was very good.

59
00:07:44,210 --> 00:07:49,280
No. Then they should still work and they should be installed.

60
00:07:49,280 --> 00:07:53,840
So you can have have a my simple alarm.

61
00:07:54,200 --> 00:08:00,979
Alarm, and this is going to give you oh, oh, I need to load this.

62
00:08:00,980 --> 00:08:08,750
Okay. By simple alarm. Okay. And if you if you ask for the help, then it's it says this, okay?

63
00:08:09,380 --> 00:08:20,930
And if you give a help first, a simple linear regression, it does give a very simple, you know, documentation.

64
00:08:20,930 --> 00:08:28,220
So it looks like it's a complete package. And you can you can also use it it just to make sure that this works.

65
00:08:30,020 --> 00:08:34,129
And, uh. Yeah. Simple linear regression.

66
00:08:34,130 --> 00:08:38,020
And Y and x should work. Okay. So. Uh.

67
00:08:38,070 --> 00:08:41,240
Seems like working. Okay. So this part was done. Okay.

68
00:08:41,780 --> 00:08:44,960
So this. So this time I didn't make any mistake.

69
00:08:45,140 --> 00:08:55,770
So good. But all the steps are here. And, you know, if you miss some stuff, it can be tricky to recover.

70
00:08:55,790 --> 00:09:01,400
Sometimes it's better to just, uh, start from scratch.

71
00:09:01,480 --> 00:09:07,580
So that's why I learned it. But if you know the details of what what to fix, why this doesn't.

72
00:09:08,060 --> 00:09:11,360
This step doesn't work and so on, that if you can figure it out, that'll be great.

73
00:09:11,510 --> 00:09:15,990
Okay. So I, you know, let me.

74
00:09:16,790 --> 00:09:26,090
So this one, I, I just wanted to teach you how to make a recipe package, which is not very different.

75
00:09:27,020 --> 00:09:35,110
Uh, but I know that art making a recipe package, you could, could have more places that could go wrong.

76
00:09:35,120 --> 00:09:42,050
So I want to, uh, so I want to make sure that I don't miss anything this time.

77
00:09:42,440 --> 00:09:49,880
Okay. So, uh, if I make a mistake by any chance, I'm not gonna redo it, because I think we need to move on.

78
00:09:50,000 --> 00:09:55,030
But, uh, so what are the C++ code?

79
00:09:55,040 --> 00:10:04,790
So you need to use the recipe package. And so, and you need to add, add this headline in your, in your R in your C++ file.

80
00:10:04,790 --> 00:10:17,480
You need to, you usually you probably want to you include this line and for every function you want to export to r you, you need to include this line.

81
00:10:18,170 --> 00:10:28,490
But other than that, if you wanted to document this C++ code in the RCP style, you can do that by doing this.

82
00:10:28,610 --> 00:10:41,420
Okay. So, uh, so instead of the short, sharp the single code and you know that, uh, use a select single code, otherwise actually pretty much similar.

83
00:10:42,140 --> 00:10:54,020
So that's, that's a good thing. I'm not this is a translation of the those first, uh, linearly, uh, uh, linear regression function in C++.

84
00:10:54,020 --> 00:11:00,200
So it probably is worth taking a look and see what was changed to what was not.

85
00:11:00,890 --> 00:11:11,030
And some, some function like a mean is available because this is a RCP dot object so that they provide some convenience function.

86
00:11:11,390 --> 00:11:17,120
Usually R doesn't provide a function like a mean usually, but this is ah, this is a numeric vector.

87
00:11:17,810 --> 00:11:24,620
So that's worth mentioning. But other, other things are pretty much in a some function is the same actually.

88
00:11:24,620 --> 00:11:25,300
This is a,

89
00:11:25,430 --> 00:11:40,309
this is a convenience function that RCP P provides as in but from here you're just doing the scalar calculation and this is a t statistic or you know,

90
00:11:40,310 --> 00:11:49,340
returning as a numeric vector and so on. So you can take a look at this and this is maybe a good exercise to not to look into this.

91
00:11:49,340 --> 00:11:56,360
And I want to try to implement all the other function in RTP that there is a, there is a good exercise you can try.

92
00:11:56,430 --> 00:12:00,169
Okay. But this is a this is a step by step instruction.

93
00:12:00,170 --> 00:12:07,459
I have some some examples here, but I don't have all the screens at this time.

94
00:12:07,460 --> 00:12:10,690
So let's try to try to do this way.

95
00:12:10,700 --> 00:12:14,100
So I hope that I have RC recipe here. Okay.

96
00:12:14,930 --> 00:12:18,150
Okay. So participate. Believe so.

97
00:12:18,170 --> 00:12:27,860
Okay. So I do have it. Okay, so and then this time I think of what, what, what, what changing is that you need to, when you,

98
00:12:27,860 --> 00:12:34,110
when you install the package, when you make a package instead of Eugene package the skeleton.

99
00:12:34,110 --> 00:12:37,790
Now use the RCP, ACP, the package, the skeleton.

100
00:12:37,790 --> 00:12:41,300
Because if you have a C++ file,

101
00:12:42,110 --> 00:12:52,129
then there is an additional thing that the package manager taking should take care of and quote files equals the files you include the r file.

102
00:12:52,130 --> 00:12:59,750
So simple m that is what you want to include. And ACP files is a C++ files.

103
00:12:59,750 --> 00:13:09,070
In this case, CPP first 11 people in the RCP skeleton gives the example quarter by default.

104
00:13:09,080 --> 00:13:15,740
This is very annoying actually, so I'm going to just put false, especially when you already have a C++ file.

105
00:13:16,610 --> 00:13:23,929
So this this, this is what you do. And after that, you're pretty much doing the same thing here.

106
00:13:23,930 --> 00:13:27,650
So now I have this, this thing. So let's go to set w theme.

107
00:13:29,020 --> 00:13:32,050
My first, uh, simple alarm.

108
00:13:34,060 --> 00:13:39,250
And. But you need to modify this into your way.

109
00:13:39,940 --> 00:13:45,520
I'm going to just change my name this time to.

110
00:13:50,840 --> 00:14:01,860
And when you have a description it are simply oxygen are oxygen within comply with with complaint.

111
00:14:03,110 --> 00:14:06,620
If if you don't have this including you call UTF eight.

112
00:14:06,770 --> 00:14:16,760
So I'm adding it and you go to man and package manager and you just make, make some some changes here too.

113
00:14:16,770 --> 00:14:21,349
So. Well. So note that this format is slightly different.

114
00:14:21,350 --> 00:14:25,460
Sometimes this template, you need to put your name again.

115
00:14:25,490 --> 00:14:33,320
So just to make sure that you put the information you need, it's necessary here.

116
00:14:34,040 --> 00:14:43,489
Obviously, I'm not putting everything here, so I'm going to just, you know, have very minimal changes now.

117
00:14:43,490 --> 00:14:49,940
But you should provide a full documentation of it. And after that, I think it's pretty much the same.

118
00:14:50,360 --> 00:14:59,030
Uh, until, uh, you have, uh, you need it, so you need to run this.

119
00:14:59,030 --> 00:15:02,350
So there is a, there is a something called compile attribute. Okay.

120
00:15:03,380 --> 00:15:05,810
So this is a recipe specific thing.

121
00:15:05,810 --> 00:15:21,889
So if you have a C++ code, you need to do this to, uh, if you do this it, the, ah ah, a studio will recognize the C++ function as a function.

122
00:15:21,890 --> 00:15:26,090
Otherwise it doesn't know that that functioning with the code just so some.

123
00:15:26,210 --> 00:15:33,230
So this is of exporting the function based on this RTP export line.

124
00:15:33,530 --> 00:15:41,060
So it now recognize this is our ship function. It does it it will try to build that.

125
00:15:41,420 --> 00:15:46,160
But you have a source code but it didn't compile, so you need to.

126
00:15:46,190 --> 00:15:52,600
So these two steps are step specific. So you need to use this load underscore all.

127
00:15:52,610 --> 00:16:00,530
So once you have the make the C++ press function, recognize whenever you test your C++ code,

128
00:16:00,530 --> 00:16:05,989
if you do load all, then it's going to re compile those the files you have.

129
00:16:05,990 --> 00:16:11,900
So it's going to if there's a compilation error, it'll, it'll say there is an error, otherwise it's going to compile.

130
00:16:11,990 --> 00:16:17,180
Okay. And you need to delete these two files.

131
00:16:17,360 --> 00:16:24,500
Okay. Because our our ship oxygen will will try to regenerate.

132
00:16:25,070 --> 00:16:30,250
Okay. And this time, I think I hope that this works.

133
00:16:30,260 --> 00:16:33,380
Okay. Document. Okay. And then pulls.

134
00:16:36,290 --> 00:16:46,670
Okay. So there's two notes.

135
00:16:48,020 --> 00:16:51,259
Uh, there's some global variable. I don't know.

136
00:16:51,260 --> 00:16:54,350
I never saw this. I don't know what this is.

137
00:16:54,350 --> 00:16:58,249
I hope that this is not a problem. Don't notice. It's usually not a problem.

138
00:16:58,250 --> 00:17:02,180
So I'm going to ignore it. Uh, I. I'll try to google it.

139
00:17:02,180 --> 00:17:08,300
What? Which what? Why that that happens. But you have this part of g file here, okay?

140
00:17:09,320 --> 00:17:14,960
So the same, same thing. Now I'm going to, to install the packages here in four packages.

141
00:17:16,310 --> 00:17:20,270
My first simple one to make sure the okay.

142
00:17:20,270 --> 00:17:25,450
In a report. No. Then you're going to install it.

143
00:17:25,640 --> 00:17:29,420
You see that it's actually compiling the C++ code here.

144
00:17:29,570 --> 00:17:34,430
Okay. So in this package, it doesn't comply. It is kind of cool automatically.

145
00:17:34,880 --> 00:17:48,410
And you can oh, now I have my first oh, I actually make the, uh, make like made a typo in the library but should be okay.

146
00:17:49,070 --> 00:17:52,790
So it's a complaining because I have a same function here.

147
00:17:52,850 --> 00:17:57,080
Okay. So I, but I have another function.

148
00:17:57,320 --> 00:18:01,490
P p what is the name of the function l am.

149
00:18:03,840 --> 00:18:07,500
Sweet pea soup first to see people first.

150
00:18:09,430 --> 00:18:15,510
Oh, wait, it's not. Okay, uh, this is interesting.

151
00:18:15,990 --> 00:18:19,170
Okay. Is it because I think I.

152
00:18:24,350 --> 00:18:29,430
Okay. So this is unexpected. Uh.

153
00:18:32,490 --> 00:18:36,440
I don't know why that happened. Because I did participate.

154
00:18:37,110 --> 00:18:40,530
Okay. Okay. Okay.

155
00:18:40,680 --> 00:18:43,740
So I was case sensitive.

156
00:18:43,770 --> 00:18:52,910
Okay. So this is this is the document. And you can say now I'm going to first tell them why an X.

157
00:18:52,920 --> 00:18:57,090
I already have that. Doo doo doo doo.

158
00:18:57,150 --> 00:19:03,140
What was it this time? Hey.

159
00:19:03,850 --> 00:19:08,570
Come on. Okay.

160
00:19:10,830 --> 00:19:18,960
Oh. Something's wrong. So my paid for.

161
00:19:25,800 --> 00:19:31,470
And it's not export. So this this note, it's saying something?

162
00:19:31,470 --> 00:19:37,620
I think. So this was not exported correctly, I think, for whatever reason.

163
00:19:37,630 --> 00:19:43,470
So, uh, so that, that is good to know.

164
00:19:43,470 --> 00:19:50,280
I, I actually didn't, didn't double check this, I guess I just tried last time when I tested,

165
00:19:50,700 --> 00:19:56,220
I tested only within our studio and I didn't, didn't realize this wasn't working as expected.

166
00:19:57,420 --> 00:20:03,059
But there must be some step that's that's causing this note problem.

167
00:20:03,060 --> 00:20:07,680
And this is actually because this is a weird problem where I never saw this.

168
00:20:07,680 --> 00:20:11,249
But this is the this global variable doesn't exist.

169
00:20:11,250 --> 00:20:16,170
So there is a some problem that's happening inside.

170
00:20:16,190 --> 00:20:26,080
I think so. Uh, let me just try to make sure that if sometimes this kind of problem can be, it's,

171
00:20:26,100 --> 00:20:36,960
it's this kind of problem happens if there's a some missing line in the, in the, in the documentation, sometimes, sometimes that could be the problem.

172
00:20:38,760 --> 00:20:45,780
So, for example, if I, I, I don't think I should put the export here, but I'm going to try that just in case.

173
00:20:46,000 --> 00:20:50,670
I don't know what the other problem might be.

174
00:20:50,670 --> 00:20:55,799
It might be. So I'm going to just try this once and see what happens.

175
00:20:55,800 --> 00:21:04,860
If it doesn't work, I'm going to move on. Okay. So this is so this kind of tiny problem.

176
00:21:04,860 --> 00:21:09,329
If you have that, it takes sometimes forever to change it.

177
00:21:09,330 --> 00:21:13,770
So that's that's the complicating part in making the.

178
00:21:17,570 --> 00:21:21,130
Making the package. So I see.

179
00:21:21,140 --> 00:21:28,160
So the document then it generated namespace so getting everything right.

180
00:21:28,160 --> 00:21:42,350
So, so the most likely the problem is that these, these, these functions were not recognized for some reason and we just need to check why.

181
00:21:51,660 --> 00:21:54,930
Now we have one. One.

182
00:21:55,740 --> 00:21:59,250
Okay. This is a better. Better. This note is a probably.

183
00:21:59,970 --> 00:22:08,010
Okay. I think so. I think the the problem the cause of the problem is that I should put the export here to in the ah oxygen.

184
00:22:08,010 --> 00:22:15,330
Otherwise ah oxygen doesn't, doesn't respect this, which I didn't think that was the case, but maybe, maybe to change it.

185
00:22:16,350 --> 00:22:21,090
So hopefully this time it works. So let's see. Oh, I didn't build it.

186
00:22:21,450 --> 00:22:29,070
Never mind. Okay, so I'm going to build it and install again.

187
00:22:30,090 --> 00:22:42,300
Well, listen to this. I'm going to install it from scratch so that the previous installation doesn't affect this result.

188
00:22:42,550 --> 00:22:46,410
Okay. So this time, if I do the.

189
00:22:48,730 --> 00:22:51,880
I made a typo in the package name and it's still here.

190
00:22:51,940 --> 00:22:55,770
Okay. Sorry about that. And zip first.

191
00:22:55,990 --> 00:22:59,200
Ellen. Now, this. This function works. Okay.

192
00:22:59,230 --> 00:23:02,770
So, uh, that's a that's a useful.

193
00:23:02,770 --> 00:23:12,190
I didn't mean I didn't mean to generate this area, but this is a good lesson to how how you can deal with those errors in a way.

194
00:23:12,190 --> 00:23:18,319
And X and. Uh, no, it wasn't.

195
00:23:18,320 --> 00:23:22,520
Wasn't wasn't wasn't clearly fixed.

196
00:23:23,210 --> 00:23:27,470
So this means that this function is does not exist.

197
00:23:27,470 --> 00:23:34,570
Can it cannot find. So it does not work as expected to.

198
00:23:35,210 --> 00:23:38,330
Okay. And, uh.

199
00:23:41,090 --> 00:23:44,150
Import field not imported from OCP.

200
00:23:45,290 --> 00:23:52,399
So but I don't think this is the region. So if you if you see this kind of thing,

201
00:23:52,400 --> 00:24:03,830
I also have to Google it and try to find and so usually there is a sunsetting you're missing or that that is very quirky about it.

202
00:24:03,830 --> 00:24:06,650
There might be some quirky requirement that you need to follow.

203
00:24:06,770 --> 00:24:13,880
So I do not know how to fix this right now, but you might encounter a similar kind of problem.

204
00:24:13,890 --> 00:24:17,510
So when you have that problem, I'm happy to give.

205
00:24:17,510 --> 00:24:20,750
Otherwise I probably don't know how to fix it every, every time.

206
00:24:21,830 --> 00:24:24,590
But let's let's see how much I can help it.

207
00:24:24,590 --> 00:24:33,860
So I wouldn't I would like to redo this step and see what happens if maybe this problem may not appearing in your computer because of my computer

208
00:24:33,860 --> 00:24:44,479
is is the M1 MacBook and it's more so if you don't have an intel machine some it gives a more it gives you a harder time to compile something.

209
00:24:44,480 --> 00:24:47,720
So I wonder if that was a case or if there's something else.

210
00:24:48,650 --> 00:24:55,160
But let's set it aside and then move on because we need the other contents to cover.

211
00:24:56,000 --> 00:25:02,930
So then if you have that, I'm going to show by slide because this this didn't work for me.

212
00:25:03,830 --> 00:25:08,450
But you can compare how each of the method works.

213
00:25:08,630 --> 00:25:23,330
And if you believe this, the result is, is that a line takes 600 million times 756 milliseconds with 100 with the 1 million observation.

214
00:25:24,050 --> 00:25:31,520
And the first simple regression takes about 100 milliseconds.

215
00:25:31,520 --> 00:25:40,940
But the CPP version is much faster, which is quite encouraging that you probably want to use a C++ version if possible.

216
00:25:40,940 --> 00:25:47,590
But our version is already giving us several times of speedup compared to the regulator.

217
00:25:49,520 --> 00:25:54,319
Okay, so that's what I can cover today.

218
00:25:54,320 --> 00:26:02,840
So sorry that it didn't go all the way to the successful way, but that's kind of what I expected anyway,

219
00:26:02,840 --> 00:26:09,560
because when I try to do it myself, you know, when I make a package, always there, there are some hiccups happening.

220
00:26:09,890 --> 00:26:14,180
And this is not the only time I've seen this. Okay.

221
00:26:15,020 --> 00:26:22,280
Any any question or if if anyone know how to solve this bug and that we can we do this, then that would be terribly awesome.

222
00:26:23,180 --> 00:26:32,389
Okay. So I think there is a some so either I need to change this this description or namespace or something else.

223
00:26:32,390 --> 00:26:37,100
I'm not that description. I guess so. Most likely.

224
00:26:38,060 --> 00:26:45,130
I mean source code. I don't see I don't see this is a problem.

225
00:26:45,140 --> 00:26:51,500
So I really don't don't exactly know what these these are.

226
00:26:51,500 --> 00:26:55,040
But if you Google it a little something I think, yeah.

227
00:26:57,230 --> 00:27:11,690
Okay. So if you don't have other questions, then we're going to move on to the letter 12 and Nature 13, which is already available in the campus.

228
00:27:12,020 --> 00:27:16,249
Okay. And move on to the lecture 16, which is dynamic problem.

229
00:27:16,250 --> 00:27:19,790
So like the 12 and 13 is relatively short.

230
00:27:19,790 --> 00:27:25,339
So I think I might be able to cover all the lecture 12 and possibly lecture 13.

231
00:27:25,340 --> 00:27:33,920
But let's see. Okay. So this is the this is a monte Carlo inference, right?

232
00:27:34,670 --> 00:27:40,190
So we in the chapter so that now let's look back to the most common problem.

233
00:27:40,190 --> 00:27:43,280
So we talked about the Monte Carlo integration.

234
00:27:43,460 --> 00:27:50,780
Okay. So my integration is not the only Monte Carlo method you can you need to deal with.

235
00:27:50,780 --> 00:27:57,170
So a monte Carlo method encompasses a lot of computational tools in the model statistics.

236
00:27:58,580 --> 00:28:05,840
So, so you can evaluate the statistical method like a square minsky that is one

237
00:28:05,840 --> 00:28:12,530
example and calculating the confidence intervals or coverage probability for,

238
00:28:14,900 --> 00:28:20,990
you know, for a complicated distribution and a type one error rate or the power of the task.

239
00:28:20,990 --> 00:28:30,440
Those, those, those things are typically done with the Monte Carlo method, often times when there is a no closed form analytical solution available.

240
00:28:31,220 --> 00:28:40,040
And another good example is a bootstrap where you actually use a bootstrap to reduce the bias in estimates and consider confidence intervals and.

241
00:28:40,490 --> 00:28:47,930
Because of the test, so on. So bootstrap is like lecture 13 and we are going to in lecture 12, we are going to cover this part.

242
00:28:48,230 --> 00:28:55,010
Okay. So let's talk about the problem of estimating the risk that are first.

243
00:28:55,340 --> 00:29:07,790
Okay, so what is a creditor? So means credit error is the expected value between your estimated value, your estimate are of a certain parameter theta.

244
00:29:08,240 --> 00:29:12,440
Okay. And, and take the difference of the true parameter.

245
00:29:13,010 --> 00:29:14,360
And it's clearly okay.

246
00:29:14,630 --> 00:29:28,530
And I think the expectation of so that's that's the mask that I'm so means credit has a very interpretable meaning that this is actually addition a

247
00:29:28,550 --> 00:29:33,560
combination of a bias and variance as a phase of the estimate or so as long

248
00:29:33,560 --> 00:29:39,230
as you actually know the what the to the parameter is in the setting means.

249
00:29:39,230 --> 00:29:47,240
Okay, that is probably the least controversial way to estimate the accuracy of your method.

250
00:29:47,450 --> 00:29:55,240
Okay. And it captures both bias and, you know, precision of your estimate.

251
00:29:55,790 --> 00:29:56,000
Okay.

252
00:29:57,080 --> 00:30:12,979
So, okay, multi-color method for computing mass e is is basically calculating because to calculate the expectation you need to analytical integration,

253
00:30:12,980 --> 00:30:15,020
but you're not going to be able to do that.

254
00:30:16,250 --> 00:30:27,050
So Monte Carlo method is that of changing this expectation to some other Monte Carlo method and what what is the what is the way to do it?

255
00:30:28,130 --> 00:30:35,270
How do you calculate the expectation in Monte Carlo way? Well, that's what we learned is Chapter 11.

256
00:30:35,270 --> 00:30:43,790
Just take a bunch of generate a bunch of a monte Carlo sample based on this expression and take the mean of it.

257
00:30:43,880 --> 00:30:52,400
Right. So that's that's that's a most straightforward way to calculate the mean.

258
00:30:52,400 --> 00:31:02,840
So you can try the same thing here. So you can say, I'm going to throw the a lot of samples from independent samples from the description of,

259
00:31:02,840 --> 00:31:09,200
of generating function of X and the calculator estimated for each of the instances.

260
00:31:09,530 --> 00:31:10,370
And after that,

261
00:31:10,790 --> 00:31:19,399
I'm going to empirically calculate the mean of the squared differences and they should be converting to the actual expectation of squared.

262
00:31:19,400 --> 00:31:31,490
I mean differences. So I'm going to say this is my estimate of MSE because you cannot get a MSI with a closed form often in the

263
00:31:31,490 --> 00:31:41,240
case that your distribution is not very nice and a nice form that the easily that is easy to calculate.

264
00:31:41,780 --> 00:31:46,460
Okay. Yeah. I wonder what else this.

265
00:31:48,060 --> 00:31:52,260
That's Jamie Lynn and the statistic that came from the nice Jane.

266
00:31:53,720 --> 00:31:57,560
Uh, sorry. Oh, this is a theta head.

267
00:31:57,570 --> 00:32:02,070
I'm sorry. This is theta hat. Okay, so this is the theta hat.

268
00:32:02,280 --> 00:32:05,309
I think thank you for pointing out this.

269
00:32:05,310 --> 00:32:13,920
The theta had had, which is your estimate. Yeah. So this is that I have nice training and of course that makes.

270
00:32:16,900 --> 00:32:26,080
Yes. So you you have a date. So you have a multiple and different observations and different random samples of X.

271
00:32:26,320 --> 00:32:36,160
Okay. So each of the random sample, these are data that is just a simple function that converts the your data into estimate a parameter.

272
00:32:36,310 --> 00:32:44,920
Okay. So you apply the function and that they should be ideally, if your estimate is perfect, it should be always the same as theta.

273
00:32:44,920 --> 00:32:50,380
But that's not the case. It would be close to the data, but not exactly so.

274
00:32:51,210 --> 00:32:58,360
So that's. That's how you do it. So if you are if you haven't taken six or two, this might be a little bit.

275
00:33:01,420 --> 00:33:03,310
You know, hard to understand.

276
00:33:05,140 --> 00:33:16,360
So in the case of what I usually do, when you see this kind of this kind of general statement, I always say, oh, you know, what is the easiest way?

277
00:33:16,400 --> 00:33:20,080
You just the problem of statistical inference. Well, Quintus problem.

278
00:33:20,390 --> 00:33:27,640
Okay, so you have. So I'm going to I usually just think of like, oh, I have a ten coins.

279
00:33:27,640 --> 00:33:31,540
I flip, flip. And these X's are basically 0 to 10 values.

280
00:33:32,560 --> 00:33:36,250
And theta had is the what is the probability of a head.

281
00:33:36,520 --> 00:33:41,919
Okay. So that should be, you know, that that is your estimate or so your estimate.

282
00:33:41,920 --> 00:33:47,360
Or could it be just that if you're using that the name makes you more likely estimate or

283
00:33:47,380 --> 00:33:52,720
that would be whatever number divide by ten is your estimate if you're using Bayesian

284
00:33:52,720 --> 00:33:58,990
estimate or you can use as a pseudo kind of like I don't know just a the your observation

285
00:33:58,990 --> 00:34:06,360
plus 0.5 divided by 11 or or well which would be 2.25 divided by 10.5 or you know,

286
00:34:06,700 --> 00:34:11,889
depending on the what your priority is. So yeah.

287
00:34:11,890 --> 00:34:15,340
Then, then you can have that estimate or, and.

288
00:34:17,170 --> 00:34:23,530
Yeah. And and that if you if you exemplify in that way, it's probably easier to see what this means.

289
00:34:23,650 --> 00:34:30,820
Okay. So obviously that in this case, that data is a parameter of the true probability of ahead.

290
00:34:31,660 --> 00:34:35,380
That could be 0.5 and then some some some cardinal. It may not be.

291
00:34:37,150 --> 00:34:41,080
Okay. So. Okay.

292
00:34:41,170 --> 00:34:45,760
So now the problem the the question question here.

293
00:34:46,060 --> 00:34:51,120
Another example is estimating the MSI of the trimmed mean.

294
00:34:51,700 --> 00:35:04,120
So what does that mean. So when you have, uh, when you have with the beta theta, uh, median is a pretty robust estimate of what the mean may not be.

295
00:35:04,840 --> 00:35:14,200
So if you have, uh, you know, nice nicely distributed value, uh, mostly.

296
00:35:14,200 --> 00:35:22,780
But if you have some outliers in your distribution, mean can be affected quite, quite a lot.

297
00:35:22,790 --> 00:35:26,230
So mean if you calculate the mean.

298
00:35:26,710 --> 00:35:30,030
If there is outliers, your mean could be shifted a lot.

299
00:35:30,040 --> 00:35:32,620
So that's the disadvantage of mean.

300
00:35:33,220 --> 00:35:43,960
So sometimes when you need a stable estimate or people usually use median instead of mean, even though that that that has their own problem sometimes.

301
00:35:44,110 --> 00:35:49,820
So some in some circumstances you may want to calculate the mean.

302
00:35:50,370 --> 00:35:56,740
I mean after removing certain number of outliers to make your estimate or state stay stable.

303
00:35:57,220 --> 00:36:09,190
So one can argue that, oh, if I have any different observations, I'm going to take the key elements from the upper, you know, from the tail.

304
00:36:09,370 --> 00:36:17,050
I'm going to remove the key largest in case smallest value and take the rest of them to calculate the mean.

305
00:36:17,530 --> 00:36:23,200
This is a more stable. If the and if the distribution is below, they shouldn't create any bias.

306
00:36:23,920 --> 00:36:31,210
So that's one way to calculate the mean in a more stable way.

307
00:36:31,450 --> 00:36:36,309
Okay. So and if your purpose is not to calculate the mean itself,

308
00:36:36,310 --> 00:36:42,820
if you calculate if you are trying to estimate the actual parameter behind the distribution, this might be a useful way to do it.

309
00:36:44,170 --> 00:36:55,180
So in this case, like, let's say your data is distributed in a, in a normal, perfectly normal distribution.

310
00:36:56,290 --> 00:37:02,770
And in that case, maybe removing the outliers is probably not necessary, right?

311
00:37:03,430 --> 00:37:10,840
So because, you know, why would you the this one the if are if your purpose is to estimate the zero.

312
00:37:11,020 --> 00:37:19,809
Well just to take the mean should be fine. I don't know if you can prove that if you remove the outliers,

313
00:37:19,810 --> 00:37:25,960
it'll be closer to the actual intended mean that that will be interesting to inc to prove.

314
00:37:27,040 --> 00:37:32,800
I don't think it's necessarily true but it be good to know what, what, what the actual answer is.

315
00:37:34,480 --> 00:37:42,870
So, uh, but if you have some cosmic features like, oh, you have a problem with the p that,

316
00:37:43,080 --> 00:37:48,130
that, that the data is coming from the standard normal distribution.

317
00:37:48,850 --> 00:37:59,500
But you have a one minus p probability that the data is coming from a normal distribution with a really large variance.

318
00:37:59,770 --> 00:38:08,410
Okay. So in that case, you're going to basically have some outliers in that that are liars and can affect your mean quite a lot.

319
00:38:08,650 --> 00:38:20,020
So in this case, you know, if you know that, oh, I have this particular P, I know then you can decide the what, what kind of K I should be using.

320
00:38:20,290 --> 00:38:29,740
Okay. And let's say P is a I'm, I'm sampling million samples and my P is, you know, point 1%.

321
00:38:30,070 --> 00:38:37,510
Okay. One out of thousand then how many do you need to how many those do you want to remove?

322
00:38:41,160 --> 00:38:46,110
Well, because I want to be 100 or I want to remove a thousand.

323
00:38:46,860 --> 00:38:50,399
Okay. Or I want to remove 10,000 or 100.

324
00:38:50,400 --> 00:38:58,410
That right. If you if you remove 100, you probably these are probably two too few because you still have outliers.

325
00:38:58,980 --> 00:39:01,980
If you 2000, maybe that's the right amount.

326
00:39:01,980 --> 00:39:10,030
Amount. But you have a chance that you still have outliers left and that might affect your estimate.

327
00:39:10,030 --> 00:39:19,410
Or if but if you exclude the more and more the problem is that then it's you're going to have less and less number of sample

328
00:39:19,590 --> 00:39:29,819
to take the mean from that at some point your estimation would be less separate than not including all the our like.

329
00:39:29,820 --> 00:39:37,889
So this is interesting problem and you can figure out optimal number of okay empirically by try different kind of experiment experiments.

330
00:39:37,890 --> 00:39:45,150
So this is a this is the second example we're going to try any questions about the settings.

331
00:39:47,710 --> 00:39:51,670
Okay. So let's talk about the square at a first.

332
00:39:52,000 --> 00:40:00,220
Okay. So. So it means credit is you can do this way.

333
00:40:00,380 --> 00:40:08,890
Okay. So so this function. So now I'm going to I'm going to use this, you know, I have been using this are of oxygen.

334
00:40:09,340 --> 00:40:16,749
Two types of function description, the function description.

335
00:40:16,750 --> 00:40:25,510
So the parameters are number of replication, simple sizes and you need to provide the parameter MSI need to know the true parameter.

336
00:40:26,140 --> 00:40:32,860
Otherwise you can then you can look at the various and the simulator is a function to simulate the data and estimate.

337
00:40:33,100 --> 00:40:37,060
So basically this is a generating function. This is PI of data.

338
00:40:37,690 --> 00:40:40,990
Okay. And estimate R is a theta of X.

339
00:40:41,110 --> 00:40:44,799
So I have a data and I want to estimate of my parameter.

340
00:40:44,800 --> 00:40:50,770
Okay. And you can add more parameters here if you put that data like this.

341
00:40:51,310 --> 00:40:57,770
So what what this does is pretty simple. You, you have MSI here, okay?

342
00:40:57,880 --> 00:41:01,240
So and the number of replicate,

343
00:41:01,240 --> 00:41:08,860
replicate you create and you simulate the data and estimate the parameter and assign

344
00:41:09,790 --> 00:41:16,659
security mean differences to calculate the MSI and the SKU scale mean differences here.

345
00:41:16,660 --> 00:41:24,940
So usually, you know, the the reason we are calculating mean is that sometimes your the there could be multiple parameters

346
00:41:24,940 --> 00:41:30,370
and taking the mean but usually the if this is scalar if you don't even need to take the mean here.

347
00:41:30,370 --> 00:41:34,030
So it's just calculating the squared differences.

348
00:41:34,210 --> 00:41:48,850
Okay. So this is a very simple way to calculate the MSI and very, you know, basically the same procedure to describe here.

349
00:41:48,850 --> 00:41:53,410
You generate a lot of random samples and calculate the MSI and then take the average of it.

350
00:41:54,460 --> 00:42:09,480
Okay. So, and okay, uh, now this is the, this is the function three mean, okay.

351
00:42:09,490 --> 00:42:15,280
Three mean is a super simple function where I sort of value, okay?

352
00:42:15,490 --> 00:42:19,930
I mean, maybe that this is not the most efficient way to implement it, but it's convenient.

353
00:42:20,890 --> 00:42:31,690
So sort of value and I'm taking the part of X that excludes the first K in the last K and I take the mean of it.

354
00:42:32,020 --> 00:42:48,320
Okay, so that's trim. That means function do. So now let's try to calculate the MSI of between 2 to 2 functions for first to one.

355
00:42:48,340 --> 00:42:58,260
What I'm going to try is that I'm using the are known functions and I know what I'm sampling the data from no standard normal and I'm going

356
00:42:58,260 --> 00:43:13,590
to do 100,000 replicates and in the first estimate I'm going to use a I'm going to use a zero trim and a second one I'm going to name five.

357
00:43:14,550 --> 00:43:19,680
And which one do you think it'll do better? I actually am curious to know what's going to happen.

358
00:43:27,100 --> 00:43:30,880
So it is. Yeah. So.

359
00:43:31,240 --> 00:43:35,049
Well, it's 200,000 times in this case.

360
00:43:35,050 --> 00:43:38,860
Each of the time there's only 20. Said the side is 20.

361
00:43:40,180 --> 00:43:44,770
So the first one didn't remove any sample.

362
00:43:44,860 --> 00:43:55,600
Second one removed the five samples. So if you remove the five sample in both sides, this is only moving half of the sample.

363
00:43:56,530 --> 00:44:06,850
Okay. So this is. So that actually could include could reduce your the precision of your estimate.

364
00:44:07,510 --> 00:44:13,450
So in this case, what happens is that the first one, which one did which did you not remove?

365
00:44:13,990 --> 00:44:22,790
Your removed outliers did either have a smaller MSE than the one that has light that removed the outlier.

366
00:44:22,810 --> 00:44:34,270
So in this case trim mean didn't actually helped encouraging you know, your your accuracy or your precision for accuracy of your estimators.

367
00:44:34,660 --> 00:44:40,960
So that that is okay so well that that's expected because you are just sampling from the normal distribution.

368
00:44:42,790 --> 00:44:49,300
Now let's think about, you know, doing the mixture of normal.

369
00:44:49,310 --> 00:44:53,280
So in this case, we're generating the mixture of a normal distribution.

370
00:44:53,830 --> 00:44:57,560
We've done this very similar done this similar similar thing.

371
00:44:57,580 --> 00:44:58,300
In this case,

372
00:44:58,660 --> 00:45:09,340
where we're using this gender in the in the in this is of it and use a different item parameter for for the one that are in the indices or not.

373
00:45:10,030 --> 00:45:18,850
I think this is a pretty straightforward to understand. And now instead of using the our norm, we're using the.

374
00:45:19,090 --> 00:45:22,510
And makes norm here. Okay. And try to see what happens.

375
00:45:22,660 --> 00:45:30,129
Okay. So in this case, what what I'm going to do is I'm going to do a similar thing this time.

376
00:45:30,130 --> 00:45:33,550
I'm I'm going to use only 10,000. I'll repeat.

377
00:45:33,850 --> 00:45:40,120
Okay. And so this is a one to the ten.

378
00:45:40,330 --> 00:45:44,170
Okay. So I'm going to try ten different cases.

379
00:45:44,710 --> 00:45:52,690
And what I'm going to do is I'm going to use the tree trimming estimate here by using K minus one as K.

380
00:45:52,690 --> 00:46:02,559
So we have the. So if K was one, I, I'm putting zero here, which is not naming anything.

381
00:46:02,560 --> 00:46:11,090
So it should be same as a regular mean. If K k is a 2 to 10, the value of the k value that was in is the 1 to 9.

382
00:46:11,740 --> 00:46:16,450
So that's what is going to happen. And let's see what happens here.

383
00:46:23,180 --> 00:46:38,840
Okay. So, uh, so what you have here is that if you didn't trim anything because you have, you have a punctures that always can come into,

384
00:46:39,650 --> 00:46:50,420
you have a very high chance of, uh, you know, being affected by outliers that you have a five, five or the MSI of five, right?

385
00:46:51,260 --> 00:46:55,190
So and these, you know, these are mixed.

386
00:46:55,190 --> 00:47:01,249
Norm has a 90% probability that is simple, the from component one versus component two.

387
00:47:01,250 --> 00:47:08,300
And we are sampling 20. So the expected number of our sample from all those is two, right?

388
00:47:08,900 --> 00:47:16,040
So if you see K for one, it reduces if you go to the MSE reduces, that's all good.

389
00:47:16,760 --> 00:47:23,230
But if you use K equal three, it further reduces.

390
00:47:23,310 --> 00:47:30,110
Why is that? Because sometimes it's a it's all probabilistic.

391
00:47:30,350 --> 00:47:36,880
So this mixture of normal so it doesn't doesn't always it doesn't always sample to sample from our lives.

392
00:47:36,890 --> 00:47:42,140
There is a case that because you have a multiple more than two sample from these outliers.

393
00:47:42,140 --> 00:47:47,320
So it's accounting for that probably sometimes they moving three more aggressively.

394
00:47:47,330 --> 00:47:50,660
Three. So three samples helps better.

395
00:47:51,320 --> 00:47:56,209
If you remove four, it's even better. If you remove five, it's even better.

396
00:47:56,210 --> 00:48:02,210
But once you so once you have a cake and five, you're removing half of the sample, right?

397
00:48:02,690 --> 00:48:09,589
So maybe this might be a little too much. So you now the performances start to deteriorate.

398
00:48:09,590 --> 00:48:13,850
So if you use a key or six, then it's a removing.

399
00:48:14,510 --> 00:48:24,290
Well, it's an impulse you have when you're using the 40% of sample so that that actually increased your mse.

400
00:48:24,290 --> 00:48:31,220
Now it makes it less accurate even though there is a small chance that it can be used, you can remove the outliers.

401
00:48:31,880 --> 00:48:40,370
It's a very unlikely that you have a six outliers when you are expecting number two, so you can calculate the probability of that happening.

402
00:48:40,970 --> 00:48:47,150
So you probably can analytically find the what is the optimal value of this in these two simple cases.

403
00:48:47,930 --> 00:48:55,219
But in general, finding this is this as experimental way is an interesting way to go about this problem.

404
00:48:55,220 --> 00:49:02,570
So obviously it starts increasing and from here it gets pretty bad.

405
00:49:02,810 --> 00:49:12,680
Okay. Okay. So that's one example of the estimating MSE with a trimmed mean.

406
00:49:16,800 --> 00:49:25,140
Any question. Okay.

407
00:49:25,920 --> 00:49:29,580
Let's now think about the estimated confidence interval.

408
00:49:29,730 --> 00:49:35,760
Okay. So again, if you haven't taken six or two,

409
00:49:35,760 --> 00:49:45,839
this might be a little bit confusing because of all the notation theta of x and l of x, u of x is a is confusing.

410
00:49:45,840 --> 00:49:49,320
So. But uh.

411
00:49:50,580 --> 00:50:01,010
If you want to if you are a person thinking by example, x is the number of coin tosses and theta is probably like x divided by ten L of x.

412
00:50:01,020 --> 00:50:06,180
I don't know. So you can you can, you can make some, some, some function.

413
00:50:06,510 --> 00:50:13,169
We can we can come up with it, but basically lower lower end of your your estimate of data.

414
00:50:13,170 --> 00:50:22,200
So I'm going to say is the theta ten over ten, I'm going to data divide by 20 that that's my law and I'll point the data theta by five.

415
00:50:22,390 --> 00:50:24,630
That could be my opinion. I'm just making it up.

416
00:50:25,320 --> 00:50:30,840
So that could be just the e general function you can think about if you're unsure what this what this is talking about.

417
00:50:31,980 --> 00:50:44,450
So. So this is confidence interval estimate for unknown parameter data and the confidence level which is also the same time.

418
00:50:44,450 --> 00:50:52,219
The equivalent term is a coverage. Probability is the probability that the interval covers the true value of the parameter theta.

419
00:50:52,220 --> 00:50:58,370
So this is a I'm not going to get, get, get to this because you are going to need a six or two if you haven't.

420
00:50:59,510 --> 00:51:08,809
But this is not the same as the probability that true parameter is inside this confidence interval,

421
00:51:08,810 --> 00:51:14,660
because in this frequentist approach, we don't have we don't consider data as random variables.

422
00:51:14,660 --> 00:51:19,670
So you, you only, you know, data theta is already given.

423
00:51:19,820 --> 00:51:29,120
And what it is trying to say is that what is the probability that your confidence interval covers that for a parameter.

424
00:51:29,120 --> 00:51:34,729
So that's a different thing. So if you it's like p value pr u, that means different things.

425
00:51:34,730 --> 00:51:41,570
So this is also means means different thing than the credible, credible probability, which is a different thing.

426
00:51:42,560 --> 00:51:45,370
So yeah, but anyway, so this is a,

427
00:51:45,380 --> 00:51:54,440
this is a standard definition of a confidence level and you just need to find the probability that this confidence level includes the true parameter.

428
00:51:55,070 --> 00:51:58,400
How do you do it? Well, it's not that hard.

429
00:51:58,640 --> 00:52:04,880
Okay. Once you have L of X in view of x, and if you know what to do,

430
00:52:05,870 --> 00:52:11,329
you'll have a true popular and you have you have a board function, so you got the interval.

431
00:52:11,330 --> 00:52:20,120
So just calculate how many times this interval was, include those three parameter and take the take the mean.

432
00:52:20,660 --> 00:52:25,250
So that that's pretty simple. And how do we quote unquote it up?

433
00:52:25,250 --> 00:52:30,380
So this this concept itself is not necessarily hard.

434
00:52:30,390 --> 00:52:34,820
What I wanted to get at here is that how you call it up, right?

435
00:52:34,880 --> 00:52:47,120
So it's a good you know, I I'm I don't think I should give you too much of time to practice and start quoting yourself.

436
00:52:47,120 --> 00:52:58,669
But if you want to do it, you can you can skip skip the looking at the code and try to try to implement yourself that that's a good exercise.

437
00:52:58,670 --> 00:53:05,270
I think. So let's hope let's think about this problem.

438
00:53:05,450 --> 00:53:12,230
So let's the problem is that estimating the confidence interval for various.

439
00:53:12,500 --> 00:53:18,950
Okay, so when you have a normal it should be simple.

440
00:53:20,030 --> 00:53:34,700
Okay. The sample variance which is a calculated as in a variance divided by input and minus one that and then.

441
00:53:36,930 --> 00:53:50,070
That the sample variance the follows the distribution of high school distribution if you kill them properly like this.

442
00:53:50,470 --> 00:54:00,870
Okay. So and you can prove these also in six or two or even with a 6 to 1 knowledge.

443
00:54:00,990 --> 00:54:04,500
But we're not we're not doing that here. Okay. So that's a fact.

444
00:54:04,740 --> 00:54:16,740
Okay. So and then what you can do is that the question is, oh, I actually have my variance here.

445
00:54:16,980 --> 00:54:20,730
Okay, then. But my.

446
00:54:21,090 --> 00:54:24,870
So less than my my sample variance is one.

447
00:54:26,010 --> 00:54:30,190
But I don't want I want to be a little bit conservative about estimating variance.

448
00:54:30,210 --> 00:54:35,490
So what is the reasonable upper bound of my variance estimation with various estimates?

449
00:54:35,500 --> 00:54:40,170
So that's that's the question. So it's a you can make a one sided compilation of all that.

450
00:54:41,190 --> 00:54:45,300
I'm going to estimate the variance can be as small as zero, but there is upper bound.

451
00:54:45,490 --> 00:54:49,770
Okay. So that's confidence double you can you can get.

452
00:54:50,160 --> 00:54:55,709
And one possible estimate are based on the theory, based on using based on using.

453
00:54:55,710 --> 00:55:05,330
This fact is that if you use this as a chi square quantile of alpha upper quantile of our fat, and this is the good estimate.

454
00:55:05,580 --> 00:55:11,580
Well, actually, sorry, it's a lower quantile of Alpha than it is because you are dividing it.

455
00:55:11,840 --> 00:55:24,090
Okay. Then. Then this is a good way to estimate the upper bound of your true, true variance.

456
00:55:24,330 --> 00:55:28,140
Okay. So. Okay.

457
00:55:28,210 --> 00:55:28,800
So then.

458
00:55:30,180 --> 00:55:40,620
Then if this all fact in theory is correct and this is the, the confidence interval, that should give a commodity probability one minus alpha.

459
00:55:40,620 --> 00:55:44,520
So if you if you choose a value of 5.05,

460
00:55:45,240 --> 00:55:56,370
that means that there is a 95% of confidence that that 95% of probability that your confidence level covers the total parameters.

461
00:55:57,550 --> 00:56:01,890
Okay. Okay. So let's see if that that works.

462
00:56:02,160 --> 00:56:08,850
So so this is empirically we're just trying to verify that expectation.

463
00:56:10,200 --> 00:56:15,840
So how do we do it? So estimating confidence level, you basically have pretty much the same thing here.

464
00:56:17,280 --> 00:56:23,670
You have a number of replicate sample size and a total parameter in the simulator.

465
00:56:24,330 --> 00:56:29,940
And this now you have a function to create a PSI function, which you give the two numbers.

466
00:56:30,060 --> 00:56:33,180
Right. So upper bound and lower bound. Okay.

467
00:56:33,690 --> 00:56:37,870
So then what you're doing is clone of I.

468
00:56:38,280 --> 00:56:48,720
Is that so? The other, the other two part. The same date you quote, you calculate the confidence interval and return this this part returns a zero.

469
00:56:48,990 --> 00:56:53,550
Or if your total parameter is, I'll say the confidence interval.

470
00:56:53,580 --> 00:56:57,240
Otherwise it is a little true and it becomes a one.

471
00:56:57,930 --> 00:57:04,470
So you keep adding them, adding the value of one and the the mean as a double digit probability.

472
00:57:05,320 --> 00:57:08,840
Okay. So that's that's how this is designed.

473
00:57:12,330 --> 00:57:19,410
So then the confidence interval estimate we have here is that, oh, I'm,

474
00:57:19,620 --> 00:57:25,979
I'm going to calculate the sample variance of X and multiply by and minus one and divide by

475
00:57:25,980 --> 00:57:34,770
the chi square quantile of the alpha of the two or by the rejection probably ten to the null.

476
00:57:36,210 --> 00:57:41,070
Then if you do this in a lower, lower bound is always zero.

477
00:57:41,070 --> 00:57:47,670
This is a valid estimate of variance, I believe.

478
00:57:47,940 --> 00:57:56,730
Okay, so then let's try this again and see what happens.

479
00:57:57,000 --> 00:58:09,629
Okay, so this one is your populating the is a we are doing the repeating this 50,000 times and the sample size is 202.

480
00:58:09,630 --> 00:58:14,370
The parameter is the one. So I'm sampling from the normal distribution with the various variance one.

481
00:58:15,330 --> 00:58:29,250
And similarly, your simulator is basically normal distribution with with this tentatively standard deviation and so as as these variance actually.

482
00:58:29,250 --> 00:58:41,790
So it's so these variance and what you are doing the spirit of S as a standard deviation parameter and I'm going to use this of our Darci as my,

483
00:58:42,120 --> 00:58:46,470
my estimate for the confidence interval.

484
00:58:46,590 --> 00:59:00,420
Okay. Then when you do this, you got the 95% of probability that the total parameter which is in this case one is included inside your estimate.

485
00:59:00,510 --> 00:59:03,510
So this is doing as expected.

486
00:59:05,160 --> 00:59:09,990
What about I use the zero during five here.

487
00:59:10,170 --> 00:59:17,310
Okay. So now now I'm giving the to the parameter is a five in the simulator.

488
00:59:17,610 --> 00:59:21,569
Is you using that to the parameter.

489
00:59:21,570 --> 00:59:29,850
So it's a, it's a same simulated function here and I just change it to the true various and still works.

490
00:59:29,970 --> 00:59:40,290
Okay, so that's good. What about if the true distribution is a mixture of norm?

491
00:59:41,880 --> 00:59:49,920
So if you if your data comes from the mixture normal but I did not know that this is coming from mixture of normal.

492
00:59:50,340 --> 00:59:57,780
So I am still assuming that this is normal distribution and I'm still using the same formula like this.

493
00:59:58,590 --> 01:00:03,780
What do you think of do you think you're going to your coverage? Probability will increase or decrease.

494
01:00:09,290 --> 01:00:13,340
So in this case, it's a 95%, 95% in this case.

495
01:00:13,370 --> 01:00:28,010
What do you what do you expect? And if you think the coverage of poverty will increase and if you think the poverty will decrease.

496
01:00:29,060 --> 01:00:33,260
Okay. Okay. So what?

497
01:00:33,710 --> 01:00:37,730
What? So let's think about this. Okay. So because this is an interesting problem.

498
01:00:37,740 --> 01:00:43,340
If you want to make sure that you understood this, how this function works so poorly.

499
01:00:43,340 --> 01:00:49,010
Okay. If you were one teacher. But I appreciate someone who raised a hand either way.

500
01:00:49,220 --> 01:00:53,080
So that's that's better because I want you to see your best guess.

501
01:00:53,090 --> 01:00:57,830
I don't I didn't want to necessarily see the right answer.

502
01:00:57,990 --> 01:01:03,290
Okay. So I actually don't remember what the answer was.

503
01:01:04,580 --> 01:01:09,230
So. But in my guess, if you use a mixture of normal.

504
01:01:09,320 --> 01:01:14,150
So compared to. So in this case, if you use an unknown.

505
01:01:14,440 --> 01:01:18,530
Okay. What, what do you expect in terms of the sample variance?

506
01:01:19,700 --> 01:01:25,520
If you estimate from the variance of one, you're going to see the estimated variance close to one.

507
01:01:25,790 --> 01:01:33,350
Right. But if if the data is coming from Excel, no more, do you think the estimate variance will be larger or smaller?

508
01:01:37,240 --> 01:01:41,770
Your problem because there's outliers, your variance will probably increase.

509
01:01:42,010 --> 01:01:48,969
Right. So you're going to see even even if you intend to sample from the various one you probably see,

510
01:01:48,970 --> 01:01:53,170
you probably will sample from something that is greater than one.

511
01:01:53,200 --> 01:01:57,670
Right? So the estimated variance is greater than one because there are lives.

512
01:01:58,780 --> 01:02:06,489
And then because your your various estimate is already very large and you're keeping a credible interval that is,

513
01:02:06,490 --> 01:02:10,210
you know, to some large value multiplied by some other factor.

514
01:02:10,690 --> 01:02:17,980
Your credible interval is very, very large as it makes sense that it becomes a larger than it should be.

515
01:02:19,270 --> 01:02:22,780
But the two parameters are one. So in the lower bound is always zero.

516
01:02:22,780 --> 01:02:26,740
So I think the credible probability will actually increase.

517
01:02:27,160 --> 01:02:30,790
Okay. Let's see if that's the case. I might be wrong.

518
01:02:32,080 --> 01:02:43,360
So in this case, credible probabilities was one good. Well, so the reason is that you have, you know, this this estimate.

519
01:02:43,600 --> 01:02:56,500
So simulator similarly to create a two in your thought that the true param is one but the parameter should be much greater than one, basically.

520
01:02:56,650 --> 01:03:00,430
So you this is a problem.

521
01:03:00,430 --> 01:03:03,339
The true parameter is a kind of incorrect. I mean,

522
01:03:03,340 --> 01:03:12,760
if you in some sense because you're generating the generated this region was and wasn't really a normal distribution so it's a it's a very confusing.

523
01:03:13,420 --> 01:03:19,000
But in this particular case if you simulate this way, the answer is, you know,

524
01:03:19,120 --> 01:03:27,429
it's generating the you know, the you thought the true to that to the variance was one.

525
01:03:27,430 --> 01:03:29,740
So that's why you put the to the parameter equals one.

526
01:03:30,310 --> 01:03:37,300
But in fact the two variance was much larger, so it gives a unreasonably large coverage probability.

527
01:03:40,510 --> 01:03:54,400
So in fact, the rule of thumb is that it's much more likely that you can't you can underestimate the variance of data than overestimating it.

528
01:03:55,080 --> 01:03:59,530
That that's the that's a rule of thumb. I think in most of the day it will want better.

529
01:04:03,390 --> 01:04:10,620
Third example. Okay, so third example agenda, you need to understand a six or two.

530
01:04:10,620 --> 01:04:19,169
But I think all these principles, unless you're studying the theory, these are these are actually very common examples.

531
01:04:19,170 --> 01:04:26,430
And the mathematical notation itself is just a little bit new if you haven't taken six of three yet.

532
01:04:26,670 --> 01:04:31,830
So that would be sort of so hypothesis testing.

533
01:04:32,160 --> 01:04:41,309
Okay. So this is a lot of times you can use a monte Carlo method, so suppose that your data is sample from some distribution.

534
01:04:41,310 --> 01:04:47,670
Again, I'm going to show you the the good example here you can think about is there is a coin.

535
01:04:48,150 --> 01:04:51,210
I have a coin. Is it is this coin biased or not?

536
01:04:51,390 --> 01:04:54,870
Okay, that's one hypothesis testing you can ask. Okay.

537
01:04:55,590 --> 01:05:00,389
Then say, oh, you have a one hypothesis that that this coin is biased,

538
01:05:00,390 --> 01:05:07,260
which means that theta equal point five and oh I don't think this coin is unbiased.

539
01:05:07,260 --> 01:05:11,820
Theta is somewhere, you know, is there is arbitrary value.

540
01:05:11,940 --> 01:05:19,920
Okay, not, not, not 0.5. Okay. So then you can you can test the hypothesis.

541
01:05:20,010 --> 01:05:27,210
Okay. How do we do it? Well, so what, what, what you do is that you calculate some test statistic.

542
01:05:27,360 --> 01:05:31,200
Okay, so I have oh, I.

543
01:05:31,800 --> 01:05:39,180
So in this case you toss the hundred coins and God got 40 hand.

544
01:05:39,720 --> 01:05:44,580
Okay then it's a little suspicious, but that couldn't happen by chance.

545
01:05:44,880 --> 01:05:48,540
Okay, but so you calculate them probably.

546
01:05:48,540 --> 01:05:55,139
Then you make a decision that, oh, I, I reject no hypothesis because this is, you know,

547
01:05:55,140 --> 01:06:01,170
I don't think it's a fair if it was fair coin, this would never happen or not.

548
01:06:01,170 --> 01:06:11,219
So, you know, you're you can make your own own test statistic and decide your own test the rejection region and decide the what to accept,

549
01:06:11,220 --> 01:06:20,330
what to reject or based on the what you what you see. You have you toss the hundred coins and see all the know none of them what.

550
01:06:20,340 --> 01:06:27,149
And then that looks really suspicious. It's a really an impossible to happen almost.

551
01:06:27,150 --> 01:06:30,370
Right. So you know this they must have done something here.

552
01:06:30,600 --> 01:06:34,110
So in that case, you have a very, you know.

553
01:06:34,920 --> 01:06:43,200
Yeah. So you can you can make a decision that, oh, I'm going to reject no hypothesis, but it all depending on the different outcomes.

554
01:06:45,090 --> 01:06:52,530
So if you if you have fee of X equals one, then the null hypothesis rejected.

555
01:06:52,530 --> 01:06:56,450
And if fee of x is true, then that null hypothesis is accepted.

556
01:06:56,670 --> 01:07:06,930
Okay. So not not accepting the null hypothesis doesn't mean that are, you know, the coin is actually unbiased.

557
01:07:06,990 --> 01:07:13,170
You just don't have a strong enough evidence that you know this in this is biased.

558
01:07:13,350 --> 01:07:24,360
Okay so then when, when you do this type of hypothesis testing, you can calculate the type one error and power.

559
01:07:24,510 --> 01:07:39,540
Okay. What is a type one error? So type one error is the is the probably table probably to enter when the true the null hypothesis is true.

560
01:07:40,350 --> 01:07:46,560
So in this example of a coin pose, when your coin is unbiased, you have a fair point.

561
01:07:46,860 --> 01:07:49,330
Okay? But sometimes you can't.

562
01:07:49,350 --> 01:08:00,600
You may reject the null hypothesis, meaning that, oh, I'm going to, I'm going to I'm going to conclude that this coin is biased.

563
01:08:00,870 --> 01:08:12,900
Okay. So for example, like if you put 100 coin, okay, I'm going to reject the null hypothesis if all 100 coins was hat.

564
01:08:13,290 --> 01:08:18,720
Okay, so let's say that then you have a really, really low table type one error,

565
01:08:19,080 --> 01:08:28,170
but you can make that error if the coin was biased and if that unlikely things happen, which is a two to the minus under that you type of that.

566
01:08:29,880 --> 01:08:36,090
And if you decide to reject that all I'm I'm going to reject the null hypothesis.

567
01:08:36,090 --> 01:08:43,469
If the number of head is less than 40 or greater than 60, then you can calculate the probability how often that that could happen.

568
01:08:43,470 --> 01:08:49,830
That's a type one. And type two error is the probability that you can't you can.

569
01:08:50,820 --> 01:08:55,410
NULL hypothesis is not rejected even if you're not hypothesis false.

570
01:08:55,500 --> 01:08:58,560
Meaning that I actually do have biased coin.

571
01:08:59,070 --> 01:09:07,450
Okay. But. I have a biased claim, but my test did not reject the hypothesis.

572
01:09:07,750 --> 01:09:13,180
For example, I have a point that the probability of head is a 60%.

573
01:09:13,450 --> 01:09:20,920
Okay. And I got I got 6100. But this test didn't reject the null hypothesis that's attached to it.

574
01:09:21,250 --> 01:09:27,520
Okay. So ideally, you want to lower and lower both the type of an error and type two error.

575
01:09:28,120 --> 01:09:29,079
But I type one,

576
01:09:29,080 --> 01:09:38,820
that can be estimated because the probability of rejecting that hypothesis is a probability that your your decision fee is just returning.

577
01:09:39,010 --> 01:09:42,190
You don't have one. You can decide one or one way or the other.

578
01:09:43,360 --> 01:09:51,940
So you can calculate the probability of type one that are of type one out of this.

579
01:09:52,180 --> 01:09:58,000
Okay. When when assuming data or data or data belongs to a null hypothesis.

580
01:09:59,440 --> 01:10:06,309
So and maybe, maybe this part is not necessary to this is a background to learn.

581
01:10:06,310 --> 01:10:16,299
But you can you can also decide the how significant of the significance level of test in how much stringent should I do I want to be like,

582
01:10:16,300 --> 01:10:21,910
so would it be possible to give because the level is point of five 5%,

583
01:10:21,910 --> 01:10:28,090
that means that you have, you know, maximum of 5% of probability of the type one error.

584
01:10:28,090 --> 01:10:36,670
So you can if the null hypothesis true, you have up to 5% of chance to expect a chance of the rejecting null hypothesis.

585
01:10:37,900 --> 01:10:41,080
Okay. And power. You can do the same thing.

586
01:10:41,080 --> 01:10:49,960
But you know, when when that the null hypothesis, true parameter is not what sort of hypothesis is not the null hypothesis.

587
01:10:50,890 --> 01:10:57,010
Then you can calculate the how often I can correctly reject the null hypothesis.

588
01:10:57,010 --> 01:11:02,920
That's a called power. Okay. So this was not a sixth or two class.

589
01:11:03,020 --> 01:11:08,740
I didn't plan to cover this, but because many students didn't take the sixth or two, I just was.

590
01:11:09,070 --> 01:11:12,880
I was explaining it. So. Okay.

591
01:11:13,960 --> 01:11:20,260
So how do you do the Monte Carlo thing? So you don't need to know all these things as long as you understand this part.

592
01:11:20,380 --> 01:11:28,240
Okay. So this this part I have, you know, you can simulate a bunch of data based on your distribution.

593
01:11:28,420 --> 01:11:34,719
Okay? And you can calculate empirically how often I reject the null hypothesis,

594
01:11:34,720 --> 01:11:39,910
correctly or incorrectly, based on the whether true hypothesis is null hypothesis or not.

595
01:11:41,140 --> 01:11:42,220
So yeah.

596
01:11:44,230 --> 01:11:51,670
So in this case, if you want to evaluate the type one error, you generate a sample from the null hypothesis, you go to the parameters and data zero.

597
01:11:51,760 --> 01:11:56,990
In this case, the bias point, it's the 0.5. So you generate the sample from the VI biased point.

598
01:11:57,370 --> 01:12:05,280
Sorry. Fair point. Fair point. And calculate the test, the statistics, whatever, whatever your test statistic is.

599
01:12:05,290 --> 01:12:09,880
And of this, calculate how often you reject the null hypothesis.

600
01:12:10,930 --> 01:12:15,030
Same thing if you wanted to estimate the power to.

601
01:12:15,100 --> 01:12:21,280
Exactly. Actually, if you compare this slide and this slide, there's only two things change it.

602
01:12:22,510 --> 01:12:26,560
One is that data is the data. Zero is a data one.

603
01:12:27,370 --> 01:12:31,930
Okay. And now it says instead of type one error, it says power.

604
01:12:32,260 --> 01:12:42,879
Okay. Why? Because when the null hypothesis incorrectly, if the if the null hypothesis is not true, rejecting is a good thing.

605
01:12:42,880 --> 01:12:47,680
So it's a power instead of error. So power is one minus type two error.

606
01:12:47,680 --> 01:12:52,180
So but everything else is the same. Okay.

607
01:12:53,170 --> 01:13:00,400
So we're going to try here is that we have a random 20 samples,

608
01:13:00,580 --> 01:13:09,250
a sample from the normal distribution and we are going to check whether our being is 500 or not.

609
01:13:09,250 --> 01:13:21,159
So I guess, you know, student t test. So this should be easier to understand and this this one, you know, simply you calculate this test,

610
01:13:21,160 --> 01:13:25,180
this statistic and it should follow those two t description with the degrees of freedom.

611
01:13:25,180 --> 01:13:35,229
19 Then if if you wanted to make a null hypothesis, whether mu is mean is greater than 500 or not.

612
01:13:35,230 --> 01:13:42,100
So you assume that mean is means less than 500 equal or less than 500 or 500.

613
01:13:43,240 --> 01:13:46,840
Then this is your rejection region and this is your test function.

614
01:13:46,870 --> 01:13:56,049
So basically you calculate these t statistics and if these T statistic is created a certain threshold, I'm going to reject the null hypothesis.

615
01:13:56,050 --> 01:14:01,570
So that's what this test is doing. Okay, so let's see.

616
01:14:01,950 --> 01:14:04,650
So this is the last thing a. Let's see. Okay.

617
01:14:07,710 --> 01:14:16,920
So these are this is a very gentle function for the student, uh, not just for the student to this patient.

618
01:14:16,950 --> 01:14:23,100
You basically, in this case, you do a number of replicate the Monte Carlo replication.

619
01:14:23,670 --> 01:14:27,990
You have a sample size here sort of parameter and you have a simulator.

620
01:14:28,560 --> 01:14:36,840
So previously so just the you probably recognize that the first one has an estimate or a single, single estimate.

621
01:14:37,940 --> 01:14:43,650
The second one has, instead of estimate is a critici which give which returns to values.

622
01:14:44,640 --> 01:14:50,760
Now this one returns test function, which returns either zero or one.

623
01:14:50,760 --> 01:14:56,260
So you don't that I accept the null hypothesis. One means that I reject the null hypothesis again.

624
01:14:57,150 --> 01:15:07,460
So what you do is a calculator, you know, generate the data and run the run the test function and store them into free value to zero or one.

625
01:15:07,470 --> 01:15:14,820
If you calculate the mean value, that will be the type one error or power depending on the null hypothesis, true or false.

626
01:15:16,260 --> 01:15:21,410
So this test function is implementing the exact test we just talked about here.

627
01:15:21,420 --> 01:15:25,730
So if the t statistics greater than the threshold, I'm going to return one.

628
01:15:25,740 --> 01:15:27,270
Otherwise I'm going to be zero.

629
01:15:28,710 --> 01:15:42,450
Then if you run this, uh, you have this probability, 5% probability because that's, that's the, that's the level of significance level I designed.

630
01:15:42,450 --> 01:15:48,210
So I designed the test to have the type of an error to be about 5%.

631
01:15:48,510 --> 01:15:54,390
By you can, you can lower that or you can adjust that by changing the value of alpha.

632
01:15:56,160 --> 01:16:01,770
And the power is the case where if you look at C, the total parameter is instead of 500.

633
01:16:01,770 --> 01:16:05,020
Now I'm using the 500.5. Okay.

634
01:16:05,310 --> 01:16:11,100
In this case, what happens and I'm using the the simulators are norm, so I'm basically using the,

635
01:16:11,850 --> 01:16:21,510
uh, here using the standard deviation of one and uh, actually, yes, stick to it.

636
01:16:22,740 --> 01:16:27,900
Yeah. So standard or norm with with no standard deviation given, just sustained division one.

637
01:16:28,620 --> 01:16:37,950
So if you do this, then you have a 69% of power when you're to the parameter of 500.5.

638
01:16:38,310 --> 01:16:41,410
And if you do 500, this is a type one error, as I said.

639
01:16:41,410 --> 01:16:45,480
Right. So this is this should to be 0.5% .05.

640
01:16:46,470 --> 01:16:49,920
And if you do five point minus one, then power will reduce.

641
01:16:50,160 --> 01:16:56,580
So your through your your tool, the parameter is really two too close to the null parameter.

642
01:16:57,090 --> 01:17:04,440
So you don't have much power in this test. So you can calculate the power as a function of the parameter and the plot.

643
01:17:04,500 --> 01:17:10,440
How the power function works with when different part to the parameter differs.

644
01:17:11,370 --> 01:17:12,600
So that's what you can do.

645
01:17:13,800 --> 01:17:24,150
And you can do that thing here, basically calculating the power curve based on the different value values of these parameters.

646
01:17:24,510 --> 01:17:35,400
Okay. So what I'm doing here is that the five 5 to 502 I'm making making some grid and try to show how this power function looked like.

647
01:17:35,410 --> 01:17:47,310
So as I said, this is a close to point of five, but the power function increases as the two polymer increases and which is also part of one,

648
01:17:47,550 --> 01:17:51,540
uh, after the new parameter is greater than the final one.

649
01:17:52,260 --> 01:17:58,290
So that's, that's a, for example, maybe pointers might be more interesting, I think.

650
01:17:58,510 --> 01:18:02,640
Uh, but this was, uh, currently given in the switch.

651
01:18:04,700 --> 01:18:09,240
Okay, so that's the end of the lecture.

652
01:18:09,250 --> 01:18:18,040
12. So I don't think we have real time to cover Lecture 13, but I.

653
01:18:19,040 --> 01:18:22,760
So let me just so because we're going to go to the bootstrap,

654
01:18:23,540 --> 01:18:29,420
I think I have time to introduce the what the question is and you can talk about in the Wednesday,

655
01:18:30,670 --> 01:18:36,650
but before any any question about the lecture 12 material or or other other material.

656
01:18:39,100 --> 01:18:48,759
Okay. So we have our office hour today just saying that I'm not going to give a specific hint for the for the midterm.

657
01:18:48,760 --> 01:18:52,329
I can just, you know, give a very general advice.

658
01:18:52,330 --> 01:18:58,240
But, I mean, whenever you have a challenge, I'm not going to suggest that I try these specific methods.

659
01:18:58,450 --> 01:19:04,600
So the amount of hints I can provide or or the GSA can provide this in a minute.

660
01:19:04,810 --> 01:19:15,440
Okay. Okay. So the bootstrap.

661
01:19:15,450 --> 01:19:25,440
So Bootstrap is introduced in 1979 by Efron and it's a multicolor method that estimate the distribution of the population by resampling.

662
01:19:25,590 --> 01:19:31,140
Okay, so resampling was a kind of new idea at the time and it was surprisingly working well.

663
01:19:31,770 --> 01:19:35,640
So Resampling Method became very popular at the time.

664
01:19:36,090 --> 01:19:38,579
So even if your sample is finite,

665
01:19:38,580 --> 01:19:49,649
so you can sample from a sample with replacement that give very good properties that you probably cannot obtain from the typical palmistry estimation.

666
01:19:49,650 --> 01:20:00,580
So it was very popular at the time. So you can make inference of these resample data and those are requires a large number of computations.

667
01:20:00,580 --> 01:20:09,360
So this is a part of the esthetic of computing, but I'm pretty sure that you have learned in bootstrap in other setting motivated presenting.

668
01:20:09,360 --> 01:20:16,560
And today we're going to talk about more about how to use bootstrap in how to implement them in a competition way.

669
01:20:16,920 --> 01:20:20,370
And I'm not going to go much into detail of the theory of the strategy.

670
01:20:21,150 --> 01:20:30,120
So that gave gave the we are in time, so let's stop here and then let me then thank you for your attention.

