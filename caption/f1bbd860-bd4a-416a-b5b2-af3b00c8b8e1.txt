1
00:00:00,390 --> 00:00:23,170
So last year we gave students to work on a big national study, but they it was a large cohort study.

2
00:00:23,430 --> 00:00:32,580
Tons and tons of variables. And we told students to kind of design their own scientific question.

3
00:00:33,810 --> 00:00:40,500
So, of course, you know, they didn't have to look at everything, a big 4% to give some guidance.

4
00:00:40,650 --> 00:00:42,510
And then people were very creative.

5
00:00:42,510 --> 00:00:56,970
They came up with different ideas, some some focused on sleep health, some focused on cardiovascular health, some focused on hypertension, diabetes.

6
00:00:57,210 --> 00:01:03,270
So so basically, you know, that's what they did.

7
00:01:04,020 --> 00:01:07,020
And this year, we might do it a bit differently.

8
00:01:08,040 --> 00:01:18,690
We might give you more directions in the sense like we give you the data and a smaller dataset.

9
00:01:19,350 --> 00:01:24,240
But still, there are lots of different angles to look at.

10
00:01:26,850 --> 00:01:30,550
But I'll give you kind of more detailed directions on that.

11
00:01:31,540 --> 00:01:35,420
And as I mentioned, that included work in groups of four.

12
00:01:36,180 --> 00:01:40,110
And each group we have some students from Section one.

13
00:01:41,970 --> 00:01:46,970
I knew I wanted to do a presentation. Okay.

14
00:01:46,970 --> 00:01:50,330
So so lots of details coming up.

15
00:01:50,750 --> 00:01:57,860
But I just wanted to give you a heads up that November is already knocking on the door and November 1st and.

16
00:01:58,550 --> 00:02:03,020
And of the project. So you have plenty of time to work on it.

17
00:02:07,820 --> 00:02:16,830
At the very least, you might want to kind of meet up with your group members and start thinking about the project.

18
00:02:16,850 --> 00:02:20,650
You may not do things before the second midterm, but as.

19
00:02:22,750 --> 00:02:34,950
Enough time. So kind of think about how to approach what to do and then do the work after the second week to honor itself.

20
00:02:35,060 --> 00:02:38,260
INSKEEP okay. Any other question?

21
00:02:41,660 --> 00:02:50,930
Okay. So if not, then today we are going to talk about categorical poverty.

22
00:02:51,040 --> 00:03:01,489
So if you recall really early on when we were talking about, you know,

23
00:03:01,490 --> 00:03:07,310
sort of introducing linear regression and we were talking about simple linear regression.

24
00:03:08,090 --> 00:03:15,830
One thing that I mentioned is the the sort of the in the linear regression framework,

25
00:03:16,250 --> 00:03:29,660
why the outcome variable is continuous, but x the whole be it can be from of any measurements.

26
00:03:30,050 --> 00:03:45,200
I mean, typically we have been looking at continuous X, but it can be a nominal x can be ordinal categorical x can be.

27
00:03:45,800 --> 00:03:57,770
So basically, you know, the whole idea can be any type of any variables that can span different measurement scales.

28
00:03:59,120 --> 00:04:13,710
So today in module eight, what we are going to talk about are basically a qualitative covariance meaning and I'll give some examples.

29
00:04:14,420 --> 00:04:29,180
So think about this. Think about this ethnicity thing, about hair color, eye color, pink, about state or geographical region.

30
00:04:31,040 --> 00:04:41,659
So typically we have qualitative covariance and we can we will also talk about categorical covariates,

31
00:04:41,660 --> 00:04:45,200
but maybe there is some kind of inherent ordinal.

32
00:04:45,440 --> 00:04:53,180
And I'll come to that in a minute. So that's going to be the theme for module eight.

33
00:04:53,810 --> 00:04:56,840
And we are going to talk about design matrices.

34
00:04:56,850 --> 00:05:03,140
We are going to talk about 14 schemes for such variables, interpretation of parameters.

35
00:05:04,280 --> 00:05:09,620
And we are also going to talk about like an approach where you can score the categorical

36
00:05:09,620 --> 00:05:19,519
covariates and I need more like a like sort of linear regression with a continuous whole with it.

37
00:05:19,520 --> 00:05:26,299
So basically we are going to talk about both categorizing a continuous covariate as

38
00:05:26,300 --> 00:05:34,790
well as assigning values to two categories and running it like one degree of freedom.

39
00:05:36,050 --> 00:05:44,600
Linear regression model for the big picture. And then we are going to sort of do some examples.

40
00:05:44,960 --> 00:05:50,810
So this is chapter eight of your textbook for quality.

41
00:05:52,610 --> 00:06:06,350
So the type of covariance that we have so far talked about are mostly quantitative, although we have talked about gender in some examples.

42
00:06:07,970 --> 00:06:11,690
Finally, gender to zero one.

43
00:06:13,010 --> 00:06:16,969
But typically we have talked about like, you know, VMI that has gone to new us.

44
00:06:16,970 --> 00:06:20,630
We have we have talked about high three.

45
00:06:22,640 --> 00:06:28,130
Again, pretty much like well-defined one point scale of measurement.

46
00:06:29,330 --> 00:06:44,209
And today we are going to talk about variables that may have been collected in a qualitative fashion, in a categorical fashion.

47
00:06:44,210 --> 00:06:56,810
So these variables are represented both by categories, and we are going to focus on these types of predictors.

48
00:06:58,190 --> 00:07:08,570
I already talked about simplicity. So, you know, location, Americans, African Americans, Asians, Hispanics.

49
00:07:09,140 --> 00:07:17,150
So these are this is basically it is an example of a nominal categorical variable.

50
00:07:17,180 --> 00:07:21,320
So these are the categories and there is no inherent ordering.

51
00:07:21,560 --> 00:07:26,990
Eye color is another example here. Color is another example, categorical variable.

52
00:07:26,990 --> 00:07:34,970
And there is really no inherent ordering with whether, you know, hair color is brown or black or blond.

53
00:07:36,200 --> 00:07:40,550
These are these are categories and these are qualitative variables.

54
00:07:42,030 --> 00:07:51,120
Geography, state, region down the country, and we may even wish to categorize continuous variables.

55
00:07:51,120 --> 00:08:00,270
And this is a very common practice in the clinical research because often oftentimes what happens is,

56
00:08:01,230 --> 00:08:10,320
for example, BMI, body mass index is is like in its original scale,

57
00:08:10,320 --> 00:08:16,280
it's fine to us site, but we make up these categories like I'm going to be normal,

58
00:08:16,320 --> 00:08:25,200
be overweight or obese based on categorizing the continuous BMI variable.

59
00:08:25,350 --> 00:08:31,880
And so why do we do that? And as I said, this is quite common in the clinical literature.

60
00:08:31,920 --> 00:08:40,500
The reason why we do that is it improves interpretation of the parameters and the model.

61
00:08:40,620 --> 00:08:50,069
And we are going to talk about in module get a diagnostics for assessing linear trend.

62
00:08:50,070 --> 00:08:51,299
What do I mean by that?

63
00:08:51,300 --> 00:09:00,150
Let me just say at this point, so for example, you have a variable like BMI, which is ordinarily measured in the continuous data,

64
00:09:00,570 --> 00:09:07,440
but then you get equal rights and you have these four categories, not underweight, overweight or obese.

65
00:09:08,040 --> 00:09:12,239
So the question is which model should I go read?

66
00:09:12,240 --> 00:09:21,290
Should I go with the regional BMI or should I go with the categorical BMI, which was like probably deprivation quite a few.

67
00:09:21,320 --> 00:09:30,690
The categories might make much more sense, but from a modesty perspective is fitting.

68
00:09:30,900 --> 00:09:41,430
BMI you need or do not want to do are still going to give me better model than BMI in categorical skew based on you know end of the day diet.

69
00:09:41,760 --> 00:09:53,730
That's the question we are trying to answer. And so we will tackle that that question in module, get to a diagnostic score for linear trend.

70
00:09:54,030 --> 00:10:07,230
But at this point, please understand that there may be situations where the categorical variable essentially is arising from an underlying.

71
00:10:08,820 --> 00:10:17,130
But that was originally excuse me, that was originally measured on up on delivery scale.

72
00:10:18,930 --> 00:10:34,770
One other example that I would like to give is there may be variables where the categories have some sort of an inherent order.

73
00:10:35,700 --> 00:10:43,710
And an example is, let's again state it's a categorical very well.

74
00:10:44,340 --> 00:10:48,990
You know, stage one, two, three, four are states local, regionally distant.

75
00:10:52,140 --> 00:11:03,900
But those categories definitely have an independent delivery in the sense that stage two has, you know, stage three has worst prognosis.

76
00:11:03,900 --> 00:11:10,710
Then stage three, a distant stage has water, hospital, more sustained, localized or regional disease.

77
00:11:11,040 --> 00:11:17,099
So definitely he didn't get into detail really. But it is different from something like these four.

78
00:11:17,100 --> 00:11:23,880
I thought, okay, so, so we are going to talk about variables like that.

79
00:11:25,140 --> 00:11:33,770
Okay. So now. Let's start with an example.

80
00:11:34,820 --> 00:11:44,660
Suppose I have a study that was designed to compare out-of-pocket health care expenditures among farmers,

81
00:11:45,920 --> 00:11:53,180
and I have a random sample of four farmers taken from each of three states Michigan, North Carolina and Wisconsin.

82
00:11:53,600 --> 00:11:58,280
A small study just just to show you an example of any equal 12.

83
00:11:59,990 --> 00:12:06,350
Yeah. And the question we are interested in is, is state associated with health care costs?

84
00:12:07,790 --> 00:12:12,590
In other words, I mean, health care costs of the three states any different?

85
00:12:13,970 --> 00:12:22,160
So my outcome is why? Which is the out-of-pocket healthcare costs.

86
00:12:22,160 --> 00:12:31,640
The cost for farmer I in dollars and the predicted have been there is only one predictor here is the state.

87
00:12:34,160 --> 00:12:41,809
So this is a nominal variable, nominal categorical variable with three categories.

88
00:12:41,810 --> 00:12:46,610
What are the three categories? The three categories are Michigan, North Carolina, Wisconsin.

89
00:12:48,110 --> 00:12:54,890
Okay. So now the question is, how do I represent these different states?

90
00:12:57,050 --> 00:13:09,950
So the first type of supporting scheme for this data that we are going to talk about is called reference self hoarding.

91
00:13:11,420 --> 00:13:15,130
And I just want to make sure it's recording.

92
00:13:15,140 --> 00:13:25,250
Yes, it is. So the first type of coding scheme that we are going to talk about is difference and hoarding.

93
00:13:25,700 --> 00:13:36,440
And suppose you have a categorical variable with key categories and the values are zero one, two minus one.

94
00:13:38,300 --> 00:13:41,840
So how do I represent that variable in a linear regression model?

95
00:13:42,170 --> 00:13:48,330
So basically what I do is I construct key minus one.

96
00:13:49,340 --> 00:13:56,450
These are called dummy variables, or sometimes also referred to as indicator variables of this form.

97
00:13:57,530 --> 00:14:08,330
So I define variables like this. X X1 is the indicator that subject I is in category one.

98
00:14:09,980 --> 00:14:21,500
So basically I give a value equal to one for all subjects that are in get one and zero.

99
00:14:21,500 --> 00:14:30,440
Otherwise x2 is the second dummy variable on indicated variable for subject in category two.

100
00:14:30,680 --> 00:14:41,210
And the way I define this is it gets a vertical on each subject within category two and zero on the box and, and so on.

101
00:14:42,930 --> 00:14:47,870
Did you have that big scale minus one D minus one?

102
00:14:47,870 --> 00:14:58,280
It got the I indicated B but so there that indicator gets the value one use subject is in capital

103
00:14:58,530 --> 00:15:07,939
minus one and zero otherwise and no one here I have the the the variable has p categories.

104
00:15:07,940 --> 00:15:14,990
There is also a zero value, but I have only did that factor in creating the indicator.

105
00:15:16,610 --> 00:15:24,080
So the only just category now in this case, category zero is called the reference group.

106
00:15:27,160 --> 00:15:31,000
There is nothing holy about zero.

107
00:15:31,480 --> 00:15:36,820
The value zero. That game I decided to make that a reference group.

108
00:15:36,820 --> 00:15:40,120
I could make the key minus one category.

109
00:15:40,120 --> 00:15:51,730
All says the reference group or even, you know, for some weird reason, the category one or category two as the reference group.

110
00:15:53,290 --> 00:16:03,070
But the bottom line is, you know, I could make any of these categories as the reference group,

111
00:16:03,520 --> 00:16:12,880
but if did have key values that are key categories that this variable can t values from,

112
00:16:13,330 --> 00:16:22,000
then i k minus one indicator variables are dummy variables by convention.

113
00:16:22,000 --> 00:16:29,860
Generally, I either make the first or the last category as the reference group that's just convention.

114
00:16:31,630 --> 00:16:41,320
So now let's stick MICHI. Let's take Wisconsin as the reference group in our study and think of the following two dummy variables for state.

115
00:16:41,320 --> 00:16:50,080
So the implied subscript i.e. denotes the indicator variable for the farm.

116
00:16:50,080 --> 00:16:56,440
Are I from Michigan? So farmers from Michigan get a value one.

117
00:16:56,950 --> 00:16:58,660
Everybody else gets zero.

118
00:17:01,330 --> 00:17:12,490
I get another dummy variable corresponding to the state of North Carolina and I and for farmers from North Carolina they get a one.

119
00:17:13,630 --> 00:17:21,850
Everybody is meaning the farmers from Michigan and Wisconsin get a zero for that NC variable.

120
00:17:23,500 --> 00:17:30,639
Everybody clear. Okay, so what have I done now?

121
00:17:30,640 --> 00:17:39,580
What I have done is I have for the for the study with farmers from these three states.

122
00:17:39,580 --> 00:17:45,340
So I have like the predictor is a categorical variable with three categories.

123
00:17:45,820 --> 00:17:59,020
Now I have created two dummy variables to indicator variables out of that predictor and I'm going to write the model in this fashion.

124
00:18:00,100 --> 00:18:03,900
So the reference cell coding refers to four.

125
00:18:04,060 --> 00:18:10,390
There is a reference group and I write the model as Y equal to nine.

126
00:18:10,600 --> 00:18:20,740
As you can see, I am writing the model not in terms of the variable with those three categories,

127
00:18:21,160 --> 00:18:27,910
but I'm writing the model in terms of the dummy variables or indicator variables that they created out of that.

128
00:18:28,630 --> 00:18:35,920
What do you know? Kathy What he does people and I write the model as Y equal to B garnered plus beta one

129
00:18:36,880 --> 00:18:44,290
indicator for Michigan plus beta two indicator for North Carolina plus the random error.

130
00:18:45,100 --> 00:18:49,540
So these two are the dummy variables that I created.

131
00:18:57,270 --> 00:19:05,850
Okay. So this looks like very much like the kind of models we've been talking about.

132
00:19:07,200 --> 00:19:11,610
Right. I mean, the the look of it is very familiar to you.

133
00:19:12,870 --> 00:19:23,280
So now let's look at the in the in the table below for each state.

134
00:19:23,820 --> 00:19:36,420
I am going to write the values of the indicator variables and then let's try to see what the mean cost would be based on the model that I just wrote.

135
00:19:36,450 --> 00:19:44,430
So for Wisconsin farmers from Wisconsin, what is the value of the import indicator?

136
00:19:46,470 --> 00:19:51,870
It's zero, right? Because they might indicate there or they might very well only get some value.

137
00:19:51,870 --> 00:19:55,050
One for farmers from Michigan, for everybody else, it's zero.

138
00:19:56,040 --> 00:19:59,099
So it's zero and similar.

139
00:19:59,100 --> 00:20:04,110
And also by the same logic for farmers from Wisconsin.

140
00:20:04,530 --> 00:20:09,800
The dummy variable indicator variable NC also takes the value zero.

141
00:20:10,830 --> 00:20:17,700
Everybody clear on this? It's by way of how I constructed the dummy variables.

142
00:20:19,080 --> 00:20:25,110
Yes. What about Michigan? Michigan, that is my indicator.

143
00:20:25,110 --> 00:20:30,150
Gets the value one and the NC indicator gets the value zero.

144
00:20:34,210 --> 00:20:44,110
And for the four farmers from North Carolina, the dummy variable am I gets the value zero and the dummy variable NC gets the value one.

145
00:20:48,730 --> 00:20:52,240
Yes. Everybody with me.

146
00:20:55,130 --> 00:21:01,490
Okay. So now first tell me this.

147
00:21:03,050 --> 00:21:08,930
And we do not happen to cheer and see people audition myself a little bit.

148
00:21:09,110 --> 00:21:13,700
Oh, you know. Be awkward.

149
00:21:15,160 --> 00:21:25,280
Okay, so let's first look at first tell me what the design matrix looks like here.

150
00:21:26,360 --> 00:21:29,989
Who wants to tell me? Here is my model. Who wants to tell me?

151
00:21:29,990 --> 00:21:40,350
What does the design matrix look like? How many tools will a design matrix have?

152
00:21:50,400 --> 00:21:53,640
I'm in and it's 12.

153
00:21:55,110 --> 00:22:00,419
Right. So I have 12 rules. What about the first column?

154
00:22:00,420 --> 00:22:05,159
The first column is all ones corresponding to the intercept.

155
00:22:05,160 --> 00:22:10,350
We do not. Okay. What about the second column?

156
00:22:18,180 --> 00:22:23,999
And suppose I have my, my, my it's my observations are lined up this way.

157
00:22:24,000 --> 00:22:32,520
Let's, let's, for example, do that. My observations are lined up, as, you know, the four farmers from Michigan first.

158
00:22:37,410 --> 00:22:40,840
And then I have the for four of them.

159
00:22:41,970 --> 00:22:45,190
And then I have Wisconsin, four of them total.

160
00:22:45,240 --> 00:22:51,420
I have to. So what would the second column look like?

161
00:22:55,190 --> 00:23:02,450
So you didn't start. It starts with four once and then the rest is four zero.

162
00:23:05,300 --> 00:23:10,070
Everybody see what like that is? Okay.

163
00:23:10,070 --> 00:23:19,580
What about the third column? Yes.

164
00:23:20,010 --> 00:23:24,050
Four zeros for once. And then another fourth is.

165
00:23:33,050 --> 00:23:37,670
Okay. That's the design.

166
00:23:38,060 --> 00:23:42,650
So now tell me, based on this model for me.

167
00:23:43,310 --> 00:23:48,920
And even now, we have explicitly, explicitly written the design matrix.

168
00:23:48,950 --> 00:23:55,760
What about the. Mm hmm. What is the mean cost for farmers from Michigan?

169
00:23:56,750 --> 00:24:00,020
A very poor farmer from Wisconsin based on this model.

170
00:24:05,670 --> 00:24:09,420
So this is the mean cost. Beta.

171
00:24:10,230 --> 00:24:18,600
Beta, not correct. Okay. What about mean cost for farmers from Michigan?

172
00:24:27,270 --> 00:24:30,880
Going to be ten hour plus we go on because everybody see that.

173
00:24:31,420 --> 00:24:40,540
What am I doing. I'm just plugging in a my indicator value equal to one in the model.

174
00:24:42,700 --> 00:24:46,990
Yes. What about farmers from North Carolina?

175
00:24:48,480 --> 00:24:52,250
Better last beat up to.

176
00:24:57,270 --> 00:25:05,110
Okay. Sophia, you have a question?

177
00:25:06,330 --> 00:25:12,060
Yeah. Very afraid if I introduce.

178
00:25:14,810 --> 00:25:20,540
Acres of land and the European sovereign.

179
00:25:21,410 --> 00:25:26,460
If you introduce me to try to use the various. How would the.

180
00:25:26,890 --> 00:25:31,390
Interpretations. We can't do that. So you're saying now that it's up to you?

181
00:25:31,750 --> 00:25:36,010
Yes, we got to that. Let's tackle the simpler models first.

182
00:25:36,280 --> 00:25:41,710
Okay. So now can you tell me the interpretation of the pattern of breakdown of BRCA1 and BRCA2?

183
00:25:51,430 --> 00:25:58,990
What is the interpretation of the barometer? Better health is easy, right?

184
00:25:59,400 --> 00:26:03,880
Better not. Is the average healthcare cost for farmers in Wisconsin.

185
00:26:22,280 --> 00:26:33,160
What is the one? Can you please speak up a bit loudly so that everyone can hear the difference in the prospects for.

186
00:26:34,710 --> 00:26:37,710
For Michigan. Wisconsin. Yes.

187
00:26:37,980 --> 00:26:54,150
So now do you see how the interpretation of Beethoven kind of is different than the the sort of interpretations we were talking about previously in,

188
00:26:54,180 --> 00:26:57,690
you know, kind of the models we consider most familiar.

189
00:26:58,560 --> 00:27:13,170
So then here Beethoven is the difference in average cost between farmers in Michigan and Wisconsin.

190
00:27:29,600 --> 00:27:34,890
And what is better to return to is the same.

191
00:27:34,910 --> 00:27:50,210
It's again, the difference in average health care costs between farmers from just a minute for North Carolina versus Wisconsin farmers.

192
00:27:56,220 --> 00:28:00,960
Now. Do you see why I see that Wisconsin is the reference group?

193
00:28:01,620 --> 00:28:08,070
Because my comparisons are with respect to Wisconsin farmers.

194
00:28:09,540 --> 00:28:16,320
So that's where this scheme gets the name reference and hoarding.

195
00:28:18,720 --> 00:28:31,680
And this kind of sporting scheme for categorical covariates is the most commonly used because it lends itself to a very nice and easy interpretation.

196
00:28:32,430 --> 00:28:42,329
Last Model 15 also becomes, you know, very much like you can use the all of the machinery,

197
00:28:42,330 --> 00:28:49,770
everything that you learned so far, and you can directly apply it to the reference set of 14.

198
00:28:50,790 --> 00:28:54,060
Yes. Question. So here in our interpretation.

199
00:28:54,740 --> 00:28:59,310
It's average. We also say average. You get on to the average difference.

200
00:28:59,360 --> 00:29:05,210
So remember difference in to means is basically.

201
00:29:08,390 --> 00:29:15,890
You are basically taking defensive buildings. Is equal to the mean of the differences.

202
00:29:20,770 --> 00:29:31,839
So yes, you can either say difference in average healthcare costs or average difference in health care costs between Michigan and Wisconsin,

203
00:29:31,840 --> 00:29:35,740
farmers between North Carolina and Wisconsin for everybody.

204
00:29:35,920 --> 00:29:39,010
Clear why this is called a reference self-loading and why.

205
00:29:42,100 --> 00:29:49,930
Yes. Question why did have. Why do they migrate to?

206
00:29:57,460 --> 00:30:00,460
Okay. So why do we need to make one group reference?

207
00:30:00,760 --> 00:30:04,450
You are not asking like why you did we meet responsible, right?

208
00:30:04,780 --> 00:30:08,920
Yeah. So everybody understand? That's a very good question.

209
00:30:09,290 --> 00:30:16,780
Let me come to that. But if you want to understand that we group, we make reference, does it matter?

210
00:30:18,130 --> 00:30:21,190
We could have a big Michigan reference on an off like reference.

211
00:30:21,190 --> 00:30:26,350
That doesn't matter. But we have to meet one group, a reference group.

212
00:30:27,040 --> 00:30:37,710
And the question is, why do we need to do that? And here is tensor.

213
00:30:38,640 --> 00:30:50,640
So in other words, let's say we create dummy variables for all the three states for Michigan,

214
00:30:50,640 --> 00:30:58,620
Wisconsin, North Carolina, and we write this model in terms of all three of those.

215
00:31:03,020 --> 00:31:06,680
Actually it was coming my two flights down.

216
00:31:07,580 --> 00:31:13,010
Maybe since you asked that before, let me go to that slide first and then I'll come back to the previous one.

217
00:31:13,400 --> 00:31:24,860
So if we made a dummy readable out of Michigan, Wisconsin, North Carolina, and we fitted the model like this,

218
00:31:24,860 --> 00:31:31,610
I'm not going to for you because I want you to you will be able to give the answer back to your self.

219
00:31:31,610 --> 00:31:35,569
And I want to do that exercise. So let's say we wrote the model this.

220
00:31:35,570 --> 00:31:47,899
We get to see the model. So I did as we're able to to not last the one times they indicated for Michigan Ledbetter two time

221
00:31:47,900 --> 00:31:53,450
thing you get it for Wisconsin plus bitter or bitter two times indicator for North Carolina.

222
00:31:53,450 --> 00:31:58,730
Bitter, bitter and indicative of Wisconsin. Plus it's in effect let's add this is this is the model.

223
00:31:59,300 --> 00:32:04,280
So why do we need to create one reference group?

224
00:32:04,280 --> 00:32:11,840
Why can't we simply create down variables for all three and put them in the model and both with this model.

225
00:32:14,810 --> 00:32:18,620
Yeah. So you have the answer, right.

226
00:32:18,620 --> 00:32:24,440
Yes. But let me let me try to motivate the answer from everyone in the class.

227
00:32:24,860 --> 00:32:31,370
So now can you write the design me for this model.

228
00:32:35,510 --> 00:32:44,600
Just as we did in the previous slide. So the design metrics, again, we have how many rows, whirlpools, how many colons we need to have now?

229
00:32:45,710 --> 00:32:50,360
Four points. Great. What is the eighth step along the boundary?

230
00:32:50,360 --> 00:32:59,630
So I have the first column is the column of ones. The second column will be the fourth four would be one.

231
00:32:59,840 --> 00:33:06,920
Then the next eight would be zero. The third column would be the first four will be zero.

232
00:33:08,080 --> 00:33:15,050
I'm talking slowly, but I want you to hear me first before I show you the design which picks the.

233
00:33:15,950 --> 00:33:19,670
The third point will be the first four is going to be zero.

234
00:33:20,600 --> 00:33:26,690
The second form will be one corresponding to the finalists from North Carolina, and then the last four will be zero again.

235
00:33:27,890 --> 00:33:32,010
And the last column of the fourth column would be the fourth.

236
00:33:32,030 --> 00:33:39,050
It will be zero, and the last four will be one corresponding to farmers from Wisconsin.

237
00:33:42,100 --> 00:33:46,420
So here is how the design matrix will look.

238
00:33:51,210 --> 00:34:01,720
Okay. So each category is represented in the model, along with an intercept, just, you know, like our bread and butter division.

239
00:34:02,770 --> 00:34:05,890
Consider the design metrics on the right hand side.

240
00:34:05,980 --> 00:34:11,320
The subjects are ordered by alphabetically and by state. So now standard is design matrix.

241
00:34:11,320 --> 00:34:20,980
And I want to and I want you to add those like I saw some oh now see who wants to volunteer and.

242
00:34:21,610 --> 00:34:24,670
Yes, go ahead. Oh, you want to be boring.

243
00:34:26,330 --> 00:34:31,170
The first column was. A combination. Exactly.

244
00:34:31,560 --> 00:34:37,140
Then they really did see that. That station.

245
00:34:39,060 --> 00:34:43,799
So this would be sorry.

246
00:34:43,800 --> 00:34:53,550
I did not allow you to answer the question question at the time, because I want to give you a second state and then everybody to go, oh, now I see.

247
00:34:53,550 --> 00:35:03,600
Like. So that's the reason this would become a less than full blown design matrix.

248
00:35:03,600 --> 00:35:10,530
And we all know that it's less than full, then I won't be able to involve this extraneous matrix,

249
00:35:11,070 --> 00:35:17,880
and so I can all get unique solutions to be that I want to be exactly.

250
00:35:18,270 --> 00:35:23,339
Speaker three And guess what, as, as, as a, as a,

251
00:35:23,340 --> 00:35:35,610
as a sort of a nice deal to work problem shy in our process for to go to use in fitting this module would be indicators for me if you go to Wisconsin,

252
00:35:35,610 --> 00:35:43,730
North Carolina and I would be interested model and see what you did SAS will give you a warning sign.

253
00:35:43,770 --> 00:35:48,750
Hey, three, three. Then I would say singular make six.

254
00:35:50,610 --> 00:35:56,870
So that's what is going on. That's why you. A reference.

255
00:35:58,180 --> 00:36:02,050
Okay. Makes sense. Isn't math beautiful?

256
00:36:04,920 --> 00:36:07,990
Oh, so. So that's that's the issue.

257
00:36:08,260 --> 00:36:16,060
So now let me go back and. But thank you for asking that question.

258
00:36:16,630 --> 00:36:22,120
I'm glad you sort of. So now let's go back to the correct model.

259
00:36:22,420 --> 00:36:28,560
So we have for the variable with three categories.

260
00:36:28,570 --> 00:36:38,920
Now, I have made Wisconsin the reference group and I am fitting the model with indicated dummy variables for Michigan and North Carolina.

261
00:36:39,460 --> 00:36:46,000
And the question that I'm asking is, is the expenditure different across states?

262
00:36:46,240 --> 00:36:53,590
So the null hypothesis is that there is no difference in the group means based on the interpretation.

263
00:36:53,710 --> 00:37:00,210
For me to not be to want and be to do that you provided you gave in the previous slide.

264
00:37:00,220 --> 00:37:07,390
Can you tell me formally how to write this null hypothesis in terms of the parameters of this model?

265
00:37:10,320 --> 00:37:15,120
What would the null hypothesis?

266
00:37:20,230 --> 00:37:32,350
Did you still? Yes.

267
00:37:32,470 --> 00:37:35,780
We do want equal to be equal to zero. Right.

268
00:37:39,190 --> 00:37:47,070
And the alternative is that at least one or both different from zero.

269
00:37:47,170 --> 00:37:53,420
Some want to write it as not. It's not. Okay.

270
00:37:53,960 --> 00:37:57,830
Can you construct the the test statistic for this?

271
00:38:02,120 --> 00:38:05,900
It's a part of that? Yes, partially. How would you rate it?

272
00:38:06,230 --> 00:38:10,580
So this is the if this LA just as in our bread and butter depression.

273
00:38:12,240 --> 00:38:16,170
The extra six years for 51 years.

274
00:38:16,210 --> 00:38:21,110
Yes. I mean square. You haven't completed the whole thing is extra.

275
00:38:21,110 --> 00:38:24,890
Someone's got to be the one in bitter to give in.

276
00:38:25,310 --> 00:38:29,670
Made it even better not was already in the model and then to find.

277
00:38:31,610 --> 00:38:37,249
Do I have something else in the numerator divided by two?

278
00:38:37,250 --> 00:38:44,300
Because I have two extra barometers in the model under the alternative, right?

279
00:38:44,370 --> 00:38:48,870
Yes. Yes. And exactly.

280
00:38:49,070 --> 00:38:54,110
You may see from the model we better not be the one with the to the full model.

281
00:38:54,770 --> 00:38:59,900
That's two and that's distributed as F two.

282
00:39:01,620 --> 00:39:06,380
Minus and minus three. Yes.

283
00:39:09,580 --> 00:39:15,970
So while I am undone, I can. I can test this hypothesis of no difference in the good things.

284
00:39:18,530 --> 00:39:21,550
Okay. All good.

285
00:39:23,920 --> 00:39:32,200
So now we already convinced you, or you convinced yourself that we cannot use game dummy variables again.

286
00:39:32,200 --> 00:39:42,130
Game ticket, and really both. We have to fix one group as a reference because otherwise we get less than full and design means so.

287
00:39:43,170 --> 00:39:50,469
So this problem with this design matrix and you know, like the, the best way to deal with it is the difference.

288
00:39:50,470 --> 00:40:05,290
And 40. However, there is another alternative approach for solving this less than full design matrix problem.

289
00:40:06,070 --> 00:40:16,150
There's in and out of the 14 scheme that is used and this is an effort to SL means for me.

290
00:40:17,800 --> 00:40:30,040
And bottom line is what you do is you basically eliminate the intercept you Don because as you can see that if you eliminate the intercept,

291
00:40:30,250 --> 00:40:40,720
the design matrix now becomes, you know, the indicator for Michigan, the indicator for North Carolina, the indicator for Wisconsin.

292
00:40:40,960 --> 00:40:51,490
And you have a 12 cross three matrix and the problems of the design matrix are linearly independent.

293
00:40:53,650 --> 00:41:00,490
Yes. There's no issue with less than four.

294
00:41:00,500 --> 00:41:03,520
Right. And interestingly,

295
00:41:03,520 --> 00:41:12,520
I'm also going to point out one other thing before we move to the interpretation is if you add these three columns, what do you get?

296
00:41:14,080 --> 00:41:25,600
You get the column of one, one, one, one, all two. So basically these three columns spans or this design, it expands the column of ones.

297
00:41:33,260 --> 00:41:38,630
Okay. So that's just something to keep in mind.

298
00:41:38,960 --> 00:41:46,520
So now the model that you are fighting, I mean, when I say spends the column of funds,

299
00:41:46,520 --> 00:41:53,630
basically what I'm saying is that the if you take the linear combination of these three columns,

300
00:41:53,990 --> 00:41:58,130
then it kind of gives you the column corresponding to the intercept.

301
00:41:58,460 --> 00:42:10,520
So now the model is meta one y equal to the one times the dummy variable for Michigan plus beta, two times the dummy variable for North Carolina.

302
00:42:10,520 --> 00:42:14,480
Plus we got three times the dummy variable for Wisconsin plus the landowner.

303
00:42:16,700 --> 00:42:23,450
Can you based on this model now, can you tell me what the interpretation of the parameters are?

304
00:42:36,310 --> 00:42:41,080
What are the interpretation of the end of this? I mean, the interpretation here is easier.

305
00:42:43,300 --> 00:42:46,300
Yes, just exactly.

306
00:42:46,300 --> 00:42:53,470
It's just better. What is the average cost for Michigan farmers?

307
00:42:56,980 --> 00:43:08,530
Beta two is the average cause for NC farmers and beta three as the average cost for Wisconsin farmers.

308
00:43:10,940 --> 00:43:25,310
Yes. If I wanted to find out the difference in expenditures comparing farmers to from Michigan to Wisconsin, what do I have to do?

309
00:43:26,330 --> 00:43:29,629
I have to say subtract Habitat Street from Beethoven.

310
00:43:29,630 --> 00:43:37,130
So be doing minus three would be the difference in Boston for Michigan versus Wisconsin farmers.

311
00:43:38,180 --> 00:43:45,410
Better to minus because he would be the difference in loss for North Carolina versus Wisconsin farmers.

312
00:43:45,560 --> 00:43:53,840
So the subtracting the coefficients now will give us comparisons between the different states.

313
00:43:54,860 --> 00:44:02,420
Okay. What about hypothesis testing?

314
00:44:04,130 --> 00:44:08,720
So again, the same model under the cell means for me.

315
00:44:08,840 --> 00:44:16,250
Now I'm interested in testing that same question that there is no difference.

316
00:44:16,280 --> 00:44:21,560
The null hypothesis is that there is no difference in expenditures across states.

317
00:44:22,820 --> 00:44:32,990
So formally in terms of the parameters, how can I try the null hypothesis?

318
00:44:41,550 --> 00:44:44,550
Yes. So everybody heard that answer.

319
00:44:45,120 --> 00:44:48,180
BIEDERMAN Equal to beta. Equal to beta three.

320
00:44:49,680 --> 00:45:00,490
That saved no zero zero because they can be five and all three plus they're going to be ten, all three plus.

321
00:45:00,510 --> 00:45:06,750
So it's the null hypothesis is beta one equal to beta two?

322
00:45:07,860 --> 00:45:25,480
Equal to three. And the alternative is at least one pair is different based on non-biodegradable.

323
00:45:30,020 --> 00:45:40,250
Or veto on not equal to maybe three or better who's not equal to with that.

324
00:45:43,680 --> 00:45:47,850
In the same way. My age.

325
00:45:51,420 --> 00:45:56,730
Yes. Yes, we can do that. But we'll have to wait.

326
00:46:00,990 --> 00:46:01,950
So, no,

327
00:46:03,180 --> 00:46:21,030
I want to just look at this null hypothesis and realize that we don't know how to best how to construct a statistic for this general null hypothesis.

328
00:46:23,320 --> 00:46:34,270
Yet because they said, you know, bigger and bigger and bigger three would be equal in many different ways.

329
00:46:35,800 --> 00:46:40,720
They all can be 5 billion and then they're all going to be the old ten and whatever.

330
00:46:42,700 --> 00:46:48,760
So there are many different ways in which this knowledge can be satisfied.

331
00:46:49,660 --> 00:46:55,300
This is called a general linear hypothesis DL age,

332
00:46:56,380 --> 00:47:08,800
and we are going to talk about how to construct the test of this state for this general linear hypothesis in module g.

333
00:47:09,370 --> 00:47:19,050
So you'll have to wait till then. And exactly as you mentioned that, you know, you will see that we will have one star like in module G,

334
00:47:19,070 --> 00:47:26,950
this sort of what they like to be the one minus VW Y, you know, because these are all on one tasks.

335
00:47:27,460 --> 00:47:33,190
So we will talk about cyber as being easily constructing this contrast and talk about a

336
00:47:33,190 --> 00:47:41,269
framework very thin form struck up their statistic for these general linear hypotheses.

337
00:47:41,270 --> 00:47:55,750
So the DNA refers to general linear hypothesis, and we will construct a statistic under back hypothesis in module two.

338
00:48:05,060 --> 00:48:09,370
Yeah. So for now, I want you to appreciate that.

339
00:48:10,200 --> 00:48:24,900
Although there exists another protein constructing or creating another different hoarding scheme under less than full ramp design scenario.

340
00:48:25,680 --> 00:48:35,579
But we are not there yet in how to construct a test of this did for this hypothesis and for other

341
00:48:35,580 --> 00:48:40,350
reasons also from an interpretation part of the reference self building is is very popular.

342
00:48:40,350 --> 00:48:43,380
It's very commonly used in the literature. Okay.

343
00:48:46,470 --> 00:48:52,170
Couple more points and then we'll take a break. So there is one other option.

344
00:48:53,760 --> 00:49:05,940
And this is essentially the way that you are transforming the these three categories

345
00:49:05,940 --> 00:49:12,389
or this variable with three categories in two up quantitative covariates.

346
00:49:12,390 --> 00:49:16,230
So you kind of you give us call.

347
00:49:18,550 --> 00:49:24,510
And at this point for the speed variable, this score is somewhat arbitrary,

348
00:49:26,490 --> 00:49:35,790
but you give this score so Michigan gets a value one, North Carolina gets a value two, Wisconsin gets a value three,

349
00:49:36,930 --> 00:49:43,649
anything for the states as follows And then you basically fit this model Y equal to weight are not does

350
00:49:43,650 --> 00:49:51,060
beta one times is I would say corresponds to the scores that you assign for the states plus epsilon nine.

351
00:49:52,590 --> 00:50:04,079
So what happens here then because you have converted the categorical really appealing to a quantitative really will be the fourth you

352
00:50:04,080 --> 00:50:19,830
are using not only one degree of freedom to estimate beta one right imagine race ethnicity if you have five categories white America,

353
00:50:19,860 --> 00:50:26,050
non-Hispanic whites, Hispanics, African-Americans, Asians, Pacific Islanders.

354
00:50:27,720 --> 00:50:33,980
So you have five categories. And so if you believe the sort of the in the reference set,

355
00:50:33,990 --> 00:50:39,750
accordingly you would have to estimate for you would construct for W with you both and

356
00:50:39,750 --> 00:50:45,330
you would have to estimate four plus one for the implicit guarantee just in the model.

357
00:50:46,620 --> 00:50:54,239
If you assign scores to those five categories of race, one, two, three, four, five, then you want to estimate,

358
00:50:54,240 --> 00:51:00,360
you want me to present this like the intercept and the beta one corresponding to this score.

359
00:51:01,590 --> 00:51:11,190
So you have, you have much more power to do it, eating up less degrees of freedom and you are estimating less number of parameters.

360
00:51:12,150 --> 00:51:17,370
However, there is a limitation of this approach and what are the limitations like?

361
00:51:17,880 --> 00:51:21,630
The first thing is, you know, in the case of Steve, I mean,

362
00:51:22,230 --> 00:51:29,220
what does it mean to give a sport of one to Michigan, to North Carolina, three to Wisconsin?

363
00:51:29,550 --> 00:51:38,879
It's meaningless, though. And who tells me that the scores couldn't be like Wisconsin one, Michigan, two, North Carolina three?

364
00:51:38,880 --> 00:51:46,320
All what about like Michigan one, Wisconsin, ten, North Carolina handed?

365
00:51:46,830 --> 00:51:54,510
I mean, there is actually I mean, total arbitrariness in how we are giving that final discourse.

366
00:51:56,040 --> 00:51:59,519
So when we assign the scores, they have to be well justified.

367
00:51:59,520 --> 00:52:03,239
And clearly, I mean, I can find the justification.

368
00:52:03,240 --> 00:52:12,209
Yeah, that's number one. Number two is that by explaining this forces 1 to 3, I mean,

369
00:52:12,210 --> 00:52:18,930
implicitly what we are imposing is that there is the equal spacing between and doesn't

370
00:52:18,930 --> 00:52:26,850
get with this one sitting here is completely feels like the spacing is one you need.

371
00:52:26,850 --> 00:52:35,270
But what does it mean to talk about the spacing between Michigan and Wisconsin, Michigan and North Carolina and so on and so?

372
00:52:35,810 --> 00:52:46,080
So it's sort of like this is an option, but because severe limitations, especially when the variable is dominant.

373
00:52:47,520 --> 00:52:50,790
On the other hand, if it's like, remember I was talking about cancer,

374
00:52:50,790 --> 00:52:57,870
states make a categorical variable, but as simply put it, reality stage one, two, three, four.

375
00:52:58,260 --> 00:53:03,910
The state is justified using this form mechanism and you know.

376
00:53:04,210 --> 00:53:09,760
Creating a model like with just one word Christian corresponding to discourse.

377
00:53:10,240 --> 00:53:19,149
Although there also there could be arguments that would ensue that states do versus states.

378
00:53:19,150 --> 00:53:31,629
One is equally bad states versus states do or states for versus states who go to that state.

379
00:53:31,630 --> 00:53:41,280
School boards of states, one that's one week spacing and stage four versus states one is three times more.

380
00:53:41,300 --> 00:53:45,610
That space, it might be 1015.

381
00:53:45,610 --> 00:53:50,020
Densmore was stage four versus stage one.

382
00:53:50,260 --> 00:54:03,010
So so there are two. There could be an argument about the spacing and ordering between the categories who never know of that could be pretty,

383
00:54:03,010 --> 00:54:06,280
but still one would just keep 540.

384
00:54:08,130 --> 00:54:19,650
And so bottom line is sometimes we believe this, but please take it with a lot of grain of salt because the thought would be why doesn't.

385
00:54:22,050 --> 00:54:26,220
If you are in this category for 30.

386
00:54:31,130 --> 00:54:34,640
Yeah. Here we are not assigning a difference.

387
00:54:34,640 --> 00:54:41,090
We are just using like scores, even numbers to these categories.

388
00:54:41,090 --> 00:54:50,810
Now made up categories like hair color, eye color brown gets one, black gets to blond gets three.

389
00:54:51,260 --> 00:54:54,740
So you are giving numbers to this phenomenon. You get into this.

390
00:54:57,640 --> 00:55:00,760
We have kind of moved away from the reference point.

391
00:55:01,870 --> 00:55:05,140
Any other questions? Okay.

392
00:55:05,290 --> 00:55:09,400
So so again, like I said, please understand that.

393
00:55:10,210 --> 00:55:16,090
So now, although we can use the sports as the predictors, but the sports can be quite arbitrary.

394
00:55:16,510 --> 00:55:21,700
And in this case, like I said, that is it almost it doesn't make sense.

395
00:55:23,020 --> 00:55:28,390
So you have to be cognizant of that fact.

396
00:55:28,770 --> 00:55:34,090
And basically so I think.

397
00:55:38,180 --> 00:55:46,670
Let's see. So so let's talk about this and then we'll take a break.

398
00:55:47,840 --> 00:55:52,040
Suppose you have ordinal categories and you fit this model.

399
00:55:52,490 --> 00:55:58,459
Why are you going to be to not be the one to say plus epsilon nine then couple?

400
00:55:58,460 --> 00:56:02,540
Do you want to examine the relationship between health care cost and income level?

401
00:56:03,530 --> 00:56:10,370
So income level, the three categories are low, medium, high and low to lowest 10 to 28.

402
00:56:10,910 --> 00:56:14,360
Medium is 20 to 30 and high is greater than 32.

403
00:56:17,120 --> 00:56:25,609
So all of those those definitions don't meet meaning in the current sort of context.

404
00:56:25,610 --> 00:56:27,170
But, but let's say those are,

405
00:56:27,440 --> 00:56:39,470
those are my three categories and I give us all of the first sporting scheme gives a score of 1 to 3 to low, medium high respectively.

406
00:56:39,800 --> 00:56:47,510
And the second scoring scheme gives value 1 to 5 for the low, medium and high categories.

407
00:56:48,230 --> 00:56:51,410
So and under both models.

408
00:56:52,070 --> 00:57:00,620
So one good thing about this single variable is it's like the cancer state example I was giving that there is some inherent ordering.

409
00:57:01,340 --> 00:57:18,790
So that would be. What about the spacing?

410
00:57:20,890 --> 00:57:32,320
The spacing? I'm not sure. I mean, the low medium is it's kind of okay to space the space, but the high above 30 gig is a huge audience.

411
00:57:32,320 --> 00:57:37,060
So once again, you know, the ordering of the spacing may not be preserved.

412
00:57:37,630 --> 00:57:48,130
You would under board scale, so you would fit this Model Y equal to better or not plus beta one times the size plus epsilon

413
00:57:48,130 --> 00:57:54,940
I and but the question is what information or inference can you get from this great one?

414
00:57:56,560 --> 00:58:02,860
So one thing that I would argue is that definitely in, in in such a context,

415
00:58:02,860 --> 00:58:16,149
when you are using sports and assigning quantitative values to the categorical variable, it's more the sign of the beta.

416
00:58:16,150 --> 00:58:21,040
One coefficient is more informative than the value of Plato one.

417
00:58:24,170 --> 00:58:38,180
Okay. This can be interpreted. As the friend.

418
00:58:42,210 --> 00:58:55,830
Between the predictor and the outcome. What do I mean by that?

419
00:58:55,860 --> 00:59:00,740
So basically the sign of Beethoven is he does.

420
00:59:03,000 --> 00:59:21,330
Does it get cost increases with increasing outcome or does his cost decrease with increasing income based on whether Bitcoin is positive or negative?

421
00:59:22,590 --> 00:59:25,590
So definitely this kind of Bitcoin is information.

422
00:59:25,590 --> 00:59:33,810
Is there a positive association between the outcome in the predictor and the space between expenditure and income?

423
00:59:34,950 --> 00:59:41,460
Or is it a neighborhood association? However, yeah.

424
00:59:42,480 --> 00:59:54,780
Like the value of Beethoven by itself probably doesn't make a whole lot of sense because the,

425
00:59:54,780 --> 01:00:03,240
the, the, the values that we assign or the scores that we assign can in fact,

426
01:00:04,080 --> 01:00:17,250
the, the one more efficient and so forth say that the absolute value of Beethoven may not be as meaningful.

427
01:00:18,030 --> 01:00:23,649
We can still test for low linear trend versus.

428
01:00:23,650 --> 01:00:32,400
So there is a linear trend by testing the null hypothesis that Beethoven equal to zero versus Beethoven not equal to zero,

429
01:00:34,320 --> 01:00:45,480
but it's really the sign and less of the absolute value of Beethoven that would be informative in this context.

430
01:00:45,510 --> 01:00:57,839
And, and once again, you have to be cautious about interpretation since the beta one estimate for Beethoven itself would be dependent on the score.

431
01:00:57,840 --> 01:01:02,580
Well, then the test statistic will also depend on the scores chosen.

432
01:01:02,970 --> 01:01:10,830
So with that, I wanted to show you this other approach of getting rid of, you know,

433
01:01:10,830 --> 01:01:19,440
converting a categorical variable into a continuous predictor by assigning scores and running the model like my bread and butter regression.

434
01:01:20,460 --> 01:01:32,970
But now I want you to be aware that there are these limitations and not all of these really makes sense to assign scores to a categorical variable.

435
01:01:32,970 --> 01:01:39,120
There may be situations, but like here, you know, because there is an inherent ordering in the income.

436
01:01:39,120 --> 01:01:51,840
So, you know, giving a quantitative score might make sense, but you have to understand that the values that you assign can make a difference.

437
01:01:52,560 --> 01:01:59,850
And there's a homework problem that you have even. But we are actually going to ask you to convince yourself through an exercise,

438
01:01:59,850 --> 01:02:06,659
exercise where you assign different scores to the same underlying categories,

439
01:02:06,660 --> 01:02:20,480
values, and see how the results change in terms of the statistics on the side of freedom on sort of stays the same but the best value.

440
01:02:21,240 --> 01:02:31,530
So I'm going to stop here. I know I spent more than an hour today, but I was trying to find a nice place to stop me.

441
01:02:31,760 --> 01:02:36,720
The got here, take a break and come back at my drink if you had a question.

442
01:02:39,620 --> 01:02:43,340
Just in the last few years, I have heard of a school.

443
01:02:45,060 --> 01:02:48,970
Physical activity can make it.

444
01:02:55,490 --> 01:02:58,850
Apparently people like me the media.

445
01:02:58,850 --> 01:03:05,960
And so I just thought that goes for the trade does pretty well.

446
01:03:06,620 --> 01:03:15,840
Yeah. Yeah. So you are saying like instead of the school says one, two, three, assign, let's say the median in the first category.

447
01:03:16,070 --> 01:03:19,670
I'm just making it up like 12. Right.

448
01:03:20,210 --> 01:03:24,050
And the second one, it's 2040.

449
01:03:24,800 --> 01:03:28,610
So you assign the median? Yes.

450
01:03:29,570 --> 01:03:40,600
So do you think the school values, you will see how that means and that's precisely what problems that and it's kind of a Do-It-Yourself DIY

451
01:03:40,610 --> 01:03:49,669
guidebook that you see like how and that's the problem and that's the limitation with this reporting approach.

452
01:03:49,670 --> 01:03:58,340
Because what you assign to schools does in fact the, the, the test.

453
01:04:00,970 --> 01:04:06,790
So. So you have to be like cautious about the interpretation.

454
01:04:07,210 --> 01:04:15,070
And I mean, in this in a scenario like this, the most informative is the sign of a that one.

455
01:04:18,060 --> 01:04:22,170
People still do the best of friend.

456
01:04:22,890 --> 01:04:26,980
Assuming that the sports make sense and this is a B, get them.

457
01:04:28,170 --> 01:04:33,990
If you mean that the sports make sense. You can run a desk for a linear trend.

458
01:04:34,920 --> 01:04:39,159
Just, you know, using our simplest bread and butter reference framework.

459
01:04:39,160 --> 01:04:47,430
We don't want to be pseudo synonymous with the donut because you know what the big assumption is that the sports make sense.

460
01:04:50,480 --> 01:04:57,160
Okay. So let's take a break for 10 minutes, okay.

461
01:04:57,210 --> 01:05:30,010
We'll come back at 925. That's.

462
01:05:49,500 --> 01:05:53,040
Keeping you up to speed.

463
01:05:53,460 --> 01:06:35,050
Okay. Thank you. You.

464
01:10:07,340 --> 01:13:45,950
It's. Okay.

465
01:13:48,950 --> 01:14:06,280
Everybody back. So now.

466
01:14:12,540 --> 01:14:23,600
Now, I think the next topic that we're going to talk about actually pertains to your question.

467
01:14:23,630 --> 01:14:35,430
So, um, so suppose I have another cool video.

468
01:14:36,510 --> 01:14:46,350
So this was your question. Suppose I bring in another pool of farmers age in years.

469
01:14:46,680 --> 01:14:53,100
Suppose that I also have information on that and I want to reconsider this previous

470
01:14:53,100 --> 01:14:58,510
problem regarding out-of-pocket healthcare costs for farmers from three different states.

471
01:14:58,530 --> 01:15:03,390
But I would bring in the additional four biggest farmers age into the market.

472
01:15:04,260 --> 01:15:15,989
So we are going to go back to the reference cell for me because that we saw lends itself to a pretty easy, clean, nice interpretation.

473
01:15:15,990 --> 01:15:21,570
And also the Model 15 is so that we can pretty much use the same machinery as before.

474
01:15:22,560 --> 01:15:30,120
So I have the following model y equal to be tannock plus beta one times the

475
01:15:30,540 --> 01:15:37,410
indicator form Michigan plus beta two times the indicator for North Carolina.

476
01:15:38,910 --> 01:15:45,360
Now I have beta three times eight plus epsilon eight error.

477
01:15:47,250 --> 01:15:56,790
So this model is also in the literature referred to as an for VAR or analysis of full variance model.

478
01:15:56,790 --> 01:16:01,680
And for Y. You may have heard this terminology. So you have got ANOVA.

479
01:16:02,790 --> 01:16:12,030
ANOVA is analysis of variance. You have seen it like in our context, regression context where we are partitioning the total sum of squares,

480
01:16:12,330 --> 01:16:17,510
the into the regression model, time of birth and the residual sample squares.

481
01:16:17,520 --> 01:16:27,530
And we wrote the nice end of what table showing the partitioning of the sum squares and the degrees of freedom and how we want to test that.

482
01:16:27,600 --> 01:16:36,810
And what also is referred to as slope model that basically you have groups.

483
01:16:37,170 --> 01:16:40,920
It's it's a it's a generalization of the T test.

484
01:16:40,920 --> 01:16:52,319
And that is to compare the means of two groups like you need a standard like, I don't know, like step by step on the one leg.

485
01:16:52,320 --> 01:16:59,280
And that about figures in the framework of some comparing to a means from two groups.

486
01:17:00,150 --> 01:17:03,780
Any problem you talked about, Anna, was an extension of the T test.

487
01:17:03,780 --> 01:17:10,820
When you compare group means and maybe you have four groups, five groups and so on.

488
01:17:12,840 --> 01:17:22,230
So if I did not have this part, if I did not have.

489
01:17:27,160 --> 01:17:38,440
This. If I only had the indicators for Michigan and North Carolina in the model, I think of it like a regression model.

490
01:17:38,830 --> 01:17:45,580
Actually, that is that is a depression model, representation of an annual heart problem.

491
01:17:45,820 --> 01:17:54,100
Why? Because you are comparing out-of-pocket costs for farmers from Michigan, North Carolina, Wisconsin.

492
01:17:54,100 --> 01:17:59,610
You are comparing means of three groups. So it's a regression model.

493
01:18:00,070 --> 01:18:11,440
The presentation of the nanobot problem. If I did not have that age here, I have a mix of categorical,

494
01:18:11,620 --> 01:18:18,159
covariance and continuous coping with the categories that we need to be represented by these dummy variables.

495
01:18:18,160 --> 01:18:21,700
But I also have the additional continuous IDs.

496
01:18:22,360 --> 01:18:30,190
So this module is referred to as an GOLDBACH analysis of all variants.

497
01:18:31,390 --> 01:18:41,530
Sometimes we give strange names, but that it's it's an item for one model and this is a regression model representation of an equal back.

498
01:18:41,860 --> 01:18:55,990
So here these are dummy variables four corresponding to corresponding to a categorical covariate.

499
01:19:07,000 --> 01:19:13,600
And this baby at the age. This is basically a continuous quality.

500
01:19:22,740 --> 01:19:34,840
Okay. So. So that's the end of the woman.

501
01:19:35,590 --> 01:19:39,910
So now what is the interpretation of bigotry?

502
01:19:40,660 --> 01:19:48,090
The definition of bigotry is, is the mean genes in health care costs far increasing.

503
01:19:48,100 --> 01:19:53,470
It is conceivable, both for parents far less in the same state.

504
01:19:54,580 --> 01:19:59,800
And just add more quotations from that just in of interpretation.

505
01:20:01,420 --> 01:20:06,850
So it's that's the interpretation I just did for state.

506
01:20:08,620 --> 01:20:13,150
So that is the interpretation for data three.

507
01:20:14,150 --> 01:20:23,680
No, let's let's look at this hypothesis test.

508
01:20:23,680 --> 01:20:37,570
Suppose I want to test in the ankle one model that is there a difference in cost across states after adjusting for each

509
01:20:37,930 --> 01:20:51,729
then formally how do I write the null hypothesis and the null hypothesis is still going to be non it said tested for AIDS,

510
01:20:51,730 --> 01:20:54,940
but it's going to be same as between equal to beta two.

511
01:20:54,940 --> 01:20:59,970
Equal to zero. Yes.

512
01:21:04,280 --> 01:21:07,580
And so this is adjusted for age.

513
01:21:18,320 --> 01:21:21,920
And the alternative is that at least one is different from the.

514
01:21:23,480 --> 01:21:35,080
What about the death statistic? Can I still use the extra thumb of quest principle and concept of the statistic?

515
01:21:35,590 --> 01:21:41,829
Yes. And what would that be? So the extra sum of squares due to beta one.

516
01:21:41,830 --> 01:21:50,049
Beta two. Given what? Given beta naught and beta three were already in the model two.

517
01:21:50,050 --> 01:21:56,620
It was already in the model. Okay.

518
01:21:57,040 --> 01:22:08,680
Divided by two. Because I have two extra barometers in the alternative which can do at least one.

519
01:22:12,900 --> 01:22:16,470
But not because of it. Okay. And what about the.

520
01:22:17,430 --> 01:22:24,060
And he dominated the denominator would be basically missing from the full model or SSP from the morning.

521
01:22:24,080 --> 01:22:28,530
We better not be darn beta two.

522
01:22:28,860 --> 01:22:33,420
Beta three divided by M minus four.

523
01:22:37,610 --> 01:22:43,010
So this would have an F distribution with degrees of freedom to and in minus sport.

524
01:22:48,560 --> 01:22:52,490
Okay, so we can do the adjusted quantities.

525
01:22:52,490 --> 01:22:58,820
And also so, you know, like just as you would asking Sophia.

526
01:22:59,120 --> 01:23:13,010
Okay. Now I'm going to go into a more broadly into categorizing.

527
01:23:17,670 --> 01:23:21,630
Continuous obedience and.

528
01:23:26,730 --> 01:23:32,550
And kind of in the presence of mind people who will be idiots like this.

529
01:23:32,820 --> 01:23:36,090
So sometimes, as I mentioned,

530
01:23:36,090 --> 01:23:41,190
investigators might prefer to compare categories rather than a party meeting is like be

531
01:23:41,910 --> 01:23:48,060
sort of the interpretation in the previous slide was party unity increase change in age.

532
01:23:50,460 --> 01:23:57,290
And what's the impact on health care for actors?

533
01:23:57,300 --> 01:24:07,170
Good for us. Steve Ah, you know, you can start from the same thing, but instead of having that party,

534
01:24:07,170 --> 01:24:11,640
you need change in each party meeting within the interpretation.

535
01:24:11,650 --> 01:24:26,490
Suppose I want to warn people age categories so I could break it into these categories and and define my groups like this.

536
01:24:26,820 --> 01:24:30,620
So I assume that all the farmers are above age 20.

537
01:24:31,740 --> 01:24:43,800
So I have my first age category, i.e. one more response to the age group, 20 to 29.

538
01:24:45,090 --> 01:24:58,740
So everybody in that, in that age group 22, 29 gets a value of one for the icon, really one and zero otherwise.

539
01:24:58,920 --> 01:25:09,239
So the only one I do it three 8485 are all dummy variables based on the age groups.

540
01:25:09,240 --> 01:25:19,440
What is the I do I do is the next decade of age 3239 increase 40 to 4984 is 5259

541
01:25:19,740 --> 01:25:27,600
and 85 is the indicator corresponding to age above 60 greater than equal to 60.

542
01:25:27,600 --> 01:25:33,300
So I'm going to use this group, the oldest group as my reference group.

543
01:25:36,410 --> 01:25:42,290
Okay. So now I have a dummy.

544
01:25:42,440 --> 01:25:54,319
I have created dummy variables out of one categorical variable requested, and another quality must be the opposite.

545
01:25:54,320 --> 01:25:59,810
Because each. And I fit this model.

546
01:26:00,710 --> 01:26:07,790
I have why the cost for the I saw difficulty better or not.

547
01:26:08,740 --> 01:26:13,250
Plus, this is the part corresponding to speed,

548
01:26:14,420 --> 01:26:23,060
so I have to indicate the variables corresponding to the three states beta one dummy for Michigan because we do nothing for North Carolina.

549
01:26:23,510 --> 01:26:29,080
And then I, I have a set of indicator variables for each.

550
01:26:30,650 --> 01:26:43,150
But remember that it was continuous and I created categories out of it, so I had five categories for it.

551
01:26:44,810 --> 01:26:52,010
So I am putting in four dummy variables making, as I said, that all this group has the reference group.

552
01:26:52,010 --> 01:26:55,370
So I see I'm close to 40.

553
01:26:55,370 --> 01:26:58,669
I do. Plus with the five I treat this B2C to a four plus.

554
01:26:58,670 --> 01:27:09,570
Excellent I. So now the indicator one thing, just as a general paying for it,

555
01:27:09,960 --> 01:27:18,750
the older than 60 is the reference category and fourth state Wisconsin is the reference gap between.

556
01:27:20,770 --> 01:27:24,800
Okay. So that's what I have now.

557
01:27:24,820 --> 01:27:28,570
What is the interpretation of Peter three? Let's make a three.

558
01:27:28,570 --> 01:27:35,640
Is the whole impression corresponding to the 2229 age group dummy variable?

559
01:27:36,430 --> 01:27:43,300
So the interpretation of that is that the mean difference in cost once again remember

560
01:27:44,260 --> 01:27:49,989
the reference it's everything is with respect to the reference group for that variable.

561
01:27:49,990 --> 01:28:02,559
So this meta three has the interpretation that it is the main difference in force for age 2229 versus aged above 60 greater than equal to 60.

562
01:28:02,560 --> 01:28:14,550
Comparing farmers in the same state because it is adjusted for state now.

563
01:28:14,800 --> 01:28:23,410
So that's that's that's good. We are we are good. But now I to ask you to interpret Peter's zero.

564
01:28:25,540 --> 01:28:29,350
Then you tell me what the interpretation of beta zero is in this model.

565
01:28:44,130 --> 01:28:49,350
Okay. Did everybody here that get a zero from this one?

566
01:28:49,410 --> 01:28:53,880
What do I have to do? I have to turn off all the detectors.

567
01:28:55,590 --> 01:28:59,540
I have to turn off the indicators for each as bad as for Steve.

568
01:28:59,610 --> 01:29:02,100
So turning on the indicators means what?

569
01:29:02,220 --> 01:29:15,600
Basically B to zero corresponds to the mean health care cost for farmers in the reference state and in the reference age group,

570
01:29:16,410 --> 01:29:21,940
meaning for farmers from Wisconsin who are greater than or equal to 60 years.

571
01:29:23,800 --> 01:29:30,860
Everybody okay with that? So that's the interpretation of because you.

572
01:29:36,130 --> 01:29:39,310
Comparing two AIDS models. Mm hmm.

573
01:29:40,300 --> 01:29:43,720
So let's talk about. Hmm.

574
01:29:44,230 --> 01:29:46,660
One other interesting fact here.

575
01:29:46,720 --> 01:29:57,910
So the question that I'm asking is, is it associated with health care costs adjusting for safety on the left hand side?

576
01:29:59,050 --> 01:30:02,270
The model that I have is what this is.

577
01:30:02,320 --> 01:30:04,660
This was the end go by model. Right.

578
01:30:05,050 --> 01:30:14,230
So there is a categorical variable state and I have dummy variables for that variable incorporated into the model,

579
01:30:14,230 --> 01:30:17,440
but it enters the model as a continuous variable.

580
01:30:18,310 --> 01:30:26,020
Yeah. So example the model, the 40 minute increase in each type of interpretation that's on the left hand side.

581
01:30:26,440 --> 01:30:30,620
And on the right hand side, what do I have? I have.

582
01:30:31,210 --> 01:30:37,810
Now, the difference between these two models is in how age enters the model.

583
01:30:39,070 --> 01:30:56,140
So here AIDS. Here, AIDS endures as a continuous variable and here it enters as a categorical variable through these dummies.

584
01:30:56,500 --> 01:31:01,870
So that's the difference between these two models. Everybody see that?

585
01:31:02,890 --> 01:31:07,330
So now let's talk about let's get to business.

586
01:31:07,690 --> 01:31:10,690
So now tell me for both models.

587
01:31:11,860 --> 01:31:22,930
I am going to ask this question. Is age associated with health care costs adjusting for for speed?

588
01:31:23,620 --> 01:31:27,460
So for the left hand side model. What am I testing?

589
01:31:29,080 --> 01:31:33,970
What is the null hypothesis? Just beta three equal to zero?

590
01:31:35,200 --> 01:31:45,040
Yes. Once again, it's just the one degree of freedom associated with the coefficient for continuous.

591
01:31:47,330 --> 01:31:52,219
Age. What you what is the alternative?

592
01:31:52,220 --> 01:31:59,390
That bigotry is not equal to zero. You know how balance from the FISA court this.

593
01:31:59,600 --> 01:32:06,320
Correct. So what is the you know again using the general formulation.

594
01:32:06,410 --> 01:32:11,440
So extra small squares due to later to be given.

595
01:32:11,450 --> 01:32:20,750
We cannot veto on data to any already in the model divided by one and then MSCI.

596
01:32:23,590 --> 01:32:29,740
And what would be the distribution of this statistic?

597
01:32:30,190 --> 01:32:36,580
MSE From the model, with the full model, we better be doing better to date actually.

598
01:32:36,790 --> 01:32:43,540
And this will have an error distribution. The degrees of freedom wan n n minus four.

599
01:32:48,110 --> 01:33:03,420
Yes. Now let's look at the model on the right hand side.

600
01:33:05,130 --> 01:33:10,140
So can you tell me now? I'm interested in answering the same question.

601
01:33:10,140 --> 01:33:14,830
Is it associated with health care costs adjusting for state?

602
01:33:14,850 --> 01:33:18,780
On the right hand side, I have the model that I have on board.

603
01:33:18,960 --> 01:33:24,330
The formula stated in two categories I would make age difference and equal to 60 the

604
01:33:24,330 --> 01:33:31,620
difference and I have incorporated it through a set of dummy variables for these age groups.

605
01:33:32,310 --> 01:33:39,570
To answer my question, what is the null hypothesis formally?

606
01:33:39,570 --> 01:33:48,180
How can I write the null hypothesis? But I'm testing it with this age gap abilities are these dummy variables.

607
01:33:56,660 --> 01:34:08,300
Okay. So I'm going to write exactly what was said before the three were to be a pool equal to five equal to get the things equal to zero.

608
01:34:13,970 --> 01:34:30,110
What is the alternative that at least one. What is the if best?

609
01:34:31,580 --> 01:34:37,300
What is the statistic? Even the extra sum of squares principle.

610
01:34:40,450 --> 01:34:53,120
The extra sum of words due to. Bigotry and the right move like this to beat us.

611
01:34:53,900 --> 01:34:59,050
Okay, so maybe I think I can fit it in.

612
01:34:59,500 --> 01:35:02,709
Better, three, better, four beta.

613
01:35:02,710 --> 01:35:07,440
Five beta. B2C.

614
01:35:10,810 --> 01:35:14,560
Given beta amyloid beta one.

615
01:35:14,560 --> 01:35:24,520
Beta two were already in the model. Divided by four.

616
01:35:24,790 --> 01:35:37,000
Correct. And you may see from I'm going to write to the MSI Star because MSI started the MSI from the model on the right hand side.

617
01:35:38,680 --> 01:35:42,100
What would be the distribution of this?

618
01:35:47,540 --> 01:35:52,340
For Obama in minus seven.

619
01:36:03,160 --> 01:36:07,450
Okay. So now I'm going to say a few words about these two models.

620
01:36:08,050 --> 01:36:15,520
So comparing between these two models and we know in both the model settings

621
01:36:15,520 --> 01:36:21,430
how to test for the age association with health care cost adjusting for state.

622
01:36:21,700 --> 01:36:28,260
But I want to say a few things. So the advantage of the model on the right hand side,

623
01:36:28,280 --> 01:36:43,240
this model over this model is that the model that you are categorizing a continuous albeit it lets you get to nonlinear patterns.

624
01:36:47,250 --> 01:36:54,750
The model on the left hand side assumes a linear increase with not is a linear change with each.

625
01:36:55,710 --> 01:37:03,980
The model on the right hand side is more flexible in terms of, you know, allowing nonlinear back then.

626
01:37:03,990 --> 01:37:05,879
So maybe like I'm just making it up.

627
01:37:05,880 --> 01:37:20,840
Maybe the pattern or the association between health care cost and things is like the new shape by building chunks or each categories.

628
01:37:21,340 --> 01:37:25,920
I'm pretty happy the Beatles vary in those chunks.

629
01:37:28,580 --> 01:37:34,340
So it kind of gives me a better approximation of the nonlinear pattern.

630
01:37:34,340 --> 01:37:38,360
So that's the advantage of the model on the right hand side.

631
01:37:38,510 --> 01:37:50,030
However, the disadvantages as far back as you can see, the model on the right hand side is using up more degrees of freedom for for a scissor.

632
01:37:54,030 --> 01:38:00,999
Then the model on the left. Okay.

633
01:38:01,000 --> 01:38:16,720
So that's the disadvantage. And if the pro model is indeed linear, meaning even the fact of association between Y and its is indeed linear,

634
01:38:17,560 --> 01:38:31,060
then the model on the right hand side and like the categorical model that uses indicators will make it harder to detect the null hypothesis

635
01:38:31,060 --> 01:38:43,840
because of the fact that now we are using the f four comma in minus seven and distribution as opposed to are F one and minus four.

636
01:38:48,870 --> 01:38:49,230
Okay.

637
01:38:49,440 --> 01:39:03,810
So that's the that's the advantage or I mean, that's those are the pros and the cons of using the the categorical model versus the continuous model.

638
01:39:04,140 --> 01:39:20,550
And basically what I'm talking about here is if I can get some extra space, uh, just to, uh, maybe, maybe a lot here.

639
01:39:22,050 --> 01:39:27,420
So if the true scenario is something like this.

640
01:39:32,760 --> 01:39:48,089
Your response to this is. If that is the truth, then of course,

641
01:39:48,090 --> 01:40:00,870
the model with the continuous seeds of the linear association between age and cost would be a more powerful model.

642
01:40:01,950 --> 01:40:12,420
If, on the other hand, the pattern is something, the true pattern is something like this.

643
01:40:18,400 --> 01:40:23,410
And you are breaking up in the jar. So this is, let's say, 22, 29.

644
01:40:23,440 --> 01:40:28,840
This is 3239. This is 40 to 49 and so on.

645
01:40:29,320 --> 01:40:38,630
Then what you're doing is you are basically fitting a means to this, to this, to this group.

646
01:40:38,650 --> 01:40:53,500
And as you can see, it would be easier using the categorical or even the dummy variables to create a non-linear pattern like this.

647
01:40:53,920 --> 01:40:57,140
But the association between cost and age is perhaps not big.

648
01:40:57,700 --> 01:41:08,290
So clearly now once again, bringing home the point, having this model on the right hand side,

649
01:41:08,290 --> 01:41:16,540
using the categorical version of continuous variable, is more flexible to capture non-linear patterns.

650
01:41:17,200 --> 01:41:22,570
But the disadvantages it uses more degrees of freedom for its ISR.

651
01:41:22,870 --> 01:41:32,120
So if the true association is indeed like this, then it would be harder to reject the null hypothesis.

652
01:41:33,280 --> 01:41:39,280
Again, because of of this fact. And so, although this is a more flexible model.

653
01:41:39,660 --> 01:41:46,180
Mm hmm. And it can work in situations, but the pattern is non-linear.

654
01:41:46,240 --> 01:41:56,200
You have to be sort of careful about is that data showing any nonlinear factor.

655
01:41:58,000 --> 01:42:02,250
And again, the best way to do that is through exploratory analysis graphics.

656
01:42:02,590 --> 01:42:04,530
But we modeling key.

657
01:42:04,840 --> 01:42:13,930
We are also going to talk about a diagnostic test to assess between these two models, which seems to give a better fit to the data.

658
01:42:15,640 --> 01:42:20,380
Okay. So I think, oh, it's 953.

659
01:42:20,650 --> 01:42:26,860
I wanted to talk about this example, but I think I'm run out of time.

660
01:42:27,850 --> 01:42:34,760
Maybe just a weekly one couple comments.

661
01:42:34,770 --> 01:42:45,759
So this was a. So basically we are finishing up modulated with this example where the dataset was assembled

662
01:42:45,760 --> 01:42:52,569
consisting of life expectancy calculations as well as other population level demographic data.

663
01:42:52,570 --> 01:42:57,140
And each record in the dataset pertains to a country.

664
01:42:57,160 --> 01:43:05,560
So this is like my speed. Okay, so this is a nominal categorical variable.

665
01:43:11,140 --> 01:43:21,280
And the primary objective was to determine the role of the following descriptors as predictors of life expectancy.

666
01:43:21,280 --> 01:43:24,600
So consider gender.

667
01:43:25,450 --> 01:43:33,310
But we also had some continuous variables like persons for television persons or medical doctors.

668
01:43:33,760 --> 01:43:37,630
So this is kind of going to be like an end for what I said.

669
01:43:40,270 --> 01:43:44,050
And we will on on Tuesday. We will.

670
01:43:44,350 --> 01:43:50,170
The outcome is is life expectancy in this last column here in years.

671
01:43:50,620 --> 01:43:53,739
And on Tuesday, when we come back,

672
01:43:53,740 --> 01:44:00,399
we will basically talk about this example and wrap up as illustration of of the methods

673
01:44:00,400 --> 01:44:08,780
that we talked about and wrap up our discussion of modulate and going to interaction.

674
01:44:09,250 --> 01:44:10,990
Okay. Thank you.

