1
00:00:01,250 --> 00:00:05,320
All right. So let's continue the discussion of stationary distribution.

2
00:00:05,330 --> 00:00:09,350
So that's, you know, probably the most important concept.

3
00:00:10,520 --> 00:00:21,440
And so the fundamental property of Markov chain is everything is defined through the transition kernel,

4
00:00:21,440 --> 00:00:26,540
one step transition for right once you have one stable transition kernel,

5
00:00:27,980 --> 00:00:33,440
if obviously that's the first and the most important thing is the Markov property.

6
00:00:33,620 --> 00:00:39,740
And then we add in some assumptions like type homogeneous transition.

7
00:00:41,300 --> 00:00:51,170
And with that, the ones that transition kernel essentially define the whole behavior of the underlying Markov chain from one step transition kernel,

8
00:00:51,170 --> 00:00:58,580
you can compute a marginal distribution for any member random variables in the chain, right?

9
00:01:00,140 --> 00:01:03,860
Similarly through the chipmunk equation.

10
00:01:04,580 --> 00:01:15,950
So the stationary distribution is particularly concerned with the behavior of the Markov chain if we run that long enough.

11
00:01:17,870 --> 00:01:25,280
So you would hope there's a special class of Markov chain will get into this so-called stationary distribution.

12
00:01:25,790 --> 00:01:30,830
And then last time we, the Gordian Theorem,

13
00:01:39,410 --> 00:01:51,050
essentially defines the this stationary distribution and then specifies what clause mark on the chain satisfies these conditions.

14
00:01:51,200 --> 00:01:54,440
So essentially we need a Gordian Markov chain.

15
00:01:59,690 --> 00:02:02,810
So that's the important thing when you apply,

16
00:02:02,840 --> 00:02:10,990
when you're trying to apply a Gaudi theorem and then trying to find the underlying stationary distribution is critically important.

17
00:02:11,010 --> 00:02:18,980
You check all these conditions. The Markov chain studying is in fact below.

18
00:02:20,060 --> 00:02:27,740
So it happens to be theory use of all meaning.

19
00:02:27,740 --> 00:02:33,440
There's only one single communication class has to be.

20
00:02:35,060 --> 00:02:49,940
Therefore the following two properties will be a class problem, a positive recurrent.

21
00:02:50,180 --> 00:02:54,800
So every state has a non-zero ever return probability.

22
00:02:55,730 --> 00:03:10,830
Sorry is a. I said I'm wrong and every state has a certain average term probability being exactly one, and then the expected return time is finite.

23
00:03:11,430 --> 00:03:21,480
So that's positive recurrence. And then every state has a period one.

24
00:03:23,220 --> 00:03:27,480
All right. So this is kind of important. So this is intuitive.

25
00:03:27,600 --> 00:03:38,160
I mean, if you run the train long enough in this Markov chain, every state can be visited by B and C, a periodic.

26
00:03:39,480 --> 00:03:42,870
So this is just trying to establish the relationship.

27
00:03:42,880 --> 00:03:51,740
So if X and the X and plus one. Well, the way to think about a periodic, you can think about X and X plus one.

28
00:03:51,750 --> 00:04:00,240
So if it's not a periodic, then you probably can imagine the X and X and plus one.

29
00:04:00,360 --> 00:04:04,650
They don't have the same marginal distribution.

30
00:04:05,220 --> 00:04:10,680
Right? Think about y, but a periodic makes its possible.

31
00:04:10,680 --> 00:04:19,290
It's not guaranteed to x, x and plus one have the identical marginal distribution which is important for the.

32
00:04:19,440 --> 00:04:27,710
Okay. So these are the sign ups you need to have according Markov chain, meaning irreducible, positive, recurrent and periodic.

33
00:04:29,130 --> 00:04:42,030
And then the conclusion is the following There is multiple versions of to represent this stationary behavior.

34
00:04:42,960 --> 00:04:51,900
What we have is Levit goes to infinity he i j and equals pi.

35
00:04:51,900 --> 00:04:57,910
LJ So this is seemingly a version related to that.

36
00:04:57,910 --> 00:05:05,820
There's that transition kernel, right? So this seemingly you can calculate from the my core model of the equation and then take and goes to infinity.

37
00:05:06,450 --> 00:05:14,670
Last time we also say so the important importance of this particular destination is the j.

38
00:05:15,000 --> 00:05:17,430
So the right hand side is independent.

39
00:05:18,030 --> 00:05:31,020
The transition of the starting point right last time we also show this one is exactly the same as the probability, so.

40
00:05:31,530 --> 00:05:40,169
J So this give you a intuitive interpretation of pi?

41
00:05:40,170 --> 00:05:48,120
J Right. So this is all we're talking about a marginal distribution and goes to infinity.

42
00:05:48,120 --> 00:05:53,010
So every single number random variable will be identically distributed.

43
00:05:53,610 --> 00:05:58,530
Although they are not independent, they're, they are not they are dependent, they are not independent.

44
00:05:59,940 --> 00:06:03,330
But the marginal distribution is defined through page.

45
00:06:04,480 --> 00:06:08,960
Right. There are a few things we have.

46
00:06:09,000 --> 00:06:16,590
Look. Barry's boss, the Cobbler, mentioned during the church.

47
00:06:16,600 --> 00:06:20,300
But I'm just trying to get on the faces.

48
00:06:21,010 --> 00:06:28,840
So we're also show page.

49
00:06:30,430 --> 00:06:51,240
Can be solved from equations involving only nature.

50
00:06:54,460 --> 00:07:03,700
Right. So if I give you the transition kernel, you inspect the transition kernel, ensure the underlying Markov chain is supporting Markov chain.

51
00:07:04,340 --> 00:07:10,150
You can solve for the service side of the equation.

52
00:07:10,880 --> 00:07:18,400
I. Let me see my patient.

53
00:07:31,750 --> 00:07:44,890
What do. So for each single pie of J.

54
00:07:46,180 --> 00:07:50,620
Well, you may have a finite side of infinite side of the equation,

55
00:07:50,620 --> 00:07:59,030
but I think they are usually solvable because the summation usually involved the right hand side is finite.

56
00:07:59,080 --> 00:08:08,260
So anyway, if you think about finite state space, Markov chain, this is what we call a system of creation, and you can solve for it.

57
00:08:09,490 --> 00:08:15,250
Similarly, you can solve others. This is the general way, the most.

58
00:08:18,890 --> 00:08:27,160
It's is probably the universal way. If you are determined the underlying Markov chain is is avoiding Markov chain.

59
00:08:27,170 --> 00:08:32,600
This is the way you can solve for you. We are going to see different ways to solve for it with additional assumptions.

60
00:08:33,980 --> 00:08:41,420
But you can always go back to the recording theorem and then solve for the managing, right?

61
00:08:41,420 --> 00:08:47,660
So the PI's are the unknowns pages are known from the transition kernel in that you can solve them.

62
00:08:48,290 --> 00:08:59,150
The other implication of this equation is if your trade and the PI as initial state, the distribution.

63
00:09:00,220 --> 00:09:03,520
Right. Think about this is the next the transition.

64
00:09:03,910 --> 00:09:21,190
We get the implications if the agency once enter into a stationary distribution, a stationary distribution.

65
00:09:23,050 --> 00:09:27,760
So this concept is important for M.S., M.S., like the application.

66
00:09:28,180 --> 00:09:34,480
It's just if you're starting off training and then you happen to know what a stationary distribution is,

67
00:09:35,050 --> 00:09:42,380
then everything will stay in the stationary distribution, meaning this is the distribution.

68
00:09:42,400 --> 00:09:45,550
Every single random variable will follow, right?

69
00:09:46,660 --> 00:10:01,900
So once in one store, the Markov chain and stationary distribution will remain in the.

70
00:10:05,460 --> 00:10:18,120
In a situation like this, some other way to say it, it cannot get all of it.

71
00:10:19,050 --> 00:10:38,570
And what remains there? So the thing we didn't prove or didn't show this is the maintenance [INAUDIBLE] you did to you.

72
00:10:38,920 --> 00:10:49,270
So the uniqueness is come with this specific requirement for awarding properties of every single state, right?

73
00:10:50,230 --> 00:10:54,880
You can't imagine you have two different types of the chains you can.

74
00:10:56,710 --> 00:11:01,750
So for a boarding Markov chain, a stationary distribution is always unique.

75
00:11:02,950 --> 00:11:07,090
You can get the example that I'm showing you are not utilities.

76
00:11:07,360 --> 00:11:14,680
A markov chain have no unique long term distribution.

77
00:11:15,580 --> 00:11:34,840
It's not difficult to construct. When I say uniqueness, also, this is a for the application of CMC in the later time.

78
00:11:34,870 --> 00:11:44,500
So last time we showed this is if you have a transient state, which is the first thing you're going to get into this.

79
00:11:47,260 --> 00:11:50,560
So you have some transient state.

80
00:11:53,950 --> 00:11:59,500
So this is a class of it's a communication class.

81
00:11:59,980 --> 00:12:07,870
And then you have to recurrent state.

82
00:12:08,950 --> 00:12:14,470
I say call it r one and not hard to know within the R one.

83
00:12:15,040 --> 00:12:20,710
Maybe every state is positive, recurrent and a periodic.

84
00:12:21,100 --> 00:12:31,390
Same thing far two. All right. But you have a single transient state and then probability if you start your Markov chain in the transient state.

85
00:12:32,620 --> 00:12:35,840
So the whole Markov chain is not irreducible.

86
00:12:35,860 --> 00:12:39,490
There are three communication classes. Right. It doesn't.

87
00:12:40,090 --> 00:12:46,330
So just look at this. It doesn't satisfy the Ghatak theorem, but part of these stars.

88
00:12:47,290 --> 00:12:47,589
All right.

89
00:12:47,590 --> 00:12:56,560
What's going to happen is if we start the chain and the transient state, so the Markov chain will remain in the transient state for some time.

90
00:12:56,830 --> 00:13:00,640
And then we're going to study how long and what's it will stay.

91
00:13:01,300 --> 00:13:05,450
And then it has a chance to get into R one, an R two.

92
00:13:06,370 --> 00:13:10,960
Right. Why does he get into R1? Will remain in R1.

93
00:13:11,770 --> 00:13:14,390
Okay. There is no way to get out. Right.

94
00:13:14,540 --> 00:13:23,890
So because of the well, by definition, this is a that you reduce and that will reach the stationary distribution defined by the R1.

95
00:13:24,160 --> 00:13:27,550
Right. Because this why does it get into the R1?

96
00:13:27,970 --> 00:13:37,630
Now you can kind of narrow down the problem or redefine the problem as they start into a negative Markov chain.

97
00:13:37,810 --> 00:13:40,720
So these two paths become irrelevant.

98
00:13:41,230 --> 00:13:50,890
The point is, well, if you run this train long enough, you get into the R1, it will have a stationary distribution by one.

99
00:13:52,780 --> 00:13:58,250
Similarly, if it happens to get into the R2, you will break.

100
00:13:59,020 --> 00:14:06,370
This is also, if you look at itself, it's also of oh, the states are at Warwick within the R2, right?

101
00:14:06,790 --> 00:14:17,320
And then you kind of invoke the aborted parent to say the long run distribution for this Markov chain is high too.

102
00:14:17,950 --> 00:14:22,780
However, you cannot claim uniqueness for this whole Markov chain.

103
00:14:22,840 --> 00:14:29,350
It really depends on after finite time, it's ended in the R one or two.

104
00:14:30,190 --> 00:14:38,080
Right. So the uniqueness, you would need this first, the condition irreducible this whole Markov chain.

105
00:14:38,380 --> 00:14:45,600
The counterexample we have is not reproducible, but that particular type of the knowledge,

106
00:14:45,610 --> 00:14:53,170
like a awarded theorem, can be applied to this sort of a field.

107
00:14:53,770 --> 00:15:02,500
The more complex scenarios that view the Pong multiple communication classes.

108
00:15:02,710 --> 00:15:11,230
Right. So that's the point. That uniqueness only applies for irreducible Markov chain.

109
00:15:13,850 --> 00:15:19,670
Okay. Any questions? So the important thing is really that the interpretation of the awarding theorem.

110
00:15:19,890 --> 00:15:29,360
You have to remember the the uniqueness under the is for irreducible Markov chain.

111
00:15:30,530 --> 00:15:35,990
You also need to be able to calculate that stationary distribution.

112
00:15:36,050 --> 00:15:40,640
I interpret that stationary distribution and remember it.

113
00:15:41,000 --> 00:15:52,400
That is, the situation is reduced to essentially the marginal distribution of the number of random variables in the awarding of Markov chains.

114
00:15:52,550 --> 00:15:58,550
And then there are identical distribute distributed but not independently distributed.

115
00:16:00,500 --> 00:16:04,010
Got any questions?

116
00:16:10,410 --> 00:16:17,820
All right. So. So if we keep continuing that example.

117
00:16:19,950 --> 00:16:32,760
This from the multi communication class of example that we need to.

118
00:16:38,200 --> 00:16:48,540
The rest of. So you have a you may have multiple hour.

119
00:16:49,770 --> 00:16:54,930
So this is a recurring clause, positive recurrent clause, hour one, part two.

120
00:16:55,170 --> 00:17:02,670
You don't have to have multiple. But the for the question where for the problem where I'm interested in.

121
00:17:03,030 --> 00:17:07,680
So the question is if you start the Markov change in the transit costs.

122
00:17:09,440 --> 00:17:13,790
What is the expected time? The Markov chain will stay here.

123
00:17:13,940 --> 00:17:18,020
Right. We know that there's not gonna stay there forever.

124
00:17:19,200 --> 00:17:30,150
Right. So if because there is a non-zero probability for every state will never return back to the transient class,

125
00:17:30,160 --> 00:17:38,440
so will eventually run the chain long enough. They will transit the chain well, which will move out of this transient state.

126
00:17:38,570 --> 00:17:43,460
And the question is, what is expected to stay in the state?

127
00:17:45,590 --> 00:17:54,950
So this is if you start the chain there. So question makes sense.

128
00:17:57,230 --> 00:18:01,140
I. Spend.

129
00:18:13,380 --> 00:18:16,920
All right, so we trying to investigate this.

130
00:18:20,890 --> 00:18:36,110
All right. So. Wow. So we have to be able to solve this type of the problem.

131
00:18:36,110 --> 00:18:42,979
We have to eliminate ourself a little bit. In particular, we're going to consider this problem in a finite space.

132
00:18:42,980 --> 00:18:50,990
Space is actually not necessarily going to be a finite space space, but the transient space has to be finite.

133
00:18:51,530 --> 00:18:56,270
Otherwise, there's the problem is significantly more difficult.

134
00:18:56,570 --> 00:19:02,960
But if you can consider there are only finite states in the in the transient class, then.

135
00:19:05,840 --> 00:19:16,340
Now we should be able to handle it using some matrix algebra solvers and find out in spades.

136
00:19:20,660 --> 00:19:29,950
I would say, of course, in triathlon gods, this one is the only one.

137
00:19:30,880 --> 00:19:36,580
Obviously, you can make the problem more difficult by adding multiple times in class.

138
00:19:36,580 --> 00:19:42,100
Right. So I may have the the tee on the Taliban tee, one on the Taliban, the tee, two on the bottom.

139
00:19:42,490 --> 00:19:50,650
But you realize that if you're starting from t one, the Markov chain will never travel to a tee to.

140
00:19:52,790 --> 00:19:59,150
Right, because it has to go through our one hour to once they enter into our one hour to walk, the one getting out.

141
00:20:00,140 --> 00:20:05,090
So if you had multiple transit classes, it really doesn't matter.

142
00:20:05,240 --> 00:20:11,210
But all it matters is where the Markov checks start, which transient classes start.

143
00:20:16,960 --> 00:20:26,740
By the way, here we use the so why it is so in reality why this type of the problem matters.

144
00:20:27,040 --> 00:20:30,880
So we talk about a right fisher model, right?

145
00:20:31,240 --> 00:20:34,300
So there there are two absorbing states.

146
00:20:34,930 --> 00:20:39,760
And every state, every every other states are transient.

147
00:20:40,230 --> 00:20:48,879
Right. You have state zero. There's a mutation gain essentially eliminated from the population and then

148
00:20:48,880 --> 00:20:55,630
the state and which represented the fact that that the the mutation dominant,

149
00:20:55,720 --> 00:20:59,590
the whole population, everything else is a transient state.

150
00:20:59,920 --> 00:21:04,440
Right. So that's exactly the situation you have are one it's a single state.

151
00:21:04,450 --> 00:21:08,710
It's a recurrent as zero. And the R two is.

152
00:21:09,040 --> 00:21:18,280
So maybe you are interested in the in the in the question, like in how many generations they expected, number of generations.

153
00:21:19,060 --> 00:21:23,049
Three or frequency for this mutation is a half. Right.

154
00:21:23,050 --> 00:21:28,230
So this is an expected finite state.

155
00:21:28,250 --> 00:21:32,390
Well, this is the problem. They expected the time spent in the transient state.

156
00:21:32,410 --> 00:21:36,940
So that's sort of interesting in in real life application.

157
00:21:37,300 --> 00:21:43,210
The same thing for the gamblers, essentially the same, you know,

158
00:21:43,330 --> 00:21:51,400
what is the expected time you actually won something in the middle of if in between the.

159
00:21:52,500 --> 00:21:56,340
Bankruptcy line versus your target line.

160
00:21:56,490 --> 00:22:02,490
Right. All right. So we need to define finite state in transit, in classes.

161
00:22:07,340 --> 00:22:11,930
Right. We have set some of the topology here.

162
00:22:14,630 --> 00:22:20,900
So it's always one way transition. It can all have to wait.

163
00:22:20,900 --> 00:22:35,090
Transition. Otherwise, this is not the transit space is one way to transition from the transition to the current.

164
00:22:37,140 --> 00:22:40,890
Classes or competitions.

165
00:22:49,570 --> 00:22:53,380
All right. So this is some basic fact, as we know now.

166
00:22:53,420 --> 00:22:58,250
And now we're trying to solve the problem. The way we solve it is actually by conditioning.

167
00:22:58,270 --> 00:23:03,070
That's. But before that, we need some notations to make the whole process easier.

168
00:23:06,310 --> 00:23:16,240
In a way, you get to if you are eventually going to do other research in this area, you realize the notation is the most important thing.

169
00:23:16,420 --> 00:23:19,900
You whenever you're trying to write a map, write, hop a method,

170
00:23:20,440 --> 00:23:29,470
or just maybe just illustrating some of your thought into your audience, the notation matters a lot.

171
00:23:29,590 --> 00:23:37,270
And then not only you need a clear notation, you need to really interpret everything.

172
00:23:37,390 --> 00:23:51,940
The notation is that for. And so the notation we're going to use is trying to describe this transition within the transition class, right?

173
00:23:52,450 --> 00:24:01,630
So because it's a finite, so we can use this transition kernel idea and in the finite state space we always have a transition matrix.

174
00:24:01,960 --> 00:24:06,550
So this one is something similar but not exactly a transition matrix.

175
00:24:06,910 --> 00:24:13,719
So we can quality the Q matrix is going to be just like transition matrix.

176
00:24:13,720 --> 00:24:25,680
P one, one, one, two. So we're going to label every state in the transition class 1 to 3 opportunity not.

177
00:24:27,520 --> 00:24:39,649
So we're going to have p1t and that system P to 1 to 2 up to three to T and so on, so forth.

178
00:24:39,650 --> 00:24:49,570
So you got this kind of matrix, but this matrix is not a transition col or transition matrix.

179
00:24:49,570 --> 00:24:52,910
That terminology is reserved.

180
00:24:52,930 --> 00:24:56,749
The four. For Markov chain.

181
00:24:56,750 --> 00:25:02,059
The reason is at least one of these goals.

182
00:25:02,060 --> 00:25:05,950
Some. Should be strictly less than one.

183
00:25:08,400 --> 00:25:11,910
If that makes sense. So. So.

184
00:25:12,090 --> 00:25:18,780
Well, first of all, this api j equals the q yj.

185
00:25:19,260 --> 00:25:22,610
Oh, I should write the other way across because we're talking about.

186
00:25:25,830 --> 00:25:29,980
So for the matrix the are all j.

187
00:25:30,100 --> 00:25:35,220
The column is essentially just from the transition kernel API.

188
00:25:36,720 --> 00:25:42,070
Right. So for the state I to j. But there is a constraint.

189
00:25:42,240 --> 00:25:46,770
I and AJ are Bose belongs to this transition class.

190
00:25:50,350 --> 00:26:00,140
Unusually for all. And there is another constraint we have.

191
00:26:00,200 --> 00:26:04,380
This has to be due to the summation of.

192
00:26:04,620 --> 00:26:08,840
So we're trying to do this animation across all these columns.

193
00:26:09,590 --> 00:26:19,580
One, two t. Q H.G. Wells, last summer you build one, okay.

194
00:26:20,030 --> 00:26:28,010
And then it does well, I think. But in addition, there will be one year all at least the y0.

195
00:26:28,730 --> 00:26:32,090
This is strictly less than one, right?

196
00:26:32,450 --> 00:26:37,190
If they all take equal. That means there is no translation to our one or two.

197
00:26:37,400 --> 00:26:45,640
Right. So if. If everything is being equal to one, every row equal to one, that means there is no transition.

198
00:26:45,650 --> 00:26:49,730
So that transition out there is has to be a non-zero probability.

199
00:26:50,270 --> 00:26:59,030
None. The Markov chain can transmit the can move out of these transient states.

200
00:26:59,060 --> 00:27:25,520
So if you say so, so there exists a K in this T class such that j comes one to t q of k j strictly less than a one.

201
00:27:25,530 --> 00:27:37,710
I'm sorry it's written in the corner. So this is also and so all these three conditions has to decide this.

202
00:27:38,660 --> 00:27:42,410
So this one side is then the inequality.

203
00:27:42,410 --> 00:27:47,870
Q is less than input one. If you take this as a page, it is automatically satisfied.

204
00:27:47,900 --> 00:27:54,620
The more important thing is the existence of the state k.

205
00:27:55,190 --> 00:27:58,970
So this the state K is essentially a gateway state, right?

206
00:28:00,230 --> 00:28:09,500
You can you can try and you can. The Markov Jenkins goes through State K and the network get back to get into some of these the recurrent state.

207
00:28:09,770 --> 00:28:17,160
You can have well this only require you have at least a one gateway state but you can have multiple personal issues.

208
00:28:17,240 --> 00:28:23,660
So there is only there exists one. All right.

209
00:28:23,660 --> 00:28:31,400
That's all the notation. We're going to work with this and then try to formulate our problem.

210
00:28:32,120 --> 00:28:34,460
Using the right information means.

211
00:28:36,320 --> 00:28:51,800
So the question we're trying to solve is the expected number of visits within the to the transient state conditional.

212
00:28:52,400 --> 00:28:55,460
It will start from one of those things. Right.

213
00:28:56,420 --> 00:29:00,049
So let's define again,

214
00:29:00,050 --> 00:29:21,200
this is a notation and mind j being the expected interdependence to state j which is a

215
00:29:21,200 --> 00:29:35,590
member of this transient class plus conditional or just state given x zero even to I.

216
00:29:36,340 --> 00:29:45,440
I also belong to the same state. So this is a kind of a narrowed down the scope a little bit, but this is it becomes more approachable.

217
00:29:45,440 --> 00:29:52,580
The problem becomes more approachable. Right. So if you find two states I entry both in the transient states,

218
00:29:52,940 --> 00:30:01,760
I'm just counting if they start from the I what is expected of visit to state J and then that related to the original problem.

219
00:30:01,880 --> 00:30:08,150
So if you can enumerate all possible j that is the total time Markov chain.

220
00:30:08,150 --> 00:30:12,860
Well, state will spend this transient state.

221
00:30:13,060 --> 00:30:16,460
Right. So this is important. You have to start the Markov chain.

222
00:30:16,520 --> 00:30:18,740
Yes, please. I'm going like second seconds.

223
00:30:19,010 --> 00:30:24,020
Kind of a quick question, but the queue matrix, is it square like is it TBD or is it a different dimension?

224
00:30:26,120 --> 00:30:30,080
Yes, it is. Right. So the so you have to have t states.

225
00:30:31,760 --> 00:30:35,450
That's the the yes. Basically, the dimension is the number of.

226
00:30:35,600 --> 00:30:38,780
Yes. Good, good observation. Yes. It has to be square.

227
00:30:44,810 --> 00:30:52,280
So. So getting here so you know I mean we know the the total state in the trends state.

228
00:30:53,780 --> 00:30:57,530
All right. So how do we calculate this? So the analyze Jay.

229
00:30:59,390 --> 00:31:15,170
Well, I mean, just write it down. It's just visits to the JAY So you can define that as an Jay if that's helpful.

230
00:31:15,890 --> 00:31:23,570
But let me just using this just using the words is fine given that zero two.

231
00:31:23,620 --> 00:31:27,919
All right.

232
00:31:27,920 --> 00:31:33,170
So we write the Jay, Jay, bullseye Jay.

233
00:31:39,670 --> 00:31:47,480
Right. So this is what we're really trying to calculate. Um, so how to calculate this thing again?

234
00:31:47,510 --> 00:31:56,750
We're going to do it this way. The trick we have been using since the start of the class, we're going to conditional on the x one.

235
00:31:57,560 --> 00:32:01,090
So the first of transit. So there are two things can happen, right?

236
00:32:01,130 --> 00:32:09,230
So the first, the transit may be already. So if you're okay, what are going to do?

237
00:32:09,410 --> 00:32:18,330
We're going to we're going to try to use the total expectation lol.

238
00:32:20,060 --> 00:32:31,340
So we're still trying to figure out because it's two J so this part doesn't change i0y so we need to add in some information.

239
00:32:31,520 --> 00:32:45,850
Let's say x one. All right. I just want you to pay, all right?

240
00:32:46,100 --> 00:33:02,340
Actually. Let's first write down this condition long at this point it's just total expectation lol.

241
00:33:02,670 --> 00:33:05,940
And the way I use it is conditioning more.

242
00:33:06,030 --> 00:33:09,180
So obviously we can use the game. All right.

243
00:33:09,360 --> 00:33:19,420
So if x one. If it's state K. It's already all helped in the 26 states.

244
00:33:23,140 --> 00:33:26,930
Then the expected state will be zero.

245
00:33:26,980 --> 00:33:34,480
Right. So let me right now, as far as the what was the benefit of doing this?

246
00:33:35,170 --> 00:33:39,130
Because this is a really divide and conquer type of situation.

247
00:33:39,670 --> 00:33:48,040
If you if you make the first move, you use the Markov chain still remain in the transit class.

248
00:33:48,820 --> 00:33:53,490
Then the problem is similar, right? If not identical.

249
00:33:53,860 --> 00:34:00,820
It's just a move to a different starting point. But the expected state problem remains the same.

250
00:34:00,850 --> 00:34:11,450
This is pretty much like the. The fly in the maze or the is the same thing as the simple random walk through.

251
00:34:11,460 --> 00:34:14,940
When you make the first move, the problem regenerates itself.

252
00:34:16,350 --> 00:34:22,770
So if you're the K is still in the transient state, then the whole problem is similar.

253
00:34:22,770 --> 00:34:27,590
And then by the Markov property this is it becomes irrelevant to actually zero.

254
00:34:27,870 --> 00:34:30,959
Am I right? So it's only the same thing.

255
00:34:30,960 --> 00:34:39,180
But the inside being termed the internal expectation becomes the visit to j conditional x one equal to k.

256
00:34:39,690 --> 00:34:47,219
Right. However, if x1 the K is outside that the class that you know that overrides zero,

257
00:34:47,220 --> 00:34:52,260
the expected value is zero because so once it's outside, it cannot get better.

258
00:34:53,910 --> 00:35:00,569
But to write it formally, you need to realize this one equals delta.

259
00:35:00,570 --> 00:35:13,190
E.g. Where does this term come from? Because your target j If you're starved from the state I Then the fact is you start from state.

260
00:35:13,260 --> 00:35:17,860
I already visit state for one, but otherwise it's zero.

261
00:35:17,880 --> 00:35:21,950
So this one is kind of a bookkeeping thing.

262
00:35:22,320 --> 00:35:30,840
Right. So this is always still the idea. You first start your Markov chain at the state and then your target is counting.

263
00:35:30,840 --> 00:35:36,710
How many states in state? I need to automatically add one, so otherwise is zero.

264
00:35:36,720 --> 00:35:41,280
So this is a double function, but that's for purely for bookkeeping.

265
00:35:42,090 --> 00:35:46,920
And then plus now you need to consider this.

266
00:35:47,970 --> 00:35:54,810
You're already made of one move. Maybe you just if you're the first, the move is outside this.

267
00:35:55,680 --> 00:35:58,880
So if you can consider this zero.

268
00:36:03,200 --> 00:36:16,870
Let's say the. All right, so let's write this police inspector.

269
00:36:17,030 --> 00:36:22,040
So we need to figure all this business to J.

270
00:36:22,600 --> 00:36:26,930
Conditional on x y. Want you to think, right?

271
00:36:26,960 --> 00:36:34,310
We don't need to finish an IV zero anymore. We just need two conditional x, x y because of the mark of the property.

272
00:36:34,640 --> 00:36:38,870
So that in there conditional expectation becomes this.

273
00:36:40,520 --> 00:36:47,540
So this is a zero if k is not the right.

274
00:36:49,160 --> 00:36:57,740
If it's a zero, then? Well, I mean, you know, the what what what's the probability X, Y you go to K, there's going to be panic button this one.

275
00:36:59,960 --> 00:37:10,640
So that's right there's a nasty and t he I k so this are from I took this is the

276
00:37:10,640 --> 00:37:18,280
probability x1 equal to k so you need to translate from item K and that is disturbing.

277
00:37:20,120 --> 00:37:25,760
Otherwise I would claim the same thing would happen.

278
00:37:25,970 --> 00:37:32,550
So this is it becomes x x k, right?

279
00:37:32,840 --> 00:37:37,430
So we just change the problem instead of starting from state.

280
00:37:37,460 --> 00:37:43,550
I know I start with state K and I am curious about you know expect this state

281
00:37:43,550 --> 00:37:51,080
in the trans in class so I'm K.J. K the first the transit the first the move.

282
00:37:53,200 --> 00:37:59,230
Ended up in the state ends up in the state that's belongs in this in class.

283
00:37:59,410 --> 00:38:03,640
So that would be okay.

284
00:38:04,250 --> 00:38:09,250
But he he, I'd say I'm in jail.

285
00:38:11,680 --> 00:38:16,580
Right. So I actually did two things.

286
00:38:16,600 --> 00:38:26,740
One is invoke Marcos property, simply fire in the in their conditional expectation to this form.

287
00:38:26,860 --> 00:38:32,080
And that depends on the K value of actual antiques.

288
00:38:32,470 --> 00:38:45,580
It could be zero for this. So because this is a zero, you ended up with Delta H.J. Class a t.

289
00:38:47,230 --> 00:38:51,740
P. I j.

290
00:38:53,920 --> 00:38:57,240
And this one is I'm hijack.

291
00:39:00,280 --> 00:39:03,760
Just like before we didn't get. Oh, yes.

292
00:39:03,880 --> 00:39:07,660
There's a question. Could you describe again what the Delta is?

293
00:39:07,660 --> 00:39:12,370
I'm very confused. All right. Yes, yes, yes, of course.

294
00:39:13,420 --> 00:39:22,310
So the Delta is for bookkeeping again. Delta IPA equal to 05j.

295
00:39:24,580 --> 00:39:29,320
Sorry, doesn't count. Right. This is for the delta function.

296
00:39:31,270 --> 00:39:38,950
All right, so this is just trying to say, if you're starting from your target, you should count as one the number of states already.

297
00:39:38,950 --> 00:39:48,489
One? Yeah, that's it. That's not, you know, it's just trying to make the whole thing consistent if you start because usually you can think about this.

298
00:39:48,490 --> 00:39:54,190
I mean, j the starting point is randomly determined by the initial state distribution.

299
00:39:54,520 --> 00:40:02,260
Right? So if you already start from your target in the case equal to J, you can't as one.

300
00:40:03,290 --> 00:40:10,500
Otherwise there is no stage for the first initial stage, so it's just for keeping on.

301
00:40:11,010 --> 00:40:14,899
Good. All right.

302
00:40:14,900 --> 00:40:17,090
At the end of the day, you get this equation.

303
00:40:17,360 --> 00:40:29,550
So this is a like the recursive equation we get from the other situations, but this should be sufficient to solve I'm being here.

304
00:40:29,570 --> 00:40:32,960
So if it's a finite. If you have a finite.

305
00:40:35,400 --> 00:40:47,940
Collection of t. The T is a finite classes and if you like you can write this into a matrix four so that the way to write it,

306
00:40:48,450 --> 00:41:04,710
you can define a matrix m by arranging o the m i j term into a matrix, right?

307
00:41:04,830 --> 00:41:11,399
So this is a and so instead of asking the question individual at my age you

308
00:41:11,400 --> 00:41:17,450
can trying to solve them all together just align this am i j element in job?

309
00:41:17,730 --> 00:41:20,910
So this will be a t by matrix, right?

310
00:41:21,240 --> 00:41:25,380
So there's a square matrix and this equation that they all the function.

311
00:41:26,400 --> 00:41:30,629
You can also write that into a matrix and then the square matrix.

312
00:41:30,630 --> 00:41:34,500
Right. So those matrix has, the properties are actually diagonal.

313
00:41:34,500 --> 00:41:38,910
So there's identity matrix. So this is a high class.

314
00:41:39,180 --> 00:41:47,009
So this is a like the matrix multiplication. So the peak for K belongs to T, we already defined.

315
00:41:47,010 --> 00:41:50,560
That's the matrix. Q Remember?

316
00:41:51,420 --> 00:42:00,000
And this one is The Matrix. So you actually get the matrix equation from here.

317
00:42:00,540 --> 00:42:07,050
And then if you like, you can solve for it. So the move the terms this term to.

318
00:42:07,770 --> 00:42:20,210
So I'm minus Q because I am mobi I minus Q inverse I guess.

319
00:42:20,220 --> 00:42:24,500
So this is always in vertical, but just very loosely.

320
00:42:24,720 --> 00:42:28,590
This is this is the answer.

321
00:42:28,980 --> 00:42:33,500
But this one is equivalent to this. You don't have to write into a matrix form.

322
00:42:33,510 --> 00:42:37,830
The matrix form. Probably easier to understand or.

323
00:42:43,630 --> 00:42:51,640
I think this example. Yes, please. When you apply total exploitation, why do we have the conditioning on X, not equals I?

324
00:42:51,700 --> 00:42:54,870
Because I mean, we already have it in the inter expectation. Right, right.

325
00:42:54,870 --> 00:42:58,540
Right. So this is a total expectation law. Right? So you see. Ah, sorry.

326
00:42:58,540 --> 00:43:01,899
This is actually these are not the total expectations.

327
00:43:01,900 --> 00:43:06,550
Thanks for pointing out this infiltration law or this power law.

328
00:43:06,910 --> 00:43:12,730
So you're trying to compute some conditional expectation by you, conditional on more things in the in.

329
00:43:13,450 --> 00:43:19,530
So, yes, you're absolutely right. It's not so this is a wrong terminology to use.

330
00:43:19,540 --> 00:43:23,740
There's a filtration law if you want to compute.

331
00:43:24,910 --> 00:43:28,750
I think at the time we ask given.

332
00:43:31,060 --> 00:43:36,020
What if we use. So it's a function of X, right?

333
00:43:36,040 --> 00:43:39,580
So a z, what we can do.

334
00:43:40,270 --> 00:43:45,520
I think we used this on this one as well.

335
00:43:45,720 --> 00:43:56,490
So you see which Z is a function of y is equal to Y if you want.

336
00:43:57,580 --> 00:44:01,450
I'm sorry. I just gave a little while and then.

337
00:44:04,790 --> 00:44:09,110
Right. So we need to keep this. And why is some more information than Z?

338
00:44:09,530 --> 00:44:14,390
Z is a function of Y, so thank you for pointing that out.

339
00:44:14,420 --> 00:44:21,560
This is not the total expectation. It's really not the tower at all or feel appreciable.

340
00:44:22,280 --> 00:44:28,010
But the trick is the same condition on more things than you're trying to get.

341
00:44:29,810 --> 00:44:36,630
Good. On the other comments, questions.

342
00:44:37,510 --> 00:44:47,799
Right. So the purpose of showing this example is twofold of one is in general, if you don't have a markov chain, you can have the set up like this.

343
00:44:47,800 --> 00:44:55,210
There is a transient clause and then there are multiple. So really there is a no unique stationary distribution.

344
00:44:55,840 --> 00:45:02,590
However, eventually, if you run this train and will randomly get into one of the recurrent classes,

345
00:45:02,980 --> 00:45:11,440
one of the recurrent classes, and then the time span in the initial transient state can be calculated from here.

346
00:45:12,910 --> 00:45:18,880
So it depends on where you start. So you can read off all of this image from this kind of matrix.

347
00:45:19,810 --> 00:45:27,130
Yeah. And then if you're interested, you can sum over to the column songs or compute the.

348
00:45:28,090 --> 00:45:35,650
Yeah. So there are a few examples there. There are also application of using image to figure out the.

349
00:45:38,390 --> 00:45:46,160
The probability that return ever return probability to all the ever return probability will be always one,

350
00:45:46,160 --> 00:45:51,160
but means that return probability within the class.

351
00:45:51,170 --> 00:45:55,160
So that's in the like terminals. We don't need to go over here.

352
00:45:58,240 --> 00:46:01,410
All right. So this is kind of a topic we've.

353
00:46:04,050 --> 00:46:09,330
Compliments that work there just a little bit.

354
00:46:10,770 --> 00:46:24,150
Kind of a flavor. Not all the mark, all the chains are accorded Markov chain, but sometimes you can break it down and we can still study this.

355
00:46:28,230 --> 00:46:36,960
All right. The next topic, we're going to move on to the reversible Markov chain, the tiny reversible mark.

356
00:46:37,890 --> 00:46:43,500
Okay. So those are particularly important to for the purpose of application.

357
00:46:43,710 --> 00:46:48,590
So we're going to talk about next Wednesday.

358
00:46:49,380 --> 00:46:50,940
Markov chain, Monte Carlo.

359
00:46:51,480 --> 00:47:02,340
We need to construct a markov chain with a target distribution, with a target stationary distribution and to be able to construct.

360
00:47:02,340 --> 00:47:05,900
So now we have there's the different things, right?

361
00:47:05,910 --> 00:47:11,220
So far we have we are given the Markov chain and we're studying the long run behavior.

362
00:47:11,730 --> 00:47:14,880
Now it's like an engineering problem.

363
00:47:15,150 --> 00:47:19,049
I want to get the stationary distribution like this.

364
00:47:19,050 --> 00:47:27,480
How do you construct a markov chain such that in the long run, the Markov chat will give you the stationary distribution,

365
00:47:27,780 --> 00:47:33,450
so you will have the flexibility or you have the freedom to construct that Markov chain.

366
00:47:33,690 --> 00:47:41,490
You want your job a lot easier, right? Do that. Consider construct some transient state and make your own life miserable.

367
00:47:43,410 --> 00:47:55,200
So in that case, we can even obviously you can construct a periodic Markov chain, irreducible Markov chain and rethink this being positive recurrent.

368
00:47:55,740 --> 00:48:07,410
However, to make sure the target distribution is what you want, you probably need this additional property.

369
00:48:07,860 --> 00:48:16,140
So what we're going to study next is going to be of a again, a special class according to Markov chain.

370
00:48:16,230 --> 00:48:24,590
So avoiding Markov chain, already a special class within all of these are going to study a little bit more on.

371
00:48:29,110 --> 00:48:33,670
A special subclass. So this is a second topic.

372
00:48:34,390 --> 00:48:38,770
Tiny reversible. Reversible, reversible.

373
00:48:42,100 --> 00:48:46,989
So the reversible Markov chain, the concept come from, you know,

374
00:48:46,990 --> 00:48:55,540
it's really important to recall what stochastic process is, is the infinite collection of random variables.

375
00:48:56,140 --> 00:49:02,110
So usually, well, there is no notion of time, right?

376
00:49:02,890 --> 00:49:07,630
The time is kind of a superimpose. The order of index.

377
00:49:07,960 --> 00:49:13,270
All we need is a kind of a collection of random variable by in the Markov chain we

378
00:49:13,270 --> 00:49:19,270
talk about time because this correlation structure is related to the sequence,

379
00:49:20,560 --> 00:49:27,400
right? So if you have to have a order to talk about the past in the future and then to present.

380
00:49:28,480 --> 00:49:36,190
Right. Nevertheless, those kind of those kind of label is pretty arbitrary.

381
00:49:36,190 --> 00:49:40,330
What is your past and the future and what's your present?

382
00:49:40,450 --> 00:49:47,620
I don't mean to sounds very philosophical is surely mathematical this this in this sense.

383
00:49:47,650 --> 00:49:57,190
Right. So the reversible Markov chain is, if you can imagine, you have a finite collection and you find a sequence of random variables.

384
00:49:57,430 --> 00:50:01,749
If you look one way, there's a from the positive to the future.

385
00:50:01,750 --> 00:50:06,280
And then you can look at that the other way as a from the future to the past,

386
00:50:06,670 --> 00:50:12,010
there are mathematically equivalent because you have an infinite sequence.

387
00:50:13,030 --> 00:50:17,290
So this is a the concept of the the reversible Markov chain.

388
00:50:18,100 --> 00:50:21,969
So the time reversible Markov chain, it's always a markov chain.

389
00:50:21,970 --> 00:50:31,480
So that's should be clear, right? So that the conditional independence collect relationship doesn't really depends on how you look at this.

390
00:50:31,690 --> 00:50:40,360
If you're conditional on the present that the the disconnected in two parts so usually in the of in the

391
00:50:40,360 --> 00:50:51,710
DAG so this is an interesting being if they're interested you should everyone I think should study only.

392
00:50:52,180 --> 00:50:56,050
Is that right?

393
00:50:56,230 --> 00:51:12,390
So this is not directed but you can often not recognize that right is a signaling is wrong.

394
00:51:15,340 --> 00:51:24,579
So the dag is a very powerful to tool encode the conditional relationship and then the Markov

395
00:51:24,580 --> 00:51:32,409
chain has this simple structure is running from the past to the future and the that is

396
00:51:32,410 --> 00:51:37,900
basically saying the Markov property but that basic saying if I conditional on the present

397
00:51:38,440 --> 00:51:43,930
that essentially is connected to the chain that this part of this part becomes independent,

398
00:51:45,020 --> 00:51:50,020
right? So this is kind of a fact of language. It's not always we would get talk about that, right?

399
00:51:50,040 --> 00:51:53,109
So I know something about Collider.

400
00:51:53,110 --> 00:52:00,700
I remember. So in that sense of if it read the backwards sequence,

401
00:52:00,700 --> 00:52:08,200
it's still dealing with the same random variable and their dependance relationship is not changed.

402
00:52:11,350 --> 00:52:25,350
Therefore, the back work sequence of a markov case you mark and if you are really trying to prove it, it's really simple to prove actually.

403
00:52:25,810 --> 00:52:40,810
And so all you need to do is trying to show the probability of x t, conditional x, t plus one, x plus two and so on and so forth.

404
00:52:41,740 --> 00:52:47,559
So you see if you can simplify this into the x, t and then the x plus one, right?

405
00:52:47,560 --> 00:52:59,200
So the sequence really doesn't matter because you can all this whole thing isolate, say something like Q We call this this whole collection of run.

406
00:52:59,200 --> 00:53:06,819
The third was. Q So this is trying to show that it's actually plus one and.

407
00:53:06,820 --> 00:53:26,230
Q So if we just create a notation, the shorthand notation, this Y equals X plus one X, if you divide it by probability of x plus one.

408
00:53:28,030 --> 00:53:31,960
All right. So this is drawing the condition off.

409
00:53:32,830 --> 00:53:36,130
And then from there, everything becomes pretty simple.

410
00:53:36,430 --> 00:53:44,770
All you need to do is rearrange the terms. You light up the future conditional on the past.

411
00:53:44,890 --> 00:53:49,720
So this is this is the future. The Q Conditional on the present.

412
00:53:51,310 --> 00:54:04,480
Well, the present. The past. And then multiply by divided by the same thing.

413
00:54:04,490 --> 00:54:09,280
You can rearrange this, you x plus one.

414
00:54:10,090 --> 00:54:14,200
The probability is one. All right.

415
00:54:14,320 --> 00:54:18,969
So right here your constant ball to invoke the Markov property.

416
00:54:18,970 --> 00:54:22,570
And this is past. This is the present.

417
00:54:22,780 --> 00:54:26,409
This is the future. The Q is over T plus one.

418
00:54:26,410 --> 00:54:35,110
So this one becomes irrelevant. And now you get a cancelation here that shows you can show is this.

419
00:54:35,320 --> 00:54:41,500
Well, that's t conditional, right?

420
00:54:41,620 --> 00:54:51,069
So if the forward sequence is Marcos, the backwards sequence is also this usually goes without saying.

421
00:54:51,070 --> 00:54:55,210
But if you are if you're trying to prove it.

422
00:54:57,930 --> 00:55:04,770
All right. Now, what we're going to consider is a warning mark of changing the bank or sequence of.

423
00:55:12,370 --> 00:55:20,680
Sequins, often gaudy ibises.

424
00:55:22,180 --> 00:55:31,000
All right. So this becomes more interesting. So if you want to run the chain long enough and then look at the chain backwards.

425
00:55:31,360 --> 00:55:40,000
So there has to be that because it's a Baltic Markov chain, you have to run the chain long enough.

426
00:55:40,360 --> 00:55:44,140
So the chain must enter into a stationary distribution.

427
00:55:44,890 --> 00:55:51,110
That's assumptions or related to the back for sequence you are looking at right by core sequence.

428
00:55:51,130 --> 00:55:56,140
You have to conceptually understand also I use that sequence, right?

429
00:55:56,170 --> 00:55:59,150
So this is a clue.

430
00:56:01,270 --> 00:56:23,800
So with this margin with transition, we just add in more things transition probability, transition kernel, PJ and stationary distribution.

431
00:56:27,140 --> 00:56:33,310
Hi. All right.

432
00:56:33,310 --> 00:56:41,860
So if you look at the backcourt sequence, then you are looking at identically distributed random variables.

433
00:56:41,860 --> 00:56:45,190
And all of these random variables has the same.

434
00:56:45,240 --> 00:56:51,970
All all of them have the same marginal distribution defined by the marginal but defined by the stationary distribution.

435
00:56:52,240 --> 00:57:00,549
And. All right, so if you look at the backport sequence, we call this the Q, I use Q to many times today.

436
00:57:00,550 --> 00:57:08,980
But in here this is the transition kernel for the backport sequence from I to J.

437
00:57:09,550 --> 00:57:23,830
Specifically, this means the probability of x t equals two j given x t plus one equal to on the right.

438
00:57:24,040 --> 00:57:33,130
So the backwards kind of transition kernel should be related to the pie g, the forward transition kernel.

439
00:57:33,610 --> 00:57:54,940
And then this is the easy thing to figure out because again, we're going to use the joint x, t j x plus 1.5 divided by the probability x t plus one Y.

440
00:57:56,470 --> 00:58:05,890
Right. And all we need to do is write the numerator into the transition,

441
00:58:06,010 --> 00:58:16,540
the forward transition C kernel and then the stationary distribution you've already seen because all of these keys are essentially goes to infinity.

442
00:58:16,540 --> 00:58:29,709
So this is of you look at the back for a sequence of for example, now you know, the x key party y equals to I.

443
00:58:29,710 --> 00:58:32,940
Now probability is pi of ii. Right?

444
00:58:33,070 --> 00:58:36,220
And then as.

445
00:58:40,580 --> 00:58:45,080
So just following from the top, you can write this interview.

446
00:58:49,360 --> 00:58:59,410
I know Jay all you want, but Jay.

447
00:59:02,670 --> 00:59:06,550
It's possible. All right.

448
00:59:06,790 --> 00:59:18,190
So everything I know in this expression, the first term, in the numerator, it's essentially t j I've.

449
00:59:38,370 --> 00:59:47,250
And then the second term is hygiene and the denominator is higher.

450
00:59:48,360 --> 00:59:59,120
All right. So just put everything together. So this is a Q and by and j equals pi.

451
00:59:59,220 --> 01:00:05,820
J j. I. Divided by probably.

452
01:00:08,460 --> 01:00:19,710
So. So this conclusion holds for over the according to Markov chain.

453
01:00:19,740 --> 01:00:34,740
If you look at the blackboard sequence, you see a different Markov chain with the transition kernel being q i j equals pi j p g divided by pi.

454
01:00:35,610 --> 01:00:41,849
All right. So you may want to figure out. Well, I mean, the bank or sequence representing the Markov chain.

455
01:00:41,850 --> 01:00:45,390
Right. Is that also according to Markov training?

456
01:00:47,940 --> 01:00:53,250
Think about it. If it if it is, what is the stationary distribution should be?

457
01:00:57,370 --> 01:01:00,520
It's not trivial, but the answer should be intuitive.

458
01:01:01,530 --> 01:01:09,170
I'm not giving up the answer. No. Think about it. Think about the probate court sequence for General Gordon Chang.

459
01:01:10,360 --> 01:01:19,900
No. So this is a fought general, aborted Marshall, as I said, the so-called the time reversible mark off chain.

460
01:01:20,380 --> 01:01:27,500
It's a special case. It's going to be a special class of this unfortunate mark off chain.

461
01:01:28,540 --> 01:01:35,350
So why it's special? So this tiny, reversible Markov chain has the following property.

462
01:01:42,470 --> 01:01:46,390
So is about the fascination.

463
01:01:49,890 --> 01:01:58,740
First of all, I'm so hungry.

464
01:01:58,740 --> 01:02:05,260
First of all, MARKOFF Essentially, there is no difference from mathematical point of view.

465
01:02:05,280 --> 01:02:14,760
If you run the Markoff chain for a markov chain, forward or backwards, you know, specifically we're talking about if.

466
01:02:17,790 --> 01:02:23,880
Q Hi, AJ, this commentary was all right.

467
01:02:24,060 --> 01:02:28,200
So this is a ask. This is not a given.

468
01:02:29,070 --> 01:02:34,560
This is a strong assumption that she did not well, in most cases is not important.

469
01:02:35,520 --> 01:02:39,239
However, if you are getting this conclusion for.

470
01:02:39,240 --> 01:02:47,820
Q, are you going to pick PJ? Or all the ages.

471
01:02:49,830 --> 01:02:56,370
Then we call the Olivier Award a marker of this highly reversible.

472
01:03:14,920 --> 01:03:24,280
So if in addition, normally we have if in addition we have this idea, you call the page,

473
01:03:25,300 --> 01:03:45,880
we call the underlying problems of war, you see, is this is called high and reversible.

474
01:03:49,640 --> 01:03:53,980
All right. Basically, you look at this to sequence, you cannot tell the difference.

475
01:03:54,190 --> 01:03:57,370
That's exactly what they set the for sequence.

476
01:03:57,370 --> 01:04:01,240
And then we're sequence has the same transition, Colonel.

477
01:04:02,080 --> 01:04:10,920
And then just to summarize this, we have so what the the condition can be precisely formulated.

478
01:04:10,930 --> 01:04:14,110
Is this so called a detailed balance equation?

479
01:04:14,710 --> 01:04:23,560
High PR, AJ e post, high energy, PGA or army training.

480
01:04:23,650 --> 01:04:29,440
I am involved in the state space.

481
01:04:30,460 --> 01:04:37,610
Right. So this is on. Actually don't quote this.

482
01:04:42,440 --> 01:04:52,760
So this is an enormous, difficult balancing operation, the balance.

483
01:05:01,910 --> 01:05:11,900
So this is the definition if you have. So if you have a gaudy markov chain and then it satisfies the detailed balance equation,

484
01:05:12,380 --> 01:05:17,820
again here, the detailed balance equation only related to the page.

485
01:05:18,500 --> 01:05:27,400
Right. So the transition kernel determines that because PI over this stationary distribution is determined by PI.

486
01:05:27,410 --> 01:05:37,610
AJ Right. There is a relationship in the governing theorem saying how the pi pi day related to the the pie.

487
01:05:38,660 --> 01:05:46,129
So, so pie and the opinion page in fact a function of pi and that in addition.

488
01:05:46,130 --> 01:05:51,020
So this is stronger ask of the pie pages.

489
01:05:52,280 --> 01:05:59,660
If the detail balance equation is satisfied. In addition, then we call this hypo reversible Markov chain.

490
01:06:10,900 --> 01:06:14,710
So we have a proposition related to.

491
01:06:17,420 --> 01:06:26,170
So this definition. Just think about the logical view, the way we need to first to have a working Markov chain when you can figure all of the pie.

492
01:06:26,390 --> 01:06:30,470
J And then further we examine this detail balance equation.

493
01:06:30,770 --> 01:06:36,710
Then we can confirm the underlying Markov chain is a type reversible Markov chain.

494
01:06:37,430 --> 01:06:48,770
So the next proposition, probably the last thing we want to talk about today is saying you can skip some of the steps I just said.

495
01:06:49,220 --> 01:06:54,320
So if you have a gaudy Markov chain, you don't really need to calculate by a page.

496
01:06:54,650 --> 01:07:03,800
If you already find a solution to detail balance the equation, the on the right Markov chain is is a type of reversible Markov chain.

497
01:07:03,920 --> 01:07:15,139
Okay, so that's the proposition, too. So now we have two different ways to come up with to assert if avoiding Markov

498
01:07:15,140 --> 01:07:19,549
chains time reversible one is through destination must through definition.

499
01:07:19,550 --> 01:07:24,350
You need to first figure out this is a stationary distribution.

500
01:07:24,590 --> 01:07:30,950
So the proposition that we're going to discuss next will let you skip that step.

501
01:07:35,360 --> 01:07:40,270
So this is a proposition to an electron.

502
01:07:40,280 --> 01:08:01,099
Also suppose that, suppose that so there exists an x jackie so this is intended to be that your target stationary distribution but

503
01:08:01,100 --> 01:08:13,580
you're not calling it stationary distribution yet there exists such that the summation of x is equal to one.

504
01:08:14,090 --> 01:08:17,860
Again, this doesn't have to be a finite number of hashes.

505
01:08:18,050 --> 01:08:24,890
It could be infinite sequence as long as we are comfortable comfortably in the.

506
01:08:30,050 --> 01:08:42,010
And. The detailed balance equation outside PJM East Coast Acts.

507
01:08:42,050 --> 01:08:45,170
J. P. J. I.

508
01:08:50,970 --> 01:08:59,580
So this detailed balance equation has to be satisfied for and according to chain.

509
01:09:04,890 --> 01:09:08,430
Okay, now. Well, I think the setup is very different.

510
01:09:08,460 --> 01:09:19,530
You have a supporting Markov chain. You get the page pi, e.g. by you didn't calculate the you haven't calculated the pi apj yet.

511
01:09:20,370 --> 01:09:27,630
Just a stationary distribution. Sorry. No, not the stationary distribution, just the detailed balance equation.

512
01:09:28,230 --> 01:09:31,430
For some reason, you just want to check the detail balance equation.

513
01:09:31,980 --> 01:09:41,470
I'm only satisfied for all the pi day. So the solution for the balance equation is here.

514
01:09:42,850 --> 01:09:52,750
And then the advocacy on the right and the important mark on change is tiny, reversible.

515
01:10:00,250 --> 01:10:08,290
And I think you put that aside for a while.

516
01:10:09,160 --> 01:10:17,049
All right. So is that still balance the equation to satisfy the for all the pairs of I and J than

517
01:10:17,050 --> 01:10:23,800
the x i so this exon j indeed that represents the underlying stationary distribution.

518
01:10:24,280 --> 01:10:29,400
So this is the importance of the on the proposition too.

519
01:10:29,470 --> 01:10:35,230
So if you if you can examine the detail,

520
01:10:35,230 --> 01:10:44,380
balance the equation that you don't need to recalculate the pie pie j and then assert that the underlying Markov chains.

521
01:10:45,160 --> 01:10:49,070
So this is a very useful in terms of construction. Right.

522
01:10:49,180 --> 01:10:54,040
We have something like PIO Padre in mind. This is a like part of Monte Carlo.

523
01:10:54,550 --> 01:11:02,770
And now we're trying to deconstruct this. So obviously this give you all give us a shortcut we can only use.

524
01:11:02,800 --> 01:11:11,530
Well, we can try to make the the transition kernel satisfied with these help balance the equation then automatically down the line.

525
01:11:11,830 --> 01:11:19,150
So this is the reason that's important. If you are thinking about the point of view, you're trying to figure all this stationary distribution.

526
01:11:19,510 --> 01:11:22,550
This may not be very helpful way, right?

527
01:11:22,570 --> 01:11:26,530
Because the most of the morning Markov chain now going to be reversible.

528
01:11:28,360 --> 01:11:33,580
And then this, you know, if you are lucky, the underlying Markov chain is type reversible.

529
01:11:33,610 --> 01:11:37,660
You probably save some time. But it's not general solution they're trying to say.

530
01:11:37,900 --> 01:11:49,270
But it's a very useful or critically important thing for constructing the you know, for the algorithm like ma culture, Monte Carlo,

531
01:11:49,360 --> 01:11:58,600
which we will discuss hopefully next Wednesday, we still have some conclusion related to that time reversible Markov chain.

532
01:11:58,900 --> 01:12:02,200
There are some like symmetry, interesting symmetry.

533
01:12:03,810 --> 01:12:07,700
Properties in those time reversible mark of change.

534
01:12:08,160 --> 01:12:15,989
But we get the the most useful utility of this as really help you to construct the that the Markov

535
01:12:15,990 --> 01:12:21,690
chain gave you the target distribution give you a stationary distribution being your target.

536
01:12:22,450 --> 01:12:27,170
Okay. All right. Let's and here seems like a natural landing spot.

537
01:12:27,480 --> 01:12:31,020
No class next black Monday.

538
01:12:31,020 --> 01:12:32,140
Right looks can.

