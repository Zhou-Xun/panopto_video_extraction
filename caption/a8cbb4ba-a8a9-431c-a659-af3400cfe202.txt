1
00:00:00,390 --> 00:00:03,510
They're anxious to address the event to the point.

2
00:00:03,510 --> 00:00:07,050
I'm delighted to introduce you to Doctor, at least to me.

3
00:00:08,520 --> 00:00:12,569
Dr. Tony is a graduate from Fiji, a very recent graduate.

4
00:00:12,570 --> 00:00:18,840
He's now post-doc in psychiatry. His focus is on, let's see here a variety of things.

5
00:00:19,350 --> 00:00:28,330
But certain doses of virus is very different in global influences.

6
00:00:29,130 --> 00:00:38,760
Yeah. Oh, you're doing great. My current pitch is that I am a I'm a computational behavioral scientist with a focus on mental health,

7
00:00:38,760 --> 00:00:44,010
including suicide in global and domestic contexts. This took us a long time to write up.

8
00:00:44,160 --> 00:00:49,020
So, for example, in the computational behavioral sciences that works for the minus program,

9
00:00:49,020 --> 00:00:53,400
how many folks here are familiar with Minus here at U of M super cool initiative?

10
00:00:54,180 --> 00:00:59,070
All right, great. Well, I can tell you this about it. So minus stands for Michigan Data Science.

11
00:00:59,520 --> 00:01:02,880
And it's an initiative that's it's not exactly a department that's kind of like,

12
00:01:03,120 --> 00:01:08,940
I guess a, you know, cohort or whatever, but it's across the entirety of U-M.

13
00:01:09,630 --> 00:01:14,730
Lots of researchers, faculty and master level students participate in there,

14
00:01:15,090 --> 00:01:22,020
either certificate programs or they even have, I think, a master's level and a Ph.D. level add on.

15
00:01:22,380 --> 00:01:26,690
So I technically got a Ph.D. in each Maggie and Ph.D. in scientific computing.

16
00:01:26,700 --> 00:01:30,450
So that helps me on the job market. Like you look sexier in theory.

17
00:01:30,480 --> 00:01:31,620
We'll see how this plays out. I don't know.

18
00:01:32,640 --> 00:01:37,860
Anyways, I as just inside, I'm in psychiatry, I'm going to talk with you guys a little bit today about computing.

19
00:01:38,370 --> 00:01:44,399
I've tried to make this lecture really more sexual in nature as opposed to I'm

20
00:01:44,400 --> 00:01:48,629
not going to go through any code just because it's kind of a complex topic.

21
00:01:48,630 --> 00:01:51,030
And to get into the specific codes in the nitty gritty,

22
00:01:51,810 --> 00:01:56,220
I don't think it would be as helpful as more to give you a kind of an expansion of what the different methods are.

23
00:01:56,910 --> 00:02:02,120
I also am hoping that this class will be relatively interactive,

24
00:02:02,610 --> 00:02:07,259
so we just have some equity in teaching and rules of engagement up here as some kind of ground

25
00:02:07,260 --> 00:02:10,650
rules trying to think through as we start to interact with one another and with the material.

26
00:02:12,390 --> 00:02:15,420
So please take care of yourselves. Be as present as you can, but you need take a break.

27
00:02:15,510 --> 00:02:16,110
That's great.

28
00:02:17,070 --> 00:02:25,500
As we kind of talk with each other, if we have differences in opinions of let's try to critique the ideas and not a specific person or identity,

29
00:02:26,010 --> 00:02:29,069
and then I'm going to be asking you questions kind of an almost like a flipped

30
00:02:29,070 --> 00:02:32,430
classroom way where I'm going to be asking you to try to think through like,

31
00:02:32,430 --> 00:02:35,370
how would you do something before we necessarily go over it?

32
00:02:35,760 --> 00:02:41,669
It's totally okay to be like, Well, I don't know, but try to do your best to take a deep breath when that I don't know happens and be like,

33
00:02:41,670 --> 00:02:44,760
okay, well let's get some creative juices going in.

34
00:02:44,760 --> 00:02:47,909
Like, how might I try to engage with this? They're not going be right or wrong.

35
00:02:47,910 --> 00:02:51,030
Answers will just be thinking through some of those and then talking through some options.

36
00:02:52,080 --> 00:02:56,370
So thank to everyone. I also have a problem of talking too fast.

37
00:02:56,490 --> 00:02:59,340
If I'm talking too fast, please raise your hand and be like, Yo, Elise,

38
00:02:59,850 --> 00:03:04,950
slow it down because I get really excited and then just it comes out very fast.

39
00:03:06,060 --> 00:03:14,960
All right. Let's get going. So I'm going to ask that you guys take a quick little poll and answer this now.

40
00:03:17,510 --> 00:03:26,470
I think it should be active. Text.

41
00:03:27,130 --> 00:03:34,720
You can text or you can go to the pull ebay.com slash and these two in 091 and then you should be able to submit some answers.

42
00:03:38,710 --> 00:03:44,690
It will be using the same URL or text code for a couple of different activities.

43
00:03:44,710 --> 00:03:48,040
So hopefully this will just be the one time people enter it in.

44
00:03:48,290 --> 00:03:53,410
But feel free to keep it up and refresh as necessary if you're going from a web based space.

45
00:04:31,790 --> 00:04:50,950
You send? I wonder if that's.

46
00:04:53,460 --> 00:05:02,460
Steve, quick. I can see them on my screen, but I'd like to see them.

47
00:05:02,530 --> 00:05:06,970
I think it's because of the add on. We?

48
00:05:26,180 --> 00:05:39,490
You feel inside? There no way to, like, cast from my laptop, right.

49
00:05:41,130 --> 00:05:45,950
Oh. Maybe.

50
00:05:50,930 --> 00:06:07,490
You would need to have the dongle that kind of connects to that center, or there's also these guys in or in quality that's I get let me see if I can.

51
00:06:12,710 --> 00:06:16,490
How about this other shot at what you guys wrote? And then I'll let you start on the next one. I'll try to figure this out on the side.

52
00:06:19,910 --> 00:06:31,580
Okay. So we have some ideas, including research data, quantitative numbers, numbers in numerical numeric constructs.

53
00:06:33,450 --> 00:06:36,750
Things like like those types of words and that's like spot on.

54
00:06:36,990 --> 00:06:45,930
So the next question I have for you guys as I try to do some quick 80 is what is.

55
00:07:04,380 --> 00:07:08,050
Over. The next question is what is qualitative research?

56
00:07:08,070 --> 00:07:14,640
Just go ahead and throw up some ideas to that same spot.

57
00:07:14,790 --> 00:07:18,300
Let me see if I can sort this out.

58
00:08:11,410 --> 00:08:15,010
Yeah. Yeah. Okay, great. Sorry about that, guys.

59
00:08:17,470 --> 00:08:26,290
All right, great. So, non numeric constructs, descriptive hypotheses, relationships.

60
00:08:27,620 --> 00:08:30,680
Context interview. Awesome.

61
00:08:31,130 --> 00:08:40,280
Those are all great ideas. So the way in which we think about quantitative and qualitative research is often with this kind of dichotomy,

62
00:08:40,820 --> 00:08:44,300
and particularly in traditional statistics, those dichotomy are generally separated.

63
00:08:44,630 --> 00:08:48,400
Unless we're doing what's called mixed methods, at which point they're still separate.

64
00:08:48,410 --> 00:08:52,670
But you do them in ordinal pattern, either quantitative and qualitative all in one.

65
00:08:53,370 --> 00:08:58,340
What we're going to talk about kind of mixes the methods a little bit and it gets a little bit more nuanced.

66
00:08:59,330 --> 00:09:02,480
So, all right.

67
00:09:04,700 --> 00:09:10,999
We're going to start with out with the case study. So the problem that I'm proposing to you all is based on the literature,

68
00:09:11,000 --> 00:09:16,760
which is that most about most of what we know about substance use recovery comes from clinical literature.

69
00:09:16,790 --> 00:09:24,110
So clinical populations meeting like in-patient type treatment or treatments or patients that are identified through hospital systems.

70
00:09:24,710 --> 00:09:29,120
Yet 90% of those who achieve complete recovery, meaning that they're no longer class,

71
00:09:29,270 --> 00:09:34,100
they would no longer be classified as having given substance use disorder, don't actually go through formal treatment.

72
00:09:35,510 --> 00:09:37,910
So that's kind of crazy, right? Like, that's that's a lot.

73
00:09:38,740 --> 00:09:43,309
And so we want to kind of learn more about the informal recovery pathways from cannabis use disorder,

74
00:09:43,310 --> 00:09:46,530
specifically, which is resulting from cannabis dependance.

75
00:09:46,550 --> 00:09:50,000
This is a growing area of interest, particularly given the mass legalization.

76
00:09:50,330 --> 00:09:57,979
And then there's kind of a historical and disenfranchisement aspect of the fact that marijuana, the use of marijuana,

77
00:09:57,980 --> 00:10:03,830
has been very criminalized in different ways based on certain racial and other sort of sociodemographic features.

78
00:10:04,880 --> 00:10:12,140
So understanding cannabis use disorder and how that plays into different identities as well as the different pathways is going to be really important.

79
00:10:12,140 --> 00:10:18,680
And yet we know very little about this right now. So, I mean, how do you guys think per share for about 3 minutes?

80
00:10:19,310 --> 00:10:26,540
I want you guys to kind of think about how would we gather data and information about recovery in formal specifically recovery pathways.

81
00:10:39,630 --> 00:11:00,770
So I think that like you get it like a little easier just to be a welcome to join in too, if you like.

82
00:11:03,320 --> 00:11:22,740
Maybe background. It seems like in some of the I think like I like this, I think all of you could be rejected for the service.

83
00:11:23,020 --> 00:11:26,409
I think that. You're welcome to come.

84
00:11:26,410 --> 00:11:30,760
Tell me about your ideas. We're just saying.

85
00:11:30,760 --> 00:11:36,670
And, Jeff, I saw you before the legalization of cocaine.

86
00:11:38,360 --> 00:11:48,850
And historically, you talk about racial disenfranchisement, emancipation, the effect it has on countries where it's produced.

87
00:11:49,180 --> 00:11:54,490
Mm hmm. Having such an interested in financial interest in other countries, that probably means so much violence.

88
00:11:54,940 --> 00:11:59,980
The interesting, really interesting proposition.

89
00:12:00,350 --> 00:12:05,740
Yeah. Especially in like in the U.S., there's like crack versus like powder.

90
00:12:06,160 --> 00:12:10,540
And there's like definitely sociodemographic differences in terms of like the way

91
00:12:10,540 --> 00:12:15,399
that it's like legally criminalized and the methods around it and things like that.

92
00:12:15,400 --> 00:12:22,630
But also like another war, the war on drugs that we're importing that's, you know.

93
00:12:23,120 --> 00:12:28,020
Oh, cool. Interesting. Yeah, she's great. Yeah.

94
00:12:28,480 --> 00:12:32,110
And it's like they're not that hard to talk about.

95
00:12:32,110 --> 00:12:37,100
Actually, I had about 30 seconds, and then I'm going to ask you groups to share some of the gap.

96
00:12:37,150 --> 00:12:49,210
Who wants to share? Making that announcement as it gets really quiet doesn't a really great conversation.

97
00:12:50,020 --> 00:12:53,230
Hey, if we could have like two or three people show some ideas.

98
00:12:56,300 --> 00:13:08,310
Just turn. And I realized that just through work, I've come across a lot of anonymous meetings and Michigan happens to have one of my.

99
00:13:10,700 --> 00:13:14,959
And and structures and usually women.

100
00:13:14,960 --> 00:13:21,680
And you have folks that are there, they've stopped all drug use and most likely alcohol as well.

101
00:13:21,710 --> 00:13:31,490
So they have started the recovery process. And more often than not, cannabis is something that they've also done in addition to other drugs.

102
00:13:31,490 --> 00:13:41,000
It could be a drug that is common and that would be a great place to obtain information on recovering.

103
00:13:41,000 --> 00:13:48,160
That's not clinical. Obviously you do have some things to set up to be able to talk to folks.

104
00:13:48,270 --> 00:13:52,580
The phone part of it is anonymous. Yeah, great idea.

105
00:13:52,880 --> 00:13:59,180
Another one from another group in the back would classify as a disorder for cannabis.

106
00:14:00,020 --> 00:14:06,470
It's a great question. So within the DSM five, which is like the psychiatry's like handbook, essentially, right?

107
00:14:06,870 --> 00:14:20,000
And it's, it's like use that, it's like kind of disrupting normal like everyday activities, including like social relationships.

108
00:14:20,420 --> 00:14:27,499
And it's not being able like it's, it's having a dependance where you're not able to not use within a given amount of time.

109
00:14:27,500 --> 00:14:33,410
So if you can't, like if someone feels like they can't go 24 hours without using, I think that's one of the clinical features.

110
00:14:33,950 --> 00:14:39,410
But there's like a list of them you can look at that for us so that they use it.

111
00:14:41,180 --> 00:14:44,450
We arrive at the day the day function.

112
00:14:45,390 --> 00:14:46,860
Still classified as a disorder.

113
00:14:49,070 --> 00:14:55,790
If they're functional and it's not impairing their ability to function and be part of society, it's not considered a disorder.

114
00:14:57,350 --> 00:15:01,240
So then. Like you just need to know what I mean.

115
00:15:01,660 --> 00:15:17,200
But if they start to be unable to do their job or they get a OWI for driving while high or relationships are breaking down because of their use,

116
00:15:17,200 --> 00:15:24,440
then those are all things that would be considered problematic and that makes it in this order that you appreciate.

117
00:15:24,480 --> 00:15:33,520
I'm not sure I appreciate the question, though, because the way that disorders like defined and like actual experience abuse,

118
00:15:33,520 --> 00:15:35,470
like those don't always go together super well.

119
00:15:36,160 --> 00:15:42,760
So there are individuals we'll get to some data in a little bit, but we'll say like, you know, I don't feel like I'm like hitting rock bottom.

120
00:15:42,760 --> 00:15:48,180
I still have functional relationships, but I'm like I feel like I'm like driven to use in such a way that like,

121
00:15:48,190 --> 00:15:51,790
I'm not being present for some relationships or I'm not as like successful at work

122
00:15:51,790 --> 00:15:57,460
or it's impacting my sleep or like things like that where they're just like, I'm not living the life I really want to achieve.

123
00:15:57,790 --> 00:16:03,430
And I'm identifying that like this particular behavior of substance use is one of the reasons why I'm not achieving that.

124
00:16:04,030 --> 00:16:07,030
And I think that is a good way of kind of approaching like, okay.

125
00:16:07,340 --> 00:16:08,709
And especially when we think about recovery,

126
00:16:08,710 --> 00:16:15,070
because recovery has traditionally been thought of as like they kind of the NRA approach of like cessation of all substances,

127
00:16:15,070 --> 00:16:17,799
which it doesn't match until it experiences. For some people,

128
00:16:17,800 --> 00:16:24,670
like there's one substance maybe that their body just does crave and so they should like they decide not to use it because it does become disruptive,

129
00:16:24,670 --> 00:16:30,940
but they can still use other substances recreationally and not have the same challenges, etc.

130
00:16:31,960 --> 00:16:39,700
That's the question, I guess where I keep going. Those are good questions and thoughts on that.

131
00:16:40,030 --> 00:16:43,000
So we're going to link a lot of that data from tech and social media.

132
00:16:43,360 --> 00:16:51,679
I'm one of the challenges of I'll go back and talk about why the challenges of collecting data from like RNA or A and A is Narcotics Anonymous.

133
00:16:51,680 --> 00:16:55,180
AA is Alcoholics Anonymous is this idea of anonymity.

134
00:16:55,180 --> 00:17:05,590
Right. And there's generally not a lot of enthusiasm from like the A and A groups to have researchers present for really obvious reasons,

135
00:17:06,310 --> 00:17:09,040
in part because like it's just entirely confidential.

136
00:17:09,040 --> 00:17:14,890
So if you have to have someone say a consent form where they're providing their information that violates that idea of anonymity,

137
00:17:16,030 --> 00:17:20,079
etc., so that becomes challenging. There's some ethical questions around that.

138
00:17:20,080 --> 00:17:29,469
It's a great idea and it's challenging. And one way that we can collect it is and again, there's an ethics around this too, that we can talk through,

139
00:17:29,470 --> 00:17:32,560
but we're going to think about like the social media and the test of tech to

140
00:17:32,560 --> 00:17:37,540
use the data available through public forums and things like that as a method.

141
00:17:39,190 --> 00:17:44,950
So there's lots and lots and lots of forms of social media and socially related health apps that data can come from.

142
00:17:45,370 --> 00:17:49,870
And I'm guessing you guys recognize, even if there's not a name on it, some of these icons,

143
00:17:51,970 --> 00:17:58,420
just as a quick raise of hands, does, do do they would not have at least one of these on one of their devices right now.

144
00:18:01,120 --> 00:18:06,129
Yeah, exactly. Like here's like have you have multiple of these eight like yeah.

145
00:18:06,130 --> 00:18:13,940
So these are really present in our lives and like it's only like.

146
00:18:15,980 --> 00:18:23,040
Oh, my gosh. So smartphones are really present in our lives, like more than like 90% of adults have them.

147
00:18:23,040 --> 00:18:27,750
It's more like 95% or 99% depending on the poll that you're using in the sampling frame.

148
00:18:27,990 --> 00:18:34,620
But it's pretty ubiquitous. And this data on the left is a little bit older.

149
00:18:34,860 --> 00:18:38,460
I couldn't find newer one, but this is from like around 2014. So again, this is like almost eight years old.

150
00:18:38,580 --> 00:18:39,870
This is actually much higher now.

151
00:18:40,560 --> 00:18:46,740
But you can also see the projection of the market size as the expectation of like how this is going to continue to grow.

152
00:18:46,770 --> 00:18:48,330
So we have a big market for it.

153
00:18:49,350 --> 00:18:54,089
This is problematic in some ways because capitalism and because of data surveillance issues, we're not going get into those today.

154
00:18:54,090 --> 00:18:57,720
But if you're interested, feel free to come after me and talk a lot about that.

155
00:18:58,530 --> 00:19:02,970
But you can see like we're using our online spaces and our like tech to access health stuff a lot.

156
00:19:05,760 --> 00:19:10,640
This also plays into news and media consumption, which, you know,

157
00:19:10,680 --> 00:19:17,340
we can think about from like a political side of things and know that that can be problematic based on like fake news or biased news, etc.

158
00:19:17,700 --> 00:19:21,989
But we can also think about the health implications, which we all know clearly about relative to COVID.

159
00:19:21,990 --> 00:19:26,100
But we can see roughly half of Americans got some news about COVID 19 vaccines.

160
00:19:26,850 --> 00:19:30,810
The survey was conducted in 2021. So just a point of reference.

161
00:19:31,380 --> 00:19:34,380
And so that's important to know.

162
00:19:34,420 --> 00:19:36,270
Like, social media is playing a really,

163
00:19:36,270 --> 00:19:41,340
really big role in how people are like learning about the world and how they're thinking about the world potentially.

164
00:19:45,660 --> 00:19:49,800
And then this just shows that like people are using more social media over time.

165
00:19:50,280 --> 00:19:55,530
But there are some differences by demographic group. We're not going to get into that quite as much.

166
00:19:55,950 --> 00:20:01,080
This does play, though, a role in terms of limitations from some of stuff I'm going to show you in a few minutes,

167
00:20:01,560 --> 00:20:05,910
which is our it's really important to consider in terms of our sampling frames.

168
00:20:09,180 --> 00:20:13,390
Up lotteries. All right, we're back to this.

169
00:20:15,990 --> 00:20:22,720
How do I get out of this? Justin, do you have any ideas?

170
00:20:23,140 --> 00:20:29,320
I can't accept present remote up in the sky and send it to ASCII.

171
00:20:29,320 --> 00:20:33,520
It's not working weirdly and show them. Okay.

172
00:20:34,750 --> 00:20:39,400
So the next question is what right here?

173
00:20:41,830 --> 00:21:19,320
What kinds of data do you guys think can be drawn from social media? Yeah.

174
00:21:19,720 --> 00:21:24,459
Opinion. Attitudes. Influencers. Usage marketing patterns of use.

175
00:21:24,460 --> 00:21:29,440
Demographics. Yeah.

176
00:21:29,880 --> 00:21:34,230
Mm. Flex time you can add or remove for size.

177
00:21:34,260 --> 00:21:40,350
Yep. Mm hmm. I'm.

178
00:21:45,650 --> 00:21:51,740
Yeah. Yeah. So you guys are identifying a kind of a variety of types of data, right?

179
00:21:51,760 --> 00:21:58,490
There's some quantitative and qualitative. There are like quality features, like geographic location, which can be extracted.

180
00:21:59,010 --> 00:21:59,870
And so, again,

181
00:21:59,870 --> 00:22:04,940
kind of coming back to this like quantitative versus qualitative and the types of data we might be playing with within social media data.

182
00:22:05,450 --> 00:22:09,620
Both are present when we think about our statistically traditional approach of like one in four.

183
00:22:10,180 --> 00:22:16,730
Okay. All right. So I'm going to show you guys at some examples.

184
00:22:16,760 --> 00:22:21,650
These are Googling of like cannabis use disorder and them platforms.

185
00:22:22,730 --> 00:22:27,379
So and on the left hand side, you can see like there's a couple of different videos.

186
00:22:27,380 --> 00:22:30,380
On the right hand side are the comments related to that video.

187
00:22:30,740 --> 00:22:35,420
So in addition to the data that we could extract from the video itself, including the audio,

188
00:22:35,990 --> 00:22:44,540
the types of graphics being used, we can also extract things like likes, shares and then comments, which would be text data.

189
00:22:44,720 --> 00:22:48,800
This is from YouTube, this is from Facebook.

190
00:22:49,670 --> 00:22:52,670
And you can see there's videos and then there's like this Whitacre,

191
00:22:52,700 --> 00:22:59,030
which is a public group and they're sharing some information about this is more pro I'm more concise of pro.

192
00:22:59,060 --> 00:23:01,520
On the right hand side, more about cannabis use disorder.

193
00:23:02,450 --> 00:23:08,760
But again, we can see that there's like comments and shares in addition to the actual text of comments.

194
00:23:08,840 --> 00:23:12,380
So you guys are, you know, spot on in terms of thinking about the interactions that are occurring online.

195
00:23:12,860 --> 00:23:21,050
Again, we can pull out, you know, text from whatever written, but also audio, video, things like that because you views and time and date.

196
00:23:21,440 --> 00:23:24,799
Yes. And I'm sure there's ways around it.

197
00:23:24,800 --> 00:23:30,110
But how do you deal when you're collecting information? So how do you deal with like box and.

198
00:23:30,560 --> 00:23:34,190
Yeah, it's a good question. It can be tricky, right?

199
00:23:34,910 --> 00:23:39,560
I think part of this is being selective about which platform you use and the percentage of bots part of it.

200
00:23:39,800 --> 00:23:47,000
And there are like what they call it, kind of like black box methods where you just kind of put your dataset through the black box method.

201
00:23:47,000 --> 00:23:50,120
And it's a proven algorithm trying to pull out certain features,

202
00:23:50,120 --> 00:23:54,829
including about like is about is it not about those black boxes can be really

203
00:23:54,830 --> 00:23:58,489
problematic because of the potential biases if they're trained on Wikipedia.

204
00:23:58,490 --> 00:24:05,180
Wikipedia is mostly white men with some misogynistic, some racist, some nationalist meritocracy issues.

205
00:24:05,270 --> 00:24:12,260
So like, you know, we've seen other black box examples of like, you know, completing the sentence type half a sentence, and you see what auto fills.

206
00:24:12,590 --> 00:24:18,810
And we've seen differences, you know, in terms of like a man goes, a man's work is a woman's work is like, you know,

207
00:24:18,830 --> 00:24:24,440
there's like we've seen like differences in that as well as with, you know, by race, but ethnicity, by citizenship, things like that.

208
00:24:25,620 --> 00:24:31,129
But that's one way. The other thing is like when you're pulled off of like a Twitter or Facebook,

209
00:24:31,130 --> 00:24:37,580
you're gonna have more bots and we'll get we'll get into some websites like Reddit, identify bots.

210
00:24:38,140 --> 00:24:43,520
And I say like this, the bot like this is the Reddit bond which oh, great, here's Reddit.

211
00:24:44,540 --> 00:24:50,389
So you can see here as well, we've got like likes upvotes, downvotes in Reddit.

212
00:24:50,390 --> 00:24:53,990
You don't you can't see the number of upvotes and the number of downvotes. You just see that kind of like the mean.

213
00:24:54,680 --> 00:24:58,700
So that's different than, for example, YouTube where you could see both up and downvotes.

214
00:24:59,540 --> 00:25:04,930
You can also see the number of comments. And then on the right hand side, you have the original post as well as the comments.

215
00:25:04,940 --> 00:25:07,579
Just to give you guys an idea of what this looks like,

216
00:25:07,580 --> 00:25:19,250
if you were to click on a specific comment and this is from a a subreddit that I use a lot called Our Leaves, which is a can of association subreddit.

217
00:25:23,950 --> 00:25:28,419
Okay. And then something like tick tock where certain things are prohibited.

218
00:25:28,420 --> 00:25:33,520
So using like tick tock to study cannabis is much more tricky because of the way that like the terms

219
00:25:33,520 --> 00:25:38,110
of use that tick tock has where things like marijuana and cannabis are not allowed within the content.

220
00:25:38,620 --> 00:25:42,579
So there's like a lot of the pieces also in the background that have to be considered

221
00:25:42,580 --> 00:25:46,900
in terms of what is being brought up and presented to the person who's searching,

222
00:25:47,920 --> 00:25:54,880
what things are prohibited, what things are allowed, etc. The Internet is not really free speech when it comes to stuff like this.

223
00:25:57,430 --> 00:26:00,610
Okay. But how do we get this data? Ideas.

224
00:26:02,770 --> 00:26:03,790
You copy and paste it.

225
00:26:04,900 --> 00:26:12,580
Now, that's a bad idea because while taking forever to the inaccuracy rates high three, it's really hard to reproduce, etc. etc.

226
00:26:12,670 --> 00:26:17,230
So. No, we don't do that. Instead we use API and CAA.

227
00:26:17,320 --> 00:26:22,270
So this is where the computational piece comes in. An API is just software that helps send information back and forth.

228
00:26:22,390 --> 00:26:26,680
So when you take something into Google, you're asking for a query.

229
00:26:26,920 --> 00:26:30,310
It goes through the API, goes to the database, and it brings you back the results.

230
00:26:31,300 --> 00:26:35,800
That's an API. Okay.

231
00:26:37,210 --> 00:26:42,430
The only thing we need to think about when we are using social media data is public data and data access.

232
00:26:42,880 --> 00:26:50,740
So it's unethical and potentially illegal depending on how you go about it, to collect data that is not publicly available.

233
00:26:51,220 --> 00:26:55,690
There are ways to do it. You could get arrested, so I don't recommend that.

234
00:26:56,950 --> 00:27:01,960
But also, there's a lot of ethical questions like if people have private profiles and their data was not, you know,

235
00:27:01,990 --> 00:27:06,160
they are posting in a way that they're not anticipating that people are going to potentially be able to see it.

236
00:27:07,000 --> 00:27:11,200
We probably ethically shouldn't be able to to kind of scrape that data off the web,

237
00:27:11,650 --> 00:27:15,900
because when we scrape data off the Web, we're not asking for consent. It's it's passive, right.

238
00:27:15,910 --> 00:27:21,610
In the sense that, like, whatever we're scraping is considered public domain that's within the IAB regulations, right?

239
00:27:21,610 --> 00:27:25,780
So if you go through and try to scrape private data without permission, you're actually violating like,

240
00:27:25,780 --> 00:27:31,060
you know, company policies in terms of service, federal law, IAB practices, all that stuff.

241
00:27:31,380 --> 00:27:37,780
Okay. So this is one of those considerations that as you think through which platform or which type of question you want to ask,

242
00:27:38,350 --> 00:27:43,300
you have to kind of think through and you cannot ask every question you want to ask and not be able to ask through this way.

243
00:27:44,860 --> 00:27:49,630
And there's going to be some some things that are going to be problematic depending on how you go about it.

244
00:27:49,690 --> 00:27:53,080
Right. Which is very vague. I know. But where you get to some more concrete examples.

245
00:27:55,720 --> 00:28:00,010
Okay. So here are some examples of AVR that are available for researchers that are public.

246
00:28:00,880 --> 00:28:05,050
So there's Reddit, there's Twitter, tick tock of Facebook, there's a couple others,

247
00:28:05,050 --> 00:28:11,260
but these are the main ones I'll talk about briefly and then we'll get into some examples specifically with Reddit.

248
00:28:12,370 --> 00:28:17,950
So Reddit has two, two APIs right now that are publicly available.

249
00:28:17,980 --> 00:28:23,440
One is called PRA. That is the Reddit hosted API that actively queries.

250
00:28:23,470 --> 00:28:28,360
So if you put in a query through the API through prod, it's going to go at that.

251
00:28:28,360 --> 00:28:31,840
Like at the moment you're putting it in and go look at that moment to collect the data.

252
00:28:32,080 --> 00:28:37,540
Okay. Now, thinking about that, you can like and and like up like down like add comments and stuff.

253
00:28:37,690 --> 00:28:42,230
This type of query is not as stable because it's, it's consistently changing.

254
00:28:42,580 --> 00:28:46,480
Even if you're like, okay, I want between this date in this date, people can still go back and read,

255
00:28:46,570 --> 00:28:51,370
you know, post in the past and add additional like, like down likes or like comments, things like that.

256
00:28:51,580 --> 00:28:54,340
Okay, that's okay. That's just a consideration.

257
00:28:55,150 --> 00:29:04,059
Then there's also a catalog version called Push Shift, and that was established by a researcher who basically just collates like spends hours like,

258
00:29:04,060 --> 00:29:11,380
you know, and a lot of computational energy collating Reddit all the time on like every single subreddit.

259
00:29:12,250 --> 00:29:17,979
This is nice because it's a bit more stable, but you miss out on the new data that's coming in, right?

260
00:29:17,980 --> 00:29:23,410
It's not updated. It's just kind of like frozen in time that you know what the read it looked like at that date.

261
00:29:24,790 --> 00:29:32,350
Okay. Then there's Twitter. So Twitter through public APIs allows you to query like a very small percentage of tweets,

262
00:29:34,150 --> 00:29:36,580
and you can only put in a certain number of queries per month.

263
00:29:37,600 --> 00:29:43,210
You can apply for a greater access through academic accounts, which will give you access to the entirety of Twitter.

264
00:29:43,630 --> 00:29:48,520
There are still query limitations. You can't query more than, I think like 500,000 tweets in a month.

265
00:29:48,550 --> 00:29:54,160
Or maybe it's like a million tweets or 10 million. I can't quite remember, but it seems like a relatively large number.

266
00:29:54,160 --> 00:29:56,620
But when you start actually querying, it's not because people tweet a lot.

267
00:29:56,920 --> 00:30:02,020
And again, you're going to run into this issue of like bots and not being sure exactly if like what you might be getting.

268
00:30:02,020 --> 00:30:05,560
So that's something to consider. Tick tock has a new API.

269
00:30:05,860 --> 00:30:10,600
I've not used it, but it just came out. I want to say like maybe a couple months ago.

270
00:30:12,250 --> 00:30:16,420
That adds additional question of like videos and how do you process videos,

271
00:30:16,420 --> 00:30:20,140
which is a different computational skill as compared to just processing text or audio?

272
00:30:21,070 --> 00:30:26,110
So that's an interesting question. I have not yet seen people publish online and then excited actually one person's publisher and they

273
00:30:26,110 --> 00:30:30,340
did like a manual review qualitative manual revealed like ten videos and then like wrote it up,

274
00:30:30,940 --> 00:30:35,860
which is helpful but like not, you know, complete in terms of like all the stuff that's out there.

275
00:30:36,370 --> 00:30:44,290
And then Facebook has an API. I don't believe this is API is really meant for marketing, so I don't think it's as useful for health type research.

276
00:30:44,890 --> 00:30:51,190
And it's also only public facing accounts which a lot of stuff is no longer public facing on Facebook,

277
00:30:51,460 --> 00:30:55,570
which I think is a good thing, but you're just not going to get the same distributions because of that.

278
00:30:57,620 --> 00:31:00,710
Okay. I've just talked to you guys a lot and really sorry.

279
00:31:00,900 --> 00:31:04,580
So let's get back to our case study. You guys have a little bit more time to chat together.

280
00:31:04,760 --> 00:31:11,030
So we're going back to our original problem and goal to figure out what informal pathways of cannabis looks like use looks like.

281
00:31:11,420 --> 00:31:15,140
So we're going to gather a set of Reddit posts to analyze. We gather 30 of them.

282
00:31:15,770 --> 00:31:18,290
And my question to you is, how would you go about analyzing these posts?

283
00:31:18,440 --> 00:31:21,710
And I show you some examples of what the posts look like so you can kind of start to think through that.

284
00:31:22,430 --> 00:31:28,040
So here's three examples. So think of it as like a write in.

285
00:31:30,170 --> 00:31:35,050
So think about this. And then.

286
00:31:42,110 --> 00:31:45,290
When you're ready, go ahead and submit.

287
00:31:46,280 --> 00:31:49,400
I'm going to flip back to the presentation and then we can come back to that.

288
00:31:49,430 --> 00:31:59,000
How would you go about analyzing just so you have a chance to read it a little longer? Oh, I can, like, go like that.

289
00:31:59,390 --> 00:32:07,900
Is that big enough? I know that small. You can get closer, Justin.

290
00:32:58,700 --> 00:33:05,550
Switch back to the pool. Okay.

291
00:33:05,570 --> 00:33:13,870
Finding themes. Mm hmm. Mm hmm.

292
00:33:14,240 --> 00:33:33,290
Uh huh. Awesome.

293
00:33:33,320 --> 00:33:37,940
These are great ideas. And this really reflects the kind of the qualitative research approach, which is spot on.

294
00:33:38,570 --> 00:33:43,910
You're able to take time through all of the different posts, try to look for themes across posts,

295
00:33:43,910 --> 00:33:49,010
do some clustering maybe of themes you're doing counts of like how frequently those themes are occurring.

296
00:33:49,970 --> 00:33:56,660
One person said, Try to see if someone qualifies as having a substance use disorder, which for some posts they might.

297
00:33:56,720 --> 00:34:00,720
There might be enough information to do that. For other posts, it might be a little bit more ambiguous.

298
00:34:01,160 --> 00:34:04,580
So that's something to think about in terms of limitations of that approach.

299
00:34:04,580 --> 00:34:08,930
But it is possible to do. All right.

300
00:34:13,780 --> 00:34:14,940
So again, we you know,

301
00:34:14,950 --> 00:34:21,520
we kind of kind of touched a lot on this qualitative piece in terms of like taking building themes based on the what the data has in it.

302
00:34:21,850 --> 00:34:28,450
This is we can think of this as like an unsupervised method in the sense that we have not created a structure in which we're coding.

303
00:34:28,450 --> 00:34:31,480
Right. We're letting the data drive what comes out of it.

304
00:34:31,510 --> 00:34:35,950
We let the data kind of bring us to our conclusions about, oh, this theme is present across this data.

305
00:34:35,950 --> 00:34:40,750
Or like, oh, you know, this trend is, is in the data and that's what's, you know, we're going to present on.

306
00:34:41,920 --> 00:34:45,250
Alternatively, we have more of like what generally is like in quantitative work,

307
00:34:45,580 --> 00:34:49,000
although this is not true always, there are definitely quantitative methods that are unsupervised.

308
00:34:49,210 --> 00:34:56,170
But traditionally, when we're thinking about quantifying and categorizing texts to understand distributions, that's more of a quantitative approach.

309
00:34:57,010 --> 00:34:59,799
And we're like taking a robust, a primary clue about a thing.

310
00:34:59,800 --> 00:35:05,650
Like I want to look, for example, like, for example, like if they qualify as having a DSM disorder, that's an a priority.

311
00:35:05,720 --> 00:35:12,490
That would be kind of more like the quantitative. We're going to, you know, assign a01 20, this has it and doesn't have it and then go from there.

312
00:35:13,450 --> 00:35:23,360
And that's more of a supervised type method. Questions about unsupervised versus unsupervised in this moment will be continue to build on that idea.

313
00:35:27,220 --> 00:35:31,299
All right. So think share. We're going to have a few more than 30.

314
00:35:31,300 --> 00:35:37,870
30. We're going to have 300,000. How would you go about what types of strategies might you use?

315
00:35:38,080 --> 00:35:41,350
So let's compare back up and try to like chat through and figure out what we want to do.

316
00:35:41,890 --> 00:35:49,060
The 300,000. Yeah.

317
00:35:49,110 --> 00:36:00,860
You know what? I think that I could.

318
00:36:05,100 --> 00:36:19,140
But they haven't been thinking about it yet.

319
00:36:19,290 --> 00:36:23,240
Justin We got a 34 to 21 to take it for granted.

320
00:36:24,640 --> 00:36:33,480
I we go to 30 right over till 1015 and they're like you said, we're going to extra time.

321
00:36:42,410 --> 00:36:55,340
It's great that we can ask you questions about measuring houses, but have it always be this.

322
00:36:58,310 --> 00:37:05,070
Who's in charge? I we go to sleep.

323
00:37:09,220 --> 00:37:13,810
Yeah. Yeah. Oh, sorry if I put.

324
00:37:17,600 --> 00:37:31,400
Is it? Sounds like a production of Dirty, if that's your answer.

325
00:37:31,790 --> 00:37:35,570
Fine. But that's wrong. I can tell you right now.

326
00:37:40,010 --> 00:37:43,800
Yeah, right. It just keeps going.

327
00:37:45,830 --> 00:37:54,380
Like, can I get out of this yet? I need to get.

328
00:38:01,890 --> 00:38:05,280
Sounds like the rooms getting a little quiet. So it sounds like we have some ideas.

329
00:38:06,840 --> 00:38:11,040
I'm going to popcorn around this time, and I'm gonna start with the back room on the left.

330
00:38:11,280 --> 00:38:15,250
My left. The three of you guys are.

331
00:38:17,410 --> 00:38:27,140
I just like being, you know, being the first man to.

332
00:38:32,770 --> 00:38:36,570
Of course. Okay.

333
00:38:37,290 --> 00:38:44,730
So you want to, like identify certain keywords and then extract posts that have those keywords and then hire people to analyze those.

334
00:38:45,550 --> 00:38:50,010
Okay. How about the front group on your right?

335
00:38:50,010 --> 00:39:02,880
My left? Yes. We thought about maybe looking at some stuff that gives some idea about what the keywords might even be.

336
00:39:03,330 --> 00:39:07,000
Nice. Yeah. Yeah.

337
00:39:08,370 --> 00:39:16,020
But different demographic groups are even doing with a read an ally group interview.

338
00:39:16,590 --> 00:39:19,860
Well, themes and things that we might be looking for.

339
00:39:20,100 --> 00:39:23,690
That way we know we're going in. Yeah. Yes.

340
00:39:23,760 --> 00:39:32,579
Okay. So what I'm hearing is like having trying to cut a subsample of the post that the posts and letting that

341
00:39:32,580 --> 00:39:37,500
kind of like a primary codebook be driven both by like some like theory or like research questions,

342
00:39:37,500 --> 00:39:44,640
but also by potentially like a focus group where you can identify the types of themes that would be relevant within the posts.

343
00:39:45,270 --> 00:39:49,830
Right. Awesome. This group here, I think we had pretty similar to the last group.

344
00:39:50,340 --> 00:39:57,120
I'm kind of primarily just kind of like a pilot almost using a subset of that data to identify what our themes would be

345
00:39:57,120 --> 00:40:02,099
and then using that on the larger sample and doing some sort of coding that we don't have any idea how you would do,

346
00:40:02,100 --> 00:40:05,300
but you can probably code to pull out information.

347
00:40:05,610 --> 00:40:09,720
Yeah. Okay, cool. Would you. So you guys would also do it with the subsample approach?

348
00:40:09,810 --> 00:40:13,700
Yeah. Okay. And then the back. Right. You get the last debate.

349
00:40:14,640 --> 00:40:16,950
We also have, like a sub sample. Okay.

350
00:40:17,370 --> 00:40:28,709
Just because people are starting out at the program or people are going for 90,000 posts just to identify maybe,

351
00:40:28,710 --> 00:40:34,050
I don't know, like 10% or something, something smaller to analyze, to see what we're seeing.

352
00:40:34,050 --> 00:40:39,550
First 290 degree data, maybe 4000 posts, is not as intensive.

353
00:40:39,560 --> 00:40:50,340
But what if we're looking at a million or more and then also being mindful to know that 300,000 posts is not 300,000 people?

354
00:40:50,870 --> 00:41:01,680
Mm hmm. Multiple times. So maybe also identify whether you're looking at 300,000 or if you really do one, just post.

355
00:41:02,340 --> 00:41:12,719
Yeah. Those are all great ideas. So I think the back when I was the only ones who were saying that you guys would go for all 300,000 by having,

356
00:41:12,720 --> 00:41:16,140
like a small army of, like undergraduates or doctoral students, according to Justin.

357
00:41:19,320 --> 00:41:22,940
What's the doctoral? I read these. Is that great?

358
00:41:23,030 --> 00:41:26,710
But we're going to do a big grant. Okay.

359
00:41:26,730 --> 00:41:27,780
These are all great ideas.

360
00:41:28,200 --> 00:41:36,750
And I'm like, I think we're going to talk about different components of each idea and how we do actually approach and deal with all 300,000.

361
00:41:37,710 --> 00:41:49,590
And actually more than that. But. So we are going from our brains which have lines in this image to a computer, which is zeros and ones.

362
00:41:49,710 --> 00:41:53,280
That's what we always have to remember when we're using computational methods.

363
00:41:53,550 --> 00:41:59,550
We're talking to something that's really good at doing something once it's given a clear structure,

364
00:42:00,060 --> 00:42:04,110
but that's not very good at doing the creative, like, brain activities that humans can do.

365
00:42:04,560 --> 00:42:10,620
So at least in my research, like, it's never trying to have the computer do the thinking because computers can't think they can

366
00:42:10,620 --> 00:42:15,569
do zero one applications and they can get very good at doing zero one type applications,

367
00:42:15,570 --> 00:42:19,320
and they can do a lot of work really, really, really fast.

368
00:42:19,980 --> 00:42:23,920
But they can't they can't come up with that structure independently.

369
00:42:23,940 --> 00:42:31,080
Now there are some A.I. type things and like kind of automated A.I. stuff where it's like trying to have computers learn to think,

370
00:42:31,530 --> 00:42:37,380
but they're still given a set of parameters and through which they're thinking through like a set of logic parameters that they're using to think,

371
00:42:37,860 --> 00:42:41,250
okay. Yeah. We haven't created like a human brain in a computer yet.

372
00:42:42,030 --> 00:42:45,300
We might happen, but like, from what I know, that's not yet a thing.

373
00:42:47,310 --> 00:42:53,550
Okay. So we have both unsupervised forms of natural language processing and supervised forms.

374
00:42:54,180 --> 00:43:01,830
Natural language processing is a technique where you take large amounts of text and try to find patterns, themes,

375
00:43:02,490 --> 00:43:10,020
narratives and, you know, different kind of outcomes like that, both in a supervised and an unsupervised way.

376
00:43:10,600 --> 00:43:12,329
It's coming back to the unsupervised idea.

377
00:43:12,330 --> 00:43:18,570
We identified a lot of the kind of like grounded theory, qualitative, where you're letting the data guide the outcomes.

378
00:43:19,670 --> 00:43:25,650
Yeah. We also have methods like that in natural language processing, letting the data guide our outcomes.

379
00:43:26,760 --> 00:43:30,870
Now this comes in, I think, when one or two groups said, Oh, identify like top terms.

380
00:43:31,340 --> 00:43:38,010
That's a type of unsupervised activity that you can do where you don't have to read through and identify or like command f,

381
00:43:38,120 --> 00:43:41,120
you know, identify every single occurrence of a word.

382
00:43:41,480 --> 00:43:45,860
There's a way to program where you can just have all the top words come up like, Oh, okay, that's the top word.

383
00:43:45,860 --> 00:43:52,640
And this is the top word in the top word. The challenge in that is that you're not getting a ton of context around that word.

384
00:43:53,390 --> 00:43:56,670
So we could think of the word quit.

385
00:43:58,040 --> 00:44:04,700
How might someone use the word quit when they're talking about cannabis use or the desire to, like, stop using cannabis?

386
00:44:07,060 --> 00:44:12,340
What are some ways that someone might use the word quit? Need to quit.

387
00:44:12,730 --> 00:44:18,820
I need to quit. Okay, great. I know my answer, but I can never quit.

388
00:44:19,780 --> 00:44:25,560
I quit yesterday. I quit yesterday. Hmm. I don't feel like I need to.

389
00:44:26,220 --> 00:44:30,150
I don't feel like I need to quit. Mm hmm. Great. Others.

390
00:44:33,370 --> 00:44:39,589
Quitting cold turkey. Mm hmm. Yeah, exactly.

391
00:44:39,590 --> 00:44:44,870
So we can see how it is used in a lot in ways that we wouldn't if we were doing like a thematic analysis, right?

392
00:44:44,870 --> 00:44:48,980
Like qualitatively we probably wouldn't cluster all those things together just because they have the same word.

393
00:44:49,280 --> 00:44:55,100
We have a method of quitting cold turkey. We have a desire to quit, like I probably need to quit or I want to quit.

394
00:44:55,310 --> 00:44:59,540
We have the, the idea that, like, I don't need to quit. Like I have this under control.

395
00:45:00,200 --> 00:45:02,090
That's a different type of thing, right?

396
00:45:02,540 --> 00:45:09,079
So as much as these are supervised, you can bring up like quitting as a major term, it doesn't give us that context.

397
00:45:09,080 --> 00:45:14,670
What you probably are going to want or need. Another form is what's called engrams.

398
00:45:14,670 --> 00:45:23,780
So these are phrases. The challenge with this is that even though you have a lot of data within text, you have what's called a sparse matrix,

399
00:45:24,050 --> 00:45:27,830
which means you're not having the same words in the same orders in every text.

400
00:45:28,370 --> 00:45:34,489
So the the numeric time, like the number of times something's going to appear in the exact same way across multiple documents or

401
00:45:34,490 --> 00:45:40,040
even within the same document is much lower than if you had a categorical variable and everyone has a01,

402
00:45:40,040 --> 00:45:41,350
two, three, four, right?

403
00:45:42,120 --> 00:45:48,050
Like a matrix that has one, two, three, four and everyone has either one, two, three, four is a small matrix that is very dense.

404
00:45:49,070 --> 00:45:54,710
But in text analysis you have giant matrices that are really sparse, a lot of zeros, right?

405
00:45:55,910 --> 00:46:02,390
Where like a word is not appearing or or a word within a sentence is not appearing in the same way across documents, things like that.

406
00:46:02,480 --> 00:46:05,960
Okay. But you still can identify the top phrases.

407
00:46:06,440 --> 00:46:11,060
It's not you have to have nearly as many because again, people don't see things in exactly the same way.

408
00:46:11,630 --> 00:46:15,650
But that's an option. And that can give you a little bit more context. Right. I want to quit.

409
00:46:15,650 --> 00:46:20,330
Can be a taught phrase. Right? I'm trying to quit or I quit three days ago.

410
00:46:20,390 --> 00:46:24,140
Those could all be things that can give us more contextual information around the word quit.

411
00:46:26,210 --> 00:46:31,310
We can also do latent semantic indexing. So does anyone know what a latent class analysis is?

412
00:46:32,210 --> 00:46:34,500
Yeah. You guys are more than a year now, okay?

413
00:46:34,500 --> 00:46:39,710
It's gone for a year, but it's basically letting the data kind of like naturally cluster based on a set of variables.

414
00:46:40,190 --> 00:46:44,659
You can do this with text, which words are commonly appearing close to each other, you know,

415
00:46:44,660 --> 00:46:50,900
which words are often either you can do this in terms of like ordinal syndromes, like this one comes first, this one comes second.

416
00:46:51,290 --> 00:46:57,110
Or you can just say like within the same sentence or within the same set of sentences, we're often seeing these words in, in, you know, together.

417
00:46:57,680 --> 00:47:02,360
So those are ways to find cluster and get a little bit more context in addition to getting like, what are the top words?

418
00:47:03,230 --> 00:47:05,090
And then you can do this thing called topic modeling,

419
00:47:05,090 --> 00:47:10,669
which is where you let the data naturally cluster into the different kind of like different topics.

420
00:47:10,670 --> 00:47:13,940
And you can see which topics are most prevalent in a given document.

421
00:47:14,240 --> 00:47:16,340
And then you could code a subset of those documents, right?

422
00:47:16,340 --> 00:47:25,010
So if you are like your first topic, has the words quit sober turkey and years, that might be a document.

423
00:47:25,010 --> 00:47:29,960
And you do the documents like, Oh, someone quit cold turkey two years ago and they're talking about that.

424
00:47:30,230 --> 00:47:34,850
That might be something you see. Whereas someone saying like, I really need to quit.

425
00:47:34,850 --> 00:47:38,120
It's really hard. I don't know how to go about it. I need support.

426
00:47:38,120 --> 00:47:43,939
That topic like that might not match very well to that type of document, and there might be another topic that matches better to it.

427
00:47:43,940 --> 00:47:50,580
And then you can look at the proportion of topics across documents, things like. Questions about unsupervised.

428
00:47:53,590 --> 00:47:58,350
This is not a lot of information. You ready to go?

429
00:47:58,360 --> 00:48:05,250
Supervised. All right. So examples of supervised is like when we're predicting a given outcome.

430
00:48:05,260 --> 00:48:07,150
So regression models are supervised learning.

431
00:48:07,210 --> 00:48:11,680
We're saying, like, we have our categories that we are looking at and we think that this is going to predict this.

432
00:48:11,800 --> 00:48:16,810
And then we say, are we right? And then we look at a p value and then hopefully have the beta value and see how big it is.

433
00:48:16,810 --> 00:48:24,730
Right. Projection. Yeah. And then like causal models like ICM, which they they'll get to the ish when you guys do late and stuff,

434
00:48:24,730 --> 00:48:28,629
maybe I'll talk a little about CRM, but like, you know, if you have a causal model, you're like saying this is the structure.

435
00:48:28,630 --> 00:48:32,800
I think that the data are are going to support that you see here.

436
00:48:32,800 --> 00:48:38,190
Right. Okay. So examples of supervised NLP methods are tokenizing.

437
00:48:38,200 --> 00:48:39,489
This is part of data cleaning.

438
00:48:39,490 --> 00:48:48,460
This is extracting each word as a feature so that you can then do things like which features occur most frequently, which words occur, right?

439
00:48:48,490 --> 00:48:53,320
Again, we're working in a computer brain that's zero one, so you have to really dumb it down for the computer.

440
00:48:54,280 --> 00:49:00,579
But then the is really good at being like processing through, you know, 2 million words and being like and be able to identify like,

441
00:49:00,580 --> 00:49:08,260
oh, you know, this pattern of 01010001 occurs X number of times which we manually it would take us forever.

442
00:49:08,350 --> 00:49:11,860
Right? We can do part of speech tagging.

443
00:49:11,920 --> 00:49:18,940
So this is again like kind of a black box where you have an existing algorithm that you can apply to the data and identify like,

444
00:49:19,510 --> 00:49:22,720
yeah, these are the types of speech we're seeing most commonly.

445
00:49:23,110 --> 00:49:26,739
This is really useful in linguistics. It's not really as useful.

446
00:49:26,740 --> 00:49:30,729
I think in public health there are some applications that do work.

447
00:49:30,730 --> 00:49:35,830
So you could look at like past versus future tense. So if you're looking at me like quit, I want to quit.

448
00:49:35,830 --> 00:49:43,810
I need to quit. I quit five years ago. That could be helpful, but like other forms of semantics are not as important for us, I would say.

449
00:49:45,460 --> 00:49:47,470
Then there's name entity recognition.

450
00:49:47,470 --> 00:49:54,950
So that's again like identifying if you want to restrict your dataset based on a certain term, you need have that.

451
00:49:54,950 --> 00:49:57,910
If you're look for that term again you pre-specified like, oh,

452
00:49:57,940 --> 00:50:02,739
I know that this this word quit is going to be in some of these let's make a subset that's a

453
00:50:02,740 --> 00:50:07,620
way of doing that you'd want the computer to go through the entire post and just say like,

454
00:50:07,630 --> 00:50:11,080
is this word in there? Yes. Okay, pull that and put it into a database.

455
00:50:11,110 --> 00:50:15,510
Because, again, you have 300,000 of these you can't manage. Look through them all to get the data.

456
00:50:17,650 --> 00:50:23,440
There's sentiment analysis which is trying to determine kind of the valence of the post,

457
00:50:23,440 --> 00:50:29,230
if it's positive or negative, if there's like, you know, certain forms of affect, happiness, sadness.

458
00:50:30,850 --> 00:50:35,169
This is a little bit more tricky to interpret.

459
00:50:35,170 --> 00:50:38,590
I would say it depends on the context of your question.

460
00:50:40,540 --> 00:50:46,120
So, for example, there are posts that say, when I started using weed, it was amazing.

461
00:50:46,300 --> 00:50:51,190
I had so much fun with my friends. We were having such a good time. I You know what?

462
00:50:51,190 --> 00:50:55,240
I started when I was 14 and by 16 I was smoking daily.

463
00:50:55,690 --> 00:50:58,960
And then I started smoking in the morning and at night.

464
00:50:59,260 --> 00:51:01,419
And then I was smoking throughout the day, every day.

465
00:51:01,420 --> 00:51:09,399
And, you know, I started entering this brain haze and brain fog and all of a sudden all the things that were fun to weed were not so much fun.

466
00:51:09,400 --> 00:51:14,680
And all the things I used to do that were fun when I wasn't on weed, I didn't want to do anymore and my life is just stuck.

467
00:51:15,910 --> 00:51:19,480
So there's like positive affect early in that, right?

468
00:51:20,560 --> 00:51:23,350
Then there's more negative affect later, so.

469
00:51:24,850 --> 00:51:30,160
Trying to just like tag like is this a positive or a negative post has very little meaning in those cases.

470
00:51:30,610 --> 00:51:35,439
You could then do it by sentence by sentence. But again, unless you have like a theory of like, okay,

471
00:51:35,440 --> 00:51:38,919
we have narratives that stress out and get happy and we have narratives that start

472
00:51:38,920 --> 00:51:41,980
of sad and stay sad or we've narratives that like sort of happy and stay happy.

473
00:51:42,250 --> 00:51:46,719
And you want to analyze that as subsets that would make them more useful.

474
00:51:46,720 --> 00:51:48,220
But just having a general like this was positive.

475
00:51:48,220 --> 00:51:53,410
This was negative, I don't think would yield very much important or meaningful information in this type of example.

476
00:51:55,540 --> 00:52:04,420
And then categorization and classification, this is kind of again oh sorry I mixed up name entity recognition is like be able to identify a noun.

477
00:52:04,870 --> 00:52:10,239
Sorry. Categorization and classification is like being able to identify like this.

478
00:52:10,240 --> 00:52:13,120
This post contains a certain set of words or subsets.

479
00:52:13,120 --> 00:52:20,020
And therefore we're going to say this person has, you know, substance use disorder or they don't have substance use disorder, the classification.

480
00:52:20,230 --> 00:52:25,140
Okay. And you do that based on like a single word that based on a set criteria, etc.

481
00:52:27,960 --> 00:52:33,720
Okay. So in practice, you're going to be using the mix of supervised and unsupervised methods when you're trying to answer these questions.

482
00:52:33,780 --> 00:52:38,850
It's not just one way or the other. It's very much like an integrative, like, integrated kind of back and forth between these methods.

483
00:52:39,750 --> 00:52:45,180
So coming back to our posts, I'm going to show you guys some examples of like how I've applied different methods of kind of talking through it.

484
00:52:46,920 --> 00:52:51,069
So this is a tokenizing. This is actually supervised.

485
00:52:51,070 --> 00:52:53,580
And we're trying to identify the singular words.

486
00:52:53,880 --> 00:52:59,459
But you can see how a single sentence is broken up into a bunch of different words in a bag of words attempt.

487
00:52:59,460 --> 00:53:02,190
We're just trying to figure out which words are most common that would be unsupervised.

488
00:53:02,220 --> 00:53:06,120
See first year supervised learning of tokenizing each sentence into individual words,

489
00:53:06,840 --> 00:53:11,390
and then the unsupervised activity of figure out which words are most frequent. Okay.

490
00:53:13,500 --> 00:53:23,580
All right. And this data is based off of the top 100 posts per year between 2011 and 2021.

491
00:53:25,590 --> 00:53:32,790
So you can see with across all of the posts, this is like identifying which words are at the very, very like are the most common across time.

492
00:53:32,880 --> 00:53:37,260
Okay. So we see the terms. Smoke is the very most like it's the top one.

493
00:53:37,740 --> 00:53:45,510
Right. And then we have time. Weed day. I feel like quit your high thing, make friend people start back.

494
00:53:45,510 --> 00:53:49,080
Good work. Now, if you look at people, it's missing an E.

495
00:53:49,530 --> 00:53:58,680
That's because we did using text pre-processing because you want to be able to combine certain words like anxiety or like in anxious,

496
00:53:58,830 --> 00:54:02,820
you'd want to combine those potentially. So you didn't have the two different categories and those were combined.

497
00:54:03,240 --> 00:54:12,620
So people I'm not sure like people I'm not really sure what the other one would be, that that's a form of text pre-processing that we do.

498
00:54:12,630 --> 00:54:18,030
That would be a supervised activity in order to do this unsupervised kind of bag of words, figure out which is most common.

499
00:54:18,990 --> 00:54:24,040
Okay. And what's the problem with this data?

500
00:54:24,110 --> 00:54:31,770
Like what what can you say about people who are like trying to stop using cannabis based on this data?

501
00:54:47,820 --> 00:55:00,060
You can tell they're actually succeeding. It means when it comes to recovery and.

502
00:55:01,000 --> 00:55:08,320
You spent quite a bit of time adjusting your mind and talking about it, but that doesn't mean that you entered recovery.

503
00:55:08,620 --> 00:55:12,930
Continued recovery. Yeah.

504
00:55:13,770 --> 00:55:18,090
This doesn't tell us really about, you know, the journey. Right.

505
00:55:18,120 --> 00:55:24,540
There's not enough contextual information. How about if I give you a few more words?

506
00:55:39,800 --> 00:55:46,220
How do these things happen? So these groupings are based on which phrases are most common.

507
00:55:46,970 --> 00:55:54,130
The challenge with the current graph has used a pre-processing technique where you plug in what are called stop words.

508
00:55:54,140 --> 00:55:57,140
So words have very little meaning because they are very, very common.

509
00:55:57,140 --> 00:56:01,430
So A and make it a little bit more challenging to interpret this,

510
00:56:01,730 --> 00:56:10,190
but you can go slightly higher the increases the density of the matrix which is helpful in that you can kind of get more conclusions,

511
00:56:10,190 --> 00:56:13,220
but it decreases the amount of information which is less helpful.

512
00:56:13,550 --> 00:56:22,940
It's a balancing act within this. You are trying to create a lot of these.

513
00:56:25,730 --> 00:56:32,460
Just interesting. I can now comment more on that in a second.

514
00:56:32,790 --> 00:56:35,879
One of the things you guys I've read a lot of these.

515
00:56:35,880 --> 00:56:40,830
That's why I can comment. I've been that grad student.

516
00:56:40,980 --> 00:56:48,480
I'm not a grad student more, but I've been that person who's like, I'm not reading 3000, but are there any of these,

517
00:56:48,480 --> 00:56:55,920
like, kind of phrases that you find either confusing, hard to interpret, unexpected, expected?

518
00:57:05,590 --> 00:57:11,749
Lost, credibility lost. This gives us a little more context of it.

519
00:57:11,750 --> 00:57:16,240
It still is limited because, one, we've removed the stop words.

520
00:57:16,270 --> 00:57:19,930
So, for example, that smoked weed could be stopped smoking weed.

521
00:57:19,960 --> 00:57:23,650
I stopped. I stopped. Yeah. Okay.

522
00:57:23,770 --> 00:57:28,030
That's when you really stop smoking weed. Depends.

523
00:57:28,210 --> 00:57:35,860
We could be, like, dependent. Dependent on smoking weed or I do this.

524
00:57:36,070 --> 00:57:41,320
It depends on if I smoke weed today. Yeah, there's like the multiple iterations.

525
00:57:41,320 --> 00:57:46,420
So, again, we're losing a little bit of the content because we are because of the tax on the tax pre-processing.

526
00:57:46,930 --> 00:57:57,730
If we leave words exactly as they are, the frequency like you can see the bottom like the like this is across almost a thousand posts.

527
00:57:58,270 --> 00:58:02,800
The frequency of the phrase like we have about ten. Like ten is that bottom line right here.

528
00:58:03,520 --> 00:58:05,440
It's apparent ten times. So this is like two.

529
00:58:06,520 --> 00:58:14,340
So again, like, if we if we want to try to create some meaning in terms of what's coming together by phrases, we just use the text pre-processing.

530
00:58:14,380 --> 00:58:17,810
Otherwise you can have everything like one or two times appearing across, you know,

531
00:58:17,860 --> 00:58:21,670
entire thousand documents, at which point that doesn't tell you very much.

532
00:58:22,900 --> 00:58:23,889
This is, again,

533
00:58:23,890 --> 00:58:32,230
a limited a very limited approach in that like you're trying to give the computer clear guidelines in what is ultimately pretty messy data.

534
00:58:32,650 --> 00:58:36,340
And then having a computer do all that like you know the graduated so.

535
00:58:38,430 --> 00:58:50,040
Okay. So I can kind of play video game piece. And it turns out a lot of people talk about how they often they recount in their posts about how they

536
00:58:50,040 --> 00:58:55,230
began using and kind of the trajectory they had and like what brought them to the desire to stop.

537
00:58:55,680 --> 00:58:59,880
That's one type of post I see a lot. It's not the only type, but it's one.

538
00:59:00,120 --> 00:59:07,360
And a lot of people talk about how they would often they like often used at night.

539
00:59:07,740 --> 00:59:13,530
So I believe that night is one of the top words. Yeah, it's in the middle right here.

540
00:59:13,560 --> 00:59:20,400
Night. Okay. They talk about nighttime being a time when, like, they often enjoyed smoking or using.

541
00:59:22,230 --> 00:59:28,020
There's also a lot of, like, discussion around nighttime and sleeping relative to use.

542
00:59:29,310 --> 00:59:32,010
But a lot of times at night, people play video games while they're using.

543
00:59:32,250 --> 00:59:36,750
So video games comes up a lot because it turns out a lot of people use video games.

544
00:59:36,930 --> 00:59:43,079
That's what we see time and that's like a thing that becomes like a daily habit where you're like having online to

545
00:59:43,080 --> 00:59:48,840
either play with your friends or play games that like you can talk to the people that you're that kind of like randos,

546
00:59:48,840 --> 00:59:52,000
right? Or strangers. I don't know. I don't really go.

547
00:59:52,030 --> 00:59:57,050
But I was in high.

548
01:00:00,990 --> 01:00:04,250
Okay, here are some work correlations.

549
01:00:04,260 --> 01:00:09,510
So this is taking a subset of posts that referred to suicide.

550
01:00:10,020 --> 01:00:13,440
And this was so this, this subset comes from all posts.

551
01:00:13,920 --> 01:00:19,050
And so just looking at the top 100 and trying to identify like what are the top phrases in terms in the very, very top posts.

552
01:00:19,350 --> 01:00:25,440
This is looking across all the posts which are tell you how many there are.

553
01:00:26,550 --> 01:00:36,090
For context, there were 350,000 posts in 2021. So like there's lots of posts, but these are words that are closely correlated.

554
01:00:36,090 --> 01:00:41,190
So not as like occurring like this doesn't reflect order of words,

555
01:00:41,190 --> 01:00:45,520
but these are words that are frequently occurring in close proximity to each other within a sentence or post.

556
01:00:45,840 --> 01:00:50,340
Okay. And this gives us actually a little bit more information than the last slide, right?

557
01:00:50,850 --> 01:00:54,000
Because it doesn't force the words to be in a specific order.

558
01:00:54,870 --> 01:00:58,560
We can see more that kind of like these correlations. I can see we start to see some clustering, right?

559
01:00:59,250 --> 01:01:04,380
So Mary Jane commonly occurring together is probably Mary Jane in that way.

560
01:01:04,400 --> 01:01:11,340
Not Jane Mary. Right. Because there's a phrase for marijuana. Right. But we see psych ward, we see anxiety and depression.

561
01:01:11,610 --> 01:01:18,360
We see anonymous sponsor close together. We have many meetings which are marijuana anonymous meetings.

562
01:01:18,720 --> 01:01:25,440
And I think as we talked about earlier, we have coping mechanism occurring.

563
01:01:30,470 --> 01:01:33,570
Like panic attacks and, you know, talking about that.

564
01:01:36,100 --> 01:01:40,990
Just the darkness of the line kind of represents the frequency with which.

565
01:01:41,200 --> 01:01:45,069
Yeah. Mm hmm. Yeah. And it's I don't think it's not very clear on the screen.

566
01:01:45,070 --> 01:01:45,850
And I apologize.

567
01:01:45,850 --> 01:01:53,530
I imagine it's hard for you guys to see it, but, yeah, the darkness on the line does show kind of like the intensity of the correlation.

568
01:01:54,100 --> 01:01:57,280
And these correlations are at greater than or equal to 0.35.

569
01:02:03,420 --> 01:02:10,620
So this is a slightly more helpful than the last slide, would you say contextually, contextually, as little more information?

570
01:02:11,730 --> 01:02:16,650
Again, these are the terms occurring in suicide posts that have to do suicidality.

571
01:02:18,370 --> 01:02:23,249
Okay. And the way that we extracted those posts having to do with suicidality was to

572
01:02:23,250 --> 01:02:28,770
identify certain keywords that were commonly occurring and just extracting all of the

573
01:02:28,770 --> 01:02:34,169
posts that had those words and then doing this type of unsupervised word correlation

574
01:02:34,170 --> 01:02:38,390
where we didn't have pre determined structures that we were trying to identify.

575
01:02:38,400 --> 01:02:45,750
We're just seeing how the words clustered together in the data. So again, appearing of the supervised in terms of the extraction piece of it,

576
01:02:45,750 --> 01:02:50,640
where we said we want to have this specific thing and then unsupervised, which is like just show us the correlations.

577
01:02:51,030 --> 01:02:57,060
Now we're not going to predetermine what we want to see. Okay.

578
01:02:57,090 --> 01:03:07,320
And then here's a comparison of words that occur most frequently in suicide related posts, which are less frequent in non suicide related posts.

579
01:03:07,440 --> 01:03:10,600
So this is bringing looking at both types of post.

580
01:03:11,670 --> 01:03:17,790
And you can see words like depression, ideation, life are more frequently going to occur in suicide related posts.

581
01:03:20,190 --> 01:03:24,840
Whereas like some of these ones are a little harder to identify, but there's like more references to nature,

582
01:03:25,720 --> 01:03:30,660
things like that, which we're like to try to figure out why these don't make as much sense to us.

583
01:03:30,930 --> 01:03:39,239
When I was talking to my mentors about it from psychiatry, but I think a lot of this tracks on the things we might expect to see in posts

584
01:03:39,240 --> 01:03:42,660
that are more talking to more severe forms of mental health like suicide.

585
01:03:43,560 --> 01:03:47,960
Yes. So here are two differences.

586
01:03:47,970 --> 01:03:52,740
First. One does not happen as much in a word like you're talking about.

587
01:03:53,040 --> 01:03:58,740
I can't put into words if you've intentionally separated them.

588
01:04:00,010 --> 01:04:04,560
Right. Oh, sorry. I can't make anything worse.

589
01:04:04,800 --> 01:04:10,379
So it looks like you have two different sets of words and you having them repeat in each one.

590
01:04:10,380 --> 01:04:15,900
Are you intentionally separating them so they don't work? If you say life in suicide.

591
01:04:17,690 --> 01:04:25,910
Yeah. So that's a great question. This is the sort of analysis, I suppose, trying to figure out what are the two types of terms appearing.

592
01:04:26,150 --> 01:04:29,780
That's the first step. And then are they more likely to do one or the other?

593
01:04:30,200 --> 01:04:39,500
So in a clear analysis, you shouldn't see overlap in a lesson analysis where you're like, well, the results aren't similar, but they were.

594
01:04:40,100 --> 01:04:47,780
You might see overlap in terms. That's what I think is pretty clean though, in terms of like words and forces one side of the other.

595
01:04:50,990 --> 01:04:55,330
But yeah. Right. Yeah, exactly.

596
01:04:55,340 --> 01:05:00,370
Yeah. Yeah. And there can be some following limits.

597
01:05:01,370 --> 01:05:05,840
Yeah. And questions about this.

598
01:05:08,350 --> 01:05:14,530
Again, it's not for the contextualize. It's just bigger words. We can't do this with phrases because as you saw with the count, it's so small.

599
01:05:14,530 --> 01:05:18,070
Like that's going to be completely not like it's not meaningful analysis.

600
01:05:22,840 --> 01:05:26,770
But what we could do is we could try to classify the clusters of things.

601
01:05:26,770 --> 01:05:31,540
So like we can think about within like a suicide related post that they're

602
01:05:31,540 --> 01:05:36,249
specifically talking about forms of medication or formal systems of treatment.

603
01:05:36,250 --> 01:05:42,790
So like therapist hospitals, psychiatric ward, psychiatrist, therapist, right.

604
01:05:43,930 --> 01:05:47,739
Versus like post that don't refer to those kind of more formal systems.

605
01:05:47,740 --> 01:05:52,780
And then we could do some sort of analysis or kind of at severity or age that cannabis use

606
01:05:52,780 --> 01:05:58,000
got started or like what is the relationship and suicide alley and cannabis in these posts?

607
01:06:05,930 --> 01:06:10,670
Okay. So in the future applications, we're going to encode a subset of documents.

608
01:06:10,760 --> 01:06:15,589
So again, I guess Justin's going to be giving you some doctoral students. I'm just getting guys,

609
01:06:15,590 --> 01:06:21,830
I'm not going to we'll be encoding a subset of documents at the sentence level based on

610
01:06:21,850 --> 01:06:26,390
pre-identified codes and use supervised models to predict other like across all of their entries.

611
01:06:26,480 --> 01:06:35,630
So that means you like code, for example, 300, 300 posts and then you split that into a training and a testing model.

612
01:06:35,750 --> 01:06:42,690
And the training is where you build your AI, your algorithm, excuse me, then you test out your, your testing sample to see how accurate it is.

613
01:06:43,040 --> 01:06:47,970
If it's a decent accuracy, which is like the area under the curve is relatively high, right.

614
01:06:48,260 --> 01:06:50,460
With area under the curve being point five being chance.

615
01:06:50,480 --> 01:06:57,320
So you really want to be like ideally in the point nine range, but like you don't let your model be over fit as well.

616
01:06:57,320 --> 01:07:02,570
Like this is like the tradeoff in a lot of these algorithm based building activities is like you

617
01:07:02,570 --> 01:07:05,870
have to find that balance between like area under the curve being high but not being overfitting,

618
01:07:05,870 --> 01:07:12,920
like overfitting your model. But anyways, once we get that all sorted, we'll be able to apply it to all other posts.

619
01:07:13,040 --> 01:07:18,859
And again, I pulled like the three you going from 30 to 300000 example we have closer to like a couple million,

620
01:07:18,860 --> 01:07:24,680
but it's the same idea and we're going to examine the patterns with the themes coded.

621
01:07:24,740 --> 01:07:29,300
So for me, some questions I have is the like,

622
01:07:30,000 --> 01:07:35,629
did someone in it have to like it's someone repeating attempts or is someone talking about how they did a one time attempt?

623
01:07:35,630 --> 01:07:39,140
And, you know, for them it worked because those would be different pathways of recovery.

624
01:07:39,140 --> 01:07:45,950
Right. Do people talk about going to the whole turkey or just like complete going from like.

625
01:07:45,950 --> 01:07:51,739
No, their regular use to completely stopping that is a good thing to kind of differentiate between

626
01:07:51,740 --> 01:07:55,850
because there might there are like larger withdrawal symptoms potentially that would occur.

627
01:07:56,870 --> 01:08:03,410
But there are people who say like, I can't moderate like, you know, I have that's like that is the option is like for me to go from like 100 to 0.

628
01:08:03,890 --> 01:08:04,969
And so at that case, like,

629
01:08:04,970 --> 01:08:10,810
we could create opportunities for interventions to help handle withdrawal symptoms which generally last between 2 to 6 weeks.

630
01:08:11,420 --> 01:08:13,160
And it can include things like suicidality.

631
01:08:13,250 --> 01:08:18,590
So they are a big you know, there's also like shaking, headaches, irritability, trouble, sleeping, things like that.

632
01:08:19,820 --> 01:08:28,340
So helping with that, um, and then age, you know, of, of like, you know, like age in reference to how long a person used for.

633
01:08:28,340 --> 01:08:33,530
We have some people who are, you know, in their, you know, kind of late teens who are posting on here.

634
01:08:33,770 --> 01:08:38,690
We have people who are in their like fifties and seventies posting. I mean, like I've used for 30 years, you know.

635
01:08:41,010 --> 01:08:46,100
But I think the thing about is like because it's Reddit and it's anonymous, we don't have demographic features.

636
01:08:46,430 --> 01:08:53,870
So these are things where like we can try to like, like kind of interpolate like what we're identifying to like,

637
01:08:53,870 --> 01:08:57,160
okay, if someone references that they smoke for 30 years, they're not 18, right?

638
01:08:57,170 --> 01:09:02,270
Like that's a logic question, but it's not going to be hard to go through and say we've completed on how old these people are,

639
01:09:02,540 --> 01:09:06,850
what their race is, what their gender is, what their sex is, what their nationality is.

640
01:09:06,860 --> 01:09:10,490
So again, it's becomes a generalizability issue and trying to understand that.

641
01:09:10,970 --> 01:09:18,440
Another limitation of Reddit is that it's largely white men, although not every subreddit like there's not statistics on specific subreddits.

642
01:09:18,440 --> 01:09:20,480
It actually does differ based on the subreddit.

643
01:09:20,810 --> 01:09:26,300
But in terms of Reddit, all of you know, entire in its entirety is largely white men who are participating on it.

644
01:09:26,510 --> 01:09:33,649
So that's also a limitation question or thought or I was just wondering in terms of,

645
01:09:33,650 --> 01:09:42,290
I guess where this one example of anonymous posting, but I have seen one that's something that's less and less taboo to talk about.

646
01:09:42,920 --> 01:09:55,340
So when if you choose to let's say you want to analyze something like heroin use, can you use methods to.

647
01:09:56,560 --> 01:10:02,950
We analyze this information or you start just by how it's perceived.

648
01:10:03,060 --> 01:10:09,270
How much? People can get, even if it is anonymous, you know, like that kind of stuff.

649
01:10:09,570 --> 01:10:19,500
I just think some of the type of subjects to get information on that we would find useful, but people don't talk about as much.

650
01:10:19,500 --> 01:10:28,800
Or are you finding that anonymity does provide you a little bit more information and people are more comfortable posting?

651
01:10:30,840 --> 01:10:35,160
I'm not a heroine specifically, but you are heroin enthusiasts.

652
01:10:36,090 --> 01:10:41,100
Like that's a small number of members, right? But you have them on here and look at what they say.

653
01:10:42,840 --> 01:10:51,130
This is your account. So if you get asked later by a woman. So, like, people talk about this stuff.

654
01:10:51,150 --> 01:10:54,780
You know, again, like, it looks kind of to me the same.

655
01:10:55,380 --> 01:10:58,850
Potentially the same. No. Oh, yeah.

656
01:10:58,860 --> 01:11:02,580
No, it's prison. But, you know, there are ways also to look at.

657
01:11:03,750 --> 01:11:07,020
There's one person online, I don't know.

658
01:11:08,850 --> 01:11:12,360
There's bigger communities that are more reputable. So like our lives is one of them.

659
01:11:12,360 --> 01:11:17,189
It's more legitimate. Our patios, as people are trying to moderate their cannabis use and then there's our trees,

660
01:11:17,190 --> 01:11:23,150
which is pro cannabis use and there's like it's MDMA, it's there's 219,000 members.

661
01:11:23,160 --> 01:11:29,040
Like that's a good number of people. You know, you can have a lot of posts in those types of communities.

662
01:11:31,590 --> 01:11:36,840
This is a limited method. Every method we use is going to be somewhat limited in the best case we can do,

663
01:11:36,840 --> 01:11:41,940
kind of like representative samples that are prospective longitudinal, like,

664
01:11:41,940 --> 01:11:49,649
you know, data collection that's that has its own limitations in terms of like the amount of resources needed,

665
01:11:49,650 --> 01:11:51,810
the amount of effort, things like that, right.

666
01:11:52,590 --> 01:11:58,820
I would say, like there's differences in terms of like how how easy it is to talk about marijuana or cannabis,

667
01:11:58,830 --> 01:12:08,190
like depending on like the legal status in a given state as well as like potentially like community or family beliefs,

668
01:12:08,460 --> 01:12:14,670
kind of like culture around whether or not this is a normalized and kind of like socially permissible for anything or not.

669
01:12:14,790 --> 01:12:19,290
And there's like a lot of differences and we miss out on some of those for sure in this type of

670
01:12:19,290 --> 01:12:25,020
data because not everyone who uses a given substance is going to come to Reddit to talk about it,

671
01:12:26,700 --> 01:12:29,770
I think, because there's just so little information out there.

672
01:12:29,790 --> 01:12:36,000
This is a really great first step when trying to understand informal recovery because people are just posting about their experiences.

673
01:12:36,360 --> 01:12:40,050
And you can kind of like say like, okay, people who are saying we went to formal treatment,

674
01:12:40,290 --> 01:12:44,489
we can they kind of pull them out and look at we can compare them to people who don't have that formal treatment.

675
01:12:44,490 --> 01:12:49,710
See, there are differences. Or you can just, you know, entirely focus on people who aren't talking about formal treatment.

676
01:12:50,220 --> 01:12:53,010
Again, like just because they don't talk about it doesn't mean they haven't received it.

677
01:12:53,010 --> 01:12:58,110
So you're going to have some some kind of like muddying the waters in that sense.

678
01:13:00,720 --> 01:13:08,580
But this is like a good first effort. And then next efforts can include like, how do we recruit people in a more inclusive way?

679
01:13:08,640 --> 01:13:12,080
How do we think about, you know, populations that are minority are know,

680
01:13:12,120 --> 01:13:21,180
kind of marginalized or minoritized within the current legislation who are maybe less likely to come on a place like Reddit for various reasons.

681
01:13:21,840 --> 01:13:27,690
That's where we start to get into this intersectionality question and really try to understand kind of the heterogeneity in experiences.

682
01:13:29,210 --> 01:13:32,850
That's a great point. This is a very limited method.

683
01:13:33,510 --> 01:13:38,280
I would argue that lots of methods are really limited, but like social media is not a panacea.

684
01:13:38,280 --> 01:13:42,899
This is a limited method that has some like opportunities but we can't like.

685
01:13:42,900 --> 01:13:50,219
It's really important to state in terms of in my lectures but also my work when I write like these are the limitations.

686
01:13:50,220 --> 01:13:55,650
Like this is not the full story, this is part of a story. We need more data, we need more resources.

687
01:13:56,130 --> 01:13:59,459
And to better understand. And another thing I want to say is,

688
01:13:59,460 --> 01:14:02,790
like a lot of people in these posts are like talking about how they don't

689
01:14:02,790 --> 01:14:07,169
believe that cannabis should be illegal or that people are acknowledging like,

690
01:14:07,170 --> 01:14:11,010
no, this isn't working for me, but like I still have friends who smoke and I don't like.

691
01:14:11,010 --> 01:14:17,790
I am fully supportive of them doing what's best for them. Like this isn't an attack on weed, but in my work that's not the point.

692
01:14:17,790 --> 01:14:22,170
It's more just to figure out, like for people who are having a challenge with that, like,

693
01:14:22,830 --> 01:14:27,510
what can we do to help and where can we intervene in a way that would be helpful to people?

694
01:14:29,850 --> 01:14:33,000
Okay. I went over by minute. I'm really sorry. I did. Really.

695
01:14:34,110 --> 01:14:41,020
I'm happy to stick around for a few minutes or questions are just generally don't know if you guys have a rap routine, but you're confused.

696
01:14:41,040 --> 01:14:48,350
And I was going to confess that I was a student more recently than you are.

697
01:14:48,580 --> 01:14:53,790
Well, so first of all, thank you so much. Well, apparently, uh, yeah.

698
01:14:53,790 --> 01:14:58,109
So, uh, next week I think I'm going to probably send an email.

699
01:14:58,110 --> 01:15:03,459
So normally at this point this semester, we would move into violating yet another assumption of regression,

700
01:15:03,460 --> 01:15:10,700
and now we're gonna be looking at different sorts of outcomes. But we left factor analysis in some of the measurement pieces in kind of a.

