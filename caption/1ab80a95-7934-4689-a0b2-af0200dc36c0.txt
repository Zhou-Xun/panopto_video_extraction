1
00:00:01,790 --> 00:00:11,410
Yeah. Yeah, I think I feel like.

2
00:00:12,040 --> 00:00:29,320
I mean. You know, it wasn't like they had with like the Brady.

3
00:00:32,480 --> 00:00:36,740
And that's how we get out.

4
00:00:39,800 --> 00:00:50,370
Did you have to I mean, they do have this infrared light and it's been hard for them this morning.

5
00:00:51,390 --> 00:00:55,700
I feel like it's one that they do have to.

6
00:00:57,000 --> 00:01:05,500
I think. They also they're doing.

7
00:01:09,710 --> 00:01:15,250
I'm not sure we are. Yeah.

8
00:01:15,780 --> 00:01:24,880
We depend on the money.

9
00:01:26,020 --> 00:01:34,270
Yeah, I don't know. I don't know what you guys. It's okay.

10
00:01:34,270 --> 00:01:42,310
We're going to go ahead and get started. So. So for today's activity, we're doing one on measurement error.

11
00:01:42,490 --> 00:01:50,049
So the article that this is based on is the article that a lot of the extra credit homework questions are based on.

12
00:01:50,050 --> 00:01:56,470
So you can find that article that way. And I'll give you all like 20 minutes and then we'll go over the answers together.

13
00:02:11,640 --> 00:02:22,730
They're going to be. I guess that's why it's hard to.

14
00:02:26,460 --> 00:02:29,840
Oh. Right?

15
00:02:30,580 --> 00:02:38,060
Yeah, that's good to know.

16
00:02:48,550 --> 00:02:59,280
Yeah. Right.

17
00:03:03,860 --> 00:03:08,310
She? Okay.

18
00:03:11,420 --> 00:03:22,700
So this is how I work here.

19
00:03:22,840 --> 00:03:27,830
Oh, right.

20
00:03:33,080 --> 00:03:36,760
She's busy. No.

21
00:03:51,190 --> 00:04:14,520
What makes. We had a breakdown and I would get involved because I really like.

22
00:04:17,320 --> 00:04:21,250
Yeah. It's like it's always. They're tricky.

23
00:04:21,430 --> 00:04:25,150
They can be separate and distinct. What can the easiest way? Yeah.

24
00:04:26,650 --> 00:04:30,220
Yeah, I think I could see my kids.

25
00:04:34,370 --> 00:04:40,530
Yeah. Like. I know that.

26
00:04:40,790 --> 00:04:48,400
I've tried. So.

27
00:04:57,930 --> 00:05:05,150
Yeah. I hope.

28
00:05:14,030 --> 00:05:22,570
Have you ever said I wasn't? I'm not.

29
00:05:24,620 --> 00:05:27,650
I'm. That's how I got.

30
00:05:30,190 --> 00:05:35,030
They see. You beat them on Saturday?

31
00:05:36,490 --> 00:05:45,410
He's either running. That.

32
00:05:47,180 --> 00:05:55,350
Who else is? I think.

33
00:06:04,070 --> 00:06:10,070
Well, sometimes I don't like people. Sometimes. Oh, yeah?

34
00:06:10,970 --> 00:06:39,500
Yeah. While those are difficult to combat.

35
00:06:39,900 --> 00:06:45,960
That was. How do you.

36
00:06:50,090 --> 00:06:53,120
Oh, I don't know.

37
00:06:55,140 --> 00:07:01,080
Yeah. Okay. Now, is this the first? When I was 17.

38
00:08:14,510 --> 00:08:25,970
Know. But it's.

39
00:08:40,740 --> 00:09:07,610
I don't. What?

40
00:09:13,590 --> 00:09:31,040
I mean. I want to make the call.

41
00:09:32,900 --> 00:09:36,540
This is. Also.

42
00:09:50,850 --> 00:09:56,840
Yeah. Okay. But I. I think that connection with.

43
00:09:59,770 --> 00:10:06,300
Oh. I.

44
00:10:07,020 --> 00:10:13,030
Good. I also think it's.

45
00:10:21,980 --> 00:10:30,280
I. You can't.

46
00:10:56,390 --> 00:11:08,900
I wasn't. I don't think. Yeah.

47
00:11:11,100 --> 00:11:16,030
Do you? How much?

48
00:11:32,610 --> 00:11:52,100
So I. The.

49
00:11:59,110 --> 00:12:14,280
You might. It's like asking if.

50
00:12:22,480 --> 00:12:29,160
Now. I'm. But we just like to.

51
00:12:31,190 --> 00:12:35,540
I. We went to the fourth floor.

52
00:12:45,330 --> 00:12:53,670
Oh, I don't know. I start.

53
00:12:56,520 --> 00:13:02,410
I'm just very concerned. You see this?

54
00:13:04,560 --> 00:13:07,970
It's just anyone. The Mullah.

55
00:13:12,190 --> 00:13:19,780
You know. Bet.

56
00:13:22,850 --> 00:13:35,530
I want you to. And now I'm. If.

57
00:13:38,230 --> 00:13:45,440
So when's the next? It's going to be like everything going great.

58
00:13:45,680 --> 00:13:54,000
It's really. I know you can say whatever.

59
00:14:02,380 --> 00:14:09,610
You know, I think that. I think. Yeah.

60
00:14:12,400 --> 00:14:16,190
But she's like that.

61
00:14:38,490 --> 00:14:53,890
It would be. What do you do?

62
00:14:55,210 --> 00:15:08,260
Nobody wants. I do.

63
00:15:54,330 --> 00:16:10,160
Right. But.

64
00:16:15,170 --> 00:16:20,110
So, you know. Kids.

65
00:16:23,880 --> 00:16:35,420
I. What are you doing?

66
00:16:36,730 --> 00:16:56,380
What is happening? You go on in the movie here?

67
00:16:56,890 --> 00:17:08,880
It's quite wonderful. Why not?

68
00:17:09,840 --> 00:17:13,940
No, I would not go on the record. This is a draft.

69
00:17:16,290 --> 00:17:23,200
Now, I would never kill anybody. But if I work for you, I want to work.

70
00:17:26,430 --> 00:17:30,430
Now, I. You said.

71
00:17:33,300 --> 00:17:39,930
Allegedly. I just think I actually.

72
00:17:40,980 --> 00:17:45,650
I just feel I should be me. I remember that.

73
00:17:49,510 --> 00:17:53,840
So. I.

74
00:18:02,410 --> 00:18:23,900
Why? It. Which is.

75
00:18:25,030 --> 00:18:33,670
No, I don't think that to do.

76
00:18:36,180 --> 00:18:41,400
I wish. U.S. officials.

77
00:18:43,390 --> 00:18:48,550
One. It's.

78
00:18:50,680 --> 00:18:57,050
One. When did that happen?

79
00:19:03,040 --> 00:19:09,910
Well, let's. You say?

80
00:19:15,880 --> 00:19:26,190
It's like I told you. When you.

81
00:19:32,200 --> 00:19:45,120
I just made. This is my last.

82
00:19:51,290 --> 00:19:59,660
I. I know.

83
00:20:02,640 --> 00:20:09,959
It was, like violent. Are people ready to start going over?

84
00:20:09,960 --> 00:20:18,010
Do you need more time? People are good.

85
00:20:19,870 --> 00:20:21,670
Okay, we'll start going over it.

86
00:20:22,330 --> 00:20:31,479
So for question one, it says from the way in which weight and height were assessed, which you can find that in the exposure exposure section.

87
00:20:31,480 --> 00:20:39,430
Under the methods in the paper, we can anticipate that BMI greater than or equal to 30, will be a highly sensitive measure of obesity.

88
00:20:40,120 --> 00:20:43,000
Does anyone want to share if they said that was true or false?

89
00:20:50,730 --> 00:20:56,460
So first off, did anyone find how they measured weight in height or how it was assessed in this paper?

90
00:20:59,590 --> 00:21:04,930
Yeah. So if we go to the paper, it says right here, uh,

91
00:21:05,320 --> 00:21:13,480
maternal BMI in early pregnancy was calculated from self-reported height and weight measured in light clothing, clothing at the first prenatal visit.

92
00:21:13,990 --> 00:21:22,120
So we know our height was self-reported, but our weight was actually measured, uh, actually at the appointments.

93
00:21:22,600 --> 00:21:33,520
So because we know our height is self-reported, that could bias what the BMI is because people tend to overestimate their height.

94
00:21:34,270 --> 00:21:41,860
So if someone were to overestimate their height, that's going to cause their BMI to be lower than what it actually is.

95
00:21:42,370 --> 00:21:48,440
So that's going to affect the sensitivity. Of the measure.

96
00:21:49,580 --> 00:21:59,300
So if we're looking at what is sensitivity, so where are we actually capturing among those people who truly have a BMI greater than 30?

97
00:21:59,330 --> 00:22:07,250
Are we actually capturing all those people? So in this case, if we're looking at our obesity definition of BMI greater than 30,

98
00:22:07,550 --> 00:22:13,610
since those people are going to overestimate their height and pause their BMI to be lower,

99
00:22:13,970 --> 00:22:20,120
we're going to miss those people who are kind of like right on the cusp who should be classified as being obese.

100
00:22:20,120 --> 00:22:25,730
But since they overreported their height, they're going to be actually classified as having a BMI lower than 30.

101
00:22:26,180 --> 00:22:30,630
So that's going to affect our sensitivity of the measure. So it's not going to be highly sensitive.

102
00:22:30,650 --> 00:22:34,820
Our sensitivity is going to be like less than 100% and it isn't going to be as good.

103
00:22:35,330 --> 00:22:45,770
So this is going to be false. So then number two is kind of related to this, but it's dealing with specificity.

104
00:22:45,800 --> 00:22:53,000
So it says from the way in which weight and height were assessed, we can anticipate that the specificity of an obesity definition,

105
00:22:53,510 --> 00:22:57,050
BMI, greater than 30, is probably less effective than its sensitivity.

106
00:22:58,010 --> 00:23:08,300
Does anyone want to share whether they got true or false for this one? Just throw out an answer.

107
00:23:12,370 --> 00:23:21,940
Yeah. So it is going to be true. So if we're looking at the specificity, we're looking at among those people who had BMI, less than 30.

108
00:23:22,810 --> 00:23:27,010
How many of those with this definition would be classified as having BMI?

109
00:23:27,010 --> 00:23:33,399
Less than 30. So if we think again about how high it was reported, it was self-reported.

110
00:23:33,400 --> 00:23:40,420
And if we think they're going to overestimate their height, even if they're originally classified as having BMI less than 30,

111
00:23:40,990 --> 00:23:45,700
there's still even if they overestimate their height, their BMI is going to be even lower.

112
00:23:45,710 --> 00:23:48,970
So they're still going to be classified as having BMI less than 30.

113
00:23:49,300 --> 00:23:54,530
So the specificity shouldn't be affected. So that's going to be true.

114
00:23:59,350 --> 00:24:05,930
So then for number three, it says by taking the median of height values reported across different pregnancies for each woman.

115
00:24:05,950 --> 00:24:10,840
Investigators are primarily trying to remove systematic error in the assessment of height.

116
00:24:11,980 --> 00:24:27,890
So did anyone want to say true or false? If you're in an exam, what would you guess?

117
00:24:27,920 --> 00:24:33,230
True or false? So it's actually going to be false.

118
00:24:35,480 --> 00:24:44,030
That's fair. I feel like everyone guesses wrong on this, but so in this case, the key is systematic error.

119
00:24:44,450 --> 00:24:49,970
So if we're looking at we're taking the median of height values across different pregnancies.

120
00:24:50,060 --> 00:24:55,450
So you have these repeated measures of height there.

121
00:24:55,790 --> 00:25:01,040
Since we're dealing with adults, their heights are probably going to be pretty true to what their height,

122
00:25:01,040 --> 00:25:02,990
they're just going to be a little bit different.

123
00:25:04,070 --> 00:25:12,080
Like with random error, that could be a little bit higher, a little bit lower each time, but they should be pretty centered on the true height value.

124
00:25:12,110 --> 00:25:19,340
So it's just going to be that random error. So this median height value is actually assisting random error, not systematic error,

125
00:25:20,180 --> 00:25:24,110
because you're looking kind of like that test retest you mentioned in lecture.

126
00:25:24,740 --> 00:25:30,210
So in order, if you wanted to remove systematic error, that's when you have to look at the validity.

127
00:25:30,230 --> 00:25:40,070
So you get into like criterion validity and doing like the test against the gold standard, which we don't have in this case.

128
00:25:40,080 --> 00:25:43,920
So this is just looking at removing random error, not systematic error.

129
00:25:43,940 --> 00:25:45,080
So this is going to be false.

130
00:25:49,250 --> 00:25:57,500
So then for number four, it says there are no strong reasons to believe that misclassification of BMI is differential with respect to the outcome.

131
00:26:00,010 --> 00:26:16,100
Any guesses? So a hint for this one is think about what type of study was this?

132
00:26:22,110 --> 00:26:27,420
Was it a cohort study? Was it a case control study? I think it sounds like right at the beginning.

133
00:26:28,440 --> 00:26:38,090
Yeah. So it's a retrospective cohort study. So we're looking at misclassification of BMI and we know BMI in this case is our exposure.

134
00:26:38,100 --> 00:26:44,880
So we're looking at do we have misclassification of exposure and its differential with respect to the outcome.

135
00:26:44,890 --> 00:26:54,209
So in this case, cerebral palsy. So in this case, this usually isn't the case when you have cohort studies,

136
00:26:54,210 --> 00:27:00,180
because if you think about when is your outcome, you look at your outcome after some time has passed.

137
00:27:00,270 --> 00:27:07,229
So you assessed your exposure first. So it shouldn't matter whether they had the outcome or not.

138
00:27:07,230 --> 00:27:08,879
You're not going to know that at the beginning.

139
00:27:08,880 --> 00:27:16,230
So it's not going to you're not going to have misclassification of that exposure due to like with respect to the outcome,

140
00:27:16,230 --> 00:27:20,250
because you don't know the outcome at the time. You actually are looking at their exposure at the beginning.

141
00:27:22,870 --> 00:27:32,980
So this is going to be true. Most of the time you'll have misclassification of exposure when you're in case control studies versus in cohort studies.

142
00:27:36,120 --> 00:27:44,880
So then for number five, it says random measurement error and BMI can be clearly observed in the dags of the figure on page 931.

143
00:27:48,110 --> 00:27:52,570
Any guesses? Yeah.

144
00:27:52,630 --> 00:27:58,270
So it is going to be false. So you can actually assess random error in dags.

145
00:27:58,540 --> 00:28:09,710
There's just no way to represent it. And Dags. You can look at systematic error in Dags.

146
00:28:09,760 --> 00:28:13,180
So if you were to have something like this,

147
00:28:13,270 --> 00:28:21,310
if you see that in a dag that's actually representing systematic error, that's saying A is your actual variable.

148
00:28:21,880 --> 00:28:26,440
But again, if you're looking at systematic error, you're looking at the ability of the measure.

149
00:28:26,830 --> 00:28:28,840
Are you actually measuring what you should?

150
00:28:29,050 --> 00:28:35,640
And so if you have systematic error, you're actually measuring something that's not quite what you should be.

151
00:28:35,650 --> 00:28:39,230
So I think. So if you go back to like, oops.

152
00:28:40,790 --> 00:28:44,360
If you look, I think these are a really good example of that.

153
00:28:44,420 --> 00:28:48,079
So if you have systematic error, you're not actually measuring what you should.

154
00:28:48,080 --> 00:28:54,650
You want to be measuring the true value which is represented with the bull's eye, but you're actually kind of measuring something.

155
00:28:56,580 --> 00:29:02,490
Away from that. So that saying you're not actually measuring a you're measuring like a star or something.

156
00:29:03,090 --> 00:29:08,730
So you can represent systematic error in drugs, but you can't represent random error and x.

157
00:29:12,620 --> 00:29:19,100
So then for number six, it says measurement error and BMI was non differential with respect to the outcome.

158
00:29:19,580 --> 00:29:22,430
The cumulative incident ratios of cerebral palsy,

159
00:29:22,700 --> 00:29:31,190
one could calculate for the BMI categories presented in table three would consistently represent an underestimation of the true underlying series.

160
00:29:32,150 --> 00:29:53,910
Is that true or false? So first off, we're looking at BMI with BMI categorized as dichotomous, categorical or continuous in this paper.

161
00:30:00,070 --> 00:30:10,760
So if we actually look at table three. It's actually categorized as categorical.

162
00:30:10,780 --> 00:30:15,040
We have this less than 18.5. 18.5 to 24.9.

163
00:30:15,040 --> 00:30:26,770
25 to 29.9. So we know if you kind of go back to the lecture slides, um, when he talked about categorical exposures,

164
00:30:27,580 --> 00:30:32,319
if you have so it says if you have misclassification over exposure,

165
00:30:32,320 --> 00:30:41,980
so BMI that's non differential, it's back to the outcome you could depending on how like which categories were affected,

166
00:30:42,460 --> 00:30:47,650
your hours are going to change. So there's no way to determine how they're going to change.

167
00:30:47,710 --> 00:30:51,010
Some could be attenuated. Some can be exaggerated.

168
00:30:51,430 --> 00:30:54,460
So the direction, the bias is not always the same.

169
00:30:54,640 --> 00:30:59,050
So it depends on which categories are affected. So this is going to be false.

170
00:31:19,230 --> 00:31:26,970
Sorry. It should be false.

171
00:31:26,980 --> 00:31:32,040
I don't know why it's not writing. There you go.

172
00:31:33,060 --> 00:31:39,000
Okay. Still in for number seven. It says The validation process of cerebral palsy cases described,

173
00:31:39,270 --> 00:31:44,340
which you can find in the outcome section under the methods, is an example of criterion validity.

174
00:31:44,940 --> 00:31:58,830
Is that true or false? So if we go to that section in the paper.

175
00:32:06,520 --> 00:32:14,739
So it says in these registries, all reported cases are systematically validated through medical or record review,

176
00:32:14,740 --> 00:32:20,710
physical examination or both by pediatric neurologists who are experts on cerebral palsy.

177
00:32:21,070 --> 00:32:28,630
So they had these experts look to make sure that the cases were actually cases.

178
00:32:29,080 --> 00:32:34,210
So this is actually going to be false. It's not an example of criterion validity.

179
00:32:34,510 --> 00:32:38,260
It's actually an example of consensus validity.

180
00:32:39,310 --> 00:32:48,700
If it were criterion validity, we would have to we would be having our like obesity definition and we'd be comparing it to a gold standard.

181
00:32:49,210 --> 00:32:51,460
So that would be an example of criterion validity,

182
00:32:51,850 --> 00:33:03,040
since in this case they had experts look at the cerebral palsy cases to come to a consensus on if they're actually cases or not.

183
00:33:03,250 --> 00:33:07,330
It's an example of consensus validity. So it's going to be false.

184
00:33:10,850 --> 00:33:16,610
So then for the last one, it says investigators wish to estimate the CIA for cerebral palsy,

185
00:33:16,610 --> 00:33:22,760
according to obesity defined dichotomous dichotomous as a BMI greater than 30,

186
00:33:23,150 --> 00:33:31,490
an external validation study that compared the diagnostic algorithm for CP used in the main study against the gold standard method to identify,

187
00:33:31,490 --> 00:33:37,430
CP indicated that there was no children diagnosed with CP who in reality did not have CP.

188
00:33:37,850 --> 00:33:44,629
However, a few children who truly had CP were not captured by the diagnostic algorithm at peers,

189
00:33:44,630 --> 00:33:49,400
not having CP by the same proportion in women with or without obesity.

190
00:33:50,240 --> 00:33:56,870
Properly identifying these children as having CP would have produced a more valid CAIR than what was obtained in the main study.

191
00:33:58,710 --> 00:34:05,050
Does anyone have a guess on this one? Or how you would approach it.

192
00:34:13,830 --> 00:34:22,810
So first off. It says we're doing an external validation study where we're comparing against the gold standard.

193
00:34:23,260 --> 00:34:26,530
So, you know, first you're looking at criterion validity.

194
00:34:27,070 --> 00:34:31,150
So we know we're kind of going to look at sensitivity and specificity.

195
00:34:31,660 --> 00:34:41,110
And so this sentence here where it says there were no children diagnosed with CP who in reality did not have CP.

196
00:34:41,710 --> 00:34:48,820
So we know among those people who did not have CP, no children were actually diagnosed as having CP.

197
00:34:49,150 --> 00:34:58,990
So if we think about what specificity means, it means among those people who don't have CP, how many of them actually tested as not having CP?

198
00:34:59,320 --> 00:35:05,590
And so in this case, we know all of them should have. So that's indicating our specificity is 100%.

199
00:35:07,270 --> 00:35:15,850
If we then look at the next part, it says, However, a few children who truly had CP were not captured by the diagnostic diagnostic algorithm

200
00:35:16,240 --> 00:35:21,340
and appears not having CP by the same proportion in women with or without obesity.

201
00:35:21,880 --> 00:35:31,300
So that's actually talking about sensitivity. So it says a few children who truly had CP were not captured by the diagnostic algorithm.

202
00:35:31,780 --> 00:35:35,050
So that's if we're thinking about what does sensitivity mean?

203
00:35:35,200 --> 00:35:40,750
It means among those people who actually have CP, were they actually classified as having CP?

204
00:35:41,080 --> 00:35:45,430
And in this case, we know some of them were actually classified as not having CP.

205
00:35:45,910 --> 00:35:49,270
So we know our sensitivity is actually going to be less than 100%.

206
00:35:50,650 --> 00:35:57,610
And then it says that is the same proportion in women with or without obesity were affected by that.

207
00:35:58,000 --> 00:36:02,160
So since our exposure or exposure.

208
00:36:02,180 --> 00:36:06,970
Yeah. Or obesity, the same proportion of women with or without is affected.

209
00:36:07,450 --> 00:36:15,820
We know that misclassification of CPR outcome is non differential with respect to the exposure of obesity.

210
00:36:16,420 --> 00:36:26,380
So we know we're looking at we have 100% specificity, but we have a lower sensitivity and it's non differential with respect to the outcome.

211
00:36:26,890 --> 00:36:33,790
So if we actually look back at his PowerPoint slides and the little table he has at the end,

212
00:36:35,860 --> 00:36:44,680
we know if we have a misclassification of outcome that's non differential and it only affects sensitivity.

213
00:36:44,740 --> 00:36:48,720
We know there's no bias on the air. So this is going to be false.

214
00:36:48,790 --> 00:36:51,280
The sea air should be the same. It shouldn't.

215
00:36:53,440 --> 00:37:01,120
It says in the question the CP, whatever produced the more valid c r it's going to be the same C.R. So it's going to be close.

216
00:37:08,370 --> 00:37:20,059
Are there any questions on any of these? If not, that's all for today.

217
00:37:20,060 --> 00:37:36,860
And I'm happy to answer any questions up here, if you have any. Hey.

218
00:37:37,790 --> 00:37:41,780
Yeah. Yeah.

219
00:37:42,530 --> 00:37:47,360
So I'm basically here. Yeah. So I heard.

220
00:37:47,940 --> 00:37:51,200
It's not like I'm aware. Yeah.

221
00:37:51,380 --> 00:37:56,390
Okay. And here there is like. No, we've been just, like, a difference at first.

222
00:37:57,500 --> 00:38:00,990
Yeah. So how is your outcome classified then? Like what scale?

223
00:38:02,300 --> 00:38:06,530
Like the difference between. Yeah.

224
00:38:06,530 --> 00:38:10,399
So is it you can either have dichotomous outcomes category.

225
00:38:10,400 --> 00:38:15,740
It's continuous. Continuous. And for that they can do a ratio.

226
00:38:17,330 --> 00:38:26,090
So think about what I'm trying to say. I'm looking at the mean difference.

227
00:38:26,690 --> 00:38:29,780
Yeah, it's going to be a difference though. It's not going to be a ratio. Yeah.

228
00:38:29,780 --> 00:38:39,760
As the difference. Yeah. Can I do like can I call like cumulative difference or it's like just call in just a few differences or just difference.

229
00:38:40,130 --> 00:38:44,870
I can say I have the difference here and clear they differ on that and it's both.

230
00:38:44,870 --> 00:38:52,879
Yeah. Based on that can I say it's a systematic problem and yeah.

231
00:38:52,880 --> 00:38:56,900
So this is like the difference in Exposed and Exposed.

232
00:38:57,140 --> 00:39:00,980
So then you want to get a measure of association that compares those two.

233
00:39:01,430 --> 00:39:08,620
So how would you like how do you compare those if you're thinking of your your measure of association is a difference also abstractly.

234
00:39:08,780 --> 00:39:22,620
Yeah. So then that's your measure of notice and difference. Like usually it's going to be like 1.9, 3.9 or these two, 4.7 minus three points.

235
00:39:22,650 --> 00:39:25,160
Right. I'm part of that.

236
00:39:26,660 --> 00:39:39,350
I think it's going to be no, I mean, if you have a calculator, it's not just saying, okay, so just use calculator, like if you have that idea.

237
00:39:39,740 --> 00:39:45,200
Yeah. So differences in these two is a measure of association.

238
00:39:45,200 --> 00:39:48,350
Yeah. Okay. But, but it says here.

239
00:39:52,530 --> 00:40:02,040
So basically based on that, like there is a difference between I don't know who I and who's out there just because,

240
00:40:02,040 --> 00:40:10,870
again, I feel like systematically it's an issue because there's a difference between these two as similar or yeah.

241
00:40:11,200 --> 00:40:13,680
Um, so some interpret that.

242
00:40:14,010 --> 00:40:26,129
So we know we're taking the difference between these and we're looking at this is like the difference between 36 and 24 months for both of them.

243
00:40:26,130 --> 00:40:38,100
So you could say, um, how does this is, what do you think of like, how would you do like if you were an actual Ciara or a kid with dichotomous,

244
00:40:38,100 --> 00:40:44,729
you say the rate or risk or whatever and they expose this blank times the unexposed.

245
00:40:44,730 --> 00:40:50,150
So you can kind of follow a similar. This is like interpreting it.

246
00:40:51,290 --> 00:40:54,740
That's it. There's no control. No one can.

247
00:40:55,040 --> 00:41:00,350
And we're here. The time and place like to an ally.

248
00:41:00,860 --> 00:41:03,920
Yeah. Okay. So this is like. It's similar.

249
00:41:04,280 --> 00:41:12,570
I'm placing the same value. So, again, it's going to be on here is going to be systematic and differential because I'm playing the same.

250
00:41:14,240 --> 00:41:20,850
Yeah. So if you're if that is affecting your exposed and unexplained value.

251
00:41:20,870 --> 00:41:23,960
Yeah. It's been that different as game over the same direction.

252
00:41:24,260 --> 00:41:33,870
Yeah. Okay. And so what wanted do here is to make your input there.

253
00:41:35,990 --> 00:41:39,140
So basically, I just. Yeah. So you would just.

254
00:41:39,650 --> 00:41:43,549
Instead of 91.2, it'd be 93.2 and 92.2.

255
00:41:43,550 --> 00:41:45,680
And it's going to be the same value. Yeah.

256
00:41:46,780 --> 00:41:57,610
And and what is the effect basically is the same thing for you or at least when it comes to non-negative misclassification,

257
00:41:57,620 --> 00:42:01,490
like for continuous and yeah. The Economist is the same.

258
00:42:01,550 --> 00:42:08,240
Yeah. I mean, his slides are full summary slides are super helpful to have you kind of find what type of error it is.

259
00:42:08,240 --> 00:42:14,270
He kind of goes through how it should be affected every time because in the slides it's very, very briefly.

260
00:42:14,570 --> 00:42:22,060
And then I went back to the additional reading. He posted what that measures only about the case control.

261
00:42:22,070 --> 00:42:32,809
There's nothing mentioned in regards to cohort only mean differences of the economists and yeah I mean so in the slide he because

262
00:42:32,810 --> 00:42:38,810
he you know like sometimes I write this stuff and you guys mandate a lot of explanations like from where can I give it you know.

263
00:42:38,840 --> 00:42:48,530
Yeah. So I mean, he goes through misclassification of outcomes for continuous data and then misclassification of exposures for continuous data.

264
00:42:48,860 --> 00:42:57,760
So if you're misclassification misclassifying the outcome, you're misclassified as this can summarize outcome likelihood.

265
00:42:58,610 --> 00:43:02,970
So yeah, is a question for you. Do you think the measurement is the one that I'm.

266
00:43:04,850 --> 00:43:08,890
Yeah. So you're adding to. Okay. Yeah.

267
00:43:09,010 --> 00:43:11,090
Yeah. So you're misclassifying your outcome.

268
00:43:11,480 --> 00:43:17,300
And so you see you have your exposed and unexposed and it's going to think about how it affects each of those groups.

269
00:43:17,420 --> 00:43:20,800
Okay. And then I'll.

270
00:43:22,550 --> 00:43:27,440
I'll do that. Thank you. Yeah, I have two questions.

271
00:43:28,550 --> 00:43:34,880
One was about. Oh, you said so the misclassification of the outcome.

272
00:43:35,000 --> 00:43:45,140
Yeah. I'm just wondering is like what you said was the best classification of the outcome or was it the misclassification in response to the outcome?

273
00:43:45,230 --> 00:43:47,990
Because I was thinking, yes, when you tied, it was like,

274
00:43:48,320 --> 00:43:56,750
so who's responsible outcome was are you talking about kind of like in here he has like with respect to the outcome.

275
00:43:56,810 --> 00:44:01,250
Yeah. So this is saying if measurement error in BMI.

276
00:44:02,030 --> 00:44:11,240
So if we're looking at this one here, number six so that thing I see more but he because it's ordinal I think.

277
00:44:11,780 --> 00:44:18,560
Yeah. So if we're looking at measurement error in BMI, that's saying you have some error in calculating the BMI.

278
00:44:18,710 --> 00:44:22,880
So we know BMI is our exposure. So since we have measurement error in there,

279
00:44:22,970 --> 00:44:30,230
we know we're misclassification misclassifying our exposure and it's non differential with respect to the outcome.

280
00:44:30,650 --> 00:44:35,210
So like the respect to the outcome is different than like misclassification of outcome or exposure.

281
00:44:35,420 --> 00:44:39,110
Yeah. Yeah. I was like, yeah, this was outcome.

282
00:44:39,110 --> 00:44:42,220
And I was like, okay, I like the focus here. Yeah.

283
00:44:42,230 --> 00:44:48,230
So it's saying you're misclassifying your BMI, your exposure with respect to the outcome.

284
00:44:48,230 --> 00:44:53,270
Like the outcomes are going to be different depending on are they? Did you misclassified the exposure or not?

285
00:44:53,460 --> 00:44:54,580
No, I didn't.

286
00:44:54,840 --> 00:45:02,450
And that's different from misclassification in respect to the outcome, in respect to the outcome, which is just misclassification of the exposure.

287
00:45:03,020 --> 00:45:11,120
Yeah. So you could say like flip the misclassification of the outcome and it could be differential and differential with respect to the exposure then.

288
00:45:11,900 --> 00:45:15,719
Yeah. Okay. And I have one more question.

289
00:45:15,720 --> 00:45:20,360
Yeah. So if that's okay. And this is about the homework and it's a very simple question.

290
00:45:21,680 --> 00:45:29,450
I was doing the homework and I saw this and it's this highlighted portion as it under what conditions?

291
00:45:29,450 --> 00:45:35,359
And I was thinking, what does that mean? And I was thinking like maybe it's talking about criterion validity because I

292
00:45:35,360 --> 00:45:41,150
think this was the questions that talked about specificity and sensitivity.

293
00:45:41,180 --> 00:45:46,310
Yeah. I think he means by like what conditions. So like if you determined it was.

294
00:45:46,890 --> 00:45:54,900
Like, um, like if you look at the top one and differential sensitivity, it's always going to be attenuation.

295
00:45:55,080 --> 00:45:56,890
So like, under what conditions?

296
00:45:56,910 --> 00:46:04,350
You know, if you have a misclassification of exposure, dichotomous exposure and it's non differential with respect to sensitivity,

297
00:46:04,620 --> 00:46:07,660
you're always going to have a attenuation like the condition.

298
00:46:07,690 --> 00:46:15,090
So that's what you want the direction bias because it wouldn't be fair to the type of measurement error on the risk ratio.

299
00:46:15,900 --> 00:46:20,010
So what is the effect of this table? So what is the what is the effect?

300
00:46:20,280 --> 00:46:24,179
Yeah. So your effects are either going to be is it an attenuation?

301
00:46:24,180 --> 00:46:31,589
Is it so if your unbiased is five and your what you calculated after misclassification two and that's attenuation,

302
00:46:31,590 --> 00:46:36,660
if it's larger exaggeration or like no effect, it's it's the same.

303
00:46:36,810 --> 00:46:40,780
So it's like the first portion is what happened in response.

304
00:46:40,800 --> 00:46:46,260
And can you make like a generalization based on those and like what is the, what is the law?

305
00:46:46,260 --> 00:46:50,120
That kind of. Yeah, this is. Well, it's okay, I think.

306
00:46:52,740 --> 00:46:57,410
I just want to know if you can repeat the second class about the so random error.

307
00:46:58,310 --> 00:47:03,110
Yeah, that's what we were doing. Then you can calculate like when you give an example, we use this.

308
00:47:03,440 --> 00:47:09,440
Yeah. So systematic here you're looking at validity versus random error kind of reliability.

309
00:47:09,770 --> 00:47:16,940
So like in this case, since we're taking like the median of high values like repeatedly, that's kind of looking at the reliability.

310
00:47:16,940 --> 00:47:20,860
The measurement is kind of the same over time. Okay. Like that test retest.

311
00:47:20,870 --> 00:47:26,390
Oh, that's dealing with random error versus systematic error is looking at the validity.

312
00:47:26,900 --> 00:47:31,100
So like, does it actually truly measure the true value?

313
00:47:31,150 --> 00:47:36,370
Okay. So in this case, you could use the big one for determining systematic error.

314
00:47:36,380 --> 00:47:41,090
Is that criterion validity comparing to the gold standard?

315
00:47:41,240 --> 00:47:44,280
Okay. They didn't do that. Yes. Okay. Thank you.

316
00:47:46,970 --> 00:47:55,160
Yeah. I mean, I want to make sure, first of all, that like this is what she means when she asks.

317
00:47:56,590 --> 00:48:00,980
Yes, there's going to be systematic.

318
00:48:03,970 --> 00:48:10,400
Yeah. So, I mean. A lot of those are like kind of the head of his slides.

319
00:48:10,610 --> 00:48:20,220
So like differential misclassification of dichotomous outcomes, non or non differential misclassification of continuous outcome.

320
00:48:20,240 --> 00:48:24,110
That's kind of what he's looking for. And then.

321
00:48:25,520 --> 00:48:32,700
The. So this is where I live with the continuous this is a continuous outcome, right?

322
00:48:32,720 --> 00:48:42,400
Yeah. I'm getting like just one of them doing it correctly because it is the means and so I of the means and I got it.

323
00:48:42,860 --> 00:48:51,730
And then I just subtracted like. What was it, a two inch, two centimeters thing from those two and the year again and I got the same.

324
00:48:51,740 --> 00:48:56,629
So there's no tightness, right? So yeah.

325
00:48:56,630 --> 00:49:04,100
So you're on the right track that there's not bias, but think about what is your measure of association with continuous data.

326
00:49:04,460 --> 00:49:09,340
So here, if you look at his slides, it's the difference.

327
00:49:09,380 --> 00:49:13,190
It's the difference. You don't do ratios with continuous data.

328
00:49:13,190 --> 00:49:18,420
You're doing differences. So like in this case, he looked at the difference in the means.

329
00:49:19,180 --> 00:49:23,840
In this case, it tells you. Sorry, I didn't.

330
00:49:25,410 --> 00:49:28,410
You're looking at a difference in mean height change.

331
00:49:28,860 --> 00:49:33,390
So like what is the difference in the change for your exposed and unexposed?

332
00:49:34,240 --> 00:49:38,260
And so then those are kind of like I mean, they're not serious in this case,

333
00:49:38,410 --> 00:49:45,010
but like it's your summary measure and they expose and the unexposed and then your measure of associations is the difference.

334
00:49:45,920 --> 00:49:50,540
Between those. So it just so it would be like so.

335
00:49:52,400 --> 00:49:56,920
So let's say like. One minus point five.

336
00:49:57,850 --> 00:50:03,370
Like if I have like 36 with a 36, the difference is one centimeter and then.

337
00:50:04,960 --> 00:50:11,770
24 months. The difference is point five and then it would be one minus point five.

338
00:50:13,350 --> 00:50:16,630
So. Oh, my God.

339
00:50:17,080 --> 00:50:21,540
I mean I mean, you can compare instead of kind of comparing across.

340
00:50:21,540 --> 00:50:27,080
You can also compare. What is the main difference in the exposed?

341
00:50:27,800 --> 00:50:33,380
What is the main difference in the unexposed? So that those are kind of like your summary measures for each group.

342
00:50:33,860 --> 00:50:44,200
And then you can take compare those. Okay.

343
00:50:44,680 --> 00:50:48,309
So I'm comparing that. And then I would just do the same, same things.

344
00:50:48,310 --> 00:50:51,330
But then just however that's okay.

345
00:50:51,430 --> 00:50:57,630
And so the difference of words compared to the difference between these two values is really something like this.

346
00:50:57,640 --> 00:51:06,730
This is really cool. I mean, for this like not C.A.R., but just like there's, there like a fancy name that I need to, um, I think so.

347
00:51:06,730 --> 00:51:13,360
I think just like difference. Like, I mean in the slides we're looking at, this is kind of weird too,

348
00:51:13,360 --> 00:51:17,980
because we're not only looking at the mean difference, we're looking at like the change.

349
00:51:18,920 --> 00:51:22,670
And the means like the change of the change in the mean differences.

350
00:51:22,910 --> 00:51:27,230
Yeah. I mean, I think you can just say, okay, the difference is this.

351
00:51:28,020 --> 00:51:32,110
Okay. The difference is your measure of association. Last question.

352
00:51:32,110 --> 00:51:36,610
I'm sorry to keep you in the game.

353
00:51:36,900 --> 00:51:45,370
I'm getting confused. So, yeah, so you can kind of disregard those slides because you didn't go over them and lecture.

354
00:51:45,390 --> 00:51:49,830
He's not going to expect you to know that. So you can disregard that.

355
00:51:49,860 --> 00:51:53,660
Wouldn't be like a couple. C No.

356
00:51:53,850 --> 00:51:59,400
Yeah. C three. They really got going of the important condition to consider.

357
00:51:59,430 --> 00:52:02,570
Okay. You can just disregard those slides. Okay.

358
00:52:02,580 --> 00:52:06,120
Awesome. Thank you so much. Yeah, I appreciate it. Yeah.

359
00:52:13,370 --> 00:52:17,400
Oh, yeah. Oh, okay. Yeah, we, um.

360
00:52:17,620 --> 00:52:21,979
We can't, uh. We can't. That's the prison that is to do.

361
00:52:21,980 --> 00:52:25,680
We need to run them. Run them into, uh, Entergy.

362
00:52:27,580 --> 00:52:32,479
Hmm. I mean, I guess we're dealing with people, so you can.

363
00:52:32,480 --> 00:52:37,000
I don't think we're going to like marking down if you or even like this.

364
00:52:37,260 --> 00:52:39,290
That's like a small technicality.

365
00:52:40,590 --> 00:52:52,079
And the last question that we found that is different than the ratio of, uh, they have different conclusion in the same question.

366
00:52:52,080 --> 00:52:56,790
So do we need to mention that the ratio we go to is the.

367
00:52:57,860 --> 00:53:02,720
Uh, different. And this has this type of arrow has some effect on it.

368
00:53:03,650 --> 00:53:07,490
Well, we just need to say the national best.

369
00:53:08,790 --> 00:53:12,600
I would just say, yeah, there's no bias and biases.

370
00:53:12,840 --> 00:53:20,980
Yeah. So you use the multiplication divide by.

371
00:53:22,050 --> 00:53:26,790
But we find the ratio instead of differences.

372
00:53:27,060 --> 00:53:34,890
So give us the. Yeah. So you want to think of what is your measure of association with continuous data.

373
00:53:35,010 --> 00:53:41,450
So I just close the slides, but you don't actually calculate it.

374
00:53:41,580 --> 00:53:48,450
It's you're looking at differences. So if you're, um, is do you have a score of.

375
00:53:48,570 --> 00:53:52,690
No. Yeah. So just one of the continuous slides.

376
00:53:53,890 --> 00:53:58,930
Just what is. So he is calculating the difference in the means.

377
00:53:59,500 --> 00:54:04,270
So your measure of association with continuous data is the difference.

378
00:54:04,780 --> 00:54:08,710
You are going to calculate like ratios. It's just differences.

379
00:54:08,830 --> 00:54:13,690
So that's how we always calculate a difference in continuous our.

380
00:54:20,300 --> 00:54:27,140
So then that should make your explanation clearer if you're just looking at your differences and the ratios.

381
00:54:27,150 --> 00:54:34,280
Yes. So there's no. So could you please explain the difference between.

382
00:54:36,630 --> 00:54:45,180
Yeah. So random error is looking at reliability versus systematic error is looking at validity.

383
00:54:45,690 --> 00:54:49,760
So if you have random error, you can still have validity.

384
00:54:49,770 --> 00:54:53,160
It's still kind of measuring what it's supposed to measure.

385
00:54:53,490 --> 00:55:00,810
But you kind of if you have repeated measures, they're all going to be just slightly different due to like it being random due to chance.

386
00:55:01,500 --> 00:55:05,280
So that's just the random area. You can't get rid of random error.

387
00:55:05,280 --> 00:55:09,000
It's just there versus if you have.

388
00:55:10,200 --> 00:55:14,910
Systematic error that's looking at the validity. Are you actually measuring the true value?

389
00:55:15,540 --> 00:55:19,220
And so you want high validity.

390
00:55:19,230 --> 00:55:24,890
You want to actually measure what you're supposed to. Or else your measure is going to be biased.

391
00:55:24,910 --> 00:55:31,460
It's not, actually. Measuring the true value of the arrow will affect all.

392
00:55:34,170 --> 00:55:39,729
So there is. So.

393
00:55:39,730 --> 00:55:43,820
I mean. When it's asking, like under what conditions?

394
00:55:43,970 --> 00:55:57,020
I mean, sometimes, like in this last case, we had misclassification of the outcome with respect to the exposure, but it had no bias on the.

395
00:55:58,130 --> 00:56:02,320
Outcome are on the. So even though we had.

396
00:56:03,890 --> 00:56:08,390
Measurement error. In some instances, it's not going to be biased.

397
00:56:08,750 --> 00:56:17,960
Most of the time it probably is. But there are cases where even if you do have some sort of error, it's going to be biased.

398
00:56:20,050 --> 00:56:23,260
So we have no. Yeah. Okay. Maybe next time.

399
00:56:25,560 --> 00:56:30,180
Create more. Every time I feel like there's either a lot left or there's nothing left.

400
00:56:30,500 --> 00:56:33,810
Yeah. Thank you.

401
00:56:33,880 --> 00:56:41,540
Yeah. Yeah.

402
00:56:41,810 --> 00:56:45,790
So somewhere. That's right.

403
00:56:46,260 --> 00:56:57,220
So here. This is true. It's true. Because there's no reason to believe that Moscow is differential with respect to the outcome.

404
00:56:57,580 --> 00:57:01,570
So how do we know if this respect to the outcome or exposure?

405
00:57:01,980 --> 00:57:08,950
Yes. So we know we have the same misclassification of BMI and we know BMI is our exposure.

406
00:57:09,440 --> 00:57:14,260
So is is it differential with respect to.

407
00:57:15,170 --> 00:57:23,960
The outcome. So we know since this is a cohort study and we have our exposure at the beginning and we're looking at the development and the outcome.

408
00:57:24,900 --> 00:57:32,070
We're not going to have misclassification of our exposure in respect to our outcome because our outcome hasn't happened yet.

409
00:57:32,080 --> 00:57:36,990
It doesn't matter, like if they're eventually going to have cerebral palsy or not.

410
00:57:37,000 --> 00:57:42,900
We don't know that at the time. The exposure. Is being classified.

411
00:57:43,020 --> 00:57:48,600
So we're not going to have misclassification of exposure due to the outcome because the outcome hasn't happened yet.

412
00:57:49,710 --> 00:57:52,800
And then you mentioned that when it sits on case controls,

413
00:57:52,800 --> 00:57:58,080
that we can say that that you usually you can have misclassification of exposure

414
00:57:58,080 --> 00:58:03,090
because you're picking your cases and controls and then you're going back and looking,

415
00:58:03,540 --> 00:58:08,280
determining what is there where they expose or not. So that can be subject to like recall bias.

416
00:58:08,700 --> 00:58:12,420
Someone could forget, did they actually do this or not?

417
00:58:13,140 --> 00:58:18,720
So that's more like. So misclassification of exposure is more likely in case control studies.

418
00:58:22,560 --> 00:58:29,010
Versus this. If you have cohort study, it's more likely going to be misclassification of your outcome.

419
00:58:32,100 --> 00:58:36,590
I think I'm you not deferential respect to.

420
00:58:37,890 --> 00:58:43,520
Yeah. So we went through. We know we have 100% specificity.

421
00:58:43,540 --> 00:58:48,250
We know we have less than 100% sensitivity. And we know it affects.

422
00:58:49,320 --> 00:58:53,040
People with and without the exposure are the same. So it's not differential.

423
00:58:53,490 --> 00:58:59,200
So we have a non differential misclassification to the.

424
00:59:00,890 --> 00:59:10,580
Of the exposure of the exposure. So we know based on like this the tables in the lecture there, there's no bias in that in this specific case.

425
00:59:11,060 --> 00:59:14,590
So it's going to be false there. It wouldn't have produced more valid ACR.

426
00:59:14,600 --> 00:59:19,340
It's going to be the same. So slight changes to respect to the exposure.

427
00:59:21,550 --> 00:59:25,060
So. Yeah.

428
00:59:25,070 --> 00:59:35,770
So we wish estimates are. So we're misclassifying our CPI.

429
00:59:35,800 --> 00:59:40,150
So that's our outcome. So we're misclassification of outcome with respect to exposure.

430
00:59:40,150 --> 00:59:47,230
You. And then followed up on this question of what it's talking about, the hype, which is also.

431
00:59:47,920 --> 00:59:55,100
Yeah. So yes, I think it tells you you misclassify.

432
00:59:56,190 --> 00:59:57,930
Like your height. The height.

