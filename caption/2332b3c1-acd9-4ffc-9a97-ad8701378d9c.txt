1
00:00:00,000 --> 00:00:07,170
Ananda Sen: Do we.

2
00:00:07,170 --> 00:00:15,900
Ananda Sen: We may still be missing beyond but will will that's fine yeah.

3
00:00:15,900 --> 00:00:18,810
Ananda Sen: All right, well welcome back to the.

4
00:00:18,810 --> 00:00:22,800
Ananda Sen: Second day.

5
00:00:22,800 --> 00:00:25,230
Ananda Sen: Of.

6
00:00:25,230 --> 00:00:28,020
Ananda Sen: episode 42.

7
00:00:28,020 --> 00:00:32,310
Ananda Sen: So.

8
00:00:32,310 --> 00:00:45,060
Ananda Sen: So i'll answer that my dad all the sessions are actually on my i'm on the zoom.

9
00:00:45,060 --> 00:00:50,790
Ananda Sen: In the canvas site, but you.

10
00:00:50,790 --> 00:00:57,600
Ananda Sen: You have not seen it yet, because I have not released them, I will today.

11
00:00:57,600 --> 00:01:06,960
Ananda Sen: And and and, once it is released, you will get a message, and it will be able to extract the video.

12
00:01:06,960 --> 00:01:12,840
Christie Flanagan: So, Dr seldon Can you also share where you uploaded your annotated.

13
00:01:12,840 --> 00:01:15,120
Christie Flanagan: Like I haven't done it yet.

14
00:01:15,120 --> 00:01:22,050
Ananda Sen: Okay, all of those I didn't do a big precisely because I still wanted to go through a couple of things.

15
00:01:22,050 --> 00:01:27,030
Ananda Sen: On the first step first like you said yeah I will do that today all of those.

16
00:01:27,030 --> 00:01:29,190
Ananda Sen: um yeah.

17
00:01:29,190 --> 00:01:32,610
Mehrdad Motamed: I just wanted to make sure so he's from 130 to five right.

18
00:01:32,610 --> 00:01:34,260
Ananda Sen: So that is 130 to five.

19
00:01:34,260 --> 00:01:36,390
Ananda Sen: Okay, I was my mistake, yes.

20
00:01:36,390 --> 00:01:40,050
Mehrdad Motamed: So yes, so um.

21
00:01:40,050 --> 00:01:46,950
Mehrdad Motamed: And I think I saw you the link for us Saturday, also on this zoom section that's.

22
00:01:46,950 --> 00:01:50,520
Ananda Sen: that's a yeah that's a dummy link.

23
00:01:50,520 --> 00:01:55,050
Ananda Sen: yeah I, I will make sure that.

24
00:01:55,050 --> 00:02:13,350
Ananda Sen: That, if I take the link away it wouldn't prevent you from accessing the video I don't think so, I think the video is are active for a while, but i'll make sure i'll figure out if josh you know the answer then.

25
00:02:13,350 --> 00:02:15,690
Mehrdad Motamed: Lastly, me on Friday.

26
00:02:15,690 --> 00:02:20,010
Ananda Sen: Last class Wednesday and Friday yes.

27
00:02:20,010 --> 00:02:21,330
Joshua Bosman: i'm sorry, what was the question.

28
00:02:21,330 --> 00:02:34,110
Ananda Sen: yeah I was saying that I I set it up so that i've set up the last day of class like Saturday yeah that's that's a dummy one but um.

29
00:02:34,110 --> 00:02:40,860
Ananda Sen: But if the class ends the students should still be able to access the videos for a while right the recording.

30
00:02:40,860 --> 00:02:46,260
Joshua Bosman: Oh i'm pretty sure yeah let me check my classes from last semester, just to confirm.

31
00:02:46,260 --> 00:02:49,590
Ananda Sen: Okay okay good.

32
00:02:49,590 --> 00:02:50,580
Ananda Sen: All right.

33
00:02:50,580 --> 00:02:52,890
well.

34
00:02:52,890 --> 00:03:05,280
Ananda Sen: let's get started with the proceedings today so um so few administrative things and I mentioned, most of it by message yesterday.

35
00:03:05,280 --> 00:03:17,310
Ananda Sen: So yeah it was my mistake we were supposed to end at five o'clock and we will end at five o'clock today so so what I have done, because this half an hour less than what I originally thought.

36
00:03:17,310 --> 00:03:35,280
Ananda Sen: The brakes will take we're going to be short it's just a regular by breaks or five minutes for each of those and i'll stop roughly around one hour 35 minutes for each after each session starts so so that was one thing, the second thing is.

37
00:03:35,280 --> 00:03:40,170
Ananda Sen: i'm i'm told that there should not be any more.

38
00:03:40,170 --> 00:03:43,170
Ananda Sen: issues with.

39
00:03:43,170 --> 00:03:45,450
Ananda Sen: With the downloading.

40
00:03:45,450 --> 00:03:52,380
Ananda Sen: I have made some changes some revisions and I have uploaded.

41
00:03:52,380 --> 00:03:55,080
Ananda Sen: The revised version of.

42
00:03:55,080 --> 00:03:57,990
Ananda Sen: The first.

43
00:03:57,990 --> 00:03:59,790
yeah okay.

44
00:03:59,790 --> 00:04:02,610
Ananda Sen: First.

45
00:04:02,610 --> 00:04:05,610
Ananda Sen: lecture set and the lab.

46
00:04:05,610 --> 00:04:20,310
Ananda Sen: And I there will be every day when we go to the class if there are mistakes we find will make changes at that point and re uploaded so So hopefully we should be able to.

47
00:04:20,310 --> 00:04:24,450
Ananda Sen: grab those If not, there is problem webinar.

48
00:04:24,450 --> 00:04:29,190
Ananda Sen: that's The other thing, and the second, and the last thing is that.

49
00:04:29,190 --> 00:04:33,210
Ananda Sen: And this is.

50
00:04:33,210 --> 00:04:35,550
Ananda Sen: mostly about.

51
00:04:35,550 --> 00:04:42,780
Ananda Sen: about the wacky well we'll talk about that as as time comes, but I think.

52
00:04:42,780 --> 00:04:50,130
Ananda Sen: it's pretty oh um I do want to mention about the homework homework is is uploaded.

53
00:04:50,130 --> 00:04:54,690
Ananda Sen: The ones who are not registered for credit are not.

54
00:04:54,690 --> 00:05:03,210
Ananda Sen: required to do that, but that doesn't mean that you cannot you can certainly do it and submitted, I will I will definitely graded because I the way I.

55
00:05:03,210 --> 00:05:17,610
Ananda Sen: I think of it, this is more like a learning process so So if you want to do that and learn for yourself that will be fine absolutely a problem not too many people in the class anyway so each.

56
00:05:17,610 --> 00:05:21,930
Ananda Sen: Okay alright, so I will.

57
00:05:21,930 --> 00:05:35,220
Ananda Sen: pause for a few minutes and and let you speak about how things went yesterday so yesterday, there were a couple of things which didn't work exactly right.

58
00:05:35,220 --> 00:05:38,130
Ananda Sen: But, but still overall.

59
00:05:38,130 --> 00:05:41,850
Ananda Sen: First of all, let me ask you this question so.

60
00:05:41,850 --> 00:05:48,360
Ananda Sen: Was the speed Okay, or should I can I speed it up a little bit more, I thought I went a little slow but.

61
00:05:48,360 --> 00:05:54,300
Ananda Sen: Did you feel the same as.

62
00:05:54,300 --> 00:06:02,370
Ananda Sen: The material will be a little more involved today onwards, because the logistic regression is.

63
00:06:02,370 --> 00:06:04,140
Ananda Sen: More.

64
00:06:04,140 --> 00:06:10,560
Ananda Sen: conceptual in, although I personally feel that people in medical field in public health.

65
00:06:10,560 --> 00:06:14,400
Ananda Sen: Use logistic regression lot more than linear regression.

66
00:06:14,400 --> 00:06:16,950
Ananda Sen: So just a lot more useful.

67
00:06:16,950 --> 00:06:18,150
Ananda Sen: And we.

68
00:06:18,150 --> 00:06:27,420
Christie Flanagan: felt like this, you could speed it up, if you wanted to a little bit that would be fine and as long as everyone else feels comfortable just asking questions if we have them.

69
00:06:27,420 --> 00:06:34,320
Ananda Sen: Oh yeah please ask questions all the time, in fact, that's one thing i'm definitely going to encourage.

70
00:06:34,320 --> 00:06:37,830
Ananda Sen: anytime just stop me and ask questions.

71
00:06:37,830 --> 00:06:56,340
Ananda Sen: Because I think it's important that you get the material get the idea and we will harp on a few ideas more when we talk about logistic regression and counter aggression and so on and so forth, but, but there are some interesting interesting topic which I don't think.

72
00:06:56,340 --> 00:06:58,740
Ananda Sen: People have much chance to see another.

73
00:06:58,740 --> 00:07:05,970
Ananda Sen: context, so, for example, we'll talk about RC cars, which is very, very useful in the context of.

74
00:07:05,970 --> 00:07:16,800
Ananda Sen: logistic regression and diagnostics and we'll also talk about propensity mentioned, which is neither all applications of logistic regression, but very specific.

75
00:07:16,800 --> 00:07:18,840
Ananda Sen: Public health.

76
00:07:18,840 --> 00:07:24,090
Ananda Sen: slunk so so some some some.

77
00:07:24,090 --> 00:07:29,820
Ananda Sen: Nice topics coming up so yeah.

78
00:07:29,820 --> 00:07:40,770
Geehan Suleyman: You got files for yesterday it's an I click on it it's saying oops nothing is here is that on purpose.

79
00:07:40,770 --> 00:07:42,240
Ananda Sen: Why knows.

80
00:07:42,240 --> 00:07:47,730
Geehan Suleyman: yeah I want to be, I was clicking on some of the materials.

81
00:07:47,730 --> 00:07:48,660
Ananda Sen: yeah yeah.

82
00:07:48,660 --> 00:07:51,120
Ananda Sen: So you went you went to you went to.

83
00:07:51,120 --> 00:07:54,720
Ananda Sen: When you say yesterday.

84
00:07:54,720 --> 00:08:02,100
Ananda Sen: I have, I have uploaded I have uploaded the new files new lab one and day one lecture set.

85
00:08:02,100 --> 00:08:04,200
Ananda Sen: So.

86
00:08:04,200 --> 00:08:08,610
Geehan Suleyman: Why did you upload it because i'm on canvas hiking on.

87
00:08:08,610 --> 00:08:12,990
Ananda Sen: lectures lectures and lectures and labs.

88
00:08:12,990 --> 00:08:16,650
Ananda Sen: If you go to the folder called lectures and labs.

89
00:08:16,650 --> 00:08:21,000
Geehan Suleyman: yep I have the lectures, but i'm talking about the files.

90
00:08:21,000 --> 00:08:23,010
Ananda Sen: Moving the data files.

91
00:08:23,010 --> 00:08:24,870
Geehan Suleyman: The software codes.

92
00:08:24,870 --> 00:08:33,000
Ananda Sen: or software codes, but the software, but also should be there, I mean there is a there is a folder called software code that has all the CSS files.

93
00:08:33,000 --> 00:08:37,560
Geehan Suleyman: Oh yeah i'm clicking on it and it's saying.

94
00:08:37,560 --> 00:08:44,190
Geehan Suleyman: hey to not found.

95
00:08:44,190 --> 00:08:48,510
Christie Flanagan: I got the same error to when I just tried to click on it on the codes yeah.

96
00:08:48,510 --> 00:08:53,430
Ananda Sen: On this on the SAS on this one's correct.

97
00:08:53,430 --> 00:08:57,030
Ananda Sen: i'm.

98
00:08:57,030 --> 00:09:00,060
Ananda Sen: josh.

99
00:09:00,060 --> 00:09:15,390
Ananda Sen: Is it possible for you do, you have access to it, you are you're a post so but that probably in your your your is assigned as a teacher, can you can you access those if you can get yeah go ahead, sorry.

100
00:09:15,390 --> 00:09:20,880
Joshua Bosman: that's fine, I think it has me as assistant, so I have a little more access, did you say you went to files.

101
00:09:20,880 --> 00:09:26,490
Ananda Sen: No software codes, the the other files and files that is a sub folder called software called Africa.

102
00:09:26,490 --> 00:09:32,010
Geehan Suleyman: And it's only day one that's not working so margins and the other one are when I click on those.

103
00:09:32,010 --> 00:09:34,500
Ananda Sen: What about what about day two.

104
00:09:34,500 --> 00:09:45,300
Geehan Suleyman: And I just have day one, so let me look at day to day to.

105
00:09:45,300 --> 00:09:50,160
Geehan Suleyman: yeah even day to actually same thing getting the same message.

106
00:09:50,160 --> 00:10:02,790
Theresa Marie Kowalski-Dobson: And for me on day two I wasn't able to download the files as a PDF it tried to download it as a webpage, although I can open them, so I have them open in different tabs but they're just not downloaded.

107
00:10:02,790 --> 00:10:04,200
Ananda Sen: Okay.

108
00:10:04,200 --> 00:10:08,640
Geehan Suleyman: Either the ones that I can download it's not working.

109
00:10:08,640 --> 00:10:25,200
Ananda Sen: So so josh the person to communicate so so at this point, you guys don't have the second days lecture said, and things like that, then what i'll do is then i'll just send it to you by email, and you.

110
00:10:25,200 --> 00:10:41,730
Christie Flanagan: Yesterday, what I downloaded day to lecture and lab the pdfs for the lecture notes, and I also was able to add to download lab to codes, but I wasn't able to download.

111
00:10:41,730 --> 00:10:45,570
Christie Flanagan: Let me see, is there a data set with that one.

112
00:10:45,570 --> 00:10:47,010
Ananda Sen: There is.

113
00:10:47,010 --> 00:10:49,440
Ananda Sen: I think the same data set actually are using.

114
00:10:49,440 --> 00:11:00,840
Christie Flanagan: Okay, so I was able to yesterday, I was able to download the codes, but today when i'm clicking on it i'm not able to it's getting the same error message Oh, except for.

115
00:11:00,840 --> 00:11:16,200
Christie Flanagan: The for day two if you click on lab to code SAS not day to lab coats so the second one down i'm able to do that and I I entered it through modules and clicked on day two.

116
00:11:16,200 --> 00:11:25,410
Christie Flanagan: But I can't download the The first one is a it looks like a Doc actually not a SAS file, so the SAS file, I was able to download.

117
00:11:25,410 --> 00:11:26,580
Ananda Sen: To do so.

118
00:11:26,580 --> 00:11:34,980
Ananda Sen: So let me.

119
00:11:34,980 --> 00:11:38,460
Joshua Bosman: they're looking for me so far.

120
00:11:38,460 --> 00:11:46,950
Ananda Sen: Pretty accessible to you okay so it's probably it's probably the fact that they're the the student access is somehow broken.

121
00:11:46,950 --> 00:12:03,870
Ananda Sen: This has happened yesterday and and and the ideas person actually worked on it for a while and because I have changed the files, I asked her that specific procedure that if I change the files then we'll have the same problem, and she said no, but apparently it is, do you know Joanna.

122
00:12:03,870 --> 00:12:05,370
Ananda Sen: josh.

123
00:12:05,370 --> 00:12:07,020
Joshua Bosman: I met with her yeah.

124
00:12:07,020 --> 00:12:12,810
Ananda Sen: Okay, so can you I will take care of.

125
00:12:12,810 --> 00:12:24,150
Ananda Sen: but can you send an email to Joanna that the same problem is persisting and in the meantime, what i'm going to do is i'm going to send everybody through email the files for today.

126
00:12:24,150 --> 00:12:26,010
Joshua Bosman: Sure thanks.

127
00:12:26,010 --> 00:12:29,550
Ananda Sen: Thank you.

128
00:12:29,550 --> 00:12:40,350
Ananda Sen: So just bear with me for a couple minutes, let me just send it directly.

129
00:12:40,350 --> 00:12:44,430
Geehan Suleyman: christy for the SAS file is it a PDF or is it.

130
00:12:44,430 --> 00:12:49,230
Ananda Sen: No, no sass file is a specific dot SAS.

131
00:12:49,230 --> 00:12:53,460
Ananda Sen: that's not a PDF that that can only be open in SAS.

132
00:12:53,460 --> 00:13:12,090
Christie Flanagan: yeah I was referring to the SAS file that that I was able to download it when I access to the mcc through modules I clicked on modules on the left hand pane and then it navigates to the different modules for each day and I clicked on the July 13 one.

133
00:13:12,090 --> 00:13:13,800
Geehan Suleyman: yeah that's where I want to.

134
00:13:13,800 --> 00:13:19,020
Christie Flanagan: Okay, so the second one, the lab to codes dot SAS.

135
00:13:19,020 --> 00:13:27,210
Christie Flanagan: Is an underscore codes that when I was able to download but the the Doc before it, I was not.

136
00:13:27,210 --> 00:13:34,170
Geehan Suleyman: So when I click on it and I I say open with it doesn't it doesn't let me open it that's the problem i'm.

137
00:13:34,170 --> 00:13:35,250
Christie Flanagan: Having okay.

138
00:13:35,250 --> 00:13:37,770
Christie Flanagan: So we're having a different problem.

139
00:13:37,770 --> 00:13:39,360
yeah.

140
00:13:39,360 --> 00:13:47,610
Joshua Bosman: When I go to it that way, I can't get to day to lab code are you talking about day to lab codes that do for modules.

141
00:13:47,610 --> 00:13:50,460
Geehan Suleyman: deals not working and SAS I can't download.

142
00:13:50,460 --> 00:13:52,950
Ananda Sen: Even though I can close deals.

143
00:13:52,950 --> 00:13:57,150
Ananda Sen: deals should not work, those are those are state of files.

144
00:13:57,150 --> 00:14:02,640
Joshua Bosman: Okay, yes, as far as working for me, so I like Joanna.

145
00:14:02,640 --> 00:14:19,200
Mehrdad Motamed: Even in my case i'm into some from coast folder I just have loved 12345 cope, and I don't have those they they wanted to go file, I know, but for that is.

146
00:14:19,200 --> 00:14:21,930
Mehrdad Motamed: I can see it here.

147
00:14:21,930 --> 00:14:23,250
Mehrdad Motamed: So another thing.

148
00:14:23,250 --> 00:14:31,500
Ananda Sen: So so did you go under files and check that and because it's all under files and software codes.

149
00:14:31,500 --> 00:14:33,270
Ananda Sen: Yes, it all organized.

150
00:14:33,270 --> 00:14:39,570
Mehrdad Motamed: Right, so you go to files and then I go to software codes and they're just have.

151
00:14:39,570 --> 00:14:45,240
Mehrdad Motamed: lab Manchu five underscore codes there's SAS.

152
00:14:45,240 --> 00:14:48,240
Mehrdad Motamed: SAS close OK.

153
00:14:48,240 --> 00:15:05,040
Ananda Sen: So maybe the student view is different and that's that's where the problem is, and I, I have no clue why that is maybe what i'll do is every day, then I will I mean I will email you all the stuff for that day it's it's.

154
00:15:05,040 --> 00:15:08,850
Ananda Sen: I had no idea that this was going to happen, but well.

155
00:15:08,850 --> 00:15:12,510
Geehan Suleyman: And I share with you my screen just to show you what's happening is that oh.

156
00:15:12,510 --> 00:15:15,390
Ananda Sen: Yes, yes, hang on one second let.

157
00:15:15,390 --> 00:15:19,830
Ananda Sen: me just go there and I will give you.

158
00:15:19,830 --> 00:15:31,050
Ananda Sen: Are mission to share yes.

159
00:15:31,050 --> 00:15:32,910
Geehan Suleyman: Can you see my.

160
00:15:32,910 --> 00:15:39,060
Ananda Sen: No, not yet.

161
00:15:39,060 --> 00:15:42,510
Geehan Suleyman: Okay, so i'm clicking on this right.

162
00:15:42,510 --> 00:15:43,890
Okay.

163
00:15:43,890 --> 00:15:53,040
Geehan Suleyman: And this is what I get I save it on my desktop, but when I open it.

164
00:15:53,040 --> 00:15:56,070
Ananda Sen: Are you opening any insights so i'm in Texas.

165
00:15:56,070 --> 00:15:57,870
Geehan Suleyman: I have to open it from inside fast.

166
00:15:57,870 --> 00:16:01,290
Yes.

167
00:16:01,290 --> 00:16:04,230
Ananda Sen: So you can download it.

168
00:16:04,230 --> 00:16:09,150
Geehan Suleyman: So it's a desktop yes, I just have to open it up.

169
00:16:09,150 --> 00:16:13,860
Ananda Sen: Okay, so when you go to lecture slides what's happening, let me just see.

170
00:16:13,860 --> 00:16:24,870
Geehan Suleyman: These two are okay.

171
00:16:24,870 --> 00:16:28,260
Ananda Sen: Okay So what are the, what are the issues, then, then.

172
00:16:28,260 --> 00:16:31,890
Ananda Sen: The lectures available to.

173
00:16:31,890 --> 00:16:35,220
Marcelo Galafassi: You yeah yeah exactly it's like there is Teresa said.

174
00:16:35,220 --> 00:16:37,140
Marcelo Galafassi: We can't download it.

175
00:16:37,140 --> 00:16:38,670
Marcelo Galafassi: yeah it's not a PDF.

176
00:16:38,670 --> 00:16:44,040
Theresa Marie Kowalski-Dobson: mm hmm So if you press download look at it opens as a Internet link.

177
00:16:44,040 --> 00:16:48,600
Theresa Marie Kowalski-Dobson: like an html file versus a PDF.

178
00:16:48,600 --> 00:16:50,280
Theresa Marie Kowalski-Dobson: And i've tried it.

179
00:16:50,280 --> 00:16:51,660
Theresa Marie Kowalski-Dobson: I tried to download it from like.

180
00:16:51,660 --> 00:16:52,770
Theresa Marie Kowalski-Dobson: This view so like.

181
00:16:52,770 --> 00:16:55,920
Ananda Sen: What about the PowerPoint you don't see the PowerPoint.

182
00:16:55,920 --> 00:17:00,330
Theresa Marie Kowalski-Dobson: How about here is opening oh that's so weird mine is opening as a.

183
00:17:00,330 --> 00:17:08,010
Marcelo Galafassi: Internet file isn't the same as you three.

184
00:17:08,010 --> 00:17:14,010
Geehan Suleyman: That works for me.

185
00:17:14,010 --> 00:17:22,680
Theresa Marie Kowalski-Dobson: it's fine I don't mind i'll use it, and I can follow up after it, I don't need it to start the lecture but.

186
00:17:22,680 --> 00:17:33,360
Ananda Sen: Okay, all right i'm sure there are definitely some problems, so will will will will try to sort this out, and I will.

187
00:17:33,360 --> 00:17:45,240
Ananda Sen: let's get started with the lecture and so does everybody have a copy of the lectures today lectures and labs is there, anybody who doesn't have it.

188
00:17:45,240 --> 00:17:50,520
Ananda Sen: Okay, all right, then i'm not going to send it send anything as far as the.

189
00:17:50,520 --> 00:17:56,970
Ananda Sen: SAS code is concerned i'll come to that one time comes, so okay.

190
00:17:56,970 --> 00:18:28,800
Ananda Sen: Very good, so let me.

191
00:18:28,800 --> 00:18:32,970
Ananda Sen: Alright, let me try with.

192
00:18:32,970 --> 00:18:48,810
Ananda Sen: Try with lab to i'm sorry the D D one i'm labeling an annotated, and this is this the part i'm going to i'm going to send you later.

193
00:18:48,810 --> 00:18:56,820
Ananda Sen: So we I because I went over a bit I will what i'll do is i'll just quickly.

194
00:18:56,820 --> 00:18:59,190
Ananda Sen: start from where I.

195
00:18:59,190 --> 00:19:04,620
Ananda Sen: which I talked about a bit.

196
00:19:04,620 --> 00:19:11,730
Ananda Sen: Which is the Multi core generic so.

197
00:19:11,730 --> 00:19:25,260
Ananda Sen: So we talked about multicore narrative bit and masculinity, as I mentioned before, is something where different X variables are related and you don't want that, basically, you don't want it, because you can have all sorts of.

198
00:19:25,260 --> 00:19:41,130
Ananda Sen: Problems regression coefficients can be in precise change signs and and contradictory conclusions of significance results, I mean they the standard editor so inflated and so on and so forth.

199
00:19:41,130 --> 00:19:51,660
Ananda Sen: So to detect multipolarity there are a few things you can do you can do look at correlations just do a correlation matrix.

200
00:19:51,660 --> 00:20:08,220
Ananda Sen: That a large standard errors for the coefficients a lot of times you see standard, so you can see, in in many cases the confidence interval is huge large and there is a there's an e there's a thing called variance inflation factor.

201
00:20:08,220 --> 00:20:12,240
Ananda Sen: and various inflation factor and not even going to go into the mathematical detail but.

202
00:20:12,240 --> 00:20:22,650
Ananda Sen: But really if you're looking at the variance inflation factor that's a good check for multi coronary it and you should be looking for a threshold of 10.

203
00:20:22,650 --> 00:20:38,490
Ananda Sen: If sometimes people use five five is is also a pretty decent cutoff point at 510 in the in the in that range if you see that, then you know, there is pretty high multipolarity between several variables.

204
00:20:38,490 --> 00:20:45,840
Ananda Sen: are then there is a there is a quantity called eigenvalue, these are all going to be printed on your on your.

205
00:20:45,840 --> 00:20:55,890
Ananda Sen: output and a condition number which typically 30s the threshold between 15 and 30 you could probably say there is something going on there.

206
00:20:55,890 --> 00:21:10,860
Ananda Sen: How can you get rid of coordinating centering is a possibility, and you can do variable selection, which is something i'm going to talk very, very in great detail for logistic regression, but here also I can.

207
00:21:10,860 --> 00:21:17,040
Ananda Sen: give you some idea of what is going on, so, by the way.

208
00:21:17,040 --> 00:21:28,230
Ananda Sen: If you have multi coordinate in the context of linear regression, you should get rid of it first and there's don't try to do this.

209
00:21:28,230 --> 00:21:33,750
Ananda Sen: run the model without with Martha community.

210
00:21:33,750 --> 00:21:49,110
Ananda Sen: We talked about mobile diagnostics and I, as I mentioned, is it's it's true done through residuals you fit the model, there is an observed data observed minus the fitted value is the residual.

211
00:21:49,110 --> 00:22:01,860
Ananda Sen: And residual should have a few checks residuals should look like they come from normal distribution residuals when you plotted against that predictive value there should not be any pattern.

212
00:22:01,860 --> 00:22:12,300
Ananda Sen: residuals against covariance should not show any parent either so residuals should be something like white noise there should not be anything else leftover.

213
00:22:12,300 --> 00:22:16,410
Ananda Sen: that's a good check for that.

214
00:22:16,410 --> 00:22:20,610
Ananda Sen: Those are the two things we talked about yesterday briefly.

215
00:22:20,610 --> 00:22:32,850
Ananda Sen: Variable selection is a slightly different take on this, and this is, of course, this is something where the Community can be also.

216
00:22:32,850 --> 00:22:36,960
Ananda Sen: addressed so what is variable selection.

217
00:22:36,960 --> 00:22:46,920
Ananda Sen: You have plenty of variables, you want to build a predictive model or a risk prediction that have 20 variables variables in the in the model.

218
00:22:46,920 --> 00:22:56,130
Ananda Sen: Which is, which are the better ones, which are the ones we should keep in the more mitochondria is where the problem that's why you don't want to keep all variables in the model.

219
00:22:56,130 --> 00:23:11,580
Ananda Sen: At the most predictive variable is is the one you want to keep their it's also called parsimony you don't want to have a model with 500 observations and hundred variables hundred covariance.

220
00:23:11,580 --> 00:23:13,320
Ananda Sen: So.

221
00:23:13,320 --> 00:23:21,210
Ananda Sen: How do you how do you achieve that, how do you achieve a variable selection or how do you choose the best variables.

222
00:23:21,210 --> 00:23:32,640
Ananda Sen: In principle, this is, this is what you do well, there are three different methods for selection backward selection stepwise i'll briefly mentioned what this means.

223
00:23:32,640 --> 00:23:38,340
Ananda Sen: Forward selection you start with the actually and Cindy.

224
00:23:38,340 --> 00:23:50,490
Ananda Sen: I will, I will mention stepwise but a stepwise is a combination of foreign backward that and so that's that's the best way of doing suppose we have be predicted variables okay.

225
00:23:50,490 --> 00:23:53,400
Ananda Sen: You start by doing.

226
00:23:53,400 --> 00:24:03,900
Ananda Sen: Simple linear regression with one variable each variable so if there are 50 X variables in a 50 regression models you fit.

227
00:24:03,900 --> 00:24:05,580
Okay.

228
00:24:05,580 --> 00:24:08,850
Ananda Sen: Then, whichever is the minimum.

229
00:24:08,850 --> 00:24:17,730
Ananda Sen: P value, which means most significant just keep that in the model so now what happened, what happened was that.

230
00:24:17,730 --> 00:24:22,440
Ananda Sen: You have a very you have a simple linear regression model which is your best market.

231
00:24:22,440 --> 00:24:37,650
Ananda Sen: Now, are you going to check the p value against something, yes, there is a threshold which you use typically something like 20% or 25% something like that it's it's not it's not a 5% be that usually make it lot more conservative.

232
00:24:37,650 --> 00:24:39,780
Ananda Sen: So.

233
00:24:39,780 --> 00:24:43,680
Ananda Sen: put that in the model, the one with the minimum P better.

234
00:24:43,680 --> 00:24:46,680
Ananda Sen: Then, keeping that in the model.

235
00:24:46,680 --> 00:24:49,380
Ananda Sen: Add on other variables.

236
00:24:49,380 --> 00:24:54,600
Ananda Sen: and see if the.

237
00:24:54,600 --> 00:25:03,990
Ananda Sen: entry of another variable is significant again using the threshold be bad.

238
00:25:03,990 --> 00:25:12,690
Ananda Sen: So essentially what you do is that every step you bring in another another variable.

239
00:25:12,690 --> 00:25:22,920
Ananda Sen: and bringing that variable and in presence of the other variable in presence of the first variable if the second variable adds additional things.

240
00:25:22,920 --> 00:25:41,010
Ananda Sen: Which means P value is significant at that given threshold, then you add that in otherwise, if you go through all the variables and you do not find another one where the second variable makes it more significant then that's it your best model is that single variable more.

241
00:25:41,010 --> 00:25:48,570
Ananda Sen: Now suppose you have added a second model, you are, you are you're able to add a second variable.

242
00:25:48,570 --> 00:25:50,400
Ananda Sen: Then.

243
00:25:50,400 --> 00:26:11,850
Ananda Sen: Go to the three variable classes that's how you keep on doing that at each step once you have added these things in you also do a check to make sure that the previous variables, you have entered whether they now become insignificant or not.

244
00:26:11,850 --> 00:26:25,620
Ananda Sen: And then, if they are insignificant, and you can drop it, so it is possible in stepwise selection that a variable you have put in previously can be removed in a in a in a subsequent step.

245
00:26:25,620 --> 00:26:30,660
Ananda Sen: So, once you have gone through this back and forth several times.

246
00:26:30,660 --> 00:26:37,770
Ananda Sen: Ultimately, end up with a model which is your best model, and in that model, everything is significant.

247
00:26:37,770 --> 00:26:40,260
Right.

248
00:26:40,260 --> 00:27:00,960
Ananda Sen: Now, obviously, as you can see, this is, this is a tenable that's to perform manually, so this is done in automated way all software is actually do that and we will go through the example but, but at least that's roughly the idea.

249
00:27:00,960 --> 00:27:17,490
Ananda Sen: it's a combination of the two methods called forward selection and backward elimination in forward selection you never drop anything which you have selected in backward elimination you never add anything which you previously threw away.

250
00:27:17,490 --> 00:27:20,310
Ananda Sen: But stepwise selection, you can do both.

251
00:27:20,310 --> 00:27:22,950
Ananda Sen: that's a difference, really.

252
00:27:22,950 --> 00:27:41,490
Ananda Sen: Okay, the program stops at the stage when either all the variables have entered the model or all variables in the model have P values to remove less than PR and all variables not into that the model of P values to enter exceed that's bs before entry PR.

253
00:27:41,490 --> 00:27:41,820
Mehrdad Motamed: Is.

254
00:27:41,820 --> 00:27:45,300
Mehrdad Motamed: P value for remember.

255
00:27:45,300 --> 00:27:53,190
Ananda Sen: As I said, it's not 5% which is used for association test, this is more stringent.

256
00:27:53,190 --> 00:28:02,580
Ananda Sen: less stringent i'm sorry more conservative and this is 20% of 35% it's typically that range pretty high up.

257
00:28:02,580 --> 00:28:09,960
Ananda Sen: There are some other criteria are square a cake information mellow CP, these are all different choices.

258
00:28:09,960 --> 00:28:16,680
Ananda Sen: Are square is explained variation how much more variation you explained by adding things.

259
00:28:16,680 --> 00:28:27,150
Ananda Sen: Information criterion is a compromise between how many variables are in the model and what's the sample size it's based on something called likelihood.

260
00:28:27,150 --> 00:28:39,120
Ananda Sen: mellows CP is similar to EIC, but it is really based on the prediction remember the residuals we talked about, there is a predictive value, there is a.

261
00:28:39,120 --> 00:28:47,040
Ananda Sen: observed value, so how good is a prediction that's that's kind of what mellow CPC so so then all these different criteria.

262
00:28:47,040 --> 00:28:48,840
Ananda Sen: And you.

263
00:28:48,840 --> 00:29:07,770
Ananda Sen: use and and the thing about the different criteria is that the different criteria and do not necessarily end up with the same model and that's frequently true with these things you may end up with alternative competing models, maybe three or four models which could equally.

264
00:29:07,770 --> 00:29:17,130
Ananda Sen: do the job, what do you do, then say a four models, with four different criteria for best models.

265
00:29:17,130 --> 00:29:28,590
Ananda Sen: And then I think the clinical judgment comes in and and the judgment about which variables are better to are easier to collect.

266
00:29:28,590 --> 00:29:37,140
Ananda Sen: Right, these are all over it so so you're you're collecting data, so there may be something which is a blood based measure it's easy easy.

267
00:29:37,140 --> 00:29:49,800
Ananda Sen: thing to collect when there are labs done there may be another genetic information which is a harder one in the sense that it's more expensive, so if you have to choose.

268
00:29:49,800 --> 00:29:56,340
Ananda Sen: Where one model contains a genetic information gimmick marker and the other one involves involves that.

269
00:29:56,340 --> 00:30:04,710
Ananda Sen: Blood based marker and their performances are very, very similar and you go for the next month just which is easier easier one to.

270
00:30:04,710 --> 00:30:17,970
Ananda Sen: handle so that said that kind of judgment comes in, when you come up with different strengths and different models based on different protein that makes sense.

271
00:30:17,970 --> 00:30:20,910
Ananda Sen: So.

272
00:30:20,910 --> 00:30:31,830
Ananda Sen: What i'm going to do is to quickly switch to the lab.

273
00:30:31,830 --> 00:30:43,470
Ananda Sen: and show.

274
00:30:43,470 --> 00:30:47,910
Ananda Sen: So here is the here's the multicore nearly one.

275
00:30:47,910 --> 00:30:54,570
Ananda Sen: And if they have made some changes to this compared to what I had yesterday.

276
00:30:54,570 --> 00:31:07,140
Ananda Sen: So this is a model where age height smoke black other remember this is aggression in progress, you have to you cannot use class statement, so you have to actually use indicators.

277
00:31:07,140 --> 00:31:17,520
Ananda Sen: Black other lwt MTV and I have used those options so anything which comes after slash is an option calling and via yes.

278
00:31:17,520 --> 00:31:30,120
Ananda Sen: So it comes up with two different tables, one of the tables will have the variance inflation at the VI E, F, but it scan through this and, most of them are almost all of them are.

279
00:31:30,120 --> 00:31:40,470
Ananda Sen: Just at that above one so there's really no VI E, F even bigger than 1.5 so you say that this is the name have to worry about.

280
00:31:40,470 --> 00:31:46,680
Ananda Sen: Quality in this case, there are some other criteria so see as I was talking with eigenvalue.

281
00:31:46,680 --> 00:31:52,920
Ananda Sen: And condition index the condition index, the only condition decks that are even worth mentioning is the last one.

282
00:31:52,920 --> 00:32:10,200
Ananda Sen: Is 16.40666 the one before that is 10.9019 usually, when you see something like this, then you scan through that role and look at the proportion of variation columns and seeing that or anything which is about Point five.

283
00:32:10,200 --> 00:32:31,710
Ananda Sen: And you see that in both cases in both the 10.90919 and 16.40666 in both of those cases, the two variables which which are showing a little high proportion of variation exploded at age and lwt.

284
00:32:31,710 --> 00:32:54,870
Ananda Sen: So I just went ahead and looked at the correlation of Asian lwt came out to be about 18% which is higher than any other correlations there, but still not nothing to be alarmed about so so I was not really worried about it, I just thought I would just use it in as an example.

285
00:32:54,870 --> 00:33:05,490
Ananda Sen: So that was one I showed you the residual one yesterday I just sure show you one more time just because I was not sure whether.

286
00:33:05,490 --> 00:33:13,710
Ananda Sen: I showed it before before five o'clock some of you may have left, so the.

287
00:33:13,710 --> 00:33:22,710
Ananda Sen: The program the cord for residuals is there are many ways of doing this in proper any you can do this also.

288
00:33:22,710 --> 00:33:46,020
Ananda Sen: But this prob glm the one this particular quarter life because it does everything at one stroke so again, you wrap it in a rapper rapper is on the audience the audience graphics on and on these graphics off and in the prop glm the model statement is standard.

289
00:33:46,020 --> 00:33:56,040
Ananda Sen: But you add plots the plot statement and in the plots if you specify diagnostics and residuals ignores what blocks to.

290
00:33:56,040 --> 00:34:11,460
Ananda Sen: plot and then is output statement anytime you see in SAS and output statement you can actually throw in specific variables in those output data set so output data set is called.

291
00:34:11,460 --> 00:34:23,970
Ananda Sen: called out and and there are the in the output, you can have both out and and residuals there they're both they're in that the data set.

292
00:34:23,970 --> 00:34:35,220
Ananda Sen: So if you'll run this first of all our square is not that great it's only 18% 17 18% so it's only mildly associated.

293
00:34:35,220 --> 00:34:39,060
Ananda Sen: Then there is a diagnostic block.

294
00:34:39,060 --> 00:34:47,580
Ananda Sen: The diagnostic blog basically shows that, and you should really all you need to do is to look at.

295
00:34:47,580 --> 00:35:05,070
Ananda Sen: The left hand column in this the three columns the three graphs are good, now the predicted versus residual does not show any pattern quantity versus quantity plots of residual shows a pretty linear normal plot.

296
00:35:05,070 --> 00:35:11,610
Ananda Sen: And then the histogram also shows a reasonably normal block.

297
00:35:11,610 --> 00:35:17,580
Ananda Sen: For the residuals now.

298
00:35:17,580 --> 00:35:20,970
Ananda Sen: One thing I want to point out is that.

299
00:35:20,970 --> 00:35:37,950
Ananda Sen: This is a this is this is indicative of no additional problems, whatever you have in the model that above outside that you don't have any leftover pattern, however, that doesn't mean it's a good fit.

300
00:35:37,950 --> 00:35:41,940
Ananda Sen: See look at that are squares only 18%.

301
00:35:41,940 --> 00:35:54,720
Ananda Sen: So good fit and no residual pattern does not necessarily say the same thing you could have no residual pattern, yet the fit may be poor.

302
00:35:54,720 --> 00:36:09,540
Ananda Sen: And this is an indication of that so just something something to remember that all these different criteria of diagnostics, some of them are geared towards.

303
00:36:09,540 --> 00:36:12,630
Ananda Sen: satisfying the model assumption.

304
00:36:12,630 --> 00:36:24,960
Ananda Sen: But the others are more geared towards how good the fit is an R squared is more about fit and residual is more about model assumption so Those are the things you have to remember.

305
00:36:24,960 --> 00:36:29,130
Ananda Sen: That they they do different things actually.

306
00:36:29,130 --> 00:36:34,020
Ananda Sen: um I also do variable selection here.

307
00:36:34,020 --> 00:36:46,320
Ananda Sen: which you only get it's very easy in progress, just use the word selection equal to stepwise and see those those two last.

308
00:36:46,320 --> 00:37:02,100
Ananda Sen: Things the SL entry point 0.25 and SL stage 0.1 so that's an entry is the p value for entry so anything less than point two, five, you will enter in the model anything which is.

309
00:37:02,100 --> 00:37:13,170
Ananda Sen: Beyond point one if if SL stage 0.1 then basically if your P value for.

310
00:37:13,170 --> 00:37:26,010
Ananda Sen: For that, for the variable is is more than 3.1, then you can throw this away, otherwise you keep it in the morn so that's that's kind of idea if you go through this then.

311
00:37:26,010 --> 00:37:39,600
Ananda Sen: that's the model we ended up with ui hd lwt black smoke another so that's that's the model and you notice that the one switch got dropped off our F wt btl.

312
00:37:39,600 --> 00:37:47,460
Ananda Sen: Those are the two variables we've got dropped off and look, if you look at the p value you'll notice that all the values are significant.

313
00:37:47,460 --> 00:37:56,130
Ananda Sen: And it shows you a few model are squares and so on and so, for the last model that number six which basically has all six of them.

314
00:37:56,130 --> 00:38:07,830
Ananda Sen: So the way you should you should think about it is the first model is ui and the second model is ui plus hd the third one, is the way plus https lwt so you successively enter things.

315
00:38:07,830 --> 00:38:24,870
Ananda Sen: Last model R square is the highest and and CP value should be law, so the last CP value is the minimum one here CP is how close your prediction is to the to the actual observed.

316
00:38:24,870 --> 00:38:29,400
Ananda Sen: So, so that was a variable selection.

317
00:38:29,400 --> 00:38:49,200
Ananda Sen: Any question about this.

318
00:38:49,200 --> 00:38:54,930
Ananda Sen: So one last thing I want to do here.

319
00:38:54,930 --> 00:39:03,300
Ananda Sen: I will not, I will skip over all of these discussions about general generalizing and model, because we will be doing this anyway later.

320
00:39:03,300 --> 00:39:08,760
Ananda Sen: But I do want to point out that there are.

321
00:39:08,760 --> 00:39:19,620
Ananda Sen: One of the main things in all these models is to test for association test for the betas and.

322
00:39:19,620 --> 00:39:25,470
Ananda Sen: We typically end up doing a test for a specific.

323
00:39:25,470 --> 00:39:27,120
Ananda Sen: parameter.

324
00:39:27,120 --> 00:39:34,500
Ananda Sen: And there are three types of tests, one is called wall, the other one is score score, the third one is called likelihood ratio we're not going to.

325
00:39:34,500 --> 00:39:51,030
Ananda Sen: describe the score test at all likelihood ratio test is easy to describe which we will, and in all of these, we will get both all these programs will get both walters and likelihood test.

326
00:39:51,030 --> 00:39:53,670
Ananda Sen: Both of those.

327
00:39:53,670 --> 00:40:11,310
Ananda Sen: So let me explain this to an example which I have on the lab one, so let me go back to the lab so let's see.

328
00:40:11,310 --> 00:40:17,250
Ananda Sen: Okay So how do we do this.

329
00:40:17,250 --> 00:40:23,820
Ananda Sen: First of all, I want to do a simple test simple model.

330
00:40:23,820 --> 00:40:35,190
Ananda Sen: Where I want to know whether there is an overall race effect as far as birth weight is concerned, I also want to test separately.

331
00:40:35,190 --> 00:40:41,370
Ananda Sen: Whether there is a difference between black versus other So how do I do that in Prague glm.

332
00:40:41,370 --> 00:40:49,890
Ananda Sen: So the model part is by now you're familiar with the model statement there's an additional statement which we use.

333
00:40:49,890 --> 00:40:52,650
Ananda Sen: To just called estimate.

334
00:40:52,650 --> 00:41:00,780
Ananda Sen: there's also a statement called contrast which does similar thing but estimate is is it is slightly easier to play with.

335
00:41:00,780 --> 00:41:08,040
Ananda Sen: That black versus other within codes is a label for the test.

336
00:41:08,040 --> 00:41:19,050
Ananda Sen: If you look at the very last piece of the of the results you'd see that that appears that black versus other the word, the phrase appears right and a parameter.

337
00:41:19,050 --> 00:41:35,340
Ananda Sen: So so that's that's the black versus other parameter ization, then there is an estimate that estimate actually matches the value, corresponding to race to in the main table.

338
00:41:35,340 --> 00:41:44,010
Ananda Sen: Because what is that estimate that estimate is the difference that beta parameters that difference in average birthweight.

339
00:41:44,010 --> 00:42:02,640
Ananda Sen: Between race to race three, which is exactly black versus other so that's what you see there minus 84.3226177 so that's the difference in average birth weight of babies born to a black mother versus other mother.

340
00:42:02,640 --> 00:42:05,130
Ananda Sen: Other category.

341
00:42:05,130 --> 00:42:12,240
Ananda Sen: Okay, and then the p value of courses is 0.6099 which is not significant but.

342
00:42:12,240 --> 00:42:32,010
Ananda Sen: But but, but the real thing to understand here that last piece is generated using the estimate statement Okay, so you can also generate a similar statement for race one and race two so white versus black.

343
00:42:32,010 --> 00:42:44,580
Ananda Sen: That is not obtainable from the overall table the table which you just see above this see here the 290 9.72 is a difference between white and other.

344
00:42:44,580 --> 00:43:06,930
Ananda Sen: The minus 84 is black versus other So if I wanted a white versus black, then what I have to do is to I can do that here itself estimate white versus other but for race, what would I do, how would I, how would I specified it, let me, let me ask that question.

345
00:43:06,930 --> 00:43:15,090
Ananda Sen: suppose I wanted white versus black here.

346
00:43:15,090 --> 00:43:21,990
Ananda Sen: And I want to do this.

347
00:43:21,990 --> 00:43:29,550
Theresa Marie Kowalski-Dobson: Would you create dummy variables of white and black and then run it in the model.

348
00:43:29,550 --> 00:43:31,500
Ananda Sen: The dummy variable for white and black.

349
00:43:31,500 --> 00:43:41,760
Ananda Sen: have already created have been created by the class statement, but I just want to make that.

350
00:43:41,760 --> 00:43:55,500
Ananda Sen: Make that comparison so very similar to the black versus other So the question is, how would I do that so everything in the estimate statement you see there.

351
00:43:55,500 --> 00:44:02,700
Ananda Sen: Everything would be same, I will come up to race, but then you have specified in a certain way.

352
00:44:02,700 --> 00:44:11,220
Ananda Sen: How would they specify again white is one and black is to that is not obtainable from the main table.

353
00:44:11,220 --> 00:44:19,470
So how do you do that.

354
00:44:19,470 --> 00:44:24,990
Ananda Sen: That specific formulation does it does it tell you.

355
00:44:24,990 --> 00:44:37,890
Ananda Sen: it's it's it's a little bit puzzling what what do the 01 minus one, what does it mean, but if you understand that puzzle then then that's something you can imitate to get white versus black.

356
00:44:37,890 --> 00:44:44,760
Yoonhee Ryder: So do you set either white or black is zero and then compare.

357
00:44:44,760 --> 00:44:47,880
Yoonhee Ryder: Like instead of having other zero.

358
00:44:47,880 --> 00:44:48,660
Yoonhee Ryder: Why.

359
00:44:48,660 --> 00:44:50,190
Ananda Sen: You want a negative one.

360
00:44:50,190 --> 00:44:52,260
Ananda Sen: Ah right so.

361
00:44:52,260 --> 00:44:56,160
Yoonhee Ryder: So that.

362
00:44:56,160 --> 00:45:01,710
Ananda Sen: are equal to minus one and one that doesn't matter but, but the last one would be zero.

363
00:45:01,710 --> 00:45:07,320
Ananda Sen: So now, you see the bag, what is the pattern well, there are three races.

364
00:45:07,320 --> 00:45:13,320
Ananda Sen: And I want to what am I what am I actually.

365
00:45:13,320 --> 00:45:19,380
Ananda Sen: Actually, testing and testing whether you know.

366
00:45:19,380 --> 00:45:33,390
Ananda Sen: The beta parameters are different so so let's let's write the equation down so here the equation is something like be w T equal to beta not.

367
00:45:33,390 --> 00:45:35,850
Ananda Sen: Plus.

368
00:45:35,850 --> 00:45:39,720
Ananda Sen: beta one.

369
00:45:39,720 --> 00:45:45,360
Ananda Sen: Why.

370
00:45:45,360 --> 00:45:51,060
let's read it to black.

371
00:45:51,060 --> 00:45:55,860
expected value to average okay.

372
00:45:55,860 --> 00:46:05,370
Ananda Sen: So when I wanted other I was going to try beta two minus beta not.

373
00:46:05,370 --> 00:46:08,340
Ananda Sen: right because beta two is for black.

374
00:46:08,340 --> 00:46:10,050
Ananda Sen: or actually sorry.

375
00:46:10,050 --> 00:46:12,600
Ananda Sen: Black versus is just beta two.

376
00:46:12,600 --> 00:46:17,430
Ananda Sen: Okay, and and white versus black is beta one minus beta.

377
00:46:17,430 --> 00:46:33,660
Ananda Sen: This is the model, but when you are actually doing it, the way you should think about it is those three races are three different entities and how do I check how do I check one minus the other.

378
00:46:33,660 --> 00:46:45,570
Ananda Sen: You put one for one of them and negative one for the other ones, the ones, he wanted chip, and the other one has to be seen, you do not forget to put a zero for the one you are not check.

379
00:46:45,570 --> 00:46:58,890
Ananda Sen: So that's the statement which will allow you to do a white versus black something you should try yourself just going that procedure in the in the.

380
00:46:58,890 --> 00:47:05,790
Ananda Sen: In the code and add that estimate statement right next to the.

381
00:47:05,790 --> 00:47:09,480
Ananda Sen: The previous statement.

382
00:47:09,480 --> 00:47:16,620
Ananda Sen: and see what you get.

383
00:47:16,620 --> 00:47:19,740
Okay.

384
00:47:19,740 --> 00:47:26,670
Ananda Sen: Any question on this.

385
00:47:26,670 --> 00:47:34,470
Ananda Sen: This is Neil, this is different, this is a this is, and this is not immediate, you have to do a little bit more.

386
00:47:34,470 --> 00:47:48,270
Ananda Sen: than just running the model statement.

387
00:47:48,270 --> 00:47:54,480
Ananda Sen: Testing in in glm arm is typically.

388
00:47:54,480 --> 00:48:08,310
Ananda Sen: Setting up the coefficients you're trying to test setting up the coefficients are the parameters you're trying to test.

389
00:48:08,310 --> 00:48:21,000
Ananda Sen: Similarly, if I wanted to test white versus other than I would have one zero minus one.

390
00:48:21,000 --> 00:48:24,600
Ananda Sen: So it makes sense.

391
00:48:24,600 --> 00:48:33,090
alright.

392
00:48:33,090 --> 00:48:43,110
Ananda Sen: So what you get here is actually what is called a waltz waltz test you and also get likelihood ratio test.

393
00:48:43,110 --> 00:48:47,820
Ananda Sen: likelihood ratio tests are typically.

394
00:48:47,820 --> 00:48:53,520
Ananda Sen: done best in a different procedure called proc gen mode.

395
00:48:53,520 --> 00:49:02,580
Ananda Sen: prob gen mode is something we're going to use a lot in proper logistics, but you can also do it in the case of linear regression.

396
00:49:02,580 --> 00:49:14,160
Ananda Sen: And prob gen mode is essentially doing generalized linear model in SAS were all types of generalizing and models are are done.

397
00:49:14,160 --> 00:49:24,150
Ananda Sen: How do you how do you specify which one you're looking for logistic or normal distribution you specify something on distribution, you could have normal, which is what I did.

398
00:49:24,150 --> 00:49:53,610
Ananda Sen: So Prague gen mode class those statements, the same model statement is also the same except we don't use any solution, it will automatically give you the solution, and you said distribute equal to normal distribution equal to normal, so this basically specify.

399
00:49:53,610 --> 00:49:57,480
Ananda Sen: And the type three I.

400
00:49:57,480 --> 00:50:06,000
Ananda Sen: Market in red because type three is what you need for likelihood ratio test, so he comes up with.

401
00:50:06,000 --> 00:50:16,560
Ananda Sen: With this now, what is the likelihood ratio test like your ratio test is actually quite.

402
00:50:16,560 --> 00:50:26,760
Ananda Sen: quite easy so basically when I say that we want to do an overall race effect, what does it mean let's go back to the previous.

403
00:50:26,760 --> 00:50:33,690
Ananda Sen: Okay, let me just write it down one more time So what is it what does it mean to say overall race effect again.

404
00:50:33,690 --> 00:50:38,190
Ananda Sen: He have bw T.

405
00:50:38,190 --> 00:50:43,290
Ananda Sen: beta not plus beta one white.

406
00:50:43,290 --> 00:50:46,260
loss leader to black.

407
00:50:46,260 --> 00:50:55,320
Ananda Sen: And then, that is, the other, but the other is really better not so when I when I see.

408
00:50:55,320 --> 00:51:22,740
Ananda Sen: That.

409
00:51:22,740 --> 00:51:29,250
Ananda Sen: What is the race effect is zero what does it mean.

410
00:51:29,250 --> 00:51:40,350
Ananda Sen: What is the null hypothesis testing.

411
00:51:40,350 --> 00:51:43,800
Christie Flanagan: Be that there's no effect if you're saying it's zero.

412
00:51:43,800 --> 00:51:45,930
Ananda Sen: yeah there is no race effect.

413
00:51:45,930 --> 00:51:50,280
Ananda Sen: Which means what which means there is no difference in the races.

414
00:51:50,280 --> 00:51:58,380
Ananda Sen: So what would like what is my age, not what is my now hypothesis.

415
00:51:58,380 --> 00:52:01,650
Marcelo Galafassi: they're all equal.

416
00:52:01,650 --> 00:52:12,120
Ananda Sen: All three are equal, so if I if I wanted to write it in terms of beta as what would I write, how will I read it.

417
00:52:12,120 --> 00:52:17,610
Ananda Sen: This brings us to actually the interpretation of beta so if you're going.

418
00:52:17,610 --> 00:52:23,190
Yoonhee Ryder: Oh, is it beta zero equals beta one equals beta two or no.

419
00:52:23,190 --> 00:52:29,100
Ananda Sen: So what is beta one.

420
00:52:29,100 --> 00:52:32,460
Like slope or I guess.

421
00:52:32,460 --> 00:52:41,130
Ananda Sen: Well, there is it's not continuous so it's it's a race right so it's it's so if white if if the if the model is way too, then.

422
00:52:41,130 --> 00:52:44,190
Ananda Sen: beta one so white would be one.

423
00:52:44,190 --> 00:52:48,810
Ananda Sen: Black would be zero so you will get better not plus beta one right.

424
00:52:48,810 --> 00:53:02,880
Ananda Sen: And if the mother is other than both white and black would be zero, then it would get better or not, so what will be the one be.

425
00:53:02,880 --> 00:53:05,070
Ananda Sen: How would you interpret that.

426
00:53:05,070 --> 00:53:15,090
Ananda Sen: So for black it's been an a plus beta one for other it's better not so what is beta not what is better one.

427
00:53:15,090 --> 00:53:23,490
Ananda Sen: So this is what I was talking about last time, so the beta one is the difference between.

428
00:53:23,490 --> 00:53:28,830
Ananda Sen: black and the reference references other.

429
00:53:28,830 --> 00:53:32,400
Ananda Sen: that's so clear.

430
00:53:32,400 --> 00:53:35,850
Ananda Sen: it's not the race.

431
00:53:35,850 --> 00:53:40,920
Ananda Sen: barometer it's the difference between.

432
00:53:40,920 --> 00:53:43,410
Ananda Sen: black and the.

433
00:53:43,410 --> 00:53:57,840
Ananda Sen: And the reference category beta two is a difference between why sorry beta one is the difference between white and white and the difference category beta tool is the difference between black and the difference category.

434
00:53:57,840 --> 00:54:00,330
Ananda Sen: So now.

435
00:54:00,330 --> 00:54:02,130
Ananda Sen: You told you that.

436
00:54:02,130 --> 00:54:09,060
Ananda Sen: Now I want to know that there is no overall difference in the race, how do you set it up.

437
00:54:09,060 --> 00:54:54,030
Ananda Sen: What is good, what are you going to test.

438
00:54:54,030 --> 00:55:09,900
Ananda Sen: beta one equals zero means there is no difference between white and other beta two equals zero means there is no difference between black and the other, the other is beta not so everybody should be better not.

439
00:55:09,900 --> 00:55:22,080
Ananda Sen: So norris effect means, but I want to go to beat it that's it.

440
00:55:22,080 --> 00:55:25,650
Ananda Sen: Exactly.

441
00:55:25,650 --> 00:55:46,170
Ananda Sen: We are going to look at this more and more in logistic regression, we want to make sure that you understand this year.

442
00:55:46,170 --> 00:55:58,650
Ananda Sen: it's important to realize that when we write out the equation, with the baseline reference all the parameters, other than the intercept indicate differences.

443
00:55:58,650 --> 00:56:10,740
Ananda Sen: With the baseline.

444
00:56:10,740 --> 00:56:12,450
Ananda Sen: Okay.

445
00:56:12,450 --> 00:56:19,920
Ananda Sen: So does anybody want me to explain this one small.

446
00:56:19,920 --> 00:56:22,740
Ananda Sen: Are you Okay, with the interpretation.

447
00:56:22,740 --> 00:56:24,990
Theresa Marie Kowalski-Dobson: You could explain it one more time for me that would be.

448
00:56:24,990 --> 00:56:27,090
Ananda Sen: helpful all right.

449
00:56:27,090 --> 00:56:28,740
Ananda Sen: All right, no problem.

450
00:56:28,740 --> 00:56:31,680
Ananda Sen: Sure yeah yeah just let me.

451
00:56:31,680 --> 00:56:33,690
know.

452
00:56:33,690 --> 00:56:39,060
Ananda Sen: Okay sure, so do you understand the way a lot of the equation.

453
00:56:39,060 --> 00:56:39,810
Theresa Marie Kowalski-Dobson: mm hmm.

454
00:56:39,810 --> 00:56:43,350
Ananda Sen: yeah and then let us try to understand what does.

455
00:56:43,350 --> 00:56:45,570
Ananda Sen: beta one beta two and beta not.

456
00:56:45,570 --> 00:56:49,560
Ananda Sen: Remember, this is something we did for those Japanese and.

457
00:56:49,560 --> 00:56:55,770
Ananda Sen: American and European cars, so if I had to write this.

458
00:56:55,770 --> 00:57:05,040
Ananda Sen: Let me just do this is this is this is, this is the reason I like.

459
00:57:05,040 --> 00:57:08,880
Ananda Sen: These.

460
00:57:08,880 --> 00:57:14,280
Go.

461
00:57:14,280 --> 00:57:18,870
Ananda Sen: Ahead ah, there you go.

462
00:57:18,870 --> 00:57:32,610
Ananda Sen: So.

463
00:57:32,610 --> 00:57:41,790
Ananda Sen: What are these things, these are the indicators right so white means one if mother is white.

464
00:57:41,790 --> 00:57:48,330
Ananda Sen: Zero otherwise.

465
00:57:48,330 --> 00:57:57,000
Ananda Sen: Black is one if mother black.

466
00:57:57,000 --> 00:57:58,710
zero.

467
00:57:58,710 --> 00:58:03,780
Otherwise.

468
00:58:03,780 --> 00:58:09,720
Ananda Sen: Okay, so when.

469
00:58:09,720 --> 00:58:13,140
Ananda Sen: mother is.

470
00:58:13,140 --> 00:58:15,090
Ananda Sen: white.

471
00:58:15,090 --> 00:58:21,750
Ananda Sen: What is the equation.

472
00:58:21,750 --> 00:58:30,660
Ananda Sen: Are you with me on that.

473
00:58:30,660 --> 00:58:34,620
Ananda Sen: When mother black.

474
00:58:34,620 --> 00:58:40,050
Ananda Sen: equation looks like.

475
00:58:40,050 --> 00:58:44,250
Ananda Sen: Because there is, there is no beta beta one this one.

476
00:58:44,250 --> 00:58:55,830
Ananda Sen: When.

477
00:58:55,830 --> 00:58:57,630
Ananda Sen: bought.

478
00:58:57,630 --> 00:59:07,440
Ananda Sen: White and black or equal to zero.

479
00:59:07,440 --> 00:59:11,100
Ananda Sen: yeah.

480
00:59:11,100 --> 00:59:13,500
Ananda Sen: So beta one.

481
00:59:13,500 --> 00:59:19,110
Ananda Sen: average difference.

482
00:59:19,110 --> 00:59:22,590
Between.

483
00:59:22,590 --> 00:59:26,910
Ananda Sen: White and other.

484
00:59:26,910 --> 00:59:32,850
Ananda Sen: beta to average difference between black.

485
00:59:32,850 --> 00:59:35,940
Ananda Sen: And under.

486
00:59:35,940 --> 00:59:38,250
Ananda Sen: beta zero.

487
00:59:38,250 --> 00:59:45,030
Ananda Sen: Average be w T in other.

488
00:59:45,030 --> 00:59:47,790
Ananda Sen: Do you understand this formulation.

489
00:59:47,790 --> 00:59:57,840
Ananda Sen: This is, this is, this is the breakup of the whole mom and your mom right.

490
00:59:57,840 --> 00:59:59,790
Ananda Sen: Now.

491
00:59:59,790 --> 01:00:07,290
Ananda Sen: And my question is how do we say that there is no race difference.

492
01:00:07,290 --> 01:00:14,460
Ananda Sen: Which means the two differences I seen these two have to be zero.

493
01:00:14,460 --> 01:00:35,940
Ananda Sen: Which means all of them have to equal to be they're not basically better not whatever bit and i'm not i'm not saying that there is no race effect i'm just saying that the race effect is the same across all races that's what we test.

494
01:00:35,940 --> 01:00:38,790
Ananda Sen: So.

495
01:00:38,790 --> 01:00:43,830
Ananda Sen: No race effect.

496
01:00:43,830 --> 01:00:55,890
Ananda Sen: translates to.

497
01:00:55,890 --> 01:01:02,580
The.

498
01:01:02,580 --> 01:01:10,560
All right.

499
01:01:10,560 --> 01:01:13,050
Ananda Sen: anybody else.

500
01:01:13,050 --> 01:01:18,120
Ananda Sen: One more clarification.

501
01:01:18,120 --> 01:01:23,670
Ananda Sen: See, this is the crucial part what you are testing.

502
01:01:23,670 --> 01:01:31,980
Ananda Sen: What you're doing here is more mechanical I mean that's a specific SAS way of doing things.

503
01:01:31,980 --> 01:01:53,100
Ananda Sen: And answer, of course, is that there is there is an overall race effect, there is a difference across races so Basically, this is the p value, so this is significant.

504
01:01:53,100 --> 01:02:02,880
Ananda Sen: Good.

505
01:02:02,880 --> 01:02:07,980
Ananda Sen: question.

506
01:02:07,980 --> 01:02:14,250
Ananda Sen: Okay, so we will see most more of this.

507
01:02:14,250 --> 01:02:17,730
Ananda Sen: And next lab.

508
01:02:17,730 --> 01:02:28,770
Ananda Sen: So that's all he wanted to say about linear regression actually and and multiple want a logistic regression, but before we do that.

509
01:02:28,770 --> 01:02:37,860
Ananda Sen: Are there are there questions.

510
01:02:37,860 --> 01:02:40,080
Okay.

511
01:02:40,080 --> 01:02:42,930
alright.

512
01:02:42,930 --> 01:02:48,300
cool.

513
01:02:48,300 --> 01:02:52,800
Ananda Sen: So.

514
01:02:52,800 --> 01:02:57,390
Ananda Sen: We will start with the day who.

515
01:02:57,390 --> 01:03:06,780
Ananda Sen: Now you guys say that you are able to access the at least the PDF version.

516
01:03:06,780 --> 01:03:15,180
Ananda Sen: So.

517
01:03:15,180 --> 01:03:18,810
Ananda Sen: What time is it to 35 let me.

518
01:03:18,810 --> 01:03:21,630
Ananda Sen: let's take a very quick.

519
01:03:21,630 --> 01:08:30,630
Ananda Sen: very quick break five minutes, just to buy a break and then we'll be back at 240.

520
01:08:30,630 --> 01:08:42,600
Ananda Sen: Alright let's do something.

521
01:08:42,600 --> 01:08:46,290
Ananda Sen: let's.

522
01:08:46,290 --> 01:08:50,670
Ananda Sen: Because, because in in public health, most people.

523
01:08:50,670 --> 01:08:54,390
Ananda Sen: have seen some.

524
01:08:54,390 --> 01:08:58,860
Ananda Sen: example of logistic regression, let me ask you.

525
01:08:58,860 --> 01:09:08,820
Ananda Sen: Your exposure or your experience dealing with data, where you need to use logistic needed to use logistic regression.

526
01:09:08,820 --> 01:09:11,370
Ananda Sen: Can can you guys.

527
01:09:11,370 --> 01:09:15,390
Ananda Sen: Tell me your experience with this.

528
01:09:15,390 --> 01:09:20,040
Ananda Sen: Did you use logistic regression for something.

529
01:09:20,040 --> 01:09:27,660
Geehan Suleyman: User for research projects i've had it listed at a solution.

530
01:09:27,660 --> 01:09:28,950
Geehan Suleyman: I didn't do it myself.

531
01:09:28,950 --> 01:09:37,890
Ananda Sen: that's fine i'm not talking about the actual methodology i'm talking about more like what was the premise, what was the example, what was the reason.

532
01:09:37,890 --> 01:09:41,670
Geehan Suleyman: So we looked at risk factors.

533
01:09:41,670 --> 01:09:49,290
Geehan Suleyman: For higher mortality and covert patients, so that was one one area we used it but.

534
01:09:49,290 --> 01:09:52,380
Geehan Suleyman: I do a lot of even for Murcia.

535
01:09:52,380 --> 01:10:02,910
Geehan Suleyman: vancomycin resistance, you know infections, we looked at risk factors and outcomes and see you know what contributed so those are the areas where i've used it.

536
01:10:02,910 --> 01:10:03,870
Geehan Suleyman: Okay.

537
01:10:03,870 --> 01:10:04,350
Ananda Sen: What about.

538
01:10:04,350 --> 01:10:23,250
Others.

539
01:10:23,250 --> 01:10:26,160
Ananda Sen: So.

540
01:10:26,160 --> 01:10:30,720
Ananda Sen: logistic regression as, as you know, it's it's a.

541
01:10:30,720 --> 01:10:38,010
Ananda Sen: it's a regression model with the outcome is dichotomous yes, no great.

542
01:10:38,010 --> 01:10:45,480
Ananda Sen: Had a condition or not, does not have a condition is it control or a case.

543
01:10:45,480 --> 01:10:49,710
Ananda Sen: That sort of premise so anytime you can.

544
01:10:49,710 --> 01:10:59,670
Ananda Sen: You can label the label the outcome as a dichotomy not a continuous that's when you use and logistic regression.

545
01:10:59,670 --> 01:11:24,240
Ananda Sen: Otherwise, the purpose is the same for any regression try to find association try to find differences in group subgroups and so on and so forth, so.

546
01:11:24,240 --> 01:11:34,830
Ananda Sen: So let me.

547
01:11:34,830 --> 01:11:40,140
Ananda Sen: Let me start off this so.

548
01:11:40,140 --> 01:11:48,780
Ananda Sen: So it's a dichotomous outcome, otherwise there's the same purpose.

549
01:11:48,780 --> 01:11:52,200
Ananda Sen: Essentially, the data is binary.

550
01:11:52,200 --> 01:12:08,580
Ananda Sen: And there is a reason it's called logistic regression will come to that in a moment, but what is the structure, the structure is that it's it's 01 type of random variable it does not follow a normal distribution is not continuous.

551
01:12:08,580 --> 01:12:10,050
Ananda Sen: And the.

552
01:12:10,050 --> 01:12:21,990
Ananda Sen: probability of one, the chances of one is what we are trying to model, what are the chances of finding.

553
01:12:21,990 --> 01:12:24,180
Ananda Sen: A patient.

554
01:12:24,180 --> 01:12:32,490
Ananda Sen: or a subject to be diabetic given the risk factors, what is the likelihood of the of the of the subject to be diabetic.

555
01:12:32,490 --> 01:12:41,280
Ananda Sen: And so the chances of diabetes is is what you are modeling right, and in this case.

556
01:12:41,280 --> 01:12:56,880
Ananda Sen: You can model it in many different ways we we could ignore the dichotomous nature of why and think of this as a linear thing 012 values, but still a linear thing, and you could do it that way, there is nothing, nothing.

557
01:12:56,880 --> 01:13:05,250
Ananda Sen: Nothing preventing us from doing that right, and if you do it that way, then that model actually has some meaning.

558
01:13:05,250 --> 01:13:15,180
Ananda Sen: For example, it could the beta one could mean that it's an estimated I mean it's basically estimated accessories and so on, so.

559
01:13:15,180 --> 01:13:32,460
Ananda Sen: The problem is, it does violate one important assumption of linear regression, which is that the via the variance would be constant here the variance is not constant because the average and the variance related here.

560
01:13:32,460 --> 01:13:40,230
Ananda Sen: it's if if the if the average is what we are modeling average, meaning the probability of.

561
01:13:40,230 --> 01:13:54,660
Ananda Sen: Of of one if that's what we're modeling variance is also going to be a function if if bi is a function that we identify manage to be able to function so so that that assumption is violated.

562
01:13:54,660 --> 01:14:08,490
Ananda Sen: seeing it in any linear regression why so we normally and, moreover, very into why is Sigma squared single constant value for all subjects that is not going to happen.

563
01:14:08,490 --> 01:14:13,740
Ananda Sen: So normal regression linear regression is not possible.

564
01:14:13,740 --> 01:14:16,140
Ananda Sen: So.

565
01:14:16,140 --> 01:14:27,660
Ananda Sen: We could do a regression of logarithm of bi so logarithm of PA is just a function of bi and say that but let's let's.

566
01:14:27,660 --> 01:14:35,100
Ananda Sen: Take logarithm and do it that way, that also has some interesting.

567
01:14:35,100 --> 01:14:44,010
Ananda Sen: implications, so you could think of beta one hat, for example as a log of relative risk, so this is really modeling the relative risk.

568
01:14:44,010 --> 01:14:56,580
Ananda Sen: The problem here is estimated probability scan go beyond one which is a little awkward and it really does not work for case control study, because in case control study.

569
01:14:56,580 --> 01:15:11,370
Ananda Sen: We do not have an estimate for the prevalence so anytime we have a prevalence and we'll we'll talk about that also later, but you should not be using it for case controls, so what is done.

570
01:15:11,370 --> 01:15:17,730
Ananda Sen: What is done is, this is a little bit of mathematical construct but.

571
01:15:17,730 --> 01:15:31,890
Ananda Sen: We need to understand this to understand logistic regression, so the logistic regression is is really our model, a linear model of.

572
01:15:31,890 --> 01:15:42,180
Ananda Sen: Of a function of a function of bi that is called a legit and the legit of bi is is basically.

573
01:15:42,180 --> 01:15:44,310
Ananda Sen: This.

574
01:15:44,310 --> 01:15:58,770
Ananda Sen: Okay legit of PA is it, this is this thing inside inside the parentheses is called the odds so odds obviously has a has a connotation.

575
01:15:58,770 --> 01:16:14,010
Ananda Sen: of gambling because that's where you hear the word odds quite a bit, but really odd, this is nothing but the chance divided by the complimentary chance the chance of this happening divided by chance of this not happening.

576
01:16:14,010 --> 01:16:35,160
Ananda Sen: And if you take the log of that and model it like a linear model that's what it's called logistic regression so some quick subtle changes so one changes that when i'm modeling log of bi over one minus P, I.

577
01:16:35,160 --> 01:16:39,930
Ananda Sen: Remember that's a that's a that's a.

578
01:16:39,930 --> 01:16:53,340
Ananda Sen: parameter that's not a that's not a an observed thing it's in a linear model on the left hand side of the equation, we have an observed thing why I use observed, whether its height weight BMI score.

579
01:16:53,340 --> 01:17:05,280
Ananda Sen: some kind of continuous variable it's in observing you actually measure that in the data you don't measure log of bi over one minus p.

580
01:17:05,280 --> 01:17:14,640
Ananda Sen: So it's an indirect way of modeling things and that's that's one of the major differences between logistic regression and linear regression.

581
01:17:14,640 --> 01:17:18,540
Ananda Sen: So um so that's one thing.

582
01:17:18,540 --> 01:17:29,790
Ananda Sen: The second thing is why going through odds, why is it, why is it any better than the previous two things we're trying to look at Well, first of all.

583
01:17:29,790 --> 01:17:44,040
Ananda Sen: We are over one minus VI that's quantity, which is, which runs from zero to as large as possible when you take log of that that runs from.

584
01:17:44,040 --> 01:17:50,580
Ananda Sen: Negative infinity to positive image that's that's like over the whole real life, there is no restriction.

585
01:17:50,580 --> 01:18:08,700
Ananda Sen: which basically means that record properties will always be between zero and one, so this is, this is an unrestricted model by my making that simple transformation or not simple necessarily but but that sort of a transformation.

586
01:18:08,700 --> 01:18:14,280
Ananda Sen: What what how do probability odds law of odds.

587
01:18:14,280 --> 01:18:19,200
Ananda Sen: How do these things work so logic is basically log boards.

588
01:18:19,200 --> 01:18:35,910
Ananda Sen: So just to understand the behavior if you look at the left hand column that's scanning through the entire possible values of P, because P, is a problem, it can only go from zero to one.

589
01:18:35,910 --> 01:18:50,970
Ananda Sen: Now odds actually can can can go high it can go from zero to one in this case we stopped at 99, but it is actually the closer to one you get.

590
01:18:50,970 --> 01:18:57,510
Ananda Sen: The higher the value of God says log odds is a relatively.

591
01:18:57,510 --> 01:19:04,890
Ananda Sen: easier to handle because it doesn't go too far, but it's also symmetric.

592
01:19:04,890 --> 01:19:25,950
Ananda Sen: So, so why PS boundary between zero and one odds is is positive, but it's a symmetric and logo is unbounded it can go to the negative side and go to the positive side and it's symmetric so la god's is much better better behaved then either be or odds.

593
01:19:25,950 --> 01:19:38,220
Ananda Sen: So on this be over one minus P bees odds over one plus odds so that's the other flipped equation.

594
01:19:38,220 --> 01:19:47,610
Ananda Sen: And it, it does does it look like this, so so on the left hand side you see.

595
01:19:47,610 --> 01:19:52,410
Ananda Sen: You see, I actually did get cut off, I think.

596
01:19:52,410 --> 01:20:01,380
Ananda Sen: yeah I think I did get cut off so on the right hand side you get the law god's on the left hand side you get.

597
01:20:01,380 --> 01:20:10,830
Ananda Sen: odds So these are the two pictures.

598
01:20:10,830 --> 01:20:14,880
Ananda Sen: So, again for logistic regression.

599
01:20:14,880 --> 01:20:23,550
Ananda Sen: The parameters meaningless Amina thing so beta one is the slope of the law gods and beta.

600
01:20:23,550 --> 01:20:41,100
Ananda Sen: Zero is kind of the location is the law god's when X equal to zero again X equal to zero may or may not be in the in the data side effects equal to zero does not make any sense, then, then do some one one thing we can do is to Center that.

601
01:20:41,100 --> 01:20:50,100
Ananda Sen: And beta one the slope is is really referring to the steepness on the rise, so.

602
01:20:50,100 --> 01:20:52,650
Okay.

603
01:20:52,650 --> 01:20:55,020
Ananda Sen: So.

604
01:20:55,020 --> 01:21:16,290
Ananda Sen: These are some of the mathematical things i'm not going to worry too much about it but let's let's try to understand now what those expressions in the model means so let's take a simple example suppose I have got a model where there is law gods.

605
01:21:16,290 --> 01:21:23,490
Ananda Sen: And law gods of actually should right.

606
01:21:23,490 --> 01:21:29,490
Ananda Sen: Now, but to be not why but yeah beta not plus beta m.

607
01:21:29,490 --> 01:21:43,980
Ananda Sen: m I let's be re age, so what is, am I am I is again an indicator variable is a gender variable one if it's meal and and zero if it's if.

608
01:21:43,980 --> 01:21:51,630
Ananda Sen: me zero if the subject is female, and then there is a continuous predictor which is age okay.

609
01:21:51,630 --> 01:21:59,370
Ananda Sen: same as before law gods for males is beta not plus beta and plus beta age.

610
01:21:59,370 --> 01:22:06,450
Ananda Sen: And the odds is exponential have been an oculus beta plus beta.

611
01:22:06,450 --> 01:22:10,020
Ananda Sen: For females you don't have the beta em.

612
01:22:10,020 --> 01:22:17,460
Ananda Sen: You only have been an art class beta a dog's is exponentially better with age okay.

613
01:22:17,460 --> 01:22:31,110
Ananda Sen: So what's the odds ratio of male to female when there are the same age, and if you do the mathematics you'll see that there is nothing but exponential beta and.

614
01:22:31,110 --> 01:22:35,910
Ananda Sen: Okay, so let's try to understand this.

615
01:22:35,910 --> 01:22:40,980
Ananda Sen: If it were a linear regression, I would have called beta em.

616
01:22:40,980 --> 01:22:47,400
Ananda Sen: To the difference between males and females in the average why.

617
01:22:47,400 --> 01:22:50,460
Ananda Sen: For same age.

618
01:22:50,460 --> 01:22:59,820
Ananda Sen: Here it's the odds ratio of male to female are the same age is exponential beta m.

619
01:22:59,820 --> 01:23:05,370
Ananda Sen: So ratio of odds of male to female.

620
01:23:05,370 --> 01:23:14,550
Ananda Sen: Okay, so it is, it is a different quality it's it's it's explainer it's expressing the ratio scale.

621
01:23:14,550 --> 01:23:22,440
Ananda Sen: So more multiplicative in nature, rather than additive.

622
01:23:22,440 --> 01:23:29,250
Ananda Sen: So.

623
01:23:29,250 --> 01:23:36,780
Ananda Sen: If we, if we look at age, the continuous predictor.

624
01:23:36,780 --> 01:23:45,120
Ananda Sen: So what's the odds ratio of age, how do we explain this, how do we express this again.

625
01:23:45,120 --> 01:23:49,050
Ananda Sen: You can only do this if the.

626
01:23:49,050 --> 01:24:03,510
Ananda Sen: If the gender is fixed so odds ratio of moving up and age by a year express one two X, if you go through the calculations you end up getting exponential beta a.

627
01:24:03,510 --> 01:24:09,270
Ananda Sen: So what it is doing is it is giving you the meaning.

628
01:24:09,270 --> 01:24:19,140
Ananda Sen: of beta M and beta a in this case so beta and is the odds ratio of males to females.

629
01:24:19,140 --> 01:24:31,440
Ananda Sen: When they are the same each and beta a or exponential beta a is the odds ratio of going up by a year in age.

630
01:24:31,440 --> 01:24:35,340
Ananda Sen: For a fixed gender.

631
01:24:35,340 --> 01:24:37,050
Ananda Sen: So.

632
01:24:37,050 --> 01:24:40,950
Ananda Sen: Putting it in perspective.

633
01:24:40,950 --> 01:24:47,790
Ananda Sen: If we're at em is equal to 0.5, for example, but we could estimated that to be point 5.

634
01:24:47,790 --> 01:24:51,210
Ananda Sen: million exponentially and then you get 1.65.

635
01:24:51,210 --> 01:25:00,390
Ananda Sen: So that basically means men are predicted to have 1.65 times the odds of why compared to women.

636
01:25:00,390 --> 01:25:07,620
Ananda Sen: Given the same age.

637
01:25:07,620 --> 01:25:10,770
Okay.

638
01:25:10,770 --> 01:25:21,150
Ananda Sen: and, similarly, you can also say the administrator to have 65% higher odds of why compared with them and doing the same.

639
01:25:21,150 --> 01:25:24,360
Ananda Sen: Why could be any outcome any event.

640
01:25:24,360 --> 01:25:31,620
Ananda Sen: See the one event.

641
01:25:31,620 --> 01:25:35,340
yeah.

642
01:25:35,340 --> 01:25:55,500
Ananda Sen: Any question.

643
01:25:55,500 --> 01:26:00,300
Ananda Sen: Similarly.

644
01:26:00,300 --> 01:26:06,510
Ananda Sen: Similarly, live beta a hat is minus 0.1.

645
01:26:06,510 --> 01:26:10,530
Ananda Sen: So suppose i've got an.

646
01:26:10,530 --> 01:26:19,050
Ananda Sen: estimate of beta a to be negative 0.1 then exponential that you get 0.9 So what does it mean.

647
01:26:19,050 --> 01:26:23,430
Ananda Sen: 0.9 is point one less than one.

648
01:26:23,430 --> 01:26:37,800
Ananda Sen: So one could seat like this for every year increase in age, the odds of event for men decreased by 10%.

649
01:26:37,800 --> 01:26:45,390
Ananda Sen: But also say, for every year increase teenage daughter event for women decreased by 10%.

650
01:26:45,390 --> 01:26:53,310
Ananda Sen: Why do I say differently it I don't have to it's basically you have to fix the gender.

651
01:26:53,310 --> 01:27:15,090
Ananda Sen: So for the if we just look at the men it's every year increase in age results in a 10% reduction in the odds of event, whether it's men or women talking about.

652
01:27:15,090 --> 01:27:21,390
It.

653
01:27:21,390 --> 01:27:27,300
Ananda Sen: Another example let's do a categorical exposure.

654
01:27:27,300 --> 01:27:30,270
Ananda Sen: age is the.

655
01:27:30,270 --> 01:27:33,420
Ananda Sen: Continuous variable continuous predictor.

656
01:27:33,420 --> 01:27:38,010
Ananda Sen: And there is this three categories smoking status.

657
01:27:38,010 --> 01:27:43,080
Ananda Sen: Current past and never.

658
01:27:43,080 --> 01:27:50,010
Ananda Sen: Current is for current smoker pastors for purpose smoker never smoker is the reference guide.

659
01:27:50,010 --> 01:27:56,940
Ananda Sen: supposed to get let's let's take some numbers beta P minus 0.3 what does that mean.

660
01:27:56,940 --> 01:28:01,650
Ananda Sen: Then exponential that you get 0.7 for.

661
01:28:01,650 --> 01:28:44,460
Ananda Sen: That basically means the second bullet, is what I would use so predicted odds is 26% lower for past smokers than never smokers, given the same age.

662
01:28:44,460 --> 01:28:54,870
Ananda Sen: What a pause here for a moment and see if you're if you're understanding this interpretation.

663
01:28:54,870 --> 01:29:07,200
Ananda Sen: you're always comparing it with hundred percent if this is less than hundred percent less than one, then you subtract this from one and talk about reduction.

664
01:29:07,200 --> 01:29:25,590
Ananda Sen: If it is more than one, then you talk, then you subtract one from it and talk about the increase.

665
01:29:25,590 --> 01:29:28,170
Ananda Sen: So.

666
01:29:28,170 --> 01:30:06,000
Ananda Sen: If the coefficient is positive, then the odds ratio is bigger than one in the coefficient is equal to zero than the odds ratio is one in the coefficient is less than zero, then the odds ratio is less than.

667
01:30:06,000 --> 01:30:20,280
Ananda Sen: Are there.

668
01:30:20,280 --> 01:30:26,340
Ananda Sen: Is a premise.

669
01:30:26,340 --> 01:30:35,430
Ananda Sen: understood, I mean I and i'm not too much worried about the modeling technicalities, but I.

670
01:30:35,430 --> 01:30:44,250
Ananda Sen: am hoping that you are understanding the way to interpret this will interpret the coefficients.

671
01:30:44,250 --> 01:30:51,510
Ananda Sen: Again, the coefficients are always exponential and and described in terms of odds.

672
01:30:51,510 --> 01:30:58,110
Ananda Sen: If the exponential coefficient is more than one.

673
01:30:58,110 --> 01:31:08,850
Ananda Sen: And that happens only when the original coefficient is bigger than zero, then you explain the expanded in terms of increased odds.

674
01:31:08,850 --> 01:31:26,280
Ananda Sen: If the coefficient exponential coefficient is less than one, which means that the coefficient is less than zero, then you explain it through a decreased odds and it's an increment increase or decrease, always with respect to one.

675
01:31:26,280 --> 01:31:32,100
Ananda Sen: So as so a 76% odds ratio.

676
01:31:32,100 --> 01:31:44,280
Ananda Sen: translates to a 420 4% reduction 65% odds ratio 1.65 odds ratio translates to 65% increase.

677
01:31:44,280 --> 01:31:46,170
Okay.

678
01:31:46,170 --> 01:31:48,090
Ananda Sen: that's the part.

679
01:31:48,090 --> 01:31:51,660
to want to make sure you understand.

680
01:31:51,660 --> 01:31:53,820
Ananda Sen: Questions about this.

681
01:31:53,820 --> 01:32:08,880
Ananda Sen: Anybody.

682
01:32:08,880 --> 01:32:11,490
Ananda Sen: Now.

683
01:32:11,490 --> 01:32:14,820
Ananda Sen: Sometimes.

684
01:32:14,820 --> 01:32:16,710
Ananda Sen: it's.

685
01:32:16,710 --> 01:32:26,250
Ananda Sen: possible to express things in units which will make it more.

686
01:32:26,250 --> 01:32:31,380
Ananda Sen: Meaningful so exact, for example.

687
01:32:31,380 --> 01:32:46,710
Ananda Sen: If you find that the beta have associated with something like age is point 05 then all are associated with each increases only like 5% 1.05 so 5% increase.

688
01:32:46,710 --> 01:33:03,630
Ananda Sen: That may not be significant enough or to express and again one year increases, probably in any given problem could be may not be that useful, so you can change, you can change the.

689
01:33:03,630 --> 01:33:14,340
Ananda Sen: The unit, you can change the unit so, for example, if you if you associate try to find out what is the or associate with five years in Greece increasingly.

690
01:33:14,340 --> 01:33:16,620
Ananda Sen: If you do that.

691
01:33:16,620 --> 01:33:32,070
Ananda Sen: Then all you do is just take take a coefficient multiply that with five and then exponential which is same as saying that take the original or and just power to five.

692
01:33:32,070 --> 01:33:44,610
Ananda Sen: So in the example you see beta had at 0.05 and the or is 1.05 this is for one year increase for five year increase you take that and raised the.

693
01:33:44,610 --> 01:33:47,190
Ananda Sen: bar to five.

694
01:33:47,190 --> 01:33:52,830
Ananda Sen: And then 1.28 that's a 28% increase.

695
01:33:52,830 --> 01:34:00,420
Ananda Sen: 28% increase in odds associated with every failure increase.

696
01:34:00,420 --> 01:34:15,510
Ananda Sen: Okay.

697
01:34:15,510 --> 01:34:26,580
Ananda Sen: This is more mathematical it says basically saying that when you have an estimate you plus and minus the standard components interval business.

698
01:34:26,580 --> 01:34:29,400
Ananda Sen: standard way of.

699
01:34:29,400 --> 01:34:40,320
Ananda Sen: doing the confidence interval plus and minus 1.96 times the standard editor so that's that's what it is that last bullet is most important for me.

700
01:34:40,320 --> 01:34:51,240
Ananda Sen: The cove area of interest is significantly associated with outcome if, and only if the confidence interval is entirely situated to the right or left one.

701
01:34:51,240 --> 01:34:55,470
Ananda Sen: If the interval contains one.

702
01:34:55,470 --> 01:34:58,920
Ananda Sen: Then it's not significant.

703
01:34:58,920 --> 01:35:04,350
Ananda Sen: If the interval contains.

704
01:35:04,350 --> 01:35:12,780
Ananda Sen: An outside one, and this is this is when I say interval I mean the interval for audrey.

705
01:35:12,780 --> 01:35:18,360
Ananda Sen: Not for law god's law, but if it's longer than it's zero.

706
01:35:18,360 --> 01:35:31,680
Ananda Sen: The interval contains zero then then it's not significant other words it's significant similarly for odds ratio of the interval contains one just not to be.

707
01:35:31,680 --> 01:35:34,290
Ananda Sen: Otherwise it's significant.

708
01:35:34,290 --> 01:35:40,560
Ananda Sen: So one is what should you should be looking at.

709
01:35:40,560 --> 01:35:46,140
Ananda Sen: The interval should be away from one idea to the left or to the right.

710
01:35:46,140 --> 01:35:54,930
Ananda Sen: said understood that's that's how to interpret and we'll see more examples of that.

711
01:35:54,930 --> 01:36:10,620
Ananda Sen: So warning, this is a lot more complex to understand than the linear model, so we have to do it very carefully and I want to encourage you to ask me questions.

712
01:36:10,620 --> 01:36:18,900
Ananda Sen: So what is interpretation interaction interaction is the same as before, so.

713
01:36:18,900 --> 01:36:24,420
Ananda Sen: Just mathematically is just a product of the two X variables.

714
01:36:24,420 --> 01:36:26,910
Okay.

715
01:36:26,910 --> 01:36:31,380
Ananda Sen: But really what that's me.

716
01:36:31,380 --> 01:36:37,680
Ananda Sen: Again, better through an example so let's say lords.

717
01:36:37,680 --> 01:36:42,750
Ananda Sen: He is given by an equation, where the two risk factors are.

718
01:36:42,750 --> 01:36:50,070
Ananda Sen: Alcohol drinkers versus not and and age is well.

719
01:36:50,070 --> 01:36:53,460
Ananda Sen: age is not dichotomous ages continuous.

720
01:36:53,460 --> 01:36:57,480
Ananda Sen: And allow god's is a function of those.

721
01:36:57,480 --> 01:36:59,820
Ananda Sen: As well as their interaction.

722
01:36:59,820 --> 01:37:24,450
Ananda Sen: So if there were no interactions that meant that the age slope for both alcohol drinkers and non drinkers would be the same, so it will be the picture on the left, all right, and the intercept for alcohol non drinkers is beta not an intercept for drinkers will be beta plus beta one.

723
01:37:24,450 --> 01:37:27,810
Ananda Sen: But the slot for both of them would be better to.

724
01:37:27,810 --> 01:37:33,690
Ananda Sen: If there were no beta three now if there are be there is beta three.

725
01:37:33,690 --> 01:37:43,140
Ananda Sen: That not only are the intercepts different, but the slopes are also different so you no longer have to parallel lines.

726
01:37:43,140 --> 01:37:45,960
Ananda Sen: For the drinkers and non-drinkers.

727
01:37:45,960 --> 01:38:02,280
Ananda Sen: Okay, and when I say slope this, these are all eight slopes, by the way, so.

728
01:38:02,280 --> 01:38:06,450
Ananda Sen: Now i've gotten some of the actual calculations.

729
01:38:06,450 --> 01:38:10,710
Ananda Sen: So make it easy.

730
01:38:10,710 --> 01:38:20,760
Ananda Sen: Instead of age to be continuous will make age dichotomous old and young, some threshold and alcohol is yes or no.

731
01:38:20,760 --> 01:38:43,410
Ananda Sen: And that interaction for the model has been an operator one same model, as before, except now I am instead of am writing all so it's an indicator it's a dummy variable for old so it's all these equal to one if the age is about certain threshold you zero otherwise.

732
01:38:43,410 --> 01:38:51,330
Ananda Sen: So let's let's first try to see what is the log or associated with the drinking in the old.

733
01:38:51,330 --> 01:38:58,950
Ananda Sen: Well it's better not plus beta one is drinking so alcohol drinker so Alex Alex equal to one.

734
01:38:58,950 --> 01:39:02,760
Ananda Sen: is equal to one also.

735
01:39:02,760 --> 01:39:10,740
Ananda Sen: So Alec times old is also one, so it has got all of them they're not plus beta one plus two, plus three.

736
01:39:10,740 --> 01:39:16,590
Ananda Sen: Now it's log or are associated with drinking.

737
01:39:16,590 --> 01:39:19,350
Ananda Sen: So all this fixed.

738
01:39:19,350 --> 01:39:24,360
Ananda Sen: But it's drinker versus non drinker now if it's non drinker.

739
01:39:24,360 --> 01:39:32,310
Ananda Sen: Then alcohol is zero so beta one is vanishing beta three is managing your left with Bernard plus beta.

740
01:39:32,310 --> 01:39:39,450
Ananda Sen: So when you subtract that you end up getting beta one plus beta three.

741
01:39:39,450 --> 01:39:46,590
Ananda Sen: You do the same with love or have associated with drinking in young.

742
01:39:46,590 --> 01:39:54,570
Ananda Sen: Well it's better not plus beta one for drinkers in the young group young group means all equal to zero.

743
01:39:54,570 --> 01:39:57,390
Ananda Sen: And then for.

744
01:39:57,390 --> 01:40:00,390
Ananda Sen: The.

745
01:40:00,390 --> 01:40:02,940
Ananda Sen: Non drinkers in neon.

746
01:40:02,940 --> 01:40:08,760
Ananda Sen: So even beta one is gone it's no longer there so it's only better not.

747
01:40:08,760 --> 01:40:23,370
Ananda Sen: To do the subtraction it ends up being beta one.

748
01:40:23,370 --> 01:40:29,220
Ananda Sen: alright.

749
01:40:29,220 --> 01:40:42,150
Ananda Sen: So or associated with drinking in all is exponential beta one plus beta three or associated with drink in young is exponential beta one.

750
01:40:42,150 --> 01:40:44,520
Ananda Sen: Now tell me.

751
01:40:44,520 --> 01:40:59,580
Ananda Sen: What does beta three indicate.

752
01:40:59,580 --> 01:41:07,980
Ananda Sen: Well, if you dig the ratio of these two or you end up getting exponentially better one.

753
01:41:07,980 --> 01:41:10,860
Ananda Sen: Over exponential beta three.

754
01:41:10,860 --> 01:41:16,710
Ananda Sen: And sorry expression beta one plus beta three the verb explanation beta one.

755
01:41:16,710 --> 01:41:23,550
Ananda Sen: So.

756
01:41:23,550 --> 01:41:33,630
Ananda Sen: beta three is really the difference in log or are associated with alcohol in old.

757
01:41:33,630 --> 01:41:37,590
Ananda Sen: versus in young.

758
01:41:37,590 --> 01:41:43,980
Ananda Sen: it's.

759
01:41:43,980 --> 01:41:59,100
Ananda Sen: ratio of alcohol effect or among old vs young.

760
01:41:59,100 --> 01:42:02,130
Ananda Sen: try to understand what mega threes.

761
01:42:02,130 --> 01:42:13,980
Ananda Sen: If this were a linear model, we could have called a difference in differences difference in the average.

762
01:42:13,980 --> 01:42:18,030
Ananda Sen: Average outcome.

763
01:42:18,030 --> 01:42:22,890
Ananda Sen: difference between old and young, in the average outcome.

764
01:42:22,890 --> 01:42:28,830
Ananda Sen: And a difference of that difference between the drinkers drinkers and laundry.

765
01:42:28,830 --> 01:42:35,910
Ananda Sen: So it's a difference in differences, this is also difference in differences but in terms of the odds ratios.

766
01:42:35,910 --> 01:42:52,230
Ananda Sen: So your first calculate the odds ratio of drinking, which is drinking versus non drinking in the old, then you calculate the odds ratio of drinking versus non drinking in the young and then you think the ratio of those odds ratios.

767
01:42:52,230 --> 01:42:57,150
Ananda Sen: So the ratio of odds ratios.

768
01:42:57,150 --> 01:43:11,430
Ananda Sen: of drinking between young and old, so this is the same flavor it's only in the multiplicative scale.

769
01:43:11,430 --> 01:43:14,100
Ananda Sen: So beta three.

770
01:43:14,100 --> 01:43:25,560
Ananda Sen: Really assesses whether the alcohol effect difference by old vs young elk when I say alcohol effect the difference between a drinker versus non drinker is in built.

771
01:43:25,560 --> 01:43:38,880
Ananda Sen: Or you could say whether age effect difference by whether drinking.

772
01:43:38,880 --> 01:43:51,210
Ananda Sen: So the test of interaction really means if the alcohol effect is the same in all too young.

773
01:43:51,210 --> 01:43:59,250
Ananda Sen: Basically, the ratio of ours is equal to one.

774
01:43:59,250 --> 01:44:26,700
Ananda Sen: pause for a moment, encouraged questions.

775
01:44:26,700 --> 01:44:37,590
Ananda Sen: So.

776
01:44:37,590 --> 01:44:41,850
Ananda Sen: let's put some numbers in there and try to.

777
01:44:41,850 --> 01:44:43,980
Ananda Sen: Try to work it out.

778
01:44:43,980 --> 01:44:57,960
Ananda Sen: So let's allow god's often outcome is 0.23 minus 0.06 times age, plus 0.73 times smoke minus 5.13 times ht.

779
01:44:57,960 --> 01:45:19,560
Ananda Sen: Was 0.28 times each time 60 now, you need see that I have started using the same variables, which we have seen before in the low birth outcome data, so what could be the log odds of what so log odds off, and I will specified here very clearly.

780
01:45:19,560 --> 01:45:33,000
Ananda Sen: log odds off.

781
01:45:33,000 --> 01:45:39,510
Ananda Sen: So that's the variable we have in the data set right low birth weight is.

782
01:45:39,510 --> 01:45:48,660
Ananda Sen: Is one or zero less than 2500 gram it's one above 2500 gram it is zero.

783
01:45:48,660 --> 01:46:04,920
Ananda Sen: So law gods of low birth weight is a function of age, smoking status, hypertension and agent hypertension interaction.

784
01:46:04,920 --> 01:46:09,750
Okay.

785
01:46:09,750 --> 01:46:12,180
Ananda Sen: All right.

786
01:46:12,180 --> 01:46:14,700
Ananda Sen: So.

787
01:46:14,700 --> 01:46:21,510
Ananda Sen: What is the or of smoking in age now.

788
01:46:21,510 --> 01:46:23,760
Ananda Sen: That.

789
01:46:23,760 --> 01:46:25,020
Ananda Sen: Is.

790
01:46:25,020 --> 01:46:37,920
Ananda Sen: is something which is just a big number, and it could be any other thing it's a fixed age doesn't matter that's exponential 0.73.

791
01:46:37,920 --> 01:46:50,430
Ananda Sen: Why is that because the way to interpret this is, if you fix the age status and hypertension status.

792
01:46:50,430 --> 01:47:01,350
Ananda Sen: The same well in this case it's not hypertension Well, no, hypertension means the last two terms in this equation will be zero.

793
01:47:01,350 --> 01:47:04,080
Ananda Sen: So no issues there.

794
01:47:04,080 --> 01:47:06,000
Ananda Sen: But.

795
01:47:06,000 --> 01:47:20,340
Ananda Sen: But then I wanted to do or in smoking or of smoking in age 25 now what does what does it mean to do or of smoke well or of smoking is or of smoking vs not smoking.

796
01:47:20,340 --> 01:47:24,390
Ananda Sen: odds of smoking vs odds of not smoking.

797
01:47:24,390 --> 01:47:39,630
Ananda Sen: All right, well first of first of all you do log was an explanation well if you do log on for smoking forget about the last two terms, it will be 0.234 smokers 0.23 minus 0.06 times age, plus 0.73.

798
01:47:39,630 --> 01:47:47,640
Ananda Sen: Okay now it's non smoker than the second necessary.

799
01:47:47,640 --> 01:47:58,290
Ananda Sen: yeah if it is non smoker, then the last term is a third term is gone 0.73 times more that term is gone you're only left with 0.23 minus 0.06 age.

800
01:47:58,290 --> 01:48:14,310
Ananda Sen: Now, if you fix age between the smoker or nonsmoker same age, then the age term is also gone and the interceptor is also gone so what you're left with is the 0.73.

801
01:48:14,310 --> 01:48:19,980
Ananda Sen: And that's when you take the or then it's exponential.

802
01:48:19,980 --> 01:48:25,410
Ananda Sen: Now, I say that in in.

803
01:48:25,410 --> 01:48:40,350
Ananda Sen: explaining that it works, but but really if you see an equation like this, how do we interpret for linear regression and a coefficient coefficient is in the linear regression is essentially if it's a.

804
01:48:40,350 --> 01:48:47,250
Ananda Sen: dichotomous variable you just say that is a difference between the two groups.

805
01:48:47,250 --> 01:48:51,750
Ananda Sen: In the average outcome when the other conditions are fixed.

806
01:48:51,750 --> 01:48:54,390
Ananda Sen: The same thing here.

807
01:48:54,390 --> 01:49:18,330
Ananda Sen: it's the odds ratio of smoking vs non smoking when the other variables are fixed other variables meaning age and hypertension status well here i'm fixing age to 25 and then looking only at the know hypertension.

808
01:49:18,330 --> 01:49:29,250
Ananda Sen: If I change the age to some other number and instead of no hypertension and look at hypertension rebels get the same result, its financial 0.73 or smoking.

809
01:49:29,250 --> 01:49:34,200
Ananda Sen: So 0.73 really is the log or smoking.

810
01:49:34,200 --> 01:49:48,390
Ananda Sen: Once the other terms are fixed.

811
01:49:48,390 --> 01:49:56,640
Ananda Sen: Similarly, you can look for hd versus non hd for an H 25 smoker.

812
01:49:56,640 --> 01:50:01,890
Ananda Sen: and

813
01:50:01,890 --> 01:50:04,290
Ananda Sen: You will get.

814
01:50:04,290 --> 01:50:10,890
Ananda Sen: A similar result now there is one difference here.

815
01:50:10,890 --> 01:50:17,280
Ananda Sen: Because he is involved in the interaction term.

816
01:50:17,280 --> 01:50:22,590
Ananda Sen: The last arm cannot go out.

817
01:50:22,590 --> 01:50:28,020
Ananda Sen: you'll have to retain the last one.

818
01:50:28,020 --> 01:50:40,560
Ananda Sen: So there is a difference between or at age 25 smoker and or smoking age 25 knowledge or smoking age 25 noise is just one coefficient.

819
01:50:40,560 --> 01:50:52,950
Ananda Sen: or hgh 25 smoker or two coefficients.

820
01:50:52,950 --> 01:51:00,840
Ananda Sen: and your age has to be specified.

821
01:51:00,840 --> 01:51:05,160
Ananda Sen: Do you understand that anybody wants me to.

822
01:51:05,160 --> 01:51:19,860
Ananda Sen: explain that further.

823
01:51:19,860 --> 01:51:27,090
Ananda Sen: Their does this surprise you let's forget about the math part does it surprise you.

824
01:51:27,090 --> 01:52:12,450
Ananda Sen: That, I have an additional term, I have to deal with.

825
01:52:12,450 --> 01:52:22,440
Ananda Sen: Why should it not surprise you, what does what does having an interaction term mean somebody told me.

826
01:52:22,440 --> 01:52:28,170
Ananda Sen: The likelihood of low birth weight.

827
01:52:28,170 --> 01:52:33,780
Ananda Sen: that's what you were predicting.

828
01:52:33,780 --> 01:52:45,780
Ananda Sen: What does having an interaction term.

829
01:52:45,780 --> 01:52:49,290
Christie Flanagan: That two variables are affecting the outcome.

830
01:52:49,290 --> 01:52:51,480
Ananda Sen: Yes, that is, that is definitely true.

831
01:52:51,480 --> 01:52:55,170
Ananda Sen: But i'm i'm talking about clinical.

832
01:52:55,170 --> 01:53:06,450
Ananda Sen: clinically you see this as a public health researcher you see this and say that well I know something about how they're affecting the low birth outcome.

833
01:53:06,450 --> 01:53:09,870
Ananda Sen: or low birth weight outcome.

834
01:53:09,870 --> 01:53:16,440
Ananda Sen: So both age and hd they're predicting low work without low birth weight.

835
01:53:16,440 --> 01:53:25,110
Ananda Sen: But there is a very specific thing about that interaction, which makes it a little bit more.

836
01:53:25,110 --> 01:53:35,250
Ananda Sen: involved in the second calculation, which was not the case.

837
01:53:35,250 --> 01:53:37,320
Ananda Sen: But.

838
01:53:37,320 --> 01:53:42,300
Geehan Suleyman: I guess the fact that would be different right.

839
01:53:42,300 --> 01:53:45,570
Geehan Suleyman: The effect, each one has on it.

840
01:53:45,570 --> 01:53:49,170
Ananda Sen: Yes, and and see having an interaction.

841
01:53:49,170 --> 01:53:53,220
Ananda Sen: means see if i'm interested in finding out the difference between.

842
01:53:53,220 --> 01:54:02,940
Ananda Sen: hd hypertensive and non hypertensive what is the likelihood of a hypertensive or what are the, what are the odds of an hypertensive.

843
01:54:02,940 --> 01:54:08,610
Ananda Sen: Having a low birth weight in comparison to a non hypertensive mother.

844
01:54:08,610 --> 01:54:16,050
Ananda Sen: Now, having an interaction means that effect varies across age.

845
01:54:16,050 --> 01:54:19,350
Ananda Sen: It also depends on age of the mother.

846
01:54:19,350 --> 01:54:30,360
Ananda Sen: So the mother is 25 year old a 40 year old will make a difference that's what having an interaction means smoking.

847
01:54:30,360 --> 01:54:38,130
Ananda Sen: Smoking versus non smoking because it's not in there, there is no interaction it doesn't matter what age.

848
01:54:38,130 --> 01:54:44,370
Ananda Sen: It doesn't matter what the hd is going to be as long as they're fixed.

849
01:54:44,370 --> 01:54:47,820
We should have the same same.

850
01:54:47,820 --> 01:54:51,900
Ananda Sen: that's the difference.

851
01:54:51,900 --> 01:54:58,770
Ananda Sen: That is, after.

852
01:54:58,770 --> 01:55:13,440
Ananda Sen: So interaction essentially means that you cannot really talk about one variable effect of one variable without talking about the effect of that.

853
01:55:13,440 --> 01:55:18,060
So.

854
01:55:18,060 --> 01:55:19,530
Theresa Marie Kowalski-Dobson: So can I ask a question about.

855
01:55:19,530 --> 01:55:21,360
yeah.

856
01:55:21,360 --> 01:55:26,820
Theresa Marie Kowalski-Dobson: Basically I guess i'm just thinking about like real world doing this.

857
01:55:26,820 --> 01:55:43,830
Theresa Marie Kowalski-Dobson: I assume they're very common things that you'd put into as interaction terms or there's ways that you could test to see what would be put in as an interaction term based on hypothesis a hypothesis is that kind of how you would go about that.

858
01:55:43,830 --> 01:55:45,570
Ananda Sen: Yes, okay.

859
01:55:45,570 --> 01:55:52,830
Ananda Sen: So, so in all research all clinical research all medical research.

860
01:55:52,830 --> 01:55:56,730
Ananda Sen: There is this research hypothesis, you want to check.

861
01:55:56,730 --> 01:56:17,220
Ananda Sen: And, and this is having an interaction also means having an effect modifier so another way of seeing this would be the hd effect on the low birth with outcome is modified by age right that's your hypothesis, how would you check that you would put that term in the model.

862
01:56:17,220 --> 01:56:30,150
Ananda Sen: and see the corresponding beta coefficient is significant or not, I did not go into significance here I just gave you some point estimates, but the but that's that's how you test it.

863
01:56:30,150 --> 01:56:32,100
Ananda Sen: But.

864
01:56:32,100 --> 01:56:40,830
Ananda Sen: I mean if this is something where you have no idea how this is going to going to work then lot of times, people do a kitchen sink approach.

865
01:56:40,830 --> 01:56:50,370
Ananda Sen: They do everything and retailer with your work that the trouble with that is that oftentimes you'll get false signal false positives.

866
01:56:50,370 --> 01:56:54,840
Ananda Sen: Collecting things come up, which are not necessarily.

867
01:56:54,840 --> 01:56:56,340
Ananda Sen: So.

868
01:56:56,340 --> 01:57:05,280
Ananda Sen: But, but when it is when is based on research, when it's based on private data or some biological reason.

869
01:57:05,280 --> 01:57:13,800
Ananda Sen: And then any any let's say you you, you have a genetic marker and your your your hypothesis that genetic marker.

870
01:57:13,800 --> 01:57:28,230
Ananda Sen: Actually, its effect on the outcome would differ between males and females you've got is the case then put in the male female gender and the genetic marker interaction in the model and test for it.

871
01:57:28,230 --> 01:57:35,940
Ananda Sen: So so yeah that's that's that's typically the research step, you want to take, most of the time.

872
01:57:35,940 --> 01:57:40,200
Ananda Sen: Good question other questions.

873
01:57:40,200 --> 01:57:54,300
Marcelo Galafassi: Also clinically when I was looking both clinically on those two things agent hypertension, so one is more controllable than the other is that something that we look at to like hypertension, be more controllable than age.

874
01:57:54,300 --> 01:57:54,840
Ananda Sen: So.

875
01:57:54,840 --> 01:58:17,310
Ananda Sen: sword so that's an interesting point you make so there's 0.2 way that interaction term you can interpret in two different ways, one is you could we could talk about the same term as as if it's a it's an odds between hypertension tension and non hypertension.

876
01:58:17,310 --> 01:58:19,260
Ananda Sen: Given.

877
01:58:19,260 --> 01:58:34,800
Ananda Sen: Given the given the given and between all vs vs the young, or you could also say that really it's a difference between all than the young.

878
01:58:34,800 --> 01:58:47,910
Ananda Sen: In the hypertensive group versus the non hypertensive group so so you could you could sell it is controlling for the age or you could say it's controlling for the for the hypertension, you would get the same number.

879
01:58:47,910 --> 01:59:06,480
Ananda Sen: So, so there is no, there is one term which, which explains that the age age effect for the hypertensive is is different from age effect in the non hypertensive or you could say that the hypertension effect for for the old is the same or same or different.

880
01:59:06,480 --> 01:59:16,080
Ananda Sen: than the hypertensive affecting young right, so you could flip it and and and interpret both ways.

881
01:59:16,080 --> 01:59:19,860
Ananda Sen: understood or something yeah okay.

882
01:59:19,860 --> 01:59:24,510
Ananda Sen: Good good good questions is always good questions other other.

883
01:59:24,510 --> 01:59:32,670
Ananda Sen: Questions here.

884
01:59:32,670 --> 01:59:43,500
Ananda Sen: Okay, so i'm basically going to in the same next page i'm going through the calculations of what we just talked about.

885
01:59:43,500 --> 01:59:54,180
Ananda Sen: So, for example, if we go through the and i'm going to explain the calculations too much it's it's easier to just go through this line by line.

886
01:59:54,180 --> 02:00:04,740
Ananda Sen: But if we calculate which is let's say the one of those try to calculate the or associated with hd for a 25 year old non smoker and end up getting.

887
02:00:04,740 --> 02:00:21,450
Ananda Sen: hd versus non hd for for an age 25 non smokers 6.49 now if I if I did the same thing hd versus not hd for a given age and a smoker I end up also getting.

888
02:00:21,450 --> 02:00:43,050
Ananda Sen: 6.49 so the are associated with hd for 25 year olds smokers find that when the age is fixed, then I end up getting the same same or no matter, no matter whether I do it for non smoker or a smoker.

889
02:00:43,050 --> 02:00:54,210
Ananda Sen: And I can do the do the same thing or associated with hd for 2534 year old smoker I end up getting something of a 4.90.

890
02:00:54,210 --> 02:01:09,420
Ananda Sen: And if I take the ratio of the two or hd for age 25 smoker or hd for the age 24 smoker and i'm getting 1.32 now that's a long calculation.

891
02:01:09,420 --> 02:01:24,480
Ananda Sen: To do this, or ratio and coming up with 1.32 easiest thing to do would be take the 0.28 that you seen the equation exponential there, and you see the same 1.32 popping up.

892
02:01:24,480 --> 02:01:46,620
Ananda Sen: Okay, so what is the point of this exercise the point of this exercise is to explain what the 0.28 means to the 0.28 really means are exponential 0.28 really means the ratio of ours for hd for a smoker.

893
02:01:46,620 --> 02:01:48,810
Ananda Sen: often given age.

894
02:01:48,810 --> 02:01:51,630
Ananda Sen: are sorry.

895
02:01:51,630 --> 02:01:54,600
Ananda Sen: The all our.

896
02:01:54,600 --> 02:02:01,530
Ananda Sen: odds ratio of hd.

897
02:02:01,530 --> 02:02:07,980
Ananda Sen: For one year increase when they're smoking status is.

898
02:02:07,980 --> 02:02:22,080
Ananda Sen: Fixed so when you when you do this calculation for a non smoker were both top and the bottom in that ratio of or when you have non smoker you'll still get 1.3.

899
02:02:22,080 --> 02:02:41,820
Ananda Sen: When the smoking status is is is fixed, it is really showing ratio of ours for different age groups when they just differ by one one it's always one unit change in a continuous variable.

900
02:02:41,820 --> 02:02:43,860
Ananda Sen: Sorry, I.

901
02:02:43,860 --> 02:02:54,270
Ananda Sen: was saying, young and old, where this is the, this is the low bar with data is this their age is continuous so so.

902
02:02:54,270 --> 02:03:05,370
Ananda Sen: So this is something I was stopping interaction in the linear model is different than differences interaction in the logistic regression is the ratio of ours.

903
02:03:05,370 --> 02:03:19,980
Ananda Sen: So or itself is a difference in what or itself is a ratio to the ratio of ratios effectively.

904
02:03:19,980 --> 02:03:28,710
Ananda Sen: So this is all basically doing the same thing.

905
02:03:28,710 --> 02:03:35,670
Okay.

906
02:03:35,670 --> 02:03:48,390
Ananda Sen: So let's see.

907
02:03:48,390 --> 02:04:08,670
Ananda Sen: So I want to talk a little bit about the statistical inference next but i'm i'm thinking this might be a good time to switch to the lab.

908
02:04:08,670 --> 02:04:15,930
Ananda Sen: So the same data set the low birth with data and we're will consider the association between.

909
02:04:15,930 --> 02:04:30,630
Ananda Sen: Low birth weight as an outcome and other practice that so we changed the outcome before we were talking about birth weights we're talking about other continuous variables as outcomes, but here, though birth, where the 01 is going to be out.

910
02:04:30,630 --> 02:04:33,180
Ananda Sen: There are different ways of.

911
02:04:33,180 --> 02:04:41,340
Ananda Sen: doing some simple things, for example, if I wanted to just ask the question is low birth weight associated with history of hypertension.

912
02:04:41,340 --> 02:04:52,830
Ananda Sen: And really it's a comparison of two proportions and that are pretty straightforward ways of comparing proportions, using a Z test and that's the formula there.

913
02:04:52,830 --> 02:05:02,310
Ananda Sen: which, if you have used it before you know that it's a it's a pretty straightforward formula, you can use it.

914
02:05:02,310 --> 02:05:14,340
Ananda Sen: Almost a nice software programming in excel and it will still do it in SAS the easy thing to do would be to just use a proc freak and.

915
02:05:14,340 --> 02:05:29,550
Ananda Sen: There is a table statement which we use before now, you can ask for Chi Square and or you can also ask for the odds ratio in this context and.

916
02:05:29,550 --> 02:05:41,880
Ananda Sen: So here are the here are the outputs and you could talk about Chi square fisher's exact test and the odds ratio and relative test all of these things.

917
02:05:41,880 --> 02:06:07,650
Ananda Sen: are pretty easy that all these things, where it says probability at the end, those are the p values, so in this case, p value is significant, which basically means that yes, there is there is some association between low birth weight and hypertension status that's that's all it seen.

918
02:06:07,650 --> 02:06:09,630
Ananda Sen: Remember those.

919
02:06:09,630 --> 02:06:27,480
Ananda Sen: The way those that that cross classification table looks like it's the top one is frequency and then we have percentage low percentage zero percent in column percentage that's how it is set up.

920
02:06:27,480 --> 02:06:28,410
Ananda Sen: Okay.

921
02:06:28,410 --> 02:06:29,880
Ananda Sen: yeah sorry.

922
02:06:29,880 --> 02:06:33,360
Geehan Suleyman: How do you calculate the.

923
02:06:33,360 --> 02:06:45,690
Ananda Sen: Other degrees of freedom yeah yeah good good question so def for a Chi square distribution is look at the table the table is two by two rate.

924
02:06:45,690 --> 02:06:55,140
Ananda Sen: hmm so the degrees of freedom would be to minus one times two minus one.

925
02:06:55,140 --> 02:07:35,130
Ananda Sen: If this were a three by three table the degrees of freedom would have been three minus one times three minus one, but a three by two table then it's three minus one times two minus one it's always the number of columns minus one times number of Rule minus one so let's write it down.

926
02:07:35,130 --> 02:07:47,370
Ananda Sen: And when I say columns and rows i'm referring to this table.

927
02:07:47,370 --> 02:07:58,860
Ananda Sen: And this is all obviously says output, but but that's that's what it means that's what the degrees of freedom.

928
02:07:58,860 --> 02:08:10,410
Ananda Sen: There is also a thing which some of you may have come across it's called fisher's exact test so when you have when you have numbers which are small.

929
02:08:10,410 --> 02:08:26,670
Ananda Sen: In this case, that is the case, especially when they recommend that if you have five or less in any of the cells, and this is the case here five year and seven year you should use something called fisher's exact test.

930
02:08:26,670 --> 02:08:28,350
Ananda Sen: Which.

931
02:08:28,350 --> 02:08:46,260
Ananda Sen: Often it doesn't doesn't change too much, but in this case it's typically more conservative so, so this is, this is what you should compare it with 0.5051 cents versus 0.0262 they are.

932
02:08:46,260 --> 02:08:59,280
Ananda Sen: they're closed, but this one is technically non significant and that's not surprising fisher's exact test is typically more conservative them guys quick test so.

933
02:08:59,280 --> 02:09:16,680
Ananda Sen: In in journal papers in a situation like this one does report mode and they typically say that we have borderline significance, or something like this.

934
02:09:16,680 --> 02:09:20,460
Ananda Sen: So audrey shoe if you look at the.

935
02:09:20,460 --> 02:09:26,100
Ananda Sen: Confidence limit it does exceed one.

936
02:09:26,100 --> 02:09:37,770
Ananda Sen: So this actually says it is, it is significant, and the reason it matches is because you are this is corresponding to this.

937
02:09:37,770 --> 02:10:01,380
Ananda Sen: Is 0.036 that's why it matches if it is based on the fishes exact St it would have covered one because it's more conservative, in that sense, but the reason I see this that 1.0214 1100 so it's more than one so because it does correspond to this case with this.

938
02:10:01,380 --> 02:10:05,580
Ananda Sen: So both odds ratio and Chi square based on.

939
02:10:05,580 --> 02:10:15,570
Ananda Sen: The case with those are approximate approximate this show that there, there is a significant association.

940
02:10:15,570 --> 02:10:34,500
Ananda Sen: So essentially that says that the likelihood of hypertensive mother's having a low birth with baby is higher in fact how much higher the odds are about 3.4.

941
02:10:34,500 --> 02:10:42,600
Ananda Sen: So you can do this, we can do this, using a logistic regression and a gen mode also um.

942
02:10:42,600 --> 02:10:49,830
Ananda Sen: And here is the first statement with Jen MOD in the context of logistic regression.

943
02:10:49,830 --> 02:10:58,860
Ananda Sen: You saw this briefly just for one example in the linear regression We saw this this morning, or this little an hour back.

944
02:10:58,860 --> 02:11:03,900
Ananda Sen: The only change here will there to change this one is.

945
02:11:03,900 --> 02:11:17,760
Ananda Sen: Distribution equal to binomial and then there is a link function which I need to need to specify actually for gen model you don't need to specify the link function because.

946
02:11:17,760 --> 02:11:31,650
Ananda Sen: You do not need to specify the link function if you're using logistic regression that's default, but I just thought I would just run it because, because you could potentially change the link function in a in a given situation.

947
02:11:31,650 --> 02:11:39,390
Ananda Sen: There is one additional thing here, which is, which is important.

948
02:11:39,390 --> 02:11:48,960
Ananda Sen: After low model low I threw in that thing in the parentheses event equal to one.

949
02:11:48,960 --> 02:12:02,010
Ananda Sen: And there is a there is a very strange reason for doing that says, for some reason in gen mode it models, the likelihood of the zero coded event.

950
02:12:02,010 --> 02:12:10,830
Ananda Sen: Not the one quarter event, so it would have actually model if you didn't say that you would have modeled.

951
02:12:10,830 --> 02:12:16,260
Ananda Sen: The likelihood of not low birth weight.

952
02:12:16,260 --> 02:12:28,050
Ananda Sen: So so that's a little little awkward so you can change that by throwing in that event, equal to one, it is a generally a good practice, so I would always.

953
02:12:28,050 --> 02:12:35,130
Ananda Sen: say that because that's a fear interest rate, most of the time.

954
02:12:35,130 --> 02:12:43,860
Ananda Sen: So that's that's that single line actually produces all the things you want, so it gets your intercept and.

955
02:12:43,860 --> 02:12:51,000
Ananda Sen: hd and scale and so on and so forth, so how does it, what does it mean well, it means.

956
02:12:51,000 --> 02:13:16,170
Ananda Sen: model law god's of law is minus 0.8771 that comes from the intercept plus 1.2135 ignore that last line scale so hypertension, is that so so lots of low bar for hypertensive mothers, it is minus 0.8771 plus one plus 1.2135 right because hga equal to one.

957
02:13:16,170 --> 02:13:27,210
Ananda Sen: And for non hypertensive mothers it's exponential minus 0.8771 only there is hd is equal to zero so that's 0.416.

958
02:13:27,210 --> 02:13:35,250
Ananda Sen: Okay, so what's that what's the or the or is 1.4 divided by.

959
02:13:35,250 --> 02:13:44,520
Ananda Sen: 0.416.

960
02:13:44,520 --> 02:13:48,240
Ananda Sen: So.

961
02:13:48,240 --> 02:13:50,550
Ananda Sen: Sorry nine.

962
02:13:50,550 --> 02:14:12,060
Ananda Sen: So odds ratio is just this all point 1.2135 which is exponential one 1.2135 which is 3.365 does this ring a bell well, it should because that 3.365 should match this.

963
02:14:12,060 --> 02:14:22,080
Ananda Sen: So, again from this equation just just take this estimate and exponential that you get the odds ratio of hd versus not in hd.

964
02:14:22,080 --> 02:14:31,740
Ananda Sen: Again this is 0.0461 that 0.0461 should also match.

965
02:14:31,740 --> 02:14:40,440
Ananda Sen: Well, it doesn't match the Chi Square, but it does match the odds ratio calculation that P value is.

966
02:14:40,440 --> 02:21:07,920
Ananda Sen: Also wild desks be bad and we'll talk about those walters and i'm up doors a little later all right let's take a break now we'll come back at 352 to 47 now.

967
02:21:07,920 --> 02:21:25,440
Ananda Sen: Hello.

968
02:21:25,440 --> 02:21:28,950
Ananda Sen: Okay.

969
02:21:28,950 --> 02:21:33,720
Ananda Sen: One thing I forgot to mention is that.

970
02:21:33,720 --> 02:21:40,620
Ananda Sen: There is something I put in here which just above the output of gen mode.

971
02:21:40,620 --> 02:21:44,670
Ananda Sen: something you should.

972
02:21:44,670 --> 02:21:47,400
Ananda Sen: pay attention to.

973
02:21:47,400 --> 02:21:51,540
Ananda Sen: SAS has this annoying habit of.

974
02:21:51,540 --> 02:22:13,710
Ananda Sen: Running some procedures and still producing output, when there is some problem, so this is a key thing algorithm converged is what you should be looking at if the algorithm did not convert it will say give that message, and then it will still print out.

975
02:22:13,710 --> 02:22:21,510
Ananda Sen: Somewhere of the estimates which is, which is not a good thing, so so that's something you should be looking for.

976
02:22:21,510 --> 02:22:23,640
Ananda Sen: Now.

977
02:22:23,640 --> 02:22:26,430
Ananda Sen: It also has a heading.

978
02:22:26,430 --> 02:22:37,290
Ananda Sen: which says analysis of maximum likelihood parameter estimates what is maximum likelihood parameter estimates that will will will talk about that a little bit.

979
02:22:37,290 --> 02:22:57,570
Ananda Sen: In a little bit, but let's first go through this farther and see if we can estimate the are using the project, because obviously you can get through proc furyk but profit doesn't would not allow you to get covariance so.

980
02:22:57,570 --> 02:23:02,160
Ananda Sen: there's an estimate statement here very similar to Prague glm.

981
02:23:02,160 --> 02:23:06,480
Ananda Sen: And the estimate is.

982
02:23:06,480 --> 02:23:13,650
Ananda Sen: is the one which gives you the proc the diff gives you the or.

983
02:23:13,650 --> 02:23:16,440
Ananda Sen: So how do you how do you get.

984
02:23:16,440 --> 02:23:27,420
Ananda Sen: Direct property a gentleman the same statement as before, but throwing that estimate statement and again it's a label hd effect.

985
02:23:27,420 --> 02:23:34,170
Ananda Sen: Right it the same way as you did before see hd is to two categories one and.

986
02:23:34,170 --> 02:23:39,030
Ananda Sen: Just hate hd hd as if you're.

987
02:23:39,030 --> 02:23:48,570
Ananda Sen: estimating the coefficient between the hd acknowledged, but then add on that slash expedia.

988
02:23:48,570 --> 02:23:56,700
Ananda Sen: That will exponentially it see now if you run that that the very last.

989
02:23:56,700 --> 02:24:10,500
Ananda Sen: last page or last line last row it says exponential hdfs 3.3654 that should match my or estimate, which is right here.

990
02:24:10,500 --> 02:24:18,180
Ananda Sen: So you can directly get or estimate us in general, but you have to add that additional line.

991
02:24:18,180 --> 02:24:23,400
Ananda Sen: Can you do interaction between two categorical covariance and and yeah and.

992
02:24:23,400 --> 02:24:27,870
Ananda Sen: Of course you can do this.

993
02:24:27,870 --> 02:24:32,100
Ananda Sen: Through through prop free calls so.

994
02:24:32,100 --> 02:24:40,110
Ananda Sen: So so let's let's first talk about the interaction, but but, but before that, let me just.

995
02:24:40,110 --> 02:24:54,390
Ananda Sen: Stop here for a moment and let's see if you've got this one fine so any question about this Jen modern Logistics are the two two methods we are going to use for properties for.

996
02:24:54,390 --> 02:25:11,940
Ananda Sen: logistic regression logistic is useful for some specific forms and then model is a little bit more general that's all but.

997
02:25:11,940 --> 02:25:25,890
Okay, any any question any comment.

998
02:25:25,890 --> 02:25:30,480
Ananda Sen: let's talk a bit about interaction.

999
02:25:30,480 --> 02:25:42,720
Ananda Sen: I want to get the effect of two predictors controlling for each other so in proc freak the the interaction is obtained by just adding stars between the variables so.

1000
02:25:42,720 --> 02:26:01,680
Ananda Sen: Low birth weight smoking status and hd so so really I want to have the the the tables for lot smoking and hd stratified by the low birth weight status.

1001
02:26:01,680 --> 02:26:21,060
Ananda Sen: So you see it will it will create two tables so table one is to the right and that's for low equal to zero it's a table of cross classification of smoke by hd and for local to one you have a similar cross classified table.

1002
02:26:21,060 --> 02:26:33,960
Ananda Sen: How do you get the or how do you get the non smoker or, for example, of low associated with hd so the way you would do that is.

1003
02:26:33,960 --> 02:26:53,610
Ananda Sen: You create that odds ratio yourself how do you how do you create that if you if you look at it it's non smoker or of law so that means you're only going to look at the non smoking row which is the row corresponding to zero.

1004
02:26:53,610 --> 02:27:03,450
Ananda Sen: And just create that odds ratio, what is the odds ratio, while it's local 214 divided by three.

1005
02:27:03,450 --> 02:27:07,590
Ananda Sen: So for is here.

1006
02:27:07,590 --> 02:27:10,980
Ananda Sen: trees there.

1007
02:27:10,980 --> 02:27:22,380
Ananda Sen: Right, so it will be something like here you go.

1008
02:27:22,380 --> 02:27:33,270
Ananda Sen: And then divided by 25.

1009
02:27:33,270 --> 02:27:41,910
Ananda Sen: By three.

1010
02:27:41,910 --> 02:27:44,460
Ananda Sen: that's for non smoker.

1011
02:27:44,460 --> 02:27:47,250
Ananda Sen: For smoker.

1012
02:27:47,250 --> 02:27:52,080
Ananda Sen: You would have to use the row of one.

1013
02:27:52,080 --> 02:27:54,420
Ananda Sen: Three over two.

1014
02:27:54,420 --> 02:28:00,450
Ananda Sen: divided by 27 or 42 that will give you the smoker odds ratio.

1015
02:28:00,450 --> 02:28:05,370
Ananda Sen: of low associated with hd.

1016
02:28:05,370 --> 02:28:09,090
Ananda Sen: And that's 2.33.

1017
02:28:09,090 --> 02:28:17,490
Ananda Sen: So you can get interactions are our odds ratios of the two variables from proc frank.

1018
02:28:17,490 --> 02:28:23,250
Ananda Sen: There is a procedure called cochran mental handle test and that's.

1019
02:28:23,250 --> 02:28:36,540
Ananda Sen: that's studies association between two variables after adjusting for a third variable so kind of like the same thing as interaction basically.

1020
02:28:36,540 --> 02:28:43,380
Ananda Sen: So it provides odds ratios for each stream of smoking, as well as the combined odds ratio.

1021
02:28:43,380 --> 02:28:52,290
Ananda Sen: It also provides the test of homogeneity of odds ratio is named after to statisticians breslin day who proposed it.

1022
02:28:52,290 --> 02:29:11,760
Ananda Sen: Across and how do you get that well it's still prop frequency, but now you have got a bunch of options or stands for odds ratio blocks odds ratio plot stats that actually gives you the plots alone, but the real option is cma that's the Cochrane mental hansel test.

1023
02:29:11,760 --> 02:29:18,360
Ananda Sen: And if you do that, you get this sort of a graph so.

1024
02:29:18,360 --> 02:29:28,860
Ananda Sen: The first one, the 4.42 that's the same odds ratio, we got for smokers, I think, is it smokers.

1025
02:29:28,860 --> 02:29:31,200
Ananda Sen: Non smoker yeah.

1026
02:29:31,200 --> 02:29:37,620
Ananda Sen: And the other one the three point the 2.33 was for the for the smoker.

1027
02:29:37,620 --> 02:29:45,510
Ananda Sen: But now i've got a confidence interval too so it's a little more than just plugging in those numbers.

1028
02:29:45,510 --> 02:29:57,120
Ananda Sen: Now I haven't got two different tests, one is Cochrane mental handles statistics events test a test on the right, and then you also have the.

1029
02:29:57,120 --> 02:30:04,590
Ananda Sen: The breast load data test so let's try to figure out what is doing what.

1030
02:30:04,590 --> 02:30:14,850
Ananda Sen: breslow they test you're seeing that the the p value is 0.6025 this, by the way, is the p value of this is.

1031
02:30:14,850 --> 02:30:17,160
Ananda Sen: Always.

1032
02:30:17,160 --> 02:30:23,460
Ananda Sen: written in a very different way in each of them to probably bigger than guys good and so on, so forth.

1033
02:30:23,460 --> 02:30:31,770
Ananda Sen: And the other P value is this.

1034
02:30:31,770 --> 02:30:39,960
Ananda Sen: Point 030 that is significant, this is not so they must be doing different things.

1035
02:30:39,960 --> 02:31:17,730
Ananda Sen: Do you have any idea what their how how why their difference in P value is what are they doing what is what.

1036
02:31:17,730 --> 02:31:25,230
Ananda Sen: So the Cochrane mental handle is what what we were thinking that it's it's basically.

1037
02:31:25,230 --> 02:31:30,330
Ananda Sen: Trying to see overall if there is.

1038
02:31:30,330 --> 02:31:37,950
Ananda Sen: An association between the hypertension status and low birth weight controlling for smoke.

1039
02:31:37,950 --> 02:31:53,430
Ananda Sen: So it does kind of like the regression logistic regression but it's not quite logistic regression, so it just does the adjustment in a in a in a slightly different manner, but that's what it's doing.

1040
02:31:53,430 --> 02:32:00,300
Ananda Sen: So overall it says yeah if I control, for if I just for smoke I get.

1041
02:32:00,300 --> 02:32:03,120
Ananda Sen: A significant.

1042
02:32:03,120 --> 02:32:05,970
Ananda Sen: association between.

1043
02:32:05,970 --> 02:32:13,590
Ananda Sen: Between law and hd i'm just thinking, whether we've got.

1044
02:32:13,590 --> 02:32:20,520
I didn't run that model today.

1045
02:32:20,520 --> 02:32:22,500
Ananda Sen: um.

1046
02:32:22,500 --> 02:32:26,670
Ananda Sen: But then what is the breslow day test.

1047
02:32:26,670 --> 02:32:37,020
Ananda Sen: What does it do.

1048
02:32:37,020 --> 02:33:10,260
Ananda Sen: Anybody tell me.

1049
02:33:10,260 --> 02:33:14,640
Ananda Sen: This should be a hint homogeneity of odds ratio.

1050
02:33:14,640 --> 02:33:28,470
So does that mean.

1051
02:33:28,470 --> 02:33:33,960
Ananda Sen: ne ne ne sorry any guesses even if you don't understand.

1052
02:33:33,960 --> 02:33:48,990
Ananda Sen: what's your guess, given the words.

1053
02:33:48,990 --> 02:33:58,080
Geehan Suleyman: mean it is it says it's testing for homework done at to see how how much variation right or I don't know.

1054
02:33:58,080 --> 02:34:03,030
Ananda Sen: yeah yeah yeah home about homogeneity across what that was the question.

1055
02:34:03,030 --> 02:34:10,320
Ananda Sen: So you're right you're right it's trying to see if there is any difference, but difference across what.

1056
02:34:10,320 --> 02:34:11,640
Geehan Suleyman: It says odds ratio.

1057
02:34:11,640 --> 02:34:16,290
Ananda Sen: i'm not sure if that's yeah but odds ratios, of which two groups.

1058
02:34:16,290 --> 02:34:20,820
and

1059
02:34:20,820 --> 02:34:26,670
Ananda Sen: This and this right so smoker or nonsmoker.

1060
02:34:26,670 --> 02:34:38,700
Ananda Sen: So it looks at the odds ratio of the smoking group, it looks at the odds ratio of the non smoking room and then compares them so really compare this 4.432 2.33.

1061
02:34:38,700 --> 02:34:50,970
Ananda Sen: This is not that this is like a regression you adjust for smoking status it's like almost throwing in the two things in the model smoke and hd.

1062
02:34:50,970 --> 02:35:05,400
Ananda Sen: And then, trying to find out the odds ratio of hd overall adjusting for smoking status that's a subtle difference there is that this these two are slightly different type of.

1063
02:35:05,400 --> 02:35:09,900
Ananda Sen: calculation, because this is actually interaction test.

1064
02:35:09,900 --> 02:35:13,860
Ananda Sen: This is the overall main effect.

1065
02:35:13,860 --> 02:35:16,290
Ananda Sen: That makes sense.

1066
02:35:16,290 --> 02:35:28,230
Ananda Sen: i'm here i'm trying to test whether the odds ratio in the smoking group is the same as the non smoking group.

1067
02:35:28,230 --> 02:35:45,240
Ananda Sen: that's testing for smoking and hd interaction, this is testing whether there is an hd effect of L hd effect on the low birth weight adjusting for smoking.

1068
02:35:45,240 --> 02:35:54,240
Ananda Sen: So it's more like a regression problem.

1069
02:35:54,240 --> 02:36:00,240
Ananda Sen: Does that make sense, does that.

1070
02:36:00,240 --> 02:36:11,940
Christie Flanagan: yeah can you so, given the two results can you provide interpretation statements to help me understand a little bit better the difference.

1071
02:36:11,940 --> 02:36:14,940
Ananda Sen: So.

1072
02:36:14,940 --> 02:36:24,930
Christie Flanagan: We.

1073
02:36:24,930 --> 02:36:28,200
oops.

1074
02:36:28,200 --> 02:37:04,800
Police.

1075
02:37:04,800 --> 02:38:13,410
Ananda Sen: yeah so.

1076
02:38:13,410 --> 02:38:22,890
Ananda Sen: that's what this one is doing and the.

1077
02:38:22,890 --> 02:38:39,960
Ananda Sen: cma.

1078
02:38:39,960 --> 02:38:50,730
Ananda Sen: Sorry, I have to, I have to write it clearly or of hd versus non hd.

1079
02:38:50,730 --> 02:38:58,410
Ananda Sen: For smokers is same or different than or for non smoker see image testing testing for association.

1080
02:38:58,410 --> 02:39:01,560
Between.

1081
02:39:01,560 --> 02:39:05,400
Ananda Sen: Age hd are sorry.

1082
02:39:05,400 --> 02:39:36,810
Ananda Sen: Again, let me just make it clear.

1083
02:39:36,810 --> 02:39:46,230
Ananda Sen: So if bressler day test is a test for interaction see mh test is a test for just the main effect of age.

1084
02:39:46,230 --> 02:39:51,630
Christie Flanagan: Thank you.

1085
02:39:51,630 --> 02:39:55,320
Ananda Sen: Other questions about this.

1086
02:39:55,320 --> 02:40:16,500
Ananda Sen: This often happens because restarted test is a test for interaction, it is, it is often non significant where the overall test is significant so overall cms is significant essentially bressler days testing this 4.43 verses 2.33 are these two different.

1087
02:40:16,500 --> 02:40:22,440
Ananda Sen: Okay, and this one.

1088
02:40:22,440 --> 02:40:34,500
Ananda Sen: The the cma each test is all it is doing is it's just fitting a model, a gentleman type of thing not exactly gen one but regression model of low bar wet with.

1089
02:40:34,500 --> 02:40:40,860
Ananda Sen: hd and smoke that no interaction model just he and small.

1090
02:40:40,860 --> 02:40:49,020
Ananda Sen: So it is trying to look at the are for hd when smoke is in the model.

1091
02:40:49,020 --> 02:40:50,490
Ananda Sen: All right.

1092
02:40:50,490 --> 02:40:53,130
Ananda Sen: that's what it's.

1093
02:40:53,130 --> 02:40:59,190
Ananda Sen: that's why the differences.

1094
02:40:59,190 --> 02:41:02,730
Ananda Sen: Other questions.

1095
02:41:02,730 --> 02:41:06,690
Theresa Marie Kowalski-Dobson: Another more practical application question.

1096
02:41:06,690 --> 02:41:18,570
Theresa Marie Kowalski-Dobson: With a lot of these tests are they something that, as someone running this code, you would run every time to check, or is this something that you would just run in certain.

1097
02:41:18,570 --> 02:41:21,480
Theresa Marie Kowalski-Dobson: instances.

1098
02:41:21,480 --> 02:41:25,260
Ananda Sen: um.

1099
02:41:25,260 --> 02:41:28,410
Ananda Sen: I would probably do.

1100
02:41:28,410 --> 02:41:32,760
Ananda Sen: more of a.

1101
02:41:32,760 --> 02:41:39,660
Ananda Sen: model based analysis, so when I say model based analysis i'm talking about.

1102
02:41:39,660 --> 02:41:51,300
Ananda Sen: A regression model like a gen mode approx logistic, this is a this type of cms calculation is a little bit more basic.

1103
02:41:51,300 --> 02:41:55,230
Ananda Sen: And I would typically not.

1104
02:41:55,230 --> 02:41:57,840
Ananda Sen: Do it.

1105
02:41:57,840 --> 02:42:08,970
Ananda Sen: Unless unless I wanted to present the or or the combined or see this this this this has a combined or.

1106
02:42:08,970 --> 02:42:13,260
Ananda Sen: That is one thing which you don't get in general.

1107
02:42:13,260 --> 02:42:22,440
Ananda Sen: So if I have to do this kind of combined overall or across the two I mean combining after adjusting for smoking status.

1108
02:42:22,440 --> 02:42:34,560
Ananda Sen: Then, then I would I would do see image like this, but if I just wanted to do the association I would probably just go with a general with with a model based analysis so yeah.

1109
02:42:34,560 --> 02:42:35,910
Ananda Sen: That would be my.

1110
02:42:35,910 --> 02:43:00,360
Thanks.

1111
02:43:00,360 --> 02:43:04,650
Okay.

1112
02:43:04,650 --> 02:43:07,950
Ananda Sen: So.

1113
02:43:07,950 --> 02:43:22,230
Ananda Sen: This is actually this will explain a little bit more what I was trying to explain before, so it is the prob gentleman, and this is.

1114
02:43:22,230 --> 02:43:26,520
Ananda Sen: hd and smoke, both are in the model.

1115
02:43:26,520 --> 02:43:38,940
Ananda Sen: So estimated justin hd effect hd one minus one that is adjusting for smoking status and then of course exponential rating and so i'm getting there.

1116
02:43:38,940 --> 02:43:57,030
Ananda Sen: So, if you look at the the second table and look at the exponential adjusted at you would get that number 3.4214 and then that's that's exponential estimate.

1117
02:43:57,030 --> 02:44:03,750
Ananda Sen: And that exponential estimate is the adjusted or and and.

1118
02:44:03,750 --> 02:44:15,330
Ananda Sen: And the Chi square is point 0464 now that is compatible this this one.

1119
02:44:15,330 --> 02:44:20,820
Ananda Sen: is comparable.

1120
02:44:20,820 --> 02:44:43,440
Ananda Sen: To see him he not exactly the same test so let's see what what cma God, and this is the p value is point zero point, point 05010464 so I did we get for cma we got point 0380 and the value is point 4.3056 and that that is fine, because it's it's a little different.

1121
02:44:43,440 --> 02:44:49,470
Ananda Sen: way of calculating this this is non parametric and that one is more model based but.

1122
02:44:49,470 --> 02:44:54,570
Ananda Sen: But that's that's if you wanted understand this is, this is what we're doing.

1123
02:44:54,570 --> 02:44:56,010
Ananda Sen: For.

1124
02:44:56,010 --> 02:44:57,780
Ananda Sen: or see me.

1125
02:44:57,780 --> 02:45:02,880
Ananda Sen: If I did have an interaction, then the interaction would have been similar to.

1126
02:45:02,880 --> 02:45:06,990
Ananda Sen: The other one and we get started.

1127
02:45:06,990 --> 02:45:09,510
Ananda Sen: OK so.

1128
02:45:09,510 --> 02:45:14,070
Ananda Sen: Again, this goes through a whole bunch of interpretation.

1129
02:45:14,070 --> 02:45:18,090
Ananda Sen: For a non so one point minus 1.18.

1130
02:45:18,090 --> 02:45:35,040
Ananda Sen: that's an intercept intercept is only inevitable when smoking status and hdi are both zero to a non hypertensive in a non smoker mother, the odds of low birth weight child is exponential minus one point.

1131
02:45:35,040 --> 02:45:44,790
Ananda Sen: notice very carefully, I said, or they didn't say odds ratio, because that one is not odds ratio intercept is not odds ratio that's an odds.

1132
02:45:44,790 --> 02:46:03,840
Ananda Sen: And 0.31 which means, if you translate that into probability and you could do that by taking 0.31 divided by one plus 0.2 hundred 23.5% chance to wear a non smoker non hypertensive mother, the problem with low, but with child is 23.5%.

1133
02:46:03,840 --> 02:46:11,430
Ananda Sen: For a fixed hd status the odds ratio of smokers versus non smokers for low birth weight.

1134
02:46:11,430 --> 02:46:21,030
Ananda Sen: Is exponential 0.71 2.0 which is 2.03 fixed htc data so either hypertensive or non hypertensive.

1135
02:46:21,030 --> 02:46:33,750
Ananda Sen: And and that's that's like basically saying that smoking mothers have twice as much odds compared to the non smoking beers with the same hd status to have a little bit.

1136
02:46:33,750 --> 02:46:36,630
Okay.

1137
02:46:36,630 --> 02:46:48,840
Ananda Sen: and, similarly, for a fixed smoking status hypertensive mothers have 3.4 fold odds of having a low birth to a child complete.

1138
02:46:48,840 --> 02:46:52,140
Ananda Sen: So all you do is just take those.

1139
02:46:52,140 --> 02:46:55,530
Ananda Sen: coefficients and and.

1140
02:46:55,530 --> 02:47:04,290
Ananda Sen: And just exponential that this, by the way.

1141
02:47:04,290 --> 02:47:22,110
Ananda Sen: yeah, this is the same model, as this, so it is minus 1.17 1.23 and 0.7119.

1142
02:47:22,110 --> 02:47:27,180
Ananda Sen: You can do a con continuous exposure variable and then, of course, your.

1143
02:47:27,180 --> 02:47:37,650
Ananda Sen: Ex The explanation is for every year increase in age of mother, the odds of low birth weight decreases by 5% why the decreasing by 5%.

1144
02:47:37,650 --> 02:47:54,750
Ananda Sen: Because it's exponential minus 0.05 and that's a number, which is something like 95% and then, and then you subtract it from one you get 5% so it's a decrease.

1145
02:47:54,750 --> 02:47:59,370
Ananda Sen: For a given htm smoking status.

1146
02:47:59,370 --> 02:48:07,740
Ananda Sen: that's a brazen.

1147
02:48:07,740 --> 02:48:12,900
Theresa Marie Kowalski-Dobson: So, I guess, I have a question it doesn't surprise me, but.

1148
02:48:12,900 --> 02:48:19,050
Theresa Marie Kowalski-Dobson: Is there, like a high end to the scale so we're talking about obviously low birth weight and age of mother.

1149
02:48:19,050 --> 02:48:22,050
Theresa Marie Kowalski-Dobson: I forget the age variable so you can remind me here.

1150
02:48:22,050 --> 02:48:31,410
Theresa Marie Kowalski-Dobson: Like obviously I know there's like a great age for women to have children younger there's challenges older there's challenges does this go into the older range and talk about that, like.

1151
02:48:31,410 --> 02:48:39,360
Theresa Marie Kowalski-Dobson: Obviously, every five every increase in the year there's not going to be a better wait if you're like in your 50s right.

1152
02:48:39,360 --> 02:48:42,330
Ananda Sen: yeah I think that that's a great question actually.

1153
02:48:42,330 --> 02:48:48,390
Ananda Sen: I don't think this one I forget what the age ranges.

1154
02:48:48,390 --> 02:49:05,190
Ananda Sen: But I don't think it is going to be it's probably not gone beyond 40 or 45 or something like that in this data set and and that's part of the deal, because I think when you get into the.

1155
02:49:05,190 --> 02:49:08,040
Ananda Sen: More.

1156
02:49:08,040 --> 02:49:14,040
Ananda Sen: older women, that the it's possible that.

1157
02:49:14,040 --> 02:49:23,730
Ananda Sen: thoughts of low birth weight actually may not decrease now of course we're saying all of these things, but if you look at the p value it's and it's non significant.

1158
02:49:23,730 --> 02:49:35,700
Ananda Sen: But even if you try to interpret the the coefficient I think there is there is a there is a reason for this is happening because it's it's like you say it's a natural age range.

1159
02:49:35,700 --> 02:49:40,890
Ananda Sen: What we're considering and and also it is.

1160
02:49:40,890 --> 02:49:44,070
Ananda Sen: A small a small.

1161
02:49:44,070 --> 02:49:50,910
Ananda Sen: Change the nodes which is not even significant So those are the some some of the things which one needs to.

1162
02:49:50,910 --> 02:50:00,510
Ananda Sen: Take it yeah your point is very well taken I forget how much it is but i'm pretty sure that the upper end was not more than 50 for sure.

1163
02:50:00,510 --> 02:50:04,620
Christie Flanagan: It actually looks like it's mid 30s looking at the raw data.

1164
02:50:04,620 --> 02:50:07,830
Ananda Sen: Is that right Okay, well then it's even even the idea.

1165
02:50:07,830 --> 02:50:08,430
Theresa Marie Kowalski-Dobson: yeah.

1166
02:50:08,430 --> 02:50:13,320
Christie Flanagan: I think so youngest age was 1515.

1167
02:50:13,320 --> 02:50:15,690
Christie Flanagan: Thanks yeah so it makes sense, though.

1168
02:50:15,690 --> 02:50:20,130
Ananda Sen: yeah yeah then it just makes it.

1169
02:50:20,130 --> 02:50:22,530
Theresa Marie Kowalski-Dobson: yeah yeah.

1170
02:50:22,530 --> 02:50:28,230
Ananda Sen: yeah so so so to do that the things which you should ask yourself, when you.

1171
02:50:28,230 --> 02:50:39,780
Ananda Sen: were looking at this, I mean it's it's not that hard to actually run this any any of these programs, I mean once you get a hang of what you can get out of this and.

1172
02:50:39,780 --> 02:50:51,870
Ananda Sen: Just scored it it's if it's a few lines of code, but then, when you get the results, what do those results mean and how do you get what you want is is really.

1173
02:50:51,870 --> 02:50:59,370
Ananda Sen: 80% of the of the whole thing it's interpretation of what you have given your data.

1174
02:50:59,370 --> 02:51:02,730
yep that's it.

1175
02:51:02,730 --> 02:51:05,130
Ananda Sen: So here.

1176
02:51:05,130 --> 02:51:07,350
Ananda Sen: The next.

1177
02:51:07,350 --> 02:51:26,520
Ananda Sen: One shows how to read scale age and rescaling age is something I was talking about before since i'm wanting to increase suppose you want to do a five year increase and that again, you can use the estimate statement to do that and see how this is done.

1178
02:51:26,520 --> 02:51:41,790
Ananda Sen: For the regular or this is continuous data so for regular or one year increment is is denoted by the one and then at the very end before the.

1179
02:51:41,790 --> 02:51:50,520
Ananda Sen: slash X exponential and for the five year agreement just put in five there so it's it's actually quite simple and.

1180
02:51:50,520 --> 02:52:06,240
Ananda Sen: And you can get easily get those results so um so estimates state statement is is pretty useful in broken.

1181
02:52:06,240 --> 02:52:11,010
Ananda Sen: rescaling and shifting region.

1182
02:52:11,010 --> 02:52:27,120
Ananda Sen: So suppose I want to interpret the intercept minus 0.017 in this data, and as you saw that it is the law god's of a non smoker non hypertensive mother per age zero.

1183
02:52:27,120 --> 02:52:32,040
Ananda Sen: So again, if you want to make sense of this, you should.

1184
02:52:32,040 --> 02:52:37,140
Ananda Sen: standardize age are not necessarily standards but.

1185
02:52:37,140 --> 02:52:56,640
Ananda Sen: Center age, now we did was we did standardized the age we did Center the age and also make it a five year unit, so now, if I use that in my model eight standardized what do I get.

1186
02:52:56,640 --> 02:53:08,640
Ananda Sen: I get this get this numbers minus 1.2779112339 0.7009 minus 0.2521 and one and one that's the scale is not important.

1187
02:53:08,640 --> 02:53:16,710
Ananda Sen: Again, the smoke and he doesn't make any difference, they are the same as before they believe.

1188
02:53:16,710 --> 02:53:25,770
Ananda Sen: yeah see it's the age and the intercept that changed so.

1189
02:53:25,770 --> 02:53:43,380
Ananda Sen: So the intercept now is the law gods of bearing a low birth with child for a 25 year old mother because that's what he subtracted age so separate him from age who is non smoker and non hypertensive so that's the interesting.

1190
02:53:43,380 --> 02:53:52,650
Ananda Sen: The odds ratio associated with a five year increase in age is exponential minus 0.2521 which is 0.777 same as before.

1191
02:53:52,650 --> 02:53:57,420
Ananda Sen: seeing this little point 777 year that's.

1192
02:53:57,420 --> 02:54:00,480
that's.

1193
02:54:00,480 --> 02:54:14,430
Ananda Sen: So age variable if you divide by five that will give you that will give you a five year increments you can just throw that in the model and you get back.

1194
02:54:14,430 --> 02:54:20,970
Ananda Sen: On the equipment still the same as before.

1195
02:54:20,970 --> 02:54:25,110
Ananda Sen: So this one talks about.

1196
02:54:25,110 --> 02:54:28,950
Ananda Sen: polynomials of a continuous predictor that.

1197
02:54:28,950 --> 02:54:37,890
Ananda Sen: That sometimes can be used to model non linearity in the predictor or to remove multiple identity more, which is more relevant for integration.

1198
02:54:37,890 --> 02:54:46,470
Ananda Sen: there's one interesting thing happens in this particular problem age standardized square suppose I used that in the model to.

1199
02:54:46,470 --> 02:54:51,570
Ananda Sen: What happens is neither he nor eight Square.

1200
02:54:51,570 --> 02:54:54,000
Ananda Sen: Are are.

1201
02:54:54,000 --> 02:55:01,590
Ananda Sen: Already in the original model, they are not significant you look at the p value is the one is point 398, then the other is point 3108.

1202
02:55:01,590 --> 02:55:14,730
Ananda Sen: But if I used eight standardized suddenly the the the p value goes down to 0.0973 not significant still.

1203
02:55:14,730 --> 02:55:19,950
Ananda Sen: But standardization can actually.

1204
02:55:19,950 --> 02:55:25,260
Ananda Sen: Change the significance if it's the variable.

1205
02:55:25,260 --> 02:55:37,770
Ananda Sen: Although it looks like it's just a linear variable Why would it change, but it does does make a difference, because it is not a linear model this problem would not have made any difference if we're looking at a linear model.

1206
02:55:37,770 --> 02:55:44,460
Ananda Sen: In logistic regression model, it can make a difference, because the effect is not linear it's not only.

1207
02:55:44,460 --> 02:55:56,010
Ananda Sen: something to think about when you consider logistic regression models.

1208
02:55:56,010 --> 02:55:58,950
Okay.

1209
02:55:58,950 --> 02:56:07,980
Ananda Sen: Another thing I want to, I want to show this is this is something which is quite interesting actually.

1210
02:56:07,980 --> 02:56:12,330
Ananda Sen: I have a model for probabilities or for all odds.

1211
02:56:12,330 --> 02:56:19,890
Ananda Sen: And I want to predict the probabilities predict probabilities to understand the model.

1212
02:56:19,890 --> 02:56:41,070
Ananda Sen: How good are the the original model original data set and the fit the fit is based on the prediction, because when you predict a probably a particular subject to have or particular mother to have low birth weight to the predicted proud is 90%.

1213
02:56:41,070 --> 02:56:52,590
Ananda Sen: But do you find that the observed value for that mother is is not a lower then your model is not doing that.

1214
02:56:52,590 --> 02:56:59,310
Ananda Sen: So, so the predicted probability indirectly looks at the fit of the data.

1215
02:56:59,310 --> 02:57:04,200
Ananda Sen: But how are you going to do the prediction this model based predictions.

1216
02:57:04,200 --> 02:57:15,390
Ananda Sen: So it is, it is these are there are different ways of doing the predictions so so that's that's the part which I want to point out next.

1217
02:57:15,390 --> 02:57:27,900
Ananda Sen: There are 3232 main ways of doing the prediction, and then there is one which has got two different.

1218
02:57:27,900 --> 02:57:30,630
Ananda Sen: arm.

1219
02:57:30,630 --> 02:57:37,380
Ananda Sen: Some ways of doing the prediction so Ls means in probably gen mode is one of them.

1220
02:57:37,380 --> 02:57:55,680
Ananda Sen: So what is Ls means so considered a fitted model with agent race love odds low 0.3617 minus 0.395039575 minutes so so I have now used the race variable as.

1221
02:57:55,680 --> 02:58:00,720
Ananda Sen: an indicator of white white indicator in a black indicator right.

1222
02:58:00,720 --> 02:58:12,030
Ananda Sen: So I want to do an Ls means for white and associated standard error is estimated from this model holding age and it's observed me so let's try to do that.

1223
02:58:12,030 --> 02:58:27,330
Ananda Sen: So prop gen mode class race and then I do the usual model statement and then it's really an additional statement it says Ls means of race and, as do exponential and I do cl cl for confidence limits.

1224
02:58:27,330 --> 02:58:32,730
Ananda Sen: see what I get what I get is the least squares means.

1225
02:58:32,730 --> 02:58:40,110
Ananda Sen: minus minus 1.66 to zero point minus 0.3809.

1226
02:58:40,110 --> 02:58:45,210
Ananda Sen: And 0.5565 and so on and so forth, so what are these.

1227
02:58:45,210 --> 02:59:02,460
Ananda Sen: These are the estimated based on the model, the estimated means for those corresponding races and remember one is white two is black and three is other.

1228
02:59:02,460 --> 02:59:07,980
Ananda Sen: Okay, so these are the estimated.

1229
02:59:07,980 --> 02:59:11,430
Ananda Sen: um.

1230
02:59:11,430 --> 02:59:14,250
Where is the.

1231
02:59:14,250 --> 02:59:29,970
Ananda Sen: Ah, I shouldn't be looking at this, this is the odds ratio.

1232
02:59:29,970 --> 02:59:43,980
Ananda Sen: are actually odds not odds ratio, but odds.

1233
02:59:43,980 --> 03:00:00,390
Ananda Sen: OK, so the odds are if if there's a white mother, the odds of low birth weight is 0.32 odds of low birth weight with the black mother is 0.68 and four other is 0.57.

1234
03:00:00,390 --> 03:00:05,460
Ananda Sen: And then you get also the the the.

1235
03:00:05,460 --> 03:00:09,960
Ananda Sen: Confidence limits the lower and upper.

1236
03:00:09,960 --> 03:00:21,720
Ananda Sen: So Ellis means actually provides you with predicted probabilities are actually in this case it's the predicted odds.

1237
03:00:21,720 --> 03:00:25,260
Ananda Sen: off.

1238
03:00:25,260 --> 03:00:29,160
Ananda Sen: of a low birth weight babies.

1239
03:00:29,160 --> 03:00:32,820
Ananda Sen: that's one way of doing the prediction.

1240
03:00:32,820 --> 03:00:39,420
Ananda Sen: 32% 68% 57%.

1241
03:00:39,420 --> 03:00:53,670
Ananda Sen: All right, and then there is a there is a prediction using margins, this is an interesting option in SAS and.

1242
03:00:53,670 --> 03:01:06,540
Ananda Sen: For none of you have used data before so so in data, there is something called post estimation command margins which is very, very popular stay city users love it.

1243
03:01:06,540 --> 03:01:10,050
Ananda Sen: Because this is doing.

1244
03:01:10,050 --> 03:01:15,960
Ananda Sen: The prediction in a very flexible way.

1245
03:01:15,960 --> 03:01:18,540
Ananda Sen: The.

1246
03:01:18,540 --> 03:01:26,490
Ananda Sen: SAS users, for a long time didn't have this in built in Prague gen or anything else.

1247
03:01:26,490 --> 03:01:39,390
Ananda Sen: It still doesn't, but there is this this I don't know how many of you have been ever exposed to the concept of macro in SAS so macros are.

1248
03:01:39,390 --> 03:01:53,730
Ananda Sen: User written programs, which are add on to to the main procedures and in the way to do this would you usually download it from the SAS website and.

1249
03:01:53,730 --> 03:02:13,740
Ananda Sen: Quality using and percent in include statement so here is an example, so I included, and this is, this is my entire path and there was a margins of SAS This is also available in the.

1250
03:02:13,740 --> 03:02:15,780
In the.

1251
03:02:15,780 --> 03:02:21,090
Ananda Sen: Software codes folder and then.

1252
03:02:21,090 --> 03:02:25,710
Ananda Sen: Then you call this function it's a function.

1253
03:02:25,710 --> 03:02:30,000
Ananda Sen: So, because it's a function it doesn't end with a semi colon.

1254
03:02:30,000 --> 03:02:33,900
Ananda Sen: It is basically.

1255
03:02:33,900 --> 03:02:39,510
Ananda Sen: Data you call the data class responses low.

1256
03:02:39,510 --> 03:02:53,340
Ananda Sen: Again, our options is the event option so event equal to one is the option, you will specify the distribution binomial and in the model, you have to corporates agent race.

1257
03:02:53,340 --> 03:03:03,720
Ananda Sen: You want the margins over race which means you want a particular properties for each of the races and the options and just put in conference limit.

1258
03:03:03,720 --> 03:03:12,030
Ananda Sen: So get those numbers estimate point 246 9.46 9.3635 What are those.

1259
03:03:12,030 --> 03:03:33,600
Ananda Sen: So let's understand this, these are the average predicted probabilities of low birth weight at each level of race, calculated using the observed values, of the other predictor variables so let's take an example, so race one is white.

1260
03:03:33,600 --> 03:03:58,770
Ananda Sen: So point 2469 is the predicted proportion of low birth weight babies if everyone in the sample were white and having the observed ages.

1261
03:03:58,770 --> 03:04:00,300
Ananda Sen: So.

1262
03:04:00,300 --> 03:04:03,270
Ananda Sen: We have a model.

1263
03:04:03,270 --> 03:04:07,050
Ananda Sen: That has an age coefficient.

1264
03:04:07,050 --> 03:04:10,260
Ananda Sen: and say.

1265
03:04:10,260 --> 03:04:19,140
Ananda Sen: We have eight coefficient, meaning a minute each each square feet in an age of.

1266
03:04:19,140 --> 03:04:25,770
Ananda Sen: Age variable and in that model.

1267
03:04:25,770 --> 03:04:28,860
Ananda Sen: If everybody.

1268
03:04:28,860 --> 03:04:30,600
Ananda Sen: Had.

1269
03:04:30,600 --> 03:04:53,970
Ananda Sen: were in in that model where white, then the predicted proportion of low birth weight is just going to be simply using the model for using the age coefficient but putting in in the model white equal to one for each other.

1270
03:04:53,970 --> 03:04:58,860
Okay.

1271
03:04:58,860 --> 03:05:01,530
Ananda Sen: So.

1272
03:05:01,530 --> 03:05:14,730
Ananda Sen: So that would be the predicted probability average predicted probabilities of low back to it at each level of race, calculated using the observed values, of the other variables.

1273
03:05:14,730 --> 03:05:16,590
Ananda Sen: When.

1274
03:05:16,590 --> 03:05:27,840
Ananda Sen: When you look at the black, then you do exactly the same thing, but this time thing that everybody in this sample is black.

1275
03:05:27,840 --> 03:05:31,740
alright.

1276
03:05:31,740 --> 03:05:38,910
Ananda Sen: so effectively could say.

1277
03:05:38,910 --> 03:05:48,300
Ananda Sen: That it, but I mean the other other thing is that initial.

1278
03:05:48,300 --> 03:05:52,440
Ananda Sen: arm yes.

1279
03:05:52,440 --> 03:05:56,220
Ananda Sen: There is a different way of doing this to.

1280
03:05:56,220 --> 03:06:00,810
Ananda Sen: You could use the option at means.

1281
03:06:00,810 --> 03:06:09,960
Ananda Sen: Then we get pretty proud is a low birth weight at each level of race, holding age at it's me.

1282
03:06:09,960 --> 03:06:17,130
Ananda Sen: So for each of those levels suppose you take the mean age and use that equation.

1283
03:06:17,130 --> 03:06:25,890
Ananda Sen: Then what you get is is that are those estimates.

1284
03:06:25,890 --> 03:06:27,870
Okay.

1285
03:06:27,870 --> 03:06:37,950
Ananda Sen: it's not it's subtle it's not easy but but it, roughly speaking, you could very roughly you could say that well.

1286
03:06:37,950 --> 03:06:45,390
Ananda Sen: An average age, the chances are about 25% that.

1287
03:06:45,390 --> 03:06:47,850
Ananda Sen: That.

1288
03:06:47,850 --> 03:06:59,280
Ananda Sen: That that a white mother, will give right give birth to a little bit would be about 48.5% for a black mother about 36.4% for.

1289
03:06:59,280 --> 03:07:07,950
Ananda Sen: Mother in other race category.

1290
03:07:07,950 --> 03:07:12,960
Ananda Sen: So these are.

1291
03:07:12,960 --> 03:07:31,410
Ananda Sen: At age, probably low and predict so at the age is the mean age is 23.2381.

1292
03:07:31,410 --> 03:07:34,560
Ananda Sen: All right, this one, you have to.

1293
03:07:34,560 --> 03:07:39,000
Ananda Sen: read through a little bit more.

1294
03:07:39,000 --> 03:07:44,340
Ananda Sen: This is slightly more complicated than the rest we have talked about.

1295
03:07:44,340 --> 03:07:52,950
Ananda Sen: But this is a way to do prediction prediction of probability of of having a low birth with across.

1296
03:07:52,950 --> 03:08:02,580
Ananda Sen: categories of a variable.

1297
03:08:02,580 --> 03:08:17,370
Right.

1298
03:08:17,370 --> 03:08:27,960
Ananda Sen: How about interaction or interaction, here we have age small hd eight star hd.

1299
03:08:27,960 --> 03:08:39,780
Ananda Sen: So what is the age where efficient here represents minus 0.0621 that represent the log odds ratio of low birth weight for non hypertensive mothers.

1300
03:08:39,780 --> 03:08:43,650
Ananda Sen: For every year increase in mother's age.

1301
03:08:43,650 --> 03:08:51,510
Ananda Sen: The odds of low birth weight for non hd mother is 6%.

1302
03:08:51,510 --> 03:08:58,740
Ananda Sen: Lower 6% lower.

1303
03:08:58,740 --> 03:09:06,420
Ananda Sen: 6% lower than one so it's been lower than what this one lower than hd and the one who is hypertensive.

1304
03:09:06,420 --> 03:09:20,100
Ananda Sen: So the larger issue, the provision of minus 0.0621 is a long odds ratio of low birth weight for non hypertensive mothers, for every year increase in mother's age.

1305
03:09:20,100 --> 03:09:22,350
Okay.

1306
03:09:22,350 --> 03:09:36,840
Ananda Sen: That means the only way, you can interpret this minus 0.0621 is only at the reference category for each team, which is non non hd.

1307
03:09:36,840 --> 03:09:40,740
Ananda Sen: Because we have interaction.

1308
03:09:40,740 --> 03:09:52,170
Ananda Sen: Similarly, you can do an odds of a low budget per child for hd mother compared to non hd mother that's equal to minus 5.83 5.13.

1309
03:09:52,170 --> 03:10:07,980
Ananda Sen: But again Lo and behold, I didn't do anything with age so age is still the reference category or the baseline category for ages zero and that's odd so all subtract 25 from it.

1310
03:10:07,980 --> 03:10:14,700
Ananda Sen: And then rerun this, so the only thing that will change is is.

1311
03:10:14,700 --> 03:10:16,680
Ananda Sen: The.

1312
03:10:16,680 --> 03:10:24,300
Ananda Sen: hd variable because hd now is a difference between hd and non hd.

1313
03:10:24,300 --> 03:10:27,030
Ananda Sen: that's a log log loads.

1314
03:10:27,030 --> 03:10:31,980
Ananda Sen: loads of hd versus non hd.

1315
03:10:31,980 --> 03:10:39,390
Ananda Sen: That for for somebody with age 25 so what happened is the mother of age 25 has.

1316
03:10:39,390 --> 03:10:47,250
Ananda Sen: nearly seven times it's wonderful 1.9276 hybrids and a non hypertensive mother of age 25 of having a little bit.

1317
03:10:47,250 --> 03:10:54,000
Ananda Sen: Now it makes a lot more clinical sense.

1318
03:10:54,000 --> 03:10:58,620
Ananda Sen: Then you do the other interaction other interpretations.

1319
03:10:58,620 --> 03:11:12,540
Ananda Sen: interaction is sorry intercept is odds of a non hypertensive non smoker mother foods 25.

1320
03:11:12,540 --> 03:11:26,190
Ananda Sen: And this is ratio of all this is a good one and increasing hd to the order associated with one year in prison nh T mothers is exponential 0.2 1.3 this, we have seen before.

1321
03:11:26,190 --> 03:11:37,290
Ananda Sen: This particular example waves.

1322
03:11:37,290 --> 03:11:45,780
Ananda Sen: So there's another example of margin so you can look through this.

1323
03:11:45,780 --> 03:11:47,490
Ananda Sen: alright.

1324
03:11:47,490 --> 03:11:51,450
Ananda Sen: Before going into hypothesis test that's the.

1325
03:11:51,450 --> 03:12:03,300
Ananda Sen: second week left in this in this discussion, let me.

1326
03:12:03,300 --> 03:12:32,700
Ananda Sen: me pause for a moment, see if there are questions.

1327
03:12:32,700 --> 03:12:50,310
Ananda Sen: yeah.

1328
03:12:50,310 --> 03:12:54,000
Ananda Sen: So statistical inference.

1329
03:12:54,000 --> 03:12:56,040
Ananda Sen: To understand this.

1330
03:12:56,040 --> 03:13:00,000
Ananda Sen: First let's understand what the.

1331
03:13:00,000 --> 03:13:06,780
Ananda Sen: What the model looks like So what is the binomial distribution binomial distribution is a cow.

1332
03:13:06,780 --> 03:13:23,880
Ananda Sen: We are tossing a coin many times and we are trying to figure out how many heads are there that's binomial we are sampling individuals and trying to figure out how many of them are diabetic that's binomial.

1333
03:13:23,880 --> 03:13:27,150
Ananda Sen: We are trying to sample.

1334
03:13:27,150 --> 03:13:29,550
Ananda Sen: A whole lot of.

1335
03:13:29,550 --> 03:13:41,910
Ananda Sen: birds and then like birds and trying to count how many of them are low birth weight that's account so all of these follow binomial distribution.

1336
03:13:41,910 --> 03:13:47,550
Ananda Sen: And it's it's just a.

1337
03:13:47,550 --> 03:14:08,400
Ananda Sen: it's it's important to understand that the binomial distribution or binomial random variable is a random variable so it does have a certain probability structure, and if that has a property structure what it does have is is a way of writing out the probability, which is called the likely.

1338
03:14:08,400 --> 03:14:16,410
Ananda Sen: So likelihood function is a function of the parameter.

1339
03:14:16,410 --> 03:14:20,730
Ananda Sen: Which is the probability of the observed data.

1340
03:14:20,730 --> 03:14:35,400
Ananda Sen: So you can plot that function as a function of the parameter be and try to maximize find out based on your data, what would be the maximum plausible them for me.

1341
03:14:35,400 --> 03:14:43,440
Ananda Sen: If you can find that out, then that would be your what we call the maximum likelihood estimate.

1342
03:14:43,440 --> 03:15:06,660
Ananda Sen: So, for example, if you vote go to a logistic regression, then you can write out the likelihood function as a function of some of these so suppose your data shows three data points X is a 50 year old 20 year old 25 year old and the live birth outcome is one one and zero so.

1343
03:15:06,660 --> 03:15:15,720
Ananda Sen: What is the probability of having a life word for the first woman that's the first square bracket the second one that's a 50 year old.

1344
03:15:15,720 --> 03:15:27,540
Ananda Sen: Second square bracket is for the 20 year old the third square bracket is for the 25 year old it looks different because then the third case the outcome was zero.

1345
03:15:27,540 --> 03:15:41,340
Ananda Sen: And if you calculate this as a likelihood maximize this with respect to beta and are in beta one you'd end up getting better not had is minus 1.44 and we don't want head is 0.07.

1346
03:15:41,340 --> 03:15:47,580
Ananda Sen: Those are called maximum likelihood estimates because it's based on.

1347
03:15:47,580 --> 03:15:51,960
Ananda Sen: What is the latest on the likelihood function, based on your data.

1348
03:15:51,960 --> 03:15:56,460
Ananda Sen: Your data is that why you next pair the three bears.

1349
03:15:56,460 --> 03:16:06,090
Ananda Sen: And you write out the function, the likelihood function, based on the probability distribution, which is, in this case of binomial distribution.

1350
03:16:06,090 --> 03:16:20,670
Ananda Sen: maximize the parameters based on that function and you end up getting what are called the maximum likelihood estimates every time you run a gen mode, it shows analysis of maximum likelihood estimates Well, this is the maximum like.

1351
03:16:20,670 --> 03:16:25,770
Ananda Sen: And you can extend this to multiple logistic regression when there are multiple many, many, many, many.

1352
03:16:25,770 --> 03:16:46,500
Ananda Sen: Many, many, many, many axes essentially what you're doing is, you have a you have a graph you have a curve on the likelihood function and he tried to get that peak the corresponding beta had which is going to be a function of the data is is what is called a maximum like.

1353
03:16:46,500 --> 03:16:55,140
Ananda Sen: Okay, the next few slides talk about interval estimation for odds ratios and stuff like that which i'm not going to.

1354
03:16:55,140 --> 03:16:58,440
Ananda Sen: Look at much.

1355
03:16:58,440 --> 03:17:17,460
Ananda Sen: In the low birth weight data you do see those confidence intervals and those you can actually do the calculation yourself, would you don't have to and the walled confidence limits are given in the output, this is this is from project mode.

1356
03:17:17,460 --> 03:17:19,440
Ananda Sen: So.

1357
03:17:19,440 --> 03:17:37,680
Ananda Sen: that's that and the odds ratio is they asked for odds ratio I don't remember it now, but anyway, the odds ratio is 3.4347 and 1.01 and 11.5 992 things.

1358
03:17:37,680 --> 03:17:47,460
Ananda Sen: So essentially it's 1.017 11.60.

1359
03:17:47,460 --> 03:17:54,300
Ananda Sen: that's the so we have, we can see a 95% font and the true or four H T.

1360
03:17:54,300 --> 03:18:07,470
Ananda Sen: Is in the interval 1.017 11.60 there are many implications of that one implication is indeed the odds ratio is more than one.

1361
03:18:07,470 --> 03:18:17,640
Ananda Sen: Which means hypertensive mothers are significantly more likely to have a low birth weight baby.

1362
03:18:17,640 --> 03:18:28,410
Ananda Sen: When it's a significantly I think of 5% level of confidence 5% level of significance so P value is definitely going to be less than 0.05.

1363
03:18:28,410 --> 03:18:30,900
Ananda Sen: that's one thing.

1364
03:18:30,900 --> 03:18:36,330
Ananda Sen: The second thing is.

1365
03:18:36,330 --> 03:18:38,970
Ananda Sen: um.

1366
03:18:38,970 --> 03:18:52,860
Ananda Sen: What what does it mean to say that this is a 95% confidence interval what does it mean to say we're 95% confident.

1367
03:18:52,860 --> 03:18:57,270
Ananda Sen: Can anybody explain to me it's not really so much.

1368
03:18:57,270 --> 03:19:05,040
Ananda Sen: about the or it's true for anything because we talked about 95% conscious and all the time.

1369
03:19:05,040 --> 03:19:19,170
Ananda Sen: What does it mean.

1370
03:19:19,170 --> 03:19:24,960
Marcelo Galafassi: It will be true if I have the time, whatever it is, you know the 95%.

1371
03:19:24,960 --> 03:19:26,340
Ananda Sen: What do you, what do you see.

1372
03:19:26,340 --> 03:19:28,260
Ananda Sen: yeah when you say 95% of the.

1373
03:19:28,260 --> 03:19:33,690
times.

1374
03:19:33,690 --> 03:19:38,040
Ananda Sen: What does it really mean.

1375
03:19:38,040 --> 03:19:43,560
Marcelo Galafassi: That, if you run the scenario 100 times five times are going to be.

1376
03:19:43,560 --> 03:19:47,790
Marcelo Galafassi: True, and five times are not going to be what.

1377
03:19:47,790 --> 03:19:49,380
Marcelo Galafassi: later.

1378
03:19:49,380 --> 03:19:49,860
Ananda Sen: Right.

1379
03:19:49,860 --> 03:20:07,800
Ananda Sen: So, when you say 95 of those hundred times you're actually very close to the right answer but i'm just trying to understand when you say that when you run it 100% 100 times 95 of those hundred times it's.

1380
03:20:07,800 --> 03:20:13,320
Ananda Sen: going to be to what is going to be true.

1381
03:20:13,320 --> 03:20:16,230
Marcelo Galafassi: Like on this case.

1382
03:20:16,230 --> 03:20:19,500
Marcelo Galafassi: The five year increase.

1383
03:20:19,500 --> 03:20:22,980
Marcelo Galafassi: By Carol do within the the.

1384
03:20:22,980 --> 03:20:27,510
Marcelo Galafassi: The 19 95% and they're both like I don't know.

1385
03:20:27,510 --> 03:20:28,170
Ananda Sen: No, no, no.

1386
03:20:28,170 --> 03:20:34,170
Ananda Sen: you're you're absolutely right, but but, but the only only little.

1387
03:20:34,170 --> 03:20:56,160
Ananda Sen: Careful interpretation is that this 1.017 and i'm actually talking about just this first statement we're 95% confident that true or four H DS and then for 1.017160 okay so.

1388
03:20:56,160 --> 03:21:01,470
Geehan Suleyman: 95% of the time, your values are going to fall within that interval.

1389
03:21:01,470 --> 03:21:04,560
Ananda Sen: Within the 1.0177160.

1390
03:21:04,560 --> 03:21:10,050
Geehan Suleyman: With I think that's what we're it's within that.

1391
03:21:10,050 --> 03:21:12,090
Geehan Suleyman: The two intervals.

1392
03:21:12,090 --> 03:21:15,090
Ananda Sen: So, so the so the two numbers, you see, on the screen right.

1393
03:21:15,090 --> 03:21:18,060
Geehan Suleyman: yeah okay.

1394
03:21:18,060 --> 03:21:20,820
Ananda Sen: um.

1395
03:21:20,820 --> 03:21:24,690
Ananda Sen: So.

1396
03:21:24,690 --> 03:21:29,550
Ananda Sen: Remember, these are two numbers to fix numbers.

1397
03:21:29,550 --> 03:21:34,140
Ananda Sen: And the true or would you do not know.

1398
03:21:34,140 --> 03:21:41,010
Ananda Sen: But let's say that's that's that's the order for the population that's also a fixed number.

1399
03:21:41,010 --> 03:21:44,490
Ananda Sen: So.

1400
03:21:44,490 --> 03:21:52,020
Ananda Sen: So let's say my true or is.

1401
03:21:52,020 --> 03:21:55,380
Ananda Sen: 15.

1402
03:21:55,380 --> 03:22:09,990
Ananda Sen: Now, is it not awkward to say that 15 falls between 1.017 11.6 95% of the times and the remaining papers and other times it's outside it's always outside.

1403
03:22:09,990 --> 03:22:22,350
Ananda Sen: Or if my odds ratio is the true odds ratio is 10 it always falls between 1.01716.

1404
03:22:22,350 --> 03:22:25,590
Ananda Sen: So what i'm trying to get at is that.

1405
03:22:25,590 --> 03:22:31,680
Ananda Sen: The concept of 95% confidence interval is really a concept.

1406
03:22:31,680 --> 03:22:38,430
Ananda Sen: don't pay attention to the 1.0179160 That is exactly.

1407
03:22:38,430 --> 03:22:43,860
Ananda Sen: What confuses most of the people.

1408
03:22:43,860 --> 03:22:53,160
Ananda Sen: What marcella said is is right, if you run this experiment hundred times.

1409
03:22:53,160 --> 03:22:57,930
Ananda Sen: Set aside your true.

1410
03:22:57,930 --> 03:23:00,960
Ananda Sen: odds ratio, which you do not know what it is.

1411
03:23:00,960 --> 03:23:11,670
Ananda Sen: But if you run this experiment hundred times each time you get a different confidence interval because the data will be different.

1412
03:23:11,670 --> 03:23:18,900
Ananda Sen: So there will be hundred confidence intervals, he would actually create.

1413
03:23:18,900 --> 03:23:34,650
Ananda Sen: Out of those hundred conference intervals there your you have faith in the procedure, said that 95 of those hundred confidence intervals will capture the true a true or.

1414
03:23:34,650 --> 03:23:39,960
Ananda Sen: Which 95 you don't know.

1415
03:23:39,960 --> 03:23:42,570
Ananda Sen: You hope that this is one of them.

1416
03:23:42,570 --> 03:23:50,250
Ananda Sen: The 1.017 number six is one of them, you hope so.

1417
03:23:50,250 --> 03:23:53,400
Ananda Sen: But this is just one one data point.

1418
03:23:53,400 --> 03:23:59,280
Ananda Sen: without knowing the 99 other data points you would never be able to and without knowing the actual.

1419
03:23:59,280 --> 03:24:09,000
Ananda Sen: parameter value you'll never be able to see but but, but your procedure is such that ensures that 95%, of course, given the model is correct.

1420
03:24:09,000 --> 03:24:19,470
Ananda Sen: It will capture it 95% of 100% it's not an easy concept and when people talk about parties the devil's all the time, every single.

1421
03:24:19,470 --> 03:24:32,490
Ananda Sen: Statistical inference P value is associated with the conference in devil journals always say give us a bit of margin, give us the p value and sorry give us the conference intervals, what is it what does it really mean.

1422
03:24:32,490 --> 03:24:36,840
Ananda Sen: It is really a process.

1423
03:24:36,840 --> 03:24:42,600
Ananda Sen: is really a process.

1424
03:24:42,600 --> 03:24:44,760
Ananda Sen: That.

1425
03:24:44,760 --> 03:24:54,120
Ananda Sen: it's not an easy thing to understand, but it's a it, hopefully, hopefully, you, you are all saying it the right way it's just.

1426
03:24:54,120 --> 03:24:56,970
Ananda Sen: Getting there but.

1427
03:24:56,970 --> 03:25:03,450
Ananda Sen: But it's important understand that these but particular pair of numbers.

1428
03:25:03,450 --> 03:25:06,840
Ananda Sen: Actually, are less important.

1429
03:25:06,840 --> 03:25:18,540
Ananda Sen: As far as this this 95% is not associated with these two numbers there's 95% is associated with the process itself.

1430
03:25:18,540 --> 03:25:20,670
Ananda Sen: That makes sense.

1431
03:25:20,670 --> 03:25:29,730
Ananda Sen: But at least.

1432
03:25:29,730 --> 03:25:33,960
Ananda Sen: This, by the way, shows some calculations which.

1433
03:25:33,960 --> 03:25:42,840
Ananda Sen: we're going to worry about too much, but.

1434
03:25:42,840 --> 03:25:57,930
Ananda Sen: Given the time, let me just.

1435
03:25:57,930 --> 03:26:04,020
Ananda Sen: So.

1436
03:26:04,020 --> 03:26:09,840
Ananda Sen: How do you feel today.

1437
03:26:09,840 --> 03:26:10,800
Ananda Sen: sound like.

1438
03:26:10,800 --> 03:26:23,490
Ananda Sen: Yesterday, better than yesterday good i'm glad that you said that because, because today we are actually dealing with a little bit more complex stuff but at the same time.

1439
03:26:23,490 --> 03:26:33,690
Ananda Sen: logistic regression is is is more bread and butter for for applied applications, I mean that's that's more common.

1440
03:26:33,690 --> 03:26:42,570
Ananda Sen: And we'll be doing some very cool stuff there are a C curve and analytics a propensity matching and those Those sort of stuff so so you'll learn a lot so.

1441
03:26:42,570 --> 03:26:57,180
Theresa Marie Kowalski-Dobson: yeah I wasn't like I wasn't say, for me, I feel like i've learned about this stuff through a very heavy social science lens so you learn about like more conceptually what this stuff does and how it works and.

1442
03:26:57,180 --> 03:27:04,140
Theresa Marie Kowalski-Dobson: I, personally, I don't know how everyone else feels I personally feel like you're kind of doing it from a statistical math.

1443
03:27:04,140 --> 03:27:11,790
Theresa Marie Kowalski-Dobson: Which is like what the class is for right so i'm just trying to match those two things in my head, you know the math with the social science understanding so.

1444
03:27:11,790 --> 03:27:22,140
Theresa Marie Kowalski-Dobson: Sometimes it takes a little while to catch up, but i'm trying to that's why the examples are so helpful because I feel like it brings it full circle for me and i'm like oh that makes sense, so.

1445
03:27:22,140 --> 03:27:29,490
Ananda Sen: yeah and and i'm i'm really believe me i'm i'm i'm actually trying to de emphasize the math is my favorite candy.

1446
03:27:29,490 --> 03:27:41,040
Ananda Sen: I don't think this class is for that, I mean we have, as I said, we have a full semester of categorical data, where we talk about logistic regression effectively essentially all the.

1447
03:27:41,040 --> 03:27:59,610
Ananda Sen: All the class and then, of course, something else still but what what is what is important is for you to see what's actually happening without necessarily having to go into the details of what the math is but more like some of the stuff, for example.

1448
03:27:59,610 --> 03:28:05,670
Ananda Sen: The software is always a black box, it does something in the background.

1449
03:28:05,670 --> 03:28:07,500
Ananda Sen: What does it do.

1450
03:28:07,500 --> 03:28:11,400
Ananda Sen: So so as an applied statistician epidemiologist I think.

1451
03:28:11,400 --> 03:28:19,080
Ananda Sen: I think you need to know what what how to interpret things and I that's why i'm emphasizing a lot more on interpretation.

1452
03:28:19,080 --> 03:28:37,650
Ananda Sen: You see an output and see what it means and and how to interpret that and and suppose you want to find you want to investigate something something else which is not just running a model, how do you do, that what, what are the things and then.

1453
03:28:37,650 --> 03:28:40,230
yeah.

1454
03:28:40,230 --> 03:28:45,150
Ananda Sen: And how do you how do you reconcile with that.

1455
03:28:45,150 --> 03:28:49,590
Ananda Sen: And also, many of you are doing going in the PhD program I think.

1456
03:28:49,590 --> 03:28:53,310
Ananda Sen: Part of the research is like that it's it's.

1457
03:28:53,310 --> 03:29:02,730
Ananda Sen: The thing which you see in front of your eyes and then the thing which you want to know about how to go about and stuff like that.

1458
03:29:02,730 --> 03:29:15,630
Ananda Sen: So yeah five days is just barely scratching the surface, not even that time for that, but, but hopefully some of like what you're saying there is that what you learn before.

1459
03:29:15,630 --> 03:29:26,790
Ananda Sen: That the connection starts coming and that's why I will encourage questions whenever you have questions and you want to see try to think about.

1460
03:29:26,790 --> 03:29:43,980
Ananda Sen: Instances you have used this before and try to see well I used it maybe maybe that's what I was trying to do here what how do I go about or things you have asked before yourself that I have so many corporates what do I do with those.

1461
03:29:43,980 --> 03:29:54,780
Ananda Sen: I have three different ways of doing this thing and which one does what and and if they give different results, which is often the case in statistics.

1462
03:29:54,780 --> 03:29:59,340
Ananda Sen: Which one do I choose or do I choose one.

1463
03:29:59,340 --> 03:30:11,310
Ananda Sen: and not a combination of me so things like those asked questions hey let's have discussions i'm not so much worried about the material the material, you will have them anyway.

1464
03:30:11,310 --> 03:30:30,240
Ananda Sen: And I have always been open to my students my students who I taught five years back, still ask me questions send me emails i'm always open so so that's that's, this is not going to end here, by any means.

1465
03:30:30,240 --> 03:30:39,750
Mehrdad Motamed: So we can bind you up to five years is it.

1466
03:30:39,750 --> 03:30:41,400
Ananda Sen: Sure, why not.

1467
03:30:41,400 --> 03:30:48,450
Ananda Sen: In fact, in your case i'm on campus said sorry.

1468
03:30:48,450 --> 03:30:50,880
Geehan Suleyman: To SAS.

1469
03:30:50,880 --> 03:30:58,260
Ananda Sen: um that's a good question, I can find out, I think the way they have worked out the arrangement is.

1470
03:30:58,260 --> 03:31:00,840
Ananda Sen: i'm probably a month.

1471
03:31:00,840 --> 03:31:02,490
Ananda Sen: that's that's i'm just.

1472
03:31:02,490 --> 03:31:05,880
Ananda Sen: Throwing that number out, it could be longer.

1473
03:31:05,880 --> 03:31:08,400
Ananda Sen: and

1474
03:31:08,400 --> 03:31:13,350
Ananda Sen: Ultimately, if you think you're going to use the set you SAAs then it's probably a.

1475
03:31:13,350 --> 03:31:23,970
Ananda Sen: best idea to just go and purchase one either through your institution or through some mechanism.

1476
03:31:23,970 --> 03:31:25,770
Ananda Sen: I forgot where you.

1477
03:31:25,770 --> 03:31:27,240
Geehan Suleyman: And I Ford hospital.

1478
03:31:27,240 --> 03:31:33,390
Ananda Sen: And before so any for do do you have do you guys have things like you know discretionary fund and stuff like that.

1479
03:31:33,390 --> 03:31:36,180
Geehan Suleyman: yeah we do have our professional development funds.

1480
03:31:36,180 --> 03:31:38,580
Geehan Suleyman: There you go, I will probably use.

1481
03:31:38,580 --> 03:31:39,180
Ananda Sen: There you go.

1482
03:31:39,180 --> 03:31:40,770
Geehan Suleyman: that's what I use for this class.

1483
03:31:40,770 --> 03:31:41,820
Ananda Sen: yeah.

1484
03:31:41,820 --> 03:31:46,320
Ananda Sen: So so yeah, so I think I think that's that's a good idea and and.

1485
03:31:46,320 --> 03:31:57,420
Ananda Sen: yeah so again, I mean I don't necessarily recommend any software, because a lot of a lot of the times you work with people who use data, for example.

1486
03:31:57,420 --> 03:32:04,230
Ananda Sen: And and CDs cheaper, so instead of can do all of these everything we're talking about.

1487
03:32:04,230 --> 03:32:16,860
Ananda Sen: i'm i'm seeing less and less use of spss, by the way, because just because, not because spss is a bad software, but it's restricted it doesn't do everything it's it's more limited.

1488
03:32:16,860 --> 03:32:18,420
Ananda Sen: and

1489
03:32:18,420 --> 03:32:32,190
Ananda Sen: Because of this age of data we're getting into more complex data scenario where we use other stuff so it's data and SAS are is really for research, I would say.

1490
03:32:32,190 --> 03:32:36,270
Ananda Sen: Not so much for.

1491
03:32:36,270 --> 03:32:40,500
yeah.

1492
03:32:40,500 --> 03:32:54,300
Ananda Sen: Good good all right so yeah i'll see you tomorrow and and I will stop you're still having issues with with downloading any of these.

1493
03:32:54,300 --> 03:33:10,320
Ananda Sen: or no I don't why don't you send me an email, if you are having problem downloading any of the files and stuff like that, if you are then I will communicate with.

1494
03:33:10,320 --> 03:33:15,090
Ananda Sen: I will do that to me i'll do that today, yes, yes.

1495
03:33:15,090 --> 03:33:21,300
Ananda Sen: The recording has, we have to stop recording actually, then you stop it.

1496
03:33:21,300 --> 03:33:24,512
Ananda Sen: Otherwise, it will not know.

