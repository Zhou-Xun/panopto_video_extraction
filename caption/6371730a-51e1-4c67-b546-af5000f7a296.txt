1
00:00:00,420 --> 00:00:12,420
So today when we talk about clinical epidemiology and you will be getting your exams back at the at the end of the day today as well.

2
00:00:15,120 --> 00:00:18,870
All right. So the lecture outlines, we're going to talk about the validity of a test.

3
00:00:18,870 --> 00:00:20,489
So sensitivity and specificity.

4
00:00:20,490 --> 00:00:26,760
I know we already covered that earlier when we talked about measurement error, but I find it is helpful to remind people of it.

5
00:00:27,750 --> 00:00:31,620
We'll talk about receiver, operating curves, likelihood ratios,

6
00:00:31,620 --> 00:00:38,159
the negative predictive value and positive predictive value, single measures of test performance.

7
00:00:38,160 --> 00:00:42,510
So accuracy index and the diagnostic odds ratio.

8
00:00:43,410 --> 00:00:45,209
And then we'll talk about reliability of a test.

9
00:00:45,210 --> 00:00:55,950
So sources of variation in the agreement and capital reporting standard sort of start because diagnostic accuracy studies also reporting standards.

10
00:00:56,880 --> 00:01:02,160
And then we'll go over a bit about screening. So some of the basics of specific measures and bias.

11
00:01:04,510 --> 00:01:13,600
So for of a test, the definition is a test ability to distinguish between who has a disease and who does not have a disease.

12
00:01:13,600 --> 00:01:17,050
And so there's two components. We'll talk about rate sensitivity and specificity.

13
00:01:17,830 --> 00:01:25,149
So for sensitivity, it's the ability of a test to correctly identify those that have the disease that should look familiar.

14
00:01:25,150 --> 00:01:28,000
You've seen exactly this slide before. Right.

15
00:01:28,360 --> 00:01:34,750
So sensitivity is the number of true positives over all of those with the disease for a number of people.

16
00:01:34,770 --> 00:01:40,780
See. So can you calculate the sensitivity of this screening test?

17
00:02:22,740 --> 00:02:27,720
All right. So it should be 132 over 177, which is 74.6.

18
00:02:28,530 --> 00:02:34,259
So for specificity, it's the ability of a test to correctly identify those that don't have the disease.

19
00:02:34,260 --> 00:02:43,120
Right. So those that are healthy. So specificity are the true negatives divided by those without the disease or D over B plus D.

20
00:02:43,980 --> 00:02:47,220
So what is the specificity of that screening test?

21
00:03:16,710 --> 00:03:21,060
It should be 63,006, 50 over 64,000 633.

22
00:03:21,060 --> 00:03:22,950
So 98.5%.

23
00:03:24,690 --> 00:03:31,950
So when we think about sensitivity and specificity, ideally we'd have a perfect test rate, something that's 100% sensitive and 100% specific.

24
00:03:32,640 --> 00:03:38,220
But usually for generally, there's a tradeoff between sensitivity and specificity.

25
00:03:39,330 --> 00:03:47,850
And so when you're thinking about kind of any test, they're usually ones that are clearly positive, ones that are clearly negative.

26
00:03:48,510 --> 00:03:53,850
And then there are going to be ones that are indeterminate or kind of in this gray zone.

27
00:03:54,450 --> 00:04:07,049
Right. When people are putting together an asset class or a research vessel, whatever, you usually decide upon a cutoff point,

28
00:04:07,050 --> 00:04:12,540
at what point are you going to decide that somebody is, you know, normal or abnormal?

29
00:04:13,560 --> 00:04:18,930
Right. And that that point can be based on many different factors.

30
00:04:20,790 --> 00:04:29,819
Remember, for bias, we generally care more about specificity than sensitivity, but we're not always just thinking about recent studies and bias.

31
00:04:29,820 --> 00:04:38,700
Right, because people are getting this clinical test done. So you can do more than one test sometimes.

32
00:04:39,210 --> 00:04:43,020
And when that's done, there's two basic options.

33
00:04:43,800 --> 00:04:53,070
The tests can be done in the series. So you do one test, and if that test is positive, then you would do a second test.

34
00:04:56,430 --> 00:04:59,910
Usually the first test is is more sensitive, but less specific.

35
00:05:01,170 --> 00:05:05,190
And it's going to improve specificity at the cost of lower sensitivity.

36
00:05:05,940 --> 00:05:13,050
You can also do test in parallel. So two tests are performed at the same time and then the results are combined.

37
00:05:14,400 --> 00:05:22,800
Generally, when you would do it that way, the finding is going to be positive if either of those tests are positive.

38
00:05:23,610 --> 00:05:27,300
So you end up with higher sensitivity, but then with lower specificity.

39
00:05:28,950 --> 00:05:32,100
So this is just that serial testing, right?

40
00:05:32,820 --> 00:05:36,480
So here we've got test one.

41
00:05:36,900 --> 00:05:45,030
If you're negative. That's right. You're call not disease. But if you are positive, you get a second test done, right.

42
00:05:45,780 --> 00:05:50,370
And then only if you're positive on that second test, would you be classified as disease.

43
00:05:51,540 --> 00:05:55,640
That's in contrast to parallel testing where we have the two tests that are being done, you know,

44
00:05:56,460 --> 00:06:01,260
at the same time, or at least kind of like the interpretation is being combined at the same time.

45
00:06:02,220 --> 00:06:07,590
So if you're positive on either test one or test two, you'll be disease.

46
00:06:07,590 --> 00:06:11,960
Then you have to be negative on both of those test in order to be classified as not disease.

47
00:06:14,430 --> 00:06:20,790
So we're thinking about the sensitivity and specificity of two tests in series four parallel in series,

48
00:06:20,790 --> 00:06:24,330
you're going to multiply the sense to get the sensitivity of that test.

49
00:06:24,840 --> 00:06:29,520
You will multiply those two sensitivities together, right?

50
00:06:30,030 --> 00:06:32,280
So that's where you're going to be losing sensitivity.

51
00:06:32,790 --> 00:06:41,220
If you're doing it in parallel, it is one minus one minus the sensitivity of test, one times one minus the sensitivity of test two.

52
00:06:42,480 --> 00:06:45,510
And then for specificity here in series,

53
00:06:45,510 --> 00:06:53,250
it's going to be one minus one minus the specificity at test one times one minus the specificity of the type of test two.

54
00:06:54,150 --> 00:06:59,790
And in parallel, it will be the specificity of the test two times the specificity of of test one.

55
00:07:00,240 --> 00:07:05,070
Right. We're losing specificity there in parallel because we're calling it positive.

56
00:07:05,550 --> 00:07:15,330
Right. If either test is positive, I will say that these these formulas do assume that the test or not,

57
00:07:15,870 --> 00:07:19,559
you know, are not highly correlated or not really correlated.

58
00:07:19,560 --> 00:07:26,160
Right. So you generally be testing different model versions of the same test on two different mock up markers.

59
00:07:27,810 --> 00:07:32,720
I mean, if they were perfectly correlated, there would be no purpose in doing two test.

60
00:07:33,030 --> 00:07:37,470
So, all right. So here's an example.

61
00:07:37,950 --> 00:07:43,679
I'm looking at least meaning infection and they're using a laser.

62
00:07:43,680 --> 00:07:48,060
So that's a serology test and an immunofluorescence assay.

63
00:07:49,710 --> 00:08:00,150
And here you can see it's got the sensitivity of a lysis, 91.8% sensitivity of if a is 90.8%.

64
00:08:01,260 --> 00:08:05,160
And it just goes through and shows what happens when you do serial testing.

65
00:08:05,490 --> 00:08:12,330
Right. We see that with serial testing. The sensitivity is lower than either of the two tests alone.

66
00:08:12,990 --> 00:08:23,340
And with parallel testing, we get that increase in sensitivity because some some positives that aren't caught by allies are caught by EFA.

67
00:08:23,550 --> 00:08:28,800
And the inverse is true. Right for specificity, right?

68
00:08:28,800 --> 00:08:34,530
ELISA is more specific. So 83.8% EFA 53.4%.

69
00:08:34,770 --> 00:08:40,620
And we see here for serial testing, we get higher specificity right when we combine those two tests.

70
00:08:41,040 --> 00:08:45,690
But if we do them in parallel, we get lower specificity, right?

71
00:08:48,140 --> 00:08:50,930
And then this just shows the which we haven't really got into yet,

72
00:08:50,930 --> 00:08:59,360
the positive predictive value and the negative predictive value of those tests and when they're done in serial or parallel.

73
00:09:00,740 --> 00:09:04,290
And we'll talk more about possible predictive value and negative predictive value in a moment.

74
00:09:04,310 --> 00:09:07,670
It's really quite shining on the prevalence in the population.

75
00:09:09,140 --> 00:09:13,190
Okay. So receiver operating curves,

76
00:09:14,510 --> 00:09:27,370
this is a basic kind of a I guess a diagram of this area between where you you get a mix of both positive and negative results based on a test.

77
00:09:27,380 --> 00:09:32,690
So this is amniotic fluid level, a p fluid AP level.

78
00:09:33,350 --> 00:09:42,530
And here these individuals over here are the values you get for people well, for pregnancies when there is no spinal bifida.

79
00:09:42,980 --> 00:09:45,920
And over here. Right, we have found that.

80
00:09:46,130 --> 00:09:53,090
And so you see in this area right here, right, there's an overlap of the curves where if you pick anybody in that area,

81
00:09:53,090 --> 00:09:57,410
they may or may not be pregnant with the baby with spinal spinal bifida.

82
00:09:57,800 --> 00:10:00,050
So that's kind of what we we call the gray zone.

83
00:10:00,050 --> 00:10:06,890
And particularly this area right here is is a particularly gray zone, but really anywhere where these two curves are overlapping.

84
00:10:10,480 --> 00:10:15,490
So we use receiver operating curves to determine the cut point for test.

85
00:10:16,750 --> 00:10:20,469
It's a plot of sensitivity versus one minus specificity.

86
00:10:20,470 --> 00:10:22,660
I'll show you a receiver operating curve in a moment.

87
00:10:23,740 --> 00:10:30,310
The results are going to be represented as the area under the curve and the area will be between zero and one.

88
00:10:31,060 --> 00:10:38,320
A perfect test is a test with 100% sensitivity and 100% specificity would have an area under the curve of one.

89
00:10:40,240 --> 00:10:43,480
So here is an example of a receiver operating curve.

90
00:10:43,720 --> 00:10:50,470
Right. So we've got sensitivity here from 0 to 100% and one minus specificity here.

91
00:10:53,170 --> 00:10:59,290
So you use a receiver operating curve to help you decide upon the ideal cut point, right?

92
00:10:59,290 --> 00:11:04,780
At any point along this line, you can determine, you know, this is what the sensitivity and specificity of that test would be.

93
00:11:05,950 --> 00:11:13,809
It kind of everything else being equal, that is the risk of of a false positive versus a false negative.

94
00:11:13,810 --> 00:11:18,190
Then the cut point should really be this top left corner of the graph.

95
00:11:18,970 --> 00:11:25,060
So right there. However, it's often not as simple as that.

96
00:11:25,060 --> 00:11:27,850
Right? Because, like, things aren't always equal.

97
00:11:28,960 --> 00:11:36,700
So when you're thinking about, like determining a hot point for a test, you have to weigh the effects of a false negative versus a false positive.

98
00:11:37,240 --> 00:11:43,210
Right, on the severity of the disease and then the invasiveness of the next test or treatment.

99
00:11:43,930 --> 00:11:49,990
Right. Because if you're going to tell like send a bunch of people on to that next test or treatment if they don't really have the disease,

100
00:11:50,850 --> 00:11:53,800
you know, if it's really invasive, that's that's definitely a larger issue.

101
00:11:54,340 --> 00:12:00,640
And so sensitivity should be increased when the penalty associated with missing a case is particularly high.

102
00:12:02,250 --> 00:12:10,390
All right. Quick. In class activity, can you draw a rock curve for a worthless test?

103
00:12:10,410 --> 00:12:13,710
A perfect test. A good test and a poor test.

104
00:12:14,520 --> 00:12:18,570
APR right there. So. Well, worthless and good.

105
00:12:19,350 --> 00:12:22,580
There's no debating, but I mean, worthless and perfect. They might.

106
00:12:22,650 --> 00:12:28,130
Good for. But.

107
00:12:58,420 --> 00:13:08,520
You must choose. But now seems more reasonable.

108
00:13:08,610 --> 00:13:16,740
Yeah. You know, one touch. But I wonder if that should be.

109
00:13:17,010 --> 00:13:20,460
Yeah, that's true. It would be. But we also had trouble with the freezer room.

110
00:13:21,300 --> 00:13:25,350
It was like we got yesterday. Yeah, it was boiling hot.

111
00:13:25,350 --> 00:13:31,840
But it wasn't Tuesday. It was to stay in the freezer. Yeah, I've heard about, like, the freezer alarm going off or something.

112
00:13:31,870 --> 00:13:37,350
I was like, the freezer is separate degrees is what I thought.

113
00:13:37,920 --> 00:13:42,420
At first. I thought they were saying that the freezers were like 75 degrees.

114
00:13:42,990 --> 00:13:51,480
Yeah, it's the it was the room. I mean, I went in one time and it was like 90 something that's like we continually have trouble with that room,

115
00:13:53,610 --> 00:13:59,130
the fishbowl and like church, you know, the room on the third floor, the freezer, 20 years old.

116
00:13:59,700 --> 00:14:04,970
We have a backup big AC in there, but it couldn't keep up with the amount of food that was going down there.

117
00:14:14,170 --> 00:14:17,800
All right. So here we go.

118
00:14:18,100 --> 00:14:21,459
All right. So there are two kind of easiest ways. A perfect test, right?

119
00:14:21,460 --> 00:14:27,540
A straight line, right. Hundred percent worthless test right here.

120
00:14:27,550 --> 00:14:31,260
Right. And if you go down into this area, it's worse than a worthless test.

121
00:14:31,590 --> 00:14:36,190
You know, you're better off not doing a test at all. Here we have a poor test.

122
00:14:36,580 --> 00:14:40,780
And then here is is a fairly good fit, right?

123
00:14:40,780 --> 00:14:44,650
So, um, okay, any questions?

124
00:14:48,650 --> 00:14:52,190
Okay. So now likelihood ratios.

125
00:14:52,700 --> 00:14:58,100
All right. So the likelihood ratio of positive is the likelihood ratio of a positive result.

126
00:14:58,370 --> 00:15:02,840
It's the ratio of positive test among disease to the same result in the healthy.

127
00:15:03,830 --> 00:15:10,969
It's also the formula. There is sensitivity over one minus specificity or the probability of testing positive

128
00:15:10,970 --> 00:15:15,920
given disease divided by the probability of testing positive given not disease.

129
00:15:16,520 --> 00:15:21,290
Good tests in general are going to have a likelihood ratio positive of greater than ten.

130
00:15:24,610 --> 00:15:28,840
Likelihood ratio of negative is the likelihood ratio of a negative result,

131
00:15:29,950 --> 00:15:34,149
the ratio of negative of negative results among disease to the same result in healthy.

132
00:15:34,150 --> 00:15:41,080
This is one minus sensitivity over specificity also equal to the probability of testing

133
00:15:41,080 --> 00:15:46,000
negative given disease over the probability of testing negative given non disease,

134
00:15:46,660 --> 00:15:50,140
it's a good indicator for ruling out a diagnosis.

135
00:15:51,820 --> 00:16:02,080
A good test should have a likelihood ratio negative of less than 0.1, and the test should really always have a value of less than one.

136
00:16:02,230 --> 00:16:15,830
Right. So likelihood ratios are going to be applied to the pretest probability of disease to determine a post-test probability of disease.

137
00:16:16,520 --> 00:16:23,720
So the pretest odds is multiplied by the likelihood ratio to determine the post-test odds you'll get.

138
00:16:24,200 --> 00:16:27,250
So values of 0 to 1 will decrease. The probability.

139
00:16:27,310 --> 00:16:31,430
Values of greater than one will increase the probability. It's based on Bayes theorem.

140
00:16:32,390 --> 00:16:45,020
Where you may have seen something like this before, or maybe not, is if you have had a child and undergone some genetic testing.

141
00:16:45,020 --> 00:16:54,440
They will tell you what your what your likelihood of of having of having a child, for example, with cystic fibrosis is before the test results.

142
00:16:54,440 --> 00:17:01,040
And then what your likelihood is now that you have those test results, for example, but many other things as well.

143
00:17:06,600 --> 00:17:12,089
Okay. So sensitivity, specificity, likelihood ratios in disease, prevalence, sensitivity,

144
00:17:12,090 --> 00:17:18,360
specificity and likelihood ratios are often thought of as can have these inherent properties of a test that

145
00:17:18,360 --> 00:17:26,000
are not going to vary with disease prevalence that relies on several assumptions which may not be true.

146
00:17:26,850 --> 00:17:32,190
One is that it's truly a dichotomous disease status, typically the disease or not disease,

147
00:17:33,630 --> 00:17:37,860
and there's a homogeneous probability of disease misclassification with within

148
00:17:37,860 --> 00:17:43,770
population disease individuals and within populations of non disease individuals.

149
00:17:44,220 --> 00:17:50,430
These things don't always hold. So in fact you will see differences in these measures in different populations.

150
00:17:55,670 --> 00:18:00,380
One really interesting thing about specificity. We did like up at the beginning of.

151
00:18:02,650 --> 00:18:10,400
The SARS-CoV-2 pandemic. Like I worked with the hospital here to set up serology testing, and they were and they were.

152
00:18:10,420 --> 00:18:16,360
So we were setting up kind of an in-house serology test, but then all these clinical tests coming out and they were like,

153
00:18:16,360 --> 00:18:19,390
okay, well, we're going to we're going to test these clinical tests, too.

154
00:18:19,420 --> 00:18:21,280
So I helped put together a sample set.

155
00:18:24,160 --> 00:18:34,360
And, you know, sociologically for SARS-CoV-2, I didn't really expect it very, very that much by population, which was clearly incorrect.

156
00:18:34,870 --> 00:18:38,409
Right. And so this was before like from samples before the pandemic.

157
00:18:38,410 --> 00:18:45,399
So we're talking like samples collected in 2018. When you when you're testing that like a new clinical test, right.

158
00:18:45,400 --> 00:18:52,300
You need to check kind of in the general population, but then you check in specific populations as well.

159
00:18:52,630 --> 00:18:56,620
Right. So you might look at people who like for serology, right.

160
00:18:56,800 --> 00:19:04,240
Who had known infections. So for something like SARS-CoV-2, which is a beta coronavirus, it was really important to look at coronaviruses.

161
00:19:04,510 --> 00:19:14,049
But they also wanted to look at a variety of other diseases, including diseases that might be kind of mistaken for SARS-CoV-2.

162
00:19:14,050 --> 00:19:22,150
So influenza infections, for example, RSV infections also in people who have autoimmune disease, right?

163
00:19:22,150 --> 00:19:28,990
Because they had might have some different antibodies kind of floating around to kind of the general population and then some special populations.

164
00:19:30,220 --> 00:19:38,260
Anyways, so I was working with the hospital. I have all these samples for flu and RSV and other viruses for my studies done in Nicaragua.

165
00:19:39,370 --> 00:19:47,650
And I gave them some samples to help do some of the clinical testing in the hospital.

166
00:19:48,520 --> 00:19:55,890
Kind of at a time where we were thinking of testing people for antibodies and then transferring serum might help really, really sick individuals.

167
00:19:55,900 --> 00:20:01,990
Right. And interestingly enough, the specificity of those clinical tests, including our lysis,

168
00:20:01,990 --> 00:20:07,480
were actually different in in the Nicaraguan population, population here in Ann Arbor.

169
00:20:08,530 --> 00:20:14,259
Why that is, I don't know, some other disease that is down there has some amount of cross-reactive antibodies.

170
00:20:14,260 --> 00:20:18,129
Right. But anyways, it does vary by population.

171
00:20:18,130 --> 00:20:26,830
It's not an inherent and not always an inherent feature of the test and often not a feature of the test.

172
00:20:27,520 --> 00:20:33,760
All right. So basically kind of already told you this, but however, those assumptions.

173
00:20:34,090 --> 00:20:39,370
Right. Are likely to be violated. So disease status is often not black and white.

174
00:20:41,440 --> 00:20:48,880
Misclassification is often not homogenous. Individuals closer to the point of a test are going to be more likely to be misclassified.

175
00:20:48,890 --> 00:20:56,500
Right? So if we look back here all the way back here in Fisher's brother, right, the individuals here, wherever we decide,

176
00:20:56,500 --> 00:21:00,950
our point is that if we use a cup of water compared to individuals right around that cup

177
00:21:01,000 --> 00:21:06,010
point are more likely to be misclassified than individuals over here or over there.

178
00:21:06,060 --> 00:21:09,520
Right. So. Okay.

179
00:21:12,560 --> 00:21:15,580
All right. Negative predictive value and positive predictive value.

180
00:21:16,450 --> 00:21:24,580
All right. So positive predictive value p b is the probability that a person actually has the disease given that he or she test positive.

181
00:21:25,210 --> 00:21:29,560
So it is the true positives over all positives are a over a plus P.

182
00:21:30,880 --> 00:21:35,440
So what is the positive predictive value of that screening test we've been looking at?

183
00:21:37,930 --> 00:21:42,460
Right. Which is physical examination and mammography for breast cancer.

184
00:22:33,640 --> 00:22:39,360
132 over 1115 or 11.8%.

185
00:22:40,590 --> 00:22:43,139
Okay. So that's positive predictive value.

186
00:22:43,140 --> 00:22:52,140
So negative predictive values, the probability that a person is truly disease free given that he or she tests negative.

187
00:22:53,540 --> 00:23:00,110
So that's going to be the true negatives over all negatives or D, over C plus D.

188
00:23:02,280 --> 00:23:05,340
So what's the negative predictive value of that screening test?

189
00:23:38,420 --> 00:23:44,640
Please. All right.

190
00:23:45,450 --> 00:23:49,169
63,006. 50 divided by 63.

191
00:23:49,170 --> 00:23:55,610
6.5%. 99.9%. Right.

192
00:23:56,390 --> 00:24:01,219
So there's a relationship between predictive value and disease prevalence.

193
00:24:01,220 --> 00:24:06,950
The higher the prevalence, the higher the positive predictive power and the lower the negative predictive power.

194
00:24:07,430 --> 00:24:15,680
So here we've got a test with sensitivity and specificity of 95%, but we're going to be looking at two different scenarios.

195
00:24:15,680 --> 00:24:22,340
One, where disease prevalence is 1% and another where the disease prevalence is 5%.

196
00:24:23,670 --> 00:24:26,720
Right. So same sensitivity and specificity.

197
00:24:27,710 --> 00:24:31,700
But when it's 1%, the positive predictive value is 17%.

198
00:24:32,690 --> 00:24:35,780
Negative predictive value is 99.99%.

199
00:24:36,800 --> 00:24:41,460
However, when we now have a disease prevalence of 5%, it's still fairly rare, right?

200
00:24:41,480 --> 00:24:50,210
That positive predictive value is now 51% and the negative predictive value is 99.94%.

201
00:24:53,840 --> 00:25:00,670
So here we're looking at picture.

202
00:25:01,220 --> 00:25:06,110
Right. A test with 95% sensitivity and 95% specificity.

203
00:25:06,590 --> 00:25:10,910
Here's the negative predictive value. The the positive predictive value.

204
00:25:11,870 --> 00:25:12,290
Right.

205
00:25:12,290 --> 00:25:21,080
And we see as disease prevalence increases, the positive predictive value is going to increase and the negative predictive value is going to decrease.

206
00:25:23,250 --> 00:25:28,950
It's it's really crucial to to make sure that you understand that negative predictive

207
00:25:28,950 --> 00:25:32,729
value and positive predictive value are kind of performance characteristics.

208
00:25:32,730 --> 00:25:37,620
They're not going to be inherent characteristics or traits, intrinsic values of the test.

209
00:25:38,040 --> 00:25:41,700
Right. They're going to vary a lot from population to population.

210
00:25:42,570 --> 00:25:47,820
And that's because they're going to be strongly influenced by the prevalence of the disease in the population.

211
00:25:50,740 --> 00:25:55,299
Right. And you'll always see this positive feedback. Value is going to increase, right?

212
00:25:55,300 --> 00:25:59,260
With prevalence, negative predictive value is going to decrease with increasing prevalence.

213
00:26:02,230 --> 00:26:11,379
So this is just kind of showing that again right here, looking at a variety instead of like having everything have the same sensitivity.

214
00:26:11,380 --> 00:26:16,660
We've got varying sensitivity here looking at the positive predictive value.

215
00:26:17,410 --> 00:26:25,810
And you can see kind of regardless of the level of sensitivity, you see this increase in the prevalence of disease,

216
00:26:26,170 --> 00:26:32,290
sorry, the positive predictive value with an increase in prevalence of disease and even with really high sensitivity.

217
00:26:32,890 --> 00:26:39,100
Right. You're still going to get pretty low positive predictive value if the problem is really low.

218
00:26:44,160 --> 00:26:46,620
So protest interpretation for an individual patient.

219
00:26:46,620 --> 00:26:56,099
We're concerned with the positive predictive value and the negative predictive value of a test because of differences in disease prevalence.

220
00:26:56,100 --> 00:26:58,229
The same test can have very different predictive values,

221
00:26:58,230 --> 00:27:03,720
which I already mentioned when I administered to two populations that have different prevalence.

222
00:27:04,470 --> 00:27:10,350
And what you often see is that they will act like people will divide populations operates.

223
00:27:10,350 --> 00:27:20,640
You can divide people into high risk and groups, right? So test interpretation should be done taking into account the population that's being tested.

224
00:27:21,450 --> 00:27:26,609
So particularly if somebody is at a high risk or a low risk group, in some cases,

225
00:27:26,610 --> 00:27:33,120
it could also be appropriate to use different cut points for high and low risk groups.

226
00:27:39,390 --> 00:27:50,430
So these are much more useful, right, for for an individual kind of clinical interpretation.

227
00:27:50,880 --> 00:28:00,750
All right. So here we have back to our great zone diagram here with AFP and spinal bifida.

228
00:28:02,040 --> 00:28:05,700
Right. You can see that we've got to cut points here.

229
00:28:06,420 --> 00:28:17,760
I cut point one and cut point two. So we know that women who previously had a baby with spinal bifida are at increased risk of having another baby.

230
00:28:17,790 --> 00:28:21,060
That's right. About now. Right. So they are they're a high risk group.

231
00:28:23,250 --> 00:28:30,150
So we've now divided into women, for example, right into two different groups, our high risk group and our low risk group.

232
00:28:33,120 --> 00:28:37,290
And this is using actually the same like one cut point for both groups.

233
00:28:38,130 --> 00:28:42,660
And so what we see is in the positive predictive value is going to be quite high in this high risk group,

234
00:28:42,660 --> 00:28:47,610
82.9% negative predictive value as high, 99.9%.

235
00:28:47,940 --> 00:28:58,350
And the lower risk group, the positive predictive value is lower, 41.7%, and the negative predictive value is 99.8%.

236
00:28:59,130 --> 00:29:06,570
So if you were a physician, how would you interpret an abnormal result for a woman in the high risk group?

237
00:29:06,570 --> 00:29:16,410
When you maybe turn to a friend or colleague around you and tell them how you would interpret an abnormal result for a woman in a low risk group?

238
00:29:36,830 --> 00:29:51,940
Sorry. No higher school. Yeah.

239
00:29:51,940 --> 00:29:58,830
Go ahead and do high end and low risk. The children.

240
00:30:06,200 --> 00:30:25,410
Let's move on. Yeah.

241
00:30:28,060 --> 00:30:34,960
So. So how would people interpret an abnormal result for a for a high risk group woman?

242
00:30:35,950 --> 00:30:42,759
What would you tell? I guess one quick question.

243
00:30:42,760 --> 00:30:46,150
Do you all know what swine flu is? No.

244
00:30:46,510 --> 00:30:55,780
Okay. Spina bifida is when the spinal cord is right, but it hasn't the skin has not formed correctly over the spinal cord.

245
00:30:55,780 --> 00:31:00,580
Right. So they'll have exposed spinal cord if you do nothing about it.

246
00:31:03,430 --> 00:31:12,940
Well, it can sometimes lead to death, right. But certainly can lead to disability in the fetus as well.

247
00:31:13,750 --> 00:31:18,610
And it really depends on the kind of the level of that exposed cord.

248
00:31:20,440 --> 00:31:26,929
I'm not a physician, but that's kind of roughly. It's pretty serious.

249
00:31:26,930 --> 00:31:34,999
And so like all pregnant women in the U.S., at least who are going in for regular prenatal care will be screened for spinal bifida.

250
00:31:35,000 --> 00:31:40,430
And plus, they, you know, specifically say they do not want that screening to occur.

251
00:31:41,600 --> 00:31:45,079
So what would we tell that woman? What would you tell that woman?

252
00:31:45,080 --> 00:31:51,410
If you you're a physician. What you're thinking is that I had an.

253
00:31:53,790 --> 00:31:56,960
Pretty strong comparability better? Yeah.

254
00:31:57,900 --> 00:32:01,320
Yep. So there's a high probability that your.

255
00:32:01,620 --> 00:32:05,640
Your baby has been a. What about a woman in the low risk group?

256
00:32:07,410 --> 00:32:16,900
What would you what would you tell her? And I like a moderate probability or just a possibility.

257
00:32:17,880 --> 00:32:21,580
It's not as yeah, it's definitely not as definitive.

258
00:32:21,580 --> 00:32:27,370
In fact, most people in that group who test positive or screened positive are there.

259
00:32:27,790 --> 00:32:31,430
It will turn out that their their baby does not have it at all.

260
00:32:33,490 --> 00:32:38,350
So what I said is that although your test result was abnormal and you should be aware that there is a risk,

261
00:32:39,010 --> 00:32:43,840
it is still more likely than not that your baby will not have a neural tube defect.

262
00:32:48,060 --> 00:32:57,050
The table below previously. The the negative predictive value is was higher in the high risk group.

263
00:32:58,640 --> 00:33:06,100
Mm hmm. It's not, like, slightly above. It is slightly odd.

264
00:33:11,960 --> 00:33:15,320
Yeah. It's not what you would normally expect, but.

265
00:33:18,970 --> 00:33:21,640
I'm going to blame Gordon because I think I got the gist both from him,

266
00:33:21,700 --> 00:33:24,219
because they would have thought a lower risk group, they would have a lower prevalence.

267
00:33:24,220 --> 00:33:27,970
So their negative predictive value would be high, should be higher normally.

268
00:33:28,120 --> 00:33:33,519
But there is variation right in this and they're quite close anyways.

269
00:33:33,520 --> 00:33:36,690
Right. Wait. Oh, here, hold on.

270
00:33:37,360 --> 00:33:42,160
I think there was an error actually. Is the problem in the in the table.

271
00:33:42,430 --> 00:33:46,780
So thank you for catching that for the books like at least in this one, it's it's 100%.

272
00:33:46,780 --> 00:33:52,510
So it was probably in an error. Yeah.

273
00:33:55,540 --> 00:34:02,460
Okay. We should fix it. All right. I can't blame borders.

274
00:34:08,310 --> 00:34:12,240
So, in fact, what's often done to is that the cut point is different based on risk.

275
00:34:13,290 --> 00:34:24,390
So what point would you use for high risk women if you were deciding on a California city or C, one or C two for high risk women?

276
00:34:29,410 --> 00:34:37,060
See Juan, right. Because we want to catch all of these individuals where their baby has been a visitor and then for low risk women.

277
00:34:41,930 --> 00:34:51,590
Yeah. See, too. Right. Because relatively few people in that low risk population that are in that zone are actually going to indeed have it.

278
00:34:53,140 --> 00:35:00,200
All right. So are we doing okay?

279
00:35:00,260 --> 00:35:07,310
Single measures of test performance. We've got accuracy index and the diagnostic odds ratio.

280
00:35:09,230 --> 00:35:14,270
So for accuracy or accuracy, you tend to maximize the diagnostic odds ratio.

281
00:35:14,270 --> 00:35:19,340
For accuracy, it's what percentage of the test results are correct.

282
00:35:20,000 --> 00:35:29,270
So it's a very simple graph of some of the total test results, the correct total test results divided by the sum of the total test results times 100%.

283
00:35:31,320 --> 00:35:36,780
Four units indexer unit phase, the sensitivity plus the specificity minus one.

284
00:35:37,210 --> 00:35:46,890
It's going to vary from -1 to 1, where one is going to be a perfect test and zero is a useful test,

285
00:35:46,890 --> 00:35:52,049
and anything less than zero is a more than useless test.

286
00:35:52,050 --> 00:36:00,120
Like actually the worst of index is one of the oldest measures of global accuracy.

287
00:36:01,230 --> 00:36:06,180
One issue with it is it's not sensitive to differences in sensitivity and specificity.

288
00:36:07,140 --> 00:36:18,810
That's a test with the sensitivity of 90% and a specificity of 40% would have the same j as a test with the sensitivity of 60% and specificity of 70%.

289
00:36:22,490 --> 00:36:26,000
The diagnostics odds ratio is the ratios, right?

290
00:36:26,000 --> 00:36:31,430
So these are just place to, to compare the, um, to calculate the accuracy of a test,

291
00:36:32,720 --> 00:36:37,940
the ratio of the odds of positivity and disease relative, the odds of positivity in the non disease.

292
00:36:38,480 --> 00:36:41,870
It's an odds ratio, right. So it's going to go from zero to infinity.

293
00:36:42,360 --> 00:36:53,240
A higher number will indicate better test performance and you can calculate that this formula should look very familiar at this point in 601.

294
00:36:53,660 --> 00:36:59,420
Right. And we just put a D in front of it, but it's just the classic odds ratio formula e times D over time,

295
00:36:59,420 --> 00:37:08,120
C can also be calculated by sensitivity divided by one minus two sensitivity over one minus specificity

296
00:37:08,120 --> 00:37:14,120
divided by specificity or with the the positive predictive value and negative predictive value.

297
00:37:14,540 --> 00:37:20,389
So the positive predictive value divided by one minus the positive predictive value over one minus the negative

298
00:37:20,390 --> 00:37:28,580
predictive value over the negative predictive value or the likelihood ratio positive over the likelihood ratio negative.

299
00:37:31,570 --> 00:37:39,340
So here, this is just to kind of show what happens with the diagnostic odds ratios that can get quite large for a good test.

300
00:37:39,700 --> 00:37:47,960
So we have sensitivity increasing across the bottom. And then this is hard to read, but this is going to be the highest specificity there.

301
00:37:48,010 --> 00:37:53,950
Yep, 99%, 95%, 80% and 50%.

302
00:37:55,300 --> 00:38:04,420
So just to kind of look at what happens with the diagnostic odds ratio as the sensitivity and specificity differ.

303
00:38:06,280 --> 00:38:16,810
So here's an example. Looking at the diagnostics odds ratio of three imaging test comparison of three imaging tests in the staging of ovarian cancer,

304
00:38:17,290 --> 00:38:20,650
lymph node and hepatic metastases.

305
00:38:21,820 --> 00:38:25,630
So here we've got ultrasound, CT scan and MRI.

306
00:38:26,140 --> 00:38:35,020
Right? And you can see that there's a massive difference in these diagnostic odds ratios.

307
00:38:40,020 --> 00:38:45,900
What we see. But there you go. Okay. So reliability of a test.

308
00:38:46,680 --> 00:38:52,730
Let's talk a little bit about the different sources of variation that can come in with a test and then talk about agreement and capture.

309
00:38:54,000 --> 00:38:57,960
So for reliability of testing, need to think about the repeatability of a test.

310
00:38:58,320 --> 00:39:02,370
So if I repeat this test, how likely am I to get the same answer?

311
00:39:03,840 --> 00:39:08,490
There are different factors that can contribute to test variation. There can be interest subject variation.

312
00:39:09,870 --> 00:39:15,330
If you think about me getting my blood pressure measured right now, you know,

313
00:39:15,360 --> 00:39:24,179
probably quite different potentially than if you get it measured or I get a measure of under very stressful situation or right after a break,

314
00:39:24,180 --> 00:39:27,870
a big thing of coffee. Right. So I will vary any of those vary throughout the day.

315
00:39:28,860 --> 00:39:31,739
There's intra observer variation, right?

316
00:39:31,740 --> 00:39:40,020
So the same person might read a test differently and enter observer, a variation with different observers read differently.

317
00:39:41,580 --> 00:39:45,450
So interest subject variation is just the variation within individual subjects.

318
00:39:46,890 --> 00:39:50,280
Values of many biological characteristics are going to vary over time.

319
00:39:50,730 --> 00:39:57,300
Sorry, blood pressure varies throughout the day. Conditions under which tests are conducted can lead to different results.

320
00:39:58,290 --> 00:40:01,200
Blood pressure to dentist office versus blood pressure at home.

321
00:40:03,600 --> 00:40:10,290
For intra observer variation, it's the variation between two or more readings of the same test results made by the same observer.

322
00:40:11,250 --> 00:40:15,420
So, for example, X-rays read by the same radiologist on different days.

323
00:40:15,990 --> 00:40:25,950
They may see something different, right? Tests are going to differ in the degree to which subjective elements enter the readings.

324
00:40:26,700 --> 00:40:32,970
So the greater the amount of kind of subjective elements in those readings, the greater the internal observer or variation.

325
00:40:36,080 --> 00:40:39,790
Your observer variation is variation between two different observers.

326
00:40:40,640 --> 00:40:48,720
So two examiners may not get the same results. There are ways to measure that agreement.

327
00:40:48,770 --> 00:40:54,530
One is percent agreement. Another one is the cap a statistic. So percent agreement.

328
00:40:54,620 --> 00:41:00,280
Thus, very simple question of what percentage of the test degree the agreement is,

329
00:41:00,290 --> 00:41:04,730
is the sum of the results that agree divided by the total results times 100%.

330
00:41:05,000 --> 00:41:08,780
So here we've got an example grading by two pathologists.

331
00:41:09,740 --> 00:41:14,180
So we will add up there where they both say grade two or grade three,

332
00:41:14,180 --> 00:41:20,579
so 41 plus 27 and then divided by the total number of tests, which is 75 here, 100%.

333
00:41:20,580 --> 00:41:25,400
So we get 90.7%. And you might think that sounds pretty good, right?

334
00:41:25,910 --> 00:41:32,090
That's fairly good agreement. It kind of does depend on how much agreement you're actually expecting.

335
00:41:32,090 --> 00:41:40,850
Right. So it's usually better to use Kappas statistic or the R Cohen's Kappa.

336
00:41:41,360 --> 00:41:44,689
It measures the extent of of agreement beyond that,

337
00:41:44,690 --> 00:41:51,409
which would be expected from knowing the marginal values that is the row and column totals is a range from minus one.

338
00:41:51,410 --> 00:41:55,370
So perfect disagreement to one which is perfect agreement.

339
00:41:56,270 --> 00:41:59,720
A zero indicates the amount of agreement expected by chance.

340
00:42:00,770 --> 00:42:07,850
So we've got observed agreement in a percent minus the expected agreement divided by 100%, minus the expected agreement.

341
00:42:10,890 --> 00:42:16,830
For the expected agreement. The expected proportion in each cell is the proportion in that sales row.

342
00:42:17,220 --> 00:42:22,110
So the row total divided by the sample size times the proportion in that cells column,

343
00:42:22,110 --> 00:42:28,229
i.e. the column title total divide about the sample size expected agreement is obtained by adding

344
00:42:28,230 --> 00:42:32,550
the expected proportions of the cells along the diagonal of the table at which the observers agree.

345
00:42:33,180 --> 00:42:40,080
Agreed. Don't worry, I will give you the formula. So here is the formula for Kappa.

346
00:42:43,800 --> 00:42:47,670
All right. And it sounds harder than military.

347
00:42:48,630 --> 00:42:52,190
So calculating, powerful. We've got an agreement.

348
00:42:52,260 --> 00:43:05,160
Ten plus 75 divided by 185% in our expected agreement is going to be 20% times 15% plus 80% times 85%.

349
00:43:05,490 --> 00:43:11,220
This one's easy because of course it's over. So it's very easy to convert those numbers to percentages.

350
00:43:11,970 --> 00:43:23,280
So COPPA is going to be 85% -71% divided by 100%, -71%, which is equal to 0.48.

351
00:43:27,340 --> 00:43:36,850
All right. So one of the things that COPPA really helps with is getting around the issue that observations

352
00:43:39,190 --> 00:43:43,110
that aren't evenly distributed into two categories can be a little bit misleading.

353
00:43:43,120 --> 00:43:52,990
So if you don't have, like 5050. Right. So here in this example, we've got people hearing a gallop in a heartbeat versus no gallop.

354
00:43:53,560 --> 00:43:58,600
Right. And what you can see is for hearing a gallop, there's actually no agreement.

355
00:43:58,600 --> 00:44:04,780
Right. They both have five people where they hear a gallop right here.

356
00:44:05,230 --> 00:44:08,020
Right here. Right. But they actually don't agree on who those five people are.

357
00:44:09,730 --> 00:44:15,550
But the observed agreement here would still be 90 divided by 100 or 90%.

358
00:44:16,570 --> 00:44:19,990
Right. So like you'd say, panel, that's pretty good agreement.

359
00:44:20,470 --> 00:44:33,130
Right. But if you do the expected agreement, you get 90.5% based on these on on the column and row totals.

360
00:44:33,550 --> 00:44:39,820
Right. So when you do Kappa, you end up with a cap at of -0.05%.

361
00:44:42,720 --> 00:44:48,330
That's why Kappa Kappa is always going to be a lot lower than agreement.

362
00:44:50,190 --> 00:44:54,930
I mean, I like to see something above 0.6. Generally speaking, the higher the better.

363
00:44:55,730 --> 00:45:01,920
Um, but there you go. Okay. We need questions about, uh, Kappa.

364
00:45:05,540 --> 00:45:18,010
Um. I think then we can take a break and do the in class activity, so we will start up back up.

365
00:45:18,020 --> 00:45:21,200
Well, we'll see how we're doing, but probably 10 minutes after 11.

366
00:45:25,270 --> 00:45:39,360
It's a semi long term concept of. Yeah.

367
00:46:06,190 --> 00:46:46,110
Oh. I could be wrong.

368
00:46:47,800 --> 00:47:07,510
I'm pretty sure that. Aaron Maté But the importance of the bakery.

369
00:47:07,690 --> 00:47:12,940
Yes, I know we don't have good Greek influenza and eat well at the beginning.

370
00:47:14,650 --> 00:47:18,309
I didn't hear anything. I know.

371
00:47:18,310 --> 00:47:27,310
This weekend I told her I feel like, well, I need more supplies of tomorrow and they might learn what doesn't come into my bag.

372
00:47:27,940 --> 00:47:34,210
Maybe comes early in the year, but I can watch it changes. That's why he's got some.

373
00:47:35,150 --> 00:47:39,880
Yeah, it's like I just got serious about this.

374
00:47:42,430 --> 00:47:52,690
Yeah. Are these. So how often does confession or something about probation?

375
00:47:52,870 --> 00:47:56,020
Yeah. So you can. You can, like, get to it.

376
00:47:56,630 --> 00:48:01,820
What? So just about what I have, but all of these things, you know, some interesting things.

377
00:48:03,730 --> 00:48:08,220
I think you do get a tiny bit of variation where you can you can come up with examples first,

378
00:48:08,280 --> 00:48:11,379
a little bit of animation, but it's just different for the dough.

379
00:48:11,380 --> 00:48:15,480
Ah, yeah, yeah. Exactly. Yeah.

380
00:48:15,660 --> 00:48:20,560
You know what you're saying is good?

381
00:48:20,890 --> 00:48:30,190
Wants everyone to be more useful just for the first time, right?

382
00:48:30,340 --> 00:48:34,809
Yeah. So from that, what?

383
00:48:34,810 --> 00:48:44,860
I want to compare my medication that I'm working at to another medication like another.

384
00:48:44,860 --> 00:48:51,089
It would be like. Yeah, it would be like a kind of like comparing it to like something that's also like a standard.

385
00:48:51,090 --> 00:48:54,550
So not more for, like, something of new. Mm hmm.

386
00:48:54,850 --> 00:48:59,320
So you're trying to show that, like, when I have. That was not worse than what's already there.

387
00:48:59,680 --> 00:49:03,760
Yeah. Okay. Yeah. So, like.

388
00:49:03,790 --> 00:49:07,830
Yeah. You want to do it?

389
00:49:10,200 --> 00:49:17,250
So could I do that for. If getting the truck that I was going to use.

390
00:49:17,290 --> 00:49:24,690
Mm hmm. But what I do that for the record, I do that for the drama that I'm researching,

391
00:49:24,700 --> 00:49:29,320
even though, like, it's something that probably not necessarily like a number.

392
00:49:30,280 --> 00:49:33,670
So you do like, are you trying to grow it to. Yeah, to drugs.

393
00:49:34,270 --> 00:49:39,070
That's the questions like are you going to do that or and just do something that will be something else for your case control or.

394
00:49:39,770 --> 00:49:47,320
Mm hmm. Yeah. Because, like, my main focus is like, antidepressants and stuff.

395
00:49:49,790 --> 00:49:53,320
Like, this is my main drug.

396
00:49:56,710 --> 00:50:08,650
Um, if you go to the trials, um, I want someone to get down to it over here.

397
00:50:08,950 --> 00:50:11,970
I updated that, um, the screenshot of the site.

398
00:50:12,280 --> 00:50:22,060
I am still processing email, um, screenshot for like for paper because and so if you want to it in the files in campus, if you want to switch.

399
00:50:22,500 --> 00:50:28,840
Oh, okay. Um, the which, which triggered this.

400
00:50:34,950 --> 00:50:38,940
I like read it in case that the likes of the boys. But it's okay.

401
00:50:39,160 --> 00:50:42,480
Okay. Okay. Um. Yes.

402
00:50:43,080 --> 00:50:48,720
Yes. No. No. So this is like my main.

403
00:50:49,140 --> 00:50:56,490
Thanks for your time. You can look at all that.

404
00:50:56,490 --> 00:51:01,490
I think of us for sure. I have more than one. Yeah.

405
00:51:03,030 --> 00:51:07,290
What was the standard like to start you off on this whole thing?

406
00:51:08,600 --> 00:51:13,079
Mm hmm. Yeah. Um, it's like.

407
00:51:13,080 --> 00:51:17,400
This is my main question, right? Does taking this.

408
00:51:20,440 --> 00:51:26,139
Anything cause he was like, isn't that what a dang? Is this a causal relationship between, you know, even like, say, like an influence?

409
00:51:26,140 --> 00:51:31,210
Like it's just associations. You have to look at the positive, but because it's soothing.

410
00:51:31,450 --> 00:51:35,100
Yeah, I'm hoping it's negative. Yeah, so positive.

411
00:51:35,650 --> 00:51:38,770
Good question, Mark. So, what do you like?

412
00:51:38,770 --> 00:51:44,530
Um, like a retrospective, like everyone who has those, but like, look forward in time.

413
00:51:45,940 --> 00:51:49,180
Mhm. Yeah, but you do two studies, right.

414
00:51:49,780 --> 00:51:54,219
Yeah. So yeah, exactly. One the like the second time going I'm struggling.

415
00:51:54,220 --> 00:52:07,450
Yeah. Because it doesn't sound like cause you're not sure what you want to show to it.

416
00:52:08,150 --> 00:52:12,700
That's so I want to tell you about it when you're comparing Lexapro to like attention.

417
00:52:12,760 --> 00:52:16,570
So they were like comparing yesterday.

418
00:52:16,750 --> 00:52:19,810
They were like Lexapro was like third standard, right?

419
00:52:19,990 --> 00:52:23,440
Yeah. So research I was like I was understanding for like that person.

420
00:52:23,440 --> 00:52:27,660
And then they had a meditation and they were trying to prove that meditation was not works.

421
00:52:27,670 --> 00:52:33,940
That was as good as, for instance, just that second one.

422
00:52:33,950 --> 00:52:37,350
That's the one I'm struggling on. It's like crutch perspective for sure. Makes sense.

423
00:52:37,360 --> 00:52:39,010
Yeah, because like, you know, like, you know,

424
00:52:39,400 --> 00:52:50,430
all these exposure control over there for a while I think in like serious moments or you don't, I guess trying to find a control group.

425
00:52:54,820 --> 00:53:01,790
Yeah. But then can I like if my main outcome is just like suicide?

426
00:53:01,820 --> 00:53:05,190
Like, a lot of people are dying for me, right?

427
00:53:05,490 --> 00:53:11,190
I mean, then, like, it's like when the people were just like that, like you might want to like.

428
00:53:11,830 --> 00:53:15,610
Mhm. Um. If you have like attempted.

429
00:53:16,770 --> 00:53:29,130
First. It's like if you want to include like a ten. Those are the same categories I don't like the things I feel.

430
00:53:30,000 --> 00:53:33,840
Are people treated differently or are they to the same?

431
00:53:35,100 --> 00:53:39,840
Like if someone has on my face, which I agree, it's like. Do you agree with that?

432
00:53:41,880 --> 00:53:45,620
And just into something you would think would be a better opportunity. Okay.

433
00:53:45,660 --> 00:53:58,830
Because I am doing similar looking at depression in our bio class for our project and they talk about attempted depression.

434
00:53:59,880 --> 00:54:07,170
Yeah. Yeah. So that's the outcome. Okay. And then all the other things like that into that project.

435
00:54:07,320 --> 00:54:10,680
Right, that and completed.

436
00:54:12,330 --> 00:54:16,260
And as I say, they're almost as well.

437
00:54:16,260 --> 00:54:19,590
They include in both sides. I think so but then they also.

438
00:54:19,690 --> 00:54:30,540
Yeah. And like the not actually like but in the article like that's what they did is I think was attempted and completed,

439
00:54:30,540 --> 00:54:37,860
but they did two separate like characteristics of those at a time they were still somewhat completed.

440
00:54:38,400 --> 00:54:44,760
Right. There was another article that I read somewhere, and they also included like suicidal ideation.

441
00:54:45,150 --> 00:54:48,390
And so I think that's a really difficult thing to measure.

442
00:54:48,600 --> 00:54:57,270
Yeah. And I guess that something you can consider it, but I guess what else would you share or something like that to also include like teachers?

443
00:54:57,300 --> 00:55:12,090
I think that there's going to be it's very hard to adjust to that one person you're going to introduce you to think about,

444
00:55:12,120 --> 00:55:17,100
remember, because like, it's really hard for me to avoid the bias completely like something.

445
00:55:20,520 --> 00:55:42,190
Probably under four. It's not prosecution, but you can look at it and not only shoot the numbers you of done what you want.

446
00:55:43,670 --> 00:55:58,900
That's the meaning. But the goal is to look as far as making the biggest Eagle Ford Association.

447
00:56:00,570 --> 00:56:02,520
Mm hmm. Yeah.

448
00:56:02,540 --> 00:56:15,519
So if I had to pick between, like, a bios that I'd like to have and I want to do something that underreported or pulled it towards my partner.

449
00:56:15,520 --> 00:56:23,360
That's right. Yeah. Mean sometimes. But sometimes. If we're going to sing a song like it's one of those things where like,

450
00:56:23,360 --> 00:56:45,310
I think it's really my Contract with America is way too good because I'm worried about, like, if didn't didn't want it exaggerated your involvements.

451
00:56:46,950 --> 00:56:51,659
But can it happen where you think if you didn't include this variable?

452
00:56:51,660 --> 00:56:57,620
There's. Just think the outcome.

453
00:56:58,370 --> 00:57:02,350
I mean, if you feel like you're into the president suicide.

454
00:57:04,360 --> 00:57:11,490
And that's not as long as I suppose you are right.

455
00:57:12,760 --> 00:57:27,040
She. I was your like outcome like a book. So I mean it's I like on the call so much you like suicidal ideation is not necessarily how.

456
00:57:29,760 --> 00:57:32,820
Was like, Yeah, that's the way you're doing it.

457
00:57:33,870 --> 00:57:39,710
Because you like to take this opportunity and like increase your thoughts of suicide, rather.

458
00:57:42,070 --> 00:57:52,320
Yeah. Yeah.

459
00:57:54,000 --> 00:58:00,210
It's been there. Everyone keep on your hands. What are you going to gear again?

460
00:58:01,020 --> 00:58:04,220
I usually get the competitiveness of the sport, the social life.

461
00:58:05,610 --> 00:58:13,520
So even then, I feel like there might be things that I don't know. Yeah, I think it's just that it's like.

462
00:58:13,550 --> 00:58:22,320
It's to do with that. It's like, I'm not going to do it, but I have to find a coach attempted.

463
00:58:23,370 --> 00:58:30,510
What kind of like answer the person that was suicide is like, seriously, that's what people have done.

464
00:58:30,750 --> 00:58:41,920
Even if it's just like one of those, like I'm getting of the, like, all right, let's do like kind of snowball surgery.

465
00:58:42,120 --> 00:58:49,130
Like keep their effort to listen to you were like, oh, this is like in when I was like, yeah,

466
00:58:50,160 --> 00:59:02,010
I might have to come back to control this sort of feel sorry for the craziness as much as I feel like it's messing up so much.

467
00:59:02,290 --> 00:59:06,870
Yeah, but you know what? Maybe someone can do it.

468
00:59:07,650 --> 00:59:13,200
Like, the worst way to do it was like, that's my.

469
00:59:13,370 --> 00:59:16,830
And we're just not.

470
00:59:19,090 --> 00:59:28,850
They have this survival when this one does last with me.

471
00:59:29,380 --> 00:59:36,930
It's such a weird thing. So. Because I feel like you want to.

472
00:59:37,240 --> 00:59:49,090
I want to. Yeah. Know, assuming it was like I said, it would seem like their intention really was.

473
00:59:51,360 --> 00:59:56,370
And people realize they're going to do it correctly or whatever.

474
00:59:56,460 --> 01:00:02,180
I feel like if you say, Oh, oh, yeah.

475
01:00:03,770 --> 01:00:17,510
Right. Let's take a little bit of the real world because it wouldn't be like as far away from the whole point of our.

476
01:00:25,670 --> 01:00:33,990
Yeah. I have no answer to that.

477
01:00:34,350 --> 01:00:38,760
But anyway, I also. You need to be really,

478
01:00:38,870 --> 01:00:49,239
really very clear and specific with what your exposure to the presence of abuse use at any time you

479
01:00:49,240 --> 01:00:57,250
have something like having or like could be a thing of like you look at someone like attempted

480
01:00:57,250 --> 01:01:03,820
suicide and you look at like their medical history maybe three months before that they going

481
01:01:03,870 --> 01:01:13,390
refilling so like a rebound kind of thing and be like this cold stop or is it caused by a prisoner?

482
01:01:14,680 --> 01:01:25,300
Do you count like that as well as well as giving them like no one else will have to go think.

483
01:01:26,810 --> 01:01:31,470
What are you going to do in the question of Pakistan's border?

484
01:01:31,580 --> 01:01:40,900
I don't like expressing it, like that's what I want.

485
01:01:42,520 --> 01:01:53,540
But then I guess is look at like one or exclude, you know, you have like so my career, like she was sort of like fairly rare.

486
01:01:53,690 --> 01:02:04,489
How come it might be too much and yeah, which is why I think in that case, control in theory be better.

487
01:02:04,490 --> 01:02:14,780
But then I have the issue of I can't figure out why this suicide is a rare outcome, but I can't figure out my controls and identify my exposure.

488
01:02:15,440 --> 01:02:20,940
I'm like, not everyone's on antidepressants, you know?

489
01:02:21,310 --> 01:02:27,930
Yeah, it's. It's messy. It's really. Okay, I'll start with that.

490
01:02:28,130 --> 01:02:32,780
Yeah. And then, you know, you're not going to notice.

491
01:02:32,840 --> 01:02:36,760
It's like trying to put her in prison.

492
01:02:36,770 --> 01:02:42,800
Plus, he's in jail. I guess I'm not doing like, that kind of surgery anymore, but like,

493
01:02:42,940 --> 01:02:50,780
you think about something kind of like go pay close attention to what they talk about, like in their discussions.

494
01:02:50,780 --> 01:02:57,790
Because all like, oh, we have very extensive discussion sections of like explaining why we chose this because of this excluding these people.

495
01:02:57,800 --> 01:03:03,770
So this is probably like probably would be very detailed hopefully if I'm not in the paper.

496
01:03:03,830 --> 01:03:08,480
Yeah. Because it should be. Okay, I'll try.

497
01:03:08,540 --> 01:03:17,059
Do they often, are they often accurate with what study they actually done so.

498
01:03:17,060 --> 01:03:18,920
No they're not always I really,

499
01:03:18,920 --> 01:03:27,290
I felt like it's not like a horrible thing I've only read the paper about like I was like telling it's like to do that again.

500
01:03:29,180 --> 01:03:37,530
Okay. Yeah. Thank you. Somebody you can't question.

501
01:03:39,800 --> 01:03:42,830
That should be a common question of suicide.

502
01:03:43,610 --> 01:03:49,310
Yeah, that's a really hard that's a really tough crime claims database and match.

503
01:03:49,670 --> 01:03:53,930
But other than you would need all your pieces from. Yeah.

504
01:03:53,930 --> 01:03:58,250
So I feel like that's where they would fit into like the whole, like having depression and like maybe like feeding or like not.

505
01:03:58,580 --> 01:04:02,750
But then if you don't have insurance and like, you probably, like, be on antidepressants, so does it matter?

506
01:04:02,990 --> 01:04:09,880
Yeah, that's hard. That's really tough. I think. I think that's why I think I think you should use like a medical.

507
01:04:10,700 --> 01:04:14,700
Yeah, that's right. A retrospective study, smoking crack. Wow.

508
01:04:15,200 --> 01:04:19,720
I didn't want to be like number one on that. I was nervous.

509
01:04:20,060 --> 01:04:23,060
Yeah, I told him that before. Like, I was like, man, I'm trying to diagnose.

510
01:04:23,600 --> 01:04:36,560
But even then, like, sometimes people would live with depression for long time before that, you're like, Yeah, I will try to, like, go right now.

511
01:04:38,300 --> 01:04:40,010
But then that and that type of thing started.

512
01:04:40,220 --> 01:04:45,390
But when you switch, like if you think about a lot of things, it was like, if I don't really answer the question right now,

513
01:04:45,390 --> 01:05:03,920
I have to like more and come back on to on like restart and it's like you would, you would have to take that, you know, like I would, I would match.

514
01:05:04,220 --> 01:05:14,870
I think I would. Yeah. They don't necessarily start with the the drug and then you would match the suicide of suicide.

515
01:05:15,400 --> 01:05:17,730
All right. So where's the other person on that drug?

516
01:05:19,500 --> 01:05:28,350
I just I feel like even I was doing masochism or something, like I was on Lexapro for a long time.

517
01:05:28,850 --> 01:05:33,770
It for me, I came to like, there's a law for like Prozac or something.

518
01:05:34,010 --> 01:05:38,420
And then two months later, I committed suicide. Like, is that like Prozac or is that like.

519
01:05:40,100 --> 01:05:43,340
I think it's usually a lot like the effect doesn't work.

520
01:05:44,830 --> 01:05:50,410
Essentially you have to define what your what your exposure is, isn't it, currently.

521
01:05:51,160 --> 01:05:55,050
Yeah. Was it like a like a few months.

522
01:05:55,070 --> 01:06:03,280
Yeah. Yeah. You'd have to. You'd have to. It's probably the easiest to say of my exposure is currently ever at the time,

523
01:06:03,560 --> 01:06:11,470
within the week before you know, and you're going to judge it by the prescription, you know etc.

524
01:06:11,740 --> 01:06:19,150
So then like in your life you're going to model that. Would you include each medication from the dosage at one time?

525
01:06:19,960 --> 01:06:23,380
Well, I think who has every particular medication is concerned.

526
01:06:23,650 --> 01:06:29,160
So that's really what you're supposed to look at. But then when something is looking like, okay, let's take a look at that.

527
01:06:29,610 --> 01:06:35,680
A lot more of a personal like like having that come from a different medication before that.

528
01:06:36,220 --> 01:06:44,440
I think it's a non-issue. Hands on. Yeah, it depends on how you stop your partner to decide if they're not changeable.

529
01:06:44,450 --> 01:06:45,939
I would match your diagnosis.

530
01:06:45,940 --> 01:06:57,280
And, like, if there's something that assuming happening, and then it's not what you like, it determine severity by those pills.

531
01:06:58,750 --> 01:07:03,639
No, because it's partly based in the tabloid size like that.

532
01:07:03,640 --> 01:07:20,890
But I think I know, you know, often for people to be like getting treatment from the physician and they probably do have to say, okay, okay.

533
01:07:22,610 --> 01:07:28,600
So first of all, the extra credit went to some first specific person.

534
01:07:28,930 --> 01:07:39,970
But actually I will give a month to reach out on the I'm telling them about Myrbetriq.

535
01:07:40,800 --> 01:07:43,810
Oh yeah I know that's a lot of reading in December. Yeah.

536
01:07:45,370 --> 01:07:51,730
I usually make a difference for Thanksgiving because I want to give them a chance to get through like everything they to.

537
01:07:52,570 --> 01:07:56,800
Yeah. Yeah, everyone has to do that.

538
01:07:57,400 --> 01:08:01,330
Yeah, that's good because I'm all for that and.

539
01:08:02,110 --> 01:08:16,870
Yeah. And it's still up. I just want to say, you know, I will make a little announcement about that.

540
01:08:17,230 --> 01:08:25,750
Do you include co-morbidities? Like if you have like depression and anxiety or depression or anxiety like ADHD or like depression and like bipolar?

541
01:08:26,590 --> 01:08:36,970
I probably I probably more than that from that because like, although it's already an individual, identify themselves know using that word.

542
01:08:37,870 --> 01:08:48,189
I mean, I would match on any any diagnosis except are expected a reasonably correlated profile with regards to

543
01:08:48,190 --> 01:08:57,870
depression that would you want to match on like age and time of going into the age of two years and yeah.

544
01:08:57,880 --> 01:09:06,370
And sex and race when I wasn't too much I really was like a lot of it depends on the size of your database.

545
01:09:06,370 --> 01:09:12,530
Yeah. Like if you really expect race to be a confounding thing because like, like white men like health, much higher suicide rate,

546
01:09:12,700 --> 01:09:22,710
something like, like men in a close race or given the same as what I guess it's like a lot of so many things are going on.

547
01:09:22,720 --> 01:09:25,690
I have no idea. You're like 30 because you know,

548
01:09:25,690 --> 01:09:30,969
like if I like even like say the word mental home like Thanksgiving dinner with my black and I just kind of like, what was that?

549
01:09:30,970 --> 01:09:39,980
I'm like, we all have those. They have some clearly diagnosable condition and they're like, No, that's just my thing.

550
01:09:40,030 --> 01:09:49,839
No, it's like, Oh, all right, so we're going to get to go ahead and get started back up.

551
01:09:49,840 --> 01:09:53,980
Have people generally finished or do people generally need more time to?

552
01:09:58,270 --> 01:10:04,599
Thumbs up if you're finished, thumbs down if you're not to go to a few people.

553
01:10:04,600 --> 01:10:10,360
So we won't go over right now. We will get started back with a lecture.

554
01:10:10,900 --> 01:10:20,830
All right. So diagnostic studies, reporting standards or stars, in addition to elements that you see in other and other reporting standards,

555
01:10:21,850 --> 01:10:28,330
you also will want to see or the checklist includes how you deal with indeterminate results,

556
01:10:30,250 --> 01:10:32,380
the standard selection,

557
01:10:33,130 --> 01:10:43,120
how cut points for determining the spectrum of disease and the individuals that were included in that study and then blinding who responded.

558
01:10:46,000 --> 01:10:49,959
And that's a kind of, you know, some of the additional factors that you want to be thinking about when you're right,

559
01:10:49,960 --> 01:10:55,780
when you're reading diagnostic accuracy studies.

560
01:10:57,790 --> 01:11:06,009
All right. So you asked for not least screening or screening is the application of a test to people who are as of yet

561
01:11:06,010 --> 01:11:12,580
asymptomatic for the purpose of classifying them with respect to their likelihood of having a particular disease.

562
01:11:13,420 --> 01:11:20,680
It does not diagnose a disease. It's the same the likelihood and those who test positive are sent on for further evaluation.

563
01:11:20,680 --> 01:11:27,100
So who in here has undergone a screening test? Probably all of you.

564
01:11:27,100 --> 01:11:31,629
I'm guessing if you've ever been to a doctor in the United States.

565
01:11:31,630 --> 01:11:35,890
Right. Because they will screen you for high blood pressure every single time you go in.

566
01:11:36,100 --> 01:11:42,429
Generally speaking, some examples of screening programs in the United States are.

567
01:11:42,430 --> 01:11:46,420
Breast cancer screening. Newborn screening. Cervical screening.

568
01:11:46,690 --> 01:11:50,110
Colorectal cancer screening. Prostate cancer screening.

569
01:11:50,230 --> 01:11:57,400
Lung cancer screening. So characteristics of a disease appropriate for screening.

570
01:11:57,700 --> 01:12:07,390
And you should be serious. Right. There are questions around, you know, cost effectiveness and an ethics treatment given before symptoms develop.

571
01:12:07,540 --> 01:12:13,149
Must reduce the morbidity or mortality more than treatment given after the symptoms develop.

572
01:12:13,150 --> 01:12:15,730
You really have to benefit from catching that disease early.

573
01:12:17,320 --> 01:12:24,670
So the consequences of failing to detect early must be sufficiently grave to warrant the risks and discomforts of the screening procedure.

574
01:12:25,810 --> 01:12:30,340
And then the prevalence of the preclinical condition should be high among the population screened.

575
01:12:32,020 --> 01:12:37,240
That is because you have to see it to think about the cost of screening relative to the number of cases you're going to be captured.

576
01:12:37,280 --> 01:12:44,930
Yes, I to. So.

577
01:12:48,990 --> 01:12:54,360
I think I've got one where it's like if you're screening and you know, the test isn't that sensitive.

578
01:12:54,750 --> 01:12:57,959
If I get a lot of like sex positive, it's like,

579
01:12:57,960 --> 01:13:04,290
do you share that information with somebody and then like increased stress and all of these other downstream effects.

580
01:13:04,290 --> 01:13:11,980
But it's like, oh, actually, sorry, that was wrong. And then I also think like newborn screening in order for a test to include it on the.

581
01:13:13,060 --> 01:13:19,000
Platelet plethora of tests. You actually have to have some kind of treatment so you can test for things.

582
01:13:19,000 --> 01:13:21,129
But if there isn't an effective clinical treatment,

583
01:13:21,130 --> 01:13:26,680
they're not going to be included on that because it's like, well, maybe this thing sorry, like your S.O.

584
01:13:26,680 --> 01:13:36,030
Well, those are the two. There's also been a lot of controversy around like prostate cancer screening because it's not that accurate.

585
01:13:36,030 --> 01:13:41,720
And then if you get like a like a false positive, the next stop is a biopsy, which is I mean,

586
01:13:41,760 --> 01:13:45,240
if you want to put someone through a biopsy of the price, they don't have to.

587
01:13:45,780 --> 01:13:48,209
And it's it's like it doesn't actually catch that much many people.

588
01:13:48,210 --> 01:13:55,110
And it's not that it's one of those things where, like, that number needed to treat it is like crazy to catch like one person.

589
01:13:55,110 --> 01:14:03,929
So you put all these people through an unnecessary biopsy for like one person and then for prostate cancer and some other diseases, two for two,

590
01:14:03,930 --> 01:14:14,069
you'll catch some individuals in that screening that may have extremely slow growing cancers where they would never actually,

591
01:14:14,070 --> 01:14:17,850
you know, they they won't actually ever have clinical disease from it.

592
01:14:17,880 --> 01:14:21,700
Right. It's not always possible to differentiate those individuals.

593
01:14:21,700 --> 01:14:31,390
So. The detection rate is a term used for sensitivity and screening programs.

594
01:14:32,050 --> 01:14:38,110
Note There's also a terminal cancer detection rate that is not known for sensitivity.

595
01:14:38,950 --> 01:14:42,820
The cancer detection rate is the prevalence of cancers as screening examination.

596
01:14:43,360 --> 01:14:46,720
A better term would be screened. Positive cancer prevalence.

597
01:14:50,620 --> 01:14:57,430
False positive rate it's it's commonly seen in diagnostic accuracy reports.

598
01:14:58,060 --> 01:15:02,080
Number of false positives divided by all negatives be over B plus de.

599
01:15:02,470 --> 01:15:11,070
It's also one minus the specificity. The benefit of the service specificity is that it's easier for individuals to interpret.

600
01:15:11,080 --> 01:15:14,890
So you often see it on web pages or information.

601
01:15:15,160 --> 01:15:17,280
So you tested positive. What does that mean? Right.

602
01:15:20,380 --> 01:15:26,950
So if the specificity of two tests was nine over a 90% of 95% of positive rate of the sequence would be 10%.

603
01:15:27,310 --> 01:15:34,520
5%. The odds of being affected, given a positive result for AP,

604
01:15:34,520 --> 01:15:39,950
are the ratio of the numbers of infected to uninfected individuals among those with positive results.

605
01:15:40,700 --> 01:15:42,650
It's similar to the positive predictive value.

606
01:15:45,230 --> 01:15:52,160
It provides easier to an information to interpret information of the HPR and the possible greater value are high.

607
01:15:53,000 --> 01:16:02,000
So the paper to test for 20 to 1, 50 to 1, then the positive predictive value would be 95% and 98%.

608
01:16:02,780 --> 01:16:10,640
So you see PR a lot in, uh, in antenatal screening.

609
01:16:11,360 --> 01:16:17,810
So here it's just looking for a variety of tests, looking for Down's syndrome.

610
01:16:18,380 --> 01:16:24,410
Right. So the integrated test serum, integrated test, combine test, quadruple test and the quadruple plus in t test.

611
01:16:24,950 --> 01:16:32,900
And here it talks about possible the false positive rate as well as the odds of being infected given a positive result.

612
01:16:39,920 --> 01:16:50,930
Okay. So for screening, it's difficult to estimate the false positive rate and the demand screening for some diseases.

613
01:16:51,170 --> 01:16:57,320
The nominator may not be known. That's particularly true for cancer, right?

614
01:16:58,700 --> 01:17:05,270
And usually you have the slight problem, right? That the more detailed the investigation, the more cases you're going to be finding.

615
01:17:06,770 --> 01:17:11,179
So for bias and screening studies and what we want to think about are detection bias

616
01:17:11,180 --> 01:17:17,180
or referral or volunteer bias or any one right lead time bias and length bias.

617
01:17:19,040 --> 01:17:23,360
So for we've heard about detection bias and referral volunteer bias before,

618
01:17:24,080 --> 01:17:30,799
but for lead time bias is you've got this kind of inherent bias in screening, right?

619
01:17:30,800 --> 01:17:35,810
Where you'll detect cases earlier, you know, before the screening.

620
01:17:35,810 --> 01:17:45,410
Right. So here we've got a screen detected at 45 degree 44, age 45, but it wouldn't be clinically detected until age 50.

621
01:17:46,160 --> 01:17:49,430
But either way, that still occurs at age 60.

622
01:17:50,120 --> 01:17:56,179
Right. But if you just calculated the amount of time, you know, that somebody survived with disease,

623
01:17:56,180 --> 01:17:59,690
you would say, well, the people who were screened survived for longer. Right.

624
01:18:02,090 --> 01:18:09,840
This is from Gord is just another way to show that lead time bias here.

625
01:18:11,540 --> 01:18:20,990
There's also a length bias. So it's it which results in the overestimation of survival duration among screening

626
01:18:21,590 --> 01:18:25,100
detected cases caused by the relative excess of slowly progressing cases.

627
01:18:25,580 --> 01:18:28,940
So this is kind of like if you're just screening at one point in time,

628
01:18:29,330 --> 01:18:33,950
you've got all these cases occurring with rapidly progressing cases and slowly progressing cases.

629
01:18:33,950 --> 01:18:40,850
We've got six of each right here. Right. So you screen at one point in time, you catch two of the rapidly.

630
01:18:41,600 --> 01:18:52,800
In this example, you sort of time two of the rapidly progressing cases, but you'd catch four of the slowly progressing progression cases.

631
01:18:53,750 --> 01:18:59,360
Right. All right, so that's length bias.

632
01:18:59,370 --> 01:19:07,679
So we really need to I mean, like I said, volunteer referral bias detection bias we're concerned with as well, but we've already covered those.

633
01:19:07,680 --> 01:19:10,560
But the full time bias only bias. All right.

634
01:19:11,040 --> 01:19:22,109
So we'll just go through one example for screening and also for a a study comparing two different screening

635
01:19:22,110 --> 01:19:31,860
tests so gestational diabetes can lead to adverse health outcomes for both the pregnant woman and the infant.

636
01:19:32,070 --> 01:19:40,830
So you the preeclampsia, there's newborn shoulder disk seal, which is when the baby gets caught in the birth canal.

637
01:19:41,130 --> 01:19:49,260
Right. And it can cause some pretty severe nerve damage and actually in very severe cases can cause people or infant death.

638
01:19:51,480 --> 01:19:55,020
The U.S. Preventative Services Task Force recommends that pregnant women be screened

639
01:19:55,020 --> 01:19:59,670
for just enough gestational diabetes mellitus after 24 weeks of pregnancy.

640
01:20:02,550 --> 01:20:05,310
Two different ways that you can do screening.

641
01:20:06,360 --> 01:20:15,930
So one step screening is a fasting patient undergoes a two hour 75 gram oral glucose glucose tolerance test.

642
01:20:16,560 --> 01:20:26,070
The result is abnormal. If any one glucose results, the fasting, the one hour or the two hour is above a threshold, a specified threshold.

643
01:20:26,670 --> 01:20:34,650
Right. So the woman's going to fast go into the to the to the lab, sit around to get three blood draws.

644
01:20:34,890 --> 01:20:41,040
You don't it kind of breaks, you know, when you go in to get blood drawn.

645
01:20:41,040 --> 01:20:43,440
I go over a month all the time, study right.

646
01:20:43,800 --> 01:20:49,010
Get my blood drawn and always asks you that are you doing a, you know, a fasting like a times test, right?

647
01:20:49,050 --> 01:20:49,950
Like that's probably why.

648
01:20:51,450 --> 01:21:04,740
So the two step approach is you first do a non fasting screening, so they ingest 50 grams of oral glucose followed by a one hour glucose measurement.

649
01:21:06,180 --> 01:21:15,660
If that one hour glucose measurement is above a certain level, then you say, okay, you've got gestational diabetes.

650
01:21:16,350 --> 01:21:27,419
But if it's between 130 minutes per deciliter and 200 MCs per deciliter, the patient's going to undergo a fasting three hour glucose tolerance test.

651
01:21:27,420 --> 01:21:34,950
So they're going to be told to come back for second test, and then they use specified thresholds.

652
01:21:36,150 --> 01:21:42,090
So for one step versus to stop or it's unclear or at least at the time of this paper,

653
01:21:42,090 --> 01:21:47,730
I think it's actually sort of unclear whether one step or two step screening is superior.

654
01:21:48,390 --> 01:21:54,290
And in fact, one's suggested by and I don't remember which one the, you know,

655
01:21:54,420 --> 01:21:59,100
one medical society like looking at diabetes and the other one by obstetricians.

656
01:21:59,100 --> 01:22:09,870
Right. So there's there's a debate on that. So the one step approach leads to more diagnoses of gestational diabetes because women with

657
01:22:09,870 --> 01:22:15,810
mild hypoglycemia will read glycemia will receive a diagnosis of gestational diabetes.

658
01:22:16,590 --> 01:22:20,210
However, the health impacts on the mother and the child like, you know,

659
01:22:20,290 --> 01:22:26,910
separate preeclampsia as it related to poor birth outcomes is etc. is not known.

660
01:22:29,790 --> 01:22:40,430
I don't know if any of you in here have done a fasting glucose test or have gone with somebody exactly who comes down to do a fasting glucose test.

661
01:22:40,440 --> 01:22:46,770
So I can tell you, you know, as a pregnant woman, you know, 24 weeks to not eat anything.

662
01:22:47,160 --> 01:22:51,870
Right. And then you have to chug that like they give you a certain amount of time.

663
01:22:51,870 --> 01:22:56,040
The chug is like sickeningly sweet drink.

664
01:22:57,060 --> 01:23:01,260
And I have actually seen a number of people not be able to do it right.

665
01:23:01,260 --> 01:23:03,500
They have not been able to hold it down sort of thing, you know,

666
01:23:03,510 --> 01:23:08,489
so you'll see them go chugging out of the room or they may not even make it out of the room.

667
01:23:08,490 --> 01:23:18,440
Right. So, like, not, not the best in the world, it can be a bit uncomfortable and it's more uncomfortable than the non fasting, right.

668
01:23:18,900 --> 01:23:22,890
Just because you're drinking more with fasting, you know.

669
01:23:23,010 --> 01:23:28,620
So there you go. But, you know, the two step approach is diagnosing fewer people.

670
01:23:29,760 --> 01:23:38,370
Right. Is that a good or bad thing? We're not really sure. And it requires more visits and specifically it requires that people return.

671
01:23:39,120 --> 01:23:46,860
Right. So there you go. At least that they're kind of in that indeterminate area.

672
01:23:47,820 --> 01:23:54,210
So there was a clinical trial done in which then 2021 of one step versus two step screening.

673
01:23:55,110 --> 01:24:02,590
Also a pragmatic. Randomized clinical trial of gestational diabetes screening, published in a very good journal and internal medicine.

674
01:24:04,720 --> 01:24:14,920
Yeah, Katie's laughing because I actually got a revised resubmit a few days ago from the language medicine, which is great.

675
01:24:15,220 --> 01:24:22,840
We were discussing the merits of the Journal Re impact factor, but anyway methods.

676
01:24:23,140 --> 01:24:29,430
We performed a pragmatic randomized trial comparing one step screening that is a glucose tolerance

677
01:24:29,470 --> 01:24:35,020
test in which the blood glucose level was obtained after the oral administration of a 75 gram glucose

678
01:24:35,350 --> 01:24:42,549
load in the fasting stage with a two step screening glucose challenge test in which the blood glucose

679
01:24:42,550 --> 01:24:48,100
level was obtained after the oral administration of a 50 gram glucose load in the non fasting state,

680
01:24:48,520 --> 01:24:55,050
followed if positive, by an oral glucose tolerance test with a 100 gram glucose followed in the fasting state.

681
01:24:55,480 --> 01:24:59,110
In all, pregnant women who received care in two health systems,

682
01:25:01,540 --> 01:25:10,720
the outcomes that were measured where the primary outcomes were a diagnosis of gestational diabetes right large for gestational age infants.

683
01:25:11,260 --> 01:25:23,860
That is a risk factor for adverse birth outcomes and also for jaundice and having liver issues after being born.

684
01:25:25,090 --> 01:25:31,540
A Perinatal Composite Outcomes for stillbirth neonatal death shoulder just tox.

685
01:25:31,550 --> 01:25:33,340
Yeah, I think I'm saying that correctly.

686
01:25:33,610 --> 01:25:44,650
Bone fracture or any arm or hand nerve palsy related to birth injury, gestational hypertension or pre-eclampsia and a primary caesarean section.

687
01:25:46,450 --> 01:25:53,229
So here we look kind of familiar, right? You've got a a flow chart of people in the study.

688
01:25:53,230 --> 01:26:02,230
One thing that you'll notice here, so they've got 35,579 women without preexisting type one and type two diabetes underwent randomization

689
01:26:02,230 --> 01:26:08,440
at the first prenatal visit for gestational diabetes screening as a part of clinical care to determine,

690
01:26:08,440 --> 01:26:11,170
you know, would they get that that one test or that two test.

691
01:26:11,860 --> 01:26:18,069
What you'll notice is they lost a good number of participants, mostly because there wasn't, you know,

692
01:26:18,070 --> 01:26:25,960
a third, almost a third, not quite that miscarry a fairly common outcome early in pregnancy.

693
01:26:27,550 --> 01:26:36,910
So they ended up with 23,792 who were eligible to undergo screening 11,009,

694
01:26:36,910 --> 01:26:44,440
22 or 21 Step 11 870 were assigned to two steps right from some people didn't undergo either screening.

695
01:26:46,960 --> 01:26:51,700
And then of those that were assigned to a particular screening,

696
01:26:51,700 --> 01:26:56,830
it tell us how many what underwent one step and how many underwent two step screening for each group.

697
01:26:57,640 --> 01:27:04,210
And what you'll notice is that a lot of people who were assigned to one step here in the undergoing two step screening.

698
01:27:05,860 --> 01:27:14,650
So there you go. One thing to notice about this flow chart is every single person is accounted for.

699
01:27:15,110 --> 01:27:21,100
Right? Like in a good study flow chart of your participants, everybody needs to be there.

700
01:27:22,030 --> 01:27:27,819
And if for some reason the numbers don't add for an explainable reason, you need to stay.

701
01:27:27,820 --> 01:27:31,990
So at the bottom, like for example, we have a cohort study where we've had some people leave.

702
01:27:32,770 --> 01:27:36,370
So we had to say they drew and then they come back in, you know.

703
01:27:36,370 --> 01:27:40,689
And so if you're not showing that leaving and coming back in for some people, which is a little bit weird,

704
01:27:40,690 --> 01:27:49,060
then you just know at the bottom, no, there were, you know, two people in 2021 and five people in 2022 exited reentered in the same year.

705
01:27:49,900 --> 01:27:53,170
Right. Which is why the numbers don't match. But there you go.

706
01:27:54,820 --> 01:28:00,700
I cannot tell you how many flowcharts I see where like the numbers do not add up.

707
01:28:00,700 --> 01:28:05,620
You're like, where are the other, you know, 20% of the people that started at the top, like where do they go?

708
01:28:05,620 --> 01:28:13,840
Right. So, all right. So this is just character characteristics of the trial population.

709
01:28:13,870 --> 01:28:19,749
It's not too small. It's a little small on my screen. But what we see here are what you notice, right?

710
01:28:19,750 --> 01:28:26,530
What you're wanting to look at are do the two groups look similar, the ones that were randomized, do they look similar to you?

711
01:28:27,250 --> 01:28:33,460
We think the randomization worked. You're extremely close, right?

712
01:28:36,450 --> 01:28:48,769
Like 29.4 versus 29.3 age BMI 24.7 versus 27.6, you know, plus or minus, etc.

713
01:28:48,770 --> 01:28:51,890
Right. So looks like the randomization worked pretty well.

714
01:28:52,690 --> 01:28:56,120
You know, there are large groups, over a thousand people in each group.

715
01:28:57,110 --> 01:29:07,040
So that's what we would expect if it were done properly. So participation, a total of 23,792 women underwent randomization.

716
01:29:07,460 --> 01:29:12,800
Women with more than one pregnancy during the trial could have been assigned to more than one type of screening.

717
01:29:13,520 --> 01:29:22,190
A total of 66% of women in the one step group and 92% of those in the Two-Step group adhered to the assigned screening.

718
01:29:24,020 --> 01:29:27,280
I actually couldn't find in the article.

719
01:29:27,290 --> 01:29:32,809
It always says it somewhere. I couldn't. I, I tried to look it up this morning to figure out why they lost people.

720
01:29:32,810 --> 01:29:36,410
Because I couldn't remember. It wasn't super clear.

721
01:29:36,410 --> 01:29:42,830
It might be in the supplement. My guess is that some some women couldn't tolerate the one step very well.

722
01:29:43,010 --> 01:29:51,980
Right. And so ended up coming back in for a two step. And then probably there's some group of women who came in and went, oh, I forgot to fast.

723
01:29:52,670 --> 01:29:57,950
Right. And they just switched them to the to the two step at that point in the laboratory.

724
01:29:57,950 --> 01:30:03,589
So. So there you go. All right. So this is looking at the primary outcome.

725
01:30:03,590 --> 01:30:09,080
Sorry, it's a little bit small, but we did put the paper papers online here.

726
01:30:09,650 --> 01:30:14,660
So we see this is the intention to treat with inverse probability weighting.

727
01:30:15,200 --> 01:30:19,219
Here is the preplanned intention to treat. We're not seeing a huge difference here.

728
01:30:19,220 --> 01:30:25,910
And actually, I think the next slides go through the results. So there's what the table looks like in the in the paper.

729
01:30:26,780 --> 01:30:29,660
So gestational diabetes diagnosis,

730
01:30:30,170 --> 01:30:39,409
gestational diabetes was diagnosed in 16.5% of the women assigned to the one stop approach and an 8.5% of those assigned to the two step approach.

731
01:30:39,410 --> 01:30:47,450
So an unadjusted relative risk of 1.94. So, you know, almost twice, twice as likely.

732
01:30:47,450 --> 01:30:52,970
Right to be diagnosed with gestational diabetes if you did one step versus two step.

733
01:30:54,680 --> 01:31:01,330
Okay. So primary outcomes in intention to treat analysis the respective ended in sentences

734
01:31:01,340 --> 01:31:05,870
of the other primary outcomes were as follows large for gestational age infants,

735
01:31:06,350 --> 01:31:09,800
8.9% and 9.2%.

736
01:31:10,070 --> 01:31:13,219
Relative risk of 9.5 by 0.95.

737
01:31:13,220 --> 01:31:17,000
Sorry crosses one right. Or confidence interval.

738
01:31:17,390 --> 01:31:21,050
Perinatal composite outcome 3.1 to 3.0.

739
01:31:21,350 --> 01:31:28,430
Relative risk of 1.0 for once again, it crosses one gestational hypertension or pre-eclampsia.

740
01:31:29,390 --> 01:31:31,010
Relative risk of exactly one.

741
01:31:31,700 --> 01:31:47,150
Obviously the conflicts that a woman crosses one and then primary caesarean section relative risk 0.98 confidence interval of 0.93 to 1 .1.02.

742
01:31:47,840 --> 01:31:53,270
They did do a sensitivity analysis where they used inverse probability of treatment weighting

743
01:31:53,720 --> 01:32:01,510
because they were concerned about people not following the one step right on randomization,

744
01:32:01,520 --> 01:32:05,870
but with a group because there were big differences there, but they didn't really see much,

745
01:32:06,040 --> 01:32:09,559
much difference and they did inverse probability of treatment weighting.

746
01:32:09,560 --> 01:32:16,130
So we can say it's material largely unchanged. So there you go.

747
01:32:17,570 --> 01:32:25,370
So they had some preplanned secondary and safety outcomes, which should always be reported on in an intervention trial.

748
01:32:27,170 --> 01:32:29,050
And you can look at those. Right.

749
01:32:30,650 --> 01:32:37,760
So conclusion, despite more diagnoses of gestational diabetes, with the one step approach than the two step approach,

750
01:32:38,210 --> 01:32:46,610
there were no significant between group differences and the risks of the primary outcomes relating to perinatal and maternal complications.

751
01:32:47,480 --> 01:32:56,270
So given that conclusion, which what do you think's more favorable preferable to the two step?

752
01:32:56,670 --> 01:33:00,829
Right. So that's my conclusion.

753
01:33:00,830 --> 01:33:10,430
The one step results in more medical visits and monitoring, which is stressful for the mother, and higher medical utilization.

754
01:33:11,330 --> 01:33:15,139
Both screening procedures lead to similar pregnancy outcomes.

755
01:33:15,140 --> 01:33:22,340
I will note that the procedure, one is more uncomfortable for more women than than the two step.

756
01:33:23,150 --> 01:33:27,460
So the two step is for verbal. Okay.

757
01:33:28,180 --> 01:33:33,344
And with that, we have finished the lecture.

