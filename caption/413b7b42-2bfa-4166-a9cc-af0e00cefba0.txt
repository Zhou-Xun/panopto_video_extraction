1
00:00:00,060 --> 00:00:12,630
All right, let's get started. So last time we we gave the definition of a conditional expectation and a conditional probability.

2
00:00:13,990 --> 00:00:22,590
Um, so I think we should now understand the conditional expectation.

3
00:00:23,220 --> 00:00:31,709
Um, first of all, a random function or random variable with some special properties, right?

4
00:00:31,710 --> 00:00:48,630
So if your target random variable is why a traditional expectation of x is some optimal approximation of Y using x for information of x.

5
00:00:50,070 --> 00:00:54,350
So this lecture is trying to put everything together.

6
00:00:54,360 --> 00:00:56,550
So the new thing and then the old things,

7
00:00:56,670 --> 00:01:06,680
the numerical recipe and then the new properties we have learned and then put them together, see how we use conditional expectation.

8
00:01:06,690 --> 00:01:14,070
How do we calculate that we should know expectation of conditional probability in the general context?

9
00:01:14,490 --> 00:01:18,540
So it's going to be different scenarios.

10
00:01:18,990 --> 00:01:28,020
You can involve different you're going to use different strategies to compute a conditional expectation, slash probability.

11
00:01:29,250 --> 00:01:36,860
All right. So the first thing still, as we said, is last time we check that the elementary definition,

12
00:01:36,880 --> 00:01:41,850
the numerical recipe to compute conditional expectation still works.

13
00:01:41,940 --> 00:01:49,110
Right. So there are scenarios you're still going to use those old recipes.

14
00:01:49,680 --> 00:02:01,380
So computer games, why we say this out of tree definition.

15
00:02:03,840 --> 00:02:09,030
So the example, this is usually the problem.

16
00:02:09,690 --> 00:02:18,780
You specify the X on Y with detailed expectation, the distribution of information, for example.

17
00:02:18,960 --> 00:02:34,050
So let's say that in one you can bring say if we have two independent random variable X is distributed as or some lambda one.

18
00:02:34,140 --> 00:02:37,770
So I would expect you to understand what that means.

19
00:02:37,830 --> 00:02:43,390
So X follows for some distribution with the mean one.

20
00:02:43,510 --> 00:02:47,490
Right. So that means expected value of x is the one of that.

21
00:02:49,590 --> 00:02:54,290
So there is some review materials.

22
00:02:55,470 --> 00:03:02,010
What? On what I expect you should know about distributional theory at the end of the lecture.

23
00:03:02,010 --> 00:03:07,120
One So you can't feel fuzzy about those materials.

24
00:03:07,140 --> 00:03:11,100
Give a good review on that. So why?

25
00:03:11,400 --> 00:03:21,500
It's also a poor song. Run the parable with a different mean rate with a different rate longitude.

26
00:03:21,960 --> 00:03:29,070
Okay, importantly, we assume X is independent of Y.

27
00:03:29,460 --> 00:03:31,530
So there are two independent run the variables.

28
00:03:33,720 --> 00:03:48,390
So the question here, so the Q is and we figure out the probability distribution thanks given X plus one.

29
00:03:48,510 --> 00:03:54,990
Right. So if I know the song, what do I know about the X?

30
00:03:55,830 --> 00:04:05,970
Right. So this is a typical situation, you know, partial information, X plus Y definitely is some sort of a partial information on X, right?

31
00:04:06,450 --> 00:04:13,470
For example, X cannot exceed the song because X and Y both are some random variables.

32
00:04:13,860 --> 00:04:19,919
They are non-negative. But so, you know, the X plus Y contains information about x.

33
00:04:19,920 --> 00:04:30,330
So this is not same as probability, the distribution of X in other way, other words, this not going to be plus one.

34
00:04:30,690 --> 00:04:34,080
So we need to figure all this. So this is a uniform.

35
00:04:34,910 --> 00:04:43,650
It's a simple case, right? So in this case, you know, X, Y, those distributions are normal,

36
00:04:45,240 --> 00:04:51,600
although you don't know X plus Y, maybe at the first glance you may you may want to figure out.

37
00:04:51,870 --> 00:05:02,550
But the way to do this, when the distribution is already explicitly given, the best way to do this probably is try to use the elementary information.

38
00:05:02,820 --> 00:05:11,880
So to figure all of the probability X given X plus Y we can calculate of, let's say x equals UK.

39
00:05:12,660 --> 00:05:19,530
So for some random variables, state the support or the values they can take are not negative integers.

40
00:05:19,530 --> 00:05:24,809
And so keep that in mind and then have x plus y equals.

41
00:05:24,810 --> 00:05:31,090
And I know we have the restriction zero last night you go to K, let's start.

42
00:05:31,590 --> 00:05:38,300
And so this one is important and right so you need to write out this case.

43
00:05:38,580 --> 00:05:45,750
So you have to consider the part is no greater than the sum case.

44
00:05:46,500 --> 00:05:51,000
The other way to say if you have k greater than or equal to it, they are greater than.

45
00:05:51,000 --> 00:05:57,040
And so that case still can happen. Well, mathematically automatic get probability zero.

46
00:05:57,750 --> 00:06:04,319
Right? So you already use this kind of conditional information in this scenario.

47
00:06:04,320 --> 00:06:13,130
So you only need to explicitly compute a non-trivial case which is constrained by the K last time.

48
00:06:14,430 --> 00:06:17,430
All right. So that's pretty straightforward.

49
00:06:17,430 --> 00:06:25,830
Let's just use the elementary definition first to compute the joint and then divide it by the marginal,

50
00:06:26,190 --> 00:06:29,490
the marginal probability of what we have or condition are.

51
00:06:30,480 --> 00:06:41,190
So the probability executive K So at this stage you don't even need to say it too much.

52
00:06:43,170 --> 00:06:47,160
Just apply the formula you are familiar with.

53
00:06:48,840 --> 00:06:56,310
All right. There are a few issues here. We're going to do that and by one by one solve those.

54
00:06:57,180 --> 00:07:09,690
So when you write this statement, the joint probability acts equal Duke and X plus Y equals, and you can use the independence assumption X plus one.

55
00:07:09,960 --> 00:07:14,280
So if there are independent, then it must follows.

56
00:07:16,710 --> 00:07:22,170
This is well, this is actually don't you don't need to use independence information yet,

57
00:07:22,590 --> 00:07:35,370
but you can have an intermediate step if you go to K and the x, y plus y equal to and Ms. follows x and y equals a minus k.

58
00:07:36,600 --> 00:07:41,729
So this is not really any fancy probability manipulation.

59
00:07:41,730 --> 00:07:50,040
It's just the equivalency of that. You divide x equal to k, x plus y, you come to an s equivalent.

60
00:07:51,390 --> 00:07:55,530
So from if and only if x k.

61
00:07:57,190 --> 00:08:03,280
Alliance. Okay. Right from here, I get this right from here.

62
00:08:04,180 --> 00:08:08,560
If I only had sufficient and necessary condition. So that means this to you there.

63
00:08:10,120 --> 00:08:22,749
And then furthermore, if you write us X and Y and I use independent assumption that you could further simplify this into a

64
00:08:22,750 --> 00:08:31,960
product of the two probabilities so that we achieve some sort of simplification for the numerator here.

65
00:08:32,950 --> 00:08:42,190
And we still need to figure out x plus Y equal to a year.

66
00:08:45,010 --> 00:08:56,530
But that's a key thing. Sometimes if one form is not obvious, you know, one of the expression is the probability is not obvious.

67
00:08:57,640 --> 00:09:04,570
To apply, to use the assumptions, you have to think about the way to make a equivalent statement.

68
00:09:05,020 --> 00:09:13,810
And then you see that the assumption more straightforward the applied to the factorization factor.

69
00:09:14,320 --> 00:09:18,280
All right. So so look at the expression now.

70
00:09:21,460 --> 00:09:32,530
So we have you should be able to figure out the numerator because X is for some Y is person

71
00:09:32,860 --> 00:09:41,650
and then those two probabilities in numerators are just the probability mass function.

72
00:09:42,130 --> 00:09:48,370
Right. So you can just plug in. The only question is what is X plus Y?

73
00:09:55,010 --> 00:09:58,720
You know?

74
00:09:59,860 --> 00:10:04,340
So there is a claim. So, you know.

75
00:10:09,230 --> 00:10:17,900
Right. So the 601 should tell you. So you have two independent random variables if you want to calculate the sum, the distribution,

76
00:10:17,900 --> 00:10:24,710
to figure out the distributions of the sum of the two independent random variables, what is the general way to do it?

77
00:10:25,570 --> 00:10:34,720
Ah, you should have a general way to do it. So the perfect answer here is to use characteristic function, right?

78
00:10:34,730 --> 00:10:42,650
So you have two independent. The characteristic function of the sum is just the the product of the two characteristic function.

79
00:10:43,130 --> 00:10:47,210
And then that tells you the full distribution of information.

80
00:10:47,630 --> 00:10:54,500
And then from the characteristic function you can theoretically get the probability mass function of.

81
00:10:54,830 --> 00:11:04,250
So in the Palsson case, it's a, it's a well it's a pretty famous case or is probably from pretty well known case.

82
00:11:04,790 --> 00:11:10,370
Another X plus y is also for false.

83
00:11:10,490 --> 00:11:13,580
For some distribution. We see the function.

84
00:11:13,580 --> 00:11:17,240
This is simply what the problem was. All right.

85
00:11:18,080 --> 00:11:22,490
You could also show this with the generating moment generating function.

86
00:11:22,770 --> 00:11:28,700
Right. But I'm saying this is an imperfect solution because a moment generating function

87
00:11:28,700 --> 00:11:35,540
only tell you the moment doesn't tell you what the distribution in most cases,

88
00:11:35,540 --> 00:11:39,280
if it can figure out the moment you are all right,

89
00:11:39,300 --> 00:11:48,020
you like 90% figure if the things are not emphasized as a reader and you could use that short use moment generating

90
00:11:48,020 --> 00:11:57,200
function to see that x plus one is also follow the on distribution with x plus with a function x plus y.

91
00:11:59,200 --> 00:12:07,239
And the other way to do it. We're going to talk about this a little bit probably next Wednesday is using

92
00:12:07,240 --> 00:12:15,069
convolution that is nothing more than just enumerate all possibilities of X plus Y.

93
00:12:15,070 --> 00:12:24,129
Right, because there are two independent random variables and then the som can enumerated actually go to one x plus y, you go to a minus.

94
00:12:24,130 --> 00:12:27,400
What if you're trying to figure out the marginal distribution?

95
00:12:31,420 --> 00:12:40,360
This is not the hard problem. Right? So you can always break down into the events like on the right hand side of the upper board, right?

96
00:12:40,360 --> 00:12:46,930
So X equals zero. Like with an x equals one Y and minus y and numeric all of these.

97
00:12:47,170 --> 00:12:50,770
And you still can figure out as you get the same answer.

98
00:12:53,590 --> 00:13:00,720
The point is, you should know this. All right?

99
00:13:01,180 --> 00:13:02,440
So if you girl oh,

100
00:13:02,440 --> 00:13:16,120
this three probability mass function we're going to use to calculate the the conditional probability so the rest is just some algebra, right?

101
00:13:16,120 --> 00:13:24,040
So the important thing to know is how we right of the probability mass function, let's just do a little bit.

102
00:13:24,520 --> 00:13:37,690
So for the axis go to k, you have great lambda 1ke to the divide it by k factorial and then multiply by

103
00:13:39,670 --> 00:13:47,800
because they are a minus k e to the negative one to the minus k factorial,

104
00:13:49,210 --> 00:13:53,920
and then down to the denominator is the rate.

105
00:13:54,070 --> 00:14:01,120
It's still the position of probability mass function with the rate lambda one last month or two.

106
00:14:01,420 --> 00:14:18,100
Now the count of the event is under the total number of events is CO two and one of the two divided by seven factorial.

107
00:14:19,060 --> 00:14:24,400
All right. So you can see as I'm well I mean this is a just explicit you write out the

108
00:14:24,400 --> 00:14:28,809
probability mass function and then the rest is you'll see some cancelation.

109
00:14:28,810 --> 00:14:35,110
So for example the oh, the exponential functions are cancel out and then can click and perform together.

110
00:14:35,710 --> 00:14:51,550
You're going to get something like this you get and the factorial is same now flip through the numerator and minus k factorial factorial.

111
00:14:52,270 --> 00:14:57,080
So this is interest k right. Simply just interesting.

112
00:14:57,640 --> 00:15:01,210
The rest is lambda one to the k.

113
00:15:04,230 --> 00:15:13,200
Multiply to -1 to 1 cost opportunity.

114
00:15:14,550 --> 00:15:18,000
So that would be the correct answer. If you end up here.

115
00:15:23,740 --> 00:15:30,220
So you may or may not recognize that this is what distribution this is, but this isn't a correct answer by applying the.

116
00:15:30,430 --> 00:15:38,290
So that's the oh, the algebra. I'll bring you here. You could do a little bit more, help you to recognize what distribution this is.

117
00:15:38,680 --> 00:15:44,079
All right. So as I said, you can write this up.

118
00:15:44,080 --> 00:15:52,180
Untruths, okay? I'm so this term you're just split the the the two products, right?

119
00:15:52,180 --> 00:15:56,310
So you have a lambda one, which was okay. So this one is along the one.

120
00:15:57,460 --> 00:16:02,590
I'm the one. So I'm going to to the power of K, right?

121
00:16:04,570 --> 00:16:12,040
And then multiply by the to the one plus two and minus.

122
00:16:12,040 --> 00:16:20,620
Okay. All right. I realize my realizing this one is a fractional number in zero one.

123
00:16:20,800 --> 00:16:28,960
This one is the one minus this. So what that is, this is a by normal distribution, right?

124
00:16:29,680 --> 00:16:36,940
So now you can recognize this if you have a density like this, I implies the underlying distribution is a binomial.

125
00:16:37,540 --> 00:16:46,570
So this one I'm just saying this is a binomial with.

126
00:16:47,920 --> 00:16:52,840
So the and.

127
00:16:55,600 --> 00:17:04,990
So the number of trials is here and the success rate.

128
00:17:05,320 --> 00:17:11,530
Right. So the binomial is an independent newry and then count the number of success.

129
00:17:11,920 --> 00:17:20,860
So the Bernoulli trial, the success rate, you can use this and you go to K, so it's nominal lambda one.

130
00:17:21,010 --> 00:17:28,660
Right. So this will be the final answer.

131
00:17:29,290 --> 00:17:32,380
So what is the distribution? It's the binary.

132
00:17:33,220 --> 00:17:42,820
And, and then the success rate lambda one divided by one that we're going to see this type of thing in the plus on process.

133
00:17:46,750 --> 00:17:52,030
But here the point is the elementary definition still works.

134
00:17:52,390 --> 00:17:56,800
If you have a problem like that, you could figure out the traditional distribution.

135
00:17:57,010 --> 00:18:02,580
Right now, it's well defined. In this case, any questions?

136
00:18:03,850 --> 00:18:07,170
This is more like a review. Not necessarily something. Anything new.

137
00:18:09,970 --> 00:18:26,180
It's up. All right.

138
00:18:26,200 --> 00:18:32,460
So the next example is also kind of a partial or equal distribution of therapy.

139
00:18:33,360 --> 00:18:37,140
We're going to look into on a continuous case.

140
00:18:58,720 --> 00:19:03,690
So and so the example to me.

141
00:19:04,220 --> 00:19:11,980
So instead of using probability mass function, we can work with the density in this example.

142
00:19:14,860 --> 00:19:19,719
So first of all, we need to sort of a greedy well, we don't need to redefine,

143
00:19:19,720 --> 00:19:28,480
but you can hypothesize what the so called conditional density would look like.

144
00:19:28,510 --> 00:19:32,500
Right. So you have a density function X, conditional on Y.

145
00:19:35,710 --> 00:19:43,270
So this quantity would have issues in terms of how do we how do you define it in the elementary probability?

146
00:19:45,280 --> 00:19:52,030
It's not a probability anymore. It's a density dealing with two random variable X and Y.

147
00:19:52,040 --> 00:19:54,900
So usually you write this way maybe, right?

148
00:19:54,910 --> 00:20:04,540
It's just because we're not really writing doesn't distinguish the capital acts in the small acts very well.

149
00:20:06,480 --> 00:20:26,470
Kind of make it more well this is you could work with the joint density not as well defined X Y divided by I think y y y, right.

150
00:20:27,010 --> 00:20:29,680
So we didn't talk about this, this, this thing.

151
00:20:29,680 --> 00:20:38,340
It's not really a designation, but you could try this as this recipe follow to the modern definition, right?

152
00:20:38,350 --> 00:20:44,740
So the for modern definition, there is no emphasis on, you know,

153
00:20:44,800 --> 00:20:53,350
the underlying random the variable is a discrete or continuous or neither discrete or continuous.

154
00:20:53,410 --> 00:20:57,310
So it works for all random variable. So too.

155
00:20:57,700 --> 00:21:06,510
But if you're using elementary definition, well, you can hypothesize this is the formula to calculate the but really no force.

156
00:21:07,150 --> 00:21:15,490
Right. But I'm trying to say it's you can prove this is actually the way with eating was to run the continuous random variables.

157
00:21:15,490 --> 00:21:19,030
If their joint density is known, the marginal density is null.

158
00:21:19,420 --> 00:21:28,749
You could calculate this quantity known as conditional density, right?

159
00:21:28,750 --> 00:21:34,600
So this is a goal with without proof, but this should be intuitive.

160
00:21:35,050 --> 00:21:42,130
All right. We're going to see this if this works. So let's now compute a conditional expectation.

161
00:21:42,170 --> 00:21:51,770
And oh, by the way, so the conditional expectation of X, which is why?

162
00:21:51,860 --> 00:22:00,850
Why? Because why this sort of extrapolating from the this great case.

163
00:22:00,880 --> 00:22:04,630
Right. So you could always calculate something like this.

164
00:22:04,720 --> 00:22:22,720
So that gives you affinity with 35 x, y, z, grams y, y multiplied by x the right.

165
00:22:22,870 --> 00:22:31,990
So that would be how you calculate conditional expectation for continuous run the variable right.

166
00:22:32,020 --> 00:22:42,520
Using this, as I said, is kind of a extrapolation from the elementary definition of the discrete case,

167
00:22:42,520 --> 00:22:55,990
but you probably already use it and you may not be able to just apply this x axis.

168
00:22:56,150 --> 00:23:06,490
Why? That's why we can so see the difference.

169
00:23:06,490 --> 00:23:14,230
It's really just is that for doing summation now in the continuous case, we're going to do integration.

170
00:23:15,320 --> 00:23:18,410
Right. You measure theory.

171
00:23:18,410 --> 00:23:23,180
I think those two things are not really distinguished anymore.

172
00:23:23,380 --> 00:23:27,320
You can see there are two types of integration. So.

173
00:23:29,310 --> 00:23:35,780
So they are basically the same conceptually or theoretically speaking.

174
00:23:36,200 --> 00:23:44,269
The cultural is do we need to use the necessary calculus here anyway?

175
00:23:44,270 --> 00:23:54,110
So let's test all these. This thing works here with this stupid example.

176
00:24:00,350 --> 00:24:06,310
So the exemption tool is not going to be used.

177
00:24:22,570 --> 00:24:29,840
And so this is also kind of a new year.

178
00:24:30,390 --> 00:24:39,740
So if we have a random variable, Agnes, is exponential distributed.

179
00:24:41,730 --> 00:24:47,190
All right. Just to remind you what this particular formulation we're going to use.

180
00:24:47,700 --> 00:25:01,110
So our fun facts, the density of the exponential random variable is at Lambda Times with the indicator.

181
00:25:01,320 --> 00:25:08,130
So this is a basic. Okay, it's the other way for X with her zero, right?

182
00:25:08,190 --> 00:25:13,710
So that's the density. So you see different formulation of the exponential.

183
00:25:13,720 --> 00:25:23,910
So this type of exponential, this type of the formulation implies the expected value of the x is one over lambda.

184
00:25:25,070 --> 00:25:30,470
Right. The other formulation you may want to do that they might use one over,

185
00:25:31,160 --> 00:25:40,670
but an exponential function active x divided bellum that you can see expected value was lambda.

186
00:25:40,670 --> 00:25:47,390
So this one, it's just right here. Right.

187
00:25:47,600 --> 00:25:53,400
So this is the this one has the better connection with the Poisson later on and see.

188
00:25:55,160 --> 00:26:01,100
So the meaning the the longer is a consistent interpretation.

189
00:26:01,940 --> 00:26:14,810
Anyway, so this is the the case how we define how we write down the the density function of a exponential lambda random variable here.

190
00:26:15,500 --> 00:26:28,220
So we're going to calculate. So the question here is what is the expected amount of value X given the man x is greater than one?

191
00:26:32,820 --> 00:26:43,410
Or equal to one that doesn't really matter. So we have been dealing with so first of all, this is a condition, no expectation.

192
00:26:44,010 --> 00:26:50,670
And make no mistake, that's still that is just a little bit strange in the way.

193
00:26:50,790 --> 00:26:59,310
We haven't seen anything like this. This is X is a conditional not particular value is conditional itself X greater than one.

194
00:26:59,580 --> 00:27:04,550
So this is has a lot of, you know, practical, practical.

195
00:27:04,560 --> 00:27:10,110
You don't really have difficulty in understanding how this kind of a question can arise.

196
00:27:10,150 --> 00:27:20,400
Right. So if you're assuming kind of exponential weighting conditional, you have a waited for a minute, what is the waiting time would be?

197
00:27:21,390 --> 00:27:26,290
Let's say you wait for a bus. What is the wait time for the for minutes.

198
00:27:26,310 --> 00:27:34,710
So the problem is formulate like this is this the same thing as were discussed in the conditional expectation.

199
00:27:36,880 --> 00:27:41,710
Yes. Anything here? You couldn't define it as a random variable.

200
00:27:41,890 --> 00:27:46,960
Right. So this is basically you could define in this case, this is the event.

201
00:27:48,190 --> 00:27:58,390
But the event here, you can always write us so that the variable would be this one.

202
00:27:58,400 --> 00:28:04,770
So it's either greater than one or not. Now it's just fix the value equals one.

203
00:28:04,780 --> 00:28:13,660
So we're still in the same domain. We're still talking about an expected value X of another random variable Y.

204
00:28:14,300 --> 00:28:22,750
Right. And this Y obviously is correlated with X is defined through X, right?

205
00:28:24,550 --> 00:28:30,730
So, so nothing is special. You just need to consider everything a conditional on this.

206
00:28:32,440 --> 00:28:35,920
So consider some values of a random variable.

207
00:28:37,190 --> 00:28:40,510
Okay. So we don't need to go there too much.

208
00:28:42,670 --> 00:28:49,450
So look at that formula. What do we need to do? We need to compute.

209
00:28:50,200 --> 00:28:52,450
So, first of all, we need to figure out.

210
00:28:53,020 --> 00:29:01,060
So this is still elementary formulation, but if you're trying to apply that, you'll figure out each of the parts.

211
00:29:01,520 --> 00:29:09,850
Right. So what about the X equal to acts conditional on x greater than one.

212
00:29:17,650 --> 00:29:22,290
Can we just apply the formula? There are arguments.

213
00:29:22,300 --> 00:29:27,670
Yes, I think we could try. So, first of all, we write the condition.

214
00:29:29,170 --> 00:29:40,090
Well, we're going to use the. There are on the racial expression but not the not the numerator.

215
00:29:40,420 --> 00:29:46,800
First the right this into. A joint.

216
00:29:47,310 --> 00:30:02,340
Yeah. And then divide it by. So, technically speaking, this is a probability because this is no longer a density.

217
00:30:02,340 --> 00:30:09,300
So this is probably the case you should consider. If you write this as the indicator function already, you restart.

218
00:30:09,600 --> 00:30:14,610
So this is actually a mix the case for this particular problem, for the mix, the case,

219
00:30:14,610 --> 00:30:19,640
we can still use it because we have the modern definition, everything is well defined.

220
00:30:19,680 --> 00:30:23,759
You don't worry that too much. It's just. I mean.

221
00:30:23,760 --> 00:30:33,350
Right. Probability here. The thing you condition are free is not really a attendance.

222
00:30:34,320 --> 00:30:38,820
So let's try this. Okay.

223
00:30:38,820 --> 00:30:41,870
So how do you rate the density right here and then this?

224
00:30:41,880 --> 00:30:46,470
So the probability it's greater than one is easy to deal with in this case.

225
00:30:46,470 --> 00:30:52,530
Right? So you just use your density to integration from one to infinity.

226
00:30:52,920 --> 00:30:56,240
That's what I'm saying. And that actually has a, um.

227
00:30:57,570 --> 00:31:03,240
All right, so that's it's easy. Yeah. Let's say, let's just say one to infinity.

228
00:31:04,050 --> 00:31:17,460
BLOCK me to the next thing on the x, the x, and I will give you the what you read, what you need for the the marginal probability here.

229
00:31:18,360 --> 00:31:22,319
So what about this one? Well, this is a density function.

230
00:31:22,320 --> 00:31:26,820
The only thing the conditions of the joint here, root constraint is x squared.

231
00:31:26,820 --> 00:31:32,130
Without you we know that one. So the density doesn't change, still is about x.

232
00:31:32,220 --> 00:31:39,120
So it's still but with the indicator, if you don't want to write an indicator,

233
00:31:39,120 --> 00:31:45,190
you can write the condition here I greater than one but I'm just trying to write it in.

234
00:31:50,280 --> 00:32:00,330
So this will be the correct answer. So it's still the joint like basically tell you this is a density but you constrain x greater than one.

235
00:32:01,470 --> 00:32:06,540
So the density doesn't change. Function itself doesn't change, you just need to change.

236
00:32:06,690 --> 00:32:09,910
But you just want to constrain where the boundaries.

237
00:32:12,250 --> 00:32:19,810
Right? Right. The domain of the X, actually, you've seen everything here is small things.

238
00:32:22,030 --> 00:32:29,290
And if you want, you could do a little bit simplification because this one is this integration.

239
00:32:29,320 --> 00:32:33,940
If you do an integration by parts of this game, you get to the next block.

240
00:32:35,120 --> 00:32:40,120
Okay. All right.

241
00:32:40,120 --> 00:32:43,810
So we figure out the conditional density.

242
00:32:45,250 --> 00:32:52,330
Now we just need to calculate the expectation. All right.

243
00:32:52,390 --> 00:33:00,879
The formula is still here. It's not completely appropriate, as I said, because down here, this is not the density anymore.

244
00:33:00,880 --> 00:33:04,780
But you don't seem to care too much about this.

245
00:33:04,900 --> 00:33:13,060
We're going to still use it just by plugging in the proper things.

246
00:33:13,300 --> 00:33:21,910
Right. So we can now replace this part with all we have in there.

247
00:33:22,360 --> 00:33:43,660
Slammed into the negative blob tax indicator at square one and then divide it by into that negative blob and then multiply by X at the x, right.

248
00:33:48,760 --> 00:33:52,910
So. Okay, so why you have an indicator in the in the background?

249
00:33:53,710 --> 00:33:58,840
What it does is zero out everything and it's not in this range.

250
00:33:59,260 --> 00:34:07,210
So equivalently you can because it's o zero outside the range x three there about one.

251
00:34:07,330 --> 00:34:10,700
So we've got to effectively change, not to change.

252
00:34:10,700 --> 00:34:18,610
You are the region of integration to one to infinity.

253
00:34:18,730 --> 00:34:24,430
And then you can so you absorb this constraint to that the limit.

254
00:34:30,400 --> 00:34:33,400
So this one is lambda plus one.

255
00:34:35,780 --> 00:34:47,010
That's. Trying to write this up anyway or write this to different.

256
00:34:59,170 --> 00:35:12,500
I truly. This term has nothing to do with integration.

257
00:35:12,520 --> 00:35:21,060
I just put this on. So now you only need to calculate this is a continuous function.

258
00:35:21,070 --> 00:35:24,150
You can do the integration by part.

259
00:35:24,190 --> 00:35:35,799
Again, it's not like all the emphasis of this, but at the end of the day, what you're going to get the conclusion is interesting.

260
00:35:35,800 --> 00:35:41,260
If you get this conclusion, that makes a lot of sense, right? No, I have it right.

261
00:35:41,270 --> 00:35:45,170
But we're trying to get this.

262
00:35:48,190 --> 00:35:51,700
I mean. Right? Okay.

263
00:35:54,580 --> 00:36:00,010
So if you do the parallel calculation, we are in compression by part.

264
00:36:08,530 --> 00:36:16,360
It gives the following and it's not simply one plus one or longer.

265
00:36:19,650 --> 00:36:26,380
All right. Well, I think that's basically the the calculation procedure.

266
00:36:26,400 --> 00:36:33,540
That's not much to to talk about the way we kind of apply the elementary.

267
00:36:34,800 --> 00:36:42,630
It's not just applied elementary definition. We extrapolate the out of monetary definition in this case because we checked this,

268
00:36:43,230 --> 00:36:46,920
everything seems right and that's the conclusion we're going to get.

269
00:36:47,130 --> 00:36:52,590
So the significance of this is related to the exponential distribution.

270
00:36:52,800 --> 00:36:58,380
So you see, you actually know very well about the property of exponential distribution.

271
00:36:58,680 --> 00:37:03,150
You don't even need to do the calculation. You know, this is a correct answer, right?

272
00:37:03,180 --> 00:37:08,630
Why? Exponential distribution is one of the most interesting distribution.

273
00:37:08,640 --> 00:37:11,980
Has the so called a property of one.

274
00:37:13,890 --> 00:37:18,000
Very good. Okay, so we got. And we're in this property, right?

275
00:37:18,030 --> 00:37:19,950
Remember this property? What does it mean?

276
00:37:20,160 --> 00:37:27,810
So no matter how long you wait, the continuum, the continual waiting time has nothing to do with how long you have waited.

277
00:37:28,290 --> 00:37:34,290
Right. So what that means. So conditional. You already waited for one minute to one minute.

278
00:37:35,190 --> 00:37:41,460
It doesn't a fact that the the continuous waiting time but still has the same exponential distribution.

279
00:37:42,000 --> 00:37:49,900
And then that expectation is one over longer. But the answer is not one over Lambda, because you all have already waited a minute.

280
00:37:49,920 --> 00:37:53,370
So we need to add this up one plus one over another.

281
00:37:57,060 --> 00:38:02,310
Well, the point here is not reveal exponential, but this is definitely give us confidence.

282
00:38:02,410 --> 00:38:04,190
We did it right. Right.

283
00:38:04,640 --> 00:38:14,010
But we're going to come back to this again in the post distribution case, along with time distribution, going to be have this this form.

284
00:38:14,400 --> 00:38:18,760
So you could use this either ways to do the calculation.

285
00:38:18,780 --> 00:38:23,459
One is take advantage of the properties of the memory.

286
00:38:23,460 --> 00:38:28,190
Let's probably take the advantage of that with all doing calculation.

287
00:38:28,200 --> 00:38:39,140
But even you forgot about this. You can go back to the fundamentals and then still use these formulas to compute the desired property.

288
00:38:39,900 --> 00:38:42,950
All right. That's all I want to talk about.

289
00:38:42,950 --> 00:38:48,540
The elementary. So in such a case, well, X and Y are very well defined.

290
00:38:49,110 --> 00:38:55,140
You know, the what the the distribution of axes know what the distribution of what you're conditioned on,

291
00:38:55,710 --> 00:39:04,590
then don't think too much, just scope directly and then apply the the elementary.

292
00:39:04,600 --> 00:39:11,970
That's what I think is the generalized elementary definition going to get the answer you want.

293
00:39:13,950 --> 00:39:19,800
So the next examples are not computable, but elementary definition.

294
00:39:20,250 --> 00:39:24,329
It's either computed by either the properties we discussed,

295
00:39:24,330 --> 00:39:33,120
especially the tower and until the expectation law or you need to use some this recursive thinking.

296
00:39:33,160 --> 00:39:39,620
We first of all talk about in Gambler's Rule and let's talk about those more interesting things.

297
00:39:40,170 --> 00:39:43,170
Any questions about the previous example? Sorry.

298
00:39:43,190 --> 00:39:51,150
Yes. So the thing on the top where it's like F of X equals x x greater than one, so that things like the one that's like not really a density, right?

299
00:39:51,930 --> 00:40:03,270
That's correct. Yes. Yes. So in some case, we don't need to define that anymore in a way that's just automatically arise.

300
00:40:03,420 --> 00:40:06,570
It's a kind of intermediate steps you're trying to calculate.

301
00:40:06,900 --> 00:40:13,890
You can call that nobody can disagree with you because they're not they no longer serve us of definition.

302
00:40:14,370 --> 00:40:26,759
Right. So but the key thing is you can still name this conditional density or conditional of densities slash probability in the exponential case.

303
00:40:26,760 --> 00:40:33,390
As I said, it's not really a it's a density, but it's not the same of, you know, rigorous definition.

304
00:40:34,200 --> 00:40:41,580
So the point of all the alliance, a view that has an intermediate product or some of the things you can use, you don't need to define it.

305
00:40:44,010 --> 00:40:47,880
Right. Definition or going back to a modern definition.

306
00:40:48,210 --> 00:40:53,490
So you can verify that follows. That modern definition, therefore, is about quantity.

307
00:40:54,420 --> 00:40:59,400
That's clear. But does it change the way you do things? That's a good point.

308
00:41:01,860 --> 00:41:15,210
So while if you go to the measure theory, actually density is very you can find has expanded the view on it because the.

309
00:41:18,740 --> 00:41:23,010
The Theorem told me once, What do you see on the density? So in there?

310
00:41:23,030 --> 00:41:27,859
In the metro theory, there is no distinguish between the probability of mass function versus density.

311
00:41:27,860 --> 00:41:32,720
They consider the general density so of the theory.

312
00:41:33,200 --> 00:41:38,150
So those things are actually you can call those anything like condition of density or.

313
00:41:41,670 --> 00:41:50,310
Nobody going to say you are mistaken. Sorry.

314
00:41:52,620 --> 00:41:58,170
So the second part is now we computing by the properties.

315
00:42:05,410 --> 00:42:12,190
So the properties is the things we discussed at the end of the last lecture.

316
00:42:15,580 --> 00:42:20,049
So one of the interesting thing is what we have been using in statistics,

317
00:42:20,050 --> 00:42:29,830
especially over the years of decomposition of various phrase ANOVA stands for analysis of variance.

318
00:42:30,130 --> 00:42:38,230
So one of the most important things, probability rule is the total variance formula.

319
00:42:38,950 --> 00:42:51,840
So that's the variance of I say X equals the spike in the value or the variance of x conditional on y.

320
00:42:54,790 --> 00:42:58,629
Right this way. What's expected?

321
00:42:58,630 --> 00:43:10,540
Amount of sorry. Loss of variance irrespective to be max-q y.

322
00:43:12,700 --> 00:43:15,720
Right. So you should be familiar with this.

323
00:43:17,190 --> 00:43:22,600
No matter what context arise on this one.

324
00:43:22,620 --> 00:43:28,990
You cannot write with you cannot write with the elementary definition.

325
00:43:29,040 --> 00:43:34,380
This one has to you first need to have the modern definition in place to write this.

326
00:43:35,070 --> 00:43:39,809
Okay. So explain why our random variables and then this variance of facts.

327
00:43:39,810 --> 00:43:51,770
You can calculate this way by conditional y. So they expect provided variance of X or y and then the variance of expected value x give given a one.

328
00:43:52,110 --> 00:44:03,520
So why this is related to the number? So in the know the y would be the group structure is always kind of talking about the groups.

329
00:44:04,650 --> 00:44:08,370
So the total variance can be decomposed into two parts.

330
00:44:08,820 --> 00:44:14,160
One is within variance. Which of these two expressions?

331
00:44:15,840 --> 00:44:20,600
Shows that we think there is. The first one.

332
00:44:20,620 --> 00:44:33,669
Yes, very good. So that's the the the variance within each conditional of Thanksgiving when you calculate some sort of expected value that the second,

333
00:44:33,670 --> 00:44:37,629
then that's between variants, right. The between requirements.

334
00:44:37,630 --> 00:44:44,740
How do you calculate that? It's basically the discrepancy of the group centers, the centroid or the expected value.

335
00:44:44,740 --> 00:44:48,220
And so the variance of expected Thanksgiving line.

336
00:44:49,480 --> 00:44:59,500
So well, I think this just highlights how important this scale gives rise to this important the idea of ANOVA.

337
00:44:59,650 --> 00:45:06,220
But can we prove this of how this where this thing come from.

338
00:45:07,720 --> 00:45:12,670
So so now with the modern definition, we can calculate this.

339
00:45:12,670 --> 00:45:18,490
And so the only thing that's tricky here is the variance we don't know well,

340
00:45:18,520 --> 00:45:24,490
we don't really know the at least at this point that we didn't define conditional variance yet.

341
00:45:25,390 --> 00:45:31,719
Right. But variance is just a second moment in the in the marginal case.

342
00:45:31,720 --> 00:45:39,850
So we can define the conditional various just like we define just using the conditional expectations.

343
00:45:40,210 --> 00:45:56,650
I see how we define this first. So first so that this formula, what that means is a variance of x give a y is simply so again so the x given y.

344
00:45:57,700 --> 00:46:19,670
And the first to write this of. If it took two pairs of.

345
00:46:28,060 --> 00:46:41,320
So again, it's sort of extrapolating from the margin case.

346
00:46:41,650 --> 00:46:50,020
So if you you try to calculate a random variable X, give a Y, always think about a random variable first to calculate the second moment.

347
00:46:50,200 --> 00:47:02,620
But on the minus, the random variables expected value square very nothing.

348
00:47:02,980 --> 00:47:08,110
So this is a radio extrapolation again. So this is a second moment.

349
00:47:08,110 --> 00:47:13,550
The conditional on y minus expected value x given y square.

350
00:47:14,670 --> 00:47:21,440
Right. So just like the battery itself acts, just write these things side by side.

351
00:47:21,460 --> 00:47:28,910
So it's a clear. Yeah.

352
00:47:31,990 --> 00:47:36,520
So you need to define this is actually. That's right.

353
00:47:36,880 --> 00:47:40,660
So with this then there's nothing is going to be fine.

354
00:47:40,750 --> 00:47:49,900
So you feel this has to be some definition from right.

355
00:47:50,230 --> 00:47:57,030
But this one is a natural extension of the marginal variance definition.

356
00:47:57,370 --> 00:48:03,429
A second moment. But the second woman is conditional expectation from the conditional expectation

357
00:48:03,430 --> 00:48:08,710
minus the conditional the first moment from the conditional expectation squared.

358
00:48:10,210 --> 00:48:13,630
So if we have this done, this is a rather easy path.

359
00:48:13,960 --> 00:48:16,990
This whole thing is rather straightforward.

360
00:48:18,370 --> 00:48:26,700
All right. Let's see why. So we're trying to go to the left hand side.

361
00:48:26,970 --> 00:48:30,740
Let's do the right hand side first.

362
00:48:31,200 --> 00:48:39,450
The first term is expected to be variance of X, given Y,

363
00:48:40,920 --> 00:48:48,480
and that we're going to use that definition to write this expected value over the expected value.

364
00:48:51,560 --> 00:49:00,830
I swear. Y minus x squared.

365
00:49:02,900 --> 00:49:24,799
Right. Not expected. The two of these things on the further right is us to take expectation of distributive law in this minus so forth.

366
00:49:24,800 --> 00:49:28,040
This one. So this one. This is clear, right?

367
00:49:28,040 --> 00:49:31,940
This deal with the first term. The second term.

368
00:49:36,350 --> 00:49:41,030
You also need to keep everything in space.

369
00:49:41,570 --> 00:49:46,730
That's right. That's right.

370
00:49:49,050 --> 00:50:04,220
So which of these two terms we can simplify? Which one was first?

371
00:50:04,390 --> 00:50:11,460
First? Yes, because that's what the total expected of that expectation law tells you.

372
00:50:12,960 --> 00:50:19,470
So this is your first the conditional Y and then compute the the unconditional expectation.

373
00:50:19,470 --> 00:50:25,960
So this is simply. That's right. An A-minus.

374
00:50:31,800 --> 00:50:35,960
This one you cannot do, although very tempting to simplify it.

375
00:50:35,970 --> 00:50:43,290
But we really don't know how to deal with conditional expectations squares, so we just leave it out there.

376
00:50:45,240 --> 00:50:48,780
Okay. So the second term, right.

377
00:50:48,960 --> 00:50:54,420
Is like first. Okay.

378
00:50:55,290 --> 00:51:09,070
So the second term would do similar thing. That's how you raise this, because we already know the definition.

379
00:51:09,160 --> 00:51:14,010
Here we go. All right.

380
00:51:14,020 --> 00:51:24,780
So the second term is also important to invoke to invoke the modern definition.

381
00:51:24,790 --> 00:51:30,340
So the variance of expected value a given y.

382
00:51:33,100 --> 00:51:43,150
So only run the variable has variance. Now you see that expected value of x given y is our random variable by the model definition.

383
00:51:43,160 --> 00:51:47,010
So we can safely say there is a variance. Right.

384
00:51:47,410 --> 00:51:51,250
So how do you calculate that variance? By the definition.

385
00:51:51,550 --> 00:51:55,510
So you need to calculate this a random variables.

386
00:51:55,980 --> 00:52:06,680
The moment, which is this is a random variable null right square.

387
00:52:06,700 --> 00:52:10,390
So that's the second moment minus this.

388
00:52:11,510 --> 00:52:23,090
They surrender America's expectations square so that there's an expected value game of why.

389
00:52:23,150 --> 00:52:27,500
Right. This whole thing square. Correct.

390
00:52:28,190 --> 00:52:33,889
There's just a variance. This a marginal variance, a formula to run the variable.

391
00:52:33,890 --> 00:52:37,850
Now you really need to see this as a random variable.

392
00:52:37,850 --> 00:52:43,940
The random variable second moment that's expected of having this squared minus.

393
00:52:47,050 --> 00:52:54,370
The expected value squared. And then that's actually there is X here.

394
00:52:54,910 --> 00:53:00,790
So the whole thing, if you calculate the expected value and then squared now which term can be simplified?

395
00:53:03,150 --> 00:53:09,290
At least for the second term, right? The first term we're already seen that is right there.

396
00:53:10,370 --> 00:53:17,450
This is an expectant father who was given the Y squared.

397
00:53:19,730 --> 00:53:23,840
The second term, though, before you apply the square.

398
00:53:23,900 --> 00:53:30,470
You look at the inside is an expected value of a expected amount of a conditional distribute conditional expectation.

399
00:53:31,070 --> 00:53:40,250
So by the total expectation law. But inside is simplified to show that this is holding square.

400
00:53:41,690 --> 00:53:50,749
Right. The second term. All right.

401
00:53:50,750 --> 00:53:56,059
So when you add up that the first term, in the second term, what happens?

402
00:53:56,060 --> 00:53:59,690
Is this the troublesome term?

403
00:54:00,320 --> 00:54:03,860
Well, we don't know how to deal with. Just cancel out.

404
00:54:03,950 --> 00:54:07,370
There is a minus. That term period is a plus this term.

405
00:54:07,820 --> 00:54:13,510
So we ended up with the definition of variance.

406
00:54:13,700 --> 00:54:18,320
Right. So the right hand side is put together and basically.

407
00:54:23,880 --> 00:54:36,600
So the the right hand side is becomes you had the first turn from the top and then you get the second term from the bottom,

408
00:54:38,940 --> 00:54:43,630
which is the definition of power in cell packs.

409
00:54:45,750 --> 00:54:53,680
Right. So we basically so this is proves to the top the total variance law.

410
00:54:53,700 --> 00:54:57,780
So the variance decomposition law, whatever you want to call it.

411
00:54:58,110 --> 00:55:01,830
So every variance you can calculate in this way.

412
00:55:01,860 --> 00:55:06,390
Variance of facts equals we expected areas X gave a Y.

413
00:55:06,420 --> 00:55:14,970
So if you have a groove structure in the real data, it can calculate the power within within group.

414
00:55:16,570 --> 00:55:20,020
Barriers and then deal with between groups various.

415
00:55:20,150 --> 00:55:26,170
So this is the significance of this, but as a simple probability rule.

416
00:55:28,130 --> 00:55:35,540
This goes directly this come directly from the to the modern definition of conditional expectation.

417
00:55:47,290 --> 00:55:56,020
All right. Any questions? Good all.

418
00:56:21,170 --> 00:56:29,330
So with this, of course, the next example is called a complete random variable.

419
00:56:29,630 --> 00:56:33,440
So those things are conceptual. It becomes more complicated.

420
00:56:35,090 --> 00:56:54,950
So let me first write down this. So we're going to define a random sample as.

421
00:56:55,120 --> 00:56:58,390
So this is speed at the point of interest.

422
00:56:58,780 --> 00:57:09,280
So that X is a sample of copies of random IP from the variable x sign.

423
00:57:10,300 --> 00:57:17,530
Okay. So as it's a song. So this is the the individual component is excited actually with no excite for you.

424
00:57:18,550 --> 00:57:33,520
So that's why our I.D. follows of general distribution, as I say, with an equal to.

425
00:57:33,570 --> 00:57:49,610
Mm. And the variance seemed much simpler.

426
00:57:51,290 --> 00:58:02,480
All right, so. So if this is an idea, if I tell you a number of the copies we have by design as a 1 to 1, that's a trivial problem.

427
00:58:02,660 --> 00:58:09,680
So one problem. However, this makes the problem interesting.

428
00:58:09,680 --> 00:58:15,190
More challenging is the number of and here is a random variable.

429
00:58:18,320 --> 00:58:27,860
And it's a random variable of negative integers.

430
00:58:30,830 --> 00:58:35,430
So what does it mean? So this is what happens all the time in stochastic process.

431
00:58:35,610 --> 00:58:40,400
Then you can think about a generative process to get this type of situation.

432
00:58:40,940 --> 00:58:44,860
So maybe let's do this. So you get a bunch of idea.

433
00:58:44,870 --> 00:58:48,290
Run the variables you could do on simulation. Right.

434
00:58:48,300 --> 00:58:59,030
So you just do independent signaling. So I asked you first to draw a random integer from zero to infinity, first to draw that.

435
00:58:59,330 --> 00:59:08,090
So that's determine the copy of and here and then you conditioned on that and you can, you know, simulate each of the individual.

436
00:59:08,090 --> 00:59:15,050
So. So the as is well defined it's not defined by my I.D. process.

437
00:59:15,170 --> 00:59:19,980
They also need to go through this random process to determine the copy.

438
00:59:20,390 --> 00:59:23,750
So that as itself is interesting. Right.

439
00:59:23,750 --> 00:59:27,350
So this is the randomness of S depends on two different things.

440
00:59:27,920 --> 00:59:33,020
One is the randomness of X, which, you know, pretty good.

441
00:59:33,320 --> 00:59:43,190
And that also the number of copies you can generate in each realization, which I also claim to know is let's assume we know this distribution,

442
00:59:43,640 --> 00:59:48,320
but knowing the individual part doesn't make the problem easier, right?

443
00:59:48,680 --> 00:59:56,660
So what is the expected value of S? So if you do this process, the simulation process.

444
01:00:01,180 --> 01:00:09,610
You know, multiple times or going to a lot of time was the expected value of assets.

445
01:00:09,680 --> 01:00:15,160
Right. So a lot of times what's what is an expected value of assets?

446
01:00:16,450 --> 01:00:23,350
How do you even do the calculation here? All right.

447
01:00:23,430 --> 01:00:32,550
So what I said here. So if you just take that as a probability problem and I'm just trying to solve it, it could be difficult.

448
01:00:32,910 --> 01:00:38,430
But what I just hinted here, if you think about the generating process.

449
01:00:38,590 --> 01:00:41,730
Right. So if you are given a task to simulate.

450
01:00:43,590 --> 01:00:54,380
How do you do? All right. If you don't know the expectation law, at least you can simulate on your computer.

451
01:00:55,380 --> 01:00:59,540
Just get a numerical use, a law of large number actually together.

452
01:01:00,810 --> 01:01:05,030
I'm trying to get a sense of what the expected value will pass.

453
01:01:05,040 --> 01:01:09,870
But in that case, how do you write down the program? How do you generate as here?

454
01:01:10,590 --> 01:01:15,629
Right, you are already doing explicit conditioning like I describe you.

455
01:01:15,630 --> 01:01:23,040
First of all, to run the variable, that is the number of copies you're going to compute the sum of, right?

456
01:01:23,250 --> 01:01:29,790
That's the and and then conditional and you're going to simulate different copies in each simulation.

457
01:01:30,420 --> 01:01:33,480
Right? So that's already tell you how to do the calculation.

458
01:01:33,810 --> 01:01:39,780
And then from a more general mathematical point of view, that as is hard to compute,

459
01:01:40,740 --> 01:01:49,460
but it's not hard to compute a conditional and now we can just count even using a total expected causal expectation.

460
01:01:49,490 --> 01:01:56,160
Paul Right. This has to the right.

461
01:01:58,020 --> 01:02:05,940
So this is what we know. And then this expectation exactly that this is kind of a total expectation expression.

462
01:02:06,240 --> 01:02:09,330
Exactly reflect the generate this process.

463
01:02:09,450 --> 01:02:17,250
Right, conditional and first and then we can integrate all them and look across different simulations.

464
01:02:18,720 --> 01:02:22,680
Right. So conditional and this becomes a trivial case.

465
01:02:23,640 --> 01:02:27,850
This is. The summation.

466
01:02:27,850 --> 01:02:33,180
I want to look at my mom.

467
01:02:33,280 --> 01:02:39,820
And so you feel conditional and you treat and that's a constant.

468
01:02:39,970 --> 01:02:43,260
Why are you trying to calculate the expected value?

469
01:02:43,280 --> 01:02:46,660
Right. So the insight here becomes.

470
01:02:50,990 --> 01:02:55,420
Only times they expected valuable facts.

471
01:02:55,430 --> 01:03:02,870
Right. So that's new here. So so what is the answer here?

472
01:03:03,140 --> 01:03:06,790
So it becomes the expected amount of times.

473
01:03:09,200 --> 01:03:24,790
So it's as simple as that. If you invoke the total expected total expectation law.

474
01:03:30,530 --> 01:03:41,090
We could also do you know I'm going a little bit farther to calculate the variance I just for finding.

475
01:03:57,340 --> 01:04:01,680
All right. Before I do that, so what we talk about, like, food.

476
01:04:01,690 --> 01:04:04,000
Tricia Law told the expectation law.

477
01:04:04,330 --> 01:04:11,650
I said, maybe it's hard to understand why sometimes do we need to conditional more information to do with expectation?

478
01:04:11,800 --> 01:04:17,920
Here is a perfect example of you trying to calculate the marginal s right.

479
01:04:17,930 --> 01:04:31,299
The expected value of S that's just based on the marginal distribution or the marginal distribution so hard you can conditional you first.

480
01:04:31,300 --> 01:04:37,840
The conditional more information the more information that's like how many copies you can get from this process.

481
01:04:37,930 --> 01:04:49,540
Right. And it's it's yeah I think sometimes it's theoretically is difficult to appreciate why you need to have they

482
01:04:49,540 --> 01:04:58,300
should all more information in this hypothesis you see the condition is it's critical important change.

483
01:04:58,810 --> 01:05:06,370
Okay so we can calculate variance of s as well just using this law.

484
01:05:08,620 --> 01:05:13,090
So we first to calculate variance.

485
01:05:13,510 --> 01:05:26,290
This is a from the last as conditional and plus variance of the expected value as given a year.

486
01:05:27,370 --> 01:05:43,030
All right. So we're going to get so the variance as given and I'm going to claim so of so the variance as given is the variance.

487
01:05:51,580 --> 01:05:55,660
So you're going to calculate the variance conditional on the number of items here.

488
01:05:56,440 --> 01:06:05,560
So that's a nickel piece of x, y, each of the x hi has the r i.d. and then they are the marginal variances Sigma Square.

489
01:06:05,980 --> 01:06:09,780
So this is simply expected value.

490
01:06:10,390 --> 01:06:15,280
Sigma Square, as I said, for variances in Sigma Square.

491
01:06:16,240 --> 01:06:22,660
And then the variance of this is given and we just calculate that somewhere there.

492
01:06:22,780 --> 01:06:31,120
So there's a me here. So this one is remember is a random variable.

493
01:06:31,540 --> 01:06:35,680
MU is a constant. So that's a new square.

494
01:06:35,770 --> 01:06:43,160
So if you're factor this off from a variance, don't forget the square variance upset.

495
01:06:44,290 --> 01:06:56,140
So put together what you've got is Sigma Square is expected value plus Mu Square, lots of variance.

496
01:06:58,180 --> 01:07:02,470
So you can figure out the variance as well.

497
01:07:03,250 --> 01:07:10,810
If you're interested in the any moment, I think you can continue continually applying the total expectation law to get you.

498
01:07:13,020 --> 01:07:24,620
Oh, the necessary quantities. All right.

499
01:07:24,630 --> 01:07:28,440
I have two examples left than 10 minutes.

500
01:07:28,950 --> 01:07:32,279
Let's go to the. All right.

501
01:07:32,280 --> 01:07:38,040
So so these are some of the problems you have to.

502
01:07:40,200 --> 01:07:45,479
But in vogue or using explicit use of the properties.

503
01:07:45,480 --> 01:07:51,510
We discussed them. So the total expectation always is the example here.

504
01:07:51,630 --> 01:07:58,830
But you can imagine there's the there is the case you want to invoke.

505
01:07:59,070 --> 01:08:03,710
You can use the fuel efficient law. All the other laws are relatively easier.

506
01:08:03,720 --> 01:08:08,520
We have we some of those are already in place.

507
01:08:08,520 --> 01:08:15,540
It be invoked. But the important to laws is the filtration and the total expectation.

508
01:08:16,020 --> 01:08:20,000
They all have the same kind of assets you need to.

509
01:08:20,310 --> 01:08:26,040
Why are you trying to calculate something difficult? Marginally conditional, more information first?

510
01:08:28,020 --> 01:08:35,730
That's supposed to be, but that's the lesson. So lastly, there are two examples we want to show you how we use this.

511
01:08:36,120 --> 01:08:46,559
This conditional expectation is how important they are for dealing with stochastic process when you have,

512
01:08:46,560 --> 01:08:53,400
you know, finite possibilities for dealing with in unify next collection number on the variables.

513
01:08:54,420 --> 01:09:15,960
So I think we only have time for one for today, but maybe not just so the third party applications in stochastic processes.

514
01:09:18,630 --> 01:09:27,540
All right. So, so this example five. So we're going to talk about a trap, the fly in the maze.

515
01:09:36,780 --> 01:09:40,220
So the set up is such so there is a fly on.

516
01:09:40,530 --> 01:09:45,570
Let's fly. So in a position in the maze, there are.

517
01:09:49,550 --> 01:09:52,640
There is one. There's three different.

518
01:09:52,640 --> 01:09:59,690
So. So he is in the position. There are three dwarfs, some small three choices to make.

519
01:10:01,160 --> 01:10:07,970
And it depends on the the choice this fly makes of the consequences is different.

520
01:10:08,360 --> 01:10:15,620
So let's say this is a x is a door zero for one or two I is defined.

521
01:10:15,620 --> 01:10:28,970
The position is that if they choose the door number zero X equals zero, the fly will exit in 2 minutes.

522
01:10:32,800 --> 01:10:44,450
Okay. And if a true store one will return to is 3 minutes because some may get back to the original.

523
01:10:45,530 --> 01:11:00,360
Place the 33 minutes as if randomly choose the number two or number two or return in 5 minutes and you'll get a longer detour.

524
01:11:04,700 --> 01:11:08,630
So now you can see there are, you know, observe the fly in the maze.

525
01:11:10,280 --> 01:11:16,310
So the eyes determine the choice at the first try and second try.

526
01:11:16,450 --> 01:11:20,050
And then the third line. So we can consider this X.

527
01:11:21,410 --> 01:11:24,800
I know I can be in finite, right?

528
01:11:25,730 --> 01:11:28,880
Well, I think that there is a possibility. A fly.

529
01:11:28,920 --> 01:11:41,640
Well, trapped in the maze forever. I'm not saying probability of possibility if there is a really kind of a stubborn fly has some awareness.

530
01:11:41,660 --> 01:11:45,920
I keep choosing the door number two. As I said, it is my list.

531
01:11:45,920 --> 01:11:51,410
But the world trapped there forever. So you can have all the x equal to two.

532
01:11:51,860 --> 01:11:59,420
And so we basically the question here is what is the expected, the time, the fly?

533
01:11:59,570 --> 01:12:10,280
Well, exit the maze is the choice for each of as it is.

534
01:12:10,280 --> 01:12:17,030
Or third, every time he does choose the three doors with equal probability.

535
01:12:17,510 --> 01:12:21,440
A third, a third, the third. Now, what is the expected value?

536
01:12:22,140 --> 01:12:25,190
The the total time it takes.

537
01:12:26,030 --> 01:12:36,050
There's 2 minutes, 3 minutes, 5 minutes. You can choose zero and the Y equals two.

538
01:12:36,350 --> 01:12:47,830
And then as define that y total time three.

539
01:12:52,200 --> 01:13:02,130
Before in the maze, before exit, before exit.

540
01:13:06,420 --> 01:13:10,830
So the question is calculate the expected value of y not clear.

541
01:13:11,160 --> 01:13:20,100
So this is a kind of a simple and then you can think about exile are really in the right every time the same probability.

542
01:13:23,730 --> 01:13:30,940
Let's see how much time we can go for this. All right.

543
01:13:31,240 --> 01:13:34,290
So this has the flavor of stochastic process, right?

544
01:13:34,300 --> 01:13:37,630
So you cannot enumerate all of these actions.

545
01:13:37,810 --> 01:13:43,660
The first one. The second one is you realize there is a possibility there was a real light.

546
01:13:43,660 --> 01:13:49,930
There is a possibility you cannot do this enumerating in finite times.

547
01:13:49,930 --> 01:13:53,590
Just stop doing that. It's not going to work.

548
01:13:59,890 --> 01:14:17,770
So what is the right way then? The right way is what we're trying to calculate the expected value of why I want to think about this,

549
01:14:18,070 --> 01:14:22,300
to think about all the possibilities is impossible. But we can condition something.

550
01:14:23,620 --> 01:14:32,860
So what do we conditional on? This is a kind of a scale or the more you look at this type of a you encounter this type of the problem,

551
01:14:33,370 --> 01:14:38,680
you're feeling more comfortable or more the become more intuitive to you what to do.

552
01:14:39,670 --> 01:14:45,430
So I'm going to do quite the above, the next one.

553
01:14:46,570 --> 01:14:50,770
So what is x one, the first the choice conditional on the first choice.

554
01:14:50,770 --> 01:15:00,670
Right. And now I'm going to right now the first choice explicitly so equals.

555
01:15:01,270 --> 01:15:04,720
So what is the total time? Conditional X one. All right.

556
01:15:05,080 --> 01:15:08,770
So this is a pretty simple. So if x y equal to zero.

557
01:15:09,460 --> 01:15:14,920
So the first time it is the right exit of the right door.

558
01:15:16,410 --> 01:15:21,950
What is the expected value of Y? That's how we really try to figure out.

559
01:15:21,970 --> 01:15:27,540
Yes. To what about X to equal to.

560
01:15:27,720 --> 01:15:32,940
Sorry, x y equals two. So this is a critical I'm sorry, one.

561
01:15:34,800 --> 01:15:40,020
What about with the probability 30 actually chooses this door number one.

562
01:15:42,210 --> 01:15:47,760
What is the expected value of y conditional x y equal to one?

563
01:15:50,800 --> 01:15:55,860
Right. First thing first. You're right. You're going to spend 3 minutes.

564
01:15:56,400 --> 01:16:02,520
That's this upfront. Then they go back to the original spot.

565
01:16:03,810 --> 01:16:07,830
And what is the expected time? They actually exit.

566
01:16:08,880 --> 01:16:13,530
From that point on. Say it again.

567
01:16:15,480 --> 01:16:19,360
Speak up. Sorry. Conditional x two. Yes.

568
01:16:19,380 --> 01:16:26,270
What is what? I need you to add to this. So he plans to.

569
01:16:29,340 --> 01:16:32,490
Not to because he's going to make a three choices again.

570
01:16:33,300 --> 01:16:39,330
So I'm going to claim this one is the same as expected about it, one, because the whole process just regenerated.

571
01:16:39,360 --> 01:16:43,410
So you would spend 3 to 3 minutes and you go back.

572
01:16:43,620 --> 01:16:47,070
You were dealing with the original problem again. All right.

573
01:16:47,280 --> 01:16:53,190
I think we don't have time, but it's 2 to 5, two plus.

574
01:16:55,140 --> 01:17:01,060
Next time we will finish this problem. But this is how you calculate the conditional statement.

575
01:17:01,530 --> 01:17:06,840
You have to have them in this type of a problem. You have to have some recursive type of thinking.

576
01:17:08,190 --> 01:17:15,550
Get there. All right. See everybody on Wednesday now set up for Friday.

