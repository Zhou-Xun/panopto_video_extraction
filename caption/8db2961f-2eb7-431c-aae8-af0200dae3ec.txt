1
00:00:19,150 --> 00:00:23,620
You I just said.

2
00:00:37,210 --> 00:00:46,740
I think. No, I think that's right.

3
00:00:47,870 --> 00:00:53,410
Morning. It's just about time to get started.

4
00:00:53,420 --> 00:01:00,130
So. Let's settle down.

5
00:01:04,150 --> 00:01:19,180
You have a lot of really exciting material cover as usual, and that is the effect of measurement error on our measures of association.

6
00:01:23,380 --> 00:01:28,960
Perhaps I'd like to give a recap again of of the essence of what we are.

7
00:01:30,370 --> 00:01:33,610
Doing here, uh, to this module.

8
00:01:34,420 --> 00:01:43,480
Um, so last time we talked about measurement error rights, there are two types of major mineral.

9
00:01:45,170 --> 00:01:52,770
You remember who stakes? Got it.

10
00:01:53,700 --> 00:01:57,360
Um hmm. Well, yeah.

11
00:01:57,570 --> 00:02:08,520
Those are two ways of assessing one of the types of measurement error that we studied, which was systematic, and the other type is randomness.

12
00:02:09,840 --> 00:02:16,920
So if if you were to be asked to very quickly and in a very practical way,

13
00:02:17,220 --> 00:02:25,050
defined and tell the difference between systematic error and no matter if you could do that.

14
00:02:25,920 --> 00:02:31,320
Okay, great. So systematic error. Well, let let me give you sort of my own view.

15
00:02:31,500 --> 00:02:46,030
Let's make taking a linear. Here we have tentacles becoming intense, so systematic error is getting the wrong answer always in the same direction.

16
00:02:47,810 --> 00:02:55,410
Example. When people come to the doctor and get their blood pressure taken,

17
00:02:56,070 --> 00:03:04,470
the first measurement of blood pressure is always going to be higher than what the blood ratio really is.

18
00:03:06,420 --> 00:03:11,670
He's never going to be lower but with most knowing that their blood pressure release.

19
00:03:12,720 --> 00:03:16,060
You know why? Yeah.

20
00:03:16,080 --> 00:03:20,400
It's called a wide code of faith because people are stressed.

21
00:03:21,790 --> 00:03:27,110
When they see their doctor. Why is that systematic error?

22
00:03:29,640 --> 00:03:34,500
Because he's consistently high. Right. You can predict.

23
00:03:36,110 --> 00:03:39,300
That is going to be high. You can't predict the addiction.

24
00:03:39,590 --> 00:03:43,819
You have no list of reasons to predict the direction.

25
00:03:43,820 --> 00:03:46,940
And you actually, many of you guess there is because of the way.

26
00:03:48,780 --> 00:03:54,450
That knowledge allows you to predict and allows you to classify that error as Sistema.

27
00:03:56,750 --> 00:04:05,780
By contrast, was random. A random error is a type of error when every time you take a measurement, you will get a different result.

28
00:04:06,050 --> 00:04:09,800
But it can be either up or down the true value.

29
00:04:10,190 --> 00:04:16,790
And on top of that, you cannot really predict why it will be up or down.

30
00:04:18,790 --> 00:04:22,660
Right. Example many biomarkers.

31
00:04:23,790 --> 00:04:31,680
If you take a blood sample of a person at any given moment and let's say measure hemoglobin levels.

32
00:04:32,690 --> 00:04:36,860
You will get a value, you know, 12.6 grams per desi.

33
00:04:38,390 --> 00:04:46,520
If you intended the person that you were to take another sample maybe 5 minutes after, and you will analyze the samples for hemoglobin levels,

34
00:04:46,790 --> 00:04:57,410
that is what chances are you are going to get 12.7 and you do the third time chances that you are going to get 12.4.

35
00:04:57,650 --> 00:05:00,650
It is very unlikely that you will always get exactly this thing.

36
00:05:00,650 --> 00:05:03,860
But why did you get a different value?

37
00:05:03,860 --> 00:05:07,640
A little apparatus down every time you measured white?

38
00:05:10,840 --> 00:05:14,380
It's okay to say, you know, this is the right dance. Yeah.

39
00:05:14,710 --> 00:05:18,310
You can see. I don't know. You know, that's like.

40
00:05:18,310 --> 00:05:21,490
I don't know. That is random in.

41
00:05:23,420 --> 00:05:33,110
Now mathematically, if you were to recall, to measure the distance in values between the true measure and what you get.

42
00:05:34,780 --> 00:05:38,530
Let's start with systematic error. You do the measurement many times.

43
00:05:39,730 --> 00:05:48,220
If you get to estimate the difference between the between the measured you get and the true value will that.

44
00:05:50,000 --> 00:05:53,630
That will always be a positive or negative, right?

45
00:05:54,050 --> 00:05:57,500
You will always consistently get a measure that's up.

46
00:05:57,950 --> 00:06:01,700
Or always get information that's down. But that.

47
00:06:01,770 --> 00:06:09,380
That value will always be. We'll always have a sign. If you were to do the same with random matter.

48
00:06:11,420 --> 00:06:18,590
Each time you repeat your measurement, you might get answers that are up for answers that are down,

49
00:06:18,590 --> 00:06:21,440
and the difference can be either positive or negative.

50
00:06:23,280 --> 00:06:31,830
And if you were to add up those differences, you know, you've seen their signs over many, many, many repeats of the same measurement.

51
00:06:32,640 --> 00:06:38,820
What should you get? What should be the sum of that difference between your measurement and the true value?

52
00:06:39,300 --> 00:06:49,100
If you have found the middle. Should be zero because the values that are measured up should cancel out with the values that are measured down.

53
00:06:49,790 --> 00:06:53,090
So by definition, the sum. Of.

54
00:06:53,980 --> 00:06:58,570
Random errors after you have gone, that many measurements should be zero.

55
00:06:59,740 --> 00:07:03,370
The sum of systematic error will not be zero.

56
00:07:04,240 --> 00:07:10,650
Okay. So is it clearer now or even more clear?

57
00:07:11,430 --> 00:07:14,950
Okay. Which one?

58
00:07:16,410 --> 00:07:23,700
Yeah. Yeah. It's really random. And again, you cannot anticipated.

59
00:07:24,160 --> 00:07:31,040
You there are no variables that you could including a model to predict the direction of random.

60
00:07:32,540 --> 00:07:42,680
Okay. Now, why are we going to study the effects of error, both systematic and random, on our estimates of association?

61
00:07:43,280 --> 00:07:47,090
Why is that important? Well, you know, sort of. What's the big picture here for you?

62
00:07:49,340 --> 00:07:55,610
There are a few. Justifications for me to, as some say, torture you.

63
00:07:57,720 --> 00:08:01,680
When you read a paper in epidemiology or public health or nutrition.

64
00:08:03,850 --> 00:08:08,830
You will find that sometimes people use inadequate measures.

65
00:08:10,800 --> 00:08:14,100
And by knowing this, you might be able to say.

66
00:08:15,390 --> 00:08:19,470
Okay. These people got this answer because they use this machine.

67
00:08:21,110 --> 00:08:27,170
But then had to use an appropriate measure. Should have they gotten a different answer or the same?

68
00:08:27,890 --> 00:08:32,270
In other words, you might be able to anticipate whether the results you are seeing.

69
00:08:33,540 --> 00:08:40,280
Are an exaggeration or an attenuation of what the truth might be because of measurement.

70
00:08:41,930 --> 00:08:45,500
And that is a very powerful, critical skill to have.

71
00:08:47,750 --> 00:08:54,410
If you are the authors, you might be able to defend your methods when it comes down to it.

72
00:08:54,770 --> 00:09:03,740
We review. If you are designing this study, you should be able to select the best measures for the study based on what you have learned here.

73
00:09:04,160 --> 00:09:12,650
Let's see if you are if you need to buy a kit to do a measurement of a biomarker in blood.

74
00:09:15,140 --> 00:09:18,290
How would you go about selecting a kids?

75
00:09:19,160 --> 00:09:24,620
From the very many options and manufacturers that might be. Will you go for the cheapest?

76
00:09:26,720 --> 00:09:29,700
No. You should be able.

77
00:09:29,730 --> 00:09:39,120
You should know now that that you need to pick the one that maximizes sensitivity or or specificity also, depending on your specific request.

78
00:09:40,510 --> 00:09:45,630
That's important. Okay.

79
00:09:48,460 --> 00:09:50,890
And also. And finally.

80
00:09:52,330 --> 00:10:02,830
When you know these tools, we are giving a dataset that that's already been collected with methods, with measurements that you had no control of.

81
00:10:05,060 --> 00:10:10,760
You may get good results. You may even be aware that they may be subject to monitor.

82
00:10:12,780 --> 00:10:18,000
By doing this and I guess a version of it that you could learn more advanced courses.

83
00:10:19,230 --> 00:10:28,350
Believe it or not, you could in some instances correct your results for the effect of measurement error using external information.

84
00:10:30,090 --> 00:10:38,050
You, you should be able to remove a little bit of the measurement or using analytic tools to get a better sense.

85
00:10:39,790 --> 00:10:45,840
That's called calibration. So this is why this is important.

86
00:10:47,250 --> 00:10:50,790
All right. Any questions or comments on that?

87
00:10:55,740 --> 00:10:59,230
Um. With a blow. The slide.

88
00:11:00,980 --> 00:11:05,050
Okay. All right. So let's get started.

89
00:11:06,210 --> 00:11:09,430
First thing. Your seatbelts. Right.

90
00:11:10,120 --> 00:11:13,640
The effect of measurement error of useful information bias.

91
00:11:16,020 --> 00:11:21,720
We gave the wrong answer. And we are going to study the effects of.

92
00:11:22,710 --> 00:11:27,510
Measurement error in two stages.

93
00:11:28,770 --> 00:11:33,690
The first one is. When it happens on the exposure.

94
00:11:35,220 --> 00:11:39,080
When your exposure variable is measured, we test. Okay.

95
00:11:39,900 --> 00:11:46,260
The second is going to be when it happens and you don't know when your outcome variable is measured.

96
00:11:46,260 --> 00:11:55,860
We. Real life. You may have made some an error in both, but I won't give you that indigestion in this class.

97
00:11:57,210 --> 00:12:03,800
Too much. But I guess understanding the effects on each one is still going to be out.

98
00:12:07,490 --> 00:12:13,880
And within each of these two chapters, we will study the effects of first systematic error.

99
00:12:14,860 --> 00:12:21,860
And second random. Okay. And we will be doing this through examples.

100
00:12:22,700 --> 00:12:27,620
Um, so we may be going back and forth with tables and examples and numbers and so on.

101
00:12:27,620 --> 00:12:35,899
So every now and then I will have summary slides where you will get just the, you know, the essence of it.

102
00:12:35,900 --> 00:12:41,420
And actually they will have the word summary on the lower right.

103
00:12:43,180 --> 00:12:46,190
And. They?

104
00:12:47,340 --> 00:12:50,380
So let's begin with. Problems.

105
00:12:50,530 --> 00:12:54,470
Measurement error of the exposure. When you.

106
00:12:57,350 --> 00:13:02,000
Mr. something we enter. What happens is that.

107
00:13:03,500 --> 00:13:07,870
You will misclassify. The person.

108
00:13:09,470 --> 00:13:14,870
Because you will assign the person a value unavailable that the person does not really have.

109
00:13:15,140 --> 00:13:19,720
So that's called misclassification, and I may use that word Yandex.

110
00:13:19,770 --> 00:13:28,330
I just wanted to make sure the date I told you what I mean by misclassification is sort of the effect on the individual automation their.

111
00:13:31,250 --> 00:13:39,230
No exposure identification bias meaning measurement error in the exposure is pretty common in case control studies,

112
00:13:39,740 --> 00:13:49,580
especially in these controlled studies in which you have to ask people to recall the exposure status many years before they got the outcome.

113
00:13:49,730 --> 00:13:54,230
Because recalling case control studies, you go from outcomes to exposure.

114
00:13:54,290 --> 00:14:01,080
Right. The consequence, as I mentioned, is misclassification.

115
00:14:02,240 --> 00:14:07,880
And that there are two types of exposure misclassification.

116
00:14:10,090 --> 00:14:13,180
So misclassification or is bias?

117
00:14:17,800 --> 00:14:24,620
Depends on whether. It happens by the same amount.

118
00:14:26,240 --> 00:14:31,130
Between people with the outcome and people without the outcome.

119
00:14:31,640 --> 00:14:37,160
What whether it happens differently for people with the outcome and for people without being.

120
00:14:38,860 --> 00:14:44,490
We need a fix when when error in a statement of exposure affects.

121
00:14:45,470 --> 00:14:48,500
People with and without the outcome in the same manner.

122
00:14:49,280 --> 00:14:51,830
It is called non-defense.

123
00:14:53,290 --> 00:15:01,310
So there's no differential with respect to when it affects people with alcohol differently than it does people without the outcome.

124
00:15:01,360 --> 00:15:11,660
It's called differential. And we need to study them separately because the consequences vary depending on whether they are differential or nondefense.

125
00:15:12,580 --> 00:15:16,240
Is it clear conceptually what differential and non differential is?

126
00:15:18,310 --> 00:15:25,410
Okay. So let's begin with non differential.

127
00:15:26,630 --> 00:15:30,930
Yeah. To do that, we'll work through the first example.

128
00:15:33,120 --> 00:15:36,660
Let's assume we have a case control study of breast cancer.

129
00:15:36,960 --> 00:15:41,070
That's the outcome in relation to preterm birth.

130
00:15:41,730 --> 00:15:46,200
So we have 500 women with breast cancer.

131
00:15:46,530 --> 00:15:52,830
They are going to be the cases. Right. And we select 500 women without breast cancer.

132
00:15:55,740 --> 00:15:56,520
And we asked.

133
00:15:58,010 --> 00:16:12,020
All of them to tell us whether they had been born themselves before 37 weeks of gestation, which is the standard definition for preterm birth.

134
00:16:13,670 --> 00:16:19,150
So these women had to think hard, you know, go back to what they were memories of.

135
00:16:19,160 --> 00:16:24,620
But they may have been told, I suppose, by their parents whether or not they were born in time or before.

136
00:16:25,100 --> 00:16:31,430
Right. So if the exposure had been measured without.

137
00:16:33,200 --> 00:16:38,149
If they had been able to recall perfectly or if we had had another method like or going

138
00:16:38,150 --> 00:16:43,730
through the records and birth records and actually recording back to the time of birth,

139
00:16:44,450 --> 00:16:49,640
these would be the table summarizing the association.

140
00:16:49,850 --> 00:16:55,249
Right. So here you have. The outcome.

141
00:16:55,250 --> 00:17:00,240
And here you have the exposure and you could estimate the growth rate, right?

142
00:17:01,220 --> 00:17:05,240
The odds of exposure among cases divided by the odds of exposure among controls.

143
00:17:05,240 --> 00:17:08,660
And you get an auto ratio of six.

144
00:17:09,770 --> 00:17:14,950
Which means. Preterm birth is associated with breast cancer.

145
00:17:15,160 --> 00:17:19,520
You have a positive association strong disease. If you had measured exposure without.

146
00:17:22,630 --> 00:17:30,500
Now. Let's assume we have systematic error in ascertainment of exposure.

147
00:17:31,250 --> 00:17:36,620
And from what we discussed last time, we can quantify the amount of error.

148
00:17:37,970 --> 00:17:41,810
Using the sensitivity and specificity of the measure.

149
00:17:44,430 --> 00:17:53,290
So. Let's assume that the sensitivity of recalling being born with them was.

150
00:17:54,290 --> 00:18:02,240
Less than 100% less about the rate that saved was 80% in cases and 80% in contrast.

151
00:18:05,320 --> 00:18:10,270
Now. There is you know, this is sort of bad news, right.

152
00:18:10,280 --> 00:18:12,859
But the specificity, what the sensitivity was, though,

153
00:18:12,860 --> 00:18:23,750
because that means we have been missing some women who truly were born preterm but have been reporting perhaps that they were really not born beaten,

154
00:18:24,110 --> 00:18:30,559
that that's what the primary sensitivity is. But of of the bad news, there are some good news,

155
00:18:30,560 --> 00:18:39,830
which is that at least the problem with sensitivity is exactly the same in cases and in contrast, which means.

156
00:18:40,910 --> 00:18:44,090
It is non differential misclassification.

157
00:18:45,060 --> 00:18:48,030
And I say good news because as we will see,

158
00:18:48,030 --> 00:18:55,830
the effects of non differential misclassification tend to be at least more predictable than the effects of differential misclassification.

159
00:18:56,130 --> 00:19:05,990
Right. For the sake of, you know, an initial example, let's keep this specificity at 100%.

160
00:19:06,110 --> 00:19:14,140
No problems with specificity. Right. So those who did not have the number were truly classified as not having.

161
00:19:16,050 --> 00:19:24,800
But what would happen with our table? Because there is a problem with sensitivity only.

162
00:19:26,080 --> 00:19:33,130
The people who will be affected by this problem are those who were exposed.

163
00:19:33,880 --> 00:19:39,910
So the problem with sensitivity will affect the exposed on people with.

164
00:19:41,060 --> 00:19:45,650
That exposure, right? So the unexposed will remain the same for now.

165
00:19:46,160 --> 00:19:59,940
But then. Of the 200 truly exposed cases that you may have seen in the original table, we know that we will only observe 80% of them.

166
00:20:01,220 --> 00:20:07,110
Because we would be missing, you know, the rest. So instead of 200.

167
00:20:08,340 --> 00:20:14,430
Exposed cases, we will only see one in 160, 80% of the 200.

168
00:20:16,070 --> 00:20:20,200
And what happens. With the remaining 40.

169
00:20:21,660 --> 00:20:25,770
They are misclassified as unexposed cases.

170
00:20:26,130 --> 00:20:29,970
Right. So they would actually move.

171
00:20:30,950 --> 00:20:37,350
To this. And how about the controls?

172
00:20:37,590 --> 00:20:41,999
Well, among the controls there were originally 50 without error.

173
00:20:42,000 --> 00:20:46,380
By now, with low sensitivity, we will only see 80% of those 50, which is 40.

174
00:20:46,980 --> 00:20:51,180
Right. So this number now is 40.

175
00:20:51,930 --> 00:20:59,430
And what happens with the remaining ten? They are misclassified as unexposed controls.

176
00:21:00,030 --> 00:21:13,540
So they move to these. Let's estimate the odds ratio again with these new numbers on which there is some added systematic error.

177
00:21:15,390 --> 00:21:18,930
So the odds ratio now is 5.4.

178
00:21:20,250 --> 00:21:25,140
It's lower than the odds ratio of six that we observed when there was no air.

179
00:21:26,630 --> 00:21:30,070
Okay. Now.

180
00:21:35,170 --> 00:21:38,500
Let's assume sensitivity still 80%.

181
00:21:38,980 --> 00:21:43,390
And now let's see what happens if there was also a problem with specificity.

182
00:21:44,530 --> 00:21:50,620
So now the specificity is 90% in the cases and 90% in the controls again.

183
00:21:50,890 --> 00:21:56,140
The good news is that it still is. This is not differential because these are the same mean cases and controls.

184
00:21:56,980 --> 00:22:00,860
But it should have an effect. On our numbers.

185
00:22:03,170 --> 00:22:08,390
Each would affect the unexposed right. Because specificity.

186
00:22:10,620 --> 00:22:16,470
So we would only observe 90% of the 300 trillion exposed cases, which is 270.

187
00:22:16,740 --> 00:22:24,000
That number would be replaced by 270. The remaining 30 will be misclassified as exposed species.

188
00:22:24,000 --> 00:22:33,870
So they will move to these so. And among the controls we would only observe 90% of the for 50 truly unexposed, which is four or five.

189
00:22:35,050 --> 00:22:39,970
And the remaining 45 will be misclassified as ex-post controls.

190
00:22:39,970 --> 00:22:43,020
So they would move to these. Right.

191
00:22:44,480 --> 00:22:50,120
And we can now estimate again the ratio. And these three.

192
00:22:51,650 --> 00:22:56,070
It's even farther. From the true value of six.

193
00:22:56,310 --> 00:22:59,580
Then when there was a problem on you with sensitivity.

194
00:23:01,210 --> 00:23:07,240
So we can conclude and this is one of those summaries that we can.

195
00:23:09,840 --> 00:23:18,450
Generalized that when we have known differential misclassification of dichotomous, yes.

196
00:23:18,450 --> 00:23:23,790
No exposure. The mission of the association is attenuate.

197
00:23:25,440 --> 00:23:33,350
Meaning we get a result that is less impressive, in fact, than what it really is in.

198
00:23:33,810 --> 00:23:43,610
You know, we are. So you might also say your findings is that the result is biased or they know association

199
00:23:43,610 --> 00:23:48,170
are biased or they know because they know the association value for those ratio is one.

200
00:23:48,560 --> 00:23:58,220
So obviously this means that when you have this type of measurement error, it alteration will be closer to one than it should truly be.

201
00:24:00,670 --> 00:24:03,670
Okay. Any questions so far on that or.

202
00:24:06,320 --> 00:24:13,180
Okay. All right. What if the exposure is?

203
00:24:16,240 --> 00:24:18,970
Not dichotomous, but has more than two categories.

204
00:24:19,030 --> 00:24:30,069
Well, the situation there can be a little bit messier, and I'm not going to get into the details here, but it's just I mean, the numbers do work.

205
00:24:30,070 --> 00:24:33,639
And I just want you to grab the concept here.

206
00:24:33,640 --> 00:24:39,820
We have three level exposure. And let's assume that if it was major,

207
00:24:39,820 --> 00:24:44,770
we know that these would be the odds ratios for the medium compared to the low exposure

208
00:24:44,770 --> 00:24:49,300
level and the high compared to the low exposure level three and nine respectively.

209
00:24:50,950 --> 00:24:55,630
But suppose sensitivity was really low sensitivity message, the meaning of exposure.

210
00:24:58,580 --> 00:25:05,360
But it affected the A2 category and the MISCLASSIFIED moved to the A1 category within the medium.

211
00:25:05,930 --> 00:25:10,820
So in this particular case, the odds ratio for this category would actually go up.

212
00:25:13,020 --> 00:25:20,520
But if instead the misclassified moved to the lowest exposure category.

213
00:25:21,860 --> 00:25:26,350
These and these motivations would be attenuated.

214
00:25:26,900 --> 00:25:31,080
So, again, don't worry about the math play out here.

215
00:25:31,100 --> 00:25:38,770
What you need to. Register is that if the exposure has more than two levels.

216
00:25:40,480 --> 00:25:42,970
You cannot predict the direction of bias.

217
00:25:46,150 --> 00:25:57,490
So it can be an overestimation, an acceleration, which can be an attenuation, and it will depend on which people move to which categories.

218
00:25:58,240 --> 00:26:03,610
Right. So again, the effect of non differential misclassification of exposure.

219
00:26:06,130 --> 00:26:10,260
Differs depending on the scale of your exposure.

220
00:26:10,300 --> 00:26:14,280
But. It's dichotomous. It's going to be an attenuation.

221
00:26:14,850 --> 00:26:18,360
If it's if it has more than two categories, you cannot predict.

222
00:26:18,850 --> 00:26:24,810
Right. What about continuous exposure?

223
00:26:25,140 --> 00:26:28,710
We sometimes use continuous exposures in allergic research.

224
00:26:29,880 --> 00:26:33,210
So to illustrate the effect of non differential misclassification on.

225
00:26:34,270 --> 00:26:37,960
A continuous exposure. I have this example, let's say.

226
00:26:39,220 --> 00:26:42,430
It's a case control study of breast cancer.

227
00:26:44,180 --> 00:26:47,200
Um. My exposure is heightened.

228
00:26:49,920 --> 00:26:54,990
And then you can see be immunologists in their own. So.

229
00:26:56,210 --> 00:27:00,380
Aspiring fighting female. All right.

230
00:27:01,620 --> 00:27:09,110
Well, it turns out that actually height tolerance is a risk factor for risk.

231
00:27:11,770 --> 00:27:22,060
Because of potential mechanisms having to do with the endocrinology of you based on development and linear growth.

232
00:27:23,800 --> 00:27:28,780
So I have illustrated that situation with these two.

233
00:27:30,490 --> 00:27:35,110
Um. Gaussian curves.

234
00:27:36,200 --> 00:27:44,839
So the one in red to the right represents the distribution of height among cases.

235
00:27:44,840 --> 00:27:48,310
Women with breast cancer. And.

236
00:27:50,120 --> 00:27:57,130
The curve to the left represents the distribution of height among controls women without risk and.

237
00:28:00,100 --> 00:28:11,740
When we have a continuous measure, typically our measure of association is the difference in the means of the distribution for cases and control.

238
00:28:11,750 --> 00:28:20,710
So the mean height for cases is 165 centimeters, the mean for controls is 162,

239
00:28:20,950 --> 00:28:24,400
and our measure of association is the differential, which is three centimeters.

240
00:28:29,050 --> 00:28:34,960
Now suppose there was systematic error in the ascertainment of height.

241
00:28:35,530 --> 00:28:41,530
And the typical example is that perhaps, you know, by mistake,

242
00:28:41,530 --> 00:28:53,379
an investigator placed the metric on a three and a five centimeters down when they were taking the height of.

243
00:28:53,380 --> 00:29:00,890
Of this with. So we're actually just one and a half centimeters.

244
00:29:00,920 --> 00:29:04,270
You know, it's not not salty. So.

245
00:29:06,760 --> 00:29:12,740
That means that. Everybody was measured, one and a half centimeters up.

246
00:29:13,340 --> 00:29:18,210
Right. So what would happen with the distribution of height in the cases?

247
00:29:18,950 --> 00:29:23,419
It would go up by one and one and a half centimeters to one.

248
00:29:23,420 --> 00:29:26,420
66.5. Then you mean would be the.

249
00:29:27,880 --> 00:29:31,540
Everybody was measured up by the same amount.

250
00:29:32,590 --> 00:29:37,450
Is one and a half centimeters. So they mean would move by one and a half centimeters.

251
00:29:38,450 --> 00:29:43,600
Why? Because it's not differential. Guess what? Among the controls.

252
00:29:44,140 --> 00:29:47,260
They were also all measured up by one and a half centimeters.

253
00:29:47,680 --> 00:29:54,580
So the distribution also moves up by one and a half centimeters to 1.5.

254
00:29:56,890 --> 00:30:02,580
Recalculate the measure of association. What's the difference?

255
00:30:06,610 --> 00:30:08,680
Still three. Still three.

256
00:30:11,050 --> 00:30:22,960
So that leads us to conclude that non differential misclassification of a continuous exposure causes no bias in the mean difference.

257
00:30:26,820 --> 00:30:30,290
Um. These you can ignore because.

258
00:30:31,800 --> 00:30:36,180
I decided to remove. That was a little bit too convoluted.

259
00:30:36,440 --> 00:30:41,130
Um. Right. Okay. Hey, we are done with the first one.

260
00:30:42,120 --> 00:30:45,860
Any questions on that so far? No, a.

261
00:30:46,880 --> 00:30:53,510
So now let's move to differential misclassification of exposure.

262
00:30:55,620 --> 00:30:58,980
And for that, we have another case control study.

263
00:30:59,730 --> 00:31:06,150
This one is of Guillain-Barre syndrome in relation to Zika virus infection.

264
00:31:08,390 --> 00:31:20,470
So. You know, infectious disease that biologists of clinical epidemiology is wanted to know whether Zika infection caused Guillain-Barre syndrome.

265
00:31:22,020 --> 00:31:25,230
So Zika is the exposure and Guillain-Barre is the outcome.

266
00:31:25,410 --> 00:31:33,390
It's a case control study. So people identified 100 patients with Guillain-Barre syndrome and 100 controls without.

267
00:31:34,440 --> 00:31:37,620
And they. Provided a blood sample.

268
00:31:39,290 --> 00:31:45,350
And then the investigators made sure that they hadn't been exposed to Zika using antibodies.

269
00:31:46,020 --> 00:31:53,720
But. So if the explosion had been measured without error, this would be.

270
00:31:54,940 --> 00:32:03,460
The situation of the date would be the the Dubai duty rate we have here exposed the unexposed we here here the cases and the controls.

271
00:32:03,880 --> 00:32:10,660
We can estimate the cost ratio. And the odds of exposure among cases.

272
00:32:11,290 --> 00:32:14,530
Divided by the odds of exposure among controls is for.

273
00:32:15,470 --> 00:32:21,380
So we have a positive association between having tigers to Zika and embarrassing.

274
00:32:24,070 --> 00:32:30,920
But now. Let's say that, in fact, the sensitivity of the blood test,

275
00:32:30,970 --> 00:32:40,760
the exposure was 96% in cases and 70% in contrast is differential because no, the same between cases and controls.

276
00:32:41,120 --> 00:32:46,140
Right. For now, the specificity remains at 100%.

277
00:32:46,150 --> 00:32:54,890
So what would happen with these numbers? Well. We would only observe 96% of the 50 truly exposed cases.

278
00:32:54,920 --> 00:32:55,730
That's 48.

279
00:32:55,970 --> 00:33:04,520
So these number would be replaced by 48 here, and the remaining two would be misclassified as unexposed cases, so they would be moved to the set.

280
00:33:06,230 --> 00:33:14,600
And among controls, we would observe only 70% of those 20 truly exposed, which is 14, and the remaining six will move to.

281
00:33:15,790 --> 00:33:20,850
B an unexposed controls. If we estimate the odds ratio again.

282
00:33:22,240 --> 00:33:27,490
We get 5.7. How does it compare with the towards me.

283
00:33:27,970 --> 00:33:32,500
We don't get to. It went up. It's an exaggeration.

284
00:33:33,400 --> 00:33:37,320
Of the two. Let's reach. All right.

285
00:33:38,630 --> 00:33:44,690
Now let's assume to complicate matters that there is also a problem with specificity and it is also differential.

286
00:33:46,060 --> 00:33:55,520
So what else would happen to this table? Well. We would only observe 80% of the 80 truly unexposed controls, not 64.

287
00:33:56,420 --> 00:34:04,340
So these number is replaced by 64. And the remaining 16 would be misclassified as exposed controllers.

288
00:34:04,350 --> 00:34:09,680
So they would mostly. The new automation with this data is.

289
00:34:11,300 --> 00:34:15,820
2.20 that's it compared to the draw one is an was.

290
00:34:19,930 --> 00:34:24,940
Okay. So keep those results in mind just for a little while before we conclude,

291
00:34:27,190 --> 00:34:32,740
because Nixon would like to see what might happen with differential misclassification of a continuing.

292
00:34:35,520 --> 00:34:40,140
So. If you like, you can.

293
00:34:41,710 --> 00:34:46,590
Think of the same example and. The idea is that for some reason.

294
00:34:47,980 --> 00:34:54,370
The cases were measured systematically up and the controls were measured systematically down.

295
00:34:54,910 --> 00:34:58,360
Or vice versa? Yeah. I guess.

296
00:35:00,320 --> 00:35:08,360
These controllers may be possible if bases are selected from its near cleaning world and

297
00:35:08,360 --> 00:35:12,889
controls are selected from somewhere else and the procedures are done them separately.

298
00:35:12,890 --> 00:35:21,170
So it is possible to have this type of problem. So let's say cases where measured down.

299
00:35:22,840 --> 00:35:27,590
And controls were measured up. What happened with the difference?

300
00:35:28,340 --> 00:35:32,480
It switched. Now you have an inverse association.

301
00:35:33,400 --> 00:35:39,670
Like. And what happened if the cases were measured up and the controls were measure down.

302
00:35:40,600 --> 00:35:44,660
Now you have an exaggeration of the measure of association. So.

303
00:35:47,680 --> 00:35:55,260
Regardless of whether you. Variable hued exposure variable is customers continuous.

304
00:35:57,210 --> 00:36:02,430
Differential misclassification of exposure will have unpredictable effects.

305
00:36:03,590 --> 00:36:10,770
On. The admission of businesses. He's not or didn't know.

306
00:36:12,170 --> 00:36:17,710
Necessarily. You would need to have more information to be able to predict.

307
00:36:19,700 --> 00:36:23,840
Okay. Questions on that.

308
00:36:32,430 --> 00:36:36,880
Ooh. Done with that. All right. Random error.

309
00:36:43,690 --> 00:36:48,370
At least three drowned, no matter a boatload.

310
00:36:49,440 --> 00:36:52,590
A day of drama. From.

311
00:36:54,260 --> 00:36:57,420
The Nutritional Epidemiology Bible.

312
00:36:58,620 --> 00:37:02,760
Um, because and this is an important historical note.

313
00:37:04,460 --> 00:37:12,530
Many of the methods and the theory in measurement error was developed in the context of nutrition knowledge and was.

314
00:37:13,430 --> 00:37:18,470
Then adopted by other fields, including.

315
00:37:20,150 --> 00:37:24,090
And particularly environmental health and.

316
00:37:24,360 --> 00:37:27,830
Am. So there is you know the reason is that.

317
00:37:28,870 --> 00:37:32,900
It is this very funny joke. What?

318
00:37:34,210 --> 00:37:38,710
To a nutritional and environmental if allergies have in common.

319
00:37:44,830 --> 00:37:49,740
Neither of them has the slightest idea of what they are measuring. So.

320
00:37:50,620 --> 00:37:54,699
But, you know, he's very telling of of. Yeah, these are sort of drama.

321
00:37:54,700 --> 00:37:58,570
You know, it's measuring what people eat is exceedingly difficult.

322
00:37:59,680 --> 00:38:07,030
And then, you know, people have had to study seriously this problem and understand the nature of error and then come up with methods

323
00:38:07,030 --> 00:38:12,730
to either improve the measurements or correct the measurements when there is just no way to improve it.

324
00:38:13,400 --> 00:38:16,980
Okay. So this is like, here's a bottle of this.

325
00:38:18,750 --> 00:38:26,280
These these figures from that is I know he's he's not the easiest, straightforward, eager to understand.

326
00:38:26,280 --> 00:38:29,320
But please bear with me. Um.

327
00:38:29,740 --> 00:38:35,440
All right, so. There are two parties, right?

328
00:38:35,720 --> 00:38:40,380
Yeah. The upper and the lower. Each panel has.

329
00:38:42,040 --> 00:38:47,710
Two distributions. Two distributions of an exposure.

330
00:38:48,070 --> 00:38:53,650
So in a way, these these graphs are similar to the ones they showed you of the example of breast cancer on height.

331
00:38:57,100 --> 00:39:07,720
The distribution to the right hand side represents the distribution of a continuous exposure among people with disease cases.

332
00:39:09,040 --> 00:39:15,900
The distribution to the left hand side represents. The distribution of exposure among people without the disease.

333
00:39:16,260 --> 00:39:31,540
Right. So obviously they overlap. The upper panel represents a situation in which there is no random error in the statement of exposure.

334
00:39:32,610 --> 00:39:38,060
Okay. A couple further sort of notation things.

335
00:39:38,750 --> 00:39:44,530
They mean these these dotted lines represent the means of each distribution, right?

336
00:39:44,540 --> 00:39:50,089
So x one is the mean for the distribution of expression among cases.

337
00:39:50,090 --> 00:39:55,490
X now is the mean of the distribution of exposure among non cases or controls.

338
00:39:57,800 --> 00:40:03,610
The lower. Panel represents what would happen.

339
00:40:06,180 --> 00:40:09,690
To the distributions if there was random error.

340
00:40:11,430 --> 00:40:18,840
So I guess the good thing is that we can use our information to make some conclusions and usually they are unforgettable.

341
00:40:20,060 --> 00:40:25,110
And using increase. Was the first thing you observed.

342
00:40:25,320 --> 00:40:33,250
If you compare that, say, the distributions about the distributions between the upper and the lower plane.

343
00:40:34,760 --> 00:40:41,140
In other words, from eyeballing the submissions was the effect of mesh of random measurement error on the distributions.

344
00:40:43,120 --> 00:40:46,300
Okay. They're whiter than whiter.

345
00:40:46,840 --> 00:40:53,170
So if you think of them in statistical terms, you could say native variance has increased.

346
00:40:53,890 --> 00:41:03,310
Right. No way these motives are going to be so random that increases the viability of a continuous exposure distribution.

347
00:41:05,650 --> 00:41:10,510
What has happened. To the means of each distribution.

348
00:41:15,280 --> 00:41:27,930
The same. They haven't changed. And the reason is that by definition random error is non differential points by definition.

349
00:41:31,360 --> 00:41:40,630
If random error were differential, that means you have one variable to predict random error, which would be case status.

350
00:41:41,470 --> 00:41:46,170
And if you have anything to predict, error is no longer random. A systematic.

351
00:41:48,910 --> 00:41:52,240
So again, by definition, random error is.

352
00:41:53,240 --> 00:42:00,260
Non differential, and for that reason you should not see a change in that means no.

353
00:42:00,620 --> 00:42:06,740
The problem is though, that. Often times when you have.

354
00:42:08,090 --> 00:42:12,710
It continues distribution of an exposure you might still want to.

355
00:42:13,460 --> 00:42:16,610
They customize their distribution.

356
00:42:17,580 --> 00:42:18,570
Who made your difference.

357
00:42:18,780 --> 00:42:28,800
Meaning you may want to set a cut point on the continuous distribution to say what's high and what's low, let's expose and what's unexposed.

358
00:42:29,910 --> 00:42:41,650
And that's how the example continues here. So these investigators decided that if they traced.

359
00:42:43,180 --> 00:42:50,020
A line at Value X, and that would mean that's the cut point to this side.

360
00:42:50,980 --> 00:43:01,320
Who is exposed and who is unexposed. The exposed would be those who fall on the area under the curve above each one.

361
00:43:01,840 --> 00:43:08,230
The unexposed would be those who fall in the area under the curve under x one.

362
00:43:08,500 --> 00:43:16,340
Right. Except. So these are what I have.

363
00:43:17,010 --> 00:43:20,720
I have a highlight or underline here in.

364
00:43:22,070 --> 00:43:27,530
In red. These would be the exposed cases, right?

365
00:43:27,560 --> 00:43:31,790
Because again, this is the distribution of exposure in the cases.

366
00:43:32,240 --> 00:43:37,430
And those who are on the area under the curve above this couple are exposed.

367
00:43:38,350 --> 00:43:45,820
But. Now was the was this size in numbers?

368
00:43:46,780 --> 00:43:51,820
Of an area under the crime was the maximum size of an area under the.

369
00:43:53,710 --> 00:44:13,620
One one, right. So the sizes of areas under the curve, above or under any given point and actually proportional to the number of people in those ages,

370
00:44:14,590 --> 00:44:20,230
because they just under the gun represent actually probabilities. Right. And that's why the maximum possible values one.

371
00:44:22,690 --> 00:44:26,560
So. The area under this curve.

372
00:44:27,880 --> 00:44:30,910
Is 31% of the whole.

373
00:44:32,150 --> 00:44:40,210
Curve, which means. 31% of cases are exposed.

374
00:44:43,230 --> 00:44:52,760
Because the aid is proportional to the number of people. Now.

375
00:44:54,130 --> 00:44:55,540
Among the known cases.

376
00:44:56,170 --> 00:45:05,440
This would correspond to the exposed right because they are both the component that was chosen to say both these you are exposed.

377
00:45:07,270 --> 00:45:11,240
And this corresponds to 16% of the whole area under the curve.

378
00:45:11,270 --> 00:45:14,720
So we can put that. Proportion.

379
00:45:18,440 --> 00:45:21,889
Because we know that the total identity card is one.

380
00:45:21,890 --> 00:45:25,520
We can also guess what the values here would be.

381
00:45:25,580 --> 00:45:29,470
It would be just the. The remaining.

382
00:45:31,120 --> 00:45:34,570
So for this we would have point 69 and here point 84.

383
00:45:35,940 --> 00:45:40,830
And we can actually estimate an odds ratio in this ratio would be.

384
00:45:42,760 --> 00:45:51,040
These proportions representing the sizes of the explosives and controls and explosives and controls.

385
00:45:51,040 --> 00:45:58,130
And we get anodes ratio of 2.4. Now what happens?

386
00:45:58,150 --> 00:46:01,600
This is what we would see if there was no random measurement error.

387
00:46:02,470 --> 00:46:05,500
What happens if there is random measurement error like here?

388
00:46:07,430 --> 00:46:17,300
Well, visually, what has happened, what has happened with these two areas, the areas of exposed cases and exposed controls, what do you see?

389
00:46:18,260 --> 00:46:23,080
How do they compare visually to these? Yeah.

390
00:46:25,080 --> 00:46:28,980
Well, yeah, they sort of increased. Yeah, I don't know, maybe.

391
00:46:29,490 --> 00:46:38,580
But how do they compare to each other in relation to how they compare with each other in the upper playing field?

392
00:46:39,030 --> 00:46:43,200
They changed, you know, these in proportion. They are harder to differentiate, right?

393
00:46:43,440 --> 00:46:47,400
They are harder to distinguish. You know, they have more overlap.

394
00:46:48,000 --> 00:46:54,440
Right. The difference seems smaller. And sure enough, if you actually make the calculations,

395
00:46:55,160 --> 00:47:02,420
these would correspond to the exposed phases and these would correspond to the exposure controls.

396
00:47:02,840 --> 00:47:05,960
So, yeah, actually, you you're right. You was right.

397
00:47:05,990 --> 00:47:13,280
They have increased, but not proportionally, which means that if you estimate the new ratio, how?

398
00:47:15,220 --> 00:47:27,990
He's 1.5 this morning because again, the difference has become smaller due to the increased spread and the distributions because of random.

399
00:47:29,940 --> 00:47:33,020
All right. That wasn't so bad, was it? That's okay.

400
00:47:34,660 --> 00:47:38,650
We can conclude in the effect of random drone exposures.

401
00:47:39,130 --> 00:47:44,890
We have the customers exposures. It tends to attenuate the associations or the low value.

402
00:47:46,280 --> 00:47:48,920
And what would happen with continuous exposures.

403
00:47:51,040 --> 00:47:58,560
Look, if you were to take the mean the difference in the means of these two distributions, would you change them?

404
00:47:59,140 --> 00:48:04,670
No. So may not have an effect on differences between cases.

405
00:48:04,740 --> 00:48:05,370
In contrast,

406
00:48:06,180 --> 00:48:15,600
later on you might learn it safe that they can cause in addition to being a larger environmental technology that it may decrease the precision,

407
00:48:15,900 --> 00:48:20,760
which I remember is one of those attributes of an association that we really.

408
00:48:22,300 --> 00:48:25,360
Have not had it for that much. Right.

409
00:48:25,960 --> 00:48:30,640
Any questions so far? Okay.

410
00:48:33,390 --> 00:48:36,480
So we are done with exposure and identification by.

411
00:48:38,090 --> 00:48:42,110
Now we are going to talk about outcome id bias.

412
00:48:43,070 --> 00:48:51,170
Was the effect of misclassifying people according to their outcome on the measures of association.

413
00:48:53,780 --> 00:49:01,030
So this is more frequent, incoherent steps. Because in general, I guess, you know, you have to.

414
00:49:02,530 --> 00:49:05,830
Think very well how you are going to measure your outcome.

415
00:49:06,250 --> 00:49:10,840
Sometimes you may not know exactly when the outcome would happen, etc. in a code.

416
00:49:11,320 --> 00:49:19,040
Now it can also happen in case control systems. But for the sake of these exercises, we will focus on cohort studies.

417
00:49:21,410 --> 00:49:31,129
The consequence is again misclassification of outcome and it types are actually analogous to the types of exposure and application bias.

418
00:49:31,130 --> 00:49:43,340
So outcome identification bias can be non differential with respect to exposure risk status when it affects equally the exposed and the unexposed.

419
00:49:44,460 --> 00:49:53,730
But it can be differential with respect to exposure status when it affects differently the exposed and the unexposed.

420
00:49:54,780 --> 00:50:00,300
And as we've. Exposure identification problems.

421
00:50:01,170 --> 00:50:06,630
The effect of differential versus non differential will be also different.

422
00:50:08,400 --> 00:50:17,910
Right. So let's begin with the effects of systematic error on outcome identification process and let's do first non differential

423
00:50:18,150 --> 00:50:29,700
for that many is an example of a cohort study of a zinc deficiency as a risk factor for pneumonia in babies.

424
00:50:31,750 --> 00:50:35,200
So zinc is an essential nutrient. Essential means something.

425
00:50:35,200 --> 00:50:39,490
You have to eat from the air, from the environment, because you cannot make it yourself.

426
00:50:41,200 --> 00:50:46,570
And it turns out it's extremely important for maintaining immune function.

427
00:50:47,620 --> 00:50:55,390
So if people go too low on their zinc levels, they might start getting all sorts of infections and they might even die.

428
00:50:56,690 --> 00:51:11,210
Um. So 800 infants with serum zinc assays at recruitment were recruited and followed for one year on the development of new model.

429
00:51:11,540 --> 00:51:17,690
Now let's assume that pneumonia. We are interested in their first occurrence of pneumonia.

430
00:51:18,490 --> 00:51:25,400
It can be a recurrent outcome. But for this example, let's assume, is just one episode of pneumonia.

431
00:51:25,730 --> 00:51:31,490
Right. Follow up is the same for everyone.

432
00:51:32,060 --> 00:51:38,630
No competing risks. So let's keep it simple. The outcome was measured without error.

433
00:51:39,080 --> 00:51:43,640
This is how the debate to table would play out is exposure.

434
00:51:44,270 --> 00:51:48,620
We have. Babies with zinc deficiency on this column.

435
00:51:49,130 --> 00:51:58,460
This is the unexposed babies without zinc deficiency and in which in each column we have the numbers, we know them.

436
00:52:00,580 --> 00:52:09,909
So. We can estimate and the accumulated incidence rate you know it's a reasonable admission

437
00:52:09,910 --> 00:52:17,379
for a cohort study would be correct I mentioned it would be in the there is in the expose

438
00:52:17,380 --> 00:52:24,610
which is 40 divided by 160 the sum of this all the exposed divided by the risk in the

439
00:52:24,610 --> 00:52:31,930
unexposed which is 20 divided by 640 and you get a cumulative incidence ratio of eight.

440
00:52:32,290 --> 00:52:38,470
Very strong associations. So you need to hurry up and pack that up for The Lancet.

441
00:52:40,120 --> 00:52:46,750
It's a big discovery, right? Okay. But there are some potentially bad news.

442
00:52:48,560 --> 00:52:57,050
Let's in in in real life. What if this sensitivity for a pneumonia diagnosis is only 80%?

443
00:52:58,480 --> 00:53:06,790
Meaning. Despite all the best efforts by the investigators, they still missed 20% of all kids who developed pneumonia during follow up.

444
00:53:07,480 --> 00:53:11,020
So the sensitivity of the pneumonia diagnosis is low.

445
00:53:12,660 --> 00:53:16,950
That's bad news. But good news at least, is that it's the same in exposed and unexposed.

446
00:53:16,950 --> 00:53:25,280
So he's not differential, right? And for the sake of simplicity, for now, let's leave the specificity of the 100%.

447
00:53:25,610 --> 00:53:34,620
So this is how the numbers would play out. We will only observe 80% of the effort to expose kids truly with pneumonia.

448
00:53:34,630 --> 00:53:42,100
This 32. And the remaining eight would be misclassified as exposed without pneumonia.

449
00:53:42,100 --> 00:53:45,310
So they would move to this. So.

450
00:53:49,660 --> 00:53:55,930
We would only observe 80% of the 20 unexposed kids struggling with pneumonia in 16 year.

451
00:53:56,440 --> 00:54:00,669
The remaining four would be misclassified as unexposed without pneumonia.

452
00:54:00,670 --> 00:54:09,980
So they move here. Recall because we are talking about sensitivity of an outcome it would primarily affect.

453
00:54:11,280 --> 00:54:18,870
Kids with no right and kids without the outcome just are getting the misclassified ones.

454
00:54:20,340 --> 00:54:29,520
So we can estimate again the cumulative incidence ratio and hmm, the magic didn't work.

455
00:54:31,550 --> 00:54:38,180
Still. That ain't. What happens?

456
00:54:40,020 --> 00:54:43,380
Nothing happened. So.

457
00:54:45,290 --> 00:54:47,270
Non differential misclassification.

458
00:54:48,330 --> 00:54:58,230
Of an outcome, dichotomous outcome due only, only to lack of sensitivity does not affect the cumulative incidence rate.

459
00:54:58,800 --> 00:55:03,510
I guess mathematically, if you are so inclined you couldn't really figure it out.

460
00:55:03,510 --> 00:55:11,070
But basically both kids with and without the outcome are moving proportionally to the.

461
00:55:13,260 --> 00:55:19,320
Other categories of exposed. Question would it affect?

462
00:55:21,360 --> 00:55:24,610
Measures in the absolute. Yes, it.

463
00:55:25,550 --> 00:55:35,270
So this only applies to the cumulative incidence which might still I guess this is a powerful piece of knowledge because I mean, it sounds dramatic.

464
00:55:35,270 --> 00:55:40,720
That means. You can miss as many outcomes as well.

465
00:55:40,970 --> 00:55:54,060
You have to hold steady. But as long as you miss them, the same proportion between exposed and unexposed, there will be no bias in your relatives.

466
00:55:55,270 --> 00:55:57,380
So then. I think it is.

467
00:56:00,390 --> 00:56:09,640
Because sometimes, you know, reviewers who may not have the specific knowledge you monitor may come to you and tell you, you know, your paper.

468
00:56:09,780 --> 00:56:13,890
Hey, you missed so many cases. In Europe.

469
00:56:15,030 --> 00:56:18,780
As a statement of outcome. So there you have it, Nancy.

470
00:56:20,250 --> 00:56:25,980
So if you can show that you miss them proportionally the same in Exposed and unexposed.

471
00:56:26,760 --> 00:56:30,240
You are all set and your paper should still be accepted by the last.

472
00:56:31,110 --> 00:56:38,700
Now. If the specificity is also affected, then that's a different issue.

473
00:56:39,690 --> 00:56:46,800
They say now we have 90% we exposed 90% of the Indian experts, still 93.

474
00:56:48,620 --> 00:56:54,520
What would happen when we would only observe 90% of the 120 exposed kids truly with pneumonia?

475
00:56:54,530 --> 00:57:02,569
That's 108. So this number is replaced by one weight and the remaining 12 will be misclassified as exposed with pneumonia.

476
00:57:02,570 --> 00:57:10,340
So they move to these. On the other hand, we would only observe 90% of the six unexposed kids, three with pneumonia.

477
00:57:10,340 --> 00:57:17,660
That's 558 in this cell. And the remaining 62 would be misclassified as unexposed with pneumonia.

478
00:57:18,080 --> 00:57:23,860
They move to the set. We estimate, again, our cumulative incidence ratio.

479
00:57:25,520 --> 00:57:29,750
And we get to 26 strong attenuation.

480
00:57:30,870 --> 00:57:42,520
Strong opinions. So we can conclude that non differential misclassification of a dichotomous outcome if it's due to low sensitivity only,

481
00:57:42,910 --> 00:57:46,400
there is no bias in the cumulative incidence rate. Right.

482
00:57:47,980 --> 00:57:53,020
If there is also no specificity, it will be biased or they know association or did not.

483
00:57:55,960 --> 00:58:09,610
Yes. Usually look.

484
00:58:10,790 --> 00:58:17,990
When you have a problem with sensitivity, in what direction would the additive scale be affected?

485
00:58:18,320 --> 00:58:24,380
Usually it's an attenuation. And you can actually, if you like, you can try with those numbers.

486
00:58:24,420 --> 00:58:29,680
Look, I think. All right.

487
00:58:29,980 --> 00:58:34,150
How about non differential misclassification of a continuous outcome?

488
00:58:34,480 --> 00:58:42,220
So this what I guess the exercise is very, very similar to what we did with exposure.

489
00:58:42,490 --> 00:58:46,940
Right. But, you know, for the sake of completeness, let's work through the example.

490
00:58:46,960 --> 00:58:50,020
So it's this is a cohort study.

491
00:58:54,600 --> 00:58:59,230
With blood pressure as the exposure. We?

492
00:59:00,300 --> 00:59:10,230
No. With blood pressure as the outcome. Um, so these are the this is the distribution of blood pressure among the exposed.

493
00:59:10,860 --> 00:59:17,760
It's the high salt intake. And this is the distribution among the unexposed.

494
00:59:19,320 --> 00:59:23,770
So if. The outcome. Blood pressure was measured without error.

495
00:59:24,100 --> 00:59:30,429
We would estimate our measure of association as the difference between the means of the two distributions,

496
00:59:30,430 --> 00:59:35,560
and that would be, in this case, ten millimeters of mercury.

497
00:59:36,430 --> 00:59:42,800
Right. But what if our blood pressure device is measuring everybody up?

498
00:59:44,950 --> 00:59:55,590
That can happen. Well, in this case, the distribution among the Expos has moved to the right by 100 and by five.

499
00:59:56,460 --> 01:00:04,980
But because everybody both exposed and exposed are suffering the same major problem, distribution in the end will also move up.

500
01:00:05,450 --> 01:00:11,370
I think what has happened with the measure of association, the difference it means now.

501
01:00:12,820 --> 01:00:20,000
Okay. So. This type of matter has no bias on mean differences.

502
01:00:23,990 --> 01:00:30,680
Done with non differential. Now let's look at what happens with differential error in outcome ascertainment.

503
01:00:32,420 --> 01:00:37,130
Same example of the. Study of zinc and pneumonia.

504
01:00:40,500 --> 01:00:46,650
But now the sensitivity of the pneumonia diagnosis differs between exposed and unexposed.

505
01:00:48,030 --> 01:00:53,210
Affects more the unexposed. So specifically, 100%.

506
01:00:53,900 --> 01:00:58,760
So we would observe 80% of the effort to expose kids to living pneumonia.

507
01:00:58,790 --> 01:01:05,689
That's 32. This number becomes 32. The remaining eight would be misclassified as exposed with a pneumonia.

508
01:01:05,690 --> 01:01:12,560
So they move to so. And we would observe 60% of the 20 unexposed only with pneumonia, which is 12.

509
01:01:12,980 --> 01:01:18,380
The remaining eight would be misclassified as unexposed with on your human, which will skip.

510
01:01:19,730 --> 01:01:23,270
So the cumulative incidence ratio now is ten.

511
01:01:25,110 --> 01:01:29,180
You said. An exaggeration. Of.

512
01:01:30,670 --> 01:01:34,240
The Association because of non differential misclassification.

513
01:01:35,890 --> 01:01:45,970
And if they. I guess I did not include examples on the specificity because the end result is the same, which is is amply.

514
01:01:46,950 --> 01:01:54,270
Okay. So the direction of bias is not always the same when you have non differential misclassification, I mean differential.

515
01:01:54,990 --> 01:02:00,140
It could be an exaggeration, a donation or even a reversal. And it's difficult to predict.

516
01:02:06,160 --> 01:02:10,930
If you have a continuous outcome that's differentially misclassified again,

517
01:02:11,260 --> 01:02:16,330
the situation would be analogous to what we went through in the exposure of misclassification examples.

518
01:02:16,600 --> 01:02:22,150
It depends which group, which exposure group is misclassified in which direction.

519
01:02:22,810 --> 01:02:29,170
So in this case, if they both were messier down and the unexposed are measured up, you could have a reversal.

520
01:02:29,470 --> 01:02:34,010
Or if the exposure were measured up and the unexposed were measured down.

521
01:02:34,360 --> 01:02:42,570
You could have an exaggeration, right? So again, it's difficult to predict.

522
01:02:47,890 --> 01:02:51,820
And the last bit is on the effect of random murder.

523
01:02:52,430 --> 01:03:02,940
Yes. Yes, absolutely.

524
01:03:06,410 --> 01:03:11,030
So if only one of them. The question is, can you have.

525
01:03:12,940 --> 01:03:16,780
Let's say not differential sensitivity and differential specificity.

526
01:03:17,200 --> 01:03:20,290
Yes. Or even vice versa. Right. So the answer is yes.

527
01:03:21,270 --> 01:03:26,060
And. If specificity is not differential.

528
01:03:27,720 --> 01:03:35,390
Or sensitivity is not differential. So either of them is difference.

529
01:03:36,540 --> 01:03:44,970
It will be difficult to predict. So it only takes one to be differential for the error to be difficult to predict.

530
01:03:45,300 --> 01:03:57,120
You would need I mean it could be predictable if you have detailed information on these values and in real life you could obtain them sometimes.

531
01:03:58,420 --> 01:04:06,180
You know, because let's say you have, um, well, you have manufacturing information, so sometimes.

532
01:04:07,250 --> 01:04:12,950
Um, but yeah, it only takes one to be differential for you to not be able to be.

533
01:04:19,270 --> 01:04:25,920
Okay. Any other questions? The fact of the matter.

534
01:04:26,160 --> 01:04:38,310
So we are back to our nice. Nice diagrams stolen from women's epidemiology, but in this case, we have switched.

535
01:04:39,260 --> 01:04:44,010
So first of all, what's the effect of random error on the distributions?

536
01:04:48,930 --> 01:04:53,520
Yes. Again, that's right.

537
01:04:54,150 --> 01:05:01,830
So what has changed here is that now these cards represent the distributions of an outcome.

538
01:05:03,300 --> 01:05:07,890
For the exposed to the right hand side and for the unexposed to the left hand side.

539
01:05:09,780 --> 01:05:14,190
But you know, the issue with Degas and the calves is exactly the same.

540
01:05:14,200 --> 01:05:23,790
So let's say who has the disease when he sees people with disease will be those who fall to the right of this cut point.

541
01:05:24,210 --> 01:05:32,310
It's so and so. Among the exposed 31% will have the disease.

542
01:05:32,730 --> 01:05:36,180
Among the unexposed 16% will have the disease.

543
01:05:36,570 --> 01:05:42,780
And if you have the proportions of people with disease in exposed and unexposed, what can you calculate?

544
01:05:44,800 --> 01:05:49,300
The community incidence rate. Exactly. So in this case is 1.94.

545
01:05:50,290 --> 01:05:58,500
And if you add some random error here. What has happened in distribution has become less distinguishable.

546
01:05:58,650 --> 01:06:07,650
Right. So this one is 40% for the exposed and this one is 31% for the unexposed.

547
01:06:07,980 --> 01:06:12,510
The community ratio has been at ten 1.3.

548
01:06:14,430 --> 01:06:27,670
So the effect of random measurement error. On a dichotomous outcome is going to be an attenuation of the community resilience based on.

549
01:06:29,950 --> 01:06:34,390
Um huh. This is fun. Random error in continuous outcome.

550
01:06:34,750 --> 01:06:42,460
Beware. Mr. So. If there is no error, this is the difference.

551
01:06:42,850 --> 01:06:47,530
If there is random error. This is the difference. The same.

552
01:06:48,990 --> 01:06:52,210
Because again, random matter is not supposed to affect the means.

553
01:06:56,850 --> 01:07:06,549
So here is a summary of the effect of random on outcomes. Dichotomous outcomes tends to attenuate associations value continuous outcomes may have

554
01:07:06,550 --> 01:07:11,290
no effect on mean differences between exposed and unexposed and decreases precision.

555
01:07:14,580 --> 01:07:21,900
Any questions? Everything?

556
01:07:22,470 --> 01:07:31,110
Yes. The difference between.

557
01:07:37,080 --> 01:07:41,730
Okay. Why are we using odds ratios and our cumulative incidence ratios?

558
01:07:42,300 --> 01:07:47,459
We were using odds ratios in the examples that use case control studies because

559
01:07:47,460 --> 01:07:50,610
the odds ratio is the only measure of association that you can use there.

560
01:07:51,660 --> 01:07:53,639
And we are using medications, Rachel.

561
01:07:53,640 --> 01:08:02,410
And we were talking about college studies because I made the example so that it fulfilled the requirements for you to be able to use risk.

562
01:08:04,120 --> 01:08:07,330
You should not use. Guess what I'm going to say to us.

563
01:08:07,630 --> 01:08:13,900
We should not use the odds ratio in the code. That would be a mortal sin.

564
01:08:16,450 --> 01:08:21,730
And forgive. Yes.

565
01:08:38,850 --> 01:08:46,170
Yeah, I guess so. Is your question what happens if you have misclassification of our communities control study?

566
01:08:46,200 --> 01:08:55,090
Would that be a valid translation of your question? Their behavior is actually relatively similar to what you would see in cohort studies.

567
01:08:55,100 --> 01:08:58,970
So it depends on whether the misclassification is differential or non differential.

568
01:09:00,140 --> 01:09:04,280
If it's not differential, you might have attenuation of indications of this differential.

569
01:09:04,290 --> 01:09:07,460
You may not be able to anticipate the data. Yeah.

570
01:09:07,510 --> 01:09:15,070
Good question. I mean, yeah, you know, it's, uh, we have to scratch the surface of the issue here.

571
01:09:15,640 --> 01:09:19,570
I hope that this has given you some hunger.

572
01:09:20,050 --> 01:09:27,820
Hunger, huh? My grandmother, who was a very, very wise woman, even though she didn't have a lot of formal education.

573
01:09:29,000 --> 01:09:32,020
Let's say. He's something now.

574
01:09:32,040 --> 01:09:38,630
I tell my students every now and then. I can give you food, but I cannot leave you hunger.

575
01:09:40,020 --> 01:09:43,350
And that meant she meant something else then.

576
01:09:43,380 --> 01:09:46,460
Lunch? Yeah. Um. Yeah.

577
01:09:47,190 --> 01:09:52,049
Hope you get hungry to learn more about these. She's fascinating. Now, this is a summary of.

578
01:09:52,050 --> 01:09:56,850
Of the effects of systematic error on dichotomous exposures or outcomes.

579
01:09:58,650 --> 01:10:04,320
So misclassification or the customers exposure summary of effects on associations.

580
01:10:05,880 --> 01:10:12,570
So if you have. Poor sensitivity but is non differential.

581
01:10:12,900 --> 01:10:16,860
There will be an attenuation of your emission of association.

582
01:10:17,410 --> 01:10:26,150
The arrow down means at the noise. If you also have problems with specificity, it will also be an attenuation.

583
01:10:27,700 --> 01:10:34,480
Right. If it's differential. Well. It's hard to predict what the question mark means.

584
01:10:35,250 --> 01:10:40,350
However, in one of my. Atlas of Insomnia.

585
01:10:40,350 --> 01:10:48,330
I actually ran some simulations. And again, if you are interested, here is what would happen depending on who is more affected.

586
01:10:48,510 --> 01:10:52,589
So if cases are more affected than control, this is what might happen.

587
01:10:52,590 --> 01:10:55,770
If cases are less affected than controls, this is what might happen.

588
01:10:56,100 --> 01:11:01,739
You're going to have to learn this. I just brought this out because they had spent so much time doing it and they said,

589
01:11:01,740 --> 01:11:06,240
well, at least let me check and then you can just keep it for yourselves.

590
01:11:08,280 --> 01:11:11,490
I don't know. I would never presume.

591
01:11:13,190 --> 01:11:18,080
Yes, they keep true to my promises on why they quizzed you about and what not.

592
01:11:19,340 --> 01:11:28,610
Now misclassification of outcome. So again, if it's not differential due to low sensitivity only, there is no bias of the committee in this ratio.

593
01:11:29,360 --> 01:11:32,690
If there is problems with specificity, that is going to be an attenuation.

594
01:11:33,230 --> 01:11:39,000
If it's differential, it's hard to predict. And you have the data.

595
01:11:39,720 --> 01:11:45,930
This is what would happen depending on whether it is the data, the exposed to the unexposed or vice versa.

596
01:11:48,550 --> 01:11:51,590
Okay. Right.

597
01:11:52,390 --> 01:11:55,740
Questions? Comments.

598
01:12:01,400 --> 01:12:07,129
Okay. So here's your progress report then we you should know the effects of non differential exposure,

599
01:12:07,130 --> 01:12:12,290
misclassification and also the effects of differential exposure misclassification.

600
01:12:13,590 --> 01:12:16,739
The effects of non differential outcome misclassification.

601
01:12:16,740 --> 01:12:21,150
If there is a lack of sensitivity only, we call no effect on the recognition ratio.

602
01:12:21,900 --> 01:12:27,660
There is lack of specificity, typically an attenuation of the association.

603
01:12:29,210 --> 01:12:37,290
What are the effects of differential outcome misclassification and what are the effects of misclassification of continuous measures?

604
01:12:39,440 --> 01:12:43,100
Right. Okay.

605
01:12:43,110 --> 01:12:48,210
So if there are no more questions, then I will see you Monday.

606
01:12:48,420 --> 01:12:51,540
And the homework is already posted.

607
01:12:51,540 --> 01:13:26,460
So you should do. That's why I said that's the other side of your mind explaining how you define precision.

608
01:13:28,140 --> 01:13:34,610
Absolutely. But I invite you to go out because there is another meaning.

609
01:13:35,050 --> 01:13:41,700
Okay. You have a question.

610
01:13:42,270 --> 01:14:13,900
If we go out and. It looks like you're like everything looks pretty much the same.

611
01:14:29,610 --> 01:14:34,210
Yeah. I have.

612
01:16:09,680 --> 01:16:59,320
We're going to. You're.

613
01:17:10,610 --> 01:17:41,570
Then. It.

614
01:18:03,490 --> 01:18:04,210
How is that?

