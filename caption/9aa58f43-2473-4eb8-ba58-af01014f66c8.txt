1
00:00:05,940 --> 00:00:17,610
The Senate seat is in control of the Senate on a package as well.

2
00:00:19,460 --> 00:01:03,870
I would like to think we will see this right now.

3
00:01:04,170 --> 00:01:07,590
All right. You're on Thanksgiving break.

4
00:01:10,590 --> 00:01:30,569
Now know this is refreshing time in my life and I believe album at the end of the semester and we will have

5
00:01:30,570 --> 00:01:40,650
a tomorrow including my career and the last lecture next Thursday you're going to be a review lecture.

6
00:01:41,070 --> 00:01:50,920
That's it. Meanwhile, if you have any questions, make sure that I go to the office hours.

7
00:01:50,970 --> 00:01:55,650
Now is definitely a good time to start reviewing all the materials and preparing for the final.

8
00:01:55,950 --> 00:02:01,070
And the final is scheduled on December the 15th. Okay, leave.

9
00:02:01,110 --> 00:02:08,550
It's 1030 to 1230. And for the final, it's similar to the midterm.

10
00:02:09,210 --> 00:02:14,430
You are allowed to bring the calculator notes.

11
00:02:14,540 --> 00:02:29,130
You should close book close note same as the midterm and 2 hours and younger and is comprehensive meaning everything will be covered in the final.

12
00:02:29,520 --> 00:02:38,700
Also, the emphasis will be put on that second half of the semester, but everything will be covered in the final write the questions.

13
00:02:39,330 --> 00:02:43,170
Yes. Will be given the distribution.

14
00:02:43,560 --> 00:02:50,910
Yes, the distribution table will be provided so the same table as in the textbook.

15
00:02:52,050 --> 00:03:00,420
So in the appendix of the course there there's a distribution table with PDF CD of sometimes me and Baron.

16
00:03:00,990 --> 00:03:05,920
That's basically what we will provide this distribution table.

17
00:03:05,940 --> 00:03:09,960
I'll be provided with other questions.

18
00:03:12,390 --> 00:03:20,040
All right. So although this is the last couple of lectures, these are actually the meat of the course.

19
00:03:20,040 --> 00:03:24,090
And we're going to talk about large some large, large numbers,

20
00:03:25,260 --> 00:03:37,960
central limit theorems and some methods which are all very important methods and techniques in asymptotic statistics and especially for that,

21
00:03:38,400 --> 00:03:48,570
you know, a preparation for next semester when the starting job, when you study 602, these are the fundamental building blocks for that course.

22
00:03:48,990 --> 00:04:00,330
So we'll have one more homework on this on your own, but make sure that you check out the textbook for more exercise questions.

23
00:04:00,660 --> 00:04:07,320
The more you practice, the more you will be familiar with this others concepts.

24
00:04:07,620 --> 00:04:13,679
And I can assure you that there will be questions on this on this topic in the final.

25
00:04:13,680 --> 00:04:18,210
So these are important topics at that point, a very respectful attention to these topics.

26
00:04:19,290 --> 00:04:23,580
All right. So last time, we have to talk about three different types of convergence.

27
00:04:24,030 --> 00:04:27,360
And let's first to review what we have learned last time.

28
00:04:28,710 --> 00:04:42,540
If we have a sequence of random variable denoted by this X and so from one to infinity.

29
00:04:43,950 --> 00:04:47,309
So this is a sequence of event variables that we can talk about.

30
00:04:47,310 --> 00:04:52,860
The convergence of this sequence in particular, we defined three types of convergence.

31
00:04:53,370 --> 00:04:56,760
The strongest one is called almost short convergence.

32
00:04:57,690 --> 00:05:02,580
If a sequence of random variable x. Converge, almost surely two acts.

33
00:05:03,210 --> 00:05:17,640
What that means is if you calculate the probability of taking the limit of X and equal to x, not even has a probability of one or the other words.

34
00:05:18,000 --> 00:05:24,500
The probability of x and minus x greater than absolute and absolute.

35
00:05:24,920 --> 00:05:32,850
It is always. So that's almost sure, almost sort convergence.

36
00:05:33,420 --> 00:05:42,330
And a slightly weaker convergence is called convergence in probability, which is taking this limit outside the probability calculation.

37
00:05:43,290 --> 00:05:49,769
So the limit of the probability on a minus X greater than any epsilon,

38
00:05:49,770 --> 00:05:59,460
greater than zero is zero or an absolute after minus x of absolute value less than absolute as the limit in probability of one.

39
00:06:01,050 --> 00:06:06,990
And lastly, which is a slightly different type of convergence is called convergence in distribution,

40
00:06:07,560 --> 00:06:14,070
and that is that this theory of action to limit acts,

41
00:06:14,190 --> 00:06:22,200
an X that is equal to about X of x is the CDF function,

42
00:06:22,500 --> 00:06:33,240
or this sequence will converge to the CDF for this limit in distribution x for any X in continuity.

43
00:06:35,760 --> 00:06:46,590
Find out I saw X and for any continuity point of this limited distribution and you always have this city of convergence,

44
00:06:46,620 --> 00:06:54,750
then record emergence and distribution. The last time we also talk about the relation between this different type of convergence,

45
00:06:57,660 --> 00:07:05,040
almost sort a convergence implies convergence probability and a convergence of probability that implies convergence in distribution.

46
00:07:06,280 --> 00:07:11,280
An exception is when this limiting distribution is degenerating with the constant.

47
00:07:11,640 --> 00:07:15,270
Then we have a equivalence between the last two emergency.

48
00:07:15,480 --> 00:07:20,610
Our ability is equivalent to immerse yourself in the devices.

49
00:07:21,420 --> 00:07:24,810
Right. These are three types of convergence.

50
00:07:25,080 --> 00:07:31,500
And what are we going to talk about this time and next time?

51
00:07:31,980 --> 00:07:37,890
The last number, Central Theorem, all builds upon this, the different types of convergence.

52
00:07:38,280 --> 00:07:42,510
So make sure you bullishness on this different different modes of convergence

53
00:07:42,840 --> 00:07:48,480
and know how to prove different types of convergence given a specific problem.

54
00:07:48,780 --> 00:07:56,560
All right. So today we're going to first talk about the law of large numbers and then a very important theorem called continuous movement.

55
00:07:57,510 --> 00:08:03,090
So the law of large numbers states as follows Suppose you have a sequence of random arrivals.

56
00:08:03,450 --> 00:08:09,179
We're interested in this particular statistic that is the sample mean, and moreover,

57
00:08:09,180 --> 00:08:15,240
we're interested in what that sample mean going to become when the sample size goes to infinity.

58
00:08:16,620 --> 00:08:26,220
And that's a very practical question. For example, if you want to look at the, say, the average longevity of the population,

59
00:08:26,580 --> 00:08:37,230
you want to collect a bunch of samples and take the average use that as an estimate of the average average age for a particular species.

60
00:08:39,330 --> 00:08:48,000
So one thing that we would like is as we getting more and more samples, we want that sample average to approximating the population average,

61
00:08:48,990 --> 00:08:59,040
but we need a theorem to guarantee that that's in most cases conceptually it should be, but it doesn't come without a price.

62
00:08:59,460 --> 00:09:07,980
We actually have to impose conditions on this random samples in order to set to have the sample mean converging to

63
00:09:07,980 --> 00:09:18,630
the population mean and and in particular we start from this convergence in probability and we call it the law,

64
00:09:18,660 --> 00:09:29,740
the weak law of large numbers. And we talk about the the convergence of this y bar, the sample mean to the population in probability.

65
00:09:30,150 --> 00:09:34,469
And later on, we're going to talk about a slightly stronger convergence,

66
00:09:34,470 --> 00:09:41,070
which is almost sure the margins of the sample mean to the population mean, which we call the strong law of large numbers.

67
00:09:41,400 --> 00:09:47,970
And I will say, what's the difference between this two different kind of law of large numbers?

68
00:09:49,540 --> 00:09:56,740
So to start with, this is the most standard weak law of large numbers and states as follows.

69
00:09:57,460 --> 00:10:10,690
If we have IED samples, independent and identical distributed samples with men being have being sigma squared, both exist and finite.

70
00:10:11,440 --> 00:10:18,940
Then we have the following result. That is the sample mean well converge improbability to the population.

71
00:10:21,550 --> 00:10:30,030
All right. So that's what we call our large number, the most standard, the most classic week of last number.

72
00:10:31,980 --> 00:10:42,240
She states We have iris samples with finite mean and variance than the sample mean.

73
00:10:42,810 --> 00:10:45,830
Well, converse even probability to the population.

74
00:10:49,740 --> 00:10:57,460
But that's the weak law of large number. So in this case, in this result, a couple of important points.

75
00:10:57,850 --> 00:11:03,580
First, we need the samples to be I.D. We have to be a random sample.

76
00:11:04,300 --> 00:11:07,510
They have to be independent and identical and distributed.

77
00:11:07,900 --> 00:11:12,500
Second, both mean and a variance has to exist and finite.

78
00:11:13,540 --> 00:11:17,200
With those two conditions, we have this convergence in probabilities.

79
00:11:18,940 --> 00:11:24,040
And later on, we will say that we can relax some of these conditions, but not all of them.

80
00:11:25,390 --> 00:11:32,620
We cannot relax some, but we may need to add additional alternative conditions in order to have this result.

81
00:11:33,590 --> 00:11:34,940
But this is the most classic one.

82
00:11:35,200 --> 00:11:44,590
If you have 80 samples and a finite amount of errors, then the population a improbability to the population, to the population.

83
00:11:46,360 --> 00:11:49,810
But before we look at the proof. Think about this population.

84
00:11:50,130 --> 00:11:59,350
This sample. The reason why it and converged improbability to another round of marijuana consent

85
00:11:59,440 --> 00:12:04,270
in this case is that because the sample mean is really a sequence of random arrivals.

86
00:12:05,810 --> 00:12:09,770
I as your end goes, from one to infinity.

87
00:12:10,520 --> 00:12:15,410
You got a sequence of this sample means you start from the one sample.

88
00:12:15,560 --> 00:12:20,510
You have this y one bar equal to y one.

89
00:12:20,930 --> 00:12:31,790
If you have two samples, you have this y two bar equal to the average of yyy2 and a3y3 bar.

90
00:12:33,440 --> 00:12:38,180
That's the average of one, y two and y three and so on, so forth.

91
00:12:38,960 --> 00:12:45,400
If you have a y bar, that is the average of y one, two, y.

92
00:12:45,720 --> 00:12:54,750
And so you have this sequence of rhinovirus with a sequence of rhinovirus and talk about convergence, right?

93
00:12:56,750 --> 00:13:04,190
And this theorem states that this sequence of sample means, well, converge improbability to act.

94
00:13:09,030 --> 00:13:11,430
Recall from the previous results.

95
00:13:11,580 --> 00:13:20,640
What we have already learned is that if we calculate for this sample mean statistic, you can calculate the mean and the variance of this search.

96
00:13:21,220 --> 00:13:26,670
In particular, to calculate the mean I use in the linearity of the expectation,

97
00:13:27,030 --> 00:13:35,190
you can guide that the expectation of y and bar exam and if you count quantitative errors now you can get the balances of Sigma Square over and.

98
00:13:36,380 --> 00:13:47,430
Okay. And the proof of this there are really lies in the fact that the variance, the mean stays the same with the population.

99
00:13:47,880 --> 00:13:58,560
And the variance actually if you look at the form but vanish or diminish to zero as and becomes larger.

100
00:13:59,340 --> 00:14:05,460
Right. So conceptually, you can you can imagine what would happen with and it goes to infinity.

101
00:14:06,990 --> 00:14:11,010
This Y and bar will have a mean stay on.

102
00:14:11,910 --> 00:14:15,270
A variance becomes smaller and smaller as M becomes larger.

103
00:14:15,810 --> 00:14:20,340
So eventually it will stay at that without it at all.

104
00:14:21,030 --> 00:14:24,899
So that's why it will converge to this number.

105
00:14:24,900 --> 00:14:34,440
This population mean improper both. So more rigorously we can prove it by using the bishops inequality.

106
00:14:35,100 --> 00:14:45,209
Recall that if Archbishop's inequality, the probability of any random variable minus the mean quite are equal to some constant is always

107
00:14:45,210 --> 00:14:49,140
the last are equal to the variance of the random of motivated divided by the constant square.

108
00:14:49,860 --> 00:14:57,060
That's the generic form of Chavis absence inequality. So here we can replace these constant.

109
00:14:59,880 --> 00:15:07,410
We can replace this constant by any absolute, not only an absolute greater than zero.

110
00:15:07,710 --> 00:15:15,240
And we always have the following result replace the random variable by the sequence of random variable y and bar.

111
00:15:15,480 --> 00:15:25,350
Then we have the following relation. That is the probability of this y and bar minus the meal one and bar which is the same as the

112
00:15:25,350 --> 00:15:30,629
population mean I'm great article to a t it's always smaller or equal to an apparent a wine

113
00:15:30,630 --> 00:15:39,810
bar which is Sigma Square over and over T Square and so that is Dirac directly applying the

114
00:15:39,810 --> 00:15:45,930
championships inequality to this sequence of random arable as a result as angles to infinity.

115
00:15:46,170 --> 00:15:53,790
As we can see, the upper bound of this probability will shrink to zero, since we know the probability is always greater than zero.

116
00:15:54,000 --> 00:16:00,810
We know if you take the limit of this probability, it will always be zero for any fixity greater than zero.

117
00:16:02,130 --> 00:16:07,530
And now by definition that is exactly convergence in probability.

118
00:16:08,640 --> 00:16:15,330
But that's actually the proof. Very, very straightforward use of heavy shots in inequality.

119
00:16:15,540 --> 00:16:19,950
We can prove this. We've lost large number in the most classic setting.

120
00:16:21,780 --> 00:16:27,839
All right. All we need is to notice that the balance shrank to a zero as time goes to infinity.

121
00:16:27,840 --> 00:16:34,830
Quite a sequence of random goals. Then by applying the Chavis as the quantity with the right like this convergence in probability.

122
00:16:39,250 --> 00:16:46,890
Any questions so far about this week, la la la number or the proof of this stuff?

123
00:16:48,160 --> 00:17:00,580
Convergence, the improbability. Right.

124
00:17:00,670 --> 00:17:06,040
So this result, hopefully you'll find it intuitive.

125
00:17:07,790 --> 00:17:18,190
You have many variants. You can realize one of these conditions either the ideal condition or this finite me or Baron's condition.

126
00:17:19,160 --> 00:17:22,620
Sometimes you may have to have additional strength in particular,

127
00:17:22,620 --> 00:17:29,960
or think about the proof of the using this championships and quality in order to use the Travis shops and in quality,

128
00:17:30,550 --> 00:17:43,550
in other words, in order to have these inequality. All we need is to make sure that the barriers for this y and bar is shrink him to a zero.

129
00:17:45,680 --> 00:17:53,360
Right. As long as the Y and bar has men fix that and variance showing him to zero.

130
00:17:53,990 --> 00:18:00,080
This proof will always help. Right.

131
00:18:01,640 --> 00:18:07,040
So that tells us that we probably don't need the IED condition because it is too strong.

132
00:18:08,600 --> 00:18:21,080
As long as they have the balance of the sample means shrink or zero and the mean the sample mean stays at the same value at the population mean.

133
00:18:21,380 --> 00:18:22,390
Then we are going to go.

134
00:18:22,400 --> 00:18:31,580
We can't use the same travesty as the inequality to prove this convergence study that actually leads to the first realization of this result.

135
00:18:32,010 --> 00:18:37,460
That is, instead of having AIB samples, we can have uncorrelated samples.

136
00:18:38,810 --> 00:18:44,360
All right. Uncorrelated means the correlation between any pair.

137
00:18:44,750 --> 00:18:53,809
Y y j is always do any high, not encouraging, and it's much weaker.

138
00:18:53,810 --> 00:19:02,930
That independence and recall that we have talk about this independence imply a correlation but I'm correlated it does not imply independent.

139
00:19:04,550 --> 00:19:10,360
What is the exception? When does Hong Kong independence?

140
00:19:14,980 --> 00:19:20,710
All right. All right. When you are when we are talking about motive, our models are in normal distribution.

141
00:19:21,280 --> 00:19:25,240
Uncorrelated, in fact, implies independence.

142
00:19:26,470 --> 00:19:32,140
That's the only exception in general. Uncorrelated is much weaker than independence.

143
00:19:33,280 --> 00:19:36,610
So now we relax, not condition, that high condition.

144
00:19:37,630 --> 00:19:43,000
Instead of having independence, we only require the y one to y have been uncorrelated.

145
00:19:44,980 --> 00:19:52,480
And instead of having instead of having this identical distribution,

146
00:19:53,620 --> 00:20:02,800
we also relax it to only have the common men being the same, and they cannot even have different variances.

147
00:20:04,120 --> 00:20:15,729
And they could be from different distributions as long as they have the same mean and the virus is bounded meaning or all

148
00:20:15,730 --> 00:20:23,890
this sigma i's square is always narrow because this some large m now is the upper bound for all of this Sigma Square.

149
00:20:34,830 --> 00:20:38,610
This is what it means. The signal I scored is bounded.

150
00:20:39,090 --> 00:20:48,120
Learning is there's some calls that happen such that all of us say by square is the last article to assign this to conditions hold down.

151
00:20:48,120 --> 00:20:55,020
We still have this convergence improbability that somehow me well compares improbability to the populism.

152
00:20:56,970 --> 00:21:02,520
All right, so now we relax the original idea condition to this two conditions.

153
00:21:02,760 --> 00:21:10,590
One, they are uncorrelated. Second, they have the same mean and bounded variance.

154
00:21:11,280 --> 00:21:17,790
The variance doesn't have to be the same as on they are bounded, it's fine and they don't have to have the same distribution.

155
00:21:17,790 --> 00:21:23,120
Even it is two and use conditions which is much weaker 90 condition.

156
00:21:23,790 --> 00:21:29,370
We still have the same result and simple mean converge improbability to an.

157
00:21:32,860 --> 00:21:39,370
And why is that? Well, the same proof that charity shops inequality.

158
00:21:39,370 --> 00:21:50,110
I can recall that for the charity shops inequality by and R is the random variable that we want to control.

159
00:21:50,170 --> 00:21:57,040
Right. Minus the expectation of one bar, which is because all of this y of the same means.

160
00:21:57,040 --> 00:22:02,890
So expectation a lion bar is also then for entity.

161
00:22:03,010 --> 00:22:10,059
The difference, the absolute difference between a wine bar and great our in quantity is always the

162
00:22:10,060 --> 00:22:16,030
probabilities always that are equal to this varies of wine bar over t square.

163
00:22:17,470 --> 00:22:30,350
Now what is the variance of wine bar? To use the formula that I have provided for the linear transformation that enables the

164
00:22:30,350 --> 00:22:40,220
variance of this wine bar as well as the variance of one over as I from one to y,

165
00:22:40,580 --> 00:22:50,070
right? This is why they are uncorrelated equal to one over and square times.

166
00:22:50,450 --> 00:22:54,560
The summation of variance of y.

167
00:22:57,890 --> 00:23:08,360
Right because they are uncorrelated. So you can break down this summation of uncorrelated random variables to the summation of individual variances,

168
00:23:10,010 --> 00:23:14,749
and then we can plug in, what do we know? Individual variances, they are sigma squared.

169
00:23:14,750 --> 00:23:22,380
So in the summation of Sigma by Square, we call in the previous proof.

170
00:23:22,910 --> 00:23:30,050
All we need is this right hand side, this upper bound for this probability to shrink, to zero eyes goes to infinity.

171
00:23:30,740 --> 00:23:38,300
Now if you look at base term. As they go to zero as and go to infinity.

172
00:23:39,590 --> 00:23:45,829
It may or may not, right? We don't know. We have the denominator and the square definitely goes to infinity.

173
00:23:45,830 --> 00:23:51,500
So the denominator will push this quantity to zero.

174
00:23:52,010 --> 00:23:53,809
But if you look at the numerator,

175
00:23:53,810 --> 00:24:04,940
it's also maybe exploding because the summation of n terms avr sigma squared is not properly controlled, the summation can explode.

176
00:24:05,450 --> 00:24:10,910
So we don't know whether it goes to zero or not without any additional constraint.

177
00:24:11,410 --> 00:24:16,340
And what do we do know is that all this Sigma II squares, they are bounded that condition.

178
00:24:16,340 --> 00:24:19,790
We haven't used it since they are bounded.

179
00:24:20,300 --> 00:24:30,590
We have further got another inequality. So this guy is going to be last or equal to one over and square summation of the R about what this bounces.

180
00:24:31,520 --> 00:24:42,010
Right. So this is from I'm one two and you can replace each single sigma by square by an upper both, which is the constant M.

181
00:24:42,770 --> 00:24:52,430
And once you do that it will notice that the summation of and is end times out and that cancels one end with the denominator.

182
00:24:52,640 --> 00:25:04,640
As a result, you have this capital M over and now the numerators they call it, and the denominator it goes to you get the whole term down to zero.

183
00:25:05,300 --> 00:25:12,850
So still you have this the right hand side of this problem, of this inequality shrinking to zero as that going to be.

184
00:25:13,460 --> 00:25:16,880
So the same logic applies right?

185
00:25:17,060 --> 00:25:30,710
As a result, if you take the limit and goes the infinity, the probability on the left y and bar minus greater or equal to a t is still equal to zero.

186
00:25:33,110 --> 00:25:40,730
Right. With this two sets of new conditions, we still have this equation.

187
00:25:40,970 --> 00:25:51,530
The limit of the probability is equal to zero, and that just implies Y and far worse in probability to out by definition.

188
00:25:53,810 --> 00:26:06,840
So this way we have a weaker set of conditions, but still have this awake law number that just tells us we do not need to have either.

189
00:26:07,610 --> 00:26:13,910
A lot of times the samples are correlated, showing the same mean and the variances are bounded.

190
00:26:14,270 --> 00:26:19,900
We still have this way at all times number. Any questions?

191
00:26:27,490 --> 00:26:30,640
And this is pretty much what I just said.

192
00:26:33,520 --> 00:26:37,750
So now the question is, can we follow relax this conditions?

193
00:26:39,010 --> 00:26:45,610
Can we drop this uncorrelated mess and just put a bond on this covariance?

194
00:26:47,490 --> 00:26:56,310
Of why I. And why, again, if this uncorrelated is true, the conditions are further relaxed.

195
00:26:56,810 --> 00:27:00,120
Right. But this probably relaxed too much.

196
00:27:00,720 --> 00:27:07,950
So you start if they put a pound on the covariance between any pair of random variables, would that suffice?

197
00:27:10,860 --> 00:27:15,960
He ordered to stay one of their supplies. All we need to care about is the right hand side of the same quality.

198
00:27:16,260 --> 00:27:23,490
All right. I need to care about is whether the right hand side is still bounded, is still goes to zero and goes to infinity.

199
00:27:25,310 --> 00:27:35,340
But unfortunately, that does not. Because if you think about the right hand side, this varies of Y and bar.

200
00:27:36,090 --> 00:27:39,630
If you break it down without uncorrelated ness,

201
00:27:39,780 --> 00:27:53,310
without this correlation becomes this term one over in squares times this all summation of covariance between any pair of random variables,

202
00:27:53,610 --> 00:27:56,650
including the covariance between a wire and a y.

203
00:27:56,660 --> 00:28:00,570
I know. Where is the variance of y. Right.

204
00:28:00,870 --> 00:28:07,320
So you can double check these equation afterwards using.

205
00:28:08,040 --> 00:28:12,250
Um. The property of the Barons calculation.

206
00:28:12,960 --> 00:28:16,320
And he will say this is that this is actually the case.

207
00:28:17,520 --> 00:28:25,880
And now if you think about this, all of these conferences that we do have about, say, the last article,

208
00:28:25,890 --> 00:28:33,210
time for his term, then we would have we can use the same train to operate on this covariance by him.

209
00:28:33,480 --> 00:28:36,470
But instead of having a single end in the denominator,

210
00:28:36,510 --> 00:28:47,760
a single end we have and square terms that we need to multiply because this summation is summing over and square terms.

211
00:28:49,950 --> 00:28:56,140
All right. And that is square then and cancels out with the square from this side of it.

212
00:28:57,750 --> 00:29:01,250
And instead, we have a constant operator.

213
00:29:02,040 --> 00:29:08,430
So we cannot use the same logic. We have to prove that this guy goes to zero.

214
00:29:10,260 --> 00:29:15,090
So the same crew using those championships, the inequality does not hold anymore.

215
00:29:16,680 --> 00:29:23,700
That is to say, you cannot simply drop this and call it and is and replace it by a balance on

216
00:29:23,700 --> 00:29:27,960
the covariance and use that same proof to show this convergence in probability.

217
00:29:28,740 --> 00:29:34,890
We would need something more if we want. A drop is uncorrelated by this.

218
00:29:34,900 --> 00:29:39,240
We should have a different way to prove this convergence in probability.

219
00:29:50,510 --> 00:29:57,469
So all the above proves or we for the last number require the existence of the second thought.

220
00:29:57,470 --> 00:30:00,920
Our moment we required the barriers to exist.

221
00:30:01,640 --> 00:30:09,290
But in fact, that can also be relaxed. The weight of large number can be proved without using the existence of a balance.

222
00:30:09,500 --> 00:30:17,660
So that's another way to relax. It's a weak law, large number with some appropriate conditions added to the two previous conditions.

223
00:30:18,050 --> 00:30:24,620
We can drop that various existence conditions and we drop that condition.

224
00:30:24,620 --> 00:30:28,610
We add some additional we can conditions. We can still prove the same result.

225
00:30:29,300 --> 00:30:38,690
But the problem is we can no longer use the Chevy shop charity shops in equality because charity shops inequality requires the barons term.

226
00:30:40,190 --> 00:30:48,409
We have to use a slightly different approach to prove that that can be done, but that's beyond the scope of this class.

227
00:30:48,410 --> 00:30:57,380
So is just to ask why. So if you want to learn more relating to the textbook to say other variants of we call all large numbers.

228
00:30:59,770 --> 00:31:03,820
So the bottom line is there are different versions of this week law, large number,

229
00:31:04,250 --> 00:31:12,580
different versions require different sets of conditions and they may relax some conditions, but adding additional weaker conditions.

230
00:31:12,880 --> 00:31:19,930
At the end of the day, you always have this sample mean converge in probability to the population.

231
00:31:21,130 --> 00:31:30,430
That's the fundamental result with proper conditions, the somehow mean what always occurs interoperability to the population.

232
00:31:32,380 --> 00:31:37,300
And that's called the weight of last number. So.

233
00:31:41,480 --> 00:31:44,900
Here is an example where the simple balance is dropped.

234
00:31:45,830 --> 00:31:56,300
Y tu yy12y. And they are either rhinoviruses fight on the median and keep their idi.

235
00:31:56,510 --> 00:32:01,010
We find out. I mean we can have this convergence improbability to opposition meet.

236
00:32:01,670 --> 00:32:08,540
And the last one way to drop that existence of Barrons, you say compared to the previous version that I would talk about,

237
00:32:09,050 --> 00:32:17,480
we do require a stronger I.D. addition than we drop this very existence, embarrassed from the conditions.

238
00:32:18,470 --> 00:32:22,940
So we still have this result and that is a characteristic function theorem.

239
00:32:22,940 --> 00:32:27,030
So out will not.

240
00:32:29,560 --> 00:32:44,280
Talk about it in this class. And another variant of this week long number is we can also change the population.

241
00:32:44,360 --> 00:32:51,400
Men, instead of having a constant population mean we can allow this lie to have different genes.

242
00:32:51,790 --> 00:32:55,330
In fact, suppose each y has its own meal.

243
00:32:55,930 --> 00:33:10,180
Meanwhile, and we love this meal II and this amount to be the average of the UI for that first in terms as of this amount converge.

244
00:33:12,690 --> 00:33:22,020
You can use the same charity shops in equality to prove that the sample mean what it converge improbability to.

245
00:33:25,080 --> 00:33:35,310
So that's another variant which is less commonly used for the purpose of this course, but could be used for any other context.

246
00:33:35,790 --> 00:33:49,199
And if you do not have the same mean you can still how we live large number as of this and defining this way is converging to our sample means

247
00:33:49,200 --> 00:33:56,880
still compares to a constant that counts that you can no longer interpret it as a population mean because there is no population per se.

248
00:33:58,500 --> 00:34:06,030
I interpret that constant as the limit of this subset of population where.

249
00:34:09,920 --> 00:34:17,450
The average of this individual needs. Any questions?

250
00:34:32,630 --> 00:34:36,110
All right. So I swear, this is a good exercise.

251
00:34:36,110 --> 00:34:40,280
So probably you can take a couple of minutes trying to prove this result.

252
00:34:40,720 --> 00:34:51,680
Okay. So using the same charity shops and equality to see whether you can show that if y i c have different means each y i have me

253
00:34:51,680 --> 00:35:02,720
muli and I'm a is defined in this way with the limit being because then out then y and well converse in probability to out.

254
00:35:04,820 --> 00:35:10,860
And. So the hand is you can still use travel shops and they call it.

255
00:35:15,880 --> 00:35:21,520
Hard to prove this. Think about what you really need to show and you can go from there.

256
00:37:45,360 --> 00:40:03,450
Change. All right.

257
00:40:03,480 --> 00:40:11,880
So let's look at this together, see, how can we prove you can make a large number without having the same mean?

258
00:40:13,020 --> 00:40:24,720
And by the way, we do still need to have constraints on the variance and the thickness of the surrounding marbles so we can use the same conditions.

259
00:40:25,050 --> 00:40:28,350
Otherwise, the uncorrelated and the variances balance.

260
00:40:28,770 --> 00:40:38,009
Okay. With these we can first we we need to prove that this Y and bar minus and defining this way and

261
00:40:38,010 --> 00:40:46,229
uncovers in probability to a zero and just say that we can directly use the championships.

262
00:40:46,230 --> 00:40:52,770
Inequality tells us the difference of y bar minus.

263
00:40:57,360 --> 00:41:06,750
We are greater than and our soul is always the last article to square Barron's with Warren Buffett.

264
00:41:08,400 --> 00:41:19,170
Write with us throughout the use of quality and here this is the expectation of a client by definition.

265
00:41:20,130 --> 00:41:31,260
Right. Because an is defined as the sum of my overhead, which is equal to the sum of Y over expectation.

266
00:41:33,720 --> 00:41:36,870
So this y and is the expectation not why box?

267
00:41:40,300 --> 00:41:42,790
Or the Verizon Wireless bar. Same as before.

268
00:41:42,820 --> 00:41:53,440
Nice and square one over and square summation of individual balances because they are uncorrelated and since individual variance is often

269
00:41:53,440 --> 00:42:04,240
bounded so the whole thing is not provided by it is one over and out which goes to it goes to zero and goes up around and goes to zero.

270
00:42:04,680 --> 00:42:17,110
Then the whole thing goes to zero. So the limit of this probability or minus and greater than absolute is zero.

271
00:42:17,690 --> 00:42:25,930
And those events and championships, inequality, same logic as before we have these result.

272
00:42:26,440 --> 00:42:31,600
The limit of this probability is equal to zero any greater than zero.

273
00:42:32,410 --> 00:42:39,130
So from there we conclude not a one bar converge in probability to man.

274
00:42:39,340 --> 00:42:45,380
And we see this. If this is the correct expression.

275
00:42:47,940 --> 00:42:57,880
Yes or no? But it's not.

276
00:43:06,690 --> 00:43:11,330
Can we write it this way? Can we say why I'm converting probability to an.

277
00:43:14,250 --> 00:43:18,450
Yes. I think they're both dependent on and very good.

278
00:43:18,660 --> 00:43:22,470
You cannot. All right. This is a very common people.

279
00:43:22,950 --> 00:43:28,080
We cannot arrive this way because once on the right hand side is also a constant.

280
00:43:28,530 --> 00:43:35,550
That depends on is also a matter that depends on it. So we do not write things like this, but.

281
00:43:38,200 --> 00:43:42,050
And this is wrong. But what you can do is.

282
00:43:46,270 --> 00:43:56,739
Right then seem this way because now the right hand side is just a constant or a random variable

283
00:43:56,740 --> 00:44:03,459
that is not dependent on the one side as a random variable or a sequence of random variable.

284
00:44:03,460 --> 00:44:11,960
That depends on this, which is the correct expression and previously is the correct expression.

285
00:44:12,730 --> 00:44:16,120
So make sure that you don't make that mistake.

286
00:44:16,540 --> 00:44:21,490
You do not post something that has an ad in it on the right hand side of this convergence.

287
00:44:22,690 --> 00:44:31,950
And. So from Chevy Sharp's inequality away, you immediately got this Y in bar minus them a conversion probability to zero.

288
00:44:33,120 --> 00:44:35,190
And that's still not what do we want?

289
00:44:35,220 --> 00:44:46,020
We want wine bar to converge, improbability to have what is the limit of that and to honor to say that we still need to use.

290
00:44:51,280 --> 00:44:59,970
Don't you need to use the nomination so Your Honor, to show why then are converging probability to happen?

291
00:45:00,690 --> 00:45:17,800
This is what we need. We need to show the probability. Is it equivalent to say the probability of y and ga minus m slightly greater than absolute is.

292
00:45:18,820 --> 00:45:23,200
Zero and God stupidity and the other.

293
00:45:23,200 --> 00:45:37,740
Screw this. We need to have this. And compare this with where we are, have, let's say, this star equation, there's only a minor difference.

294
00:45:37,950 --> 00:45:40,800
And that is, instead of having an ad we should have at.

295
00:45:43,360 --> 00:45:53,560
So the idea of going from the star equation to this equation that we desire is to use the so called triangle inequality.

296
00:45:54,640 --> 00:46:09,790
So notice that this Y and bar minus M its laws are equal to lion bar minus and plus and minus.

297
00:46:12,160 --> 00:46:17,560
Okay, this is called the triangle triangle or inequality.

298
00:46:20,200 --> 00:46:25,960
So the difference between one bar and have is last are equal to the summation of this two absolute differences.

299
00:46:26,290 --> 00:46:33,670
One is one bar minus one. It's that this is a quality that it should have learned before.

300
00:46:34,960 --> 00:46:45,760
And if you look at the desired event by hand, absolute this absolute difference greater than absolute.

301
00:46:51,670 --> 00:47:05,380
But this inequality, all we need to found is the probability of y and bar minus a greater than absolute over two and minus m greater than over two.

302
00:47:06,250 --> 00:47:10,030
As long as we can both of them, then the probability will be bounded.

303
00:47:10,750 --> 00:47:15,459
So that's the idea of proving this. So with this inequality,

304
00:47:15,460 --> 00:47:20,590
I'll give you a couple more minutes and see whether you can conclude the proof and

305
00:47:20,590 --> 00:47:29,560
a go from this star equation to show this desire equation using this inequality.

306
00:49:18,100 --> 00:50:56,500
If. Right.

307
00:50:57,700 --> 00:51:03,100
Got it. So here is the more formal proof.

308
00:51:04,150 --> 00:51:05,410
Given this inequality,

309
00:51:05,680 --> 00:51:16,480
we always have these inequality in terms of the probability because of Y and bar minus M is or equal to the summation of this to absolute value.

310
00:51:16,840 --> 00:51:21,580
So Y and bar minus am greater than absolute, which is the desired event.

311
00:51:22,030 --> 00:51:29,740
The probability is upper bounded by the probability of this to us so that information greater than absolute.

312
00:51:30,400 --> 00:51:42,549
Since we know that the limit of men is equal to I'm using this speaking without a language, so speak my absolute delta language.

313
00:51:42,550 --> 00:51:51,610
We can say that there exist capital n such that for any small and greater than capital n is m a minus than an absolute value.

314
00:51:51,910 --> 00:51:55,510
That's all. The difference is always the last that half over two.

315
00:51:56,380 --> 00:52:05,080
And that give us for large enough small n we should always have y and bar minus m a absolute value greater than half of our two.

316
00:52:06,620 --> 00:52:10,960
And so the our original probability is further out propounded by this new probability.

317
00:52:11,650 --> 00:52:17,860
And it says we have already proved that this Y and bar minus conversion probabilities is zero.

318
00:52:18,070 --> 00:52:22,360
We know this quantity goes to zero and you could put everything together.

319
00:52:22,600 --> 00:52:26,470
You it get the desired limit that is and goes to infinity.

320
00:52:26,770 --> 00:52:32,650
The probability of wine bar minus greater than possible without probability zero.

321
00:52:34,330 --> 00:52:48,670
And so this is just the the use of the condition between different events said y implies the other

322
00:52:48,670 --> 00:52:53,540
than the probability of one event is the last inequality of the probability of the other event.

323
00:52:55,450 --> 00:53:00,400
So the key is to notice this triangle inequality, right?

324
00:53:01,800 --> 00:53:54,780
Okay. So let's take a break and come back to. You just going to basically how we are going to be going back to the market once

325
00:53:54,900 --> 00:54:00,780
we have days we have to since we already know that I'm not going to do this.

326
00:54:00,780 --> 00:54:12,299
And the first time we are busy trying to be clear about what to do and why.

327
00:54:12,300 --> 00:54:16,320
For my readers, that's so important.

328
00:54:16,720 --> 00:54:25,210
The small apartment complex which. Certain impacts you wouldn't require.

329
00:54:25,580 --> 00:54:36,750
The Lion Park was not only going to cost money and naturally you are somewhat concerned about a fraction of that increase.

330
00:54:38,340 --> 00:54:49,569
Saying that this is true and this is going to make sure I have proof that if the

331
00:54:49,570 --> 00:54:55,389
person can't really do zero so the entire planet has to shrink to zero and be

332
00:54:55,390 --> 00:55:00,850
able to deal with this person so that it could be the same with what you want

333
00:55:00,860 --> 00:55:22,870
to be able to download from the average in terms of how you've got to do that.

334
00:55:23,920 --> 00:55:29,079
So this event greater than ourselves is not equivalent to say either.

335
00:55:29,080 --> 00:55:37,570
This once we know that this will happen, representing your close could be smart or real.

336
00:55:38,080 --> 00:55:41,900
So they need to find an offer, right.

337
00:55:41,950 --> 00:55:49,120
Is are not an upper bound to say that the probability one is greater than epsilon epsilon.

338
00:55:52,480 --> 00:56:15,400
Everyone is going to believe that this is something that is an absolute does not imply on Twitter or the other way.

339
00:56:16,930 --> 00:56:21,050
It does not imply one way or another.

340
00:56:21,280 --> 00:56:40,150
On top of it. I need to find out 2% of the population so that we can see the events in some other proximity.

341
00:56:40,990 --> 00:56:45,440
Just like the first one is like a real mind, all possible problem.

342
00:56:45,660 --> 00:56:50,930
You want to break it down into those two parts right there.

343
00:56:51,080 --> 00:56:55,480
However, I think this is a space, so that's why we need to use this.

344
00:56:57,610 --> 00:57:07,180
We need to find like first definitely going to stay with the small constant that they have talked about the other one.

345
00:57:07,330 --> 00:57:14,320
My question is, why do we have to enumerate? Because here we show that we get them into separate complement.

346
00:57:14,500 --> 00:57:24,670
Yes. And they both are building. So I think both of them are 0.3% of them.

347
00:57:25,090 --> 00:57:32,970
And that balances is already about those who are named.

348
00:57:39,380 --> 00:57:49,420
And so this is the event that's about right.

349
00:57:50,020 --> 00:58:01,260
So these. That's not loss and far minus one.

350
00:58:03,030 --> 00:58:23,480
And we're right. You know what I mean?

351
00:58:25,860 --> 00:58:37,780
The cost of doing it was quite small.

352
00:58:45,880 --> 00:59:02,570
I've done everything to make sure that you break it down.

353
00:59:03,200 --> 00:59:13,100
It's too hard. It just gets so busy.

354
00:59:18,410 --> 00:59:35,950
It seems to be greater than council function. It's another each piece.

355
00:59:36,900 --> 00:59:41,390
I don't particularly want to say the difference.

356
00:59:41,810 --> 00:59:52,240
You don't have to have a simpler notation about what's right.

357
00:59:53,990 --> 01:00:00,640
Absolutely. There's going to be a template.

358
01:00:03,020 --> 01:00:11,650
Other states and municipalities have close to zero.

359
01:00:12,300 --> 01:00:26,330
Some schools look like in Chicago.

360
01:00:28,070 --> 01:00:33,400
The other three with like, you know.

361
01:00:59,850 --> 01:01:06,360
Right. So thanks to Robert, just to mention a cleaner version of proof.

362
01:01:06,480 --> 01:01:09,690
So you can take a look at the board before the event.

363
01:01:09,930 --> 01:01:14,549
Why don't we try to bond this to absolute value?

364
01:01:14,550 --> 01:01:21,630
Greater than absolute is what we are trying to do. But we want to show that the probability of this guy goes to zero and goes to infinity.

365
01:01:21,990 --> 01:01:28,440
So this event is actually implies another event that is.

366
01:01:42,750 --> 01:01:53,310
So the upper part implies the earth are greater than epsilon over two or the second part greater of the hops over to the right.

367
01:01:55,560 --> 01:02:11,580
Once we have these said operation, we see that the probability of this event going to be last are equal to the probability of this event.

368
01:02:12,750 --> 01:02:19,580
Right. And the probability of this event is equal to our last part.

369
01:02:20,040 --> 01:02:28,260
That's already equal to the probability of y far greater than epsilon over two.

370
01:02:29,520 --> 01:02:35,850
Plus the probability of an error greater than.

371
01:02:38,550 --> 01:02:41,880
Over to my right.

372
01:02:42,720 --> 01:02:50,510
And now we know that this guy goes to zero and this guy goes to zero because I'm

373
01:02:50,530 --> 01:02:55,470
an assassin and we already proved that I can take the limit and go stupidity.

374
01:02:55,620 --> 01:03:00,090
This probability goes to zero. So the upper bound is going to be showing zero.

375
01:03:01,980 --> 01:03:05,820
But I can also complete the proof. That makes sense.

376
01:03:06,140 --> 01:03:08,880
Yes. So what is the first line in play? The second line.

377
01:03:09,780 --> 01:03:23,610
So if you think about this event, in order for this summation to be viewed as absolute, you have to have either one to be greater than half of it.

378
01:03:26,190 --> 01:03:30,120
So that means this event implies this event.

379
01:03:31,020 --> 01:03:37,709
Or alternatively, you can consider the complement of the event if this guy is last are equal to absolute and

380
01:03:37,710 --> 01:03:45,600
both has to be Lazare to happen over to but which also means this event implies this event.

381
01:03:45,990 --> 01:03:51,740
If one event imply the other event, the probability you're going to have this loss aren't quite organized.

382
01:03:52,830 --> 01:03:59,880
So that's why we've learned when we talk about the set theory, probability calculation, right?

383
01:04:00,210 --> 01:04:07,380
And from here to here is the same thing. So here is an intersection, is a reunion event.

384
01:04:07,770 --> 01:04:15,060
The probability of the reunion of two events as lost are equal to the summation of two probabilities,

385
01:04:15,870 --> 01:04:20,520
like about the Mendelian event, eight event, see?

386
01:04:21,030 --> 01:04:24,060
So A or B, is this right?

387
01:04:24,750 --> 01:04:33,520
So the probability of a obvious place and the probability of a plus probability IP is always going to probably be.

388
01:04:34,410 --> 01:04:41,410
So that's why you have this sudden inequality and all of those are converging to zero.

389
01:04:41,460 --> 01:04:47,610
So I started yes. Also using the triangle IRC.

390
01:04:47,850 --> 01:04:57,870
You see how we know that the probability of the left hand side greater than epsilon is less than the probability of right hand side.

391
01:04:59,340 --> 01:05:07,650
So the same logic if this triangle inequality does not rely on any additional conditions, it always holds.

392
01:05:07,740 --> 01:05:15,479
Right? So then this event y and bar minus our absolute value great.

393
01:05:15,480 --> 01:05:22,770
Are equal to absolute well imply the right hand side o is greater than or equal to absolute.

394
01:05:24,210 --> 01:05:28,500
The left hand side greater are equal. That absolutely implied the right hand side great.

395
01:05:28,510 --> 01:05:33,630
All equal to absolute proof on the right hand side, always greater than or equal to you on the left hand side.

396
01:05:35,640 --> 01:05:40,410
So that's why this is a smaller event and this is a bigger event.

397
01:05:40,800 --> 01:05:47,850
That's why we have this inequalities. But the same logic can set the break down from here to here.

398
01:05:48,840 --> 01:05:55,440
And anyway, so this is just a some derivation that is for your information.

399
01:05:55,440 --> 01:05:58,440
So it's not required for this course.

400
01:05:58,440 --> 01:06:03,120
So it's something that's just good to know.

401
01:06:03,510 --> 01:06:07,350
All right. So that's we follow up.

402
01:06:07,350 --> 01:06:12,570
Last number. Any questions before we move on, talk about strong law class number.

403
01:06:17,280 --> 01:06:20,819
Regardless of all different variants of this way, global large number.

404
01:06:20,820 --> 01:06:27,510
Always keep in mind you do need some conditions while the random samples and you have this sample mean

405
01:06:27,780 --> 01:06:33,560
converging probability to the population mean that's basically the core of the weight class number,

406
01:06:34,560 --> 01:06:37,950
right? And it always is.

407
01:06:39,090 --> 01:06:43,110
There are different sets of conditions that guarantee that convergence of probability.

408
01:06:43,770 --> 01:06:50,420
Sometimes you can do you have ivy samples so you can reduce this apparent condition.

409
01:06:50,440 --> 01:06:54,840
Sometimes you do not have any samples, but you do have concordant samples.

410
01:06:55,110 --> 01:07:03,000
Then you have another set of conditions. End of the day, you have this sample me converging probability to the population.

411
01:07:03,630 --> 01:07:07,170
All right. Now moving on to the struggle of last number.

412
01:07:08,730 --> 01:07:15,629
I strongly mean that the convergence is stronger. Instead of having this convergence in probability,

413
01:07:15,630 --> 01:07:22,380
now we have convergence almost sharp and with some conditions we can prove that this

414
01:07:22,380 --> 01:07:29,040
y and bar the sample mean converge almost charting two of the population mean.

415
01:07:32,070 --> 01:07:36,270
If you have convergence on maturity, then we could struggle off large number.

416
01:07:38,220 --> 01:07:41,190
So that strong means this convergence is stronger.

417
01:07:42,120 --> 01:07:50,000
And think about this two different modes of convergence, especially in this case convergence to a constant that is the population.

418
01:07:50,640 --> 01:07:55,800
What are we the difference between this two different types of convergence?

419
01:07:57,540 --> 01:08:03,980
If this conversion is converging to a random variable, I hope you already understand the difference.

420
01:08:03,990 --> 01:08:12,150
But if his conversion has two accounts, that one would be the conceptually one would be the difference between these two types of commandments.

421
01:08:13,020 --> 01:08:17,250
We have talked about in the previous lecture, if it's true in Palestine,

422
01:08:17,460 --> 01:08:22,530
then converging in distribution is the same thing as converging improbability.

423
01:08:23,940 --> 01:08:26,009
Right. And now what?

424
01:08:26,010 --> 01:08:35,910
This result just tells us that converging improbability is not the same thing as converging in almost certain, even to a constant.

425
01:08:37,860 --> 01:08:41,220
So the rules both provide a very good description of the difference.

426
01:08:41,820 --> 01:08:44,940
It states as follows the wake of large numbers.

427
01:08:44,940 --> 01:08:58,940
States that for any fixed large value of m sansar this y and star r is likely to be near you and near this population.

428
01:08:59,460 --> 01:09:05,490
However, it does not say that a one. Ah, well, same near you.

429
01:09:06,060 --> 01:09:12,780
And it's only likely to be near, but not stay near for all values of n larger than star.

430
01:09:13,470 --> 01:09:20,100
Thus it leaves open possibility that large values of one bar star can occur infinitely often.

431
01:09:22,080 --> 01:09:26,970
The strong law says that this cannot happen if you have convergence,

432
01:09:27,240 --> 01:09:33,900
almost surely then once you become near MU, you're going to stay there and never goes away.

433
01:09:35,280 --> 01:09:46,890
So that's the difference. So the weak, a large number tells you that the sample mean as angles to infinity is going to be near mu likely,

434
01:09:47,910 --> 01:09:55,950
but occasionally it can be farther away from you and we can jump back and forth farther away from you.

435
01:09:55,980 --> 01:10:00,990
Nirmal infinitely often, but almost short a convergence.

436
01:10:01,590 --> 01:10:06,780
Once you stay near mu, you're going to stay there and never move or move away from you.

437
01:10:07,200 --> 01:10:12,000
That's the main difference and that really comes from the definition.

438
01:10:12,450 --> 01:10:18,000
So the weak law. Which is man's convergence.

439
01:10:18,020 --> 01:10:22,750
Improbability. Recall that. We have this.

440
01:10:22,780 --> 01:10:26,890
The limit outside my room goes to infinity.

441
01:10:27,490 --> 01:10:34,990
The probability of y bar minus mu within the length.

442
01:10:38,520 --> 01:10:45,940
Zero. Strong.

443
01:10:49,690 --> 01:11:05,120
She? So this is the definition directly to write out the definition of weak convergence or emergency probability.

444
01:11:05,120 --> 01:11:14,630
And almost surely in terms of this large number and if you look at the bottom one, the strong of large number,

445
01:11:15,110 --> 01:11:21,679
it means that as I'm going to infinity, this one bar are going to stay with probability.

446
01:11:21,680 --> 01:11:26,500
One will never go away from you with sufficient probability.

447
01:11:26,840 --> 01:11:38,960
But if you look at the upper the upper result, the week of last number, what it requires is that with a given small window,

448
01:11:39,500 --> 01:11:47,810
the probability of that a one falling outside of that, a window to still have a probability as long as that probability goes to zero.

449
01:11:47,930 --> 01:11:55,700
But it doesn't have to stay at zero, it's fine. So that's the main difference between its two most of convergence as a result.

450
01:11:56,120 --> 01:12:00,500
The main difference is whether you require that one bar to stay or not,

451
01:12:01,610 --> 01:12:08,210
you're required to stay that that's strong of a large number if it is not require to stay as a weight class number.

452
01:12:09,440 --> 01:12:14,540
So there are very subtle difference between this two modes, but I hope you can,

453
01:12:14,720 --> 01:12:21,730
you know, enter sound the difference between the two because this is now the same and.

454
01:12:27,040 --> 01:12:33,790
The same as the wake of last number. The strong of large number also have different variants and the standard.

455
01:12:36,650 --> 01:12:44,600
Standard Theorem states as follows acquire one to win the acceptance of either random samples with finite means.

456
01:12:45,080 --> 01:12:57,440
Then why and bar well converge almost surely to have in other words, a probability of one bar equal to an is one to the limit of one,

457
01:12:57,440 --> 01:13:06,440
bar equal to one, and the proof required this of more sophisticated techniques.

458
01:13:06,590 --> 01:13:10,670
So which will be beyond the scope of this class.

459
01:13:11,660 --> 01:13:16,820
An interesting can check out the Ross book for more details of the proof.

460
01:13:18,050 --> 01:13:27,020
Originally was first proof for a particular distribution and then later on was generalized to all distributions for any distribution.

461
01:13:27,260 --> 01:13:33,320
As long as we have samples and finite means, we always have this a strong of large number.

462
01:13:39,800 --> 01:13:41,210
So for the general approve,

463
01:13:41,810 --> 01:13:50,450
we need this so-called cosmograph inequalities which provides an upper bound from the tail probability of the maximum value of the article.

464
01:13:50,450 --> 01:13:55,350
Some event in random articles that.

465
01:14:00,010 --> 01:14:05,290
Any question about this strong of large number ten here.

466
01:14:05,440 --> 01:14:14,440
The most important thing to keep in mind is the conceptual difference of the strong off large number from the width of large number.

467
01:14:15,190 --> 01:14:17,440
To understand this, different models of convergence.

468
01:14:19,620 --> 01:14:29,850
And in practice, the wave of large numbers and much more commonly used as a convergence in is good enough in most cases.

469
01:14:34,790 --> 01:14:43,190
Vikings, but no question. Let's move on to the next, which is a very important thereon for convergence.

470
01:14:43,200 --> 01:14:46,950
That is called continuous map theorem. This is a.

471
01:14:49,590 --> 01:14:56,520
An important CRM that I'm going to use to prove more theorems later on, especially upon convergence in probability.

472
01:14:56,820 --> 01:15:03,480
So it states as follows If we have a sequence of random of our blocks and that converge improbability to us,

473
01:15:04,080 --> 01:15:09,840
and another sequence of random are about y y a converge improbability to y.

474
01:15:11,640 --> 01:15:15,600
Then we have the following results first.

475
01:15:18,370 --> 01:15:30,040
If we construct a new sequence exemplars, while a new sequence of random variable by sequence will also convert improbability to X plus one,

476
01:15:30,520 --> 01:15:37,750
the other was the summation of our original limiting distributions and construct the sequence using them.

477
01:15:38,260 --> 01:15:42,940
The minus x minus one. They will converge in comparable to x minus one.

478
01:15:44,110 --> 01:15:50,250
And if we use multiplication a same bend axiom multiply y.

479
01:15:50,260 --> 01:15:56,830
I've got two converging probability two x times one and finally for adding continuous function.

480
01:15:57,400 --> 01:16:00,640
If you apply that continuous function to the sequence,

481
01:16:01,810 --> 01:16:08,380
it will also converge improbability to the same function applying to the limiting distribution of x.

482
01:16:11,450 --> 01:16:20,390
So that's caused continuous impairment because the continuous function well metabolism, convergence, improbability.

483
01:16:21,350 --> 01:16:26,690
If you have a sequence convergence in probability through a random variable, then applying this continuous mapping,

484
01:16:26,990 --> 01:16:33,660
you still have convergence, improbability, and the same property holds for all the convergence.

485
01:16:35,750 --> 01:16:54,180
So that's the result. So before we look at the examples, let's first quickly take a look at the proof.

486
01:16:55,530 --> 01:17:03,990
So just take the first one as an example and you can follow the proof and try to prove all of the other results by yourself.

487
01:17:04,140 --> 01:17:12,510
Okay. So, Your Honor, to prove that I am plus y and converting properly to X plus one.

488
01:17:12,900 --> 01:17:16,320
First, let's take a look. What do we really need to show?

489
01:17:17,340 --> 01:17:22,770
The convergence in probability by definition, means the limit.

490
01:17:24,430 --> 01:17:30,000
So we need to show the limit of.

491
01:17:48,760 --> 01:17:53,330
We need to show this result, this equation, right?

492
01:17:53,820 --> 01:18:01,799
The probability of an X plus Y, which is our new sequence of random travel minus these X plus y,

493
01:18:01,800 --> 01:18:07,170
the new limiting distribution, the absolute difference greater than how to have someone greater than zero.

494
01:18:08,130 --> 01:18:11,160
The probability always converts to zero.

495
01:18:12,540 --> 01:18:17,070
As long as we can prove this, we have this convergence probability.

496
01:18:18,480 --> 01:18:21,540
Now use the same idea as before.

497
01:18:22,210 --> 01:18:32,100
I'll give you a couple of minutes to think about how we can probably offer about this probability to show the limit goes to zero.

498
01:18:34,140 --> 01:18:39,060
Okay. So the condition we have is this to convergence improbability.

499
01:20:12,860 --> 01:20:50,460
That's. She?

500
01:20:55,050 --> 01:20:59,790
I didn't get it. Me your hand if you got it.

501
01:21:44,680 --> 01:23:03,820
It's. She?

502
01:23:34,670 --> 01:23:38,920
All right. So let's look at this together. How to tackle this problem you got.

503
01:23:38,990 --> 01:23:42,200
Now we need to use the containment of the events.

504
01:23:43,310 --> 01:23:46,880
So this is what we are trying to prove, the limit of this probability, zero.

505
01:23:46,910 --> 01:23:53,389
If we can somehow up our bumping up or down this probability or find a superstar of

506
01:23:53,390 --> 01:24:00,020
this event and prove that the probability of that super set compares to zero down.

507
01:24:00,710 --> 01:24:11,620
Now, right now, think about this event, the absolute difference between X plus Y and minus X plus Y greater than ourselves.

508
01:24:11,930 --> 01:24:15,530
What it would be a super side of that event.

509
01:24:16,070 --> 01:24:38,660
What does this event imply? That words? First of all, we can use the triangle inequality again, right?

510
01:24:39,680 --> 01:24:51,800
Using the triangle to inequality. We know this guy. This absolute difference is class are equal to X, minus X, plus y, minus y.

511
01:24:54,500 --> 01:24:59,780
So the same as before. We used to try and going into quantity first was we have this triangle inequality

512
01:25:00,440 --> 01:25:06,680
and hope it becomes apparent that you can find a super site of the previous event.

513
01:25:09,690 --> 01:25:14,280
If the absolute defense of this guy have to be greater than Epsilon,

514
01:25:14,670 --> 01:25:24,100
the name implies the summation of these two absolute values also have to be greater than absolute right,

515
01:25:25,320 --> 01:25:30,570
because this single absolute value has to be less or equal to this summation of

516
01:25:30,570 --> 01:25:36,300
two absolute values the single absolute value greater than absolute implies.

517
01:25:36,750 --> 01:25:49,300
The summation is also greater than absolute, so that we find the first inequality that is the probability of accidental points.

518
01:25:49,410 --> 01:25:56,640
That's why the value greater is absolute is not provided by.

519
01:26:06,360 --> 01:26:12,160
This far back. And now we need to find a buyer for this.

520
01:26:12,420 --> 01:26:15,780
This one is. Same. The same logic applies.

521
01:26:16,170 --> 01:26:21,780
If the summation is greater than absolute, that implies one of the two.

522
01:26:22,620 --> 01:26:27,630
At least one of the two has to be greater than half absolute.

523
01:26:29,550 --> 01:26:35,680
Otherwise, if both our last two halves out alone, then the summation cannot be greater as absolute right.

524
01:26:35,730 --> 01:26:37,050
So that's another superset,

525
01:26:37,710 --> 01:26:52,320
which means this is further inland or equal to the probability of x and minus x bar where the absence of or y and minus y where is an absolute.

526
01:26:54,450 --> 01:27:02,490
And finally referring to that Venn diagram, the probability of a RB is always the last article through the probability of a.

527
01:27:06,870 --> 01:27:15,630
Plus the probability of being. Right.

528
01:27:17,280 --> 01:27:20,460
And I want to come. What can I say about this? Two probabilities.

529
01:27:22,890 --> 01:27:25,030
Now we have to use this condition. All right.

530
01:27:25,090 --> 01:27:34,020
So as we know that access and converging probabilities, you know, just tells us if you take the limit of the first probability, now it goes to zero.

531
01:27:35,130 --> 01:27:45,000
That's the definition of emergency probability and Y and converging probability y means the second probability will come out of the zero.

532
01:27:45,180 --> 01:27:52,220
If we take and goes to infinity. And putting everything together.

533
01:27:52,580 --> 01:27:58,460
We don't have the original equality. That is, if you take the element of this probability of desire.

534
01:27:59,150 --> 01:28:07,490
Then the limit is going to be zero because I promote showing them to zero, not complete approval.

535
01:28:08,030 --> 01:28:13,040
So really the key here is to find proper balance for this probability.

536
01:28:13,640 --> 01:28:20,090
And step by step, we use this triangle inequality, we use this content of events,

537
01:28:20,450 --> 01:28:29,480
and we use this this is property of the probability union of two events.

538
01:28:32,110 --> 01:28:38,780
And finally, we use this condition or convergence in probability, and we can prove this result.

539
01:28:39,080 --> 01:28:47,840
Similarly, you can try to prove the remaining pretty much of the same idea and apply to all these different result.

540
01:28:50,350 --> 01:28:59,520
Okay. Any questions? So again, continuous mapping theorem, very important one.

541
01:29:00,030 --> 01:29:04,430
What it says is that if you have convergence, improbability or convergence,

542
01:29:04,440 --> 01:29:10,830
almost surely if you apply a continuous transformation of the run of the sequence of run available,

543
01:29:11,160 --> 01:29:14,840
then you still have this convergence of probability or convergence almost.

544
01:29:16,320 --> 01:29:25,440
Right. The limiting distribution, the limiting random variable going to be transformed accordingly.

545
01:29:28,140 --> 01:29:33,480
So let's look at example, say the uses of this continuous mapping result.

546
01:29:34,710 --> 01:29:43,410
Say this y12in being uh, samples with mean b mu at variance being sigma squared,

547
01:29:43,470 --> 01:29:58,080
which is finite and we define as and star to be one version of sample balance and as n squared to be another version of sample virus.

548
01:29:58,440 --> 01:30:04,180
If you compare the two, the main difference is what accounts that you use in front of this summation and.

549
01:30:05,880 --> 01:30:15,290
So previously when we first introduced the Simple Parents, we have talked through why most of the people use this second definition,

550
01:30:15,310 --> 01:30:20,040
this as and square as sample because it sounds biased, right?

551
01:30:20,250 --> 01:30:26,340
If you calculate the expectation of this as a square, it will be exactly equal to sigma squared.

552
01:30:26,940 --> 01:30:33,030
The first one is not. It's biased. So we all learn more about that in next semester.

553
01:30:33,540 --> 01:30:36,600
But with this two definitions,

554
01:30:37,560 --> 01:30:50,910
what we are interested in is what this as an squared and what this as an star square going to converge to in probability and say,

555
01:30:50,910 --> 01:30:58,860
what are we going to use the large number and continuous mapping theorem that we have learned to show that constant.

556
01:30:59,350 --> 01:31:03,120
Where this to sequence all run of variables converge to.

557
01:31:05,160 --> 01:31:10,120
So I'll give you a couple of minutes trying to do some derivation and see whether we can use what

558
01:31:10,120 --> 01:31:16,890
do we have a learning this clause to find the limits of this to sequence of around variables.

559
01:36:03,050 --> 01:36:06,230
Any thoughts? Take a look at this problem together.

560
01:36:07,040 --> 01:36:17,630
So how can we use a large number? This is what occurs to probabilities of weight, loss of large number and the continuous error.

561
01:36:17,840 --> 01:36:23,990
Solve this problem. Let's problem this as as Star Square.

562
01:36:24,640 --> 01:36:35,160
Okay. So the definition of S and Star Square is one over summation of this Y by white barred squared in the current form.

563
01:36:35,180 --> 01:36:38,390
We can now directly apply the law of large number.

564
01:36:38,810 --> 01:36:42,770
Why is that? Can we just shred this?

565
01:36:44,300 --> 01:36:54,770
This entire thing is squared term y and minus y, our square as a random variable and apply the large number to find the limit.

566
01:36:55,860 --> 01:37:03,610
I we do that. Why or why not?

567
01:37:09,040 --> 01:37:14,680
Well, first of all, it is in this simple average format, right?

568
01:37:15,100 --> 01:37:18,310
We have this one over ten summation of terms.

569
01:37:19,090 --> 01:37:24,910
But that doesn't look like the sample mean. But the we have large number also.

570
01:37:25,210 --> 01:37:29,530
The conditions are not as strong, but we do have conditions that we need to check.

571
01:37:30,460 --> 01:37:42,340
In particular. Either your samples are ideal or you have uncorrelated random variables with the same mean and bounded virus.

572
01:37:42,970 --> 01:37:48,340
Either way, you have to satisfy the some constraints, right, in order to use that in a large number.

573
01:37:48,730 --> 01:37:56,570
But if you look at this terms. Each random variable inside information is y minus y bar squared.

574
01:37:57,710 --> 01:38:05,450
First of all, commonly they are not ivy. In fact, they are not even uncorrelated y y minus y.

575
01:38:05,450 --> 01:38:12,260
Bar squared is definitely correlated with y to minus y bar squared because they both involve y bar.

576
01:38:12,630 --> 01:38:18,680
Right? So it's not hard to show that they are actually correlated and in fact,

577
01:38:18,680 --> 01:38:22,910
it doesn't satisfy any conditions or any of the version that we have talk about.

578
01:38:23,240 --> 01:38:29,750
So you cannot directly use the lower number, since we cannot reliably use them.

579
01:38:29,750 --> 01:38:34,340
We need to break down this square and see where we can where we can find one.

580
01:38:34,340 --> 01:38:40,340
We can simplify this the this formula to build out a we can apply that the last number,

581
01:38:40,910 --> 01:38:50,750
the very great bonus square when we have it one over a defamation, I want to add y square minus to y y bar.

582
01:38:51,200 --> 01:38:54,230
That's why our square. Right.

583
01:38:54,800 --> 01:39:06,110
Any further rewrite this you got to try this one term is one over summation of y squared.

584
01:39:06,770 --> 01:39:13,660
The another term is minus. Why our square?

585
01:39:16,040 --> 01:39:19,400
Okay. And the reason why the second term is minus one of our score is.

586
01:39:20,090 --> 01:39:27,710
Take a look at the second summation. The summation of Y is just no end times y bar.

587
01:39:28,790 --> 01:39:31,910
So with the one over in front, you have a y bar.

588
01:39:32,150 --> 01:39:42,350
So minus y our square plus with our square. So that gives us actually it's a minus one y bar.

589
01:39:45,590 --> 01:39:55,950
Yeah, that's right. That's right.

590
01:39:55,980 --> 01:40:24,450
I don't think. So the three terms first term you're a second term this one over and summation of why I picked up two I knocked it by square last term.

591
01:40:24,960 --> 01:40:33,270
It's just the why of our square. Okay, so this is why we come after we break down this square term.

592
01:40:35,810 --> 01:40:39,280
All right. So this is what we have after we break down this square drop.

593
01:40:39,940 --> 01:40:48,640
Now, the question now is, what does this quantity, this sequence of random converts to in probability first?

594
01:40:48,910 --> 01:40:52,480
That's why back this is the sample of ivy samples.

595
01:40:52,720 --> 01:41:09,420
So what does that come to? But the liberal arts do you view are really good the population I mean.

596
01:41:09,600 --> 01:41:14,700
Right. That's what do we have to learn or the entire class this lecture.

597
01:41:17,990 --> 01:41:19,460
And what about the first time?

598
01:41:29,790 --> 01:41:42,100
If you look at the term, I find that actually it's also a sample mean instead of being the sample member why it's a sample mean a lot.

599
01:41:42,120 --> 01:41:51,850
I squared. Right. So you are taking the sample average of this y square and says y their I.D.

600
01:41:52,090 --> 01:42:02,440
Y squared also are also I.D. if y are mutually independent, then y squared is also mutually independent.

601
01:42:03,640 --> 01:42:11,320
Right. And they should also have the same distribution. So this is the sample mean of another sequence of I.D. rhinovirus.

602
01:42:12,520 --> 01:42:15,580
So what does that commerce to you square?

603
01:42:17,370 --> 01:42:23,450
What is that? You were very close to this guy, right?

604
01:42:24,250 --> 01:42:27,510
Six students. Remember that?

605
01:42:30,760 --> 01:42:35,380
The low large number tells us the sample mean always come first to the population.

606
01:42:36,400 --> 01:42:39,770
So now we're talking about a sample me of this wise square, random.

607
01:42:40,810 --> 01:42:49,900
So they should converge to the population of the wise square rectangles, which is this guy by the expectation of why I square.

608
01:42:50,140 --> 01:42:59,180
And what is that square? Sigma squared plus B squared, right?

609
01:42:59,210 --> 01:43:08,540
Because we know the variance is equal to the expectation of running a variable squared minus the expectation of the random variable squared.

610
01:43:09,440 --> 01:43:15,530
So if you move the terms, you'll see that the second order moment is equal to sigma squared, classmates squared.

611
01:43:15,530 --> 01:43:18,740
So that's what this first term converts to.

612
01:43:20,420 --> 01:43:24,350
Now, if you look at the original term, we have all the components.

613
01:43:24,350 --> 01:43:27,380
We just need to put them together. All right.

614
01:43:27,490 --> 01:43:33,830
We know what the first term converts to. That commerce team probably converts to a sigma squared plus minus square.

615
01:43:34,910 --> 01:43:40,010
And the second one, the squared is outside, inside the squared ecommerce to me.

616
01:43:41,810 --> 01:43:51,590
The final step is to use the continuous mapping theorem. If y bar converts to MMU, what do we what do we know about a y bar squared?

617
01:43:52,040 --> 01:43:56,110
What about this continuous transformation of the sequence over random of our.

618
01:44:00,100 --> 01:44:04,570
Because this result. Right, this g function is just a square function.

619
01:44:05,110 --> 01:44:14,350
Now when exactly got this with our square and what should I converge to use square.

620
01:44:15,520 --> 01:44:20,350
So that's the first usage of. Continuous, but.

621
01:44:20,840 --> 01:44:29,120
Now we can use it again because we have this two sequence of rhinovirus, both converging improbability to some cause.

622
01:44:29,130 --> 01:44:37,580
Then if I do a summation or subtraction of this to the window, it also converting probability to this.

623
01:44:39,400 --> 01:44:43,750
To the constant that is a summation or subtraction of the original result.

624
01:44:44,190 --> 01:44:54,280
And so if you put everything together now, just convert to sigma squared plus minus squared, minus male square, which is sigma squared.

625
01:44:55,330 --> 01:45:01,590
And that is what this is. And Star Square covers to improbability.

626
01:45:03,310 --> 01:45:06,970
And to solve this two points.

627
01:45:08,620 --> 01:45:13,730
First, we notice the we use a large number.

628
01:45:15,580 --> 01:45:19,930
We use a large, large number. It doesn't have to always take this y bar form.

629
01:45:20,470 --> 01:45:28,330
It can be any as long as your run of our was our idea, or at least at the same mean uncorrelated.

630
01:45:28,660 --> 01:45:32,680
Now you can use a large number to support me. Always converts the population.

631
01:45:33,970 --> 01:45:41,080
And then we use this continuous mapping which tells us any continuous transformation of the sequence.

632
01:45:41,410 --> 01:45:49,540
We converge to the transformation of the limit in probability and also the addition,

633
01:45:49,540 --> 01:45:58,300
subtraction or multiplication of two sequences for the conversion comparable to the same operation of the limits.

634
01:45:59,440 --> 01:46:03,970
And as a result, we have this as a star squared conversion probability.

635
01:46:04,270 --> 01:46:07,460
Two segments for any questions.

636
01:46:10,840 --> 01:46:15,670
And with that, we can all we can also write out the convergence for us and square.

637
01:46:16,960 --> 01:46:21,220
So recall that as a square is equal to one over a minus one.

638
01:46:21,490 --> 01:46:29,560
The summation of y minus y are square and we can take advantage of what we have just proved.

639
01:46:30,520 --> 01:46:38,540
So that is equal to and over the minus one times as and Star Square.

640
01:46:39,440 --> 01:46:44,200
Right. So that's the relation between this two different definitions of sample variance

641
01:46:44,920 --> 01:46:50,760
says as the star square we have our Y proof not converting Sigma Square.

642
01:46:51,940 --> 01:46:55,180
What do we know about this? An over A minus one.

643
01:46:57,020 --> 01:47:00,870
I'm going to infinity. What does commerce do? What?

644
01:47:01,420 --> 01:47:07,120
And that convergence. You can also say about convergence probability.

645
01:47:07,420 --> 01:47:12,490
You can consider this. It generates sequence to be a sequence of point mass.

646
01:47:14,110 --> 01:47:20,170
So you can still say that's convergence. You probably that's at the generate case if you have both.

647
01:47:20,680 --> 01:47:29,290
Now, what do we know about our original sequence? I can give you the same continuous magic theorem, right?

648
01:47:29,740 --> 01:47:32,979
So you can have one sequence convergence to one another.

649
01:47:32,980 --> 01:47:43,300
Sequence convergence to Sigma Square. Then the curve of this two or the converging probability two one times Sigma Square, which is Sigma Square.

650
01:47:45,270 --> 01:47:50,160
All right. So we can say that both as an ass and star square.

651
01:47:50,430 --> 01:47:57,480
Converge two sigma squared. And in fact, we call them.

652
01:48:07,450 --> 01:48:12,249
Says Bose, conversing, probably just like a square. We call them consistent asymptotes.

653
01:48:12,250 --> 01:48:21,670
Plus I'm got sigma squared. But as we argued before, this ass and Star Square is a biased estimate of Sigma Square.

654
01:48:22,030 --> 01:48:25,330
It's only asymptotically unbiased.

655
01:48:26,090 --> 01:48:28,600
Biased and Square is unbiased estimate.

656
01:48:29,170 --> 01:48:39,880
So in the next semester you will learn more about this consistency and how biased as a society this is give you a flavor of what that is really about.

657
01:48:40,150 --> 01:48:43,990
It's all about the convergence of this sequence of random variables.

658
01:48:45,910 --> 01:48:49,569
Any questions? All right.

659
01:48:49,570 --> 01:48:58,630
So this is the first time that you encounter this convergence in different times and also the last number.

660
01:48:58,930 --> 01:49:06,760
Make sure that you check out all these exercise problems in the textbook and familiarize yourself with this these techniques.

661
01:49:06,950 --> 01:49:10,120
Okay. So especially when you use this result,

662
01:49:10,900 --> 01:49:22,840
how to use this result to solve this different different variants of the problem and how to responsibly use it in practice that only needs practice.

663
01:49:23,290 --> 01:49:30,100
Okay. So they sometimes worked on this exercise problems and come to the office, our teaching, our questions.

664
01:49:31,840 --> 01:49:56,800
This time we're going to talk about central element. All you need to do is.

