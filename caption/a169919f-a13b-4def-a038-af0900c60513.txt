1
00:00:04,360 --> 00:00:07,389
So our COVID community level is medium.

2
00:00:07,390 --> 00:00:18,310
So this is the setting where you can use your own personal risk comfort in our setting, for example.

3
00:00:18,310 --> 00:00:26,680
But if you go on a path or if you go to a clinic, I'm going to be heading for a flu shot at most or Jordan right after class.

4
00:00:26,680 --> 00:00:32,320
So in those situations you wear a mask, but otherwise it's up to your own judgment.

5
00:00:32,650 --> 00:00:36,160
So whatever. Whatever you want to do. All right.

6
00:00:36,160 --> 00:00:41,230
So. Let's go ahead and check in on where we are in the course.

7
00:00:45,440 --> 00:00:53,450
This morning I added some links to the recordings under the day of the the class just so that it's easier

8
00:00:53,450 --> 00:00:59,510
to find and that I thought it was probably useful because last times recording did not capture sound.

9
00:01:00,140 --> 00:01:06,350
And so I have connected it to a recording I made last year when I was zooming from home.

10
00:01:06,350 --> 00:01:10,100
So you'll see me and like my, you know, my home office.

11
00:01:10,100 --> 00:01:15,440
It's actually a lot nicer than the podium picture, I think. So it'll feel very intimate if you listen to that one.

12
00:01:17,300 --> 00:01:29,480
So we are here finishing up hand out two and we're going to, by the end of today, will have covered everything you need for your assignment.

13
00:01:30,410 --> 00:01:37,520
And remember, that lab starting next week and next week's lab will also be helpful for the assignment.

14
00:01:38,300 --> 00:01:41,060
The first problem of the assignment being about data analysis.

15
00:01:41,060 --> 00:01:49,430
So a lot of the things that I'm covering in the in the handout to today will be directly relevant to your homework.

16
00:01:49,430 --> 00:01:54,050
So. I'll give you I'll give you some perk up moments.

17
00:01:54,810 --> 00:01:58,380
For that. So we're going to.

18
00:02:00,500 --> 00:02:11,989
Finish review. You know, from here, not one and two, but and then we're going to go to some information about diagnostic tests and disease screening.

19
00:02:11,990 --> 00:02:15,710
And there's a little bit of review from your first statistics course there, too.

20
00:02:16,430 --> 00:02:22,700
You've probably remember sensitivity and specificity and Bayes theorem for your very first statistics class.

21
00:02:23,300 --> 00:02:30,680
We're going to review that quickly, but we're going to very quickly from there go into receiver operating characteristic curve analysis,

22
00:02:30,980 --> 00:02:34,190
which I bet you did not do before, but is a very,

23
00:02:34,190 --> 00:02:44,629
very common tool that you need for assessing utility of biomarkers to classify people with disease or not.

24
00:02:44,630 --> 00:02:48,500
And so it's a tool I use a lot. It's worth sharing. We'll cover that.

25
00:02:48,770 --> 00:02:52,790
Their analysis of matched binary outcomes.

26
00:02:52,790 --> 00:03:00,170
You may have seen a slight version of this before, but at least when I was teaching interest that they didn't really do very much of that.

27
00:03:00,650 --> 00:03:06,889
So that won't feel very new. And then Handout five is a very quick review of logistic regression,

28
00:03:06,890 --> 00:03:13,130
mainly for the purpose of reminding you model building tools in your regression settings.

29
00:03:13,490 --> 00:03:18,979
So we'll finish that very quickly and then the rest of the course is pretty much all new material.

30
00:03:18,980 --> 00:03:28,310
So, you know, by handout, by the end of handout five, everything that I want you to be fresh on from previous courses will be fresh.

31
00:03:29,850 --> 00:03:37,270
Right. Any questions before I get started?

32
00:03:37,720 --> 00:03:44,370
Where we left off last time. Okay.

33
00:03:45,700 --> 00:03:59,570
So we'll go ahead and get started. The last time. We left off right at the beginning of our made analysis material and the setting,

34
00:03:59,580 --> 00:04:03,330
if you want, if you're the kind of person who learns by hand calculations,

35
00:04:03,630 --> 00:04:09,420
this is a very minimal meta analysis where you're only combining information from two studies.

36
00:04:09,420 --> 00:04:14,010
And so this won't be too onerous to do by hand if you're that if you have that learning style,

37
00:04:14,700 --> 00:04:18,719
I'm going to teach you how to get all of these results through software packages.

38
00:04:18,720 --> 00:04:26,220
You will never have to do this by hand. And my style of teaching is I don't really require you to memorize formulas either.

39
00:04:26,700 --> 00:04:35,159
So a lot of the hand calculation stuff is just sort of FBI information and I'll show you

40
00:04:35,160 --> 00:04:39,840
how to get everything the way I would expect you to in day to day life through software.

41
00:04:41,330 --> 00:04:48,230
So the study involved looking at ovarian cancer risk and the predictor.

42
00:04:49,140 --> 00:04:56,730
That they were evaluating was whether there had been nine or one or more term pregnancies.

43
00:04:57,210 --> 00:05:03,540
And there were two studies in the San Francisco area that collected data on this.

44
00:05:04,890 --> 00:05:08,280
And so just tabulating the results.

45
00:05:08,280 --> 00:05:12,690
Here's the two by two. Table for study one. Here's the two by choose. Table four, study two.

46
00:05:16,020 --> 00:05:20,879
And just a quick glance at the summary statistics from these.

47
00:05:20,880 --> 00:05:26,130
These are the kinds of results that will be summarized in the papers for the two separate studies.

48
00:05:26,130 --> 00:05:36,870
So if you were reading the paper about study one, you would somewhere in that paper see the odds ratio for that study,

49
00:05:36,870 --> 00:05:40,529
and they would probably also give you 95% confidence intervals for that.

50
00:05:40,530 --> 00:05:46,230
We'll have that calculation on the next slide or two. And so the odds ratio for study one was 1.58.

51
00:05:47,220 --> 00:05:53,060
Looking these are just the. The probabilities.

52
00:05:54,050 --> 00:05:57,320
Oh, sorry. The odds. Yeah.

53
00:05:57,530 --> 00:06:07,850
The odds of having ovarian cancer if you were looking at none versus one or more pregnancies.

54
00:06:08,270 --> 00:06:19,040
And so that's the odds ratio. And then the odds, if you were in the know term pregnancies is 0.33 greater than one term pregnancies is .21.

55
00:06:19,250 --> 00:06:23,630
And the only reason I'm taking a second to look at the odds rather than just the odds ratio,

56
00:06:23,960 --> 00:06:31,160
is that the odds of having ovarian cancer are higher in study two, just generally.

57
00:06:32,350 --> 00:06:38,590
And so if it is also true, that study is associated with.

58
00:06:40,500 --> 00:06:46,230
Not just the outcome, but the probability of having the exposure then studies the confounder.

59
00:06:46,530 --> 00:06:51,540
And that's actually the case. Studies had different chances of know term pregnancies as well,

60
00:06:51,840 --> 00:06:57,180
where the first study had a higher chance of people falling in net zero term pregnancies category.

61
00:06:57,510 --> 00:07:03,659
So study is a confounder and so what you would have learned from your interest that classes

62
00:07:03,660 --> 00:07:11,490
that if study is a confounder you don't create an overall two by two table to analyze the data.

63
00:07:12,150 --> 00:07:18,090
You can't just collapse and make a single table where you add all the cells together, the B cells and so on.

64
00:07:18,420 --> 00:07:23,160
You have to do some adjustment for study to get an appropriate odds ratio.

65
00:07:24,350 --> 00:07:30,009
Right. And it looks like the odds ratios from the two separate studies are pretty close to one another.

66
00:07:30,010 --> 00:07:36,300
So at least in terms of the effect size here for the odds ratio of the two studies, it looks like they're trying to get at the same story.

67
00:07:36,310 --> 00:07:39,220
When you look at the ratio of the odds, they're very close.

68
00:07:40,230 --> 00:07:45,570
And so combining these into a single story makes sense, at least by looking at the odds ratio.

69
00:07:50,790 --> 00:07:54,710
All right. So. Okay.

70
00:07:54,750 --> 00:07:58,530
This is your primary audio source is very quiet or silent.

71
00:07:58,550 --> 00:08:01,680
That's what happened last time when things didn't get recorded.

72
00:08:01,680 --> 00:08:05,610
So. I'm wondering if I can.

73
00:08:07,960 --> 00:08:12,940
So maybe this will get recorded.

74
00:08:14,650 --> 00:08:18,130
Is this is this. This isn't giving you, like, a backlash or anything, right?

75
00:08:18,160 --> 00:08:21,160
All right. So I'm going to just do this and cross my fingers.

76
00:08:21,160 --> 00:08:28,570
Otherwise, you're going to be watching me in my living room again, recording lectures from last year with all the same jokes, I'm absolutely certain.

77
00:08:28,990 --> 00:08:36,130
So. So when you're going through made analysis, you kind of go through a checklist of questions on how it's going to go.

78
00:08:36,400 --> 00:08:42,640
And the first question we've already looked at briefly when we looked at the two odds ratios for the study, the studies.

79
00:08:43,030 --> 00:08:46,690
And the question was, are the trials measuring the same treatment effect?

80
00:08:47,500 --> 00:08:52,630
There's an actual statistical test of homogeneity that I'll show you that people do.

81
00:08:53,950 --> 00:08:55,689
It's not a very high powered test,

82
00:08:55,690 --> 00:09:04,000
but people do do that to see if there's statistically meaningful differences between the odds ratios for the two studies.

83
00:09:04,960 --> 00:09:08,560
I, in addition to that test, like to look at the effect sizes themselves.

84
00:09:08,560 --> 00:09:14,770
Sometimes what you'll see is the test of homogeneity looks okay in terms of combining the studies,

85
00:09:14,770 --> 00:09:18,159
but it's so low power that the effect size is very different between the two studies.

86
00:09:18,160 --> 00:09:22,990
You might still be a little cautious about whether they're really telling the same story or not.

87
00:09:23,380 --> 00:09:30,490
Maybe the protocols were different. Patient populations were just different enough not to be applicable to one another.

88
00:09:31,240 --> 00:09:34,060
So this is sort of something you would check statistically.

89
00:09:35,100 --> 00:09:41,910
But also use your judgment about the study's findings to see if it's appropriate to combine, since this is a very low power test.

90
00:09:42,480 --> 00:09:49,440
So we'll review that soon. And then the second question is, once you decide if it's appropriate to combine the two studies.

91
00:09:49,710 --> 00:09:56,340
The second question is the common odds ratio different from one?

92
00:09:56,520 --> 00:10:06,810
So this is the interesting scientific question, whether there is an association between the exposure and the outcome that's statistically significant.

93
00:10:06,840 --> 00:10:09,120
This is the one that we want to talk about in our papers.

94
00:10:10,860 --> 00:10:20,370
And then the third question is, once you have your overall test, has it been contaminated with publication bias?

95
00:10:20,820 --> 00:10:26,379
And this is. Equally, if not more important than question two,

96
00:10:26,380 --> 00:10:36,610
because so many times the meta analyzes are not confirmed later when there's a larger randomized clinical trial,

97
00:10:36,940 --> 00:10:45,280
and often it's a publication bias issue that is resolved with the clinical trial.

98
00:10:45,580 --> 00:10:49,750
But there there are funnel plots that we will look at that we briefly picked

99
00:10:49,750 --> 00:10:54,040
out last time that should help you at least get a sense that this is an issue.

100
00:10:58,110 --> 00:11:02,940
So for all of the hand calculations, if you end up trying to learn this by doing it by hand,

101
00:11:04,830 --> 00:11:10,379
everything is kind of done on the log odds ratio level rather than the odds ratio itself.

102
00:11:10,380 --> 00:11:18,960
And the reason they're doing that is that the log odds ratio, that particular summary statistic has a nice normal distribution.

103
00:11:19,470 --> 00:11:28,650
And so, you know, averaging that has better properties than if you were trying to just average the odds ratios themselves, which don't have it.

104
00:11:30,580 --> 00:11:33,730
As good of a distribution to average across.

105
00:11:34,330 --> 00:11:38,500
And so all of these formulas kind of work on the log odds ratio scale, as you'll see.

106
00:11:38,950 --> 00:11:46,420
So step one is to calculate log odds ratios and odds ratio confidence intervals for all of the studies.

107
00:11:48,550 --> 00:11:54,160
If you're combing the literature, this will often be done for you within the papers.

108
00:11:55,780 --> 00:12:01,150
And we've already done it for these particular two studies for ovarian cancer.

109
00:12:01,960 --> 00:12:07,370
And then ask the question, do estimates from the different studies show clinically meaningful differences by.

110
00:12:10,150 --> 00:12:14,770
And so here are those two studies again. And on the log odds ratio scale.

111
00:12:15,280 --> 00:12:20,200
There's the information for study one. So here's the point estimate for the log odds ratio for study one.

112
00:12:20,680 --> 00:12:27,540
And then here also, I've put the variance of that log odds ratio, which is basically one over all the different cell counts.

113
00:12:27,550 --> 00:12:30,890
That's not too hard of a formula to deal with.

114
00:12:31,210 --> 00:12:41,290
And so here is the variability of that estimate. These variability terms are going to get used in averaging in a lot of the formulas that we'll see.

115
00:12:42,340 --> 00:12:49,270
And here's study two, same deal. And so for the first study,

116
00:12:49,270 --> 00:12:57,840
a 95% confidence interval for the odds ratio takes the confidence interval for the log odds ratio on the inside of each of these parentheses.

117
00:12:57,850 --> 00:13:07,419
So here's the log odds ratio estimate and then this inside of this parentheses is the -1.96 times the squared of the variance here and here.

118
00:13:07,420 --> 00:13:13,180
Inside the parentheses is the log odds ratio plus 1.96 times the squared off variability.

119
00:13:13,570 --> 00:13:20,049
And we, we have we you've probably gotten used to this trick because you've all had logistic regression before,

120
00:13:20,050 --> 00:13:26,920
but if you have confidence intervals on the log odds ratio scale to get back to the confidence of growth on the odds ratio scale,

121
00:13:26,920 --> 00:13:34,030
you have to exponentially both the lower confidence limit and you have to exponentially rate the upper confidence limit.

122
00:13:34,780 --> 00:13:40,030
All right. So here finally is the 95% confidence interval for the odds ratio.

123
00:13:40,360 --> 00:13:44,230
And in that particular study, the confidence interval covered one.

124
00:13:44,240 --> 00:13:48,220
So that particular study did not have a statistically significant result.

125
00:13:49,720 --> 00:13:54,400
And so, yeah, that was probably very upsetting for them.

126
00:13:54,700 --> 00:13:56,540
The second study was a little luckier.

127
00:13:56,540 --> 00:14:04,950
Is that kind of doing similar calculations with with the data over here for 32, you get a 95% confidence interval that does not cover one.

128
00:14:04,960 --> 00:14:12,850
So they were probably very excited. And so the media analysis is using information from both studies to come up with an even yet even better estimate.

129
00:14:13,790 --> 00:14:21,739
Combining across those. So the next thing we generally think about is whether we should combine the study results.

130
00:14:21,740 --> 00:14:25,400
And I was talking about a test for homogeneity that I want to show you,

131
00:14:25,790 --> 00:14:30,770
but one of the elements in the head calculations is the overall odds ratio estimate.

132
00:14:30,780 --> 00:14:34,939
So I'm going to just take a step back first and show you a couple of ways that

133
00:14:34,940 --> 00:14:39,890
people get an overall odds ratio because they'll get used in the homogeneity test.

134
00:14:41,660 --> 00:14:45,060
And so that there are two methods that are used.

135
00:14:45,080 --> 00:14:48,350
The first is called the wolf method with two O's in Wolf.

136
00:14:49,430 --> 00:14:56,450
And I'm going to interchangeably use the term inverse variance method.

137
00:14:58,670 --> 00:15:01,100
With the wolf method it turned.

138
00:15:01,180 --> 00:15:11,329
It turns out that you'll see things are average with respect to inverse variances, and that approach generalizes to a lot of different made analysis.

139
00:15:11,330 --> 00:15:17,240
Not just that ones for two by two tables. And so I'll cover that one and.

140
00:15:18,810 --> 00:15:25,350
Next. And it's actually quite easy to work with in terms of hand computations if you learn that way.

141
00:15:25,860 --> 00:15:31,979
The mental handle method you've probably seen before, this one is vastly preferred.

142
00:15:31,980 --> 00:15:36,270
If you're actually combining two by two tables because it does very well,

143
00:15:36,600 --> 00:15:43,049
even if you have many, many tables and accounts and them include zeros and very small numbers,

144
00:15:43,050 --> 00:15:49,590
it does it's very stable and performs extremely well in terms of its operating characteristics.

145
00:15:49,590 --> 00:15:53,910
The wolf method requires large sample sizes for each study for it to work well,

146
00:15:54,300 --> 00:15:59,490
we so we have large sample sizes for each study in the ovarian cancer example.

147
00:15:59,490 --> 00:16:03,020
So we're okay. So the wolf method.

148
00:16:04,370 --> 00:16:09,860
Here are a lot of formulas. The Wolf method takes each of the study tables this year.

149
00:16:10,130 --> 00:16:14,810
Each study is indexed with little I and there's big capital I.

150
00:16:14,840 --> 00:16:20,419
Total studies were combining so big I was two for our term pregnancy ovarian cancer

151
00:16:20,420 --> 00:16:26,830
example and we already kind of did the calculations for the log odds ratio.

152
00:16:26,840 --> 00:16:36,739
Here it is in terms of the A, B, C, D notation and here is the weight Y that we're going to use to average these like odds ratios.

153
00:16:36,740 --> 00:16:43,879
So you can see on the inside here, it looks a lot like that variance of the log odds ratio we saw earlier.

154
00:16:43,880 --> 00:16:48,820
It's one of our all of the cell counts for that study, but we're doing one over that.

155
00:16:49,070 --> 00:16:53,750
So this is like the inverse variance of the log odds ratio for that study.

156
00:16:54,140 --> 00:16:57,410
That's why I'm going to keep calling it inverse variance method.

157
00:17:01,040 --> 00:17:10,400
And so the wolf method for estimating the common log odds ratio is to do these weighted averages of the log odds ratio for the various studies.

158
00:17:11,250 --> 00:17:14,490
So, so these little weights y are here.

159
00:17:14,510 --> 00:17:23,389
So what does that doing? It's basically saying if you're variance for the log odds ratio for a study is particularly precise.

160
00:17:23,390 --> 00:17:27,440
So it's very small. We're going to weight that study more in this average.

161
00:17:29,000 --> 00:17:37,280
And so the more precise in terms of the variability, the smaller the variability is, the bigger the weight is when you do this averaging.

162
00:17:40,610 --> 00:17:52,939
All right. And there are formulas for the confidence intervals for the common log odds ratio here, and I'll have an example of their use shortly.

163
00:17:52,940 --> 00:17:58,610
But if you're the type of person who learns by doing by hand, by all means, you know, you'll have an example of this by hand,

164
00:17:58,610 --> 00:18:03,890
but I'm going to kind of quickly move through it as well, since you've seen some of this before, at least.

165
00:18:04,310 --> 00:18:08,620
And you won't. Need to do it by hand unless you really like learning that way.

166
00:18:10,590 --> 00:18:15,510
The common odds ratio, you exponentially rate the common log odds ratio.

167
00:18:15,600 --> 00:18:20,610
So you take the if this is the lower confidence limit and this is the upper confidence limit,

168
00:18:21,180 --> 00:18:26,319
but 95% confidence interval for the overall odds ratio using this method is exponentially

169
00:18:26,320 --> 00:18:30,210
hitting whatever that lower number is in exponentially whatever that upper number is.

170
00:18:34,030 --> 00:18:41,150
All right. So in the privacy of your own room, you can double check that these formulas give these.

171
00:18:42,840 --> 00:18:50,969
These little results here. So just quickly, the wait for the first study is 17.2.

172
00:18:50,970 --> 00:18:55,620
After you plug in all of these things and the wait for the second study is 20.83.

173
00:18:55,920 --> 00:18:57,989
And so this makes a lot of sense, right?

174
00:18:57,990 --> 00:19:03,780
Because you can just tell from the second study, the sample size is so much larger, you would expect it to have a larger weight.

175
00:19:04,230 --> 00:19:08,580
And it is so it is capturing intuitively what you would expect to be true.

176
00:19:09,270 --> 00:19:13,739
So the overall estimate for the common log odds ratio is 0.479,

177
00:19:13,740 --> 00:19:20,490
so it's slightly closer to 2.498 because of that weight than the point four or five seven.

178
00:19:21,390 --> 00:19:25,830
And the overall odds ratio estimate exponentially and that is 1.61.

179
00:19:26,370 --> 00:19:31,710
So in the software output, we're going to see this number 1.61 a lot.

180
00:19:32,010 --> 00:19:36,630
It's going to show up as the common odds ratio when we get to the the code in the output.

181
00:19:38,510 --> 00:19:46,729
And similarly looking for the 95% confidence that over the log odds ratio here's you know in the privacy of your own room

182
00:19:46,730 --> 00:19:57,350
you can confirm that these calculations work out that that 95% confidence level for the log odds ratios 0.161 and .9.797.

183
00:19:58,380 --> 00:20:03,720
So that the 95% confidence level for the current odds ratio is 1.17 and 2.22.

184
00:20:03,990 --> 00:20:08,760
So these are all the numbers that we can find in the output. And I'll show you where to find those.

185
00:20:11,960 --> 00:20:18,920
So one of the things that I like to emphasize in this course is how to write manuscript worthy sentences.

186
00:20:19,340 --> 00:20:25,070
And so this is kind of a perk up moment because this is my first time giving you a manuscript worthy sentence.

187
00:20:25,580 --> 00:20:31,940
And so I want you to see I have a very systematic way of what elements I like to see in these sentences.

188
00:20:32,510 --> 00:20:35,840
And so first, I'm going to read the sentence and then I'm going to point out the elements I'm looking for.

189
00:20:35,870 --> 00:20:42,620
So that is women who have never had a term pregnancy have an odds of developing ovarian cancer.

190
00:20:42,620 --> 00:20:48,950
That is 1.61 times greater than the odds of women who have had greater than one, greater than or equal to one term pregnancy.

191
00:20:49,400 --> 00:20:53,150
95% confidence interval. 1.17.

192
00:20:53,150 --> 00:20:58,389
Comma 2.2 times greater. Eventually I'm going to have a p value for this too.

193
00:20:58,390 --> 00:21:01,930
I just haven't shown you how to get it yet. That's actually an element I look for in these sentences.

194
00:21:01,930 --> 00:21:06,069
It's a p value, but we'll repeat this again once we have that extra element.

195
00:21:06,070 --> 00:21:13,480
So what are the things I'm looking for? So first off, the obvious one is the odds ratio.

196
00:21:14,970 --> 00:21:19,260
Second element confidence interval. Third element would be p value if we had that.

197
00:21:19,920 --> 00:21:28,830
But the fourth element that is critical is to make clear what the direction of the effect is, what that odds ratio means.

198
00:21:29,550 --> 00:21:36,660
So it's very clear you don't just state the odds ratio, but you say, which is the group with the higher odds.

199
00:21:37,080 --> 00:21:46,890
Right. So women who have never had a term pregnancy have an odds ratio of developing ovarian cancer that is 1.61 times greater than the odds.

200
00:21:47,130 --> 00:21:50,760
So this times greater is making clear the direction of the effect.

201
00:21:51,450 --> 00:21:53,150
So it's not enough to say odds ratio,

202
00:21:53,160 --> 00:21:59,850
confidence interval p value without making clear the direction of the fact which group was the one with the higher odds of getting cancer?

203
00:22:00,180 --> 00:22:04,280
That's the that's the most critical element of the sentence in your manuscript.

204
00:22:04,290 --> 00:22:07,320
Otherwise, the 1.61 number is meaningless.

205
00:22:12,030 --> 00:22:18,090
And so because the confidence level doesn't cover one that's association significant with P less than .05.

206
00:22:18,100 --> 00:22:29,090
But I have to show you how to get the actual p value. It's probably also worth noting you might want to circle the word ODS here.

207
00:22:29,100 --> 00:22:38,220
Right. Because one thing that I see that comes up on exams when you're trying to pick what's the most appropriate manuscript worthy these sentences,

208
00:22:38,640 --> 00:22:43,650
not having the right, you know, parameter that you're discussing.

209
00:22:43,650 --> 00:22:51,240
So this is about odds ratios. So the odds is here, you know, if there are other sentences that have other elements in there,

210
00:22:52,140 --> 00:22:59,050
you know, they may not be correct because this is about an odds ratio. All right.

211
00:22:59,260 --> 00:23:02,390
So that was the Wolfe method or the inverse variance method.

212
00:23:02,410 --> 00:23:08,350
Here's the mental Hansel method that you've seen before. So you've seen this formula before in your other classes.

213
00:23:09,160 --> 00:23:14,500
And so this is a slightly more stable estimate for the common odds ratio that works really well,

214
00:23:14,500 --> 00:23:20,300
even if you have many, many tables with like one or two people each and them, it's just amazingly robust.

215
00:23:20,860 --> 00:23:31,600
And one of the reasons it works so well is that the the cross products that you usually use for odds ratios like eight times D or B times C,

216
00:23:31,990 --> 00:23:36,100
you're doing them for each of the separate tables and summing them.

217
00:23:36,100 --> 00:23:43,390
So in a times a D has a zero in it for one table, when you add it across all the different tables,

218
00:23:43,690 --> 00:23:47,139
you'll have something that's non-zero and the same thing for the bottom.

219
00:23:47,140 --> 00:23:52,000
I mean, if you have A, B or C, sell that zero for the wolf method,

220
00:23:52,330 --> 00:23:57,790
it'll end up making all the formulas explode because there's zeros and the denominators explode.

221
00:23:57,790 --> 00:24:00,129
It's a little bit dramatic, but we like to say that in my field.

222
00:24:00,130 --> 00:24:08,050
So but here, you know, as long as some of the tables have non-zero entries, the denominator won't be zero.

223
00:24:08,050 --> 00:24:17,379
And you'll it's much more stable because of that. And so just emphasizing that this mental Hansell version remains valid,

224
00:24:17,380 --> 00:24:23,590
even when the number of strata I or the studies you're comparing is large and the table counts are very small.

225
00:24:24,010 --> 00:24:27,520
And it's worth reviewing, even though you've seen it before, because in this course,

226
00:24:27,520 --> 00:24:34,000
there are many situations where the mental Hansel kind of rears its head as the backbone of a statistic that we're learning.

227
00:24:34,390 --> 00:24:39,340
So when we learn survival analysis, there is a test that people use called the log rate test.

228
00:24:39,340 --> 00:24:43,000
That is actually a special case of a mental Hansel statistic.

229
00:24:43,450 --> 00:24:47,859
So it's just good to have this fresh on your mind so that you can appreciate when we see it coming up

230
00:24:47,860 --> 00:24:54,070
again and again in the course that you'll you'll remember the backbone starts with mental handles idea.

231
00:24:57,190 --> 00:25:08,190
All right. And so the Wolf method has to have sample size for each of the two buy tables being combined that are, you know, appropriate.

232
00:25:08,200 --> 00:25:16,120
So in Intrastat classes, I think that they say things like expected cell counts for each of the four cells for a study have to be greater than,

233
00:25:16,360 --> 00:25:20,740
you know, five or the asymptotic stunt work.

234
00:25:21,040 --> 00:25:23,439
That's kind of the requirement for the wolf statistic, too.

235
00:25:23,440 --> 00:25:28,750
Each of the studies has to have expected cell counts for each of the two by two table entries.

236
00:25:29,050 --> 00:25:32,890
That's greater than or equal to five for it to work well in the averaging process.

237
00:25:33,160 --> 00:25:38,260
And we certainly had that with them with the term pregnancy, ovarian cancer example.

238
00:25:41,010 --> 00:25:45,480
So I showed you how to do the confidence intervals for the inverse variance method.

239
00:25:45,840 --> 00:25:50,670
There are confidence intervals that the software will do for you for the mental handle style method.

240
00:25:50,910 --> 00:25:58,560
They're not simple to do by hand, and so it would be kind of wasted class time, even flipping through the few pages of slides for that.

241
00:25:59,010 --> 00:26:01,800
But there's a good reference if you do learn best that way.

242
00:26:02,160 --> 00:26:12,420
I have this poster on canvas and it does include the formulas for confidence, zeros for mental health statistics if you really want to try that out.

243
00:26:12,420 --> 00:26:17,550
But I made an executive decision that it wasn't worth our time to go through those hand calculations.

244
00:26:20,130 --> 00:26:27,330
And so for our term pregnancy example, the mantle here for odds ratio also ends up being 1.61.

245
00:26:28,630 --> 00:26:32,470
So it agrees perfectly with the inverse variance method in this case.

246
00:26:32,470 --> 00:26:35,620
And that tends to happen for for studies that are large enough,

247
00:26:35,620 --> 00:26:41,320
they tend to have very similar results as long as each of the individual studies that you're combining are large enough.

248
00:26:43,190 --> 00:26:47,120
And so now that we have estimates, we can do the test of homogeneity.

249
00:26:47,540 --> 00:26:55,040
So step three. So this is the test to remember. This isn't getting to the science of whether the exposure is associated with the outcome or not.

250
00:26:55,050 --> 00:26:58,430
Yeah, we're just trying to ask statistically.

251
00:26:59,120 --> 00:27:05,089
Is there any evidence that we shouldn't be doing this combining of odds ratios,

252
00:27:05,090 --> 00:27:10,460
that there's statistically different odds ratios in these various studies that we're combining?

253
00:27:10,910 --> 00:27:17,420
So the null hypothesis is just are the odds ratios from the various studies similar?

254
00:27:18,360 --> 00:27:24,120
So that we can combine them logically. And so it doesn't say whether they're similar and equal to one or not.

255
00:27:24,120 --> 00:27:25,440
It just says, are they similar?

256
00:27:28,070 --> 00:27:34,760
So if this test rejects the null hypothesis, then the main analysis is trying to combine interventions and outcomes that are too different,

257
00:27:34,970 --> 00:27:41,390
and you should report the separate study results or further dig into why you got different results for the different studies.

258
00:27:41,390 --> 00:27:51,570
And maybe you know. Try again with protocols that are more similar or something that there's something off that you shouldn't combine them.

259
00:27:55,080 --> 00:28:01,590
And so since trials that contribute to meta analysis are based on different protocols, the question arises as to whether the trial should be combined.

260
00:28:03,030 --> 00:28:09,930
A test of homogeneity has the null hypothesis that the odds ratios are the same, but not what they actually are.

261
00:28:10,290 --> 00:28:19,649
And the statistic looks like this. So it's looking at the log odds ratio for study I minus the overall estimate for the log odds ratio.

262
00:28:19,650 --> 00:28:25,980
That was this Tao hat thing. This is the overall overall estimate for the log odds ratio.

263
00:28:27,750 --> 00:28:31,290
And then here's that same weight that we used in the Wolfe method.

264
00:28:31,290 --> 00:28:36,440
So this W is it's again, it's the inverse variance of the log odds ratio for study.

265
00:28:36,540 --> 00:28:42,150
That's what that is. And so under that null hypothesis stated above here,

266
00:28:42,420 --> 00:28:48,959
this should have a chi square distribution with degrees of freedom being the number of studies you're combining minus one.

267
00:28:48,960 --> 00:28:56,410
So that capitalized the number of studies you're combining. And if that statistic is very, very large,

268
00:28:56,830 --> 00:29:06,490
then the individual log odds ratios are too different from the overall summary to really logically combine them.

269
00:29:07,550 --> 00:29:12,260
So then you really need to look into which trials are different and identify reasons for the differences.

270
00:29:12,260 --> 00:29:16,100
And here's a nice reference for that. Discusses that idea.

271
00:29:18,640 --> 00:29:25,690
So again, just emphasizing this test does not address the issue of whether a common odds ratio is significantly associated with a response.

272
00:29:25,690 --> 00:29:32,440
And it's just at answering in part the question of whether you should be even attempting a meta analysis.

273
00:29:34,360 --> 00:29:36,700
And so in the in the privacy of your own room,

274
00:29:36,700 --> 00:29:46,689
you can confirm that the head calculations for the test of homogeneity end up with statistic that 0.016 and this is the P value,

275
00:29:46,690 --> 00:29:54,309
this is actually the chi squared statistic and it has one degree of freedom because we were combining two studies and that's capital.

276
00:29:54,310 --> 00:29:57,580
I was two here minus one. So one degree of freedom.

277
00:29:57,850 --> 00:30:01,870
And so the P value is quite large. So.

278
00:30:02,810 --> 00:30:07,130
What does that mean when the value is quite large? That means.

279
00:30:08,220 --> 00:30:20,010
We fail to reject this hypothesis, right. So there's no statistical evidence that the odds ratios for those two studies were vastly different.

280
00:30:20,310 --> 00:30:23,520
So this is kind of a check that we can continue.

281
00:30:25,160 --> 00:30:35,860
If the P-value had been less than 0.05, then we have to kind of stop and say, uh, why were these two studies different from one another?

282
00:30:36,050 --> 00:30:40,130
Because that would be rejecting the null hypothesis that they were the same odds ratio.

283
00:30:42,410 --> 00:30:47,750
So in this case, there's little evidence P equals 0.9 against homogeneity.

284
00:30:47,840 --> 00:30:52,190
So we fail to reject that null hypothesis that there's the same odds ratio and

285
00:30:52,190 --> 00:30:56,210
and statistically that we don't have any evidence saying we shouldn't combine.

286
00:30:56,510 --> 00:31:05,240
So I have a couple of addendums here. And the first one is that this is kind of a treatment by trial interaction test.

287
00:31:05,660 --> 00:31:12,139
You know, whether the odds ratios in the trials are different as a treatment by sorry,

288
00:31:12,140 --> 00:31:19,670
a treatment by trial interaction test and like other interaction tests, it lacks power in many practical situations.

289
00:31:20,210 --> 00:31:31,280
So when you do this test and you get a non-significant result like we did here, we can't take it as evidence in favor of treatment effect homogeneity.

290
00:31:31,580 --> 00:31:36,560
We can just say we failed to reject the null hypothesis. We don't say we accept the null hypothesis.

291
00:31:37,070 --> 00:31:39,290
And because it's so low powered,

292
00:31:40,010 --> 00:31:46,550
it could be that the two studies really still are quite different and you just don't have a lot of power to detect it.

293
00:31:47,000 --> 00:31:52,159
So that kind of limits the usefulness of the test. So we always look at this test,

294
00:31:52,160 --> 00:32:03,440
but my own judgment is when I'm looking at these stories is to see what are the odds ratios clinically meaningful from one another study to study.

295
00:32:03,950 --> 00:32:09,380
And if they're if they look vastly different. So if you're looking at combining odds ratios of ten versus two.

296
00:32:10,390 --> 00:32:13,660
That's that's a lot different. Right.

297
00:32:14,140 --> 00:32:19,629
And so you have to kind of ask, even if this test of homogeneity fails to reject that whole hypothesis,

298
00:32:19,630 --> 00:32:24,820
you kind of have to ask yourself, why was one study having an odds ratio of ten and the other two?

299
00:32:25,270 --> 00:32:30,550
Was there something meaningful that could have caused that that I need to look into further?

300
00:32:31,000 --> 00:32:34,090
Are these not the same story after all? Right.

301
00:32:34,090 --> 00:32:36,660
So maybe there could have been a if it was a treatment trial,

302
00:32:36,670 --> 00:32:43,360
maybe there were different doses or maybe they were looking at outcomes over different follow up periods.

303
00:32:43,360 --> 00:32:47,200
And so in odds ratio of ten showed up if you watched them for two years.

304
00:32:47,890 --> 00:32:53,950
And two is that after just one year. So there might have been something vastly different between the studies you really need to take into.

305
00:32:56,890 --> 00:33:02,560
And addendum to is that I showed you the inverse variance version of this test.

306
00:33:02,570 --> 00:33:07,629
There's a slightly different Breslow homogeneity test that's often reported in software.

307
00:33:07,630 --> 00:33:16,330
SAS reports it with the CMH option and it's it's got the same footnote of you can

308
00:33:16,330 --> 00:33:21,790
do it by hand and that same Woodward reference will show you how to do that.

309
00:33:21,790 --> 00:33:25,120
But it's pages of calculations compared to this inverse variance method.

310
00:33:25,450 --> 00:33:30,430
I don't think it's a good learning experience to do all those calculations.

311
00:33:31,510 --> 00:33:36,400
So I'm not I'm not showing you those by hand, but we'll see that in the output.

312
00:33:38,470 --> 00:33:44,620
All right. So the last next to last step is to do the test for the overall treatment effect.

313
00:33:44,630 --> 00:33:53,380
So now that we have this idea that we can combine and have a common odds ratio, is it actually an interesting odds ratio?

314
00:33:54,190 --> 00:33:58,059
Is it is there an odds ratio that is different from one?

315
00:33:58,060 --> 00:34:02,380
So the null hypothesis is that there's nothing interesting going on that the common odds ratio is one,

316
00:34:02,620 --> 00:34:10,210
and we're hoping to reject that in favor of story where there's an association between the exposure and the outcome.

317
00:34:12,140 --> 00:34:17,570
And so here are some of the formulas that you'll see. Again, we'll be looking at the output to kind of match up some of this stuff.

318
00:34:19,010 --> 00:34:29,839
But the overall mental Hansell statistic using notation from Slide 38 for some of these things is it looks like this.

319
00:34:29,840 --> 00:34:35,900
And so what is this? This is summing over all of the studies, all of the cells.

320
00:34:36,080 --> 00:34:45,139
So those are that are the first row, first column counts and then you're subtracting off these my terms.

321
00:34:45,140 --> 00:34:53,480
Those are like the expected counts that you would expect to see if there was no association between the rows and the columns in these studies.

322
00:34:54,350 --> 00:35:02,480
So the observed counts for all the cells minus the expected counts for all the cells are being compared here.

323
00:35:03,550 --> 00:35:07,210
And there is some accounting for variability here in the denominator.

324
00:35:07,570 --> 00:35:11,500
So under the null hypothesis, this has a chi squared with one degree of freedom,

325
00:35:11,740 --> 00:35:15,200
so that to one degree of freedom, regardless of how many studies you're combining here.

326
00:35:15,220 --> 00:35:16,090
So that's kind of nice.

327
00:35:16,990 --> 00:35:26,680
And so that's how you're going to get your P values by comparing your observed chi square meal Hansel statistic to the Chi Square one distribution.

328
00:35:28,630 --> 00:35:30,280
And in the privacy of your own room.

329
00:35:30,280 --> 00:35:37,540
If you want to do these calculations, here's just an example of how they work with the observed and the expected cell count.

330
00:35:37,540 --> 00:35:45,730
For the first study that we had with ovarian cancer and the observed and expected cell counts for the second study that we had for ovarian cancer

331
00:35:46,000 --> 00:35:56,500
and the variability estimates that are required for the test statistic so that actual maintains the test statistic ends up with a value of 8.86.

332
00:35:56,500 --> 00:36:04,330
So we'll see that value in our output. And the p value that goes along with that is 0.003.

333
00:36:05,050 --> 00:36:08,440
And so. So how do you interpret this P value?

334
00:36:08,440 --> 00:36:16,330
This is basically saying that if there was no association between the term pregnancies and ovarian cancer,

335
00:36:16,690 --> 00:36:24,610
then the chances the data would have laid out this way just randomly is 4.3%.

336
00:36:25,900 --> 00:36:27,280
P-value 0.03.

337
00:36:27,670 --> 00:36:34,600
So it's very unlikely that we would have seen the data lay out this way if there was no association between the exposure and the outcome.

338
00:36:35,870 --> 00:36:39,230
So that kind of gives statistical evidence. There's something going on.

339
00:36:41,260 --> 00:36:45,470
And so here's the manuscript worthy sentence. Now that includes the P value.

340
00:36:45,490 --> 00:36:52,569
So after adjusting for study, women who have never had a term pregnancy have a significantly higher odds of developing

341
00:36:52,570 --> 00:36:59,440
epithelial ovarian cancer than women who have had one or more term pregnancies 1.61 times higher,

342
00:36:59,860 --> 00:37:06,159
95% confidence interval P-value. And so that summarizes everything from that analysis.

343
00:37:06,160 --> 00:37:10,870
Nice and tight, it has the direction because it says a higher odds.

344
00:37:11,860 --> 00:37:18,520
Right. Comparing the the group with those who've never had a term pregnancy versus those who have had one or more.

345
00:37:19,530 --> 00:37:27,249
No higher than gives the direction. All right.

346
00:37:27,250 --> 00:37:30,459
So finally we get to the the code.

347
00:37:30,460 --> 00:37:37,690
And as I mentioned in the first class, I'm going to be showing you both South and ah.

348
00:37:38,260 --> 00:37:44,739
And so here is the SAS just putting the data in step.

349
00:37:44,740 --> 00:37:52,480
So input study. No term as the yes or no did they have any?

350
00:37:54,120 --> 00:38:00,270
Term pregnant fetus. Or yes, if they had no term pregnancies.

351
00:38:00,280 --> 00:38:04,269
I guess that's kind of confusing. We've got double net negatives there. And then cancer.

352
00:38:04,270 --> 00:38:06,880
Yes. No, and then the count.

353
00:38:07,480 --> 00:38:15,190
So if you haven't seen that at at before, this is something that you instructors use a lot just so they can fit code on a PowerPoint slide.

354
00:38:15,190 --> 00:38:23,770
But it just is basically saying, I'm going to have these one, two, three, four data entry points and I'm going to allow more than one per line.

355
00:38:24,220 --> 00:38:30,700
So this first four elements here is like the first row of an Excel table, if you like.

356
00:38:31,480 --> 00:38:36,780
And so this is study one. This is the ACL.

357
00:38:36,780 --> 00:38:40,200
So, yes, they didn't have any term pregnancies and yes, they had cancer.

358
00:38:41,300 --> 00:38:44,780
31. So that's the first row of data.

359
00:38:45,050 --> 00:38:48,350
And then the ad says, I can put another row of data right there.

360
00:38:49,390 --> 00:38:52,390
So this is actually the second row you might have in your Excel file.

361
00:38:52,540 --> 00:38:56,359
Still study one. And we're.

362
00:38:56,360 --> 00:39:03,580
Yes, they're in the know. They didn't have any term pregnancies, but no, they didn't have cancer in the count.

363
00:39:03,590 --> 00:39:09,320
And so we're just you can sort of see how the data matches up with the two by two tables we had earlier.

364
00:39:13,310 --> 00:39:22,580
And then proc freak has ah, you know, just reads in the data you have this order equal data command table looks at the table,

365
00:39:22,580 --> 00:39:28,610
command has study this variable no term and the variable cancer and then the option CMH

366
00:39:28,610 --> 00:39:33,800
is giving you all the Cochrane mental Hansel kind of information odds ratios and so on.

367
00:39:35,450 --> 00:39:38,690
And then wait. The wait statement has to count for the cell counts.

368
00:39:40,620 --> 00:39:47,370
So the output looks like this. Here's the data again, just to make sure you double check that you have your data entered correctly.

369
00:39:47,610 --> 00:39:53,700
And so what are you looking for here? So some of these numbers are going to look really familiar to the ones that came from the hand calculations.

370
00:39:54,700 --> 00:39:57,850
So the chi squared mental hansell test.

371
00:39:58,870 --> 00:40:04,480
Two. That was the test that was seeing. Is there an association that's significantly different?

372
00:40:05,520 --> 00:40:13,469
In terms of the odds ratio being different from one. And that test statistic was 8.8270 with a P value of 0.03.

373
00:40:13,470 --> 00:40:25,090
That's the one we just looked at. And so yes, if you combine the odds ratios, they are significantly different from one at this with this p value.

374
00:40:26,570 --> 00:40:40,610
And then down here. Buxton read this very bottom row is the Wolff method, the inverse variance method giving you the odds ratio,

375
00:40:40,610 --> 00:40:47,390
and in the 95% confidence intervals that will match the hand calculations from the previous slide with the wolf method.

376
00:40:47,990 --> 00:40:51,440
And the row above is the mantel hansell.

377
00:40:52,560 --> 00:41:00,710
Method. And there's almost no difference between these two for the study because both of the studies were very large.

378
00:41:00,720 --> 00:41:08,070
So that's a case where whether you're using the inverse variance method or the manual Hansell method, you'll get very similar answers.

379
00:41:08,820 --> 00:41:14,850
So if you have lots of zeros and small studies, you'll get different results.

380
00:41:14,850 --> 00:41:26,990
But they agree pretty well here. So either one will look the same. This is a common way you'll see made analysis results displayed.

381
00:41:27,000 --> 00:41:34,370
It's called a forest plot. And I use this plot not just for main analysis, but for a lot of like subgroup analysis.

382
00:41:35,060 --> 00:41:44,030
And so what you see here is the results from each study reported separately and then the overall meta analysis results combined here.

383
00:41:44,390 --> 00:41:48,620
So here is it's actually on the log scale.

384
00:41:49,870 --> 00:41:58,150
But they've exponentially detected the kind of grid marked numbers so that it looks like the odds ratio scale.

385
00:41:58,870 --> 00:42:09,040
So this is the the odds ratio and the 95% confidence interval for study one, the odds ratio, the 95% confidence interval for study two.

386
00:42:09,280 --> 00:42:21,159
And then here's the overall result. And then here is the homogeneity test.

387
00:42:21,160 --> 00:42:25,149
The label, says Breslow. They test for the homogeneity of the odds ratio.

388
00:42:25,150 --> 00:42:32,500
So this is the test that you do to see is there statistical evidence that the odds ratios in the studies are different from one another?

389
00:42:33,620 --> 00:42:39,260
So the hype, the hand calculations from earlier gave us this same number.

390
00:42:40,210 --> 00:42:45,940
Well, actually, I think we did the we did the inverse variance version of the homogeneity test,

391
00:42:45,940 --> 00:42:51,460
but they're pretty much the same for the for these two studies. For these two studies that were combining.

392
00:42:51,910 --> 00:42:56,350
And the and the here's the p value for the test for homogeneity.

393
00:42:58,060 --> 00:43:01,390
So this is very close to the version of The Hobbit George has that we did by hand.

394
00:43:01,840 --> 00:43:07,030
Again says This person uses much more complex formulas in the background,

395
00:43:07,300 --> 00:43:11,800
which is cumbersome to do by hand and probably not worth our time to look at in detail.

396
00:43:16,340 --> 00:43:22,810
So here is how. You go about analyzing the data with ah.

397
00:43:23,620 --> 00:43:29,320
And how many of you just to give me a sense how many of you in here use are regularly.

398
00:43:30,960 --> 00:43:37,160
Okay. So if you use our regularly, I really like these functions in R.

399
00:43:37,170 --> 00:43:43,740
I actually often feel more comfortable in R myself, but some of the graphics are really, really nice.

400
00:43:43,800 --> 00:43:48,780
So the package that we're going to load is the media package.

401
00:43:49,050 --> 00:43:51,270
And so we install the package and do the library.

402
00:43:51,270 --> 00:43:58,560
You can do this through our studio if you work in our studio, but otherwise, if you just have an AR prompt, you can just type this stuff.

403
00:43:58,980 --> 00:44:04,260
It's not necessarily important to do this live logo statement.

404
00:44:04,260 --> 00:44:08,160
It'll put it wherever wants to put it. So you could just do library made and you'd be fine.

405
00:44:09,240 --> 00:44:12,240
And so the data is it is being put in here.

406
00:44:12,240 --> 00:44:17,820
So I've created study labels in this variable called stub lab.

407
00:44:18,240 --> 00:44:23,760
And so for those of you who haven't used R before, whenever you see a little C, it's basically just saying,

408
00:44:23,760 --> 00:44:27,960
I have a list of things I'm about to tell you that I want you to put in this variable.

409
00:44:29,010 --> 00:44:38,669
So if you want, you can call it a vector of two things where the first is a character text, a character string saying study one.

410
00:44:38,670 --> 00:44:42,390
And the second element of this vector is a character string for study two.

411
00:44:42,690 --> 00:44:48,690
But really it's just a lit. Whenever you see C, just think of a list of some things that's about to store for you.

412
00:44:50,280 --> 00:44:58,069
And so event dot e. I think I've got some nice, helpful descriptions here.

413
00:44:58,070 --> 00:45:03,340
So Event Diary lists the number of events in the experimental group for Study one and Study two.

414
00:45:03,350 --> 00:45:06,380
So these are all the cells of the tables.

415
00:45:06,830 --> 00:45:12,230
So the ACL for study one was 31, the self study two was 39.

416
00:45:12,770 --> 00:45:17,419
An entry lists the number in the experimental group for each study.

417
00:45:17,420 --> 00:45:20,060
So these are anyone I cells of the table.

418
00:45:20,070 --> 00:45:32,660
So this is so study one 124 study two 113 that's how they want you to put in the data for for those two variables for the experimental group.

419
00:45:34,300 --> 00:45:41,290
And then for the control group, I've just put a dot C down here to stand for control two to differentiate these

420
00:45:41,290 --> 00:45:46,960
two event C lists the events in the control groups of the CI cells of the tables,

421
00:45:47,260 --> 00:45:51,790
and that C lists the number in each control group or the end to isolate at the tables.

422
00:45:52,150 --> 00:45:57,219
And so you'll sort of see how these look compared to the two by two tables we had earlier.

423
00:45:57,220 --> 00:46:02,890
So you can make sure you're putting the right numbers in the right place. And then once you have all the data in like this,

424
00:46:03,280 --> 00:46:12,640
you just call this function called meta by with the events with the event that e end event dot C and see here my study labels

425
00:46:12,940 --> 00:46:21,490
and then the options that are useful for this example are the manual Hansel method and the summary measure is odds ratio.

426
00:46:24,520 --> 00:46:27,560
All right. And so the output looks like this.

427
00:46:28,970 --> 00:46:35,540
I really like this feature of the output. There's several different R packages that can help you with this type of analysis.

428
00:46:35,840 --> 00:46:44,660
What I like about this particular package is that it will give you the study specific odds ratios and confidence intervals for you.

429
00:46:45,080 --> 00:46:51,970
You know, not every package will do that. And so those are the study specific odds ratios.

430
00:46:51,980 --> 00:47:00,440
And 95% confidence intervals look really nice. Here's in a red box the mantle here for odds ratio and 95% confidence interval and p value.

431
00:47:00,800 --> 00:47:06,830
So all in a row here, all the things that I would want to put in my manuscript were these sentence all conveniently together.

432
00:47:08,540 --> 00:47:12,970
And then they also have our test of homogeneity.

433
00:47:12,980 --> 00:47:16,070
Our R is labeling it the test of heterogeneity.

434
00:47:16,070 --> 00:47:20,000
So it's a cup half full cup, half empty situation of what they're calling the test.

435
00:47:20,420 --> 00:47:25,250
But this is the same test of homogeneity we were talking about earlier with the p value of point nine.

436
00:47:31,570 --> 00:47:44,900
All right. So. I want to show you a couple of different packages for this, mainly because this next package does really nice plots.

437
00:47:45,470 --> 00:47:52,460
So the same example using the our metaphor package to remember why I like this package.

438
00:47:52,470 --> 00:47:58,880
Just think of this if that appears in metaphor and F-4 funnel plot.

439
00:47:59,240 --> 00:48:06,990
So I want to produce funnel plots. Metaphor with the F has a funnel plot as I like it, if that helps at all.

440
00:48:07,410 --> 00:48:12,030
And so installing and loading the package metaphor here, again,

441
00:48:12,030 --> 00:48:21,089
putting study label study one study to at this package once all of the IBC idea cells of your tables entered this way.

442
00:48:21,090 --> 00:48:27,960
So all the air cells for study, one study to all the B cells for study, one study to, that's how they want the data put in.

443
00:48:30,250 --> 00:48:34,200
All right. And then once you have. So if you have lots and lots of tables,

444
00:48:34,200 --> 00:48:40,500
you just kind of put all the cells in one big list with the see all the bar cells in one big list with the C and so on.

445
00:48:40,860 --> 00:48:44,580
And then the remade. MH mh. Think mental Hansel.

446
00:48:46,060 --> 00:48:56,530
Has you put all that the ABC and I cells in correct equals false is necessary to match up with our hand calculations.

447
00:48:56,530 --> 00:49:02,470
If you don't put correct equals false, it'll use the continuity correction that I don't have in the hand calculations.

448
00:49:04,800 --> 00:49:11,820
And it will already by default give you the odds ratio summary using the manual hands on method as the default.

449
00:49:12,630 --> 00:49:22,040
And so here is the output for this function. And so what you don't see is the individual odds ratios for study one, study two.

450
00:49:22,050 --> 00:49:24,660
So that's the first package did that very nicely.

451
00:49:24,660 --> 00:49:32,520
This one not so much but it does give you is the overall odds ratio estimate confidence interval over here.

452
00:49:34,960 --> 00:49:42,580
I guess in order here, this is the homogeneity test. Again, using this package with that p value of 4.9 that we've learned to look for.

453
00:49:44,030 --> 00:49:50,209
And here's the mantle handle odds ratio and confidence limit over here and the Cochrane mental

454
00:49:50,210 --> 00:49:56,660
Hansel test with the P-value of 0.003 that we've learned to look for from our hand calculations.

455
00:49:56,930 --> 00:50:02,570
For some reason it has the test for homogeneity down here. Once again, I'm not sure why it shows that twice, but it does.

456
00:50:05,960 --> 00:50:10,240
So forth. I should have said fourth plot and funnel plot.

457
00:50:10,250 --> 00:50:14,330
So fourth plots can be done with this metaphor package.

458
00:50:14,960 --> 00:50:20,030
So I have to say, this is the same thing we had earlier, even down to this command army.

459
00:50:20,240 --> 00:50:29,120
MH That's all just copied from the previous slide and put inside this other command for army.

460
00:50:29,690 --> 00:50:39,920
So the same command that we used to get all of our summary statistics, just copy and paste it inside this US Army and your.

461
00:50:41,550 --> 00:50:45,630
Get the following output here. So here's study one.

462
00:50:45,690 --> 00:50:56,530
Study two. And here is the overall made analysis result and their reporting all in the log odds scale.

463
00:50:57,160 --> 00:51:01,840
So these plots look very similar to what we saw earlier.

464
00:51:04,360 --> 00:51:06,040
But it's all on the log as well as your scale.

465
00:51:06,040 --> 00:51:15,459
So what people tend to do is create text boxes and exponentially rate all the numbers here so that the odds

466
00:51:15,460 --> 00:51:21,970
ratio for study one is e to this number and the 95% confidence interval for 30 one's E to this number,

467
00:51:21,970 --> 00:51:25,660
comma, each of this number. So people will just put a text box over this plot and.

468
00:51:26,750 --> 00:51:31,130
You know, and change. These are all numbers to the odds ratio scale, but keep the picture.

469
00:51:31,400 --> 00:51:39,650
Same here. This is all in the log odds ratio scale, so people tend to put a textbox here and change the grid marks to each of the minus .02.

470
00:51:40,100 --> 00:51:46,940
This will end up being each of the zero or one and so on. That's basically what the plot earlier was doing.

471
00:51:49,730 --> 00:51:54,800
So we'll come back to it for this particular example with two studies.

472
00:51:55,130 --> 00:52:01,280
A funnel plot isn't really helpful, but we'll show how to do a funnel plot when we have a lot more studies done.

473
00:52:01,760 --> 00:52:13,749
So that's kind of the review for two by two tables, but the same inverse variance idea of a meta analysis can be extended to other data structures.

474
00:52:13,750 --> 00:52:21,220
So this is where review has ended, but the stretch to the new begins.

475
00:52:21,230 --> 00:52:26,389
So that will approach to combining study specific odds ratios based on inverse variance where

476
00:52:26,390 --> 00:52:31,430
it can be used to combine any estimates that follow an approximately normal distribution.

477
00:52:32,270 --> 00:52:34,640
So here there's a reference if you want to look at that.

478
00:52:34,970 --> 00:52:42,320
So for instance, if I wanted if I had found a whole bunch of results where people were comparing differences in means for different studies,

479
00:52:42,620 --> 00:52:46,940
I could use the same approach to come up with an overall difference in means across studies.

480
00:52:47,450 --> 00:52:52,790
If I have a whole bunch of studies that look at sample proportion differences.

481
00:52:53,890 --> 00:53:02,469
I can come up with a summary statistic combining the, the, the overall difference in the sample proportions across studies and so on.

482
00:53:02,470 --> 00:53:10,959
So even regression coefficients, you know, either logistic regression or survival analysis regression, all of the different regression methods.

483
00:53:10,960 --> 00:53:16,750
If you have regression coefficients for a bunch of different studies you want to combine, you can use the same technique to do that.

484
00:53:19,190 --> 00:53:25,909
So there in SAS there's a macro called Main Verse that I have on canvas.

485
00:53:25,910 --> 00:53:29,000
I'm going to show you how to use that to get the results with, you know.

486
00:53:31,100 --> 00:53:37,339
You know, a quick example, and I'll also show you our code on how to do this as well.

487
00:53:37,340 --> 00:53:41,210
So because you probably are dying to have a break.

488
00:53:43,000 --> 00:53:46,700
Let's let's let's meet up again in 10 minutes.

489
00:53:47,540 --> 00:53:54,230
So. 904 and we'll we'll get into more code.

490
00:54:23,800 --> 00:55:21,800
Just. Yeah, I do.

491
00:55:32,050 --> 00:55:46,620
Think. You.

492
00:56:02,150 --> 00:56:45,530
Yeah. But I am.

493
00:58:33,380 --> 00:58:53,260
I. I.

494
00:58:58,680 --> 00:59:08,110
I remember. Really?

495
00:59:12,550 --> 00:59:19,610
Yeah. They're not.

496
00:59:33,210 --> 00:59:40,550
Yeah. Never.

497
01:00:34,500 --> 01:01:57,060
Yeah, I. Let's do the first.

498
01:02:07,830 --> 01:02:13,570
So that the second step was also adjusted this week.

499
01:02:13,770 --> 01:02:17,780
We've only done the adjusted one. Yeah, right.

500
01:02:19,950 --> 01:02:34,220
The the fourth step was doing a hypothesis, a test to get a p value to see if it was statistically significant from, you know, different times.

501
01:02:46,980 --> 01:02:53,940
So the random effect estimate is very similar to the fixed effect, really.

502
01:02:56,050 --> 01:03:01,680
It's it's still there's still a question of is it appropriate to combine them?

503
01:03:03,180 --> 01:03:12,390
So the method doesn't care that you have to ask yourself if you have one study where the odds ratios over here and in other words, way over here.

504
01:03:13,170 --> 01:03:16,620
Are they telling the same story? Is this just random noise?

505
01:03:18,040 --> 01:03:23,580
I mean, if they have confidence intervals that don't overlap, would you combine those?

506
01:03:24,570 --> 01:03:31,470
No. So the random effect doesn't fix that issue.

507
01:03:33,030 --> 01:03:37,499
If there's heterogeneity, you have to ask why it is there.

508
01:03:37,500 --> 01:03:41,340
The same story happening or two separate stories that deserve their own attention.

509
01:03:43,220 --> 01:03:57,600
Yeah. Yeah. Right?

510
01:03:59,610 --> 01:04:09,150
Right. And we're going to see soon that you can do a made analysis using logistic regression as well.

511
01:04:09,330 --> 01:04:18,870
And this will show up as a significant interaction term between the study and the treatment group, the exposure group.

512
01:04:19,590 --> 01:04:26,550
And if there is a significant interaction, you report them as two different things as well.

513
01:04:26,610 --> 01:04:30,300
Right. You wouldn't just remove the interaction term and pretend it wasn't there.

514
01:04:30,970 --> 01:04:35,100
You keep it in the model. Right. And it's the same thing.

515
01:04:36,300 --> 01:04:43,680
It's the same thing. So the random of the random of fact approach to analysis is just a different approach.

516
01:04:44,850 --> 01:04:51,420
Usually very similar results. I actually prefer the effects approach myself, but that's just me.

517
01:04:53,130 --> 01:04:57,600
They're both different approaches. But they won't fix. They won't fix that story issue.

518
01:04:57,990 --> 01:05:14,840
Is that the same story or not? It doesn't fix it. And that's what I'm.

519
01:05:17,360 --> 01:05:20,540
We think that you're allowed to have one in 20 outliers.

520
01:05:20,780 --> 01:05:24,830
That's like a 5% chance of being an outlier. I think you're allowed to do that.

521
01:05:25,880 --> 01:05:30,920
But the same thing is fair. Why is it an outlier?

522
01:05:30,950 --> 01:05:34,430
Is it just randomness which could happen more than 20 times?

523
01:05:35,450 --> 01:05:39,109
No, that's like a 5% of weirdness we're used to.

524
01:05:39,110 --> 01:05:44,000
Right. Or is there something about that study that's quite different?

525
01:05:44,030 --> 01:05:47,360
Is there data quality? Is there protocol for it different?

526
01:05:47,450 --> 01:05:53,600
What is it about that study? If there's not if it's just randomness, then you still use it.

527
01:05:54,080 --> 01:05:58,370
It shouldn't result in it shouldn't result in everything.

528
01:05:58,370 --> 01:06:03,410
So it will still fail to reject the homogeneity test.

529
01:06:04,250 --> 01:06:08,720
If it's one in 20. But you should still ask the question.

530
01:06:09,930 --> 01:06:13,220
Yeah. Then you might be missing, like the whole point.

531
01:06:13,730 --> 01:06:19,130
Like if that's the one study, why? And if it's not just randomness.

532
01:06:19,350 --> 01:06:23,810
If there's something about that study, like maybe they didn't give the treatment long enough for it to produce the effect,

533
01:06:24,380 --> 01:06:29,750
then they should know that they have to actually read the papers to figure out what was different about that study.

534
01:06:30,920 --> 01:06:35,670
And that's part of the story. And that's part of the story. Yeah.

535
01:06:44,230 --> 01:06:48,190
All right. Are you ready to get back to work?

536
01:06:49,800 --> 01:07:04,870
Okay, so just as a reminder, so I'm now showing you tools that can be used to combine any estimates for made analysis, not just like odds ratios,

537
01:07:04,870 --> 01:07:13,120
but any estimates, whether there are differences in means, differences in sample proportions, any estimates across studies.

538
01:07:13,420 --> 01:07:17,560
And so for the main verse macro, the SAS macro.

539
01:07:18,730 --> 01:07:23,740
We're going to have the following things that we need to enter into this package.

540
01:07:23,740 --> 01:07:26,950
So one is study label. That one's easy.

541
01:07:27,620 --> 01:07:30,870
S stands for effect size. So this is it.

542
01:07:30,880 --> 01:07:36,430
In the two by two table setting we just saw, this would be like the log odds ratio for each study.

543
01:07:36,970 --> 01:07:44,290
We we need to put in and see is the standard error for whatever your yes numbers were.

544
01:07:44,380 --> 01:07:51,610
So for our example, we would be putting in the standard error for the log odds ratio for each study, but there could be a list of anything.

545
01:07:51,610 --> 01:07:54,129
So if you have risk ratios across studies,

546
01:07:54,130 --> 01:08:01,990
you could as long as you have the estimate of the log risk ratio and it's standard error, you can use this package.

547
01:08:02,800 --> 01:08:05,080
All right. Sample size is optional.

548
01:08:05,110 --> 01:08:11,770
Honestly, it's frustrating to me why they even have it if it's optional, because I don't think it actually does anything in the software at all.

549
01:08:12,190 --> 01:08:17,710
But so, you know, it's there not you can put it in just for your your notes I suppose.

550
01:08:19,840 --> 01:08:24,650
So is the he can be any normally distributed quantity with his corresponding standard error.

551
01:08:24,670 --> 01:08:29,110
So if you have regression coefficients and they are standard errors, you can just put those.

552
01:08:29,320 --> 01:08:39,110
It could be anything. So it's more it's a more general usage than the SAS code using PROC Freak and the CMH option that we saw earlier.

553
01:08:40,890 --> 01:08:48,300
So I'm still using this example with ovarian cancer in term pregnancy exposure.

554
01:08:48,660 --> 01:08:55,550
And so when I calculate S for my estimates, I'm actually calculating the log odds ratio for all the studies.

555
01:08:55,560 --> 01:08:58,780
So this is the typical eight times. Do you ever beat time see?

556
01:08:59,790 --> 01:09:04,560
And putting it on the log scale. And here is the standard error.

557
01:09:04,770 --> 01:09:09,150
I'm taking the square root of the variance for for the study.

558
01:09:10,830 --> 01:09:15,809
And I'm putting sample size in there. Just can't help myself.

559
01:09:15,810 --> 01:09:23,600
If they say it's an option, I'm going to put it in there. Here is the dataset that we're going to use for Main Vas,

560
01:09:23,600 --> 01:09:32,330
where I have study EMC and same size and then printing the data just to show you what that is so we can have it with our output.

561
01:09:32,720 --> 01:09:34,850
And then here is the call to the macro.

562
01:09:36,230 --> 01:09:44,480
I have main verse dot text on canvas that you can download and I just included it from my desktop for this code.

563
01:09:44,480 --> 01:09:48,530
But you know, so just include it wherever it is on your laptop.

564
01:09:49,130 --> 01:09:55,850
And then here is the call with the percent sign main verse with the data set that has all that information in it.

565
01:09:56,030 --> 01:10:02,670
The study easy in sample size. So the output looks like this.

566
01:10:03,270 --> 01:10:08,790
And remember this. This doesn't know what your ease is supposed to mean.

567
01:10:08,800 --> 01:10:13,650
So only you know that this these is numbers are log odds ratios.

568
01:10:14,580 --> 01:10:21,630
Right? It just uses whatever you put here in this column, in the column to come up with the overall estimate.

569
01:10:22,020 --> 01:10:26,219
So when you see the results here, your log odds ratios,

570
01:10:26,220 --> 01:10:34,500
the standard errors that we calculated by hand in the SAS code and then we have the overall estimate of the log odds ratio here.

571
01:10:35,930 --> 01:10:40,990
Right. So main verse doesn't know. It needs to exponentially give it back to you on that scale.

572
01:10:41,000 --> 01:10:47,480
It's still giving it to you in the log odds ratio scale, and it's giving the standard error for this estimate.

573
01:10:47,870 --> 01:10:53,870
So for you to use the estimate, you need to exponentially this number and the confidence limits.

574
01:10:53,870 --> 01:10:59,749
These are the confidence limits for the log odds ratio overall and you need to

575
01:10:59,750 --> 01:11:05,270
exponentially those to get the confidence interval for on odds ratio scale.

576
01:11:07,520 --> 01:11:12,800
So you have to know to do that work because, you know, you put it in on a log odds ratio scale.

577
01:11:13,070 --> 01:11:14,090
And just as a reminder,

578
01:11:14,090 --> 01:11:24,020
we we used the log odds ratio scale because averaging it on the log scale has better statistical properties than averaging it on the odds ratio scale.

579
01:11:26,900 --> 01:11:30,320
And here is the the test.

580
01:11:30,360 --> 01:11:38,390
It's very similar to what we saw before because this is basically the inverse variance approach that we saw.

581
01:11:38,510 --> 01:11:47,899
The wolf method that we saw earlier. So that the same p value we get that we did earlier, this is presented on the z-score level.

582
01:11:47,900 --> 01:11:56,120
But if you square this number, you'll get that eight point something that we saw for the chi squared statistic in the hand calculations before.

583
01:11:58,870 --> 01:12:01,780
All right, so that's how you do this with SAS.

584
01:12:02,690 --> 01:12:08,899
Or my remembering that you need to you need to be the one to remember to exponentially to get back to the odds ratio scale.

585
01:12:08,900 --> 01:12:12,080
When you're reporting a results and writing your manuscript where the sentence.

586
01:12:14,720 --> 01:12:20,420
So the arm made a package, made a gene function.

587
01:12:21,140 --> 01:12:23,990
Does this made analysis using inverse variance? Wait.

588
01:12:23,990 --> 01:12:34,880
So here again, I'm just calculating the the the options and are they use T for treatment effect and CTE for stated error of treatment effect.

589
01:12:35,720 --> 01:12:41,240
But I'm I'm just calculating the log odds ratios and the stated error for the log odds ratios.

590
01:12:41,240 --> 01:12:48,320
Again, this is just doing it in R and then using the medication package with the the treatment effect,

591
01:12:48,530 --> 01:12:52,430
standard error of the treatment effect in the labels. So very, very similar.

592
01:12:53,240 --> 01:13:03,650
Once you put in whatever this is, this could be your log of risk ratios or could be regression coefficients or differences in shape or proportions.

593
01:13:03,950 --> 01:13:12,650
This is basically just like what we had e f in in SAS and this is basically the standard error of the s that we had in SAS.

594
01:13:15,500 --> 01:13:19,340
Okay. And it also doesn't know what you put in.

595
01:13:19,370 --> 01:13:21,949
Only you know that you put in log odds ratios.

596
01:13:21,950 --> 01:13:31,580
So it'll give you the results and it will give you the combined estimates, and you have to remember to to exponentially them.

597
01:13:32,600 --> 01:13:43,220
So here is the overall estimate of the log odds ratio, confidence interval, etc. on P value and it'll do that same test of homogeneity.

598
01:13:44,980 --> 01:13:51,410
That we saw earlier. But it's just applying it to whatever your estimates and your your.

599
01:13:52,570 --> 01:13:58,420
Standard errors of those estimates are it's just doing that. It doesn't know what you're doing things for to buy two tables necessarily.

600
01:14:01,400 --> 01:14:05,870
So again, you need exponentially to get back to the scale, the odds ratio when you're reporting your results.

601
01:14:09,600 --> 01:14:24,060
So there's this other package Ahmed at uni that performance made analysis using inverse variance weights as well and it has nice forest plots,

602
01:14:24,180 --> 01:14:26,380
so it's useful for doing this.

603
01:14:27,020 --> 01:14:35,370
So this earlier one gave us the nice study specific results that are kind of nice, but this other package will give you nice fourth plots.

604
01:14:35,820 --> 01:14:39,629
So here is the same code creating the treatment effects and standard error of the treatment

605
01:14:39,630 --> 01:14:47,940
effects for our ovarian cancer example and the code for giving you the overall results.

606
01:14:49,730 --> 01:14:52,910
And I used method equals epi for fixed effects.

607
01:14:52,910 --> 01:15:01,190
Generally, that's my preferred method. And then you just copy this whole line of code inside the first command, and I made a label for it.

608
01:15:03,560 --> 01:15:06,830
And it's going to look very similar to the Abbott we saw earlier.

609
01:15:07,100 --> 01:15:11,150
The main difference is that we didn't tell you it was data from two by two tables.

610
01:15:11,180 --> 01:15:17,180
We just gave it the estimates in the standard errors, which could have been estimates or senators from anything.

611
01:15:21,150 --> 01:15:28,889
All right. So the last step of a good mate analysis is evaluating a diagnostic called the funnel plot.

612
01:15:28,890 --> 01:15:31,740
And I did a teaser at the end of the last class for this.

613
01:15:32,790 --> 01:15:40,830
It's a useful graph that's designed to check the existence of publication bias in systematic reviews and meta analyzes.

614
01:15:41,430 --> 01:15:47,190
So the overall gestalt is that it assumes the largest studies.

615
01:15:48,580 --> 01:15:56,770
We'll be near the average, the true average that you are eventually going to report.

616
01:15:57,160 --> 01:16:05,170
And small studies, if it doesn't have publication bias, they should be spread on both sides of this average.

617
01:16:06,370 --> 01:16:13,540
And if you don't see that pattern, you see variation from that assumption that that that could indicate publication bias.

618
01:16:16,130 --> 01:16:22,310
So a symmetric, inverted funnel shape arises from a well behaved data set in which publication bias.

619
01:16:22,310 --> 01:16:33,480
Is that likely? If you see an asymmetric funnel that indicates a relationship between treatment effect and studies size in some way?

620
01:16:33,500 --> 01:16:38,450
So either you have publication bias that some studies weren't getting published,

621
01:16:38,990 --> 01:16:46,730
or sometimes there can be systematic differences between smaller and larger studies that are called small study effects.

622
01:16:47,090 --> 01:16:55,579
These can be caused by things like, you know, within an institution may be there's trouble maintaining a blind of of which treatment people were on.

623
01:16:55,580 --> 01:17:00,080
And so you can little biases can creep into small studies like that.

624
01:17:02,230 --> 01:17:07,170
And so if you see an asymmetric funnel plot that leads to doubts over the appropriateness of

625
01:17:07,180 --> 01:17:11,860
a simple made analysis and suggests that there needs to be investigation of possible causes,

626
01:17:12,250 --> 01:17:19,330
this is different from a homogeneity issue. This is an issue where you're only seeing a biased part of the story.

627
01:17:21,070 --> 01:17:24,880
And that your summary is likely biased as a result.

628
01:17:28,910 --> 01:17:35,180
So we're going to see some funnel plots soon and kind of learn how to recognize issues.

629
01:17:36,050 --> 01:17:42,830
There's a lot of choices of measures of study size available is what the vertical scale is is.

630
01:17:44,320 --> 01:17:48,940
Basically trying to capture precision of the estimates you're combining.

631
01:17:49,630 --> 01:17:59,380
So you might see packages that measure this precision of each study's estimates using studies sample size.

632
01:17:59,380 --> 01:18:06,190
But most commonly you look at the standard error of the treatment effect and the inverse variance of the treatment effect.

633
01:18:08,120 --> 01:18:15,979
So there's been some research on what the best vertical stock scale and these plots are.

634
01:18:15,980 --> 01:18:20,090
And standard error is the one that's most commonly recommended most packages for use.

635
01:18:20,480 --> 01:18:26,959
And the reason it's nice is that when you use the standard error as the vertical scale on these plots,

636
01:18:26,960 --> 01:18:35,870
then you can kind of draw the funnel itself and the lines have slopes plus or minus one over 1.96.

637
01:18:37,190 --> 01:18:43,490
And then 95% of the points from the studies should be within the funnel.

638
01:18:44,090 --> 01:18:47,930
So that's kind of a nice feature of using the standard error, the vertical scale.

639
01:18:52,010 --> 01:18:55,400
So I think I showed you this funnel plot example last time.

640
01:18:55,410 --> 01:19:01,100
So each one of these dots comes from a study and here they weren't combining odds ratios,

641
01:19:01,100 --> 01:19:05,750
they were actually combining risk ratios, mortality risk ratios.

642
01:19:06,140 --> 01:19:09,620
And so they were using like the inverse variance method to do that.

643
01:19:10,100 --> 01:19:14,930
And so the vertical scale here is based on standard error.

644
01:19:15,800 --> 01:19:21,620
And I want you to just notice that the that it's a reversed flipped scale.

645
01:19:21,620 --> 01:19:27,560
So the smaller the standard error that's near the top, the larger standard error is near the bottom.

646
01:19:27,680 --> 01:19:35,210
So when they generate this plot, they reverse the scale and usually it goes from 0 to 2, now goes from 2 to 0.

647
01:19:36,340 --> 01:19:42,700
And these lines here have a slope of plus or minus one over 1.96.

648
01:19:43,300 --> 01:19:52,120
And so theoretically, 95% of the studies should be within the funnel shape if there's no issues, and we only see one that's kind of creeping out.

649
01:19:52,130 --> 01:19:54,700
So that part doesn't seem to suspect.

650
01:19:55,570 --> 01:20:02,670
So the other thing you're supposed to look at is the study with the smallest standard here should be at the top of the funnel.

651
01:20:02,710 --> 01:20:10,450
That's this one. And if there's no issues with publication bias,

652
01:20:10,450 --> 01:20:19,900
then you should see if this is really the true the closest thing to the true estimate that we have based on this being the largest study.

653
01:20:20,960 --> 01:20:28,850
Then randomly the smaller studies should kind of be spread equally and either side of that large studies estimate.

654
01:20:30,190 --> 01:20:39,040
All right. So in this particular plot, this was looking at trials of ACE inhibitors.

655
01:20:40,620 --> 01:20:52,800
And in this particular plot, most of the dots are on the side of the funnel that say that ACE inhibitors are keeping people alive.

656
01:20:55,780 --> 01:21:04,420
Wright said the risk ratio was less than one. So all of the dots on this left side are saying that ACE inhibitors are are

657
01:21:04,720 --> 01:21:14,170
preserving life and there's many fewer dots on the side where ACE inhibitors are.

658
01:21:15,190 --> 01:21:27,179
Causing issues. And so because there's fewer studies over here on this side of the funnel, it raises this question of, you know,

659
01:21:27,180 --> 01:21:32,219
maybe there were some studies that that were smaller that couldn't get published

660
01:21:32,220 --> 01:21:38,100
because they were saying ACE inhibitors were not helpful in protecting life.

661
01:21:38,430 --> 01:21:46,469
So these smaller studies might have been easier to publish if it sounded exciting that ACE inhibitors were preserving life.

662
01:21:46,470 --> 01:21:48,360
So maybe they had an easier time getting published.

663
01:21:48,750 --> 01:21:55,230
But on this side, they were like, I don't care about this story because it doesn't tell me how to treat my patients.

664
01:21:57,020 --> 01:22:00,230
Better than standard care. All right.

665
01:22:00,680 --> 01:22:05,720
So here's. So this is an example of a publication, potential publication bias.

666
01:22:07,200 --> 01:22:16,140
That could be happening. And if you need to have a definitive answer, you need to run a larger randomized clinical trial.

667
01:22:16,170 --> 01:22:22,650
Yeah. Yep. There. You're looking at the district.

668
01:22:22,670 --> 01:22:25,969
Yeah. So the question is about what we're looking at.

669
01:22:25,970 --> 01:22:31,790
And yes, you're looking at the distribution of dots on either side of this top study.

670
01:22:33,270 --> 01:22:42,240
Yeah. So we're looking at how many dots are on the left of that top study, how many dots are on the right of that top study?

671
01:22:43,410 --> 01:22:49,540
And it looks like there's many more. In this side of the funnel.

672
01:22:49,570 --> 01:22:52,959
So here's the null hypothesis that the risk ratio is one.

673
01:22:52,960 --> 01:22:58,720
That's the null hypothesis, right? If the risk ratio is one ACE inhibitors, it's neutral.

674
01:22:58,720 --> 01:23:03,630
It's not helping or harming. Whether you're on ACE inhibitors.

675
01:23:05,020 --> 01:23:13,860
So if you're on this side, ACE inhibitors sound exciting because people are dying less frequently and there's many studies over here.

676
01:23:13,870 --> 01:23:17,980
So maybe those were exciting to publish is possibly what was going on.

677
01:23:18,580 --> 01:23:21,580
And on this side, ACE inhibitors weren't helping anything.

678
01:23:23,140 --> 01:23:26,920
And down here for the smaller studies, it probably wasn't even statistically significant.

679
01:23:27,310 --> 01:23:30,190
So it might have been really hard to publish in this case.

680
01:23:31,490 --> 01:23:40,310
So we might be only capturing studies that had a good chance of getting published and they were more likely to be published on this side.

681
01:23:41,530 --> 01:23:50,810
So the average is going to be biased towards. The studies that were published, which tended to say ACE inhibitors were great.

682
01:23:54,230 --> 01:24:04,100
So here's a different study. And I like this study because the very top part is the randomized clinical trial that was eventually done.

683
01:24:04,160 --> 01:24:09,680
So this is the deterministic answer. That was the final step of understanding this.

684
01:24:10,190 --> 01:24:15,890
So they were looking at trials of low dose aspirin in the prevention of pre-eclampsia.

685
01:24:17,600 --> 01:24:22,340
And there were two main analyzes that were done. The first one is the black dots.

686
01:24:22,820 --> 01:24:26,480
I think I might have shown you I might have showed you this funnel plot at the end of last time.

687
01:24:26,960 --> 01:24:36,230
So the first made analysis used studies that were, you know, available in 1991.

688
01:24:36,950 --> 01:24:39,380
And so there were one, two, three, four, five, six studies.

689
01:24:40,040 --> 01:24:49,129
And if you were to look at the imagined funnel here, they don't have the funnel lines drawn here.

690
01:24:49,130 --> 01:24:54,830
But you could sort of see here's the top of the funnel is the one that has the most precision.

691
01:24:55,160 --> 01:24:59,180
So here these were reported probably in the statistical methods.

692
01:24:59,420 --> 01:25:03,560
They'll say what the precision is, but they don't really define it well here.

693
01:25:03,950 --> 01:25:07,210
But the larger, more precise studies are near the top.

694
01:25:07,220 --> 01:25:14,880
So this is the top of the funnel. And it looks like, you know, it's about in the middle of the study.

695
01:25:14,920 --> 01:25:22,050
So probably that first made analysis suggested there wasn't a lot of reason to worry about publication bias.

696
01:25:22,980 --> 01:25:31,050
And and they were saying, well, we should look more into this low dose aspirin for the prevention of pre-eclampsia based on these meta analysis.

697
01:25:31,080 --> 01:25:38,850
This could be something that could help. A second meta analysis included additional studies that are.

698
01:25:39,120 --> 01:25:42,659
So the new studies that were added to the meta analysis are the open circles.

699
01:25:42,660 --> 01:25:46,650
So they use the black circles and the open circles for that meta analysis.

700
01:25:48,450 --> 01:25:57,990
And suddenly you have this trial up here that has a lot more precision than any of the other smaller trials.

701
01:25:58,950 --> 01:26:04,950
And so this is now. A very plausible top of the funnel.

702
01:26:06,120 --> 01:26:09,929
And if you imagine drawing the lines there,

703
01:26:09,930 --> 01:26:20,850
most of the studies are on the side of that funnel top that suggests that low dose aspirin is helpful and very few are on this other side.

704
01:26:21,240 --> 01:26:25,410
So no one really knows for sure what the real top of the funnel is, right?

705
01:26:25,410 --> 01:26:30,750
You just use what data you have and say if this is the top, is there a potential issue here?

706
01:26:31,050 --> 01:26:34,170
So if this is the new understood top of the funnel,

707
01:26:34,410 --> 01:26:40,200
that would suggest that there's a lot of publication bias because there's almost no studies on the other side over here.

708
01:26:41,880 --> 01:26:55,470
And so they did do a large trial, probably started after this first made analysis, you know, and it ended up being published in 1994.

709
01:26:55,470 --> 01:27:04,950
And here were the results. And indeed, the clinical trial, which is the gold standard for finding out treatment effects in an unbiased manner,

710
01:27:05,460 --> 01:27:09,660
was actually closer to this study that turned up later.

711
01:27:12,140 --> 01:27:19,570
And so a bit disappointing. This made analysis, the black dot made analysis did their best.

712
01:27:20,670 --> 01:27:25,710
But they didn't know that all of the studies they were showing were kind of in the publication bias world.

713
01:27:26,190 --> 01:27:33,000
The study suggested there might be an issue, but it wasn't until the clinical trial that you really knew for sure what was going on.

714
01:27:35,100 --> 01:27:40,530
So there's a common thing with made analysis that, you know, these smaller studies are easy to do.

715
01:27:40,800 --> 01:27:48,450
You try to combine information to see is it worth spending patient and financial resources on coming up with a definitive answer.

716
01:27:49,240 --> 01:27:51,720
It doesn't always agree with the main analysis.

717
01:27:52,740 --> 01:28:04,880
So here's a results from a paper that was summarizing characteristics of meta analysis and corresponding large trials where they were both available.

718
01:28:04,890 --> 01:28:10,110
So in each one of these situations, the meta analysis suggested, Let's do a large trial.

719
01:28:10,650 --> 01:28:19,920
And the top examples are cases where the clinical trial agreed with the meta analysis results.

720
01:28:19,920 --> 01:28:30,340
So each one of these studies. Had a meta analysis and a corresponding a large trial, and they both agreed.

721
01:28:32,950 --> 01:28:36,750
That something cool was going on that could be changing medical practice.

722
01:28:37,290 --> 01:28:43,590
The bottom examples, one of which I've got boxed here, is something that we've been looking at,

723
01:28:44,550 --> 01:28:50,940
is these are situations where the main analysis said there's some potential treatment here.

724
01:28:50,940 --> 01:28:54,150
I want to. That might that might be helpful.

725
01:28:54,480 --> 01:29:00,300
But when they did the clinical trial, they saw that there was nothing interesting happening after all.

726
01:29:02,180 --> 01:29:08,540
All right. So this boxed and read example, we're going to look at a little bit further.

727
01:29:09,290 --> 01:29:15,120
And so the meta analysis was to add all. And the clinical trial was this ice is for.

728
01:29:17,760 --> 01:29:29,710
So here. This is kind of a clumsy plot that I did before I had access to fancy R, so I should have probably done a fancy R plot.

729
01:29:29,720 --> 01:29:35,630
But so here are the various studies that went into the total made analysis.

730
01:29:36,110 --> 01:29:43,070
And so the horizontal scale is the log odds ratios from the seven studies that were used in that made analysis.

731
01:29:43,520 --> 01:29:47,209
And then the vertical scale is based on standard errors of the estimated log odds

732
01:29:47,210 --> 01:29:51,920
ratios were the scale has been reversed with the most precise studies at the top.

733
01:29:52,430 --> 01:29:55,960
So here these are the studies then. So the question is, you know what?

734
01:29:56,480 --> 01:30:04,559
What's the top of the funnel here? So the most precise study is what we usually think of as the top of the funnel.

735
01:30:04,560 --> 01:30:11,850
And so if I use this one, then I it looks like I don't really have a publication bias issue, right?

736
01:30:11,850 --> 01:30:20,400
Because I'm seeing a lot of studies on either side. The second study is very close and precision to this other one.

737
01:30:20,420 --> 01:30:26,460
So it's a plausible other top of the funnel because I don't again, I don't know what the truth is.

738
01:30:27,790 --> 01:30:32,000
But it's definitely a contender for being a precise study.

739
01:30:32,020 --> 01:30:34,570
Very little difference in precision from this other one.

740
01:30:34,840 --> 01:30:42,670
And if this is the real top of the funnel, then there's huge publication bias because all of the other studies are on this other side.

741
01:30:43,270 --> 01:30:51,400
So this is kind of a funnel plot that's very tricky because you could convince yourself of either story being potentially the case.

742
01:30:54,090 --> 01:31:01,630
So it was reasonable for the authors of this main analysis to argue for magnesium as a treatment based on this plot.

743
01:31:01,650 --> 01:31:09,330
But in light of the negative clinical trial results that came after the fact, after the main analysis,

744
01:31:09,810 --> 01:31:18,450
the study that showed no treatment effect here, this is near the null hypothesis was the more reliable study, but you wouldn't have known it.

745
01:31:18,900 --> 01:31:27,360
It was very difficult to know ahead of time that this was closer to the truth than this until the clinical trial results became available.

746
01:31:30,170 --> 01:31:33,590
So I want to show you this in a little bit more detail,

747
01:31:33,620 --> 01:31:44,060
because this is close to what your homework is like where you have many studies and you have to input the data to do the overall calculations.

748
01:31:44,660 --> 01:31:53,149
And so here are the seven studies, and there's a couple that we looked at in detail,

749
01:31:53,150 --> 01:32:06,080
this ref museum study and I believe with the felt stat study, those were the two studies that had the most precision, I think, in the plots.

750
01:32:08,200 --> 01:32:11,470
And we're like being questioned as the top of the funnel.

751
01:32:13,870 --> 01:32:20,529
And so the way that these are the this is the data in each row for the two by two table.

752
01:32:20,530 --> 01:32:24,340
So it shows you the number dead.

753
01:32:24,550 --> 01:32:27,370
It should have a period after that. No, it looks like no dead,

754
01:32:27,370 --> 01:32:33,850
but it's it's supposed to be the number dead and the number followed up from the magnesium group and from the control group.

755
01:32:34,300 --> 01:32:39,670
And so this is like an air cell. And I think this is like a C cell.

756
01:32:39,910 --> 01:32:45,670
And then the row totals are there. You're supposed to do subtraction to get the the B in the details.

757
01:32:46,570 --> 01:32:56,200
All right. So. Each of these papers had enough here to put this into the main analysis.

758
01:32:58,580 --> 01:33:06,190
And then Total did not follow standard made analysis calculations and producing the crude total results and read above.

759
01:33:06,890 --> 01:33:10,370
He did this thing that you're not supposed to do of studies a confounder.

760
01:33:10,940 --> 01:33:16,669
He just summed up all the deaths over all the people and then denominator and summed

761
01:33:16,670 --> 01:33:20,120
up all the deaths in the control group over all the people in the control group.

762
01:33:20,450 --> 01:33:27,979
So it's like he made a one hole two by two table as a study was not a potential confounders.

763
01:33:27,980 --> 01:33:33,880
So we know we're not really supposed to do that. But fortunately for the author, study really wasn't a confounder,

764
01:33:33,930 --> 01:33:41,720
so the combination ended up being very similar to those results that we'll see where we formally treat study as a confounder.

765
01:33:43,340 --> 01:33:47,510
So I have this question. Would you know how to perform the correct maid analysis calculations?

766
01:33:47,900 --> 01:33:53,900
And I'm hoping at this point you said yes, because we've done this in the previous slides where we,

767
01:33:53,900 --> 01:33:59,450
you know, combine the odds ratios across all these seven studies using mental hansell.

768
01:34:00,050 --> 01:34:04,430
So in this case, the results using manual hands on methods end up being similar to the crude.

769
01:34:04,430 --> 01:34:13,730
Just because study wasn't really a confounder. It wasn't associated both with the outcome for mortality as well as the treatment group.

770
01:34:13,910 --> 01:34:16,010
And I think that's probably reasonable.

771
01:34:16,400 --> 01:34:25,520
Each of these studies was probably a randomized trial, so there was probably no link with the exposure and the study probably in each site.

772
01:34:26,000 --> 01:34:30,620
The chances of being on that magnesium versus not was the same.

773
01:34:30,650 --> 01:34:37,250
So that's the link that was probably removed. So that study wasn't a confounder that there was no association between treatment.

774
01:34:38,610 --> 01:34:42,630
And study it. Probably you were equally likely to be on either treatment regardless of study.

775
01:34:44,810 --> 01:34:48,470
So here's some R code.

776
01:34:50,240 --> 01:34:58,340
I want to show you the funnel plot. So I started with ah because ah, you know, there's easy code to use for the funnel plot.

777
01:34:58,640 --> 01:35:06,320
So this is an example of the made the bind cap package and what it does for the funnel plots.

778
01:35:06,320 --> 01:35:12,110
It has code for the funnel plots, but I will show you why I do not like their funnel plots.

779
01:35:12,230 --> 01:35:17,270
It has nice features, but there's a deal breaker in how it selects the top of the funnel.

780
01:35:17,280 --> 01:35:26,749
That's just not correct. So just to show you what it does give you here, study labels, here are the event dot.

781
01:35:26,750 --> 01:35:39,320
In any event dot C and C for the, you know, the cells and this and the C cells and so on that it that it needs to give you the results.

782
01:35:39,560 --> 01:35:43,850
And we can select method equals mental Hansel in summary measure odds ratio just

783
01:35:43,850 --> 01:35:48,260
like we did before with the ovarian cancer example and do this funnel plot.

784
01:35:50,310 --> 01:35:53,930
So here's the nice part that I like about it.

785
01:35:53,940 --> 01:36:01,590
This particular package that gives you all the study specific odds ratios and confidence intervals, which are really handy to have.

786
01:36:02,400 --> 01:36:11,530
But, you know, for forest plots, you might want to have all of these handy to use text boxes to put over log odds ratios, for example.

787
01:36:11,550 --> 01:36:16,190
So I do like this part and you know, it has the,

788
01:36:16,500 --> 01:36:25,200
the overall odds ratio and confidence interval and p value just perfectly ready for your manuscript worthy studies test of homogeneity is here.

789
01:36:26,940 --> 01:36:33,089
So the it failed to reject the test of homogeneity.

790
01:36:33,090 --> 01:36:36,390
So it said it was okay to combine these odds ratios.

791
01:36:37,870 --> 01:36:52,110
And. And it said there was a significant association between the treatment and the outcome with that P value of 0.0009.

792
01:36:53,340 --> 01:36:57,870
So the only problem I have is the funnel plot.

793
01:36:58,710 --> 01:37:01,710
So there's some parts of this I really like.

794
01:37:01,710 --> 01:37:06,980
I really like that each study has its corresponding label of where the data came from.

795
01:37:06,990 --> 01:37:12,880
So I know that this is from the Rasmussen study and this is the start over here is from the failed stud study.

796
01:37:13,470 --> 01:37:17,370
So what is what is the problem with this funnel plot?

797
01:37:20,230 --> 01:37:27,610
Well, it centers the top of the funnel around the overall made analysis odds ratio estimate.

798
01:37:27,640 --> 01:37:38,540
So this point here. Where they move this top of this funnel is exactly where the overall odds ratio estimate is.

799
01:37:38,720 --> 01:37:46,700
And so it's always, you know, going to look like it's in the middle of the data because it's around the overall odds ratio.

800
01:37:46,910 --> 01:37:51,110
You're supposed to put the top of the funnel around the most precise study, right?

801
01:37:51,110 --> 01:37:59,600
So it should either be here. That's like our default is to look at the study with the smallest standard error and center the funnel there.

802
01:37:59,960 --> 01:38:04,520
Or if you wanted to just look at it, you could play around and make the top of the funnel here,

803
01:38:04,820 --> 01:38:08,420
but you shouldn't just put it smack dab in the middle where the point estimate is.

804
01:38:08,780 --> 01:38:11,479
So whoever wrote the package,

805
01:38:11,480 --> 01:38:18,560
they just blew it on this one detail with a beautiful plot aside for the fact that it's not useful for diagnosing publication bias.

806
01:38:19,690 --> 01:38:24,760
So what do you do? So there's the metaphor package. So remember, there's an F in here.

807
01:38:26,210 --> 01:38:31,370
So F for fourth plot, F for funnel plot. This is the package that does both of those really well.

808
01:38:31,940 --> 01:38:36,170
So putting in the the studies and the AIB is the idea.

809
01:38:36,350 --> 01:38:37,370
I sells.

810
01:38:38,480 --> 01:38:48,050
And doing the analysis that this is going to give us the overall P values and confidence intervals and overall odds ratio estimates that we want.

811
01:38:48,410 --> 01:38:58,880
And then here I've got code for the funnel plot that adds in specifically where I want my reference line of the funnel plot to be.

812
01:38:59,240 --> 01:39:04,790
So one of these is for the Rasmussen study, one of these is for the film stud study.

813
01:39:04,790 --> 01:39:14,150
Did I get that right? And so I can physically say where I want my top of the funnel to be and the other package doesn't allow you to do this.

814
01:39:15,140 --> 01:39:19,100
So here is one option for guessing the top of the funnel.

815
01:39:19,100 --> 01:39:28,130
This is, I think, the Rasmussen study. And so if this is the true top of the funnel, you're probably okay, right?

816
01:39:28,160 --> 01:39:34,940
There's one study that popped out of the the funnel shape, and that's only supposed to happen 5% of the time.

817
01:39:34,940 --> 01:39:38,090
But it it only happened once. So it might not be an issue.

818
01:39:39,420 --> 01:39:47,310
But if you. Change it to this next highest precision, if that's actually the truth.

819
01:39:47,320 --> 01:39:54,820
And you're in big trouble with with publication bias and of course, you don't know which is really closer to the truth.

820
01:39:54,820 --> 01:40:00,160
You just know they're both on the more precise side of the studies that were reported.

821
01:40:00,160 --> 01:40:03,190
So you don't really know for sure which one is going to be the truth.

822
01:40:03,610 --> 01:40:09,610
But if this one ends up being closer to the truth, then you've got a severe publication bias issue.

823
01:40:14,750 --> 01:40:21,020
And of course, this is one of those cases where the randomized clinical trial ended up being closer to that second case.

824
01:40:23,740 --> 01:40:26,610
Here is South Code for doing a funnel plot.

825
01:40:26,620 --> 01:40:34,630
So this is a little bit more manual or can be really nice for giving you preprogramed things that are easy to use.

826
01:40:35,050 --> 01:40:42,250
And in south oh excuse me, you actually have to physically put in the lines of the funnel.

827
01:40:43,400 --> 01:40:47,150
So here is code putting in the data from all the studies.

828
01:40:48,960 --> 01:40:54,300
And here is code for making up the funnel plot based on the estimates and standard errors.

829
01:40:56,020 --> 01:41:03,900
Where I've put in, uh, you know, the log odds ratio of the study with the smallest standard error.

830
01:41:03,910 --> 01:41:07,040
So this is the Rasmussen log odds ratio.

831
01:41:07,330 --> 01:41:10,330
And here I'm putting in the funnel slope.

832
01:41:10,660 --> 01:41:14,080
This is one over 1.96. This is one over.

833
01:41:15,900 --> 01:41:22,260
-1.96. So you have to just physically put in that yourself to get those lines.

834
01:41:25,610 --> 01:41:30,670
And so this is what and I'm not you know, I'm a clumsy programmer when it comes to sass.

835
01:41:30,680 --> 01:41:37,100
They didn't hire me for my for my programing skills, although, you know, I'm not terrible.

836
01:41:39,110 --> 01:41:44,270
So it's not quite as pretty as what our we'll do for you with professional programmers behind the scenes.

837
01:41:44,600 --> 01:41:48,890
But this will do it for you if you're a SAS programmer and you don't want to do the ah.

838
01:41:50,730 --> 01:41:55,300
All right. So.

839
01:41:58,290 --> 01:42:05,820
This is kind of the summary of the the total studies is this meta analysis result.

840
01:42:06,090 --> 01:42:10,250
And then here is the clinical. A single large clinical trial result.

841
01:42:14,020 --> 01:42:25,569
And so here are the four examples where, you know, the clinical trial tended to be similar to the main analysis.

842
01:42:25,570 --> 01:42:34,240
But boy, these were quite different. And most of the time the large clinical trial of these cases trended towards the null hypothesis.

843
01:42:35,580 --> 01:42:39,900
As opposed to what the main analysis suggests, it could be quite exciting.

844
01:42:43,500 --> 01:42:51,660
Okay. So your first homework is going to be very situated around doing these.

845
01:42:53,510 --> 01:43:04,850
Meta analysis. Let's just take a peek. At homework, one which you really could start next week,

846
01:43:04,910 --> 01:43:11,420
that will be very helpful in programing and that that you have enough from the lecture to to get your feet wet on this assignment.

847
01:43:20,410 --> 01:43:28,870
So here. Is that made analysis problem problem and so boxed in red.

848
01:43:30,260 --> 01:43:39,800
There are some studies regarding the use of corticosteroid steroids in non ICU COPD patients experiencing a pulmonary exacerbation.

849
01:43:40,250 --> 01:43:43,130
And so each one of these comes from a separate study.

850
01:43:43,520 --> 01:43:54,469
And what they've got for you is here here is the raw data over here, the successes over the tunnel total.

851
01:43:54,470 --> 01:44:00,920
Let's put it in a very similar way to what we saw in the handout from the total study.

852
01:44:00,930 --> 01:44:13,810
So. Success over total for the systemic corticosteroids that this group and then the control the successes over the total right.

853
01:44:15,220 --> 01:44:20,920
So here's the raw data that you can put in, very similar to the way we did the total results.

854
01:44:21,700 --> 01:44:25,509
This is there they did really nice forest plots.

855
01:44:25,510 --> 01:44:31,810
It looks like they were using log to to do their forest plots that they program these by hands that didn't use either the packages that we used.

856
01:44:32,320 --> 01:44:38,530
But you can kind of go through you can kind of go through the assignment to see how to do some of these things.

857
01:44:38,540 --> 01:44:44,800
So I have a few little steps to kind of make sure you know what they did.

858
01:44:44,860 --> 01:44:52,600
So this one study near Wellner, the tabulated data just was so crunched together.

859
01:44:53,200 --> 01:44:58,060
See this? It's really hard to read what's going on here, which is so crunched together.

860
01:44:58,390 --> 01:45:08,620
And so I just have you verify that my best guess of what those numbers were was correct, because they also have their odds ratios over here.

861
01:45:10,610 --> 01:45:21,250
So just verifying that kind of stuff. And then one of these studies had a zero count for one of the cells, the Thompson study.

862
01:45:21,820 --> 01:45:27,560
So here's. How how the the row of numbers for the Thompson study.

863
01:45:29,380 --> 01:45:36,210
Right. That's this one. How these counts translate to the two by two table.

864
01:45:38,280 --> 01:45:40,990
And I'm just asking you to, you know,

865
01:45:41,010 --> 01:45:49,990
confirm that they got their overall odds ratio results and confidence intervals by this common trick of adding point five to each of the four cells.

866
01:45:50,010 --> 01:45:55,950
Often if there's a zero cell count, people will just add 0.5 to all four cells and do the calculations.

867
01:45:55,950 --> 01:46:02,040
And this is just you verifying that that's how they got their estimates for the

868
01:46:02,040 --> 01:46:06,600
odds ratio and confidence interval that they show in that same table over here.

869
01:46:06,990 --> 01:46:11,990
So here's the odds ratio. That's pretty huge. And the confidence limits.

870
01:46:12,380 --> 01:46:16,100
So that's you confirming that's what they did.

871
01:46:17,820 --> 01:46:25,430
And then the rest of part C is just U programing, the log odds ratio,

872
01:46:25,440 --> 01:46:32,220
the 95% confidence interval for the log odds ratio and the standard error of the log raised odds ratio for all the studies.

873
01:46:32,910 --> 01:46:35,910
So you can use either R or South to get those.

874
01:46:36,360 --> 01:46:43,710
Looking at the total examples, probably the most useful because it had all the, you know, similar data the way it went in.

875
01:46:46,040 --> 01:46:52,370
And then Part D is doing the meta analysis in two different ways.

876
01:46:52,400 --> 01:46:57,980
The first way is to use just mental Hansel methods, because we know these are from two by two tables.

877
01:46:59,240 --> 01:47:04,240
So you can use manual hands on. I kind of point you to the, the slides where the south ah.

878
01:47:04,280 --> 01:47:11,660
Code is to help you out. And the second way is to use the inverse variance rate method, the Wolfe method to do the same thing.

879
01:47:12,750 --> 01:47:19,880
Um, and there's some steps that you need to do, like adding point five to each cell from the Thompson study to avoid problems with your cell count.

880
01:47:19,890 --> 01:47:24,050
So it's sort of just taking you through that exercise and.

881
01:47:25,820 --> 01:47:30,880
And part is creating the funnel plot. And you can use either or stars.

882
01:47:31,980 --> 01:47:36,150
I like our. But, you know, the plot didn't look too bad, actually.

883
01:47:38,760 --> 01:47:42,330
All right. So you should be able to tackle that for problem two.

884
01:47:44,220 --> 01:47:49,680
Last time we reviewed Pearson Chi Square tests and Cochrane Armitage trend tests.

885
01:47:50,190 --> 01:47:51,840
So you can work on that.

886
01:47:53,220 --> 01:48:02,910
I haven't talked to you much about sensitivity and specificity, so you might want to wait on this part f until next week when I review sensitivity.

887
01:48:02,910 --> 01:48:09,090
Specificity, but all the rest of the homework, if you so chose, you can tackle.

888
01:48:10,200 --> 01:48:14,820
And next week the lab will be helpful. It'll focus on the meta analysis part again.

889
01:48:15,360 --> 01:48:21,060
Okay, so that's going to be it for today. We will do handout three next time.

890
01:48:21,150 --> 01:48:24,360
Have a wonderful weekend.

891
01:48:27,290 --> 01:48:27,710
By.

