1
00:00:02,300 --> 00:00:06,710
All right. So we're at the same. Community status of hi.

2
00:00:06,720 --> 00:00:14,760
So this is the we're still wearing masks more often indoors and in public transportation.

3
00:00:14,760 --> 00:00:20,670
So that's why I've got my mask on. I, I think that the level changes every Thursday, so tomorrow there'll be an update.

4
00:00:22,290 --> 00:00:30,240
Just so you know, they have on campus flu shots set up.

5
00:00:30,810 --> 00:00:36,360
And when I went to get mine, they also let me take the new COVID booster.

6
00:00:36,990 --> 00:00:42,209
And so if you're thinking about doing that, you can do it all at once.

7
00:00:42,210 --> 00:00:47,850
It was quite easy, but you have to look for those locations online.

8
00:00:47,850 --> 00:00:51,660
It might only have the flu shot locations marked, but they're doing both.

9
00:00:52,950 --> 00:00:56,460
So it's it was so convenient. I just did it.

10
00:00:58,820 --> 00:01:05,820
Okay. So. So where are we?

11
00:01:06,240 --> 00:01:09,290
Still looks like I did hit record. Yes.

12
00:01:13,970 --> 00:01:19,630
Okay. So we are here. Handout for.

13
00:01:24,280 --> 00:01:29,649
So we'll be doing analysis of match binary outcomes today and we'll have a lot of different examples.

14
00:01:29,650 --> 00:01:35,200
So you can recognize settings where these analysis tactics techniques are useful.

15
00:01:36,490 --> 00:01:46,630
So I'll get started with that in just a moment. I just wanted to remind you that the first assignment is due on the 18th.

16
00:01:46,960 --> 00:01:53,460
So that Sunday. At around midnight.

17
00:01:54,120 --> 00:01:59,520
Okay. So it is a lot of work if you haven't started yet.

18
00:02:01,260 --> 00:02:02,489
You might want to take a look at it.

19
00:02:02,490 --> 00:02:08,880
If your lab is still coming up and you haven't started because you're waiting for the lab, you should at least take a look at what the assignment is.

20
00:02:09,270 --> 00:02:14,400
So you go into the lab with all your questions ready so that you can get help.

21
00:02:15,030 --> 00:02:20,130
The last officer that I have before the assignments do is this Friday at 4:00.

22
00:02:21,090 --> 00:02:26,700
So you can zoom in with me at that time and still have questions answered by me.

23
00:02:26,700 --> 00:02:30,570
I think that the GSI is also have a Friday office hour.

24
00:02:31,680 --> 00:02:36,420
So and then of course. Oh, actually Monday before the assignment.

25
00:02:36,720 --> 00:02:39,720
No, that's after the assignment. Duties, assignments, choose on Sunday.

26
00:02:40,500 --> 00:02:46,260
Okay. I think that's all the announcement.

27
00:02:46,270 --> 00:02:50,280
So let's go ahead and get started on hand out for.

28
00:02:59,240 --> 00:03:02,540
All right. So you might have seen this material before. Some introductory statistics.

29
00:03:02,540 --> 00:03:12,709
Classes cover this and some do not. So what are my intent for this handout is to get us all up to the same page again and to also

30
00:03:12,710 --> 00:03:20,570
have a starting place for when we talk about regression models with correlated outcome data.

31
00:03:21,050 --> 00:03:29,870
And so a lot of this is kind of seeding into what we'll be doing later when we do correlated regression analysis.

32
00:03:31,070 --> 00:03:34,160
So matched binary data is the focus for today.

33
00:03:34,160 --> 00:03:41,209
So yes, no kind of outcomes that are correlated. And so this can happen by measuring response at two or more occasions.

34
00:03:41,210 --> 00:03:49,110
Yes. No. So it can be based on longitudinal data that you're just following someone over time and recording.

35
00:03:49,110 --> 00:03:56,750
Yes, they have certain response. Or it can be part of a pretest post-test kind of interventional study design.

36
00:03:58,210 --> 00:04:06,880
Or it can even be based on matching on possible confounders or sets of confounders in a prospective or cross-sectional study.

37
00:04:07,330 --> 00:04:19,220
So you can match people on various characteristics. And there's also match data when you have evaluation of a patient by more than one reviewer.

38
00:04:19,240 --> 00:04:26,550
So this is kind of related to what we looked at last time in the previous lecture on agreement analysis, view of the cap and method.

39
00:04:26,560 --> 00:04:30,850
So we talked about measures of agreement in hand out three,

40
00:04:31,450 --> 00:04:39,980
but you could also view that as match data saying diagnosis yes for review or one versus diagnosis, yes for review or two.

41
00:04:40,300 --> 00:04:46,720
And it's correlated because you're looking at the same patient's data. So this can come up in a number of settings.

42
00:04:47,600 --> 00:04:54,660
The benefits of matching. Or that there's lots of sources of variability that drive these outcomes.

43
00:04:54,670 --> 00:05:02,400
But if you match. Then some of the sources that you match on for confounding can be controlled,

44
00:05:02,420 --> 00:05:07,630
so controls sources of confounding that are like in each match group of individuals or outcomes.

45
00:05:08,340 --> 00:05:16,510
So that's the goal. And there are statistical benefits to that approach that, you know,

46
00:05:16,510 --> 00:05:22,210
whenever you reduce sources of variability in the data, you get a more precise estimate of what's going on.

47
00:05:22,720 --> 00:05:28,150
And so that can increase study power when comparisons are made between paired outcomes.

48
00:05:28,150 --> 00:05:32,830
If you use the appropriate analysis, it will not increase power.

49
00:05:33,370 --> 00:05:42,100
If you use an analysis that assumes independence between outcomes, that that analysis may be biased as well as a very, very inefficient.

50
00:05:45,090 --> 00:05:49,710
So there are also, you know, cons or detriments to matching.

51
00:05:50,280 --> 00:05:54,359
And that is, you know, sometimes it's hard to fully match every individual to someone.

52
00:05:54,360 --> 00:05:58,800
That's a light enough with respect to confounders to really make that a good strategy.

53
00:06:00,040 --> 00:06:07,149
And if you are doing a prospective study and you've kind of enrolled people in matched sets,

54
00:06:07,150 --> 00:06:11,890
then if one individual in that set or in that pair is most.

55
00:06:12,810 --> 00:06:15,570
To follow what any other paired member state is offering.

56
00:06:15,570 --> 00:06:22,830
Useless if you're counting on differences between matched individuals for your primary analysis.

57
00:06:26,160 --> 00:06:31,490
Analysis methods are sometimes more complex when you have to deal with the correlation in the data as well.

58
00:06:31,500 --> 00:06:37,739
So we're certainly going to learn how to deal with this later in the course.

59
00:06:37,740 --> 00:06:45,270
But it can get more and more complex depending on how many layers of matching are happening.

60
00:06:49,220 --> 00:06:55,730
So I'm going to kind of back up a little bit and just think about how we tabulate paired data.

61
00:06:55,730 --> 00:07:00,470
So suppose we want to study smoking behavior of 300 women.

62
00:07:01,460 --> 00:07:07,680
Before and after pregnancy. So, you know, a lot of women quit smoking, for example.

63
00:07:07,700 --> 00:07:16,040
But you want to kind of know if there's an association between the pregnancy status and and any smoking status that they may have had.

64
00:07:16,040 --> 00:07:21,089
So. Here is one possible way to lay out the data.

65
00:07:21,090 --> 00:07:24,870
So why is it misleading to summarize the data in this way,

66
00:07:25,740 --> 00:07:35,100
where you have the timing of the measure after pregnancy versus before pregnancy and you have this smoking size non smoker smoker.

67
00:07:37,460 --> 00:07:42,950
And so I want to just give you a second to actually actively think, you know, process this.

68
00:07:44,200 --> 00:07:49,810
And while you're thinking, I'll just talk about the table so you can come up with ideas of why this might be a bad way to summarize the data.

69
00:07:50,820 --> 00:07:56,610
So this is saying that before pregnancy there were, let's say, 150 smokers.

70
00:07:57,890 --> 00:08:03,230
And after pregnancy, there are 81 smokers. For pregnancy.

71
00:08:03,650 --> 00:08:07,760
There were 150 smokers after pregnancy, 219 smokers.

72
00:08:10,500 --> 00:08:15,570
So I mean, you're you're sort of seeing that, you know, there's fewer smokers after pregnancy.

73
00:08:16,870 --> 00:08:20,710
So what's wrong with the way this two bar two table is laid out?

74
00:08:21,160 --> 00:08:34,180
What's misleading about it? Is there some loss of data?

75
00:08:34,510 --> 00:08:43,419
Oh, yes. Thank you. Oh, gosh.

76
00:08:43,420 --> 00:08:48,820
You know what I think I've never used these things, but. Ah, these things. Have you used these before?

77
00:08:49,110 --> 00:08:54,370
I can, yeah. Okay. It just.

78
00:08:57,320 --> 00:09:01,570
After the pregnancy. When you're smokers or.

79
00:09:03,820 --> 00:09:07,330
Okay. So I'm going to paraphrase.

80
00:09:08,470 --> 00:09:11,830
And. So the comment is that.

81
00:09:13,080 --> 00:09:16,229
You have smoking behavior after,

82
00:09:16,230 --> 00:09:20,879
but there's not really a clear link to which of the people smoked before and

83
00:09:20,880 --> 00:09:25,890
changed behavior and which of the people didn't smoke before and change behavior.

84
00:09:25,890 --> 00:09:30,110
So. So that's that's correct.

85
00:09:30,140 --> 00:09:33,590
You don't get a sense of within person what happened?

86
00:09:33,590 --> 00:09:37,820
What did each person choose to do during their own pregnancy?

87
00:09:38,240 --> 00:09:45,710
So you get kind of these aggregate counts, but not within person information about switching your smoking behavior.

88
00:09:46,610 --> 00:09:53,090
That's definitely key that you're losing that information when you present the data that way.

89
00:09:53,630 --> 00:09:58,400
There's a statistical thing to to notice, and that is that if you present the data this way,

90
00:09:59,450 --> 00:10:03,590
it looks like you have 600 independent observations from women.

91
00:10:05,230 --> 00:10:17,090
And we only have 300 women. So if you put together a two by two table like this and you analyze it like you would analyze a two by two table.

92
00:10:18,070 --> 00:10:23,830
You're kind of falsely implying you have 600 people that have independent observations

93
00:10:23,830 --> 00:10:28,690
that you're measuring without any way to account for the correlation between measures.

94
00:10:28,950 --> 00:10:32,980
There's not this table doesn't tie in which measures go to which woman?

95
00:10:36,310 --> 00:10:45,430
And so if you were to put the data together like this and can I go through the motions of doing your old odds ratios, you know, the L.A. Times,

96
00:10:45,430 --> 00:10:53,230
do you ever B time C then you might compute in odds ratio that looks like this and you would say

97
00:10:53,770 --> 00:11:00,100
the odds of not smoking after pregnancy is 2.7 times the odds of not smoking before pregnancy.

98
00:11:01,900 --> 00:11:10,780
And whatever standard errors that you compute for this will be off because you have an account for the correlation.

99
00:11:11,410 --> 00:11:17,830
There's actually another problem as well, and that is that if you don't keep track of who actually chase behavior.

100
00:11:19,240 --> 00:11:23,130
This 2.7 is biased towards the null hypothesis.

101
00:11:23,140 --> 00:11:30,850
So this is closer. This is going to kind of bias the data towards no association if you don't take into account.

102
00:11:32,500 --> 00:11:36,520
The changes within women. And so we're going to see that over and over.

103
00:11:38,050 --> 00:11:43,270
And I'm going to show you how to set up a table for analysis with this data structure,

104
00:11:43,660 --> 00:11:48,010
how to get the right odds ratio, how to do all the analysis and tests that you want to do.

105
00:11:48,850 --> 00:11:56,140
And yes, we go through the head and I'll show you different examples of what to look for, for this kind of data structure so you can recognize it.

106
00:11:56,680 --> 00:12:04,210
And I'm also going to show you how to extend the method so that it's not just two measures prepare, you know,

107
00:12:04,660 --> 00:12:11,920
that you could have several controls matched to one case and still do an analysis that looks at odds ratios and that sort of thing.

108
00:12:12,610 --> 00:12:17,600
That's kind of what we're going to go. So how would we look at this data?

109
00:12:19,440 --> 00:12:22,290
Correctly. So this is just notes on the previous slide.

110
00:12:22,290 --> 00:12:31,680
The data as displayed on the previous slide incorrectly implies that you have 600 independent observations, but you have 300 before after pairs.

111
00:12:32,760 --> 00:12:34,889
And there's independence between the pairs.

112
00:12:34,890 --> 00:12:42,420
So one woman and her smoking status doesn't affect any of the other women in their smoking status, presumably.

113
00:12:43,840 --> 00:12:53,050
But there's dependants within the pair. So for instance, someone who is a nonsmoker or before pregnancy is very likely to still be a non smoker after.

114
00:12:53,650 --> 00:12:57,150
It's not like that's just an independent thing.

115
00:12:57,170 --> 00:13:05,810
It's very, very related. So the data should be summarized in terms of the 300 pairs, and this is the typical way that we do that.

116
00:13:05,900 --> 00:13:10,460
So you have. Before pregnancy.

117
00:13:10,700 --> 00:13:21,980
So that's like the status of each of the 300 women before pregnancy versus the status after pregnancy for each of the 300 women.

118
00:13:21,990 --> 00:13:31,149
So every woman is in this table only once. And 79 of them were smokers, both before and after pregnancy.

119
00:13:31,150 --> 00:13:35,520
So they stayed smokers stubbornly. And I think this is an old data set.

120
00:13:35,530 --> 00:13:39,549
So before you panic that people are just crazy.

121
00:13:39,550 --> 00:13:41,860
Smokers think this is a very dated data set.

122
00:13:43,300 --> 00:13:52,810
Which is useful because, look, there's some there's a couple of women who were nonsmokers before pregnancy and they started smoking,

123
00:13:52,810 --> 00:13:56,770
which today is just like they'd be pariahs with society.

124
00:13:57,250 --> 00:14:00,700
But we won't judge them. It's an old, old data set. Maybe they didn't know better.

125
00:14:01,900 --> 00:14:10,080
Right. And then so 148 of them were non smokers, stay non smokers and then are 71 who started off as smokers.

126
00:14:10,440 --> 00:14:12,840
But by the end of the pregnancy they were non smokers.

127
00:14:14,840 --> 00:14:21,980
So you want to know if there's an association between smoking status and the timing related to pregnancy?

128
00:14:22,040 --> 00:14:27,110
You know, just to say that if this was a significant association and what they did.

129
00:14:29,000 --> 00:14:36,710
And the problem with the early analysis is that it ignore information specific to each pair to change behavior before versus after pregnancy.

130
00:14:37,910 --> 00:14:39,319
So some of this I already mentioned.

131
00:14:39,320 --> 00:14:45,920
So an analysis that ignores the correlation between period outcome leads to a conservatively biased estimate of the odds ratio.

132
00:14:46,850 --> 00:14:52,009
So that earlier odds ratio of 2.7 was biased more towards one than it would be if we did.

133
00:14:52,010 --> 00:14:59,090
The appropriate analysis and the degree of bias will depend on how positively correlated the peer outcomes are.

134
00:14:59,750 --> 00:15:03,410
So the stronger the positive correlation is,

135
00:15:03,800 --> 00:15:09,590
it'll make it harder to reject the null hypothesis if using a statistical methods assumes zero correlation.

136
00:15:14,340 --> 00:15:19,700
So I want to get some notation together so I can talk about how we do the estimation testing.

137
00:15:19,710 --> 00:15:28,380
So if we stick with this smoking and pregnancy example and we want to assess changes in smoking behavior before and after pregnancy,

138
00:15:28,380 --> 00:15:39,090
we focus upon two probabilities that describe within pair changes, and the subscripts here are chosen to hopefully be helpful by this point.

139
00:15:39,840 --> 00:15:45,600
In statistics classes, you probably are always associated one zero variables with yes no.

140
00:15:45,600 --> 00:15:49,380
So one is usually stands for yes, zero stands for no.

141
00:15:49,620 --> 00:15:55,980
And I do that too. So this first subscript is their smoking status before.

142
00:15:56,040 --> 00:16:02,130
So one is a yes. And the second subscript is their smoking status after.

143
00:16:02,520 --> 00:16:07,540
So zero is a no. So p10 is given.

144
00:16:07,540 --> 00:16:12,670
They were a smoker before. What's the probability they're a non smoker after?

145
00:16:13,780 --> 00:16:17,500
So is the probability of changing from a smoker to a non smoker.

146
00:16:19,440 --> 00:16:22,979
And p01 is so the zero was first.

147
00:16:22,980 --> 00:16:27,959
So given they were nonsmoker before was the probably they were a smoker after.

148
00:16:27,960 --> 00:16:32,670
So both of these are probabilities of changing their smoking behavior.

149
00:16:34,740 --> 00:16:39,899
And if the timing in relation to pregnancy has no effect on the smoking status,

150
00:16:39,900 --> 00:16:45,900
then you would expect that there would be very similar probabilities here.

151
00:16:45,930 --> 00:16:54,630
So if every smoker who quits is canceled out by a non smoker start smoking, then really pregnancy have nothing to do with these behavior changes.

152
00:16:55,470 --> 00:16:59,760
So that's the null hypothesis that this p10001.

153
00:17:01,920 --> 00:17:06,840
And that equality, that null hypothesis is known as marginal homogeneity.

154
00:17:07,650 --> 00:17:11,639
And I never use this phrase. I only put the phrase in the handout.

155
00:17:11,640 --> 00:17:16,860
So if you see it somewhere as you're reading other outside materials, you'll know what they're talking about.

156
00:17:17,430 --> 00:17:21,190
I personally don't use this phrase, so you'll never hear it from me again.

157
00:17:21,210 --> 00:17:29,370
But in your materials, if you see marginal homogeneity in this context with pure data, you're just talking about the null hypothesis.

158
00:17:33,610 --> 00:17:39,860
All right. So if we look at the data, we can easily get these probabilities.

159
00:17:39,870 --> 00:17:48,740
So the probability that given they were a smoker before that they changed to a non smoker.

160
00:17:50,150 --> 00:17:54,980
Is this count over 150. Right.

161
00:17:56,200 --> 00:18:05,920
And the probability that given they were nonsmoker before they changed to a smoker is two over 150.

162
00:18:07,720 --> 00:18:14,320
So if these estimates look quite different, so that's a strong indication that marginal homogeneity is violated.

163
00:18:14,320 --> 00:18:20,640
And sorry, I said I would never use again, but I guess I did one more time. The null hypothesis is violated.

164
00:18:22,420 --> 00:18:29,350
So we've only used these two counts, these just in the B cell, the C,

165
00:18:29,370 --> 00:18:38,740
so to estimate these and that's going to be a common theme that it's the cells where there is a change.

166
00:18:40,140 --> 00:18:46,500
That are going to drive the analysis. So the cells, the B cells and the C cells that are different.

167
00:18:47,940 --> 00:18:52,950
Where there's a change, we call those discordant incels. And that's actually a phrase I will use again and again.

168
00:18:53,010 --> 00:18:58,889
Discordant spells, meaning there was a change in the concordant cells or the A in a D cells.

169
00:18:58,890 --> 00:19:02,310
So that's where they were smoking instead of smokers. So no change.

170
00:19:02,310 --> 00:19:10,500
That's concordant smoking status in 79 people and concordant non smoking status in 148 people.

171
00:19:10,830 --> 00:19:20,489
So discordant and concordant. I do use that a lot just because we're going to have to look at these ABCD and I can group the the B and

172
00:19:20,490 --> 00:19:25,170
the C cells together and call them discordant in the and the D cell together and call them concordant.

173
00:19:25,170 --> 00:19:35,960
And it's just good shorthand. So we want to see if the you know, if those probabilities are statistically different from one another.

174
00:19:37,130 --> 00:19:44,980
You know, you're used to kind of doing this. And probably the first structure of the test that you would look at would be something like this.

175
00:19:44,990 --> 00:19:46,550
You have two probabilities.

176
00:19:46,880 --> 00:19:56,480
No hypothesis is that there is a same figure out the variability to a test statistic, and that's certainly a reasonable thing to do.

177
00:19:56,990 --> 00:20:08,030
However. Such a statistic is rarely used because it was preceded by another statistic first that was recommended by McNamara in 1947.

178
00:20:08,390 --> 00:20:14,810
So even though this is what you would think to do immediately, there's another test that's done that I'll show you instead.

179
00:20:15,440 --> 00:20:20,240
And so McNamara test conditions on the sum of the discordant cells.

180
00:20:20,420 --> 00:20:26,630
So the B and C cells. And for us, that's, you know, people who were smoking that quit.

181
00:20:27,260 --> 00:20:36,060
Plus people who were non smoking. It started. And so those are all the people who changed the count of people who changed.

182
00:20:36,840 --> 00:20:44,980
And if the normal path is. This is true. Then the people who changed behavior should be equally distributed among both discordant cells.

183
00:20:44,990 --> 00:20:57,870
So on average, the count who smoked and quit and the count who didn't smoke and started should be and start over too.

184
00:20:57,880 --> 00:21:02,709
So the sum of everybody you changed over to. So it's like kind of observed and expected.

185
00:21:02,710 --> 00:21:07,200
We're kind of creating here. And put another way.

186
00:21:08,630 --> 00:21:17,270
You know, and one zero over the total or in zero one over the total has an approximately normal distribution

187
00:21:17,810 --> 00:21:22,610
where you expect that proportion to be about half have switched to one way or the other.

188
00:21:23,090 --> 00:21:30,450
And because that's a p hat, you know, the variability of a of a P hat would have a point,

189
00:21:30,530 --> 00:21:35,480
you know, p times one minus P over the total as the variability so that pops in there.

190
00:21:36,290 --> 00:21:40,100
And so this would be a basis for constructing a test statistic.

191
00:21:42,590 --> 00:21:47,300
So an approximate normal zero one version of the McNamara statistic comes with some algebra.

192
00:21:47,900 --> 00:21:56,870
The observed counts the observed p hat for a smoker becoming a non smoker minus what

193
00:21:56,870 --> 00:22:00,440
should happen under the null hypothesis that about half of them do that switch?

194
00:22:01,620 --> 00:22:07,470
Divided by some variability, you know, for that part and we have a little bit of algebra,

195
00:22:08,160 --> 00:22:13,710
it reduces to a test statistic that really only uses the discordant cell counts.

196
00:22:14,590 --> 00:22:19,540
And so this is an interest that textbooks if you ever covered this test,

197
00:22:19,840 --> 00:22:27,490
you would have just seen this part of the statistic and maybe or maybe not go through the logic of why that's what's done.

198
00:22:30,560 --> 00:22:30,970
All right.

199
00:22:33,290 --> 00:22:42,910
And as you've seen, as you've been working your homework and in other classes, you now open the square version of McNamara's Tarts is presented.

200
00:22:42,920 --> 00:22:47,240
So if it's the one on the left, it is like a normal zero 100 hypothesis.

201
00:22:48,020 --> 00:22:54,889
Whenever you square a normal zero one statistic, it has a chi square one distribution under the North caucuses.

202
00:22:54,890 --> 00:22:57,110
So depending on your software package,

203
00:22:57,440 --> 00:23:04,580
you'll either see it reported as a Z score with a P value or you'll see it reported as a chi squared one with a p value.

204
00:23:05,480 --> 00:23:10,700
And so in SAS I know that they print out the squared version, the chi square one version.

205
00:23:13,390 --> 00:23:21,240
And some packages will do a version of this test where they have a little minus one squeezed in here.

206
00:23:21,250 --> 00:23:28,420
That's called a continuity correction, and it's meant to make it even closer to a Chi Square distribution.

207
00:23:30,640 --> 00:23:38,650
So I. I just wanted to warn you, if you see differences, it's that maybe that package is using a continuity correction.

208
00:23:38,650 --> 00:23:45,280
You need to check for an option to uncheck that if you want it to agree with what Sass does.

209
00:23:47,990 --> 00:23:58,160
So in our example, when we look at the difference in the discordance so squared over the sum, this is the chi square version of this statistic.

210
00:23:58,880 --> 00:24:05,990
It's huge. So if you remember for our chi squared one, the critical value is 3.84.

211
00:24:06,020 --> 00:24:11,990
So whenever you get a test statistic that's greater than 3.84, you get excited about it being highly significant.

212
00:24:12,440 --> 00:24:19,150
This is 65.2. So the P value is going to be less than .0001.

213
00:24:19,160 --> 00:24:21,590
You know, we'll see in the software how it gets reported.

214
00:24:22,530 --> 00:24:29,189
But we conclude that the probability of changing from a smoker to a non smoker across the course of a

215
00:24:29,190 --> 00:24:35,100
pregnancy is a significantly higher than the probability of changing from a non smoker to a smoker.

216
00:24:37,380 --> 00:24:40,709
So it's not a p value is not a very satisfying analysis.

217
00:24:40,710 --> 00:24:44,700
We want that odds ratio to report from our manuscript where the sentence is.

218
00:24:44,700 --> 00:24:48,240
We always want an effect size. Here would be an odds ratio.

219
00:24:48,510 --> 00:24:58,649
We want a 95% confidence interval. We want to put the direction of what's happening in the sentence itself and we want a p value.

220
00:24:58,650 --> 00:25:02,040
So we've got the p value here. We need the odds ratio and the confidence interval.

221
00:25:03,310 --> 00:25:10,000
So we'd like a value that summarizes the odds of smoking before versus after pregnancy and its own corresponding confidence interval.

222
00:25:14,030 --> 00:25:17,030
So in the peer data setting, it's a really easy formula.

223
00:25:17,030 --> 00:25:22,069
So we can calculate a conditional odds ratio estimate that compares the odds of smoking before

224
00:25:22,070 --> 00:25:29,630
pregnancy to the odds of smoking after pregnancy by looking at the ratio of the discordant cell counts.

225
00:25:29,810 --> 00:25:36,740
So this is the number of people who were smoking and then quit over the number of people who didn't smoke and then started.

226
00:25:37,160 --> 00:25:46,639
So in the example, it's 35.5 is our conditional odds ratio that takes into account that you know,

227
00:25:46,640 --> 00:25:51,590
that these are measures of before and after in the same women, you know, that they're paired.

228
00:25:53,120 --> 00:26:03,260
And so that's quite different from 2.7 that we calculated based on representing the data, 600 independent observations.

229
00:26:04,010 --> 00:26:08,780
So this is a common thing that if you ignore the correlated pairs,

230
00:26:09,140 --> 00:26:14,300
you're going to have an estimate that's much closer to the null hypothesis of an odds ratio of one,

231
00:26:15,170 --> 00:26:18,350
as opposed to the odds ratio that's really catching that.

232
00:26:18,710 --> 00:26:22,160
There's a lot more people, a lot more women who quit smoking.

233
00:26:26,780 --> 00:26:31,250
So ignoring the apparently too much weaker estimated effect of the intervention.

234
00:26:33,690 --> 00:26:38,040
So I'm just giving you the formula. But where does the odds ratio estimate come from?

235
00:26:38,220 --> 00:26:41,940
It's not like a DBC anymore, right? So why is it this?

236
00:26:42,890 --> 00:26:48,980
And at first glance it looks more like an odds estimate rather than an odds ratio.

237
00:26:48,980 --> 00:26:52,990
That is, you know what, if you just look at that, count it,

238
00:26:53,040 --> 00:27:01,520
it really does look like given there's a behavior change, what's the odds that a smoker becomes a non smoker?

239
00:27:02,510 --> 00:27:10,250
And so that is one way you could interpret it. So given there's a behavior change, the probability a smoker becomes a non smoker.

240
00:27:10,850 --> 00:27:19,480
Is this count over this total count for the scoring cells and the probability that a non smoker becomes a smoker given this

241
00:27:19,490 --> 00:27:30,200
behavior change is this and so that the total number of people with behavior changes that some cancels and you get this ratio.

242
00:27:31,950 --> 00:27:35,130
So that's one way to interpret it. And you can write your sentences.

243
00:27:36,780 --> 00:27:45,990
That in terms of this ratio. So given there's behavior change, they were more likely to become a smoker.

244
00:27:47,160 --> 00:27:51,810
Then to become a non, they were more likely to become a nonsmoker than a smoker.

245
00:27:53,260 --> 00:28:00,909
So you can do that. But there is a justification for the conditional odds ratio that comes from mental hassle

246
00:28:00,910 --> 00:28:07,120
estimation of a common odds ratio adjusted across all the individual pairs or cluster levels.

247
00:28:07,840 --> 00:28:14,470
So let's just kind of break that down a little bit. So what I'm saying is if you take.

248
00:28:15,410 --> 00:28:23,100
Each pair of women. And you create your own two by two table with just those two measures in it.

249
00:28:23,520 --> 00:28:27,840
For that one woman, you'll have 300 tables like this.

250
00:28:28,920 --> 00:28:35,340
And if you combine odds ratios for each of those 300 tables.

251
00:28:36,670 --> 00:28:40,300
Using a manual handle technique, you will get the same result.

252
00:28:40,660 --> 00:28:46,840
So I'm going to show you that really briefly. So.

253
00:28:49,810 --> 00:28:54,610
The mantle had for pooled odds ratio estimate across the end pairs is going to look like this formula.

254
00:28:54,610 --> 00:28:58,090
So we have 300 women. So that's the big end.

255
00:28:59,780 --> 00:29:06,710
And the eye is going over each pair of observations in the same woman.

256
00:29:06,830 --> 00:29:11,630
So this nine is the number of observations in general.

257
00:29:11,660 --> 00:29:14,809
The number of observations in your cluster correlated?

258
00:29:14,810 --> 00:29:24,020
Yes, no outcomes. So in our example, now is always two because we have two measures in each woman before pregnancy, after pregnancy.

259
00:29:25,500 --> 00:29:35,459
And so we're going to create two by two tables for each woman with each woman and calculate their eight times D and calculate their B,

260
00:29:35,460 --> 00:29:39,210
times C and so on, and do this mantle here for odds ratio.

261
00:29:44,540 --> 00:29:54,140
And this is, you know, very, very small sample sizes in these tables now is going to be to, for example, that's going to give you some zeros in here.

262
00:29:54,680 --> 00:30:02,389
And so remember how when we talked about meta analysis in the mental handle odds ratio approach,

263
00:30:02,390 --> 00:30:05,570
we also in your homework as well had this alternative method,

264
00:30:05,960 --> 00:30:12,230
the well for the inverse variance method and we said don't use the wolf method when cell counts are small.

265
00:30:13,050 --> 00:30:18,050
In fact, in your homework you kind of see how you have to do things when you have zero cell counts.

266
00:30:18,050 --> 00:30:23,120
And then for your study, that's a lot of work. So here we're going to have to zero cell cancel over the place.

267
00:30:23,120 --> 00:30:27,010
So we can't use the wolf estimate for the coming out version. We have to use manual here.

268
00:30:27,020 --> 00:30:33,140
So unfortunately, Hazel does really, really well, even with a lot of zeros in these tables.

269
00:30:37,590 --> 00:30:41,280
So so just a handful techniques applied to match data.

270
00:30:41,640 --> 00:30:45,730
You know, we've kind of looked at this already sort of previous biostatistics of epidemiology.

271
00:30:45,730 --> 00:30:46,049
Of course,

272
00:30:46,050 --> 00:30:53,940
you may see the mantle hits the odds ratio constructed from a series of tables displaying associations within different levels of a confounder.

273
00:30:54,720 --> 00:31:01,320
So this is typically your first taste of mantle. HANSELL You know that there's a confounder that's got several levels to it,

274
00:31:01,920 --> 00:31:07,370
and you calculate the odds ratio on each one of those, and then you combine those using mantle.

275
00:31:07,380 --> 00:31:11,800
Hansell And so you adjust for confounding. Where the confounder is.

276
00:31:11,800 --> 00:31:19,540
The different the different tables. And in our inmate analysis discussion from Handout two,

277
00:31:19,540 --> 00:31:25,300
we used a very similar idea where study was the confounder, if you want to think about it that way.

278
00:31:26,170 --> 00:31:32,440
And we used the middle here estimate to construct an overall odds ratio estimate across studies.

279
00:31:33,530 --> 00:31:40,129
And so here this is yet a third time we look at the mantle, Hansel, to help us out.

280
00:31:40,130 --> 00:31:45,650
And so here would be Brad. It's matched pair or matched set as a separate stratum.

281
00:31:46,130 --> 00:31:49,530
So it's as if we're saying something to the effect of, you know,

282
00:31:49,550 --> 00:31:54,470
each person has enough stuff that's different about them to be a potential confounder.

283
00:31:55,410 --> 00:32:03,990
And so we're going to adjust for all of those unmeasured things that make those, you know, that make that affects that person's chance of.

284
00:32:05,000 --> 00:32:11,030
Change in behavior and affects that chances person's chance of having the before versus after.

285
00:32:17,290 --> 00:32:21,730
So we're going to have one table for each of these 300 paired before and after outcomes.

286
00:32:22,700 --> 00:32:29,989
And just going through the four types of you know, there's two concordant cells, two discordant cells.

287
00:32:29,990 --> 00:32:36,910
So there's 148 tables where the mother is a nonsmoker, both before and after pregnancy.

288
00:32:36,920 --> 00:32:40,850
That's like enduring zero. And that was the ACL, the 148.

289
00:32:43,240 --> 00:32:47,920
And so what would those tables look like? So here's a table for each woman.

290
00:32:47,930 --> 00:32:51,880
They are all going to look the same for for these 148 women.

291
00:32:53,070 --> 00:32:57,600
Where they were, you know, a nonsmoker, both before and after pregnancy.

292
00:33:00,770 --> 00:33:16,220
So they're a B, C, D. Within woman you know we're going to have a times D is going to be zero and B times C is also going to be zero.

293
00:33:16,760 --> 00:33:24,979
So for all of these tables, when we sum up the part of the mental handle that concerns these types of women who were smokers,

294
00:33:24,980 --> 00:33:29,380
all the were all the time. They're not going to contribute to the numerator.

295
00:33:29,390 --> 00:33:31,540
They're not going to contribute to the denominator.

296
00:33:32,540 --> 00:33:38,870
So these people who didn't change behavior, they don't contribute anything to dismantle harmful odds ratio.

297
00:33:40,580 --> 00:33:44,959
So there's 71 tables that are just scored right.

298
00:33:44,960 --> 00:33:48,830
The subscripts change. So they were smoker before, non smoker after.

299
00:33:50,470 --> 00:33:59,960
And when you look at those 71 tables. Here's the two measures in in that type of woman and before pregnancy smoker.

300
00:34:01,740 --> 00:34:06,240
After pregnancy. Nonsmoker. So there a and there D cells are both one.

301
00:34:08,470 --> 00:34:14,560
So when we sum up that part of the medical Hansell odds ratio, we're going to have 471 tables,

302
00:34:14,560 --> 00:34:21,940
we're going to have eight times D is one and is two, so that some will be like 71 over two.

303
00:34:24,400 --> 00:34:27,730
And the B and C cells will contribute anything.

304
00:34:28,900 --> 00:34:35,470
So the discordant pairs contribute to the numerator for these 71 women.

305
00:34:37,520 --> 00:34:42,530
And there's two tables where they switch from a nonsmoker to a smoker.

306
00:34:42,980 --> 00:34:52,800
Those tables look like this. So before non smoker after smoker and the eight times D cells are zero, the B times C cells are one.

307
00:34:53,580 --> 00:34:56,639
So they're not going to contribute anything to the numerator of the manual hand.

308
00:34:56,640 --> 00:34:59,280
So for those two tables, but for the denominator,

309
00:35:00,120 --> 00:35:09,630
those two women who had that behavior switch of this kind will have a B times C of one and I have two and there's two of them.

310
00:35:10,380 --> 00:35:13,830
So that'll that'll end up being one.

311
00:35:16,140 --> 00:35:19,320
So these discordant pairs contribute to the denominator of the mantle.

312
00:35:19,320 --> 00:35:22,600
Cancel. Odds ratio estimate.

313
00:35:22,900 --> 00:35:30,220
And then we have the last concordant seller, 79 tables where the mother was a smoker, both before and after pregnancy.

314
00:35:30,940 --> 00:35:34,780
And those tables will look like this. So they were smoker both before and after.

315
00:35:35,530 --> 00:35:39,879
And eight times D is going to be zero. The B times is going to be zero.

316
00:35:39,880 --> 00:35:46,900
So there's no part of the mental Hansell statistic that's going to change based on these 79 women.

317
00:35:47,800 --> 00:35:52,150
Right. So we've actually 3300 tables.

318
00:35:52,150 --> 00:36:00,460
We've got how all of them are going to behave. And so it's just a matter of putting together the numbers that we've got on those slides.

319
00:36:01,000 --> 00:36:07,210
So the mental health odds ratio for the paired data is going to become, you know,

320
00:36:08,020 --> 00:36:13,479
zero plus one half times the count of women who changed from smokers to nonsmokers,

321
00:36:13,480 --> 00:36:20,890
4000 plus zero plus one half times the number of nonsmokers who started smoking.

322
00:36:21,460 --> 00:36:27,250
And the one half are going to cancel out. And that's where this formula that we saw earlier comes from.

323
00:36:28,710 --> 00:36:32,550
So that same ratio of the discordant cell counts is our conditional odds ratio,

324
00:36:32,550 --> 00:36:41,220
where you take into account the correlation and in smoking status both before and after pregnancy, when you're looking at the same woman.

325
00:36:42,140 --> 00:36:47,330
So it's the same number we got before, but it came entirely from the mental Hansell statistic.

326
00:36:50,730 --> 00:36:55,050
So I have some formulas here in case you learn best by hand.

327
00:36:56,220 --> 00:36:59,400
So for large values of the discrete cell counts.

328
00:37:00,490 --> 00:37:06,550
There are estimates of the variability of the log odds ratio and confidence limits that you can calculate.

329
00:37:08,350 --> 00:37:13,320
And then you can exponential the lower and upper limits of the confidence limits,

330
00:37:13,450 --> 00:37:17,350
you know, the way you usually do when you find that on a large scale.

331
00:37:19,280 --> 00:37:22,670
There's actually one thing I want to have you perk up for here.

332
00:37:22,680 --> 00:37:26,959
I don't want you to focus too much on the computations by hand in general,

333
00:37:26,960 --> 00:37:35,420
but I wanted to give you a heads up that sometimes when I'm reporting the confidence intervals for the odds ratio,

334
00:37:35,420 --> 00:37:45,440
I'll write it a slightly different way. And so if you exponential rate this entire formula.

335
00:37:47,040 --> 00:37:51,690
E to the log of this race. So it's just going to be like the odds ratio again itself.

336
00:37:52,260 --> 00:37:57,420
And then this plus or minus will end up being e to the rest of the stuff.

337
00:37:58,260 --> 00:38:09,960
So sometimes what I will do is write the 95% confidence interval for the odds ratio as the odds ratio itself times e to the rest of this stuff.

338
00:38:11,180 --> 00:38:17,270
It's algebraically the same. It's just shorthand because I've already got the odds ratio handy.

339
00:38:18,080 --> 00:38:25,190
So the odds the odds ratio itself times e to the rest of the stuff here, sometimes just shorter to do.

340
00:38:25,550 --> 00:38:30,709
And there's an example later in the handout where I do this and I just didn't want to throw that at you before I warned you.

341
00:38:30,710 --> 00:38:35,060
I sometimes do that, and I think if this formula is interchangeable,

342
00:38:35,750 --> 00:38:39,740
I just don't want you to get thrown by the fact that I do it different ways at different times.

343
00:38:45,490 --> 00:38:51,590
All right. So just for those. Students who really do learn best by hand.

344
00:38:51,600 --> 00:38:54,200
I'm giving some of the hand calculations here.

345
00:38:54,210 --> 00:39:02,820
So here is for our table the variance of the log odds ratio and 95% confidence intervals here on the log scale.

346
00:39:05,780 --> 00:39:12,770
And then if you exponential rate the limits here is the 95% confidence interval for the the crucial odds ratio.

347
00:39:17,180 --> 00:39:20,540
So we are actually some very small cell counts.

348
00:39:20,640 --> 00:39:29,420
We had that cell count. That was two. And, you know, so there's some literature that says that small this great cell counts require adjustment.

349
00:39:29,420 --> 00:39:32,750
And so I have a couple of slides on how people do that.

350
00:39:33,020 --> 00:39:36,430
It's not in general, it's not in the software.

351
00:39:36,440 --> 00:39:43,660
So this you may not see these results come up just because software doesn't seem to have caught on to this idea.

352
00:39:43,670 --> 00:39:50,270
But I thought I would put them in the slides just so that if someone ever mentions that, you'll know that this exists.

353
00:39:50,780 --> 00:39:59,270
So this is small values of N1 001 McNamara's test and the confidence interval just discussed are less reliable.

354
00:39:59,720 --> 00:40:03,350
And so here I just kind of for your notes.

355
00:40:03,350 --> 00:40:12,560
This is just for your own personal benefit, not something I'm going to be covering as an outcome that you own at the end of the course.

356
00:40:13,310 --> 00:40:23,180
But you can have a confidence interval for the hypothesis test situation where this is the lower limits, this is the upper limits.

357
00:40:23,450 --> 00:40:37,310
And these little things, kind of the script F with L and you you get that from the 97.3% of the S to F distribution with these degrees of freedom.

358
00:40:38,710 --> 00:40:46,210
So in the privacy of your own room, if you're interested in how this comes about, you want to play with it.

359
00:40:47,110 --> 00:40:53,830
There are some notes on how to get those values for this little example.

360
00:40:55,000 --> 00:41:00,820
And the 95% confidence interval where you use this kind of small sample version.

361
00:41:00,830 --> 00:41:05,560
And so these are and end up being your confidence limits when you do this.

362
00:41:06,070 --> 00:41:09,040
Again, I don't think software packages incorporate this at all.

363
00:41:09,580 --> 00:41:16,899
So you may never see this used in practice, but there may be some person someday who says, Why didn't you do this in a review?

364
00:41:16,900 --> 00:41:23,950
And you'll know what they're talking about now. Okay.

365
00:41:24,130 --> 00:41:27,400
So that's the general gestalt of pair data.

366
00:41:27,400 --> 00:41:33,850
So I just wanted to make sure that you thought about different ways this can happen.

367
00:41:33,850 --> 00:41:39,700
So to this point, the matching occurred because we have repeated or longitudinal measurements on each subject.

368
00:41:39,700 --> 00:41:42,940
So each woman was paired with her self with the before or after.

369
00:41:43,820 --> 00:41:51,110
Right. Let's look at another example. And this time the matching is done by pairing each individual with another similar individual.

370
00:41:52,870 --> 00:41:59,949
And so this is a case control study. Where are the effect of estrogen use on the risk of endometrium?

371
00:41:59,950 --> 00:42:04,419
Cancer was looked at and the exposure was estrogen use.

372
00:42:04,420 --> 00:42:08,379
Yes. Now. And the outcome is the presence of enemy throat cancer.

373
00:42:08,380 --> 00:42:18,470
Yes. No. And the pairing came out because each control was matched to each case.

374
00:42:18,800 --> 00:42:23,720
So there were 183 cases. So there will be 183 matched controls.

375
00:42:24,200 --> 00:42:30,770
And the matching information was related to age, race, hospital admission and the date of the hospital admission.

376
00:42:32,950 --> 00:42:42,070
So this is what the data looked like. And so this is the if you accidentally ignore the matching, this is the odds ratio that you would get.

377
00:42:42,340 --> 00:42:51,460
I mainly just have this here so you can see how much it biases your estimates if you assume that matching wasn't an issue.

378
00:42:52,150 --> 00:42:54,879
So you can put a big red X through this 3.7,

379
00:42:54,880 --> 00:43:01,420
but I want you to have that number in mind when we eventually see the correct odds ratio, how much it biased it towards one.

380
00:43:03,390 --> 00:43:11,719
And so if you consider the matching. And you look at the ratio of the discordant cells, your odds ratio is much higher, right?

381
00:43:11,720 --> 00:43:19,450
6.1. And here's an example where I used that trick for the confidence interval,

382
00:43:19,450 --> 00:43:24,909
where I just take the odds ratio from here and I multiply it in front and then

383
00:43:24,910 --> 00:43:30,640
I do e to the rest of the confidence limit part to get the confidence interval.

384
00:43:30,650 --> 00:43:37,740
So that's what's happening there. And in the privacy of your own room.

385
00:43:37,770 --> 00:43:43,080
You can look through the calculations there, really just the same mechanics that we saw with the first example.

386
00:43:43,380 --> 00:43:46,410
So I have it here in case you want to practice more by hand.

387
00:43:46,920 --> 00:43:52,020
But the main point of these slides was to just give you different settings where you'd want to use these methods.

388
00:43:52,710 --> 00:43:56,670
So this is just an example of McNamara's test for this situation.

389
00:43:57,750 --> 00:44:05,310
This is conducted on the Chi Square one level because you've got the square of the difference in the discordant cell counts over the thumb.

390
00:44:05,970 --> 00:44:13,110
And so this is supposed to be significant if it's greater than 3.84 and it's quite a lot bigger with a very small p value.

391
00:44:14,640 --> 00:44:19,950
And so a manuscript worthy sentence that you might write based on this analysis is

392
00:44:19,950 --> 00:44:26,330
that the exposure to estrogen significantly increased the odds of endometrial cancer.

393
00:44:26,440 --> 00:44:30,360
That's the direction. It increased the odds.

394
00:44:30,480 --> 00:44:39,150
So we got the direction there. And then you have the effect size, the 6.1 conditional odds ratio, confidence interval and p value.

395
00:44:39,210 --> 00:44:43,070
So it has all four ingredients of the sentence. Direction.

396
00:44:44,220 --> 00:44:46,770
Effect size confidence interval p value.

397
00:44:52,010 --> 00:44:58,740
So in terms of software, I haven't really shown you much about how to do that, although you've done some mental handling before.

398
00:44:58,760 --> 00:45:04,250
So the main work here is going to be in setting up the data correctly to use mental Hansel techniques.

399
00:45:05,090 --> 00:45:12,260
So those are going to be what we use in both SASS and R to handle paired data of yes no outcomes.

400
00:45:12,260 --> 00:45:17,030
So the paired odds ratio estimate is going to come from a mental Hansell odds

401
00:45:17,030 --> 00:45:21,960
ratio estimate with one stratum for each pair so you know how to do mental health,

402
00:45:22,010 --> 00:45:25,969
but setting up the data is going to be the part that's the learning of how to

403
00:45:25,970 --> 00:45:29,330
set up the data correctly so that mental health will give you the right answer.

404
00:45:30,340 --> 00:45:34,100
And the confidence intervals for the trans racer can also be obtained for mental health.

405
00:45:34,100 --> 00:45:39,730
So odds ratio output. And it turns out that if you have matched pairs,

406
00:45:40,480 --> 00:45:46,209
McNamara's task is equivalent algebraically to the Cochrane Mental Hansell statistic

407
00:45:46,210 --> 00:45:50,830
that you used for the significance of an odds ratio pooled across individual pairs.

408
00:45:51,490 --> 00:45:54,700
So even though we talked about it as this ratio.

409
00:45:58,440 --> 00:46:04,910
You know the difference between the scoring so counts over you know the some with some.

410
00:46:05,610 --> 00:46:09,420
Scaling like the different squared over the sum of discordant cells.

411
00:46:10,230 --> 00:46:17,310
The algebra is going to end up being the same as what you would do if you recalculate the complementary statistic.

412
00:46:18,430 --> 00:46:23,860
With all of the individual tables for each of the pairs.

413
00:46:25,620 --> 00:46:29,760
So I'm going to show you how to do that in the output, and I'll show you that they're the same.

414
00:46:30,830 --> 00:46:36,200
But the mental Hansell relationship is useful because it generalizes.

415
00:46:36,350 --> 00:46:40,310
McNamara's test is only good for pairs. Quality pairs.

416
00:46:41,660 --> 00:46:45,800
But sometimes you have more than one control per case that you've matched,

417
00:46:46,550 --> 00:46:52,490
or sometimes you have two cases and three controls that are matched, you know.

418
00:46:52,850 --> 00:46:58,370
So the mental handle relationship generalizes to stuff that's not just pairs,

419
00:46:58,790 --> 00:47:03,800
but different clusters of people who are correlated for some reason that they were matched.

420
00:47:05,120 --> 00:47:15,030
And so. Going through the metal hansol method is is worth it for that reason alone that it generalizes so nicely.

421
00:47:16,880 --> 00:47:22,480
So let's look. At this example of paired data.

422
00:47:24,070 --> 00:47:29,110
And how you would set up the data for the company to handle statistics.

423
00:47:29,160 --> 00:47:35,730
You have 183. We have correlated pairs.

424
00:47:36,790 --> 00:47:43,390
And the pairs are similar 12 times where they're both the case that controller exposed.

425
00:47:45,070 --> 00:47:52,360
43 times. They're going to look similar where the cases are exposed, but the control is not and so on.

426
00:47:52,360 --> 00:48:00,880
So you need a table for each matched pair, but you kind of only need to figure out four types of tables.

427
00:48:02,320 --> 00:48:07,960
And then know how many of the individuals contribute to the different four types of tables.

428
00:48:10,280 --> 00:48:16,879
And actually this is a good time to stretch, I think, because, you know, your brain really needs to perk up to see what's happening here.

429
00:48:16,880 --> 00:48:20,970
And I want to make sure that you get a chance to stretch so that we can dove in.

430
00:48:21,000 --> 00:48:28,970
Most of the work is going to be setting up the data and then use commands of users in yourself of before for getting these observations and tests.

431
00:48:29,480 --> 00:48:33,800
So let's take a ten minute break and we'll be back at 9 a.m.

432
00:48:59,480 --> 00:49:08,390
It's hard to.

433
00:49:11,190 --> 00:49:27,370
My. And so I just, uh.

434
00:49:28,000 --> 00:49:40,070
Uh. You still are. But I still have the same clothes.

435
00:49:40,580 --> 00:49:47,310
But I can only come. Okay.

436
00:49:47,330 --> 00:49:52,530
So I did just have a movie out here about that very issue.

437
00:49:52,590 --> 00:49:58,470
Oh, yeah. Yeah, they did. Because they, uh, they updated the matrix in the package.

438
00:49:58,500 --> 00:50:03,570
Yeah, I think so. In the announcement. If you go to the Kansas City.

439
00:50:06,630 --> 00:50:16,130
Oh, it's that one. Yeah. So this is how to load the old package that I fly through.

440
00:50:16,420 --> 00:50:22,610
So if I. If we knew how to just pick different outputs, it's not.

441
00:50:22,620 --> 00:50:26,370
You didn't do anything wrong. It's just that they changed the way they should be out here.

442
00:50:27,180 --> 00:50:35,270
So you have the whole package. They change some different outputs so that we have that's do.

443
00:50:36,700 --> 00:50:41,079
Right. Right. So you just choose instead of. So you're overloaded.

444
00:50:41,080 --> 00:50:44,350
Okay, I just load it and then you'll see exactly what I saw. Okay.

445
00:50:44,740 --> 00:50:51,380
And also, I'm wondering if this become one. I didn't want to do that for now.

446
00:50:52,060 --> 00:50:55,300
So I'm wondering if.

447
00:50:57,250 --> 00:51:04,320
Is the problem too serious to decide which should be the right.

448
00:51:04,770 --> 00:51:09,970
Right. Right. So the table works and everything on the scale.

449
00:51:10,870 --> 00:51:16,580
So that's going to be the scale that you do the power. It'll be all on the logout process.

450
00:51:16,990 --> 00:51:20,740
So you want to find the standard error of the log odds ratio?

451
00:51:20,740 --> 00:51:24,260
That's the smallest slender error I found.

452
00:51:25,290 --> 00:51:33,920
So I have some code further down in where I calculate the standard error by here.

453
00:51:36,280 --> 00:51:41,290
Uh, I think it's maybe further. It might be one of the leaders like major.

454
00:51:41,830 --> 00:51:46,630
I think so. Oh.

455
00:51:48,040 --> 00:51:52,060
Oh, it's right here. It's right here on your screen.

456
00:51:52,750 --> 00:51:56,590
So that this is the standard error of the log odds ratio.

457
00:51:57,070 --> 00:52:03,490
I take the one you picked, the one that's the smallest, and that's where you want off the top of your funnel to be.

458
00:52:04,390 --> 00:52:13,270
So wherever. So whatever the problem was, where you created the table, you should have log odds, ratio estimates and standard error for column.

459
00:52:13,270 --> 00:52:16,540
Okay. So you want to center the funnel.

460
00:52:17,410 --> 00:52:21,430
There's a ref line command in the center of the funnel.

461
00:52:21,880 --> 00:52:24,940
Okay. And you're putting that around the log.

462
00:52:24,940 --> 00:52:29,200
That's where it has the smallest care center in.

463
00:52:30,510 --> 00:52:34,200
You know, you got it right, because the line will be straight through the half dog.

464
00:52:34,500 --> 00:52:37,620
Yes. So you could even double check.

465
00:52:38,490 --> 00:52:45,280
Thank you, sir. But for.

466
00:52:47,850 --> 00:52:51,970
And. Bad.

467
00:53:07,750 --> 00:53:15,690
I don't think this question makes any sense for our estimates affective in any meaningful way on just one or two factors as opposed to right.

468
00:53:16,590 --> 00:53:19,740
Ten or something like that. Do they change in any kind of way or is it pretty much?

469
00:53:20,760 --> 00:53:25,350
Or is that just kind of included? So that's a really good question.

470
00:53:25,590 --> 00:53:32,630
Right. So when you're matching on more than one thing, it's clear, right?

471
00:53:33,390 --> 00:53:37,379
It's making them more correlated. Right. You're trying to control for more confounders.

472
00:53:37,380 --> 00:53:42,200
So the more confounders you control for the left, by your estimate is going to be right.

473
00:53:42,270 --> 00:53:52,950
Okay. So the things you want to match on things where the matching factor is both related to the yes no outcome and the yes, no exposure or otherwise.

474
00:53:52,950 --> 00:53:57,330
If it's not related to one of those, it's a waste of time that you don't need it to match on it.

475
00:53:57,540 --> 00:54:03,060
Right. Okay. So the more confounders you adjust for, the less those it is.

476
00:54:03,930 --> 00:54:09,230
I see. But I guess I'm also thinking in terms of you can match on like I don't know how many.

477
00:54:09,240 --> 00:54:17,130
I guess it depends on what your exposure. If you match a of 15 things, which could be a massive headache, right.

478
00:54:17,280 --> 00:54:22,410
You're going to have probably a much smaller. And then if you were to have three or four things.

479
00:54:22,570 --> 00:54:28,080
Right. Right. So I have a couple of thoughts.

480
00:54:28,500 --> 00:54:34,799
First, at some point in the course, I'm going to talk about propensity score matching.

481
00:54:34,800 --> 00:54:39,060
That's going to be logistic regression. It's going to be part of the logistic regression handout.

482
00:54:39,750 --> 00:54:50,640
And so it's a way to match on tons of stuff and you kind of, you know, so you maintain your sample size of match people through that method.

483
00:54:51,240 --> 00:54:58,920
It's not perfect because it's not matching on all the individual measures, but just like probability of, you know,

484
00:54:58,920 --> 00:55:05,090
characteristics that give you a higher, low probability of being exposed and match on probably being exposed.

485
00:55:05,100 --> 00:55:10,649
So I'll go through that. The other thing, though, is there are you know,

486
00:55:10,650 --> 00:55:18,690
there's always a tradeoff between whether you match or whether you use a regression model to adjust for confounder.

487
00:55:19,710 --> 00:55:25,950
And you don't have to do all of it the same way. So you can match on some really important things.

488
00:55:27,180 --> 00:55:33,450
Right. And maybe the less important things that are causing you trouble in the matching process,

489
00:55:33,870 --> 00:55:38,340
maybe you use those in a regression, or maybe you just go straight to the regression.

490
00:55:39,630 --> 00:55:46,090
All of these are possible. I see. So yeah, I didn't think about the fact that you could come later on here.

491
00:55:46,200 --> 00:55:49,860
Just match on just a couple of things. Yeah, I see. Okay, that makes sense.

492
00:55:50,400 --> 00:55:54,060
Yeah, I had another question so I might ask.

493
00:55:54,690 --> 00:56:18,520
Thank you. Yeah, yeah, sure. Absolutely. She this.

494
00:56:27,540 --> 00:56:45,750
They? So you say.

495
00:56:47,470 --> 00:57:21,610
It's too late. 97.

496
00:57:37,520 --> 00:57:42,680
We have regulations. That.

497
00:58:03,170 --> 00:58:09,460
You know. I in New Hampshire.

498
00:58:27,310 --> 00:58:43,640
Like. I know it's going to be.

499
00:59:05,830 --> 00:59:10,930
Yes. Okay.

500
00:59:10,930 --> 00:59:19,090
Let's get back to work. All right, so brace yourself, because this is where we figure out how to set up the data, which is the hard work.

501
00:59:19,990 --> 00:59:28,690
So we are going to need to put in 183 tables into our software packages.

502
00:59:28,690 --> 00:59:34,700
And so there are going to be 12 tables that all work like this.

503
00:59:34,720 --> 00:59:40,360
That's going with this, a cell count. So 12 people where the case and control were both exposed.

504
00:59:41,530 --> 00:59:45,810
And so that's going to look like the so the A is a one that is a zero.

505
00:59:45,820 --> 00:59:56,240
The B is a1260. It's going to be 43 tables that look like this where the case exposed the controls not exposed.

506
00:59:57,350 --> 01:00:02,690
There's going to be seven tables that look like this where the control is exposed and the case is not exposed.

507
01:00:03,110 --> 01:00:08,480
And there's going to be a 121 tables where both the case and the controller are not exposed.

508
01:00:09,230 --> 01:00:15,290
So that is what we're dealing with. And so we have you know, you can put in the data in a number of ways.

509
01:00:15,620 --> 01:00:18,769
Everybody's going to have their favorite. I'm going to show you what I do.

510
01:00:18,770 --> 01:00:23,330
The GSA, I may show you a different way. You may even have a third or even fourth way.

511
01:00:23,990 --> 01:00:31,660
But I'll show you how I do it. So SAS is going to want both talk about both SAS and ah,

512
01:00:31,690 --> 01:00:39,880
so SAS is going to want one individual per line in the data set with an I.D. that indicates that the individuals are from the same table.

513
01:00:41,910 --> 01:00:49,830
So R is going to want values for each of the AIB, IKEA, India styles for all the tables.

514
01:00:50,910 --> 01:00:55,380
And so I'm going to show you how to do each of these. So here's Seth.

515
01:00:56,450 --> 01:01:08,990
And this is putting in the table just as we first experienced it, where our case is a10 variable that says yes or no that the case was exposed.

516
01:01:09,650 --> 01:01:15,930
Control is that one zero variable that indicates whether the control was exposed.

517
01:01:15,950 --> 01:01:22,190
So here's kind of that note over here. The count is the number of pairs that look like that.

518
01:01:24,170 --> 01:01:30,530
So what's happening here? So here I'm trying to create one rope for every single person.

519
01:01:30,740 --> 01:01:36,920
So to prepare. Right. And I do that by just kind of stretching out the data set.

520
01:01:37,130 --> 01:01:46,610
So I don't know if how strong you are in SAS coding, but you can kind of initialize these I.D. variable.

521
01:01:46,610 --> 01:01:50,510
We want this ID variable to look like one, one, two, two, three, three.

522
01:01:50,930 --> 01:01:53,450
It's the same for the two people in the matched pair.

523
01:01:54,290 --> 01:02:03,440
And so I'm going to do IDs, I.D. plus one to ID, plus count counts, like the number of people we want to have in the various pairs.

524
01:02:04,690 --> 01:02:08,650
So the first 12 people will.

525
01:02:11,020 --> 01:02:21,640
Have you no I.D.? And it will kind of each of these are kind of spitting out lines to put in the data set.

526
01:02:21,660 --> 01:02:25,719
So the first for the first I.D. equals one.

527
01:02:25,720 --> 01:02:30,700
It'll say, you know, I want a variable called exposed.

528
01:02:31,690 --> 01:02:35,170
And I'm going to put it to whatever the case exposure status was.

529
01:02:36,420 --> 01:02:41,880
So this is this will be the first or it will be one or zero of the cases exposed or not.

530
01:02:42,420 --> 01:02:45,960
And this is just labeling that the responses from the case.

531
01:02:46,920 --> 01:02:50,490
So the first row is saying the case is exposure data.

532
01:02:51,390 --> 01:02:54,510
The second row is saying the controls exposure data.

533
01:02:54,510 --> 01:03:01,080
So exposed is going to be one or zero depending on what whether the control is exposed or not.

534
01:03:02,200 --> 01:03:06,730
And response is just murky that it is a control person, an output.

535
01:03:08,700 --> 01:03:14,850
And so it'll go to the next I.D. and look at the next person.

536
01:03:15,420 --> 01:03:22,070
So person to one that'll do the exact same thing because the case and that control status hasn't changed.

537
01:03:22,080 --> 01:03:26,500
Right. And it will do that all the way through.

538
01:03:28,430 --> 01:03:37,730
And so in the end, we want to keep the data set that has the ID, the exposure variable and the response variable.

539
01:03:40,130 --> 01:03:47,480
So we so that will have a row for every person in the dataset and then we can use the Cochrane Mental Hansell

540
01:03:48,200 --> 01:03:56,210
statistic we're crop free where the idea is letting us know that it sits on table for its own person.

541
01:04:00,830 --> 01:04:04,640
And so. Here is.

542
01:04:05,620 --> 01:04:18,280
Where you find the data set up is the big step, you know, and the results you've already been figuring out how to see from your home at one.

543
01:04:19,120 --> 01:04:22,599
And so this is going to be the same thing as McNamara's test.

544
01:04:22,600 --> 01:04:27,760
It's actually the Cochrane Mental Hansell test, but it's the same as McNamara's test that we got by hand.

545
01:04:28,570 --> 01:04:33,160
And here are the odds ratios and confidence intervals that count for the paired nature of the data.

546
01:04:33,610 --> 01:04:37,000
So here is the conditional odds ratio and it's confidence interval.

547
01:04:38,120 --> 01:04:44,479
And just for curiosity's sake, if you look one row down, that's like the inverse variance method that you've been doing in homework one,

548
01:04:44,480 --> 01:04:48,740
and it's really far off and it's because of all the zero counts.

549
01:04:48,740 --> 01:04:51,860
It does not perform well when there's a lot of zero counts.

550
01:04:57,570 --> 01:05:02,280
His battery keeps dying. Uh, give me a second here.

551
01:05:02,430 --> 01:05:07,090
Replace the battery. I'm afraid if the recording doesn't record my voice, it's bad, right?

552
01:05:07,110 --> 01:05:19,990
So. Give me a second is going to take very long.

553
01:05:35,210 --> 01:05:54,600
Sorry about this. I just noticed. He's probably going to make a horrible, loud noise in a moment.

554
01:06:01,370 --> 01:06:04,760
All right, that's. That should be. It's actually doing something else.

555
01:06:13,710 --> 01:06:18,270
I have this terrible feeling that I'm going to have to post last year recording again because of this Mike.

556
01:06:19,110 --> 01:06:28,170
Let's cross our fingers. Okay. So as I was just saying, the McNamara's test results are the same as the Concord mental Hansell test results.

557
01:06:28,800 --> 01:06:35,790
And here's the conditional odds ratio with the confidence interval and the inverse variance method that we looked at in homework.

558
01:06:35,790 --> 01:06:42,330
One really is a fail here because it has so many zero cell counts in each of these paired tables.

559
01:06:43,110 --> 01:06:48,689
So we can't use that in the output. We have to do the the mantle here.

560
01:06:48,690 --> 01:06:52,450
So. All right, so when are.

561
01:06:55,860 --> 01:07:01,530
McNamara's test is really simple. You don't even have to switch the data to one row per person yet.

562
01:07:01,530 --> 01:07:11,610
So here's the matrix of the ABCD cells for the pair data and I've just put some

563
01:07:12,090 --> 01:07:15,729
labels here to keep track of it so that we can see what that table looks like.

564
01:07:15,730 --> 01:07:18,180
So this is the same table I had earlier in the handout.

565
01:07:20,170 --> 01:07:29,740
And then in this form, you can do McNamara's test just like this with correction equals false so that you'll get the same calculations by hand.

566
01:07:31,150 --> 01:07:34,360
And so this is the McNamara's test results prepared data.

567
01:07:34,810 --> 01:07:42,070
So you can do this if it's just a paired setting. But otherwise, you have to use the mental hansell code.

568
01:07:42,190 --> 01:07:50,020
And that code does require that, you know, the ABC idea for each of the each of the tables.

569
01:07:50,470 --> 01:07:57,220
And so the code is going to look very similar once you get the ABC idea I felt counts

570
01:07:57,220 --> 01:08:01,630
together or using that same package metaphor that you're using in homework one.

571
01:08:03,630 --> 01:08:09,900
And so. Just a short thought to show you what this is doing.

572
01:08:10,590 --> 01:08:20,340
The air cells are looking at all of these cells from the 12 tables, from the 43 tables, from the seven and the 121.

573
01:08:20,730 --> 01:08:30,410
And because these first two types of tables have one in the cell, I just repeated 112 plus 43 times.

574
01:08:30,420 --> 01:08:33,480
That's where this repeat 155 times comes from.

575
01:08:34,980 --> 01:08:38,130
And then the remaining cells are all zero.

576
01:08:38,140 --> 01:08:42,150
So that's seven plus 121 times we have zeros.

577
01:08:42,900 --> 01:08:46,050
So this is now repeating zero, 128 times.

578
01:08:46,680 --> 01:08:54,450
So in this big list, I've got all the cells from all of the individuals.

579
01:08:56,310 --> 01:09:01,940
Individual tables here are just laid out like that for the B-cell.

580
01:09:01,950 --> 01:09:09,930
I don't I don't have an edition Trix, so it's one zero, one zero and I just have repeat 112 times for the first type of table,

581
01:09:10,920 --> 01:09:20,430
43 times for the second type of table, seven times for the third type of table and 121 times for the fourth type of table.

582
01:09:20,430 --> 01:09:24,320
So there's no quick some trick here.

583
01:09:24,630 --> 01:09:27,780
But for this table, again, I do something similar.

584
01:09:28,020 --> 01:09:31,979
So these two will have zeros, these two will have ones.

585
01:09:31,980 --> 01:09:39,180
And so I just kind of group the 12 plus the 43 that have zeros and the seven and 121 that have ones.

586
01:09:39,960 --> 01:09:47,430
Right. And so on. So this is how you get all of the tables ABC sells.

587
01:09:47,970 --> 01:09:53,430
And then the code is very similar to what you saw in homework one using our mirror image.

588
01:09:56,730 --> 01:10:00,840
And so this is the odds ratio and confidence limits that you get.

589
01:10:01,650 --> 01:10:04,870
And the Cochrane Mental Handle tests is the same as McNamara's test.

590
01:10:04,890 --> 01:10:10,980
So you could just skip the McNamara's test part altogether and just go straight here and you'll get everything you need.

591
01:10:19,780 --> 01:10:24,490
Okay. So this is all covering the simplest case where you just got matched pair.

592
01:10:24,520 --> 01:10:29,329
So I want to prepare you for more complicated settings.

593
01:10:29,330 --> 01:10:36,010
And then when you have more than one control per case, the McNamara's part goes away.

594
01:10:36,730 --> 01:10:43,900
We have to use cork or mental Hansel. And so again, most of the work is in setting up the data set properly.

595
01:10:43,900 --> 01:10:50,080
The code is very similar once you've got the data set in place, but you have to get the data set together.

596
01:10:50,080 --> 01:10:53,950
So here's an example with 1 to 2 matching.

597
01:10:53,950 --> 01:10:56,980
So each case is matched to two controls here.

598
01:10:59,030 --> 01:11:07,730
And when you have one case in to control it, there's six unique types of two by two tables in the man to handle the application.

599
01:11:08,540 --> 01:11:15,110
So with matched pairs, we had four types of tables. Now, because we've got extra control, we've got six types of tables.

600
01:11:15,680 --> 01:11:19,310
And so this is where, you know, you just it's just the bookkeeping. That's the work.

601
01:11:20,240 --> 01:11:24,260
And unfortunately, software won't do this part for you. You have to do the bookkeeping yourself.

602
01:11:25,130 --> 01:11:29,760
And so I've tried to kind of simplify this a little bit with color.

603
01:11:29,780 --> 01:11:34,750
So in each table, there's one case.

604
01:11:34,790 --> 01:11:39,409
So a policy is going to have to be one. And there's two controls.

605
01:11:39,410 --> 01:11:44,120
So B plus D is going to have to be two and I's three.

606
01:11:44,270 --> 01:11:51,260
But otherwise, we have to figure out, you know, what the individual ABCD cells are.

607
01:11:53,160 --> 01:11:59,990
So I've used orange for all the table types where the case is exposed.

608
01:12:00,000 --> 01:12:04,470
So there's three of those here for one exposure, two exposures and three exposures,

609
01:12:05,310 --> 01:12:10,230
and all the rows in yellow are indicating that the case is not exposed.

610
01:12:11,100 --> 01:12:14,309
So that's this, this, this. All right.

611
01:12:14,310 --> 01:12:15,990
So that's going to help us a little bit.

612
01:12:17,170 --> 01:12:26,650
So if there's no exposures, that is the easiest of all the cases because both the case and the control are not exposed.

613
01:12:27,670 --> 01:12:36,370
And so the C cell is going to be a one that's for the case and the D cell is going to be a two.

614
01:12:36,370 --> 01:12:39,970
That's for the two controls. So none of them are exposed.

615
01:12:42,500 --> 01:12:51,709
And for the mental handle statistic, it's handy to know what the eight times D is and what the B times C is,

616
01:12:51,710 --> 01:12:58,370
because we put together the mental handful statistic. If we're if we're doing it by hand,

617
01:12:58,880 --> 01:13:06,260
it's easier if you know what these are and the number of tables that look like this so that you can do that calculation quickly.

618
01:13:06,920 --> 01:13:12,070
You don't necessarily have to do this if you're using the software, these last two columns you don't have to do.

619
01:13:12,090 --> 01:13:18,020
But you do have to know what's going on in these first four columns when you're setting up your data set.

620
01:13:21,240 --> 01:13:28,960
All right. So. So again, the yellow rows are that the case is not exposed.

621
01:13:28,970 --> 01:13:36,430
So if there is one exposure and the case is not exposed, air is going to be zero,

622
01:13:36,440 --> 01:13:43,940
B is going to be one, and then there's going to be one exposure for the controls.

623
01:13:43,940 --> 01:13:47,180
A C is going to be one and it's is going to be one.

624
01:13:49,940 --> 01:13:56,270
And for two exposures where the case is not exposed, those are the exposures people are going to be controls.

625
01:13:56,840 --> 01:14:00,980
So that's going to give us the eyes to see this one.

626
01:14:06,670 --> 01:14:11,020
And then further cases where the case is exposed.

627
01:14:12,980 --> 01:14:18,320
Notice all three of those rows that are orange air is one that's for the exposed case.

628
01:14:19,220 --> 01:14:24,290
And then the the other counts are related to what's going on with the controls.

629
01:14:24,330 --> 01:14:30,020
If there's only one exposure that's the case, then neither of the controls are exposed.

630
01:14:30,020 --> 01:14:37,499
So this to if there's two exposures and one of them is the case, only one of the controls is exposed.

631
01:14:37,500 --> 01:14:41,210
So that's where the B in the door coming from of one.

632
01:14:43,120 --> 01:14:48,249
And if there are three exposures and one is the case, actually all of them are exposed.

633
01:14:48,250 --> 01:14:58,940
So B is two. So that's kind of where this is coming from. And so here are.

634
01:15:01,240 --> 01:15:04,450
This is the kind of table you might see where there's 1 to 2 matching.

635
01:15:04,450 --> 01:15:08,500
So you'll have the case status and whether that case was exposed or not exposed.

636
01:15:08,980 --> 01:15:13,060
And then the number of exposures controls zero one or two.

637
01:15:16,090 --> 01:15:24,040
And so there's 75 cases that are exposed, as were the orange arrows on the previous slide.

638
01:15:24,070 --> 01:15:32,590
So in each of those, if you go back, we had a column for the Times C and we had a column for the Times DE.

639
01:15:33,770 --> 01:15:40,010
Right. So for hand calculations, I'm just sort of keeping track of what these products were.

640
01:15:42,850 --> 01:15:55,340
And so for the ten people where there were zero exposed controls and the case was exposed, uh, for those ten times d was two.

641
01:15:55,360 --> 01:16:04,739
So I'm getting that from the previous table. So a case was exposed and that's the only one.

642
01:16:04,740 --> 01:16:09,360
So eight times D is to be times C zero. Right.

643
01:16:10,190 --> 01:16:13,760
And 25 had one match control exposed.

644
01:16:14,480 --> 01:16:19,160
So for those 25, the end times D is one.

645
01:16:19,400 --> 01:16:27,290
So again, we're looking at one of the orange rows, two exposures ones, the case ones, the control eight times D is one.

646
01:16:27,320 --> 01:16:38,809
You see where I'm kind of pulling these numbers from. And 40 had the case exposed as well as the controls, and eight times D was zero in that case.

647
01:16:38,810 --> 01:16:45,050
And again, it's coming from the previous slide, the orange row, where all three were exposed and there's a zero here.

648
01:16:47,570 --> 01:16:51,980
Right. And so similarly, you can go to the next row.

649
01:16:52,010 --> 01:16:58,270
These are all the rows that were in yellow on the previous slide, and there were 25 cases that were not exposed.

650
01:16:58,280 --> 01:17:05,000
And you can kind of go through the same exercise. And for each of the yellow rows, eight times D was zero.

651
01:17:05,210 --> 01:17:09,860
So it doesn't contribute to the numerator being too Hansel and the denominator.

652
01:17:09,950 --> 01:17:23,840
It broke down like this. So for the 15 where there were no controls that were exposed, the B times C was zero for the case where one was exposed.

653
01:17:24,680 --> 01:17:28,219
The B times C was one, and for this last entry were both matched.

654
01:17:28,220 --> 01:17:35,660
Controls were exposed to B times C was two. And so these are all the terms we need to put together the mental handle by hand.

655
01:17:39,970 --> 01:17:46,630
And so we you know, if we're estimating the odds ratio of disease for exposed versus unexposed subjects for this dataset,

656
01:17:47,650 --> 01:17:53,350
we're just filling in this mental handful estimate and I've taken out the divided by and

657
01:17:53,350 --> 01:17:57,940
I since it's both in the top and the bottom and it's the same for every single table,

658
01:17:58,150 --> 01:18:06,340
it's always going to be three. And so I'm just summing up the Air Times di in the top and the by time on the bottom.

659
01:18:08,480 --> 01:18:15,800
And so in the top, only the orange cells with the case exposed contributed in the bottom.

660
01:18:16,340 --> 01:18:19,370
Only the yellow rose contributed.

661
01:18:19,730 --> 01:18:28,880
And so when you just put together the counts times the A times D for that type of table, we should get a three for this conditional odds ratio.

662
01:18:30,690 --> 01:18:35,430
And so we need to figure out how to put this into the software and get that three.

663
01:18:36,360 --> 01:18:41,189
So we'll do that in a minute. And, you know, in the privacy of your room,

664
01:18:41,190 --> 01:18:46,410
if you want to see how much bias you avoided by taking into account the matching, it's possible to do that.

665
01:18:47,580 --> 01:18:54,629
So if you set up a two by two table where you have ignored the matching, you'll get an odds ratio to see all again.

666
01:18:54,630 --> 01:19:00,870
See this behavior where it will bias the odds ratio towards one if you don't account for the matching.

667
01:19:01,860 --> 01:19:07,620
And just this is a little puzzle in the privacy of your room. If you want to think about this, you can see where that came from.

668
01:19:07,620 --> 01:19:16,590
But I'm not going to focus on it. I just wanted to show you the degree of bias that we got from the adjusting for the matching.

669
01:19:17,940 --> 01:19:23,519
And so you can kind of tell that it gets more and more complicated the more people you

670
01:19:23,520 --> 01:19:27,430
have in your matched set because you have more unique types of tables that come out.

671
01:19:27,450 --> 01:19:34,139
So in general, when each case is matched to see controls, there are two times three plus one unique tables.

672
01:19:34,140 --> 01:19:37,560
And so this is just a lot to deal with.

673
01:19:38,190 --> 01:19:46,600
Fortunately, a colleague of mine sort of showed that you really don't need more than three controls per case.

674
01:19:47,580 --> 01:19:54,210
That you get diminishing returns in your precision of your estimates and your power when you have more than three controls per case.

675
01:19:54,960 --> 01:20:01,380
So if you are putting together your data set for the first time and it's a headache,

676
01:20:01,710 --> 01:20:05,970
you can kind of keep that in mind and see, you know, see doesn't really need to be more than three.

677
01:20:08,590 --> 01:20:16,239
And so we focused upon by hand estimation of odds ratio with one or two matching and their corresponding confidence intervals and cockrum in a handful

678
01:20:16,240 --> 01:20:22,209
statistics with 1 to 2 or one to see matching and the mental health of all

679
01:20:22,210 --> 01:20:27,520
four handle situations where you have a variable number of controls per case,

680
01:20:27,700 --> 01:20:30,159
you know, it'll handle all kinds of different settings.

681
01:20:30,160 --> 01:20:38,200
You just have to know which were matched, which, which cases in which trials were matched, and they could be in varying numbers.

682
01:20:40,120 --> 01:20:47,260
So there's a reference on canvas, Woodward, that you could read if you were more curious about this, if you ever have to do this in practice.

683
01:20:49,340 --> 01:20:56,840
So the go to method is going to be to use the mental Hansel strategy, either in SAS or to deal with these more complicated settings.

684
01:20:57,890 --> 01:21:08,030
And I don't want to necessarily drive you crazy this, but I want you to have in your notes examples of how to set up these data sets.

685
01:21:08,900 --> 01:21:15,050
And so this is that same setting where you had one case and two controls.

686
01:21:16,550 --> 01:21:20,840
And so just putting in the data, it's going to be a one.

687
01:21:24,190 --> 01:21:31,910
So I've got the three people and I'm just, you know, calling them all, you know, the first person.

688
01:21:31,930 --> 01:21:35,950
Are they a case and are they exposed? So in the first person, I just set it up.

689
01:21:35,950 --> 01:21:41,680
So the first person is always a case. So for all the table types that first.

690
01:21:42,970 --> 01:21:46,480
So I've got a table type one, two, three, four, five, six that corresponds to three yellow.

691
01:21:46,480 --> 01:21:53,680
The three orange table types from previous slides and I've always got the first entry is the case.

692
01:21:54,310 --> 01:21:57,110
And so the first row is where the case is.

693
01:21:57,510 --> 01:22:03,940
The cases expose second row, the cases exposed, third row cases exposed in the last through the case is not exposed.

694
01:22:04,240 --> 01:22:10,270
Right. And then these are the this is one of the controls, right?

695
01:22:10,270 --> 01:22:15,790
So case two and exposed two is covering the data for one of the controls in case three.

696
01:22:15,790 --> 01:22:22,360
Exposed three is covering the data for the other one of the controls. So these two controls.

697
01:22:23,610 --> 01:22:26,309
They were not a case, right? So the second person was not a case.

698
01:22:26,310 --> 01:22:34,410
They were controls that are zero because they're not a case and it's a zero because they were also not exposed.

699
01:22:34,710 --> 01:22:41,400
This third person was not a case. So their case three is zero and they're supposed three is zero because they were not exposed.

700
01:22:41,910 --> 01:22:48,240
So this is going to be the ten tables where the case was exposed, but there were no exposed controls.

701
01:22:48,990 --> 01:22:54,930
That's what that data is going to look like. And I could have done something similar for every entry in that table.

702
01:22:58,580 --> 01:23:03,660
And. Here we the conquer mental Hansel.

703
01:23:05,460 --> 01:23:09,330
You know, we're going to want to have one row per person.

704
01:23:10,170 --> 01:23:14,070
And so just like before, I'm kind of stretching out those three people.

705
01:23:15,120 --> 01:23:20,400
There's three types of people for this. These ten matched.

706
01:23:21,830 --> 01:23:34,120
Triples. And I'm stretching them out so the first person's going to have I'd one and the first row with ID equals one is going to be the case.

707
01:23:34,120 --> 01:23:43,700
So I'm going to I'm printing out the yes now are the case and it's always going to be a one for the first person and their exposure status.

708
01:23:45,170 --> 01:23:50,570
And then this is going to give me a row for the the first control and the second control.

709
01:23:52,890 --> 01:23:59,670
And so after you finish this and, you know, you can run the code and sort of see what the data set looks like,

710
01:23:59,880 --> 01:24:08,730
and it's just basically having one row per person where they have, you know, whether they were a case or not and whether they were exposed or not.

711
01:24:11,970 --> 01:24:22,530
And then we can do the Cochrane Mental Hansell from there. So figuring out, you know, how to put in the data for these ten types of table,

712
01:24:22,530 --> 01:24:25,710
you know, for these ten people in this type of table and so on, that's the work.

713
01:24:27,740 --> 01:24:31,850
And then the interpretation of the output is very simple because you've been doing that already.

714
01:24:32,180 --> 01:24:35,580
So here's the mental Hansell test.

715
01:24:35,600 --> 01:24:38,780
We don't have a McNamara's test when we have two controls.

716
01:24:39,380 --> 01:24:45,470
So it's it doesn't. This is just some cockamamie cancel test that accounts for the match groups.

717
01:24:45,980 --> 01:24:49,250
And here's our conditional odds ratio that we got by hand, the three.

718
01:24:50,090 --> 01:24:55,430
And the confidence limits that go with that. And we did I did not show you how to do the confidence limits by hand.

719
01:24:55,440 --> 01:25:04,900
So that's just software here. And again, don't use the logit rho.

720
01:25:05,590 --> 01:25:12,100
The inverse variance method is not going to work for these types of analyzes because there's just so many zeros in these tables.

721
01:25:17,400 --> 01:25:22,500
So the R code requires that A, B, C, D for each of the tables.

722
01:25:23,220 --> 01:25:31,380
So here's our original table. And so you kind of have to at least for me, I have to write out all the table types.

723
01:25:32,550 --> 01:25:36,090
Two. So I can put all the A's bases and D's together.

724
01:25:36,090 --> 01:25:41,580
So there are ten tables that look like this where the case is exposed and the controls aren't,

725
01:25:42,390 --> 01:25:47,310
and 25 tables where the case is exposed and there's one control that's exposed or not.

726
01:25:47,560 --> 01:25:56,280
So for me, I just write them out so that when I put together the ABCDE stuff, I can just go through.

727
01:25:57,030 --> 01:26:04,980
And so I, I did the same trick where the first three types of tables all have equal to one.

728
01:26:04,990 --> 01:26:12,930
So I just summed up the ten plus 25 plus 40, and I know that the I sells the first 75 people should have a one.

729
01:26:15,700 --> 01:26:21,360
And the rest all have zeros for the ACL. So 15 plus five plus five, all had zeros.

730
01:26:21,370 --> 01:26:28,719
That's where the second repeat zero 25 times comes from. All right.

731
01:26:28,720 --> 01:26:36,220
So I have 100. This is the length of 100 and a sort of the cells from all the hundred tables.

732
01:26:37,290 --> 01:26:41,520
I've covered and I do the same thing with the B, C and D cells.

733
01:26:41,940 --> 01:26:51,540
So just to see another example of it, let's look at the D cells. So I've got to I've got ten tables where I have a two is the first entry.

734
01:26:51,540 --> 01:26:55,110
So that's repeat 210 times. That's where this first thing comes from.

735
01:26:57,030 --> 01:27:02,969
And then I have 25 tables where the D is a one that comes right after that.

736
01:27:02,970 --> 01:27:06,210
That's repeat 125 times for this case.

737
01:27:08,450 --> 01:27:14,450
That I have zero in 40 tables or a zero 40 times is covering this case.

738
01:27:16,350 --> 01:27:23,640
Then here the DSL is two for 15 tables, then repeat 215 times for that case.

739
01:27:24,870 --> 01:27:31,730
D is one for five tables. That's here D zero for five pebbles that's here.

740
01:27:32,100 --> 01:27:34,650
And so I just this is how I'm listing them all together.

741
01:27:35,010 --> 01:27:44,070
And then from there, once you've got all that, the ABCD from all 100 tables, you can just use the army image just like we did before.

742
01:27:44,640 --> 01:27:50,250
And here is your conditional odds ratio estimate, confidence interval and p value.

743
01:27:55,560 --> 01:28:00,209
And so an example of a manuscript where the sentence would be, you know,

744
01:28:00,210 --> 01:28:07,500
the estimated odds ratio of disease for exposed versus unexposed subjects accounting for the one or two matched aspect of the design.

745
01:28:09,390 --> 01:28:23,879
Is three with a confidence interval and a p value. All right.

746
01:28:23,880 --> 01:28:35,990
And so, as I said earlier, you can have many, too many matching, so many cases matched too many controls, all in one with one common matching idea.

747
01:28:37,230 --> 01:28:40,020
And the same analysis methods will apply.

748
01:28:40,500 --> 01:28:47,880
And it's not common to have more than one case in a match set, since cases tend to be harder to obtain for analysis and controls.

749
01:28:48,840 --> 01:28:55,020
But there are sometimes, you know, people like to have more than one case per match set just the case,

750
01:28:55,020 --> 01:29:00,240
because if the case drops out, you lose all the data from the match controls that go along with it.

751
01:29:01,250 --> 01:29:06,530
So if controls are matched to a single case, in that case drops out and the data from the matched controls are useless in the analysis.

752
01:29:06,530 --> 01:29:14,889
So. The number of unique two by two tables grows quickly and inference becomes more computationally intense.

753
01:29:14,890 --> 01:29:20,920
So you already saw how complex it was to set up the dataset when you had to match controls.

754
01:29:21,250 --> 01:29:29,680
And it gets worse the more and more there are. So later in the handout, I just have an example with, you know,

755
01:29:29,790 --> 01:29:34,620
one more example with a lot of match controls just so you can have it and see how it's done.

756
01:29:35,370 --> 01:29:46,060
But I think my main goal is that you know how to set up the data for simple cases for this class and perform the analysis.

757
01:29:46,080 --> 01:29:52,080
I'm not going to make your life harder with like 1 to 5 matching just to make you sweat, you know?

758
01:29:52,590 --> 01:29:56,190
But I wanted you to have examples of how to do it in case it comes up.

759
01:29:57,360 --> 01:30:00,810
So what other what other situations are you going to need to use these methods?

760
01:30:00,840 --> 01:30:06,299
So one example is crossover studies where you have a yes no outcomes.

761
01:30:06,300 --> 01:30:13,740
The recall that a longitudinal study by design leads to a matched design as their outcome on the same subjects matched with each other.

762
01:30:13,770 --> 01:30:18,929
So another design that matches each subject with itself as a crossover design in

763
01:30:18,930 --> 01:30:22,980
which each subject is given multiple different exposure levels of the risk factor.

764
01:30:23,700 --> 01:30:26,849
And crossover designs are most often used,

765
01:30:26,850 --> 01:30:32,459
and intervention studies will randomly assign you to one intervention and then switch it

766
01:30:32,460 --> 01:30:36,840
to the other and you get two outcomes on the two different interventions per person.

767
01:30:37,860 --> 01:30:41,489
So one example, this is a little bit more complex than just matched pairs,

768
01:30:41,490 --> 01:30:48,030
but one example of a crossover design might be say you have three drugs that you want to compare for migraines,

769
01:30:48,660 --> 01:30:55,670
and you give all three drugs sequentially to each subject, usually in random order with a washout period in between.

770
01:30:55,680 --> 01:31:03,870
So you might randomize them to the first medication, see what happens with their migraine, and wash out the medication from the system for a while.

771
01:31:04,290 --> 01:31:11,480
And then the next time they have a migraine, giving the second randomize medication and so on.

772
01:31:11,490 --> 01:31:15,960
So you get three observation periods with Yes. Now, did the treatment help the migraine?

773
01:31:19,980 --> 01:31:24,990
So there's also a case crossover study design that will give you this kind of data.

774
01:31:25,470 --> 01:31:32,880
And so crossover designs applied to a case control study or result in a case crossover study.

775
01:31:33,690 --> 01:31:38,550
And such a design can only be used in exposures that are fairly acute and transient.

776
01:31:39,420 --> 01:31:41,880
I've got an example coming up in a minute,

777
01:31:42,120 --> 01:31:49,170
but the exposure must be really obvious and memorable because they have to think backwards and see if they were exposed or not.

778
01:31:51,340 --> 01:31:58,450
And exposure must not have lasting effects because whatever windows you're comparing, they need to not affect one another.

779
01:31:59,860 --> 01:32:05,799
So essentially you take cases with the outcome you're interested in and retrospectively

780
01:32:05,800 --> 01:32:10,690
identify windows of time in which they were each exposed and not exposed to a risk factor.

781
01:32:11,830 --> 01:32:17,580
And the example I haven't seen a ton of examples of this in my own practice, but I'm not an epidemiologist.

782
01:32:17,590 --> 01:32:27,190
So you may have this happen to you all the time, but there is an example of a case crossover study of sleep in childhood injury that I found.

783
01:32:27,910 --> 01:32:31,600
And the setting was, you know.

784
01:32:33,240 --> 01:32:36,660
These 181 boys had gotten injured.

785
01:32:37,500 --> 01:32:43,440
And so they were asked about sleep patterns in the previous 24 hours before their injury.

786
01:32:43,440 --> 01:32:48,420
That was like the case winter. How much sleep did they get to the day before they injured themselves?

787
01:32:49,500 --> 01:32:53,850
And then the control window was 24 hours preceding that.

788
01:32:54,030 --> 01:33:02,760
So they had to remember how much sleep they got even the night on the previous day before the day they got injured.

789
01:33:03,210 --> 01:33:08,610
So that makes sense. And so here's what the data looked like.

790
01:33:08,610 --> 01:33:14,130
40 boys that were injured had less than 10 hours of sleep on both of the days concerned.

791
01:33:15,420 --> 01:33:18,350
111 had more than 10 hours of sleep on both days.

792
01:33:18,360 --> 01:33:26,040
So these are the concordant cells, right where they had the same amount of sleep, whether it was not very much or a lot.

793
01:33:27,090 --> 01:33:35,130
And then the discordant cells were 21, had less than 10 hours sleep on the day before the injury, but slept more than 10 hours on the day before that.

794
01:33:36,120 --> 01:33:41,730
And nine had more than 10 hours of sleep on the day before the injury, but slept less than 10 hours on the day before that.

795
01:33:43,750 --> 01:33:54,310
And so with this data structure, would you know how to set up or recognize the appropriate source or code for analyzing this data?

796
01:33:56,800 --> 01:34:02,890
So in the previous year, every room you can think about that, but it's very similar to the setup we've done for the other parent data.

797
01:34:04,700 --> 01:34:05,299
So the strength,

798
01:34:05,300 --> 01:34:12,800
the strength of a case across a positive result is that the within subject matching reduces the variability or increases the efficiency in the power.

799
01:34:12,800 --> 01:34:17,060
But the weaknesses are that, you know, especially with this sleep study,

800
01:34:17,360 --> 01:34:23,690
they had to remember how much night they got, not just one night ago, but the night before that as well.

801
01:34:24,290 --> 01:34:32,300
So determining the windows of exposure, not just not exposure is dependent on subject recall and recall bias is very possible,

802
01:34:32,660 --> 01:34:36,100
especially if they just had a lot of, you know, not much sleep the night before.

803
01:34:36,110 --> 01:34:44,360
Then they really have to work to remember the sleep the night before that. It's often impossible to confirm that the windows don't overlap,

804
01:34:45,650 --> 01:34:50,990
as it's difficult to determine the instance when the exposure occurred and its effect has completely ended.

805
01:34:51,380 --> 01:34:57,740
So for instance, in this sleep study, if two nights ago they didn't get much sleep.

806
01:34:58,870 --> 01:35:07,840
How is it possible that that is still kind of affecting them even another day later that they haven't quite caught up like you do in Alma?

807
01:35:08,230 --> 01:35:13,510
Not that little boys do all nighters, but maybe they had a gaming. I mean, they were on their headsets all night, I don't know, playing games.

808
01:35:14,140 --> 01:35:19,320
And then that lack of sleep affected them not just for the next day, but the day after that.

809
01:35:19,330 --> 01:35:24,490
So in that case, the exposure overlaps and interferes with the study design.

810
01:35:27,580 --> 01:35:31,780
A carryover effects occur when the exposure window precedes the non exposure

811
01:35:31,780 --> 01:35:34,810
window in the actual end of the exposure when there's longer than believed.

812
01:35:35,680 --> 01:35:43,540
And so ah, if, if you do have a carryover effect, you need to have a washout period to ensure that the windows don't overlap.

813
01:35:45,800 --> 01:35:50,000
If you have multiple exposure levels, actually, even if you just have two exposure levels,

814
01:35:50,000 --> 01:35:58,610
you might have to consider the ordering of which, you know, is ordered first versus second versus third.

815
01:36:01,660 --> 01:36:05,889
And unless an investigator can be certain that the weaknesses can be adequately addressed,

816
01:36:05,890 --> 01:36:09,850
the gain in efficiency from this design is outweighed by potential bias issues.

817
01:36:09,860 --> 01:36:16,040
So when I'm looking at choices of study design, I,

818
01:36:16,660 --> 01:36:22,450
I generally avoid crossover studies just because my experience is that it's very easy for bias to creep in,

819
01:36:22,450 --> 01:36:24,790
but they are very convenient studies to do.

820
01:36:27,970 --> 01:36:41,049
So I have in the next few slides, I have some information about looking for effective modification with pairing and interactions,

821
01:36:41,050 --> 01:36:50,350
i.e. interactions with paired data. But what I've decided is that I'm not going to spend time on that or cover it on exams for the course.

822
01:36:50,710 --> 01:36:53,770
We're eventually going to learn how to analyze that data with regression methods.

823
01:36:54,280 --> 01:36:57,320
And this will just be a special case of a regression method.

824
01:36:57,340 --> 01:37:00,640
So for your notes, it'll be here.

825
01:37:01,120 --> 01:37:06,099
But you can put X's over this for studying, as far as I'm concerned.

826
01:37:06,100 --> 01:37:16,030
So for. So let's say 553, 54, 55, 56, 57, 58.

827
01:37:19,060 --> 01:37:22,420
Those. The slides are just for your own information,

828
01:37:22,420 --> 01:37:28,720
but you'll eventually be doing those analyzes with regression methods so you're not really losing your ability to analyze data.

829
01:37:29,530 --> 01:37:41,910
It's just going to be a special case. And I think I also have just an extra example of how to program McNamara's test.

830
01:37:42,720 --> 01:37:46,410
Uh, that is just another kind of for your own information.

831
01:37:46,420 --> 01:37:51,510
It's repetitive. The skills are repetitive from what you've already seen, but it's another example of how to program.

832
01:37:52,050 --> 01:37:57,360
So it's a respective matched case control study of thromboembolism and oral contraceptive use.

833
01:37:58,380 --> 01:38:06,570
And so there were 175 women of reproductive age who were discharged after diagnosis and treatment for thrombotic and ballistic event.

834
01:38:06,900 --> 01:38:14,790
And each was matched to a control. And so the matching was by hospital, race, age, marital status, parity and status.

835
01:38:15,420 --> 01:38:20,640
And the question of interest was, is oral contraceptive use more frequent among cases than controls?

836
01:38:21,880 --> 01:38:28,900
And I just wanted to give you another example of code. And so I'm not going to really this is just think of it as extra reading.

837
01:38:30,810 --> 01:38:36,700
And so. Another example of how to set it up and are.

838
01:38:41,020 --> 01:38:44,070
And so that's just just f y just another example.

839
01:38:44,080 --> 01:38:47,380
Examples are good. And this is I guess I put in that same category.

840
01:38:48,520 --> 01:38:56,290
I wanted to show you what happens when you have 1 to 5 matching just to kind of, you know, if you ever need it, you see how it's done.

841
01:38:56,950 --> 01:39:03,010
But this is also just for your information only I'll never put you in a situation where you have to program this by hand.

842
01:39:03,980 --> 01:39:07,209
Um, your, your study might, but I won't.

843
01:39:07,210 --> 01:39:13,480
So in this setting there, we're looking at a vaccine for the prevention of tuberculosis.

844
01:39:13,480 --> 01:39:21,580
And there were five controls for each matched tuberculosis case, and matching was done on gender and age and date of birth.

845
01:39:22,090 --> 01:39:27,100
And so the table is set up, as you know.

846
01:39:27,520 --> 01:39:34,030
Does the case have the vaccine, yes or no? And then the number of controls with the vaccine, zero one, two, three, four, five.

847
01:39:34,030 --> 01:39:38,800
So this is the way they might display the data in the table, in the paper.

848
01:39:39,490 --> 01:39:50,200
And so each one of these cell entries is going to end up being a type of two by two table that you have to put together.

849
01:39:50,890 --> 01:39:59,799
And so in the privacy of your own room, you can sort of go through how you can set up this data in SAS.

850
01:39:59,800 --> 01:40:03,760
But just briefly, you've got six people across and five controls.

851
01:40:04,540 --> 01:40:08,409
And so I do the same trick where you have. Are they a case?

852
01:40:08,410 --> 01:40:11,680
Yes. Now, are they exposed? Yes. Now, are they a case? Yes.

853
01:40:11,680 --> 01:40:19,770
Now, are they exposure now for each of the six people? And then the count of of how many are exactly like that.

854
01:40:19,770 --> 01:40:26,940
So there's one expose, there's one exposed case with zero of the five controls exposed, and that's this row here with one of them.

855
01:40:27,450 --> 01:40:33,540
And each of these cell counts are kind of one of those entries at the table, just so you can see how I set this up.

856
01:40:37,350 --> 01:40:44,160
And you know, this is how I stretch out the data set so that there is one row per person.

857
01:40:46,050 --> 01:40:49,140
And then the the copper mental Hansel stuff.

858
01:40:49,140 --> 01:40:53,370
So you can look through this again in the privacy of your own room.

859
01:40:53,370 --> 01:41:01,800
You can just sort of see how that's done just so that you can if you ever have to figure that out.

860
01:41:03,670 --> 01:41:07,120
All right. So that's all I really wanted to cover for.

861
01:41:07,120 --> 01:41:12,650
Handout for. So.

862
01:41:19,610 --> 01:41:24,030
I think I'll just wait till Monday to know.

863
01:41:24,050 --> 01:41:29,900
I haven't posted a handout five yet. So on Monday we're going to do a quick review of logistic regression.

864
01:41:29,900 --> 01:41:34,520
And as part of that, I'm going to show you how to do matching using propensity score.

865
01:41:34,520 --> 01:41:42,740
So that'll be one of the new things we learn how to do with logistic regression that kind of ties into this matching idea from handout four.

866
01:41:43,610 --> 01:41:51,680
And I'll also be showing you how to do a meta analysis using logistic regression, tying in to what you did for one.

867
01:41:53,540 --> 01:41:58,140
All right. And then after the handout five, we'll be going all into new materials.

868
01:41:58,180 --> 01:42:02,540
That'll be the end of the review. Slash a little bit of new material.

869
01:42:03,890 --> 01:42:09,810
All right. I'm going to answer any questions before we go that you want to get on the class recording.

870
01:42:12,960 --> 01:42:16,770
And hopefully it did really record that whole time. Little nervous.

871
01:42:19,030 --> 01:42:20,630
All right, then. I'm going to stop the recording.

