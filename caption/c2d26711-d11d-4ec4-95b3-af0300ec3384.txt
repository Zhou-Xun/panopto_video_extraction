1
00:00:01,670 --> 00:00:07,650
And so it's 1030.

2
00:00:07,710 --> 00:00:17,220
If anyone wants to come by my office and say hello or get more tips on what she said, you should do what life is like in Cleveland.

3
00:00:17,910 --> 00:00:22,950
Come by tens of tens of millions. Okay. Yeah.

4
00:00:23,010 --> 00:00:31,290
Anyone wants to come by and tell me what I should do. So thank you for here today.

5
00:00:32,280 --> 00:00:36,659
Let me talk to you about some of the work I've done in early phase clinical trial design,

6
00:00:36,660 --> 00:00:40,670
and I'm going to tie it all together with a case study about Atezolizumab.

7
00:00:40,790 --> 00:00:48,630
I'll start by kind of introducing that and talking a little bit about that trial, and I'll be using it as a motivating example.

8
00:00:50,760 --> 00:00:56,130
So just to orient you with where we are in early phase oncology trial design,

9
00:00:56,460 --> 00:01:00,600
there's been a lot of changes in recent years in response to the changing treatment landscape.

10
00:01:00,600 --> 00:01:06,719
So historically, oncology drug development was focused on chemotherapies.

11
00:01:06,720 --> 00:01:14,970
And with these types of drugs, the efficacy really increased with increasing dose and also the toxicity increased.

12
00:01:14,970 --> 00:01:19,330
And so these trials were focused on identifying the maximum tolerated dose.

13
00:01:19,470 --> 00:01:24,750
Usually a single dose would identify this in a small number of patients and then move on to phase two.

14
00:01:25,440 --> 00:01:31,409
But with these molecularly molecularly targeted agents and immunotherapies, that's it's not always the case.

15
00:01:31,410 --> 00:01:41,910
The efficacy increases with increasing dose, sometimes lower doses can have equal efficacy to higher doses or even better efficacy at lower doses.

16
00:01:41,910 --> 00:01:48,450
And so this traditional approach of finding the single maximum tolerated doses doesn't always work.

17
00:01:48,450 --> 00:01:53,939
And people started kind of adding ad hoc use those expansion cohorts on the back end of

18
00:01:53,940 --> 00:01:58,319
these trials to try and get more information about the doses and what to do in phase two.

19
00:01:58,320 --> 00:02:06,720
And so these trials have gotten bigger and bigger. One area of really rapid development is immune checkpoint inhibitors.

20
00:02:07,080 --> 00:02:10,680
You can see here the very first one was approved in March of 2011.

21
00:02:10,680 --> 00:02:12,870
It was ipilimumab for melanoma.

22
00:02:13,200 --> 00:02:20,880
And then there was kind of a long break and then really an explosion starting in 2014 of approvals of these immune checkpoint inhibitors.

23
00:02:21,840 --> 00:02:29,489
And you can see here on the bottom in May 2016, Atezolizumab was approved for use in metastatic urothelial carcinoma.

24
00:02:29,490 --> 00:02:35,850
And that's what I'll be talking about today. So it's usually as a MAB, as a PD-L1 checkpoint inhibitor.

25
00:02:35,970 --> 00:02:45,510
And what that means is that it blocks the binding of PD one to PD l one to allow that t cell to attack that cancer cell and cause cell death.

26
00:02:45,900 --> 00:02:51,810
Because when there's that binding, it prevents the T cell from leading to cell death in the in the tumor cells.

27
00:02:52,440 --> 00:02:57,240
So that's what Atezolizumab does. It's manufactured as a centric by the company Roche.

28
00:03:00,180 --> 00:03:05,729
And the Phase one study of this drug included multiple types.

29
00:03:05,730 --> 00:03:15,120
So it really started with a pretty traditional phase one, three plus three design, looking at the eye, trying to identify the maximum tolerated.

30
00:03:15,330 --> 00:03:21,180
So you can see on this top part of this figure the doses that were investigated in the three plus three design.

31
00:03:21,600 --> 00:03:25,500
And then there were these expansion cohorts down here in a bunch of different tumor types.

32
00:03:28,050 --> 00:03:32,160
And the results of the Phase one trial, they ended up enrolling 95 patients.

33
00:03:32,160 --> 00:03:39,990
So it was a pretty large trial. In the end with the expansion cohorts and this biomarker subgroup of interest called the ICI two or three subgroup.

34
00:03:40,290 --> 00:03:45,000
And that means a certain number of PD-L1 expressing cells,

35
00:03:45,060 --> 00:03:54,930
immune expressing cells so that this was greater than I think 5% a of pd l one expressing cells in this sub in this biomarker subgroup of interest.

36
00:03:54,930 --> 00:03:58,469
They had a 40% response rate in this phase one trial.

37
00:03:58,470 --> 00:04:01,470
So they didn't take it on to phase two. They consider that promising.

38
00:04:02,550 --> 00:04:13,440
And in the phase two trial where you can see in the subgroup of interest there were 100 patients, but the whole phase two trial had 310 patients.

39
00:04:15,030 --> 00:04:20,549
They got an objective response rate of 26%, which they were comparing to a historical control rate of 10%.

40
00:04:20,550 --> 00:04:24,690
So they did consider that promising and went on to phase three.

41
00:04:25,650 --> 00:04:28,950
But before the phase three trial was concluded,

42
00:04:29,370 --> 00:04:36,149
this drug was granted accelerated approval for the indication of metastatic urothelial carcinoma on the basis of those phase two trial results.

43
00:04:36,150 --> 00:04:38,520
So it was approved and it started being used in patients.

44
00:04:41,060 --> 00:04:48,740
And then when the phase two trial concluded, they found no difference between Atezolizumab and standard of care chemotherapy in a randomized trial.

45
00:04:48,740 --> 00:04:52,219
So this trial enrolled like 900 and some patients.

46
00:04:52,220 --> 00:04:58,160
But you can see in this biomarker subgroup of interest, they were maybe a little over 100 patients in each of the randomized groups.

47
00:04:58,160 --> 00:05:05,959
And we see here these overlapping overall survival curves with a hazard ratio of 0.87.

48
00:05:05,960 --> 00:05:14,300
And when we look at the response rates and the biomarker subgroup of interest, they were 23% versus 21.6%.

49
00:05:15,970 --> 00:05:26,320
So there was no difference. And the company voluntarily withdrew the approval for this indication on the basis of these phase three trial results.

50
00:05:27,580 --> 00:05:32,420
It was slightly better, wasn't it? When you look at the survival curve, it's good at the end.

51
00:05:32,830 --> 00:05:45,320
Yeah, maybe a little bit at the end. Yeah. Yeah. You know, they've done some follow up studies on this, though.

52
00:05:46,220 --> 00:05:50,810
The interesting thing about this trial, just say a little bit more about that, because that's a good question.

53
00:05:53,480 --> 00:05:57,469
Even though they were interested in this biomarker subgroup, this I.S. two or three subgroup,

54
00:05:57,470 --> 00:06:01,820
the whole trial was actually planned around the entire patient population.

55
00:06:02,120 --> 00:06:07,790
So I'm showing here the results for the subgroup, which does look maybe a little better in the tails of this plot.

56
00:06:07,790 --> 00:06:12,349
But the mean study was in the overall patient population, which looked even worse.

57
00:06:12,350 --> 00:06:18,950
But I think this is particularly of interest because they had these higher response rates in this subgroup

58
00:06:18,950 --> 00:06:27,500
of interest and it really showed that this biomarker is predictive as a prognostic biomarker in this case.

59
00:06:27,510 --> 00:06:33,409
So both the standard of anyone in this biomarker subgroup is doing better than patients, not in this biomarker subgroup.

60
00:06:33,410 --> 00:06:38,750
So I didn't show those results. But the response rates are much lower in the patients, not in this biomarker subgroup.

61
00:06:45,970 --> 00:06:48,070
Okay. So based on the results of this,

62
00:06:48,070 --> 00:06:54,320
I'm going to talk about three areas of methodological improvement that could help avoid this type of situation in future trials.

63
00:06:54,340 --> 00:06:59,860
The first is dose expansion cohort design. The second is phase two design, and the third is a basket trial.

64
00:07:00,490 --> 00:07:03,729
So I'll go through each of these individually and I can pause for questions.

65
00:07:03,730 --> 00:07:08,980
Anytime you have a question, please raise your hand. So I'll start with dose expansion cohort design.

66
00:07:11,050 --> 00:07:18,820
So the use of dose expansion cohorts, as I mentioned in the very beginning, is really been increasing over time with these new types of therapies.

67
00:07:18,820 --> 00:07:25,330
And you can see here that in this meta analysis that was published in JCO in 2013,

68
00:07:25,750 --> 00:07:34,629
that the percentage of phase one trials, including an expansion cohort, increased from 12% in 2006 to 38% in 2011.

69
00:07:34,630 --> 00:07:38,030
And I would not be surprised if that's even gone up since then.

70
00:07:39,580 --> 00:07:44,530
And In a different matter analysis published in Clinical Cancer Research in 2017,

71
00:07:44,920 --> 00:07:51,970
they found that trials with expansion cohorts did have higher rates of Phase two success, but that larger trials weren't necessarily better.

72
00:07:52,000 --> 00:07:59,350
So in this plot, from that meta analysis, the number of patients enrolled in the expansion cohorts on the x axis and the probability of

73
00:07:59,350 --> 00:08:05,860
having at least one positive phase two trial for that treatment being studied is on the Y axis.

74
00:08:05,860 --> 00:08:12,610
And you can see there's kind of a plateau starting pretty, pretty low, maybe around 20 or 40 patients in this and this plot.

75
00:08:14,920 --> 00:08:20,170
So the goal here was to develop a pre specified dose expansion design that can maintain

76
00:08:20,170 --> 00:08:25,900
traditional error rate control while also making efficient use of possibly limited resources,

77
00:08:26,040 --> 00:08:28,390
meaning keeping the sample size as small as possible.

78
00:08:31,170 --> 00:08:38,190
And if utility stopping is one way that we can do this, it can be used as a mechanism to achieve multiple feasible goals,

79
00:08:38,190 --> 00:08:45,660
including being ethical for patients, not enrolling patients on drugs that aren't working, and also making an efficient use of resources.

80
00:08:48,480 --> 00:08:53,549
So we'll consider the setting of a one hour clinical trial as a binary response and point,

81
00:08:53,550 --> 00:08:57,030
which is the most common type of endpoint used in this type of trial.

82
00:08:57,510 --> 00:09:05,400
And a patient either has the outcome or not so that they can either be assigned to the one or those zero.

83
00:09:05,700 --> 00:09:10,890
And then this Capital X will be our total number of responses out of the patients we've observed so far.

84
00:09:11,280 --> 00:09:13,169
And typically in a trial like this,

85
00:09:13,170 --> 00:09:19,530
we wish to test the null hypothesis that our response rate is less than some unacceptable level versus the alternative.

86
00:09:19,530 --> 00:09:26,250
That our response rate is greater than some acceptable level. P one toxicity is not part of this one.

87
00:09:26,700 --> 00:09:36,290
No, no. So in this in this setting, I'm imagining the scenario where the toxicity has already been studied in a phase one way,

88
00:09:36,570 --> 00:09:39,809
and now we're in phase one B doing an expansion to really look at preliminary

89
00:09:39,810 --> 00:09:44,460
efficacy and imagining that the dose has already been established as being safe.

90
00:09:49,040 --> 00:09:54,860
So I'll be using the Bayesian statistical paradigm for this, this work.

91
00:09:54,870 --> 00:10:05,570
And so we have our prior here, which is a beta prior and specifically here I'll be only talking about a beat up point, 5.5 higher here which is.

92
00:10:06,580 --> 00:10:07,900
Somewhat uninformative.

93
00:10:08,290 --> 00:10:17,830
So our likelihood is the binomial likelihood for a data because we have that binary response and beta is the conjugate prior for our likelihood.

94
00:10:17,840 --> 00:10:25,899
So we have a beta posterior as well with this form. And so then we would declare our treatment to be efficacious at a posterior

95
00:10:25,900 --> 00:10:30,900
threshold of theta if our probability that our response rate exceeds that null,

96
00:10:30,910 --> 00:10:40,520
given our data is greater than that threshold. So predictive probability monitoring will stop the trial according to a threshold as well.

97
00:10:40,520 --> 00:10:48,110
So the posterior predictive distribution of the number of responses X star in the remaining patients that we haven't seen yet.

98
00:10:48,110 --> 00:10:55,040
So this is at an interim moderating point when we don't have all our patients follows a beta binomial distribution and then we

99
00:10:55,040 --> 00:11:03,890
can calculate the posterior predictive probability of success at the end of the trial when we have reached full enrollment.

100
00:11:04,160 --> 00:11:08,030
And so then we've stopped for futility at our predictive threshold data star if

101
00:11:08,030 --> 00:11:12,440
our posterior predictive probability falls below this predictive threshold.

102
00:11:15,060 --> 00:11:22,320
So the challenge with a design like this is calibrating those two thresholds to have operating

103
00:11:22,320 --> 00:11:26,310
characteristics that are acceptable in terms of the type one error and the power of the study.

104
00:11:26,700 --> 00:11:29,849
And so the way we're going to do this is just by looking at a grid search.

105
00:11:29,850 --> 00:11:37,080
So imagine a grid like this of our posterior thresholds on the rose data and our predictive thresholds on the column status star.

106
00:11:37,110 --> 00:11:45,929
So in this case, we would be looking at using simulation methods to calculate the operating characteristics for, in this case,

107
00:11:45,930 --> 00:11:51,240
40 different designs and then choosing a design that would be acceptable in terms of the type one area in power.

108
00:11:53,500 --> 00:11:56,110
So you know your sample size already? Yes.

109
00:11:56,120 --> 00:12:03,710
So you have to fix the sample size, the maximum sample size, and you also have to fix when you're going to do the interim monitoring looks.

110
00:12:05,300 --> 00:12:09,890
After how many patients? And I'll show you what I did in this in a couple of slides.

111
00:12:11,180 --> 00:12:14,690
So then, you know, you have these 40 designs. How do you choose one?

112
00:12:16,070 --> 00:12:22,670
So the work that I sent in one of the papers in the JCO precision oncology paper that I sent proposed

113
00:12:22,670 --> 00:12:28,130
to optimization criteria for selecting a design from among those options from the grid search.

114
00:12:28,790 --> 00:12:34,310
The first is called the Optimal Accuracy Design, and the second is called the Optimal Efficiency Design.

115
00:12:34,670 --> 00:12:39,889
And so for the optimal accuracy design, imagine that you take your 40 designs.

116
00:12:39,890 --> 00:12:46,490
So each of these points represents one of those designs. And you plot the type one error on the X axis versus the power on the Y axis.

117
00:12:47,030 --> 00:12:53,089
And then you can imagine calculating some type of distance to select a design.

118
00:12:53,090 --> 00:12:58,160
And I'll show you what I, what what I used for that on the next slide and the optimal efficiency design.

119
00:12:58,460 --> 00:13:03,860
Again, these are all the points from our possible designs with different threshold combinations.

120
00:13:04,190 --> 00:13:10,880
So on the x axis we have the average sample size under the knoll, and on the y axis is the average sample size under the alternative.

121
00:13:12,170 --> 00:13:16,060
And seven. Mm. Tons of us pretty spare.

122
00:13:16,100 --> 00:13:21,340
So yes. So you have yes. You have to set the number and the alternative rate, that unacceptable rate.

123
00:13:21,720 --> 00:13:23,750
P Not in the acceptable rate. P one.

124
00:13:26,660 --> 00:13:32,600
And so then you simulate under both a null scenario and alternative scenario to calculate these operating characteristics for both.

125
00:13:33,780 --> 00:13:40,499
And I noted here that the optimal efficiency design really does need to be subject to constraints on the type one error in power,

126
00:13:40,500 --> 00:13:48,420
because otherwise it is possible to find to identify an optimal design that has either very low type one error or too low power.

127
00:13:51,080 --> 00:14:00,229
So in this case, I'm proposing to use Euclidean distance for this so we can do it with optional weights on those two points.

128
00:14:00,230 --> 00:14:05,780
So without weights, we're just looking at the closest point to this top left point on both of these plots.

129
00:14:07,280 --> 00:14:13,040
But there could be weights put on the x axis or the y axis, depending on the clinical setting of interest.

130
00:14:16,820 --> 00:14:21,440
Okay. So back to the case study of metastatic urothelial carcinoma.

131
00:14:22,880 --> 00:14:29,240
This was the original design of the study, which had a number of planned expansion cohorts and metastatic urothelial carcinoma.

132
00:14:29,240 --> 00:14:32,810
Wasn't actually even one of those. It was added later through a protocol amendment.

133
00:14:34,340 --> 00:14:38,419
And it's not very clear even in the protocol what the design of the study was.

134
00:14:38,420 --> 00:14:45,950
So the original expansion cohort design for those preplanned cohorts was to have a total sample size of 40 patients with an

135
00:14:45,950 --> 00:14:52,760
into a single interim a futility look that would stop the trial if there were zero responses out of the first 14 patients.

136
00:14:53,210 --> 00:15:01,490
And they said in the protocol this was led to a 4.4% chance of stopping if the true 20%.

137
00:15:02,940 --> 00:15:06,509
But the metastatic urothelial carcinoma cohort enrolled 95 patients.

138
00:15:06,510 --> 00:15:09,690
So it clearly wasn't following this preplanned design,

139
00:15:10,140 --> 00:15:15,780
and I never was able to find any information about this and there wasn't any stated alternative response rate.

140
00:15:16,110 --> 00:15:19,220
So was it 20%? Is that why they have this in there?

141
00:15:19,230 --> 00:15:23,130
So it's a little unclear what these designs were from the protocol.

142
00:15:24,500 --> 00:15:29,000
So I investigated six different simulation settings based on the original.

143
00:15:29,420 --> 00:15:32,030
Or you could call it inferred of trial design.

144
00:15:33,140 --> 00:15:39,379
I looked at two different null response rates point one or point two and two different alternative response rates, either point two or point three.

145
00:15:39,380 --> 00:15:44,570
So that that's either a 10% increase in efficacy with the new treatment or at 20%.

146
00:15:45,020 --> 00:15:52,430
And then I looked at two sample sizes of 40, which was what was planned in the protocol and then 95, which was the realized sample size of the trial.

147
00:15:55,520 --> 00:16:02,660
And I, I looked at those 40 different combinations of posterior predictive thresholds that I showed earlier.

148
00:16:03,530 --> 00:16:07,900
So here I'm showing the results for the optimal efficiency design.

149
00:16:07,910 --> 00:16:12,049
So again, on the x axis, we have the average sample size under the normal.

150
00:16:12,050 --> 00:16:15,680
On the y axis is the average sample size under the alternative.

151
00:16:16,070 --> 00:16:20,120
And this orange point is the optimal efficiency design with no weighting.

152
00:16:20,120 --> 00:16:28,040
So considering equally those two sizes, this black diamond is the protocol design with that single futility look.

153
00:16:28,040 --> 00:16:32,360
So you can see that the optimal efficiency design.

154
00:16:33,530 --> 00:16:43,069
Uses far fewer patients, especially under the north. And here are the other characteristics of these trials.

155
00:16:43,070 --> 00:16:47,180
We can see that the protocol design is on the bottom in each of these sections.

156
00:16:47,180 --> 00:16:51,500
So each of these little table sections is a different combination of null and alternative.

157
00:16:51,890 --> 00:16:56,810
And the protocol designs have both two low type one error and two low power.

158
00:16:57,050 --> 00:17:00,170
The powers are on 50% for all of these different combinations.

159
00:17:00,470 --> 00:17:05,090
This whole table is for a sample size of 95. I'm not showing the results for a sample size of 40 here,

160
00:17:06,050 --> 00:17:13,010
whereas these optimal designs using predictive probability monitoring have much higher power and closer

161
00:17:13,010 --> 00:17:19,940
to that .05 level of type one error that we're kind of aiming for closer to that range of 0.52.1.

162
00:17:21,380 --> 00:17:25,250
And again, they have much smaller sample sizes under both the null and alternative.

163
00:17:26,200 --> 00:17:29,889
So you're really able to identify a design with much better operating characteristics

164
00:17:29,890 --> 00:17:33,760
than what was used in practice using fewer patients and still having higher power.

165
00:17:33,910 --> 00:17:43,950
By incorporating these predictive probability methods for futility, stopping you looking at every how often are you doing this sort of interim look?

166
00:17:44,830 --> 00:17:52,600
So I'll show that here. So I did it every five patients, up to a total of possible possibly 95 patients.

167
00:17:52,600 --> 00:17:58,270
So there is a possibility of stopping pretty early on these trials, even after five patients.

168
00:17:58,270 --> 00:18:01,749
But what I'm showing here is the decision walls.

169
00:18:01,750 --> 00:18:06,040
So the nice these designs are a little computationally intensive to get.

170
00:18:06,070 --> 00:18:12,129
But the nice thing is you can get all the properties of them before you start your trial and you can have either a table or a plot like this,

171
00:18:12,130 --> 00:18:17,630
a decision rule. So here we have on the x axis the sample size of the interim analysis.

172
00:18:17,650 --> 00:18:22,959
You can see looking after every five patients and the number of responses on the Y axis.

173
00:18:22,960 --> 00:18:28,160
And here are the decisions at each of these and around ten points of whether you would stop or proceed.

174
00:18:28,180 --> 00:18:34,239
So you can see after the first five patients, we would stop the trial if we saw zero responses.

175
00:18:34,240 --> 00:18:46,300
Otherwise we would continue on and so on and so forth. And you can also calibrate for this portion of the design by examining different stopping

176
00:18:46,960 --> 00:18:53,980
calendars and seeing what the operating characteristics under different stopping calendars,

177
00:18:53,980 --> 00:19:02,170
what they look like, and how they would compare to a new picture which has looks like an RC kind of.

178
00:19:03,760 --> 00:19:12,370
Walk me through why it's good to be close to the top left. Oh, it's good to be close to the top left because when we're under the null scenario,

179
00:19:12,370 --> 00:19:18,579
we want the sample size to be as small as possible because we don't want to be treating patients on a drug that doesn't work.

180
00:19:18,580 --> 00:19:24,729
So in the null setting, the drug doesn't work. So we really want to be stopping that trial early and so that those patients

181
00:19:24,730 --> 00:19:28,900
are free to enroll in another trial or go on to some other type of treatment.

182
00:19:29,290 --> 00:19:31,600
And under the alternative, when the drug does work,

183
00:19:31,780 --> 00:19:38,349
we want to be maximizing that sample size and treating as many patients as possible to get that information on the efficacy.

184
00:19:38,350 --> 00:19:46,360
And also to I mean, this is considering that in the setting we're in, these patients don't have treatment alternatives.

185
00:19:46,360 --> 00:19:49,630
And so we do want to be treating them on these trials if the drug is working.

186
00:19:51,640 --> 00:19:56,950
Does that make sense? Yeah. On the table where you showed the actual, like.

187
00:19:57,220 --> 00:20:05,100
I think. Yeah. That one. Yeah. So it seems like what this is showing is that the protocol was to too conservative.

188
00:20:05,130 --> 00:20:15,690
Yes. But kind of like the lesson that I tell as a man was that I that I was like that maybe I should have stopped sooner.

189
00:20:15,900 --> 00:20:23,000
Yeah. Yeah. So, you know, this is this is the alternative being that the drug doesn't work.

190
00:20:23,010 --> 00:20:26,700
And in in the actual case of it's easily is a map.

191
00:20:27,240 --> 00:20:31,229
The drug wasn't better than the alternative. And so I'm going to get into that.

192
00:20:31,230 --> 00:20:38,370
And the next part is that like this is a still assuming that the drug and you can't.

193
00:20:40,280 --> 00:20:43,819
You can't ever really get around that. Like the drug doesn't work.

194
00:20:43,820 --> 00:20:48,709
The drug doesn't work. But this would allow you to stop if it if it was showing that it didn't.

195
00:20:48,710 --> 00:20:55,370
But in this case, you would have the same problem for the at least mapped study even using this design if if the

196
00:20:55,370 --> 00:21:01,010
drug was working like it did in the phase one trial compared to a historical control rate,

197
00:21:01,490 --> 00:21:07,580
you would still say that the drug was working. That's definitely true. I'll talk about that a little bit more in the next section, though.

198
00:21:12,690 --> 00:21:16,830
Any other questions about the dosing, this dose expansion cohort part before I go on?

199
00:21:17,700 --> 00:21:25,730
Yeah. When you did the curves, why did you choose to do a Euclidean distance instead of just like an area underneath it?

200
00:21:26,140 --> 00:21:34,170
They are discrete points. You know, I no reason.

201
00:21:36,900 --> 00:21:42,809
Yeah. I you know, I was trying to think about and I think you would get the same you would get the same kind of result.

202
00:21:42,810 --> 00:21:49,260
Either way, you can you can do the same calculations considering calling it an hour of secret or just looking at the individual points.

203
00:21:49,260 --> 00:21:52,319
But in this case, you know, it's just a discrete number of points.

204
00:21:52,320 --> 00:21:58,560
And so there's there's no reason not to just do a simple distance, um, allowing for the weight it gives you some of those options to.

205
00:22:02,170 --> 00:22:08,980
The company probably likes to have a bigger expansion cohort because it gives them more data to go to the FDA sooner.

206
00:22:09,850 --> 00:22:16,700
Yeah. Yeah. And you know, if the drug is working, then you get a U.N. that you should end up with a pretty large sample size.

207
00:22:16,960 --> 00:22:21,100
You can see that, you know, the total maximum was 95.

208
00:22:21,100 --> 00:22:28,299
And under the alternative, this is getting pretty close to some of these designs are getting pretty close to full enrollment under the alternative.

209
00:22:28,300 --> 00:22:31,450
So getting up to, you know, 80, 90 patients.

210
00:22:31,810 --> 00:22:37,200
So I think that's pretty acceptable. It's a pretty large sample size to move forward.

211
00:22:37,200 --> 00:22:41,669
And we're still talking about the phase one setting here. So this is a phase one dose expansion cohort.

212
00:22:41,670 --> 00:22:47,690
So you would still have your phase two trial after this to. Anything else?

213
00:22:49,400 --> 00:22:57,920
All right. So next, I'm going to talk about phase two design and I'll get into some of these issues of what actually went on in this trial because.

214
00:22:59,560 --> 00:23:04,240
So pointed out, this wouldn't have helped in this case. We still would have said the drug was working.

215
00:23:07,720 --> 00:23:18,220
So just a reminder of these numbers that I showed earlier in the phase two trial, we saw this 26% response rate in the biomarker subgroup of interest.

216
00:23:18,640 --> 00:23:25,540
And then in phase three, we saw a pretty similar response rate on the on the in the treatment group of 23%.

217
00:23:25,540 --> 00:23:28,270
So that confirmed what we found in phase two.

218
00:23:28,810 --> 00:23:39,070
But the response rate to chemotherapy was close to 22%, so much higher than the 10% historical control rate that they use to plan this trial.

219
00:23:40,240 --> 00:23:45,549
And this can happen as this can be a problem because historical control rates really arise

220
00:23:45,550 --> 00:23:49,900
as population averages and they may not apply to these biomarker targeted subgroups.

221
00:23:49,900 --> 00:23:53,530
And so in this case, they did have a fantastic biomarker.

222
00:23:53,530 --> 00:23:59,680
And so the historical control rate of 10% just wasn't wasn't right for this subgroup of interest.

223
00:24:01,750 --> 00:24:05,139
So I mentioned that with the atezolizumab,

224
00:24:05,140 --> 00:24:11,650
it got the accelerated approval and it was being used while the phase three trial was going on, the phase three trial.

225
00:24:12,940 --> 00:24:18,460
I don't remember exactly what year it came out, but it came out no results.

226
00:24:19,000 --> 00:24:22,989
But this approval is still out there and this is a thing that's known as a dangling,

227
00:24:22,990 --> 00:24:27,310
accelerated approval, and it's something that the FDA is now kind of looking out for.

228
00:24:27,910 --> 00:24:32,350
But in this table, I'm showing some other examples of this that's easily is a map is not the only one.

229
00:24:32,380 --> 00:24:40,510
There were actually ten dangling accelerated approvals just among anti PD-L1 antibodies, which is what the Teasel use map the drug class.

230
00:24:40,510 --> 00:24:43,959
But people use a map between 2015 and 2021.

231
00:24:43,960 --> 00:24:48,340
So that's a large number. And I'm only talking about this one class of drugs right now.

232
00:24:49,060 --> 00:24:56,560
And you can see here a use map is up here. So the FDA actually did kind of a review of these all of these accelerated approvals and

233
00:24:56,560 --> 00:25:01,420
found that there were quite a few of them that were still have their approval on the market.

234
00:25:01,420 --> 00:25:04,150
But the phase three trial had shown no results.

235
00:25:04,330 --> 00:25:12,819
And so they kind of did this audit of their accelerated approvals and many of the companies withdrew these approvals for their indication.

236
00:25:12,820 --> 00:25:16,630
And the FDA kind of went back to the ones who didn't voluntarily do that.

237
00:25:20,020 --> 00:25:25,239
So the goal here is to develop a randomized phase two design for trials of biomarker targeted

238
00:25:25,240 --> 00:25:30,520
subgroups using their optimal efficiency predictive probability method that I already mentioned.

239
00:25:31,660 --> 00:25:39,160
And the reason that I'm interested in randomization here in the phase two setting is to get that control rate right.

240
00:25:41,570 --> 00:25:49,630
By having a contemporary group of controls, you won't run into that problem of having the wrong the wrong historical control.

241
00:25:51,880 --> 00:25:56,890
So now I'm going to be considering the setting of a randomized to our ARM trial with three biomarker subgroups.

242
00:25:56,890 --> 00:26:03,250
So similar to the Italy's. I mean, have they had the biomarker subgroup of interest, which was the ICI two or three subgroup?

243
00:26:03,790 --> 00:26:10,660
And then there were patients also classified as ICI zero, so they had no PD-L1 expressing immune cells and ICI one,

244
00:26:10,960 --> 00:26:17,440
which was between zero of between one and 5%, PD-L1 expressing immune cells.

245
00:26:17,710 --> 00:26:25,420
So those are the three subgroups. They have equal population prevalence of 33%, which was the case in this population.

246
00:26:26,350 --> 00:26:30,370
And the null response rate in the design of these trials will be based on the historical

247
00:26:30,370 --> 00:26:35,139
control rate of 10% and then subgroup specific alternative response rates of 10%,

248
00:26:35,140 --> 00:26:40,750
20% and 30%. So in this case, we're hypothesizing the biomarker to be predictive.

249
00:26:45,880 --> 00:26:50,830
So I'm proposing three different randomized designs. The first is a pooled control arm design.

250
00:26:51,340 --> 00:26:59,950
So we enroll all the patients and then randomized to either a chemotherapy arm or easily a smart arm and a 3 to 1 ratio of treatment to control.

251
00:27:00,400 --> 00:27:07,690
And then in the atezolizumab arm, the PD-L1 testing is conducted and the patients are stratified into the three subgroups.

252
00:27:07,900 --> 00:27:16,640
And so this is a cool control group. And they'll talk about the pros and cons of different design.

253
00:27:16,650 --> 00:27:19,800
So the second is a stratified controller design.

254
00:27:20,340 --> 00:27:23,940
So you enroll 300 patients, conduct PD-L1 testing on all of them.

255
00:27:24,240 --> 00:27:26,190
Stratify them into three subgroups.

256
00:27:26,460 --> 00:27:34,010
And then do randomization within the three subgroups, 1 to 1 randomization to either with chemotherapy standard of care or having introduced arm.

257
00:27:36,170 --> 00:27:41,930
And the third is an encouragement design, where the stage one is just the pooled controller design that I already showed.

258
00:27:42,440 --> 00:27:49,160
And then you choose a winning subgroup from this stage, and I'll talk about how I did that and a little bit.

259
00:27:49,520 --> 00:27:53,730
And in the stage two, you'll hear more patients from the winning subgroup.

260
00:27:53,810 --> 00:27:58,130
You conduct PD-L1 testing on all of them, only keep the patients from the winning.

261
00:27:58,340 --> 00:28:01,909
I'm sorry I said that wrong. You enroll patients, do the PD-L1 testing,

262
00:28:01,910 --> 00:28:07,670
then you only keep patients from the winning subgroup and you randomize them 1 to 1 to chemotherapy in its latest map.

263
00:28:07,940 --> 00:28:13,910
But then you include the stage one patients from the winning subgroup in this comparison as well.

264
00:28:14,750 --> 00:28:18,750
So this is 500 patients in this study. Yeah.

265
00:28:18,840 --> 00:28:23,250
That you need to screen. You actually enrolled 200 over here and you keep 100 over here.

266
00:28:23,430 --> 00:28:29,340
You want because you want to keep the patients from the winning subgroup, which in this case we're saying is about a third of a population.

267
00:28:31,620 --> 00:28:39,450
So this one also can enroll a maximum of 300. And here are the results.

268
00:28:39,780 --> 00:28:45,990
For this, I'm looking at the same 40 combinations of posterior and predictive, and in this case,

269
00:28:47,190 --> 00:28:51,840
looking after every ten patients and are doing interim monitoring after every ten patients.

270
00:28:52,500 --> 00:28:56,430
And so here are the optimal efficiency results.

271
00:28:57,240 --> 00:29:03,959
So the average sample size under the null is on the x axis and the average sample size under the alternative is on the Y axis.

272
00:29:03,960 --> 00:29:07,800
And the panels here are the three different designs.

273
00:29:07,800 --> 00:29:13,320
So the pooled stratified in enrichment and the scoring point is our optimal efficiency design with no weighting.

274
00:29:13,320 --> 00:29:22,680
So just the closest point to this top left corner. And we can see that all of these designs result in a much lower average sample size than the 310.

275
00:29:22,680 --> 00:29:26,850
That was the actual phase two sample size of the tea leaves and study.

276
00:29:27,210 --> 00:29:31,590
And that study didn't even include controls that was all treated patients in the 310 patients.

277
00:29:31,590 --> 00:29:36,780
So these sample sizes are much lower than that, both under the null and the alternative.

278
00:29:39,250 --> 00:29:43,149
And the operating characteristics are reasonable for them as well.

279
00:29:43,150 --> 00:29:51,850
So we see that for the subgroup of interest and the pool design, we have a type one error of 7% and a power of 80%.

280
00:29:52,360 --> 00:29:55,870
The power and type one error are quite low for the other two subgroups of interest.

281
00:29:55,870 --> 00:30:00,040
But that's acceptable in this case because we're not really interested in what's going on in those subgroups.

282
00:30:01,510 --> 00:30:05,440
And the stratified design is very similar to the pooled and we only get operating

283
00:30:05,440 --> 00:30:10,540
characteristics for the overall overall operating characteristics for the enrichment design.

284
00:30:10,930 --> 00:30:18,250
And I targeted a 10% type one error in stage one and I wanted to keep that kind of on the higher end.

285
00:30:18,670 --> 00:30:28,989
And so the way I targeted that was I looked and chose the winning subgroup was to look at the 80th percentile of predicted probability

286
00:30:28,990 --> 00:30:38,380
for each of the subgroups and choose a subgroup that was that had the highest predictive probability of success at the end of the trial,

287
00:30:39,910 --> 00:30:43,149
subject to a lower bound, which was the 80th percentile.

288
00:30:43,150 --> 00:30:49,420
So if none of them met that, then they would stop the trial after stage one.

289
00:30:52,340 --> 00:30:56,180
And this was calibrated to have a 10% type one error rate in that stage one.

290
00:30:56,690 --> 00:31:05,930
And in this case, actually, 100% of the time that it moved that this design moved a subgroup forward to stage two.

291
00:31:06,260 --> 00:31:10,190
It was always the subgroup, the right subgroup, the ICI two, three subgroup.

292
00:31:10,520 --> 00:31:15,470
So these characteristics here for stage two could be considered the ICI to three characteristics.

293
00:31:15,560 --> 00:31:18,650
Yeah, I actually have two questions at this point.

294
00:31:18,980 --> 00:31:22,880
So what if the treatment was equally efficacious in all three subgroups?

295
00:31:23,190 --> 00:31:25,030
Does the design allow you to? Maybe I misspoke.

296
00:31:25,160 --> 00:31:30,980
Could you pick all three or is there some sort of test or assessment of that if they were completely equal?

297
00:31:33,560 --> 00:31:37,340
If the biomarkers are not predictive at all. If it's just if it was just a noise.

298
00:31:37,670 --> 00:31:42,140
Yeah. So I did not look at the possibility of picking all three.

299
00:31:42,590 --> 00:31:45,889
But the enrichment design would not work very well in that setting.

300
00:31:45,890 --> 00:31:49,310
I actually ran that simulation setting and it's it's it.

301
00:31:49,310 --> 00:31:54,320
It's in the paper. And now I have to try and remember off the top of my head what the results were.

302
00:31:54,320 --> 00:31:57,500
But it was pretty low power because it it only guesses the rate.

303
00:31:57,500 --> 00:32:01,970
So, you know, if they're equally efficacious, it's only going to get the right subgroup like a third of the time.

304
00:32:03,800 --> 00:32:10,070
And just back to maybe to Jeremy's earlier. So if that's your hypothesized setting, this is not a design that you would want to use.

305
00:32:10,400 --> 00:32:13,460
And sometimes you don't know when you're designing. Oh, I know, I know.

306
00:32:13,850 --> 00:32:18,979
Yeah. And back to Jeremy's question about the average sample size under the alternative

307
00:32:18,980 --> 00:32:24,530
and know if all of those designs give you the same power and type one error rate.

308
00:32:25,160 --> 00:32:28,940
I guess I'm still trying to think why you don't want to be closest to the bottom. Oh, they're not all the same.

309
00:32:29,030 --> 00:32:33,139
Oh, I thought they all controlled the type. I'm not the same, but they're not all the same.

310
00:32:33,140 --> 00:32:37,820
So actually in this plot, I don't think I filtered any of those out.

311
00:32:37,820 --> 00:32:40,970
So some of these could have very low power or very low type one error.

312
00:32:41,180 --> 00:32:48,560
Then when I did, but when I chose that orange point that's on here, I did limit it in this case to designs that had at least 80%,

313
00:32:48,770 --> 00:32:54,830
I think it was at least 80% power and type one error between .05 and point one.

314
00:32:55,130 --> 00:32:59,640
But I'm showing all the plot, all the points here. So some of these points you would not consider, okay,

315
00:32:59,720 --> 00:33:07,580
because you wouldn't necessarily want to maximize sample size under the alternative necessarily know if it didn't achieve gains in power, right?

316
00:33:07,670 --> 00:33:12,550
Yeah. Yeah. You want to be done and you have your significant results or move on or something like that.

317
00:33:12,890 --> 00:33:17,209
Yeah, maybe I should have used a different point to show which ones actually met those criteria,

318
00:33:17,210 --> 00:33:23,030
but I think it was only like six of the 40 thresholds were in that range of acceptable, acceptable power and type one error.

319
00:33:23,570 --> 00:33:30,230
So still to that point that if you have six of those dots at all. A satisfactory power in sample size.

320
00:33:30,860 --> 00:33:33,800
Why do you want to be closest to the top left and not the bottom left?

321
00:33:33,920 --> 00:33:38,690
Well, I'm considering the setting where these are patients who really don't have any other treatment options.

322
00:33:38,690 --> 00:33:44,430
And so we do want to be enrolling as many patients as possible because these approval processes take so long.

323
00:33:44,750 --> 00:33:49,430
Like this is the only. A lot of times this is the only treatment option for these patients.

324
00:33:49,430 --> 00:33:52,610
So if we think if that if we have evidence that drug is working, we.

325
00:33:54,000 --> 00:33:59,280
The reason I'm saying top left is because it's the idea that we want to enroll as many patients as possible

326
00:33:59,280 --> 00:34:03,720
on this trial because those are patients who won't get any treatment that works for them otherwise.

327
00:34:04,470 --> 00:34:08,450
So. But that wouldn't be true in every setting.

328
00:34:08,450 --> 00:34:09,870
So if, you know,

329
00:34:10,430 --> 00:34:17,030
there could be a there could be a treatment setting where you wouldn't necessarily want that and then you could use those weeks to control that.

330
00:34:18,440 --> 00:34:21,610
Yeah. Yeah.

331
00:34:21,610 --> 00:34:29,530
So these are all really good questions. So here's a table kind of trying to think about some of the ways you could decide between these different.

332
00:34:30,510 --> 00:34:36,030
Settings. And, you know, you don't always know what your truth is.

333
00:34:36,030 --> 00:34:42,629
And so my I think that the stratified control arm design is really the one that's going to give you the

334
00:34:42,630 --> 00:34:50,460
most information because you get those and you get those individual biomarker specific control group rate.

335
00:34:50,470 --> 00:34:52,350
So that's the only design that's going to give you.

336
00:34:52,350 --> 00:34:59,249
That rate for all three of those is the only design that would allow have allowed you in this case of a to easily use something app to find out at the

337
00:34:59,250 --> 00:35:03,540
phase two setting that this was a prognostic biomarker and that the patients

338
00:35:03,540 --> 00:35:07,320
in that subgroup of interest were doing better on either of these treatments.

339
00:35:07,560 --> 00:35:11,670
So this you would have had a field phase two trials still you would have concluded no difference,

340
00:35:11,670 --> 00:35:16,409
but you would have gotten that information much sooner in this case.

341
00:35:16,410 --> 00:35:20,069
And I put this question, I used to have a check mark here,

342
00:35:20,070 --> 00:35:25,080
but I put this question mark here just because I still think this is the best design for this setting.

343
00:35:25,560 --> 00:35:30,270
But you will still end up with a quote unquote, failed trial in that case.

344
00:35:32,420 --> 00:35:40,040
Yes. It also seems like another point in stratified favor is that you don't have to turn away patients after you've tested them.

345
00:35:40,040 --> 00:35:43,090
Yes. Or tested their disease for the biomarker because.

346
00:35:43,160 --> 00:35:49,160
That's right. And also like from the companies, the funders perspective, like you're paying for a lot of.

347
00:35:51,270 --> 00:35:54,270
Sampling. Yeah. Why don't you pay for the testing and the screening?

348
00:35:54,270 --> 00:35:57,990
You kind of just want to enroll those patients, right? Yeah, that's a that's a really good point, too.

349
00:35:58,950 --> 00:36:00,840
Just one other quick question. Yeah. I don't know.

350
00:36:00,960 --> 00:36:07,660
All of these settings are there are some settings where you think that drug may be most efficacious in the middle group, like for PDL one,

351
00:36:07,700 --> 00:36:14,190
always feel like it's high or you know, in some other settings it might be low is it sometimes it's middle expressing patients would be that.

352
00:36:14,400 --> 00:36:18,030
Yeah I guess I have not personally encountered a setting like that.

353
00:36:18,180 --> 00:36:26,139
It's usually either the high probability group. So you think you could just throw out those mental patients?

354
00:36:26,140 --> 00:36:30,810
I don't know. I guess I don't. Just curious. Yeah, that's a reasonable.

355
00:36:31,980 --> 00:36:35,910
You think that could happen before you run the trial? Would you believe it if that.

356
00:36:35,910 --> 00:36:46,280
If it selected the middle group? Oh, yeah. That's a really good question.

357
00:36:48,820 --> 00:36:57,580
I don't know. You know, there's there's this whole a whole nother challenge of these trials is even identifying the right biomarker.

358
00:36:57,580 --> 00:37:01,830
And this I don't have the time to talk about this today, but, you know,

359
00:37:01,840 --> 00:37:09,370
there's been some really interesting examples of where that was like a year long challenge where they knew they had a treatment that worked,

360
00:37:09,370 --> 00:37:13,959
but they didn't know why. So that's kind of the opposite problem.

361
00:37:13,960 --> 00:37:18,820
Like this is talking about a case where we think we have a known biomarker and we're trying to find a treatment to target it.

362
00:37:19,210 --> 00:37:25,540
Sometimes the opposite thing happens where people kind of accidentally discover a treatment that works in only some patients,

363
00:37:25,540 --> 00:37:27,699
but they don't know how to identify those patients.

364
00:37:27,700 --> 00:37:37,029
Are and the EGFR inhibitor because this one is a really good example of that and I'm not touching on that here,

365
00:37:37,030 --> 00:37:40,780
but these designs will help you figure out the right biomarkers. That's a good question.

366
00:37:40,780 --> 00:37:45,630
I haven't thought about that much. All right.

367
00:37:45,760 --> 00:37:52,809
So this is just my last slide on this part that the stratified control arm design average 214 patients under the alternative,

368
00:37:52,810 --> 00:37:59,680
compare with control groups in each of those subgroups compared to the 310 that was actually used in the phase two study.

369
00:37:59,680 --> 00:38:10,750
So you can you would get your answer sooner. And also you would be able to avoid enrolling the 935 patients that were on the phase three trial.

370
00:38:12,640 --> 00:38:15,160
So that's my last slide about this.

371
00:38:15,160 --> 00:38:24,940
So if anyone has questions about this phase two portion before I go on to the last section, I think you see that that average is 240 patients.

372
00:38:24,940 --> 00:38:30,669
You mean under the of like simulating under the alternative and simulating under the null or that's under the alternative?

373
00:38:30,670 --> 00:38:35,740
I think the I don't I don't have the slide up here with the total sample size under the null is lower than that.

374
00:38:36,220 --> 00:38:46,530
Okay. Yeah. It's yeah, that's a really good point because the actual trial wasn't all setting, so the sample size is even lower than under the null.

375
00:38:47,040 --> 00:38:51,090
Yeah. So in the in this case, the sample size would have been even larger.

376
00:38:51,200 --> 00:38:54,940
Yeah, that's a really good point. I don't have that up here.

377
00:38:57,280 --> 00:39:03,819
And just a quick slide to say that there's an art package I wrote in our package, too, that can implement all of these designs.

378
00:39:03,820 --> 00:39:12,010
So check it out. So the last section is on basket trial design, and I'll go through this relatively quickly.

379
00:39:12,010 --> 00:39:20,440
I'm not going to show a lot of technical details for this section, but just a quick refresher on basket trials or introduction to basket trials.

380
00:39:20,440 --> 00:39:25,870
If you're not familiar, a basket trial is when you have a single target, but multiple tier types.

381
00:39:25,870 --> 00:39:31,130
So our baskets are the different tumor types, often a different tumor location like, you know,

382
00:39:31,330 --> 00:39:38,650
breast cancer versus bladder cancer, etc., with a common genetic or biologic target and a single therapy is being studied.

383
00:39:40,350 --> 00:39:43,570
So the Atezolizumab Phase one trial was a basket trial.

384
00:39:43,590 --> 00:39:46,980
They had all these expansion cohorts in these different tumor types,

385
00:39:47,340 --> 00:39:53,070
but they planned it as independent studies for each of the different tumor types, and that's how they analyzed the data.

386
00:39:53,490 --> 00:39:56,280
So this is kind of a different slide than I showed earlier.

387
00:39:56,280 --> 00:40:00,870
It shows some of the ones they actually ended up doing, including bladder cancer and some of the others.

388
00:40:00,870 --> 00:40:05,160
So I think there was a total of one, two, three, four, five, six.

389
00:40:05,880 --> 00:40:14,580
This has nine, but I think there were ten. So the goal here is to incorporate control for multiple testing into a basket trial design

390
00:40:15,150 --> 00:40:19,469
that shares information across baskets to leverage the strength of multiple subgroups.

391
00:40:19,470 --> 00:40:25,140
Design because when you're analyzing those independently, you don't have any information about what's going on in the others.

392
00:40:25,140 --> 00:40:30,120
And so if you have unequal sample sizes or something, you really are losing out on information.

393
00:40:30,210 --> 00:40:37,080
And I'll talk about that a little bit more. So the basis of this basket trial design is the multi source exchange ability model.

394
00:40:37,080 --> 00:40:40,290
This was not my method. This is a method proposed by someone else.

395
00:40:40,290 --> 00:40:43,380
So you can check out the papers here if you're interested in it.

396
00:40:43,950 --> 00:40:53,609
But basically the multi source exchange ability model considers all possible pairwise comparisons between baskets and looks at how

397
00:40:53,610 --> 00:41:02,180
exchangeable they are and then kind of gives you uses smooths shares parameters between baskets that are considered exchangeable.

398
00:41:05,850 --> 00:41:08,559
So the diesel you hear I'm saying 11 cancer types.

399
00:41:08,560 --> 00:41:15,540
So the Atezolizumab study evaluated 11 cancer types with had very different sample sizes in the end.

400
00:41:15,540 --> 00:41:21,809
So you can see here be different sample types here, different different cancer types.

401
00:41:21,810 --> 00:41:28,950
And the sample sizes ranged from 112 and triple negative breast cancer all the way down to nine and ovarian cancer.

402
00:41:29,340 --> 00:41:32,100
And these are ordered by the overall response rates they saw.

403
00:41:32,100 --> 00:41:39,299
So from point three and melanoma down to a 4% response rate in prostate cancer is a single arm studies.

404
00:41:39,300 --> 00:41:45,930
There's no randomization. These are single arm studies. Yeah. These were all the these were the phase one dose expansion cohorts.

405
00:41:45,930 --> 00:41:53,950
Single arm studies. Yep. And these are just the references for those response rates.

406
00:41:55,510 --> 00:42:00,010
So these are the results of the multi source exchange ability model applied to this data.

407
00:42:00,040 --> 00:42:03,120
This is a network graph showing the exchange ability results.

408
00:42:03,130 --> 00:42:13,300
So what we have here is the color of the nodes represents the posterior probability of exceeding the null response rate of 10%.

409
00:42:13,750 --> 00:42:22,120
So these yellow nodes are a high posterior probability of exceeding that and views blue and purple nodes are a low posterior probability.

410
00:42:22,390 --> 00:42:31,030
And then the edge waves represent the exchange ability, posterior exchange ability, probability of each pair of baskets.

411
00:42:31,330 --> 00:42:37,540
And I've only plotted here the edges that had at least a posterior exchange ability of 0.25.

412
00:42:37,840 --> 00:42:44,770
So not every single line is on this plot. So you can see here a thin line represents a low posterior exchange, ability,

413
00:42:44,770 --> 00:42:49,930
probability, and a thick line is a high posterior exchange, ability, probability.

414
00:42:50,170 --> 00:42:54,549
So we really see here kind of three clusters coming out this group over here that are

415
00:42:54,550 --> 00:43:01,360
exchangeable and have high posterior probability of exceeding the normal response,

416
00:43:01,360 --> 00:43:02,290
kind of a middle group.

417
00:43:02,290 --> 00:43:11,290
And then this group here that has very low posterior probability of exceeding the null and are also quite exchangeable with each other.

418
00:43:13,580 --> 00:43:21,980
So to incorporate false discovery, I'm incorporating false discovery rate control because it really meets our discovery oriented objective here of,

419
00:43:22,010 --> 00:43:26,450
you know, in the phase one setting, we want to be moving promising drugs under phase two.

420
00:43:26,460 --> 00:43:31,970
So we don't want to control our family wise error rate to strictly.

421
00:43:33,490 --> 00:43:40,840
So the way we're going to incorporate this is to obtain the posterior probability that each basket exceeds the null response rate.

422
00:43:41,260 --> 00:43:44,560
Then where are those probabilities from largest to smallest.

423
00:43:45,010 --> 00:43:49,300
And for a given threshold of posterior probability field,

424
00:43:49,660 --> 00:43:56,799
we identify the largest of those posterior probabilities so that it's subject to this constraint.

425
00:43:56,800 --> 00:44:00,550
So K over capital G, which is the total number of baskets, times fee,

426
00:44:01,060 --> 00:44:07,060
and all the baskets from that one up are declared to be promising at that threshold.

427
00:44:09,830 --> 00:44:15,220
And this was the other people that I sent to this. This work is from the clinical trials paper that I share.

428
00:44:17,320 --> 00:44:21,549
So in this case, I'm not doing any. And what I'm showing you here, I'm not doing any calibration.

429
00:44:21,550 --> 00:44:28,629
I'm just showing an example. So if we use the posterior threshold of 0.95, we would declare seven baskets promising.

430
00:44:28,630 --> 00:44:34,450
So you can see here the baskets are now ranked and in terms of their posterior probability of exceeding the null.

431
00:44:35,200 --> 00:44:42,580
So we have four here that have a 100% posterior probability of exceeding that null and then a few others that are pretty high.

432
00:44:42,820 --> 00:44:47,440
And then these bottom four would not be considered promising with this false discovery rate control.

433
00:44:47,800 --> 00:44:52,480
So in this case, we would say these seven baskets should be continued on.

434
00:44:52,870 --> 00:45:00,130
And I'm just going to show here one of the really good things about this information sharing is that this is the effective sample size.

435
00:45:01,210 --> 00:45:08,770
And we see that the ovarian basket, which only had nine patients because of its exchange ability, has an effective sample size of 73.

436
00:45:08,770 --> 00:45:13,989
So that sharing of information can really help with these imbalanced sample sizes,

437
00:45:13,990 --> 00:45:18,160
especially if you have some rare tumors when you do have exchange ability.

438
00:45:20,710 --> 00:45:24,850
Okay, so just my last two slides and then I'll take any remaining questions.

439
00:45:25,210 --> 00:45:29,170
I think we can learn a lot from case studies like this, but not everything.

440
00:45:29,170 --> 00:45:34,540
So you can think a little bit about what went wrong, what are areas for improvement and what,

441
00:45:34,540 --> 00:45:37,929
if anything, could have been foreseen in the planning stage.

442
00:45:37,930 --> 00:45:42,339
But then there's always uncontrollable factors, like in this case you don't.

443
00:45:42,340 --> 00:45:45,669
If you don't expect it to be a prognostic biomarker, you can't plan for that.

444
00:45:45,670 --> 00:45:50,379
And at least your trials are going to end up being failed no matter what kind of design you use.

445
00:45:50,380 --> 00:45:56,590
And the goal here is to have it fail earlier because we have to do trials that fail and then you have some information.

446
00:45:56,590 --> 00:45:59,920
And actually this is a good treatment. It's just not better than chemotherapy.

447
00:46:02,540 --> 00:46:06,590
There are many more areas of methodological improvement in these types of designs.

448
00:46:07,070 --> 00:46:12,709
And there are a lot of other issues that I didn't discuss, including methods for non-binary endpoints,

449
00:46:12,710 --> 00:46:18,710
whether these are either even the right endpoints to use late onset toxicities, dose or imaging studies.

450
00:46:18,710 --> 00:46:24,460
And that's just a few. So. I'm happy to take any questions.

451
00:46:24,460 --> 00:46:28,990
And here's my little pitch for anyone who wants to come and be my post-doc.

452
00:46:38,440 --> 00:46:44,130
Any other questions? Yeah.

453
00:46:45,600 --> 00:46:49,350
Another one, then. What's the role of dose here? I don't know this drug at all.

454
00:46:49,360 --> 00:46:53,760
Or was was dose checked early and then it was never an issue later or is there any chance?

455
00:46:53,940 --> 00:47:01,760
Yeah, I completely glossed over this, but they did a traditional three plus three study in the in the phase one.

456
00:47:02,490 --> 00:47:06,930
But then they took three doses forward to phase two. Actually didn't randomize.

457
00:47:06,930 --> 00:47:13,330
They just actually I'm only showing. One of the doses, but they actually did this in a number of doses.

458
00:47:14,170 --> 00:47:17,970
Was there any dose response, relationship response? I don't think they.

459
00:47:18,160 --> 00:47:22,209
I have not seen any published information on that. I wasn't actually involved in this trial.

460
00:47:22,210 --> 00:47:25,540
So I only have access to, you know, what's been published on it.

461
00:47:26,530 --> 00:47:36,040
But but I don't. I don't. Not as far as I know. But the dose question is a is a big question in this study, because a lot of these drugs are,

462
00:47:36,130 --> 00:47:41,680
you know, being being approved at much too high or too low doses.

463
00:47:42,340 --> 00:47:47,210
So. Something else.

464
00:47:49,220 --> 00:47:53,480
Similarly, what you would what's done in a basket trial like that,

465
00:47:53,480 --> 00:48:01,100
where there's seven different disease sites pushed forward, are those all at different doses or are they there?

466
00:48:01,370 --> 00:48:05,179
You know, in this case, they really just chose one dose.

467
00:48:05,180 --> 00:48:13,040
So the the dose the dose escalation phase, those cancer types were all pooled.

468
00:48:13,430 --> 00:48:16,430
And it was only when they move to the dose expansion phase.

469
00:48:16,520 --> 00:48:19,999
But they didn't examine. Like I said, they took three doses forward.

470
00:48:20,000 --> 00:48:28,640
So there was some uncertainty left of the dose. And I actually I don't know how they ended up deciding on which dose got approved or how.

471
00:48:29,030 --> 00:48:32,300
I never saw any details. That's why I crossed it over.

472
00:48:32,390 --> 00:48:34,910
But I know they took three doses forward,

473
00:48:35,360 --> 00:48:41,179
but I don't know if they were different in the different cancer types or if they were looking at all three of them within each cancer type.

474
00:48:41,180 --> 00:48:45,620
But for sure in this study, I don't think it was formalized, but it should be.

475
00:48:46,460 --> 00:48:50,960
And the dose can definitely be different for different baskets. I think that's that's possible.

476
00:48:50,960 --> 00:49:00,870
But that's I think most of the time that it studied. This class of drugs turned out to be quite toxic, too.

477
00:49:00,950 --> 00:49:04,490
Generally? Not usually, no.

478
00:49:04,900 --> 00:49:13,310
No. So that's one of the reasons that those dose escalation trials don't really work well, because the toxicity is often pretty low.

479
00:49:13,700 --> 00:49:19,909
But also a lot of these drugs, these immunotherapies, are given on a long term basis.

480
00:49:19,910 --> 00:49:24,020
And so those acute toxicities aren't necessarily the most relevant things.

481
00:49:24,020 --> 00:49:28,040
So there can be accumulating toxicities that start happening, you know,

482
00:49:28,070 --> 00:49:33,410
especially in some of these breast cancer treatments that women are taking for years and years, Tamoxifen and things like that.

483
00:49:33,950 --> 00:49:40,490
The toxicity is accumulate over time and they haven't really been studied well in these trials because of that.

484
00:49:45,990 --> 00:49:49,020
Thanks so much.

485
00:49:54,800 --> 00:49:57,720
There's a sign in sheet going round ransomware.

