1
00:00:09,220 --> 00:00:16,480
Imagine for a moment that you are an industrial hygienist, meaning that it's your job to look at the health and safety of workers.

2
00:00:17,080 --> 00:00:22,570
You want to conduct a study on whether or not nanoparticles in the air impact human health.

3
00:00:23,080 --> 00:00:28,420
Now, nanoparticles are extremely small, hard to see, hard to smell or to taste.

4
00:00:28,720 --> 00:00:35,260
And most people do not know what they're being exposed to. If you didn't have any measurements of nanoparticles,

5
00:00:35,530 --> 00:00:41,290
how well do you think you'd be able to analyze the association between nanoparticle exposures and health?

6
00:00:41,620 --> 00:00:48,950
If you just asked workers whether or not they were exposed, in all likelihood you wouldn't be able to do a very good job.

7
00:00:48,970 --> 00:00:53,860
And your associations between nanoparticles and health would likely be biased.

8
00:00:55,250 --> 00:01:01,910
In this particular video, I'm going to talk through how errors in data can produce information bias,

9
00:01:02,240 --> 00:01:05,870
meaning you're getting the wrong association in comparison to truth.

10
00:01:06,800 --> 00:01:12,350
I'll also talk about how we distinguish non differential bias from differential bias.

11
00:01:13,440 --> 00:01:17,130
So thinking about studying an exposure and an outcome.

12
00:01:17,250 --> 00:01:24,900
You recall that we so often used to buy two tables to cross, tabulate how exposure and health are tracking together.

13
00:01:25,710 --> 00:01:31,680
Clearly, in order to quantify what the relationship is between an exposure and a disease in the real world,

14
00:01:31,950 --> 00:01:39,540
we need to have accurate data once we start enumerating people and assigning them to the wrong cells of our two by two table,

15
00:01:39,810 --> 00:01:43,560
you can imagine that it becomes almost impossible to get the right answer.

16
00:01:44,660 --> 00:01:47,660
This is the fundamental premise of information bias,

17
00:01:47,660 --> 00:01:54,770
which is defined as when the quality of your information or data distorts the observed measures of associations that you see.

18
00:01:55,880 --> 00:02:01,820
Just as with selection bias, one of the most important things to consider when you're dealing with measurement error is

19
00:02:01,820 --> 00:02:07,370
whether or not the errors in your exposure differ between disease and healthy individuals,

20
00:02:07,940 --> 00:02:16,880
or if errors in your outcome differ between those with and without exposure, as you'll see in much greater detail in the next videos.

21
00:02:17,180 --> 00:02:23,690
And as you can likely intuit, the biggest problems come about when errors differ between groups.

22
00:02:25,060 --> 00:02:31,430
When errors differ between groups. We call this differential error for binary outcomes and exposures.

23
00:02:31,450 --> 00:02:38,920
You may hear this called as differential misclassification, whereas for continuous measures it's often called differential measurement error.

24
00:02:39,790 --> 00:02:46,869
Differential errors is often considered to be the most serious type of measurement error since the resulting

25
00:02:46,870 --> 00:02:54,700
bias in your associations can either make the observed association appear too large or too small.

26
00:02:55,690 --> 00:03:02,500
In other words, the directionality from information bias from differential errors can be unpredictable.

27
00:03:02,980 --> 00:03:06,400
And we'll walk through some scenarios of this in a future video.

28
00:03:08,190 --> 00:03:12,599
In contrast, if we find that the errors are similar across all groups,

29
00:03:12,600 --> 00:03:18,480
then we would call our errors non differential because they don't differ by exposure or outcome group.

30
00:03:19,470 --> 00:03:27,630
People often perceive this to be a far less serious problem since non differential errors typically will introduce information bias.

31
00:03:28,020 --> 00:03:36,540
The bias is associations towards the null. In other words, it simply makes it harder to see a true association that exists.

32
00:03:37,590 --> 00:03:40,680
Of course, this is not actually always the case.

33
00:03:40,680 --> 00:03:44,130
And we'll talk about when this does not occur in a future video.

34
00:03:46,060 --> 00:03:54,820
So the key takeaway here is that information bias occurs when the quality of your information distorts the observed measures of association.

35
00:03:55,600 --> 00:04:00,910
It's extremely important to be thinking about whether or not your errors are different between groups.

36
00:04:01,660 --> 00:04:08,140
In the scenario where the errors are different, we can bias associations either towards or away from the null.

37
00:04:08,710 --> 00:04:15,970
Whereas when errors are non differential, it tends to bias results towards the null, although not always.

38
00:04:17,040 --> 00:04:25,200
In future videos. We'll walk through examples and look at the math to see how these errors play out in terms of information bias.

