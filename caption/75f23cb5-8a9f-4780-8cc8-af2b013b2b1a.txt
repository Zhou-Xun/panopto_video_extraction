1
00:00:00,090 --> 00:00:03,900
You refer to these as papayas? Sorry, I forgot.

2
00:00:04,050 --> 00:00:09,150
Oh, no worries. And I can record the first half again later if you need me to.

3
00:00:09,270 --> 00:00:13,140
Oh, no, no, no, no. It's okay. Okay.

4
00:00:13,230 --> 00:00:16,860
Okay. Yeah. Sorry. Oh, no worries.

5
00:00:17,100 --> 00:00:22,230
Okay. So here we're discussing the two different types of errors that can occur very broadly.

6
00:00:22,470 --> 00:00:25,740
So it could happen randomly or could happen systematically.

7
00:00:26,160 --> 00:00:29,610
So on the left is an example of random error.

8
00:00:29,730 --> 00:00:33,500
So in the example of the dartboard, we're trying to hit our bullseye.

9
00:00:33,810 --> 00:00:37,350
But when we throw our darts, we keep randomly missing the target.

10
00:00:37,680 --> 00:00:42,660
It doesn't seem like there's any sort of pattern. And this left this left bullseye.

11
00:00:42,720 --> 00:00:48,950
So this is what we consider errors by random chance. On the right, however, we have systematic error.

12
00:00:48,960 --> 00:00:52,200
So we're throwing our darts at the target, but we're missing the mark.

13
00:00:52,530 --> 00:00:58,170
But there's less randomness to it. It actually looks like there's some sort of pattern that we're missing the target by.

14
00:00:59,310 --> 00:01:06,390
So for errors, we can either miss it by chance or we can introduce it by some systematic reason that we've introduced.

15
00:01:07,620 --> 00:01:12,270
And so that's where we'll dove a little bit deeper into is the systematic error.

16
00:01:15,630 --> 00:01:21,370
All right. So let's look at an example where we get to design our own cohort study to answer a research question.

17
00:01:21,810 --> 00:01:28,860
So our question in this example is, is there an association between shift work and COVID and COVID 19?

18
00:01:29,430 --> 00:01:36,120
So in our cohort, we defined first define our exposure groups and then we observed the disease status.

19
00:01:36,450 --> 00:01:44,340
So in this example, let's say that we're studying two different group of workers at U of M so the top group is referred to as the unexposed group.

20
00:01:44,430 --> 00:01:48,030
So we'll say that these are 9 to 5 office worker.

21
00:01:48,030 --> 00:01:52,169
So maybe you and faculty, even though I'm not sure 9 to 5 is of realistic,

22
00:01:52,170 --> 00:01:57,290
but we'll say it as the bottom group will refer to these as the exposed group.

23
00:01:57,300 --> 00:02:02,610
So these are also shift workers at the university, but let's say that they are truck drivers.

24
00:02:03,690 --> 00:02:11,040
So we have the two groups that we're comparing. And then we follow them over to time and determine who got COVID and who didn't.

25
00:02:11,610 --> 00:02:21,480
Let's suppose that in this study we did find a conclusion of some sort of association between shift work and COVID 19.

26
00:02:21,930 --> 00:02:28,530
So does that mean that we've necessarily shown a causal association between shift work and COVID 19?

27
00:02:30,390 --> 00:02:38,220
And then also along that line, what are some other possible explanations that could go be could be determining this association?

28
00:02:39,060 --> 00:02:44,430
Well, here I think it's important to think about how the people in the study got into these

29
00:02:44,430 --> 00:02:49,020
different groups or factors about them that may be different from the other groups.

30
00:02:49,740 --> 00:02:57,060
So there may be differences that are associated with the outcome with outcome, the disease, which is coded in this example.

31
00:02:57,510 --> 00:03:02,550
So in this example, we have truck drivers who may have more underlying conditions.

32
00:03:03,060 --> 00:03:09,450
We have the faculty members who may actually interact with more individuals than somebody who drives a truck.

33
00:03:10,080 --> 00:03:14,790
And also to the union, faculty might have higher vaccination rates.

34
00:03:15,360 --> 00:03:22,500
So what this example is trying to demonstrate is that there may be other factors that have systematically biased our results.

35
00:03:25,050 --> 00:03:29,940
So one type of systematic error that can be introduced is known as selection bias.

36
00:03:30,360 --> 00:03:36,900
So selection bias is a systematic error in the recruitment or retention of the study subjects.

37
00:03:37,500 --> 00:03:45,750
So errors arise due to systematic differences in relevant characteristics between those who are included in the study and those who aren't.

38
00:03:46,890 --> 00:03:55,650
Another way of putting that is that it involves bias that arises from the procedures by which the study participants were selected,

39
00:03:55,890 --> 00:03:59,520
or they selected themselves by agreeing to participate.

40
00:03:59,910 --> 00:04:05,250
Participate. So selection bias can be introduced from various sources.

41
00:04:05,790 --> 00:04:13,170
It can come from the investigators by how we choose subjects into our subject in tasks like our survey or study.

42
00:04:13,740 --> 00:04:20,100
It can also come from personal choices so people can select themselves into the study based on certain characteristics.

43
00:04:20,400 --> 00:04:24,990
Or maybe if we're doing a longitudinal one, we lose them to follow up.

44
00:04:24,990 --> 00:04:30,000
And the people who are in our study group who remained are different than those who we lost.

45
00:04:31,350 --> 00:04:38,280
It can also be introduced by external factors such as differential referral or diet diagnosis.

46
00:04:40,620 --> 00:04:43,950
Okay. So let's look at an example of selection bias.

47
00:04:44,340 --> 00:04:53,490
So let's say let's look an example in practice where a study is looking at the effects of jogging on coronary heart disease.

48
00:04:53,970 --> 00:04:56,360
So researchers compared the incidence of C,

49
00:04:56,700 --> 00:05:04,380
D and a sample of joggers and a sample of individuals from the general population who didn't record regularly exercise.

50
00:05:05,340 --> 00:05:12,659
So we can think about selection bias in this example because the joggers were also more likely

51
00:05:12,660 --> 00:05:18,840
to have other health characteristics or engage in health behaviors that reduce the risk of c d.

52
00:05:19,410 --> 00:05:24,740
Then selection bias may account for an observed association between jogging and C HDI.

53
00:05:25,260 --> 00:05:28,830
And this is especially if other variables are not measure or controlled.

54
00:05:29,490 --> 00:05:35,760
So in this example, the joggers had different characteristics about them that tended to for them to be more healthier,

55
00:05:35,760 --> 00:05:40,110
reduce the risk of C d as compared to those in the general population.

56
00:05:42,950 --> 00:05:49,460
A specific type of selection bias that's important in workplace health is called a healthy worker effect.

57
00:05:49,970 --> 00:05:54,560
So the healthy worker effect presents itself because active workers are more

58
00:05:54,560 --> 00:05:58,460
likely to have better general health than those who are not currently working.

59
00:05:59,630 --> 00:06:06,320
This comes right if you think about the you know, the requirements that come along with most jobs is that you are healthier as opposed

60
00:06:06,320 --> 00:06:09,980
to those who may be unhealthy and unable to keep up with those expectations.

61
00:06:11,330 --> 00:06:16,490
So generally, working individuals are healthier than individuals who are not working.

62
00:06:16,910 --> 00:06:26,900
Therefore, in occupational exposure studies where the cases are workers then are controls or who we compare them to should also be workers.

63
00:06:27,290 --> 00:06:32,270
Otherwise, this association between the exposure and the outcome will tend to be biased.

64
00:06:33,500 --> 00:06:39,620
So two important aspects of healthy worker effect to keep in mind when we're thinking about study design is

65
00:06:39,620 --> 00:06:46,490
that healthy people are selected into the workforce and unhealthy people are selected out of the workforce.

66
00:06:47,240 --> 00:06:52,460
So we haven't talked much about if a bias leads to overestimation or underestimation,

67
00:06:52,700 --> 00:06:59,720
but in the case of healthy worker effect, it often leads to an underestimation of exposure outcome effects.

68
00:07:02,430 --> 00:07:06,930
So there are some other types of selection bias that I think are important for you to be aware of.

69
00:07:07,470 --> 00:07:12,750
I heard that you all have a that you get to design a survey as part of your course.

70
00:07:12,750 --> 00:07:20,430
I think that you're graded on it as well. So I'm going to go through some other types of selection bias and then highlight the ones I think you should

71
00:07:20,430 --> 00:07:26,820
specifically pay attention to when you're thinking about designing the survey and analyzing data from said survey.

72
00:07:27,900 --> 00:07:32,040
So the first one I want to introduce is called Self-Selection or membership bias.

73
00:07:32,400 --> 00:07:38,430
So this results because characteristics of an individual cause a person to be either

74
00:07:38,430 --> 00:07:45,090
consciously or unconsciously selected into a certain group and then actually

75
00:07:45,150 --> 00:07:50,550
healthy worker effect as a specific example or specific type of self-selection bias

76
00:07:50,820 --> 00:07:55,830
where we have those healthier workers who are if we're comparing working groups.

77
00:07:57,330 --> 00:08:00,660
Another type of selection bias is called prevalence incidence bias.

78
00:08:01,020 --> 00:08:08,700
So this results from the inclusion of prevalent cases in a study when the goal is to make inferences about relation to disease or risk.

79
00:08:09,810 --> 00:08:17,040
Remember that prevalent cases include new and existing cases, while incident cases refer to only new cases.

80
00:08:17,370 --> 00:08:24,170
And we normally are. Usually when we're looking at risk of a disease, we're looking at instinct cases.

81
00:08:24,180 --> 00:08:32,720
It's much harder to get that from prevalent cases. Another important type of selection bias is called non-response bias.

82
00:08:33,050 --> 00:08:37,640
This results when people who agree to participate in the study may be different in

83
00:08:37,640 --> 00:08:42,380
terms of exposure or other important characteristics from those who did not agree.

84
00:08:43,340 --> 00:08:48,500
The kind of opposite of this effect is known as the motivated respondent bias,

85
00:08:48,740 --> 00:08:54,020
where people who are highly motivated may be more likely to take your bias and

86
00:08:54,020 --> 00:08:57,620
that may be related to your outcome or your exposure that you're studying,

87
00:08:57,860 --> 00:09:01,310
which would make them different than those who are unmotivated to be in their study.

88
00:09:03,230 --> 00:09:07,700
And then lastly, the one that I want to discuss is loss of follow up or withdrawal bias.

89
00:09:08,030 --> 00:09:10,700
This is kind of the analog for non-response bias,

90
00:09:10,700 --> 00:09:18,920
but when we're considering longitudinal studies and so this results when the incidence of the outcome is different among those who are exposed,

91
00:09:19,040 --> 00:09:22,760
who who are followed as compared to those who were lost,

92
00:09:23,120 --> 00:09:31,639
as I think that's the main takeaway from those is that the people that remained in our study might be different than those who were left in.

93
00:09:31,640 --> 00:09:34,550
Those characteristics that are different may be related to our outcome.

94
00:09:35,600 --> 00:09:41,120
Two other types that I'll mentioned, but not cover our diagnostic suspicion, bias and bergson's bias.

95
00:09:41,450 --> 00:09:46,910
These are very specific and often related to medical or medical studies,

96
00:09:47,180 --> 00:09:53,930
but I wanted to leave them here to kind of help you place it in the context of selection bias and where it falls.

97
00:09:56,950 --> 00:09:59,960
Welcome. Hi, Liane.

98
00:10:00,360 --> 00:10:04,470
Yeah, maybe I'll address this later. Sorry if it's getting outside.

99
00:10:05,300 --> 00:10:12,170
I would say myself and probably maybe most of the people in the room in the future primarily

100
00:10:12,170 --> 00:10:20,350
deal primarily data collection with hard to reach populations or maybe vulnerable populations.

101
00:10:20,360 --> 00:10:27,079
And so like, you know, like when you or you have such a hard time getting people to participate,

102
00:10:27,080 --> 00:10:31,290
you just kind of like take who will participate, right?

103
00:10:31,310 --> 00:10:39,770
So in that sense, I feel like there is always going to be bias in the study because it's not like we're able and not like most of us.

104
00:10:39,770 --> 00:10:42,920
Don't you do secondary data analysis, I would say.

105
00:10:43,460 --> 00:10:47,630
Okay. Is there a way to get around? No.

106
00:10:47,930 --> 00:10:48,590
This is like.

107
00:10:50,430 --> 00:11:00,479
Well, I think that you I think you you mentioned kind of the solution is that a lot of times we're knowledgeable that these bias occur in our studies,

108
00:11:00,480 --> 00:11:04,050
but a lot of times sometimes we're not able to remove them.

109
00:11:04,410 --> 00:11:14,010
So I think the next steps after that is kind of then there are steps that you can take to figure out how much is that actually impacting my study?

110
00:11:14,250 --> 00:11:23,490
How much bias is this introducing? And then you can also think about which direction it might be bias in your study or your results towards.

111
00:11:24,660 --> 00:11:30,870
So that direction piece of, you know, if you want to be make more conservative conclusions,

112
00:11:30,870 --> 00:11:34,680
you would want something that biases it towards like a normal conclusion,

113
00:11:35,640 --> 00:11:42,930
whereas you might be more cautious of the opposite, where you're saying something is a stronger association than there actually is in reality.

114
00:11:44,190 --> 00:11:50,040
But I think you're right. A lot of times, especially in harder to reach populations, you were just thankful for anybody who will respond,

115
00:11:50,040 --> 00:11:54,030
who will answer and the hard work that goes into those studies, too.

116
00:11:54,690 --> 00:11:59,190
So I think just trying to minimize it and then mention it and your limitations as well.

117
00:11:59,220 --> 00:12:05,850
So I think that some of these, if you get responses back from viewer reviewers and they're like, oh, well, what about this bias?

118
00:12:06,360 --> 00:12:11,730
Hopefully this will give you a starting point for how you might respond to those those concerns.

119
00:12:12,720 --> 00:12:19,620
I think you I mean, most of the time, reviewers are just like, we hated your study design, the point leader of the study.

120
00:12:19,620 --> 00:12:23,010
But it's like I've actually seen one of those on Monday, so. Right.

121
00:12:24,100 --> 00:12:29,730
Right. Yeah. But yeah, you're right. There is sometimes you can address it and sometimes sometimes you can't.

122
00:12:29,880 --> 00:12:33,570
So. Yeah. Yeah. Thank you. Yeah.

123
00:12:34,650 --> 00:12:39,660
So this slide is kind of focusing on selection bias in survey studies.

124
00:12:40,530 --> 00:12:45,389
And so I'm not sure the full extent of your studies,

125
00:12:45,390 --> 00:12:50,700
but I think that it's important to keep these in mind when you're analyzing a cross-sectional survey.

126
00:12:51,600 --> 00:12:59,729
So incidence prevalence bias is particularly important because most clean and simple surveys, just because they're not longitudinal.

127
00:12:59,730 --> 00:13:03,810
And over time, most of the time, these are cross-sectional in nature.

128
00:13:04,050 --> 00:13:10,810
That means that they're a snapshot in time. This makes them particularly vulnerable to incidence prevalence bias.

129
00:13:10,830 --> 00:13:14,250
So if you're doing a single time point, be careful.

130
00:13:14,760 --> 00:13:18,690
Single time point survey. Be careful about the conclusions you draw about risk.

131
00:13:20,160 --> 00:13:26,880
Another one to consider, even though there may not be much that you can change about it, since it's about the behavior of who's participating.

132
00:13:27,240 --> 00:13:35,490
But think about self-selection bias. I'm not sure if you have to have two or more comparison groups for your survey, but if you do,

133
00:13:35,790 --> 00:13:44,550
maybe consider if there are factors that would make somebody more likely to be represented in your survey as compared to somebody who isn't.

134
00:13:45,990 --> 00:13:52,380
And then lastly, just one for you all to consider is non-response bias or that motivated respondent bias.

135
00:13:52,410 --> 00:14:01,020
So ask yourself, are the people who disagree to be in my survey different in terms of exposure as compared to those who did agree to be in my survey?

136
00:14:02,690 --> 00:14:09,650
I feel like when I talk about even when I take epidemiology courses and people draw on exposure disease, it's hard for me to follow sometimes.

137
00:14:09,980 --> 00:14:15,770
So I actually I have some questions for you all that I think kind of test those objectives of forgetting it.

138
00:14:15,770 --> 00:14:21,680
So I'm not going to switch back and forth between the pull everywhere site, if that's okay with everyone.

139
00:14:24,080 --> 00:14:32,360
And I'll just kind of like summarize the results to you all, but you can log on to Paul everywhere dot com and then the link is in the bottom.

140
00:14:32,780 --> 00:14:36,500
And so then this will be the first question for you all.

141
00:14:38,810 --> 00:14:43,340
And looks like I already have one respondent, so I appreciate who responded.

142
00:14:48,160 --> 00:14:52,960
Is there anybody who would prefer to do it via text as opposed to a website?

143
00:14:54,850 --> 00:15:00,750
I'm doing it. Everyone's like how people are doing it on their computers and all of us are doing it on their phones the time.

144
00:15:03,220 --> 00:15:11,440
Okay. Cool. Sammy. Okay.

145
00:15:11,450 --> 00:15:15,079
I'll give you maybe like 15 more seconds to respond.

146
00:15:15,080 --> 00:15:25,319
And then I think that this one. Poll everywhere shows me the percentage of how many people have responded or the percentage of responses.

147
00:15:25,320 --> 00:15:31,080
But it doesn't tell me how many have, actually. So I apologize if I don't allow enough time for everyone to respond.

148
00:15:31,950 --> 00:15:39,629
There's only five of us today. Is that how many have actually, maybe.

149
00:15:39,630 --> 00:15:45,450
I don't know how to view it, but it doesn't. It doesn't show me how many people have responded.

150
00:15:46,030 --> 00:15:49,340
Oh, that's probably good. Good.

151
00:15:49,350 --> 00:15:55,700
Yeah. Okay. Cool. Okay. So yeah, I think everyone got that one correct.

152
00:15:55,700 --> 00:16:02,540
So false selection bias can also be introduced by individuals in the study.

153
00:16:02,570 --> 00:16:13,490
As we discussed last, a follow up or self selection and then also other external factors related to diagnosis or assessment can also cause that.

154
00:16:14,480 --> 00:16:22,400
Okay. So this question in question number two, let me make sure that active this one is a little bit of a harder question,

155
00:16:22,400 --> 00:16:26,600
I think, because I didn't specifically define it and this language.

156
00:16:26,870 --> 00:16:31,969
So maybe take a little bit of extra time to go through these these options and

157
00:16:31,970 --> 00:16:37,070
see if you can figure it out based on on the definition that we discussed.

158
00:17:33,610 --> 00:17:40,770
Okay. So it looks like the majority. I think has everybody had the chance to respond?

159
00:17:41,910 --> 00:17:47,980
Yeah. Cool.

160
00:17:47,990 --> 00:17:55,760
Yeah. So I think everyone got that one right as well. So the correct answer is A, so the survey participants are not randomly chosen from population.

161
00:17:55,760 --> 00:18:04,490
So if we're doing a survey, we the more randomly our participants have been chosen from the population,

162
00:18:05,240 --> 00:18:09,350
the better it is or the less likely we are to introduce selection bias.

163
00:18:09,350 --> 00:18:15,530
So that's why Selection Bias is referring to when we are randomly choosing from the population,

164
00:18:15,530 --> 00:18:18,920
we're systematically getting people from the population.

165
00:18:21,120 --> 00:18:25,050
Okay. One more question for this one. Let me make it active.

166
00:18:25,620 --> 00:18:29,010
I'll give about 20 seconds for this one.

167
00:18:29,430 --> 00:18:33,180
So actually, I'll let you all read it for yourselves, if that's okay.

168
00:19:21,710 --> 00:19:28,810
Okay. All right.

169
00:19:28,810 --> 00:19:35,800
So I'm going to go ahead and go through this one. So the correct answer for this one is actually non-response bias.

170
00:19:36,580 --> 00:19:40,570
I could see why the other ones would be tempting to choose.

171
00:19:40,870 --> 00:19:51,740
But here, since I'm worried that the 121 people who responded are systematically different from the rest, actually,

172
00:19:51,870 --> 00:19:59,920
I think I'd change the wording on this question, so I think the audio should be correct and actually D would be I really change the word on this.

173
00:20:00,190 --> 00:20:03,700
So it should be d d is the correct answer. The motivated respondent.

174
00:20:07,450 --> 00:20:12,440
Thank you all. Thank you. Really mi pilot my questions with you all I've got.

175
00:20:12,470 --> 00:20:16,840
I did that in the last the last minute. And so the correct answer here is D.

176
00:20:19,430 --> 00:20:22,520
Okay. Well, so let's have a question.

177
00:20:22,970 --> 00:20:32,000
Oh, yeah, it's okay. I just have a question about what's empathetically that there was a guest card attached to that survey.

178
00:20:32,000 --> 00:20:38,810
And I guess I'm curious, what do you think about attaching, like bonuses or gifts or like money?

179
00:20:39,020 --> 00:20:44,899
Is there a response? Because there hasn't been any related research demonstrating that there are maybe those with lower income

180
00:20:44,900 --> 00:20:50,660
or such demographics are more likely to respond to that for some kind of cares about and skews responses?

181
00:20:52,280 --> 00:20:56,929
Yeah, that's a great question. I think that you're absolutely right.

182
00:20:56,930 --> 00:21:02,059
That is a concern whenever you're thinking about introducing an incentive to your study,

183
00:21:02,060 --> 00:21:07,130
because then depending on the study population of who you're interested in studying,

184
00:21:07,430 --> 00:21:14,760
maybe a $25 incentive could mean way more to somebody of lower income than somebody who isn't.

185
00:21:14,780 --> 00:21:24,200
And so then you might actually be over incentivizing or creating some other type of selection bias by introducing an incentive.

186
00:21:24,710 --> 00:21:28,070
So but that really it depends on the study population.

187
00:21:28,080 --> 00:21:34,790
So if you're trying to look at a population whose that covers all income levels,

188
00:21:35,930 --> 00:21:40,910
then I think you should be concerned of introducing that incentive because you might get more participants.

189
00:21:42,410 --> 00:21:49,280
But other things that you can do as well is that you can always collect that income information as well.

190
00:21:49,310 --> 00:21:53,030
And so then on the back end, if you have introduced incentive,

191
00:21:53,030 --> 00:22:02,510
you could kind of do a demographic table and see what did we actually recruit more more lower income people because of the incentive.

192
00:22:02,540 --> 00:22:05,610
So there are ways to summarize it and discuss it.

193
00:22:06,100 --> 00:22:12,840
Yeah, I think that and that's very important to think about for selection, bias and incentives if.

194
00:22:16,690 --> 00:22:23,320
All right. I'm going to keep moving. So now we're going to move into this section of information bias.

195
00:22:23,650 --> 00:22:27,160
So let's go back to that study of shift work and COVID.

196
00:22:27,520 --> 00:22:30,129
And so now we've kind of switched up our groups here.

197
00:22:30,130 --> 00:22:38,709
So instead of comparing the truck drivers to office and maybe desk employees, now we're going to look at two different groups of nurses,

198
00:22:38,710 --> 00:22:46,080
one who are low exposed or one who are high exposure, and then we'll compare them instead.

199
00:22:46,090 --> 00:22:52,209
So the idea here is now we're comparing workers to other workers that are low exposure to high exposure.

200
00:22:52,210 --> 00:22:56,890
So hopefully we've kind of worked out some of that selection bias.

201
00:22:57,190 --> 00:23:03,970
So now we can ask the same question Is there a causal association between shift work and COBA 19?

202
00:23:04,960 --> 00:23:12,910
Well, again, it's still depends because there are some new things that we need to focus on, on how we measure the exposure and disease of interest.

203
00:23:13,330 --> 00:23:18,490
So we also need to consider for COVID specifically, was it a PCR test or a rapid test?

204
00:23:19,360 --> 00:23:23,320
Did they have symptoms? No symptoms. And then also, what was the timing of the test?

205
00:23:24,340 --> 00:23:32,530
So then when we're thinking about measurement and how you measure disease and exposure, that leads us into information bias.

206
00:23:32,980 --> 00:23:36,850
So information bias is a systematic error.

207
00:23:36,850 --> 00:23:43,240
It's introduced by a systematic error in the collection, recall recording or handling of our information.

208
00:23:44,170 --> 00:23:49,720
Information bias occurs when information is collected differentially between two different groups,

209
00:23:50,140 --> 00:23:53,920
leading to an error and the conclusion of the association.

210
00:23:54,520 --> 00:23:58,330
So this occurs in two different ways.

211
00:23:58,990 --> 00:24:02,200
It can occur non differentially or differentially.

212
00:24:02,260 --> 00:24:08,500
I think for the sake of time I'm going to kind of glance over the non differential and differential classification,

213
00:24:08,830 --> 00:24:16,390
but I think it's important to notice that well here it's thinking about how well did we classify our exposure in terms of disease,

214
00:24:16,630 --> 00:24:22,480
how will that we define our exposure in terms of non disease or non exposed in terms of disease?

215
00:24:23,380 --> 00:24:29,800
We could be misclassifying them both at the same rates or we could be misclassifying them at different rates.

216
00:24:29,800 --> 00:24:37,120
And so that's what the non differential and differential misclassification get into, however,

217
00:24:38,200 --> 00:24:42,820
is important to think about how we measure disease and our other covariates in the study.

218
00:24:43,210 --> 00:24:51,250
But most of the time the biggest amount of information bias is going to come from how we measure our exposure assessment.

219
00:24:51,610 --> 00:24:54,760
So this is a huge source of bias in occupational studies.

220
00:24:57,260 --> 00:25:06,770
So when we're thinking about exposure assessment, how accurately can we go about studying these these exposures?

221
00:25:06,770 --> 00:25:08,270
How well can we measure them?

222
00:25:08,630 --> 00:25:16,400
So if we think about age, race, dietary intake, lead exposure, these all have different scales that we're going to need to measure them on.

223
00:25:16,670 --> 00:25:19,880
And we're going to have different ways about going about assessing them.

224
00:25:21,140 --> 00:25:26,900
And then we can also think about how well we can accurately account for these health conditions.

225
00:25:26,900 --> 00:25:36,890
So depression, dementia, diabetes. So this is kind of what motivates that idea of using a standardized or validated measurement tool for research.

226
00:25:37,310 --> 00:25:43,010
So we want to use these assessment tools that have been validated to help us reduce our information bias.

227
00:25:43,460 --> 00:25:47,480
Ultimately, we want to make sure that we're classifying people into the correct groups.

228
00:25:48,230 --> 00:25:56,300
So just a small aside, when we think about validated measurement tools, we really need to consider the populations that they were created on.

229
00:25:56,660 --> 00:26:04,460
A lot of times the tools that we have in the literature now were created on a general middle age, says white male.

230
00:26:04,760 --> 00:26:10,550
And whenever you think about setting other populations, it doesn't mean that that tool is going to necessarily translate.

231
00:26:10,850 --> 00:26:15,409
And that's because of selection bias. So just something to keep in the back of your mind.

232
00:26:15,410 --> 00:26:17,690
If you're using validated assessment tools,

233
00:26:17,930 --> 00:26:23,240
look in the literature to see if these have been adapted or used in the population that you're actually studying.

234
00:26:23,570 --> 00:26:27,470
Otherwise, you might be introducing information bias into your study.

235
00:26:28,340 --> 00:26:31,850
And I think that there is kind of a cognition of this now in the literature,

236
00:26:31,850 --> 00:26:40,580
and that's moving towards having better tools that are been validated on more populations.

237
00:26:42,530 --> 00:26:46,650
Okay. So let's go back to the example of coffee that I mentioned before.

238
00:26:46,670 --> 00:26:50,389
So it seems like every week you can kind of check the news and see that there's a

239
00:26:50,390 --> 00:26:54,550
new health benefit or new risk that goes along with coffee or caffeine nation.

240
00:26:55,370 --> 00:27:02,750
And here's some examples of those conflicting findings. So one study found that too much coffee increases your risk of heart disease.

241
00:27:03,020 --> 00:27:06,950
Another one on the decaf. Decaf coffee is linked to heart risk.

242
00:27:07,970 --> 00:27:12,620
And then we have some other ones on the flip side that say that drinking more coffee is associated

243
00:27:12,620 --> 00:27:19,700
with a decreased risk or that a few cups of coffee can lower your color colon cancer risk.

244
00:27:20,030 --> 00:27:28,310
So oftentimes we find these results, these conflicting results, and it could come from an information bias.

245
00:27:28,340 --> 00:27:30,469
And so this paper by Schrieber,

246
00:27:30,470 --> 00:27:38,390
it all looked at how coffee intake is measured and shows how considerable misclassification of caffeine intake there can be.

247
00:27:38,930 --> 00:27:42,110
So if we kind of focus on this red box on the right,

248
00:27:42,440 --> 00:27:50,150
we can see that there's a wide variation of how much caffeine is in a single cup of coffee, depending on the style of drip of the coffee.

249
00:27:50,480 --> 00:27:57,630
Or we should also think about issues calculating caffeine level from chocolate or tea or medications.

250
00:27:57,650 --> 00:28:05,810
And a lot of times the studies that were published didn't even consider this type of classification or this detailed this like granular,

251
00:28:06,080 --> 00:28:09,080
granular level of detail as far as confirmation.

252
00:28:09,770 --> 00:28:15,139
Then what happens is these information bias, these errors start to add up in your study,

253
00:28:15,140 --> 00:28:21,200
which can skew the results to where we're not sure if we knew then what we've observed is actually the truth.

254
00:28:22,310 --> 00:28:27,980
So this is an example of information. Bias can skew results of what we've observed.

255
00:28:29,840 --> 00:28:33,770
So when we think about collecting information about exposure,

256
00:28:33,770 --> 00:28:38,810
we need to consider the timing of exposure and also how we go about quantifying exposure.

257
00:28:39,410 --> 00:28:44,210
So for the timing of exposure, we want to think about the onset of that exposure.

258
00:28:44,570 --> 00:28:49,700
We want to think of the duration of time that the subject had with that exposure.

259
00:28:50,360 --> 00:28:56,660
We also need to take into consideration the appropriate amount of lag time from exposure to disease.

260
00:28:57,110 --> 00:29:01,910
And then lastly, consider if we're studying chronic effects or acute effects.

261
00:29:03,470 --> 00:29:09,650
When we think about quantifying our exposure, I think that this is going to be really important when you're developing your survey designs,

262
00:29:10,010 --> 00:29:15,560
is think about the exposure, the intensity of it, the frequency and the duration.

263
00:29:15,890 --> 00:29:23,950
So the intensity would be how much caffeine was there in my double express espresso this morning, the frequency as well.

264
00:29:23,960 --> 00:29:26,180
How many double espressos did I have today?

265
00:29:26,600 --> 00:29:32,960
And then duration could be how long have I been having double espressos every day, something like that, or multiple.

266
00:29:33,320 --> 00:29:37,129
So there's different levels of information that we need to collect.

267
00:29:37,130 --> 00:29:44,840
And we can always we always want to try to move towards collecting better information so we're less likely to make a misclassification error.

268
00:29:48,540 --> 00:29:58,679
So continuing on this thought of data collection and health research, we find that group survey questions can be put into two broad categories.

269
00:29:58,680 --> 00:30:04,889
We have subjective questions, which are normally interviews or questionnaires where we have objective questions.

270
00:30:04,890 --> 00:30:13,650
So these are usually biomarkers or hard endpoints. There isn't a blanket approach, though, for using subjective versus objective questions.

271
00:30:13,650 --> 00:30:21,030
It'll kind of depend on the exposure of interest and also the feasibility of the sources that are resources that are available to you.

272
00:30:22,050 --> 00:30:27,060
So the example on the left again are some caffeine studies. I'll kind of skip those just for the sake of time.

273
00:30:30,970 --> 00:30:40,300
So some final thoughts about information, bias and exposure misclassification is that it kind of occurs in all studies.

274
00:30:40,720 --> 00:30:45,560
So then the important question is to ask how much misclassification is there?

275
00:30:46,660 --> 00:30:51,550
So we rarely get tests that are perfect. So it's important to remember that in all epidemiologic studies,

276
00:30:51,880 --> 00:30:57,700
their exposure will be measured with some type of error, the disease will be measured with some type of error.

277
00:30:57,700 --> 00:31:02,170
The confounders or the covariates will also be measured with some type of error.

278
00:31:02,620 --> 00:31:06,310
So when we want to think about how much misclassification is actually going on here,

279
00:31:08,770 --> 00:31:11,620
I have some other notes about ways that we can reduce measurement.

280
00:31:11,620 --> 00:31:20,049
I think we actually talked about some of these with our discussion question before I'll leave these for you to review in your own time,

281
00:31:20,050 --> 00:31:28,480
but I just want to leave these here as a resource for you. So again, with information bias, there are specific types of information bias that occur.

282
00:31:29,110 --> 00:31:39,280
One of the most common is recall bias. So this occurs when participants don't remember previous events or experience accurately, or they omit details.

283
00:31:40,330 --> 00:31:45,010
Or it can almost be the opposite of this, where if they have a disease of interest,

284
00:31:45,250 --> 00:31:51,639
they may be more likely to remember certain exposures or events that happened in their life,

285
00:31:51,640 --> 00:31:54,760
as opposed to those who are on disease or don't have the disease.

286
00:31:56,500 --> 00:31:57,909
We also have interviewer bias,

287
00:31:57,910 --> 00:32:05,500
which can occur when systematic differences occur with how we solicit record or interpret information on our study subjects.

288
00:32:06,930 --> 00:32:11,520
And then we have family information bias, which is a little bit more specific.

289
00:32:11,520 --> 00:32:16,589
But it does occur whenever cases or more aware of a family history because the occurrence of

290
00:32:16,590 --> 00:32:23,040
their disease has stimulated some sort of discussion or investigation of past disease history.

291
00:32:23,940 --> 00:32:29,730
And then I'll leave these other information biases here for your reference and just help you put them in context of the field.

292
00:32:31,820 --> 00:32:35,960
So for your cross-sectional studies, if you're designing a cross-sectional survey,

293
00:32:36,260 --> 00:32:41,390
two really important things I think you should focus on or the recall bias that we discussed.

294
00:32:41,870 --> 00:32:48,980
And then also just really focus on how you're measuring your exposures, your outcomes in your relevant covariates.

295
00:32:49,250 --> 00:32:55,400
So are they clearly defined? Are the categories that you're giving them defined?

296
00:32:56,060 --> 00:32:59,389
Are there potential biases related to the accuracy of their measurement?

297
00:32:59,390 --> 00:33:05,570
Are the two techniques that were used to collect it? So these are the things to keep in mind when you're designing your cross-sectional survey.

298
00:33:07,490 --> 00:33:12,650
Okay. So I have another call everywhere. Question for you. This one is an open response question.

299
00:33:12,710 --> 00:33:20,340
Let me get active. So this is a question where the researchers wanted to ask their participants.

300
00:33:20,340 --> 00:33:26,700
How often do you record exercise? They put that their categories were regularly or occasionally.

301
00:33:27,540 --> 00:33:33,120
This is a potential source for information bias because it's very vague and not exhaustive.

302
00:33:33,570 --> 00:33:40,620
So what is another way that you think would propose to ask this question about how often do they exercise?

303
00:34:30,430 --> 00:34:33,970
Good. I'm seeing some. Thank you for your responses. I appreciate the interaction.

304
00:34:34,450 --> 00:34:39,470
Okay. There are some good ones in here. Great.

305
00:34:39,530 --> 00:34:44,660
Yeah, I think that these are all great ways of going about asking this.

306
00:34:44,790 --> 00:34:46,460
Yeah. Give examples. Yeah.

307
00:34:47,360 --> 00:34:54,770
So some of them, I won't go through all the responses, but the general consensus here is that we need more than just regularly are occasionally.

308
00:34:55,070 --> 00:34:59,270
And even I put an example of another one that I saw in a survey.

309
00:34:59,270 --> 00:35:07,730
So they asked, they actually put some numbers to that of like twice a week or more often once a week, less than once a week.

310
00:35:08,270 --> 00:35:12,830
I saw some great examples or answers that came through that actually put numbers of will.

311
00:35:13,250 --> 00:35:16,910
Sure. How often you exercising. But maybe we want to know the duration.

312
00:35:17,210 --> 00:35:20,480
How long are you exercising? And is a weekly.

313
00:35:20,480 --> 00:35:25,580
More than weekly. So so kind of keep that in mind of how you break down.

314
00:35:27,390 --> 00:35:32,940
These categories. But based on the responses, I think you have a great grasp of how to make those more specific and exhaustive.

315
00:35:35,270 --> 00:35:39,560
Okay. I'm going to skip question number five so we can kind of get to the confounding part.

316
00:35:40,340 --> 00:35:46,880
So just a quick summary, though, of biases. So we talked about bias as a systematic departure from the truth.

317
00:35:47,300 --> 00:35:52,100
And then we talked about two broad categories of bias selection bias,

318
00:35:52,340 --> 00:35:56,510
which is a systematic error in the recruitment and retention of study participants.

319
00:35:56,870 --> 00:36:04,520
And we also talked about information bias, which is a systematic error in the collection, recall recording or handling of information.

320
00:36:05,000 --> 00:36:11,719
So as Dr. Lee proposed, a good study is free of bias.

321
00:36:11,720 --> 00:36:17,740
But we do address it and we try to minimize it. All right.

322
00:36:17,740 --> 00:36:25,210
So let's get into confounding. And so the section about systematic errors present themselves through bias.

323
00:36:25,240 --> 00:36:28,750
Now we're going to discuss systematic errors that present themselves through confounding.

324
00:36:29,440 --> 00:36:37,900
But I guess before we move on to this next section, what questions you all have about bias or association and causation?

325
00:36:44,070 --> 00:36:47,290
Magic's. All right.

326
00:36:48,190 --> 00:36:54,940
Okay. So let's go back to. Oh, I'm sorry. Okay, Nancy, out of the seven more minutes before the next class comes in.

327
00:36:55,360 --> 00:36:57,880
Okay, perfect. I will wrap it up. So.

328
00:36:58,350 --> 00:37:06,460
So this next part that you need to worry about when you're trying to make causation, one of the last parts is really due to confounding.

329
00:37:07,330 --> 00:37:10,990
I'm going to I apologize. I went a little bit slower today than I expected.

330
00:37:12,010 --> 00:37:19,720
But so when we're thinking about confounding, I think that a lot of people should be familiar with this idea of confounding.

331
00:37:19,750 --> 00:37:27,850
So if we're interested in assessing an exposure, so say lighters and then lung cancer is our outcome,

332
00:37:28,630 --> 00:37:35,680
we may consider that there's a third variable that is associated with these that's kind of skewing this association.

333
00:37:35,680 --> 00:37:43,959
So confounding is really getting at this idea that we've observed something that maybe there's a third or multiple variables that are confounding,

334
00:37:43,960 --> 00:37:50,860
that result that are giving us results that are either positive or it's saying there is a result when in reality there isn't,

335
00:37:51,280 --> 00:37:56,350
or it's saying there's no result and it's kind of hiding the fact that there is a true association there.

336
00:37:57,160 --> 00:38:01,300
So one example to look at would be cigaret use.

337
00:38:01,600 --> 00:38:06,540
So a confounder needs to be associated with the exposure and with the disease.

338
00:38:06,550 --> 00:38:15,860
So if we look at this graph, we notice that there is arrows going from cigaret use to lighter and cigaret use going to lung cancer.

339
00:38:15,880 --> 00:38:24,490
So for it to be considered a confounder, the key idea here is that it needs to be this confounder needs to be associated with both.

340
00:38:27,350 --> 00:38:32,200
So here in this example of cigaret use, it's likely that there is a confounder at work,

341
00:38:32,210 --> 00:38:42,050
namely smoking cigarets because considering that the if we adjust for cigaret use lighters in lung cancer are no longer associated.

342
00:38:45,040 --> 00:38:52,210
So then just some final notes about confounding is that confounding refers to a situation where a non causal association

343
00:38:52,480 --> 00:38:58,990
between exposure and outcome is observed and it's observed as a result or the influence of some third variable.

344
00:38:59,410 --> 00:39:09,520
So confounding is one type of systematic error that can occur in epidemiologic studies and it may be present in almost any observational study.

345
00:39:09,520 --> 00:39:14,140
So this is actually confounding is the motivation for why we do randomized controlled trials.

346
00:39:14,980 --> 00:39:23,470
But when we have an observational study, we probably end up with some sort of imbalance of covariates, baseline covariance between our participants.

347
00:39:24,040 --> 00:39:29,470
And so then the aim for confounding is that we want to control it and we want to eliminate it.

348
00:39:29,830 --> 00:39:34,450
And so a lot of times when you're reading through the literature and you hear that we adjusted for age,

349
00:39:34,450 --> 00:39:40,300
comorbidities, etc., by adjusting for those, we're accounting for that confounding effect.

350
00:39:40,780 --> 00:39:45,070
And so we never want to report measure of associations confounded.

351
00:39:45,430 --> 00:39:53,830
So this is kind of the last, last step before we can get to the causality piece.

352
00:39:54,370 --> 00:39:59,620
So I'll leave some additional slides for you to review and I'll actually provide the notes for you all as well,

353
00:39:59,620 --> 00:40:03,610
so you can review them at your own pace if you like.

354
00:40:03,820 --> 00:40:09,640
There's some criteria that we briefly discuss for determining if something is a confounder is not a confounder.

355
00:40:10,390 --> 00:40:13,210
That's the word version of what I went through or.

356
00:40:15,690 --> 00:40:23,880
And then maybe we have time for one last question to ask you how we feel about this idea of confounding.

357
00:40:24,990 --> 00:40:36,090
So question number six is, given that we have this, we want to look at this association between the BRCA1 disease and breast cancer.

358
00:40:37,080 --> 00:40:43,650
Do we need to adjust for age when we're evaluating between a genetic factor and breast cancer?

359
00:40:44,070 --> 00:40:48,270
So question six Should we live either answer yes or no.

360
00:41:05,350 --> 00:41:13,930
So the correct answer here is actually it's actually no, we don't need to adjust for age.

361
00:41:14,230 --> 00:41:23,380
And let me explain why. So we said that a confounder needs to be associated with the exposure of interest and the outcome of interest.

362
00:41:23,800 --> 00:41:31,750
And so for this age is actually not associated with the BRCA1 gene because there's the gene.

363
00:41:31,750 --> 00:41:35,140
Is that expressed differentially over time as far as we're aware?

364
00:41:35,410 --> 00:41:43,060
And so since age is not related to the BRCA1 gene, then we don't need to adjust for age compounding.

365
00:41:43,150 --> 00:41:49,790
So no is the correct answer to this one. Um, so I.

366
00:41:50,090 --> 00:41:52,549
So just kind of to summarize what we talked about today,

367
00:41:52,550 --> 00:41:58,580
we talked a lot about association causation and we spent a lot of our time discussing selection and information bias,

368
00:41:58,580 --> 00:42:02,450
which I think is actually really important when you think about designing your survey design.

369
00:42:03,230 --> 00:42:10,880
I apologize. I didn't save as much time to discuss confounding, but I'm happy to answer any questions you might have in your survey about confounding.

370
00:42:11,690 --> 00:42:16,040
But with that, I'll leave the last few minutes for for any questions.

371
00:42:17,710 --> 00:42:27,900
Well, let's get Lance or Dr. Porter hanging. Anna and I have a QR codes on items, and you scan that to fill it out instantly.

372
00:42:28,840 --> 00:42:31,690
I said you have time. I'd appreciate the feedback.

373
00:42:32,380 --> 00:42:39,240
It's a one minute student evaluation because really I think that you should be able to finish it in one minute or less.

374
00:42:39,250 --> 00:42:46,180
But I appreciate any responses that you have for my questions for Dr. Ford.

375
00:42:48,460 --> 00:42:58,840
For that last question. We just said, instead of risk of breast cancer, early onset of breast cancer, then what age be a confounding or not?

376
00:43:02,020 --> 00:43:08,139
So the answer and I guess I might have to think about that.

377
00:43:08,140 --> 00:43:18,970
My initial response is that, no, I don't think so, because the I think the key takeaway there is that age.

378
00:43:20,360 --> 00:43:29,540
Is associated with breast cancer. The BRCA1 gene is associated with breast cancer, but age does not ever influence the BRCA1 gene.

379
00:43:29,600 --> 00:43:33,170
So as far as we know, this gene is expressed throughout your entire life.

380
00:43:33,650 --> 00:43:42,380
So because I just realized I'm using my laser pointer in this story because this link isn't here between age to the BRCA1 gene,

381
00:43:42,740 --> 00:43:47,570
then we actually don't need to adjust for it because it doesn't have the ability to act as a confounder.

382
00:43:48,650 --> 00:43:55,890
Okay. Thank you. Yeah. Yeah. What's really got me thinking, Lantz?

383
00:43:57,510 --> 00:44:05,850
I mean, based on the kind of research I do, I don't ever know if I can establish causation based on the kind of research that I do.

384
00:44:06,540 --> 00:44:09,360
So that might just be up to the epidemiologists.

385
00:44:10,980 --> 00:44:20,320
Yeah, I think there's a key takeaway from today's is that just kind of understanding how messy it is to actually determine causation.

386
00:44:20,940 --> 00:44:30,540
But I think the association studies that we do are beneficial because they provide evidence when we have bigger conversations about causality.

387
00:44:30,870 --> 00:44:40,160
So yeah, for epidemiologists who do primary data collection, I mean, generally, they're the ones that are doing the longitudinal studies.

388
00:44:40,170 --> 00:44:45,280
Is that right? That's right. Yeah. Okay.

389
00:44:45,280 --> 00:44:54,040
Well, thank you again so much for this. You made AP interesting, which I don't feel like it usually is.

390
00:44:54,040 --> 00:45:01,270
So that's. But hopefully they'll be able to link some of these concepts, their future assignments.

391
00:45:01,280 --> 00:45:06,920
So with that, I'll go ahead of them, stop the recording and I will let you go.

392
00:45:06,940 --> 00:45:10,960
Thank you. And thank you all so much. Have a good day. And I.

