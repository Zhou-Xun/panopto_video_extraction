1
00:00:05,423 --> 00:00:08,473
Hello, this lecture will focus
on hypothesis testing and

2
00:00:08,473 --> 00:00:11,980
biostatistics when looking
at continuous outcomes.

3
00:00:11,980 --> 00:00:15,320
This lecture will focus on
the comparison of two groups

4
00:00:15,320 --> 00:00:19,240
with respect to their population means.

5
00:00:19,240 --> 00:00:23,462
Let's review first what we saw in our
previous lecture about hypothesis testing

6
00:00:23,462 --> 00:00:28,447
when we covered our first hypothesis test,
the one-sample t test.

7
00:00:28,447 --> 00:00:35,095
In our example, we had a population of
babies born to women living in poverty.

8
00:00:35,095 --> 00:00:39,740
µ represented the population mean
birth weight of these babies.

9
00:00:39,740 --> 00:00:43,950
We then conjecture a null and
alternative hypothesis for this parameter.

10
00:00:43,950 --> 00:00:47,555
Our null hypothesis is that the average
birthweight in the population is

11
00:00:47,555 --> 00:00:48,830
2,800 grams.

12
00:00:48,830 --> 00:00:54,510
Versus the alternative that the average
birthweight is not 2,800 grams.

13
00:00:54,510 --> 00:00:57,380
We then collect a sample of
data from this population

14
00:00:57,380 --> 00:01:01,960
from which we get a sample mean
birthweight, which we call x̅.

15
00:01:01,960 --> 00:01:04,833
We then compare the difference between x̅,
and

16
00:01:04,833 --> 00:01:09,048
the null hypothesis value of
the population mean which is 2,800.

17
00:01:09,048 --> 00:01:12,730
We then divide this difference
by the sampling variability,

18
00:01:12,730 --> 00:01:16,380
because our x̅ will differ
across many samples.

19
00:01:16,380 --> 00:01:21,710
The ratio of this difference and
the variability is our t-statistic.

20
00:01:21,710 --> 00:01:25,630
We then look up where this t-statistic
lies in a normal distribution,

21
00:01:25,630 --> 00:01:30,170
which then produces a p-value for
us to make inference.

22
00:01:30,170 --> 00:01:34,382
However, we are often less interested
in the value of one population mean.

23
00:01:34,382 --> 00:01:38,087
And our instead interested in comparing
the means of two populations in

24
00:01:38,087 --> 00:01:42,780
determining if those means
are different from each other.

25
00:01:42,780 --> 00:01:46,400
So now suppose our first population
is again babies who are born to women

26
00:01:46,400 --> 00:01:47,930
living in poverty.

27
00:01:47,930 --> 00:01:52,310
We represent that population's
mean by μ with a subscript of 1.

28
00:01:52,310 --> 00:01:56,750
Our second population is babies born
to women who are not living in poverty.

29
00:01:56,750 --> 00:02:01,330
Their population mean is represented
by μ with a subscript 2.

30
00:02:01,330 --> 00:02:04,310
Our goal is to compare the difference
between these two means

31
00:02:04,310 --> 00:02:07,220
through a sample of data.

32
00:02:07,220 --> 00:02:11,660
Because on average our question is,
does a mother's living in poverty

33
00:02:11,660 --> 00:02:15,790
have any association with
the birthweight of her newborn?

34
00:02:15,790 --> 00:02:19,650
If in fact a mother's living in poverty
has an association with birthweight of

35
00:02:19,650 --> 00:02:24,115
the newborn, then the two population
means must be different from each other.

36
00:02:24,115 --> 00:02:26,190
μ1 is not equal to μ2, or

37
00:02:26,190 --> 00:02:29,910
we can say that the two means
have a difference not equal to 0.

38
00:02:29,910 --> 00:02:32,780
This is our alternative hypothesis.

39
00:02:32,780 --> 00:02:37,380
Our null hypothesis, therefore, is that
the two populations have the same mean or

40
00:02:37,380 --> 00:02:40,420
the difference is exactly 0.

41
00:02:40,420 --> 00:02:43,290
So we return to our two populations.

42
00:02:43,290 --> 00:02:47,090
From the first population, we collect
a sample of data, and we compute a sample

43
00:02:47,090 --> 00:02:52,360
mean, a sample standard deviation, and the
number of observations or the sample size.

44
00:02:52,360 --> 00:02:54,960
We do the same thing for
the second population.

45
00:02:54,960 --> 00:03:00,270
And we note that the two sample
sizes are not necessarily equal.

46
00:03:00,270 --> 00:03:03,240
The difference in
the sample means x̅ 1- x̅

47
00:03:03,240 --> 00:03:09,600
2 is the best estimate of what we think
the population means might differ by.

48
00:03:09,600 --> 00:03:13,540
If this difference is big enough then we
can reject the null hypothesis, and we

49
00:03:13,540 --> 00:03:19,300
are able to conclude that the populations
themselves have different means.

50
00:03:19,300 --> 00:03:23,730
However, how do we quantify how big
enough the two sample means must be

51
00:03:23,730 --> 00:03:26,380
before we believe we have enough evidence?

52
00:03:26,380 --> 00:03:32,100
This again is measured by the noise or
the standard error of the difference.

53
00:03:32,100 --> 00:03:36,200
Now, if the two sample means have
corresponding standard errors that we

54
00:03:36,200 --> 00:03:38,890
had discussed in previous lectures.

55
00:03:38,890 --> 00:03:42,970
Then mathematically, we can show that
the difference in the two sample means

56
00:03:42,970 --> 00:03:48,290
has a standard error equal to the square
of the individual standard errors

57
00:03:48,290 --> 00:03:52,240
added together, and
taking the square root of that sum.

58
00:03:52,240 --> 00:03:56,280
This quantity is put in
the denominator of a new t-statistic.

59
00:03:56,280 --> 00:03:59,610
The numerator is, again,
the difference in the two sample means.

60
00:03:59,610 --> 00:04:02,310
And the denominator measures
how much variability there is

61
00:04:02,310 --> 00:04:05,040
from sample to sample.

62
00:04:05,040 --> 00:04:08,330
Again, I want to emphasize that
the denominator of the statistic is not

63
00:04:08,330 --> 00:04:10,580
the sum of the standard errors.

64
00:04:10,580 --> 00:04:16,010
But it is the square root of the sum
of the squared standard errors.

65
00:04:16,010 --> 00:04:19,800
We now have a statistic which again is the
difference in the sample means divided by

66
00:04:19,800 --> 00:04:21,720
their variability.

67
00:04:21,720 --> 00:04:25,650
The statistic is then converted to a
p-value that we used to decide whether or

68
00:04:25,650 --> 00:04:28,160
not we can reject the null hypothesis.

69
00:04:28,160 --> 00:04:29,870
As with the one sample t-test,

70
00:04:29,870 --> 00:04:33,100
we know that the t-statistic
under the null hypothesis

71
00:04:33,100 --> 00:04:37,540
will have a normal distribution with a
mean of 0, and a standard deviation of 1.

72
00:04:37,540 --> 00:04:39,000
Therefore, remember,

73
00:04:39,000 --> 00:04:45,050
that two standard deviations from 0
encompasses 95% of all the t-statistics.

74
00:04:45,050 --> 00:04:47,639
So a t-statistic bigger than 2 or

75
00:04:47,639 --> 00:04:52,770
less than -2 would give me
a p-value that's less than 0.05.

76
00:04:52,770 --> 00:04:56,980
Correspondingly, I can compute
a 95% confidence interval for

77
00:04:56,980 --> 00:04:59,700
the difference in the population means.

78
00:04:59,700 --> 00:05:03,970
That 95% confidence interval is the
observed difference in the sample means,

79
00:05:03,970 --> 00:05:07,650
plus your -2 standard
errors of that difference.

80
00:05:07,650 --> 00:05:13,478
The confidence interval and a p-value
corespond to each other because if the 95%

81
00:05:13,478 --> 00:05:19,813
confidence interval does not contain zero
then the p-value should be less than 0.05.

82
00:05:19,813 --> 00:05:24,739
I now provide you with an example
that was published in 2017, by.

83
00:05:24,739 --> 00:05:28,919
In this manuscript what they examined
was whether or not consumption of sugary

84
00:05:28,919 --> 00:05:34,470
beverages in adults was associated with
the level of their caloric intake.

85
00:05:34,470 --> 00:05:37,530
Our first population in this
manuscript was US adults

86
00:05:37,530 --> 00:05:41,320
who report consuming less than
one sugary beverage per day.

87
00:05:41,320 --> 00:05:44,670
Again, we have a population mean μ1
representing the average number of

88
00:05:44,670 --> 00:05:48,820
calories consumed per
day in this population.

89
00:05:48,820 --> 00:05:52,600
The second population was all US adults
who we're poor consuming one to two sugary

90
00:05:52,600 --> 00:05:54,070
beverages per day.

91
00:05:54,070 --> 00:05:57,190
Their population mean
is represented by μ2.

92
00:05:57,190 --> 00:06:02,140
Again, the average number of calories
consumed in this population.

93
00:06:02,140 --> 00:06:06,880
Our hypothesis the null hypothesis is that
the difference in the means is zero or

94
00:06:06,880 --> 00:06:09,270
that the two means are equal.

95
00:06:09,270 --> 00:06:12,200
The alternative is that
the difference is not zero or

96
00:06:12,200 --> 00:06:16,200
that the two population means
are different from each other.

97
00:06:16,200 --> 00:06:19,880
Now, Collected a sample of data
from the first population.

98
00:06:19,880 --> 00:06:22,170
The had nearly 2,400 subjects.

99
00:06:22,170 --> 00:06:27,557
They had a sample mean of 1,782,
and a standard deviation of 594.

100
00:06:27,557 --> 00:06:33,325
They collected a sample from the second
population of about 1,200 subjects

101
00:06:33,325 --> 00:06:39,958
with the mean of 2,007 calories, and a
sample standard deviation of 626 calories.

102
00:06:39,958 --> 00:06:44,456
The test statistic again is
the difference in the two sample means

103
00:06:44,456 --> 00:06:49,120
relative to how much variability
there is in the data.

104
00:06:49,120 --> 00:06:52,323
That statistic ends up being -10.4.

105
00:06:52,323 --> 00:06:56,462
And note that's a statistic that's
simply then 10.4 here I defind the 2

106
00:06:56,462 --> 00:06:58,920
populations in the reverse order.

107
00:06:58,920 --> 00:07:02,453
Again, it is irrelevant which is
population 1 and which is population 2,

108
00:07:02,453 --> 00:07:07,847
because we are concerned with
the magnitude the test statistic.

109
00:07:07,847 --> 00:07:11,459
So the question is,
is the resulting p-value for

110
00:07:11,459 --> 00:07:14,560
this hypothesis test less than 0.05?

111
00:07:14,560 --> 00:07:18,781
And hopefully, know that the answer
is yes, it will be less than 0.05.

112
00:07:18,781 --> 00:07:22,463
Because again, any statistic
less than -2 or bigger than 2,

113
00:07:22,463 --> 00:07:25,570
will give me the p-value
that is less that 0.05.

114
00:07:25,570 --> 00:07:28,760
And our statistic is very, very small.

115
00:07:28,760 --> 00:07:31,350
It is in the left tail of
the normal distribution

116
00:07:31,350 --> 00:07:34,670
corresponding to
an extremely small p-value.

117
00:07:34,670 --> 00:07:38,080
We can also compute a 95% confidence
interval for the difference in

118
00:07:38,080 --> 00:07:42,600
the population means, by taking
the difference in the two sample means.

119
00:07:42,600 --> 00:07:47,060
And adding and subtracting two
standard errors from that difference.

120
00:07:47,060 --> 00:07:51,970
That produces a confidence
interval of -268 to -182.

121
00:07:51,970 --> 00:07:54,970
Again, I could have reversed
the order of the populations and

122
00:07:54,970 --> 00:07:57,320
gotten the confidence
interval of 182 to 268.

123
00:07:57,320 --> 00:08:01,600
Again, the sign is irrelevant.

124
00:08:01,600 --> 00:08:06,260
So now I have two pieces of evidence,
I have a T statistics of -10.4.

125
00:08:06,260 --> 00:08:10,240
And I have 95% confidence interval for
the difference in the population means,

126
00:08:10,240 --> 00:08:14,490
there ranges from -268 to -192.

127
00:08:14,490 --> 00:08:19,060
So my question to you based on these data,
would you support a press release stating

128
00:08:19,060 --> 00:08:24,440
that consumption of sugary beverages
leads to higher caloric intake?

129
00:08:24,440 --> 00:08:27,120
The answer of this question might be, yes.

130
00:08:27,120 --> 00:08:30,062
However, we must be careful
with our semantics.

131
00:08:30,062 --> 00:08:34,530
A t-test is useful for showing the
association between group membership and

132
00:08:34,530 --> 00:08:35,380
an outcome.

133
00:08:35,380 --> 00:08:40,280
However, it is not able to prove
causality from a two sample t-test.

134
00:08:40,280 --> 00:08:45,060
So although we see an association between
the number of sugary beverages consumed,

135
00:08:45,060 --> 00:08:48,270
and the total number of
calories consumed we as of yet

136
00:08:48,270 --> 00:08:54,534
cannot prove there is a causation or
casual effect between these two factors

