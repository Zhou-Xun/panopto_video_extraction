1
00:00:02,340 --> 00:00:05,370
Okay. I think we can go ahead and get started.

2
00:00:06,810 --> 00:00:12,150
So I know last week was a bit complicated of class.

3
00:00:12,750 --> 00:00:20,070
The lecture, you know, we went really in-depth into counterfactuals and these alternative counterfactuals.

4
00:00:20,880 --> 00:00:24,780
But this week, you know, we're taking a bit of a breather.

5
00:00:24,780 --> 00:00:30,690
A lot of this lecture will be and hoping to get some new information to you.

6
00:00:31,140 --> 00:00:35,820
But it is also a bit of a recap of some stuff that you probably learned in other classes.

7
00:00:36,360 --> 00:00:40,470
And there is no homework assignment for this.

8
00:00:43,080 --> 00:00:48,780
Okay. To recap, what is the direct effect?

9
00:00:49,890 --> 00:00:56,280
And if we look at this, we have two different models here which are controlling for different things.

10
00:00:58,080 --> 00:01:02,850
And the direct effect is the theta one.

11
00:01:11,340 --> 00:01:19,590
So five one, which is this thing right here, that is the total effect.

12
00:01:21,270 --> 00:01:28,770
So the total like the total effect decomposes into the direct effect which is here and the indirect effect which is this beta one, two theta.

13
00:01:29,040 --> 00:01:34,170
So beta one and theta two are the indirect effects.

14
00:01:36,210 --> 00:01:41,850
Theta one is the direct effect and PHI one is the total effect.

15
00:01:43,350 --> 00:01:47,880
So I realize, you know, these these Greek letters are a bit complicated.

16
00:01:49,110 --> 00:01:51,870
I hope that didn't results in anybody answering correctly.

17
00:01:51,870 --> 00:01:58,649
But I think you should, at least conceptually, regardless of knowing the Greek letters, being able to understand this is the total effect.

18
00:01:58,650 --> 00:02:02,520
And the direct effect is simple and generally enough.

19
00:02:02,550 --> 00:02:09,840
Imagine we care about the total effect and not the direct effect, although there certainly are circumstances where we do care about the direct effect.

20
00:02:10,440 --> 00:02:20,100
But you know, in most cases, or if you're just not given additional information, this is what you want and this is what you would want to estimate.

21
00:02:25,750 --> 00:02:30,050
So then the indirect effects, most of you got that that is beta one and theta two.

22
00:02:30,070 --> 00:02:34,450
So it's this pathway through the mediator. That is what the indirect effects.

23
00:02:41,760 --> 00:02:47,400
Okay. So you're studying hydroxychloroquine use and mortality.

24
00:02:47,790 --> 00:02:53,970
The counterfactual is and most of you are getting it, this is great.

25
00:02:54,600 --> 00:02:59,190
So you observe that if somebody dies after they have H.Q. and then going back in time,

26
00:02:59,190 --> 00:03:05,099
changing it so they don't have a Q and then observing whether they die. So a randomization, this is experimental evidence.

27
00:03:05,100 --> 00:03:13,200
So that B like an experimental condition, this one just like a typical observational study, there would be an observational condition.

28
00:03:13,770 --> 00:03:20,420
So counterfactual again, counter to fact. It's not reality. Okay.

29
00:03:20,510 --> 00:03:30,320
Now this is where it gets a bit confusing. So understandable that there is some, you know, heterogeneity in how you're responding to this.

30
00:03:32,270 --> 00:03:40,130
So we're studying the effect of a gene you miss on lung cancer and we're thinking of smoking as a mediator.

31
00:03:43,240 --> 00:03:47,320
Okay. So what would be the natural direct effects here?

32
00:03:48,220 --> 00:03:58,570
We have three options. Um, it's we're looking at the rate of lung cancer where we're setting the levels of smoking as if everyone had one.

33
00:03:58,900 --> 00:04:03,100
We're looking at the rate of lung cancer with all individuals said to be smokers.

34
00:04:03,460 --> 00:04:11,350
And then we're looking at the rate of lung cancer, you know, differentially across the two gene groups with everyone set to be a non smoker.

35
00:04:14,450 --> 00:04:17,420
So the answer is the first one.

36
00:04:18,080 --> 00:04:24,230
So there's a few things to keep in mind with this, and I absolutely understand that this is like a bit of a confusing thing,

37
00:04:24,500 --> 00:04:28,430
and that's why we're kind of rehashing it and we'll continually be doing that.

38
00:04:29,720 --> 00:04:43,070
So for one, when we're looking at the direct effects, so the direct effect is looking at the values of, you know, the exposure on the outcome.

39
00:04:43,550 --> 00:04:45,560
I guess it's it's in here in this model.

40
00:04:45,770 --> 00:04:54,110
But, you know, we're looking at the image gene on lung cancer and then we're thinking of smoking the images here.

41
00:04:54,620 --> 00:04:58,250
So this is the value that we're looking we're interested in.

42
00:05:01,310 --> 00:05:07,050
So every everybody's comparing like these two genetic groups. Hopefully that makes sense as like a direct effect.

43
00:05:07,080 --> 00:05:14,180
So then the thing that we're contrasting across these is what is the natural direct effect and what is a controlled direct effect?

44
00:05:14,870 --> 00:05:20,750
The natural direct effect that we're natural there in your mind, there's a few things you can keep.

45
00:05:22,160 --> 00:05:25,550
Try to keep it natural, will have a convoluted definition.

46
00:05:25,580 --> 00:05:35,240
So that's one thing. And the thing with the natural is that you aren't directly manipulating the mediator.

47
00:05:35,450 --> 00:05:39,259
You're basically like, you have your one time line of counterfactuals.

48
00:05:39,260 --> 00:05:45,830
Whether somebody has you missed one or you missed two, and then you cross over a separate set of timelines for the mediator.

49
00:05:46,480 --> 00:05:50,560
And in the situation you're setting the levels of smoking as if everyone had you.

50
00:05:50,570 --> 00:05:55,790
Rizwan feel like your values for your mediator will depend on your exposure.

51
00:05:56,870 --> 00:06:02,720
That is the natural director. So natural direct effect. We are not directly controlling, we're not directly manipulating the mediator.

52
00:06:03,020 --> 00:06:11,570
Instead, we're letting the value of the mediator very naturally based on what the exposure would be like.

53
00:06:12,410 --> 00:06:16,700
The other, you know, maybe that's confusing. That's a bit of a mouthful for me even to explain.

54
00:06:16,940 --> 00:06:20,450
So let's think about the other ones. These are controlled direct effects.

55
00:06:20,840 --> 00:06:29,390
And the thing about controlled direct effects is there's the number of controlled direct effects is equal to the levels of mediators there are.

56
00:06:29,420 --> 00:06:32,629
So in this analysis we're saying everything is dichotomous.

57
00:06:32,630 --> 00:06:34,610
So people could be a smoker or a non smoker,

58
00:06:35,390 --> 00:06:41,120
but we could think of a situation where we have like a third mediating level, which is like a former smoker,

59
00:06:42,920 --> 00:06:48,020
in which case we'd have three controlled direct effects where one of them would be what is the rate of lung

60
00:06:48,020 --> 00:06:53,000
cancer among those with the English one versus tumors two with all individuals set to be former smokers.

61
00:06:54,440 --> 00:06:59,240
So controlled direct effect is where you really are directly manipulating the mediator.

62
00:06:59,570 --> 00:07:06,649
And I think like in people's minds it just like makes sense that that's what you would do for a direct effect.

63
00:07:06,650 --> 00:07:10,790
And so I think a controlled direct effect makes logical sense to people.

64
00:07:11,210 --> 00:07:18,500
The natural direct effect has a very convoluted explanation, but statistically it's equations are very beautiful.

65
00:07:18,500 --> 00:07:27,590
They simplify a lot. And so that is why statisticians like these, again, if you keep this like a bit in the back of your mind,

66
00:07:28,520 --> 00:07:33,860
I'm not going to try to have like extensive test questions on this at the end of the semester.

67
00:07:34,250 --> 00:07:39,350
But, you know, if you go more into a peachy program or if you're interested in epidemiological methods,

68
00:07:39,680 --> 00:07:44,270
I think it's important to pass out like or to be able to distinguish natural and controlled direct effects.

69
00:07:46,750 --> 00:07:52,220
Any questions on that? Okay.

70
00:07:54,930 --> 00:08:01,649
The last one we will look at later on. Okay.

71
00:08:01,650 --> 00:08:10,350
So model building, this comes from the reading for today, but if at all possible, don't use stepwise selection.

72
00:08:10,860 --> 00:08:17,189
I think especially in like the social sciences, maybe this is me, you know, I'm not trying to make fun of them at all or anything,

73
00:08:17,190 --> 00:08:27,989
but I think there's a tendency maybe in like sociology or psychology maybe to stepwise selection a bit more than in public health.

74
00:08:27,990 --> 00:08:35,549
But if there's anything that you get out of today's class like I am, okay, if you never remember natural direct effects or controlled direct effects.

75
00:08:35,550 --> 00:08:41,030
But if in the future you think, Oh, I shouldn't do a stepwise selection, that would be great.

76
00:08:41,040 --> 00:08:50,280
I would feel like I succeeded today. So, you know, I think the article goes over pretty well by you wouldn't want to do stepwise selection.

77
00:08:50,420 --> 00:08:53,520
Any questions on that or anything that they've brought up?

78
00:08:56,180 --> 00:09:05,600
I mean, I think part of the thing about stepwise selection is like we build our models to test the significance of a particular association,

79
00:09:05,960 --> 00:09:10,070
but we stepwise selection. You are building your model based on the P values.

80
00:09:10,400 --> 00:09:18,170
So then, you know, it's a bit circular in terms of the logic of like what what does a p value mean if that should be our outcome,

81
00:09:18,170 --> 00:09:26,920
but instead that's a building block of the model. But I will say, you know, like I because it has ever been done, the tendency.

82
00:09:28,880 --> 00:09:33,800
Okay. All right. That. Okay.

83
00:09:34,880 --> 00:09:39,460
So I you know, I've been on papers which have you step by selection.

84
00:09:39,830 --> 00:09:45,780
A lot of times it is, you know, other offers on it, just being really heavy to emphasize that.

85
00:09:46,820 --> 00:09:51,570
But, you know, it's something I've tried to move away from. Okay.

86
00:09:51,570 --> 00:09:57,780
So when we're thinking of model building, what I want to think about first off is like, why are we building the model?

87
00:09:58,260 --> 00:10:00,870
So there's two things that we can do when we create a model.

88
00:10:00,870 --> 00:10:08,160
And by model building, I mean, you know, we're putting independent variables and covariates into a multivariable regression model.

89
00:10:09,570 --> 00:10:11,850
So there's two reasons why we might be doing that.

90
00:10:12,270 --> 00:10:21,360
One is, and I think this is most common in epidemiology, we're looking at the association between a particular exposure and an outcome.

91
00:10:21,360 --> 00:10:30,959
So, you know, what is the estimated association of the estimated effect of coffee drinking on diabetes?

92
00:10:30,960 --> 00:10:35,370
That is, you know, one of the big things that we try to do in epidemiology.

93
00:10:36,030 --> 00:10:43,169
The other thing that we might be interested in is just computing somebody is like the risk score or this is also the propensity.

94
00:10:43,170 --> 00:10:48,059
So, you know, for the the class and marginal structure models for the homework assignment for that,

95
00:10:48,060 --> 00:10:52,200
you did have to do this where basically you output a propensity score.

96
00:10:52,740 --> 00:10:58,020
So outputting a propensity score could be another type of or another reason that you do modeling.

97
00:10:58,590 --> 00:11:03,690
So I mean, and there may be different model building strategies between these.

98
00:11:03,690 --> 00:11:08,820
So we're predominantly focusing on this first one here, but that's all to say that, you know,

99
00:11:09,030 --> 00:11:13,590
there could be certain situations where you really you just want to predict somebody's risk.

100
00:11:13,710 --> 00:11:20,340
For instance, you know, you have a number of different risks that an individual has.

101
00:11:20,340 --> 00:11:25,860
You can compute like there are we look at risk factors for a particular patient and then we can compute,

102
00:11:25,860 --> 00:11:32,009
you know, what is their risk of getting diabetes or having a heart attack in the next few years?

103
00:11:32,010 --> 00:11:37,810
That's something that you could do and might be interesting for you. Okay.

104
00:11:38,050 --> 00:11:42,340
So I will push this back to you for the first small group discussion.

105
00:11:43,570 --> 00:11:51,220
Consider the following scenario. In 2005, a study shows a strong, positive relationship between coffee and Type two diabetes in 2010.

106
00:11:51,260 --> 00:11:56,740
There's no relationship. And in 2011, a third study shows a negative relationship.

107
00:11:58,900 --> 00:12:04,420
Why? Why does that happen? So in your groups discuss several reasons why that possibly could.

108
00:12:17,805 --> 00:12:22,215
Maybe. Let me start with the group in the back, the cake maker.

109
00:12:22,575 --> 00:12:28,065
Do you what are some reasons why you think there could be differences across these studies?

110
00:12:38,015 --> 00:13:01,435
I'm sorry. Yeah those are all really critical.

111
00:13:01,645 --> 00:13:04,554
So they make mentioned, you know,

112
00:13:04,555 --> 00:13:15,415
ah what are they two founders versus mediators or what is their like causal diagram that they're throw off with that can be, you know, an issue.

113
00:13:15,715 --> 00:13:24,385
So they could be controlling for different things. Um, let me move to the group heterogeneity.

114
00:13:24,385 --> 00:13:27,385
Did you have anything else or reiterating what they said?

115
00:13:28,975 --> 00:13:34,445
We mentioned that as well. Obviously we don't know for sure, but we.

116
00:13:36,585 --> 00:13:40,205
General population may have died a few years.

117
00:13:51,005 --> 00:13:56,825
Yeah. So there could be something different. We might think that there's, like other ongoing secular trends.

118
00:13:57,125 --> 00:14:01,685
And first off, this is when the studies are published, but who knows when the actual study took place?

119
00:14:02,075 --> 00:14:06,145
You know, maybe the 2005 one actually took place like earlier in the 2000.

120
00:14:06,155 --> 00:14:09,825
So there could be a larger time point.

121
00:14:09,845 --> 00:14:18,095
I think one of the other things that the K.K. group mentioned, which I didn't repeat, was like there were could be differences in like the sample.

122
00:14:18,095 --> 00:14:23,195
I think you mentioned sampling bias, but there could just be differences across the samples.

123
00:14:24,005 --> 00:14:28,324
Um, maybe one more group surviving life.

124
00:14:28,325 --> 00:14:34,395
Did you have any additional comments? We haven't seen.

125
00:14:36,505 --> 00:14:43,845
341478428. Oh, great point.

126
00:14:43,965 --> 00:14:48,165
You know, like who is actually included in this study? So it could be different ages.

127
00:14:48,915 --> 00:14:51,385
It could be people in like different countries. You know what?

128
00:14:51,405 --> 00:14:56,835
Actually, another thing that I'll mention, you know, how do they measure coffee drinking?

129
00:14:56,895 --> 00:15:01,005
You know, already it's kind of nebulous like you are or you aren't, or as I think most people are,

130
00:15:01,005 --> 00:15:06,795
kind of somewhere in between how they even measure type two diabetes.

131
00:15:08,055 --> 00:15:14,445
But yeah, I think, you know, what ages are included would be a huge one. So there clearly could be a lot of differences here.

132
00:15:15,405 --> 00:15:20,475
The problem is, though, that we do end up with a literature where they're just like,

133
00:15:21,195 --> 00:15:23,895
you know, a large number of studies which might say different things.

134
00:15:24,795 --> 00:15:30,325
And oftentimes the public might be somewhat interested in this, especially if it's things that people will eat and drink a lot.

135
00:15:30,345 --> 00:15:36,074
So, you know, the studies which go on about like are it's good for you.

136
00:15:36,075 --> 00:15:39,945
Are they bad for you? Is drinking wine good for you? Is it bad for you?

137
00:15:40,215 --> 00:15:46,065
These are, you know, perennially of interest on the front pages of newspapers.

138
00:15:46,065 --> 00:15:47,505
And people like to discuss them a lot.

139
00:15:47,505 --> 00:15:53,715
And I think a lot of things you mentioned today might explain why why we see heterogeneity in those results as well.

140
00:15:56,675 --> 00:15:57,205
But I mean,

141
00:15:57,215 --> 00:16:09,335
I think part of being an epidemiologist is to be able to be a bit cogent and to be able to talk with people and maybe like the general public about,

142
00:16:09,335 --> 00:16:12,365
you know, oh, there are a number of different articles which say different things.

143
00:16:12,365 --> 00:16:17,135
Why could that be the case? Okay.

144
00:16:19,385 --> 00:16:22,925
Next small group question what does a p value mean?

145
00:16:23,825 --> 00:16:28,565
So offer an interpretation if you don't know a frequentist is just ignore that for now.

146
00:16:29,135 --> 00:16:38,105
We'll talk about that later. Offer an interpretation for what a p value of 0.0 for is and say this is like we have a logistic regression model.

147
00:16:38,495 --> 00:16:42,005
So see the models, you know that we control for all the confounders that we need to.

148
00:16:42,275 --> 00:16:45,005
And it's looking at the relationship between coffee and diabetes.

149
00:16:45,455 --> 00:16:50,705
And so I do not want you to say like, oh, it's significant at a p value at an alpha level of 0.05.

150
00:16:50,735 --> 00:16:55,085
Like that's not, but like what does that like 0.04 what does this actually mean?

151
00:16:55,475 --> 00:17:02,795
You know, think back to some of your earlier statistics courses. Like what does this value represent?

152
00:17:35,625 --> 00:17:42,635
I call. Yeah.

153
00:17:47,675 --> 00:18:00,408
I can't. Love. Yeah.

154
00:18:08,603 --> 00:18:16,083
So. What does a p value mean to us?

155
00:18:18,243 --> 00:18:22,353
And I will just move on over to the dengue find.

156
00:18:22,383 --> 00:18:27,063
Do you have an interpretation point or an attempt at interpretation that we can talk about?

157
00:18:28,503 --> 00:18:33,253
We're not entirely sure how to interpret. I felt.

158
00:18:35,023 --> 00:18:39,473
Right? Yeah. So let's just start there. What would the p value?

159
00:18:40,643 --> 00:18:44,533
It's like the popularity of all these different.

160
00:18:47,243 --> 00:18:51,203
Okay. So I'm just going to write down some thoughts and we'll combine these all together.

161
00:18:51,623 --> 00:18:56,873
So p value. So kind of like different results from null hypothesis.

162
00:18:58,733 --> 00:19:00,503
Let me move up here to the Wagner IDs.

163
00:19:00,533 --> 00:19:07,013
Did you have any thought on how to interpret 24 or like different thoughts or similar thoughts about what a P value would mean?

164
00:19:10,123 --> 00:19:19,183
Under the. Like You've got it.

165
00:19:19,693 --> 00:19:32,413
Yeah. Okay.

166
00:19:32,563 --> 00:19:43,153
So I like how you reading this. So first off, like, just so that we're all on the same page, the null hypothesis means that there is no relationship.

167
00:19:44,083 --> 00:19:49,063
So the null hypothesis, like no relationship between coffee and diabetes.

168
00:19:54,503 --> 00:20:03,653
And so what the P value is saying is that under the null hypothesis, what is the probability that we will see as extreme or more extreme of a result?

169
00:20:04,373 --> 00:20:10,743
And so by the results, to be specific, the result is the test statistic.

170
00:20:10,763 --> 00:20:17,063
So, you know, that could be like a T test or an EV test or could be like a chi square.

171
00:20:21,553 --> 00:20:27,942
But so it's not like seeing like you would see as extreme or more of extreme of an odds ratio.

172
00:20:27,943 --> 00:20:29,383
It's like actually looking at the test.

173
00:20:29,383 --> 00:20:36,193
So that's probably one of those calls like if you output SAS or is problem is comes you're not really paying too much attention to.

174
00:20:37,813 --> 00:20:45,553
But like different models will have different types of tests but what the what this P-value is saying 4.04 is it saying

175
00:20:45,673 --> 00:20:54,163
that there would be a 4% chance that we would see the result that we would saw to be as extreme or to be more extreme?

176
00:20:57,713 --> 00:21:01,403
This is very convoluted and, you know,

177
00:21:01,693 --> 00:21:09,023
similar to how like maybe we were thinking earlier today about how like a natural directive to the government to make it easy to think about.

178
00:21:09,323 --> 00:21:14,003
I think P values are another one of those things which are just really confusing to think about when you dive into it,

179
00:21:14,363 --> 00:21:19,823
because the basis of a p value is that there is a null hypothesis.

180
00:21:20,363 --> 00:21:25,343
So what we are assuming is that there is no relationship whatsoever.

181
00:21:25,973 --> 00:21:32,243
And then what we're saying is that, oh, but there would be a 4% chance if there is no relationship,

182
00:21:32,243 --> 00:21:37,313
that we would see a value as extreme or more extreme that we thought we actually saw.

183
00:21:38,333 --> 00:21:44,572
So let me go to an example and then we're kind of going to go back to this topic because, you know,

184
00:21:44,573 --> 00:21:50,003
this this this is something which I think that you should have in the back of your mind.

185
00:21:51,563 --> 00:21:56,512
But it also could be that in the in the future we just like rely less and less on p values,

186
00:21:56,513 --> 00:22:00,863
partially because the the interpretation is so it's complicated,

187
00:22:00,863 --> 00:22:04,192
it's convoluted and it doesn't really get at what we're interested in, which is like,

188
00:22:04,193 --> 00:22:11,553
is there a real effect between the exposure and the outcome or are these variables like really related together?

189
00:22:11,573 --> 00:22:12,713
That's what we're interested in.

190
00:22:12,983 --> 00:22:19,043
But a p values like this is really like a backwards way of saying like, Oh, let's first assume that there's not a relationship.

191
00:22:20,063 --> 00:22:25,043
And then what? How would like the values that we found fit into that?

192
00:22:26,363 --> 00:22:36,833
Okay. So another thing that people often think is that the P value is a percent chance that your experimental results are due to random chance.

193
00:22:38,063 --> 00:22:46,013
So, you know, people might say, oh, with the p value point of four, that means there's only a 4% chance that our results are due to random chance.

194
00:22:46,613 --> 00:22:52,913
So that is not the case at all. And so over the next few slides, I'll be explaining this a bit more.

195
00:22:52,913 --> 00:22:59,453
But I also note that there are some really great explanations and a bit more colloquial and not too statistics heavy.

196
00:23:00,383 --> 00:23:06,203
So there's this Vox article here, and then I think there's another website that I link to in a in a in the next slide.

197
00:23:06,213 --> 00:23:11,122
So I would heavily recommend you to like look at those, especially if what I'm saying doesn't make sense.

198
00:23:11,123 --> 00:23:15,713
But this is also something I'm really happy to talk with you about during office hours,

199
00:23:15,713 --> 00:23:21,413
because this is like a core concept of epidemiology and statistics, which frankly doesn't make sense.

200
00:23:21,413 --> 00:23:28,673
People in the public probably aren't interpreting this the way that it should, and in many epidemiologists aren't as well.

201
00:23:30,143 --> 00:23:38,272
Okay. So let's, you know, come to a hypothetical world and maybe you are a pharmaceutical company and

202
00:23:38,273 --> 00:23:47,353
you have 100 cancer treatment drugs and let's say that ten out of 100 work.

203
00:23:47,933 --> 00:23:49,523
And so you're going to have to try to, like,

204
00:23:50,093 --> 00:23:54,563
pretend that we're God for a moment that we would know this because there's no statistical way of knowing this.

205
00:23:54,563 --> 00:23:57,473
But just say, like in the background, for whatever reason, we know there's ten.

206
00:23:57,773 --> 00:24:03,443
So this is this is basically just like an assumption that we're making for the purposes of this thought experiment.

207
00:24:03,443 --> 00:24:12,883
But again, there's no way in reality of knowing that ten of these so like this is a, you know, a ten by ten grid and these are the ten number.

208
00:24:13,733 --> 00:24:24,442
So that's right. Those are the ones that we're trying to find out. The first thing that we do is we need to understand that we only have 80% power.

209
00:24:24,443 --> 00:24:30,473
So this might be something that you remember from your sample size class from the winter,

210
00:24:30,563 --> 00:24:41,333
hopefully when you're talking about sample size and Cornell sees that as part of our sample of these calculations, we have to see what the power is.

211
00:24:41,333 --> 00:24:43,312
And usually we just set 80%.

212
00:24:43,313 --> 00:24:50,962
And it's, you know, one of those things similar to like saying significance is at .05, it's just like a cultural aspect of epidemiology.

213
00:24:50,963 --> 00:24:54,653
You could change if you wanted to, but we're going to say we have 80% power.

214
00:24:55,103 --> 00:25:04,762
That means that through all the statistical tests that we can do, we actually would only be able to identify these AIDS as being actual cancer.

215
00:25:04,763 --> 00:25:09,592
Fighting drugs like these two are just going to be lost forever. So that's a power means.

216
00:25:09,593 --> 00:25:13,793
Power means like, are we actually able to detect a positive result?

217
00:25:16,043 --> 00:25:20,303
Then what we have is that we're probably going to have an Alpha 0.05.

218
00:25:20,573 --> 00:25:31,883
And that means that if we look at the null hypothesis, 5% of our results will show as extreme or more extreme of a value.

219
00:25:33,953 --> 00:25:41,842
So what that actually means is that of the remaining 95% would show as extreme or more extreme.

220
00:25:41,843 --> 00:25:46,913
So it's actually like 4.5. But I'm just rounding up to five here for simplicity's sake.

221
00:25:50,743 --> 00:25:54,642
So these are like actually not related to that.

222
00:25:54,643 --> 00:25:58,603
There's no cancer fighting this in any of these drugs.

223
00:25:58,963 --> 00:26:03,913
But as part of our alpha level, we will say that there is this relationship.

224
00:26:05,963 --> 00:26:15,893
So as part of our study, we actually of these 100 drug candidates, we found eight that truly were effective, but we also found five that were not.

225
00:26:17,393 --> 00:26:25,093
So that means that of the 13 results which are shown to be significant, only eight of them are truly effective.

226
00:26:25,103 --> 00:26:35,653
So that's kind of 62%. So I think, you know, this maybe means that we should have some humility when we see a significant level,

227
00:26:35,663 --> 00:26:39,913
because in your mind, I think what people think in their mind is that like,

228
00:26:39,913 --> 00:26:47,023
oh, the percentage has something to do with all these other ones, but really like we should be thinking about,

229
00:26:47,233 --> 00:26:51,612
you know, what is our power and what are we likely to see significant.

230
00:26:51,613 --> 00:27:00,913
But in reality isn't is so our denominator is maybe a bit different in terms of how good our statistical tests are.

231
00:27:01,093 --> 00:27:04,603
Like the denominators are these 13 not like the total 100.

232
00:27:07,403 --> 00:27:14,733
So this is an example where we're assuming that there are ten that are actually true.

233
00:27:14,753 --> 00:27:17,093
That's like our original assumption.

234
00:27:17,393 --> 00:27:24,503
People have done a number of different like simulations of what it would be, you know, under different circumstances.

235
00:27:26,883 --> 00:27:31,923
And if you specify an alpha level of 0.05.

236
00:27:35,733 --> 00:27:44,853
It'll be somewhere between 23 and 50% of your significant results will actually be a true null hypothesis.

237
00:27:46,533 --> 00:27:52,863
And so, like, you know, a substantial minority, maybe even about half of the times we say something is significant,

238
00:27:53,043 --> 00:27:59,313
there actually is no there's no real relationship there. And with the p value point of one, we cut down on that a bit.

239
00:28:04,243 --> 00:28:10,833
So this all goes to say, like, you know, maybe instead of throwing out key values altogether, maybe we should just change the alpha level.

240
00:28:10,843 --> 00:28:13,903
Maybe we should change like the boundary of whether something is significant or not.

241
00:28:14,323 --> 00:28:16,392
And so different subfields kind of do this already,

242
00:28:16,393 --> 00:28:21,973
especially if you work in genetic epidemiology or if you're doing these large scale genetic arrays.

243
00:28:22,243 --> 00:28:28,272
Oftentimes, you know, something will be only significant if it's like a P value of under .01 or something like that.

244
00:28:28,273 --> 00:28:32,413
So already there, you know, can be a bit more robust.

245
00:28:33,553 --> 00:28:38,923
Alpha levels and you know, you in your research, you could specify different alpha level if you wanted to.

246
00:28:40,483 --> 00:28:47,173
Um, but there is this like movement amongst some teachers.

247
00:28:47,443 --> 00:28:52,543
Why don't we just change .05, 2.05 and I suppose I don't have like the values here,

248
00:28:52,543 --> 00:28:58,813
but this theoretically would cut down a lot on us incorrectly rejecting a true null hypothesis.

249
00:28:58,813 --> 00:29:03,253
And I think this is a, you know, what we're particularly interested in,

250
00:29:03,943 --> 00:29:10,813
in epidemiology and in population sciences is like we really don't want to see that there is a significant association where,

251
00:29:10,813 --> 00:29:14,383
as in reality, there's no no causal relationship whatsoever.

252
00:29:16,543 --> 00:29:22,753
So there are some people who suggest that we should just change the upper level 2.05 Um, so again,

253
00:29:22,753 --> 00:29:29,623
that would mean instead of having 95% confidence intervals, you would have like 99.5% confidence intervals.

254
00:29:31,123 --> 00:29:36,643
You know, we'd change things quite a bit. Okay.

255
00:29:36,653 --> 00:29:41,323
So let's go into interpretations of borderline p value.

256
00:29:41,333 --> 00:29:51,093
So this is what we responded to earlier. Okay.

257
00:29:51,333 --> 00:30:02,283
So say that, you know, you are analyzing your data for an alley and you found that your main test you have a value of like 0.0.

258
00:30:03,063 --> 00:30:08,642
Maybe it's even like .05 to it's so close to being under point of five.

259
00:30:08,643 --> 00:30:14,942
You know what? What do you do? And you, you know, we'll talk more about hacking in a future class but you've like tried everything to

260
00:30:14,943 --> 00:30:21,663
get this p value down but you have like a P value point of five to what can you fix?

261
00:30:23,133 --> 00:30:28,653
So there are some of you who say that you can't see anything. There are some of you that like this word trend.

262
00:30:30,543 --> 00:30:34,533
There's other people who like the word tense. Like it tends to be related, but it's not significant.

263
00:30:35,073 --> 00:30:38,313
And there are some of you who like the word marginally significant.

264
00:30:39,963 --> 00:30:48,933
So I am here to nail you that there is different people will have different answers for this.

265
00:30:49,293 --> 00:30:53,973
There are some people who are very hardcore and will, you know, say that this is the correct answer.

266
00:30:56,613 --> 00:31:00,033
But there are other people who will be more lenient and see this kind of language as okay.

267
00:31:01,473 --> 00:31:04,983
And I don't think, you know, any of these are particularly better than others.

268
00:31:07,833 --> 00:31:20,833
But, you know, in my mind, I would like you to disentangle this idea of significance in this idea of substance or this this and that substance size.

269
00:31:20,833 --> 00:31:27,153
There's this idea of like reality or like what's actually important because your p value point of you.

270
00:31:27,933 --> 00:31:31,353
That could be a very important result.

271
00:31:31,593 --> 00:31:36,243
It could be in line with literature, which, you know, many previous papers might have found a significant result.

272
00:31:37,083 --> 00:31:40,443
So it could be a very important result. It could be very substantive.

273
00:31:40,923 --> 00:31:44,252
So this isn't to say that, like, if you find a value point or five to,

274
00:31:44,253 --> 00:31:50,543
then that like rejects all of the previous literature which has found a significant association.

275
00:31:50,553 --> 00:32:00,423
That's not what I'm trying to say here. I will also say that clinical journals in particular are very ornery about this.

276
00:32:00,423 --> 00:32:05,913
So they are very much into like not saying anything in terms of significance.

277
00:32:06,243 --> 00:32:10,442
I remember there was an article, I think it came out in JAMA Journal, the American Medical Association.

278
00:32:10,443 --> 00:32:13,023
So, you know, a big clinical oriented journal.

279
00:32:13,413 --> 00:32:23,553
And it was looking I believe it was looking at the relationship of exercise and risk of cardiovascular events.

280
00:32:23,943 --> 00:32:32,973
And basically the people found something, but it had a p value of 0.055 or it was like very close to being under two point of five.

281
00:32:32,973 --> 00:32:37,532
But it's not quite so like in like all over the manuscript.

282
00:32:37,533 --> 00:32:40,383
They're like, Oh, we did not find a significant result.

283
00:32:40,773 --> 00:32:45,903
And then in the discussion they spent all this time talking about like, you know, why did they find a significant result?

284
00:32:45,903 --> 00:32:53,403
Whereas all this other research had found that there was this relationship between exercise and lower risk.

285
00:32:54,993 --> 00:32:59,523
To me, that's kind of like wasted space because there's a lot of reasons why you could have

286
00:32:59,883 --> 00:33:04,623
lower versus higher P values and like sample size is a big contributor to this.

287
00:33:05,673 --> 00:33:10,653
And you know, if you do want to have like a P value .05 as your decision making guideline,

288
00:33:11,073 --> 00:33:14,493
you know, that's I think that's historically what's been done.

289
00:33:14,823 --> 00:33:16,592
But I think that ignores the fact that, you know,

290
00:33:16,593 --> 00:33:27,573
studies can be a bit messy and it's certainly something which has like a borderline or a marginally significant or a somewhat low p value,

291
00:33:27,573 --> 00:33:31,203
but not quite a .05. That could still be an important result.

292
00:33:31,443 --> 00:33:37,643
So we'll talk more in a future class about meta analysis, which can kind of delve into this issue a bit more.

293
00:33:37,953 --> 00:33:44,673
But this is all to say that, you know, I my my own preference, if I were to choose one of these things would be a bit of a hybrid.

294
00:33:44,673 --> 00:33:48,842
I you know, in my own research, I wouldn't say that something was significant because to me,

295
00:33:48,843 --> 00:33:53,103
significant just has to do with the statistics, it has to do with the statistical test.

296
00:33:53,403 --> 00:34:01,112
But again, you know that that doesn't 100% mapped onto reality into whether there's actually a causal relationship.

297
00:34:01,113 --> 00:34:09,603
So, you know, for me, if I had a value of like 1052 in a test, I would say, you know, it wasn't significant.

298
00:34:10,023 --> 00:34:12,243
But like in the discussion, I would talk about, you know,

299
00:34:12,243 --> 00:34:17,462
maybe the direction of association was very similar to what other studies have found and like my results could

300
00:34:17,463 --> 00:34:22,143
still form part of that body of research and it wouldn't necessarily be in contradiction to that body of research.

301
00:34:22,953 --> 00:34:25,803
Does that make sense? There's a bit of a nuance there.

302
00:34:26,193 --> 00:34:34,863
But, you know, I think there can be I certainly don't think we necessarily live in a world where, like, we just ignore all P values.

303
00:34:35,373 --> 00:34:41,553
Maybe, maybe we move to that world. But I'd argue some flexibility is okay.

304
00:34:41,823 --> 00:34:47,213
So this is a bit of a trick question in the sense that different people will have different ways that they talk about this.

305
00:34:52,153 --> 00:34:59,863
Okay. So many epidemiology journals have actually just switched to reporting confidence intervals and not p values.

306
00:35:00,223 --> 00:35:05,803
So you'll see that I like the American Journal of Epidemiology, I believe the International Journal of Epidemiology as well.

307
00:35:06,103 --> 00:35:13,963
Like they're big into you know, let's reports confidence intervals and not P values like in my mind.

308
00:35:14,353 --> 00:35:20,973
Well let's let's first have you discuss so what does a 95% confidence interval mean and say that you you know,

309
00:35:20,983 --> 00:35:27,513
again you did a logistic regression model. This is what you found for the relationship between coffee and diabetes.

310
00:35:28,033 --> 00:35:32,293
What does this confidence interval actually mean?

311
00:35:36,133 --> 00:35:38,746
Yeah. This guy's. I'll do that.

312
00:35:40,399 --> 00:35:45,739
Um, so I will move on to the group here in the front part.

313
00:35:46,069 --> 00:35:52,969
Did you have any thoughts on how you would interpret this confidence interval between 1.5 and 3.75?

314
00:36:01,359 --> 00:36:07,029
Mr. Howard has been at the lower. Okay.

315
00:36:08,559 --> 00:36:15,219
So 95% confidence. True number in between lower and higher.

316
00:36:15,609 --> 00:36:22,789
Is that okay? A great to move to another group just in case people have their thoughts.

317
00:36:23,699 --> 00:36:28,669
The phone frequencies. Did you have any thoughts similar or different to this?

318
00:36:35,949 --> 00:36:39,338
Oh yeah. So my. Yeah.

319
00:36:39,339 --> 00:36:54,489
I think this is a great start and potentially like a fine, succinct answer, the way that I would change this would just be like across multiple tests,

320
00:36:55,689 --> 00:37:07,239
95% of the time the true value or the true number will fall between the lower and entire interval.

321
00:37:08,199 --> 00:37:12,008
So I think that's kind of what you're getting with this 95% confidence.

322
00:37:12,009 --> 00:37:24,158
But it's more so that if we're running studies many, many times, like if we have 100 or a thousand studies, are searching the exact same thing,

323
00:37:24,159 --> 00:37:32,259
looking at the relationship between coffee and diabetes, 95% of the time the true number would be between the lower and the higher interval.

324
00:37:32,679 --> 00:37:35,349
But of course, these intervals would change between studies.

325
00:37:35,649 --> 00:37:43,359
So it's not to say that the true number is actually between 1.5 and 3.75, because maybe our number is like, you know,

326
00:37:44,019 --> 00:37:51,639
kind of way off base and maybe the, you know, the bulk of the other numbers would have a widely different set of confidence intervals.

327
00:37:53,839 --> 00:38:01,729
But yeah, so across a lot of different studies that are doing the same thing, 95% of times the true value will fall in between these levels.

328
00:38:03,409 --> 00:38:07,999
Okay. With that, I will give you a bit of a break.

329
00:38:07,999 --> 00:38:11,449
Let's come back at 205 to finish off the US.

330
00:38:21,223 --> 00:38:27,523
Okay. Any questions on key values or confidence intervals?

331
00:38:28,513 --> 00:38:40,213
I think this is one of the things where we use them a lot, but their interpretation is incredibly confusing and that leads us to kind of a big debate

332
00:38:40,213 --> 00:38:46,993
within the world of statistics about how should we think about significance testing,

333
00:38:46,993 --> 00:38:54,493
how should we actually go about doing the analysis. And so there's kind of this debate now between frequentist and Bayesian statistics.

334
00:38:54,493 --> 00:39:01,993
So how many of you have heard of like frequentist or Bayesian statistics?

335
00:39:01,993 --> 00:39:05,683
I promise not to call any both show of hands. Have any of these words?

336
00:39:07,833 --> 00:39:16,613
Okay. Not many of you. So frequentist is pretty much what we taught you in any of your previous biostatistics courses.

337
00:39:16,623 --> 00:39:20,973
So when we think of like P values with this, they go under the null hypothesis.

338
00:39:20,973 --> 00:39:27,872
This is a percent chance that something would happen, you know, under confidence intervals.

339
00:39:27,873 --> 00:39:33,303
We're thinking about like the true value will be within the confidence interval across a number of different studies.

340
00:39:33,573 --> 00:39:34,563
That is frequentist.

341
00:39:35,283 --> 00:39:43,293
The idea behind the word frequentist is I think the word frequency just means that in the back of our mind, whenever we're computing a statistic,

342
00:39:44,703 --> 00:39:53,493
we are also thinking about, you know, hundreds or thousands of other studies which are doing a similar thing that are operating in the background.

343
00:39:53,493 --> 00:39:55,383
And they might not have actually been conducted.

344
00:39:55,713 --> 00:40:03,513
But like our P values in comparison to all those other studies and our, you know, our confidence intervals are interpreted relative to them.

345
00:40:06,033 --> 00:40:13,053
So that is what that what we that's what we mean by frequentist is like there's whenever we're calculating something, there's,

346
00:40:13,053 --> 00:40:19,502
you know, in the background, there's like what would happen if hundreds of other studies try to do the same thing again?

347
00:40:19,503 --> 00:40:24,003
Convoluted. Another way of looking at things is through Bayesian statistics.

348
00:40:24,453 --> 00:40:31,293
So Bayesian statistics is this idea that we can incorporate information from previous studies.

349
00:40:31,683 --> 00:40:35,973
So maybe we have our relationship between coffee and diabetes.

350
00:40:35,973 --> 00:40:41,342
We are doing we're running analysis based on data that we got now from Michigan,

351
00:40:41,343 --> 00:40:47,763
but maybe there's like five or ten previous studies which have been done for Bayesian statistics.

352
00:40:48,033 --> 00:40:53,703
We will use those as what we call a prior or an informative priors.

353
00:40:53,703 --> 00:40:58,983
So. So for Bayesian you have something called a prior.

354
00:40:59,433 --> 00:41:09,332
And so I guess in frequentist we're kind of like being a bit, I don't want to say unbiased,

355
00:41:09,333 --> 00:41:14,583
but we're just kind of neutral in thinking like our study operates against the backdrop of

356
00:41:14,583 --> 00:41:18,573
all these hypothetical studies that probably are being conducted with Bayesian statistics.

357
00:41:18,573 --> 00:41:26,373
You're actually looking at, you know, for the 5 to 10 previous studies which had been conducted, what did they find?

358
00:41:26,553 --> 00:41:34,893
And then you use their results as generally you'd call it like an informative and informative prior and informative prior.

359
00:41:34,983 --> 00:41:37,293
And so you actually are using the results from previous studies.

360
00:41:38,853 --> 00:41:46,713
So basically you use the results from previous studies to compute the what we would call a credibility interval.

361
00:41:48,243 --> 00:41:52,083
So frequentist statistics have what we call confidence intervals.

362
00:41:53,223 --> 00:41:57,153
And for Bayesian statistics we have what are called credibility intervals.

363
00:41:58,173 --> 00:42:03,473
And so those are often abbreviated CROI versus a conference survey which is just CHI.

364
00:42:04,473 --> 00:42:07,622
So for Bayesian statistics you do not get any p value.

365
00:42:07,623 --> 00:42:11,942
So like for frequentist, you can get a p value for Bayesian statistics.

366
00:42:11,943 --> 00:42:17,593
There's no such, you know. But you do have these credibility intervals.

367
00:42:17,603 --> 00:42:23,293
So basically you're basing the bounds of your credibility interval based on all these other previous studies.

368
00:42:23,563 --> 00:42:29,592
And that's such like a different thing from how we operate in frequentist statistics,

369
00:42:29,593 --> 00:42:35,713
because oftentimes the frequent statistics is like we should be unbiased as we look at our results and

370
00:42:35,713 --> 00:42:41,053
we should ignore what people have done previously and we should just like see what arises from our,

371
00:42:41,983 --> 00:42:46,663
our study and then that's like the true value.

372
00:42:47,023 --> 00:42:51,403
Whereas for Bayesian statistics, you really do look to see like what's happening previously.

373
00:42:52,603 --> 00:42:57,043
Most of the time you'll do an informative prior, you can actually do a non informative prior if you want.

374
00:42:57,043 --> 00:43:02,022
So a non internet prior just means like maybe you have no information,

375
00:43:02,023 --> 00:43:12,073
maybe you're looking at like a novel relationship between this newly developed drug and, you know, some, some health outcomes.

376
00:43:12,073 --> 00:43:17,983
So maybe you don't have any previous information. So you can use a non informative prior, but generally you'll use an informative prior.

377
00:43:28,833 --> 00:43:34,143
And then your output just kind of as symmetry of this is often just called like a posterior.

378
00:43:35,913 --> 00:43:42,422
So like in for frequentist results, you have like a table of like this is what your results are like your,

379
00:43:42,423 --> 00:43:48,903
your odds ratio, your confidence intervals, things like that. For Bayesian statistics, they'll just call that a table of your posterior.

380
00:43:49,233 --> 00:43:56,433
And in the posterior there also be a credibility interval. So we're not really going to dive into Bayesian statistics in this course.

381
00:43:57,203 --> 00:44:02,612
You know, there's probably been a debate raging for well, for a long time.

382
00:44:02,613 --> 00:44:12,033
This is actually named after Bayes, who was sort of this this cleric polymath from, I believe, the 1700s.

383
00:44:12,033 --> 00:44:17,703
So, you know, he he has been around for a while, but I think in the last few decades,

384
00:44:17,703 --> 00:44:24,813
a lot of biostatistician biostatistics has shifted from thinking about things from a frequentist perspective to Bayesian perspective.

385
00:44:24,823 --> 00:44:31,473
So I think a lot of our statistics methodologies will advocate using Bayesian statistics.

386
00:44:32,013 --> 00:44:37,473
We're not quite there yet in epidemiology. You know, maybe we will be in the next decade or so.

387
00:44:37,473 --> 00:44:39,332
But I will say that, you know,

388
00:44:39,333 --> 00:44:47,433
for a it's been a while now that bio statisticians have kind of been very much advocating for using Bayesian statistics.

389
00:44:47,433 --> 00:44:52,832
And I don't think it's really caught on much in other places. But I you know, I do think it's important to learn.

390
00:44:52,833 --> 00:44:59,373
And, you know, anything you're doing right now, like you're running logistic regression model or a linear regression model or doing some,

391
00:44:59,673 --> 00:45:03,603
you know, correlation there, there's always going to be a Bayesian analog to that.

392
00:45:03,603 --> 00:45:07,743
So you really could switch wholesale from doing things frequentist to B0.

393
00:45:08,523 --> 00:45:13,773
And I'm sure there's all sorts of packages in R which would explain that and you can do Bayesian statistics and SAS as well.

394
00:45:17,253 --> 00:45:22,603
Any questions about? Okay.

395
00:45:22,813 --> 00:45:28,643
So getting into the meat of the class for today, Margaret.

396
00:45:28,843 --> 00:45:34,633
So model building there is. You know what I mean is what explanatory variables should be put into a multivariable model.

397
00:45:35,833 --> 00:45:41,503
You know, how many variables should be in there? There's other things called variable selection, model selection.

398
00:45:41,503 --> 00:45:45,133
I think those are relatively synonymous with model building.

399
00:45:47,953 --> 00:45:55,243
This is maybe a bit different than model specification. So model specification is like, did you use a logistic regression or placental regression?

400
00:45:56,633 --> 00:46:03,493
What's your your link and distribution statements like in your multivariable models?

401
00:46:04,933 --> 00:46:09,163
But they're kind of similar items. Okay.

402
00:46:09,193 --> 00:46:14,153
But before we get to this step, so this is maybe some of the you should be thinking right now, if you have an elite project,

403
00:46:14,193 --> 00:46:22,182
you're doing some analysis of questions to ask yourself, is this an observation or an experimental study?

404
00:46:22,183 --> 00:46:26,333
Because if it's experimental, you might not even want to do a multivariable model.

405
00:46:26,353 --> 00:46:30,252
You can just do like a simple chi square or a t test or, you know,

406
00:46:30,253 --> 00:46:34,533
depending on your outcome, because you might not need to control for these third variables.

407
00:46:34,573 --> 00:46:38,703
If you have an experiment, what is the main driver of your research?

408
00:46:38,713 --> 00:46:42,612
Is it the explanatory variable or is it the outcome? What do I mean by this?

409
00:46:42,613 --> 00:46:51,613
So, you know, I think the easiest thing to think about is like I'm interested in the relationship between coffee and diabetes.

410
00:46:51,613 --> 00:46:58,153
So then you can have like this really beautifully thought out, Dag, that you put together and then you develop a model based on that.

411
00:46:59,113 --> 00:47:05,772
But sometimes when you're interested in is like, I just want to know how does the outcome vary across different groups?

412
00:47:05,773 --> 00:47:14,383
So, you know, I've done a number of studies in the past which have looked at vaccination and like who is getting vaccinated or not?

413
00:47:14,383 --> 00:47:18,703
So we don't necessarily have like one explanatory variable of interest.

414
00:47:18,903 --> 00:47:28,693
There could be a few that are important. So certainly, you know, that depends on what you'll eventually select into model.

415
00:47:31,303 --> 00:47:38,262
In this class, we're pretty much talking about dichotomous outcomes, but certainly if you have interval or null or nominal outcomes,

416
00:47:38,263 --> 00:47:45,793
you may not be able to do like a logistic regression or plus some regression prolapse do like a multi normal regression, logistic regression model.

417
00:47:45,793 --> 00:47:51,433
Or you might have to treat it as continuous and just do like a linear regression model.

418
00:47:53,473 --> 00:47:57,693
We talked about this last time with the idea positivity, but you know,

419
00:47:57,733 --> 00:48:04,332
if you just like don't have a lot of people and certain explanatory variables in certain groups of these voluntary variables,

420
00:48:04,333 --> 00:48:10,963
you might need to collapse your variable. And it could be that you're just not able to ask the question that you're really interested in.

421
00:48:11,353 --> 00:48:13,932
You know, maybe we're interested in, you know,

422
00:48:13,933 --> 00:48:21,643
for people who drank any amount of coffee versus those who've never had any coffee in their life, what is their risk of diabetes?

423
00:48:22,153 --> 00:48:27,342
But frankly, like in the US, the number of people who've never drank coffee, I, I don't know the number,

424
00:48:27,343 --> 00:48:30,973
but I assume it's like very small because, you know, many people have had like a cup here or there.

425
00:48:32,143 --> 00:48:35,173
So it would be very difficult to estimate that.

426
00:48:38,383 --> 00:48:42,463
Other things to keep in mind, like, are you doing a mediation analysis or an interaction analysis?

427
00:48:42,853 --> 00:48:46,063
My recommendation is to not do those.

428
00:48:46,303 --> 00:48:49,332
If it's a really important part of your aim, of course you can do them.

429
00:48:49,333 --> 00:48:52,213
And you know, we talked a bit last time about what you can do.

430
00:48:52,483 --> 00:49:02,953
But like, if if it's not part of your research aims, just don't do them because like ignore them because the more that you delve into them,

431
00:49:03,253 --> 00:49:08,323
the more work you'll have to do and your analysis can quickly just become really confusing.

432
00:49:12,783 --> 00:49:16,723
Okay. So when I talk about model building, I'm going to, you know,

433
00:49:16,803 --> 00:49:22,413
be a bit stereotypical and talk about two different types of approaches, epidemiological and statistical.

434
00:49:22,713 --> 00:49:29,223
These are not based on, you know, some consensus of what epidemiologists and what bio statisticians do.

435
00:49:29,493 --> 00:49:36,272
This is just like my feeling, having worked, you know, ten years in this area and worked with a number of epidemiologists,

436
00:49:36,273 --> 00:49:40,893
a number of our statisticians, and kind of done the nitty gritty of model building with them.

437
00:49:42,093 --> 00:49:47,253
How do they do? And I noticed that there are trends in like two different types of approaches.

438
00:49:47,643 --> 00:49:49,442
So that's how I'm going to refer to them.

439
00:49:49,443 --> 00:49:58,043
But, you know, this is just a way to, you know, make some broad statements and for you to think about like what's useful and important for you,

440
00:49:58,053 --> 00:50:02,282
I don't think either way is like wrong or not.

441
00:50:02,283 --> 00:50:05,883
I, you know, if I had to advocate, I would advocate for the epidemiological approach.

442
00:50:05,883 --> 00:50:12,272
But I think you could you know, you could do an alley project. You could do an entire career based on using both statistical purposes.

443
00:50:12,273 --> 00:50:19,203
And that'd be totally fine. There's, you know, nothing wrong with that. Another way of thinking about this.

444
00:50:19,203 --> 00:50:26,463
The epidemiological approach is more dealing with a prairie hypothesis, whereas the Boustead school approach is more of a data driven approach.

445
00:50:28,533 --> 00:50:32,163
So the basis of the epidemiological approach is to put together a DAG.

446
00:50:32,313 --> 00:50:36,573
So you have exposure, you have an outcome.

447
00:50:37,143 --> 00:50:40,623
Put that in DAG and you think about like what other potential confounders there are

448
00:50:40,833 --> 00:50:47,043
and then control for them if they are confounders in a model of the total effect.

449
00:50:47,253 --> 00:50:52,513
I think and you know, you could do a mediation analysis or whatnot, but that that's what the epidemiological purchase like.

450
00:50:52,533 --> 00:50:59,793
You don't look at the distribution of your data at all except to maybe like see that there's enough people in different groups to,

451
00:50:59,793 --> 00:51:02,793
you know, see there's enough coffee drinkers versus not coffee drinkers.

452
00:51:03,363 --> 00:51:07,713
But the epidemiological approach with these drugs is really just you think of everything

453
00:51:07,713 --> 00:51:11,313
ahead of time and then you run your models and then you interpret the results and that's it.

454
00:51:15,663 --> 00:51:23,163
But we might move slightly away from that in certain circumstances, maybe were unsure what the confounders are.

455
00:51:23,883 --> 00:51:28,173
And, you know, there is the theoretical approach of just seeing like what what the stated literature is.

456
00:51:28,563 --> 00:51:34,713
But you could also think about, you know, maybe I just want to see, do the confounders actually matter?

457
00:51:35,193 --> 00:51:40,983
Like do these potential confounders like maybe there's no statistical relationship between them and the exposure in the outcome,

458
00:51:40,983 --> 00:51:43,713
so we might as well not even include them in the multivariable model.

459
00:51:44,373 --> 00:51:52,713
So what you could do is you could run bivariate tests on all of the exposure, confounder relationships and all the confounder outcome relationships.

460
00:51:53,013 --> 00:51:57,963
So say that you, you know, you have your one exposure, one outcome, and then you have five confounders of interest.

461
00:51:58,233 --> 00:52:04,503
So really you'd have like ten different estimates that you'd have or ten different tests that you'd have here.

462
00:52:06,063 --> 00:52:13,313
And then what test you use would depend on, like what the distribution of the variable is, you know, is it, is it nominal, is it ordinal?

463
00:52:13,323 --> 00:52:20,082
Is it an interval variable? You could just do these different tests and then maybe what you decide is like, Oh,

464
00:52:20,083 --> 00:52:26,433
if there's a p value of under 2.5, then I will include that confounder in the final model.

465
00:52:26,523 --> 00:52:33,663
That could be something that you to do. Okay.

466
00:52:33,673 --> 00:52:40,243
So one of the problems which arises with this is like we might be end up doing a lot of significant tests.

467
00:52:40,243 --> 00:52:46,213
So I give an example of if there's five confounders, but in reality, what if you have ten or 20 different confounders,

468
00:52:48,163 --> 00:52:59,322
all of a sudden the interpretation of our P value gets really tricky because if you recall from earlier in this class with the P value means is,

469
00:52:59,323 --> 00:53:06,063
you know, what is the correct.

470
00:53:08,703 --> 00:53:17,313
Therapy p value is looking at saying that there is a chance of observing this value as extreme or more extreme under the null hypothesis.

471
00:53:18,093 --> 00:53:21,423
If we start running like ten, 20, 30 different tests,

472
00:53:21,813 --> 00:53:32,042
then we really are going to start getting a lot of supposedly significant values just because under the null hypothesis,

473
00:53:32,043 --> 00:53:36,993
there will be this kind of random distribution of P values from 0 to 1.

474
00:53:36,993 --> 00:53:40,953
So there will be some that are by chance under point of five, but will be meaningless.

475
00:53:42,483 --> 00:53:47,733
So this is all to say there is a way to correct for testing on multiple p values.

476
00:53:48,753 --> 00:53:55,893
The easiest approach would be the bonferroni correction. But I'll also talk about the home bonferroni correction.

477
00:53:56,463 --> 00:54:02,193
There are two ways of doing this. One way is you can change the alpha level and one way is you can change the p value.

478
00:54:02,853 --> 00:54:06,993
So I'm going to be talking about the way of changing the p value.

479
00:54:06,993 --> 00:54:10,562
But you might have heard of the way of changing the alpha value in the past.

480
00:54:10,563 --> 00:54:19,773
So for and this is an example, so the bonferroni correction say that you're doing ten different tests.

481
00:54:21,213 --> 00:54:30,002
What you could do is you could multiply all of your P values by ten or you could change the alpha level from .05 and just divide it by ten.

482
00:54:30,003 --> 00:54:38,343
So it would be .05. And then what if something is if something is significant or not would be the exact same because you know, that's just algebra.

483
00:54:39,903 --> 00:54:45,123
But I think of multiplying p values is just like more intuitive because then you just keep the alpha level at point five.

484
00:54:46,233 --> 00:54:52,593
So again, bonferroni correction, you see how many comparisons you have. You multiply your P values by those number of comparisons.

485
00:54:53,433 --> 00:55:00,123
The whole bonferroni correction is a bit less conservative, so you'll end up with more significant results.

486
00:55:01,593 --> 00:55:06,002
And here are my instructions and I'll give you a let you have a chance to actually do this.

487
00:55:06,003 --> 00:55:14,883
But basically the lowest p value, the one closest to zero will essentially be the bonferroni correction.

488
00:55:15,153 --> 00:55:19,673
But then all the other ones you will you will subtract by one.

489
00:55:19,683 --> 00:55:26,553
So if you had ten, you know, your lowest valued multiplied by ten, your second lowest, you multiply by nine, your third lowest, you multiply by eight.

490
00:55:26,553 --> 00:55:30,993
And so. Okay.

491
00:55:31,113 --> 00:55:38,013
So I will have you do this in groups. I want you to find out what the Bonferroni corrections are and the whole Bonferroni corrections are.

492
00:55:38,673 --> 00:55:44,582
So right now we have these are just you know, it doesn't matter really what the meaning of this is.

493
00:55:44,583 --> 00:55:51,723
Maybe we are just looking at yeah, we're looking at three different confounders and the relationship with hypertension.

494
00:55:52,233 --> 00:56:00,723
These are the P values which are unadjusted. So there are three comparisons here because there's one comparison of sex and hypertension.

495
00:56:01,023 --> 00:56:05,703
One comparison of income and hypertension and one of agent hypertension.

496
00:56:06,863 --> 00:56:11,073
Okay, so I'll put this back here, but please let me know if you have any questions.

497
00:56:12,973 --> 00:56:39,113
Yeah. Thank you for doing that.

498
00:56:53,733 --> 00:57:21,953
Now trying to set. I.

499
00:57:26,873 --> 00:57:36,153
I just. I was to.

500
00:57:37,763 --> 00:57:43,933
Out of. Yeah. Yeah.

501
00:58:04,853 --> 00:58:12,603
And then. I.

502
00:58:19,113 --> 00:58:44,973
Okay. What is the purpose of it?

503
00:58:46,423 --> 00:58:52,243
Oh, man, I wonder. I about.

504
00:58:59,793 --> 00:59:15,633
I think it's quite. Now.

505
00:59:20,583 --> 00:59:31,903
That. Yeah.

506
00:59:33,523 --> 00:59:39,043
I have a little something for you. Yeah.

507
00:59:47,693 --> 01:00:13,853
I felt. I love cigaret lighters.

508
01:00:15,763 --> 01:00:23,993
I don't know about. You know.

509
01:00:34,703 --> 01:00:42,753
I haven't heard about. That was actually quite a lot.

510
01:00:57,653 --> 01:01:07,483
No. Have.

511
01:01:29,573 --> 01:01:33,683
Okay. Let's come back and talk about this.

512
01:01:36,773 --> 01:01:48,133
Necessary. So let me go to the proc freaks.

513
01:01:48,143 --> 01:02:06,522
What do you have for the bonferroni values? So I would say there are three comparisons here.

514
01:02:06,523 --> 01:02:09,883
So I would change this to 0.009.

515
01:02:14,623 --> 01:02:22,093
Are we talking about the home bonferroni method? We?

516
01:02:24,743 --> 01:02:28,373
Really? Yeah.

517
01:02:28,513 --> 01:02:32,922
So people will always get this is a confusion.

518
01:02:32,923 --> 01:02:37,153
So I understand the confusion. So you're saying like, oh, they're male and female here.

519
01:02:37,153 --> 01:02:42,433
So that's like the two comparison groups. So no, I understand the impulse for wanting to do that,

520
01:02:42,943 --> 01:02:48,583
but by comparisons we mean like the number of people that in the number of people you test, there aren't.

521
01:02:50,053 --> 01:02:57,132
So, you know, the, the number of comparisons on one colloquial sense.

522
01:02:57,133 --> 01:03:01,033
Yes. For for this p value, like we're comparing males and females, that's two different groups.

523
01:03:01,453 --> 01:03:06,643
But for the purposes of a bonferroni correction, we just need to count up how many P values we have.

524
01:03:07,243 --> 01:03:13,812
So for it, like for sex, for income and age, those are three different P values.

525
01:03:13,813 --> 01:03:18,403
That means we have three comparisons. So then we just multiply everything by three.

526
01:03:19,063 --> 01:03:23,682
So like four. So does that make sense?

527
01:03:23,683 --> 01:03:26,773
What do you think? That's an important thing in understandable confusion.

528
01:03:28,003 --> 01:03:33,023
So just add up the number of P values. That's how many comparisons you have. Any questions on that.

529
01:03:34,643 --> 01:03:39,442
But otherwise, the bonferroni is, you know, relatively easy to compute.

530
01:03:39,443 --> 01:03:43,012
You just multiply everything by the number of comparisons. So I put No.

531
01:03:43,013 --> 01:03:51,323
Nine, I have point oh, .24 and I have 0.045.

532
01:03:56,183 --> 01:04:02,473
Does that make sense? Okay.

533
01:04:03,313 --> 01:04:08,082
I don't think I've talked to me yet. Do you want to take a stab at the home?

534
01:04:08,083 --> 01:04:14,773
Bonferroni corrections. Yeah.

535
01:04:16,173 --> 01:04:26,763
It is. He is.

536
01:04:28,843 --> 01:04:39,203
Four or five. Yep.

537
01:04:39,253 --> 01:04:49,273
So the homebound for money will never be a higher p value than the bonferroni, but for the lowest numbers they'll be equivalent.

538
01:04:50,263 --> 01:04:56,592
So the issue here is, you know, having three, you can probably struggle it in your mind.

539
01:04:56,593 --> 01:05:00,973
But you know, how I would do this is I would like have a separate table where I'd like actually

540
01:05:00,973 --> 01:05:05,213
start everything by the p values that I make sure that I'm not missing anything.

541
01:05:07,363 --> 01:05:11,433
And then also, like, I mean, I'm sure SAS and R can just do this all.

542
01:05:11,713 --> 01:05:19,003
So there's probably commands that you can do in any program or any package to just automatically compute these corrected P values.

543
01:05:19,843 --> 01:05:32,923
But so the lowest p value be multiplied by the number of comparisons and we just remove that penalty until we get to the um, the highest p value.

544
01:05:35,633 --> 01:05:39,743
And, you know, statisticians have worked on how you can do this.

545
01:05:39,743 --> 01:05:43,613
And apparently the home bonferroni method is still very adequate.

546
01:05:43,943 --> 01:05:51,173
There is no reason why you would do a bonferroni over home bonferroni, except that the FRONI is easier to do, I guess.

547
01:05:52,223 --> 01:05:57,473
But the whole bonferroni will be adequate for decision making.

548
01:05:59,833 --> 01:06:01,863
But does it also make sense, like why we would do this?

549
01:06:01,873 --> 01:06:07,573
I mean, again, the idea is like P values can lie to us sometimes and the more p values that we have,

550
01:06:08,323 --> 01:06:12,613
the more of a chance that we will have like a liar in the table.

551
01:06:12,943 --> 01:06:17,533
So by correcting or just like reducing the chance that there will be that there will be that line.

552
01:06:21,083 --> 01:06:27,233
Any other questions? Okay.

553
01:06:27,233 --> 01:06:30,503
So how many statistical tests did you do in one paper?

554
01:06:30,533 --> 01:06:33,533
There are several people who just advocate just doing one test.

555
01:06:34,133 --> 01:06:37,003
So say that we have the same one, one test per unit.

556
01:06:37,313 --> 01:06:41,063
And so, you know, your study, your paper might have like three different things that be three tests,

557
01:06:41,753 --> 01:06:48,593
but say you have this one in the study, assess the relationship between coffee consumption and type two diabetes.

558
01:06:49,233 --> 01:06:54,443
Ah P-value of interest then is the coffee parameter in a multivariable model

559
01:06:55,583 --> 01:06:58,943
or if we had some experimental study we might just even do a chi square test.

560
01:07:02,283 --> 01:07:04,383
What often is done is in a paper,

561
01:07:04,383 --> 01:07:14,093
because I think we all learn how to do all of these statistical tests through our both statistics and epidemiology courses.

562
01:07:14,103 --> 01:07:22,893
So we like to, you know, put them all in our paper and just kind of show off what we're able to do, which, you know, I understand the compulsion.

563
01:07:23,613 --> 01:07:25,613
So oftentimes what people do is, you know,

564
01:07:25,623 --> 01:07:33,633
they'll have a table where they look at they'll do tests between the coughing confounders and the confounders and the outcome.

565
01:07:34,173 --> 01:07:36,663
They might even have an unadjusted regression model.

566
01:07:37,233 --> 01:07:44,223
And beyond interpreting this value for the coffee parameter, they might interpret other values within the multivariable regression model.

567
01:07:45,843 --> 01:07:49,293
What I'm suggesting to you is you don't need to do all of this.

568
01:07:49,683 --> 01:07:57,363
You know, maybe there are reasons to show this, like, I get it. And oftentimes if I don't have this reviewer's will come back and want some of this.

569
01:07:57,363 --> 01:08:06,363
But I think that's out of a misguided sense from peer reviewers to just make everything boil down to a1p value.

570
01:08:06,363 --> 01:08:13,473
Whereas hopefully one of the takeaways from this class is that P values don't always necessarily mean what we think they should mean,

571
01:08:13,833 --> 01:08:19,323
but they're just like the best and easiest way under a frequentist framework of explaining our results.

572
01:08:21,273 --> 01:08:26,073
One thing to keep in mind is the table two fallacy. The table two fallacy comes from this.

573
01:08:26,133 --> 01:08:33,513
You know, oftentimes table twos in paper will show like a multivariable regression model.

574
01:08:35,833 --> 01:08:48,103
And say we have this situation where we are looking at maybe this is like the the risk of a heart attack or something.

575
01:08:48,133 --> 01:08:54,013
So our outcome is a heart attack and we have two different variables, lack of exercise and stress.

576
01:08:54,463 --> 01:08:58,813
And we're finding that both of them are significantly related to our risk of a heart attack.

577
01:09:01,153 --> 01:09:09,613
The issue is that we don't know just by looking at this table, we don't know what the causal diagram is.

578
01:09:10,483 --> 01:09:17,233
And there are three potential causal diagrams here. So for outcome is cardiovascular disease events.

579
01:09:17,923 --> 01:09:24,763
It could be that we think these are independent and there's no relationship between lack of exercise and stress that these are just independent.

580
01:09:25,183 --> 01:09:28,843
LI related to the outcome. That's one option.

581
01:09:29,413 --> 01:09:37,182
Another option is that stress is a mediator in that.

582
01:09:37,183 --> 01:09:42,463
Like, if you don't exercise, that might maybe that increases your stress.

583
01:09:44,083 --> 01:09:46,183
So that's one theoretical underpinning.

584
01:09:47,383 --> 01:09:54,373
But another thing is that maybe exercise is actually the mediator, or maybe if you're really stressed, then you'll be getting less exercise.

585
01:09:54,403 --> 01:09:56,262
So, you know, there's a bit of circular in this.

586
01:09:56,263 --> 01:10:01,633
You know, it depends on how things are measured and so on and so forth, but it's just unclear from this table.

587
01:10:03,373 --> 01:10:07,073
So in this table, we don't know what is the main exposure.

588
01:10:07,093 --> 01:10:17,263
We also don't know what is a mediator. So if some if we are in a situation of B or C, one of these will be a mediator,

589
01:10:17,263 --> 01:10:21,013
and then one of these will just be measuring the direct effect and not the total effect.

590
01:10:21,403 --> 01:10:25,153
But generally, how we interpret things is through the total effect and not the direct effect.

591
01:10:26,263 --> 01:10:35,332
So this is all to say that like oftentimes people will you you'll run a multivariable model, you'll have like ten variables in it,

592
01:10:35,333 --> 01:10:36,913
and maybe you have like one exposure of interest,

593
01:10:36,913 --> 01:10:41,803
but then you have all these confounders and the impulse is to just like, let's interpret all these different values.

594
01:10:42,193 --> 01:10:52,093
Let's, you know, give our interpretation, give our thoughts on like the relationship between all these values, including the confounder.

595
01:10:53,713 --> 01:11:01,603
But you don't need to do that because all those values of the confounders are measuring again, they're making a direct effect, not a total effect.

596
01:11:02,443 --> 01:11:07,363
And there's, you know, there's there's potential mediation that's occurred.

597
01:11:08,503 --> 01:11:18,913
So my my recommendation is to off the bat, think of all your causal diagram is and then for your tables to just focus on interpreting the,

598
01:11:18,913 --> 01:11:24,373
your main exposure and to kind of ignore all of the other variables as much as possible.

599
01:11:25,933 --> 01:11:33,503
Does that make sense? Okay.

600
01:11:33,833 --> 01:11:38,513
Just a few slides on, kind of getting into more about his skill approach.

601
01:11:38,963 --> 01:11:44,663
Oftentimes, what people will be interested in, you know, epidemiologists can be interested in this as well as model fit.

602
01:11:45,173 --> 01:11:53,893
And the whole idea of model fit or goodness of it is comparing what our actual values are and what the model predicts are values should be.

603
01:11:53,903 --> 01:12:00,113
So it's looking at observed values and expected values, and there's a number of different ways of like doing that comparison.

604
01:12:00,593 --> 01:12:08,723
So there is the AIC, there is the basi, there's the likelihood ratio for odds, regret or for logistical regression models.

605
01:12:08,723 --> 01:12:14,582
There's the house where let me show test. So for us, this is kind of like what you see.

606
01:12:14,583 --> 01:12:18,483
And oftentimes we like scroll past these in the output. We don't really pay attention to them too much.

607
01:12:20,133 --> 01:12:25,443
And for our like in any, you know, model, you can call these if you need them.

608
01:12:26,673 --> 01:12:29,252
So oftentimes it's up to email. Just we kind of ignore these.

609
01:12:29,253 --> 01:12:33,753
But Biostatistician in particular will focus on this a lot because what they will try to do is

610
01:12:33,753 --> 01:12:38,703
like run a bunch of different models and to improve the model fit across those different models.

611
01:12:39,783 --> 01:12:43,833
So like for epidemiologists, oftentimes we're interested in, you know, like, what is one, um,

612
01:12:45,303 --> 01:12:49,563
what is the strength of association for like our main exposure and our outcome for biostatistician?

613
01:12:49,563 --> 01:12:53,073
Is there kind of like looking overall and holistically? What is the model fit?

614
01:12:55,653 --> 01:13:01,413
So stepwise regression is one way of doing more of a data driven approach.

615
01:13:02,103 --> 01:13:08,643
There's also something called the best subset selection model. I'm just going to briefly talk about it here.

616
01:13:08,673 --> 01:13:13,023
You know, you probably won't have to do much of this in the future, but, you know, in case you do.

617
01:13:13,473 --> 01:13:20,853
The whole idea behind the best subset selection model is that you tell the program how many variables that you want,

618
01:13:21,243 --> 01:13:31,053
and then it will like say that you have a list of of ten possible confounders or ten possible independent variables and covariates,

619
01:13:32,643 --> 01:13:34,533
but you only want five in your model.

620
01:13:34,803 --> 01:13:40,163
So you tell the program, I only want five in your model, and then it will output the model which has the best model fit.

621
01:13:43,503 --> 01:13:48,033
So, you know, there's a continuum of different approaches.

622
01:13:48,033 --> 01:13:53,163
Maybe more of the epidemiological side is thinking about things more theoretically having a priority considerations,

623
01:13:53,163 --> 01:13:57,242
meaning that we develop our model and then we run things for epidemiology.

624
01:13:57,243 --> 01:14:05,582
We might focus more just on like one association, one outcome between one exposure and outcome for bias statistics.

625
01:14:05,583 --> 01:14:12,513
It's a bit more data driven. It can be easier to be automated. You know, there's a number of different approaches that we could do.

626
01:14:16,393 --> 01:14:20,823
And you know, I again, I'm not trying to say like one is better or worse than the others.

627
01:14:20,833 --> 01:14:28,063
I think you can have collaborators who want to do some things one way versus the other of your,

628
01:14:28,393 --> 01:14:32,292
you know, preceptor for your iili might have their own approaches.

629
01:14:32,293 --> 01:14:38,083
I think, you know, be flexible about it. I think that's served me pretty well to have a bit more of a flexible mindset.

630
01:14:38,323 --> 01:14:45,283
But you also will encounter people who are just like very strongly believing that like, you know, we should be completely a priority.

631
01:14:45,493 --> 01:14:51,053
There could be other people who are just much more like, let's just focus on what the moral fit is, because that's the most important thing.

632
01:14:51,073 --> 01:14:57,292
So there are people who are more at the extremes. That is all for today.

633
01:14:57,293 --> 01:15:04,073
Again, no homework for today, although there is a reading quiz for next time.

634
01:15:04,073 --> 01:15:07,253
So I will see you next week. If you have any questions, just come to me here.

635
01:15:07,893 --> 01:15:13,163
You could if you could bring your placards and your name cards and put them at the front table.

636
01:15:13,163 --> 01:15:14,003
That would be lovely.

