1
00:00:04,970 --> 00:00:17,300
How frequently are. I was over.

2
00:00:29,970 --> 00:00:33,210
Oh. Okay. Yeah.

3
00:00:54,860 --> 00:01:00,710
I thought of you. Good morning, everybody.

4
00:01:01,910 --> 00:01:07,630
Good morning. Thank you all for your patience.

5
00:01:08,230 --> 00:01:15,750
You see, you could probably tell the class before us had an exam this morning, so yay for exams.

6
00:01:21,220 --> 00:01:27,070
We've got a lot to cover today. It's loud, Slobogin. We have a lot to cover today.

7
00:01:27,070 --> 00:01:37,020
And. If you have a chance to look at the size of the slide deck, you know, we've got a lot of slides.

8
00:01:37,620 --> 00:01:41,040
So I'm just going to go ahead and jump in if.

9
00:01:45,620 --> 00:01:48,860
I'm going to do questions a little bit different just because of the size of the deck.

10
00:01:48,870 --> 00:01:59,359
So I will stop periodically and ask if you have questions rather than looking up at every slide and if we don't get through all of them.

11
00:01:59,360 --> 00:02:05,300
So please feel free to ask all your questions. But if we don't get through all of them, I will just carry over the rest.

12
00:02:05,570 --> 00:02:11,900
On Tuesday. But it is kind of a heavy content deck today.

13
00:02:13,700 --> 00:02:21,430
So let's get started. So announcements just again saying I changed the guidelines for draft number two.

14
00:02:21,680 --> 00:02:28,670
There are assignment number two. So if you haven't observed that, please take a look.

15
00:02:29,270 --> 00:02:34,070
It is labeled as version two or V two on the slide.

16
00:02:34,100 --> 00:02:42,380
I mean that the slides on canvas also we're in the process of doing the modifications on the quiz.

17
00:02:43,520 --> 00:02:48,200
I need to check in with Hannah to see if she's finished it,

18
00:02:49,730 --> 00:02:55,970
but just know that we're in the process of doing that for quiz one to remember the matching questions.

19
00:02:57,140 --> 00:03:04,520
I feel like somebody else reached out to me and said something to you about the question or needs assessment, but I can't find the email.

20
00:03:05,120 --> 00:03:20,160
What was it about the needs assessment question? Well, imagine if if you all could just email me because I can't find the email that said it, but.

21
00:03:22,170 --> 00:03:28,559
I thought it might have been something to do with the spelling the way the the because I had to put in all spellings.

22
00:03:28,560 --> 00:03:32,400
Misspellings. But. So I might have missed one.

23
00:03:34,050 --> 00:03:37,770
So, you know, just let me know within the next week.

24
00:03:38,040 --> 00:03:39,210
Thank you for affirming that.

25
00:03:40,320 --> 00:03:47,010
So let me know that next week so we can kind of catch make sure we do it manually, because that's a question we would not have grade it manually.

26
00:03:48,540 --> 00:03:51,870
But if somebody misspells it, then it won't catch it.

27
00:03:54,570 --> 00:04:01,890
All right. And review. And I mention for those who are just walking in.

28
00:04:02,460 --> 00:04:05,490
Lots of lots of content today.

29
00:04:05,500 --> 00:04:11,069
So if so, I'm just going to stop for questions periodically.

30
00:04:11,070 --> 00:04:14,490
And if we don't get through all of it, we'll carry on on Tuesday.

31
00:04:14,820 --> 00:04:17,850
But it is important content. So I want to make sure that you get it.

32
00:04:19,440 --> 00:04:22,350
So review process evaluations.

33
00:04:23,250 --> 00:04:34,290
We use these to monitor programs to describe and assess services, provide it so what we did and then to how satisfy stakeholders are,

34
00:04:34,560 --> 00:04:39,210
in essence, how do people feel about it, what we did, how people feel about it.

35
00:04:39,870 --> 00:04:45,510
And then there are some key concerns of process evaluations which include fidelity,

36
00:04:46,080 --> 00:04:53,910
those delivered, those received participant satisfaction, reach, recruitment and context.

37
00:04:54,420 --> 00:05:05,640
And these come from Sanders framework, which you can find the definitions and examples on the slide deck from Tuesday.

38
00:05:07,530 --> 00:05:10,320
So let's jump into outcome evaluations.

39
00:05:11,490 --> 00:05:22,020
So in contrast to process which focuses on what was done, I'll come evaluations are really about understanding.

40
00:05:22,050 --> 00:05:27,120
Was an intervention effective in producing intended changes in outcomes?

41
00:05:27,720 --> 00:05:33,570
And just because I haven't said that before for the purpose, including for the purposes of the recording,

42
00:05:34,440 --> 00:05:39,030
I will sometimes use intervention and program interchangeably.

43
00:05:39,180 --> 00:05:40,950
Just know we're talking about the same thing.

44
00:05:43,230 --> 00:05:51,270
Outcome evaluations are undertaken when it's important to know whether and how will the goals of an intervention were met.

45
00:05:52,400 --> 00:06:02,450
So think of process evaluation as focusing on the performance aspect of a program and outcome evaluations.

46
00:06:02,450 --> 00:06:11,150
Focus on effectiveness. This is the slide that I mentioned on Tuesday but didn't put in there.

47
00:06:11,660 --> 00:06:16,070
So in contrast to process, which is the do part.

48
00:06:17,940 --> 00:06:21,850
Of this. Of this logic model.

49
00:06:23,680 --> 00:06:27,590
Get. What do we get out of it?

50
00:06:27,620 --> 00:06:41,090
It's the focus of outcome. And the outcome evaluations, as you know, especially if you have your theory of change documented,

51
00:06:41,400 --> 00:06:45,720
they're really meant to confirm the theory of change embedded in the logic model.

52
00:06:46,380 --> 00:06:48,240
If we say we will do something,

53
00:06:49,230 --> 00:06:59,130
we should get something in particular and outcome evaluations in another way of thinking about it or about confirming that theory of change.

54
00:07:02,980 --> 00:07:06,700
We'll talk about four key concerns and outcome evaluations,

55
00:07:06,700 --> 00:07:14,980
and then we'll get into different designs that you can apply to be able to address these key concerns.

56
00:07:18,260 --> 00:07:28,010
So the first key concern that outcome evaluation could focus on is whether there were changes in the outcome after the intervention.

57
00:07:28,700 --> 00:07:34,550
And this is a general literally after the intervention.

58
00:07:35,840 --> 00:07:43,310
So some outcome evaluation questions we might ask associated with this type of concern,

59
00:07:44,180 --> 00:07:50,450
one that participants in the program report a change in knowledge or attitudes after the intervention.

60
00:07:51,770 --> 00:08:01,880
Or we can ask a question of the type that participants in the program report a change in behavior or skill level after the intervention.

61
00:08:03,160 --> 00:08:09,120
And now this with the bolts. The first question is referring to short term.

62
00:08:15,740 --> 00:08:19,460
Whereas the second one is referring to mid term.

63
00:08:20,900 --> 00:08:27,709
Notice that there is no long term outcomes in this concern because if you're measuring

64
00:08:27,710 --> 00:08:33,800
something that occurred after the intervention or very closely after the intervention,

65
00:08:33,830 --> 00:08:37,550
like, say, a month after the intervention ended.

66
00:08:38,790 --> 00:08:41,820
That's still not enough time to observe change in condition.

67
00:08:42,540 --> 00:08:51,780
So if you were trying to measure what happened immediately after the intervention ended, you would not be able to measure conditions.

68
00:08:53,100 --> 00:09:00,450
But thankfully, we can also ask outcome evaluation questions about things that are sustained over time.

69
00:09:01,830 --> 00:09:07,020
So, for example, we can ask a question of the type that approach.

70
00:09:08,300 --> 00:09:18,170
So that participants in the program still report a change in knowledge, attitudes or behavior six months after the intervention.

71
00:09:19,010 --> 00:09:22,520
And notice that this is a limp amount of time.

72
00:09:22,520 --> 00:09:25,850
So what we're thinking about is whether they are changing condition.

73
00:09:28,210 --> 00:09:31,720
Six months is not completely arbitrary. There's a lot of.

74
00:09:33,460 --> 00:09:37,570
You know, multiple health behavior theories that.

75
00:09:38,560 --> 00:09:42,790
Really measure at the three and a six and.

76
00:09:44,000 --> 00:09:54,650
Consider that part of the kind of conceptual nature of the theory that if you're maintaining behavior, you're maintaining for about six months.

77
00:09:56,220 --> 00:10:00,750
That lets us know that it's become part of your way of being, if you will.

78
00:10:02,390 --> 00:10:13,610
So another type of question under this concern, how many participants maintain their behavior change for at least 12 months after their intervention?

79
00:10:14,780 --> 00:10:19,790
So again, these two questions are really about changing conditions.

80
00:10:19,790 --> 00:10:30,890
So your long term outcomes. I was trying to think of something I wanted to say.

81
00:10:31,640 --> 00:10:38,120
Oh. So one thing just thinking, you know, especially in terms of your evaluation plan,

82
00:10:39,500 --> 00:10:45,080
if you're going to ask a question about something being sustained over time,

83
00:10:45,800 --> 00:10:58,220
that means that not only do you need to have a timeframe with it, but you should also account for that in the design, the design part of the plan.

84
00:10:58,700 --> 00:11:03,140
So this is just, you know, something, again, that Hannah and I will be looking for.

85
00:11:03,500 --> 00:11:07,639
If you say you're going to measure, if you're looking for change over six months,

86
00:11:07,640 --> 00:11:12,020
we would expect that you would do some sort of data collection at six months.

87
00:11:13,880 --> 00:11:17,260
And I'm not saying that because I don't think you're capable of realizing that.

88
00:11:17,270 --> 00:11:20,180
It's it's it's amazing how.

89
00:11:21,320 --> 00:11:30,320
Much you don't realize you have an accountant for until you really start to look at everything as kind of a chain of processes.

90
00:11:31,580 --> 00:11:34,880
So that's how we will look at the way you write the plan.

91
00:11:35,270 --> 00:11:38,690
If you say at the beginning, we're going to look for a sign of it and.

92
00:11:41,910 --> 00:11:47,640
Third concern is whether you see change in an outcome differing across groups.

93
00:11:48,610 --> 00:11:54,820
And these groups can be between participants and non-participants in the program,

94
00:11:55,630 --> 00:12:01,570
but they could also be for subgroups within the populate within your program participants.

95
00:12:03,030 --> 00:12:06,180
And you can see questions of those type here.

96
00:12:06,900 --> 00:12:14,610
The participants in the program report a greater change in knowledge, attitudes or behavior compared to non-participants.

97
00:12:15,490 --> 00:12:21,730
So again, notice that not only does the question point out that it's compared to non participants,

98
00:12:22,210 --> 00:12:25,630
but it's also giving you the direction of change with greater.

99
00:12:28,240 --> 00:12:34,510
So we you know, in this case, we want to know, did the intervention actually have an effect in creating change?

100
00:12:37,900 --> 00:12:46,060
Among participants. Another type was the program more successful so certain for certain groups of people than for others?

101
00:12:50,490 --> 00:12:54,180
So this second question, like I mentioned, refers to.

102
00:12:56,530 --> 00:13:05,980
The sample is entirely from an analytical perspective of participants, but what we're doing is dividing into subgroups.

103
00:13:06,700 --> 00:13:10,960
This is pretty common. We might do subgroups by age.

104
00:13:11,290 --> 00:13:18,370
Say we're implementing something for youth. We might do subgroups that are by race and ethnicity.

105
00:13:18,760 --> 00:13:21,940
We might do subgroups by gender identity.

106
00:13:23,950 --> 00:13:37,870
And so part of asking that question is making sure that you sample so that you can anticipate being able to do such an analysis on even if that means,

107
00:13:37,870 --> 00:13:41,560
for example, like what I'm doing now, we're sampling,

108
00:13:42,010 --> 00:13:48,580
trying to make sure we have for one of my projects people in different fields related to health care.

109
00:13:49,240 --> 00:13:53,790
So we're going to make sure that we have so we're watching as we recruit.

110
00:13:53,800 --> 00:13:58,960
We're watching the sampling to make sure that we have people in all three of those groups

111
00:13:59,530 --> 00:14:07,030
to a number that is sufficient for us to be able to do a proper comparative analysis.

112
00:14:11,270 --> 00:14:17,680
You're. And then finally, the fourth concern that we generally will look at with outcome evaluations,

113
00:14:18,070 --> 00:14:21,550
whether changes in outcome were caused by the intervention.

114
00:14:22,330 --> 00:14:30,340
So, you know, amusingly enough, this is the first time we actually have asked this question in all four of these concerns.

115
00:14:30,970 --> 00:14:34,780
And so what that tell should tell you is that for the first three questions.

116
00:14:37,670 --> 00:14:44,000
We don't necessarily know if we answer them if that means that the intervention actually caused the change.

117
00:14:44,840 --> 00:14:50,330
When we get into the actual research designs, you'll see why and you'll see that.

118
00:14:51,910 --> 00:14:57,940
Different designs are more properly suited for answering different kinds of questions.

119
00:14:59,260 --> 00:15:09,700
But in this case, a question bless you that we might ask did the intervention as a whole saw the entire program from start to finish?

120
00:15:09,700 --> 00:15:17,200
All components, the back calls to observe changes in knowledge, attitudes, or behavior among participants.

121
00:15:18,510 --> 00:15:22,080
But we can also look at specific intervention activities.

122
00:15:22,860 --> 00:15:28,080
For example, if we have classroom learning, we have a workbook.

123
00:15:29,100 --> 00:15:33,090
We might want to know, is the workbook a value add?

124
00:15:33,450 --> 00:15:40,230
Or is the classroom a value add? So we would look and analytically to understand,

125
00:15:41,070 --> 00:15:48,060
did specific intervention activities cause a change in knowledge, attitudes or behavior among participants?

126
00:15:50,800 --> 00:15:56,230
So I want to stop there before we get into the next section, see if anybody has any questions.

127
00:16:01,110 --> 00:16:05,870
All right. So how do we answer these questions?

128
00:16:05,870 --> 00:16:11,779
I just presented with at least eight questions, eight types of the valuation questions.

129
00:16:11,780 --> 00:16:16,840
How do we answer them? Well, we have research designs.

130
00:16:18,590 --> 00:16:23,200
Let's start by. And again, this is going to be a lot.

131
00:16:23,340 --> 00:16:29,799
I'm I was putting this together and I'm like, oh, this is a lot. But I will keep referring back to it.

132
00:16:29,800 --> 00:16:35,230
So don't don't worry. In terms of like future lectures, we'll keep reiterating all of this.

133
00:16:37,110 --> 00:16:43,020
But to understand research design, we first have to start at two types of research design.

134
00:16:45,340 --> 00:16:48,520
Descriptive research and experimental research.

135
00:16:49,450 --> 00:16:57,430
So with descriptive research, which will also can also be known as pre experimental.

136
00:17:03,480 --> 00:17:06,720
The goal is to describe, right?

137
00:17:07,980 --> 00:17:16,410
So process evaluations are, for the most part, descriptive research designs.

138
00:17:17,700 --> 00:17:24,390
So you might want to know the program staff feel confident in their ability to implement the activities as planned.

139
00:17:25,940 --> 00:17:28,639
With with descriptive design,

140
00:17:28,640 --> 00:17:38,960
we don't manipulate the variables of interest and the manipulation happens with the way that we sample in the arm or with the way that we sample,

141
00:17:40,670 --> 00:17:45,500
as well as the intervention itself being a sort of manipulation.

142
00:17:47,680 --> 00:17:51,790
With the script. We're not really trying to infer causality.

143
00:17:52,120 --> 00:18:01,600
We're not trying to identify did something make our staff feel confident in their ability to implement the activities as planned?

144
00:18:03,110 --> 00:18:07,790
That doesn't preclude us from asking why staff didn't feel confident.

145
00:18:08,920 --> 00:18:16,550
It simply means that. We're not the point of this study is not to find out, did staff fail?

146
00:18:16,790 --> 00:18:24,130
Why did staff not feel confident? Because what they're doing is part of the activities.

147
00:18:24,140 --> 00:18:29,270
They're simply delivering a service to delivering program activities.

148
00:18:29,540 --> 00:18:34,220
It really not the interest in terms of understanding.

149
00:18:34,670 --> 00:18:39,230
Did a cause be? So the question.

150
00:18:39,250 --> 00:18:44,380
A question like did program staff feel confident? Why or why not?

151
00:18:44,710 --> 00:18:52,990
Is really simply about program improvement. And so you might often use this for process evaluation.

152
00:18:54,650 --> 00:19:01,430
In contrast, experimental research is about testing a cause and effect relationship.

153
00:19:04,240 --> 00:19:15,440
Okay. So these are the question. These are the these are the types of research design that kind of sit at the heart of outcome evaluation.

154
00:19:16,420 --> 00:19:25,960
We want to know, did our program or did the policy if you're doing policy evaluation, did that cause the expected outcomes?

155
00:19:27,420 --> 00:19:32,130
And so there is an intentional manipulation of the independent variable.

156
00:19:33,780 --> 00:19:38,390
So. Program activities, we might.

157
00:19:38,410 --> 00:19:43,240
We will implement an intervention. That is the manipulation that we're talking about.

158
00:19:45,400 --> 00:19:48,550
And really it's about inferring causality.

159
00:19:49,030 --> 00:20:00,330
We want to know. What would happen if there if there was no intervention with that relationship between to time points look like.

160
00:20:00,900 --> 00:20:06,700
So say I'm delivering an intervention. At Point A.

161
00:20:10,650 --> 00:20:13,680
And then I want to know, did it?

162
00:20:15,180 --> 00:20:21,590
Do we see a difference at point B? So I want to know.

163
00:20:23,810 --> 00:20:31,360
If I'm in the intervention. Was there a change?

164
00:20:32,560 --> 00:20:39,380
Oh, I raced it. That's my shorthand for intervention.

165
00:20:44,140 --> 00:20:47,320
I want to know, is there a difference between.

166
00:20:49,030 --> 00:20:56,890
Those who participated in the intervention or who were intervened upon versus those who did not receive that.

167
00:20:58,520 --> 00:21:02,760
Again. I'm trying to understand causality. Real reason.

168
00:21:03,140 --> 00:21:06,830
Oh. Oh, oh, yeah. I wonder if I can.

169
00:21:07,070 --> 00:21:12,170
Yeah. I know I can't pull it down like this, can I?

170
00:21:12,950 --> 00:21:19,070
No. Is it over there? Let's find out.

171
00:21:19,520 --> 00:21:25,210
No, no, no. I will just it basically is.

172
00:21:26,340 --> 00:21:31,240
On a. Point B? A and B.

173
00:21:34,290 --> 00:21:44,380
And now I'll fix it too. With. Come on.

174
00:21:45,610 --> 00:21:49,000
I will fix it when I close that down.

175
00:21:49,030 --> 00:21:53,170
Is that okay? Now try it. I'm not going to do a lot of writing, by the way, so.

176
00:21:53,530 --> 00:21:58,690
But that's kind of what I wrote on the bottom. Thank you for pointing that out.

177
00:22:01,880 --> 00:22:06,230
So what I did just explain, though, this I this right here on the side.

178
00:22:08,410 --> 00:22:13,800
Is. An intervention in its counterfactual.

179
00:22:14,760 --> 00:22:22,410
So when we're trying to assess causality, what we really need to know is what is the counterfactual?

180
00:22:24,180 --> 00:22:30,060
And that counterfactual, the basic question is what would happen to an individual?

181
00:22:30,360 --> 00:22:33,450
Have they not received this intervention? Right.

182
00:22:33,900 --> 00:22:42,030
So if they were not participating and so they are in a safer sex intervention and.

183
00:22:43,600 --> 00:22:48,160
They learn how to put on a condom without breaking it.

184
00:22:49,620 --> 00:22:55,450
What if they hadn't been in this intervention? What they have just learned that through the course of their natural life.

185
00:22:55,950 --> 00:23:01,740
Because that's going to tell us. Is the intervention actually effective in eliciting change?

186
00:23:02,770 --> 00:23:10,180
But obviously we can't observe a counterfactual with a program participant because they're a program participant.

187
00:23:10,690 --> 00:23:15,860
You can't take back what they've learned. So research,

188
00:23:16,250 --> 00:23:25,220
experimental research designs are really about how well can we create or recreate

189
00:23:25,460 --> 00:23:34,250
a counterfactual within a sample and within the context of this evaluation study.

190
00:23:35,240 --> 00:23:45,830
And so these principles apply whether, again, if we're doing a program evaluation or doing some experimental work in the lab, we are.

191
00:23:47,890 --> 00:23:50,710
You know, doing social science research, etcetera, etcetera.

192
00:23:53,730 --> 00:24:05,310
So there's three types of experimental research design that we might apply to be able to answer these outcome evaluation questions.

193
00:24:06,180 --> 00:24:10,810
And be able to. As much as possible.

194
00:24:11,590 --> 00:24:28,400
Create a counterfactual. So there are three types and I mentioned that sometimes pre experimental and descriptive are used interchangeably.

195
00:24:28,940 --> 00:24:37,040
They're not completely the same, but. It, people generally will kind of switch them back and forth.

196
00:24:37,370 --> 00:24:41,040
So. You know, it's helpful to know.

197
00:24:41,640 --> 00:24:48,750
So pre there's pre experimental, quasi experimental and true experimental.

198
00:24:49,770 --> 00:25:00,370
Or just experimental? And if you look at them on a continuum of rigor, your premium,

199
00:25:00,640 --> 00:25:09,070
your pre experimental designs are going to be the least rigorous in your true experimental designs are going to be the most.

200
00:25:10,790 --> 00:25:15,440
And rigor. What we're talking about is quality.

201
00:25:19,760 --> 00:25:24,460
Of being. Exhaustive.

202
00:25:29,900 --> 00:25:39,180
Or accurate. And that is exhaustive or accurate with respect.

203
00:25:40,170 --> 00:25:41,400
To the counterfactual.

204
00:25:43,400 --> 00:25:53,180
So our true experimental designs are going to be the best to be able to set up accurate the most accurate counterfactual that we possibly can.

205
00:25:53,540 --> 00:25:56,480
And your pre experiment tools are going to be the least accurate.

206
00:25:59,920 --> 00:26:05,590
So before we get kind of into the different designs that we're going to talk about in the context of this class.

207
00:26:09,230 --> 00:26:15,980
There's some design notation. So generally research design has notation associated with it.

208
00:26:18,080 --> 00:26:23,750
So you'll see an X that refers to the intervention, whether it's a program or a policy.

209
00:26:24,950 --> 00:26:33,890
Oh. And with its subscript r refer to observations of variables the intervention is trying to influence.

210
00:26:36,310 --> 00:26:42,850
So again, it could be condom use, it could be eating vegetables, etc.

211
00:26:44,160 --> 00:26:51,900
Ah. If you see that that refers to random assignment, that means that people were randomly assigned to groups.

212
00:26:52,500 --> 00:26:56,810
And then if you see in our. It's not a random assignment.

213
00:26:57,050 --> 00:27:00,080
That means that people were placed in groups, but it wasn't random.

214
00:27:01,110 --> 00:27:05,970
And the goal is really to identify the relationship between X and O.

215
00:27:06,840 --> 00:27:15,490
How does X influence O? So any questions?

216
00:27:20,380 --> 00:27:27,360
Well, right. So our true experimental designs, those are often referred to as the gold standard.

217
00:27:27,390 --> 00:27:31,650
You probably heard that 50 million times. Gold standard research.

218
00:27:32,040 --> 00:27:37,860
This is the gold standard, etc. And that's because they provide the strongest evidence of causality.

219
00:27:38,130 --> 00:27:47,790
Because with those designs, we're able to see the counterfactual, the best the best creation of a counterfactual compare to the intervention group.

220
00:27:49,470 --> 00:27:56,860
Part of that. Accurate creation of the counterfactual has to do with random assignment.

221
00:27:57,370 --> 00:28:03,370
So we randomly assigned participants to either an intervention group or a control group.

222
00:28:04,380 --> 00:28:10,710
Or are there people who've ever participated in a study like me just to make some extra money?

223
00:28:11,970 --> 00:28:15,720
Okay. I wouldn't say got rich. Okay. I don't have to participate in studies.

224
00:28:17,320 --> 00:28:23,620
I drank cranberry juice for 54 for three months straight, trying to make 80 bucks.

225
00:28:27,220 --> 00:28:32,240
But but in that that cranberry juice study I participated in,

226
00:28:32,290 --> 00:28:37,119
I don't know if it was cranberry juice or just some fake cranberry juice because

227
00:28:37,120 --> 00:28:44,890
I was assigned to either a real a real intervention group or a control group.

228
00:28:45,460 --> 00:28:48,930
They were trying to understand you. I'm like. I like cranberry juice.

229
00:28:48,940 --> 00:28:56,950
Okay, I'll sign up. But now they said that random assignment is blind.

230
00:28:57,250 --> 00:29:03,149
It's blind to the participants. With program evaluation.

231
00:29:03,150 --> 00:29:08,450
It is not blind. Because somebody obviously knows.

232
00:29:08,840 --> 00:29:15,560
They may not know that there's another another intervention going on, but they already know that they're not receiving something.

233
00:29:16,640 --> 00:29:26,450
Or they might be receiving something else. So it's not blind in the same way that I was drinking cranberry juice or something like that.

234
00:29:29,490 --> 00:29:31,160
And that random assignment.

235
00:29:31,170 --> 00:29:39,750
The benefit of it is that helps to ensure that any differences between the intervention and the control group are likely due to chance.

236
00:29:41,180 --> 00:29:51,690
Which is important analytically. So, you know, again, just reiterating randomization.

237
00:29:51,700 --> 00:29:57,759
What it does is it ensures that each individual has an equal probability of assignment to either an

238
00:29:57,760 --> 00:30:03,730
intervention group or they have an equal probability of being assigned to the intervention group,

239
00:30:04,630 --> 00:30:08,950
which really gives us the best opportunity to test that counterfactual.

240
00:30:10,650 --> 00:30:13,860
It also gives us an equivalent control group.

241
00:30:14,400 --> 00:30:19,590
And the idea is that if the group the control group was assigned at random,

242
00:30:20,250 --> 00:30:26,400
it is going to account for or control for almost all other possible explanations,

243
00:30:27,600 --> 00:30:31,950
thereby ensuring that outcome effects can be attributed to the intervention.

244
00:30:32,900 --> 00:30:36,410
So in other words, if intervention group is random.

245
00:30:37,870 --> 00:30:49,570
And control group is random. Chances are variables that would be confounding or might otherwise influence the outcome.

246
00:30:50,590 --> 00:30:54,460
Have already been accounted for with the balance of the two groups.

247
00:30:57,140 --> 00:31:02,870
So they as much as possible. They look to say. So when do we use these?

248
00:31:03,890 --> 00:31:10,530
I'm going to tell you in the program evaluation, at least in program evaluation with organizations.

249
00:31:10,910 --> 00:31:20,300
Hardly ever. But because they are, as you might guess, expensive, but you should use them whenever possible.

250
00:31:20,640 --> 00:31:26,810
There's a way to make something be experimental in line with, again,

251
00:31:26,810 --> 00:31:34,640
those values that we've talked about in evaluation, such as feasibility of impropriety, you know, ethics.

252
00:31:35,930 --> 00:31:39,920
If you can account for those use, use an experimental design.

253
00:31:42,050 --> 00:31:46,070
So you have to have the funding and other resources available.

254
00:31:46,190 --> 00:31:50,660
You have to have time to set up the random assignment and recruit for random assignment.

255
00:31:51,260 --> 00:31:59,210
You have to have the funding to. You know, account for all the participants you have.

256
00:31:59,240 --> 00:32:03,260
So things like incentives, staffing, etc.

257
00:32:04,810 --> 00:32:09,640
You also have to be you also have to have the ability to randomize the participants.

258
00:32:10,120 --> 00:32:13,989
And so you can see how they might be problematic with program evaluation.

259
00:32:13,990 --> 00:32:20,500
Because what you're essentially saying is some of these people are not getting this this

260
00:32:20,500 --> 00:32:26,260
intervention that we think will help change something in their lives and help them be healthier.

261
00:32:26,980 --> 00:32:30,820
So that's a little bit of an ethical dilemma for a lot of organizations.

262
00:32:33,800 --> 00:32:39,410
No. We don't want to deny people who are in need of service. Also,

263
00:32:39,410 --> 00:32:46,190
there needs to be close supervision and project management because there's all kinds of ways that someone could

264
00:32:46,190 --> 00:32:53,570
figure out that they are now part of a control group or an intervention group and let somebody else know.

265
00:32:55,820 --> 00:33:01,490
For example, when they were testing the COVID vaccines, I had a friend who was given the shot.

266
00:33:01,610 --> 00:33:09,530
He was either in the intervention or the control, but he could have had somebody he could have a friend who works at the hospital.

267
00:33:10,670 --> 00:33:18,590
You live here, by the way? And the friend of said, Oh, I saw your name on the list of people who are participating in this study that's in the you're

268
00:33:18,830 --> 00:33:26,240
you got a real Kovic shot and that just you know that that that compromises the study so

269
00:33:26,360 --> 00:33:32,299
and it's to be close supervision and project management to ensure that the ran or it could

270
00:33:32,300 --> 00:33:37,130
be people like oh I'll tell you go in that group because you you don't get the real shot.

271
00:33:37,580 --> 00:33:41,300
So there's all kinds of ways that you can compromise an experimental design.

272
00:33:42,590 --> 00:33:51,020
So close supervision is needed. Three types of experimental design that we'll talk about in this class.

273
00:33:52,370 --> 00:34:02,760
Post Post-test Control Group Design. Post-test only control group design and cluster randomized controlled trial.

274
00:34:07,970 --> 00:34:11,720
Randomized controlled trial, also known as a RTC.

275
00:34:15,880 --> 00:34:24,430
So your p0pp value pretest post test control group design and now the notation.

276
00:34:24,700 --> 00:34:33,279
So you see the R that means that there was random assignment and then you see the old that's the observation time observation

277
00:34:33,280 --> 00:34:41,920
one observation two for the intervention group and then observation three observation for for the control group.

278
00:34:42,770 --> 00:34:49,850
And what this does is that it determines the effect of intervention by calculating the gains scores for each group.

279
00:34:50,420 --> 00:35:01,610
So that from a statistical perspective, what I'm trying to find out is what is observation to score minus observation one,

280
00:35:02,630 --> 00:35:08,300
and then what's observation four's score minus observation three.

281
00:35:09,110 --> 00:35:16,190
And then I want to know the difference if the difference between those scores is statistically significant.

282
00:35:19,290 --> 00:35:23,600
And that is not a matter of just looking at the numbers. It's the.

283
00:35:25,040 --> 00:35:30,080
You know, statistical tests that you need to be able to say it's actually statistically significant.

284
00:35:31,770 --> 00:35:39,520
So here's another representation of that. The outcome is on your.

285
00:35:40,650 --> 00:35:47,410
Why access. And then your intervention time is on an X.

286
00:35:48,910 --> 00:35:53,410
So and then the X you can see here, that's when the intervention takes place.

287
00:35:54,460 --> 00:36:01,270
So pre intervention. One observation for both the expect or the intervention and the control.

288
00:36:01,870 --> 00:36:12,090
And then after the intervention. One observation for the intervention and one observation for the control.

289
00:36:19,170 --> 00:36:23,850
Oh, one thing also just to mention is that. I dearly.

290
00:36:25,240 --> 00:36:28,990
Observation one and three should be the same.

291
00:36:35,310 --> 00:36:41,150
If they are different, statistically speaking, then that is a problem.

292
00:36:42,140 --> 00:36:46,610
Because that means that there is a variable at work that you have not accounted for.

293
00:36:51,130 --> 00:36:55,210
But we won't. You won't really need to get into that for the class.

294
00:36:58,180 --> 00:37:03,670
Next one, pulse test. Only control group design and see the notation.

295
00:37:04,000 --> 00:37:09,340
What that's saying is that there was no observation before the intervention took place.

296
00:37:12,630 --> 00:37:19,150
Oh. I got a typo. Okay.

297
00:37:19,510 --> 00:37:27,790
So there's no pretest for this design. So we don't know. What we don't know is, is there a difference between the two groups before the intervention?

298
00:37:28,630 --> 00:37:33,130
We're only going to know. Is there a difference between the groups after the intervention?

299
00:37:35,230 --> 00:37:42,250
So you really, really if if you want this type of design and you want it to.

300
00:37:45,270 --> 00:37:52,620
If you really want to use this design and you want it to remain experimental, you really need to be relying on your randomization.

301
00:37:54,540 --> 00:38:01,080
And so again, that's what you specially need to be careful for any compromises in the randomization process.

302
00:38:01,920 --> 00:38:05,610
So these are useful for evaluating outcomes instead of change.

303
00:38:06,000 --> 00:38:11,430
Maybe we just want to see is there a difference between the two groups after the intervention?

304
00:38:12,060 --> 00:38:14,400
And we just want to see is there a difference in outcome?

305
00:38:17,800 --> 00:38:25,050
And as you can see that this is what it would look like if we are comparing the outcome against time.

306
00:38:30,650 --> 00:38:39,620
Now, not all interventions in public health take place specifically just what individuals.

307
00:38:39,800 --> 00:38:42,890
Right. So many public health interventions that we do.

308
00:38:43,290 --> 00:38:51,710
Target populations. So for example, we might be targeting a school or we might be targeting a work site.

309
00:38:52,310 --> 00:38:58,310
We might be targeting a place of worship or geographically designed communities.

310
00:38:59,740 --> 00:39:07,390
We're still trying to work at the individual level, but we're trying to elicit change in a place.

311
00:39:08,450 --> 00:39:14,520
Or a setting. So if we're doing something that's like that.

312
00:39:16,370 --> 00:39:22,250
Like I'm working with, you know, Ann Arbor Public Schools, how can I really randomize groups?

313
00:39:25,410 --> 00:39:30,300
So that's where you might bring in cluster randomized controlled trials.

314
00:39:34,540 --> 00:39:42,430
And so with these. Rather than randomizing at the level of person we randomize at the level of the group.

315
00:39:43,740 --> 00:39:48,150
So we would randomize a school to either the control or the intervention.

316
00:39:51,780 --> 00:39:58,800
And then that intervention is delivered to all populations in their intervention group at approximately the same time.

317
00:39:59,550 --> 00:40:07,709
Again, because what we're trying to make sure is that we're controlling for any kind of bias,

318
00:40:07,710 --> 00:40:16,170
any kind of exposure to the intervention that would compromise the counterfactual or the control group.

319
00:40:16,770 --> 00:40:19,680
So we have to do the intervention at the same time.

320
00:40:20,340 --> 00:40:29,520
So if you're going to use this design, you need to be able to have the funds to be able to implement a program at the same time.

321
00:40:33,260 --> 00:40:38,360
And that's just something that you will also need to consider if you're going to use this.

322
00:40:39,970 --> 00:40:44,080
So I thought. So any questions about the experimental designs?

323
00:40:52,640 --> 00:40:55,840
Am I going fast? I'm. Yes.

324
00:40:55,840 --> 00:40:59,530
Do I get out of here early? I don't know. Do I think it's go.

325
00:40:59,810 --> 00:41:07,210
Okay. So those were the most rigorous, those true experimental designs.

326
00:41:07,690 --> 00:41:16,280
The next step down. Is a quasi experimental design sop.

327
00:41:16,280 --> 00:41:21,740
And what this basically means is that is almost true, but it's not.

328
00:41:24,960 --> 00:41:30,090
So some will use a comparison group to determine the effects of the intervention.

329
00:41:30,600 --> 00:41:35,730
But your participants are not randomly assigned to either the intervention or comparison group.

330
00:41:36,210 --> 00:41:42,510
So note the change in language rather than calling it a control group or calling it a comparison group.

331
00:41:43,390 --> 00:41:54,340
Because we might say, for example, okay, I would like a school that is similar to the demographics of the intervention school.

332
00:41:55,760 --> 00:42:00,590
You know, say that, you know, it's a big school. It's located in the urban area.

333
00:42:01,340 --> 00:42:04,460
It's predominantly Hispanic.

334
00:42:05,870 --> 00:42:14,120
Then what I'm going to do is try to find a comparison school that is pretty big in a urban area, predominantly Hispanic.

335
00:42:14,930 --> 00:42:23,420
And the way that I pick those characteristics is really based on variables that I think will influence the outcome.

336
00:42:24,440 --> 00:42:28,130
So say, you know, in this case of what I just described,

337
00:42:28,910 --> 00:42:40,160
maybe I have a culturally a culturally appropriate or, you know, why can I think of the word culturally?

338
00:42:40,430 --> 00:42:43,700
Now, it's not competent, but culturally tailored there.

339
00:42:43,700 --> 00:42:46,730
Let's go with that today. Culturally tailor intervention.

340
00:42:47,830 --> 00:42:53,470
For those who identify as Latino or Hispanic.

341
00:42:56,600 --> 00:43:01,970
So what you have to be able to do is compare how similar the two groups are at baseline.

342
00:43:02,000 --> 00:43:05,630
If you have the intervention in that comparison group,

343
00:43:06,410 --> 00:43:13,790
because it's important that we understand how similar or how different are they in terms of or with respect to the outcome.

344
00:43:14,990 --> 00:43:22,040
There are some quasi experimental designs that also just use multiple observations instead of comparison groups.

345
00:43:22,730 --> 00:43:34,400
So I'm going to give you two examples of those. So when we use a quasi experimental, perhaps randomization is not feasible.

346
00:43:35,450 --> 00:43:45,080
You know, we already talked about logistical or financial constraints, and we also talked about ethical and political or legal constraints.

347
00:43:46,320 --> 00:43:51,630
You know, there's a reason that we can't apply an experimental group.

348
00:43:52,650 --> 00:43:55,770
Maybe there is no viable control group available.

349
00:43:56,610 --> 00:44:07,560
Maybe the characteristics of the intervention group are so specific that we really just can't find a good counterfactual.

350
00:44:08,250 --> 00:44:11,340
That would be completely random.

351
00:44:13,060 --> 00:44:23,120
Or maybe we just don't have access to people. You know, for example, if it's a neighborhood, we're not going to be able to find a neighborhood that's,

352
00:44:23,660 --> 00:44:27,590
you know, exactly like another neighborhood, like this intervention neighborhood.

353
00:44:29,780 --> 00:44:37,280
We might also use quasi experimental design if we have something that started off as an artsy.

354
00:44:37,850 --> 00:44:41,210
But then something happens during implementation.

355
00:44:41,570 --> 00:44:55,129
So again, I mentioned, you know, the idea of somebody compromising the intervention and the control randomization or maybe what you

356
00:44:55,130 --> 00:45:01,220
might see in a program environment is that you've set up an intervention group and a control group,

357
00:45:01,790 --> 00:45:08,540
but then an implementation staff have allowed people who are in the control group to attend,

358
00:45:09,140 --> 00:45:19,160
or maybe the intervention participants have started sharing intervention materials with the comparison group or the control group.

359
00:45:20,210 --> 00:45:31,680
So. If you find in supervision that something is happening, you can transition a true experimental to a quasi experimental.

360
00:45:32,960 --> 00:45:37,700
So all is not lost if everything. Hits the fan.

361
00:45:39,510 --> 00:45:50,190
So the types of cause that we'll talk about today, pretest post test non equivalent comparison group and a time series design.

362
00:45:53,340 --> 00:45:59,100
So here's a notation for the pretest post-test non equivalent comparison group design.

363
00:46:00,520 --> 00:46:06,730
And generally this is probably the most common design that I use.

364
00:46:07,180 --> 00:46:10,480
If I'm not using a pre experimental.

365
00:46:13,320 --> 00:46:17,940
And you can see in the notation it looks similar to the control group design one.

366
00:46:18,300 --> 00:46:23,460
But the difference is that it has inner. So that just refers to the fact that there's no randomization.

367
00:46:25,530 --> 00:46:37,470
So you do get your baseline data to be able to assess whether or not groups are the same at observation one or observation three.

368
00:46:39,750 --> 00:46:46,450
So you can see right here again. We want them to be the same.

369
00:47:01,890 --> 00:47:24,570
Yes. Quickly. Well, if if if it is one, you know, a project where they could do that.

370
00:47:33,110 --> 00:47:34,520
Yeah. So that introduced. Yeah.

371
00:47:34,530 --> 00:47:43,340
So the question was like if you're trying to, you know, find out that your control group actually but then you but you have to ask everybody.

372
00:47:44,470 --> 00:47:47,680
Because otherwise you just compromised the study.

373
00:47:47,890 --> 00:47:51,969
So that's why it's expensive, because you need staff to do all that question asking.

374
00:47:51,970 --> 00:47:55,900
They need to follow up. They need to observe.

375
00:47:56,290 --> 00:48:01,420
Yeah. So that that that's part of what makes them expensive. If you don't have to do that with a, with a comparison group.

376
00:48:05,390 --> 00:48:14,400
Because they're a comparison group. And it's again, not you're not expecting the same level of rigor.

377
00:48:20,810 --> 00:48:29,180
So the other design that we will talk about for the class that is quasi experimental are time series analysis.

378
00:48:30,230 --> 00:48:34,820
And that is when we talked about if you don't have a comparison group.

379
00:48:35,860 --> 00:48:36,820
But you do.

380
00:48:37,540 --> 00:48:48,790
If you don't have a comparison group but you want a quasi experimental a time series, design is a good design to use because it does not require it.

381
00:48:49,780 --> 00:48:55,480
So you might see these referred to as Natural Experiments Interrupted Time series.

382
00:48:57,430 --> 00:49:08,230
And what you're really looking for is some kind of interruption at a trend on a trend line at the same time as an intervention went into effect.

383
00:49:09,960 --> 00:49:18,410
So here's an example. It's why we do a Why Time series is helpful.

384
00:49:20,540 --> 00:49:25,440
So I might look just at the I might just look at the orange line.

385
00:49:25,460 --> 00:49:31,850
So I take two observations. I take observation one here and I take observe.

386
00:49:33,000 --> 00:49:38,860
And I take observation to here if I just look at those two observations.

387
00:49:38,880 --> 00:49:46,750
Well, I'm thinking, oh, man, the intervention really worked like because all I know is time one and time two.

388
00:49:47,430 --> 00:49:50,880
I don't see the dip at that. I don't see this dip.

389
00:49:51,150 --> 00:49:56,460
And I definitely don't see what happened beforehand and what happened after.

390
00:49:58,630 --> 00:50:02,950
Or say so it could just be noise. It could just be random change.

391
00:50:06,780 --> 00:50:13,360
Or it could be a trend. So again, I take a measurement.

392
00:50:15,520 --> 00:50:18,880
At time at one right before the intervention.

393
00:50:19,360 --> 00:50:23,370
And I take it again. An observation to.

394
00:50:25,570 --> 00:50:28,750
And I'm like, great. There was a change between one and two.

395
00:50:30,150 --> 00:50:35,970
But it could be a trend that was already starting before I started the intervention.

396
00:50:37,940 --> 00:50:50,600
So what time series does is that allows me to capture more of what happened before the intervention and more of what happened after the intervention.

397
00:50:51,260 --> 00:50:55,730
So requires multiple observations before and after intervention.

398
00:50:57,420 --> 00:51:02,430
But now, again, look at the male patient. There's only one line, so I don't need that comparison group.

399
00:51:04,890 --> 00:51:10,200
And I don't have to have the same number of observation at pre and post intervention.

400
00:51:10,530 --> 00:51:17,940
So I could just have to two on one side, four on the other, four on one side, two on the other.

401
00:51:18,480 --> 00:51:21,600
So this can be a useful design.

402
00:51:22,200 --> 00:51:25,830
And even as I'm talking through it, I'm like, I should probably use this one more actually.

403
00:51:28,350 --> 00:51:34,079
Yeah. Because say you're working with a social service agency that takes a lot of intakes.

404
00:51:34,080 --> 00:51:37,980
If you've ever worked a social service agency, there's always some intake.

405
00:51:39,040 --> 00:51:46,760
And. When I'm working with those clients, I often try to capitalize on what they're already measuring.

406
00:51:47,940 --> 00:51:52,079
So oftentimes I will bring I will find, like I say,

407
00:51:52,080 --> 00:52:02,370
they're using some scales that they found from the youth behavior risk the youth risk behavior survey from the CDC.

408
00:52:03,350 --> 00:52:07,990
Which is common. You know, love it. Social service agencies will do well.

409
00:52:08,120 --> 00:52:14,390
Draw scales from instruments they're already going to have to report to some fund or another.

410
00:52:16,270 --> 00:52:21,340
So I could just simply capitalize on that by.

411
00:52:22,340 --> 00:52:31,040
Asking them to more repeatedly give that the surveys as part of that that are already

412
00:52:31,040 --> 00:52:37,280
in the intake so they already have intervention one in or intervention sorry.

413
00:52:37,640 --> 00:52:41,780
Observation one. They might even have observation, too.

414
00:52:42,560 --> 00:52:51,230
So as an evaluator, all I have to do is do a third and the fourth observation before the intervention takes place.

415
00:52:52,890 --> 00:53:02,020
Then. I'm breaking the pan and then I just have to do some other observations.

416
00:53:02,800 --> 00:53:06,760
And they may already be doing their own like exit survey.

417
00:53:07,680 --> 00:53:17,249
So this is why it's also important when you're working as an evaluator, get to know how your client, how their organization are.

418
00:53:17,250 --> 00:53:23,940
They collect data because that may inform how you design in a way that is saving

419
00:53:23,940 --> 00:53:29,220
money and capitalizes on what the organization already has capacity to do.

420
00:53:35,860 --> 00:53:47,680
So any questions about Kwanzaa? How would you?

421
00:54:01,760 --> 00:54:04,940
You know what? You. Yeah.

422
00:54:05,240 --> 00:54:08,390
So the question is, what about survey fatigue? People hate doing.

423
00:54:08,750 --> 00:54:10,970
People hate doing surveys over and over again.

424
00:54:11,880 --> 00:54:20,160
I mean, you're definitely going to get what we call attrition, where the number of participants in the survey goes down.

425
00:54:21,240 --> 00:54:27,210
I would if you're asking me what I would do, I would cut down the number of observations.

426
00:54:29,310 --> 00:54:36,660
I wouldn't change the design. And that's because unless there's just a reason why.

427
00:54:37,800 --> 00:54:41,190
I can't still do at least like two on each side.

428
00:54:44,580 --> 00:54:49,950
You know what I mean too, is the minimum on both on either side of the intervention.

429
00:54:50,910 --> 00:54:55,290
So if I can't do that, then I have to think about it. But if I were planning on doing it for.

430
00:54:57,800 --> 00:55:03,860
You know, I can I can cut that down probably and still be able to see an effect.

431
00:55:04,470 --> 00:55:10,070
But and so there, you know, you do lose some rigor by doing that.

432
00:55:11,130 --> 00:55:16,860
But you're still able to capitalize on what's already being done.

433
00:55:17,310 --> 00:55:20,070
Like I would. That's why I was like, Why don't I do this more often?

434
00:55:20,520 --> 00:55:28,560
Because if they've already done one observation, all I have to do is the second one, because they've done it with the with the entering.

435
00:55:29,470 --> 00:55:33,250
Intake, for example. They've already done it, so I just need to do another one.

436
00:55:37,240 --> 00:55:44,930
But ideally, yeah, I'm going to keep the. I'm going to keep the design just because I think I might probably will be.

437
00:55:45,050 --> 00:55:49,550
That's probably less of a compromise than changing the design.

438
00:55:51,230 --> 00:55:55,890
Yup. You know, like if other.

439
00:56:03,130 --> 00:56:10,440
Tell us. Yeah.

440
00:56:10,860 --> 00:56:18,060
Yeah. Oh, yeah. Yeah. So the question was, but I need to know what else happened around in account for that.

441
00:56:18,210 --> 00:56:27,660
And the answer is yes. So when we get into validity, we'll talk about threats to validity and one of them is contextual is related to context.

442
00:56:27,990 --> 00:56:39,360
Um, if we, you know, there's something else going on that's a threat, it doesn't mean that we have to cancel the, you know, the study.

443
00:56:39,360 --> 00:56:42,780
We can still do a, you know, a valid analysis,

444
00:56:42,780 --> 00:56:51,570
but we just have to be aware what potentially affected the outcomes of the study other than the intervention.

445
00:56:53,820 --> 00:57:00,490
In the other questions. All right.

446
00:57:01,030 --> 00:57:07,960
So we'll do the third one. We're going to finish out who are pretty experimental designs.

447
00:57:11,700 --> 00:57:16,650
I was really worried. I'm like, We're not going to get through this stuff. Pre experimental design.

448
00:57:17,520 --> 00:57:21,750
These often only offer a single group that receives the intervention.

449
00:57:21,780 --> 00:57:24,810
So there's no control, no comparison group.

450
00:57:25,410 --> 00:57:28,020
You can include a comparison group.

451
00:57:28,020 --> 00:57:36,930
What pre experimental design, but that's when you have no way to know or the test whether the two groups are comparable at baseline.

452
00:57:38,240 --> 00:57:48,680
So one you'll see the pulse test only you'll see why it ends up in pre experimental if we don't have randomization.

453
00:57:51,310 --> 00:57:56,650
So when do we use these? We might use these during a pilot study.

454
00:57:57,100 --> 00:58:04,030
And, you know, again, I think I mentioned other than the pretest post-test compare comparison group design,

455
00:58:04,780 --> 00:58:07,960
I often end up doing pre experimental designs.

456
00:58:09,760 --> 00:58:14,410
Part of that is because I like working with people who are doing pilot studies.

457
00:58:16,350 --> 00:58:21,990
So during a pilot study to test feasibility for a more robust follow up study.

458
00:58:23,180 --> 00:58:27,440
So if you're working with a program, they have kind of a sketch of a program.

459
00:58:28,670 --> 00:58:36,469
And they want to learn a little bit more about it in order to further develop it prior.

460
00:58:36,470 --> 00:58:39,500
Experimental design is a good idea there to use that.

461
00:58:39,770 --> 00:58:43,220
No point investing a lot of money in something that might change.

462
00:58:44,970 --> 00:58:49,980
Say the results are not intended for broad dissemination as a successful intervention,

463
00:58:50,370 --> 00:58:53,940
but are meant to offer insight to those within the organization.

464
00:58:55,200 --> 00:58:58,890
And this is becoming increasingly more common with philanthropy.

465
00:58:59,040 --> 00:59:04,980
They don't always need to know that it was a successful design.

466
00:59:05,460 --> 00:59:12,270
What they're more interested in is supporting the work happening in a given area or with a given population.

467
00:59:14,600 --> 00:59:17,690
Or you can also use them when the evaluation this is.

468
00:59:18,260 --> 00:59:25,040
I'm laughing because I'm like, this is probably what happens the most of the time when the evaluation was not planned ahead of time and

469
00:59:25,040 --> 00:59:30,590
their intervention was either already implemented or you're coming in at the very end and they're like,

470
00:59:30,620 --> 00:59:37,520
Oh crap, we got to have an evaluation because USDA told us we were supposed to do this and we didn't.

471
00:59:37,580 --> 00:59:44,930
It did not follow directions. So that's when these are often used.

472
00:59:46,670 --> 00:59:50,030
So the ones we'll talk about one group post-test.

473
00:59:51,060 --> 00:59:59,520
Only one group pretest post-test design and then the post-test only with non equivalent comparison groups.

474
01:00:02,120 --> 01:00:08,870
So you're one group post-test only design. So there's no pretest, no comparison group.

475
01:00:12,070 --> 01:00:19,060
So without pretest observation, it's really hard to know what changed as a result of the intervention.

476
01:00:20,140 --> 01:00:23,980
Because we don't have any baseline data and we don't have any comparison group.

477
01:00:25,180 --> 01:00:28,660
So if we were looking at this x y axis.

478
01:00:29,910 --> 01:00:34,050
You can see there's only one observation and it happens after the intervention.

479
01:00:34,830 --> 01:00:38,040
We don't know any comparison to whether or not.

480
01:00:39,220 --> 01:00:45,100
The counterfactual was better or worse, and we don't know if it was just noise.

481
01:00:50,620 --> 01:00:55,660
But again, there's reasons why you might use it because you're coming in at the end, for example.

482
01:00:56,630 --> 01:01:02,180
One group pretest post-test design. This is probably the second most common one that I use.

483
01:01:03,230 --> 01:01:11,990
Still no comparison group, but now we have a pretest and we can see if there's a gain score to determine whether the change occurred.

484
01:01:13,280 --> 01:01:20,480
So it does help us see if there was some kind of change or before the intervention, before or after the intervention.

485
01:01:21,200 --> 01:01:25,820
But what we don't know is whether that change was the result of the intervention.

486
01:01:26,360 --> 01:01:32,750
So, again, we don't have a we don't have a count. We can't observe the counterfactual in any way.

487
01:01:35,160 --> 01:01:39,150
So it could be the program, but they could be other factors.

488
01:01:40,640 --> 01:01:48,290
And statistically speaking, we can account for it. The other thing is,

489
01:01:48,290 --> 01:01:55,879
is that what I've learned through experience is that you may also not even have the same

490
01:01:55,880 --> 01:02:02,720
participants complete the complete data collection at the pretest in the post test.

491
01:02:03,440 --> 01:02:07,250
And why is that? Because you might have participants drop out.

492
01:02:08,090 --> 01:02:12,590
You might have participants come in after the programs already started.

493
01:02:13,640 --> 01:02:18,860
And so you have to decide from your perspective, when do we stop doing pretest?

494
01:02:20,920 --> 01:02:25,510
I have a project right now where we started doing pretest.

495
01:02:27,270 --> 01:02:35,040
In March. But this was part of a re granting initiative.

496
01:02:35,370 --> 01:02:38,970
So the grantors they just kept throw our money out.

497
01:02:39,300 --> 01:02:44,670
And the last. Even though we intended on cutting off the pretest in April,

498
01:02:45,210 --> 01:02:55,860
it is literally still open at this point as we speak because and I analyzed the data two weeks ago and there were 49 projects for it.

499
01:02:56,220 --> 01:03:01,210
They're talking about projects. And to when I looked yesterday, there were 51.

500
01:03:01,780 --> 01:03:08,270
So somebody's still giving out money. So now I need as an evaluator to go find out.

501
01:03:08,320 --> 01:03:13,490
Well. What's going on. But also, I need to consider.

502
01:03:14,150 --> 01:03:27,400
Might there be some overlap? And the participants who started their projects in March versus those who started in September to find out if

503
01:03:27,400 --> 01:03:35,470
any effects I observed might be because there just some exposure among the people that they're working with.

504
01:03:35,710 --> 01:03:41,440
That makes sense. So I've got to do my due diligence when I analyze the data to account for the fact that people were

505
01:03:41,440 --> 01:03:48,970
doing pretest and starting their projects at totally different times and in the same geographic area.

506
01:03:50,320 --> 01:03:56,890
So you could see that that could be problematic. But in the real world, sometimes it is going to be the case that you do that.

507
01:04:01,620 --> 01:04:07,260
The last one I wanted to talk about is a pulse test only with nine equivalent groups.

508
01:04:08,310 --> 01:04:14,700
So here it's like the post-test, only with the equivalent groups, but no one's randomized.

509
01:04:15,270 --> 01:04:20,610
So there's really no guarantee if the comparison group is comparable to the intervention group.

510
01:04:23,160 --> 01:04:27,960
So I measure you know, I do assessment and a post test point with both groups.

511
01:04:28,200 --> 01:04:32,010
It could have been the same. They could have been different at the beginning. I don't know.

512
01:04:32,520 --> 01:04:35,730
And that's what makes us different than the quasi experimental design.

513
01:04:36,930 --> 01:04:42,750
Because I'm really not able to to even get a counterfactual that I can trust.

514
01:04:49,050 --> 01:04:53,790
And so that's what that looks like on this on this x axis and y axis.

515
01:04:57,960 --> 01:05:08,530
So any questions about pre experimental. We did it, folks.

516
01:05:09,310 --> 01:05:13,630
I hope I didn't talk it through too fast through all of it. I'm like, I'm really not going to make it.

517
01:05:14,900 --> 01:05:18,140
But we're early. So in summary.

518
01:05:19,850 --> 01:05:23,780
Key concerns of outcome evaluations. We really want to know.

519
01:05:25,100 --> 01:05:29,440
About change. So did that change occur after the intervention?

520
01:05:29,450 --> 01:05:35,060
So immediately after the intervention? Were there changes that were sustained over time?

521
01:05:36,080 --> 01:05:46,550
Were there changes that differed across groups, either participants versus non participants or subgroups within the participant group?

522
01:05:47,750 --> 01:05:52,220
Or I might ask about change that were caused by the intervention.

523
01:05:52,940 --> 01:05:59,510
So now you can see, like you've gone through the design. Different designs are going to allow you to answer different questions.

524
01:06:01,390 --> 01:06:08,410
A true experimental is the best if what you're trying to do is ask that and answer that question.

525
01:06:10,220 --> 01:06:15,140
And then we talked about three broad categories of research design that vary in their

526
01:06:15,140 --> 01:06:22,490
level of rigor or accuracy or ability to recreate account or create a counterfactual.

527
01:06:24,070 --> 01:06:31,180
Korea experimental being the least rigorous, quasi experimental, falling in the middle because it's like.

528
01:06:32,130 --> 01:06:35,970
Like an experimental, but not quite. It's missing something.

529
01:06:36,450 --> 01:06:44,490
And then you are experimental, which is your gold standard or your most rigorous form of design.

530
01:06:46,920 --> 01:06:54,220
So any questions, folks? Yes. For, like, an hour.

531
01:07:04,750 --> 01:07:09,130
So the question is when you're doing the assessment.

532
01:07:10,020 --> 01:07:18,580
Or survey and. Is there a the effect of the question of asking the.

533
01:07:19,450 --> 01:07:23,470
Can happen on the group. Yes. That is another threat to validity.

534
01:07:25,210 --> 01:07:29,110
And it has to do with. It basically has to do with.

535
01:07:30,980 --> 01:07:37,310
Question, directing our attention toward what we're supposed to be learning in the intervention.

536
01:07:38,690 --> 01:07:49,320
We try. We try to write questions and mix up questions in a way that we can at least mitigate that.

537
01:07:50,640 --> 01:07:58,049
But we can't eliminate it completely. So again, when we get into threats to validity, we'll talk about what you can do.

538
01:07:58,050 --> 01:08:03,510
But the truth is, you can never completely get rid of threats to internal validity.

539
01:08:05,850 --> 01:08:09,639
That's why if you ever read a peer reviewed journal, there's like 50 limitations.

540
01:08:09,640 --> 01:08:14,030
There are always limitations because we just can't completely eliminate everything.

541
01:08:16,040 --> 01:08:29,919
Yes. So when?

542
01:08:29,920 --> 01:08:33,220
When would you otherwise do a pulse test? Only design.

543
01:08:34,690 --> 01:08:37,210
That is a basically you came in at the end.

544
01:08:45,150 --> 01:08:55,050
To be honest with you, I cannot think of a reason why you would do that other than other than, ah, like like an issue of resources.

545
01:08:56,000 --> 01:09:02,450
Like. And then just I mean, frankly, sometimes people are uncomfortable with it as well.

546
01:09:02,650 --> 01:09:10,250
So, you know, getting to that idea of survey fatigue, maybe I have a client that really does not.

547
01:09:11,600 --> 01:09:15,860
They already don't want the serving to get in the way of the programing.

548
01:09:16,100 --> 01:09:21,010
So they might just say. We're just going to do it at the end.

549
01:09:21,610 --> 01:09:26,200
Or you might. They might only. Be sharing data with you.

550
01:09:27,140 --> 01:09:30,260
And so they're like, we are we are only going to collect data at the end.

551
01:09:31,370 --> 01:09:38,360
So. But there's no, like, scientific reason why you would only do a pulse test.

552
01:09:38,450 --> 01:09:44,269
Really? But it's really just about, you know, working in the real world and people, you know,

553
01:09:44,270 --> 01:09:48,440
saying that they're really not comfortable with it or there's no money for it.

554
01:09:49,940 --> 01:09:57,690
But scientifically speaking, though, there isn't. I was trying to think if there's a good reason why somebody would do that either.

555
01:09:57,690 --> 01:10:03,330
But honestly, I suppose that might actually think it might actually.

556
01:10:04,580 --> 01:10:08,540
If you're really concerned about that threat to validity about the test.

557
01:10:09,520 --> 01:10:14,090
Affecting the response to the intervention. You could.

558
01:10:15,300 --> 01:10:20,150
Do it. You could you could just choose to do a post-test only design.

559
01:10:20,150 --> 01:10:24,470
But the pros don't outweigh the cons to that.

560
01:10:25,730 --> 01:10:30,290
You covered a lot of. Yeah.

561
01:10:30,830 --> 01:10:35,780
Could you change it from. Designed to act as.

562
01:10:37,330 --> 01:10:42,000
It's like. If you have a lot of nutrition for a lot of.

563
01:10:43,170 --> 01:10:52,809
Oh. So if you have a lot of. So she asked you if you had a lot of attrition or people dropping out between the protests in the polls tests.

564
01:10:52,810 --> 01:10:58,210
Could you change a pretest post-test design to a pulse test?

565
01:10:59,300 --> 01:11:07,850
Or if you just have different people coming in. I probably would not do that unless like say I have had it happen.

566
01:11:07,850 --> 01:11:14,180
Where? The program starts off and it already has a low count.

567
01:11:15,220 --> 01:11:19,960
And when the attrition is so bad that by the time we get to the end,

568
01:11:20,560 --> 01:11:29,290
there's not enough there's not enough people left to do a statistically valid pretest post test analysis.

569
01:11:29,950 --> 01:11:36,960
So then. Yes, so then I. But if that is the case, I'm probably not doing the pulse test analysis either.

570
01:11:37,470 --> 01:11:40,770
Because of that, there's not enough people that even do an analysis.

571
01:11:43,680 --> 01:11:50,020
And so that gets into his own issues. Recruitment it.

572
01:11:50,480 --> 01:11:53,140
I went before I decided to change it.

573
01:11:53,150 --> 01:12:00,950
A pretest pulse test to a pulse test because there's so many new people that the pulse test is like almost completely different.

574
01:12:01,400 --> 01:12:04,460
I'm going to look to see if the groups themselves are comparable.

575
01:12:05,780 --> 01:12:11,360
Because even if they're not the exact same people, if they're similar enough that they could.

576
01:12:12,460 --> 01:12:18,100
That. I can. Argue reasonably that.

577
01:12:19,340 --> 01:12:25,580
Even though they're different individuals, they're the same group. Like, they have the same characteristics that I care about.

578
01:12:26,300 --> 01:12:29,300
Then I would probably do the analysis and report it as a limitation.

579
01:12:32,440 --> 01:12:36,970
So they can see this is all a game. Just a game. Research is just a game.

580
01:12:40,470 --> 01:12:47,910
It's exciting. It's like car racing online. It's not, but it's still fun if you like car racing in your brain.

581
01:12:48,750 --> 01:12:55,830
Any other questions? If you like a challenge but not rock climbing, be a researcher.

582
01:12:57,330 --> 01:13:02,280
Any other questions? All right.

583
01:13:02,280 --> 01:13:04,439
So. Oh, yeah, today is Thursday.

584
01:13:04,440 --> 01:13:11,549
So spend your weekend meditating on research design and if you have any other questions on Tuesday, we'll talk about them.

585
01:13:11,550 --> 01:13:15,570
Otherwise, enjoy the weekend. I'm going camping.

586
01:13:15,570 --> 01:13:25,020
So good luck to you folks. If you email me, only email me during the day because I'll probably not have service at night.

587
01:13:27,930 --> 01:13:32,339
Oh, where do we go. Oh, she, she just opened up the rest.

588
01:13:32,340 --> 01:13:35,940
Yeah, I could go, you could go camping everywhere.

589
01:13:36,120 --> 01:13:41,340
Our state, Michigan State Parks are lovely. They're lovely.

590
01:13:42,450 --> 01:13:49,420
Michigan State Parks. Yeah.

591
01:13:52,880 --> 01:14:12,120
You know, there are like there are only three places and I think you all.

592
01:14:13,700 --> 01:14:20,080
Yeah. Yeah, that was my.

593
01:14:23,700 --> 01:14:30,050
I feel that if you buy the argument, you know what I mean?

594
01:14:30,750 --> 01:14:40,530
It's not my regulation. Hi, Chris.

595
01:14:47,350 --> 01:14:53,350
Oh, well, your group. I mean. Yeah, yeah, I can meet whenever you want, but, um.

596
01:15:08,060 --> 01:15:11,490
I can't, I. I told you, I don't try to remember the day.

597
01:15:12,320 --> 01:15:19,280
I just tried to keep track of the the next thing coming up is the quiz.

598
01:15:19,280 --> 01:15:23,300
And that's the 20th. All right. The next group assigned is November 10th.

599
01:15:23,450 --> 01:15:27,799
November 10th. Okay. Thank you, Chance. Have a good time with the bank.

600
01:15:27,800 --> 01:15:32,420
You. And if you ever want a specific recommendation, I'm happy to give it to you.

601
01:15:32,420 --> 01:15:38,450
But you're all over there? Yes. How do you say that?

602
01:15:38,840 --> 01:15:48,060
Because the great. But if you go to the group, if you go camping all the way through.

603
01:15:48,570 --> 01:16:00,600
But honestly, I mean, I know if you're in you know, in the state of Missouri is not as well, but they can still get really cold at night.

604
01:16:00,650 --> 01:16:03,670
Yeah, but I mean, even during the summer when a lot of my children are just.

605
01:16:04,830 --> 01:16:09,710
But I'm afraid I can't offer a lecture on building.

606
01:16:10,630 --> 01:16:13,980
It was awesome. I love campus.

607
01:16:46,740 --> 01:16:53,440
This question. Did you not see that this new program didn't have.

608
01:16:54,580 --> 01:16:58,390
You remember we made that four by four debut? Yeah.

609
01:16:59,950 --> 01:17:03,570
That's a that's a good point. That's why I drew.

610
01:17:03,580 --> 01:17:09,550
Because you said that, you know, some people may not be interested and they may not have, but we have to include them.

611
01:17:11,080 --> 01:17:16,209
We made the four by 40 billion class. And yeah, that's what I meant.

612
01:17:16,210 --> 01:17:22,750
And that's why I'm like, okay, I have to check the wording on that one, because what I meant by account,

613
01:17:23,230 --> 01:17:28,600
I think what I said is accounted for, but I don't think that's enough of a difference to justify you losing a point on it.

614
01:17:30,130 --> 01:17:35,980
You have to account for what they're doing, even if they're not engaged in the actual planning.

615
01:17:37,070 --> 01:17:40,969
Like there's a difference between accounting for what they do or what they

616
01:17:40,970 --> 01:17:46,700
care about and just kind of being aware of it versus saying recruiting them.

617
01:17:46,700 --> 01:17:47,689
So, for example,

618
01:17:47,690 --> 01:17:57,470
to be part of a steering committee or coming in or doing participating in the planning is if they're not interested and if they're not interested,

619
01:17:57,890 --> 01:17:59,540
they're probably not to participate.

620
01:18:00,890 --> 01:18:08,959
So it's actually like Ford's it is actually fast, but I acknowledge the way that I work at it and I'm looking at I'm like,

621
01:18:08,960 --> 01:18:16,130
okay, I could see I try to make sure that it's clear that it's doing this so long that sometimes too fuzzy.

622
01:18:16,700 --> 01:18:26,040
Why is this? Can't. Because it doesn't it doesn't portray the theory.

623
01:18:26,370 --> 01:18:28,710
It portrays the operation of the program.

624
01:18:29,280 --> 01:18:38,100
The theory of change is the theoretical, conceptual version, and then the logic model is the operational side of it.

625
01:18:39,060 --> 01:18:44,160
Okay, so that other point, I just move it because I'm pretty sure like other people.

626
01:18:44,390 --> 01:18:49,320
So I'll tell that you 12, I'll change that.

627
01:18:49,320 --> 01:18:52,880
But the other one that the logic model. Yeah.

628
01:18:53,370 --> 01:18:56,010
Thank you. You're welcome. Thank you for asking.

