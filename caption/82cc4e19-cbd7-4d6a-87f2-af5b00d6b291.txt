1
00:00:00,510 --> 00:00:09,310
All right. So. As usual.

2
00:00:09,320 --> 00:00:12,320
Let's just take a quick look at where we are in the course.

3
00:00:12,320 --> 00:00:16,000
And we are. Pretty much at the end.

4
00:00:16,010 --> 00:00:28,909
So today I have a very long handout, but right before class this morning I decided I would really rather split it up into two or four handouts.

5
00:00:28,910 --> 00:00:33,800
So I might do that after class because there's a natural cut point.

6
00:00:34,070 --> 00:00:41,000
What I'd like to cover today, it's the part of the Hanna that talks about competing risks and dependent censoring.

7
00:00:41,330 --> 00:00:50,630
And then next time I want to talk about the dependent outcomes like paired or clustered type two outcomes when you have time to time to event data.

8
00:00:51,920 --> 00:00:59,030
So that's going to be this week. Next week, I'm going to talk about another type of regression model,

9
00:00:59,030 --> 00:01:03,620
four times two event that's an alternative to the Cox model that I'm very fond of.

10
00:01:04,890 --> 00:01:11,799
And so neither handouts, 19 or 20 or it's going to look like 19, 20 and 21.

11
00:01:11,800 --> 00:01:18,180
And once I split up this big one, those are not covered on the final quiz.

12
00:01:20,190 --> 00:01:24,059
This is the mature kind of material that I would present to my graduate student

13
00:01:24,060 --> 00:01:30,150
research assistants to do different types of analyzes that I use frequently.

14
00:01:31,800 --> 00:01:39,360
It's related to things that you've learned in 523, so it's completely within your wheelhouse to learn this material.

15
00:01:39,990 --> 00:01:43,920
And I'm going to be teaching it to you just as if you were going to be one of my research assistants.

16
00:01:44,310 --> 00:01:47,490
And I wanted you to be able to do these things. Okay.

17
00:01:48,640 --> 00:01:52,840
That's my goal. Everything for the exam has been covered.

18
00:01:52,840 --> 00:01:59,890
The last lab is being happening this week and it should help you with your final homework.

19
00:02:00,250 --> 00:02:07,060
The final homework is due the 7th of December.

20
00:02:07,930 --> 00:02:12,340
I will not be able to accept the late homeworks on that one.

21
00:02:13,360 --> 00:02:15,520
I do dropped the lowest homework assignment.

22
00:02:15,530 --> 00:02:21,700
So if you're having trouble figuring out how to make everything work towards the end of term, you have that as an option.

23
00:02:21,700 --> 00:02:25,719
But I will tell you, it's such an important topic.

24
00:02:25,720 --> 00:02:31,220
It is very much covered on the quiz. The best way to learn it is to do this homework.

25
00:02:31,970 --> 00:02:36,590
And so I would I would advise you to get it started if you haven't already.

26
00:02:36,980 --> 00:02:40,490
And do your best because you'll be studying for the quiz by doing that homework.

27
00:02:42,530 --> 00:02:47,060
All right. I've also put together.

28
00:02:48,280 --> 00:02:52,510
The practice quiz. Actually, let me show this to you the way it will look to you.

29
00:02:52,960 --> 00:02:57,970
So I've also put together the practice quiz so you can.

30
00:02:59,100 --> 00:03:06,330
Once you've you know you know how you best you study so you can either study and then try to take it or just peek at it at whoever you want to use it.

31
00:03:06,380 --> 00:03:10,230
It's very similar to the structure of practice.

32
00:03:10,230 --> 00:03:16,050
Quiz one So Will and it's meant to reflect what you'll see.

33
00:03:17,330 --> 00:03:22,070
The types of the level of what you would see on the final quiz.

34
00:03:27,310 --> 00:03:34,060
All right. And recall that for the final quiz. It's also 15 one 5%.

35
00:03:34,780 --> 00:03:42,100
So it's enough to hopefully inspire you to study and learn the material, but not enough to be super painful.

36
00:03:44,760 --> 00:03:49,230
And you're allowed to have two pieces of paper front and back.

37
00:03:49,530 --> 00:03:54,330
As you know, your cheat sheets for the material for the for the quiz.

38
00:03:54,630 --> 00:04:04,050
It's going to be online canvas just like last time. So we won't come to campus that day to do the quiz you'll do at home or wherever you prefer.

39
00:04:08,900 --> 00:04:16,110
All right. Any questions about. The administrative parts of wrapping up the course.

40
00:04:17,850 --> 00:04:25,440
Because we are now wrapping up the course. Yes. I'm so sorry, but I cannot hear you.

41
00:04:25,470 --> 00:04:32,800
Can you shout? Just to confirm.

42
00:04:32,810 --> 00:04:36,920
Yes. This is the last week of labs.

43
00:04:36,920 --> 00:04:41,020
There's no labs. Next week. Yes.

44
00:04:41,960 --> 00:04:48,490
Okay. So. With that said, let's go ahead and get.

45
00:04:49,480 --> 00:05:00,180
Started. If you downloaded this is this handout last night, you should.

46
00:05:01,180 --> 00:05:09,250
Read Download because I was ending it right up to the last minute today, finding little things like lowercase, td4 and other stuff.

47
00:05:09,700 --> 00:05:12,940
So go ahead and read download if you downloaded it early.

48
00:05:20,640 --> 00:05:29,750
Okay. So the topics that I plan to cover today are going to be competing risks, which is a.

49
00:05:31,940 --> 00:05:35,479
It kind of covers the cases where you have dependent censoring.

50
00:05:35,480 --> 00:05:43,129
So what do I mean by that? Throughout the whole course so far we've had this assumption that the time to

51
00:05:43,130 --> 00:05:50,390
event that you wanted to model was independent of the censoring mechanism.

52
00:05:50,870 --> 00:05:57,080
And we said that, you know, throughout the course and we were able to weaken the assumption a little bit.

53
00:05:57,110 --> 00:06:03,250
So for the Cox model. We could say conditional on the covariates in the Cox model.

54
00:06:03,580 --> 00:06:08,350
We needed independence between the time to event we were modeling and the censoring mechanism.

55
00:06:09,190 --> 00:06:13,480
But that's not always going to be an assumption that we can live with.

56
00:06:14,020 --> 00:06:19,300
And so when you don't have independent censoring, we call it dependent censoring.

57
00:06:20,170 --> 00:06:28,930
Right. And so and it can be a very common and thorny problem, so much as the raised have had to deal with this.

58
00:06:28,930 --> 00:06:34,630
And now I'm making sure you'll know how to deal with this as well, or at least get you started along that path.

59
00:06:36,890 --> 00:06:38,780
So just a little history.

60
00:06:38,780 --> 00:06:46,460
And it's it's kind of interesting because not a lot has changed about the types of questions with competing risks that we're trying to address.

61
00:06:46,910 --> 00:06:53,270
So competing risks methodology acknowledges that there are many risks active acting upon

62
00:06:53,270 --> 00:06:59,420
a population and it tries to isolate the effects of each one on events we observed.

63
00:06:59,960 --> 00:07:10,580
And probably one of the earliest documented controversies involving competing risks dates to a discussion of smallpox inoculation in the 1700s.

64
00:07:11,360 --> 00:07:19,580
And what's interesting to me is that we have this same conversation today with vaccines,

65
00:07:21,410 --> 00:07:27,020
you know, and the competing risks that may come about when you're thinking about vaccines.

66
00:07:27,470 --> 00:07:35,000
And so in the 1700s, physician physicians were arguing that the benefit of inoculation would not be enough to overcome

67
00:07:35,000 --> 00:07:41,570
the initial inoculation risk for this smallpox inoculation and that they had come up with.

68
00:07:42,880 --> 00:07:47,620
All right. Sound familiar? Risk of vaccine versus benefit of vaccine.

69
00:07:48,460 --> 00:07:56,380
And one of the earliest probable lists that math and statistics statistics professors want to claim

70
00:07:56,380 --> 00:08:02,740
is their own Bernoulli the same Bernoulli that we talk about with the binomial distribution.

71
00:08:03,490 --> 00:08:12,790
So he presented a paper to the French Academy of Sciences estimating the expected increase in lifespan if smallpox were eliminated.

72
00:08:13,810 --> 00:08:21,600
So he's trying to get, you know, understand if if smallpox did not contribute to the deaths, you know,

73
00:08:21,640 --> 00:08:27,040
what would be the expected increase in lifespan, knowing that there are other causes of death that would replace smallpox.

74
00:08:28,030 --> 00:08:32,139
Potentially. And so that was the beginning of the theory of competing risks.

75
00:08:32,140 --> 00:08:36,760
And, yes, he he brought in his Bernoulli distribution as part of this argument.

76
00:08:36,760 --> 00:08:43,510
But I won't I won't really chase that thread down. So.

77
00:08:46,270 --> 00:08:52,510
This is one way to sort of peek at competing risks to so you can see, you know, some specific examples.

78
00:08:53,020 --> 00:08:56,259
And so many people think of it as a multi state models.

79
00:08:56,260 --> 00:09:03,530
These start off as a live. And you can die from a number of causes.

80
00:09:03,540 --> 00:09:12,449
So let's just call this cause one, this cause two, this cause three and you can't see you only die once.

81
00:09:12,450 --> 00:09:16,879
So you can only see one of these. So long so can only die once.

82
00:09:16,880 --> 00:09:24,050
Only one of the competing events can be observed, and most analysis techniques assume that these event times are independent of one another.

83
00:09:24,050 --> 00:09:27,160
But this is impossible to verify and often hard to believe.

84
00:09:28,690 --> 00:09:35,770
All right. So if we were to use the regular Cox model. And we thought all of these causes of death.

85
00:09:36,970 --> 00:09:41,290
You know, the time to death from any of these causes were totally independent of one another.

86
00:09:41,530 --> 00:09:47,649
We might be happy just doing our Cox model and censoring the events at the other death types.

87
00:09:47,650 --> 00:09:58,540
But that assumption that cause of death from type one and type two is independent is is very troubling most of the time.

88
00:09:59,170 --> 00:10:05,329
So as an example, this is an example that I've had to deal with. In my own collaborations.

89
00:10:05,330 --> 00:10:08,840
Suppose you are following heavy smokers.

90
00:10:09,980 --> 00:10:11,840
And in my own experience,

91
00:10:11,840 --> 00:10:24,710
there was a national lung cancer screening trial where heavy smokers were being followed and then causes of death were recorded later.

92
00:10:25,490 --> 00:10:30,110
And so the first cause of death was lung cancer. You know, it was a lung cancer screening trial.

93
00:10:30,110 --> 00:10:41,060
And so they wanted to collect a lot of predictors and try to figure out, you know, who got lung cancer and who inevitably died of lung cancer.

94
00:10:41,540 --> 00:10:49,790
And so that was the first type of death. But heavy smokers can also develop and die from chronic obstructive pulmonary disease.

95
00:10:49,790 --> 00:10:54,739
This is the disease where you see people walking around with oxygen tanks, emphysema.

96
00:10:54,740 --> 00:10:58,010
We've we've actually worked with this disease a little bit in our homeworks.

97
00:10:59,210 --> 00:11:02,450
All right. So heavy smoking leads to both.

98
00:11:03,440 --> 00:11:13,140
And it's hard to imagine that these two types of times two event are independent of one another.

99
00:11:13,160 --> 00:11:16,790
They tend to have the same risk factors over time.

100
00:11:17,510 --> 00:11:23,960
All right. Damage to the lung and some of it goes into cancer and some of it goes into emphysema or small airways disease.

101
00:11:24,960 --> 00:11:27,360
And then there are going to be a lot of other causes of risk.

102
00:11:27,360 --> 00:11:34,920
I think that they had things like cardiac events that were pretty heavy in these smokers and they had a whole bunch other stuff, including old age.

103
00:11:35,550 --> 00:11:45,600
And so one of the research questions that we wanted to figure out was, you know, if if someone gets lung cancer.

104
00:11:50,590 --> 00:11:55,690
Is it worth treating them for COPD if they also get COPD?

105
00:11:56,720 --> 00:12:01,280
Right, because lung cancer can kill people very quickly.

106
00:12:02,370 --> 00:12:09,120
And so treatment for COPD, including maybe a lung transplant, you know,

107
00:12:09,720 --> 00:12:18,330
is it is there some utility to treating their COPD aggressively when they have lung cancer and are.

108
00:12:19,780 --> 00:12:25,630
Likely to die from that cancer. And so a lot of active questions about how to treat patients.

109
00:12:28,150 --> 00:12:34,120
Arise when you have multiple causes of death that are coming at these heavy smokers.

110
00:12:35,290 --> 00:12:38,560
And so or or vice versa, you know.

111
00:12:40,380 --> 00:12:45,090
Well, actually, that's really the only interesting. You can live a long time with COPD.

112
00:12:45,510 --> 00:12:52,240
It's lung cancer that's going to. Really. Probably be the more aggressive cause of death.

113
00:12:52,900 --> 00:12:58,590
And so that's, you know, what do you do with these people that have both lung cancer and COPD?

114
00:12:58,600 --> 00:13:04,360
How aggressively do you treat COPD? Do you even try to do like a transplant?

115
00:13:08,360 --> 00:13:12,950
And so if you do a lung screening program.

116
00:13:14,480 --> 00:13:19,430
And you want to prevent deaths. I. You know, from lung cancer.

117
00:13:19,430 --> 00:13:26,930
And that's the goal. There's another question of, you know, if you prevent death due to lung cancer.

118
00:13:27,740 --> 00:13:37,380
Have you kept. Have you really reduced overall mortality because lung cancer death might be immediately supplanted with death from COPD.

119
00:13:37,400 --> 00:13:45,060
You know, at the same risks, are there so few screening and treat their lung cancer and they survive the lung cancer?

120
00:13:45,440 --> 00:13:53,240
Are they going to die from COPD making that screening kind of ineffective as a way to reduce overall mortality?

121
00:13:53,750 --> 00:13:59,150
So all these kind of things are brewing in in the data that was being collected here.

122
00:13:59,690 --> 00:14:08,569
And central to this data is the fact that these two types of death, the times two, the death of for either of these causes,

123
00:14:08,570 --> 00:14:13,840
you can't see them at the same time, you only die from one thing and they are very dependent.

124
00:14:13,850 --> 00:14:21,340
They have all the same risk factors going in. So the primary problem with competing rests.

125
00:14:21,360 --> 00:14:27,540
The main difficulty occurs when the competing event types occur frequently and are correlated with one another,

126
00:14:27,540 --> 00:14:31,320
for instance, due to underlying age or health status or smoking status.

127
00:14:31,770 --> 00:14:40,740
So if both lung cancer and COPD deaths are frequent and they were in this dataset, then an analysis of all cause mortality.

128
00:14:41,520 --> 00:14:49,980
Ignoring the cause of death may obscure associations between patient characteristics and lung cancer mortality as opposed to COPD mortality.

129
00:14:50,760 --> 00:14:57,060
And so if you really want to describe lung cancer related deaths separately from COPD related deaths,

130
00:14:57,810 --> 00:15:00,360
all cause mortality is going to make that a difficult job.

131
00:15:03,440 --> 00:15:11,780
If lung cancer and COPD mortality are both driven by similar risk factors, then censoring lung cancer follow up at COPD Death Times.

132
00:15:13,690 --> 00:15:17,170
Well, overestimate lung cancer survival rates.

133
00:15:18,490 --> 00:15:26,600
So why would that be? So.

134
00:15:28,640 --> 00:15:35,900
The people who die of COPD were probably also at high risk for eventually getting lung cancer because these are smokers.

135
00:15:36,080 --> 00:15:43,220
COPD is a big smoking disease or maybe dust in the air can happen as well, causing COPD.

136
00:15:44,330 --> 00:15:47,120
And so if you sense or someone that there's COPD death time,

137
00:15:47,180 --> 00:15:53,360
it's it's as if you're saying that they are similar in risks to everybody else in the dataset.

138
00:15:53,630 --> 00:15:58,940
But really, they were probably at a higher risk for lung cancer compared to everybody else in the dataset.

139
00:15:59,720 --> 00:16:05,360
And so you're kind of be giving them too much credit for living a long time.

140
00:16:06,330 --> 00:16:08,490
And that estimates lung cancer survival.

141
00:16:12,810 --> 00:16:21,240
So this is just one example where the independent censoring assumption is violated with these two types of deaths that,

142
00:16:21,810 --> 00:16:27,050
you know, the time those events are correlated. Okay.

143
00:16:27,090 --> 00:16:31,459
So what if you could assume that competing Time's 200 independents?

144
00:16:31,460 --> 00:16:37,400
I suppose we believe that times to death from lung cancer and times to death from COPD are conditionally independent.

145
00:16:37,700 --> 00:16:43,580
Once you have measured covariates that capture the underlying health status and you're taking that into account.

146
00:16:44,030 --> 00:16:47,359
So in this case, the Cox proportional hazards model,

147
00:16:47,360 --> 00:16:53,090
that sense is follow up at the time of the competing event is valid as long as those covariates are in the hazard model.

148
00:16:53,110 --> 00:16:59,419
So if you really do think once you account for age and smoking and other covariates that you measure,

149
00:16:59,420 --> 00:17:02,990
at the time they were screened in this niche national lung cancer screening trial.

150
00:17:03,410 --> 00:17:09,500
If you as in the conditional on all those covariates the time to death.

151
00:17:11,180 --> 00:17:15,000
Related to COPD versus lung cancer are independent again.

152
00:17:15,020 --> 00:17:17,780
Then you can go ahead and use the traditional Cox model.

153
00:17:18,560 --> 00:17:23,660
It's a strong it's an untestable assumption because you never do observe both events in a person.

154
00:17:23,660 --> 00:17:29,569
So you can't model within a person the correlation between those times to event.

155
00:17:29,570 --> 00:17:31,430
You only get to see one per person.

156
00:17:33,390 --> 00:17:40,390
And Kaplan-meier survival estimates a log rank test that don't adjust for covariates may still be subject to large bias.

157
00:17:40,410 --> 00:17:45,090
So you haven't kind of escaped this descriptive aspect in the data.

158
00:17:46,320 --> 00:17:54,470
You've only maybe. I got a Cox model that you can interpret if you think it's independent, conditional on these covariates in the model.

159
00:17:56,960 --> 00:18:07,580
And there are some times when there's just no possible way to use a covariant adjustment to fix the standard Cox model.

160
00:18:09,560 --> 00:18:12,590
So here's an example that I personally.

161
00:18:13,790 --> 00:18:17,479
Came in, you know, had to deal with where there was.

162
00:18:17,480 --> 00:18:21,680
No there were. We just the converts were not available to do this.

163
00:18:22,700 --> 00:18:31,860
Fixed, which is the standard model. And so the goal was to estimate long waitlist survival.

164
00:18:32,510 --> 00:18:36,440
If you were waiting for a transplant, but the transplant wasn't available.

165
00:18:36,920 --> 00:18:48,200
And so this was a project that I worked on between 2000 and 2010 trying to figure

166
00:18:48,200 --> 00:18:53,930
out how to allocate lungs to people who are waiting for a lung transplant.

167
00:18:54,050 --> 00:19:01,760
And I was on this national committee trying to figure out a score to order people to get a lung transplant if they needed one.

168
00:19:02,450 --> 00:19:11,350
And so part of that is the need to know how urgent their their situation is, how long will they live without a transplant?

169
00:19:11,360 --> 00:19:15,120
So that's a measure of urgency. Okay.

170
00:19:15,120 --> 00:19:21,930
So for our purposes, we want to have some kind of a survival estimate for people who are on the wait list,

171
00:19:23,520 --> 00:19:27,060
you know, and what would that look like if they never got a transplant?

172
00:19:29,880 --> 00:19:38,860
And the lung allocation score. The first one that we put together went into effect in 2005.

173
00:19:38,880 --> 00:19:44,550
Like midway between my time on this contract, I came up with a long allocation score that was implemented nationally.

174
00:19:44,940 --> 00:19:54,960
It was really great and it included an urgency measure related to the time you would live on the waiting list if you didn't get a transplant.

175
00:19:55,900 --> 00:20:00,130
All right. We were very, very happy about that. It was used to just die transplant offers.

176
00:20:00,760 --> 00:20:10,750
But then once it was implemented, the higher your lung allocation score was, the more likely you were removed from the waitlist to get a transplant.

177
00:20:12,460 --> 00:20:15,610
So we introduced dependent censoring.

178
00:20:15,850 --> 00:20:25,150
So let's think about why. Okay. So someone is floating along, waiting for a lung to come to get transplanted.

179
00:20:25,570 --> 00:20:35,980
They have a really, really high score. So they are very urgent because we developed a score to capture urgency as well as transplant benefit.

180
00:20:37,260 --> 00:20:42,300
And so if you are very urgent and also have a chance at a good transplant benefit, the score is high.

181
00:20:42,960 --> 00:20:48,720
And if it's high that you will be grabbed off that wait list and transplanted.

182
00:20:49,230 --> 00:20:53,700
And it actually happens very quickly today compared to what it was before this algorithm.

183
00:20:54,750 --> 00:20:58,829
And so the people who are censored from the wait list are censored.

184
00:20:58,830 --> 00:21:05,370
There are waitlists served. Time is censored because they were alive on the wait list at the time they were transplanted.

185
00:21:05,370 --> 00:21:09,570
We'll never see their death on a waitlist once they're removed for transplant.

186
00:21:10,510 --> 00:21:15,220
So if you're looking at time to death on the wait list, you censor them.

187
00:21:15,490 --> 00:21:18,800
When they get their transplant. You'll never see the waitlist to.

188
00:21:20,590 --> 00:21:26,830
Okay. So your outcomes are going to be tied to death on the wait list or time to censoring.

189
00:21:27,040 --> 00:21:34,540
And that time, the censoring variable is so related to transplant and the urgency of the patient

190
00:21:34,540 --> 00:21:38,620
at the time they were removed for transplant that you have dependent censoring.

191
00:21:39,020 --> 00:21:44,330
You see how that works. So by fixing the problem, we created a statistical problem.

192
00:21:45,350 --> 00:21:52,580
So the next generation of the loan allocation score, we had to figure out how to estimate urgency.

193
00:21:53,850 --> 00:21:59,310
Survival on the wait list with this dependent censoring that we pretty much created.

194
00:22:00,310 --> 00:22:05,440
With this covariate that we measured every single day called the lung allocation score.

195
00:22:09,510 --> 00:22:15,489
So Kaplan-meier survival estimates will be biased from the dependance between the time to death, which was the outcome of interest,

196
00:22:15,490 --> 00:22:22,620
the time to death on the waitlist and time to transplant the competing risk that was censoring the waitlist death time.

197
00:22:25,050 --> 00:22:30,450
And if we were to try to attempt a Cox model approach.

198
00:22:31,840 --> 00:22:39,820
That approach would require us to have covariates that make the time to transplant and time to death conditionally independent.

199
00:22:40,420 --> 00:22:44,380
And so that would certainly be lovely if we could make that happen.

200
00:22:46,100 --> 00:22:50,389
And the most obvious covariate is the current low long allocation score value that

201
00:22:50,390 --> 00:22:54,860
gives the current transplant allocation priority and involves current urgency.

202
00:22:55,520 --> 00:23:02,059
So up until the point where they get transplanted, we have this lung allocation score.

203
00:23:02,060 --> 00:23:05,930
It's a time we have it up to the day they get transplanted.

204
00:23:10,020 --> 00:23:20,200
So the the problem. That defeats this approach is that patient urgency and and the alumni allocation score both change over time.

205
00:23:21,550 --> 00:23:31,510
So even if we put today's on the allocation score in the Cox model, there are going to be future and unknown changes in urgency for each patient,

206
00:23:31,510 --> 00:23:36,700
and the lung allocation score will keep those competing risks dependent.

207
00:23:37,540 --> 00:23:41,430
So both of these. At any point in time.

208
00:23:41,970 --> 00:23:47,820
You know, if you want to know the urgency for a patient and you have today's last score.

209
00:23:50,240 --> 00:23:56,540
That won't be enough to remove the dependance censoring because you're going to keep getting more urgent.

210
00:23:56,540 --> 00:24:02,930
And you're going to keep having. Your last score changes well.

211
00:24:06,260 --> 00:24:10,100
So you can't use the traditional Cox model to adjust for the dependance between these

212
00:24:10,100 --> 00:24:14,690
competing risks because you don't know future Elliott's values to adjust for them.

213
00:24:17,690 --> 00:24:21,589
So the solution is to do something called inverse probability weighting.

214
00:24:21,590 --> 00:24:26,630
And just as a question, have you used inverse probability weights in your other courses?

215
00:24:26,780 --> 00:24:35,720
Like what context did you use that in? Okay.

216
00:24:36,190 --> 00:24:39,790
You speak. You speak. Course numbers.

217
00:24:39,790 --> 00:24:44,649
Is that the basic epidemiology intro? Okay.

218
00:24:44,650 --> 00:24:48,630
So it was but it was related to sampling. Right.

219
00:24:49,260 --> 00:24:54,660
So you've seen inverse probability weights related to kind of adjusting the sampling distribution.

220
00:24:55,020 --> 00:24:59,419
This is going to be a little bit different. Inverse weights are wonderful things.

221
00:24:59,420 --> 00:25:07,909
They can be used to tackle a number of different problems. In this particular case, we're going to be using it to address dependent censoring.

222
00:25:07,910 --> 00:25:20,239
And the idea is related, right? So if you have someone who is censored in this dependent way, then you don't have you know,

223
00:25:20,240 --> 00:25:23,660
they're removed from the dataset and they don't reflect who's left.

224
00:25:24,410 --> 00:25:34,160
It's almost like a sampling issue, right? Because your sample's been affected by being removed in a way that relates to these these covariates.

225
00:25:34,670 --> 00:25:40,880
And so the inverse probably weights in this setting are going to be adjusting.

226
00:25:42,650 --> 00:25:46,790
Oh, I've heard this this term, and I kind of like it.

227
00:25:46,790 --> 00:25:54,170
It's it's like ghosting in people who are removed by overweighting the people who were left that are similar to them.

228
00:25:55,320 --> 00:26:06,390
And so it's it's related to this fixing of the way data was sampled, but it's in the survival analysis context that each survival follow up time.

229
00:26:07,140 --> 00:26:14,010
People who are dependently censored are going to kind of be ghosted back into the

230
00:26:14,010 --> 00:26:18,690
data set by overweighting people who were similar to them and were still at risk.

231
00:26:19,900 --> 00:26:24,760
And I don't want you to focus too much on this. The the subtlety.

232
00:26:26,210 --> 00:26:32,240
Of this argument, if that helps you because of what you've seen before with inverse weighting, I'm happy that it helps you.

233
00:26:32,690 --> 00:26:34,850
But I'm going to show you how to do the fix.

234
00:26:35,480 --> 00:26:42,830
And you know, over time, you know, if you do some reading, if you have to address this topic, you can read more about it.

235
00:26:43,400 --> 00:26:47,880
So I'm going to show you the fix. But they are.

236
00:26:48,270 --> 00:26:56,490
But they are related. It's just that instead of one single inverse weight applied to a person in a population,

237
00:26:56,760 --> 00:27:05,219
we're going to be using inverse weights at each follow up time in the survival analysis to try to adjust for the fact that we

238
00:27:05,220 --> 00:27:12,060
have some people who were censored that we would have liked to have kept in the analysis as if they had independent censoring.

239
00:27:14,320 --> 00:27:21,190
So there are modifications to Cox regression that then incorporate weights related to the dependent censoring mechanism called inverse,

240
00:27:21,190 --> 00:27:23,080
probably weighted Cox regression.

241
00:27:25,110 --> 00:27:33,510
And so the estimation of weights related to the dependent censoring mechanism is key to adjustment for dependent censoring bias.

242
00:27:35,100 --> 00:27:44,549
There's an R package called IP. W, I don't know if you've used it for your other dependent censoring or your other inverse probability weighting.

243
00:27:44,550 --> 00:27:49,080
I don't. They probably have their own package for that in ap6 hundred.

244
00:27:49,890 --> 00:27:56,880
But for survival analysis, this is really the package, the go to package I send all of my research assistants to.

245
00:27:58,620 --> 00:28:05,489
And the gestalt of this is that there's this function called IP, WTM that estimates the desired time,

246
00:28:05,490 --> 00:28:12,330
varying weights related to, you know, the reason for people being removed from the risk set.

247
00:28:12,690 --> 00:28:17,490
And then those weights are fed into the COX Proportional Hazards model, regular package.

248
00:28:20,740 --> 00:28:23,680
So dependent censoring is related to a time dependent variable,

249
00:28:24,310 --> 00:28:30,790
then adjustment for the dependent censoring can be handled via weights is so estimated with this IP ATM function.

250
00:28:31,450 --> 00:28:40,659
And so we're going to look at an example of that that's provided along with this our IP package and on the canvas page,

251
00:28:40,660 --> 00:28:45,129
I have links to the documentation for this package.

252
00:28:45,130 --> 00:28:48,370
So I'm taking the example right from that documentation.

253
00:28:50,110 --> 00:28:54,370
There is also something.

254
00:28:56,200 --> 00:29:00,430
That is maybe closer to what your AP 600 would look like.

255
00:29:01,540 --> 00:29:09,250
And there's treatment as a time dependent variable in this particular dataset that's taught in the package.

256
00:29:09,640 --> 00:29:12,610
And so if treatment is a time dependent variable.

257
00:29:14,340 --> 00:29:21,900
Then adjustment for confounders that vary prior to treatment can also be handled via weights estimated with the IPI ATM function.

258
00:29:22,620 --> 00:29:25,580
And so there's two different weights being talked about here.

259
00:29:25,590 --> 00:29:33,540
One, to fix the dependent censoring and one to fix the fact that before they get treatment,

260
00:29:33,900 --> 00:29:38,940
the risk factors might be different than for people who had gotten the treatment.

261
00:29:39,240 --> 00:29:42,330
And so you want to do some kind of a fix for that.

262
00:29:45,770 --> 00:29:50,670
And so we'll be. Looking at that as well.

263
00:29:53,870 --> 00:29:58,820
So to inverse probability weighting adjustments can be done in the same analysis.

264
00:29:59,820 --> 00:30:09,180
One related to the dependent censoring. And one that's trying to adjust for confounders that vary prior to some time dependent treatment kicking in.

265
00:30:12,760 --> 00:30:16,370
Right. So you can read more about that.

266
00:30:16,730 --> 00:30:21,080
And here's kind of where to read about it in the documentation, if you want to follow up with this.

267
00:30:22,660 --> 00:30:25,830
So here is the example.

268
00:30:25,840 --> 00:30:36,430
So there was. HIV mortality was of interest in this dataset, and they simulated a data set to reflect something they had to deal with in real life.

269
00:30:37,630 --> 00:30:42,280
So there's 1200 simulated HIV infected patients in this data set.

270
00:30:43,630 --> 00:30:48,970
And time zero is HIV seroconversion followed until death or censoring?

271
00:30:51,510 --> 00:30:59,610
So the patient can start taking highly active antiretroviral therapy, the heart therapy, at any time.

272
00:31:00,330 --> 00:31:05,880
And so, you know, not everybody starts at day zero in this data set, you know.

273
00:31:07,830 --> 00:31:11,390
So it's a time dependent coverage. It's going to be like 00000.

274
00:31:11,400 --> 00:31:16,710
And then when they start the therapy, whatever time that happens, it's one four from there on.

275
00:31:18,580 --> 00:31:31,390
And the covariant. That we really want to help us with both dependent censoring and in balance before and after her therapies.

276
00:31:31,400 --> 00:31:35,450
This patient city for count. It's a CD4 count.

277
00:31:35,450 --> 00:31:37,280
The lower it gets, the stickier you're getting.

278
00:31:37,850 --> 00:31:45,130
And in this in the data set that they were really wanting to analyze and therefore simulated the problem as well.

279
00:31:45,140 --> 00:31:50,660
For our little example, data set patient sitting for kind of fix the dropout time.

280
00:31:50,750 --> 00:31:55,400
So the sicker they were, the more likely they were to drop out. And that was a censoring event.

281
00:31:56,720 --> 00:32:03,170
Okay. But it also the lower it gets, the more likely you were to have a death, a mortality event.

282
00:32:04,840 --> 00:32:12,930
So the competing risk is dependent censoring from informative drop out in this case.

283
00:32:12,940 --> 00:32:20,709
So the time to drop out and the time to death were both related and tied to the city for count.

284
00:32:20,710 --> 00:32:31,880
That was getting worse over time. And the Patient City four account profiles can also vary before versus after the initiation of heart therapy.

285
00:32:31,880 --> 00:32:38,720
You can sort of imagine that as people get sicker, you know, maybe they go into this therapy, they go into this therapy.

286
00:32:39,920 --> 00:32:46,489
And so an inverse way, it can also be used to adjust for these differences without distorting their treatment effect interest.

287
00:32:46,490 --> 00:32:52,850
So what do I mean by distorting the treatment effect of interest when we talked about the Cox model before.

288
00:32:54,320 --> 00:33:01,280
In the part of the course that's covered on the exam. So here we're tying into it something that helps you study, you know?

289
00:33:03,290 --> 00:33:11,450
We said, if you're if you're trying to get at a treatment effect on mortality, you shouldn't adjust for.

290
00:33:14,620 --> 00:33:18,210
Anything post baseline. That is.

291
00:33:19,180 --> 00:33:22,450
Something that could be helped by treatment but also related to mortality.

292
00:33:22,780 --> 00:33:30,750
Remember that conversation? And so you guys call these things like colliders or something and epidemiology.

293
00:33:32,160 --> 00:33:36,299
But I just think of it as, you know,

294
00:33:36,300 --> 00:33:44,880
a confounder that you can't adjust for because it adjusts the way the treatment effect you're interested in if the treatment's helping.

295
00:33:45,150 --> 00:33:48,900
For instance, if the treatment's helping, the CD4 count get better.

296
00:33:50,990 --> 00:33:59,809
Ah, and that's the main place where the treatment is benefiting mortality than if you adjust for city for account after baseline,

297
00:33:59,810 --> 00:34:03,470
you're adjusting away the treatment effect. That's the way I think of it.

298
00:34:05,240 --> 00:34:13,840
Okay. So. So you can't just stick these tar Pepsi four counts in your model in your Cox model and adjust for them that way.

299
00:34:14,180 --> 00:34:17,420
But it turns out that you can use this inverse weight approach.

300
00:34:19,150 --> 00:34:24,700
To adjust for the differences without distorting that treatment effect of interest.

301
00:34:25,180 --> 00:34:37,129
Okay. So it's again, it's sort of like, you know, fixing up the weights so that you have a fair game before and after art therapy.

302
00:34:37,130 --> 00:34:40,910
In terms of the three four count distribution, the inverse weights, trying to fix that up.

303
00:34:43,360 --> 00:34:53,419
So here's and all of this is in ah I haven't found yet a South counterpart to this that I'm happy with.

304
00:34:53,420 --> 00:34:59,610
So I always point my GSR rays to r. And this is what the data set looks like.

305
00:34:59,620 --> 00:35:05,020
So when I just described these variables a little bit as we go through.

306
00:35:05,040 --> 00:35:08,220
So there's the patient I.D. and then.

307
00:35:09,170 --> 00:35:15,200
These variables to start a f up time for follow up time, the treatment indicator,

308
00:35:17,270 --> 00:35:26,510
whether they had the event or not and then some a few covariates sex and age do not change in this data set over time.

309
00:35:26,810 --> 00:35:35,750
City for count does change over time. And so let me just sort of kind of go a little bit through these in more detail.

310
00:35:35,780 --> 00:35:44,899
The patient is the patient it. And then t start is a starting time for each interval of follow up.

311
00:35:44,900 --> 00:35:53,240
So the follow up time is kind of being split up into 100 day intervals here and.

312
00:35:55,630 --> 00:35:59,530
The the, the first window is a little bit strange.

313
00:35:59,530 --> 00:36:07,870
The first interval of follow up is -100 to 0, and it's meant to capture those who start therapy at time t0.

314
00:36:10,170 --> 00:36:19,500
All right. So t start minus energy zero and then follow up all the way till the end of follow up is sort of split up into these 100 day periods.

315
00:36:20,710 --> 00:36:27,280
So that they can kind of talk about CD4 counts that apply to those 100 day periods.

316
00:36:27,400 --> 00:36:31,900
That's kind of the goal when you have 10% covariates that are measured over time.

317
00:36:31,910 --> 00:36:36,250
This is a very common way to create time to predict incorporates for the Cox model

318
00:36:36,970 --> 00:36:42,250
is to split it up with those type of covariates changing over some intervals.

319
00:36:43,810 --> 00:36:53,460
A follow up time. And so follow up time is the end time for each interval of follow up measured in days since HIV seroconversion.

320
00:36:53,790 --> 00:36:59,580
So this is like almost I think sometimes people call it t start and t stop, you know,

321
00:36:59,910 --> 00:37:04,500
but it's just trying to split at the beginning and the end of follow up intervals here.

322
00:37:09,250 --> 00:37:14,830
And then heart end is an indicator for the initiation of heart therapy at the end of each interval.

323
00:37:15,400 --> 00:37:24,930
So it's zero if in that interval heart has not been initiated all the way through the end, and it's one if heart is initiated.

324
00:37:24,940 --> 00:37:33,130
So now this first window makes sense because they want this variable to be heart as was initiated by the end of the interval.

325
00:37:33,970 --> 00:37:40,660
So if this is a you know, if you had a person who started at times zero, you'd want the first indicator to be one.

326
00:37:41,350 --> 00:37:55,270
And this allows you to do that. So over here for this patient one, sometime between 607 hundred days from time zero there seroconversion.

327
00:37:55,270 --> 00:38:01,450
I think that was the time zero. Sometime in that window, they started the heart therapy.

328
00:38:03,360 --> 00:38:08,459
All right. So here are their city. Four counts before heart therapy, and here are their city.

329
00:38:08,460 --> 00:38:11,670
Four counts after heart therapy, you know? And so.

330
00:38:15,330 --> 00:38:23,400
We want to appreciate the fact that they're going to be differences before and after within patient and across patients.

331
00:38:24,680 --> 00:38:29,770
When they start their therapy. Events an indicator for death.

332
00:38:30,190 --> 00:38:37,419
At the end of the interval. So this person is obviously alive all the way through these windows.

333
00:38:37,420 --> 00:38:42,730
But at some point there's going to be a window where, you know, some people are going to die.

334
00:38:46,240 --> 00:38:49,530
Sex is. Should have been called female.

335
00:38:49,540 --> 00:38:54,370
I always like verbal names that say what it is, but in this dataset it's called sex.

336
00:38:55,180 --> 00:39:00,520
And it's one if it's a female. And age is the age at the start of follow up.

337
00:39:00,520 --> 00:39:10,690
So they're not updating that for each window. 34. insecurities.

338
00:39:10,690 --> 00:39:17,170
The square root of the city, four count measured at the end of each interval, but before heart end.

339
00:39:19,680 --> 00:39:32,960
So in each row. Corresponding to time point j an individual I city for does as QR has an effect on heart end in the same row, including at time zero.

340
00:39:36,650 --> 00:39:40,940
And dropout is an indicator for drop out of the study.

341
00:39:42,060 --> 00:39:47,940
At the end of the interval. Zero means they didn't drop out for that interval when they did drop out.

342
00:39:52,240 --> 00:39:55,370
Okay. So how do we get the inverse weights?

343
00:39:55,510 --> 00:39:59,550
This is definitely the how to. So for this,

344
00:39:59,700 --> 00:40:06,089
we're going to do two inverse ways and one of them is going to be correcting for dependent censoring related to Siri

345
00:40:06,090 --> 00:40:15,360
for one of them is going to be trying to adjust for side for being different before versus after therapy is started.

346
00:40:15,690 --> 00:40:23,700
So for this first one, the exposure is this indicator that they're starting therapy.

347
00:40:24,940 --> 00:40:31,709
All right. And so these inverse probability weights with exposure equal to heart end are used to

348
00:40:31,710 --> 00:40:37,650
adjust for potential differences in see for profiles before versus after heart therapy.

349
00:40:39,840 --> 00:40:45,660
And so the inputs here are numerator and denominator.

350
00:40:46,440 --> 00:40:54,660
So the numerator you are supposed to include time fixed covariates that are not confounders but that are associated with the exposure,

351
00:40:54,990 --> 00:40:58,050
which in this case is the, the treatment initiation.

352
00:40:58,900 --> 00:41:07,570
And so the two variables in the data set that are potential confounders are are sex and age.

353
00:41:09,320 --> 00:41:13,160
And those serve the purpose of stabilizing the ways that they don't get too big.

354
00:41:13,160 --> 00:41:16,489
You can actually have a tilde one and not put anything in there,

355
00:41:16,490 --> 00:41:22,250
but it tends to help make better weights if you put in the time fixed covariance in

356
00:41:22,250 --> 00:41:28,309
that numerator and then the denominator includes numerator terms plus any confounders,

357
00:41:28,310 --> 00:41:31,160
either time fixed or time varying for the exposure.

358
00:41:31,850 --> 00:41:41,210
And so CD four is our main confounder here that we're trying to adjust for, and so we're sticking it in the model.

359
00:41:45,270 --> 00:41:55,409
So that. Oh, and is there anything else here? And then here you just have, you know, ideas for the patient, start time, various follow up time,

360
00:41:55,410 --> 00:41:59,819
all these things you can kind of get from the description of the variables.

361
00:41:59,820 --> 00:42:06,770
Those are other things that you put in. And then we have a second inverse.

362
00:42:06,770 --> 00:42:10,850
Wait that we want to calculate to deal with dependent censoring.

363
00:42:12,390 --> 00:42:15,750
And so this time we have exposure equals the drop out variable.

364
00:42:16,170 --> 00:42:20,850
And so these inverse probability of censoring weights with exposure equals drop are used to

365
00:42:20,850 --> 00:42:25,170
adjust for dependent censoring bias due to time varying city for count prior to dropout.

366
00:42:26,160 --> 00:42:31,380
And so everything else is the same in this example.

367
00:42:31,590 --> 00:42:33,479
Even though we're thinking about them in different ways,

368
00:42:33,480 --> 00:42:40,350
that the numerator gain includes time fixed converts that are not confounders but that are associated with the exposure dropout.

369
00:42:41,190 --> 00:42:41,489
All right.

370
00:42:41,490 --> 00:42:49,850
So the only thing that's changed between this slide and the previous slide is that last the last slide exposure was the initiation of treatment.

371
00:42:49,890 --> 00:42:58,470
This time, it's the dropout. So we're trying to adjust for two different aspects of a bias in the analysis.

372
00:43:00,740 --> 00:43:06,620
And the denominator includes the numerous terms plus any confounders, either time fixed or time varying for the exposure drop out.

373
00:43:08,300 --> 00:43:19,340
So when you run those two different functions and ah you get output that are inverse probability weights.

374
00:43:19,340 --> 00:43:27,049
And so the first set that we got that was adjusting for CD4 count being different

375
00:43:27,050 --> 00:43:32,450
before and after HAART therapy started that is saved in this first bit.

376
00:43:33,080 --> 00:43:40,880
And the weights that we got to account for dependent censoring where we were modeling the exposure equals dropout, that's the second weight.

377
00:43:41,210 --> 00:43:46,250
And so you can actually multiply those two weights together and stick them into the

378
00:43:46,250 --> 00:43:52,130
regular Cox function so that so we're going to fix two problems at once in this data set.

379
00:43:54,300 --> 00:43:54,690
All right.

380
00:43:55,020 --> 00:44:04,530
And if you were to peek at all of these weights, they're actually quite complicated because there's a weight for each person and each follow up time.

381
00:44:04,530 --> 00:44:10,140
It's actually a big monster of weight data here that's being fed in.

382
00:44:13,050 --> 00:44:20,040
And after you run this function, you know, you get output that looks very nice and friendly.

383
00:44:20,070 --> 00:44:27,150
It looks just like regular Cox model output, except that you've adjusted for these two problems in the data.

384
00:44:28,200 --> 00:44:34,649
And so here is the hazard ratio and you have confidence limits and p values.

385
00:44:34,650 --> 00:44:38,879
And so you can write a manuscript where the sentence after you've done this.

386
00:44:38,880 --> 00:44:46,020
So after adjusting for dependent censoring related to the oops, I should have had a cut of all these.

387
00:44:46,440 --> 00:44:51,450
I keep on using like a variable name that should be capital city for account.

388
00:44:51,690 --> 00:44:55,229
So after adjusting for dependent sensing related to C for count as well as

389
00:44:55,230 --> 00:45:00,450
potential confounding due to different CD4 counts prior to initiation therapy,

390
00:45:01,590 --> 00:45:05,730
patients who initiated the the heart therapy had 0.39.

391
00:45:06,540 --> 00:45:13,020
The hazard of those not initiating heart therapy with hazard ratio confidence interval p value.

392
00:45:13,320 --> 00:45:21,920
So this is the same kind of manuscript where the sentence that you would write related to our Cox model stuff that we did earlier in the course,

393
00:45:21,930 --> 00:45:23,009
it is covered on the exam,

394
00:45:23,010 --> 00:45:33,479
but we fixed two problems one for dependent censoring and one for city for kind of being different before and after therapy.

395
00:45:33,480 --> 00:45:40,710
And we wanted to it's a kind of an example of causal inference, trying to adjust for that behind the scenes.

396
00:45:43,930 --> 00:45:47,440
And so just recently I've had.

397
00:45:48,760 --> 00:45:54,370
Research assistants use this function to deliver dependent censoring data.

398
00:45:55,390 --> 00:46:05,830
And I and I'm already thinking I need to point someone else to this idea to adjust for differences before and after like a time dependent treatment.

399
00:46:05,830 --> 00:46:11,960
So this comes up a lot in research, so I hope that you will use it.

400
00:46:11,980 --> 00:46:15,460
That's my favorite, favorite technique for dealing with dependent censoring.

401
00:46:16,180 --> 00:46:20,920
So but I need to kind of educate you on what other things are done out there.

402
00:46:21,880 --> 00:46:27,550
So you're familiar. And if someone is trying to talk to you about they want to do a different approach.

403
00:46:27,550 --> 00:46:37,090
You'll know what they're talking about and you'll know how to argue for your preferred analysis, which I'm trying to push these inverse proportional.

404
00:46:37,270 --> 00:46:41,650
It's on you. So you're going to come away with my bias if you trust me on this stuff.

405
00:46:42,130 --> 00:46:47,170
So what other strategies are available to us and standard software and what are their advantages and limitations?

406
00:46:48,100 --> 00:46:53,860
So I BW methods can only adjust for sources of dependent censoring bias that are related to measured covariates.

407
00:46:54,370 --> 00:46:58,600
So if you think that there's still point censoring out there and you don't have any covariates to fix it,

408
00:46:58,930 --> 00:47:06,310
then you you want to at least test how much your analysis changes under various assumptions.

409
00:47:06,580 --> 00:47:11,530
So you don't always have access to enough measured coverage to address all the bias in your data.

410
00:47:11,530 --> 00:47:22,000
So what can you do? So method one is to acknowledge that you can't possibly look at these types of, you know, these.

411
00:47:23,050 --> 00:47:32,430
Times to event separately. And you can just study all cause mortality where you don't distinguish between the different types of death.

412
00:47:32,440 --> 00:47:37,929
That's one solution because all cause mortality will remove the dependent censoring that you

413
00:47:37,930 --> 00:47:43,780
would have to deal with if you were studying some cause specific like lung cancer mortality.

414
00:47:45,360 --> 00:47:50,580
So that's one approach. It's not very satisfying, but it will be unbiased.

415
00:47:50,910 --> 00:47:59,290
So method two. Which I'll talk about a little more, is to censor at the competing risk.

416
00:47:59,300 --> 00:48:04,940
So for instance, when you were studying lung cancer versus COPD, censor, the one you're not interested in,

417
00:48:05,510 --> 00:48:11,780
and then perform sensitivity analysis covering extreme cases of what could have happened.

418
00:48:14,260 --> 00:48:18,220
At the time that competing event was censored. So we'll talk about that in a minute.

419
00:48:19,330 --> 00:48:25,569
And then method three I have to cover because it's out there and I'm constantly telling people not to do it,

420
00:48:25,570 --> 00:48:32,170
but it's out there and it's popular, unfortunately, is to study cumulative incidence of all the competing events.

421
00:48:32,590 --> 00:48:38,560
And I'm going to take you through an example of why I really dislike this method, and it can confuse the story.

422
00:48:40,900 --> 00:48:47,260
And, you know, for years I was the statistical editor at one of the premier lung journals.

423
00:48:47,260 --> 00:48:50,469
And every time someone came to me with the cumulative incidence analysis,

424
00:48:50,470 --> 00:48:54,430
I sent them straight to the inverse weight method and say, Please don't do it.

425
00:48:54,430 --> 00:48:55,839
Just use this inverse weight stat.

426
00:48:55,840 --> 00:49:03,980
So at least in pulmonary disease, I think I've had an influence of steering away, so maybe the rest of you can steer other people away from this.

427
00:49:05,980 --> 00:49:09,730
Okay, so strategy one all cause mortality. Oh, wait.

428
00:49:09,940 --> 00:49:14,500
So I haven't given you a break. Before we dive in, let's take a ten minute break and come back.

429
00:49:14,530 --> 00:49:17,860
So at 9 a.m., we'll start up again.

430
00:49:40,750 --> 00:49:44,190
I'll do. Good. How are you?

431
00:49:44,610 --> 00:49:47,940
You want to show me over here? This is.

432
00:49:51,480 --> 00:49:57,160
Okay. Yes.

433
00:49:59,630 --> 00:50:05,350
I just. This is the real thing.

434
00:50:08,040 --> 00:50:18,310
It looks like you did it. Maybe.

435
00:50:27,010 --> 00:50:47,860
Scores were in their. So the way you get to The Matrix, I'm not sure that's addressing your question or not.

436
00:50:47,910 --> 00:50:50,980
Once you have the Matrix, you're doing it correctly. Okay. So.

437
00:50:52,090 --> 00:50:55,200
What is this? So how did you I guess.

438
00:50:55,210 --> 00:50:58,480
How did you decide the group's is.

439
00:50:59,020 --> 00:51:02,190
Yes. Okay. So they told me what was about.

440
00:51:03,590 --> 00:51:08,820
Although you're good. Okay. I feel very nervous about this because I don't want to.

441
00:51:09,840 --> 00:51:13,730
Yeah, but. And then my next question about was.

442
00:51:13,740 --> 00:51:19,380
Was about a continuity correction. Yeah. So I didn't teach the version with the continuity correction.

443
00:51:19,430 --> 00:51:22,960
Yeah, that's fine. Yeah, you should. So you can.

444
00:51:23,170 --> 00:51:26,640
I think there was, like, some option that you could set to false.

445
00:51:27,010 --> 00:51:33,330
Yeah, if you wanted to get rid of it. But I don't think it'll affect your site as much at all either way.

446
00:51:33,340 --> 00:51:37,370
Yeah, either way. It's significant in like these values of. Anyway.

447
00:51:37,370 --> 00:51:41,329
But is there one? Should I give them or you?

448
00:51:41,330 --> 00:51:45,170
She'll just choose one. Okay. I think it's okay to use the regular.

449
00:51:46,740 --> 00:51:55,000
I mean, the science is so the so the reason there's a continuity correction is that for us,

450
00:51:55,710 --> 00:51:59,820
there was an argument way back when that said that if you use the continuity correction,

451
00:52:00,090 --> 00:52:05,880
the Chi Square distribution that you're using to get your P values is slightly closer.

452
00:52:05,910 --> 00:52:13,010
Yeah. And but it's but scientifically, scientifically, it's been in nothing.

453
00:52:13,020 --> 00:52:16,760
So it's just used the regular formatting. Thank you.

454
00:52:16,770 --> 00:52:19,820
I like this is so this is the thing.

455
00:52:19,830 --> 00:52:27,120
This is another personality test, right? Because the person is looking at a .05 and a point of that and thinking that's really different.

456
00:52:27,120 --> 00:52:33,420
Thanks. We care about this. Yeah. But for me, I'm thinking that's nearly the same strength of evidence.

457
00:52:33,450 --> 00:52:40,190
I agree. So I don't care. No, I didn't.

458
00:52:40,410 --> 00:52:48,540
And I was like, wow, this is so I was I thought it was really cool because like, you can, you know how to do this, right?

459
00:52:48,540 --> 00:52:52,889
I was like, yeah, like where did this semester code for it?

460
00:52:52,890 --> 00:52:56,900
But um. Yeah also. A lot of pressure.

461
00:53:00,090 --> 00:53:05,610
Well. So the values are great. You just have to make sure you give the right words.

462
00:53:06,630 --> 00:53:10,320
Right. That's always the hard part is this part's the easy part.

463
00:53:11,790 --> 00:53:16,399
There's significant. What does it mean? Yeah. All right.

464
00:53:16,400 --> 00:58:49,360
Cool. Thank you. Yeah. Okay.

465
00:58:50,230 --> 00:58:57,240
Time to get back to work. I really enjoyed that break.

466
00:58:57,260 --> 00:59:04,129
I got a lot of stuff done. All right. So we're talking about this competing risk setting.

467
00:59:04,130 --> 00:59:13,700
And what can you do if you don't have all the cohorts available that you would like to use for the inverse proportional weight approach?

468
00:59:14,300 --> 00:59:18,709
So. Strategy. One was just to look at all cause mortality.

469
00:59:18,710 --> 00:59:26,470
So events from the competing risks that are of no research interests are rare compared to the one that you're interested in.

470
00:59:26,500 --> 00:59:33,590
Then a common approach is to analyze all, cause mortality and separately report the breakdown of types of death contributing to the analysis.

471
00:59:33,610 --> 00:59:44,499
So for instance, when I'm, you know, analyzing a data set and the main cause of death is the predominant cause,

472
00:59:44,500 --> 00:59:50,440
and there might but there might be a few people who had heart attack or something, but very, very small numbers.

473
00:59:50,980 --> 00:59:58,000
Then just an analysis of all cause mortality is going to get to the main point of the science I'm trying to do,

474
00:59:58,960 --> 01:00:02,500
and it fixes the problems associated with independence,

475
01:00:02,500 --> 01:00:08,380
since the combined outcomes should be independent of administrative censoring, which is the only censoring type that's left.

476
01:00:10,800 --> 01:00:14,640
But it can blur the interpretation of the main type of outcome being studied.

477
01:00:15,000 --> 01:00:18,540
If there are too many types of competing risks occurring in the data.

478
01:00:19,020 --> 01:00:21,450
So in the National Lung Cancer Screening trial,

479
01:00:21,600 --> 01:00:29,700
this was not an approach that we could do well because deaths from lung cancer and deaths from COPD were both large in large numbers.

480
01:00:30,420 --> 01:00:37,220
And you couldn't just look at all cause mortality and understand the causes relating to the separate types of death very well.

481
01:00:40,750 --> 01:00:46,809
So strategy too is to sensor the competing risk and then perform sensitivity

482
01:00:46,810 --> 01:00:52,600
analysis for how much the analysis can change under two different extremes.

483
01:00:53,140 --> 01:00:56,920
So the primary analysis was sent to the event at the time of the competing risks.

484
01:00:57,280 --> 01:01:04,030
So X is the time of competing risk and delta zero for people who have the competing event type you're not interested in.

485
01:01:05,350 --> 01:01:11,200
And then sensitivity analysis, one assumes that you're going to redo the analysis,

486
01:01:11,200 --> 01:01:16,150
assuming that the event of interest occurred at the same time as the competing event.

487
01:01:16,720 --> 01:01:23,860
So for instance, if you were trying to study lung cancer mortality and someone died of COPD,

488
01:01:24,730 --> 01:01:35,770
then this first sensitivity analysis could assume that the lung cancer event happened at the same exact time as the COPD event death.

489
01:01:36,670 --> 01:01:44,079
And you would so it's the worst case scenario is at the time they died of COPD, they would have died of lung cancer at the exact same time.

490
01:01:44,080 --> 01:01:51,370
And that's one extreme. And so you can see how much sensitivity analysis one changes your inference compared

491
01:01:51,370 --> 01:01:56,920
to the primary analysis where you just censored at the competing event time.

492
01:01:58,770 --> 01:02:01,980
So it's the same as all cause mortality. Really?

493
01:02:02,310 --> 01:02:07,440
It gives an upper bound of the risk associated with the competing risk that you're interested.

494
01:02:07,590 --> 01:02:10,220
That the event type that you're interested in.

495
01:02:12,140 --> 01:02:18,500
And so sensitivity analysis to assumes that the event of interest doesn't occur during follow up at all.

496
01:02:18,860 --> 01:02:23,660
So if they had an event, if they were interested in studying lung cancer mortality,

497
01:02:23,930 --> 01:02:35,930
someone dies from COPD is sort of unskilled them and assume that their lung cancer death would have never occurred right when they were.

498
01:02:35,960 --> 01:02:39,230
So this kind of overestimates survival by a lot.

499
01:02:39,650 --> 01:02:46,340
Say sort of saying that if they hadn't died from the competing risk, they would have just lived forever.

500
01:02:47,000 --> 01:02:51,020
And so, again, you kind of have a lower bound of risk in that case.

501
01:02:51,740 --> 01:02:57,080
And so between these two sensitivity analyzes, you've made the most extreme assumptions.

502
01:02:57,080 --> 01:03:00,350
They would have died right away when they were censored from the competing risk.

503
01:03:00,680 --> 01:03:04,880
Or they would have lived forever when they were censored by the competing risk.

504
01:03:05,330 --> 01:03:10,900
And so if you're the truth is somewhere between those two extremes.

505
01:03:10,910 --> 01:03:16,280
So if the results don't change much between the extremes and the primary analysis is probably okay.

506
01:03:21,400 --> 01:03:28,150
Otherwise, if the story does change a lot between these two different sensitivity analysis,

507
01:03:28,150 --> 01:03:35,620
then that gives a measure of the potential bias that could be affecting your analysis if the competing risks aren't independent.

508
01:03:36,590 --> 01:03:42,200
So it may be if you're competing, risks are independent.

509
01:03:42,200 --> 01:03:47,240
After you put your stuff in the Cox model, then the primary analysis is supposed to be okay anyway.

510
01:03:49,410 --> 01:03:58,170
But if you're not sure, these two extremes kind of help you get a sense of what potential bias could

511
01:03:58,170 --> 01:04:02,940
be there if you still had some dependance between your competing risk events.

512
01:04:03,890 --> 01:04:11,200
Conditional on the cover. It's in your cocks model. Okay.

513
01:04:11,200 --> 01:04:17,770
Strategy three when you have competing events is to do something called a cumulative incidence function analysis.

514
01:04:18,400 --> 01:04:25,450
And I'm going to try to tell you about this analysis and when it's useful and when it's not useful.

515
01:04:26,170 --> 01:04:35,350
And so this is kind of a perk up moment kind of a thing that I hope that it sticks with you, that it's not a great analysis to do.

516
01:04:36,400 --> 01:04:41,170
So the cumulative incidence function estimates the probability that the event of interest

517
01:04:41,170 --> 01:04:48,580
occurs before time T and that it occurs before any of the competing causes of failure.

518
01:04:49,930 --> 01:04:53,950
And so if the sentence ended before all the yellow stuff,

519
01:04:54,400 --> 01:04:59,110
I would be super interested in this function because I would want to know the

520
01:04:59,110 --> 01:05:04,899
cumulative incidence of the probability that the event of interest occurs before time.

521
01:05:04,900 --> 01:05:08,620
T That would be super cool and interesting to interpret.

522
01:05:09,130 --> 01:05:13,060
The second part ruins it for me though, because it's also modeling.

523
01:05:13,480 --> 01:05:18,190
At the same time, this joint probability that occurs before you see any of the other causes of failure,

524
01:05:18,490 --> 01:05:25,390
that makes it very difficult to interpret this function and compare it for different coverage profiles.

525
01:05:28,310 --> 01:05:34,010
So this is just the definition of the cumulative incidence function.

526
01:05:34,010 --> 01:05:41,860
It involves a kaplan-meier estimate. And it involves a proportion here.

527
01:05:41,890 --> 01:05:50,410
So what are these? What are these notation things? So t i equals one through k are distinct times when one of the competing risks occurs.

528
01:05:50,650 --> 01:06:00,430
So you're all of the different types of competing risk and the times that they happen, they're all being summed over all of those unique times.

529
01:06:00,940 --> 01:06:07,600
And then this as hat t minus is the kaplan-meier estimated value estimate or evaluate just before t i.

530
01:06:08,540 --> 01:06:14,930
When you treat the competing risks, all of them as events or all cause mortality.

531
01:06:18,550 --> 01:06:24,100
And Little aura is the number of subjects with an occurrence of the event of interest at time tie.

532
01:06:24,580 --> 01:06:36,040
So this proportion here is trying to get at, you know, splitting up the overall all cause mortality kind of into the different event types here.

533
01:06:36,310 --> 01:06:42,580
And why is the number of subjects that are at risk at that little time tie.

534
01:06:46,850 --> 01:06:55,100
So just to kind of get a sense of what these curves look like and how to interpret them, let's look at a one sample analysis example.

535
01:06:55,490 --> 01:07:01,760
And so this is taken from a textbook by Klein in Moche Berger, a bone marrow transplant for leukemia, data set.

536
01:07:02,480 --> 01:07:09,850
And so the treatment failure is death and either remission or relapse, whichever comes first.

537
01:07:09,860 --> 01:07:17,120
You only have one death that you get to observe, right? Either happened when they were in remission or when they were in relapse.

538
01:07:18,570 --> 01:07:23,130
And so here's kind of a graphic of what these cumulative incidence functions look like.

539
01:07:23,700 --> 01:07:33,660
So the. Solid black line is this cumulative incidence function for death and remission.

540
01:07:34,850 --> 01:07:43,999
So what does that mean? So it's the probability that you observe a death in remission at each time in days post-transplant,

541
01:07:44,000 --> 01:07:49,070
and that you saw that type of death before you would have been able to see a death and relapse.

542
01:07:50,130 --> 01:07:53,370
So the latter part of the phrase makes it really hard to interpret. Right.

543
01:07:54,800 --> 01:07:57,800
Uh. So what if they don't?

544
01:07:58,280 --> 01:08:02,960
So what if they don't have a death while they're in remission?

545
01:08:02,990 --> 01:08:11,399
Well. Then. There's another way they could die or they could live entirely.

546
01:08:11,400 --> 01:08:15,720
Right. So the red dashed line is the cumulative incidence.

547
01:08:16,730 --> 01:08:23,780
Of deaths in relapse. So it's a probability at each day post-transplant that you have a death.

548
01:08:24,820 --> 01:08:33,070
While the patients in relapse and that that was an event that happened before a death in remission could have happened.

549
01:08:34,220 --> 01:08:37,370
So again, it's everything after the end makes it hard to interpret.

550
01:08:37,970 --> 01:08:48,980
So if you have any person in this black curve that doesn't die in remission, they're immediately possibly, you know,

551
01:08:49,040 --> 01:08:54,170
possibly going to appear in this red curve, but otherwise they wouldn't have appeared in the red curve at all.

552
01:08:56,100 --> 01:09:04,620
Right. So any individual data point, if you change their cause of death there, that data point can affect both curves.

553
01:09:05,430 --> 01:09:10,620
It can lower this curve and increase the other curve if they end up having the death of the other type instead.

554
01:09:13,270 --> 01:09:19,210
So you can imagine if the time to death in remission and in times to death and relapse are very correlated.

555
01:09:19,750 --> 01:09:24,370
Like if they're almost the same, you know, and you remove one,

556
01:09:25,840 --> 01:09:33,430
they just there imagine death and relapse and death in remission, more like a day or a part or something.

557
01:09:33,760 --> 01:09:37,389
Then that one day affects which curve that person is in.

558
01:09:37,390 --> 01:09:42,460
And it's going to increase the curve that the event happened for the event type that that it happened in.

559
01:09:42,850 --> 01:09:47,140
And it'll it'll mean that that other competing curve is.

560
01:09:48,330 --> 01:09:52,400
Lower. All right.

561
01:09:53,750 --> 01:09:59,600
So fun fact, if you sum these curves at each of the time points, you know.

562
01:09:59,600 --> 01:10:07,819
So all of the heights were summed together for the red dash and the black solid that actually it's

563
01:10:07,820 --> 01:10:12,590
going to be algebraically equal to one minus the kaplan-meier curve for all cause mortality.

564
01:10:13,190 --> 01:10:18,380
So it really is trying to just split up one minus the kaplan-meier curve into these two groups.

565
01:10:19,610 --> 01:10:24,020
It's very but it's very hard to interpret the individual lines.

566
01:10:24,350 --> 01:10:35,660
So when do I use this? I will use a graphic like this when I'm trying to describe just the death types in a paper that we're seeing.

567
01:10:36,200 --> 01:10:47,950
So in other words. It's very, very attractive for someone to say, I observed this many deaths in remission and this many deaths and relapse.

568
01:10:48,220 --> 01:10:53,320
That's just a count. Or this graphic is slightly more information than those counts.

569
01:10:55,030 --> 01:10:59,319
So I might include the graphic just so they can sort of see what was the observed data?

570
01:10:59,320 --> 01:11:03,149
What did it look like? Doing further inference.

571
01:11:03,150 --> 01:11:06,720
Beyond that, I discourage. So.

572
01:11:07,140 --> 01:11:10,590
So let's. Let's see why I feel that way.

573
01:11:10,740 --> 01:11:16,230
Here's an example where you're trying to compare two different types of patients.

574
01:11:16,470 --> 01:11:23,590
So two sample comparisons. So this is a different data set, but related, you know, it's similar in style.

575
01:11:23,620 --> 01:11:29,519
So 35 acute leukemia patients underwent hematopoietic stem cell transplantation.

576
01:11:29,520 --> 01:11:38,140
I'm sure I'm mispronouncing that. And the competing risk events were either death from relapse of the original disease,

577
01:11:38,230 --> 01:11:45,760
which I'm calling Oreo and death from transplant related mortality, which I'm calling Terim.

578
01:11:48,350 --> 01:11:52,310
All right. So again, you could you can only die once.

579
01:11:52,550 --> 01:12:00,110
So each person, you only observe one. Event time and that death either happened.

580
01:12:01,630 --> 01:12:07,750
While they were in, you know, relapse of the original disease or related to transplant related mortality.

581
01:12:07,750 --> 01:12:15,040
And so they have a way to designate that. And so the variables in the data set are the follow up time and months of time.

582
01:12:16,050 --> 01:12:20,950
The status. So we have a censoring potential here.

583
01:12:20,950 --> 01:12:24,179
If they didn't die from either cause, if they were alive at the end.

584
01:12:24,180 --> 01:12:29,549
We have a censoring indicator, but we have two different indicators for death.

585
01:12:29,550 --> 01:12:35,640
Depending on what kind of death it was, the relapse related or the transplant related mortality to death.

586
01:12:36,860 --> 01:12:45,170
And we now have a covariant disease, which is the type of leukemia and Miller ALS.

587
01:12:46,980 --> 01:12:57,629
And so this is now we want to compare what's going on in these groups and understand more about when you have this type of leukemia,

588
01:12:57,630 --> 01:13:00,750
you know, versus this other type of leukemia.

589
01:13:00,750 --> 01:13:08,719
What what does your death look like? So there's a lot here.

590
01:13:08,720 --> 01:13:15,560
We're going to unpack this slowly. This is a very busy plot. And if you really have to kind of stare at it to understand what's going on.

591
01:13:16,370 --> 01:13:19,820
But they're going to be four cumulative incidence curves here.

592
01:13:20,780 --> 01:13:26,720
So there's two different groups of types of leukemia, the AML.

593
01:13:27,770 --> 01:13:38,570
And each of those groups has a cumulative incentive curve related to death while in relapse or death from transplant related causes.

594
01:13:39,470 --> 01:13:44,900
All right. So two types of death. Two groups ends up with four curves.

595
01:13:46,470 --> 01:13:52,590
And so let's find these curves so that we can at least start to try to understand what's happening here.

596
01:13:52,890 --> 01:13:58,160
So the biggest the highest curve here. Is death.

597
01:13:59,420 --> 01:14:02,840
From Relapse for the Alamo Group.

598
01:14:03,740 --> 01:14:15,460
All right. So that's this one here. And the other type of death for the whole group is this very bottom, solid curve here.

599
01:14:15,490 --> 01:14:19,210
So this is the transplant related mortality over here.

600
01:14:19,900 --> 01:14:24,570
So not many of those were observed. In this dataset.

601
01:14:24,840 --> 01:14:31,130
All right, so that's the l l. Event types.

602
01:14:31,910 --> 01:14:39,830
Those two solid curves. And then the two dashed curves are for the AML leukemia type.

603
01:14:39,840 --> 01:14:45,500
So in this group. Transplant related mortality was much.

604
01:14:46,630 --> 01:14:51,580
More commonly observed. So it actually is the higher of the two death types.

605
01:14:52,960 --> 01:14:58,030
And the events in relapse were were lower.

606
01:15:00,490 --> 01:15:07,010
All right. So the two dashed curves are kind of. Now closer together.

607
01:15:07,400 --> 01:15:13,639
So. That's the overall picture of the curves.

608
01:15:13,640 --> 01:15:17,170
And so, you know, people want to interpret what's going on here.

609
01:15:17,180 --> 01:15:20,440
So if you're trying to understand. The.

610
01:15:22,310 --> 01:15:30,560
Transplant related mortality events for the two groups and you want to compare them then your I would try to find this.

611
01:15:32,950 --> 01:15:35,440
Red bracket kind of comparison.

612
01:15:35,480 --> 01:15:43,510
So the top one is for transplant related mortality for AML, and the bottom one is the transplant related mortality for Aiello.

613
01:15:44,200 --> 01:15:51,130
And there is a statistic that will compare those curves for you and tell you whether they are significantly different from one another.

614
01:15:51,400 --> 01:15:57,690
And here's the p value for it. We need to think about what we can learn from that in a minute.

615
01:15:57,700 --> 01:16:03,429
But no matter what the package is, we'll give you p value saying if these curves are statistically different or not,

616
01:16:03,430 --> 01:16:06,880
whether that makes any sense, interpreting it later is another question.

617
01:16:08,200 --> 01:16:12,100
Right. And so similarly, if you look at the relapse events.

618
01:16:13,820 --> 01:16:19,070
We're looking at the purple bracket now. So for the AOL group.

619
01:16:20,170 --> 01:16:23,290
That was the most events that were observed in this dataset. Right.

620
01:16:23,800 --> 01:16:27,280
And so that's this top curve. And then the.

621
01:16:28,360 --> 01:16:38,079
For the small group, that same event type of death and relapses over here so that that purple distance is much bigger right than the red difference.

622
01:16:38,080 --> 01:16:45,100
And so for death and relapse, there is a statistically significant difference between those two curves.

623
01:16:46,140 --> 01:16:54,540
.0.008. And so what we have to do next is and see if that helps us understand this disease any better or not.

624
01:16:55,560 --> 01:16:58,560
So I want us to think about this together.

625
01:17:02,310 --> 01:17:08,400
So I have notes on the following slide. So you're going to everything I say is going to be repeated on the next few slides.

626
01:17:08,400 --> 01:17:20,219
But one feature that makes this very difficult to interpret from my point of view is that for any if you focus on one of the types of leukemia,

627
01:17:20,220 --> 01:17:24,020
say, AOL. I.

628
01:17:25,670 --> 01:17:37,580
For a little more relapse. Events were observed and if they had a relapse event observed and it was the first to be observed.

629
01:17:38,660 --> 01:17:40,640
You know, that's this probability here,

630
01:17:41,540 --> 01:17:52,970
which means and any person who appears with an event in this top curve cannot possibly be observed in this bottom solid curve there.

631
01:17:53,240 --> 01:17:59,990
They weren't at risk for having that transplant related event first.

632
01:18:01,210 --> 01:18:05,850
That doesn't mean that they weren't susceptible to having transplant related mortality.

633
01:18:05,860 --> 01:18:11,680
It just means that of the two events where the relapse events tended to be.

634
01:18:13,670 --> 01:18:19,220
A, you know, happening and observed prior to any transplant related mortality event.

635
01:18:21,700 --> 01:18:27,709
Okay. So. So that's kind of fact.

636
01:18:27,710 --> 01:18:32,390
One, the relapse curve is on top for the AML group. For the AML group.

637
01:18:33,610 --> 01:18:38,720
That direction switches. So now for the AML group.

638
01:18:39,800 --> 01:18:47,600
There are many more transplant related mortality events that happen and happen before the relapse event is observed.

639
01:18:48,870 --> 01:18:56,070
Okay. So for ALO, the relapse is more observed early on.

640
01:18:57,290 --> 01:19:03,560
You know, and for the AML, the transplant really mortality is observed.

641
01:19:05,610 --> 01:19:07,290
First more often.

642
01:19:09,660 --> 01:19:22,140
And remember how I said that any one person, if you remove if their event times were so correlated that it was like a tie maybe by a day.

643
01:19:22,710 --> 01:19:26,260
Then one day difference could move.

644
01:19:26,280 --> 01:19:37,090
Both of those curves. So if, say, a transplant related mortality hadn't happened, this curve would go down.

645
01:19:37,300 --> 01:19:44,290
And if they were really, really correlated so that the relapse happened instead, this other curve would go up.

646
01:19:46,900 --> 01:19:55,990
So correlated events, moving one person from either curve can kind of move them closer together.

647
01:19:59,760 --> 01:20:10,319
And so similarly for these black curves, you had so many relapse related mortality events happening quickly.

648
01:20:10,320 --> 01:20:18,240
If that was very correlated to having a transplant related mortality event, we wouldn't be able to see them because these happened first.

649
01:20:21,340 --> 01:20:28,389
And so it might be very well the case that there's a high risk for transplant related mortality in the AML group,

650
01:20:28,390 --> 01:20:31,480
but we don't get to see it if we see the relapse first.

651
01:20:33,140 --> 01:20:39,920
Because again, these are the probabilities that you see that type of event and it's the, first of all, the competing risks to be seen.

652
01:20:41,510 --> 01:20:48,440
So this high event rate for mortality and relapse could be masking a high risk of transplant,

653
01:20:48,440 --> 01:20:51,950
really mortality that you don't get to see because the relapse happened first.

654
01:20:57,830 --> 01:21:02,220
So. If so, how do we deal with this?

655
01:21:02,240 --> 01:21:06,620
I mean, it it makes it very hard to interpret these curves.

656
01:21:06,620 --> 01:21:10,970
Right. So when you look at this peak was 0.008.

657
01:21:12,060 --> 01:21:15,510
For the relapse related deaths. This difference in the purple curves.

658
01:21:16,020 --> 01:21:21,380
Is that different? So big. Because, you know.

659
01:21:23,300 --> 01:21:36,140
Relapse. How much of a shift would it have taken to have the the a little relapse events become a treatment transplant where they mortality events.

660
01:21:36,150 --> 01:21:41,490
Right if they're very highly correlated then these.

661
01:21:42,780 --> 01:21:48,780
This difference is really quite fuzzy to understand.

662
01:21:52,530 --> 01:22:00,509
It could be that they're not having as many events in this AML relapse group because they had many more

663
01:22:00,510 --> 01:22:05,010
transplant related mortality groups that masked possible events that could have been observed here.

664
01:22:06,560 --> 01:22:12,799
So the fact that this treatment related mortality for the AML group is higher might mean

665
01:22:12,800 --> 01:22:17,450
that we're masking some real risk here that would have moved this purple bracket lower,

666
01:22:17,450 --> 01:22:24,340
bound higher and removed the. Remove this p value from being an interesting story.

667
01:22:28,090 --> 01:22:32,920
And if your brain is and is twisting itself trying to understand these arguments,

668
01:22:33,610 --> 01:22:38,110
then you're in the right place because it is hard to understand this.

669
01:22:38,440 --> 01:22:45,850
It's very difficult to interpret these curves because of the and it's the first type of event to be seen.

670
01:22:46,090 --> 01:22:49,690
Part of. Part of the probability you're looking at.

671
01:22:51,280 --> 01:22:56,639
And so here are some. Here are the notes now, so you'll hear the same ideas again.

672
01:22:56,640 --> 01:22:58,350
But now it's written down for you.

673
01:22:58,860 --> 01:23:09,120
So the P equals point to five with a statistic, you know, comparing the transplant related mortality groups for the different types of leukemia.

674
01:23:10,860 --> 01:23:15,749
And so there was no significant difference observed in those cumulative incidence

675
01:23:15,750 --> 01:23:20,340
functions for transplanted related mortality between the AML and the ALO groups.

676
01:23:21,000 --> 01:23:25,829
And you know, it might be low power because there were few transplant related mortality events.

677
01:23:25,830 --> 01:23:29,580
So, you know, the the read differences.

678
01:23:29,700 --> 01:23:32,160
There were there were differences. Maybe it was low power.

679
01:23:32,170 --> 01:23:38,040
But I don't want to get too bogged down in that idea, since I don't think it's easier to interpret these curves anyway.

680
01:23:39,560 --> 01:23:44,630
And in this kind of looking at the transplant related mortality,

681
01:23:45,020 --> 01:23:50,630
the AOL cumulative incidence function was below the AML human events, its function in the plot.

682
01:23:51,230 --> 01:23:54,440
Right. That was the difference that you saw.

683
01:23:55,460 --> 01:24:01,190
And when you were looking at the relapse mortality events, we saw this really significant difference,

684
01:24:01,190 --> 01:24:06,080
the purple bracket difference, comparing the groups in terms of time to relapse.

685
01:24:06,860 --> 01:24:12,620
And so there was a significant difference in those cumulative incidence functions between the AML, AOL groups.

686
01:24:14,820 --> 01:24:22,890
But the direction switch. So the AML cumulative incidence function was below the AOL cumulative incidence function in the plot.

687
01:24:27,140 --> 01:24:39,170
Now if they had all been ordered in the same way. So if mortality was always higher in the AML group, regardless of the type of mortality,

688
01:24:39,680 --> 01:24:45,650
I would be slightly better able to think about the interpretation in that case.

689
01:24:46,070 --> 01:24:51,590
But this the switching of the order of the events, if those events are correlated,

690
01:24:51,590 --> 01:24:54,740
that makes it very difficult for me to make any sense of what's going on.

691
01:24:56,320 --> 01:25:03,549
So recall that the cumulative incidence function estimates the probably at the event of interest

692
01:25:03,550 --> 01:25:09,460
occurs before time t and that it occurs before any of the competing causes of failure.

693
01:25:11,000 --> 01:25:19,880
So change in one person's data affects both the T transplant related mortality and the relapse related mortality curves.

694
01:25:19,970 --> 01:25:28,880
One person's data changes both curves, and if they're correlated, it's pushing the curves closer together when one hops from one curve to the other.

695
01:25:33,720 --> 01:25:41,850
Early transplant related mortality for a patient means the patient won't experience a relapse of the original disease later on.

696
01:25:44,780 --> 01:25:49,669
And it's possible that a person who had transplant related mortality also had a higher risk of the

697
01:25:49,670 --> 01:25:55,790
relapse that went unobserved just because they had the transplant related mortality event first.

698
01:25:56,540 --> 01:26:03,770
And that so that higher risk of death and relapse is not being reflected in that curve, that cumulative incidence curve for relapse.

699
01:26:07,920 --> 01:26:17,520
So in the plot, the direction of the different switches, the AML curve is higher for tier EM and lower for RL, so it would be easier to interpret.

700
01:26:17,520 --> 01:26:20,940
The results of the ordering remain the same as for both types of events.

701
01:26:21,330 --> 01:26:27,630
Then you could make some statement that, you know, this type of leukemia seems to be worse overall for everything.

702
01:26:27,990 --> 01:26:35,490
But with the switching, I can't really figure out. What what's going on at all?

703
01:26:37,450 --> 01:26:45,880
So the conclusion to this part, to this handout, is that it's a competing versus a thorny problem that's difficult to negotiate.

704
01:26:47,110 --> 01:26:55,190
And if covariate information is available that captures dependance between censoring and event times, then the inverse probability way.

705
01:26:55,210 --> 01:26:57,520
COX Regression is an appropriate analysis.

706
01:26:57,910 --> 01:27:06,549
And the key is you have to have these covariates measured over time that can be used to adjust for dependent censoring or just for,

707
01:27:06,550 --> 01:27:11,380
you know, whatever that censoring is, including the competing risk as a dependent censoring.

708
01:27:16,930 --> 01:27:21,910
There's lots of inverse probability weighting methods out there.

709
01:27:22,060 --> 01:27:27,310
One that you mentioned that you learned in 600 for correcting sampling weights.

710
01:27:27,310 --> 01:27:33,300
But there's other methods that are making their way into software packages as well.

711
01:27:33,310 --> 01:27:41,460
So for instance, mixed models with an inverse probability way is in the future going to be something you can do?

712
01:27:41,470 --> 01:27:46,150
I just haven't googled lately to see if that package is out there and easy to use,

713
01:27:46,540 --> 01:27:49,929
but I hope it is because I need a research assistant to figure that out.

714
01:27:49,930 --> 01:27:53,260
If that's the case, because we have an analysis that could use that trick.

715
01:27:53,980 --> 01:28:00,340
So these methods are going to, as you grow into your field, they're going to become more and more available.

716
01:28:00,340 --> 01:28:05,980
And I really like these methods for fixing problems of this nature.

717
01:28:06,070 --> 01:28:16,300
So look for them. If people if you're missing data over time is related to covariance, these inverse probability weights are very helpful.

718
01:28:18,950 --> 01:28:25,280
But if you don't have the covariance over time, measure that you can use to correct your analysis.

719
01:28:25,760 --> 01:28:34,420
Analysis options are limited. You know, we have the sensitivity analysis, we have the give up and go to all cause mortality analysis.

720
01:28:36,070 --> 01:28:42,700
And then we have this cumulative instance function analysis that I'm really trying to steer away from because I think you can you can

721
01:28:42,700 --> 01:28:52,000
actually put in put stories out there that are incorrect if you try to interpret something that really can't be interpreted well.

722
01:28:55,700 --> 01:28:59,029
All right. So that is all that I wanted to cover today.

723
01:28:59,030 --> 01:29:02,060
So I'm happy to stop here.

724
01:29:02,630 --> 01:29:06,440
Just as a preview of what's coming in the next handout.

725
01:29:07,460 --> 01:29:13,730
Actually, I'm going to just chop hand 19 and make this rest of the handout.

726
01:29:13,730 --> 01:29:17,260
Handout 20. I want to do that after class. Just I think it'll be neat her.

727
01:29:18,470 --> 01:29:23,000
It's related because you have dependent outcomes again with times to event.

728
01:29:23,660 --> 01:29:30,320
But this time we're not going to be dealing with competing risks where you only get to see one event type.

729
01:29:31,430 --> 01:29:40,700
In this next section of the course, this next handout, I'm going to be looking at outcomes that are all potentially observable.

730
01:29:41,150 --> 01:29:49,040
So you have maybe paired times two event or cluster times two event, and they're all subject to an independent sensory mechanism.

731
01:29:49,610 --> 01:30:01,190
So the what are examples of this? So one example of this that I have come in to a lot is studies of patients who have diabetic retinopathy.

732
01:30:02,810 --> 01:30:10,190
And so if you have diabetes, a lot of people kind of fall into this situation where they get diabetic retinopathy.

733
01:30:10,460 --> 01:30:14,690
And so it can affect both of their eyes, but it can affect them at different rates.

734
01:30:14,690 --> 01:30:18,410
There's all kinds of variability of the vision in each eye that can change over time.

735
01:30:18,860 --> 01:30:23,840
And so the time to event that people measure in these studies is time to severe vision loss,

736
01:30:24,860 --> 01:30:31,100
and there's time to severe vision loss in the left eye, time to severe vision loss on the right eye right.

737
01:30:31,970 --> 01:30:36,440
And so a lot of clinical trials for diabetic retinopathy will randomize one eye

738
01:30:36,470 --> 01:30:41,480
to one approach for therapy and the other eye to the alternative approach.

739
01:30:41,930 --> 01:30:48,890
So there's lots of datasets that involve diabetic retinopathy where they're treating each eye separately in a randomized clinical trial.

740
01:30:49,370 --> 01:30:52,100
So you can imagine that within a person,

741
01:30:52,430 --> 01:31:03,530
the deterioration at the time of randomization is very correlated to the time to severe vision loss in the same person's eyes.

742
01:31:04,190 --> 01:31:11,000
Those are going to be very, very correlated. Some people are more advanced in their diabetic retinopathy than others, for example.

743
01:31:11,810 --> 01:31:19,940
And so there's dependance in the outcomes where we couldn't just use a Cox analysis and get the right P values and so on,

744
01:31:19,940 --> 01:31:26,360
because there are these times to better correlate and we've learned we need to account for that in our analyzes or we get the wrong P values.

745
01:31:27,020 --> 01:31:33,209
So that's one example. Of correlated, dependent outcomes that we're going to talk about.

746
01:31:33,210 --> 01:31:40,800
And so when I talk about paired dependent outcomes, cluster dependent outcomes,

747
01:31:41,910 --> 01:31:46,870
and how to analyze these and try to take you through like paired log ranked,

748
01:31:46,870 --> 01:31:57,210
test paired, restricted mean tests paired or cluster to regression and so that you can deal with this when it comes across your desk.

749
01:31:58,700 --> 01:32:07,950
All right. Okay. So I'm going to go ahead and stop there and I will stick around if you have any

750
01:32:07,950 --> 01:32:12,000
questions about your homework or anything else that you want to come up and talk about.

751
01:32:12,390 --> 01:32:17,550
Happy to give this time to you to do that. But I'll stop the recording.

