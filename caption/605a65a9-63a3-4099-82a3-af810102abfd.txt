1
00:00:00,410 --> 00:00:04,890
And suddenly it started. Welcome to your first day.

2
00:00:06,840 --> 00:00:13,590
Half of you in one place. And the other opinion for today is we're going to talk.

3
00:00:13,610 --> 00:00:17,820
So the end of last class we went over structured report.

4
00:00:18,780 --> 00:00:25,620
We're going to start with what you're going to do for Project One, which will be like a little bit different from a report.

5
00:00:25,620 --> 00:00:30,420
Hopefully the connection is clear if we were successful in that.

6
00:00:30,900 --> 00:00:42,270
So we'll go over that a little bit here and then we will do some content about how to collaborate and some content about transformations.

7
00:00:43,530 --> 00:00:54,630
So for Project one, so if you go to the project one page, you'll see deconstructed report questions that you can download in two formats.

8
00:00:55,440 --> 00:01:00,719
So if you download that, you've got is this document.

9
00:01:00,720 --> 00:01:10,620
So this is sort of your deliverable for project one is that you will go through this document and answer these questions for Project one.

10
00:01:10,950 --> 00:01:18,089
The goal of this was to sort of take the report form and break it up into a bunch

11
00:01:18,090 --> 00:01:22,440
of individual pieces for the first project so that you can go through and like,

12
00:01:22,920 --> 00:01:26,760
you know, that you got the important information and if you answer all the questions.

13
00:01:27,090 --> 00:01:37,590
So the other sort of idea with to having the first project in question for me is potentially this will be something if you find this useful,

14
00:01:37,590 --> 00:01:44,370
you can look back at this in project two, three, four when I'm writing a full report and you can check,

15
00:01:44,370 --> 00:01:48,900
oh, did I answer question six in here somewhere. Did I put that in the right section.

16
00:01:49,200 --> 00:01:55,770
So the idea is to make it so there's some sense in which like a 699 report is like a formula.

17
00:01:55,830 --> 00:01:59,310
If you know the formula, you plug stuff in and you'll get a good report.

18
00:01:59,520 --> 00:02:03,660
So this was sort of hopefully to make it that formula transparent.

19
00:02:03,780 --> 00:02:07,380
That's sort of the goal of this process.

20
00:02:07,830 --> 00:02:21,300
So I'll walk through this a little bit. I'm like, the questions should correspond to the sections that we went through in the lecture on Tuesday.

21
00:02:21,450 --> 00:02:27,629
Today's Thursday, we talked about that on Tuesday, and we can go back to that if there's questions here.

22
00:02:27,630 --> 00:02:33,360
So I'll just go through this sort of in an abbreviated way in the background introduction.

23
00:02:33,570 --> 00:02:36,629
This is sort of following that inverted triangle form.

24
00:02:36,630 --> 00:02:39,720
So what's the general topic? Why is the topic important?

25
00:02:41,640 --> 00:02:44,940
What is the research gap? That's the focus of the report.

26
00:02:45,750 --> 00:02:48,870
Why is the research gap relevant and interesting?

27
00:02:48,870 --> 00:02:56,849
And then number five is sort of the guiding light for the rest of your report,

28
00:02:56,850 --> 00:03:00,390
which is what are the specific questions that you want to answer in this report?

29
00:03:00,720 --> 00:03:08,400
And then you're going to number these because you're going to come back to them. They're going to keep coming up in the in the question.

30
00:03:08,410 --> 00:03:16,320
So then you have your methods questions. I'm going to start with describing the study design, the same sort of who, what, when, where, how, topics.

31
00:03:18,840 --> 00:03:23,640
Question seven just asked you to make a table one. Oh, no, it asked you how you're going to make a table one.

32
00:03:23,910 --> 00:03:28,980
So what variables do you want to put in your table one Are there things that you're going to split table one on,

33
00:03:29,250 --> 00:03:37,530
like we saw before, question eight asks you about missing data and what you want to do about the missing data.

34
00:03:37,530 --> 00:03:41,280
So question eight is in here partly as a clue.

35
00:03:41,280 --> 00:03:45,750
We sort of always want you to think about missing data and what you're going to do with it.

36
00:03:47,370 --> 00:03:52,620
And then Question nine is sort of the biggie Oh, these parentheses are points.

37
00:03:52,680 --> 00:03:59,640
So these should all add up to 15, which is corresponds to in the syllabus.

38
00:04:03,670 --> 00:04:08,980
In the syllabus, there's this like breakdown of how many points go with each section,

39
00:04:09,310 --> 00:04:14,820
and these add up to 50, and then you get 100 because two of us, two of your professors will do this.

40
00:04:14,830 --> 00:04:19,360
So two same deal. Two of us will grade this form.

41
00:04:19,690 --> 00:04:24,460
These are sort of the approximate. They're not approximate. These are the points that we'll use for these questions.

42
00:04:26,290 --> 00:04:31,190
So they should correspond to the. So the syllabus pretty well.

43
00:04:31,670 --> 00:04:36,560
So question nine is sort of the big mÃ©thodes question. This is in question nine you're going to describe.

44
00:04:37,680 --> 00:04:41,220
How you're going to answer the questions with statistical methods.

45
00:04:43,230 --> 00:04:50,190
The reason that there's a lot of words in the phrasing of Question nine is that we wanted to

46
00:04:50,370 --> 00:04:56,350
guide you through how to describe a method without fencing you into a particular type of method.

47
00:04:56,370 --> 00:05:05,130
So we laid out these questions eight through H that are a little bit geared towards a regression model.

48
00:05:05,310 --> 00:05:07,350
But if you're not doing a regression model,

49
00:05:07,530 --> 00:05:15,089
your idea is you should have you should be able to answer similar information for your non regression models.

50
00:05:15,090 --> 00:05:19,440
So I gave an example of these questions.

51
00:05:19,440 --> 00:05:27,920
I'll just go through them. Start with what is the outcome in primary exposure for let's say I'm trying to answer you.

52
00:05:27,940 --> 00:05:30,780
I think the thing to do is an example before we go back through.

53
00:05:31,020 --> 00:05:39,659
So if you keep scrolling after the six questions in the main part, there are two examples in this document.

54
00:05:39,660 --> 00:05:45,459
So I took two example reports, this one and this one.

55
00:05:45,460 --> 00:05:53,490
And actually I think one of these links is broken and I didn't fix it, but I think the links are unbroken in lectures so we can go and see.

56
00:06:00,570 --> 00:06:03,960
So this is the report that I took.

57
00:06:03,990 --> 00:06:11,639
Answers in purple out of. So and I tried to be clear about where they were coming from.

58
00:06:11,640 --> 00:06:22,000
So in background, this report is about an intrauterine growth restriction and dietary quality.

59
00:06:22,020 --> 00:06:28,409
So they have a study of pregnant women in Mexico City and they're asking them these questions about the things that they eat.

60
00:06:28,410 --> 00:06:37,050
And then they also are measuring like the femur length and the head circumference and stuff of that, the fetus.

61
00:06:37,440 --> 00:06:46,739
So I'm not going to go through all of this because I think you might be better served by looking at the report and going through it yourself.

62
00:06:46,740 --> 00:06:52,320
And it is a little bit boring to get straight into the details of the intrauterine growth restriction.

63
00:06:52,590 --> 00:06:59,069
But you'll be able to see that like a lot of these either like copied and pasted out of the report.

64
00:06:59,070 --> 00:07:05,760
So you could go the other way, right? If you said what specific topic or research gap am I going to focus on?

65
00:07:06,000 --> 00:07:10,510
And we have the research gap is to assess the relationship between maternal dietary quality.

66
00:07:10,510 --> 00:07:15,120
And so that's going to be the focusing principle of this report.

67
00:07:15,570 --> 00:07:18,959
And then for this report, I had two questions under five.

68
00:07:18,960 --> 00:07:23,520
So is fetal growth in utero associated with maternal dietary quality?

69
00:07:23,520 --> 00:07:29,580
And does pre gestational BMI modify this association? You all might have.

70
00:07:31,540 --> 00:07:38,080
This might be questions that correspond to the last slide of Tom's presentation for you guys.

71
00:07:38,770 --> 00:07:47,950
So if we look at five and then we come down to question nine, which is asking us about the methods that we're going to use to address these problems.

72
00:07:48,580 --> 00:07:52,390
Question nine is going to have one section for each of the questions in five.

73
00:07:52,780 --> 00:07:58,120
So because we have two questions in five, we're going to answer question nine twice, once for question one and once.

74
00:07:58,390 --> 00:08:01,450
Question two If it was three, it would be three, etc.

75
00:08:01,570 --> 00:08:03,200
And these answers are going to be long, right?

76
00:08:03,220 --> 00:08:10,000
There's a lot of information in Question nine because if you're going to describe the whole model in Question nine,

77
00:08:10,010 --> 00:08:16,659
so I think there maybe it can be an allusion in that like, oh, it's just 16 questions.

78
00:08:16,660 --> 00:08:18,700
This is sort of like a short answer assignment.

79
00:08:19,720 --> 00:08:28,480
Your output is going to be about the length of a report, but just in the format of answering 16 questions.

80
00:08:28,720 --> 00:08:35,470
So in question nine, we have these parts A through H, so we what is the outcome in primary exposure of interest?

81
00:08:35,470 --> 00:08:40,390
So in this first question, is fetal growth in utero associated with maternal dietary quality?

82
00:08:40,540 --> 00:08:44,260
I copied it down so that it would be convenient to check back.

83
00:08:44,620 --> 00:08:52,719
So we have the outcomes are fetal ultrasound measurement and then we're specific about what those are and then the exposures are empty.

84
00:08:52,720 --> 00:08:56,350
Q Subcategories. I was pretty abbreviated with that answer.

85
00:08:57,580 --> 00:09:02,170
And then our second question what other covariates are important to include in the model and why?

86
00:09:02,590 --> 00:09:06,520
And so I sort of I inserted this, I as though I was the student.

87
00:09:06,520 --> 00:09:10,989
So I will control from maternal age, infant gender, pre gestational BMI,

88
00:09:10,990 --> 00:09:16,180
etc. And I pulled these out of the model that the student described in their report.

89
00:09:17,110 --> 00:09:23,439
And then additionally, because there's longitudinal measurements, I will also include time as a covariate, etc.

90
00:09:23,440 --> 00:09:31,440
So this. Should Matt back to if we find their results section.

91
00:09:37,530 --> 00:09:46,030
But we're in methods. I apologize. This is taken from their description of their methods.

92
00:09:46,150 --> 00:09:53,740
So. All adjusted models are controlled for maternal age, infant gender, pre gestational BMI, etc.

93
00:09:53,750 --> 00:10:01,459
So I just copy that chunk out. Right. Question, see what type of regression will you use?

94
00:10:01,460 --> 00:10:07,400
So this is a linear regression. Question RD Are there repeated measurements or correlated clustered observations?

95
00:10:07,400 --> 00:10:13,219
How will you deal with this? So they did a linear, mixed model. So I said, yes, there's multiple measurements through pregnancy.

96
00:10:13,220 --> 00:10:19,220
They have a longitudinal study, so they're going to model it using a linear mix model for you guys.

97
00:10:19,490 --> 00:10:23,340
Just to reiterate, give me permission to ignore the clustered measurements.

98
00:10:23,340 --> 00:10:29,630
So for RD, you might say yes, there's multiple measurements and I'm dealing with it by, let's say, taking one off.

99
00:10:29,960 --> 00:10:35,930
Right. And then question E is sort of a a bigger one.

100
00:10:35,930 --> 00:10:39,229
Right, right. Out of mathematical model for your regression here.

101
00:10:39,230 --> 00:10:43,310
I didn't I just this is a screenshot from their report.

102
00:10:44,180 --> 00:10:54,049
You can you can format this however you want. If you want to write this in latex or word or etc., you can format it however you want.

103
00:10:54,050 --> 00:10:59,690
I didn't want to struggle with the equation formatter in Google Docs,

104
00:10:59,690 --> 00:11:06,530
so I used a screenshot which if you put a screenshot in and I can tell what your equation is, that's fine.

105
00:11:07,460 --> 00:11:13,220
So they have this equation for their model and they tell us what all of the variables are.

106
00:11:13,220 --> 00:11:15,740
So that's nice. So I would encourage you to also do that.

107
00:11:15,740 --> 00:11:21,860
So if you have a variable in your model, don't just say like B and hope that I know that that means BMI.

108
00:11:24,650 --> 00:11:30,290
All right. So question s which parameters in the model we you used to answer your question and how.

109
00:11:30,860 --> 00:11:36,070
So for this question, they have the main effect coefficient on M2 Q category.

110
00:11:36,080 --> 00:11:41,840
They actually had kind of a complicated model and the Q category time interaction.

111
00:11:41,840 --> 00:11:47,650
And so that's they're going to use that to compute the association between fetal measurement and McHugh

112
00:11:47,660 --> 00:11:53,380
category at each time point resulting in three association measurements for each outcome exposure pair.

113
00:11:53,420 --> 00:11:59,870
So they have a complicated model and they have a lot of results. And then G.

114
00:12:01,450 --> 00:12:04,840
Are there modeling assumptions that you can check and how will you check these?

115
00:12:05,260 --> 00:12:13,350
So for this student in their report. The modeling assumptions that they talked about were making spaghetti parts to look for

116
00:12:13,350 --> 00:12:18,899
nonlinear eddies in fetal growth trajectories so that they could build their build this model.

117
00:12:18,900 --> 00:12:26,520
They ended up deciding to put a time squared term in. You might do more model tracking than this and that.

118
00:12:26,760 --> 00:12:33,030
That is fine to have more model checking than this in your let's call this a

119
00:12:33,390 --> 00:12:38,940
what are we calling it deconstructed report that you hand in you might not.

120
00:12:40,880 --> 00:12:44,690
Not all of this model checking might make it into your final report.

121
00:12:44,840 --> 00:12:50,000
You might have, like, a residual plot in your supplement.

122
00:12:50,390 --> 00:12:55,940
You probably won't have like you definitely won't have every plot that you made in your report.

123
00:12:56,750 --> 00:13:01,880
And then each is sort of an open ended. Are there other details that you think are important?

124
00:13:01,910 --> 00:13:03,500
So in this case, I've said no.

125
00:13:04,010 --> 00:13:10,160
And then in the second question, they had a comment about there being lots of tests and using a bond for any correction.

126
00:13:10,730 --> 00:13:14,450
The other thing that I wanted to point out here is so we answered this question twice.

127
00:13:14,780 --> 00:13:24,260
There are two models are really similar rate because they to answer their second question, they've just added a an interaction term.

128
00:13:24,290 --> 00:13:27,980
Right. So they took their model that they've already described in the added in interaction term.

129
00:13:28,610 --> 00:13:35,450
If you do that, you don't have to like write the same thing in that two parts.

130
00:13:35,480 --> 00:13:40,010
So I just wrote same as in one for B right there. Covariates are the same as in one.

131
00:13:40,220 --> 00:13:44,380
And so you don't have to rewrite that. Just say it's the same.

132
00:13:44,390 --> 00:13:50,420
And then that sort of corresponds to in your report, you might say to test if there's an interaction,

133
00:13:50,420 --> 00:13:54,750
we use the same model, but we added an interaction, right? So it sort of corresponds there.

134
00:13:55,010 --> 00:14:00,310
The amount of information that you're giving. Okay.

135
00:14:00,490 --> 00:14:04,570
So that's that's the methods section. Are there questions about.

136
00:14:05,640 --> 00:14:09,150
This format so far or what we've talked about so far.

137
00:14:13,440 --> 00:14:18,840
Okay. So the results section is going to go back up to just the clean question form.

138
00:14:19,740 --> 00:14:26,280
So the results section is asking you to interpret the results of the thing that you describe that you were going to do in the method section.

139
00:14:27,270 --> 00:14:32,219
Question ten just asked you to make a nicely formatted table one, as though you're going to put it in your report.

140
00:14:32,220 --> 00:14:38,640
So we saw an example. I think the example that I showed in the slides was straight out of the report that I also used for the purpose of answers.

141
00:14:38,640 --> 00:14:48,930
So, so that's that. Question 11 gives you this chance to put some intermediate results in so this wouldn't make it into a final report.

142
00:14:49,140 --> 00:14:58,200
But for this sort of deconstructed version, there's a question of fit the model and show the results in this one instance.

143
00:14:58,980 --> 00:15:03,420
You can include your like R output if you want in this question.

144
00:15:03,930 --> 00:15:06,780
You don't put your R output in a final report.

145
00:15:06,780 --> 00:15:14,910
Generally, this like question 11 is like you'll do that and then process the results into questions 12 and 13.

146
00:15:15,960 --> 00:15:23,530
So in question 12, you take. The results that you got in 11 in your answer.

147
00:15:23,530 --> 00:15:29,260
In question. So in question ask you said, how am I going to answer this question with the model that I fit?

148
00:15:30,010 --> 00:15:33,790
Question 11 You should be able to say, okay, now I have a number that goes with that.

149
00:15:34,300 --> 00:15:37,330
I said I was going to use Beta four and now I have an estimate for beta four.

150
00:15:37,600 --> 00:15:43,299
So using your answer to nine F for each of the questions in five,

151
00:15:43,300 --> 00:15:49,420
you're going to write like a description of your primary answer to the question based on your model.

152
00:15:50,470 --> 00:15:54,520
And we can go and see what the purple student did.

153
00:15:54,730 --> 00:16:01,210
And then 13 is make a display item for your results in 12.

154
00:16:01,220 --> 00:16:05,440
So some kind of like nicely formatted table or figure that shows us your results.

155
00:16:06,370 --> 00:16:11,230
So for our purple student, what did they do?

156
00:16:11,440 --> 00:16:20,979
I'm sure they weren't purple at the time, but so I didn't I obviously don't have their output.

157
00:16:20,980 --> 00:16:24,340
So I left question 11 blank. You can put whatever it is that you got.

158
00:16:24,610 --> 00:16:27,850
And I didn't copy their table out of their report. So you can go and look at that.

159
00:16:29,170 --> 00:16:31,870
This I just copied straight out of their results.

160
00:16:31,900 --> 00:16:43,690
So for question one, their answer is they sort of long paragraph the estimated difference in expected five parietal diameter at 28 weeks of gestation.

161
00:16:43,690 --> 00:16:49,750
Comparing women that met and did not meet the recommended daily legume intake is 0.09 centimeters.

162
00:16:49,960 --> 00:16:51,580
They give this confidence interval,

163
00:16:52,000 --> 00:17:00,790
whereas the estimated difference in expected by parietal diameter at 40 weeks of gestation compared women that met and did not meet.

164
00:17:00,790 --> 00:17:05,800
The recommended daily legume intake is 0.01 centimeters with this confidence interval.

165
00:17:05,950 --> 00:17:13,029
That's a nice sentence. It's long and it's got. You have to remember what bi parietal diameter is.

166
00:17:13,030 --> 00:17:16,480
But hopefully at this point, if you've read the report, you know what that is.

167
00:17:16,720 --> 00:17:20,410
So having this point estimate and the confidence interval is nice.

168
00:17:21,040 --> 00:17:23,830
You'll notice they don't have a p value, which is fine.

169
00:17:24,670 --> 00:17:31,990
I think people are sort of have different opinions about whether they really want to see or don't want to see a p value in their interpretation.

170
00:17:32,350 --> 00:17:40,030
I personally don't care, but I want to see the confidence interval and then they have.

171
00:17:41,060 --> 00:17:46,639
Also an interpretation for question two. After considering the Bonferroni corrected P-value threshold,

172
00:17:46,640 --> 00:17:52,340
the linear mixed model with femur length as the outcome and added sugar as the M.D q category of interest had a

173
00:17:52,340 --> 00:17:58,700
significantly better fit if interactions between added sugar and pre gestational BMI and time were included.

174
00:17:59,150 --> 00:18:03,410
All other tests were non-significant, so I think that's also a nice interpretation.

175
00:18:05,000 --> 00:18:08,059
There's a second example that I'll show you in a minute,

176
00:18:08,060 --> 00:18:12,830
and then they have some nice tables that I also didn't clip out of their reports you can go look at.

177
00:18:15,350 --> 00:18:21,920
And then finally, if we roll back up, there's two questions for discussion and conclusion.

178
00:18:22,280 --> 00:18:27,160
So based on the results section, what are the main answers to the questions in five?

179
00:18:27,170 --> 00:18:32,780
So this is sort of your like zoomed out, high level view. And then what are the limitations of the study?

180
00:18:33,800 --> 00:18:39,680
I think it's fine. You'll see in some of the answers that I put in purple, I use bullet points sometimes.

181
00:18:39,680 --> 00:18:43,880
Right. So in in 14, this one is clipped right out of their report.

182
00:18:44,330 --> 00:18:51,030
So it's it's in sentences. This is their their overview of the results, right?

183
00:18:51,050 --> 00:18:57,380
Unadjusted and adjusted associations between empty Q subcategories and ultrasound measurements were largely non-significant

184
00:18:57,560 --> 00:19:03,620
and won't test for interactions between maternal dietary indicators and pre gestational BMI were mostly non-significant.

185
00:19:03,620 --> 00:19:07,430
That's their overview of the results. I think that's a nice overview.

186
00:19:08,030 --> 00:19:13,999
And then in limitations, I made two bullet points based on the limitations that they put in their discussions.

187
00:19:14,000 --> 00:19:22,850
So they have. A limitation about actually knowing what pregnancy is is hard and.

188
00:19:25,430 --> 00:19:34,410
This is sort of a generic limitation of the effect. Sizes are small and we could use more sample size, which I guess is fine.

189
00:19:34,490 --> 00:19:38,450
I mean, I expressed my opinion about the sample size limitation last time.

190
00:19:38,450 --> 00:19:44,930
So I would say limitations include really what you think are actually the limitations of the study.

191
00:19:46,580 --> 00:19:49,500
And then abstract. Write a paragraph.

192
00:19:49,520 --> 00:19:55,009
So this question 16 is just write an abstract, but it sort of gives you an instruction about how to do that, right?

193
00:19:55,010 --> 00:19:59,930
So for each of the four sections above, write 1 to 3 sentences describing the main points.

194
00:20:00,500 --> 00:20:08,210
Try to link your sentences together so that they flow logically. So if we go and look at their report, we can see what they did for their abstract.

195
00:20:08,570 --> 00:20:12,440
And this is sort of. Nice for these two examples.

196
00:20:12,440 --> 00:20:18,440
There's two different styles, so they have a long abstract and they have these headings in the abstract.

197
00:20:18,740 --> 00:20:22,459
I think this is this is definitely on the longer side.

198
00:20:22,460 --> 00:20:25,490
For an abstract, it could be shorter.

199
00:20:27,350 --> 00:20:35,510
The other example that's in here, so there's a second example, which is this red example about smoking cessation we can go and look at.

200
00:20:36,700 --> 00:20:41,730
That one briefly. Okay.

201
00:20:42,000 --> 00:20:48,980
So they, they do the other style of abstract that just paragraph style and that's also fine I think

202
00:20:49,860 --> 00:20:54,120
I think stylistically I sort of prefer the paragraph style and being a little bit shorter,

203
00:20:54,120 --> 00:20:58,559
but I think that's purely preference.

204
00:20:58,560 --> 00:21:02,900
I don't have a substantive reason for preferring that.

205
00:21:02,910 --> 00:21:07,730
So do whichever one you like. Yeah.

206
00:21:07,740 --> 00:21:13,590
So this, this abstract is just a couple of sentences for each section and they connect.

207
00:21:14,910 --> 00:21:22,350
They connect logically. I won't go through all of the answers for the Red Report.

208
00:21:22,770 --> 00:21:27,299
It's sort of a similar process. I left I left some notes, right?

209
00:21:27,300 --> 00:21:30,420
So for missing data, this person just dropped all of their missing data.

210
00:21:30,430 --> 00:21:38,830
So they started with like 11,000 observations and dropped anybody that had any missing news and ended up with like 7300.

211
00:21:38,850 --> 00:21:42,149
So I just left a note that we're not endorsing.

212
00:21:42,150 --> 00:21:49,320
That is the right thing to do. This is just an example of how you would what your answers would look like for for that report.

213
00:21:49,320 --> 00:21:54,810
And it may have been that that you're, you know, similar to like how we haven't covered cluster data.

214
00:21:55,200 --> 00:22:02,550
It may be that they were told, it's fine to drop your missing observations because we don't want to cover imputation yet.

215
00:22:02,800 --> 00:22:06,870
So I'm not there's not criticism for that student.

216
00:22:06,870 --> 00:22:10,620
It's just a note so that you don't feel like this is like a gold standard.

217
00:22:14,390 --> 00:22:18,440
So that is the deconstructed report.

218
00:22:18,470 --> 00:22:27,020
Hopefully that connects with what you saw yesterday about what a report looks like when you have several questions about is construction.

219
00:22:27,140 --> 00:22:31,190
Yes. First is how we are to actually put the cleaning parts inside.

220
00:22:34,730 --> 00:22:38,270
What do you think? You should answer that first.

221
00:22:38,930 --> 00:22:49,310
I think. The place that I would probably put it is in measurement methods for study design.

222
00:22:49,790 --> 00:23:01,009
So in study design you have how the data is collected, etc. and then there can be a little piece for post-processing, right?

223
00:23:01,010 --> 00:23:08,719
So the study design sort of includes like, you know, there were longitudinal measurements,

224
00:23:08,720 --> 00:23:21,440
but we just took the first one is sort of part of study design. So that's I think where I think my second question is wish that how should we use

225
00:23:21,440 --> 00:23:25,610
for table what the road and other did how we use after the cleaning or both?

226
00:23:26,570 --> 00:23:29,629
It's a good question. I think so.

227
00:23:29,630 --> 00:23:38,470
Philip expressed I think some. Preference for baking table one be about the data that's in your analysis.

228
00:23:38,470 --> 00:23:43,710
And I sort of I like that. I think that's. Generally a good approach.

229
00:23:45,360 --> 00:23:50,220
I guess I could imagine an instance where you don't do that, but I think that's like a reasonable approach.

230
00:23:50,490 --> 00:23:55,649
I think there's a couple reasonable things you could do, though. You might depend a little bit on the context.

231
00:23:55,650 --> 00:23:59,639
I mean, potentially you could have a report about, if you think that's important,

232
00:23:59,640 --> 00:24:04,440
to sort of demonstrate that that they've analyzed is representative of a whole dataset.

233
00:24:04,440 --> 00:24:09,389
On some cases, you might just say, no, we deleted that one with a measurement under 60.

234
00:24:09,390 --> 00:24:12,450
And you know, when you don't have to tell us about getting too much. Right.

235
00:24:12,450 --> 00:24:16,920
So if you're saying we're going to focus, we're focusing on people who are above 60.

236
00:24:17,430 --> 00:24:24,330
Just tell me about those people. If it's something of like, well, we're going to, like, drop all of our.

237
00:24:26,500 --> 00:24:30,640
Drop all of like some subset, but we want to show you that that didn't change anything then.

238
00:24:30,910 --> 00:24:36,310
I'm just reiterating what Jeremy said, but that's sort of it's a judgment call, I guess.

239
00:24:37,000 --> 00:24:42,879
My final question is we asked you if the model selection process in the in the paper, for example,

240
00:24:42,880 --> 00:24:47,440
if we chose several models in the way compare them by state by state R squared,

241
00:24:47,650 --> 00:24:52,840
should we include it in the paper or should we just mention it briefly?

242
00:24:53,320 --> 00:25:00,370
So I think there's two places that you could put that. One of them is what covariates are you including and why?

243
00:25:00,850 --> 00:25:08,880
So that y can be. These I'm including these covariates because I think they're, like, biologically important.

244
00:25:10,290 --> 00:25:18,110
It could also be. We examined several models, and the one that fit best in some way was this model.

245
00:25:18,470 --> 00:25:21,860
You could also put that in G.

246
00:25:21,950 --> 00:25:25,400
Right. Are there modeling assumptions that you can track? So this is.

247
00:25:26,900 --> 00:25:29,630
The Methods section say you're going to say.

248
00:25:30,900 --> 00:25:40,530
If part of your methods is we're going to perform model selection by AIC, then you might say we're going to consider covariates one through 100.

249
00:25:40,980 --> 00:25:44,730
And then part of our method is that we're going to do model selection by AIC.

250
00:25:44,940 --> 00:25:54,120
And so I'll put that either like in G or, you know, somewhere in, somewhere in this methods questions.

251
00:25:54,120 --> 00:25:57,149
And I do want to save for this for nine.

252
00:25:57,150 --> 00:26:04,740
So I answered these as like putting one answer for A through H if you would rather answer this as like

253
00:26:04,740 --> 00:26:11,670
a paragraph or like your answers don't quite fit in a through h we tried to allow room for that.

254
00:26:11,670 --> 00:26:17,579
So describe your model in a way that does address everything in a true age.

255
00:26:17,580 --> 00:26:21,060
But if you want to do it in a slightly different format, then just like.

256
00:26:22,310 --> 00:26:29,150
A. Answer. Be answer. That's fine with me as long as I can rebuild a little paragraph and match it.

257
00:26:29,420 --> 00:26:34,220
Like know that all the answers are there. Thank you. Yeah.

258
00:26:34,250 --> 00:26:40,700
SELINA Yes. For like, 13 words, just provide a, like, display.

259
00:26:41,030 --> 00:26:42,019
Is it like.

260
00:26:42,020 --> 00:26:48,860
So she would just give, like, one display that sort of summarizes all of her results or like one of her like a question from number five or.

261
00:26:49,490 --> 00:26:55,969
I think you could do it either way. So it may depend on your questions, right?

262
00:26:55,970 --> 00:27:01,520
So it might be that some of your questions are like answered by your descriptive table.

263
00:27:02,860 --> 00:27:07,719
It might be that one of your questions is best answered by just like a sentence,

264
00:27:07,720 --> 00:27:12,790
and there's no display item really to go with that because you did a simple linear regression or something.

265
00:27:12,970 --> 00:27:16,810
So it might not be that every question needs a display item.

266
00:27:16,810 --> 00:27:20,629
And hopefully, like if you had five questions, you don't want five display items.

267
00:27:20,630 --> 00:27:25,930
So you want to figure out like what is the. What is the most?

268
00:27:26,990 --> 00:27:30,290
Useful display item to convey these results.

269
00:27:30,620 --> 00:27:35,150
If there's results that don't make sense to put in a display item, then don't in there.

270
00:27:36,260 --> 00:27:41,440
And also for the sort of like list of questions that we're going to be trying to answer,

271
00:27:41,450 --> 00:27:45,240
is it basically just that slide of like four questions that we all saw?

272
00:27:45,650 --> 00:27:53,960
Like pretty much the same questions for everybody? Yeah, right. So Tom's Tom slides sort of laid out his questions.

273
00:27:54,200 --> 00:27:59,930
I think that you could take those questions and like reconfigure them into a

274
00:27:59,990 --> 00:28:04,140
different number as long as like the questions that you're answering sort of map,

275
00:28:04,240 --> 00:28:10,399
the easiest thing to do is take his four questions and like make your questions sort of match those,

276
00:28:10,400 --> 00:28:14,180
although you might want to change the phrasing to more specifically reflect what you're doing.

277
00:28:14,180 --> 00:28:16,820
Right. So you sort of nonspecific in some of his questions.

278
00:28:17,840 --> 00:28:28,150
I think there's also an option to like combine two of the investigators questions into like one statistical question or like vice versa.

279
00:28:29,420 --> 00:28:35,750
So I don't want to you're not prescribed to like have to have the number of questions that are like,

280
00:28:36,260 --> 00:28:39,950
adds the investigator post that you have a take on that.

281
00:28:40,640 --> 00:28:46,250
Yeah, that sounds good. I mean, I think also going back to your earlier question, too, I mean,

282
00:28:46,250 --> 00:28:52,190
if somehow you do need a table and a figure to answer a question, I don't feel like you constrain,

283
00:28:52,190 --> 00:28:56,329
but, you know, you have to make choices about what's the most important way and the fact that

284
00:28:56,330 --> 00:29:00,530
this has a nicely formatted table or figure you can have more than that.

285
00:29:00,590 --> 00:29:02,870
But again, sort of same guideline as report.

286
00:29:03,560 --> 00:29:13,639
I like if you're over four display items including table one, probably want to pick and choose and also for like the reports in general,

287
00:29:13,640 --> 00:29:17,150
I think you give us like a sort of guidelines on page limits.

288
00:29:17,150 --> 00:29:21,930
Do you have a suggestion for this one? I think it will be similar, right.

289
00:29:21,980 --> 00:29:27,260
That if you certainly shouldn't have a lot more text here than you would have in a report,

290
00:29:27,560 --> 00:29:38,510
the the only thing that's going to be in this these answers that wouldn't be in a report is 11, which is sort of just a stepping stone question I.

291
00:29:40,950 --> 00:29:44,340
It might be harder to judge how much text you add depending on how you like.

292
00:29:44,490 --> 00:29:53,530
Format your answers. But sort of a ballpark is like it shouldn't be more text than you would have for a reporting service.

293
00:29:53,580 --> 00:29:57,690
So if you if you produce what the purple student produced, what is that about?

294
00:29:57,690 --> 00:30:00,989
Right. If you're you're twice as much as that. Is that too much?

295
00:30:00,990 --> 00:30:04,530
You know, but yeah, I think you're a half of is possibly too little.

296
00:30:04,860 --> 00:30:10,409
Yeah. I think the purple student, as I answered, is probably about close.

297
00:30:10,410 --> 00:30:15,780
I was like a little terse in some places and I left out like I didn't put the table in here.

298
00:30:16,080 --> 00:30:21,989
So you could write more than I wrote here. I wouldn't, you know, in question 12.

299
00:30:21,990 --> 00:30:27,240
I thought I wouldn't write more than this, right? Yeah.

300
00:30:27,240 --> 00:30:31,440
I would say like the examples are like about the amount of text I'm expecting,

301
00:30:31,440 --> 00:30:38,969
but like if you have more or both of these have two questions and you might have four, so you might have more to write.

302
00:30:38,970 --> 00:30:42,750
Although if your models are similar, that might not add too much sense.

303
00:30:45,590 --> 00:30:49,790
Can I go back to your question about where do you put in sort of a model selection stuff?

304
00:30:49,800 --> 00:30:53,690
So just remember my real reports you're writing for the investigator,

305
00:30:53,690 --> 00:30:59,440
so you don't want sort of a blow by blow description of the main text of, you know, this.

306
00:30:59,450 --> 00:31:00,620
I said it was too big.

307
00:31:00,620 --> 00:31:06,389
And so we change that model and then we thought about putting an interaction with that would if it goes anywhere, it go in a supplement.

308
00:31:06,390 --> 00:31:12,680
But that's not you writing for him. I you wouldn't see that sort of thing in the paper, in the journal, for example.

309
00:31:12,680 --> 00:31:21,290
So just keep that in mind. It's not really the statistical methods process as you went through, which have a central goal of report.

310
00:31:21,290 --> 00:31:28,170
It's sort of a conclusions and how you think. Tell me your name.

311
00:31:28,690 --> 00:31:33,500
I'm Rosita. Rosita? Oh, other questions about for this project.

312
00:31:33,510 --> 00:31:39,300
We also have questions regarding the accuracy for all devices other than black and white.

313
00:31:40,230 --> 00:31:50,790
So I see that as a secondary interesses that I might use a separate model in this case to iui p e to h again for the separate model.

314
00:31:51,390 --> 00:32:02,520
Yeah. So you can see, I think in both the red example and the purple example there like second question was really similar to their first question.

315
00:32:02,820 --> 00:32:06,330
So I did a lot of saying like same as in one.

316
00:32:06,720 --> 00:32:10,680
Rather than rewriting the same model. And I think in.

317
00:32:13,230 --> 00:32:21,450
See how well I remember. So in. In the second question for the I guess, the right one, I have three questions.

318
00:32:21,680 --> 00:32:23,630
In the second question for the red one.

319
00:32:27,280 --> 00:32:38,349
I just wrote like we used the same model and there's almost no new information in this response other than like in this one,

320
00:32:38,350 --> 00:32:47,140
they they took exactly the same model and just replaced the indicator for menthol cigaret user with e-cigarette user and these two questions.

321
00:32:47,170 --> 00:32:50,410
So I think this maybe this example will work.

322
00:32:50,650 --> 00:32:53,010
Does that answer that question for how to do that?

323
00:32:53,020 --> 00:33:00,020
Like if you have two similar questions that you're answering using very similar methods, you don't have to repeat all of the information.

324
00:33:00,040 --> 00:33:07,149
I think you could also like validly answer this second part with just a set of sentences

325
00:33:07,150 --> 00:33:12,010
like I wrote out the parts through H so that you could see what they all were.

326
00:33:12,130 --> 00:33:18,310
But if you just wanted to write like three sentences that included this information,

327
00:33:18,310 --> 00:33:24,430
that would be fine as long as it referred to like, Oh, we're using the same model that I just described.

328
00:33:24,430 --> 00:33:32,180
And so I know that that's what you're doing. Other questions.

329
00:33:36,010 --> 00:33:40,210
Okay. So we do next.

330
00:33:40,720 --> 00:33:44,910
So we have how to collaborate and transformation.

331
00:33:44,920 --> 00:33:53,550
Some discussion and discussion on Project one. So maybe we'll do discussion on Project one break and then the two topics.

332
00:33:53,640 --> 00:33:57,990
Okay, thanks.

333
00:33:58,020 --> 00:34:06,690
I left Project one discussion off of my schedule. So you probably saw an email about, you know,

334
00:34:06,690 --> 00:34:11,580
Tom Vallely came back with lots of answers to many questions and hopefully

335
00:34:12,150 --> 00:34:15,990
some of them were clarifying and some of them perhaps not quite so clarifying.

336
00:34:15,990 --> 00:34:22,530
But anyway, there was a lot of it. He was very responsive and he just laid out data issues, basically.

337
00:34:23,190 --> 00:34:31,020
Yeah. So these responses are in discussions, if you haven't seen that, take a look.

338
00:34:32,310 --> 00:34:36,660
These are the questions, as I phrase them. So if it's not how you were phrased, I apologize.

339
00:34:39,170 --> 00:34:43,190
Should we go through them or should we ask questions about them?

340
00:34:43,490 --> 00:34:52,710
Just. And when I have questions about these or just projects project in general, I have several questions about a project in general.

341
00:34:53,610 --> 00:34:56,760
First is you mentioned that we are only using a linear model,

342
00:34:56,970 --> 00:35:00,930
but actually there is a clustering effect on the hospital and in the researchers

343
00:35:00,980 --> 00:35:06,150
is said that we can guarantee that a hospital using the same set of machines.

344
00:35:06,150 --> 00:35:11,850
So there must be some random in terms of sap and I put that for them interested in the

345
00:35:11,850 --> 00:35:21,930
model it improves the performance a lot needs and can use nonlinear and other mixed models.

346
00:35:22,080 --> 00:35:25,800
Yeah, I think so. And so as we discussed on Tuesday.

347
00:35:26,920 --> 00:35:33,030
For this project. You've been given special dispensation to ignore the hospital hospital clustering.

348
00:35:33,180 --> 00:35:36,550
That doesn't mean we don't think it's a good idea to do something with hospital clustering.

349
00:35:36,580 --> 00:35:41,170
So if you want to put the random effect in, I think that's probably a good idea.

350
00:35:41,190 --> 00:35:44,640
Just ask we from 0.07 to 0.2.

351
00:35:44,880 --> 00:35:46,800
Oh, interesting. That's quite a change.

352
00:35:46,830 --> 00:35:58,290
The second question is that the observations of two method within 10 minutes, but actually one difference of time is more than 5 minutes.

353
00:35:58,320 --> 00:36:03,450
There are very few observations are about less than 10%.

354
00:36:03,780 --> 00:36:08,880
And these observations, if removed, will improve the performance a lot.

355
00:36:09,210 --> 00:36:15,330
So these are some good. Can I just remove those with the time difference?

356
00:36:15,600 --> 00:36:19,979
More than five, 5 minutes. Well, what is what's is third question?

357
00:36:19,980 --> 00:36:23,510
Isn't this first question something about your time?

358
00:36:23,610 --> 00:36:29,820
Is it time matter? Right. There is a question about whether time met her, but the difference in time from 0 to 10 minutes,

359
00:36:30,090 --> 00:36:34,590
there are so few observations after five, 6 to 10 minutes.

360
00:36:35,400 --> 00:36:44,430
Right. So you might are you sort of thinking about like does it make sense to try to fit a model where you don't have a lot of data or how many?

361
00:36:45,420 --> 00:36:51,110
Just wondering how many observations over here. So 10,000, like 10% of 10,000.

362
00:36:51,110 --> 00:36:59,240
And so we have lots a force of 47,000 observations and goodness see how many we have before.

363
00:37:04,020 --> 00:37:14,639
Okay. Well, I mean, I think he's fundamentally quite interested in knowing if, you know, if a gap was 8 minutes and he does two things break down.

364
00:37:14,640 --> 00:37:18,360
And so you might want to just throw away that data.

365
00:37:18,360 --> 00:37:23,040
You're not going to be able to address that part of the question. I mean, it is it's sort of open ended, right.

366
00:37:23,040 --> 00:37:29,060
So it doesn't you could say, I'm going to answer this question for within 5 minutes.

367
00:37:29,070 --> 00:37:38,950
Right. How does time. Relate to inaccuracy if time is less than 5 minutes and.

368
00:37:41,290 --> 00:37:50,619
I think it depends on how you interpret the goal of that question is whether what the most important part of the data and also any

369
00:37:50,620 --> 00:38:01,390
thoughts on there are of 40 of about 40,000 observations and the difference in time above 5 minutes are only hundreds of them.

370
00:38:02,140 --> 00:38:07,240
So it's not that small of compared to the total, but it's not three, right.

371
00:38:07,240 --> 00:38:11,950
It's not a tiny, tiny number. There's another question.

372
00:38:12,400 --> 00:38:15,490
Let me just see anyone else have any thoughts on that?

373
00:38:21,480 --> 00:38:26,610
All right. We'll let you get down your list of questions. The question is, you like it, by the way?

374
00:38:26,610 --> 00:38:32,130
We like questions. I think the question is what the threshold for that patient versus white patient.

375
00:38:32,390 --> 00:38:40,620
So actually, it is is that an obstacle when we're blocking several of the real values of our covariates?

376
00:38:40,860 --> 00:38:45,990
So you need to give a confidence interval for this threshold. Yeah.

377
00:38:46,740 --> 00:38:55,440
So that that is it. I think that is a tricky question as written and it's worth probably talking about the different things that that could mean.

378
00:38:55,950 --> 00:39:02,190
So, so how is it you want to sort of venture how where interpreting question to.

379
00:39:09,430 --> 00:39:14,229
Now it sounds like you have an interpretation for question to an interpretation.

380
00:39:14,230 --> 00:39:17,360
Just wondering whether we should have a combination of offers.

381
00:39:17,680 --> 00:39:21,700
Right. So you don't have an interpretation, but you do want to consider this.

382
00:39:22,540 --> 00:39:25,810
Okay. In the green. Tell me your name. Andre. Andre. Yeah.

383
00:39:25,840 --> 00:39:32,260
I was thinking more like you find, like the distribution for each black patient in the white patient, and you find,

384
00:39:32,260 --> 00:39:38,580
like, some threshold that you would set where like only some percent is below that and that would be the threshold.

385
00:39:38,590 --> 00:39:42,190
So it's just a point estimate is what I was thinking.

386
00:39:42,730 --> 00:39:48,880
So you're sort of your goal is like pick your I was thinking like a Bayesian analysis for this maybe.

387
00:39:49,420 --> 00:39:57,380
Yeah. So I guess one of one point is when we say threshold, we mean threshold for the spo2 measurement, right?

388
00:39:57,400 --> 00:40:04,980
Because that's the information the doctor gets to see. And then there's kind of this like open question is what is right?

389
00:40:04,990 --> 00:40:10,030
I mean, right. And so you're thinking of it in terms of. Like.

390
00:40:10,050 --> 00:40:16,350
At what point where it is like letting a certain amount of people kind of miss this?

391
00:40:18,380 --> 00:40:26,900
Yeah. Like this decision, I guess. So you think he'd like 20% of a sample on the arterial measurement below the threshold?

392
00:40:27,350 --> 00:40:33,020
What threshold do I use for the to give a device when it was called to.

393
00:40:33,020 --> 00:40:36,070
So it's the same percentage below that right. Is sort of higher.

394
00:40:36,800 --> 00:40:43,850
Yeah. I've got some SBO two that would relate to the like, I don't know, less than 5% or whatever safe number we want.

395
00:40:44,270 --> 00:40:53,030
So like give us a picture like this and we're saying, okay, we want like less than X percent to be below 88%.

396
00:40:53,030 --> 00:40:58,580
And then I just like find the box plot where the tail is smaller than that percentage.

397
00:40:59,030 --> 00:41:04,879
How do you take that percentage? Yeah, I think it's very safe.

398
00:41:04,880 --> 00:41:11,150
Like 1%. They're like less. I don't know. So you haven't directly from the arterial data, right?

399
00:41:11,150 --> 00:41:18,590
You know, the percentage in the arterial data for that. But the question is, how do you check how much of this tail, how much of the tail of the box?

400
00:41:18,590 --> 00:41:24,020
What do I want to let B below the dash line?

401
00:41:24,320 --> 00:41:30,200
That's sort of the question. Whatever percentage is based on the arterial track population?

402
00:41:32,100 --> 00:41:35,250
No. We were thinking. I'm not understanding that. Sorry, Jeremy.

403
00:41:35,270 --> 00:41:40,470
You explain that to me. Right. Right. But that would be, like, unadjusted for covariates.

404
00:41:40,480 --> 00:41:47,740
Is that. Yeah. Well, you don't actually have any covariates here, right? We have we have a time frame and sex is okay.

405
00:41:47,740 --> 00:41:51,730
So. Yes, yes, it would that would be completely unadjusted for covariance.

406
00:41:52,060 --> 00:41:57,520
And for us what you were hinting at just a simple percentage of matches.

407
00:41:57,520 --> 00:42:01,900
What's in me? I'm sorry. Can you explain what that means to me?

408
00:42:01,930 --> 00:42:06,730
So 10% of the materials were white. So below 88.

409
00:42:06,790 --> 00:42:12,249
So when Spo2 reads, let's say because I have 89 through 92.

410
00:42:12,250 --> 00:42:17,110
So when Spo2 reads 90, we have let's say this is 33% of the white.

411
00:42:17,630 --> 00:42:23,740
No, I'm starting with the arterial measurements and saying we're going to use the threshold of 88 for that.

412
00:42:23,800 --> 00:42:27,610
But in the white population, that's your like reference.

413
00:42:30,660 --> 00:42:34,980
You know, tell me how to line up the arterial ESPN.

414
00:42:35,640 --> 00:42:37,830
See, with the current group for a group perspective,

415
00:42:39,270 --> 00:42:47,270
10% of the arterial and the white patients are below 88 overall are among those who have an spo2 reading or something overall.

416
00:42:47,910 --> 00:42:52,740
Like I just care about the total of the population because it should match.

417
00:42:52,860 --> 00:42:55,019
It should match and we have a measurement, right?

418
00:42:55,020 --> 00:43:02,669
If were measuring the same percentage, measuring the same quantity, they just shifted down measurement.

419
00:43:02,670 --> 00:43:06,940
So I'm going to shift it up to get brightness. And also, this is a best analysis for the system.

420
00:43:07,230 --> 00:43:13,530
Okay. I kind of understand what you mean. That is not what I thought that Andre meant, but it might have been my idea.

421
00:43:14,250 --> 00:43:19,920
So let's go to the relates to save to that like in a safe level,

422
00:43:19,920 --> 00:43:28,080
like where obviously I think that's the question but at what point that spo2 is like related to some real value?

423
00:43:28,110 --> 00:43:39,780
Okay. So you would say I'm willing to let 5% of people be below 88 when I think they're above 88.

424
00:43:40,110 --> 00:43:46,440
And so that would be like whichever of these box plots has less than 5% of its tail below the dash line.

425
00:43:47,400 --> 00:43:54,809
So that we are thinking think more. But so I guess I want to for this question,

426
00:43:54,810 --> 00:44:04,710
I did want to point us towards I like maybe unhelpful answer from Tom in this because I asked him about this question so I asked.

427
00:44:06,780 --> 00:44:13,769
About the cost of getting it wrong the other way. Right. So we know that if I think someone's above 88 and they're below 88, that's bad.

428
00:44:13,770 --> 00:44:18,370
They're not getting treatment. So then the question is, well, let's just treat everybody right.

429
00:44:18,390 --> 00:44:22,650
Like, why not make a threshold a hundred? What's wrong with that?

430
00:44:23,370 --> 00:44:27,389
So I asked what the cost of doing that would be.

431
00:44:27,390 --> 00:44:31,870
Right? What's the cost of treating someone who? Does it need to be treated?

432
00:44:32,200 --> 00:44:35,610
And his answer was essentially very low, right?

433
00:44:35,620 --> 00:44:40,630
There's like maybe resource use related and not patient harm related.

434
00:44:41,830 --> 00:44:50,320
So he says basically false positives don't don't matter which if false positives really didn't matter.

435
00:44:51,610 --> 00:44:58,990
It seems to me like the right answer would be 100. Right? Let's just treat everybody like ICU beds or something like I can imagine.

436
00:44:59,000 --> 00:45:01,630
But we don't treat everybody so clearly. There's some reason.

437
00:45:01,780 --> 00:45:10,390
I mean, my gosh, I've already really chosen 88 as that threshold for if you had arterial measurements and it gets to 88 or below,

438
00:45:10,720 --> 00:45:14,470
we're going to do something. And that's what they want to calibrate towards.

439
00:45:14,860 --> 00:45:19,570
If they had the data on me, SPRO ran for my patient, obviously.

440
00:45:20,020 --> 00:45:26,590
But if there's no cost to the thinking that Joe and I agree on here, I mean, this is like another help from humans.

441
00:45:27,550 --> 00:45:31,890
Well, maybe not. In every country, there is like an excess of oxygen.

442
00:45:31,900 --> 00:45:35,020
Like there are certain countries that were running out of oxygen. Right.

443
00:45:35,020 --> 00:45:41,169
And I think this is probably one of them that, like, if we could just treat everyone and there's no cost to treating everyone, we would do it.

444
00:45:41,170 --> 00:45:44,730
So there's clearly some colonies chosen 88 already have it, right.

445
00:45:44,770 --> 00:45:48,350
Yeah. Chosen 88 I think. Rosita.

446
00:45:48,520 --> 00:45:54,999
Yeah, I would come and I'll tell you why not treating people to 100% because I have some

447
00:45:55,000 --> 00:46:00,430
of the medical background of sometime if you give a patient that have high oxygen,

448
00:46:00,460 --> 00:46:05,050
oxygen, they will feel very uncomfortable because it's kind of like pushing oxygen to them.

449
00:46:05,380 --> 00:46:09,340
So sometimes they take it off. So yeah, that's like the reason why.

450
00:46:10,000 --> 00:46:14,980
Got it. So essentially no cost is not really so are they to disagrees.

451
00:46:16,700 --> 00:46:27,760
So it sounds like there's some unquantifiable cost, but it's a smaller cost on the false positive side, then on the false negative side.

452
00:46:33,200 --> 00:46:37,249
I think there's a bunch of ways that you could interpret or like things that you

453
00:46:37,250 --> 00:46:41,630
could do that would answer question to how or other people thinking about that.

454
00:46:42,460 --> 00:46:44,990
Yeah. Tell us your name. My name's Jess.

455
00:46:45,020 --> 00:46:57,559
My thought was to read, to address like the arterial oxygen with the other covariance onto the pulse oximeter and then plug in this 83 threshold.

456
00:46:57,560 --> 00:47:04,160
So if the gold standard is at 88, what would the pulse ox reading be?

457
00:47:04,160 --> 00:47:08,120
And then look at it over race and sex and stuff.

458
00:47:08,120 --> 00:47:16,579
But I'm just struggling with the negative skewness of the data because I really only know how to handle a positive skew.

459
00:47:16,580 --> 00:47:21,860
So then I did a transformation, but it's still working through it.

460
00:47:22,190 --> 00:47:31,670
So your mother you spoke to on the left arterial on the right was other covariates and then the ideas around just plug in 88.

461
00:47:32,270 --> 00:47:39,330
If I get that model right and I plug in 88, I should get what I SPOG with reading would be let me know.

462
00:47:40,070 --> 00:47:45,670
Yeah, yeah, that makes sense to me. And then you said you have an issue of like the distribution of the.

463
00:47:45,740 --> 00:47:49,370
Yeah. So like we have a lot of like really high percentages.

464
00:47:50,120 --> 00:47:55,249
And so I was going to fit like a guy with all the germs that I know tend to handle

465
00:47:55,250 --> 00:47:59,030
stuff that's like closer to zero rather than closer to the other boundary.

466
00:47:59,030 --> 00:48:04,880
So the only thing that I could find or think of was just subtract it from the max.

467
00:48:05,330 --> 00:48:09,050
So it just like switches it back. So I did like 101 minus.

468
00:48:09,350 --> 00:48:10,910
And then what would you do after that?

469
00:48:13,250 --> 00:48:24,799
I sent a person because the pulse ox is zero like integers, so it would be like count data, but then there's a lot of over dispersion.

470
00:48:24,800 --> 00:48:29,920
So then I said a negative binomial instead. Yeah.

471
00:48:29,940 --> 00:48:35,569
So that's sort of your. Flipping the side that it's on.

472
00:48:35,570 --> 00:48:40,970
And then you have like a log link for the time model.

473
00:48:47,410 --> 00:48:52,910
So you might want to be a little. So have you. Good luck. I mean, they are some more or less on the same scale, right?

474
00:48:53,570 --> 00:48:55,470
Arterial pulse oximeter. Yeah.

475
00:48:55,770 --> 00:49:03,090
So you do lot of on one side, you probably should log on the other side too, because they are sort of measured in the same way.

476
00:49:03,630 --> 00:49:09,120
Right. And so that sort of like you're thinking about the ratio as.

477
00:49:14,100 --> 00:49:18,270
Your outcome. Well.

478
00:49:18,300 --> 00:49:21,450
So my. Be careful about the influence of the.

479
00:49:23,080 --> 00:49:28,430
Far out points. Right. That like if your fifties are dragging.

480
00:49:31,050 --> 00:49:34,710
Fifth, I set the cut off as it had to be.

481
00:49:35,010 --> 00:49:40,770
You had to have a reading of 70%. So I don't quite have the relief part.

482
00:49:40,790 --> 00:49:47,040
One sitting next to me. 31 on the ARTERIAL in Montreal.

483
00:49:47,040 --> 00:49:51,800
You. And you got like a linear model for spo2 versus arterial.

484
00:49:53,090 --> 00:50:03,710
They're not linearly related. I was like looking at ways I haven't tried log, but I've seen a cubic spine that fit the best so far.

485
00:50:05,720 --> 00:50:11,870
Everyone along those lines, right? Sort of scatter plots of the data and Lois curves through them.

486
00:50:11,870 --> 00:50:17,600
It's a sort of a good preliminary step to get a sense of if it's linear or is it a curved relationship?

487
00:50:18,170 --> 00:50:21,290
Yeah. In response.

488
00:50:23,800 --> 00:50:24,850
Anybody else have ideas?

489
00:50:26,900 --> 00:50:38,510
Just wondering, would that make sense to 50 different species in the material and to be able to instead of spitting it separately.

490
00:50:38,960 --> 00:50:45,140
So it should give us a relatively normal reading in this case,

491
00:50:45,140 --> 00:50:51,050
but I'm not sure that's something that it makes sense to do or will I lose some information along the way?

492
00:50:53,570 --> 00:50:56,570
But I do fitting a take the difference between the observer,

493
00:50:56,570 --> 00:51:00,889
like on the left hand side and then the arterial or something on the right hand

494
00:51:00,890 --> 00:51:04,750
side means you're learning about the relationship between the two to that here.

495
00:51:05,780 --> 00:51:10,220
I think, yeah, Jeremy's good on team difference, I think from the beginning.

496
00:51:10,460 --> 00:51:21,030
One thing you might think about there is that the size of the difference might depend on, say, the arterial or the spot to fit.

497
00:51:21,050 --> 00:51:27,260
Like if someone's at like close to 100, it might be that that difference just like can't be very big.

498
00:51:27,710 --> 00:51:31,760
Whereas if somebody is at 85, the difference can be bigger.

499
00:51:32,120 --> 00:51:37,280
So you might need one of the, one of the measurements might need to show up on the right hand side.

500
00:51:42,590 --> 00:51:47,399
So what's your name? I'm Maya. Maya. But I'm also thinking about strategy.

501
00:51:47,400 --> 00:51:55,380
But the issue of having to tell the direction of the difference is, I think, also important because they care more about this.

502
00:51:55,410 --> 00:51:59,040
Like what's negative in the false positives. Just.

503
00:52:00,600 --> 00:52:04,080
You keep the sign, right? If you took the difference, then you saw the sign, right?

504
00:52:05,220 --> 00:52:11,320
That's true. Yeah. So then you're just caring about is it negative or is it positive?

505
00:52:16,790 --> 00:52:26,020
She? Very yeah I don't questioning giving them a line of questioning not just what she mentioned that we're

506
00:52:26,030 --> 00:52:33,090
using that as response center as opposed to our style predictor and she adjusts for other covers.

507
00:52:33,370 --> 00:52:36,640
But I thought the question we're interested in is the race bias.

508
00:52:36,940 --> 00:52:42,900
So let's say that let's say there is actually a race bias on the field to reading.

509
00:52:42,930 --> 00:52:51,410
Then they're so social that there's probably a association between people too, and the race and that we treat the ABC as a gold standard.

510
00:52:51,460 --> 00:52:55,060
So we cannot say that race has no effect on the ABC.

511
00:52:55,330 --> 00:53:03,340
So race is has like a causality relationship with the history or two and S0 two is connected to the ABC.

512
00:53:03,640 --> 00:53:11,550
So in this, if we treat the model fit the model, I would just trust that we don't really conditioned on the race.

513
00:53:11,560 --> 00:53:15,280
Right. And just as model your you've spoke to on the left.

514
00:53:15,280 --> 00:53:18,520
Right. And then do you have race in your model?

515
00:53:18,910 --> 00:53:22,150
I do. Okay. So that's on the left?

516
00:53:22,270 --> 00:53:26,200
Yeah. So just Jess has a spot here on the left and then race shows up on the right.

517
00:53:26,410 --> 00:53:29,810
Does that fit with. How you were conceiving it.

518
00:53:30,830 --> 00:53:34,340
Okay. Sorry. I think I just misheard it.

519
00:53:34,790 --> 00:53:38,390
Yeah, I. I also mix up which one is which sometimes.

520
00:53:38,930 --> 00:53:43,550
I mean, there's no suggestion of racial bias associated with the material.

521
00:53:43,930 --> 00:53:50,780
So, no, I don't think that we have a suggestion that people like.

522
00:53:51,650 --> 00:53:55,310
I think everyone wants to be at 100. Right. Yeah.

523
00:53:55,340 --> 00:53:58,730
Immeasurably material gives you is a right valid measurement.

524
00:53:59,060 --> 00:54:03,650
Yes. Irrespective of race. Yes. I think that this that's also my understanding.

525
00:54:06,230 --> 00:54:18,800
See the problem in export analysis, I found that the difference in two measurements the errors are of a high difference between white and black.

526
00:54:19,280 --> 00:54:26,150
The the variation of the difference in white is about twice the time, the variation in black in the data.

527
00:54:26,450 --> 00:54:34,429
So is there something that the old model that to compensate for this is interesting are they different average

528
00:54:34,430 --> 00:54:45,470
levels to this is a part of this is a difference in time the access is a variation in the difference of measure.

529
00:54:45,680 --> 00:54:51,889
And you can see that the white has about twice than black, but the white has more variation.

530
00:54:51,890 --> 00:54:57,380
And the the why is variation that an X is the difference in time of the Americans.

531
00:54:57,590 --> 00:55:07,330
But which group has higher variance? White. So just as a corrected for population has a higher presence as the white population have a higher

532
00:55:07,700 --> 00:55:14,750
like per spo2 measurement or just a variation of the difference between two measurements.

533
00:55:14,810 --> 00:55:18,320
The difference is the difference in my model.

534
00:55:18,320 --> 00:55:27,350
I have the difference on the left. I guess there's a couple things that that could be related to.

535
00:55:27,620 --> 00:55:35,149
Right. So there is. So Phil and I were thinking that the like we were talking about with Rosita that

536
00:55:35,150 --> 00:55:41,180
the you have more variation in the difference when it's lower potentially.

537
00:55:41,180 --> 00:55:44,180
So there could be some relationship there.

538
00:55:49,010 --> 00:55:52,010
Try to see that, but like maybe more generally,

539
00:55:52,010 --> 00:56:00,950
like what if there's one of those different variants in one group then another that might be probably one covariate balanced in another way.

540
00:56:01,730 --> 00:56:11,630
What would you do for that? I mean, you could you know, you can model variances as well as means and statistical models to monitor.

541
00:56:11,960 --> 00:56:16,700
Is that for like all measurements of where Spo2 is like even less than 50 for the initial?

542
00:56:19,520 --> 00:56:29,250
Because I feel like that's like just an error. I don't think you should even consider hospitals that low for anything just from the device.

543
00:56:30,320 --> 00:56:37,130
I mean, you've got a very skewed sort of distribution with Taylor measurements near 99 101 might tail off.

544
00:56:37,670 --> 00:56:42,620
So the variance is going to get quite impacted by the outliers at the low end.

545
00:56:42,620 --> 00:56:51,080
So make sure you know. Yeah, I found like it's actually a thing that said like for the pulse ox,

546
00:56:51,500 --> 00:56:57,530
like less than 70 or something that like the accuracy of the device, really, they just don't.

547
00:56:58,010 --> 00:57:04,670
Would you be willing to post that on the discussion board? Sure. And I think, Tom, I asked about these low readings.

548
00:57:04,820 --> 00:57:11,780
He says, I don't believe him, basically. Yeah. He says, I think it's true that something below 70% might be artifact.

549
00:57:11,810 --> 00:57:19,549
So he's guess at the same threshold that you came up with and says values of zero 220 are most assuredly correct.

550
00:57:19,550 --> 00:57:26,440
And he said for the if it's low in the arterials, it could be that they got a vein and not the arteries.

551
00:57:31,440 --> 00:57:34,920
Okay. Just take a couple more questions and we have a little break, I think.

552
00:57:35,580 --> 00:57:39,899
Do you had another one? Yeah, I had another one. So kind of a dumb question.

553
00:57:39,900 --> 00:57:48,810
So usually I'll include more data into my model. But if I'm just answering the question, if there's a race bias between white and black,

554
00:57:49,650 --> 00:57:56,670
I I'm not sure if I should only use the data with white and black patient because in this case I don't even know

555
00:57:56,670 --> 00:58:05,550
the hidden mechanism behind or other than the blood oxygen level of why there's like a difference in the reading.

556
00:58:05,670 --> 00:58:15,750
So if it's because of skin tone, let's say there's like a huge variation in the skin tone within one specific race category.

557
00:58:16,080 --> 00:58:21,170
So if I include other race, such as Asian, Hispanic.

558
00:58:21,690 --> 00:58:25,450
Well, you know, it's like it's like the ordinary categorical variable.

559
00:58:26,640 --> 00:58:30,270
And each one of them is like a very heavy tail distribution.

560
00:58:30,600 --> 00:58:39,809
And then if I include the middle part, the middle category is interior data without actually improve my model fitting or that won't cause problems.

561
00:58:39,810 --> 00:58:46,860
I'm not really sure. He answers questions, right?

562
00:58:46,860 --> 00:58:54,959
So, I mean, either implicitly he didn't. Right. So he has to say he really thought about black and white.

563
00:58:54,960 --> 00:58:58,170
But then he said there are these sort of other categories.

564
00:58:58,170 --> 00:59:04,230
Right. So I think the first question is about the difference between black and white, because that's what they looked at in the paper.

565
00:59:04,650 --> 00:59:07,110
And then the last question is about.

566
00:59:08,930 --> 00:59:16,790
Accuracy for non-black nonwhite patients in which presumably you would want to compare those groups with the groups we've already looked at.

567
00:59:17,300 --> 00:59:25,100
Although but if just for a question, what which model do you think is better?

568
00:59:25,250 --> 00:59:29,990
Is it? So we tend not to answer questions exactly which model is better.

569
00:59:30,680 --> 00:59:34,160
If you post bottles that we give in your patients, maybe it looks like.

570
00:59:34,490 --> 00:59:39,920
I think that the first question is about the difference between black and white based on what they wrote in the paper.

571
00:59:40,320 --> 00:59:43,700
Yeah. Tell us your name. I'm Hannah. So I guess follow up to that question, then.

572
00:59:44,720 --> 00:59:51,140
Is it would it be valid to use different subsets of the data to answer each of the questions if the same data cleaning process is used?

573
00:59:51,500 --> 00:59:55,700
Or to that question, for example, if you're dividing,

574
00:59:56,270 --> 01:00:02,800
deciding to divide races into just black and just white, or if you're using the different categories,

575
01:00:03,170 --> 01:00:08,069
can you just get rid of those categories when you're answering question one, for example, is that about thing to do?

576
01:00:08,070 --> 01:00:11,480
Where should you be using all the data and like recategorized? That makes sense.

577
01:00:12,890 --> 01:00:18,140
I mean, you wouldn't take someone who's like categorized as Hispanic and say, I'm going to recategorized you as white, right?

578
01:00:18,680 --> 01:00:21,379
So I guess the different subsets. Is that a valid thing to do?

579
01:00:21,380 --> 01:00:28,490
Answering the questions based on what the question is getting at question one is more or less ignore anyone who is black.

580
01:00:28,580 --> 01:00:28,720
White.

581
01:00:29,300 --> 01:00:38,090
Yes, I think question four is potentially you know, there's a group of a mixture of others maybe that's I don't know how big of a group of others is.

582
01:00:38,090 --> 01:00:42,860
But and then in the actual deconstructed report we would just mentioned, this is the subset that we used.

583
01:00:43,040 --> 01:00:47,870
The data cleaning is the same that we said before, but we're only considering this sample here.

584
01:00:48,380 --> 01:00:50,870
And I think in one of our examples, like they,

585
01:00:50,870 --> 01:00:59,599
they looked like only they had this whole data set and they only look at smokers because they're caring about smoking cessation.

586
01:00:59,600 --> 01:01:04,909
So some of the kids are actually going off of that.

587
01:01:04,910 --> 01:01:05,510
First question.

588
01:01:05,510 --> 01:01:15,680
One, is it more like, you know, we noticed that black patients had lower or zero oxygen compared to white patients, sort of like as an incidence.

589
01:01:15,680 --> 01:01:16,759
Like incidentally,

590
01:01:16,760 --> 01:01:24,500
we did this analysis and we found that like five are lower oxygen or is it like we try to actually replicate what they did in their paper?

591
01:01:26,180 --> 01:01:29,209
I would tend more towards the first one,

592
01:01:29,210 --> 01:01:37,460
sort of like we found this this replicates this result from this previous paper as opposed to like we're

593
01:01:37,460 --> 01:01:42,230
trying we tried to generate the exact numerical results of this previous paper and here's how close we got.

594
01:01:42,440 --> 01:01:45,980
I would tend more towards the first one. I'm sure you've got exactly the same data.

595
01:01:45,990 --> 01:01:54,650
Yeah, maybe you can tell. Yeah, but I mean, if I have a numerical thing, it's like three points lower.

596
01:01:55,280 --> 01:02:00,140
You know, you could probably if you got two and a half is your estimate or something, you could say that, right.

597
01:02:00,170 --> 01:02:03,920
If you get 12, you might want to mention like this is a lot bigger than they saw.

598
01:02:04,000 --> 01:02:07,340
Right. Much good zero, you might say.

599
01:02:07,340 --> 01:02:13,130
That's not what they thought. Right. So we don't necessarily have to use their hypoxemia.

600
01:02:13,340 --> 01:02:18,200
Very good. Right. Interpret question one qualitatively.

601
01:02:22,400 --> 01:02:32,540
All right. We take a break here. Yeah. It's sure to come back to a seven questions.

602
01:02:32,540 --> 01:02:49,800
Everybody thinks for the same reasons.

603
01:02:50,060 --> 01:03:01,690
First, to give Iowa where I come from, you know, I think that maybe I of from the doctor.

604
01:03:03,730 --> 01:03:15,200
Right. Yeah. It's sort of like my my interview yesterday.

605
01:03:15,890 --> 01:03:21,680
Oh, yes. I was so happy, you know?

606
01:03:22,020 --> 01:03:28,990
I don't know. You could argue for this long. Yeah.

607
01:03:29,000 --> 01:03:41,540
I was going to say that, you know, about three years ago.

608
01:03:42,440 --> 01:03:47,470
I wonder if you were just doing so well.

609
01:03:50,360 --> 01:03:56,660
You know, we all agree with that. Oh, yeah. I think nobody nobody gets the cost of zero.

610
01:03:59,620 --> 01:04:07,790
How do you think you'll find the right point?

611
01:04:07,820 --> 01:04:16,830
I think also says and I think you've heard so many, you should be completely at odds if you go through those two years.

612
01:04:18,590 --> 01:04:40,600
Right now, you know, I think we're not even allowed to use our future media.

613
01:04:40,610 --> 01:04:48,140
It is time for the president irrespective of anything else.

614
01:04:48,170 --> 01:04:59,340
I think this that equation, I think it is thinking of prediction.

615
01:05:02,910 --> 01:05:08,230
And I want to get a chance to hear from you.

616
01:05:09,020 --> 01:05:26,810
Yeah. You know, I don't know if you want to say how many people are like misclassified because they were treating them like a patients myself.

617
01:05:28,710 --> 01:05:32,840
But I did want to answer the question.

618
01:05:32,840 --> 01:05:38,140
And either way, my guess is. Yeah, yes.

619
01:05:38,260 --> 01:05:41,600
It's just really time for more of us.

620
01:05:44,450 --> 01:05:49,070
Think you're going to get a hundred thousand?

621
01:05:49,820 --> 01:05:56,600
I'll be honest with you.

622
01:05:56,600 --> 01:06:03,919
Say six instead of oh eight, six, seven, eight, eight, hopefully was surprised because most of the time,

623
01:06:03,920 --> 01:06:20,750
like people do appreciate it, most of which, you know, you were saying, yes, this was sitting on this exam or something like that.

624
01:06:22,030 --> 01:06:47,390
So it was encouraging statisticians like something like, you know, I didn't know what part of the business because he was like ventriloquism.

625
01:06:47,930 --> 01:06:53,930
So she really didn't even ask the question.

626
01:06:53,930 --> 01:06:58,830
Like you just sort of like quizzes those things.

627
01:06:58,850 --> 01:07:07,190
So like there's a saying more like what's more surprising to you?

628
01:07:10,890 --> 01:07:14,630
Because that's how, you know, he's like, because what?

629
01:07:15,110 --> 01:07:24,320
I didn't know what I. Yeah, I know you have different questions.

630
01:07:24,340 --> 01:07:32,050
Yeah, he's got, you know, it's like now because, like, it also seems like.

631
01:07:32,230 --> 01:07:39,130
Yeah. Like this is the case.

632
01:07:39,240 --> 01:07:43,350
Like, it was like. Yeah.

633
01:07:44,140 --> 01:08:04,120
So I really didn't want to be like, I don't know how, you know, how, how versatile Johnson is going to be.

634
01:08:04,180 --> 01:08:08,410
But, you know, you read, I guess.

635
01:08:14,000 --> 01:08:37,600
I know. I know you want to make movies going here because I was thinking like, it's okay, it's okay.

636
01:08:37,990 --> 01:08:47,680
Everybody gets hurt. So the plan, I think, really get through at all the resources to try to come up with two things.

637
01:08:47,680 --> 01:08:52,330
One of them is about transformations, and one of it's about generally how to collaborate.

638
01:08:52,660 --> 01:09:03,069
So you'll see Film Bravo talking about the same stuff before using slight different slides, and there's sort of reasons for that.

639
01:09:03,070 --> 01:09:05,889
And so for transformations, I'm going to wrap fast.

640
01:09:05,890 --> 01:09:13,780
And so basically the one film Bravo using is more or less a type version of the one I'm going to use.

641
01:09:13,980 --> 01:09:18,560
And you'll see you can actually more or less follow along with some other things different.

642
01:09:18,610 --> 01:09:23,850
But I'm going to use this one on the bottom, which is my very neat just sounds right.

643
01:09:27,000 --> 01:09:32,070
Services just felt transformation. So it wasn't about 20 minutes just going through this.

644
01:09:32,100 --> 01:09:42,170
And, you know, this is not necessarily exactly relevant for this first project because it's sort of generally relevant to the model building on time.

645
01:09:42,550 --> 01:09:48,720
And then potentially those variables you might think about transforming time in your data center and necessarily think about,

646
01:09:49,020 --> 01:09:53,489
you know, now Jeremy said that, you know, you use transformation, so how do I fit that into project?

647
01:09:53,490 --> 01:09:57,270
Well, that's not the idea at all. This is just information.

648
01:09:57,810 --> 01:10:03,660
That's something useful that you should know about so you can think about transforming.

649
01:10:03,990 --> 01:10:11,220
So first, nonlinear transformations, it's not just sort of adding three and multiplying by seven, it's some sort of nonlinear function.

650
01:10:12,360 --> 01:10:16,370
So you can transform data, you can transform parameters or statistics.

651
01:10:16,370 --> 01:10:20,550
So I'm going to be mainly talking about transforming data and.

652
01:10:21,870 --> 01:10:26,099
So here's two power transformation. So why is like an observation?

653
01:10:26,100 --> 01:10:26,880
Like your height?

654
01:10:27,300 --> 01:10:33,629
You might choose to take the square root of height and somehow work with the square root of a height where you might take the cube root by three,

655
01:10:33,630 --> 01:10:37,709
three or one over height or something. That might be exactly how you want to think about these things.

656
01:10:37,710 --> 01:10:43,050
And sometimes these are natural. You know, some things are sort of measured on a log scale or something like that.

657
01:10:43,050 --> 01:10:47,400
So there's already been some transformations already been done for you, but so it's sort of a given.

658
01:10:47,910 --> 01:10:56,879
You know, these are nice round numbers, but you can also think about taking power .3712 if you want to do something illegal about that,

659
01:10:56,880 --> 01:11:00,450
makes it a little harder to interpret, but that doesn't matter too much.

660
01:11:02,750 --> 01:11:06,590
Okay. So what is it that were just taking your power?

661
01:11:06,590 --> 01:11:14,290
So. People who are very famous statisticians, George Box and David Cox.

662
01:11:15,000 --> 01:11:25,220
It's the bench that is our David Cox was the person who won the first international prize for statistics he founded about five years ago.

663
01:11:25,240 --> 01:11:25,810
He was the winner of.

664
01:11:25,990 --> 01:11:33,640
So he's done a lot of work, very, very important work in terms of, you know, survival analysis, the Cox model, this is the same David Cox.

665
01:11:34,930 --> 01:11:39,370
Okay. So his is just a slight re expression of a power transformation.

666
01:11:39,370 --> 01:11:45,459
So you think y you take power lambda and you just rescale a little bit, subtract one divided by lambda.

667
01:11:45,460 --> 01:11:52,300
So it was just constants lambda zero. And reason you do that is to make it nice and smooth when lambda equals zero.

668
01:11:52,300 --> 01:11:58,600
So is this set up? So when lambda equals zero, this function is smoothly transition into the log.

669
01:11:59,590 --> 01:12:06,520
So that's the box. Cox Transformation. And just one little note, maybe you don't read it very well, but it says,

670
01:12:06,520 --> 01:12:14,710
look to embrace E so that's actually reflector just remember you we're quite you know sort of mathematical background you're quite

671
01:12:15,340 --> 01:12:22,940
comfortable and happy and naturally using log to ABC but if you're going over fields quite often use long to base two or one to base ten.

672
01:12:22,940 --> 01:12:27,100
And so make sure you sort of clear you're using logs what you're actually using.

673
01:12:31,120 --> 01:12:37,110
I got a very snooty letter from someone when I'd had some form of rapid response to you, and I just said Log.

674
01:12:37,770 --> 01:12:42,669
And he wrote, Very nasty, saying, You know, I've tried logging your formula doesn't work.

675
01:12:42,670 --> 01:12:48,460
And I said, Well, let's log in. And he said, Well, you should have told us that anyway.

676
01:12:49,000 --> 01:12:55,180
So it's a continuous a family, a family of transformations indexed by Lambda Monotonic.

677
01:12:56,110 --> 01:12:59,460
It's only going to work if data's positive. Why is positive?

678
01:12:59,470 --> 01:13:03,460
Right. You can't take the square root of the negative number and.

679
01:13:05,800 --> 01:13:10,720
In statistics, you don't have to take a square root of a negative number, but that's okay.

680
01:13:10,900 --> 01:13:16,270
Most actors net positive, you know, measure negative actuarial blood measurements or.

681
01:13:18,470 --> 01:13:22,520
So here's what you are actually doing. You're just it just nonlinear functions.

682
01:13:23,090 --> 01:13:26,300
There's a whole family of these functions through.

683
01:13:30,530 --> 01:13:36,550
Right. So if you have. And he goes to it goes one way and it goes minus one.

684
01:13:36,570 --> 01:13:40,860
It goes the other way. And Landry goes one is just a linear, linear function, right?

685
01:13:40,890 --> 01:13:45,750
So it's just, it's just a function non-linear which either is, you know, convex or concave.

686
01:13:47,410 --> 01:13:54,310
That's all that is just a function. One very common choice of.

687
01:13:54,800 --> 01:14:02,080
You don't have to face this. The only choice you can make is to take locks to replace the gas or two or whatever you want to do.

688
01:14:02,080 --> 01:14:05,920
It won't matter too much except to say where it is.

689
01:14:06,880 --> 01:14:13,390
So this tends to be quite often suitable if you have sort of multiplicative type factors happening.

690
01:14:13,390 --> 01:14:17,320
If you multiply something, if you rescale stuff in a multiplicative way,

691
01:14:17,890 --> 01:14:22,299
you take the logs of it and it's going to turn into an additive change as opposed to a multiplicative change.

692
01:14:22,300 --> 01:14:30,190
The log is quite natural there. So I can I work in cancer research quite a bit and you know, tumors grow exponentially.

693
01:14:30,190 --> 01:14:34,450
So it's quite natural to sort of take logs and make some large scale by growing linearly.

694
01:14:34,450 --> 01:14:41,049
So it's sometimes a rationale for various transformations. So one thing transformations two.

695
01:14:41,050 --> 01:14:46,240
So I'm going to start with just a set of numbers services, just a representation of a.

696
01:14:47,840 --> 01:14:56,290
A histogram of a set of numbers. So just one variable was not why not have a Y on an axis, just kind of x variable here at the water column.

697
01:14:57,080 --> 01:15:00,260
So think of us as a histogram. This one's a little bit skewed to the right.

698
01:15:00,710 --> 01:15:06,680
So what are some of the tail? The big numbers. Beautiful, right? So it was just said your data is very much skewed to the left.

699
01:15:08,360 --> 01:15:13,960
So if you take the square root of that data tools in the right hand tail and so stretches out the left hand tail,

700
01:15:13,970 --> 01:15:17,480
so has now turned that into skewed to the left.

701
01:15:17,750 --> 01:15:25,829
So these transformations change with skewness. Sometimes you sort of want something to look approximately symmetric or Gaussian you

702
01:15:25,830 --> 01:15:30,830
want might search for transformation does that if you square these numbers you'd make

703
01:15:30,830 --> 01:15:36,530
it even more skewed to the right and we talk about sort of why it's helpful sometimes

704
01:15:36,530 --> 01:15:41,210
or not or not necessary to to think about transforming data to make it symmetric.

705
01:15:42,530 --> 01:15:45,740
Okay. So so that's what we do best.

706
01:15:45,920 --> 01:15:52,720
In fact, on on data. Now let's talk a little bit about the model.

707
01:15:52,810 --> 01:16:01,160
So you have an album Wired on X. So got you're thinking about regression type models as no hospital clustering.

708
01:16:01,210 --> 01:16:04,780
No repeated measures per person is just why I use independent observations.

709
01:16:06,910 --> 01:16:07,450
And of them.

710
01:16:09,700 --> 01:16:17,470
And you're thinking of doing some sort of regression Y on X and just this scale, as I wouldn't have noticed, because it's just one dimensional.

711
01:16:18,850 --> 01:16:24,570
So you might think about. You know, you transform the Y amendment model somehow.

712
01:16:24,960 --> 01:16:29,460
If it's better. Maybe. Or you might transform your ex. And my model fits better.

713
01:16:29,520 --> 01:16:33,450
So you might. There's sort of two possibilities you might do in a simple setting.

714
01:16:35,500 --> 01:16:43,900
And you know, so why might you do this? It's not usually sort of a main goal to learn about the transformation,

715
01:16:44,440 --> 01:16:51,280
but it's maybe gives you a better fitting body model, which you can then, you know, so if you're going to fit a model,

716
01:16:51,550 --> 01:16:56,530
benefit the data well and if and so this might help if a model fit with data well

717
01:16:56,530 --> 01:17:01,839
and managing data fits for your model fits data fits for model fits the data,

718
01:17:01,840 --> 01:17:07,420
which is, would you say model fits data what benefits anyway?

719
01:17:07,540 --> 01:17:12,669
If an agreement you be in a better situation to interpret any results from it.

720
01:17:12,670 --> 01:17:16,239
Whereas if a model and the data are not in agreement, not compatible with each other,

721
01:17:16,240 --> 01:17:21,250
you're going to get trouble and possibly in the corrective conclusions if your model doesn't show.

722
01:17:21,970 --> 01:17:27,340
Okay, so it's not so much about what the transformation is, but how it helps you describe or interpret the data.

723
01:17:28,270 --> 01:17:33,850
And then particularly this last point is to allow you to satisfy the assumptions in a lot.

724
01:17:36,410 --> 01:17:40,220
Okay. So here's a very nicely, clear picture.

725
01:17:41,270 --> 01:17:46,910
So you can look at that and it's sort of obvious there's a nonlinear relationship between Y and X.

726
01:17:47,690 --> 01:17:53,180
So if you if you just did a linear regression Y on X, that wouldn't be a good description of this data.

727
01:17:53,600 --> 01:17:59,690
So it's obvious. And so you might think about, well, can I use transformations to make this better?

728
01:18:03,020 --> 01:18:06,950
So you might either transform.

729
01:18:06,950 --> 01:18:17,070
Why? Example, take the logarithm of all the Y values so you might transform the axes and take the square of all the X values.

730
01:18:17,370 --> 01:18:20,760
So what is the question? So here's the data again.

731
01:18:22,350 --> 01:18:28,590
So what's taking the log of a y values is going to take these guys.

732
01:18:28,620 --> 01:18:36,390
Can you see the pointer in Ms. region and sort of pull them down, pulls it in, logs, pull in the right, big numbers, compress them.

733
01:18:36,720 --> 01:18:43,920
So you can imagine it would pull down all these these numbers in this region and then I could probably get a make a straight line out of it.

734
01:18:45,290 --> 01:18:53,419
All I could think about taking all these numbers here and pushing them out of a ride would also be a straight line potentially.

735
01:18:53,420 --> 01:18:56,870
So transform, relax and set. So.

736
01:18:58,260 --> 01:19:02,460
So essentially these two two choices. So any any thoughts on.

737
01:19:03,780 --> 01:19:07,710
What for these particular data? What do you think about.

738
01:19:09,400 --> 01:19:14,890
Be a good a good way to think through whether you prefer to transform your X or transform a Y you.

739
01:19:19,490 --> 01:19:24,440
This is like. Supposed to, like, give opinions on this question?

740
01:19:24,470 --> 01:19:29,380
Have. Sure. Transformer mouse tool X tool, quadratic work.

741
01:19:29,670 --> 01:19:32,730
Okay. So you got one vote for quadratic x.

742
01:19:33,150 --> 01:19:38,880
Okay. You want to just say say y y just squirts.

743
01:19:39,360 --> 01:19:44,010
Okay. So you could square Vieques, isn't it? And they would make it more or less linear, you think?

744
01:19:44,570 --> 01:19:49,870
Yeah. And it probably would. Any one of anyone alternative.

745
01:19:50,850 --> 01:19:53,920
You have a choice. Anyone to articulate a reason for. Do we have a choice?

746
01:19:57,090 --> 01:20:06,180
So remember what we're trying to do. We're trying to satisfy assumptions of model as and here of our models again.

747
01:20:07,850 --> 01:20:11,790
Okay. So I talked about Y and I talked about expert results a little term here.

748
01:20:12,770 --> 01:20:16,740
Right. Residual of error. So what?

749
01:20:17,490 --> 01:20:22,470
So typically you make you start making assumptions about E when you write down models, right?

750
01:20:23,400 --> 01:20:31,900
So what are the typical assumptions? We all deserve constant variance and Gaussian sometimes.

751
01:20:31,910 --> 01:20:37,100
Right. Okay. So, but so I'm written back. But let's assume that was what was intended here.

752
01:20:37,130 --> 01:20:40,310
Right. Because that's sort of what we usually do. So.

753
01:20:40,460 --> 01:20:41,030
So you want to.

754
01:20:42,680 --> 01:20:51,530
So either I transform y and then I look at the residuals from that and I think of a constant variance, an approximate Gaussian or I transform X.

755
01:20:52,130 --> 01:20:57,360
So going back to the picture. Would you like to revise your answer?

756
01:20:57,410 --> 01:21:01,010
Maybe. So what?

757
01:21:01,460 --> 01:21:05,510
So what? What do you see in this picture? If you think about variances a little bit.

758
01:21:06,740 --> 01:21:12,470
You see. So what's the variance of why at low values of X, it's not small, right?

759
01:21:12,620 --> 01:21:15,740
The variance of why the bigger values of X is bigger.

760
01:21:16,110 --> 01:21:19,760
All right. So what? So what transformed the X?

761
01:21:19,880 --> 01:21:24,850
I took all these. X is a big values that sort of stretched them off to the right.

762
01:21:26,430 --> 01:21:31,070
Would that change your variance? Alvarez Depend on the pump.

763
01:21:31,150 --> 01:21:37,630
Be independent of X or Y? Maybe contains some functional facts.

764
01:21:38,200 --> 01:21:41,229
I could write, I could make reverse, have some function of X or Y.

765
01:21:41,230 --> 01:21:48,300
I was sort of hoping about this. This model assumption here has constant variance to explicitly write back.

766
01:21:48,310 --> 01:21:55,270
Right? So what happens if I, if I move over to X is the bits of the big four dots, big value of x.

767
01:21:55,270 --> 01:22:00,730
If I moved to the right, I'm still going to have a same spread right as a certain spread of values here.

768
01:22:01,370 --> 01:22:08,110
If I just stretch the X's out, I'm still going to have that spread about. So that would be a case where I don't have constant variance.

769
01:22:09,190 --> 01:22:09,730
And so.

770
01:22:12,910 --> 01:22:20,559
I think I like I like to have her answer better when you transform y because if you stretched out all the whys, you would compress stronger values.

771
01:22:20,560 --> 01:22:23,799
Could you dress them together? Might have smaller variance.

772
01:22:23,800 --> 01:22:27,210
So I think that. The assumption that the.

773
01:22:28,240 --> 01:22:33,850
Variance is constant across thread. Most must the data we better satisfy by transforming one.

774
01:22:36,620 --> 01:22:40,340
So that was. So that was what I did.

775
01:22:40,450 --> 01:22:47,620
So so, you know, so transformations do a few things. They change sort of the main structure and they have implications for the varying structure, too.

776
01:22:48,700 --> 01:22:52,980
And so this is just writing that out a little more formally.

777
01:22:52,990 --> 01:22:56,550
So now I've got a whole bunch of covariates. It was a vector of x's.

778
01:22:57,700 --> 01:23:03,750
So the typical assumptions in this model is that after this transformation, it's linear mixes.

779
01:23:04,190 --> 01:23:07,749
It's one of assumptions about what this additive is.

780
01:23:07,750 --> 01:23:10,750
No interactions in this model, which what's written here.

781
01:23:14,200 --> 01:23:23,470
And has got some variance and and he has Gaussian sometimes front of a base and so you try to satisfy all those three things and if.

782
01:23:26,490 --> 01:23:34,310
And so what do you think in terms of relative importance of getting that sort of getting most satisfied?

783
01:23:34,470 --> 01:23:39,320
I mean, for some, you think one is more important or three or two or.

784
01:23:45,470 --> 01:23:52,210
He won't vote for three. But for one good.

785
01:23:55,340 --> 01:23:59,079
Yeah. So we were getting a mean structure of a model, a central structure,

786
01:23:59,080 --> 01:24:03,790
a model as is sort of a crucial, the most important of the, some of the other aspects.

787
01:24:03,790 --> 01:24:07,179
Getting the constant variance is good.

788
01:24:07,180 --> 01:24:12,430
You'd like that if you can. And sometimes, whether it's exactly Gaussian or not, it doesn't matter quite so much.

789
01:24:12,850 --> 01:24:15,940
Matters tend to be somewhat robust or rates Gaussian or not.

790
01:24:15,940 --> 01:24:24,069
But. No guarantee. But, you know, this data I'm sort of claiming if you take the log of Y, it's going to look linear.

791
01:24:24,070 --> 01:24:28,719
Well, maybe it does, but there's no guarantee it'll give you exactly constant variance.

792
01:24:28,720 --> 01:24:33,400
But it looks like in this picture I tried to construct it, so this was revised down.

793
01:24:33,400 --> 01:24:37,000
The variance will also be approximately constant. Okay.

794
01:24:37,000 --> 01:24:40,480
So it is different parts of a model to worry about. What mean structure?

795
01:24:42,910 --> 01:24:46,670
Infrared structure. Okay.

796
01:24:46,670 --> 01:24:50,840
So the services of you can think of Lambda as a parameter if you want in a model.

797
01:24:51,380 --> 01:24:54,770
So you could all you can sort out that a tubule.

798
01:24:54,770 --> 01:24:58,099
I'm just going to take the logs and then it's not really a parameter at all.

799
01:24:58,100 --> 01:24:59,509
You've just chosen a transformation.

800
01:24:59,510 --> 01:25:04,610
But if you're going to sort of investigate what's the best parameter for best transformation, it could be used as a parameter.

801
01:25:05,810 --> 01:25:10,950
So it's, you know, if you think about how to estimate Lambda, you can just do plots, right?

802
01:25:10,970 --> 01:25:15,410
I mean, you're right in this picture here, I could easily plot.

803
01:25:15,420 --> 01:25:18,860
Well, one could have easily plotted, but transformed.

804
01:25:18,860 --> 01:25:23,060
Why is that X right? And until it looks linear, that would be a way to estimate lambda.

805
01:25:26,710 --> 01:25:36,130
It's not going to work. If you have four Xs, for example, just you could you could try to make just a histogram of y symmetric.

806
01:25:37,170 --> 01:25:45,030
But that's not necessarily going to actually be very helpful. You just try to draw a histogram of the values of Y from this picture.

807
01:25:46,140 --> 01:25:54,629
It's a bit hard to tell, but it probably is about symmetric, right? You know, just think about the vertical values of y histogram of those values.

808
01:25:54,630 --> 01:26:02,280
Looks are more or less symmetric. So if you just wanted to get y symmetric, that would not give you sort of a good model for these data.

809
01:26:02,550 --> 01:26:08,640
So symmetry isn't necessarily of X or Y distribution themselves isn't necessarily that useful for.

810
01:26:14,970 --> 01:26:20,680
Well, you can. So to view it as a parameter and do maximum likelihood.

811
01:26:20,680 --> 01:26:24,370
So I just give you just a very brief overview of that.

812
01:26:24,370 --> 01:26:33,339
So hopefully you'll remember what maximum likelihood is techniques for estimating parameters of the model right down to probability,

813
01:26:33,340 --> 01:26:36,910
observing the data you did when you maximize fabulous.

814
01:26:37,540 --> 01:26:47,200
So here's the likelihood. So the likelihood is a probability. Observing y y given x product of all people assuming are independent.

815
01:26:47,860 --> 01:26:57,190
So you can see this the first bit here. Is the usual Gaussian density race wide of a lambda minus beta x.

816
01:26:57,590 --> 01:27:03,440
But then there's this other bit here, Y development minus one, which is which Caribbean.

817
01:27:04,070 --> 01:27:10,310
And so the first bit Gaussian kernel is the density of white of a lambda.

818
01:27:10,580 --> 01:27:15,139
But the likelihood I want to write down the probability of y not wide of lambda.

819
01:27:15,140 --> 01:27:19,549
So I have to correct that with a JAKOBSSON So that's what this does.

820
01:27:19,550 --> 01:27:22,430
And I don't know what to say to much more about that except but if you want to,

821
01:27:24,240 --> 01:27:29,450
you know, calculate to compare likelihoods for two models of different transformations,

822
01:27:30,020 --> 01:27:38,750
you got to, you got to include Jacobi in the calculation of Y's, it's just not meaningful to calculate likelihoods.

823
01:27:39,590 --> 01:27:43,680
To compare likelihoods. Okay.

824
01:27:43,680 --> 01:27:49,560
So. So here's another sort of issue if you go back to the original model.

825
01:27:54,130 --> 01:28:00,300
You sort of you're familiar with sort of the concept of, you know, interpreting a regression coefficient, right?

826
01:28:00,310 --> 01:28:08,230
So for a unit change in x one, how much do we of X, how much do we expect we're seeing on the left hand side to change?

827
01:28:08,780 --> 01:28:15,879
Right. So it's a bit a bit awkward if I have sort of a, you know, a cube root of y, I'm on the left hand side.

828
01:28:15,880 --> 01:28:23,500
So I say for a unit change of so beta one is how much does the cube root of y change if I change x one by one unit?

829
01:28:23,500 --> 01:28:26,620
So it's a bit awkward to think about, well cube roots of numbers sometimes.

830
01:28:26,620 --> 01:28:33,820
So if you want to, you know, if you if your goal is to somehow interpret that you have to be careful how you phrase it and.

831
01:28:35,700 --> 01:28:39,060
It was so easy, but not necessarily problematic either.

832
01:28:41,830 --> 01:28:45,190
Okay. So so it depends on the Y, right?

833
01:28:45,200 --> 01:28:52,209
So if you have a, you know, if you if you did a model with the cube root and you did a model with a square root, your betas are very, very different.

834
01:28:52,210 --> 01:28:56,680
So you can't just compare them. Exactly. And so it depends on the units.

835
01:28:57,570 --> 01:29:08,630
That's a that's a bit awkward, but. The one thing to remember of beta test or you know, assessing whether that coefficient is zero.

836
01:29:08,970 --> 01:29:13,430
Doesn't really matter so much. You don't need that question of whether there's any association.

837
01:29:13,850 --> 01:29:20,770
I still have the same question. If you took a cube root over square. Okay.

838
01:29:20,840 --> 01:29:23,910
So go back to the. Picture.

839
01:29:24,060 --> 01:29:29,190
All right, I'm done. Said that it's a little bit awkward to interpret things on a cube root scale.

840
01:29:30,330 --> 01:29:33,760
So I make for doing my modeling.

841
01:29:35,070 --> 01:29:44,240
I might take a lot of wide benefit remodel, but I might want to produce a picture which gives me the predictive value of why not a lot of why.

842
01:29:44,250 --> 01:29:49,950
So I could fit my I could transform my date a supermodel and then transform it back to the original scale.

843
01:29:49,950 --> 01:29:54,330
So I'm going to draw, you know, predicted line through this,

844
01:29:54,720 --> 01:30:00,900
which would follow of a data that I first did, the physical transformation benefit and predictive back.

845
01:30:01,710 --> 01:30:05,160
And so that's sort of. Nice thing you can do.

846
01:30:07,970 --> 01:30:13,550
Okay. So this is after you fit the model, put things back on my original scale so you can interpret what's going on.

847
01:30:14,530 --> 01:30:25,040
And so this is just a so if I have this model and my model predicted a value of X naught.

848
01:30:25,370 --> 01:30:31,610
So this formula for y hat value rexnord is just sort of the inverse of that box cogs transformation.

849
01:30:31,970 --> 01:30:38,180
So you can plug in x no multiply by B to have a problem to add.

850
01:30:38,180 --> 01:30:42,169
Well, then take one of the lambda trimester predictive value.

851
01:30:42,170 --> 01:30:47,630
And then I have. This is not next question.

852
01:30:47,990 --> 01:30:51,060
This is a predicted median of a conditional distribution.

853
01:30:51,110 --> 01:30:56,080
Why is it not a predictive mean? So.

854
01:30:59,050 --> 01:31:08,990
But also for that. Promises approximately wise it approximately predicted medium.

855
01:31:10,070 --> 01:31:17,360
So let's go back to the. So we just saw pictures of data as these histograms.

856
01:31:19,690 --> 01:31:24,639
If I took the median of this set of Y's some value in the middle here.

857
01:31:24,640 --> 01:31:31,600
Right. And then I take, you know, just for a moment, I take a median of a set of a square root of wise.

858
01:31:32,600 --> 01:31:38,720
I would exactly that would be exactly the square root of a median median stretched monotonically.

859
01:31:39,420 --> 01:31:42,140
And you go to invariance of a to a transformation.

860
01:31:42,290 --> 01:31:46,969
If you're a middle of a distribution, still the middle of a distribution of I take the square root of it, right?

861
01:31:46,970 --> 01:31:50,330
So of a median strength, a preserved root of transformations.

862
01:31:50,330 --> 01:32:00,139
But if I took the mean of the values of y, the mean of these values of the square root of Y, one of them wouldn't be the square root of the other.

863
01:32:00,140 --> 01:32:05,290
So medians don't don't transform on the variance of a transformation.

864
01:32:05,920 --> 01:32:15,710
And so, so when I think about that, so that's just from a univariate distribution, you're looking at this picture here.

865
01:32:16,520 --> 01:32:21,110
So the model after I transform is sort of assumed to be linear.

866
01:32:21,170 --> 01:32:26,600
And then when I'm at distribution symmetric that for symmetric distributions mean equals median.

867
01:32:27,260 --> 01:32:29,540
So that so you so you have the same thing.

868
01:32:29,540 --> 01:32:39,800
So I've transformed I fit the model and it's my fitted root and it's for mean estimated of a mean of transform y given x that's also the median.

869
01:32:40,190 --> 01:32:46,040
So I can transform a median back to the original scale, but I can't transform the mean back to the original scale.

870
01:32:46,730 --> 01:32:50,780
Okay, so just remember when you when you do sort of undo restore linear transformations,

871
01:32:50,780 --> 01:32:55,710
it's sort of the quantile so that your preserving my median over 25% times.

872
01:33:00,720 --> 01:33:05,830
Okay, girls. Okay.

873
01:33:05,840 --> 01:33:10,990
So that's what that that's what I want. This is sort of just a.

874
01:33:11,840 --> 01:33:17,389
Cute little aside here, it's because you got two variables and you fit a model.

875
01:33:17,390 --> 01:33:23,330
So I found that X1 next to my both continuous and I'm doing a transformation so.

876
01:33:25,010 --> 01:33:31,130
So this you know, I've told you, Peter Walton, Peter, to depend on the value of LAMDA strongly,

877
01:33:31,760 --> 01:33:34,970
but actually the ratio is not going to depend on Lambda very strongly.

878
01:33:35,330 --> 01:33:45,200
So. Why is that? Look ahead if you want, or you could try to think about this too.

879
01:33:45,300 --> 01:33:49,230
Can you interpret a ratio of two parameters in a model like this?

880
01:33:50,550 --> 01:33:57,840
It's a finger as some as an X1 in the next two. So something about the contrast between x1 x2 beta one over beta two.

881
01:33:58,170 --> 01:34:03,870
So something about the magnitude of the effect of X1 and better magnitude of the effect of x2 event.

882
01:34:04,500 --> 01:34:08,420
She doesn't shout at me for using a word effect in regression models but mean.

883
01:34:10,500 --> 01:34:17,280
Okay, so it's a neat little interpretation. What if you change X1 by adding one unit to it?

884
01:34:18,720 --> 01:34:24,450
How much does X2 change need to change to get the same amount of the same outcome?

885
01:34:25,050 --> 01:34:28,950
So it's sort of it's relative importance of X1 to x2.

886
01:34:29,550 --> 01:34:33,670
So you just the answer is minus B to what it would be to two.

887
01:34:33,690 --> 01:34:38,430
And you know, here's the algebra, which is so this is the right hand side of the equation.

888
01:34:39,090 --> 01:34:44,790
I'm going to say I'm going to add one on to a value of X1 and I want to get the same outcome.

889
01:34:45,780 --> 01:34:50,460
So how much do I have to subtract from x2? To get the same outcome.

890
01:34:50,490 --> 01:34:55,560
So this is just, you know, just added B to one in here and subtracted beta one here.

891
01:34:55,900 --> 01:35:01,200
Right. So I've seen you have to change X to by to get the same outcome as beta one of the beta two.

892
01:35:01,200 --> 01:35:05,579
So that's sort of same variance more or less whether you took the logs of a square root.

893
01:35:05,580 --> 01:35:16,190
So so it's a nice little property. There's no way I'm going to get to the final section today.

894
01:35:16,490 --> 01:35:21,770
It's okay. This is sort of a history of this class. We always plan stuff and we get for about two thirds of it.

895
01:35:21,860 --> 01:35:27,750
Not always, but we. But Phil was terrible, by the way, if you want to.

896
01:35:30,320 --> 01:35:33,920
Okay. So you so you could do transformations on the right hand side to.

897
01:35:35,920 --> 01:35:39,010
So again, it's the same goal you're trying to make.

898
01:35:39,190 --> 01:35:43,090
Write down a model which satisfies with type assumptions after you transform.

899
01:35:44,080 --> 01:35:51,100
So it's linear. Linear and linear models tends to be linear in my parameters.

900
01:35:51,110 --> 01:35:57,920
You can also think about it linear in X or linear parameters, but when you say linear model instead of linear parameters,

901
01:35:58,400 --> 01:36:01,969
because you look at this and you tell me, well, you, you took the square of the axes.

902
01:36:01,970 --> 01:36:06,140
And so it's not linear an experience. Linear model terminology is linear parameters.

903
01:36:12,490 --> 01:36:17,860
Okay. So we're getting, you know, getting the right structure and getting homogeneous variance is probably the most important things.

904
01:36:19,740 --> 01:36:24,580
We're going to go through this. Can do so now the likelihood.

905
01:36:24,700 --> 01:36:29,200
Right. So remember before I was trying to explain you know why you need to Jacoby

906
01:36:29,200 --> 01:36:33,970
own because you've transformed the data so that was a transformation of why.

907
01:36:34,570 --> 01:36:40,210
So this is the likeliest probability of observing why. So when you judge from the right hand side,

908
01:36:40,600 --> 01:36:48,309
the density I write down is Gaussian looking heat of a minus something squared should be little squared up.

909
01:36:48,310 --> 01:36:51,430
Here is the density of y.

910
01:36:51,860 --> 01:37:00,850
Right? So I don't need to have a Jacoby tell. Okay.

911
01:37:01,380 --> 01:37:05,550
As you know, this is boxing cock transformation.

912
01:37:05,820 --> 01:37:11,150
This was 1964. How did you. Many of your parents weren't even born properly.

913
01:37:11,160 --> 01:37:20,780
That name came out in 1764. It's sort of a step in different ways of doing this, which have been you know,

914
01:37:20,800 --> 01:37:29,140
a lot of you don't have to express nonlinear functions through parametric models like power transformations.

915
01:37:29,140 --> 01:37:33,430
You can do things like blind general smooth functions.

916
01:37:33,430 --> 01:37:38,420
G. If you have multiple axes, you might transform all of them or.

917
01:37:40,390 --> 01:37:44,320
Gamze says, I will never turn GAM generalize out of this model.

918
01:37:45,510 --> 01:37:51,390
That's where you should look for non-linear functions. She wanted x one plus G2 of x two.

919
01:37:51,420 --> 01:37:57,600
So instead of just putting a linear combination of a beat as you're willing to transform all of them using smooth functions,

920
01:37:57,600 --> 01:38:02,970
alignment, use algorithms for how to estimate whichis so this is so additive.

921
01:38:06,690 --> 01:38:09,820
And you can put link functions to make it like logistic regression too.

922
01:38:09,870 --> 01:38:13,350
So it's additive additive because we explore some interactions in here.

923
01:38:17,310 --> 01:38:21,540
Talk about that. I can do repeated measures.

924
01:38:22,950 --> 01:38:26,690
You can do other things of Mississippians. Quite a lot.

925
01:38:26,930 --> 01:38:34,590
Sometimes you might. I mean often so biological systems that some of your observations are zero.

926
01:38:34,980 --> 01:38:38,370
So if you start to try to take the logarithm of zero, you get in big trouble.

927
01:38:38,700 --> 01:38:42,999
So you sort of add one to the values and then you take the log, you add water,

928
01:38:43,000 --> 01:38:49,950
and then you take some transformation of there's families here, it's a log of y minus them.

929
01:38:49,950 --> 01:38:54,309
You might be minus one or something like that. Okay.

930
01:38:54,310 --> 01:38:57,380
Remember last. Thing. Okay.

931
01:38:57,590 --> 01:39:03,470
So I was going to talk about generally about transforming data between those two things and more.

932
01:39:04,400 --> 01:39:10,580
You might say this is old fashioned statistics, but it's sort of neat to know and something to be aware of.

933
01:39:10,580 --> 01:39:15,440
And so any questions on sort of the data part of it?

934
01:39:20,380 --> 01:39:26,190
I did my dissertation on bogus transformations before all of you were born.

935
01:39:27,030 --> 01:39:35,950
3.3 billion. So you all know what Pearson's correlation coefficient is, right?

936
01:39:35,960 --> 01:39:39,520
You draw a scatterplot, you can calculate Pearson correlation coefficient.

937
01:39:39,580 --> 01:39:46,340
I'm very familiar. I mean if you want to do just a descriptive, right, it's just, you know,

938
01:39:46,390 --> 01:39:54,370
you say a correlation coefficient is 0.3 and even you sort of know a little bit of association or is point eight is like really big.

939
01:39:54,910 --> 01:39:58,210
So maybe you want to give a confidence interval or some inference about that.

940
01:39:59,170 --> 01:40:05,440
So one way to do that is to rely on asymptotic distributions to be approximate confidence.

941
01:40:05,630 --> 01:40:08,790
Well, so here's the property of Pearson correlation coefficient.

942
01:40:08,800 --> 01:40:14,080
So the asymptotic distribution is Gaussian with a certain variance.

943
01:40:15,040 --> 01:40:24,249
And so it tells you that the consistency and gets larger estimate is consistent and you don't need the N here,

944
01:40:24,250 --> 01:40:27,610
but the variance sigma squared is actually a function of zero.

945
01:40:28,550 --> 01:40:34,340
This is sort of the old result from. More than a hundred years ago.

946
01:40:35,050 --> 01:40:38,800
And so to the issue of a problem, is the lack of a formula for this variance.

947
01:40:38,800 --> 01:40:48,470
It depends on. And so what would you know if you wanted to use this to construct a confidence interval?

948
01:40:48,490 --> 01:40:55,600
One thing you do is you just take the estimate plus or -1.9, six times over the standard error.

949
01:40:56,140 --> 01:41:01,630
And that's a confidence interval. That's a very standard world confidence interval, which hopefully you're all familiar with.

950
01:41:02,650 --> 01:41:09,340
So you do that. So so you take road plus a -1.96 sigma hat over and return,

951
01:41:10,270 --> 01:41:16,480
but so say so sigma how do you get Sigma how you plug in your estimate of rho would be what it was.

952
01:41:16,780 --> 01:41:21,340
But the estimate of Sigma, you know, is a function of Rho.

953
01:41:21,880 --> 01:41:26,050
So you don't really know you're trying to get an interval for, you don't know its accurately,

954
01:41:26,050 --> 01:41:29,200
so you've got to plug in some value for something you don't quite know.

955
01:41:29,200 --> 01:41:34,810
We had to plug in sort of a gas, so that's sort of can be a little bit problematic and so we can.

956
01:41:36,440 --> 01:41:43,239
Get over that problem by using. Fisher Z transformation.

957
01:41:43,240 --> 01:41:49,570
So this is the same fisheries as. All right fish fishers exact test people have heard about it made for two by two tables.

958
01:41:50,110 --> 01:41:55,090
Hopefully this good Fishers Z transformation.

959
01:41:55,510 --> 01:42:03,639
So you just take a transformation, a nonlinear function of a row which is of a spring half log, basically one cluster over one minus row.

960
01:42:03,640 --> 01:42:07,460
And you can also write it into some of a way to write it ten times.

961
01:42:08,030 --> 01:42:19,390
It is a ten h was a tangent h anyway the right in terms of that and then was a property but z this new variable new parameter.

962
01:42:20,740 --> 01:42:24,250
When you look at its asymptotic distribution, it doesn't depend on Roe.

963
01:42:25,010 --> 01:42:32,980
So whatever value of ROE has, you can get a you can get a decent estimate of a decent estimate of the variance.

964
01:42:33,490 --> 01:42:45,260
So that's a nice little. Trick and you'll see this and use sort of subtly in any sort of papers within trying to derive some some sort of algorithm,

965
01:42:45,260 --> 01:42:49,520
some estimates and situations where they have correlation or covariance matrices.

966
01:42:50,240 --> 01:42:55,010
So what the trick is to create the confidence interval for Z.

967
01:42:55,700 --> 01:43:02,830
You have an estimate of a correlation, you transform it, you get an estimate of this almost Z scale, create a confidence interval there.

968
01:43:05,310 --> 01:43:06,150
So see,

969
01:43:06,150 --> 01:43:15,210
plus or -1.96 times we got a root and then I'm transformers so you get confidence interval one scale you transform the limits back to the other scale.

970
01:43:15,660 --> 01:43:19,350
So that's a sort of a very nice trick and that's going to have better properties

971
01:43:19,350 --> 01:43:24,540
because you didn't have to assume anything about right when calculating the variance.

972
01:43:25,590 --> 01:43:39,959
And what's more, sometimes if your sample size is small, this confidence interval grow plus or -1.96 can go outside the range -1 to 1.

973
01:43:39,960 --> 01:43:44,950
So that's sort of embarrassing, right? No, call it correlation expressed between minus one and one.

974
01:43:44,950 --> 01:43:54,150
And you're going to tell someone is a confidence interval. It's like 8.7 to 1.3, you know, some kind of, you know, like that's not good,

975
01:43:54,930 --> 01:44:01,020
but is if you do have a Z transformation, that's just not going to happen. Just always kept it within that small range.

976
01:44:03,800 --> 01:44:08,380
I mean, probably just philosophical. Yet to serve a binomial.

977
01:44:09,490 --> 01:44:16,750
So the answer number binomial is did you learn about sort of confidence intervals for binomial probabilities?

978
01:44:20,520 --> 01:44:24,720
That being 6655635.

979
01:44:24,850 --> 01:44:29,580
Okay. What did they tell you was a good way of getting confidence intervals for binomial probabilities?

980
01:44:30,030 --> 01:44:35,100
Per person. Per person. Okay, well, that's one way to do it.

981
01:44:35,460 --> 01:44:42,030
Yes. As a whole in books on this stuff, actually there's lots of choices, but.

982
01:44:43,120 --> 01:44:47,080
Another example of a transformation based way of doing it.

983
01:44:47,380 --> 01:44:49,930
But it's more than one way transformation is.

984
01:44:55,000 --> 01:45:02,980
Civil service has the same problem you're trying to get a confidence interval for for p even a probability of a variance depends on P itself.

985
01:45:03,640 --> 01:45:07,750
So you think you're trying to get a confidence interval for you have to plug in an estimate of it.

986
01:45:08,170 --> 01:45:11,470
So acknowledging that you don't really know what it is anyway. So that's that's a problem.

987
01:45:12,280 --> 01:45:16,780
So is what's called variance stabilizing estimate.

988
01:45:17,410 --> 01:45:24,610
So you take the square root in a sign of a variance of that doesn't depend on P so you get a confidence

989
01:45:24,610 --> 01:45:31,900
interval on that scale and then you transform back to events or you can do it on the logic scale and.

990
01:45:33,390 --> 01:45:37,520
Go to the. You're going to stop here.

991
01:45:38,930 --> 01:45:49,260
You look at me. Just to show you how nicely Phil illustrated this.

992
01:45:52,500 --> 01:45:58,799
Barbara So Phil took my tourist slides. I just went through and thought they were too, like, ugly and my handwriting was bad.

993
01:45:58,800 --> 01:46:06,510
And so he modified him a little bit and put them in in a PDF.

994
01:46:13,020 --> 01:46:17,930
It's more fun to do mine. I think so. You know, same pictures, right?

995
01:46:18,600 --> 01:46:25,200
Was just my. Oh, some of my artistic same points.

996
01:46:27,830 --> 01:46:31,890
But I mean, something about these confidence intervals.

997
01:46:33,450 --> 01:46:39,129
Go ahead. So here's an example.

998
01:46:39,130 --> 01:46:50,670
I just went through his binomial example. So this oxide is very stabilizing when you can also take the logic of probability and use that,

999
01:46:50,870 --> 01:46:56,780
calculate the confidence interval on the larger scale and then transform back and see.

1000
01:46:57,000 --> 01:47:00,930
And you can see is just an example of a data set.

1001
01:47:01,200 --> 01:47:11,160
25 observations, three of them were ones and 20 2a0 is right, so the estimate is 1 to 12%.

1002
01:47:12,240 --> 01:47:17,610
So if you did the Standard World thing estimate plus or -1.9, six times the standard error.

1003
01:47:17,610 --> 01:47:21,320
So looking at the left hand end is a negative number here.

1004
01:47:21,420 --> 01:47:24,930
We just negative. It's negative. So it's not so good.

1005
01:47:26,100 --> 01:47:28,530
You do this arc sign transformation.

1006
01:47:30,350 --> 01:47:36,070
It's slightly different in the room who doesn't have a property that goes negative or if you do a legit transformation.

1007
01:47:37,590 --> 01:47:39,630
So it's a little different, you know?

1008
01:47:40,100 --> 01:47:46,410
You know, as I say, there's books written about how to do count covers, a set of rules for the with The Sopranos.

1009
01:47:51,960 --> 01:47:57,020
That's it. I think for today we want to have. Any questions soon?

1010
01:47:58,840 --> 01:48:04,120
Yeah. I'm Hannah again. I just had a quick question. So you usually would transform one or the other?

1011
01:48:04,120 --> 01:48:07,630
You wouldn't. There's not really an instance for to transform both an X and a Y.

1012
01:48:07,660 --> 01:48:15,550
Correct. I'm probably there, but it's some semblance sometimes, you know, if something really what someone biologically is like,

1013
01:48:16,390 --> 01:48:19,900
you know, experiencing, growing, you might always just transform that taking long.

1014
01:48:20,530 --> 01:48:24,480
Then you may be another variable. You know, you look at the data, you drew a scatterplot.

1015
01:48:24,520 --> 01:48:30,400
It doesn't look linear in the X. And so you might think about taking adjustment that's more context dependent.

1016
01:48:30,940 --> 01:48:34,450
Yeah, I think so. Let me just make one point mental.

1017
01:48:34,840 --> 01:48:41,600
So sometimes if you transform to think about this, we see this often as sort of a temptation.

1018
01:48:41,600 --> 01:48:48,010
So to think that you're going to take over your wife or your ex and let's just transform it to make it look symmetric.

1019
01:48:48,670 --> 01:48:57,850
That's not necessarily helpful and not necessarily not useful potentially to and but let's imagine a situation where

1020
01:48:57,850 --> 01:49:05,980
you got some X data and there's a few really big outliers in me X and you fit a regression model like Y on X,

1021
01:49:06,550 --> 01:49:10,810
there's big outliers in X could be very, very influential.

1022
01:49:11,080 --> 01:49:18,040
You know, whatever, whatever the Y value is, the values are going to be so too strongly influencing what I've become efficient like coefficient.

1023
01:49:18,610 --> 01:49:22,750
So then sometimes it makes sense time to pull in to do some transformation.

1024
01:49:22,760 --> 01:49:25,930
So you avoid some extremely influential observations.

1025
01:49:28,570 --> 01:49:40,250
How do you feel about inverse normal transformations? Just so that I just take all the quan and I map them on to a normal transformation.

1026
01:49:40,310 --> 01:49:45,530
Right. Right. So if you have a univariate set of data, you know,

1027
01:49:45,530 --> 01:49:50,320
I talked about taking square root some logs and you look at that and it looks about Gaussian height.

1028
01:49:50,330 --> 01:49:55,930
So you can actually sort of figure out exactly what the transformation is to make it look exactly Gaussian,

1029
01:49:55,940 --> 01:49:58,997
some sort of monotonic linear transformation. So you.

