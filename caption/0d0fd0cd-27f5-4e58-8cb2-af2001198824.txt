1
00:00:08,620 --> 00:00:12,220
I think it's. Okay.

2
00:00:12,240 --> 00:00:19,080
Welcome back. So? So last time we left it at a bad spot.

3
00:00:19,080 --> 00:00:24,570
So then we are going to kind of like go back and then what I'm going to do today that I'm going to do it with you.

4
00:00:25,080 --> 00:00:28,080
And remember, we have two different studies.

5
00:00:28,110 --> 00:00:36,060
The survey in 1987, that's the overweight 97 that I said, and then one in 2004, that's the 2004.

6
00:00:36,090 --> 00:00:45,790
Okay. So then we will be switching from one to the other. So what I'm doing here is that I'm I will create my what is this?

7
00:00:49,520 --> 00:00:53,720
I will run my library. Hopefully I have my.

8
00:00:54,650 --> 00:00:59,240
Oh yeah. There, here. I'm going to create temporary that essence.

9
00:00:59,750 --> 00:01:04,670
Right. So then always check. They love to make sure that things are clean.

10
00:01:04,670 --> 00:01:10,309
And then you can see that there were white 97 that I said has 400 situations.

11
00:01:10,310 --> 00:01:14,240
And then there they go. The one that was written for has 307.

12
00:01:14,510 --> 00:01:19,820
Okay. So then we were at that point in the kind of like.

13
00:01:23,120 --> 00:01:27,160
And it was possible like. Right. Um.

14
00:01:33,160 --> 00:01:37,270
If we go to them to the lab.

15
00:01:37,660 --> 00:01:43,629
So we were doing we were creating binary outcomes and report the prevalence of the outcomes of this, decide the outcome.

16
00:01:43,630 --> 00:01:48,820
So we are creating binary variables based on the three set scores, right?

17
00:01:48,970 --> 00:01:52,390
And then we're using minus two as the catalyst. So don't get confused.

18
00:01:52,390 --> 00:01:55,390
This mine is less than minus two.

19
00:01:55,390 --> 00:01:58,450
So some people were put in like an equal or something like that.

20
00:01:58,900 --> 00:02:04,180
So so you can actually at four do that for doing that.

21
00:02:04,180 --> 00:02:07,270
And this is these datasets. So we do.

22
00:02:11,950 --> 00:02:18,350
During my temporary there I said, so then I don't kind of like do anything in the permanent one.

23
00:02:18,370 --> 00:02:28,330
Right. So then you you can definitely use an F then a statement like if the z-score is less than minus two,

24
00:02:28,360 --> 00:02:35,830
then my new variable will be one as if will be kind of like a zero.

25
00:02:36,130 --> 00:02:39,010
Oh, you can use this other one that I personally like a lot,

26
00:02:40,450 --> 00:02:49,929
which is very elegant and I think I have should show you this before, so I need to remember.

27
00:02:49,930 --> 00:02:59,799
So this is the other thing that I realized the other day is that I know these data sets my heart rate,

28
00:02:59,800 --> 00:03:03,650
so then I know what the variable name said that, but you don't.

29
00:03:03,670 --> 00:03:09,130
So then any time that you have to start something, then you have to do a bit of content.

30
00:03:09,910 --> 00:03:13,420
Okay. Because that will kind of like basically give you.

31
00:03:15,890 --> 00:03:23,780
The list of variables you have with the labels, and then you will know how they name and then what they are.

32
00:03:23,780 --> 00:03:28,010
And sometimes in the label that is going, I add Vicodin in the label.

33
00:03:28,310 --> 00:03:33,799
So if I do that now, you can see here that you have all the variables that you have in the dataset.

34
00:03:33,800 --> 00:03:38,240
Right. So can you see the screen.

35
00:03:38,300 --> 00:03:41,360
Okay. Not really. I yeah.

36
00:03:42,140 --> 00:03:45,890
Let me see because I you can see this very right.

37
00:03:45,890 --> 00:03:55,640
So this is okay, so let me see if I can. And then I'm very sensitive to visual things because I myself cannot see in the near distance.

38
00:03:56,030 --> 00:03:59,569
I cannot see in any of this. Okay. So let me see.

39
00:03:59,570 --> 00:04:03,910
I think is. Uh.

40
00:04:08,840 --> 00:04:13,550
What would they have to lose? Right here.

41
00:04:23,990 --> 00:04:47,550
No. I don't know what it is.

42
00:05:01,580 --> 00:05:05,180
Nothing that changes.

43
00:05:05,180 --> 00:05:12,380
They don't know how to change the font in there in their output.

44
00:05:12,500 --> 00:05:17,870
I mean, they know how to change it here. So then you can see it much, even much larger.

45
00:05:17,870 --> 00:05:22,760
But I don't know here. But it's okay. You just kind of run it with me and then you can see it on your screen.

46
00:05:23,090 --> 00:05:30,560
I'll check later if I. If I see how to do that. Anyway, so here you can see that that you have labels for everything.

47
00:05:33,020 --> 00:05:36,330
So that's the first thing that you have to do with any data set. Right.

48
00:05:36,360 --> 00:05:41,419
I mean, because if you don't know whether I said you go, I mean, sometimes you are when you're given addresses,

49
00:05:41,420 --> 00:05:44,840
sometimes you're given documentation like either the dictionary.

50
00:05:44,840 --> 00:05:49,700
Right. Or like a document that says actually this kind of things like I mean,

51
00:05:49,700 --> 00:05:54,020
what variables you have what, what, what, where they are, how they are going, that is like that.

52
00:05:54,030 --> 00:06:01,159
But if you are not given that for whatever reason, then at least you can always have a contest and take whatever they will say how they are,

53
00:06:01,160 --> 00:06:05,989
name what type of variable that this is kind of like sometimes important because I mean

54
00:06:05,990 --> 00:06:10,610
here I always use numeric variables by default because I think they are easy to work with.

55
00:06:10,820 --> 00:06:15,890
But some people like using that variable. So then you have to be aware of that because and this I mean,

56
00:06:16,250 --> 00:06:24,190
it's not the same to work with I whatever that nomadic for this class and worry about that because all of them will be nomadic.

57
00:06:24,620 --> 00:06:27,950
But in the future, that's something that you have to pay attention to.

58
00:06:28,520 --> 00:06:32,420
Okay. So then I going back to how to create those variables.

59
00:06:34,670 --> 00:06:42,390
So remember something you had to use with h a z score the height for edge C it's called.

60
00:06:43,860 --> 00:06:49,970
So. So if you write this.

61
00:06:50,750 --> 00:07:04,550
So basically what I'm asking says here is to create a variable that says is going to go through this experiment and then this is taking this through.

62
00:07:04,670 --> 00:07:11,480
So you get height for H, this core is less than minus two, then that variable is going to be one.

63
00:07:11,900 --> 00:07:15,800
And in this case, they mean is false that whatever is going to be zero.

64
00:07:16,340 --> 00:07:22,639
So you can see that this is equivalent to use an event statement but actually is a kind of like nice,

65
00:07:22,640 --> 00:07:28,000
short, elegant way of creating binary variables that you can use in the future.

66
00:07:28,030 --> 00:07:33,020
You don't like this one. Go back to your eve then, and that's perfectly fine.

67
00:07:33,050 --> 00:07:37,210
Right. So I'm just giving you this as another option then.

68
00:07:38,540 --> 00:07:42,290
And then we can do the same for waste, Steve.

69
00:07:44,600 --> 00:07:49,810
And then they will be there. And they work.

70
00:07:49,870 --> 00:07:54,740
However, they closed on their way.

71
00:07:55,400 --> 00:07:59,750
We've got it. I mean, we can do this things for the place.

72
00:08:10,970 --> 00:08:13,010
Wait for it. Right.

73
00:08:13,370 --> 00:08:20,950
So and you can create, of course, the three variables in the same that I said you don't need to create to do one data set for every variable.

74
00:08:20,960 --> 00:08:25,900
Right. So if I run that. Looks good, right?

75
00:08:25,960 --> 00:08:31,120
I'm not making any mistake. If not, SAS is going to tell me anyway.

76
00:08:32,700 --> 00:08:37,599
So it looks like it's okay. So whenever you do that, whenever you create one variable.

77
00:08:37,600 --> 00:08:45,850
Even if I'm not asking for that in the homework, go and check that the variables you created I will create.

78
00:08:45,880 --> 00:08:54,370
Right. So how so? How do you think that you can check that those variables were well created?

79
00:09:00,630 --> 00:09:04,160
I'm sorry. Can you go to a temporary departure that you didn't know?

80
00:09:04,350 --> 00:09:09,630
School. War crime data. So go to Assad and check.

81
00:09:10,080 --> 00:09:14,610
I mean, you can do that and see that the first few observations are fine.

82
00:09:14,610 --> 00:09:22,020
But that I mean, what if for whatever reason, I mean, this situation probably will work like for other more complicated things.

83
00:09:22,230 --> 00:09:25,230
It won't work because maybe you are missing some observations that may.

84
00:09:25,260 --> 00:09:29,070
I mean, some categories may not be well created and then you're missing something.

85
00:09:29,340 --> 00:09:33,690
Or maybe in this situation, there are no missing variables that are missing variables.

86
00:09:33,690 --> 00:09:35,130
Maybe you have problems at this level.

87
00:09:35,400 --> 00:09:44,480
So the kind of like a better way of chicken is that for that you are creating binary variables for continuous variables using Godot.

88
00:09:44,640 --> 00:09:52,220
Right. So what you can do is a broke means of that continuous variable using the binary variable in the class estimate.

89
00:09:52,230 --> 00:09:56,450
And then you can see the range goes kind of like in, in the proper way.

90
00:09:56,460 --> 00:10:07,830
I mean as you expect ratio, I can do this. Let's do it for the standing.

91
00:10:09,510 --> 00:10:18,480
And then the variable is this. And if I run that, what I'm going to have is.

92
00:10:21,270 --> 00:10:28,440
I get. And you? I get my variable standing zero once I have 183.

93
00:10:28,560 --> 00:10:31,200
It's not a stunt in 107 standard.

94
00:10:31,500 --> 00:10:40,310
And then I can see here in the minimal maximum that actually they're the minimum for the stunt in is -1.99, which is exactly what I'm saying.

95
00:10:40,320 --> 00:10:46,820
Kind of like if you are below minus two kind of light, so you are above minus two, then you are okay, right?

96
00:10:46,830 --> 00:10:51,800
You are not this 90 and then this the maximum here is minus two and goes to minus five.

97
00:10:51,810 --> 00:10:55,610
So then you are kind of like you can see in the range that it's correct.

98
00:10:55,620 --> 00:11:01,880
So then we are cabinet minus two and then everyone above minus two is classified as not standing.

99
00:11:02,460 --> 00:11:05,760
Everyone below minus two is classified as a standing.

100
00:11:06,150 --> 00:11:10,320
Right. So you can do that for the other two to make sure that that you I mean,

101
00:11:10,320 --> 00:11:15,360
maybe you don't need to do it now, but for the future, it's always good to check the Bible.

102
00:11:15,750 --> 00:11:19,170
Okay, so now that you bear all that step.

103
00:11:19,650 --> 00:11:24,600
No, you have to to check the prevalence of everything.

104
00:11:24,600 --> 00:11:33,059
Right. And the first thing and of course, I'm asking you to use the the sorry, Brooks, because remember,

105
00:11:33,060 --> 00:11:38,220
the whole thing about this that I said is that it was collected using a complex design,

106
00:11:38,640 --> 00:11:43,020
a design that involves clustered clustering in several stages in this situation.

107
00:11:43,020 --> 00:11:50,339
Right. So then for this particular or this one actually has also Estrada, remember?

108
00:11:50,340 --> 00:11:56,159
So it has both I mean they of a white the 97 only has clustered in the 2004 has both

109
00:11:56,160 --> 00:12:00,150
clustered in and this thread right so you have to take into account those things.

110
00:12:00,630 --> 00:12:03,930
So you go and you do your scientific.

111
00:12:12,470 --> 00:12:17,660
And then remember that the same back score, they put everybody out at the same table.

112
00:12:17,660 --> 00:12:25,220
So then you can put your all on your brochure and.

113
00:12:34,030 --> 00:12:38,920
And you need to add your cluster statement.

114
00:12:39,820 --> 00:12:47,770
So that statement and witness statements. Right. And then I don't remember from the top of my head actually I gave you the whole thing.

115
00:12:47,770 --> 00:12:51,940
So this is the stress statement you can see. So you can just copy and paste.

116
00:12:56,520 --> 00:12:59,910
So you can go here? Yes.

117
00:13:04,350 --> 00:13:19,850
This is a cluster statement. And then we can go to the weight statement.

118
00:13:31,770 --> 00:13:37,260
Now don't get confused with this with the other that I said that we saw in this life.

119
00:13:37,470 --> 00:13:41,880
Because the other one, I said, first, do they have this statement or you need that?

120
00:13:42,180 --> 00:13:49,080
And secondly, what I was there was the classic the environment was called clustered and the white variable was, well, which way?

121
00:13:49,260 --> 00:13:53,880
So then use the proper variables in each that I said, otherwise you won't be able to get anything right.

122
00:13:54,180 --> 00:13:59,879
So then you run that. Then in this situation, you have your three binary variables.

123
00:13:59,880 --> 00:14:05,970
You want to know the prevalence of the standing question and then the weight taking into account the complex the same.

124
00:14:06,540 --> 00:14:11,820
So that means taking into account the clustering, the stratification and the sample weights.

125
00:14:12,240 --> 00:14:25,120
Right. So we do that. And then we get three tables for each of the variables.

126
00:14:25,570 --> 00:14:36,730
And then you can see that. Remember that, that this prevalence is already weighted already by the sampling weights.

127
00:14:36,880 --> 00:14:45,910
Okay. So if you divide 170 by 300 is probably not 38 because I will be then not weighted a prevalence which is not the one you want.

128
00:14:45,970 --> 00:14:50,640
Right, because that's wrong. I mean, the one you want is the way the one because you want to apply the sampling weights.

129
00:14:50,660 --> 00:14:56,260
Right. So you have a prevalence of the stunting that is 38%.

130
00:14:56,650 --> 00:15:01,360
Then you have a prevalence of wasting that is 4.8%.

131
00:15:01,750 --> 00:15:07,870
And then you have a prevalence of underweight that is 12.5%.

132
00:15:08,470 --> 00:15:17,830
Right. Now, I think I may say what I am asking you with their confidence interval.

133
00:15:21,400 --> 00:15:27,040
So what you can do. Yes.

134
00:15:27,040 --> 00:15:34,209
Here you put a slice and then you put C, and that's going to give you the confidence limit.

135
00:15:34,210 --> 00:15:37,750
So then I'm going to run this again as I'm asking you the confidence.

136
00:15:39,870 --> 00:15:42,879
So see, now you have the confidence interval.

137
00:15:42,880 --> 00:15:48,430
So that kind of like for a standing, you have your prevalence still 78%, right?

138
00:15:48,430 --> 00:15:52,060
But this 30 to 45 is the confidence interval, right.

139
00:15:53,020 --> 00:16:00,309
And the same for the others. Now, this is the correct way of doing things here, right?

140
00:16:00,310 --> 00:16:05,709
So taking into account the complexity, saying back in the in the homework,

141
00:16:05,710 --> 00:16:12,670
I'm actually asking in C I'm asking you to report the prevalence of a standing

142
00:16:12,670 --> 00:16:16,030
and the way down waste in the same with a corresponding confidence limit.

143
00:16:16,450 --> 00:16:24,489
But assuming that this data is not coming from this kind of like complex design, but it's coming from random simple sampling rights,

144
00:16:24,490 --> 00:16:29,830
assuming that you don't have to apply either sampling weights or clustering or stratification.

145
00:16:29,890 --> 00:16:42,030
Okay, so then basically what you have to do. If you can, is the I mean, you could use a normal proc freak or even easier actually.

146
00:16:42,050 --> 00:16:49,130
Well, you can do that because that way then you can continue using the confidence limit by default.

147
00:16:49,610 --> 00:16:54,700
Is that you use the proxy effect, but you delete all the statements.

148
00:16:55,310 --> 00:16:56,330
So then you do that.

149
00:16:56,630 --> 00:17:04,300
Then basically SAS is going to report like not weighted prevalence without taking into account any clustering or any stratification.

150
00:17:04,310 --> 00:17:09,080
So these will be equivalent. This is going to be equivalent.

151
00:17:12,110 --> 00:17:21,070
To this. The only thing is that I don't know why I improperly that confidence limit option doesn't work that way.

152
00:17:21,080 --> 00:17:24,740
You had to do something else. So that's why I'm kind of like telling you to do this other way.

153
00:17:25,100 --> 00:17:30,290
Okay. But in theory, they are equivalent in the in terms of, of, of, of preventing.

154
00:17:30,380 --> 00:17:36,160
Actually, what we can do is that we can get rid of this, but you will still get the same brilliance.

155
00:17:36,350 --> 00:17:44,570
So you run this and then you can see that the prevalence here is 35%.

156
00:17:44,960 --> 00:17:50,150
And remember, what was the prevalence before? What was the prevalence before?

157
00:17:53,560 --> 00:17:56,720
What, 30, 38. Yeah. So you can see it's different, right?

158
00:17:56,740 --> 00:18:00,640
I mean, that. Is that what you were expecting? Yeah.

159
00:18:00,850 --> 00:18:05,350
Yeah. They should be different because here you are not applying weight and in the other way you're applying what's.

160
00:18:05,620 --> 00:18:10,880
They are not really different. Honestly, I mean, most likely because maybe the weights are not that different.

161
00:18:10,910 --> 00:18:15,380
Right. I mean, it's not that some kids have huge weights and some other kids don't.

162
00:18:15,400 --> 00:18:18,700
Right. So maybe they are not that different or maybe the representation is not that variable.

163
00:18:18,700 --> 00:18:23,350
Right. But but but they are different. They are still different, which is what you were asking.

164
00:18:23,680 --> 00:18:28,240
And you look at the confidence limits. Should they be different?

165
00:18:32,990 --> 00:18:38,720
In theory, yes. Right. Again, Santis may not be that different, but in theory, yes.

166
00:18:38,760 --> 00:18:43,790
And I'm not going to answer the other question because that's something that you have to think about.

167
00:18:43,790 --> 00:18:50,630
But the idea is kind of like you go to the and eat and then you tell me if there are differences and if so, why?

168
00:18:50,870 --> 00:18:55,879
I mean, this is something that you were expecting, right? Even if there are no differences, you can tell me what I mean.

169
00:18:55,880 --> 00:18:59,180
There not huge differences, but I'm expecting differences because of these, this and this.

170
00:18:59,450 --> 00:19:03,200
So remember and this is everything based on one thing.

171
00:19:03,200 --> 00:19:08,150
Is there sampling weights? The other thing is they're clustered in this stratification.

172
00:19:08,240 --> 00:19:20,310
And the sampling weights affect mostly the prevalence, the point estimate, because the point estimate is basically a weighted prevalence.

173
00:19:20,360 --> 00:19:22,010
So you don't apply the sampling weights,

174
00:19:22,370 --> 00:19:29,570
you will find difference in prevalence while they clustering and they stratification affect the confidence interval.

175
00:19:31,070 --> 00:19:36,200
And this is because remember last week at the beginning of the class that I was telling you,

176
00:19:36,200 --> 00:19:43,250
this is correlated data in a way because this is redundant data because they come from the same village in the same household.

177
00:19:43,460 --> 00:19:46,910
So they have more things in common than gifts from all their relatives.

178
00:19:46,910 --> 00:19:52,100
Right. So when you do simple random sampling, people are completely independent.

179
00:19:52,250 --> 00:19:56,479
But when you do this type of clustering, people are a little kind of like correlated.

180
00:19:56,480 --> 00:19:58,580
I mean, not terribly, but a little correlated.

181
00:19:58,580 --> 00:20:08,090
And correlation means that you have more uncertainty in terms of kind of like because in a way, the kids are more Rwandan, they are more similar.

182
00:20:08,090 --> 00:20:14,990
So they are not giving as much information and that that uncertainty translates into wider confidence intervals.

183
00:20:15,710 --> 00:20:23,930
Okay. So in theory, the the the the clustering and the certification is giving you wider confidence intervals.

184
00:20:24,560 --> 00:20:28,160
If you remove that, then the confidence interval should be narrower.

185
00:20:28,690 --> 00:20:32,420
And I'm giving you the answers. So please pay attention and take note.

186
00:20:32,690 --> 00:20:34,909
Okay. So that's that's the whole theme.

187
00:20:34,910 --> 00:20:44,420
And this is this is the main message of this whole topic on survey design, understanding, sampling weights versus justification eyeglasses.

188
00:20:44,720 --> 00:20:48,260
Okay. Okay. So let's let's continue.

189
00:20:49,100 --> 00:20:52,770
So now let's go back to the to them.

190
00:20:55,190 --> 00:21:00,190
So let me see this one moment.

191
00:21:12,530 --> 00:21:17,730
So. Okay.

192
00:21:17,940 --> 00:21:21,180
So so let's go back to the next step.

193
00:21:21,240 --> 00:21:24,900
Okay. So the first thing you do is to just get the prevalence.

194
00:21:24,960 --> 00:21:28,200
So now that you want to do something else with that, with your data, right.

195
00:21:28,200 --> 00:21:31,590
You want to kind of like be able to analyze other things.

196
00:21:31,950 --> 00:21:35,820
So I think we left here.

197
00:21:37,950 --> 00:21:45,670
So now let's see how we can kind of like check categorical association of categorical variables.

198
00:21:45,690 --> 00:21:50,220
Our main outcome is a binary variable. It's a categorical variable, right?

199
00:21:50,430 --> 00:21:57,329
It's a stamping yes. No. For the homework or overweight?

200
00:21:57,330 --> 00:22:01,320
Yes. No for this. Let's remember, we are working in parallel.

201
00:22:01,440 --> 00:22:07,229
Don't get confused. So you can also do two like two tables or two.

202
00:22:07,230 --> 00:22:11,580
But in my enables, I mean it doesn't have to be binary,

203
00:22:11,580 --> 00:22:16,980
but in this situation is going to be binary and out of the variables that we are going to check are going to be binary to the parameters.

204
00:22:17,520 --> 00:22:22,640
So so you can do two by two table with blocks are reflect the same as you do them with property.

205
00:22:22,860 --> 00:22:29,110
Right. So and then calculate the corresponding statistical test which should be what is the test?

206
00:22:29,160 --> 00:22:39,150
Is that the single best that you do when you have a do I do table. You mean the statistical this.

207
00:22:39,170 --> 00:22:43,090
Yeah. No, but that's. That's for the multivariate.

208
00:22:43,090 --> 00:22:46,569
Well, I mean, this is just bivariate. You have a two way to table.

209
00:22:46,570 --> 00:22:50,200
You take the association with you there, the guys.

210
00:22:50,440 --> 00:22:57,340
Exactly. So it's a chi square is the same exact way, but it's especially Chi Square, right.

211
00:22:57,520 --> 00:23:01,569
Because they designed the complexes and require some tweaking.

212
00:23:01,570 --> 00:23:05,320
Right. So this is actually called Ra scored chi square.

213
00:23:05,860 --> 00:23:09,280
That takes into account the composition, but it's the same as I score. Okay.

214
00:23:09,760 --> 00:23:16,300
So SAS is going to give you that statistic with a p value that will tell you if it's statistically significant or not.

215
00:23:16,600 --> 00:23:26,770
So that's not different that what you are doing. So I, I, I'm trying to kind of like, I'm not sure if I'm doing okay,

216
00:23:26,770 --> 00:23:35,870
but kind of a trend that you feel comfortable because this is the same things that you have been doing so far is just there are small tweaks, right?

217
00:23:35,890 --> 00:23:39,550
But is the same is like a square. I mean that doesn't that is not different, right?

218
00:23:39,700 --> 00:23:41,800
And then you interpret things the same way,

219
00:23:41,980 --> 00:23:46,570
says you have to kind of like take into account those things of the sampling ways that clustered in and so on.

220
00:23:46,570 --> 00:23:49,600
But the, the overall thing is the same, right?

221
00:23:50,170 --> 00:23:58,450
So, so now remember, we are going back, we're going to do first the, the, the 97 survey.

222
00:23:58,780 --> 00:24:09,970
I want to live with you so then you can do it with me. And our question is, if there is any association between being bottle fed and being overweight.

223
00:24:11,590 --> 00:24:18,760
So if I'm telling you what I'm interested in exploring, is this an association between being bottle fed and being overweight?

224
00:24:18,760 --> 00:24:22,120
What would be your hypothesis based on your nutrition knowledge?

225
00:24:32,190 --> 00:24:36,239
Yes. I mean, I see people having I don't know what you know, but what does it mean?

226
00:24:36,240 --> 00:24:40,950
I mean, what are the hypotheses? What is that? What is the direction of the association?

227
00:24:40,950 --> 00:24:44,849
What would you expect? Well, first, we just put an association, yes or no.

228
00:24:44,850 --> 00:24:49,020
And if is an association, what is there that action of people?

229
00:24:51,390 --> 00:24:55,980
So you would expect that being bona fide will increase the risk of overweight.

230
00:24:56,050 --> 00:24:59,520
Right. Yeah. That's what that's what we know from the literature.

231
00:24:59,520 --> 00:25:07,530
Right. That in general kind of like model said as opposed to breastfeeding tends to increase the risk of overweight babies,

232
00:25:07,800 --> 00:25:12,330
except that that's that's what we would expect to see.

233
00:25:12,360 --> 00:25:15,960
Let's see if that's what we find. So now this is the syntax.

234
00:25:16,080 --> 00:25:21,580
So you use the same sort of risk. Remember, this one doesn't have a stratification.

235
00:25:21,580 --> 00:25:28,290
So I'm only put in the clustered and the weight and not here. Don't get confused because sometimes I'm moving the statements up and down.

236
00:25:28,500 --> 00:25:35,880
It doesn't matter. I mean, SAS is not picky about that. So you can put the table statement above their weight below,

237
00:25:36,120 --> 00:25:41,060
or you can just make them as long as they are between the block and the run, it will be okay.

238
00:25:41,070 --> 00:25:46,920
Right. So I have my statements here that could be below, but it doesn't matter.

239
00:25:46,920 --> 00:25:48,989
And then in the tables statement,

240
00:25:48,990 --> 00:25:57,870
I'm doing the same as I do in a I just take my outcome variables have a weight and my predictor or specialist bottle fed is called bottle.

241
00:25:58,200 --> 00:26:02,400
And then I just put them with an asterisk. So that's going to create a two by two table.

242
00:26:03,090 --> 00:26:12,629
And here if you remember freak from previous classes and sass output block three

243
00:26:12,630 --> 00:26:17,370
gives you like a two over two table that gives you the row frequencies and then 3%.

244
00:26:17,370 --> 00:26:25,020
That is right. Those three percentages are the cell percent that the row percentage and the column percentage which usually they are,

245
00:26:25,590 --> 00:26:32,249
is very kind of like it's like a mess because sometimes you get confused about which one you have to big and so on.

246
00:26:32,250 --> 00:26:38,340
And then you had to kind of like think a little bit about, okay, no, I want the role I to go along and things like that.

247
00:26:38,370 --> 00:26:47,189
Right. Okay. So in Brookside with Rec, the two by two table is a little different because there is so much information because it says

248
00:26:47,190 --> 00:26:53,700
has to add the weighted frequencies that it can really give you the usual two way to table.

249
00:26:54,330 --> 00:27:00,120
So because of that, by default, it's only going to give you the cell percentage.

250
00:27:02,370 --> 00:27:07,950
Cell percentage is that basically is whatever you have in that cell divided by the delta.

251
00:27:08,400 --> 00:27:17,880
But you know from previous classes that you don't want the cell percentage because that's usually what you do when you when you wrap or something.

252
00:27:17,910 --> 00:27:23,430
You have like a table that you have standard, not a standard or he had this overweight, not overweight.

253
00:27:23,730 --> 00:27:31,650
And then you want to see the percentage of kids who are both of among those who are overweight and among those who are not overweight.

254
00:27:31,650 --> 00:27:36,270
So that's more like a column percentage, right? So the cell percent, this is not useful for you.

255
00:27:36,900 --> 00:27:44,580
So now I'm going to add here and I'm going to put the row percentage because and this is I know it's confusing

256
00:27:44,580 --> 00:27:50,400
because I told you you just told me that is the column percentage depends on how you construct your table.

257
00:27:50,430 --> 00:28:00,450
Okay. So based on how I put my table and how I put my two and what I was here in this situation, the one I want is the row percentage.

258
00:28:00,750 --> 00:28:04,110
But that's something that you can change. I mean, depending on how you I mean,

259
00:28:04,110 --> 00:28:12,089
and I encourage you to play with that later when you have some time to kind of like change the order of the variables.

260
00:28:12,090 --> 00:28:18,059
And then you will see that your row now will be like the column that you want, didn't want to go the other way around.

261
00:28:18,060 --> 00:28:23,940
Right? So wrong column. It doesn't matter as long as you understand what is the role and what is the column that you want to report.

262
00:28:23,970 --> 00:28:27,720
Okay, but for sure you have to add something because what you don't want is the cell.

263
00:28:28,080 --> 00:28:43,709
So be careful about that. And I have to add so I have to add the guy square here, it has to be there because.

264
00:28:43,710 --> 00:28:47,850
Well, okay, so, so those two things are new here.

265
00:28:48,270 --> 00:28:56,520
So let's, let's go and then let's try and access.

266
00:29:01,610 --> 00:29:11,960
So I, I probably need to kind of, like, create this sort.

267
00:29:23,920 --> 00:29:38,590
And. You haven't really thought that you would have to do that the same as I'm doing that.

268
00:29:41,410 --> 00:29:53,020
We were using we were getting what I don't remember from the top of my head when I said that the vision and the inimitable,

269
00:29:54,070 --> 00:29:57,790
it was what I did write like this.

270
00:29:58,370 --> 00:30:04,870
Now they're way too high to score more than one day. Can someone take them to.

271
00:30:05,310 --> 00:30:08,330
Negative? No, that was for a Sunday.

272
00:30:08,360 --> 00:30:11,509
Now we remember we're switching from one extreme to the other.

273
00:30:11,510 --> 00:30:19,830
So this is they were weighed one. So then the the at risk of overweight attribute not so much like the variable overweight that's.

274
00:30:20,420 --> 00:30:24,710
Oh, it's already there. Okay, great. Thank you. Okay, wonderful.

275
00:30:25,100 --> 00:30:34,069
So we know how to. Okay. So then we are going to do we actually can use various blocks, every flake as a template.

276
00:30:34,070 --> 00:30:38,280
And then we will just. Change things.

277
00:30:38,310 --> 00:30:49,520
Now, remember, this is the other one. Okay, so change the overweight volume and then that would weigh the risk.

278
00:30:49,530 --> 00:31:05,370
And then this is the, um, we want to do all the weight, uh, by body because I know this is a bowl of get rid of the coffee limit.

279
00:31:05,430 --> 00:31:11,580
You don't want that. What you want now is a square and you want the overall percentage, hopefully.

280
00:31:11,970 --> 00:31:15,480
And now remember this one, there's a half a stratification.

281
00:31:15,990 --> 00:31:22,950
And then the clustering is called cluster and the weight is called weight.

282
00:31:23,130 --> 00:31:27,270
Right. Wait, wait.

283
00:31:28,110 --> 00:31:38,069
Thank you. Yeah. Okay, so we will run this and then I'm going to show you the slide to because this is c I mean,

284
00:31:38,070 --> 00:31:44,450
this is this is your do I do table, which is you look at that, I say, I mean, does not apply to table.

285
00:31:44,460 --> 00:31:47,660
That looks like so many rows and so many columns. Right.

286
00:31:47,970 --> 00:31:53,490
And it's true. I mean, it's too much information, but actually it's a two by two table because it's kind of like here.

287
00:31:53,490 --> 00:32:00,360
I mean, look at you have here, your outcome is always zero or one and then your special is zero one, zero one.

288
00:32:00,360 --> 00:32:03,690
So now weight is kind of like you said to like two table in rows, right?

289
00:32:04,050 --> 00:32:11,220
So let's, let's, let's look at that in the in the in the slide because you can look at that better.

290
00:32:12,240 --> 00:32:24,840
Well, so, so, so, okay, so, so see that this percentage that SAS gives me by default, this is this small percent,

291
00:32:24,840 --> 00:32:32,630
this you don't want that one because this is basically is is this 26% means that do anything.

292
00:32:32,940 --> 00:32:36,929
36% of all kids are overweight.

293
00:32:36,930 --> 00:32:43,379
I'm not not overweight, I'm afraid. Right. Of 53% of all kids are not overweight.

294
00:32:43,380 --> 00:32:54,480
Are not. But as I said in this list, these two and these two, so 53 plus 2 to 26, that 70 plus two, they should sum up to 100.

295
00:32:55,080 --> 00:33:00,809
You don't want that cell percent because I mean, you don't want that. I mean, maybe at some point in your life you need that to report that.

296
00:33:00,810 --> 00:33:02,969
But usually you never report things like that.

297
00:33:02,970 --> 00:33:10,830
Usually what you report is, okay, what is the percentage of body fat kids are mono normal weight and what is the percentage of body fat kids?

298
00:33:11,130 --> 00:33:14,340
I'm on overweight because that's what you're comparing, right?

299
00:33:14,850 --> 00:33:19,190
So then for that, you need that percentage. They're all percentage, see.

300
00:33:19,500 --> 00:33:26,370
So then basically you can see that I'm on non other weight, 32, almost 33%.

301
00:33:26,730 --> 00:33:30,360
I bought five and I'm on overweight kids.

302
00:33:30,930 --> 00:33:45,330
14% are total thing which is kind of like hmm that is going there that Asian that you on by the way then you get your you go to SAS,

303
00:33:45,450 --> 00:33:52,559
you can see here that the table is here of their always scored guys casualties

304
00:33:52,560 --> 00:33:56,190
and of course SAS is going to give your more theirs that you're asking for.

305
00:33:56,310 --> 00:34:00,360
But it's okay. You just ignore everything and you just pick the one that you need.

306
00:34:00,690 --> 00:34:04,649
You ignored these two things. You are this and then you just go to this.

307
00:34:04,650 --> 00:34:10,770
This is the real split. It's called Chi Square. So this is the the statistic and this is their p value.

308
00:34:10,770 --> 00:34:15,540
This is your British P value. This is the one that you want to tell you. If it is, that's a statistically significant.

309
00:34:15,540 --> 00:34:19,709
Right? So so this one.

310
00:34:19,710 --> 00:34:22,950
So the p value is less than 0001.

311
00:34:22,950 --> 00:34:27,179
So then this is a statistically significant, highly statistically significant.

312
00:34:27,180 --> 00:34:30,450
Right, which is if you were expecting an association.

313
00:34:30,450 --> 00:34:36,480
But now look at the percentages and tell me, is it going in the direction that you were expecting?

314
00:34:40,940 --> 00:34:49,260
No, actually the opposite. Right. So you have less M&A over where you would expect in a higher percentage of bonafide gifts and the other way around.

315
00:34:49,280 --> 00:34:51,800
Right. And actually, it's not like that.

316
00:34:52,040 --> 00:34:59,640
So you have more bona fide gifts in the overall in the non overweight and less overweight kids in the in the overweight.

317
00:34:59,660 --> 00:35:03,890
So what what's going on? Why do you think that is going on?

318
00:35:17,030 --> 00:35:20,240
And there is no wrong or right answer. You can just. Yes.

319
00:35:23,620 --> 00:35:32,290
Many more children are being. Populations are on population and children being vital to this.

320
00:35:33,840 --> 00:35:45,280
Well, these are the percentages in your population. So it actually is like let me say that you can look at the numbers actually.

321
00:35:45,280 --> 00:35:49,599
Let's look at the other raw numbers. So, I mean, you're right.

322
00:35:49,600 --> 00:35:52,900
I mean, there are not many people who are more afraid.

323
00:35:53,170 --> 00:36:01,930
Most mosquitoes are breast fed. So so you're so you're saying that because you have such a small number of associations can go in any direction?

324
00:36:02,770 --> 00:36:06,970
That would be. Yeah. Because randomly I mean, you don't have kind of like random.

325
00:36:07,420 --> 00:36:15,510
What are the things you think that could and and I don't know, I don't know what the association is going in the other.

326
00:36:15,610 --> 00:36:18,970
I mean, I have some kind of like theories, but I don't really know.

327
00:36:18,980 --> 00:36:20,750
I mean, this was completely unexpected.

328
00:36:24,150 --> 00:36:34,590
Is it possible that the people who had to fight over their babies were like malnourished themselves and living so they couldn't breastfeed,

329
00:36:34,590 --> 00:36:38,820
therefore they moved to bottle feeding and therefore the whole family had malnourished.

330
00:36:39,390 --> 00:36:42,630
Yeah, and actually that's one of one of my theories is around that.

331
00:36:42,900 --> 00:36:48,750
So maybe because here our outcome variable is not is just telling us, okay,

332
00:36:49,020 --> 00:36:57,120
there are some risk of overweight and then the rest the rest may involve kids that are actually undernourished.

333
00:36:57,150 --> 00:37:00,120
Right. So because of diseases or whatever, they cannot breastfed.

334
00:37:00,360 --> 00:37:05,099
So maybe that that that was my theory, actually, that what happened here is more like reverse causality,

335
00:37:05,100 --> 00:37:09,839
kind of like I mean, because if you are already undernourished, then you cannot be kind of like breast fed.

336
00:37:09,840 --> 00:37:16,889
You have to be able to fit. Another issue is that in this, uh, which one we can reverse causation.

337
00:37:16,890 --> 00:37:22,830
But in these settings, when you bottle fed, you need some water.

338
00:37:22,830 --> 00:37:27,870
If the water is not in good conditions, then those kids may be kind of like sick.

339
00:37:28,140 --> 00:37:30,760
And again, they can be kind of like lose weight. Right.

340
00:37:30,780 --> 00:37:36,760
So then there are many I mean, we could that there may be also some of that that biases or whatever.

341
00:37:36,780 --> 00:37:47,339
So what I what I'm kind of like trying to emphasize here is that many times you will find things go against your expectations and hypotheses,

342
00:37:47,340 --> 00:37:53,010
and that's okay. I mean, it's up to you to come up with that with an alternative explanation and see,

343
00:37:53,280 --> 00:37:56,810
I mean, first you have to check your analysis and maybe you do something wrong.

344
00:37:56,820 --> 00:38:03,960
I mean, it happens all the time, right? But second, when you check your analysis many times and you realize, no, I mean, is is correct.

345
00:38:04,290 --> 00:38:11,850
Then you have to come up with other explanations. And there are all sorts of biases that maybe kind of like working here.

346
00:38:11,910 --> 00:38:17,610
Right. Okay. So now that you know how to do this, now was the break.

347
00:38:18,390 --> 00:38:23,460
So let's continue with those.

348
00:38:23,470 --> 00:38:24,510
Well. Yes.

349
00:38:24,840 --> 00:38:37,260
I was wondering, like our original hypothesis of the bottle phone being associated with a higher weight, what is that globally like showing or.

350
00:38:37,410 --> 00:38:42,570
Yeah, just like not apply to this population because we're like facing chocolate.

351
00:38:42,900 --> 00:38:50,060
That's a great point because those hypotheses have been built in kind of like rich countries that have different situation.

352
00:38:50,070 --> 00:38:57,270
And that's true. I mean, maybe in other countries, in other situations that no longer works because of all the things that we were saying.

353
00:38:57,480 --> 00:39:00,750
One thing me modify with water that is contaminated is not going to work,

354
00:39:01,020 --> 00:39:05,220
or if for whatever reason that gets out of rhythm, the knowledge is not going to work either.

355
00:39:05,400 --> 00:39:06,450
Yeah, you're right. Exactly.

356
00:39:06,450 --> 00:39:16,170
So that's that's that's is very important to understand the context, because the context will completely change the way you see associations.

357
00:39:16,710 --> 00:39:26,820
Okay, good. Okay, so let's now move into, uh, we still have our binary outcome,

358
00:39:27,030 --> 00:39:32,040
but now we are going to have a continuous positive rate of we have continuous by binary, right?

359
00:39:32,400 --> 00:39:38,160
So then we are going to use the age of the mother and see how it distributes by overweight status.

360
00:39:38,160 --> 00:39:45,059
And we may not have any specific kind of hypotheses or we can I mean,

361
00:39:45,060 --> 00:39:54,030
we may seem like or maybe kind of like older mothers are kind of like, I don't know, better position, they have more income or whatever.

362
00:39:54,030 --> 00:40:00,510
And, and we know that with income in certain populations that are in nutrition transition, maybe they tend to have a higher risk of overweight.

363
00:40:00,960 --> 00:40:05,790
Or we can think about the other way around. I mean, there can be many kind of like different hypothesis.

364
00:40:07,440 --> 00:40:13,349
But again, you had simple random sampling you would get you user approximate by as we did for

365
00:40:13,350 --> 00:40:18,690
checking the variables like but pregnancy is not going to take into account the whites.

366
00:40:18,690 --> 00:40:20,489
That's not going to take into account the question.

367
00:40:20,490 --> 00:40:26,540
And so our mean is going to be incorrect because it won't be weighted and our confidence intervals are going

368
00:40:26,550 --> 00:40:31,350
to be incorrect because we won't take into account the clustering and potentially stratification as you have.

369
00:40:31,530 --> 00:40:35,560
Right. So then we need to means so this is how it looks.

370
00:40:35,590 --> 00:40:46,770
So we means this is the the syntax and is similar to the mean syntax in the sense that you have kind of like your model, the average of the model,

371
00:40:47,340 --> 00:40:53,340
but if you want to look at it has some differences is like instead of having like

372
00:40:53,340 --> 00:40:57,930
the closest naming where you put the categorical variable the same in school domain.

373
00:40:58,170 --> 00:41:01,870
Okay. So this is equivalent to the closest thing.

374
00:41:01,890 --> 00:41:05,010
Okay. And you still need to kind of like report that.

375
00:41:05,010 --> 00:41:08,050
So let's let's do that. Let's see.

376
00:41:08,070 --> 00:41:27,780
I'm going to live with your. Oh.

377
00:41:28,550 --> 00:41:37,970
So now when we do, the survey means.

378
00:41:42,000 --> 00:41:54,840
And. H Mama, I think.

379
00:42:02,660 --> 00:42:06,320
You see? Ajmal.

380
00:42:06,560 --> 00:42:14,360
Yeah, I know, by the way. Yeah, I know that I can mix and juggle the statements.

381
00:42:14,360 --> 00:42:19,270
It's okay. Right. So then says one complain as long as everything is between these two.

382
00:42:19,280 --> 00:42:21,700
So to make up for this, to avoid whatever. Right.

383
00:42:22,070 --> 00:42:29,070
But the idea that these two things are the same as before because you always have to, they can talk on their way.

384
00:42:29,070 --> 00:42:33,350
It's listening. This is their violence that we're going to look at.

385
00:42:33,440 --> 00:42:39,290
This is like a huge violent image of the mother and this is the equivalent of a glass of statement over weight.

386
00:42:39,290 --> 00:42:42,840
So we're going to look at each of the mother by overweight status.

387
00:42:43,070 --> 00:42:58,490
Okay. So then if I was this, of course, if I run that and hopefully I didn't make any mistake, but so mistakes, so that's fine.

388
00:42:59,600 --> 00:43:03,800
So you can kind of like ignore the box plot.

389
00:43:04,370 --> 00:43:10,580
This is the and you can also kind of like, I mean, this gives you so much information anyway.

390
00:43:10,910 --> 00:43:19,850
So, so what is interesting is that the proposal women's here is going to be viewed the mean age of the mother of aunt,

391
00:43:20,000 --> 00:43:23,569
which is getting I mean, it's for this purpose if I.

392
00:43:23,570 --> 00:43:29,120
So you see that the mean age of the mother in the whole sample is 28 years.

393
00:43:30,080 --> 00:43:35,560
But really what we are interested in and this is kind of like nice to look at how the these divisions

394
00:43:35,570 --> 00:43:41,930
are because then you cannot like in a way this is a distribution of the of the or the mother.

395
00:43:41,930 --> 00:43:44,810
You can see if it's normally distributed or not. Right.

396
00:43:45,230 --> 00:43:51,590
Which is it can be important later on if you want to do it this way, because those will require normality.

397
00:43:53,210 --> 00:43:57,110
But what we really want to check now is this one, right?

398
00:43:57,530 --> 00:44:04,850
So you have that for kids who are not at risk of overweight, the age of the mother is 28.

399
00:44:05,330 --> 00:44:10,219
And for kids who are at risk of overweight, the age of the mother is 30.

400
00:44:10,220 --> 00:44:12,260
So it's kind of like a difference of two years.

401
00:44:15,080 --> 00:44:25,730
So if you want to do I mean, if you want to see that this is statistically significant, then let me show you.

402
00:44:32,240 --> 00:44:36,810
You can add this beef mince in.

403
00:44:37,370 --> 00:44:45,290
If you are these, Dave means you have to have it here. Bellamy.

404
00:44:49,350 --> 00:44:53,640
He didn't stick. Yeah. So.

405
00:44:56,430 --> 00:44:59,490
So this is going to be. You like this? In a way.

406
00:44:59,610 --> 00:45:06,330
Right. So now I run this, I get exactly the same as I got before.

407
00:45:07,410 --> 00:45:11,850
But on top of my table, I get this. Which is the difference.

408
00:45:12,060 --> 00:45:15,810
My two years of difference estimate.

409
00:45:16,170 --> 00:45:20,730
And then this is the statistic and this is the p value.

410
00:45:20,770 --> 00:45:24,360
0.0968. So what do you think?

411
00:45:29,900 --> 00:45:35,390
It's not statistically significant. Right. Which is perfectly fine, but.

412
00:45:40,170 --> 00:45:43,649
You have to think about and for this situation especially.

413
00:45:43,650 --> 00:45:49,020
Fine. Okay. So the age of the mother is not that different. 28 or 30, you have to think about that.

414
00:45:49,290 --> 00:45:56,160
Also, that P values are driven not only because of the defense but because of the sample size, right?

415
00:45:56,430 --> 00:46:05,100
So when you have a smaller sample sizes, you you cannot really detect a statistical difference, significant differences that are small.

416
00:46:05,520 --> 00:46:07,660
I mean, they will be large. Right.

417
00:46:07,920 --> 00:46:15,750
And the other way around, when you have very large sample sizes, then you detect statistically significant, even differences that are minimal.

418
00:46:15,760 --> 00:46:24,180
Right. So it's up to you to decide also what is clinically or public health or whatever important in terms of the unit.

419
00:46:24,190 --> 00:46:32,639
Right. So even if in this situation two years is important, two years is an important difference in age, you can say, well,

420
00:46:32,640 --> 00:46:38,180
it's not statistically significant, but you can think, well, but maybe it's because I have a small sample size.

421
00:46:38,310 --> 00:46:42,810
I know that I'm not saying that you can say, oh, there is a difference because there is not.

422
00:46:42,870 --> 00:46:45,870
I mean, clearly your test is telling you that there is not that difference.

423
00:46:46,200 --> 00:46:51,750
But you can always say, well, but let's say that the difference was instead of two years was yes,

424
00:46:51,840 --> 00:46:55,050
I mean, ten years, everyone will agree that is an important difference.

425
00:46:55,260 --> 00:46:59,430
But still, you get a line that's significant. You can see what I mean. There's a difference of ten years.

426
00:46:59,430 --> 00:47:05,430
Clearly I'm underpowered to detect significance, but it looks like there is a difference.

427
00:47:05,430 --> 00:47:10,230
Right. So we need larger studies, right? You can go the other way around.

428
00:47:10,260 --> 00:47:18,120
I mean, you have you have a super large study. Maybe you get a difference of six months and it is statistically significant,

429
00:47:18,480 --> 00:47:22,020
but who cares that that is statistically significant if six months is nothing?

430
00:47:22,020 --> 00:47:25,220
Right. Right. So I always tell the same story.

431
00:47:25,230 --> 00:47:34,450
But this is studies that are done in in Sweden is like paradise for the epidemiologist because they have every one link in the population.

432
00:47:34,450 --> 00:47:41,069
Right. So then when they do their studies, they do actual real population studies that they can take everyone.

433
00:47:41,070 --> 00:47:47,820
Right. So they have millions of people, right? So they when they check, they do their table one and then they check differences.

434
00:47:47,910 --> 00:47:52,799
They never put B values because they say that everything is significant, even even very small things.

435
00:47:52,800 --> 00:47:56,430
I mean, so then they just kind of like want to show that is critics and that's it.

436
00:47:56,430 --> 00:48:03,569
I mean, not doing kind of like comparisons that I mean, showing like a six months difference is significant.

437
00:48:03,570 --> 00:48:06,960
Who gets it right. So yeah,

438
00:48:07,740 --> 00:48:15,780
technical question like in literature or in popular research like to people specify significance level because they're know out of

439
00:48:15,780 --> 00:48:23,019
point of five this is often but if you're saying that it's almost like more and more than that is that I'm not sure how common it is.

440
00:48:23,020 --> 00:48:26,850
Don't you mean that the threshold that you use for the p value.

441
00:48:26,970 --> 00:48:35,010
Yeah. Is it just quantitative. And they know commonly it's one of I think different studies will use either point one or 2.01.

442
00:48:35,520 --> 00:48:39,959
Yeah. But from one it's sometimes.

443
00:48:39,960 --> 00:48:44,310
Yeah, yeah we've had an Alpha of ten. Oh okay.

444
00:48:44,310 --> 00:48:53,640
Well that does not, that's not that common because I think that actually people tend to be more conservative and choose a lower P-value,

445
00:48:54,090 --> 00:49:02,129
even lower than 0.05. So you get something like Bono five or Bono for nine or something like that.

446
00:49:02,130 --> 00:49:04,710
People will say, that's borderline significant.

447
00:49:04,720 --> 00:49:10,049
I kind of like and I mean it it depends on the study and it depends on where you studying because I mean,

448
00:49:10,050 --> 00:49:17,100
sometimes you can say you look at the difference in their point estimates and you see that is actually a huge difference.

449
00:49:17,100 --> 00:49:20,370
And and the p value is kind of like a little higher.

450
00:49:20,370 --> 00:49:24,960
You're going to say, well, I mean, yeah, that looks like there is something going on, but yes.

451
00:49:25,590 --> 00:49:29,669
Oh, sorry. No, no, that that it happens.

452
00:49:29,670 --> 00:49:35,640
It will happen. But by not being one, you sometimes use that one for interactions.

453
00:49:35,970 --> 00:49:40,049
These interactions are very conservative. So sometimes kind of like you can say, well,

454
00:49:40,050 --> 00:49:45,270
if you get point one and then you can see clearly that there is something there's a modification very clear.

455
00:49:45,450 --> 00:49:48,659
You can see that there is that. And you kind of say that is statistically significant.

456
00:49:48,660 --> 00:49:51,780
You shouldn't actually, but you can say looks like there is something going on.

457
00:49:52,170 --> 00:49:57,630
Yeah, well, if it had, for instance, like if there was a really large effect size.

458
00:49:57,960 --> 00:50:02,850
But yes, exactly as you said, it might be like this the rest of the data.

459
00:50:02,910 --> 00:50:03,239
Yeah.

460
00:50:03,240 --> 00:50:10,770
Because you can say it could possibly you could say that you on the power and that's why you are getting no but but it is not that normal usually.

461
00:50:10,770 --> 00:50:15,329
7.5. Yeah. Okay.

462
00:50:15,330 --> 00:50:26,760
So, so now, now let's work in pairs for question two because you will have to kind of like do this for them and,

463
00:50:29,400 --> 00:50:35,360
and I'm going to allow you to, to do it on your own. So now you have to do the question to you how you divide by analysis.

464
00:50:35,370 --> 00:50:43,999
So basically, I'm giving you here the. The table that you have to fill out with the p value of this.

465
00:50:44,000 --> 00:50:47,690
And then you can see that your outcome is instantaneous stamped in this binary.

466
00:50:47,710 --> 00:50:51,230
But then in your creditors you have all sorts of predictors.

467
00:50:51,590 --> 00:50:55,250
Some of them are continuous, some of them are categorical binary, actually.

468
00:50:55,310 --> 00:50:55,610
Right.

469
00:50:55,850 --> 00:51:02,209
So then for some of them, you will have to use reflect on your chi square for some of then you will have to use your proc means and the diff means.

470
00:51:02,210 --> 00:51:08,480
Okay. And then here you have to report when when you have a continuous one, you have to report min and the standard deviation.

471
00:51:08,780 --> 00:51:17,930
Well standard error broadly that what you get and when you have a binary predictor you will have to report the percentage.

472
00:51:19,520 --> 00:51:24,440
Please, please put a lot of attention that you are reporting the correct percentage.

473
00:51:24,440 --> 00:51:28,340
I mean, here, if I have like let me see.

474
00:51:28,620 --> 00:51:29,599
See, I was born,

475
00:51:29,600 --> 00:51:39,530
I said what I want to do is remember the percentage of what if I gets an mon a standard and the percentage of whatever it gets am on not standard.

476
00:51:39,530 --> 00:51:46,219
So choose correctly, it should be either the row or the column depending on how your order, your variable.

477
00:51:46,220 --> 00:51:50,600
So be careful. You you can check that with kind of like a calculation.

478
00:51:50,600 --> 00:51:59,299
I mean, making sure that I know this is the one. So I always tell students, I mean, I still make mistakes with those percentages.

479
00:51:59,300 --> 00:52:02,730
If you go very fast, then sometimes you pick the ones that are not correct.

480
00:52:02,840 --> 00:52:07,970
So to pay a lot of attention, okay. To, to, to choose the ones that that you have to.

481
00:52:08,510 --> 00:52:15,979
Okay. And then remember, you will have to answer the question be if based in your bivariate analysis,

482
00:52:15,980 --> 00:52:24,650
the mother education is associated and and j descriptive therefore success to be Polish and to make sure that that you don't forget anything.

483
00:52:24,650 --> 00:52:33,559
Okay. So then I'm going to give you actually maybe you can take a break now because it's almost two and then go back and work a little bit on that.

484
00:52:33,560 --> 00:52:37,520
You don't need to do that because that's probably something that because we need to move to the next thing.

485
00:52:37,520 --> 00:52:40,670
Okay. So then you can do a couple and see if you feel comfortable.

486
00:52:40,730 --> 00:52:44,000
You know, you can ask me and they will move into the next one.

487
00:52:44,060 --> 00:52:48,080
Okay. And I got to do that.

488
00:52:48,470 --> 00:52:56,240
So which are you asking us to work percentage for the table.

489
00:52:56,630 --> 00:53:00,590
Yeah. So if the variable is binary, the territory was binary.

490
00:53:00,590 --> 00:53:07,700
Yes. Percentage is the variable is continuously. For example, mother's age then a mean, mean and standard error I believe.

491
00:53:07,700 --> 00:53:14,630
I think I was telling you here. I think I'm telling you here.

492
00:53:18,320 --> 00:53:26,030
Reporting means only standard errors for the continued variables and the percent for categorical variables.

493
00:53:26,540 --> 00:53:35,419
Okay, so read it first and also the go for the binary variables.

494
00:53:35,420 --> 00:53:41,600
It is one yes, zero or no unless it's specified here.

495
00:53:41,900 --> 00:53:46,010
Not this. Yeah, I forgot. The sex of the child is zero girls.

496
00:53:46,010 --> 00:53:53,270
One boys. Okay. And the. And the no toilet in the house is one of those negative kind of like variables.

497
00:53:53,270 --> 00:53:56,810
So actually, one means that there is no toilet.

498
00:53:56,820 --> 00:54:01,490
So that's the percent that I want you to kind of like report and zeros out that is doing so.

499
00:54:01,490 --> 00:54:06,770
The variable is a negative is like there is no toilet as a percent that I want to not not know that there is toilet.

500
00:54:06,890 --> 00:54:10,180
Okay. So those are the only two that are a little different. The other side of.

501
00:54:10,200 --> 00:54:15,500
Yes. No. Okay. Zero one. Okay. I'll go to the bathroom.

502
00:54:16,040 --> 00:54:20,580
You can have 5 minutes and then match and then you have.

503
00:54:20,590 --> 00:54:35,560
I continues to work on that. And then we will the next. Do.

504
00:54:44,140 --> 00:55:43,170
You better. They have to go.

505
00:55:48,630 --> 00:55:58,120
Quite simply. No conclusion.

506
00:56:00,970 --> 00:56:14,540
So you have no idea how to do this.

507
00:56:15,590 --> 00:56:26,550
Come on. You have to take me to.

508
00:56:34,010 --> 00:56:40,900
I am going to follow up on that notion, I believe.

509
00:56:48,240 --> 00:56:57,240
Most touching, of course, you need to do is try to leave.

510
00:57:36,270 --> 00:57:40,620
She? She?

511
00:58:23,400 --> 00:58:39,440
Ping pong. I did not get.

512
00:59:56,580 --> 01:00:03,990
Yes. Know within.

513
01:00:14,160 --> 01:00:20,030
So the. Oh, yeah.

514
01:00:24,500 --> 01:00:29,900
It's a story about. Hey, you can use it if you have the chance.

515
01:00:29,990 --> 01:00:42,210
Yeah. Oh.

516
01:01:01,340 --> 01:01:25,890
Just this. It's amazing.

517
01:01:35,220 --> 01:03:09,600
Each. So.

518
01:03:52,430 --> 01:04:46,720
Frequency. Yeah.

519
01:04:50,200 --> 01:04:54,490
And. You have to.

520
01:05:02,280 --> 01:05:13,210
Okay. Oh, no, no.

521
01:06:57,440 --> 01:07:02,090
Okay. How are you doing so far? Any problems?

522
01:07:03,920 --> 01:07:08,470
I mean, in theory, this question is a lot of variables, but all of them are the same.

523
01:07:08,480 --> 01:07:13,290
They are either categorical or continuous. So you are able to do one or the other.

524
01:07:13,290 --> 01:07:21,350
Then you should be fine filling out. So let's let's move on because we still need to kind of like combat linear regression and logistic regression.

525
01:07:21,530 --> 01:07:31,210
Okay. So then, then our next, I mean, we are continue with the other way to sample and then what we are going to look at.

526
01:07:31,220 --> 01:07:40,460
I mean, it's okay, I mean with the proposal remains and they propose to reflect you are done with your bivariate analysis more or less,

527
01:07:40,470 --> 01:07:46,790
but you may want to do multivariable analysis and linear regression or logistic regression.

528
01:07:46,790 --> 01:07:51,320
You can do other things, of course, but we are going to just touch on those two.

529
01:07:51,410 --> 01:07:51,710
Okay.

530
01:07:52,280 --> 01:08:04,129
So so the question we are going to ask is the age of the children is associated with white for height and why white for height and not of overweight?

531
01:08:04,130 --> 01:08:09,530
Because overweight is a binary variable. And then if we want to do linear regression, we need a continuous outcome.

532
01:08:09,530 --> 01:08:13,729
So we are going to kind of like instead of looking at our binary variable,

533
01:08:13,730 --> 01:08:18,290
we are going to look at weight for height, which is as is called, and it's a continuous body.

534
01:08:18,470 --> 01:08:25,880
So you can use that in linear regression. So outcome variable would be this, it's called weight for height.

535
01:08:26,510 --> 01:08:28,249
Age will be the predictor.

536
01:08:28,250 --> 01:08:33,860
And of course, I mean, we're going to just use one predictor, but you know that in linear regression, you can use as many as you want.

537
01:08:33,920 --> 01:08:38,390
You can add more things to the to the right side of the equation, right?

538
01:08:38,900 --> 01:08:50,690
So, so these happen observer right. So if you remember from previous classes or whatever that is appropriate to do linear regression ratio,

539
01:08:50,690 --> 01:08:58,210
then blocks are will right is the equivalent for complex the and the syntax again is very similar.

540
01:08:58,220 --> 01:09:03,470
You have your model statement where you have your continuous variable here,

541
01:09:03,470 --> 01:09:09,230
your outcome variable and you have your predictors here in this situation, the age of the children,

542
01:09:09,500 --> 01:09:13,879
but you have many other operators and of course you can have remember you can have

543
01:09:13,880 --> 01:09:18,260
both a continuous and categorical operators in your right side of the equation.

544
01:09:18,410 --> 01:09:24,620
Right. So that's that's okay. And they don't need to be the continuous one on the right side of the equation.

545
01:09:24,620 --> 01:09:26,209
They need to be normally distributed.

546
01:09:26,210 --> 01:09:32,750
The one that needs to be normally distributed is their weight for height, actually, not even the variable question about the receivers.

547
01:09:33,140 --> 01:09:41,360
But we won't go into those effects. We are going to assume that results going to be well distributed and then this is what we are going to run.

548
01:09:41,420 --> 01:09:46,790
Okay, so you run that and I'm not going to allow you to try this time because then you can try later.

549
01:09:48,290 --> 01:09:50,840
This is what we get. I mean, you get many things right,

550
01:09:51,170 --> 01:10:00,560
but kind of like and put in this kind of like this in a multi because this is the same kind of like output that you have seen before for profit.

551
01:10:00,950 --> 01:10:04,610
So you have your intercept and you have your slope right for months.

552
01:10:05,000 --> 01:10:10,280
So so this is the data that you are kind of like looking for, right?

553
01:10:10,730 --> 01:10:20,240
So then basically this better means that for every kind of like change unit change in the return,

554
01:10:20,300 --> 01:10:25,010
the outcome variable will increase as much as they will assess.

555
01:10:25,520 --> 01:10:32,780
The situation you see is for every increase or decrease depending on this same way in this situation is positive.

556
01:10:32,780 --> 01:10:42,950
So it will increase. If it's negative, it will decrease. Right. So this situation for every month of age, the W h C score increases by .016.

557
01:10:43,610 --> 01:10:49,489
Okay. And this is you can see the world, this is statistically significant.

558
01:10:49,490 --> 01:10:58,879
So this is kind of like so this is how you do linear regression in and see that the only thing that we are

559
01:10:58,880 --> 01:11:05,780
doing here is that we're using nursery procedure and we are taking into account the clustering and the weights,

560
01:11:06,500 --> 01:11:09,260
although I would say something about the later. Okay.

561
01:11:10,640 --> 01:11:18,830
So now if you want to kind of like do logistic regression, now we can go back to our binary variable, right?

562
01:11:18,830 --> 01:11:21,290
Because logistic regression is for binary variables, right?

563
01:11:21,620 --> 01:11:27,439
So we can go back to our overweight variable and then we can actually we already did this in the bivariate,

564
01:11:27,440 --> 01:11:33,680
but we are not now going to do it for logistic regression, which is perfectly fine a B model for this associated with overweight.

565
01:11:33,830 --> 01:11:38,149
Right. And again, in the right side of the equation,

566
01:11:38,150 --> 01:11:46,580
you can pull many more things because you can assume that okay being model Fed may be associated with overweight, but there may be many confounders.

567
01:11:46,820 --> 01:11:51,530
So then I can adjust for other confounders. We are not going to do that now, but you could do that in the future.

568
01:11:51,530 --> 01:11:56,230
Right? So. That approximate logistic.

569
01:11:56,440 --> 01:12:00,820
Yes. So this is the same as your logistic, but in ceremony, right.

570
01:12:01,330 --> 01:12:09,040
So that there's just one small thing that I have highlighted here, that in your model,

571
01:12:10,450 --> 01:12:16,500
this is the word weight equals water, and then you shall logistic.

572
01:12:16,530 --> 01:12:25,509
You have two options to tell SAS, which is the kind of like code that you want to assume that is there the the case.

573
01:12:25,510 --> 01:12:30,700
Right so that SAS will will estimate the probability of being a case, right.

574
01:12:30,760 --> 01:12:33,210
Because you don't want the probability of being controlled.

575
01:12:34,090 --> 01:12:40,150
So if you have over weight, you want to estimate the probability of being overweight, not the probability of not of being overweight.

576
01:12:40,230 --> 01:12:46,810
Right. So you don't say anything, says by default, takes the lower number and then it will do the opposite.

577
01:12:46,930 --> 01:12:54,100
Right. So that's why you have to kind of like specify in brackets that the event is one.

578
01:12:54,160 --> 01:12:57,760
In this situation, it's called in this way. Okay. It could be called event.

579
01:12:57,760 --> 01:13:01,150
Something else. I mean, that in the situation is way.

580
01:13:01,180 --> 01:13:06,750
Okay. In the usual proc logistic, you have another option which is best and then option.

581
01:13:06,760 --> 01:13:11,730
So you could put here descending and then that will do the same. So this is is more convenient.

582
01:13:12,190 --> 01:13:14,649
For example, logistic doesn't have the this and then option.

583
01:13:14,650 --> 01:13:20,560
So you have to use the event option which is also common to the blocks at the block logistic.

584
01:13:21,170 --> 01:13:25,479
Anyway, so this is the goal. You run that again.

585
01:13:25,480 --> 01:13:32,320
You will get a lot of stuff that you can ignore and you go to this table.

586
01:13:32,330 --> 01:13:40,800
This is the the debate us right so you have again intersection as low by remember in with

587
01:13:40,810 --> 01:13:46,690
brought logistic you don't want to report virus because the virus are in the log or the scale,

588
01:13:46,690 --> 01:13:51,640
which is completely what. Right. But you want to report is odds ratios.

589
01:13:51,760 --> 01:13:58,389
Right. So from your whereas you get odds ratios and SAS is going to give you the odds ratios,

590
01:13:58,390 --> 01:14:04,660
that ratio here is giving you the odds ratio is point 34 and is giving you like they've got previous in the right.

591
01:14:05,590 --> 01:14:13,030
Right. So coming to this and this is you will interpret and address you the same as you have always an odds ratio.

592
01:14:13,300 --> 01:14:21,520
And that brings an important point because I want you to be very orthodox in interpreting those ratios.

593
01:14:21,850 --> 01:14:25,270
So if it's an old ratio, don't tell me risk.

594
01:14:25,750 --> 01:14:31,120
There's no risk here. That is not okay, because risk is for resource base.

595
01:14:31,480 --> 01:14:38,590
Right. And then I'm giving you something that I always give the basics or to feel this, but I think is useful for everyone.

596
01:14:39,340 --> 01:14:45,430
That is that table of templates that you can use to interpret those odds ratios.

597
01:14:46,450 --> 01:14:52,630
So you go to to canvas and it should be here.

598
01:14:54,380 --> 01:14:59,260
Okay. You didn't see this.

599
01:15:00,130 --> 01:15:06,160
Here is measures of this in Moya's measures of association in the petition table.

600
01:15:06,670 --> 01:15:10,450
So as you can see that for every different measure of association,

601
01:15:10,450 --> 01:15:17,349
I'm giving you templates which are kind of like more or less the same is just for that ratio you use for the ratio,

602
01:15:17,350 --> 01:15:20,770
you just risk for the right ratio you use rate and so on.

603
01:15:21,040 --> 01:15:23,560
Note that for this class you only need the ratio.

604
01:15:23,590 --> 01:15:29,150
You don't need anything else because we're not going to use all this, but it will be good for you, for the future.

605
01:15:29,170 --> 01:15:33,280
And then note that I'm putting kind of like different examples here.

606
01:15:34,930 --> 01:15:41,440
Some can see that another variable is categorical or binary, and some consider the variables continuous.

607
01:15:41,800 --> 01:15:45,960
And also some consider that that your odds ratio is harmful.

608
01:15:45,970 --> 01:15:51,040
So it's above one, and some, considering that your odds ratio is protected below one,

609
01:15:51,040 --> 01:15:55,120
which are the trickiest, the protective odds ratios are very tricky to interpret.

610
01:15:55,150 --> 01:16:04,209
Well, okay, so then kind of like be careful about that. So what I have here in this example for assuming that you have a ratio of 1.6

611
01:16:04,210 --> 01:16:10,210
and let's say that is your exposure to alcohol and your outcome is cancer.

612
01:16:10,220 --> 01:16:15,690
So then you say the odds of breast cancer and again is the odds don't use risk.

613
01:16:15,730 --> 01:16:19,180
Okay. This is the odds are 1.6.

614
01:16:19,180 --> 01:16:21,219
And then you put in brackets the confidence interval,

615
01:16:21,220 --> 01:16:27,010
which is nice white banks higher among those who drink alcohol compared to those who don't drink alcohol.

616
01:16:27,130 --> 01:16:40,450
So that's I mean, there are other ways of that are, okay, you don't have to follow the same words, but I encourage you to do it because it's easier,

617
01:16:40,450 --> 01:16:45,009
because if you start using your own words, you may kind of like deviate from what is orthodox, right?

618
01:16:45,010 --> 01:16:48,729
And then I really want you to follow first the then place and then later on in your

619
01:16:48,730 --> 01:16:52,420
life you can kind of like you either have to follow exactly the words I told you.

620
01:16:52,420 --> 01:16:59,330
Right? But make sure that the thought is there and then the repetition is correct in what is the reference, one is not right.

621
01:16:59,350 --> 01:17:03,750
And when you have a categorical variable, you are comparing those who drink alcohol.

622
01:17:03,760 --> 01:17:06,590
Alcohol versus those who don't drink. Right, alcohol.

623
01:17:06,860 --> 01:17:14,019
So then you have to do that when you have a continuous variable, the, the change in the odds is for everyone.

624
01:17:14,020 --> 01:17:16,270
You need the same as we did for the linear regression.

625
01:17:16,270 --> 01:17:25,750
So then in this situation will be for every one unit increase in alcohol which that unit, if you know the units, you have to tell the unit, right?

626
01:17:26,020 --> 01:17:33,339
So if that unit is service, you have to say for every serving of alcohol or if that unit is a gram,

627
01:17:33,340 --> 01:17:39,940
you have to say for every gram of alcohol, then the odds of breast cancer are 1.6 times higher.

628
01:17:40,120 --> 01:17:46,419
Okay. And note that I put the other two options are when you use like the attributable thing,

629
01:17:46,420 --> 01:17:52,300
which is also fine, you can use those like instead of C 1.6, you can say 60% more.

630
01:17:52,630 --> 01:18:02,100
Right. So you can I mean, I usually when when it's a harmful ratio, I prefer the 1.6 when it's a protective one.

631
01:18:02,110 --> 01:18:09,120
I definitely prefer the, the, the attributable thing because otherwise it's super tricky.

632
01:18:09,130 --> 01:18:17,260
Right. So then when you have the situation of a protective use, they're kind of like this one, the 11%.

633
01:18:17,260 --> 01:18:26,380
So just extract from you have 2.89. You can say that the odds of breast cancer are 11% lower among those who are physically active

634
01:18:26,590 --> 01:18:31,060
compared to those who are not physically active and they see for the one unit increase.

635
01:18:31,450 --> 01:18:36,939
This one is here. But I personally don't like it because you cannot say that the odds of breast cancer

636
01:18:36,940 --> 01:18:42,010
that point 89 times lower because that is true because it's a number below one.

637
01:18:42,730 --> 01:18:46,330
So so because of that I prefer to use the 11%.

638
01:18:46,990 --> 01:18:55,570
You can see them as likely among those who are out which is sounds horrible I mean I body because it will be okay but to me I don't like it so.

639
01:18:56,340 --> 01:19:01,630
So you have a brother one use this one for categorical and use this one for continuous.

640
01:19:01,880 --> 01:19:07,209
Okay. So now that I insist that so much that you have to use it, then please.

641
01:19:07,210 --> 01:19:10,960
I don't want to see any homework with your own language.

642
01:19:10,960 --> 01:19:17,620
I want you to follow. I mean, you just need to take this and say, okay, now you don't have breast cancer, you have overweight or you have a standing.

643
01:19:17,890 --> 01:19:22,000
Now you don't have either. No, I don't remember from the top of my head what is this possible?

644
01:19:22,000 --> 01:19:25,510
But whatever is positive. So you just change those words and the number that it is.

645
01:19:25,510 --> 01:19:30,370
Right, and then that that way would be perfect. Okay. Don't try to use your own wording.

646
01:19:30,460 --> 01:19:35,020
Okay? Okay. Okay.

647
01:19:35,020 --> 01:19:44,040
So now. Yeah.

648
01:19:44,050 --> 01:19:47,260
So this is just. There's something that I already told you.

649
01:19:47,980 --> 01:19:54,790
If you have a complex, savvy design, you definitely need to use the survey logistic, because if you use a normal logistic,

650
01:19:54,790 --> 01:20:02,020
you know, you wait that because in probability you pull the weights with the confidence intervals.

651
01:20:02,050 --> 01:20:05,770
Look at that. You're not thinking to connect less to the statement.

652
01:20:05,770 --> 01:20:07,599
So what is the difference between these two?

653
01:20:07,600 --> 01:20:14,319
I mean, you can see that the point estimate is the same because I'm still waiting like value because I'm not thinking.

654
01:20:14,320 --> 01:20:17,680
The question is given here. Look at this conference center.

655
01:20:17,680 --> 01:20:20,980
One is super narrow. This is the current one, right?

656
01:20:21,670 --> 01:20:28,270
So this is the problem when you don't use the proper kind of like and level, right?

657
01:20:28,270 --> 01:20:32,530
I mean, you have to take into account the clustering so the confidence interval is calculated properly.

658
01:20:32,620 --> 01:20:36,880
Okay. So this is just one example of why you have to do those things.

659
01:20:37,900 --> 01:20:42,790
But there is one less thing about sampling weights.

660
01:20:43,600 --> 01:20:50,650
And the issue is that when you are doing descriptive statistics and that means that when you are calculating means and proportions,

661
01:20:50,860 --> 01:20:55,540
proportions are prevalence is right. What we did with the browser before take on the proper means and so on.

662
01:20:55,930 --> 01:21:03,280
You always need to use the sampling weights always because otherwise you don't get the proper numbers right.

663
01:21:03,280 --> 01:21:09,189
So the prevalence is not weighted, is not correct that when you're making inference.

664
01:21:09,190 --> 01:21:23,740
So when you are doing linear and logistic regression, either bits, sometimes you may need to wait, sometimes not and you may not know when.

665
01:21:24,190 --> 01:21:35,620
So what you have to do is to ask and check, like for example, in DHS, which is one of the demographic health survey that are surveys in many,

666
01:21:35,620 --> 01:21:40,389
many countries in different years and so on, they specifically do go to the West.

667
01:21:40,390 --> 01:21:48,340
They they will specifically tell you use of sample weights is appropriate when representative levels of statistics are beside are such as percent.

668
01:21:48,340 --> 01:21:55,210
That is millions and millions. What I just told you that descriptive however use of sample weights is inappropriate

669
01:21:55,570 --> 01:21:59,020
for estimating relationship such as regression and correlation coefficient.

670
01:21:59,020 --> 01:22:07,300
So in the context of DHS you are working with DHS, you should not use weights for the linear regression or the largest iteration,

671
01:22:08,050 --> 01:22:13,990
but a Haynes actually recommends you to use the weights.

672
01:22:14,470 --> 01:22:19,959
So he is telling you you have to use the way you use the weights and the same for the health and retirement study.

673
01:22:19,960 --> 01:22:22,120
So every survey is different.

674
01:22:22,420 --> 01:22:29,229
One of the reasons because of that in a case I think is because that using the waist or not is a little controversial because I mean,

675
01:22:29,230 --> 01:22:32,500
there are pros and cons, so it's not like is wrong is just in the best.

676
01:22:32,540 --> 01:22:38,769
Right. And some surveys really want you to use the weights because in the sampling ways they are able to incorporate in

677
01:22:38,770 --> 01:22:44,620
some non responds ways and other things that they need you to kind of like use and that's why they will tell you,

678
01:22:44,620 --> 01:22:51,850
yes, use the weight. So for the future, remember, the script is always regression models.

679
01:22:52,330 --> 01:22:54,130
It depends. It depends on the survey.

680
01:22:54,220 --> 01:23:00,130
Some surveys will tell you yes, use them sensibly what they do, not in the homework, and then you have to use it or not.

681
01:23:00,280 --> 01:23:04,120
That what we know this is in the scope of the class.

682
01:23:04,120 --> 01:23:07,780
But why? Why is there that discrepancy?

683
01:23:08,110 --> 01:23:11,350
Why? Why is what why is it different depending on the survey?

684
01:23:12,280 --> 01:23:19,839
Well, I don't know, because it depends. I don't know what a big, wide some service tells you or not, I think is.

685
01:23:19,840 --> 01:23:27,970
Because like, for example, in in Hays, I think is because the sampling weights sometimes they only represent the inverse probability of selection.

686
01:23:28,450 --> 01:23:34,870
So in that situation, some people prefer not to use the weights because I mean, I don't remember from the top of my head,

687
01:23:34,870 --> 01:23:38,589
but it's kind of like the is beyond the scope, even the scope of my spaghetti essentially.

688
01:23:38,590 --> 01:23:42,219
So it's kind of like something related to the confidence interval.

689
01:23:42,220 --> 01:23:48,940
So I don't know, I don't remember. But when those weights also incorporate nonresponse ways and other things,

690
01:23:49,270 --> 01:23:55,000
then the statisticians for the service prefer you to use the weights because that would be more correct.

691
01:23:55,120 --> 01:23:57,579
So that that's that's what I think that happens in the case.

692
01:23:57,580 --> 01:24:04,660
And the health editor may study that by using the weights you get kind of like more than if no using the weights.

693
01:24:04,750 --> 01:24:10,930
And again is is controversial. I mean some people say, no, it's okay to use the way some people say no, you shouldn't use the weights.

694
01:24:11,290 --> 01:24:15,260
So it's not kind of like right or wrong, but everybody's like double.

695
01:24:17,560 --> 01:24:23,560
Yeah. So I always ask. Yes. So and I'm glad that we're here.

696
01:24:23,830 --> 01:24:27,220
Other than that first question, we're not using.

697
01:24:27,610 --> 01:24:35,770
Well, let me see, because now I don't remember if I told you to use them or not, but I think I'm asking you not to use them.

698
01:24:36,190 --> 01:24:39,880
Yeah. Do not use week's wait for this month.

699
01:24:40,570 --> 01:24:45,460
Yeah. So basically for the lab, I'm asking you not to use it.

700
01:24:46,930 --> 01:24:50,380
I have told you the other way around.

701
01:24:50,430 --> 01:24:56,020
I remember you're not using so. So see that this is not kind of like something that you have to know in advance.

702
01:24:56,200 --> 01:25:00,130
You have to ask. Yes. So don't you start a cluster, or do we sort of just.

703
01:25:00,250 --> 01:25:02,110
No, no, no. This. Wait, wait.

704
01:25:02,140 --> 01:25:09,860
Oh, the second question that the way several related to the clustering or stratification, the questionnaire stratification is a different thing.

705
01:25:09,880 --> 01:25:15,130
You still need to use those because those are part of the complex design and that will affect the confidence of.

706
01:25:15,970 --> 01:25:19,480
So is there way it's only the ways that that you have to use. So be careful.

707
01:25:19,510 --> 01:25:23,739
Okay. Straight and plastic. Yes. Always. Wait.

708
01:25:23,740 --> 01:25:27,030
Always. No matter if you are doing regression or exclude.

709
01:25:27,030 --> 01:25:32,130
This is the ways that that change. Yes. I put this. It's not working like the model.

710
01:25:32,280 --> 01:25:35,910
I don't know. I just keep saying the statement is not valid, so I don't know what the.

711
01:25:36,420 --> 01:25:53,380
I just. He know doesn't like this.

712
01:25:57,550 --> 01:26:14,310
It's like, I still wish you were here, but it's not even remotely an interesting space.

713
01:26:15,610 --> 01:26:21,470
Oh, this is. Yeah, it's not like, you know.

714
01:26:22,520 --> 01:26:37,900
Oh, yeah. At least that was one situation in which that is still in that is changing the policy and there's something wrong in their syntax.

715
01:26:40,240 --> 01:26:51,610
Okay. So let's go back to the to the because I have just find a few things to tell you and then you can continue doing the homework.

716
01:26:55,450 --> 01:26:58,690
Oh, I can say very difficult about this.

717
01:26:59,950 --> 01:27:03,399
This is an anecdote that I felt.

718
01:27:03,400 --> 01:27:15,790
But so you can you can now work on the on the homework question, kind of like three where I want to do the multivariate analysis.

719
01:27:15,850 --> 01:27:22,180
Okay. So then what we're going to do is there logistic regression actually C and then I'm giving you the table will.

720
01:27:22,240 --> 01:27:29,470
So see you are going to run a group model and then you want to run a fully adjusted model using these other variables.

721
01:27:29,620 --> 01:27:43,340
Okay. And then based on that, you have to kind of like tell me it is clear evidence of confounding by the variables you're destined for.

722
01:27:43,360 --> 01:27:49,270
So the idea is that when you have a model through model where you look at an exposure and an outcome,

723
01:27:49,960 --> 01:27:53,170
that kind of like association could be confounded.

724
01:27:53,170 --> 01:27:56,350
Right? Because we have observation. I mean, we're working with motivational data.

725
01:27:56,350 --> 01:28:01,840
So then the the the that there is all sorts of biases that could be kind of like working here.

726
01:28:02,320 --> 01:28:09,399
So the idea is that I'm telling you, well, instead of asking you to come up with potential confounders,

727
01:28:09,400 --> 01:28:13,510
I'm telling you to adjust for a few variables that actually they are not true confounders.

728
01:28:13,510 --> 01:28:18,220
But it's okay for the purpose of the of the of the homework is enough.

729
01:28:18,640 --> 01:28:24,550
So you run for your group model and then when you adjust for these other variables,

730
01:28:25,300 --> 01:28:32,290
then you look at the odds ratios in the group for Malahide Elementary School, which is this portion of interest.

731
01:28:32,800 --> 01:28:40,600
So you look at the group model and you look at the fully adjusted model and you see they are different and different.

732
01:28:41,050 --> 01:28:46,660
How much different? We sometimes use like a 10% rule, but that's able.

733
01:28:46,750 --> 01:28:54,670
Okay. So then kind of like calculate, just think like something goes from one from either noise 1.2 and it goes to two by five.

734
01:28:54,820 --> 01:29:00,820
I mean, clearly they are very different ratios. If it's 1.21, 1.25, they are not.

735
01:29:01,150 --> 01:29:05,500
Right. So kind of like I will the same as with the normality, right?

736
01:29:06,010 --> 01:29:10,240
So then based on that, you can tell me if there is evidence of confounding or not.

737
01:29:10,450 --> 01:29:15,409
Okay. And again, this is a little bit in the eye of the beholder because it is not that different.

738
01:29:15,410 --> 01:29:20,760
Some people with like, well, is not very different. And other people will look at what is enough different.

739
01:29:20,770 --> 01:29:24,880
Right. So think about that. 10% or more. More or less than 0%.

740
01:29:25,120 --> 01:29:38,020
Okay. And then the other thing is that when you and this is very important, when you have a continuous variable,

741
01:29:40,120 --> 01:29:45,130
the odds ratio that you are calculating and you interpret them for one unit change.

742
01:29:45,340 --> 01:29:52,990
Right. But one unit change sometimes may be very small or very kind of like let me, for example, think about income.

743
01:29:53,440 --> 01:29:57,400
Income is given in dollars. So one unit changes $1.

744
01:29:57,610 --> 01:30:05,350
Right. If I asked you the odds ratio, whatever for $1 change is going to be very, very, very small.

745
01:30:06,010 --> 01:30:11,110
It can still be significant because income is associated with many things, but it will be so small.

746
01:30:11,110 --> 01:30:19,150
That is very difficult to interpret, right? Because $1 is nothing. So then you have to we scale those things many times, right?

747
01:30:19,330 --> 01:30:25,590
So instead of $1, it will make more sense to put $1,000, for example, or 100, I don't know, but something bigger.

748
01:30:25,610 --> 01:30:34,930
Right. So then in order to rescale, you can use this context contrast statement and I'm quoting here, so then you can just copy and paste.

749
01:30:35,320 --> 01:30:46,000
Because what I'm asking you is now in Z, I'm asking you, instead of interpreting the ratio for one month change, let's do it for ten months change.

750
01:30:46,240 --> 01:30:50,649
Right. And they are going to change because it's 14 months change, right.

751
01:30:50,650 --> 01:30:57,680
So that this face is the same model. But your rescaling the, the, the, the operation.

752
01:30:57,730 --> 01:31:03,820
So you could do it manually or you can do it with the, you know how to do it manually.

753
01:31:03,820 --> 01:31:14,950
Basically do not forget you do remember that you have to do it is usually a contrast estimate and kind of like estimate and interpret that ratio.

754
01:31:15,340 --> 01:31:18,549
Okay. So see that I'm using the contrast.

755
01:31:18,550 --> 01:31:27,800
Then I'm put in a label which in this case whatever, whatever is being done in what you can do, whatever that I put ten months in challenge.

756
01:31:28,030 --> 01:31:35,409
You can put anything away. And then the the variable, which is the violin.

757
01:31:35,410 --> 01:31:43,000
And then Anne Boleyn came here. If I want to do it for two, then I would put a two ratio, then just put the number.

758
01:31:43,010 --> 01:31:45,400
So then by pulling that you are going to get,

759
01:31:45,940 --> 01:31:52,389
you will still pay attention because you will still get the same results as you got before the model is the same,

760
01:31:52,390 --> 01:31:58,240
but you will get an additional table with that. Contrast the statement that the one that you have to look at now.

761
01:31:58,320 --> 01:32:04,590
Okay. This is how you would do it.

762
01:32:04,620 --> 01:32:08,830
And my money. So you could you could do that, too.

763
01:32:08,850 --> 01:32:11,910
I mean, you feel like you want to do it. Okay.

764
01:32:13,170 --> 01:32:17,490
Okay. So that's, I think everything you have to do.

765
01:32:18,660 --> 01:32:27,420
Sure. I we still have, like, 80 minutes, so please keep working.

766
01:32:27,420 --> 01:32:30,870
And then if you have any issues, let me know I'm here.

767
01:32:31,470 --> 01:32:37,650
If, remember, this homework is due next week. If for whatever reason you have, this was just a minimum.

768
01:32:37,740 --> 01:32:45,719
Okay? And then if someone is very last weekend, you can do an appointment for office hours.

769
01:32:45,720 --> 01:32:47,670
It probably will be by zoom by with me. Okay.

770
01:32:47,670 --> 01:32:52,520
So you have like you are completely lost and I say, no, I'm trying to do this and I don't understand whatever.

771
01:32:52,710 --> 01:33:00,410
Okay. I mean, I'll be in office hours on Friday, but by five, it's probably too late to.

