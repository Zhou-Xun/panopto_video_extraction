1
00:00:01,660 --> 00:00:17,670
Very different story. If you look at all of this for us, I think a surprise to me and I.

2
00:00:19,670 --> 00:00:26,760
So I welcome so many volunteer races.

3
00:00:27,900 --> 00:00:31,500
Welcome to Biased Fox five Planetary Lab Number one.

4
00:00:31,980 --> 00:00:35,300
My name is Le and I'll be the GSI for this section.

5
00:00:36,900 --> 00:00:42,230
So what we're going to do today, we're going to just introduce the lab.

6
00:00:42,240 --> 00:00:50,610
What is it for? What's the main objective? And then we're going to work in the main objective objective of the lab, which is just to review some code.

7
00:00:50,610 --> 00:00:54,270
And it's going to hopefully it's going to be very useful for your homework.

8
00:00:54,450 --> 00:01:01,930
Okay. So okay, so before we start, there are two guesses for this class.

9
00:01:02,010 --> 00:01:07,170
On the one on the left and that's my email link is you ever want to like send me an email?

10
00:01:07,630 --> 00:01:15,120
I'm second. My name is Daniel and I am a second year master's student seen by Scott and I.

11
00:01:15,120 --> 00:01:19,150
My. I'm from Colombia. I have to say.

12
00:01:21,770 --> 00:01:29,030
Okay. I have in Charge Labs Mondays and Wednesdays.

13
00:01:29,390 --> 00:01:39,950
And immediately after the lab I have office hours and so so my office hours are 6 to 7 on zoom on this only you can find in the campus page.

14
00:01:40,910 --> 00:01:45,380
Okay, please feel free to email me whenever you want.

15
00:01:45,830 --> 00:01:49,970
Just two things about email if you can just like are in the subject.

16
00:01:50,330 --> 00:01:58,430
523 so I know is like about this class and also when you are emailing like emailing code which is

17
00:01:58,580 --> 00:02:06,050
what most of your questions just make sure to like either take a screenshot of the entire code,

18
00:02:06,260 --> 00:02:10,399
not only of whatever is going wrong because sometimes that's very hard for me to understand.

19
00:02:10,400 --> 00:02:14,180
So just like take a screenshot of everything so I can just review the whole thing.

20
00:02:14,180 --> 00:02:18,440
I'm not only whatever is not working, okay?

21
00:02:18,830 --> 00:02:21,860
So lab sections are what are they for?

22
00:02:23,360 --> 00:02:26,179
So basically what I want to make weekly,

23
00:02:26,180 --> 00:02:35,839
we are going to review code that's going to be useful for the next homeboy's labs are in person on lease only.

24
00:02:35,840 --> 00:02:38,660
Attend to the lab that you are enrolled in.

25
00:02:40,250 --> 00:02:47,350
I do understand that sometimes we kind of make out we like a lot of things can happen in a day, but please just email me.

26
00:02:47,410 --> 00:02:49,069
You're going to go to another lab,

27
00:02:49,070 --> 00:02:58,700
especially the one on Mondays because I want on Monday you see some like it's here in the other classroom a which is of way more is more classroom.

28
00:02:58,700 --> 00:03:04,460
On last Monday I couldn't see everyone, so I just email me to make sure I can, like, save you a spot.

29
00:03:05,870 --> 00:03:09,560
What else? Labs are recorded, which is great news.

30
00:03:09,620 --> 00:03:12,650
I'm recording myself right now, so hopefully everything will be fine.

31
00:03:13,760 --> 00:03:23,450
The record I'm recording in front of so you can make after lab 10 minutes later, you can immediately find the recording on the campus site.

32
00:03:25,950 --> 00:03:29,100
Again. What is the main objective of the lab? Just review code.

33
00:03:30,150 --> 00:03:36,660
We have source on our. You are free to use whatever you want either for homeworks,

34
00:03:38,190 --> 00:03:43,800
for anything you want related to this class you can use either source or or even maybe a combination of both.

35
00:03:45,000 --> 00:03:50,520
Just so I have an idea how many of you plan to use SAS?

36
00:03:53,780 --> 00:03:58,990
Okay. And the rest, maybe. Oh, no.

37
00:03:59,360 --> 00:04:03,340
Okay. What else? Just a reminder.

38
00:04:03,350 --> 00:04:09,919
We have six homework this semester. The due dates and so are already posted on campus of today.

39
00:04:09,920 --> 00:04:14,330
We're going to work on homework number one, which is due on Sunday, September 18.

40
00:04:15,320 --> 00:04:18,380
Any questions so far? Okay.

41
00:04:19,940 --> 00:04:25,850
So before we start with the homework, I just want to take you to.

42
00:04:26,270 --> 00:04:33,590
So if you go to 523, the campus site here at the top, you can find log files.

43
00:04:34,190 --> 00:04:39,380
If you click on that every week, we're going to be updating lab files before the lab.

44
00:04:40,580 --> 00:04:42,890
You have absolutely everything that you need. Put it up.

45
00:04:43,130 --> 00:04:47,750
You have the presentation, which is going to be exactly the same as the one that I'm going to go through.

46
00:04:48,050 --> 00:04:56,030
And you have either source code or our code. So we just like download whatever is more like whatever you use you are going to use.

47
00:04:56,080 --> 00:05:03,200
Right? There is a I think that's a major difference between 522 and 521 lots.

48
00:05:03,470 --> 00:05:06,500
So I don't know if you remember about four or 522 and 521,

49
00:05:06,500 --> 00:05:10,850
I was like coding and you were like copy pasting while I was coding here you

50
00:05:10,850 --> 00:05:14,000
already have the code so you don't have to like actually worry about that.

51
00:05:14,240 --> 00:05:22,580
Just download it and make sure it works and make sure you are understanding what is it doing, how to read all of the outputs, so on and so forth.

52
00:05:22,730 --> 00:05:25,790
Okay. Okay.

53
00:05:29,100 --> 00:05:33,730
Then just to be safe you are using SAS.

54
00:05:34,390 --> 00:05:40,060
So they there on campus. I have loaded four different things with the SAS files.

55
00:05:40,060 --> 00:05:45,930
So if you're using sausages, download that and for the ones that are using R, I have three different scripts,

56
00:05:46,320 --> 00:05:52,980
the art script, which is my recommendation for you because this is just like running the thing, the art of markdown.

57
00:05:53,520 --> 00:05:59,370
If you haven't worked with markdown before, maybe just done downloaded, that's just like another way to run our code.

58
00:05:59,760 --> 00:06:03,290
You don't need to worry about that if you have a new set. Just like do not.

59
00:06:03,300 --> 00:06:10,470
We didn't download it. And then there is some HTML file which is just like output of the art of markdown.

60
00:06:10,680 --> 00:06:17,070
Okay. And if you are using source, there's only one SAS file that should run.

61
00:06:17,490 --> 00:06:22,260
And also if you are using SAS, there's two ways you can use SAS.

62
00:06:22,560 --> 00:06:27,870
So either log in this computers which have source or use three ways.

63
00:06:27,900 --> 00:06:34,200
Either use this computers use a virtual site or use SAS on demand.

64
00:06:34,380 --> 00:06:41,510
Okay. If you're using SAS on demand, ah, here is some link.

65
00:06:41,520 --> 00:06:53,330
Or you can just like go to the main. Create an account and that is just like working source from Mozilla or from any explorer that you're using.

66
00:06:54,380 --> 00:06:57,380
Okay, now to the fun part.

67
00:06:57,830 --> 00:07:05,059
Homework. So I my recommendation for you is to at least read the homework before coming here.

68
00:07:05,060 --> 00:07:08,570
So, you know, more or less, what are you, like, supposed to do?

69
00:07:09,140 --> 00:07:14,480
So this homework, you have two problems. The first problem is mainly about meta analysis on.

70
00:07:15,770 --> 00:07:25,590
Meta analysis. I think that's all. And then the second problem is probably it's our ozone hole here of, um, maybe chi square and chi square.

71
00:07:25,920 --> 00:07:31,560
Yes. So one problem, number one, meta analysis.

72
00:07:32,280 --> 00:07:34,740
Oh, I forgot to tell you this.

73
00:07:34,750 --> 00:07:42,659
If you don't allow the presentation, which I highly recommend, these things are links that just like if you click on it,

74
00:07:42,660 --> 00:07:50,270
they're going to go directly to the R is like with the R or source code for that specific thing.

75
00:07:50,280 --> 00:07:55,169
So for example, if we are working with make analysis and you need to figure out the source code,

76
00:07:55,170 --> 00:08:00,480
just click here or if you are working, make analysis on me to figure out the R code, click here.

77
00:08:00,810 --> 00:08:05,130
So I highly recommend to download the thing because we have both of these codes here.

78
00:08:06,090 --> 00:08:11,480
Okay. So almost number one, we have to do all this on a phone plot.

79
00:08:11,970 --> 00:08:19,440
So meta analysis for the purpose of the lab, we are using a different an example.

80
00:08:21,630 --> 00:08:34,450
I'm so sorry. All right.

81
00:08:34,840 --> 00:08:40,690
So for the purpose of the plasma, I'm using an example, but it is very, very similar to the table that you have in the home.

82
00:08:41,230 --> 00:08:43,420
So here we have different papers.

83
00:08:43,780 --> 00:08:52,120
And then the most important part is that for each paper, we have some data that will be useful to construct two by two table.

84
00:08:52,390 --> 00:08:58,780
So in this case, we have the control, the treatment group, which is magnesium and the control group.

85
00:08:59,230 --> 00:09:06,220
And then we have number and then I'm after the number and then we have a number of people like in each group.

86
00:09:06,550 --> 00:09:12,040
So for example, here for this paper, there were 40% in the treatment group.

87
00:09:12,550 --> 00:09:16,870
One of them that and that's how we read this thing makes sense.

88
00:09:19,060 --> 00:09:22,450
Okay. Okay.

89
00:09:22,560 --> 00:09:29,860
So, sex. First thing we need to do, either science or art, is to just create our dataset.

90
00:09:30,130 --> 00:09:38,200
In fact, for us, the way to create the dataset, it's first to convert each and every one of these papers into a two by two table.

91
00:09:38,710 --> 00:09:49,510
So if we chose the first paper, we have the treatment treatment group and the control group and then the the CS, whether they died or not.

92
00:09:49,870 --> 00:09:56,590
And based on those numbers, we can construct a two by two table. So for example, we have one people from the magnesium group die.

93
00:09:56,650 --> 00:10:00,350
So that's one here, one people from the magnesium group died.

94
00:10:00,820 --> 00:10:04,640
And then we have in total 40 people of the magnesium group for that paper.

95
00:10:04,660 --> 00:10:11,830
So here I have 40, which means that there must be 39 people in the magnesium group who didn't died.

96
00:10:12,340 --> 00:10:15,350
Makes sense. Sure.

97
00:10:15,890 --> 00:10:20,540
And then the same with the other two numbers. So here is the control group.

98
00:10:20,540 --> 00:10:23,600
In total, I have 36, 36 people in the control group.

99
00:10:23,930 --> 00:10:31,190
So if I were to assume equal now this is 36 group three, 36 people from those 36 people do died.

100
00:10:31,210 --> 00:10:34,490
So I have a two here, which means this must be 34.

101
00:10:35,210 --> 00:10:40,420
Makes sense. Okay, so you these you have to do manually.

102
00:10:40,430 --> 00:10:43,190
There's no way to do it and you have to, like, do it manually.

103
00:10:43,520 --> 00:10:48,110
And then once you do it manually, we are just going to tell us how to read those things.

104
00:10:48,440 --> 00:10:51,440
So as you can see, first of all, we have seven papers.

105
00:10:51,950 --> 00:10:57,440
Yep. One, two, three, four, five, six, seven papers. So that's my first column here.

106
00:10:57,650 --> 00:11:03,320
So one, two, seven. And for each paper, I have four numbers A, B, C and E.

107
00:11:03,770 --> 00:11:11,730
So those are the four numbers that I have here. So for paper number one, Magnus, it's equal to yes, I'm very sequencer.

108
00:11:11,790 --> 00:11:15,530
Yes. And then I have only one people in that. So does that make sense?

109
00:11:16,130 --> 00:11:21,710
And then so on and so forth. So for the first paper, magnesium is equal to yes, they didn't die.

110
00:11:21,980 --> 00:11:28,010
I have 39 people. So is this the 89? And you have to do all of that for the seven papers.

111
00:11:28,280 --> 00:11:32,780
Is there an easier way to do it? Unfortunately not. There is no easier way to do it.

112
00:11:32,780 --> 00:11:35,780
You just have to consider the two, two tables and then do it.

113
00:11:37,420 --> 00:11:41,210
Any questions so far? Okay.

114
00:11:42,080 --> 00:11:51,830
So once you create a table, we will like to run a test for the overall odds ratio.

115
00:11:52,160 --> 00:11:54,410
That would be the amount that he saw in this case.

116
00:11:55,550 --> 00:12:05,840
So that's rather like, okay, so inside we are going to use made data is whatever name you chose for the data file before.

117
00:12:06,140 --> 00:12:09,710
So here are data. I name my mother's death.

118
00:12:10,460 --> 00:12:16,010
And then so here I have a correct and then data is whatever name I chose.

119
00:12:16,490 --> 00:12:22,670
And then please order the data that's very important and source and then just create a table with the common table,

120
00:12:23,030 --> 00:12:29,450
the name of my variables, a study magnitude on that and then the common to create the month.

121
00:12:29,450 --> 00:12:38,530
Okay, so is CMH and that's it. And finally, just remember to weight all of the sales but the column by the comparable.

122
00:12:39,170 --> 00:12:43,820
Once you run the code, you should have something like this.

123
00:12:44,480 --> 00:12:53,660
Here we have the month old hotel for the general association so we don't care about the non zero correlations or the role or the row mean scores.

124
00:12:53,660 --> 00:13:03,200
We only care about the General Association and this is that p value associated with that best remembered of the mantle Hazel Fest is the one for the

125
00:13:03,200 --> 00:13:09,079
overall you know including like condition on the seven stories a studies what

126
00:13:09,080 --> 00:13:12,860
is the overall odds ratio for that disease and that particular treatment.

127
00:13:12,860 --> 00:13:20,360
Right. So here we have the tests that they seek and here we have the P.

128
00:13:20,360 --> 00:13:27,530
But since this is any common hypothesis test, you have two ways to complete the test.

129
00:13:27,860 --> 00:13:36,530
Either compare these to a critical value or use the P value and compare it to the significance level and then reject or do not reject.

130
00:13:37,160 --> 00:13:40,870
Does that make sense? Okay. Any questions so far?

131
00:13:45,210 --> 00:13:57,570
Okay. Part of the that frequency procedure is that it also gives you the odds ratio.

132
00:13:57,600 --> 00:14:03,509
Remember that in this table, the one that I have before, I only have the p value and the test statistic.

133
00:14:03,510 --> 00:14:07,650
I don't have the overall odds ratio or the 95% confidence interval.

134
00:14:07,980 --> 00:14:15,150
For that, I need to go to my other table, which is a common observation table and then the odds ratio using of, okay,

135
00:14:15,160 --> 00:14:21,660
so you have the odds ratio because the estimate of the odds ratio and then the confidence interval for that estimate.

136
00:14:24,430 --> 00:14:28,680
All right. That would be using SAS.

137
00:14:29,290 --> 00:14:38,230
So now how do we do it using art? So in art, we are going to use a package called the make up output.

138
00:14:39,370 --> 00:14:43,300
Very, very important because a lot of you are using our.

139
00:14:46,170 --> 00:14:50,850
If you run the code right now, it is good luck.

140
00:14:51,090 --> 00:14:55,530
Chances are that the output that you are going to get is not the same one that I have here.

141
00:14:55,830 --> 00:15:00,899
And that's because we are using them like a package. And that package was recently updated.

142
00:15:00,900 --> 00:15:05,820
And all of this is lines are with the previous version version of the package.

143
00:15:06,120 --> 00:15:10,990
So to get the previous version freeze, please run.

144
00:15:11,040 --> 00:15:18,820
Run the following. You just. Seems.

145
00:15:21,390 --> 00:15:33,010
Uh huh. Oh, yeah.

146
00:15:34,100 --> 00:15:50,520
This is what you need. Let me make this a little bigger so you can just copy paste it.

147
00:15:59,650 --> 00:16:02,980
Oops. Oh, my. Better.

148
00:16:14,790 --> 00:16:20,100
Here. This is one eight.

149
00:16:21,190 --> 00:16:30,280
So instead of just like installed all packages, make up leaves, do all of these because otherwise your output is not going to be the same as mine.

150
00:16:30,400 --> 00:16:35,020
And then we're going to have a little bit of problem here. So I'm just going to pause here 5 minutes.

151
00:16:35,200 --> 00:16:42,350
So you might do that if you're using mine. And do not run it.

152
00:16:42,370 --> 00:16:46,690
For now, just copy, paste the code. And then I'm going to tell you something before you run it.

153
00:18:02,520 --> 00:18:11,080
Okay. Okay. So before you run these lines, go to the right bottom panel,

154
00:18:11,110 --> 00:18:19,300
go to packages and then in these search bar type made that like the number of the the name of the package.

155
00:18:19,960 --> 00:18:26,350
I don't have it. So it's not going to show for me. But if you do, please make sure it's a box.

156
00:18:26,500 --> 00:18:30,940
So let's see. Let's. Let's assume here is the make up package.

157
00:18:31,210 --> 00:18:34,930
Just click it. Okay. So, like, e download it again.

158
00:18:35,830 --> 00:18:43,040
And then after that, we should have the same outfit. All right.

159
00:18:44,860 --> 00:18:53,650
So for our for my ballot, this is where when I use those two packages, then make a package with the old version of the metaphor package.

160
00:18:53,740 --> 00:18:59,230
So make sure you install those. The question.

161
00:18:59,390 --> 00:19:06,190
Yes, I'm clicking on checking before we install. Yes, on check it before you install OC.

162
00:19:10,430 --> 00:19:15,380
So coming back to our how do we do you make analogies in art?

163
00:19:15,770 --> 00:19:20,960
It's somewhat similar. The first thing we need to do is constructed two by two tables.

164
00:19:21,080 --> 00:19:28,450
Nothing you can do that is do it by hand unless we are going to create vectors with all of the two to can take.

165
00:19:28,520 --> 00:19:33,680
So for example, in this case, I should have seven de France, two by two table, right?

166
00:19:34,010 --> 00:19:41,270
One for each study, one of each two by two table has a cell which is normally this one.

167
00:19:41,630 --> 00:19:46,070
So what I'm going to do is to create a vector with all of the a cell.

168
00:19:46,120 --> 00:19:52,429
So it's a vector with seven positions. The first numbers correspond to the A cell for the first study.

169
00:19:52,430 --> 00:19:56,960
The second number corresponds to the eight cell for the second study, so on and so forth.

170
00:19:57,350 --> 00:20:06,260
And that's what I have here. So, for example, these A's, this is a cell is the number one because it's the number one here.

171
00:20:06,680 --> 00:20:16,520
So here I'm creating a vector which has a length, 711 number for each study, and it just has all of the eight cells for all of this studies.

172
00:20:16,790 --> 00:20:20,120
So 1921 ten one one.

173
00:20:20,540 --> 00:20:27,470
Okay. Really, it's not easy to visualize because you have to create a two by two tables, but that's what I'm doing here.

174
00:20:27,830 --> 00:20:32,630
So I'm creating the A I'm also creating make there for these numbers,

175
00:20:33,020 --> 00:20:40,729
also creating a vector for these numbers and for these numbers and then for the remaining cells.

176
00:20:40,730 --> 00:20:52,240
I'm just doing b whatever I need in mind, which is just like. Do it in minus between the total number of people in each group and how many died.

177
00:20:52,940 --> 00:20:56,659
And then the odds ratio will be our general formula.

178
00:20:56,660 --> 00:20:59,980
Just a pie was the divided by the time.

179
00:20:59,990 --> 00:21:03,469
See? Okay, you don't need to do that.

180
00:21:03,470 --> 00:21:07,880
I just do it because I think it's easier than for like recognize which corresponds to which.

181
00:21:08,120 --> 00:21:11,140
But this is just a vector with the name of the states. Okay?

182
00:21:11,330 --> 00:21:13,100
So it's a vector with the name of the studies.

183
00:21:13,670 --> 00:21:24,050
And then to run the model, hazel, I'm going to use a function which is then between function and it's going to ask me for all of those numbers.

184
00:21:24,410 --> 00:21:30,710
So all of the A's, all of them, the total number of people in each group, all of the, you know,

185
00:21:30,950 --> 00:21:35,750
all of the different numbers in the two way, two tables and then very, very important.

186
00:21:36,320 --> 00:21:41,540
Um, so in this case, for example, method equal inverse.

187
00:21:41,870 --> 00:21:48,740
If I choose inverse, I'm doing the odds ratio with the inverse variance method.

188
00:21:49,190 --> 00:21:54,650
If you want the multiple, hey, I'll just change this inverse for an H.

189
00:21:55,190 --> 00:22:00,530
Okay? So just copy basically unchanged inverse for an H.

190
00:22:00,680 --> 00:22:08,509
If you run it like this right now, it would give you the estimates of the odds ratio, but we'd be embarrassed.

191
00:22:08,510 --> 00:22:12,320
Variance matter. Does that make sense? Okay.

192
00:22:12,740 --> 00:22:17,610
And then since we're there in the homework, we are only using odds ratio.

193
00:22:17,630 --> 00:22:21,560
Just make sure that summary is and here it's odds ratio.

194
00:22:21,560 --> 00:22:26,780
So those are all the only outputs. We are like looking up questions so far.

195
00:22:29,560 --> 00:22:38,200
Okay. Good. Yeah. So if you run this code, then the output should look something like this.

196
00:22:38,710 --> 00:22:45,100
You have for each of the studies the odds ratio and then the 95% confidence interval.

197
00:22:45,370 --> 00:22:49,270
So, for example, that's a table you need to field in homework, number one.

198
00:22:49,790 --> 00:22:55,000
It's just coffee in facing this out this table. This outperform from our.

199
00:22:55,990 --> 00:22:59,500
The only thing is that for the table thing, you have to use the amount, the lazy method.

200
00:22:59,500 --> 00:23:03,060
So make sure you change your method to match.

201
00:23:03,580 --> 00:23:12,430
Just make sure you're, like, changing those things. So you have here the old three from the 95% confidence interval.

202
00:23:12,760 --> 00:23:25,150
And then here you have in the fixed effect model, you have the overall odds ratio in this case using the invariance, the inverse variance method.

203
00:23:26,850 --> 00:23:30,480
Any questions so far? Does that make sense?

204
00:23:30,660 --> 00:23:33,920
More or less. Okay?

205
00:23:34,800 --> 00:23:40,760
Ah, yes. Are the people running for office asking for an actual log of the odds ratio?

206
00:23:40,760 --> 00:23:44,120
Is that what that is, giving them an actual line? Yeah.

207
00:23:44,120 --> 00:23:47,390
This is the odds ratio. This is not. That's a lot. Yes.

208
00:23:49,850 --> 00:23:54,290
Okay. What else? Any other questions so far?

209
00:23:58,400 --> 00:24:08,930
Okay. And then we also have the test for if there is no if the ATO is in Haiti, which is another question in the homework.

210
00:24:09,620 --> 00:24:17,540
Remember that this test is testing whether all of the odds ratio are the same between the seven studies in this case.

211
00:24:17,900 --> 00:24:24,650
And then here we have the test is probabilistic that the degrees of freedom and the p value.

212
00:24:24,890 --> 00:24:33,770
Okay, which is everything you need for the test. Okay.

213
00:24:34,940 --> 00:24:39,940
So using the same, there are two ways actually.

214
00:24:39,950 --> 00:24:45,230
So if you are using art, there are two ways to solve the question to solve the homework.

215
00:24:45,590 --> 00:24:52,909
One is using them make from function and then changing this method to either inverse or month.

216
00:24:52,910 --> 00:24:58,610
Okay, so which are the ones that you need or I think there's another one that you alternate.

217
00:24:59,090 --> 00:25:05,420
But yeah, it's either changing this method or like these my book in the function make up.

218
00:25:05,930 --> 00:25:09,860
Or you can use another function which is for all. If I just use whatever you want.

219
00:25:10,970 --> 00:25:22,940
Respond to an error and either make only works for them on the way so you can prove you should have the same results should give you the same thing.

220
00:25:24,200 --> 00:25:28,970
So this one is for month old you. It can only be used for eight month old Hazel.

221
00:25:29,030 --> 00:25:33,890
Never. But it should give you the same results as if you were using the method main function.

222
00:25:34,940 --> 00:25:43,070
So here is asking you for the same exact things and then you also have the Aboriginality test the amount of hazel method,

223
00:25:43,610 --> 00:25:53,690
the estimate of the mental, hence the odds ratio, the confidence interval, and then the test statistic of the degrees of freedom under Peebles.

224
00:25:54,470 --> 00:25:58,710
Okay. All right.

225
00:25:59,640 --> 00:26:13,740
Just a question. You know that in the homework there is one study I think is the fun site that has a cell with a zero count.

226
00:26:13,890 --> 00:26:20,010
Right. What to do in that case? 5.5.

227
00:26:20,190 --> 00:26:26,360
Correct. Just make sure you acknowledge that for the month.

228
00:26:26,520 --> 00:26:32,430
Hazel matter. There is no need to add the point five because yeah.

229
00:26:32,550 --> 00:26:37,230
In you just can't do it because never in the months and months though.

230
00:26:37,230 --> 00:26:44,610
Hazel, I'm dividing by zero, which is the problem. So you don't need to add the point five for that is three using the month.

231
00:26:44,610 --> 00:26:44,909
Okay.

232
00:26:44,910 --> 00:26:54,780
So but they invariance invariance inverse variance method you do have the the point five because otherwise it's not there, it's just not your problem.

233
00:26:55,110 --> 00:26:58,200
So if you have a problem running the inverse variance method,

234
00:26:58,380 --> 00:27:07,260
it's probably most likely because you haven't asked the point five to each of the cell in each of the four cells.

235
00:27:07,470 --> 00:27:11,200
So that counts on. Is that okay?

236
00:27:11,530 --> 00:27:14,710
Does that make sense? Just make sure you're doing that. Yes.

237
00:27:15,280 --> 00:27:20,800
If you do that, the medicine version with the methods of people as mental.

238
00:27:21,110 --> 00:27:24,180
And so does it matter that you had a 2.5 or. Yeah.

239
00:27:24,190 --> 00:27:27,820
If you are 2.5, you're going to get a slightly different estimate.

240
00:27:28,450 --> 00:27:32,410
If you don't do it. So for the mental patient, that's not need to do it.

241
00:27:32,830 --> 00:27:39,400
But if you do it, you're going to get a different estimate. So if we compare arms right answers, they may be a little different.

242
00:27:39,640 --> 00:27:43,180
Okay. You mean so there's the meds. So the other one not.

243
00:27:43,660 --> 00:27:49,900
Oh, okay. You select can sort of inverse, but you go ahead and put the point five of them.

244
00:27:52,090 --> 00:27:55,590
Yeah. We give you the same answer as if you didn't know.

245
00:27:55,600 --> 00:27:57,570
No. Yeah. Yeah. No. Mm hmm.

246
00:27:58,040 --> 00:28:08,080
Actually, in this function, there are certain parameters where, like that you can either set two true or false to add for you the point five.

247
00:28:08,200 --> 00:28:12,910
You just have to look for it, or you can do it manually, which is probably the easiest way for you to do it.

248
00:28:13,540 --> 00:28:20,739
But yes. So if there's a difference, it's a slightly it's likely because you have an added point five for the inverse

249
00:28:20,740 --> 00:28:25,809
finance matrix or you added the point five for the month that sells mental hazel,

250
00:28:25,810 --> 00:28:31,090
in which case please don't because there's only I mean, if you do it, it's not going to be that different.

251
00:28:31,330 --> 00:28:35,110
But if there is a difference, it's probably because in the month, okay, so you don't need to do it.

252
00:28:35,350 --> 00:28:39,520
But for the inverse inverse variance method, you do need to do it.

253
00:28:39,970 --> 00:28:45,580
So that makes those that make sense. Okay.

254
00:28:47,120 --> 00:28:50,900
Okay. So just think of that.

255
00:28:51,980 --> 00:28:58,100
All right. And then someone was asking me for the table.

256
00:28:58,580 --> 00:29:01,819
We need the natural logarithm of the odds ratio.

257
00:29:01,820 --> 00:29:11,330
Right? So to get that, if you use this function, if you use this function, then there is a parameter that you can access for that function,

258
00:29:11,330 --> 00:29:19,520
which is a Y in this case that will give you the natural logarithm of the odds ratio.

259
00:29:19,700 --> 00:29:29,750
Okay. And then you can also, if you ask for the V i's, you would get the variance of the natural logarithm of the odds ratio,

260
00:29:30,110 --> 00:29:32,750
which are the things you need to fill out that table.

261
00:29:33,320 --> 00:29:40,250
So you can either do it by hand, which is just like taking the natural logarithm or just asked these functions to do it for you.

262
00:29:41,140 --> 00:29:46,670
Does that make sense? Any questions so far?

263
00:29:51,340 --> 00:29:54,580
Oh. Now fun and plot.

264
00:29:54,820 --> 00:30:00,280
So for the fun of flood. Oh, so the final flood.

265
00:30:01,030 --> 00:30:08,380
It's a Scottish flood. But in the x axis has the loss of the odds ratio.

266
00:30:08,710 --> 00:30:16,780
And the in the y axis, you have the standard error of the odds of that odds ratio here.

267
00:30:16,990 --> 00:30:20,080
All of the dots represent one study.

268
00:30:20,830 --> 00:30:25,240
So the first lot is, yes, I need to like create a scatterplot with these two things.

269
00:30:25,600 --> 00:30:33,940
But then the very interesting thing of a different look is just these two lines which correspond to a 95% confidence interval.

270
00:30:33,970 --> 00:30:36,820
So in this case, for example, we can see that there is like one,

271
00:30:36,820 --> 00:30:42,820
a study that is like we don't trust it very much because it falls out of the 95% region.

272
00:30:43,270 --> 00:30:46,720
So how to create the point of blood? We need to do two things.

273
00:30:46,810 --> 00:30:50,830
The first thing is just to create a scatterplot for these dots.

274
00:30:51,220 --> 00:30:55,930
And then the second thing is to create these lines for the 95% confidence interval.

275
00:30:56,200 --> 00:31:01,890
Makes sense. Okay. So how to create these lines?

276
00:31:01,900 --> 00:31:08,260
So this kind of one plot is very secret because we can just use juju plot or something very easy to like, you know, create a plot.

277
00:31:08,650 --> 00:31:22,450
These lines are the actual problem. So these lines are a 95% confidence interval with respect to the study with the minimum a standard error.

278
00:31:22,870 --> 00:31:31,509
So in this case, if you look at this plot, it's actually very weird because normally it's like the numbers should go increasing.

279
00:31:31,510 --> 00:31:35,470
As I go up here, they are decreasing because that's the fun of plot.

280
00:31:35,890 --> 00:31:41,980
But we are going to look for the study with the minimum standard error among myself.

281
00:31:42,280 --> 00:31:47,290
So in this case, it should be this for the study that is like more a.

282
00:31:48,250 --> 00:31:53,890
So in this case, it would be this one which is like the one that has the minimum standard error.

283
00:31:54,340 --> 00:32:01,990
So once I have identified that study, I'm just going to create the 95% confidence interval of that study.

284
00:32:02,260 --> 00:32:06,370
And these are those two lines. So. Three steps.

285
00:32:06,530 --> 00:32:13,070
First, create this current block, then identify this study with the minimum standard error.

286
00:32:13,340 --> 00:32:19,220
And then based on that, create 95% confidence lines make sense.

287
00:32:20,060 --> 00:32:32,990
Okay, so what I'm doing here in this domain as these is our code, is to identify the study with the minimum or with the smallest as standard.

288
00:32:33,560 --> 00:32:37,060
So that's what I'm doing here. I'm just identifying. That's what I use.

289
00:32:37,070 --> 00:32:44,810
I'm using the mean function, identifying the study with the smallest standard error.

290
00:32:45,320 --> 00:32:51,260
And then once I have that, I'm just going to use this function.

291
00:32:51,650 --> 00:32:56,479
So final thought and a is the way to create.

292
00:32:56,480 --> 00:32:59,860
I want to plug in. It's within the make up package.

293
00:33:00,410 --> 00:33:05,690
And then here I have an H. And now this is what is an H analysis.

294
00:33:08,240 --> 00:33:12,350
It's the output of this function. Okay.

295
00:33:12,560 --> 00:33:17,209
So first you do this function, which is imagine, hey, so because the fun of what is based on the month.

296
00:33:17,210 --> 00:33:29,290
Okay so so you didn't you do them until. You save the output and then you just run this nine funnel per there are eight.

297
00:33:29,480 --> 00:33:33,770
This first parameter is the output for the month.

298
00:33:33,770 --> 00:33:42,110
Okay, so function and then this red line, it's the line that I created across the smallest is standard error.

299
00:33:42,470 --> 00:33:46,060
So that makes sense. And then it should look something like it's.

300
00:33:48,910 --> 00:33:55,840
Questions so far. Oh, it.

301
00:33:59,210 --> 00:34:03,140
Funnel flood in source. It's a little bit more complicated.

302
00:34:05,000 --> 00:34:11,900
The logic is exactly the same. So you have to access lots of the operation than the standard error.

303
00:34:11,930 --> 00:34:21,830
You have this current flood of all of these things. You identify the study with that as well as the standard error and then draw the two lines.

304
00:34:22,130 --> 00:34:28,370
So it's basically the same as just a little bit more code. I'm just going to go directly to the code.

305
00:34:29,630 --> 00:34:32,870
So if you're using source, this would be the code.

306
00:34:34,400 --> 00:34:44,810
Um, so here, I'm just, I'm going to create a data set when I'm creating the data set.

307
00:34:44,900 --> 00:34:51,890
I'm going to have four variables that study the cell bay and one C and dual.

308
00:34:52,280 --> 00:35:00,110
And then here I'm creating two new more variables based on those variables that I'm going to input, which are the B and the cells.

309
00:35:00,440 --> 00:35:07,280
And then here I'm just creating the odds ratio. You can see here that this is the odds ratio and then the natural logarithm of that thing.

310
00:35:07,670 --> 00:35:13,040
And then here, this is the standard error of the part of the natural logarithm of the odds ratio,

311
00:35:13,250 --> 00:35:17,600
one over eight plus one over B plus one to receive, plus one over D and then the square root.

312
00:35:18,650 --> 00:35:24,560
And then here, just the sample size would that would be just adding all of the cells together.

313
00:35:25,010 --> 00:35:28,290
And then after data lines, I'm actually going to include the data.

314
00:35:28,310 --> 00:35:33,980
So here I have the name of the study. And then here I have one for a.

315
00:35:34,130 --> 00:35:43,270
So remember here about this is a. Then here I have in one, which is that photo over there, then it should be seen,

316
00:35:43,270 --> 00:35:50,590
which is that two over there and then 36, which is N2 and then so on and so forth for all of the seven studies.

317
00:35:51,040 --> 00:35:58,780
And then if you run this, it won't create the funnel plot, but it will create the data that will create the final one.

318
00:35:59,710 --> 00:36:05,830
And then for the final flood, remember that we need to identify this study with the small.

319
00:36:05,830 --> 00:36:06,850
This is standard error.

320
00:36:07,210 --> 00:36:16,750
So if you run these lines, you are going to create a table with four inches three I half the natural logarithm of the odds ratio.

321
00:36:17,260 --> 00:36:22,570
The variance well actually the standard error of that natural logarithm of the odds ratio.

322
00:36:23,110 --> 00:36:28,540
I'm going to check in this variance, which is the one with the smallest value.

323
00:36:28,870 --> 00:36:32,350
It will be this bounce, this 0.41.

324
00:36:32,650 --> 00:36:35,860
And then I'm just that this is this is going to be my baseline of study.

325
00:36:36,310 --> 00:36:41,620
And then for this study, just remember these value -1.05.

326
00:36:42,010 --> 00:36:45,610
Why this? Because is this study with this small is a standard error.

327
00:36:46,090 --> 00:36:51,610
Remember this value because when I'm creating the fun of blood in SAS,

328
00:36:52,000 --> 00:36:57,460
what I'm doing is first creating this color blood and then creating these two lines.

329
00:36:57,820 --> 00:37:02,469
So a little bit more complicated than I. So I create this current blood here.

330
00:37:02,470 --> 00:37:09,010
And then in these the lines line part M, I'm creating those 95% confidence lines.

331
00:37:09,790 --> 00:37:23,650
These X -1.05. It's the natural dividing of the odds ratio of this study with this smallest a standard error and then y equals zero.

332
00:37:23,660 --> 00:37:27,490
Yes, it's always y equals zero. So you can create that kind of a line.

333
00:37:27,940 --> 00:37:38,500
And then for this low I have 0.510, which there's no birth comes from one over 1.96.

334
00:37:39,040 --> 00:37:49,420
That number is just ensuring that we create a 95% confidence interval because remember that 1.96 is the 95% versus 95.

335
00:37:51,630 --> 00:37:56,460
Person thought 95 percentile of the standard normal distribution.

336
00:37:57,960 --> 00:38:04,110
So that's it. If you're using source, it's a little bit longer, but basically the same three steps.

337
00:38:04,650 --> 00:38:09,840
First, create a scatterplot, then identify this study with the as small as estimator error,

338
00:38:10,230 --> 00:38:17,340
then create the two lines of the confidence interval based on that style, which is exactly what we are doing here.

339
00:38:18,540 --> 00:38:23,390
Questions so far. Okay.

340
00:38:24,440 --> 00:38:30,570
So. Another part of your homework.

341
00:38:30,580 --> 00:38:34,180
It's to create a rock cure, I think.

342
00:38:34,310 --> 00:38:37,420
Yeah. So how do we do that?

343
00:38:38,140 --> 00:38:45,070
For now, we're going to do it very manually. Next lab, we're going to do it a little bit more automated.

344
00:38:45,700 --> 00:38:50,520
So just a brief review. If you have a two by two table.

345
00:38:50,530 --> 00:38:56,710
So here I have the test results and here I have the actual value of the disease.

346
00:38:57,340 --> 00:39:03,520
I can I can measure Susy from I'm there.

347
00:39:03,730 --> 00:39:10,660
I can estimate two different measures. The first one, it's called sensitivity, which is the true positive rate.

348
00:39:10,990 --> 00:39:15,220
And the second one is the specificity, the true negative rate.

349
00:39:15,550 --> 00:39:26,800
So sensitivity will be the percentage of people who have the disease, who I identify correctly as having the disease would be A or B plus C.

350
00:39:27,280 --> 00:39:38,880
And then the specificity is the people who do not have the disease that I can correctly identify as do not having the disease which we ve obviously.

351
00:39:39,080 --> 00:39:47,200
B Plus. B So for each do I do table, I can always estimate these two values and then these two values.

352
00:39:47,200 --> 00:39:51,550
I can just plot them and create kind of a plot. And that's the rub here.

353
00:39:51,850 --> 00:40:00,190
Basically, that's it. So as an example, let's say I'm measuring Alzheimer's disease.

354
00:40:00,520 --> 00:40:11,590
So for Alzheimer's disease, there is this test that I can create and then the test is going to be a score on a scale of 1 to 4.

355
00:40:12,010 --> 00:40:23,620
So for example, this table is telling me there were 22 people who have Alzheimer's disease who score one in my test.

356
00:40:24,280 --> 00:40:27,760
There are 77 people who have Alzheimer's disease.

357
00:40:27,850 --> 00:40:39,880
Who is going to invite this? So on and so forth. So with this kind of test, which my my actual tests to identify the disease is not yes or no,

358
00:40:40,090 --> 00:40:43,990
but a spectrum of things in this case is just a scale from 1 to 4.

359
00:40:44,260 --> 00:40:49,930
I can create different two by two tables and then plot all of those sensitivity side specificities.

360
00:40:50,260 --> 00:40:52,420
And that's exactly the problem here.

361
00:40:52,960 --> 00:41:03,240
So we are going to create from this table, we are going to create four different two by two tables each for one different thresholds.

362
00:41:03,250 --> 00:41:11,079
So, for example, if I say that someone has, according to my test, someone has Alzheimer's,

363
00:41:11,080 --> 00:41:20,080
if you test scores at least two in the past that I did, then I can create two way to table for them.

364
00:41:20,500 --> 00:41:25,090
That two by two tables should look something like this. Let me see if I can.

365
00:41:25,090 --> 00:41:28,510
Right. Yeah. So for the threshold score.

366
00:41:29,350 --> 00:41:32,510
Oops. Greater than two.

367
00:41:32,520 --> 00:41:36,209
I can create a two by two table. So this will be.

368
00:41:36,210 --> 00:41:40,530
Yes, this will be no. This is the test.

369
00:41:41,250 --> 00:41:44,880
And this is the true Alzheimer's disease. This will be yes.

370
00:41:45,330 --> 00:41:46,320
And this will be no.

371
00:41:50,600 --> 00:41:59,120
So again, what I'm doing is for my threshold, if someone scores greater than double, that would mean that that person has the disease.

372
00:41:59,540 --> 00:42:05,600
So based on these table, they know that do would be 77 plus 40 plus three.

373
00:42:06,200 --> 00:42:10,049
So. 30 plus 47.

374
00:42:10,050 --> 00:42:13,170
The lost 77 is 147. Correct.

375
00:42:13,590 --> 00:42:20,700
So that 147 would go here. Does that make sense?

376
00:42:21,360 --> 00:42:27,989
Is it in Alzheimer's? Yes, because I'm only adding these numbers and it's called plus double just because that's my sample.

377
00:42:27,990 --> 00:42:30,000
But I have four defined thresholds.

378
00:42:30,540 --> 00:42:39,570
And then that means that if a person is score one, in my case for that threshold, it would mean that they don't have the disease according to my best.

379
00:42:40,050 --> 00:42:43,050
So those 22 people go here.

380
00:42:44,300 --> 00:42:49,700
Does that make sense? And then I do the same thing for no Alzheimer's.

381
00:42:49,760 --> 00:43:01,850
So he knows. I mean, I simply be 25 plus two, which is 27, that would go here and then 73 here.

382
00:43:03,470 --> 00:43:11,810
And then this is the two by two table for that threshold. For these two were to table, I can estimate sensitivity and specificity.

383
00:43:11,870 --> 00:43:26,390
Correct. For example, sensitivity. In this case, sensitivity would be 147 over 147 plus 22.

384
00:43:28,580 --> 00:43:32,570
On that, I do the same thing for the specificity. Does that make sense?

385
00:43:34,010 --> 00:43:40,790
Okay. So once I do this for all of the thresholds here, I have an example of the thresholds,

386
00:43:41,870 --> 00:43:49,040
a score greater or equal to one score greater only for them to score various equal than three or it's called greater than four.

387
00:43:49,460 --> 00:43:58,280
For each of those three thresholds, I have to write a table, which means that for each threshold I have a sensitivity and specificity.

388
00:43:58,820 --> 00:44:03,620
If I plug those two things, I'll really dig holes later.

389
00:44:03,620 --> 00:44:08,270
But if I flood those two things, then I have a rock here.

390
00:44:08,420 --> 00:44:14,120
Does that make sense? So for example, here are the I have four thresholds, right?

391
00:44:14,420 --> 00:44:17,890
So here before threshold, this is one threshold.

392
00:44:17,900 --> 00:44:20,960
This is the older one. This is the older one and this is the other one.

393
00:44:21,290 --> 00:44:24,859
So for one of those thresholds, for example, I don't remember which one.

394
00:44:24,860 --> 00:44:28,030
So you have to do it by hand. I don't remember which one.

395
00:44:28,040 --> 00:44:39,020
But the sensitivity, it's like around 8.0. 85 and the one minus the specificity is 0.25.

396
00:44:39,350 --> 00:44:43,730
Okay. So, yeah, so you can do it by hand.

397
00:44:43,970 --> 00:44:53,390
Of course, because there are like only four thresholds. So you can just basically do it by hand or you can just ask R or SAS to do it for me.

398
00:44:53,960 --> 00:44:57,650
So how do I record using fast?

399
00:44:58,040 --> 00:45:01,190
The first thing is just to create a data set.

400
00:45:02,080 --> 00:45:11,260
So why don't you create a data set in SAS? So in SAS, what I would like is a data set that looks something like this.

401
00:45:12,910 --> 00:45:19,280
So I have these core. On whether someone has Alzheimer's or not.

402
00:45:20,700 --> 00:45:27,430
And this is my data. My data would have two columns, one for this court and one for.

403
00:45:28,230 --> 00:45:34,080
If that person has or non timer's. So for example, I have 22 people here.

404
00:45:34,560 --> 00:45:37,890
They have a score one. So one, one, one.

405
00:45:38,490 --> 00:45:44,290
And I have 22 people like that. They have a score one and they have Alzheimer's.

406
00:45:44,310 --> 00:45:49,050
Yes. So Alzheimer's. Yes. For me is going to be just a one and then I have a one here.

407
00:45:50,130 --> 00:45:58,920
So that's how the dataset looks like. I'm going to create 22 rows that are exactly the same one for the score and one for assignment.

408
00:45:59,250 --> 00:46:03,890
And that's just these. So and I'm going to repeat the same for all of the sets.

409
00:46:04,200 --> 00:46:15,180
So for example, for this 25 cell, I'm going to have a score two and then Alzheimer's zero, a score two and then Alzheimer's zero.

410
00:46:15,450 --> 00:46:19,140
And I'm going to have 25 rows. That looks like that.

411
00:46:19,620 --> 00:46:24,310
Does that make sense? And this is how to do this.

412
00:46:24,820 --> 00:46:27,910
How do we do it? Is we all of these is do right here.

413
00:46:28,330 --> 00:46:34,180
So, for example, the first one is the move from 1 to 22, y 22, because we have 22 people in this cell.

414
00:46:34,600 --> 00:46:37,479
I'm going to create a score equal to one another time,

415
00:46:37,480 --> 00:46:43,960
which is equal to one because there is a one here and then sometime there's one here and so on and so forth for all of the cells.

416
00:46:44,320 --> 00:46:55,190
Makes sense. Okay. Once you create that data setting source, then we can just use for our logistic data.

417
00:46:55,240 --> 00:47:03,190
It's the data that we just created. And then in plots, we are going to create the core flow model.

418
00:47:03,490 --> 00:47:07,270
In the model, we are going to give it the two variables that we are measuring.

419
00:47:07,510 --> 00:47:10,839
In this case, it's Alzheimer's and scenes.

420
00:47:10,840 --> 00:47:17,480
In my dataset, I called it Alzheimer's. I one year after Alzheimer's.

421
00:47:17,500 --> 00:47:24,489
I'm going to make sure the logistic, the sass understands that for me,

422
00:47:24,490 --> 00:47:32,190
the event assignment is coded as one so that this here I'm just making sure and signer is quoted as one and that is Alzheimer's.

423
00:47:32,200 --> 00:47:36,310
Find the score and then create your score.

424
00:47:36,640 --> 00:47:43,090
Just use this line and it should look something like this.

425
00:47:45,900 --> 00:47:50,340
All right. Now, how do we do it in our.

426
00:47:51,450 --> 00:47:55,560
Okay. So how do we do it in our. We need a new package.

427
00:47:55,700 --> 00:48:02,779
We are. O.C. And then basically we are creating exactly the same dataset.

428
00:48:02,780 --> 00:48:06,440
So the data set is going to be exactly as we did in SAS.

429
00:48:06,920 --> 00:48:15,110
So I hope I'm going to have something that it's called a score, I'm going to have something that is Alzheimer's, and then that's my entire data set.

430
00:48:15,110 --> 00:48:21,710
I just have two columns. So in this dataset I'm going to have 22 rows that looks exactly the same.

431
00:48:22,070 --> 00:48:28,610
They are going to have one in this core and one in Alzheimer's, so on and so forth.

432
00:48:28,790 --> 00:48:35,270
That's how it looks like. So how do we create these data structure in our.

433
00:48:36,700 --> 00:48:40,210
A little bit more simpler. More. Yes.

434
00:48:40,300 --> 00:48:45,360
Way more. Simpler. So for the score. A few.

435
00:48:49,060 --> 00:48:56,440
Yes. So so for this quarter, I have I'm just going to use the function graph, which is just, you know,

436
00:48:57,130 --> 00:49:10,900
11111a number of times in this case, it's going to be 195 times Y 95 times because a score equal to one would be in 95 of my rows.

437
00:49:11,170 --> 00:49:16,780
A score equal to two will be in 102 rows in my data set.

438
00:49:17,110 --> 00:49:24,610
So I have a score of three, one repeated 95 times called number two repeated 102 times, so on and so forth.

439
00:49:24,940 --> 00:49:30,430
And for the five year I have something similar. So for Alzheimer's I'll we all have.

440
00:49:33,020 --> 00:49:37,670
For Alzheimer's. I have Alzheimer's equals to 122 times.

441
00:49:38,050 --> 00:49:41,120
Then. Then equal to. To 73 times.

442
00:49:41,480 --> 00:49:44,540
Then Alzheimer's. Equal to 177 times.

443
00:49:44,870 --> 00:49:48,080
Then equal to to 25 times. So on and so forth.

444
00:49:48,860 --> 00:49:54,010
That's what I have here. And then I create the data. Once you create the data set.

445
00:49:57,380 --> 00:50:05,330
Then I'm just going to use the function 0rocoi have my response vector,

446
00:50:05,330 --> 00:50:09,800
which is Alzheimer's, my predictor, which in this case is the, it's called vector.

447
00:50:10,280 --> 00:50:13,760
And then that's it. That's, that's everything we need.

448
00:50:14,240 --> 00:50:17,760
And then to predict what you'll see is the function that.

449
00:50:22,760 --> 00:50:26,060
I know it's a lot. Any questions so far?

450
00:50:30,670 --> 00:50:33,790
All right. So unfortunately.

451
00:50:34,790 --> 00:50:41,750
We don't have more time. There is only something else that we need to review for this class.

452
00:50:45,130 --> 00:50:50,250
It's off of a lot of things, but it's mostly for.

453
00:50:54,290 --> 00:51:02,300
Mostly for the second part of the homework, which is Chi Square test standard, the trend test, so on and so forth.

454
00:51:03,680 --> 00:51:09,980
All the code you need, it's already on the. It's already uploaded in the lab files.

455
00:51:10,700 --> 00:51:15,889
But if you need help, just please email me. These are first lap.

456
00:51:15,890 --> 00:51:23,570
It's a little bit longer than all the other labs. Just because we needed to, you know, like first ten, 15 minutes of the class was introduction.

457
00:51:23,570 --> 00:51:26,210
And this is the lab. That's what I what we are going to do.

458
00:51:26,870 --> 00:51:31,250
But next time, we're just going to get right into the homework and hopefully we'll finish on time.

459
00:51:32,570 --> 00:51:37,960
I'd love to. Remember, I have office hours right now.

460
00:51:38,580 --> 00:51:44,320
They are on Zoom, so I need to go to my office. I'm going to me to zoom by.

461
00:51:44,460 --> 00:51:48,230
And again, if you just have questions, email me on.

462
00:51:48,630 --> 00:51:51,660
And again, all the code that you need for the home.

463
00:51:51,660 --> 00:51:54,450
What should be on the lot? Slides. Okay.

