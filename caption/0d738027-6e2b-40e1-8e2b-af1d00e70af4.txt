1
00:00:05,330 --> 00:00:08,719
Okay. Perfect. Um, so I'm Abram Wagner.

2
00:00:08,720 --> 00:00:16,129
I'm a research assistant professor in the department. As I'm sure Dr. Anne mentioned, she's at a conference this week.

3
00:00:16,130 --> 00:00:23,180
So I'm happy to come in and talk to you today about interventions or experiments or randomized controlled trials.

4
00:00:23,930 --> 00:00:29,930
There are a lot of slides today, so I'm just going to try to get through them as as quickly as possible,

5
00:00:29,930 --> 00:00:33,620
while also providing as much information that I think you need to know about this topic.

6
00:00:34,400 --> 00:00:41,220
And can everyone hear me okay? All right. So a lot to get to.

7
00:00:41,250 --> 00:00:44,940
We're going to be talking about the design of our cities.

8
00:00:44,940 --> 00:00:52,410
You know, what do we mean by randomization and allocation, blinding analysis, monitoring, study design, reporting, ethics?

9
00:00:52,500 --> 00:01:01,110
Again, a lot of stuff here, but I think we all have an idea of what randomized controlled trials are from many of our previous epidemiology courses.

10
00:01:01,950 --> 00:01:06,719
These typically have been thought of as like a gold standard for evaluating effectiveness or

11
00:01:06,720 --> 00:01:13,080
efficacy and the amount of side effects which might come up from new interventions and treatments.

12
00:01:13,740 --> 00:01:18,629
And of course, you can do a randomized controlled trial for some sort of drug or some sort of therapeutic,

13
00:01:18,630 --> 00:01:22,740
but you can also do it for some sort of educational or behavioral intervention.

14
00:01:23,010 --> 00:01:27,660
And the whole idea behind randomized controlled trials is that you're controlling the randomization.

15
00:01:27,990 --> 00:01:34,860
So there is you know, we're randomly assigning people across the different exposure groups.

16
00:01:36,990 --> 00:01:44,520
So we have this slide here and throughout this lecture there's going to be some diagrams which kind of use a similar schematic.

17
00:01:44,520 --> 00:01:48,390
So I want to make sure that we understand what's what's going on here.

18
00:01:49,350 --> 00:01:54,590
So it's perfect.

19
00:01:54,990 --> 00:02:02,250
Okay. So we have like our entire population, like the entire population of the world is encompassed within these dotted lines.

20
00:02:02,790 --> 00:02:08,850
And then we are trying to get a sample of individuals and that's represented by this square.

21
00:02:09,900 --> 00:02:14,729
And of course, in reality, you know, like our sample is a much smaller proportion of the total population.

22
00:02:14,730 --> 00:02:18,660
But, you know, for simplicity's sake, it looks like this is, you know, relatively large.

23
00:02:19,810 --> 00:02:25,920
So the whole idea behind a randomized controlled trial is there is points of randomization.

24
00:02:26,220 --> 00:02:32,700
And then we put people into different groups so we could think of putting them into like a treatment group versus a placebo.

25
00:02:33,090 --> 00:02:39,120
There could be different levels of exposures for different types of drugs.

26
00:02:39,690 --> 00:02:46,589
And then over time we measure how much disease do they have versus not this and I

27
00:02:46,590 --> 00:02:50,520
guess an implication of this is that at baseline no one should be having disease.

28
00:02:54,670 --> 00:02:57,880
Okay. So let's talk about this randomization component.

29
00:02:58,540 --> 00:03:06,400
And by randomization, we mean that every study participant has an equal probability of being selected into each study arm.

30
00:03:07,120 --> 00:03:11,620
So generally the classic is that we have a placebo versus a new drug.

31
00:03:11,980 --> 00:03:14,320
So then there would be like a 5050 split there.

32
00:03:16,510 --> 00:03:21,790
And the whole idea behind randomization is that we want to make the control in the treatment groups as similar as possible.

33
00:03:21,800 --> 00:03:28,990
So like all of those confounders or those those extraneous variables that in observational studies we need to really be paying attention to.

34
00:03:29,230 --> 00:03:33,340
Through randomization, we can kind of control all of that.

35
00:03:36,370 --> 00:03:41,170
So we could also try to decrease the selection bias.

36
00:03:42,760 --> 00:03:48,120
And I think this last point removed the investigator from the allocation of purchase.

37
00:03:48,320 --> 00:03:55,510
So, you know, if there's just like some observational study, it could be that like a doctor trying a new treatment,

38
00:03:55,520 --> 00:04:02,169
maybe they are going to tend to making some people get the treatment and have some people get the placebo.

39
00:04:02,170 --> 00:04:07,390
Maybe they're not even consciously thinking about this, but we can remove that investigator bias through the randomization scheme.

40
00:04:09,260 --> 00:04:16,220
So exchange ability basically has to do with what are the distribution of third variables like these confounders.

41
00:04:16,230 --> 00:04:23,810
So if we had some sort of observational study, what are the confounders that we'd want to control for in a randomized controlled trial?

42
00:04:23,990 --> 00:04:28,040
There should be this idea of exchange ability in the sense that there should be an even distribution

43
00:04:28,250 --> 00:04:34,129
of these confounders across the different exposure groups and I guess exchange ability.

44
00:04:34,130 --> 00:04:43,550
The idea behind this word exchange ability means that. So in reality we have like your treatment group, we followed them over time.

45
00:04:43,550 --> 00:04:47,270
We see do they get the disease or not? And then we have the placebo group.

46
00:04:47,270 --> 00:04:49,310
We followed them over time, see if they get the disease or not.

47
00:04:49,640 --> 00:04:55,610
Exchange ability means that what if we like went back in time and we flipped to those groups so that the

48
00:04:55,880 --> 00:05:03,260
people who were in the treatment group now are placebo treatment that's in effect like their outcomes.

49
00:05:03,260 --> 00:05:08,930
So regardless of if you are in the treatment group or in the placebo group,

50
00:05:09,860 --> 00:05:14,480
if you were to be flipped, you're your risk of getting the disease should be the same.

51
00:05:15,410 --> 00:05:20,710
Does that make sense? Okay.

52
00:05:20,780 --> 00:05:22,520
I think that's the same thing here.

53
00:05:24,770 --> 00:05:33,440
So there could potentially be some bias and some residual confounding in randomized controlled trials that, you know, they're there.

54
00:05:33,440 --> 00:05:41,599
Nothing is completely perfect, though, we think, especially if there's like a relatively small study,

55
00:05:41,600 --> 00:05:48,229
maybe there is some residual confounding or we'll be talking, I believe, about that more in some future classes.

56
00:05:48,230 --> 00:05:51,650
But throughout this class, we'll talk a bit more about this as well.

57
00:05:55,080 --> 00:05:57,600
Okay. So how do we randomize people?

58
00:05:57,600 --> 00:06:06,330
And this is actually a bit more difficult than you might think because I think, you know, in in my hand and my head.

59
00:06:06,600 --> 00:06:10,139
How would you randomize people? I think like, oh, I just go to like Excel.

60
00:06:10,140 --> 00:06:12,700
You know, I create like a random number on it,

61
00:06:12,720 --> 00:06:18,900
flips between zero and one that I know if somebody is an exposure group and somebody is in like a treatment or in a placebo,

62
00:06:20,130 --> 00:06:23,220
it's not necessarily maybe you can do some things like that,

63
00:06:23,220 --> 00:06:32,190
but it's not necessarily as simple as that because all of the algorithms in like Excel or in SAS are and are behind random numbers.

64
00:06:32,370 --> 00:06:36,750
There's like a computer program which says what your random number should be.

65
00:06:37,440 --> 00:06:41,909
So you might notice that in a lot of times when you use your statistical program,

66
00:06:41,910 --> 00:06:45,330
if there is some sort of random number generator, you'll mention like a seed.

67
00:06:45,630 --> 00:06:54,720
And that just has to do with like the computer program understanding what is the order of the different supposedly randomized numbers that there are.

68
00:06:55,590 --> 00:07:03,659
So, you know, I don't necessarily trust the algorithms to come up with random numbers because it's the software programmers who are kind of basically

69
00:07:03,660 --> 00:07:13,020
directing the programs which say what their randomization scheme should be and even things like flipping rolling dice or flipping a coin.

70
00:07:13,650 --> 00:07:25,229
Theoretically, if we know all of the variables, like how hard and what angle, where you flipping the coin and what is the atmosphere,

71
00:07:25,230 --> 00:07:30,690
pressure and all these things you should be able to predict, like with very high accuracy what the coin flip actually will be.

72
00:07:32,250 --> 00:07:39,330
So there's you know, this is just me to say that it's not necessarily easy to actually come up with real random numbers in the world.

73
00:07:43,100 --> 00:07:51,950
One thing that might happen when you do a completely random assignment is that, say,

74
00:07:51,950 --> 00:07:58,040
you have a study of a thousand people, so you want 500 in the placebo or 500 in the treatment group.

75
00:07:59,330 --> 00:08:05,899
If you just do like a randomization at a single point for each individual,

76
00:08:05,900 --> 00:08:12,740
you could end up with like 600 people in the placebo group and 400 in the treatment group.

77
00:08:13,910 --> 00:08:18,890
So and that's just, you know, how random numbers work. It's not going to be exactly 50% of the time.

78
00:08:19,850 --> 00:08:24,830
So one thing you can do to try to even out the number of participants is to use block randomization.

79
00:08:25,100 --> 00:08:34,610
And the whole idea behind block randomization is that, first off, you create sequences of of randomization schemes.

80
00:08:34,700 --> 00:08:42,769
So if you had like three different groups, you had like a placebo and two study arms A, B and C, you know, you could have like ABC,

81
00:08:42,770 --> 00:08:51,740
ACB, CBC, ACB, CBA, if you just have to probably you'd want to go on a block of like four or six or eight.

82
00:08:52,160 --> 00:08:56,540
So basically something that can just be divisible by the number of study arms that you have.

83
00:08:57,470 --> 00:09:06,100
But basically the whole idea behind block randomization is that instead of randomizing the individual, you randomize a block.

84
00:09:06,110 --> 00:09:14,060
So say you have like three people coming into clinic to be part of this randomized controlled trial.

85
00:09:14,780 --> 00:09:27,230
You will just, you know, randomize and you'll have like some random random number generator which decides which one of these six choices they are.

86
00:09:27,500 --> 00:09:32,060
So for this group of three people, it's BC and maybe the next three people come in.

87
00:09:32,750 --> 00:09:36,910
You randomly choose which one of these it would be in, it'd b ACB though.

88
00:09:36,960 --> 00:09:45,110
So the whole idea behind block randomization is at the end you should have like an even number of people within each study arm.

89
00:09:50,510 --> 00:09:54,110
That. So BLOCK Romanization is different than stratified randomization.

90
00:09:54,800 --> 00:10:00,590
Stratified randomization is for us to think about some different characteristics,

91
00:10:00,590 --> 00:10:10,640
maybe some sociodemographic characteristics which might be strongly related to or somewhat related to the risk of getting disease in the population.

92
00:10:10,940 --> 00:10:14,600
And then we might want to stratify individuals based on that.

93
00:10:15,890 --> 00:10:21,110
And one thing, whenever you hear the word stratification, stratification enhances power.

94
00:10:21,110 --> 00:10:29,089
So stratification can, in the end, you know, make you have more precise confidence intervals and potentially lower p values.

95
00:10:29,090 --> 00:10:35,240
So people like this idea of stratification. So this is an example of what we mean by stratified randomization.

96
00:10:35,570 --> 00:10:40,750
Maybe we have prespecified that we want 1000 participants in our study.

97
00:10:40,760 --> 00:10:47,450
That's our sample size calculator. And maybe we want to, for whatever reason, oversample males.

98
00:10:47,780 --> 00:10:53,929
So we have an idea that we'll want 600 males and for females and then we'll also stratify based on age.

99
00:10:53,930 --> 00:11:02,420
Maybe there's some, you know, I mean, age is kind of related to many health outcomes, so we could stratify in age as well.

100
00:11:02,720 --> 00:11:09,799
Again, what we want to stratify our thing on are things that would be related to the health outcomes.

101
00:11:09,800 --> 00:11:13,790
So, you know, generally age is related to any health outcome in sex might be as well.

102
00:11:13,790 --> 00:11:20,870
So again, the idea behind here is that for each of these like four different categories for age and sex,

103
00:11:21,200 --> 00:11:29,050
you will have a similar number of individuals who have the placebo versus the gender.

104
00:11:33,760 --> 00:11:41,770
Weighted randomization is potentially when you don't necessarily want a 5050 split.

105
00:11:42,670 --> 00:11:52,000
So maybe you want to have more people in the intervention, especially if you're really concerned about certain side effects.

106
00:11:55,510 --> 00:12:03,730
So I guess weighted meaning like we're, we're updating the number of people who are in the, uh, the treatment arms.

107
00:12:06,500 --> 00:12:14,989
We could also think of adaptive randomization. Adaptive randomization is sort of giving power to maybe kind of like a statistical

108
00:12:14,990 --> 00:12:21,320
program to decide what people should be in the placebo versus the treatment group.

109
00:12:21,650 --> 00:12:29,680
And the idea behind this is like maybe the first person who comes into your study is female with adaptive randomization.

110
00:12:29,690 --> 00:12:39,230
Then maybe if the next person comes in is female, maybe there's like a lower chance for them to get the same assignment as the first person.

111
00:12:41,090 --> 00:12:48,410
So again, the first assignment is truly random, but then after that, there is, you know, statistical programs to draw your feet in.

112
00:12:48,650 --> 00:12:52,790
What is the demographic background of the person who's standing before you?

113
00:12:53,030 --> 00:13:02,360
And then the computer will spit out which if they should be in the placebo or the treatment based on sort of the past people who've been enrolled.

114
00:13:02,720 --> 00:13:08,450
Again, trying to evenly distribute those three variables across the different study areas.

115
00:13:11,210 --> 00:13:18,470
Pseudo randomization or quasi randomization means that you actually have broken the randomization and you can do that in different ways.

116
00:13:19,430 --> 00:13:23,899
So one, you could use nonrandom methods to assign participants.

117
00:13:23,900 --> 00:13:32,480
So maybe you think like, oh, let's just make it so people who are in an even yea are in the placebo group in an odd year of the treatment group.

118
00:13:32,870 --> 00:13:37,460
It could be though the birth year is highly related to a variety of things.

119
00:13:37,710 --> 00:13:40,700
You know, if we're thinking of COVID 19, you know,

120
00:13:40,700 --> 00:13:46,580
the type of people who were born in 2019 might be very different from those who are born in like 2020,

121
00:13:48,290 --> 00:13:54,769
which is all to say that birth year is not entirely random day of week, that they're at the clinic,

122
00:13:54,770 --> 00:13:58,720
you know, saying, oh, on Friday I'm going to put people in the placebo group Monday.

123
00:13:58,790 --> 00:14:04,489
And if the people in the treatment group in reality, like what days of the week you go to a clinic, could be very different.

124
00:14:04,490 --> 00:14:04,700
You know,

125
00:14:04,700 --> 00:14:13,670
are you showing up Friday afternoon at 4:50 p.m. or are you like Monday morning at 8 a.m. like those could be entirely different kinds of people.

126
00:14:17,070 --> 00:14:21,149
And so this is all to say that, you know, like maybe you'll end up with like a well-balanced group,

127
00:14:21,150 --> 00:14:26,580
but like there could be other selection bias things which we don't even know about which are operating around in the background.

128
00:14:30,200 --> 00:14:39,110
So what can be randomized? Typically, we think of individuals being randomized like an individual human being is the one who comes into

129
00:14:39,250 --> 00:14:44,750
a clinic and they're the ones who are randomized to get the treatment or to get the placebo.

130
00:14:45,740 --> 00:14:48,980
But you could randomized groups, you could randomize families,

131
00:14:50,000 --> 00:14:57,260
groups you might think of like certain hospitals or certain clinics being given one like everyone,

132
00:14:57,260 --> 00:15:04,310
they're being given a placebo and then another clinic, everyone be given a treatment that is called a cluster randomization.

133
00:15:06,680 --> 00:15:18,920
So let's talk now about allocation. And the whole idea behind allocation is to limit the amount of selection, bias and confounding.

134
00:15:20,390 --> 00:15:28,820
So, you know, the idea here is that it kind of depends on like how you're doing your randomized controlled trial.

135
00:15:28,820 --> 00:15:34,700
And, you know, is this more of like a behavioral intervention or more of like some sort of drug or therapeutic?

136
00:15:35,810 --> 00:15:38,270
But especially if you're getting to much more clinical things,

137
00:15:39,470 --> 00:15:45,680
what you would have is you'd have some sort of envelope which would have information about the allocation.

138
00:15:45,690 --> 00:15:49,460
So this envelope would ideally be as tamper proof as possible.

139
00:15:50,420 --> 00:15:58,190
You know, it's like a fun thing in, uh, TV shows to talk about how people mess up with the allocation.

140
00:15:59,470 --> 00:16:04,850
Um, but yeah, so the idea behind the allocation is that like the,

141
00:16:04,850 --> 00:16:15,710
the person doing the treatment will not know whether the person is part of the treatment or part of the placebo until like the very last moment.

142
00:16:16,760 --> 00:16:19,069
Um, Gray's Anatomy reference.

143
00:16:19,070 --> 00:16:26,270
If everyone actually watched that episode, they were doing a clinical trial for the Alzheimer's and she went through and switched,

144
00:16:26,420 --> 00:16:34,280
I think so that she or her mom could get to the treatment instead of the placebo, which wasn't a nightmare watching it.

145
00:16:37,130 --> 00:16:43,520
Yeah, I, um, I think it's. I haven't watched Gray's Anatomy in a few years, but I think I did watch that episode and, you know, of course,

146
00:16:43,520 --> 00:16:51,169
like the whole thing, then it's like the randomization is broken and, you know, that study would be like treat it as a failure.

147
00:16:51,170 --> 00:16:55,969
And that's probably like millions of dollars then from the NIH down the hall.

148
00:16:55,970 --> 00:16:59,390
So, you know, not a great thing. There'd be like huge misconduct.

149
00:17:01,040 --> 00:17:05,120
I don't know, like if she kept her temperature.

150
00:17:06,580 --> 00:17:11,570
Um, I think so. Blinding. Blinding has to do with measurement bias.

151
00:17:11,600 --> 00:17:19,940
So allocation is all about selection bias. Um, blinding is all about measurement bias.

152
00:17:21,140 --> 00:17:25,610
So what do we mean by blinding? We can blind, like, a number of different people.

153
00:17:25,610 --> 00:17:31,280
We can blind the individual, um, you know, so they might not know if they're in the placebo or the treatment group.

154
00:17:31,580 --> 00:17:40,690
We could blind the investigator or like the clinician so that they don't know if their patient is in the, um, what group they're in.

155
00:17:40,700 --> 00:17:47,970
And we can also blind the statistician who might not know what the groups are and instead just has a variable in their data set of like zero and one.

156
00:17:47,990 --> 00:17:52,850
We don't know which one is which. So single blind.

157
00:17:52,850 --> 00:17:58,070
It just means that one of those groups of individuals doesn't know often it's the participant.

158
00:17:58,460 --> 00:18:06,320
Um, I don't know of any situation why it would be another group, but I suppose for single blind it it just means there's a single group.

159
00:18:07,070 --> 00:18:15,770
Double blinded is typically the, um, the participant and either the analyst or the, the clinician.

160
00:18:16,010 --> 00:18:19,090
And then triple blinded would be that like all three of those don't. Yeah.

161
00:18:23,950 --> 00:18:28,090
And you know, this is possible sometimes, you know, if you're just having like an injection of a drug,

162
00:18:28,450 --> 00:18:35,829
whether it is like the actual placebo or not, I think that can be somewhat easily able to be blinded,

163
00:18:35,830 --> 00:18:38,620
although sometimes it's not, you know, sometimes, you know,

164
00:18:38,620 --> 00:18:44,890
like getting the actual treatment might be a bit more painful than just getting like a saline solution.

165
00:18:46,000 --> 00:18:51,010
Certainly if you're doing any sort of behavioral intervention, it's pretty obvious which group you're going to be in.

166
00:18:51,850 --> 00:18:55,960
Maybe you could blind the analyst to that, but like you can't really blind the participant.

167
00:18:59,610 --> 00:19:07,560
So moving on to analysis, we're going to be talking about like a bill actually before I go on to that, any any questions up to this point?

168
00:19:07,570 --> 00:19:13,560
I know I was going through these slides, but there's a lot of them. Okay.

169
00:19:13,680 --> 00:19:19,110
So when we're thinking about the analysis of a randomized controlled trial, obviously we have our health outcomes.

170
00:19:19,110 --> 00:19:25,200
So we want to talk here today about like what is a clinical versus a surrogate outcome, what are some issues,

171
00:19:25,440 --> 00:19:32,400
statistics, uh, what are the numbers of outcome variables and how also do we deal with adverse events?

172
00:19:33,870 --> 00:19:45,689
So surrogate outcomes, this is like, you know, in plus and maybe some more of some, some simpler clinical trials or if we're thinking of,

173
00:19:45,690 --> 00:19:49,080
you know, I don't think these three clinical trials would necessarily use a surrogate outcome,

174
00:19:49,470 --> 00:19:59,070
but the idea behind a surrogate outcome is that there might be some sort of biological or clinical characteristic which isn't,

175
00:19:59,070 --> 00:20:03,030
you know, our health outcome of interest, but it's highly related to that health outcome of interest.

176
00:20:03,540 --> 00:20:14,490
So I think about this a lot in terms of vaccines, because for vaccines, if we're doing like a phase three clinical trial of like a rotavirus vaccine,

177
00:20:14,820 --> 00:20:19,530
of course we'd want our outcome to be, did this kid get rotavirus or not?

178
00:20:20,100 --> 00:20:27,780
But a surrogate outcome might be after getting vaccinated, was there an immune response?

179
00:20:27,780 --> 00:20:31,950
Like what are the antibodies like in that kid?

180
00:20:32,250 --> 00:20:40,980
And theoretically there would be some direct relationship between if you have higher antibody titers, you're much less likely to get rotavirus.

181
00:20:41,880 --> 00:20:49,020
So for the vaccination for infectious disease case, we might call a surrogate outcome also a correlate of protection.

182
00:20:50,100 --> 00:20:57,450
And again, you might think of like an antibody titer or some sort of immunogenicity outcome as a surrogate.

183
00:20:58,410 --> 00:21:04,620
And again, that's different than like did you actually get this case of disease, other things.

184
00:21:05,100 --> 00:21:11,790
If you're looking to do a clinical trial of the risk of fracture, maybe your surrogate would be low bone density.

185
00:21:12,210 --> 00:21:18,580
And again, the idea is that you have more statistical power to look at these surrogate outcomes than to look at these other outcome.

186
00:21:18,600 --> 00:21:24,690
So there it'll be easier looking at bone density or antibody titers than it will be to

187
00:21:25,620 --> 00:21:32,310
count how many people have had a fracture or who have ended up with a case of disease.

188
00:21:36,810 --> 00:21:43,230
So there there are some things that you need to be aware of, like a surrogate is not the same thing as a clinical outcome.

189
00:21:43,560 --> 00:21:48,900
And there's a number of studies which have cautioned our use of this.

190
00:21:49,440 --> 00:22:02,700
So, you know, we might think, for instance, that like having some sort of arrhythmia is strongly related to myocardial infarction.

191
00:22:02,700 --> 00:22:10,560
So having a heart attack. So you might use this arrhythmia as a surrogate of or as a as a know a circuit.

192
00:22:12,150 --> 00:22:18,870
But so, you know, there were these studies done which found that certain drugs suppress arrhythmia,

193
00:22:18,870 --> 00:22:21,780
so that if you get these drugs, you have a lower risk of arrhythmia.

194
00:22:22,890 --> 00:22:30,570
But subsequent trials, subsequent like for phase three clinical trials have found that those same drugs,

195
00:22:30,570 --> 00:22:36,630
although they repress arrhythmias, they increase the rates of myocardial infarction.

196
00:22:37,230 --> 00:22:43,530
And, you know, it's probably just one of those weird biological pathways where generally we think arrhythmias are related to myocardial infarction.

197
00:22:43,530 --> 00:22:48,510
But like maybe with this one drug, there's like different interesting things which are happening biologically.

198
00:22:52,260 --> 00:22:57,340
Okay. So in analysis, we need to think of three different ways.

199
00:22:57,360 --> 00:23:00,420
I think the big two are like content to treat and per protocol,

200
00:23:00,930 --> 00:23:08,940
but there's as treated also and these are like the three different ways that we can analyze randomized controlled trials.

201
00:23:11,130 --> 00:23:17,760
So intent to treat is basically us saying that we randomized people into getting the

202
00:23:17,760 --> 00:23:25,440
placebo or the treatment and that randomization point is what we are analyzing.

203
00:23:26,640 --> 00:23:33,420
So we don't actually in in an attempt to treat analysis, we don't actually care if they ended up getting the treatment or not.

204
00:23:34,650 --> 00:23:42,630
You know, maybe this is a drug which they're supposed to come every week to the clinic to get, but in an intent to treat analysis.

205
00:23:42,990 --> 00:23:46,740
That's not we don't measure whether they came every week to the clinic to get it.

206
00:23:47,010 --> 00:23:53,250
We don't measure if the placebo people ended up getting the drug or not or vice versa.

207
00:23:54,090 --> 00:23:55,950
All we care about is that like single point.

208
00:23:56,190 --> 00:24:05,100
And the whole point of that is that single point is the part of a randomized controlled trial where we remove any amount of confounding over.

209
00:24:05,430 --> 00:24:09,930
We're ideally removing the confounding. And so that's where we have exchange ability.

210
00:24:11,280 --> 00:24:14,400
And so like statistically this is very nice.

211
00:24:14,410 --> 00:24:21,180
You might not like in a real world setting, it might not be that useful, especially if there's a lot of drop off.

212
00:24:21,180 --> 00:24:27,780
But statistically and from like a perspective of removing confounding, this is great.

213
00:24:28,770 --> 00:24:39,120
And I would say like, you know, in a lot of like submissions to the FDA and regulatory bodies, this is a lot of what they're interested in.

214
00:24:41,460 --> 00:24:49,590
So in a per protocol approach, you look to see who are the people who actually followed the treatment and did not,

215
00:24:49,590 --> 00:24:59,969
or among a placebo group, maybe they ended up getting the treatment. And then you only analyzed those participants who followed the protocol.

216
00:24:59,970 --> 00:25:04,230
And you probably have to have some prespecified definition of what does it mean to follow the protocol?

217
00:25:05,730 --> 00:25:09,570
Could this be that they took 80% of the medications?

218
00:25:09,570 --> 00:25:16,860
Or maybe like you want them to take 100% of the medications, otherwise they're going to be considered, you know, lost.

219
00:25:18,150 --> 00:25:23,670
So, again, per protocol, we're only analyzing those people who did what they were supposed to.

220
00:25:25,430 --> 00:25:29,800
As treated is where we actually look to see what did they do.

221
00:25:29,810 --> 00:25:36,260
So maybe there's crossover. So maybe people who originally were in the placebo group ended up being in the treatment

222
00:25:36,260 --> 00:25:40,850
group and maybe some of the people in the treatment group just ended up not taking the drug,

223
00:25:41,670 --> 00:25:45,110
then they're effectively a placebo. So as treat is.

224
00:25:45,110 --> 00:25:50,579
But we actually look at their behaviors. So, you know,

225
00:25:50,580 --> 00:25:58,650
the problem with student approaches like we're really getting away from the randomization point and at this level you're probably more of

226
00:25:58,680 --> 00:26:08,370
like an observational study you definitely want to control for confounders and think about like what biases might be present in your sample.

227
00:26:13,330 --> 00:26:18,850
Yeah. So I would say for both as freedom per protocol there we lose the benefits of

228
00:26:18,850 --> 00:26:22,510
randomization and there could be confounding there could be selection bias.

229
00:26:26,040 --> 00:26:42,660
Um, but, you know, I, I will say that I do think the per protocol effect probably more reasonably represents what's happening in a real world setting.

230
00:26:43,190 --> 00:26:50,280
Um, and, you know, as part of this class, you're talking a bit about causal inference methods and things like that.

231
00:26:50,280 --> 00:26:58,910
And one of the big things is that causal inference methods are those which are based off of per protocol approaches.

232
00:26:58,920 --> 00:27:04,920
So like if you have, like, if you let's back up for a moment like a, a per protocol approach,

233
00:27:04,920 --> 00:27:08,270
probably more replicates what's gone on during an observational study.

234
00:27:08,280 --> 00:27:17,429
So if you have one study which is looking at a randomized controlled trial of, let's say, influenza vaccine, so we're getting half people in funds.

235
00:27:17,430 --> 00:27:21,659
The vaccines have people with placebo. We do an intent to treat analysis.

236
00:27:21,660 --> 00:27:28,770
And then we could also do a per protocol analysis if we did in a separate, entirely different observational study.

237
00:27:29,190 --> 00:27:37,980
Um, probably that observational study will be more in line with the per protocol approach.

238
00:27:40,230 --> 00:27:46,350
And similarly, if, you know, we have our observational study, maybe we're going to be using all these fancy causal inference methods.

239
00:27:46,830 --> 00:27:51,209
Those causal inference methods will be very similar to the per protocol approach and probably less

240
00:27:51,210 --> 00:27:55,260
similar to the intent to treat approach in terms of like the magnitude of effect that we're seeing.

241
00:27:58,160 --> 00:28:05,840
And oftentimes we will see that the treatment effect is larger in a per protocol approach than in an intent to treat approach.

242
00:28:08,620 --> 00:28:19,390
And so this is an example. So people, patients with atrial fibrillation either got a catheter ablation or were given sort of standard treatment.

243
00:28:20,260 --> 00:28:25,180
And so, you know, there was a number of different health outcomes that were that people were interested in.

244
00:28:27,310 --> 00:28:32,120
So, you know, we randomize people there is about 2200 individuals who were randomized.

245
00:28:32,140 --> 00:28:39,130
1100 were in the ablation for the treatment group. 1100 were in the standard group.

246
00:28:39,970 --> 00:28:48,940
Of those 1100 who got the ablation group, you know, almost 10% didn't end up receiving the procedure.

247
00:28:49,720 --> 00:28:52,780
Any other could ideally in a randomized controlled trial,

248
00:28:52,780 --> 00:28:57,130
you'll have like your or your research coordinators go out and try to figure out what are the reasons for this.

249
00:28:57,460 --> 00:29:00,520
You know, maybe people got scared and didn't want to do ablation.

250
00:29:01,180 --> 00:29:05,560
Maybe they moved away. You know, there's there's all sorts of there's all sorts of reasons for this.

251
00:29:06,190 --> 00:29:14,170
For the people who are randomized to get drug therapy, you know, almost a third also underwent ablation.

252
00:29:14,500 --> 00:29:20,020
You know, I think we live in a world where you can't just, like, tell a patient that they can't get a certain drug treatment.

253
00:29:20,020 --> 00:29:25,450
So maybe this person was part of a clinical trial, but then got seen by another doctor.

254
00:29:25,450 --> 00:29:28,270
And that other doctor is like, oh, you should get the ablation.

255
00:29:31,200 --> 00:29:38,520
So we see how, you know, there's could be huge differences than if we're doing the intent to treat approach versus other approaches.

256
00:29:38,730 --> 00:29:46,170
And one of the things that you might then see is like why the intent to treat approach is probably like not as strong of

257
00:29:46,170 --> 00:29:52,290
association as the peer protocol approach is that the intent to treat approach will just mix a lot of people together.

258
00:29:52,290 --> 00:29:58,109
So the intent to treat approach, there's going to be a lot of people in the treatment group like in the ablation group who didn't get it.

259
00:29:58,110 --> 00:30:03,150
And there's going to be people in the placebo group who actually ended up getting the treatment and they're getting the ablation.

260
00:30:03,330 --> 00:30:09,720
And because there's that mixing, then like you're like the actual effect that you see from the treatment is just going to be so much lower.

261
00:30:11,840 --> 00:30:14,630
But you don't have confounding. And that's that's that's the nice thing.

262
00:30:17,100 --> 00:30:25,050
Um, and then, you know, I think this study goes on to talk about like what the per protocol analysis is like.

263
00:30:25,440 --> 00:30:38,610
Um, and they also did an treated analysis, um, in the, in their st analysis, I think they were trying to also consider,

264
00:30:38,610 --> 00:30:41,810
you know, different confounders and time, varying covariates and things like that.

265
00:30:43,740 --> 00:30:46,469
And so that, that is something to say.

266
00:30:46,470 --> 00:30:52,590
Like when you start deviating from the intent to treat approach, then you do you want to start considering things like confounding.

267
00:30:53,460 --> 00:31:00,210
So you might want to consider certain baseline characteristics as covariates in your model to reduce the amounts of confounding.

268
00:31:02,810 --> 00:31:14,600
And this is just you know, what they what they found is that the intent to treat was at 0.86 per protocol, .74 as treated .67.

269
00:31:15,020 --> 00:31:23,870
And you know, I think the jaded scientist in me thinks that they were just like running all these analyzes until they got a result,

270
00:31:23,870 --> 00:31:30,779
which was significant. But and, you know, like this was there was 2200 people this was like a huge study.

271
00:31:30,780 --> 00:31:40,189
It was probably really expensive. But I am glad that this one paper kind of shows all of these results together so that, you know,

272
00:31:40,190 --> 00:31:46,430
we as as the discerning audience can kind of think through what how we would interpret this.

273
00:31:48,800 --> 00:31:54,260
Amy I mean, like my, my first thought on thinking about this trial is just really to think about like why are people,

274
00:31:54,560 --> 00:31:58,820
why is there such a substantial movement of people across the placebo and the treatment groups?

275
00:32:01,040 --> 00:32:08,509
And, you know, it could be that at some point in time, maybe there's not maybe there's not clinical equipoise any more, maybe there's not.

276
00:32:08,510 --> 00:32:13,880
And even if so, maybe ethically, like, it's not worth, you know, dividing people up anymore.

277
00:32:17,210 --> 00:32:21,140
Okay. You can do subgroup analysis. I would super conscious.

278
00:32:21,950 --> 00:32:29,990
I would super caution you from doing this and I would only do subgroup analysis if that's part of the original protocol.

279
00:32:31,010 --> 00:32:41,780
And so this is where so the idea behind a subgroup analysis is like we have, you know, our ablation group versus our standard of care group.

280
00:32:41,930 --> 00:32:43,460
What is their risk of disease?

281
00:32:43,700 --> 00:32:49,129
Now let's do it by age, unless you by gender and let's do it by age and gender and let's do it by like age, gender and race.

282
00:32:49,130 --> 00:33:00,560
And, you know, you could go on and on and on with like a number of different things, which is all to say that I think this is really ripe for hacking,

283
00:33:01,430 --> 00:33:09,709
for, you know, finding the one subgroup that has like a really significant result and kind of amplifying your findings based on that.

284
00:33:09,710 --> 00:33:15,770
Whereas, you know, if you're doing ten, 20, 30 different subgroups, you know, it's highly likely that you'll get spurious results.

285
00:33:19,510 --> 00:33:25,690
Again. So subgroup analysis just pre-specified this in your protocol and then, you know, people won't be able to.

286
00:33:28,040 --> 00:33:34,700
Complain that you were potentially hacking. And this is just an example of something that you might see in a paper.

287
00:33:35,330 --> 00:33:43,700
This is looking at whether alendronate can reduce the risk of clinical or political fractures.

288
00:33:44,750 --> 00:33:52,550
And what they decided to do was to stratify based on bone density.

289
00:33:53,270 --> 00:34:00,530
So preexisting bone density. And, you know, as long as that something that was in the original protocol, I think they're in the clear.

290
00:34:00,540 --> 00:34:06,020
But if this is something where, you know, oh, they tried to do an analysis, they didn't find a significant result.

291
00:34:06,590 --> 00:34:13,100
So there we go. What other variables do we have in our data set? So let's divide people based on their bone marrow density.

292
00:34:13,850 --> 00:34:24,230
I would say that would be problematic. Oh, monitoring what we mean by monitoring.

293
00:34:24,260 --> 00:34:29,840
There is like a lot of different things that you want to do in clinical trials, and this is why there is huge study staff associated with them.

294
00:34:30,350 --> 00:34:32,360
There's, of course, people involved with recruitment,

295
00:34:32,810 --> 00:34:39,290
thinking about people who are looking at measuring what the adherence to the treatment versus the placebo regimen is.

296
00:34:40,040 --> 00:34:43,220
You want people involved with the randomization, with the blinding scheme.

297
00:34:43,490 --> 00:34:49,370
You need people to be following up with individuals and then, of course, measuring those important variables, the outcomes,

298
00:34:49,370 --> 00:34:57,380
the adverse events, other potential confounders, especially if you're thinking of doing some sort of protocol or street analysis.

299
00:35:01,290 --> 00:35:11,639
So interim monitoring. So this is something which I am going to try to caution you about, whether you should or should not be doing so.

300
00:35:11,640 --> 00:35:17,340
The whole idea here is that, you know, throughout the trial, we're, of course, collecting information about,

301
00:35:17,700 --> 00:35:21,600
you know, people's health status, including whether they've had certain adverse events.

302
00:35:22,560 --> 00:35:25,960
And maybe we find out the intervention is more effective than we thought.

303
00:35:25,980 --> 00:35:30,090
Maybe we find out the intervention is less effective than we thought.

304
00:35:31,560 --> 00:35:39,280
But the important thing to note is that, like when we develop our clinical trials, there is, um,

305
00:35:41,040 --> 00:35:48,029
there is a sample size calculation which we do ahead of time and we really can't

306
00:35:48,030 --> 00:35:52,620
see anything until we get enough people that hits that sample size calculation.

307
00:35:54,390 --> 00:36:07,200
And maybe I'll give you like an example on the board about this is say we have I got to tell you, I can see if I like right down here.

308
00:36:07,290 --> 00:36:21,729
Okay. So this is time. And maybe we are looking at what let's raise the stakes.

309
00:36:21,730 --> 00:36:26,980
Maybe we are, you know, ten years ago. We are trying to develop an Ebola vaccine.

310
00:36:27,760 --> 00:36:31,930
And this is in the middle of, you know, the Ebola outbreak in Africa.

311
00:36:33,490 --> 00:36:40,430
And so we have been drawing people, obviously dividing back into getting the Ebola vaccine happened to not getting it.

312
00:36:40,750 --> 00:36:44,460
And we are measuring the effectiveness.

313
00:36:44,470 --> 00:36:47,770
Maybe we're doing a surrogate, maybe we're actually looking at the outcome.

314
00:36:48,610 --> 00:36:56,380
But what we. So we can think of like the key value that we find.

315
00:36:56,390 --> 00:37:04,190
So maybe the first time points and let me just say this like 0.05.

316
00:37:05,450 --> 00:37:10,009
Um, so obviously 0.05 is what we're interested.

317
00:37:10,010 --> 00:37:17,870
We want like a P-value 0.05 to say that this, this, this vaccine is significant in its effects.

318
00:37:19,400 --> 00:37:24,050
So generally, like, you know, for the first few days, there's just going to be like a really high p value.

319
00:37:24,230 --> 00:37:27,680
And that's just because, you know, we don't have a huge sample size.

320
00:37:28,910 --> 00:37:33,470
And also, it takes time to figure out if people have had Ebola or not.

321
00:37:35,000 --> 00:37:45,620
But there will be variation in the p value. Uh, but maybe at some point in time we like reach a point where it is under 0.05.

322
00:37:46,730 --> 00:37:51,890
Do we stop the trial then because like, oh, we found that the Ebola vaccine is effective.

323
00:37:52,510 --> 00:37:55,910
Um, and presumably that would be like a great thing.

324
00:37:56,600 --> 00:38:03,560
Is it ethical to, like, keep on doing the clinical trial when there are people in the placebo group who haven't gotten the,

325
00:38:03,830 --> 00:38:07,190
um, haven't gotten the vaccine?

326
00:38:08,510 --> 00:38:14,250
My one rejoinder to that is that like, we don't know if we just stopped the trial here.

327
00:38:14,270 --> 00:38:20,440
We don't know what would happen. Like, maybe like later on,

328
00:38:20,450 --> 00:38:27,050
you would actually bump back up and it was just kind of like a local minimum that actually wasn't really reflective of the final sample size,

329
00:38:27,380 --> 00:38:37,250
but maybe it would still continue going downwards. So if we stop a clinical trial too early, we don't know what the final sample size would be like.

330
00:38:37,610 --> 00:38:42,980
And this is the final sample size, which, like all of our statistics are based off of.

331
00:38:44,960 --> 00:38:58,100
So I just caution against this idea of stopping clinical trials, because you think there might be some huge positive effects.

332
00:38:58,850 --> 00:39:02,090
Certainly, you know, there might be situations where you do you want to do that.

333
00:39:03,260 --> 00:39:07,459
But I think it'd be important to get in, you know, have a third party board involved.

334
00:39:07,460 --> 00:39:13,360
And ideally you'd have this written into your protocol ahead of time of like when you'd be stopping at a clinical trial earlier,

335
00:39:13,640 --> 00:39:17,360
you'd want to get the IRB involved and you'd want to cover your bases.

336
00:39:17,360 --> 00:39:22,790
So that doesn't look like you are just trying to, again, pack your way into a lot of people.

337
00:39:24,940 --> 00:39:32,470
Does that make sense? Of course, there could be other reasons to stop a trial.

338
00:39:33,560 --> 00:39:36,850
You know, it could be that there's a lot of adverse events happening.

339
00:39:36,880 --> 00:39:43,360
You know, if this is suspected, that is it might just not be as safe as you thought.

340
00:39:43,360 --> 00:39:52,719
That that certainly is reasonable. You might think about like modifying the trial, in which case, you know, like you'd have to think like,

341
00:39:52,720 --> 00:39:56,680
are you really going to be able to maintain your randomization scheme or are you basically starting over again?

342
00:39:58,030 --> 00:40:04,150
And of course, if you think about extending the trial or enlarging the trial sample, if you realize that you don't have sufficient power.

343
00:40:07,770 --> 00:40:16,380
Okay. Um, so this is just like, you know, an example of this cardiac rhythmic arrhythmia suppression trail cast.

344
00:40:16,800 --> 00:40:26,850
Um, and so they had planned on doing this trial for five years to study the effect of antiarrhythmic therapy.

345
00:40:27,550 --> 00:40:36,360
Um, but basically what they found is that there was higher mortality among those who had the drug than those who had the placebo.

346
00:40:36,960 --> 00:40:43,830
So I think, you know, if you're stopping a trial because there's higher mortality or because there's high side effects, I think that makes sense.

347
00:40:44,610 --> 00:40:50,250
This is another example where people had did they did their sample size calculation.

348
00:40:50,490 --> 00:40:54,299
And as part of their sample size calculation, they said that over the study period,

349
00:40:54,300 --> 00:41:01,350
we expect there will be around 733 people who will die of cardiovascular disease.

350
00:41:02,220 --> 00:41:11,310
And so they are powered to try to detect a significant difference for those who use aspirin or not based on that number.

351
00:41:12,030 --> 00:41:20,430
But in this one, I mean, they I don't know who is making the calculations ahead of time, but only 88 people had died in this time period.

352
00:41:21,120 --> 00:41:27,870
So clearly, you know, there's just never going to be enough statistical power to detect what they had originally, one suspects.

353
00:41:28,140 --> 00:41:32,850
And at this point in time, it's just not what the use of. It's not a good use of time for the study.

354
00:41:32,850 --> 00:41:37,460
Participants like the study trial just like will not generate any information.

355
00:41:37,470 --> 00:41:43,890
So what's the point in continuing you? Okay.

356
00:41:43,900 --> 00:41:47,350
One thing that we could think about doing is called a run in period.

357
00:41:47,500 --> 00:41:55,570
And the idea behind a running period is that you have your sample and then you keep them for a bit of time.

358
00:41:56,740 --> 00:41:59,770
And so you don't do their randomization right away.

359
00:42:00,610 --> 00:42:05,980
The idea behind this is to sort out the people who are easily lost to follow up.

360
00:42:06,340 --> 00:42:09,740
And I just think there is this one study that I did in India.

361
00:42:09,760 --> 00:42:15,250
It wasn't a randomized controlled trial, but we were following kids over time to measure antibody titers within them.

362
00:42:15,640 --> 00:42:28,480
And like a month after we started the study, there was this there was this phone company which was like new to the area.

363
00:42:28,480 --> 00:42:30,510
And they had all these discounts on people if they, like,

364
00:42:30,520 --> 00:42:36,460
switched their phone number and switched into their study or switched into their phone plans.

365
00:42:37,300 --> 00:42:41,860
And the effect of it was that we'd lost, like, I don't know,

366
00:42:41,860 --> 00:42:45,790
like a fourth of our sample to these people and we just like we're not able to follow up with them.

367
00:42:46,060 --> 00:42:51,510
I guess we have not. This is why you probably should collect information about like contact from other family members for a study.

368
00:42:51,560 --> 00:42:56,140
So we used to have information to contact these people again.

369
00:42:57,010 --> 00:43:03,640
And so the idea behind running period then is that, you know, we can see if people are more easily going to be lost to follow up.

370
00:43:03,970 --> 00:43:11,260
And then all the people who are just like hard to reach or who, you know, seems seemed excited about participating in study.

371
00:43:11,260 --> 00:43:16,420
But then it's like never respond to any of your any of your communications.

372
00:43:16,690 --> 00:43:19,190
They're just like out of the study now.

373
00:43:19,540 --> 00:43:26,650
And then so after the random period, which, you know, maybe it's a month, maybe it's longer than that, then we randomize people.

374
00:43:27,520 --> 00:43:32,259
I would argue then you're kind of like randomizing to like a certain group of people who like participating

375
00:43:32,260 --> 00:43:37,630
in studies and have easiness and maybe they have like the socioeconomic status where they can,

376
00:43:37,930 --> 00:43:42,640
you know, afford to answer all of your emails and your calls right away.

377
00:43:42,650 --> 00:43:49,450
But this is one way of just like limiting the amount of loss to follow up after the randomization time period.

378
00:43:53,370 --> 00:43:59,429
Okay. So now we're going to be talking about just a few different a few different study designs.

379
00:43:59,430 --> 00:44:05,159
And I would say there is this continuum from more of an explanatory trial to more of a pragmatic trial.

380
00:44:05,160 --> 00:44:10,920
So that's what we're going to kind of try to distinguish. But they're not there's not like a clear difference between these two.

381
00:44:11,430 --> 00:44:18,270
Again, it's a continuum. And there's also this framework called the pragmatic explanatory continuum indicator summary with the precis.

382
00:44:18,690 --> 00:44:21,809
And that is a way for you if you're doing a clinical trial,

383
00:44:21,810 --> 00:44:27,180
if you want to kind of tell people or tell your readers where you're at on this continuum, you could.

384
00:44:28,750 --> 00:44:34,870
Okay. So an explanatory trial is like as much as possible.

385
00:44:35,140 --> 00:44:38,770
You are trying to be as rigorous with your protocol.

386
00:44:39,610 --> 00:44:44,349
So you and the whole idea is like you want to know whether your intervention works.

387
00:44:44,350 --> 00:44:48,300
Like, does this drug does this new therapy? Does this new behavioral intervention?

388
00:44:48,310 --> 00:44:55,840
Does it work? So we'll be a bit more strict with our inclusion criteria because we really don't want people being lost if all we really

389
00:44:55,840 --> 00:45:05,710
don't want to have to do like a per protocol analysis and we'll probably use like very clear placebos as controls.

390
00:45:08,610 --> 00:45:17,910
That's different from pragmatic trials. Pragmatic trials are a bit more like how could this be implemented in the real world?

391
00:45:18,900 --> 00:45:25,830
So we'll be a bit more lax with the inclusion criteria again, because we want to be more reflective of what the population is like in the real world,

392
00:45:25,830 --> 00:45:33,570
and not just those people who are really good at, you know, calling in every few weeks and talking about like any symptoms that they've received.

393
00:45:33,600 --> 00:45:37,379
So it will be a bit more lax. There could be no placebo control.

394
00:45:37,380 --> 00:45:53,940
So, you know, there could be more. It could be you know, there could be different types of trials where you are like if you're doing a vaccine trial,

395
00:45:54,240 --> 00:46:00,180
you could have a placebo be just like a seasonal solution. But oftentimes what people will do is they'll just give people another vaccine.

396
00:46:00,540 --> 00:46:09,389
So, like, if I'm trying to study influenza in adults, maybe I'll give half the people in forms a bit.

397
00:46:09,390 --> 00:46:17,560
Half the people I'll give like meningitis B or something like that. So, you know, there are different nontaxable controls that you could use.

398
00:46:18,750 --> 00:46:25,520
And maybe you're more interested. And it could be that you're more interested in things which are easier to measure.

399
00:46:25,530 --> 00:46:32,429
It could be that you're more interested in these surrogate outcomes. Again.

400
00:46:32,430 --> 00:46:38,759
So there's a continuum. There could be people like very trials, which are very much in one corner versus the other.

401
00:46:38,760 --> 00:46:42,719
But oftentimes they're there on this continue. Okay.

402
00:46:42,720 --> 00:46:48,270
So how can we think about this in terms of vaccine effectiveness?

403
00:46:49,140 --> 00:46:56,490
So I would say, you know, like the big take home is efficacy is generally like more of an.

404
00:46:59,360 --> 00:47:04,190
It's more of an, uh, like a randomized controlled trial.

405
00:47:04,620 --> 00:47:13,070
The closer we get to, like, more observation or more real world settings, the more we might think of this being like effectiveness.

406
00:47:15,980 --> 00:47:21,190
So let's think about how this works in terms of an explanatory trial and a pragmatic trial.

407
00:47:22,100 --> 00:47:29,600
With an explanatory trial, we can estimate efficacy in an intent to treat approach.

408
00:47:32,530 --> 00:47:39,159
Or is it pragmatic trials more on effectiveness? And you could think of this, you know, like an observational study.

409
00:47:39,160 --> 00:47:46,370
We definitely would just be like estimating effectiveness. First launched her trials.

410
00:47:46,670 --> 00:47:50,870
Again, we're typically doing like an intention to treat kind of analysis.

411
00:47:52,340 --> 00:47:59,680
But we could do some sort of per protocol and estimate efficacy. But my takeaway from this would generally be explanatory trials.

412
00:47:59,690 --> 00:48:03,860
You're generally looking at efficacy, pragmatic trials, you're generally looking at the correctness.

413
00:48:04,310 --> 00:48:09,320
And the reason why we have those different words in in English is just to kind of get at, you know,

414
00:48:09,320 --> 00:48:17,960
are we able to clearly take away any of those problems of like exchange, ability and confounding and a selection bias?

415
00:48:18,380 --> 00:48:26,690
Um, in like a very ideal study population that is efficacy, whereas effectiveness is like, oh,

416
00:48:26,690 --> 00:48:33,650
you know what happens in a real world implementation setting where we don't have control over like every life.

417
00:48:39,180 --> 00:48:46,530
Okay. So the next part of this is just like going over a few different trial designs, but maybe I would give you like a five minute break.

418
00:48:46,960 --> 00:48:50,800
Um, so you see, to turn on the brakes. All right.

419
00:48:50,880 --> 00:48:57,745
Yeah. Let's just come back at 11:00. Right. So what brings you down?

420
00:49:19,131 --> 00:49:23,261
So we're going to be talking about a few different types of trial designs.

421
00:49:23,831 --> 00:49:27,971
There's lots of different ways you can set up randomized controlled trials. That's the whole idea behind it.

422
00:49:28,751 --> 00:49:32,201
When we think of clinical trials like randomized clinical trials,

423
00:49:32,201 --> 00:49:37,991
I think the idea here is that we're thinking of more clinical outcomes like RB treating a recurring disease.

424
00:49:39,551 --> 00:49:44,921
But I think a randomized controlled trial is just like a bit broader of focus.

425
00:49:45,251 --> 00:49:48,881
And of course, there's been, you know, clinical trials for decades and decades.

426
00:49:50,021 --> 00:49:58,601
Here's one on antibiotic treatment of tuberculosis. But I think the idea behind randomized controlled trials is a bit more comprehensive.

427
00:49:58,961 --> 00:50:05,231
For a field trial, that is where, you know, a randomized clinical trial, maybe people are more so by coming into the clinic to do things.

428
00:50:05,441 --> 00:50:11,611
For a field trial, we're like going out to the community to implement some sort of intervention.

429
00:50:11,621 --> 00:50:22,571
These can be huge. One that you shall know of as University of Michigan students is the trials for the Salk vaccine for polio.

430
00:50:23,051 --> 00:50:28,511
And so in the 1950s, you know, millions of children participated in this.

431
00:50:28,841 --> 00:50:36,941
And Tommy Francis, who was professor of epidemiology here in the School of Public Health and Speech two, is named after him.

432
00:50:37,421 --> 00:50:41,831
He was the one who, like Salk, was the one who, you know, developed the vaccine.

433
00:50:41,831 --> 00:50:46,301
But Francis was the one who, like, ran the statistics and ran the trial.

434
00:50:47,441 --> 00:50:51,911
And again, this is like millions of children and like before computers.

435
00:50:51,911 --> 00:51:03,970
So I'm not exactly sure how he did it, but they found that the vaccine was effective and they announced that at the the Rackham grad school.

436
00:51:03,971 --> 00:51:10,661
What does that build is? It is called Rackham? Yeah, just like the main auditorium, you know, just like a couple of blocks down there.

437
00:51:11,831 --> 00:51:17,171
But, you know, that was that was a huge thing that was announced here at the University of Michigan.

438
00:51:19,871 --> 00:51:23,461
So you might have heard about these one, two, three, four clinical trials.

439
00:51:23,471 --> 00:51:31,031
So that's what we're going to be talking about right now. This is just like a simplified diagram of what that actually means.

440
00:51:31,301 --> 00:51:36,491
So we could have like pre clinical trials that would be like laboratory studies, animal based studies.

441
00:51:37,691 --> 00:51:39,101
But then we get to phase one trial.

442
00:51:39,111 --> 00:51:46,151
So the idea behind Phase one trials is we have like, you know, maybe a couple dozen individuals and we're assessing safety of the drug.

443
00:51:47,951 --> 00:51:54,701
And this is an example. So I have some examples from a dengue vaccine called Dengvaxia.

444
00:51:55,211 --> 00:51:59,201
Also see why DTB, again, people love their acronyms.

445
00:51:59,501 --> 00:52:11,261
And so phase one clinical trial. I think, you know, this diagram is a bit hard to read if you're not looking up close with me like I am.

446
00:52:11,531 --> 00:52:21,430
But there's somewhere around like, you know, a hundred individuals who were enrolled at the last point in this study and

447
00:52:21,431 --> 00:52:29,291
it was looking at the risk of any adverse events in the study participants.

448
00:52:29,591 --> 00:52:36,401
So the and this is looking at different age groups and they also had like different dosing regimens.

449
00:52:36,401 --> 00:52:40,331
And that's something that you can do in phase one clinical trials is just like test out, you know,

450
00:52:40,391 --> 00:52:44,141
like how much are we giving or like what's the order of different doses, things like that.

451
00:52:45,401 --> 00:52:51,311
So they're looking at like any reaction or is this a systemic reaction or is it like an injection site reaction?

452
00:52:52,361 --> 00:52:54,670
I mean, the thing with Dengvaxia is it's pretty reactogenicity.

453
00:52:54,671 --> 00:53:03,071
So, you know, over 80% of individuals were getting the we're getting some sort of side effect.

454
00:53:04,181 --> 00:53:07,510
So we have phase two clinical trials. This is where we start randomize.

455
00:53:07,511 --> 00:53:12,011
And so phase one, you're not really randomizing anybody, but phase two, you can randomize them.

456
00:53:13,001 --> 00:53:19,841
You're still heavily focused on the safety, but you're also looking at surrogate measurements.

457
00:53:19,841 --> 00:53:26,421
And you know, you'll collect information on clinical outcomes too, like for Dengvaxia.

458
00:53:26,651 --> 00:53:28,480
They're going to look to see who gets dengue or not,

459
00:53:28,481 --> 00:53:36,310
but probably more so looking at a surrogate outcome in this is the mean titer of antibodies and this is,

460
00:53:36,311 --> 00:53:41,020
you know, antibodies for those who didn't get the vaccine in weight, in those who did get it.

461
00:53:41,021 --> 00:53:50,351
So, you know, higher titers for those who got it. Um, and, but also still looking at adverse events.

462
00:53:50,801 --> 00:53:52,241
So that's spec. And then here, you know,

463
00:53:52,241 --> 00:54:00,130
they have the people who were randomized and they have a flow chart for those who got placebo or those who got the actual Dengvaxia.

464
00:54:00,131 --> 00:54:05,981
I think it's about and this is where there's slightly more in the Dengvaxia group, 100 versus 50 in the placebo.

465
00:54:06,281 --> 00:54:11,401
And again, they were just from the Phase one clinical trial. They're really interested in the side effects.

466
00:54:11,411 --> 00:54:22,091
They want to continue doing that. Phase three clinical trials is like what you need to get to submit your your application for licensure to the FDA.

467
00:54:23,141 --> 00:54:26,710
This is what people that like if you're thinking about vaccines,

468
00:54:26,711 --> 00:54:31,931
the Advisory Committee on Immunization Practices at CDC will look at phase three clinical trial results.

469
00:54:34,211 --> 00:54:43,061
And so for DENGVAXIA, they were doing clinical trials throughout Southeast Asia and Latin America.

470
00:54:44,351 --> 00:54:48,551
And, you know, they also did an intense treat and a per protocol analysis.

471
00:54:53,731 --> 00:55:00,360
Yeah. So phase four studies are post licensure studies.

472
00:55:00,361 --> 00:55:03,941
So after they've been given approval, these are now on the market.

473
00:55:04,331 --> 00:55:11,491
Phase four just kind of means that we are continuing to evaluate especially the safety but also the, the effectiveness of this.

474
00:55:11,951 --> 00:55:21,161
Um, and, you know, potentially we're also going to broaden the therapeutic uses of the, of the drug or the treatment.

475
00:55:24,421 --> 00:55:27,051
So we've kind of been inundated with this information before.

476
00:55:27,061 --> 00:55:31,591
But I do think this is important for you to know as epidemiologist, because I still get this question a lot.

477
00:55:33,031 --> 00:55:36,781
How were COVID vaccines completed so quickly? How were they developed so quickly?

478
00:55:37,141 --> 00:55:43,291
Because in a traditional vaccine development timeline, it takes about 15 years or longer to develop a vaccine.

479
00:55:43,411 --> 00:55:47,521
So we could have years of doing animal or laboratory studies.

480
00:55:47,941 --> 00:55:55,141
And then, you know, we could have a couple of years of a phase one, a couple of years of face to face three might take two or three or four years.

481
00:55:55,141 --> 00:56:06,931
And then, you know, it will take a while for the FDA to evaluate it and then we will do it after the FDA issues their approval,

482
00:56:07,471 --> 00:56:17,071
then we will start actually producing the vaccine. And so that's why it takes a while for the COVID vaccine.

483
00:56:17,431 --> 00:56:22,381
We were able to do, you know, a lot of laboratory studies in parallel.

484
00:56:22,381 --> 00:56:27,301
And there's also just like so much effort devoted to this, a lot oftentimes with other vaccines,

485
00:56:27,301 --> 00:56:31,561
it's like one or two laboratory groups working on this over a long period of time.

486
00:56:31,561 --> 00:56:36,390
And, you know, there's may may or may not be a lot of political will and power to do it.

487
00:56:36,391 --> 00:56:44,431
But for SARS-CoV-2, we had lots of studies that were happening at the same time, and then we stacked the clinical trials on top of each other.

488
00:56:44,971 --> 00:56:53,881
But what do I mean by that? What happens in a traditional framework is that, you know, it takes so long to enroll people into studies.

489
00:56:54,181 --> 00:57:03,691
So especially if you're thinking of a clinical trial where there are maybe, you know, the phase three clinical trials for COVID vaccines,

490
00:57:03,691 --> 00:57:10,081
those were like 30 or 40,000 individuals and those to enroll that many people can take months or even years.

491
00:57:11,281 --> 00:57:22,531
So what the vaccine manufacturers were doing is while earlier phases were being completed, they were enrolling people for the subsequent phase.

492
00:57:22,771 --> 00:57:27,841
So they did not wait for results from phase one clinical trials to start enrolling people for phase two.

493
00:57:28,051 --> 00:57:34,411
And similarly, they were starting to enroll people in phase three, just like at the get go on.

494
00:57:34,831 --> 00:57:40,501
And I think what they were doing is like once they got some preliminary findings about phase one clinical trials,

495
00:57:40,771 --> 00:57:46,291
then they were searching the phase two. So in this way, you know, oftentimes in the traditional pathway,

496
00:57:46,501 --> 00:57:51,841
people will take their time submitting articles for publication, you know, getting peer reviews.

497
00:57:51,991 --> 00:57:58,050
And that, you know, can take months up to a year before the peer review article is completed.

498
00:57:58,051 --> 00:57:59,791
And then they will do the phase two clinical trial.

499
00:57:59,801 --> 00:58:08,161
But again, once like internally and this information was publicly distributed as well through preprints and things like that,

500
00:58:08,161 --> 00:58:10,290
but once that information was available for Phase one,

501
00:58:10,291 --> 00:58:18,631
they would immediately be able to start giving people or randomize people for the the subsequent clinical trials.

502
00:58:19,291 --> 00:58:22,861
And then during the phase three clinical trials, they also started doing production.

503
00:58:24,541 --> 00:58:29,941
So then like once the FDA had approved it, they like already had a batch of vaccines available.

504
00:58:32,481 --> 00:58:37,161
Many questions with the. Okay.

505
00:58:38,331 --> 00:58:42,380
Other things that we could think about is, are we doing like superiority trail?

506
00:58:42,381 --> 00:58:46,371
Are we doing an equivalent trial or are we doing a noninferior noninferiority trial?

507
00:58:46,581 --> 00:58:51,801
The idea behind this is like at this point in time, we have like drugs for a lot of different things.

508
00:58:52,011 --> 00:58:56,841
So if we're developing a new treatment, is there really a peer placebo?

509
00:58:56,851 --> 00:59:06,771
Like are we really just going to give somebody some like saline solution injection as a placebo or like some sugar pill as a placebo?

510
00:59:06,771 --> 00:59:14,571
Or is there like a standard of care that we need to compare things to so we can think about these things in

511
00:59:14,571 --> 00:59:19,761
a number of different ways and how we develop the trial and how we analyze that with a superiority trial.

512
00:59:20,121 --> 00:59:25,041
We're trying to say that like our new treatment is better than the thing that we have before.

513
00:59:26,151 --> 00:59:35,901
So we think of P like the probability of getting the illness or getting sick or, you know, having some sort of bad health outcome.

514
00:59:36,441 --> 00:59:43,251
The null hypothesis would be that like the probability of that in the treatment group in the new treatment is the same as in the standard.

515
00:59:44,121 --> 00:59:48,711
But our alternative process is that probability is less in our new treatment,

516
00:59:48,861 --> 00:59:53,691
where you could do like a two tailed hypothesis where it's just like not equal.

517
00:59:55,371 --> 00:59:58,401
So that's a superiority trial in equivalence trial.

518
00:59:58,401 --> 00:59:59,871
You're just saying that this is going to be the same,

519
00:59:59,931 --> 01:00:06,411
like the probability of getting sick is going to be the same for this new treatment than for an existing treatment.

520
01:00:06,771 --> 01:00:15,651
So the null hypothesis. So it's kind of a flip because the null hypothesis is that, uh, the treatment is like the,

521
01:00:15,651 --> 01:00:18,621
the difference in that or one of the treatments is going to be better than the other.

522
01:00:19,401 --> 01:00:25,251
And the alternative hypothesis is that they are the same, they're within each others like equivalence margin.

523
01:00:25,281 --> 01:00:30,921
And we'll be talking about this equivalence margin in the moment. But why do we want to do equivalence trials?

524
01:00:31,221 --> 01:00:36,921
Maybe the new treatment is easier to use. Maybe it has fewer side effects, maybe it's less costly.

525
01:00:37,101 --> 01:00:44,721
Maybe it's just like a new manufacturer which has come into the arena and wants money.

526
01:00:45,111 --> 01:00:46,641
So they're developing a new drug.

527
01:00:46,841 --> 01:00:54,351
You know, there's all sorts of reasons to do equivalence trials as an example of one that we'll skip over that for now.

528
01:00:54,591 --> 01:01:03,351
So non-inferiority trials, this is still in I have graphical representations of this because it kind of sounds like it's an equivalence trial,

529
01:01:03,351 --> 01:01:15,590
but it's not in a noninferiority trial. You're saying that it's not worse than the existing treatment, but you have to define this margin.

530
01:01:15,591 --> 01:01:20,871
And again, we'll talk about this margin in a moment, but. Think?

531
01:01:21,231 --> 01:01:25,700
Yeah. Here we are. So for all of these, we need to come up with a margin.

532
01:01:25,701 --> 01:01:27,801
And here the margin is this Delta sign.

533
01:01:29,001 --> 01:01:39,591
And this Delta sign is something that we are thinking is an example of whether the drug is significantly better or significantly worse.

534
01:01:39,861 --> 01:01:46,941
So this is like pre-specified by us, the researcher, and ideally we specify it before we actually do the studies instead of,

535
01:01:47,241 --> 01:01:52,851
you know, making it up afterwards because then we could really, you know, create whatever results we want.

536
01:01:53,661 --> 01:01:56,871
But let's, you know, think about this more concretely.

537
01:01:57,351 --> 01:02:07,760
Um, so, you know, we have our existing influenza vaccine, which kind of has middling levels of, of effectiveness for the seasonal influenza vaccine.

538
01:02:07,761 --> 01:02:12,381
Maybe we are developing a new influenza vaccine and we're going to say it's 10% better.

539
01:02:12,801 --> 01:02:18,831
So that is what this delta is like. This is, you know, us saying that our new influenza vaccine is 10% better.

540
01:02:20,811 --> 01:02:26,781
So we could look to see what our results versus that.

541
01:02:27,831 --> 01:02:35,540
And this is like two different examples. So in this one, the confidence interval is above this.

542
01:02:35,541 --> 01:02:39,281
So maybe we would say this like has evidence of being potentially superior in this one.

543
01:02:39,291 --> 01:02:43,041
It is not superior. You know, we can't see your point there.

544
01:02:44,091 --> 01:02:49,661
Thank you. I think this is this one is potentially evidence of superiority.

545
01:02:49,681 --> 01:02:52,701
This one not for equivalence.

546
01:02:52,701 --> 01:02:56,601
We need to set the balance like a lower limit and an upper limit of the balance,

547
01:02:56,901 --> 01:03:08,810
because we're trying to see like is the vaccine between 10% worse and 10% better than the existing vaccine in these would be examples of zeros,

548
01:03:08,811 --> 01:03:13,761
kind of like the existing treatments or the existing drug.

549
01:03:14,061 --> 01:03:16,721
And so we're just saying, but this is like relatively poor.

550
01:03:19,161 --> 01:03:26,781
For Noninferiority we are specifying a higher value for just specifying a lower bounds and we want to see if things are less than that.

551
01:03:27,891 --> 01:03:33,661
I think this might be a slightly easier chart to remember.

552
01:03:33,681 --> 01:03:37,191
So again, we're specifying this this condition.

553
01:03:37,191 --> 01:03:47,001
And so we want to see, is this new vaccine within 10%?

554
01:03:48,171 --> 01:03:52,761
You know, it's it's at least not as bad as 10% less than the previous six.

555
01:03:53,571 --> 01:03:57,591
So that's what this negative delta is. It's like 10% worse than the existing vaccine.

556
01:03:57,861 --> 01:04:05,001
But, you know, with both confidence intervals and with, you know, margins of errors and stuff, we just think that would be acceptable.

557
01:04:05,781 --> 01:04:11,151
So starting from the bottom, this so each of these are different vaccines that we're comparing to the standard.

558
01:04:11,451 --> 01:04:17,571
So the standard is zero. So this vaccine here is like clearly worse.

559
01:04:17,571 --> 01:04:21,821
It's like lower than our noninferiority margin.

560
01:04:21,831 --> 01:04:26,001
So this is like, you know, clearly a worse vaccine.

561
01:04:26,301 --> 01:04:31,281
It's inferior to, you know, what we have existing.

562
01:04:33,021 --> 01:04:39,171
We also have up here something which is superior. It's clearly better than the standard.

563
01:04:39,651 --> 01:04:45,951
So this is like a superior vaccine. And then in the middle, we have a different wording that we can use.

564
01:04:46,251 --> 01:04:50,601
You know, maybe something like this one. It's not inferior, but it's not superior.

565
01:04:50,871 --> 01:04:56,750
Like it's, it's not totally above the zero, but it's also not crossing this line we have here.

566
01:04:56,751 --> 01:05:04,641
This one is not inferior because it is, you know, not crossing this line as well.

567
01:05:07,751 --> 01:05:12,651
Yeah. Does that make sense?

568
01:05:12,831 --> 01:05:16,160
I think the whole idea behind this is like when we are evaluating a new treatment,

569
01:05:16,161 --> 01:05:29,901
are we really able to evaluate it against a pure placebo or do we need to think about like some other sort of like existing standard of care?

570
01:05:30,051 --> 01:05:35,031
And I think a lot of times now we're going to have to do that. So we need to think about like inner or design.

571
01:05:35,421 --> 01:05:41,171
Are we testing for non-inferiority or are we testing for superiority or are we testing for problems?

572
01:05:41,791 --> 01:05:49,131
Yeah. What would be the placebo effect and other studies should be that.

573
01:05:50,811 --> 01:05:56,821
Most other vaccine. Or I should test for that specified because.

574
01:06:00,711 --> 01:06:01,851
That's a great question.

575
01:06:02,601 --> 01:06:12,141
Like, do you run the trial yourself with that or do you just say like, oh, there's this existing study from like five years ago which found this?

576
01:06:12,291 --> 01:06:18,831
I think you'd have to. I think it is it depends on, you know, maybe if you had some sort of surrogate outcome,

577
01:06:18,831 --> 01:06:22,400
you might be able to just like rely on previously published data.

578
01:06:22,401 --> 01:06:28,881
But probably you as part of your study would be offering the like the gold standard or the standard of care as a placebo.

579
01:06:36,171 --> 01:06:42,251
Well. So oftentimes we do parallel trials. That's probably like the standard way of doing a randomized controlled trial.

580
01:06:42,881 --> 01:06:46,571
And basically we have the treatment and the placebos operating at the same time.

581
01:06:47,771 --> 01:06:51,821
So like temporally, these are occurring at the same time.

582
01:06:56,781 --> 01:06:59,090
Another example we could do is the factorial design.

583
01:06:59,091 --> 01:07:07,671
And in a factorial design you have a couple of different drugs that you are trying to evaluate in combination with each other.

584
01:07:08,121 --> 01:07:14,431
So say that we have two different drugs, drug A and B, so we can have a placebo for drug.

585
01:07:14,721 --> 01:07:19,651
We can have a placebo for drug B. So there are going to be some people who just have both placebo.

586
01:07:19,771 --> 01:07:25,821
There are some people that don't. And B, and then you have some people who are like drug and placebo B and placebo, any drug.

587
01:07:28,701 --> 01:07:36,291
And similarly, we follow them over time and we see if they get the disease or not.

588
01:07:36,711 --> 01:07:39,321
So this is a multifactorial experiment.

589
01:07:39,651 --> 01:07:47,271
And like in our analysis, we would just have, you know, two different exposures that we are looking at at the same time.

590
01:07:52,381 --> 01:07:57,961
This is an example of a factorial trial where people were given aspirin and vitamin E and different combinations of that.

591
01:07:58,901 --> 01:08:08,191
Uh, and so you out of like the original 5000, basically, you know, uh, 2000 were given aspirin,

592
01:08:08,641 --> 01:08:12,631
2000 were not given it, two dozen given by each death were not given it.

593
01:08:13,021 --> 01:08:16,471
Um, and we can analyze those at the same time.

594
01:08:17,701 --> 01:08:25,180
We can think of cross-over trial designs. So a crossover trial design is that everybody will get the placebo in the treatment.

595
01:08:25,181 --> 01:08:34,021
They'll just get it at different times. So, you know, at time, one, this group gets the placebo group gets the treatment, we need a washout period.

596
01:08:34,021 --> 01:08:39,661
So if there is some sort of, you know, maybe this is a treatment for arrhythmia or whatnot,

597
01:08:39,661 --> 01:08:45,271
we'll have a period where just like people go off any types of treatment and then we'll switch the treatments on.

598
01:08:51,231 --> 01:08:59,301
Oh, yeah. So previously we had just been talking about individual beast trials, but we could think of doing cluster randomized trials.

599
01:08:59,511 --> 01:09:02,931
And there's a few different reasons why we want to do cluster randomized trials.

600
01:09:04,581 --> 01:09:12,680
They could be a lot cheaper to do. The other thing is that it just might not be feasible to do in individual trials.

601
01:09:12,681 --> 01:09:20,691
So, um, I have read a lot recently about different interventions that clinics are trying to do to get more people vaccinated.

602
01:09:20,901 --> 01:09:24,950
And a lot of these are through cluster randomized trials because basically within

603
01:09:24,951 --> 01:09:29,510
each clinic people will be given a different set of educational materials.

604
01:09:29,511 --> 01:09:32,991
And it's really hard to think about like within one clinic,

605
01:09:33,981 --> 01:09:39,411
them giving out different types of educational interventions just because that logistically would be very, very difficult.

606
01:09:40,911 --> 01:09:44,871
So you could think of cluster in terms of like the clinic where people are getting access to treatment.

607
01:09:45,111 --> 01:09:52,371
You can think of it in terms of a geographical area. Um, you know, could be a neighborhood, it could be a city, it could be a school.

608
01:09:54,591 --> 01:10:00,531
We still are looking at individual level outcomes only and this will be a bit more of a multi level analysis.

609
01:10:00,831 --> 01:10:04,730
But we are looking at, you know, does the individual get the vaccine?

610
01:10:04,731 --> 01:10:08,311
Is the individual having a lower risk of heart attack? Um,

611
01:10:09,111 --> 01:10:14,871
it's just that people in their neighborhood or people in the same clinic will have

612
01:10:14,871 --> 01:10:20,031
a similar set of exposures as they do instead of it being individually randomized.

613
01:10:26,201 --> 01:10:30,221
And in through these things because we are looking at things in a bit more of a multi-level way.

614
01:10:30,221 --> 01:10:36,791
So we are able to look at indirect effects as well. Indirect effects are like, you know, does giving somebody to an individual,

615
01:10:36,851 --> 01:10:39,911
giving some intervention to an individual, does that affect the people around them?

616
01:10:43,771 --> 01:10:48,401
Okay. So the problem here is that people within a cluster can be highly related to each other.

617
01:10:48,421 --> 01:10:52,051
So that's what we need to deal with when we design these studies.

618
01:10:53,461 --> 01:10:57,361
How we measure that is through the ICC or the inter class correlation coefficient.

619
01:10:57,811 --> 01:11:05,011
This is often designated by the Greek letter row, which looks like an italicized P, but it is in our sound actually.

620
01:11:06,781 --> 01:11:17,641
So basically the higher the in your class correlation coefficient, the greater the degree of similarity there are between people in that same cluster.

621
01:11:18,931 --> 01:11:29,851
And this is you. I mean, how you measure this in reality is if you do some sort of multi level analysis like some mixed effects model in our or SAS,

622
01:11:31,381 --> 01:11:36,391
really one of the outputs that the program will give you is this in your class correlation coefficient,

623
01:11:36,391 --> 01:11:44,291
you usually can call it, but the formal measurement is you're looking at the variance between clusters and within clusters.

624
01:11:45,901 --> 01:11:55,831
And so you are looking at how much is, uh, how much is it between the clusters versus how much is it like all the variance overall.

625
01:11:57,031 --> 01:12:03,541
So the inter class correlation coefficient, another way of putting it, it's the variance that is explained by that between cluster variance.

626
01:12:08,781 --> 01:12:14,481
The ICC is related to the design effects and basically the design effect is.

627
01:12:15,021 --> 01:12:21,501
So the ICC is, you know, this measure between zero and one. It's a bit like ambiguous to think about, like what does it actually mean?

628
01:12:21,711 --> 01:12:26,510
But a design effect actually thinks more holistically about when given an ICC and

629
01:12:26,511 --> 01:12:31,071
given how many people are in your cluster and how many different clusters you have,

630
01:12:32,421 --> 01:12:36,021
how does that affect your like measure of associations?

631
01:12:36,051 --> 01:12:41,081
So say like what you're trying to measure is like a risk ratio for the,

632
01:12:41,211 --> 01:12:49,941
the risk of heart attack for people who have the placebo versus or the the treatment versus the placebo, that risk ratio.

633
01:12:50,241 --> 01:12:58,100
How would that risk ratio change if you had a purely like individual randomized study versus a cluster randomized study?

634
01:12:58,101 --> 01:13:09,231
That's kind of like what this design effect is getting. Yeah. So this is the equation for the design effect equals one plus and minus one times row.

635
01:13:09,831 --> 01:13:15,531
So if I could get a couple ones.

636
01:13:15,741 --> 01:13:24,471
Some of this. Okay.

637
01:13:25,091 --> 01:13:28,481
So if we have a situation where.

638
01:13:43,911 --> 01:13:58,911
So if the ICC, if this is zero, then this will then end up being just, you know, like it'll just equal outstanding, in fact, is one.

639
01:14:09,291 --> 01:14:12,521
I think it's like a simple mathematical thing.

640
01:14:12,791 --> 01:14:28,781
The end is equal to the number of people in your cluster. So if you have a lot of people in your cluster say you have 20 people in your cluster,

641
01:14:29,741 --> 01:14:36,851
you'll end up with higher design effects than if you had, say, only like four or five people in your cluster.

642
01:14:37,811 --> 01:14:42,491
And if you only have one person in your cluster, then again the design effects would be one.

643
01:14:43,031 --> 01:14:50,921
So it's like the M equals one. Then, you know, you just have one minus one here and then you zero.

644
01:14:51,191 --> 01:15:01,681
And then you're designing for people one. Like a cluster size of one just means that you have, like an individual level study.

645
01:15:04,481 --> 01:15:08,661
So how this works in principle is, you know, you might have, uh,

646
01:15:09,251 --> 01:15:15,971
you might from your sample size calculation, figure out that you need to have 500 people in your study.

647
01:15:16,631 --> 01:15:22,750
Then what you do is you need to think realistically about like how many clusters you need to go to and then how many people will be in those clusters.

648
01:15:22,751 --> 01:15:27,431
So if you need 500 people and if you can go to ten different clusters,

649
01:15:27,431 --> 01:15:33,191
then your cluster size would be 50 versus like if you could go to 50 different clusters, then your cluster size would be ten.

650
01:15:34,271 --> 01:15:41,441
So if you had this choice between having like ten versus 50 clusters, then you could see that like for the, the ten clusters,

651
01:15:41,801 --> 01:15:49,391
your design effects would be a lot more than if you had 50 clusters just because there'd be fewer people per cluster.

652
01:15:53,431 --> 01:15:55,891
I guess like one rule of thumb, they could think, you know,

653
01:15:56,311 --> 01:16:02,401
you could think about is that the number of people in your cluster should probably not be greater than one over Roe.

654
01:16:02,971 --> 01:16:12,281
So if you're if you found out your IKI is 0.05, then, you know, having 20 people per cluster kind of makes sense.

655
01:16:12,301 --> 01:16:16,771
Like any more than 20. And you're not going to really be improving your statistical power.

656
01:16:19,191 --> 01:16:27,561
But you know, if you have an IQ of 0.001, this means there's very little relationship between people in the cluster.

657
01:16:28,281 --> 01:16:32,361
Then you could have like 2000 people per cluster and probably not much of an issue.

658
01:16:39,031 --> 01:16:45,141
And, you know, so I think this happens a lot when there are interventions which have to kind of take advantage of the environment.

659
01:16:45,151 --> 01:16:55,761
So this is an example where they were doing cash transfers to look at incidence of HIV and herpes.

660
01:16:56,841 --> 01:17:02,671
And so there were some clinic or some villages which.

661
01:17:02,691 --> 01:17:11,661
Which got the cash transfers and some were up. Okay then I don't think we need to go through that.

662
01:17:11,661 --> 01:17:22,671
But, um, you know, I hear they're just like reporting their results and showing that HIV prevalence was,

663
01:17:23,811 --> 01:17:28,100
you know, it's like 1.2% in the intervention group versus 3% in the control group.

664
01:17:28,101 --> 01:17:31,671
And they can do odds ratios and they can also look at that for herpes as well.

665
01:17:34,321 --> 01:17:36,811
But for any of these studies, you know, because it's cluster,

666
01:17:37,081 --> 01:17:44,851
the things taken into account here is that this isn't going to be a statistically as efficient as if they did an individual trial.

667
01:17:44,881 --> 01:17:53,790
The problem is that like that individual trial is just not really feasible in a situation like this where you're doing like cash transfers and

668
01:17:53,791 --> 01:18:00,571
you're probably going to have to be setting up things within each village for like all the kids in that village to be getting these cash transfers.

669
01:18:01,681 --> 01:18:05,881
And, you know, it probably the optics of doing an individual transfer where like some kids get in,

670
01:18:05,881 --> 01:18:09,421
some don't within the same village might be a bit problematic.

671
01:18:14,821 --> 01:18:27,661
Okay. We could think of a stepped wedge cluster, randomized controlled trial, and this is where we do the cluster randomization over time.

672
01:18:30,971 --> 01:18:33,581
So what do I mean by that in a typical cluster design?

673
01:18:33,981 --> 01:18:42,731
You know, at time one, we randomize everyone to or all the clusters to either get the the treatment or get the placebo.

674
01:18:43,961 --> 01:18:47,851
But in this step, wedge design, you know, our time, you know,

675
01:18:47,891 --> 01:18:53,290
here they have time to but that time to only one of the clusters get at time for two of the clusters get it at time.

676
01:18:53,291 --> 01:19:00,911
Six three of the clusters get it. So who is in the placebo group changes over time versus who is in the control group?

677
01:19:02,021 --> 01:19:06,641
So here it's mentioned that like maybe this is useful when there's not equipoise.

678
01:19:07,061 --> 01:19:11,590
So equipoise would mean that we think that there is.

679
01:19:11,591 --> 01:19:16,241
We have no evidence to suggest that the intervention would actually be better than the placebo.

680
01:19:17,741 --> 01:19:21,821
But if there's not equipoise, then presumably we think that the treatment is going to be much better.

681
01:19:23,231 --> 01:19:24,401
So in a situation like this,

682
01:19:24,401 --> 01:19:31,571
maybe our thought is like we really do think that this intervention is going to be better and we want to make sure that everybody gets it.

683
01:19:31,751 --> 01:19:36,861
But one, you know, maybe we don't have all the funds right away to give everybody this.

684
01:19:36,881 --> 01:19:42,521
And then also in the stepwise design, we are able to evaluate the effectiveness of the intervention.

685
01:19:44,921 --> 01:19:48,041
So maybe we're having a bit of doubts on how effective it is.

686
01:19:48,041 --> 01:19:55,721
But like because we will have like time where people are or where these clusters are placebos, we're able to compare the outcome.

687
01:19:56,411 --> 01:19:59,920
Whereas if like everybody got it right away, then that's not with a randomized controlled trial.

688
01:19:59,921 --> 01:20:03,011
That's just everybody gets a everybody gets a treatment.

689
01:20:09,091 --> 01:20:13,881
And this is just another example of a cash transfer program.

690
01:20:13,921 --> 01:20:24,451
And they looked at, uh, you know, they, I think they split people into being early on in it and late on in it based on,

691
01:20:24,451 --> 01:20:26,911
you know, like the availability of funds. And they were able, you know,

692
01:20:26,911 --> 01:20:36,571
because they split people into these early and later groups like the later groups were able to serve as the placebo for the early intervention people.

693
01:20:37,131 --> 01:20:42,631
Um, so this is just looking at the number of people who were or like the total amount of money that was transferred.

694
01:20:42,631 --> 01:20:46,261
But from this you are able to calculate like measures of association.

695
01:20:50,591 --> 01:21:00,791
And if one trials are for an individual person and this typically would be done for like a drug, you will give them one drug,

696
01:21:01,241 --> 01:21:05,750
you'll have a washout period, and then they'll give them another drug and then have a washout period.

697
01:21:05,751 --> 01:21:10,691
Then you kind of like go back and forth and see, you know, what the effect of the treatment is.

698
01:21:11,081 --> 01:21:15,460
And in reality, I think this this is like what doctors do a lot when they're trying to figure out,

699
01:21:15,461 --> 01:21:18,641
like, what kind of medication should my patient be going on?

700
01:21:19,271 --> 01:21:25,930
Maybe they're thinking of like, uh, uh, psychiatric medications or maybe cardiovascular medications.

701
01:21:25,931 --> 01:21:28,871
And there's, you know, many different medications out there.

702
01:21:28,871 --> 01:21:35,981
So, um, I think in a less systematic way, oftentimes doctors will just see like, Oh, this person is on this one drug.

703
01:21:36,131 --> 01:21:42,461
What's, what are their outcomes like? Let's draw some blood, see, like, is there, are there biomarkers getting better?

704
01:21:43,721 --> 01:21:46,721
And if they're not, they might switch them to another drug in an end of one trial.

705
01:21:46,721 --> 01:21:52,571
You're just doing that a bit more systematically, um, where you are specifically looking at,

706
01:21:53,111 --> 01:21:56,441
you know, having a set period of time where they have a drug and you have a set regimen.

707
01:21:58,361 --> 01:22:04,241
Otherwise, you know, like as much as possible, you want to have randomization and blinding as well in anyone one trials.

708
01:22:04,241 --> 01:22:07,810
Like it's not necessarily saying that like when you report these results,

709
01:22:07,811 --> 01:22:14,860
you'll only have one person because like you can have basically you can have results from many different individuals.

710
01:22:14,861 --> 01:22:19,121
It's just like within each individual you'll have information about them being on the

711
01:22:19,121 --> 01:22:22,421
placebo in on the treatment or like if there's two different types of treatments.

712
01:22:23,501 --> 01:22:30,401
So this is an example where they were looking at celecoxib and paracetamol.

713
01:22:30,461 --> 01:22:40,211
Paracetamol is just like acetaminophen or Tylenol, and it's looking at the effect of usage of that on osteoarthritis.

714
01:22:41,171 --> 01:22:50,321
And of course, because like Tylenol sort of maybe more of like a baseline thing, we're really looking at the advantage of using Celecoxib.

715
01:22:51,131 --> 01:22:58,481
But in this particular study there's actually, um, I think 33 individuals.

716
01:23:00,601 --> 01:23:07,741
Or 41. So there's 41 individuals in this. But we just have timepoints where they were given celecoxib and ten points where they're given paracetamol.

717
01:23:12,101 --> 01:23:16,911
Okay. So that's kind of like all about the design of clinical trials.

718
01:23:16,911 --> 01:23:23,171
So for the last 15 minutes, we're just talking about more ethical things and logistical things.

719
01:23:23,771 --> 01:23:29,261
I know this is a lot. So if it's, you know, hitting you very hard, that's that's all understandable.

720
01:23:31,911 --> 01:23:37,911
So the one thing about clinical trials is that they're supposed to be registered. So here in the United States, we have the site clinicaltrials.gov.

721
01:23:38,751 --> 01:23:43,491
There are ones in other locations as well, although I will say a lot of people,

722
01:23:43,491 --> 01:23:48,380
even like in Europe and Asia, will use clinicaltrials.gov because you don't need to be registered.

723
01:23:48,381 --> 01:23:52,371
You don't it doesn't need to be a US based, it doesn't need to be a U.S. researcher.

724
01:23:53,571 --> 01:24:02,091
So most journals now require you to have submitted your trial information and your protocol

725
01:24:02,361 --> 01:24:08,091
into clinicaltrials.gov prior to reporting or prior to you starting data collection,

726
01:24:08,391 --> 01:24:11,391
but certainly prior to you submitting the manuscript for publication.

727
01:24:11,901 --> 01:24:18,711
The idea here is that, you know, this is a record of people seeing like what your protocol is prior to actually doing the data analysis.

728
01:24:19,041 --> 01:24:24,020
The other reason why clinicaltrials.gov documents are in existence is because what people are

729
01:24:24,021 --> 01:24:28,071
finding out is that the NIH was giving money for all these people to do clinical trials,

730
01:24:28,311 --> 01:24:31,191
and then we just weren't finding out the results of those clinical trials.

731
01:24:31,461 --> 01:24:36,530
So for clinical trials, like there is at least a mandate by an age that, you know,

732
01:24:36,531 --> 01:24:41,481
within a certain year you need to put together a timeframe of like you will

733
01:24:41,481 --> 01:24:45,111
submit your final results to clinicaltrials.gov at a certain point in time.

734
01:24:45,591 --> 01:24:52,641
The other thing which is nice about that is like you have because you specify when you submit clinical your application,

735
01:24:52,641 --> 01:25:03,381
like what your study design is. So then you have to report your results according to that according to your baseline protocol.

736
01:25:03,711 --> 01:25:08,540
Whereas like if you were to publish a paper, you could kind of change the protocol,

737
01:25:08,541 --> 01:25:14,181
but you could change like your analytical plan and there wouldn't be much of a record of that.

738
01:25:17,741 --> 01:25:20,891
There's also you know, there's all sorts of statements out there.

739
01:25:20,951 --> 01:25:26,231
There's the concert statements which is like, how are you supposed to write about clinical trials?

740
01:25:27,071 --> 01:25:33,041
Any other many of these there's like strobe for observational studies, there's Prisma for systematic reviews.

741
01:25:35,291 --> 01:25:39,250
I would say like stroke, poor observational studies generally journals don't require it,

742
01:25:39,251 --> 01:25:43,931
but for randomized clinical trials, probably when you submit your article for publication,

743
01:25:43,931 --> 01:25:48,221
they will also require you to submit this concert statement where you explain, you know,

744
01:25:48,221 --> 01:25:56,501
there's just a number of different things that they think need to be in a manuscript and you need to explain where those arguments go.

745
01:26:00,041 --> 01:26:09,221
Okay. Ethical issues, equipoise, equipoise is absolutely needed for us to justify randomization.

746
01:26:09,971 --> 01:26:12,671
So if there is equipoise,

747
01:26:13,151 --> 01:26:22,301
that means that we're not sure if there is like equality in outcomes between like a new intervention and the standard of care or a placebo.

748
01:26:24,841 --> 01:26:30,901
Um, so, but, you know, like, what does it mean to be slightly better or to be actually better?

749
01:26:30,931 --> 01:26:37,411
You know, this isn't. There could be some controversy or there could be some vagueness about, like, what is the line for?

750
01:26:37,681 --> 01:26:45,091
Like, a new treatment could be better than the standard of care. But the idea here is that, like, you know, if we know that.

751
01:26:48,521 --> 01:26:54,851
Wait for the measles vaccine. If we know that the measles vaccine is really good and it's very effective.

752
01:26:55,301 --> 01:27:03,581
Then we can run like a new randomized controlled trial looking at the measles vaccine versus like a saline solution, placebo.

753
01:27:03,761 --> 01:27:05,681
That just wouldn't be ethical. There's not equipoise there.

754
01:27:09,911 --> 01:27:16,030
And I think this is also the hard thing where there's some you know, there is there are so much early on in the pandemic where people are like,

755
01:27:16,031 --> 01:27:21,401
oh, what's the benefit of wearing a mask or what's, you know, the benefit of doing these social distancing measures?

756
01:27:21,401 --> 01:27:24,280
We need randomized controlled trials. Those are the gold standard treatments.

757
01:27:24,281 --> 01:27:28,751
But like if you think about these things logically, there wasn't equipoise between, you know,

758
01:27:28,811 --> 01:27:34,030
wearing a mask and not wearing a mask when there's a huge outbreak happening or, you know, social distancing or things like that.

759
01:27:34,031 --> 01:27:37,951
So just ethically, it wasn't there. And I think it has to this idea that the place.

760
01:27:41,411 --> 01:27:44,650
There could be, and I'll give an example later.

761
01:27:44,651 --> 01:27:48,551
There could be ethical issues with like what your intervention is.

762
01:27:51,311 --> 01:28:00,611
And if any of you are also in what is it? There's, uh, that class for epilepsy students about like doing our CRC training.

763
01:28:00,791 --> 01:28:04,121
I give some more examples later on in the semester. I believe I have you in like a month.

764
01:28:08,381 --> 01:28:13,781
So, you know, there is this debate about like, should we be using placebos or should we be using.

765
01:28:15,491 --> 01:28:17,321
Should we be using like a standard of care?

766
01:28:18,661 --> 01:28:29,141
And, you know, I would say we use the placebo if there's no effective treatment that is existing, if participants.

767
01:28:29,981 --> 01:28:35,631
Just like if the standard treatment doesn't work for a lot of participants, this is the debatable one.

768
01:28:35,651 --> 01:28:40,121
Like what if the effective treatment isn't available in a local setting?

769
01:28:40,151 --> 01:28:50,621
Like maybe here in the U.S. we have this like fancy treatment for hepatitis C, but maybe you go over the border in Mexico and they don't have that.

770
01:28:51,671 --> 01:28:57,941
So like in the U.S., if you're trying to develop like a new treatment for hepatitis C, we probably have to compare it to the standard of care.

771
01:28:58,241 --> 01:29:06,421
But in Mexico, could be compared to a like sugar corn or do we need to like compared to what we have here in the U.S.?

772
01:29:10,971 --> 01:29:15,651
And we'll be talking more about an example of that moment. Eligibility and exclusion criteria.

773
01:29:17,181 --> 01:29:27,381
So like here in the U.S., I think more recently, the NIH has gotten very cognizant about having a diverse group of individuals in our clinical trials.

774
01:29:27,711 --> 01:29:28,610
And it's like amazing.

775
01:29:28,611 --> 01:29:37,821
If you look 30 or 40 years ago, like who is in clinical trials, there would be like clinical trials on pregnancy drugs and it'd be all in common.

776
01:29:38,031 --> 01:29:42,350
And then, you know, there would be this idea that like, oh, women are too proud to participate in randomized clinical trials,

777
01:29:42,351 --> 01:29:47,891
but there seems to be some reasons why, you know, maybe we have different criteria there.

778
01:29:49,551 --> 01:29:50,351
Also, you know,

779
01:29:50,361 --> 01:29:58,461
we want to make sure that there's people of like a variety of differences in demographic stances of different racial groups that we're not just,

780
01:29:58,461 --> 01:30:03,981
you know, targeting certain individuals. And this is, you know,

781
01:30:03,981 --> 01:30:11,750
a concept of of justice that the people who are bearing the risk of participating in

782
01:30:11,751 --> 01:30:15,111
a study should be the same kinds of people who will benefit from that intervention.

783
01:30:18,051 --> 01:30:21,681
Okay. So I will leave you with this one study.

784
01:30:23,421 --> 01:30:27,981
So AZT is an antiretroviral therapy.

785
01:30:28,041 --> 01:30:35,180
And, you know, by the nineties, it was found that it could, uh, you know,

786
01:30:35,181 --> 01:30:43,251
it could be used in people who were living with HIV to to extend their lifespan.

787
01:30:44,901 --> 01:30:58,791
It was this amazing drug. And then the thought was, could we use AZT to prevent transmission of HIV from a mother to a child during childbirth?

788
01:31:00,201 --> 01:31:07,610
So there's something which is called long course AZT, which I guess is what the typical treatment is,

789
01:31:07,611 --> 01:31:15,701
just like in the long course later on added to distinguish it from short course, but the typical treatment reduced HIV transmission by 68%.

790
01:31:15,711 --> 01:31:20,931
So it was great. And certainly that was something which was starting to be used in more high income settings.

791
01:31:21,591 --> 01:31:27,051
But there just like was not the funding for it in places like Africa, especially when you're considering that.

792
01:31:27,351 --> 01:31:32,631
Know, I don't think this drug was like that difficult to produce. But, you know, there is all sorts of IP issues, um, you know,

793
01:31:32,631 --> 01:31:41,121
the patent being held by relatively wealthy pharmaceutical companies and not really wanting to manufacture it in low income settings.

794
01:31:43,431 --> 01:31:49,771
So some researchers thought this AZT therapy's really expensive.

795
01:31:49,791 --> 01:32:04,610
What if we, like, kind of cut the treatment half into a short course therapy and see if that's the tough thing is like in the US,

796
01:32:04,611 --> 01:32:11,901
if we're thinking of we know that the long course treatment is effective.

797
01:32:12,831 --> 01:32:24,381
I don't think there would be any ethical way in the US studying our short course therapy just because we know that the long course works.

798
01:32:24,651 --> 01:32:30,171
And you know, are we really going to what's the risk of potentially getting all these kids

799
01:32:30,411 --> 01:32:34,641
infected with HIV from their mothers if we know that the treatment already exists?

800
01:32:36,051 --> 01:32:45,531
So I think in the US there would be a balance there. But in potentially other locations they're thinking, well, maybe this short course that,

801
01:32:45,571 --> 01:32:51,441
you know, it's relatively cheap or cheaper than the long course maybe to improve access.

802
01:32:53,031 --> 01:33:02,571
So this is the argument. So some people argued that, you know, for this study, they were arguing that, you know,

803
01:33:02,571 --> 01:33:07,341
in this in these in these African countries, like people just not receiving any treatment.

804
01:33:07,641 --> 01:33:13,731
So by actually doing this clinical trial, if we find an effect of short course, then all of a sudden,

805
01:33:13,731 --> 01:33:18,351
you know, there might be a much higher likelihood of the short course therapy becoming available.

806
01:33:20,301 --> 01:33:28,521
So critics argued that they took a huge aim at this idea of like, what is the placebo here?

807
01:33:28,911 --> 01:33:33,451
Because, like, we know that we can prevent HIV transmission.

808
01:33:33,471 --> 01:33:38,331
So, like, is it really ethical to not have a placebo?

809
01:33:41,181 --> 01:33:54,051
One thing I'll also mention is this was so the declaration of Helsinki has ended up being a bit stronger in terms of like the the ethics

810
01:33:54,051 --> 01:34:02,721
part of that than in the Declaration of Helsinki is just this thing which came out of Europe after the Nuremberg trials of Nazi Germany.

811
01:34:02,721 --> 01:34:05,421
And it was all about like, we need to have patient consent during research.

812
01:34:05,751 --> 01:34:11,541
And in the intervening period they've had like a lot of work on like what is an ethical placebo and things like that.

813
01:34:12,081 --> 01:34:19,820
And this has tended to be a bit more robust and a bit more rigorous or a bit more stringent maybe than the United States version.

814
01:34:19,821 --> 01:34:24,621
So the United States version we'd be thinking of like the Belmont Report or the common rule.

815
01:34:25,971 --> 01:34:34,311
So basically one of the issues here is that seemingly this kind of study would violate the Declaration of Helsinki,

816
01:34:34,551 --> 01:34:39,771
but it probably would not violate the US version like the Belmont Report and the Common Law.

817
01:34:42,911 --> 01:34:49,581
Um. So in your brains you can think like, is this study ethical or not?

818
01:34:50,451 --> 01:34:58,280
I think probably a lot of public health research would say it's not, but, uh, it's like it is the hard thing to think about and you know,

819
01:34:58,281 --> 01:35:04,670
is it different if like somebody this is maybe like a more interesting spin on this is like,

820
01:35:04,671 --> 01:35:12,761
is this different if an American goes over to Zimbabwe and tries to run this trial versus like somebody in Zimbabwe,

821
01:35:12,771 --> 01:35:17,001
like a Zimbabwe researchers, like we just our standard of care is like nothing.

822
01:35:17,211 --> 01:35:21,111
So why don't we start off trying to look at a short course versus standard of care?

823
01:35:21,831 --> 01:35:30,050
I think there it's like a bit more complicated with like some of the ethics, you know, the Zimbabwean the local Zimbabwean one.

824
01:35:30,051 --> 01:35:37,520
I'd have to think about it a lot more. I feel very uncomfortable with like this idea of Americans going on to other countries and like using in a way,

825
01:35:37,521 --> 01:35:45,671
it's kind of like ethics dumping like we can. I think there's this idea that we could use, like a pristine group of people who, uh,

826
01:35:46,521 --> 01:35:51,531
we can institute like a placebo arm, whereas it might not be possible to do that here in the United States.

827
01:35:51,591 --> 01:35:53,181
And I think that is problematic.

828
01:35:54,621 --> 01:36:01,131
But yeah, the I mean, they published their study, and I think they did find that the short course therapy was effective.

829
01:36:01,131 --> 01:36:06,171
And I think as a result, the short course therapy was implemented in a lot of locations.

830
01:36:06,561 --> 01:36:12,561
I guess in my mind there's like this counterfactual world where instead of implementing this short course therapy,

831
01:36:12,561 --> 01:36:20,720
we found a way to like think through all the financial logistical things and instead have long course therapy available in any settings.

832
01:36:20,721 --> 01:36:24,891
And we have to think it, you know, in the grand scheme of things,

833
01:36:25,671 --> 01:36:29,571
all of these pharmaceutical companies probably would have still been raking in profits and whatnot.

834
01:36:29,571 --> 01:36:33,980
So, you know, complicated stories to think about. But that's all I would say around this controlled trials.

835
01:36:33,981 --> 01:36:38,871
There is controversy in how we set them up, what the placebo is, who's doing them.

836
01:36:39,831 --> 01:36:43,641
And I think those are important things for you to be thinking about as students.

837
01:36:44,511 --> 01:36:49,491
Oh, you all you do that, you know, please come up if you have any other questions.

838
01:36:50,121 --> 01:36:54,271
I hope you have a wonderful day. And the rest of the.

