1
00:00:06,990 --> 00:00:14,960
Thank you. OK, we're going to go ahead and get started just by way of announcements.

2
00:00:14,960 --> 00:00:18,680
So we had a quiz do business class was starting.

3
00:00:18,680 --> 00:00:23,270
The next phase is going back to the to the normal due time on Tuesdays.

4
00:00:23,270 --> 00:00:29,990
We also had posted the extra credit assignment. So that is on the bottom of the module list.

5
00:00:29,990 --> 00:00:35,360
You've got about a month, a little less than a month to do it.

6
00:00:35,360 --> 00:00:39,230
I highly recommend that you do that. It is a paper format.

7
00:00:39,230 --> 00:00:46,880
You're proposing to studies to solve or answer any question that you're interested in.

8
00:00:46,880 --> 00:00:55,070
So today we have a guest lecture from the doctor, Dr. Jennifer Smith, to introduce her briefly.

9
00:00:55,070 --> 00:00:59,780
Dr. Smith is a genetic epidemiologist with appointments in the Energy Department,

10
00:00:59,780 --> 00:01:05,810
School of Public Health and the Survey Research Center Institute for Social Social Research broadly.

11
00:01:05,810 --> 00:01:14,510
Her research investigates the relationship between genetic epigenetic and trans filmic variation in age related chronic diseases,

12
00:01:14,510 --> 00:01:21,500
including cardiovascular disease and dementia. She's a court faculty member of the Center for Social Safety and Population

13
00:01:21,500 --> 00:01:26,480
Health and is affiliated with the Michigan Center on the Demography of Aging.

14
00:01:26,480 --> 00:01:31,460
The Center for Midwifes Science and the Population Development and Program.

15
00:01:31,460 --> 00:01:35,510
She also directs speeches, certificate, program and public health genetics.

16
00:01:35,510 --> 00:01:38,429
So I think I need to use the recording.

17
00:01:52,881 --> 00:01:58,221
I like to come and teach in this class.

18
00:01:58,221 --> 00:02:06,741
It's probably my first time, I guess, doing this lecture. I think that it's a good lecture for me to do because I am a genetic epidemiologist.

19
00:02:06,741 --> 00:02:15,691
And so if you know anything about genetic genealogy, you know that it's a field where we have generally pretty small effects.

20
00:02:15,691 --> 00:02:22,491
So there's lots of genes all across the genome and we're trying to look for the relationships between genes and disease.

21
00:02:22,491 --> 00:02:31,761
And it's it's often the case with complex diseases that you have a lot of contributing genes and they each have very small effects.

22
00:02:31,761 --> 00:02:34,311
And because of that,

23
00:02:34,311 --> 00:02:42,651
it is sometimes difficult to replicate the work that we find in one population versus another because there's lots of pieces that can come into play.

24
00:02:42,651 --> 00:02:48,621
There might be other teams influencing. There might be other environments. Of course, confounding factors.

25
00:02:48,621 --> 00:02:54,021
And so I'll give you the history of the history of the field of genetic epidemiology.

26
00:02:54,021 --> 00:03:02,271
But I think Aubrey pinged me to do this lecture because it's kind of replication and reproducibility has become

27
00:03:02,271 --> 00:03:10,341
a very important focus of our field because of the difficulties we've had in reproducing things in the past.

28
00:03:10,341 --> 00:03:19,191
And so so I'll talk about that. And then also kind of turns into this conversation later in the lecture about, you know,

29
00:03:19,191 --> 00:03:22,851
what are the scientific standards that we actually really need to be doing in order

30
00:03:22,851 --> 00:03:36,461
to hold that hold that focus of being able to replicate and reproduce results.

31
00:03:36,461 --> 00:03:42,701
OK, so just to give you an outline, let's talk a little bit about, like I said,

32
00:03:42,701 --> 00:03:47,561
sort of the history of our field and how we got to where we're at and then start to talk

33
00:03:47,561 --> 00:03:52,601
about some of the investigation into the potential reasons for the lack of reproducibility.

34
00:03:52,601 --> 00:04:01,631
And then in our field, can you talk about the conclusions and the recommendations in the strategies that we've sort of come to in that area?

35
00:04:01,631 --> 00:04:08,021
And then we'll take a break and then we'll come back and we'll talk about the scientific process itself.

36
00:04:08,021 --> 00:04:14,781
So what is going on with the media in the scientific community in terms of how they think about the reproducibility?

37
00:04:14,781 --> 00:04:20,711
And then there's this thing that they turn to the reproducibility crisis.

38
00:04:20,711 --> 00:04:27,991
And how is that portrayed in the media and how is it portrayed in the scientific community and what are some of the reasons for it?

39
00:04:27,991 --> 00:04:32,111
And then, of course, what are the recommended solutions?

40
00:04:32,111 --> 00:04:40,031
So I, I really want to encourage you to to participate all stop and ask questions, have a different point.

41
00:04:40,031 --> 00:04:48,131
So even if you think it's an obvious question, maybe if you want to throw it out there and tell me your opinion, I mean,

42
00:04:48,131 --> 00:04:53,741
you know, I can lecture all day, but I think the classes are better when people kind of jump in and participate.

43
00:04:53,741 --> 00:04:59,321
So you'll have an opportunity to do that. All right.

44
00:04:59,321 --> 00:05:07,301
So then this was sort of my slide to say this is the way that pretty much every genetic kind of genealogist felt about 15 years ago,

45
00:05:07,301 --> 00:05:13,421
that we had this two decades of research on what we thought we knew about genetics of disease

46
00:05:13,421 --> 00:05:17,981
and that people were feeling like we can just actually toss those studies out the window.

47
00:05:17,981 --> 00:05:24,911
So if you know the genetic field, while there's this sort of stigma around what we call candidate gene studies,

48
00:05:24,911 --> 00:05:27,731
so before we could measure the genome at scale,

49
00:05:27,731 --> 00:05:33,521
we actually would measure just really specific genes that we thought were biologically related to our trait of interest.

50
00:05:33,521 --> 00:05:39,931
Right then that makes sense. We have a biological hypothesis. We're looking for mutations in those genes.

51
00:05:39,931 --> 00:05:50,081
And but what people found was that there were a lot of studies out there that found associations between certain mutations and

52
00:05:50,081 --> 00:05:57,941
diseases of interest and that we would repeatedly try to look for those in other populations and they wouldn't replicate.

53
00:05:57,941 --> 00:06:06,791
So from about the mid 80s to around the mid 2000s, all these gene studies, people don't trust them.

54
00:06:06,791 --> 00:06:16,901
And so our field kind of was one of the first, I think, to really experience this kind of like vast gravity of the reproducibility crisis.

55
00:06:16,901 --> 00:06:24,701
So this is just an example. This is published in the New England Journal of Medicine, which is, of course, a really great journal.

56
00:06:24,701 --> 00:06:32,561
It was an association that they found between a specific mutation in this gene called a polyone.

57
00:06:32,561 --> 00:06:39,401
And what they found was they looked at people who had coronary artery disease so early, CAIB.

58
00:06:39,401 --> 00:06:47,351
So this is before, you know, sort of women in their mid 40s and 50s are developing, developing.

59
00:06:47,351 --> 00:06:51,461
They're getting heart attacks, you know, things early in life.

60
00:06:51,461 --> 00:06:58,181
So they found a specific mutation that was in twenty eight out of 88 cases of early coronary artery disease,

61
00:06:58,181 --> 00:07:03,131
but only five of one hundred and twenty three cab free controls.

62
00:07:03,131 --> 00:07:09,971
Right. So that's a really big odds ratio. I think it's like 11 or something like that, but it's a really strong association.

63
00:07:09,971 --> 00:07:13,751
They found that that gene was also biologically plausible.

64
00:07:13,751 --> 00:07:18,851
So the APOE A1 protein levels were also associated with coronary artery disease.

65
00:07:18,851 --> 00:07:24,191
And so there was this sort of biological hypothesis.

66
00:07:24,191 --> 00:07:30,791
There was also other evidence of when they looked at people with low levels of the APOE one protein,

67
00:07:30,791 --> 00:07:36,161
they also found an even greater access for other disease cases.

68
00:07:36,161 --> 00:07:39,461
It was also associated with HDL, which is a related risk factor.

69
00:07:39,461 --> 00:07:48,581
Right. So there's all these pieces. And actually, when this study came out, it made such a huge impact on the field that people started talking about,

70
00:07:48,581 --> 00:07:53,411
for example, newborn screening for this particular mutation.

71
00:07:53,411 --> 00:07:58,481
So when you think about it, like, OK, it's got this huge effect, like early onset.

72
00:07:58,481 --> 00:08:05,171
So, you know, we've got be worth screening programs where we can actually screen people for these genetic diseases.

73
00:08:05,171 --> 00:08:14,831
But if we look for this one mutation and then, you know, without even any other evidence like this, these conversations were already happening.

74
00:08:14,831 --> 00:08:21,971
So if you really think about how that plays out, you know, you're you're in the hospital, you just have a baby.

75
00:08:21,971 --> 00:08:28,661
And then they're saying, oh, your baby has the mutation that might cause it to get early onset coronary artery disease.

76
00:08:28,661 --> 00:08:32,691
And like you said, the right time to be giving them information is that.

77
00:08:32,691 --> 00:08:37,671
The right time to be discussing it, but all these things were already happening, right?

78
00:08:37,671 --> 00:08:42,211
So no one could ever replicate that time.

79
00:08:42,211 --> 00:08:46,401
You ever, never did.

80
00:08:46,401 --> 00:08:53,841
So just to give you some clarification, there are other mutations and equally one that we have found to be associated with artery disease.

81
00:08:53,841 --> 00:08:58,381
So it's not like the biology was wrong, but our inference was was wrong.

82
00:08:58,381 --> 00:09:03,441
OK, so like, what do you think were some of the potential reasons for that?

83
00:09:03,441 --> 00:09:04,501
Like just in general,

84
00:09:04,501 --> 00:09:11,631
what could what could have possibly been some of the reasons why we didn't replicate that fighting in other populations are different,

85
00:09:11,631 --> 00:09:21,771
like like blacks, Hispanics. And so you'll find probably the same mutations in the white people that black people weren't.

86
00:09:21,771 --> 00:09:25,551
OK, so populations are different in their do that, right.

87
00:09:25,551 --> 00:09:35,661
In their mutational distribution. OK, so can anybody take that one step further and talk about like, OK,

88
00:09:35,661 --> 00:09:41,031
you said one thing where you said the same mutation might not be present in multiple populations.

89
00:09:41,031 --> 00:09:48,231
So maybe this was found in European and African ancestry and Hispanic ancestry or ethnicity don't actually have that.

90
00:09:48,231 --> 00:09:56,051
What else? Yeah, something different.

91
00:09:56,051 --> 00:10:05,921
Right, so so you're both hitting on this key piece about your ancestry, so you may know the ancestry and genetics measures matters a lot.

92
00:10:05,921 --> 00:10:09,431
Right. So so one thing that could be happening,

93
00:10:09,431 --> 00:10:22,481
and it's called population stratification to where you basically have you have different groups that are contributing to your cases and controls.

94
00:10:22,481 --> 00:10:27,761
And any place in the genome that they differ is going to look like it's associated with disease.

95
00:10:27,761 --> 00:10:31,451
Right. So if you're very careful in genetics for controlling your ancestry.

96
00:10:31,451 --> 00:10:39,191
So I'll talk a little bit about that later. What are other potential reasons in general for lack of replication that could

97
00:10:39,191 --> 00:10:45,101
have been happening in the genetics field or even outside the genetics field?

98
00:10:45,101 --> 00:10:48,561
Yeah, the lack of power, right.

99
00:10:48,561 --> 00:10:52,911
So we've got really small effects. We might this is a really small sample size.

100
00:10:52,911 --> 00:10:53,261
Right.

101
00:10:53,261 --> 00:11:05,651
So lack of power in its own different ways can sometimes lead to false inferences, can be related to both positive and negative false inferences.

102
00:11:05,651 --> 00:11:11,691
We talk about that later. Anything else comes to mind.

103
00:11:11,691 --> 00:11:18,351
All right, so the things that's great, the things that I thought of were the ancestor differences in cases and controls,

104
00:11:18,351 --> 00:11:24,741
which I think actually ended up playing into this this particular scenario.

105
00:11:24,741 --> 00:11:31,591
Other confounding differences. Right. The small sample size, how they measured the polymorphism.

106
00:11:31,591 --> 00:11:43,881
So maybe there is measurement error in the genetic factor. And somebody you had mentioned the difference across ancestry groups.

107
00:11:43,881 --> 00:11:47,631
But of course, you know, the genetic differences aren't the only ones.

108
00:11:47,631 --> 00:11:51,591
There's all these different exposures that can differ across ancestry groups where they can differ

109
00:11:51,591 --> 00:11:57,051
across other types of groups that we may be point into our study differentially by case control status.

110
00:11:57,051 --> 00:12:04,491
Right. So, of course, you all know that. So so these are potential things that really plagued the literature.

111
00:12:04,491 --> 00:12:11,151
And it just gave this impression that genetics is not the thing that actually matters and that nothing is reproducible.

112
00:12:11,151 --> 00:12:16,461
And so there was some research to kind of investigate this.

113
00:12:16,461 --> 00:12:25,001
So like what really is going on? So this was a study that looked at publications from 1986 to 2000 and it looked at one hundred

114
00:12:25,001 --> 00:12:32,361
and sixty six putative or potential disease associations that had been identified at that time.

115
00:12:32,361 --> 00:12:37,791
And they wanted to see if there was consistent replication.

116
00:12:37,791 --> 00:12:45,541
So of all these Swifties associations, how many of them actually had consistency in the effects?

117
00:12:45,541 --> 00:12:53,991
Right. And they considered that to be a significant five percent or five and at least seventy five percent of the studies.

118
00:12:53,991 --> 00:13:01,911
OK, and they looked at a whole bunch of different diseases and they kind of tracked the publications over time.

119
00:13:01,911 --> 00:13:06,801
So these are where their new gene and disease associations were happening.

120
00:13:06,801 --> 00:13:10,611
Right. So in the early 90s that it really started to pick up.

121
00:13:10,611 --> 00:13:17,061
And then I have this question. What happened here around like 1997?

122
00:13:17,061 --> 00:13:24,661
What do you think was happening there from what I told you? Wasn't it a genome project?

123
00:13:24,661 --> 00:13:30,391
Well, actually, the genome, the Human Genome Project did start around in the in the in 2000.

124
00:13:30,391 --> 00:13:39,751
Around 2000 was when when that really started to influence our ability to look at gene disease associations.

125
00:13:39,751 --> 00:13:47,881
But even earlier than that, what I wanted to draw your attention to is that we've got these new gene disease associations being discovered.

126
00:13:47,881 --> 00:13:54,751
And it was around that time, like in nineteen ninety seven or something, that people started to be like, oh, wait, hold on a minute.

127
00:13:54,751 --> 00:14:01,591
We're finding all these things that like none of them are replicating, like we need to go back and look at our science and see if we can replicate.

128
00:14:01,591 --> 00:14:10,411
So this was like this brief moment in time where we actually tried to do replication studies before we started finding new things.

129
00:14:10,411 --> 00:14:16,411
OK, so what they found was they're very stringent, I would say definition of replication.

130
00:14:16,411 --> 00:14:21,181
They only found that six of the associations were consistently replicated.

131
00:14:21,181 --> 00:14:28,951
OK, so very low replication rate of the one hundred and sixty that were not replicated consistently,

132
00:14:28,951 --> 00:14:33,691
though the associations were often observed more than once.

133
00:14:33,691 --> 00:14:43,771
So not everything is agreeing. But you see some some degree of agreement and the potential reason for kind of things we've already talked about.

134
00:14:43,771 --> 00:14:50,161
So you could have a false positive discovery studies, right. So that the association didn't exist to begin with.

135
00:14:50,161 --> 00:14:57,781
You could have false negative replication studies. So the association did exist, but a replication didn't have power to detect,

136
00:14:57,781 --> 00:15:04,201
for example, or there could be true variability among different populations.

137
00:15:04,201 --> 00:15:11,251
Right. Actual heterogeneity in the causal effect of the genetic mutation.

138
00:15:11,251 --> 00:15:19,591
So I guess the question is, is it really false positives that are driving all of these associations that we're seeing?

139
00:15:19,591 --> 00:15:28,831
Right. So how would you maybe begin to examine that hypothesis if you were trying to look at these gene disease associations?

140
00:15:28,831 --> 00:15:37,681
Like how might you start to interrogate whether it's just a bunch of false positives and it's all.

141
00:15:37,681 --> 00:15:47,771
Often that you have any ideas. OK, well, I'll tell you what they did then,

142
00:15:47,771 --> 00:15:58,391
so they so another group focused on twenty five known disease associations and they took all

143
00:15:58,391 --> 00:16:03,811
the published studies for those twenty five associations that had been heavily investigated.

144
00:16:03,811 --> 00:16:08,171
OK, and that was a total of three hundred in one study.

145
00:16:08,171 --> 00:16:11,711
They did this thing where they excluded the very first study.

146
00:16:11,711 --> 00:16:20,921
Do you know why they did that. So we'll talk about that, too.

147
00:16:20,921 --> 00:16:29,801
So we've got these twenty five known disease associations. They've got all the studies they recorded or calculated the P values from those studies,

148
00:16:29,801 --> 00:16:33,491
and they look at the distribution of the P values and the trends.

149
00:16:33,491 --> 00:16:39,881
OK, so the first thing they did was they were starting to say, OK, let's assume, for example,

150
00:16:39,881 --> 00:16:48,851
for now that all of the studies that were done on this particular disease snip is just a mutation.

151
00:16:48,851 --> 00:16:54,521
Lesnik Disease Association. Let's assume all the papers are here.

152
00:16:54,521 --> 00:17:03,191
So if there are not true associations and everything is really due to false positives, we'd expect that to follow a normal distribution,

153
00:17:03,191 --> 00:17:08,831
essentially, and we'd expect five percent of the associations to have a P value at some point or five.

154
00:17:08,831 --> 00:17:16,871
Right. That's kind of the definition of like sort of that null distribution. So they found that actually of the 300 studies,

155
00:17:16,871 --> 00:17:23,591
almost 60 of them had less than 25 versus what they would have expected if by chance alone, which was 15.

156
00:17:23,591 --> 00:17:30,371
Right. Five out of every hundred. And so when they looked at point one, the evidence was even stronger.

157
00:17:30,371 --> 00:17:34,931
So they had twenty six versus three, which would be expected by chance one.

158
00:17:34,931 --> 00:17:42,881
So based on that, they were like, OK, it doesn't seem to be that false positives are really the sole driving factor here.

159
00:17:42,881 --> 00:17:46,371
So what other things cross your mind? As I'm telling you this,

160
00:17:46,371 --> 00:17:54,301
is there something else that another thing that could be happening where we're seeing more than we would expect by chance alone?

161
00:17:54,301 --> 00:18:01,691
It kind of hinted at it when you talked about this slide. Yeah, they're only exactly.

162
00:18:01,691 --> 00:18:06,911
They're only publishing studies with good results. Right. So that's publication bias.

163
00:18:06,911 --> 00:18:10,661
Right. Could the results be due to publication bias?

164
00:18:10,661 --> 00:18:14,531
Right. Only studies where you see a national association get published.

165
00:18:14,531 --> 00:18:18,891
So how can you investigate publication bias if you heard about this before?

166
00:18:18,891 --> 00:18:27,781
Yeah. So what are the methods that are looking at that? Would you say are some ideas that you might have?

167
00:18:27,781 --> 00:18:37,411
Yeah, well. Yeah, so, oh.

168
00:18:37,411 --> 00:18:46,571
OK, so publication bias is sort of this preferential publication of studies that achieve statistical significance, so they investigated that two ways.

169
00:18:46,571 --> 00:18:50,251
One way is what you said by looking at final thoughts.

170
00:18:50,251 --> 00:18:56,011
And then there was another way where they kind of looked at it statistically. So.

171
00:18:56,011 --> 00:19:05,221
So one thing is if if you're interested in an effect so let's say I publish a paper where I say,

172
00:19:05,221 --> 00:19:13,561
OK, the APOE Epsilon four mutation is associated with higher risk of heart disease.

173
00:19:13,561 --> 00:19:20,731
And then another study looks at that and they find that the appeal for mutation is associated with lower risk of heart disease.

174
00:19:20,731 --> 00:19:22,491
They would still want to publish that right.

175
00:19:22,491 --> 00:19:28,801
So even though it doesn't agree with my hypothesis, it's like strong evidence in support of a different hypothesis.

176
00:19:28,801 --> 00:19:32,131
Right. That's still publishable paper where it's like a null five.

177
00:19:32,131 --> 00:19:41,071
It might not be as publishable. Right. So what they did was they looked at consistency of effect, directions.

178
00:19:41,071 --> 00:19:49,381
So of the papers, whether they're finding a significant effect, those fifty nine studies that found a significant effect,

179
00:19:49,381 --> 00:19:55,981
how many of them were actually consistent with the effect direction reported by the original study?

180
00:19:55,981 --> 00:20:03,421
And they found that that was actually pretty high. So forty seven out of the fifty nine were associated in the same direction.

181
00:20:03,421 --> 00:20:06,871
Right. You expect 30 by chance alone.

182
00:20:06,871 --> 00:20:10,081
So that's doing better than chance. Right.

183
00:20:10,081 --> 00:20:20,371
And then they did this interesting thing, I thought was they tried to figure out if it was solely publication bias,

184
00:20:20,371 --> 00:20:27,691
how many studies would have actually really need to be done to get the ones that were published.

185
00:20:27,691 --> 00:20:36,391
If you just had a association so they they said, OK, the chance of replicating with a consistent effect direction is one in 40.

186
00:20:36,391 --> 00:20:43,381
That's like your point on five P value times, one half chance of replicating with the same effect direction.

187
00:20:43,381 --> 00:20:47,341
And they said that if that was the case,

188
00:20:47,341 --> 00:20:56,021
they would have had to conduct eighteen hundred and eighty studies in order to get the results of the published studies that they saw.

189
00:20:56,021 --> 00:21:02,761
So they, they were like, OK, we can't just all be publication bias because there's no way they could have conducted that many studies.

190
00:21:02,761 --> 00:21:19,921
Yeah. Researchers had previously worked for you.

191
00:21:19,921 --> 00:21:29,461
Well, my point was that, yes, they would maybe hope to see the same effect direction, but my point was that if you like,

192
00:21:29,461 --> 00:21:37,711
if you're trying to replicate something and you got the same effect or significant opposite effect,

193
00:21:37,711 --> 00:21:43,771
both of those would be likely to be published compared to a finding where you don't find an effect at all.

194
00:21:43,771 --> 00:21:52,221
Does that make sense? I might not have said that, though. Well, OK, other questions or things.

195
00:21:52,221 --> 00:21:55,741
OK, so then and then they can also look at funnel plot.

196
00:21:55,741 --> 00:22:02,761
So you may have seen these before, but these are where you have we're looking at a specific association.

197
00:22:02,761 --> 00:22:09,691
So here on the top they're looking at the association between a Bowis, probably the Epsilon for a little,

198
00:22:09,691 --> 00:22:18,541
which is not a very strong risk factor for Alzheimer's disease and heart disease, actually.

199
00:22:18,541 --> 00:22:26,731
So they're looking at people with schizophrenia, for example, and what the follow through is,

200
00:22:26,731 --> 00:22:35,321
they look at the strength of the association or the odds ratio on the on the y axis and the precision of the study.

201
00:22:35,321 --> 00:22:41,131
So the sample size basically on the x axis, how well they could they estimate the effect.

202
00:22:41,131 --> 00:22:51,541
And if you see that actually that looks like a funnel where you've got like more precise studies are going to be able to estimate the effect,

203
00:22:51,541 --> 00:22:58,771
like what it actually is. So above the line, if it's a true association and then these studies at the end that have less

204
00:22:58,771 --> 00:23:04,201
precision are still going to have like a distribution around that true effect size.

205
00:23:04,201 --> 00:23:16,351
Right. And if you see that funnel shape, it means that and you even see, like a lot of values in here at one,

206
00:23:16,351 --> 00:23:21,751
it means that all the all the subjects are probably getting published or most of the studies are getting published.

207
00:23:21,751 --> 00:23:29,251
You're not seeing a piece missing where there's no association or the opposite association, though.

208
00:23:29,251 --> 00:23:40,411
There's no one. You actually do see something a little bit weird, which is that you see a piece missing here and there is no effect.

209
00:23:40,411 --> 00:23:47,011
Right. So there could be evidence of publication bias there where there could be studies right here that don't have precision,

210
00:23:47,011 --> 00:23:53,371
that weren't published because they didn't have significant findings.

211
00:23:53,371 --> 00:24:00,581
So that's how you can start to look for that. OK.

212
00:24:00,581 --> 00:24:11,201
All right, so if then at least some of the findings are real, what really is the reason for this inconsistent replication?

213
00:24:11,201 --> 00:24:18,731
And so this paper looks at the associations that had the multiple replications

214
00:24:18,731 --> 00:24:24,431
and 11 eleven of those twenty five associations did have multiple applications.

215
00:24:24,431 --> 00:24:33,671
But even for those that were pretty consistent overall or had multiple replications, we didn't see that all studies were able to replicate.

216
00:24:33,671 --> 00:24:46,151
Right. So maybe half the studies or something like that. And then and the other associations, they had really little or weak evidence or replication.

217
00:24:46,151 --> 00:24:54,671
So in those twenty five that were super investigated, they found like half of them had evidence for some replication and half of them really didn't.

218
00:24:54,671 --> 00:25:00,111
So so we've talked about some of these possible reasons for inconsistency.

219
00:25:00,111 --> 00:25:05,771
So confounding a lot of times will lead to that false positive association.

220
00:25:05,771 --> 00:25:18,291
The lack of power can lead to the effect size overestimation, which which could then make false negative replication, something that happened.

221
00:25:18,291 --> 00:25:22,541
You can also get false positive associations when you have a lack of power,

222
00:25:22,541 --> 00:25:34,821
because the the estimate is very wide and it can if the chance causes it to be like for whatever reason,

223
00:25:34,821 --> 00:25:43,301
higher than you identify it, that can actually be a false positive association from lack of power and then true effects modification.

224
00:25:43,301 --> 00:25:47,081
So let's go through each of those with just a little bit of data.

225
00:25:47,081 --> 00:25:55,571
I don't know what happened here. OK, so this one is confounding by genetic ancestry.

226
00:25:55,571 --> 00:26:06,421
So it should say we're looking at an association between this.

227
00:26:06,421 --> 00:26:17,121
For. OK, we're looking at an association between the snip or the genetic mutation here, your disease of interest over here.

228
00:26:17,121 --> 00:26:26,091
So you're looking at this association, right, for the exposure to the disease and then ancestry is sort of your confounding variable here.

229
00:26:26,091 --> 00:26:29,631
So the snip is associated with ancestry, right?

230
00:26:29,631 --> 00:26:39,021
Because different populations from an ancestor perspective might have different mutation frequencies just because of their unique mutational,

231
00:26:39,021 --> 00:26:42,161
history, migration and things like that.

232
00:26:42,161 --> 00:26:55,251
OK, so when you have this situation where the Smith the mutation frequency differs by ancestry, you can get that positive confounded association.

233
00:26:55,251 --> 00:27:02,111
Right. So this is a huge concern in genetic studies. It can also happen in what we call admixture populations.

234
00:27:02,111 --> 00:27:07,821
So those are if you have a sample of people that come from two different ancestry.

235
00:27:07,821 --> 00:27:16,911
So African-American have European chromosome contributions, an African chromosome contributions a lot of times,

236
00:27:16,911 --> 00:27:23,661
and like the proportion of African versus European can differ across people.

237
00:27:23,661 --> 00:27:28,521
So if we do a study of African ancestry for African-Americans,

238
00:27:28,521 --> 00:27:34,281
we have to consider how much of those two different ancestries are actually in the genome,

239
00:27:34,281 --> 00:27:43,071
either on the global scale or even at the same scale, like by chromosome and chromosomal location, or else we might get confounding happening.

240
00:27:43,071 --> 00:27:51,801
That can happen in other populations, too. It's just that it depends on how different the illegal frequencies are from the ancestral populations.

241
00:27:51,801 --> 00:28:02,011
Does that make sense? OK, question about that piece.

242
00:28:02,011 --> 00:28:06,121
Another thing that we really need to think about is the of modification.

243
00:28:06,121 --> 00:28:16,681
Right. So, like, what if what if the associations really are different across groups and why so this could be due to other genes.

244
00:28:16,681 --> 00:28:26,341
So you could have modified genes, what we call modifying genes that change the effect of that mutation or some kind of environmental interaction.

245
00:28:26,341 --> 00:28:34,291
And so for the longest time when we got those when we had the issues with replication,

246
00:28:34,291 --> 00:28:39,391
people always just point to that, although like, well, you know, it's a different genetic background.

247
00:28:39,391 --> 00:28:48,001
It's a different environment. Here's the reason that it could be, but it's a very difficult hypothesis to test without a large sample size.

248
00:28:48,001 --> 00:28:55,801
And it sort of just became this catch. All the people said, you know, what's going on, but we didn't really have great evidence of that.

249
00:28:55,801 --> 00:29:00,031
So so there's lots of reasons why that could potentially exist.

250
00:29:00,031 --> 00:29:05,071
Right. We can think of biological reasons. We can think of theoretical reasons.

251
00:29:05,071 --> 00:29:11,041
Does anybody know of any actual examples that they can think of of like a gene environment

252
00:29:11,041 --> 00:29:24,951
interaction or gene gene interaction come to mind from your own work or things you've heard about?

253
00:29:24,951 --> 00:29:36,201
OK, so some things that come to mind for me are, oh, maybe we can think about let's see.

254
00:29:36,201 --> 00:29:49,531
So one that I like is there was a study done. It was probably I about 10 years ago now where they looked at the genetic risk factors for obesity.

255
00:29:49,531 --> 00:29:52,911
OK, so we did these genome wide association studies.

256
00:29:52,911 --> 00:30:00,051
We identified in some population all of the genetic mutations that might give you an increased risk of obesity.

257
00:30:00,051 --> 00:30:04,011
And using those, we calculated what is known as a genetic risk score.

258
00:30:04,011 --> 00:30:13,941
So looking at your whole genome, is your genetic risk of obesity higher or lower than what we would expect to kind of somebody with,

259
00:30:13,941 --> 00:30:21,591
you know, some reference set of mutations? OK, so you got your genetic risk for obesity.

260
00:30:21,591 --> 00:30:27,051
Then they added on whether you drank sugar sweetened beverages or not.

261
00:30:27,051 --> 00:30:34,281
OK, and combined people who drank sugar sweetened beverages that had the high genetic risk for obesity

262
00:30:34,281 --> 00:30:39,831
had a much higher chance of having a higher BMI in that study than people who did it right.

263
00:30:39,831 --> 00:30:43,671
So it's that sort of idea, like you've got your genetic predisposition,

264
00:30:43,671 --> 00:30:50,421
you've got some kind of environment that may or may not have an independent effect on your risk factor bias or of your disease by itself,

265
00:30:50,421 --> 00:30:54,711
but then you get some kind of modification of what's happening with your genetics.

266
00:30:54,711 --> 00:31:02,961
Right. OK, so like I said, there was kind of a lack of evidence for this phenomenon widespread.

267
00:31:02,961 --> 00:31:09,651
And so what that is, I did have another slide in here, but I don't have it now.

268
00:31:09,651 --> 00:31:14,361
So that's still ways that we can start to investigate that.

269
00:31:14,361 --> 00:31:19,311
For example, our kind of just the normal things that you think about when you're thinking about it.

270
00:31:19,311 --> 00:31:30,481
A regular up updates study is really like looking at the heterogeneity of effects across, for example, different groups of people.

271
00:31:30,481 --> 00:31:48,351
So if we find, you know, genetic risk factors for BMI, are they the same, for example, in men versus women and trying to get at that heterogeneity?

272
00:31:48,351 --> 00:31:52,641
Right. Because one sample might be a study of women, one sample might be a study of men.

273
00:31:52,641 --> 00:31:54,501
BMI is very different between the groups.

274
00:31:54,501 --> 00:32:04,461
And so we want to try to look at those stratified effects to see if they hold across groups and things like that.

275
00:32:04,461 --> 00:32:09,321
This is the other thing that we've been talking about, power, power, power in the region that affects.

276
00:32:09,321 --> 00:32:16,161
Right. So you've got if you have a true association, it's very difficult to reproduce if you have a weak effect.

277
00:32:16,161 --> 00:32:24,471
Right. Because you need a big sample size and you need a chance to not push it too far one way or the other.

278
00:32:24,471 --> 00:32:34,641
And so when you have replication samples that are underpowered, you can get those false negatives happening and fail to achieve significance.

279
00:32:34,641 --> 00:32:40,071
And when you're trying to estimate the sample size that you need to replicate a study,

280
00:32:40,071 --> 00:32:43,791
what do you need to calculate a sample size that to replicate a study?

281
00:32:43,791 --> 00:32:55,441
What do you need to know if you had done this before? What are the pieces that you're thinking about?

282
00:32:55,441 --> 00:33:06,811
Yeah. So the estimated size, right, so in order to calculate your sample size that you're going to need to replicate association,

283
00:33:06,811 --> 00:33:10,481
you actually need to have an estimate of what that effect sizes.

284
00:33:10,481 --> 00:33:19,231
OK, but I told you before that we have a problem with the first time somebody publishes something,

285
00:33:19,231 --> 00:33:23,941
the first time that you get a publication on a specific association.

286
00:33:23,941 --> 00:33:29,181
A lot of times it's overestimated. And that's this phenomenon called the winner's curse.

287
00:33:29,181 --> 00:33:34,861
OK, so if you have has anybody heard of this before in the winner's curse?

288
00:33:34,861 --> 00:33:42,901
OK, so so imagine that you're at an auction.

289
00:33:42,901 --> 00:33:46,441
Auction is where for those of you who aren't from the United States,

290
00:33:46,441 --> 00:33:55,261
I don't know if they have these in other countries, but basically you got something that is something that people want.

291
00:33:55,261 --> 00:34:01,141
Like let's say you're auctioning off a car. OK, everybody in the audience can bid on the car, OK?

292
00:34:01,141 --> 00:34:06,181
You can raise your hands to keep it in a higher price if you want to outbid the person before you.

293
00:34:06,181 --> 00:34:15,331
Right. So let's say that everybody in the audience collective will or let's say the true price of the car is ten thousand dollars.

294
00:34:15,331 --> 00:34:20,191
Everybody in the audience is going to have their best guess of what the true price of the car is.

295
00:34:20,191 --> 00:34:25,861
Right. So let's say that you guys are all really good at guessing the price of the car.

296
00:34:25,861 --> 00:34:31,711
But there's noise, right? There's noise in the estimates, but distributionally our estimates are onepoint.

297
00:34:31,711 --> 00:34:36,181
So if I took a mean of all your guesses, that would be a ten thousand.

298
00:34:36,181 --> 00:34:40,501
OK, but some people are going to go higher and some people are going to are going to go lower.

299
00:34:40,501 --> 00:34:47,281
Right. And that can represent sort of like that the noise or the chance or the sporadic aspects of doing a study.

300
00:34:47,281 --> 00:34:53,701
So who's going to get the car? The person that gets ten thousand know who's going to get the car?

301
00:34:53,701 --> 00:34:55,771
The highest bidder. Right.

302
00:34:55,771 --> 00:35:08,251
So that's the winner's curse is like if you've got studies that are all linked with noise estimating the true effects, if you have, for example,

303
00:35:08,251 --> 00:35:13,531
if you have a no effect, the ones that that's going to get published on that far outside,

304
00:35:13,531 --> 00:35:17,641
the one that found the highest effect size and then actually significant. Right.

305
00:35:17,641 --> 00:35:21,991
So that's the first time you reported the association is probably overestimated.

306
00:35:21,991 --> 00:35:27,121
Even if the association isn't null, you're still probably going to get an overestimate the first time,

307
00:35:27,121 --> 00:35:36,551
because the the because the studies aren't, like, so well powered that they're going to to be able to estimate it truly.

308
00:35:36,551 --> 00:35:42,961
I mean, that's the winner's curse. So that is why they excluded that first study.

309
00:35:42,961 --> 00:35:49,201
When I told you they had three hundred one papers they were looking at for those associations, that's why they exclude the first study.

310
00:35:49,201 --> 00:35:57,811
And I did a little bit here where I looked at the odds ratios here for the twenty five associations.

311
00:35:57,811 --> 00:36:07,681
So this are the odds ratio is reported in that paper where they actually took all the studies and they looked at the analysis,

312
00:36:07,681 --> 00:36:13,321
they looked at the joint odds ratio. OK, so for example,

313
00:36:13,321 --> 00:36:21,721
if they look at all the replication studies that ABQ eight was associated with Type two diabetes with the odds ratio of two point two.

314
00:36:21,721 --> 00:36:28,261
Well, I looked up the very first paper from, you know, and the odds ratio reported there was three point of one.

315
00:36:28,261 --> 00:36:37,981
Right. It's an overestimate. If you kind of stand on this, almost every single one of these examples or maybe every single one of these examples,

316
00:36:37,981 --> 00:36:49,591
the first paper actually was in overreport. But the odds ratios, some of these down here that did not have replication effects,

317
00:36:49,591 --> 00:36:53,871
that wasn't really the case, although this one this one was the one point.

318
00:36:53,871 --> 00:36:58,261
So so that's kind of just illustrating the winner's curse.

319
00:36:58,261 --> 00:37:00,691
So that's an issue.

320
00:37:00,691 --> 00:37:11,461
So the conclusions and recommendations here are false positive associations are probably abundant in that genetic literature during that time.

321
00:37:11,461 --> 00:37:17,761
True associations also exist with modest or relatively weak effect sizes.

322
00:37:17,761 --> 00:37:24,211
And this is where people started to say, we want replication in independent population, preferably more than one.

323
00:37:24,211 --> 00:37:32,371
We want large collaborative studies so that can do the analysis to really better estimate that true genetic effect.

324
00:37:32,371 --> 00:37:39,691
And we're going to try to try to publish all well powered and well conducted studies.

325
00:37:39,691 --> 00:37:42,481
So that led us to this era of genetic exhaustion.

326
00:37:42,481 --> 00:37:55,021
That's what this is me right here on the phone with a whole bunch of different people because the the genetic community to find the genetic.

327
00:37:55,021 --> 00:38:03,931
Effects for these diseases. We have to have these huge sample sizes right in the hundreds of thousands upward of 25 to 50 participating studies,

328
00:38:03,931 --> 00:38:09,631
hundreds of authors, a conference call. So this was my life for like five years.

329
00:38:09,631 --> 00:38:15,331
And this is a paper, just one example here. I mean, this was on the authors.

330
00:38:15,331 --> 00:38:22,511
Here's the rest of the author listings to be put on there. OK, this is my life because we can't do it alone.

331
00:38:22,511 --> 00:38:29,191
So, like, one independent study doesn't work. You actually have to have this accumulated evidence then.

332
00:38:29,191 --> 00:38:32,871
So the way that our field handled this was, you know.

333
00:38:32,871 --> 00:38:39,611
Oh, and just to tell you a little more about the problem. So in our genetic studies, we're not looking at candidate genes anymore.

334
00:38:39,611 --> 00:38:46,181
We're looking at all across the genome like mutations. We're trying to capture the whole spectrum of mutations across the genome.

335
00:38:46,181 --> 00:38:51,511
So these are millions of steps. We want to know if they're associated with the trait.

336
00:38:51,511 --> 00:38:55,951
OK, so the way that we do this is each cohort.

337
00:38:55,951 --> 00:39:06,211
Well, actually, whoever is really interested in the work will develop an analysis plan that will be distributed to each of the participating states.

338
00:39:06,211 --> 00:39:10,801
Each of the studies will follow the analysis plan about running associations,

339
00:39:10,801 --> 00:39:18,721
exactly how you said and we'll look in race ethnic groups separately to perfect confounding by genetic ancestry.

340
00:39:18,721 --> 00:39:28,211
And we'll also adjust for ancestry. So we'll try to look within ancestral groups individually and we'll try to adjust for admixture.

341
00:39:28,211 --> 00:39:34,741
OK, then all the cohorts will give their study results.

342
00:39:34,741 --> 00:39:42,421
So the debaters from aggression and P values for each step to somebody who analyzes that.

343
00:39:42,421 --> 00:39:47,791
And then we can also assess the heterogeneity of effects across groups by doing that.

344
00:39:47,791 --> 00:39:54,991
And then once that's all done, we find the steps that are most associated with the disease and then we replicate in another population.

345
00:39:54,991 --> 00:39:59,671
So that's how the field has handled this for probably the last 50 years.

346
00:39:59,671 --> 00:40:05,491
Well, 10 years, 10, 12 years. So I'm thinking about that.

347
00:40:05,491 --> 00:40:10,781
What do you think are the major strengths and weaknesses of that approach?

348
00:40:10,781 --> 00:40:18,101
Because there are some definite strengths, but there are also some drawbacks, too. Does anybody have any strengths?

349
00:40:18,101 --> 00:40:23,941
These are kind of things who may have already touched on yet because they're all it's going to be a more diverse group.

350
00:40:23,941 --> 00:40:27,761
You're going to get a lot of different types of individuals. Yeah, that's a great point.

351
00:40:27,761 --> 00:40:32,431
So I don't even know if I listed that. But you're going to have a lot of different groups.

352
00:40:32,431 --> 00:40:36,901
And so you're what's going to rise to the top is actually genetic effects that are crosscutting

353
00:40:36,901 --> 00:40:44,491
across different different ancestries that are included as well as different environmental factors.

354
00:40:44,491 --> 00:40:58,891
Yeah, that's a great, great point. What else? Yeah, so the power, the increased power is very important here.

355
00:40:58,891 --> 00:41:05,221
That's the key aspect, right? What about witnesses?

356
00:41:05,221 --> 00:41:13,511
Yeah, pretty extensive. How many people involved in this study?

357
00:41:13,511 --> 00:41:19,521
Yeah, so I'm not going to torture you by going on to a tangent about the funding,

358
00:41:19,521 --> 00:41:27,411
but I will just tell you that our lab has run so many jobs that aren't funded because it's so expensive right here.

359
00:41:27,411 --> 00:41:33,861
You've got all these cohorts that are trying to analyze like they all have to do the same study.

360
00:41:33,861 --> 00:41:44,691
So aside from some specific pots of money that are set aside for like the formation of construction, we barely get paid to run any of it.

361
00:41:44,691 --> 00:41:48,281
OK, I'll tell you one more thing.

362
00:41:48,281 --> 00:41:56,931
So they're so about five years ago, six years ago, the National Heart, Lung and Blood Association did this really amazing thing.

363
00:41:56,931 --> 00:42:00,861
And it was amazing where they actually pinned cohort's.

364
00:42:00,861 --> 00:42:06,681
And we're like, we want to do whole genome sequencing on your cohort because you have like,

365
00:42:06,681 --> 00:42:14,001
for example, we have African ancestry, population, a high prevalence of hypertension.

366
00:42:14,001 --> 00:42:16,011
So they wanted to do whole genome sequencing.

367
00:42:16,011 --> 00:42:23,931
So they paid for the sequencing, which is very expensive, but they paid for all these genome to be sequenced.

368
00:42:23,931 --> 00:42:29,361
And I mean, like one hundred thousand genomes. Right. But they didn't give anybody any money for analysis.

369
00:42:29,361 --> 00:42:34,221
So we're going to all of our time because we want to be part of this big project.

370
00:42:34,221 --> 00:42:38,031
Right. But we got the data.

371
00:42:38,031 --> 00:42:42,171
We got no money for analysis. So those kind of things. So it's a little tricky that way.

372
00:42:42,171 --> 00:42:46,701
All right. What other things? What's another weakness?

373
00:42:46,701 --> 00:42:53,901
Yeah, I mean, this is like my.

374
00:42:53,901 --> 00:42:59,431
Now, the. Results in.

375
00:42:59,431 --> 00:43:12,341
Yeah, so definitely so one limitation that is huge is that the analysis plans tend to be very, very rudimentary and they aren't flexible.

376
00:43:12,341 --> 00:43:18,001
OK, so if you're telling me I've got to run guys for this, treat you better,

377
00:43:18,001 --> 00:43:23,331
give me a really simple model of covariates because every single copart has to have the same covariate.

378
00:43:23,331 --> 00:43:29,161
So it's not like we're going to do something with some tricky thing. It's like age and sex.

379
00:43:29,161 --> 00:43:34,261
And if you have a study center and if you have family, you're going to you're going to be with that.

380
00:43:34,261 --> 00:43:39,601
And that's basically right. A lot of times sometimes there's like a second model.

381
00:43:39,601 --> 00:43:50,081
So, for example, when we did use of cognitive function, we did age, sex.

382
00:43:50,081 --> 00:43:56,261
I think that was that just age, sex and then age, sex and education, so two models, right?

383
00:43:56,261 --> 00:44:04,061
You can't, like, do a bunch of different variations because nobody's going to be able to go back and review that stuff.

384
00:44:04,061 --> 00:44:07,181
You can't also follow up things very easily.

385
00:44:07,181 --> 00:44:15,521
So once you get a cohort to actually send you results, it's very hard to go back and ask for, like, oh, can we follow up on this?

386
00:44:15,521 --> 00:44:19,271
Let's do a finer detail. Let's do some more models. Let's do a heritability estimate.

387
00:44:19,271 --> 00:44:25,061
Let's do so. You'll see these genetic papers. They'll have their discovery is like big,

388
00:44:25,061 --> 00:44:30,521
but then they're follow ups are going to be in just one or two cohorts because you just keep this to a larger scale.

389
00:44:30,521 --> 00:44:36,701
Right. How long do you think it takes to do this work?

390
00:44:36,701 --> 00:44:41,081
Years. Years. I have papers coming out still that I'm on that.

391
00:44:41,081 --> 00:44:45,711
I did the analysis for probably eight years ago. So it takes a long time.

392
00:44:45,711 --> 00:44:48,431
You've got to wrangle everybody. It's hard.

393
00:44:48,431 --> 00:44:56,951
So and then the other piece is that, you know, it only really captures those genetic effects that are consistent across populations,

394
00:44:56,951 --> 00:45:01,911
but it doesn't allow for any kind of gene environment urging them to change the interaction.

395
00:45:01,911 --> 00:45:06,881
OK, so now we do have like this new thing that's come up,

396
00:45:06,881 --> 00:45:12,311
which is actually now we're trying to do gene environment interaction studies across the whole genome.

397
00:45:12,311 --> 00:45:19,841
Right. So we did all the regular genomes. Now we're doing interactive studies and now we need four times as many samples and we have

398
00:45:19,841 --> 00:45:24,131
to pick the right environments and everybody's got to be able to measure that environment. Well, so like.

399
00:45:24,131 --> 00:45:32,711
Right, it's a lot. But, you know, I will say this. The stuff we find is pretty bulletproof and they're there.

400
00:45:32,711 --> 00:45:38,021
Those associations are there. So the stuff we find is there. There.

401
00:45:38,021 --> 00:45:44,351
There is one issue with that, though, is that with genetics, you can find the associations.

402
00:45:44,351 --> 00:45:53,231
But then what does it actually mean? Is a major piece like you have to do all these functional follow up studies in animal models or cell models.

403
00:45:53,231 --> 00:45:56,201
Like what? What do you do with that information? Yeah, yeah.

404
00:45:56,201 --> 00:46:05,371
I was going to ask about like to do when you're selecting what mutations to look you like from a public health perspective,

405
00:46:05,371 --> 00:46:10,601
consider mutations that are going to be like clinically significant.

406
00:46:10,601 --> 00:46:19,631
Let's say I'm going to study mutation that I know that I will be able to, you know, change or trend by making people healthier,

407
00:46:19,631 --> 00:46:25,271
for instance, versus a mutation that, you know, there's not going to be there's no effect that's going to change that.

408
00:46:25,271 --> 00:46:28,931
And so if you consider all these things, it's just I don't know.

409
00:46:28,931 --> 00:46:35,771
It's a great question. And actually, we're done with this section. So we have a couple couple more two more minutes till ten fifty one.

410
00:46:35,771 --> 00:46:36,671
We're going to take a break.

411
00:46:36,671 --> 00:46:46,901
So with the genome wide association studies, like I just described, we're actually looking at the mutational spectrum across the entire genome.

412
00:46:46,901 --> 00:46:52,091
So we're testing essentially everything that we can that we can.

413
00:46:52,091 --> 00:47:01,991
The clinical pieces and the relevant pieces come into play because we'll have a list of snips or mutations we think are important.

414
00:47:01,991 --> 00:47:07,301
Then the trick is, do those steps all together help us clinically?

415
00:47:07,301 --> 00:47:16,511
Do they add information clinically like a genetic risk, or are there specific signals that are pointing to biologically relevant genes?

416
00:47:16,511 --> 00:47:22,601
Right. So if we can get the signals, we can see the genes that are affected.

417
00:47:22,601 --> 00:47:28,241
Can we actually know learn more about the biology and learn more about potential pharmaceutical targets?

418
00:47:28,241 --> 00:47:32,201
Right. So we start broad where we look at everything now.

419
00:47:32,201 --> 00:47:38,471
Then we go deep in the in the things and try to look for the clinical relevance it used to be.

420
00:47:38,471 --> 00:47:43,301
We started with the biology, with the candidate genes, but we just didn't know enough.

421
00:47:43,301 --> 00:47:48,911
We missed a lot of stuff and so we had to start now agnostic and go the other way.

422
00:47:48,911 --> 00:47:55,701
Does that make sense? Other questions? Yeah.

423
00:47:55,701 --> 00:48:01,331
Yeah. So that's a great question, too.

424
00:48:01,331 --> 00:48:09,701
So the question was about our genome wide association studies of a truly genome wide like they have for the entire genome,

425
00:48:09,701 --> 00:48:14,111
or are they really just looking at the coding regions of genes which are called the Exon?

426
00:48:14,111 --> 00:48:20,111
And I don't know if you knew that you might know this already, but only two percent of our genome actually codes for genes.

427
00:48:20,111 --> 00:48:25,721
So the other 98 percent, it doesn't make proteins. It's mostly regulatory.

428
00:48:25,721 --> 00:48:33,611
It regulates all the genes and it makes little little tiny micro parties that that don't get made into proteins.

429
00:48:33,611 --> 00:48:39,161
They actually might have different functions in the cell. So so we do both.

430
00:48:39,161 --> 00:48:49,841
So most almost all studies that our genome wide using a broad based technology where we're measuring snips on a chip microchip technology,

431
00:48:49,841 --> 00:48:53,471
those are all almost all pretty much now genome wide.

432
00:48:53,471 --> 00:48:59,381
We do have some chips that will try to capture the variants specifically within the genes themselves.

433
00:48:59,381 --> 00:49:08,261
The benefit of looking at the exome is on the whole, they are more likely to be associated with disease because they're in those coding regions.

434
00:49:08,261 --> 00:49:11,771
And you can look at more rare variants.

435
00:49:11,771 --> 00:49:22,631
So you can precisely measure the mutations in instances where a lot of people in your sample don't have that mutation.

436
00:49:22,631 --> 00:49:28,991
So looking at Axum can be good for that. You can look at the rare variants and you can you're more likely to get a functional effect.

437
00:49:28,991 --> 00:49:38,321
But when you actually consider all that you signals, even though things in genes are more likely to be associated,

438
00:49:38,321 --> 00:49:46,181
when you look at all the signals because there's 98 percent of the genome that's not in genes, most of the signals are actually outside of the gene.

439
00:49:46,181 --> 00:49:49,001
So most studies will look genome wide approach.

440
00:49:49,001 --> 00:49:57,041
If you're doing a sequencing study, which is where you measure every single DNA piece that can be added, whole genome or full exome.

441
00:49:57,041 --> 00:50:01,781
And people started with the exome because it was cheaper and now we're moving to whole genome.

442
00:50:01,781 --> 00:50:08,521
But yeah, all those variations exist. Yeah, great question. Anything else?

443
00:50:08,521 --> 00:50:23,589
All right, cool. So let's break and come back at 11 and then we'll switch gears.

444
00:50:36,895 --> 00:50:48,385
There's no one. Why are there?

445
00:50:48,385 --> 00:51:04,505
No. All right, we're ready to get back to it, a little more energy and cleaner air.

446
00:51:04,505 --> 00:51:05,705
All right.

447
00:51:05,705 --> 00:51:13,805
So in this next section, we're just going to spend a little bit of time talking about the scientific process and how that plays in reproducibility.

448
00:51:13,805 --> 00:51:18,875
So we kind of talked before about like kind of data specific stuff.

449
00:51:18,875 --> 00:51:24,365
And now we're going to talk more about people, specific stuff like investigator related things.

450
00:51:24,365 --> 00:51:31,445
To some extent I might try to play this video for you.

451
00:51:31,445 --> 00:51:38,255
So it is funny and humor. It has humor.

452
00:51:38,255 --> 00:51:44,915
It is. It also has a swear word. And it sort of the key to that, which is the F word.

453
00:51:44,915 --> 00:51:52,955
And I think otherwise it is not a sense of humor. So hopefully it will be OK.

454
00:51:52,955 --> 00:52:01,025
So I'm going to play this for you because I, I saw this and it's really for me,

455
00:52:01,025 --> 00:52:07,715
it really captures the essence of the way that the media oftentimes thinks about science.

456
00:52:07,715 --> 00:52:14,885
Right. So we think about science as like, you know, if it's truth seeking thing and it is.

457
00:52:14,885 --> 00:52:24,455
But there's been a lot of attention actually in the media about the scientific process and about the substandard science that's out there.

458
00:52:24,455 --> 00:52:29,595
So just a bad science. So does anybody like what I see that does anything come to mind,

459
00:52:29,595 --> 00:52:34,895
like things that you've heard about or thought about or like a way that you've heard science represented or.

460
00:52:34,895 --> 00:52:40,595
Yeah, and I like the idea of the vaccines. All right.

461
00:52:40,595 --> 00:52:49,115
So, for example, when there something that I found that really rings true for people, I think a lot of times,

462
00:52:49,115 --> 00:52:55,465
like even if it's disproven over and over and over, those things stick in people's minds.

463
00:52:55,465 --> 00:53:00,995
Right. So the classic example, probably there would be about the link between vaccines and autism.

464
00:53:00,995 --> 00:53:11,285
Right. So there was a study that showed that they later found the study to be not correct and they couldn't erase that from people's minds.

465
00:53:11,285 --> 00:53:15,485
And that still plays out today. Right. Other things that come to mind.

466
00:53:15,485 --> 00:53:27,425
Yeah. So. Right.

467
00:53:27,425 --> 00:53:36,125
So the information keeps changing, right? How hard is it to tell me if there's a relationship between X and Y?

468
00:53:36,125 --> 00:53:41,555
Right. So I try not to go into it, but then I just do it anyway.

469
00:53:41,555 --> 00:53:45,935
So my partner, God bless her, is happy.

470
00:53:45,935 --> 00:53:50,765
She's got crystals just healing. And she's in such a case.

471
00:53:50,765 --> 00:53:54,785
It was so hard for me to convince her actually to get a vaccine.

472
00:53:54,785 --> 00:54:02,405
Right. Because what she kept hearing was like, she's not a scientist.

473
00:54:02,405 --> 00:54:09,605
She doesn't understand the scientific process. So she's like, Jen, you know, you said that the vaccine is effective.

474
00:54:09,605 --> 00:54:16,385
But I when I heard, you know, from some media that actually it's not completely effective.

475
00:54:16,385 --> 00:54:19,715
And even if you have the vaccine, you can get the virus. And I'm like, yes, that's true.

476
00:54:19,715 --> 00:54:23,405
But like, here's the context around and here's why it's better here.

477
00:54:23,405 --> 00:54:31,985
And I had to do so much work to explain to this person that science isn't bad or wrong just and that we learn

478
00:54:31,985 --> 00:54:37,745
things new all the time and that there's a difference between clinical trials and observational trials.

479
00:54:37,745 --> 00:54:43,865
Right. And it took me so much effort and I went with her and she's my partner and she trusts me and I'm an epidemiologist.

480
00:54:43,865 --> 00:54:50,885
Right. So so thinking about like how this comes to the general public.

481
00:54:50,885 --> 00:54:57,505
Right. The thing that people say that I hear all the time is also I think about coffee break.

482
00:54:57,505 --> 00:55:02,115
Is it good for you? Is it bad for you in this case? In that case now it's good for you know, it's bad for you.

483
00:55:02,115 --> 00:55:08,555
Again, I don't get it right. That kind of stuff is not something that people understand about science.

484
00:55:08,555 --> 00:55:15,975
Right. Are there I mean, is there anything else that comes to mind? I think these are really great examples.

485
00:55:15,975 --> 00:55:20,315
Right. So this is going to basically echo a lot of those pieces.

486
00:55:20,315 --> 00:55:26,555
I mean, it's from a while ago now, so before covid, but I think it's still kind of relevant.

487
00:55:26,555 --> 00:55:35,885
We'll see if it works. Are you all over 18?

488
00:55:35,885 --> 00:55:40,915
All right. Maybe we should do a test run of this before we try to.

489
00:55:40,915 --> 01:33:32,847
Oh, wow. Um, give me one second. Good that you are to where I used to be, I think it's totally only masquerading.

490
00:56:13,875 --> 00:56:20,775
All right, ready to it.

491
00:56:20,775 --> 00:56:26,565
Here we go, the science. So tonight we go talk about a few of the reasons why.

492
00:56:26,565 --> 00:56:34,845
And first, not all scientific studies are evil. Some might appear less than legitimate scientific journals and others might be subtly biased

493
00:56:34,845 --> 00:56:39,375
because of scientists feeling pressured to come up with all Eye-Catching positive results.

494
00:56:39,375 --> 00:56:47,445
My success as a as a scientist depends on me publishing my findings, and I need to publish as frequently as possible.

495
00:56:47,445 --> 00:56:50,025
The most prestigious outlets that I can. Now, that's true.

496
00:56:50,025 --> 00:56:55,725
Scientists are under constant pressure to publish with tenure and funding on the line and to get published.

497
00:56:55,725 --> 00:57:04,515
It helps to have results. See you. And striking because scientists know nobody is publishing a study that says nothing off with ASOL Everiss.

498
00:57:04,515 --> 00:57:09,765
And to get those results, there are all sorts of ways that consciously or not, you can tweak your study,

499
00:57:09,765 --> 00:57:18,495
you could alter how long it lasts or make your random sample too small to be reliable or engage in something that scientists call p hacking.

500
00:57:18,495 --> 00:57:20,025
That's happening with a hyphen.

501
00:57:20,025 --> 00:57:30,525
Not to be confused with [INAUDIBLE] which I don't think everyone knows is a euphemism for the Phillies on that story is very complicated.

502
00:57:30,525 --> 00:57:34,965
But it basically means collecting lots of variables and then playing with your data until

503
00:57:34,965 --> 00:57:40,005
you find something that counts as statistically significant but is probably meaningless.

504
00:57:40,005 --> 00:57:45,315
For example, the website 538 surveyed 54 people and collected over a thousand variables.

505
00:57:45,315 --> 00:57:46,335
And through peacocking,

506
00:57:46,335 --> 00:57:54,945
the results was able to find statistically significant correlations between eating cabbage and having any bellybutton drinking iced tea.

507
00:57:54,945 --> 00:58:01,225
Unbelieve Crash didn't deserve to win best picture and eating raw tomatoes and Judaism.

508
00:58:01,225 --> 00:58:09,735
I was the only thing. Tomatoes have in common with Judaism is that making them really feel quite at home in the upper Midwest.

509
00:58:09,735 --> 00:58:15,705
You don't even need to engage in these kinds of manipulations to get results that don't hold up.

510
00:58:15,705 --> 00:58:23,895
Even the best design studies can get Salukis results and the best process the science has to guard against that is the replication study,

511
00:58:23,895 --> 00:58:28,575
where other scientists reading your study and see if they get similar results.

512
00:58:28,575 --> 00:58:38,595
Unfortunately, that happens way less than it should. Replication studies are some really funded and is so underappreciated they never get published.

513
00:58:38,595 --> 00:58:43,605
No one wants to do them. There's no reward system there in place that enables that to happen.

514
00:58:43,605 --> 00:58:50,235
So you just have all of these exploratory studies out there that are taken as fact that this is a scientific fact.

515
00:58:50,235 --> 00:58:57,265
There's never actually been confirmed. Exactly. There was no reward for being the second person to discover something in science.

516
00:58:57,265 --> 00:59:00,795
There's no Nobel Prize for fact checking. And incidentally,

517
00:59:00,795 --> 00:59:13,635
there's no Nobel Prize for fact checking because a motivational poster in Brian Williams is MSNBC dressing up as scientists themselves know not

518
00:59:13,635 --> 00:59:21,015
to attach too much significance to individual studies until they're faced with a much larger context of all the work taking place in that field.

519
00:59:21,015 --> 00:59:27,465
But too often, a small study with new ones, tentative findings get blown out of all proportion.

520
00:59:27,465 --> 00:59:32,625
All right. So that's basically the gist. So is that part of what you're thinking?

521
00:59:32,625 --> 00:59:38,265
It's like, you know, we don't know what to believe. What are scientists doing?

522
00:59:38,265 --> 00:59:43,305
So what were some of the pieces in there that you think?

523
00:59:43,305 --> 01:33:32,847
What were some of the pieces in there that kind of stuck out to you that we had already talked about?

524
00:59:47,775 --> 01:33:32,847
We touched on some things that actually are real issues in this reproducibility.

525
00:59:54,945 --> 01:00:00,885
I think the pressure that researchers feel that they have published in the journals

526
01:00:00,885 --> 01:00:08,385
really do something significant and innovative in order to get that knowledge.

527
01:00:08,385 --> 01:00:17,475
So what acknowledgment? I mean, I think you mentioned, like a lot of the professors getting grants,

528
01:00:17,475 --> 01:00:24,135
they look at the type of publications that you produced just in order to get it exactly right.

529
01:00:24,135 --> 01:00:30,015
So the pressure is the funding agencies. What if they want to fund new science?

530
01:00:30,015 --> 01:00:34,485
They would never want to fund replicating. Right. They want to fund new things.

531
01:00:34,485 --> 01:00:39,495
Tenure looks at new findings like are you making a name for yourself?

532
01:00:39,495 --> 01:00:44,835
Right. That's the main thing they care about is actually what are you bringing to the scientific community?

533
01:00:44,835 --> 01:00:48,255
So it's not. Are you able to actually replicate someone else's work?

534
01:00:48,255 --> 01:00:54,915
And that's what new novel stuff. Are you free? So everybody cares about novelty and sort of these big impact things.

535
01:00:54,915 --> 01:00:58,905
And so, you know, I will tell you for sure,

536
01:00:58,905 --> 01:01:05,295
like as a genetic epidemiologist who kind of came up in my PhD during the transitional time between candidate

537
01:01:05,295 --> 01:01:12,875
Gene and was we were trying to run like whole genome association studies and these small samples and.

538
01:01:12,875 --> 01:01:16,625
Realizing that we actually needed to do the meta analysis and all the things and

539
01:01:16,625 --> 01:01:21,185
like it's impossible to to find things in your own study with those small effects.

540
01:01:21,185 --> 01:01:24,185
And there is a lot of pressure, you know,

541
01:01:24,185 --> 01:01:33,425
as a sort of junior scientist or even even as you become a more senior scientist to really actually find something significant.

542
01:01:33,425 --> 01:01:42,915
Right. So so this is a paper that I like that was called Why are most published research findings or why are they?

543
01:01:42,915 --> 01:01:52,005
Why are they most published? Research findings are false. Why are we talking about the sample size, talking about the smallest effect sizes,

544
01:01:52,005 --> 01:01:57,025
the other pieces in their time of war around that P hacking concept and things like that?

545
01:01:57,025 --> 01:02:02,865
So. So what's going on there? Has anybody heard of P hacking before?

546
01:02:02,865 --> 01:02:09,795
There are other names for it too. Like and data dredging and snooping and things like that.

547
01:02:09,795 --> 01:02:17,425
Right. So what's going on there? What's really happening in that scenario?

548
01:02:17,425 --> 01:02:22,095
Yeah, just that's what he is.

549
01:02:22,095 --> 01:02:31,365
Yeah, for my understanding, it's basically playing with your models and adding different variables or taking out the three until you get a signal.

550
01:02:31,365 --> 01:02:42,105
Right. So who does that? Who was.

551
01:02:42,105 --> 01:02:55,905
I would venture to say to some extent all, you know, because because this is one of those places where there's there's a definition of bad,

552
01:02:55,905 --> 01:02:59,835
there's a definition of perfect, and most people fall somewhere in the middle.

553
01:02:59,835 --> 01:03:05,145
Right. Most people who are doing things will take a closer look at that. Did you want to say something else?

554
01:03:05,145 --> 01:03:17,505
So you had to raise your taxes or, you know, OK, OK, OK, so one piece around that is a large number of effects are tested.

555
01:03:17,505 --> 01:03:23,645
Right. So with genetics, that's why we have to have these really tiny P values for significance.

556
01:03:23,645 --> 01:03:29,955
So in genetics, if you're doing it, you don't know to study the significance. Fine for only Carex for a million tests.

557
01:03:29,955 --> 01:03:36,435
Right. So the significance P value is five times higher than the minus eight.

558
01:03:36,435 --> 01:03:42,525
So that's because we can't use point five because we use we do so many tests.

559
01:03:42,525 --> 01:03:48,585
Right. That we have to make our significant level more stringent looking at all of these effects by chance.

560
01:03:48,585 --> 01:03:58,635
All right. Looking like they're significant. This is the studies with flexible design definitions, outcomes, an analysis.

561
01:03:58,635 --> 01:04:07,275
That's kind of what we are getting at before. Like, what can we change? Well, maybe they're not associated if we don't control for smoking.

562
01:04:07,275 --> 01:04:12,855
But now it is. If we do control for smoking, well, obviously that's the right answer to things like that.

563
01:04:12,855 --> 01:04:19,575
Some kind of played around. And we can catch that in sort of a bad light.

564
01:04:19,575 --> 01:04:27,555
But like the flip side of that is that actually those are the pieces that are important as scientists.

565
01:04:27,555 --> 01:04:34,455
Right. Like, we don't always know everything before we look at our data and we get ideas when we look at our data.

566
01:04:34,455 --> 01:04:40,815
And there's nothing wrong with that. But we have to be very mindful of how we are conducting our science.

567
01:04:40,815 --> 01:04:50,265
And we'll go into that in more detail. And then also the financial or other interest rate, which we've touched on some of those pieces already.

568
01:04:50,265 --> 01:04:53,895
So I don't know if you had a chance to sort of read the papers for today,

569
01:04:53,895 --> 01:05:02,295
but there was this really good study in nature where they actually asked researchers in all these different disciplines,

570
01:05:02,295 --> 01:05:11,655
do you think there's a reproductive reproducibility crisis behind like 90 percent of them said, at least to some extent, yes.

571
01:05:11,655 --> 01:05:16,735
And most of them thought there was a significant crisis.

572
01:05:16,735 --> 01:05:26,485
They asked, have you failed to reproduce an experiment, someone else's or your own, and, you know,

573
01:05:26,485 --> 01:05:32,005
between 60 and 80 or something, percent of people have tried to reproduce someone else's experiment.

574
01:05:32,005 --> 01:05:38,695
You failed. And this is across all the disciplines. Right. And then a lot of people can't even recreate their own results at times.

575
01:05:38,695 --> 01:05:41,155
Right. And this could be looking, you know,

576
01:05:41,155 --> 01:05:48,085
like an association between a social factor and disease in two different populations or or it could be something really straightforward,

577
01:05:48,085 --> 01:05:51,865
like we did this experiment on a cell population. We couldn't replicate it.

578
01:05:51,865 --> 01:05:55,195
Right. So all of those things could contribute. Right.

579
01:05:55,195 --> 01:06:03,945
So what do you think are some of the reasons are there any reasons that we haven't already talked about that people cited for lack of reproducibility?

580
01:06:03,945 --> 01:06:08,575
Is there anything else that that comes to mind?

581
01:06:08,575 --> 01:06:17,465
So as you're thinking about conducting the science, have you ever tried to reproduce what somebody else did?

582
01:06:17,465 --> 01:06:21,815
What you know, not an easy thing. Why not?

583
01:06:21,815 --> 01:06:27,665
What are the things that we're missing? What's what's going on with that, you think?

584
01:06:27,665 --> 01:06:39,995
Yeah. Yeah, so, I mean, the devil's in the details, right, and so so we write these papers and they have word limits and we're like,

585
01:06:39,995 --> 01:06:45,695
OK, we're going to discuss the methods down and we basically get these things. But when you actually get the data, you try to do it.

586
01:06:45,695 --> 01:06:49,925
There's a lot of details missing. You don't really know how to handle stuff. Right.

587
01:06:49,925 --> 01:06:52,855
So that's that's a huge one. Is there anything else that comes to mind?

588
01:06:52,855 --> 01:07:02,305
Yeah, it's hard because you don't want the scientific community to think you're just like.

589
01:07:02,305 --> 01:07:04,575
Like plagiarism,

590
01:07:04,575 --> 01:07:11,835
like the fact that you're just doing the same thing and how you want to tweak your word so it doesn't look like something that has been done.

591
01:07:11,835 --> 01:07:16,395
So I think that part is. Yeah. So there's two pieces here, right?

592
01:07:16,395 --> 01:07:22,965
One is the value of reproducing is reproducibility is not valued for multiple reasons.

593
01:07:22,965 --> 01:07:27,495
Right. And so one other one is we don't want people to think that we're just copying other people.

594
01:07:27,495 --> 01:07:32,805
Right. So, like, why are we going to do that then? Other pieces if we try to do it for whatever reason.

595
01:07:32,805 --> 01:07:40,845
So, for example, when I was a student was when we started putting all this genetic data up on DVD.

596
01:07:40,845 --> 01:07:46,275
And how many people have heard of that before? Just a few people, probably. It's a database of genotypes and phenotypes.

597
01:07:46,275 --> 01:07:53,895
And so if your study is NIH funded, you have to submit your genetic data to a public repository.

598
01:07:53,895 --> 01:08:04,125
And so people would publish these papers using data IDBI So you'd have the data and I remember my friend at the time who was also a student,

599
01:08:04,125 --> 01:08:07,155
was like went through all this to get the data from the again,

600
01:08:07,155 --> 01:08:12,975
like tried to follow the method and I completely couldn't replicate at all what the person had.

601
01:08:12,975 --> 01:08:17,715
Right. So those kind of issues are even worse because he wanted to build off of that.

602
01:08:17,715 --> 01:08:21,705
Right. Let's start with what they did. Make sure we can do it now. We're going to extend it.

603
01:08:21,705 --> 01:08:27,375
Right. So that's a good reason to replicate. Couldn't do it. Could never do it.

604
01:08:27,375 --> 01:08:34,575
So reasons are which we've already talked about. A lot of it is pressure to publish selective reporting, low power.

605
01:08:34,575 --> 01:08:40,995
The original lab put out bad work. It wasn't replicated there, insufficient oversight and monitoring.

606
01:08:40,995 --> 01:08:47,685
So a lot of you are PhD students or master students who are working on projects.

607
01:08:47,685 --> 01:08:54,855
And you can probably see how thin a lot of your mentors are spread.

608
01:08:54,855 --> 01:08:57,045
So it's not that they don't want to be good mentors,

609
01:08:57,045 --> 01:09:05,475
but they also have like the time and energy to be like a mentor that can actually really oversee everything.

610
01:09:05,475 --> 01:09:10,075
So that's an issue in academia methods and coder unavailable.

611
01:09:10,075 --> 01:09:18,105
The original data is unavailable. Notice that insufficient peer review, which I could go on and on about, but I won't.

612
01:09:18,105 --> 01:09:26,175
And most people I mean, some people say they think it's due to fraud, but that's not really the main concern.

613
01:09:26,175 --> 01:09:28,575
So it is fraudulent science,

614
01:09:28,575 --> 01:09:38,385
but mostly it's people doing the best they can that to what extent or another are just doing things that aren't really great practice.

615
01:09:38,385 --> 01:09:44,835
So what are some ways that good corrective answers could be or some corrective actions that we can take?

616
01:09:44,835 --> 01:09:56,895
But how do we change that? How do we address these issues as scientists?

617
01:09:56,895 --> 01:10:00,465
Yeah, I mean, the woman in the video mentioned, like, there is no reward,

618
01:10:00,465 --> 01:10:12,435
so there has to be some reward system and in some ways, yeah, for actually verifying things other people have found.

619
01:10:12,435 --> 01:10:21,955
Yeah. Right, exactly.

620
01:10:21,955 --> 01:10:31,425
So we need to hold people to a higher standard in terms of reporting, in terms of making things available, in terms of, you know, being transparent.

621
01:10:31,425 --> 01:10:37,115
Right. So we'll talk about some of those standards, too. So I think both of those things are kind of exactly what I was looking for.

622
01:10:37,115 --> 01:10:43,445
Right. As a scientific culture, we need novel and positive findings.

623
01:10:43,445 --> 01:10:48,995
Sorry, we have novel and positive findings. Incentivize and replication studies are undervalued.

624
01:10:48,995 --> 01:10:54,275
Everybody wants the groundbreaking work. And then there's also financial incentives that do plan.

625
01:10:54,275 --> 01:11:00,215
Right, not just things like tenure raises and things like that,

626
01:11:00,215 --> 01:11:06,935
but also if you're working with companies, there can be, you know, kind of competing interests there.

627
01:11:06,935 --> 01:11:14,105
We've talked about publication bias, substandard practices and blatantly fraudulent science as potential reasons.

628
01:11:14,105 --> 01:11:18,285
Also noticing that the pace of publishing is really increasing.

629
01:11:18,285 --> 01:11:23,795
So how many of you have heard of predatory journals?

630
01:11:23,795 --> 01:11:32,165
Right. So these are journals where, you know, they might say they're peer reviewed, but the peer review is very weak if it happens at all.

631
01:11:32,165 --> 01:11:36,935
I give you an article where they were like, get me off. Your mailing list was published.

632
01:11:36,935 --> 01:11:41,375
Like, this is the paper that it just said that over and over again. And it was actually published like this.

633
01:11:41,375 --> 01:11:44,705
Somebody sent it. And that is like a trial, right?

634
01:11:44,705 --> 01:11:50,135
Because these predatory journals, they want you to send in your work and then pay them to publish it.

635
01:11:50,135 --> 01:11:53,825
Right. So it's like a money making scheme. And they they're out there.

636
01:11:53,825 --> 01:12:02,555
And then there are some that are more in between where, like the peer review is just very weak, you know, but people want to publish their work.

637
01:12:02,555 --> 01:12:11,195
And so, so much stuff gets out there. The other thing that's happened is that peer review becomes compromised because peer review is right.

638
01:12:11,195 --> 01:12:16,805
When you as a scientist are reviewing the work of all your fellow scientists and you don't usually get paid for it.

639
01:12:16,805 --> 01:12:20,915
You know, sort of the reward is like keeping the standard in your scientific community.

640
01:12:20,915 --> 01:12:27,195
Right. Or, you know, if you're on grant review panels, like you can meet other people.

641
01:12:27,195 --> 01:12:35,075
But like if you're just reviewing the manuscript, it's kind of just to hold everybody to the same standard in the field and to say you've done it.

642
01:12:35,075 --> 01:12:47,165
So if you have all these publications, like what's going into each individual publication is a lot less in a sense, like the rigorous of the science.

643
01:12:47,165 --> 01:12:51,395
This is much less. But there's so many more papers to reveal, right.

644
01:12:51,395 --> 01:13:00,605
So everybody gets overwhelmed. And we talked about this a little bit before, is that most most of the initial results, too, are never written up.

645
01:13:00,605 --> 01:13:16,265
Right. So for strong results, there was this study and they found that for strong results, like 63 percent were published in the journal of some kind.

646
01:13:16,265 --> 01:13:25,505
And and then between like another 30 percent were unpublished, but written so probably will get published.

647
01:13:25,505 --> 01:13:30,245
So if you have a strong finding, it will eventually probably make its publication.

648
01:13:30,245 --> 01:13:38,255
If you have no finding about 65 percent of the results, people are saying they're just unthreatened, like we never even wrote it up.

649
01:13:38,255 --> 01:13:49,205
Right. So that's the publication bias piece on. And so so that that was a study that looks across disciplines and across countries

650
01:13:49,205 --> 01:13:59,885
and basically found that the results are not in the literature anymore. And this was like, I don't know if you guys you guys ever read this.

651
01:13:59,885 --> 01:14:06,455
It's piled higher and deeper. And I did, too, when I was back in the day.

652
01:14:06,455 --> 01:14:14,425
But basically, this is like talking about the scientific method and what's supposed to happen and what actually happened.

653
01:14:14,425 --> 01:14:21,425
So the scientific method that we all learned in third grade, you observe a phenomenon or maybe sixth grade, I don't know,

654
01:14:21,425 --> 01:14:28,115
formulate a hypothesis about it, test it rigorously, then you can maybe modify the hypothesis, test it again.

655
01:14:28,115 --> 01:14:31,685
Right. And then establish a theory based on repeated validation of the results.

656
01:14:31,685 --> 01:14:42,515
But like in reality, what tends to sort of happen at times is we make up a theory based on what the funding agency wants to be true.

657
01:14:42,515 --> 01:14:52,295
We design some sort of minimum level of experiments that could prove or show or suggest that this theory is true.

658
01:14:52,295 --> 01:14:59,585
You can modify your theory to fit the data, publish the paper and rename the theory a hypothesis and pretend like you use a

659
01:14:59,585 --> 01:15:03,515
scientific method and then defend the theory despite all evidence to the contrary.

660
01:15:03,515 --> 01:15:11,585
And obviously, like it's not really blown out of proportion when you think about the way that some people approach science.

661
01:15:11,585 --> 01:15:19,305
But like, that's what we're pushed into is scientists a lot of times. And so it's important to really think about that process and make sure.

662
01:15:19,305 --> 01:15:26,595
That you're holding yourself to a standard and the others around you to a standard where you're not actually doing that to the extent possible.

663
01:15:26,595 --> 01:15:32,295
Right. And so this is a little bit about he had here.

664
01:15:32,295 --> 01:15:39,945
So this is basically what we talked about before, like trying to multiple things until you get the desired result.

665
01:15:39,945 --> 01:15:48,255
And, you know, if you have to have less than 25 life, you know, you tested six, six different models or something.

666
01:15:48,255 --> 01:15:53,145
And one of them is significant. Then there's the temptation to report that.

667
01:15:53,145 --> 01:16:00,285
And also, I've been in this business long enough to know that you can make up a story about anything.

668
01:16:00,285 --> 01:16:11,235
Right. Anything that you find, you can say, oh, that makes sense, because this and it's not dishonest, but it is problematic.

669
01:16:11,235 --> 01:16:21,655
Yeah, I papers and some papers.

670
01:16:21,655 --> 01:16:27,025
Yes, so when you're talking about protocol papers, are you talking about so there's two different things that I'm thinking about.

671
01:16:27,025 --> 01:16:37,885
One is when you write a study protocol and you publish it in like a like a database, like you put it into a database and it's there.

672
01:16:37,885 --> 01:16:39,715
And so when you actually publish your results,

673
01:16:39,715 --> 01:16:43,525
people can go back and look at your protocol and make sure that you were following the scientific method.

674
01:16:43,525 --> 01:16:44,635
That's one thing.

675
01:16:44,635 --> 01:16:54,055
Then there's actually just writing up like actually publishing in a journal, like for a study like how the data were collected and all of that.

676
01:16:54,055 --> 01:16:58,285
So which are you talking about? The first one. The second one.

677
01:16:58,285 --> 01:17:08,125
So I think it depends a lot on your sort of discipline and how things go there.

678
01:17:08,125 --> 01:17:14,515
So to me, what you're talking about is sort of like like here's this cohort that we're

679
01:17:14,515 --> 01:17:18,055
developing and here's all the characteristics for the Cold War and things like that.

680
01:17:18,055 --> 01:17:25,075
Right. So that's an informational paper that will describe like if people want to use that data or if you have,

681
01:17:25,075 --> 01:17:29,035
like, papers that use that data, you can refer back to it.

682
01:17:29,035 --> 01:17:36,775
Right. I think that and that if you're establishing a new cohort, it's not a terrible thing to do,

683
01:17:36,775 --> 01:17:45,605
but it doesn't necessarily solve the issue of like all the different data analysis that's going to be done on that cohort.

684
01:17:45,605 --> 01:17:49,675
Does that make sense? But that's a really good it's a really good idea.

685
01:17:49,675 --> 01:18:02,075
I think it's to of get those pieces out there. OK, so then we've talked a little bit about the hacking and the motivations.

686
01:18:02,075 --> 01:18:10,045
A lot of times people aren't trying to be intentionally devious, like they really believe the hypotheses, but there's ambiguity in how to analyze it.

687
01:18:10,045 --> 01:18:16,315
So if you've ever sat there with a bunch of data and SAS and you're like, oh,

688
01:18:16,315 --> 01:18:21,895
I have to do a research question for my P, like, I think I'm interested in this research question.

689
01:18:21,895 --> 01:18:27,845
How the heck do I analyze it? Like, you know, it's a lot of different ways you can think about that data and put it together.

690
01:18:27,845 --> 01:18:36,865
Right. So so I did put on here I was going to show you, but I think it's complicated with all of the pieces.

691
01:18:36,865 --> 01:18:40,315
So there is this website, 538. I don't know if you've heard of it,

692
01:18:40,315 --> 01:18:55,195
but it's kind of interesting to kind of try to look at different pieces around science and things and come up with some, I don't know, commentary.

693
01:18:55,195 --> 01:19:04,435
So if you actually use that, there's this article called Sciences in Brooklyn, which I gave you and I really like this with.

694
01:19:04,435 --> 01:19:16,315
It's basically like a little software thing where you can click on different options and to analyze data and look at the associations.

695
01:19:16,315 --> 01:19:22,855
And depending on what your hypothesis is, you can click the right combination of data like real data.

696
01:19:22,855 --> 01:19:26,395
It's real data to actually make that hypothesis true.

697
01:19:26,395 --> 01:19:31,045
So it's based on political affiliation and the economy.

698
01:19:31,045 --> 01:19:37,645
So like, if if people of one political party are in office, what does the economy look like in these different metrics in the economy,

699
01:19:37,645 --> 01:19:43,945
like GDP and employment and all that stuff, different kinds of politicians.

700
01:19:43,945 --> 01:19:50,815
And you can basically show that the economy is good when Democrats are in power and you

701
01:19:50,815 --> 01:19:54,755
can show the economy's bad when Democrats are in power and then both Republicans do.

702
01:19:54,755 --> 01:20:01,125
So I actually really like that website. I thought it was very illustrative.

703
01:20:01,125 --> 01:20:10,995
OK, so different strategies that people might implement that can kind of go on this hacking track or like stop collecting data when you get it,

704
01:20:10,995 --> 01:20:16,965
point of five tests, multiple things, tweak the methods like that or take away covariates,

705
01:20:16,965 --> 01:20:24,285
try different kinds of modeling strategies and then excluding different participants or selectively exclude outliers.

706
01:20:24,285 --> 01:20:30,645
And I think we could go through this list and with the exception of maybe the first one,

707
01:20:30,645 --> 01:20:34,635
make a very strong scientific argument for why you might do those things.

708
01:20:34,635 --> 01:20:41,895
Right. But here's kind of the evidence of where that's led us.

709
01:20:41,895 --> 01:20:48,435
So this is the ratio of publication with results between point of five to point six.

710
01:20:48,435 --> 01:20:57,605
So, like, just not significant in red and then point out four point four, nine in blue.

711
01:20:57,605 --> 01:21:03,855
So, like, just barely significant and not significant. It's looking at a good number of papers.

712
01:21:03,855 --> 01:21:12,915
Right. And you can see over time that around 1990, both of those kind of results had a similar chance of being published.

713
01:21:12,915 --> 01:21:19,605
But now there's this huge gap, right, where it's pretty obvious that publication bias is coming into play here.

714
01:21:19,605 --> 01:21:23,125
Right. And potentially right.

715
01:21:23,125 --> 01:21:29,805
We don't know exactly which one is happening, but probably, you know.

716
01:21:29,805 --> 01:21:37,545
Yes. Do you think that a lot of this is happening where we're seeing a lot more people overnight?

717
01:21:37,545 --> 01:21:46,065
Do you think that journalists and selective publications only publish or do you think there's also some aspect where people,

718
01:21:46,065 --> 01:21:51,435
researchers aren't even submitting because they just don't think it matters? Oh, I think it's both.

719
01:21:51,435 --> 01:21:58,275
I think that it's hard to get it to journalists like even middle tier journalists with no results.

720
01:21:58,275 --> 01:22:05,145
So, I mean, that's definitely a disincentive if you're I mean, writing papers takes a lot of time.

721
01:22:05,145 --> 01:22:09,675
So you don't you don't want to write for no reward if you can't give in the journals.

722
01:22:09,675 --> 01:22:18,645
But also because, like in genetics, it's a really clear a clear difference between a positive finding.

723
01:22:18,645 --> 01:22:21,705
And I'll find it because like with some discipline,

724
01:22:21,705 --> 01:22:29,685
no findings are kind of meaningful in a way and in genetics because you're looking at so many things across the genome.

725
01:22:29,685 --> 01:22:35,245
It's like everything is normal until you find the one thing that isn't right.

726
01:22:35,245 --> 01:22:40,425
And so I think it depends a little bit on the discipline. It depends on the reward structure around.

727
01:22:40,425 --> 01:22:43,695
Write nothing up.

728
01:22:43,695 --> 01:22:49,185
What I said is that the genetic one? You know what I mean?

729
01:22:49,185 --> 01:22:54,615
Right. Have you guys heard of this before, Hakin?

730
01:22:54,615 --> 01:22:56,625
This is one that was kind of new to me.

731
01:22:56,625 --> 01:23:04,965
So this is a concept that I feel like might be more applicable to other disciplines that are very strongly theory based.

732
01:23:04,965 --> 01:23:12,765
So a lot of times I think of epidemiology a little bit more agnostic where you're kind of like looking at the distribution of exposures,

733
01:23:12,765 --> 01:23:18,645
looking at the disease, and then it kind of seems like you don't necessarily have to have a really strong

734
01:23:18,645 --> 01:23:24,105
directional hypothesis about what's going on to observe an association and then explain it.

735
01:23:24,105 --> 01:23:32,145
So this might be a little bit more like for scientists, I think, that are more like the social sciences and things like that.

736
01:23:32,145 --> 01:23:37,275
But one thing that people talk about is hypothesizing after the results are known.

737
01:23:37,275 --> 01:23:45,645
So this is the idea that, you know, basically you see something in your results, you make a hypothesis from it,

738
01:23:45,645 --> 01:23:53,715
and then you purposefully make people think that you set out to test that one hypothesis and that one hypothesis is only right.

739
01:23:53,715 --> 01:24:04,365
And so that can be discounted. But I do think that, like in the when you when you start agnostically, then it's called results interpretation.

740
01:24:04,365 --> 01:24:07,995
But you don't necessarily like, make the reader think that that's what you tested.

741
01:24:07,995 --> 01:24:11,235
It's only what you just said. You did it. One directional test you did.

742
01:24:11,235 --> 01:24:20,685
Right. So that's where the line, I think is there. OK, so the solutions I think we've talked a lot about.

743
01:24:20,685 --> 01:24:26,265
So for me, when I was thinking about it, to me it's like a culture shift and a personal commitment.

744
01:24:26,265 --> 01:24:34,725
Right. So a personal commitment as a scientist to be conscious of the temptation for substandard science,

745
01:24:34,725 --> 01:24:43,965
to be vigilant in our own research practices and in our own mentorship and then working to change those incentive systems in academia.

746
01:24:43,965 --> 01:24:48,165
So this could be like, is there a way to reward replication studies?

747
01:24:48,165 --> 01:24:55,935
Is there a way to reward high quality instead of quantity and reward for performing peer review,

748
01:24:55,935 --> 01:25:02,325
which basically, like I said, is unpaid but incredibly important work?

749
01:25:02,325 --> 01:25:06,615
This thing about quality instead of quantity, I feel like it can get problematic.

750
01:25:06,615 --> 01:25:15,285
So so there are some departments in schools where they're going to just basically be bean counters.

751
01:25:15,285 --> 01:25:19,095
They're like, how many public how many publications do you have? Do you have this many?

752
01:25:19,095 --> 01:25:22,845
First of all, there's many laughs out there. That's OK. You're good, right?

753
01:25:22,845 --> 01:25:27,165
And all your promotion decisions and all this stuff will be based on that.

754
01:25:27,165 --> 01:25:35,955
There are other ones that are sort of like trying to get more at like, are you a visionary in your field?

755
01:25:35,955 --> 01:25:39,765
Are you presenting at conferences where you are able to be a leader?

756
01:25:39,765 --> 01:25:43,935
Are you, you know, like those other things? Are you in high quality journals?

757
01:25:43,935 --> 01:25:48,435
Right. And so that's why we've developed all those metrics in journals like The Impact Factor.

758
01:25:48,435 --> 01:25:52,605
And then we've got the heat index and like individual people metrics.

759
01:25:52,605 --> 01:25:56,745
Right. And so all schools and disciplines to do that differently.

760
01:25:56,745 --> 01:26:00,855
So this is arguing more for a high quality.

761
01:26:00,855 --> 01:26:07,905
Right, because if you really are someone who wants to do high quality work, it will take you a lot longer to make papers.

762
01:26:07,905 --> 01:26:14,895
Right. So the quantity will probably go down. Depends but can be.

763
01:26:14,895 --> 01:26:22,815
And then the pre specified study protocols, so specifying the aspects of the study before they even begins, including a core analysis plan.

764
01:26:22,815 --> 01:26:33,465
So there's a place where you can register an actual protocol for analysis, like sort of her analysis plan and databases like open science framework.

765
01:26:33,465 --> 01:26:37,975
And what you basically do there is you include your analysis plan.

766
01:26:37,975 --> 01:26:42,525
So you talk about, you know, you describe your study, but then you talk about the hypotheses.

767
01:26:42,525 --> 01:26:49,935
You'll test how you're going to do the variables, how you're going to do the models if you have multiple outcomes or different multiple

768
01:26:49,935 --> 01:26:56,295
hypothesis testing and you kind of describe it all there before you dig into your data.

769
01:26:56,295 --> 01:27:04,695
So it's published into that database. And so when your paper comes out, people can trust more that you actually didn't do a bunch of data.

770
01:27:04,695 --> 01:27:09,555
Fregene, that it actually was always out there. Right. So what do you think of the.

771
01:27:09,555 --> 01:27:24,495
I think we've covered a lot of the pros of the analysis plans, but what do you think are the drawbacks to prespecified analysis plans?

772
01:27:24,495 --> 01:27:30,315
Yeah, there's another team that's kind of looking at the same research you're doing,

773
01:27:30,315 --> 01:27:34,815
you'll be giving them the lead and going back to the novelty part.

774
01:27:34,815 --> 01:27:38,185
Well, that's that's a great point. I actually hadn't considered that until now.

775
01:27:38,185 --> 01:27:46,375
But basically, you're giving people the opportunity to see your thought process and all your planning and they can kind of scoop that, right?

776
01:27:46,375 --> 01:27:58,255
That's a great point. I didn't think about that. What else? Yeah.

777
01:27:58,255 --> 01:28:03,415
Then you just go from. Right.

778
01:28:03,415 --> 01:28:07,255
So then there's not always built in flexibility. Right.

779
01:28:07,255 --> 01:28:12,415
You almost got yourself into a corner. And now what if a new method comes along?

780
01:28:12,415 --> 01:28:21,715
What if a new idea comes along? Now, you you kind of like, oh, people are going to think that it's not legit because I didn't say it to start with.

781
01:28:21,715 --> 01:28:28,215
Right. That's a huge limitation for anything else.

782
01:28:28,215 --> 01:28:35,655
OK, so essentially we've got the pros are what we've talked about, it can increase confidence in results.

783
01:28:35,655 --> 01:28:40,605
There's not a lot of burden relatively in lining up in somebody else's claims.

784
01:28:40,605 --> 01:28:50,895
If you're going to write your analysis plan anyway, find out or at least have some idea about it becomes really are those optimal analysis?

785
01:28:50,895 --> 01:28:55,245
There might be unforeseen decision points, right? That's the huge thing.

786
01:28:55,245 --> 01:28:58,725
You can't always see what's coming and you're going to have to make decisions.

787
01:28:58,725 --> 01:29:07,335
And so if you can write a plan with flexibility, sort of incorporated, that's maybe the best piece because you've got to find that balance right.

788
01:29:07,335 --> 01:29:13,725
It can also reduce new and unexpected findings because of that lack of flexibility and that you can't easily incorporate those

789
01:29:13,725 --> 01:29:20,745
advances in the field that are going to come certainly between the time you submit your plan and the time that you publish your paper.

790
01:29:20,745 --> 01:29:29,265
So some solutions to the publication pressure issue, selective reporting, substandard science are mostly things we've talked about.

791
01:29:29,265 --> 01:29:40,405
So the data availability in the methods, transparency, including the clear, transparent and complete methods and results is really important.

792
01:29:40,405 --> 01:29:45,825
So a lot of journals now you can publish your paper unless you're also publishing your

793
01:29:45,825 --> 01:29:51,705
data and some of them require you to do now like like your code and things like that.

794
01:29:51,705 --> 01:29:56,835
Or they strongly advise that. Right, because because they want people to be able to really see what you did.

795
01:29:56,835 --> 01:30:04,755
Right. Then there are sort of reporting guidelines around like all the things you need to report that you do.

796
01:30:04,755 --> 01:30:08,235
And then there's this issue around the culture of journals. Right.

797
01:30:08,235 --> 01:30:13,185
And so, like I said, they're starting to require a lot of different pieces.

798
01:30:13,185 --> 01:30:19,575
Journals for genetics have required replication now since 2011 or 12.

799
01:30:19,575 --> 01:30:28,515
So after the first two years of GW came out like you can't get a G was published about replication, basically.

800
01:30:28,515 --> 01:30:38,135
Which is good, which is good. And this last piece is there are some transparency and openness, promotion guidelines are top guidelines.

801
01:30:38,135 --> 01:30:46,815
So this is community driven efforts, some kind of grassroots at the scientists level to align the scientific ideals and the actual practices.

802
01:30:46,815 --> 01:30:55,695
And so this is kind of a group that's really advocating for an open and transparent research culture where people are held accountable,

803
01:30:55,695 --> 01:31:04,425
basically every level. So so thinking about all these different kinds of standards for citations, for methods,

804
01:31:04,425 --> 01:31:10,185
transparency, design, transparency, the preregistration of the analysis plan,

805
01:31:10,185 --> 01:31:19,425
data research materials, the preregistration of studies, or the sort of cohort descriptions of studies and then also replication.

806
01:31:19,425 --> 01:31:29,405
Right. So they have these guidelines around all of that stuff. So I think those are all important pieces.

807
01:31:29,405 --> 01:31:35,285
Do you have any other questions or commentary or things that came up around that?

808
01:31:35,285 --> 01:31:42,785
Yeah. So sometimes.

809
01:31:42,785 --> 01:32:03,295
Yes, I am. Yes, so that is a great example of how two sets of ideals come head to head and clash with each other,

810
01:32:03,295 --> 01:32:08,755
so the openness of data and the protection of human subjects are two things,

811
01:32:08,755 --> 01:32:15,595
that it's a very difficult balance sometimes to work within the best practices for both.

812
01:32:15,595 --> 01:32:23,185
And so there are a lot of times when if you're using human data, if you're IRP says you can't share the data,

813
01:32:23,185 --> 01:32:30,025
you just can't share the data, and you have to provide a good justification for that to the journals.

814
01:32:30,025 --> 01:32:37,155
And at least so far, they will take those justifications. Right, because our primary concern is to protect the people.

815
01:32:37,155 --> 01:32:43,225
Right. But if you're using data like like for example, we have gene expression data,

816
01:32:43,225 --> 01:32:50,005
which is not really regulated in the same way because irony's because it's not independently like individually identifiable.

817
01:32:50,005 --> 01:32:50,995
Right.

818
01:32:50,995 --> 01:33:01,885
So in that kind of situation, we will get pushed to publish that, I'm sure, a publicly available sort of registry or to link that to our papers.

819
01:33:01,885 --> 01:33:07,585
But if there is truly Manabe issue, they will honor that usually.

820
01:33:07,585 --> 01:33:12,615
Good questions. Other questions. Cool.

821
01:33:12,615 --> 01:33:25,035
Well, thanks, guys, for having me come and go forth and keep being great scientists and your genetics if you want.

822
01:33:25,035 --> 01:33:32,847
Bye bye. I knew that.

