1
00:00:10,200 --> 00:00:15,570
Okay. So thank you all for spending your Thanksgiving eve with me.

2
00:00:16,020 --> 00:00:22,710
I'm sure this is probably one of the last classes that you have before the break, and I appreciate you being here.

3
00:00:24,600 --> 00:00:30,600
So today we will be talking about counter bias analysis.

4
00:00:31,830 --> 00:00:37,860
But before we get to that, I just wanted us to have a recap of some of the material that we've gone through so far.

5
00:00:39,840 --> 00:00:45,030
So I think I'm going to have to put this in presentation mode.

6
00:00:45,450 --> 00:00:48,660
So if you have not already finished, kick you off.

7
00:00:54,740 --> 00:00:57,799
Okay. So some reasons that we don't like odds ratios.

8
00:00:57,800 --> 00:01:02,120
There are many of these. They are not collapsible.

9
00:01:03,530 --> 00:01:08,630
Yeah. I mean, it's not bias, but they can appear larger odds as confusing.

10
00:01:09,170 --> 00:01:20,750
They're hard to interpret. I think those are all great, great reasons because I guess, okay.

11
00:01:20,900 --> 00:01:27,260
They're thinking of a counterfactual comparison for hydroxychloroquine as a malaria prophylactic.

12
00:01:28,910 --> 00:01:31,700
So what is the counterfactual comparison?

13
00:01:31,700 --> 00:01:37,670
I think the easiest way to do this is to kind of have the time travel analogy, which many of you are doing it.

14
00:01:38,690 --> 00:01:47,880
You can kind of like simplify it a bit. Like I think somebody wrote What would happen with your malaria outcome if you did use hydrochloric acid?

15
00:01:47,960 --> 00:01:53,990
Q Hydroxychloroquine versus if you did not? And so I think that that that makes sense.

16
00:01:53,990 --> 00:01:58,310
The time travel is nice because then, like everything else in their life is equal.

17
00:02:00,440 --> 00:02:05,659
Of course you can think about, oh, what if we did like some sort of experimental comparison,

18
00:02:05,660 --> 00:02:09,080
you know, maybe that that can kind of sort of get at that idea.

19
00:02:09,410 --> 00:02:20,180
I think some of you are thinking also about I think somebody wrote about controlling for some other variables, but.

20
00:02:24,120 --> 00:02:29,180
Yeah. I mean, I think most of you are getting this, which is great. Okay.

21
00:02:29,810 --> 00:02:36,620
And then what are the limits to using race in causal inference?

22
00:02:37,460 --> 00:02:42,920
Some really good responses here. I mean, it's very highly correlated with many other things.

23
00:02:44,240 --> 00:02:49,700
I think the counterfactual is a great way to think about this because there's not a real great race counterfactual.

24
00:02:49,700 --> 00:02:52,760
Like what would it mean to go back in time and change somebody's space?

25
00:02:52,790 --> 00:02:57,619
I think it gets a bit perplexing, but I think, you know,

26
00:02:57,620 --> 00:03:03,730
what is important to think about is like what does race overlap on to or does it overlay on to?

27
00:03:03,740 --> 00:03:10,370
And there can be all sorts of other things like discrimination, environmental exposures.

28
00:03:10,790 --> 00:03:17,060
So yeah, I think those are probably what race is being a proxy for in most of our analysis.

29
00:03:19,130 --> 00:03:22,220
Okay. So this is really, really good. I like a lot of your responses.

30
00:03:24,490 --> 00:03:27,820
Okay. On a natural a direct effect.

31
00:03:27,970 --> 00:03:36,070
When we think of hydroxychloroquine as the main exposure and the mediator is inflammation and the outcome is malaria.

32
00:03:37,990 --> 00:03:45,070
And this is this is a bit iffy. Some of your responses are getting, you know, natural direct effects are a bit confusing.

33
00:03:45,700 --> 00:03:50,349
You know, using the word natural, like natural variation, I think makes sense.

34
00:03:50,350 --> 00:03:53,320
So you're naturally varying the mediator.

35
00:03:54,040 --> 00:03:59,560
I mean, that's different than a controlled, direct effect where you are directly fixing the mediator to be a specific level.

36
00:04:02,760 --> 00:04:13,010
Okay. And then going back to a frequentist interpretation of a p value of 0.03.

37
00:04:13,520 --> 00:04:18,450
Um. This one sets it up really well.

38
00:04:18,460 --> 00:04:25,600
So a p value point of a three, that's a probability. So it's like 3% of the time under the null hypothesis.

39
00:04:27,280 --> 00:04:33,340
I would change this just to say that the test value that we got would be as extreme or more extreme.

40
00:04:36,380 --> 00:04:41,690
So I think this is like a great preliminary phase. There's a 3% chance of seeing an estimate as extreme or more extreme.

41
00:04:41,930 --> 00:04:45,650
You kind of need to like an extra phrase, though, under the null hypothesis.

42
00:04:46,010 --> 00:04:53,650
So like assuming that there is no association. Okay.

43
00:04:54,580 --> 00:04:59,200
You're designing an experiment to reduce risk of neuropathy among patients with diabetes.

44
00:04:59,470 --> 00:05:03,370
You randomized individuals to receiving a recommendation to attend Weight Watchers.

45
00:05:03,670 --> 00:05:11,680
What experimental effect are you estimating? So the options here are how does reduced weight affects neuropathy?

46
00:05:11,770 --> 00:05:18,790
How does attending Weight Watchers affect neuropathy? Or how does receiving a recommendation to ten Weight Watchers affect risk in AARP?

47
00:05:18,820 --> 00:05:26,380
And this is the correct answer. So I think what in our brains a lot of times is that we're thinking like, oh, you know, you know what?

48
00:05:27,010 --> 00:05:33,580
If we're designing and designing this trial, of course, that what we're interested in is like, how does a change in weight affect neuropathy?

49
00:05:34,330 --> 00:05:41,680
But the thing is, there's no counterfactual for that. Like, what does it mean to like remove ten or Â£20 from somebody?

50
00:05:41,680 --> 00:05:44,840
Like, there's no medical way that we can do that.

51
00:05:44,860 --> 00:05:51,370
There's no, like, time travel way that we can do that. We can, you know, try to modify somebody's diet.

52
00:05:51,370 --> 00:06:01,500
We can try to change somebody's exercise. You know, we might not even think that, like the weight change is is actually the important key here.

53
00:06:01,510 --> 00:06:05,770
And I would say that, you know, there's there's a lot of fat stigma in today's world.

54
00:06:05,770 --> 00:06:09,160
So, you know, if somebody has neuropathy, there could be all sorts of reasons for that.

55
00:06:09,790 --> 00:06:15,219
But if we're trying to really delve into this idea of weight, you know, there's no real good experimental way we can do that.

56
00:06:15,220 --> 00:06:19,300
We can just have proxies. And so that's what I think most of you are catching on to.

57
00:06:20,560 --> 00:06:27,750
Any questions? Okay.

58
00:06:27,760 --> 00:06:30,790
So I don't think I need to like go through all these again.

59
00:06:30,790 --> 00:06:42,610
But like, if you want to look in my PowerPoint slides, I do have answers, or at least like how I would answer these.

60
00:06:43,400 --> 00:06:50,469
Uh, I think this one about natural control, direct effects might be something that you might want to look back at,

61
00:06:50,470 --> 00:06:53,680
because I think that was, you know, it's a bit harder of a concept to understand.

62
00:06:55,030 --> 00:06:59,170
But getting into puzzling for setting, it's important to start thinking about things like that.

63
00:07:00,800 --> 00:07:06,520
Okay. Well, let's get started with today's class then.

64
00:07:09,230 --> 00:07:18,290
And today we are going to be talking about biases in our analysis and what can we do about that?

65
00:07:19,310 --> 00:07:24,740
Because this lovely thinking about a perfect world where there are no biases or were there, you know, very limited.

66
00:07:24,740 --> 00:07:29,209
But in reality, we have messy data sets. We have imperfect data collection techniques.

67
00:07:29,210 --> 00:07:32,840
Our skills aren't precise. So there's error.

68
00:07:33,800 --> 00:07:38,510
So there's something in the survey methodology literature, which is called the total error paradigm.

69
00:07:38,900 --> 00:07:49,250
And that's what we're going to go over. And this has to say that error can kind of seep into studies through two different pathways.

70
00:07:49,250 --> 00:07:54,230
One is through your measurements, and then the other is through your representation.

71
00:07:54,560 --> 00:08:00,020
So measurement in epidemiology, we might also consider this like an information related error.

72
00:08:01,430 --> 00:08:08,120
And we can think of like, like a construct that we have.

73
00:08:08,690 --> 00:08:13,550
And maybe our construct is immunity to COVID 19.

74
00:08:14,000 --> 00:08:19,260
That might be the concept that we have. But like, how do you measure immunity to COVID 19?

75
00:08:19,280 --> 00:08:20,990
It actually kind of gets to be pretty difficult.

76
00:08:21,440 --> 00:08:29,629
So we might have some sort of measurement and maybe this is a laboratory test of like some antibodies that somebody has,

77
00:08:29,630 --> 00:08:31,940
like antibodies to a spike protein, something like that.

78
00:08:34,640 --> 00:08:47,780
And so, you know, there can be some error in that error would mean that there is, you know, not any, you know, directionality.

79
00:08:47,780 --> 00:08:50,750
It's just kind of like imprecise the the measurement.

80
00:08:51,320 --> 00:08:58,070
But when we talk about a bias, so like a measurement bias here would mean that it's kind of like an error in one direction or another.

81
00:09:00,140 --> 00:09:05,299
Another way we could think about this is in terms of like if we're doing more like a of a psychometric study,

82
00:09:05,300 --> 00:09:07,700
so maybe we're trying to be interested in depression.

83
00:09:08,330 --> 00:09:14,290
So that would be our concerns, like whether somebody is depressed or not, our measure might be, you know,

84
00:09:14,330 --> 00:09:21,830
their response to a certain depression scale or like it might be a depression scale that people have put together,

85
00:09:21,830 --> 00:09:24,860
some psychologists have put together. But then there's the response.

86
00:09:24,860 --> 00:09:32,689
This is like how an individual actually responds to that measurement scale, and maybe they don't quite understand it.

87
00:09:32,690 --> 00:09:38,870
You know, maybe English isn't their first language or maybe, you know, there's some sort of like confusing concepts in it,

88
00:09:39,440 --> 00:09:43,910
you know, maybe there's some sort of social desirability thing where they just don't want to respond in a certain way.

89
00:09:44,090 --> 00:09:48,230
So error or bias could creep up between the measurement and the response.

90
00:09:49,610 --> 00:09:56,599
The edited response here is just talking about, you know, how is it present in our datasets?

91
00:09:56,600 --> 00:10:03,229
How are we kind of deriving our variable and maybe like we on SAS or are we might

92
00:10:03,230 --> 00:10:07,310
be putting some error or maybe even a bias based on how we're coding things.

93
00:10:08,660 --> 00:10:17,059
So that's like the measurement pathway. There's also the representation pathway and we need to think about what is our target population.

94
00:10:17,060 --> 00:10:24,620
So, you know, maybe we're trying to do a study of, you know, immunity towards COVID 19 in Washtenaw County.

95
00:10:24,620 --> 00:10:28,280
So our target population is Washtenaw County.

96
00:10:29,390 --> 00:10:34,250
And you know, it'd be lovely if we could sample everybody in Washtenaw County, but you know, we don't have money for that.

97
00:10:34,860 --> 00:10:42,020
That's really infeasible. So we have a sampling frame. Our sampling frame is like the list of possible respondents in our study.

98
00:10:43,340 --> 00:10:47,990
And so, you know, there's no real like email address list.

99
00:10:48,650 --> 00:10:54,500
But, you know, maybe we could buy from, you know, a market survey firm.

100
00:10:54,500 --> 00:10:59,150
They might have a list of all the addresses or what they think are all the addresses in Washtenaw County.

101
00:10:59,690 --> 00:11:07,009
And that could be a sampling frame. But, you know, maybe there is some error in that.

102
00:11:07,010 --> 00:11:12,950
You know, we're not going to be getting the population of people experiencing homelessness.

103
00:11:13,340 --> 00:11:16,729
There might be some new houses which are not part of this.

104
00:11:16,730 --> 00:11:20,420
Or it could be that, you know, the person who went around just didn't report all the houses.

105
00:11:21,980 --> 00:11:26,959
So there could be could be errors in that. You know, maybe our target population is the University of Michigan.

106
00:11:26,960 --> 00:11:32,390
And so we do have like a list or maybe somewhere somebody has a list of all the email addresses of

107
00:11:32,390 --> 00:11:37,220
everybody at the University of Michigan so that the sampling frame that would be that that list of emails.

108
00:11:37,550 --> 00:11:46,670
But, you know, what about people who are, you know, new to the university, maybe like they haven't set up their emails yet.

109
00:11:48,260 --> 00:11:54,050
It could be that like some people that don't check their emails, in which case the sampling frame just like it's not really able to reach them.

110
00:11:55,310 --> 00:11:57,470
So that's like who we could actually sample.

111
00:11:57,680 --> 00:12:02,780
But once we have that list of emails with that list of all the addresses in the area, we actually come up with our sample.

112
00:12:02,780 --> 00:12:08,500
And this is what you learned last year in your sample size calculation class, like how many people need to be per?

113
00:12:08,680 --> 00:12:11,799
Of the sample. Do we only sample hundred people?

114
00:12:11,800 --> 00:12:19,030
Do you sample 10,000 people? Those are our sample. So, you know, and we could have bias from who we are actually sampling in the sampling frame.

115
00:12:20,710 --> 00:12:27,610
And so we might want these hundred people from Washtenaw County, we might want these 10,000 people at the University of Michigan.

116
00:12:27,610 --> 00:12:31,179
But who's actually going to respond to our survey? And there can be error in that.

117
00:12:31,180 --> 00:12:41,050
There could be bias, you know, who's more likely to, you know, respond to a letter in the mail or to actually open up their email and to do a survey?

118
00:12:43,670 --> 00:12:48,920
So in all of these, there can be errors, there can be bias.

119
00:12:50,030 --> 00:12:56,840
Again, error is kind of like non directional, whereas bias is pushing in one direction or another.

120
00:12:57,350 --> 00:13:04,999
And these are kind of some of the words that we say to describe the problems between these boxes.

121
00:13:05,000 --> 00:13:14,659
So, you know, measurement error means that we have like this, this, this depression scale, but how are people actually responding to it?

122
00:13:14,660 --> 00:13:19,160
If they're not understanding it fully, then there can be measurement or even measurement bias.

123
00:13:20,960 --> 00:13:21,860
Similarly, you know,

124
00:13:21,860 --> 00:13:31,819
like our we could have coverage error if we're not getting everybody in Washtenaw County if if not everybody is showing up in our sampling frame.

125
00:13:31,820 --> 00:13:36,640
That's the coverage area. So again, things between constructing your measure that's validity.

126
00:13:37,030 --> 00:13:45,219
So is there validity in this in this test of cognitive immunity?

127
00:13:45,220 --> 00:13:50,890
Is there validity of this, uh, of this depression scale?

128
00:13:59,030 --> 00:14:03,560
So let's bring this back to the epidemiology literature.

129
00:14:04,220 --> 00:14:13,940
And so I'm going to introduce like some, some terminology and it's kind of kind of some ways maybe some grammar of how people talk about error.

130
00:14:14,540 --> 00:14:16,699
I think this is pretty consistent through the literature.

131
00:14:16,700 --> 00:14:20,089
But, you know, it's always, you know, if you're if you're really diving into this literature,

132
00:14:20,090 --> 00:14:25,729
it's always best to kind of keep an eye out for any legends or legends or any

133
00:14:25,730 --> 00:14:30,980
way that people are describing how they how they graphically depict things.

134
00:14:32,720 --> 00:14:45,170
But conditioning in that would mean that we are putting something in a multivariable model or we are we could be stratifying on it.

135
00:14:46,220 --> 00:14:54,560
We could be so like conditioning is just, you know, we're incorporating it into our study design either in an analysis way or in a representation.

136
00:14:54,560 --> 00:14:58,070
We use that by square brackets.

137
00:14:58,850 --> 00:15:05,960
If you're limiting it to one stratum, then you can just specify what stratum you are limiting it to.

138
00:15:09,290 --> 00:15:17,509
And if there is an unknown and an unmeasured confounder, we call that you or just some third variable, something that we just don't know about.

139
00:15:17,510 --> 00:15:22,070
That's you if we know about it, but we don't measure it, we often just put that in a parentheses.

140
00:15:23,480 --> 00:15:30,500
We also can have a proxy variable in that is by an asterisk, and I'll explain that a bit more what that would actually mean.

141
00:15:33,430 --> 00:15:37,370
So what do we mean by some sort of information bias or measurement error?

142
00:15:37,390 --> 00:15:41,680
Again, measurement error is sort of a bit non directional, whereas bias is in one way or another.

143
00:15:43,240 --> 00:15:49,840
This is what we say that we are really interested in the effect of coffee on diabetes.

144
00:15:55,200 --> 00:15:59,280
How do we measure coffee drinking, though? That is our proxy variable.

145
00:15:59,290 --> 00:16:04,680
So maybe our our our variable is like your response to a question.

146
00:16:05,310 --> 00:16:10,320
Have you ever drunk coffee in your life or you know how we want to put that in a survey format?

147
00:16:10,650 --> 00:16:13,680
That is what we're actually measuring. So that is the X asterisk.

148
00:16:14,100 --> 00:16:18,600
But in reality, we don't care how somebody responds to a survey for this.

149
00:16:18,600 --> 00:16:21,930
We really want to know, did somebody ever have coffee in their life?

150
00:16:22,680 --> 00:16:27,810
The thing is, there is no way for us to actually know whether somebody had coffee or not.

151
00:16:28,650 --> 00:16:34,709
So, you know, maybe this is a moment of humility for us because like whenever we're collecting information, we don't know if that's real or not.

152
00:16:34,710 --> 00:16:40,320
We hope it's real. But, you know, there could be all sorts of reasons for measurement or, you know,

153
00:16:40,530 --> 00:16:43,450
based on how we read the question, maybe the respondent just doesn't care.

154
00:16:43,470 --> 00:16:47,610
Maybe there's like clicking through all the answers just for them to get to the end of the survey.

155
00:16:48,510 --> 00:16:51,899
So yeah, so this acts in parentheses. That's what we really want.

156
00:16:51,900 --> 00:16:56,340
We want to know what is somebody who's actually coffee drinking habits,

157
00:16:56,640 --> 00:17:00,629
but what we have is just a measurement of it and the arrows pointing this way because

158
00:17:00,630 --> 00:17:06,570
presumably there should be a very strong relationship between what they're real in reality,

159
00:17:06,570 --> 00:17:10,500
but what their actual coffee drinking consumption is like and how they measure it.

160
00:17:10,830 --> 00:17:15,810
But, you know, it's not going to be 100%. And similarly, we can think about this for diabetes.

161
00:17:16,080 --> 00:17:20,129
You know, maybe there are a bit more objective measures. Maybe there's some laboratory measurements we could do.

162
00:17:20,130 --> 00:17:27,510
But even with those, there could be potentially some errors. So why asterisk is what we actually are able to why in parentheses is what we want.

163
00:17:28,410 --> 00:17:33,630
Any questions with that? Okay.

164
00:17:34,680 --> 00:17:39,000
So it's interesting to think about how measurement error can crop up.

165
00:17:39,570 --> 00:17:46,980
So this is a this is a study of men who have sex with men.

166
00:17:47,130 --> 00:17:51,210
And they were comparing standardized and conversational interviewing.

167
00:17:51,540 --> 00:17:57,749
And the exact difference between these isn't really important for the sake of this course, but just for you briefly to understand,

168
00:17:57,750 --> 00:18:03,540
standardized interviewing is sort of the traditional way that we would do telephone interviews or,

169
00:18:03,540 --> 00:18:07,620
you know, interviews like in person with somebody asking you the questions.

170
00:18:08,700 --> 00:18:15,149
Basically, they would ask a question and then if the respondent would be like, Oh, I don't really understand,

171
00:18:15,150 --> 00:18:24,600
or the interviewer wouldn't really be able to explain the question, but would just repeat the question in a conversational interviewing technique.

172
00:18:25,050 --> 00:18:34,830
The interviewer will first state the question, but then if the interviewee if the respondent has some questions,

173
00:18:35,130 --> 00:18:42,420
then the interviewer has a bit more flexibility in providing some guidance for, you know, what the question actually means.

174
00:18:43,590 --> 00:18:46,170
So let's take an answer or a question. What is your age?

175
00:18:47,940 --> 00:18:52,230
You know, and so people are randomized into getting conversational interviews or standard interviews.

176
00:18:52,710 --> 00:18:55,380
So what is your age? We see very similar responses.

177
00:18:55,380 --> 00:19:00,720
You know, in half the group that we're under, the conversational interview is 45 and standardized about 44.

178
00:19:01,110 --> 00:19:02,910
There's not really a significant difference there.

179
00:19:03,570 --> 00:19:09,150
Well, see, if you ask what people's educational levels are like, those are pretty much going to be the same across the two different groups.

180
00:19:12,800 --> 00:19:18,680
But if you start talking about more sensitive things or with things which are more of like a complicated topic,

181
00:19:19,040 --> 00:19:23,000
this is where you can actually start to see some differences.

182
00:19:23,030 --> 00:19:28,310
So one thing they asked is, you know, did you have condom, less sex?

183
00:19:28,730 --> 00:19:37,910
And basically, under the conversational interview, there are more people who report that than under the standardized interview.

184
00:19:38,210 --> 00:19:41,510
In this asterisk is just in their study, they will find a significant difference.

185
00:19:42,530 --> 00:19:48,200
And, you know, we don't know what, like the actual real value is, but we assume that, you know,

186
00:19:48,200 --> 00:19:52,490
it is probably of the higher number is more accurate and they have some reasons why they make that assumption.

187
00:19:53,450 --> 00:19:57,769
So this is just a separate with something which might be like a bit more complicated or

188
00:19:57,770 --> 00:20:01,190
something which requires a bit more explanation or for people to like think through a bit more.

189
00:20:01,490 --> 00:20:11,120
Maybe a conversational interview is a bit better. But, you know, the other interesting thing is when they asked people if they were Hispanic or not,

190
00:20:12,290 --> 00:20:17,510
there was a much larger proportion of them in the conversational interview who said that versus the standardized interview.

191
00:20:18,890 --> 00:20:22,490
So even for something which, you know, presumably isn't that that sensitive,

192
00:20:22,490 --> 00:20:26,330
there could be a difference in, you know, this could be because maybe people are confused.

193
00:20:26,330 --> 00:20:32,570
But like the order, I don't know if you've you've had to do surveys on like race and ethnicity, but it's kind of confusing sometimes.

194
00:20:34,490 --> 00:20:43,370
So this is just basically a study showing what the potential is for this this X to X asterisk.

195
00:20:44,360 --> 00:20:51,169
You know, people may not be understanding the questions and for things which might even seemingly be really obvious,

196
00:20:51,170 --> 00:20:55,980
they might not necessarily get what you were trying to say.

197
00:20:56,030 --> 00:21:00,650
So again, the difference between conversation and Sandra is not important for this class,

198
00:21:01,040 --> 00:21:04,760
but it's all to say that, you know, how you ask about questions really does matter.

199
00:21:07,140 --> 00:21:13,830
We can think about selection bias and selection bias can creep into our studies in a number of different ways.

200
00:21:14,760 --> 00:21:24,150
You know, see that we were doing a study of the effect of vaccination on COVID 19 incidence.

201
00:21:24,600 --> 00:21:35,339
If we limited it to the University of Michigan Medical School or the hospital system Michigan Medicine, we could directly do that.

202
00:21:35,340 --> 00:21:43,950
And that would be, you know, the square brackets of equals, one that would just be a direct arrow from that to to the SMI.

203
00:21:44,430 --> 00:21:51,450
But, you know, there could be biases there because, you know, if there's a mandate for vaccines and only some people are able to get out of that,

204
00:21:51,450 --> 00:21:54,959
you know, there would be some difficulties in kind of doing that study.

205
00:21:54,960 --> 00:21:56,640
We might end up with some biased results.

206
00:21:58,230 --> 00:22:09,150
But selection bias can kind of seep into our studies a bit more insidiously if we're not keeping track of some of these unmeasured confounders,

207
00:22:09,150 --> 00:22:12,570
which maybe are even unknown for us in this happens a lot.

208
00:22:12,600 --> 00:22:17,129
If you're doing a hospital based study because in essence,

209
00:22:17,130 --> 00:22:23,150
the type of people who go to hospitals might be the ones who are more likely to have better insurance.

210
00:22:24,570 --> 00:22:29,190
You know, it could be that they are sick for a variety of reasons.

211
00:22:29,230 --> 00:22:32,850
You know, it depends on what kind of department you're going to.

212
00:22:33,660 --> 00:22:39,780
So this is all to say. This is the selection bias can kind of come into your study, you know, in a lot of different ways.

213
00:22:39,780 --> 00:22:44,459
So maybe you're you're aware, for instance, that everyone's going to be at the hospital.

214
00:22:44,460 --> 00:22:52,170
But the selection bias could be that you're kind of selecting for a certain stratum of socioeconomic status or something like that.

215
00:22:54,840 --> 00:22:58,010
Of course, there's uncontrolled confounding. I think we're all aware of this.

216
00:22:58,020 --> 00:23:03,660
This could be with a variable that we are aware of. Again, that's represented by Z with parentheses.

217
00:23:03,870 --> 00:23:13,139
Or it could be unknown and there would just be a U. The other important thing to think about is these biases don't operate independently.

218
00:23:13,140 --> 00:23:16,500
It's not just like your study would only have one bias and not this other bias.

219
00:23:16,860 --> 00:23:18,089
Like you can have confounding.

220
00:23:18,090 --> 00:23:25,680
You can have selection problems, you can have measurement problems operating all at the same time and likely you do in your studies.

221
00:23:26,520 --> 00:23:33,899
So again, these it looks simple just having like these these one set of arrows,

222
00:23:33,900 --> 00:23:39,540
but in reality, this is probably what's happening in your specific study.

223
00:23:42,770 --> 00:23:51,200
So what do we do about this? I'm a strong advocate that like if you're doing research and if you're spending time putting together some analysis,

224
00:23:51,200 --> 00:23:53,509
like, let's get that research out there, let's get it published.

225
00:23:53,510 --> 00:24:01,610
It doesn't need to be a perfect study, but we should just be acknowledging what are some of the biases that are in our study.

226
00:24:02,750 --> 00:24:09,590
So quantitative bias analysis is a bit more of a formal approach to doing that, and we're going to be talking about that throughout this class today.

227
00:24:10,640 --> 00:24:13,370
And it might be something that you have not heard of.

228
00:24:13,370 --> 00:24:19,310
I'm guessing that most of you are probably not heard of quantitative bias analysis, but it's not a new thing.

229
00:24:19,640 --> 00:24:27,950
It's been around for decades. So this is a study from the mid 1960s where people are basically talking about 92 bias analysis.

230
00:24:29,150 --> 00:24:31,820
I would say the reason why we don't really talk about it so much is it's sort of

231
00:24:31,820 --> 00:24:35,840
like an additional analysis you do on top of your already existing analysis.

232
00:24:35,840 --> 00:24:42,950
And I'm sure you're kind of if you're thinking about your daily project or any other research projects you get on,

233
00:24:43,490 --> 00:24:48,140
if you spend a lot of time on them at some point in time, you just don't want to like continue doing stuff on them.

234
00:24:48,560 --> 00:24:55,310
And quantitative bias analysis is just like an additional set of things that you we probably should mostly all be doing,

235
00:24:55,670 --> 00:24:58,900
but we often and you know, me included, just go.

236
00:25:00,980 --> 00:25:06,230
So of course, if we back up, we want to minimize bias from the start of our study.

237
00:25:06,650 --> 00:25:07,850
So how do we do that?

238
00:25:08,270 --> 00:25:16,820
You know, prospectively thinking we should be developing a plan for analysis, like as the data is being collected, let's minimize those errors.

239
00:25:17,570 --> 00:25:21,170
Let's make sure our analysis is really robust to enhance the validity.

240
00:25:22,760 --> 00:25:29,629
And then, you know, during our. So that's like the study design process.

241
00:25:29,630 --> 00:25:35,209
But then there's also the bias analysis design process, in which case, you know, we should throw out all this.

242
00:25:35,210 --> 00:25:38,660
We can also be doing this bias analysis.

243
00:25:40,470 --> 00:25:42,810
So these can happen. Kind of like in tandem.

244
00:25:45,400 --> 00:25:51,730
But before we get into what I consider bias analysis is this is just a discussion for you and your groups.

245
00:25:52,210 --> 00:25:57,310
If you do not have anybody else that you can just like join a group next to you.

246
00:25:58,000 --> 00:26:03,880
But is it better to have a measurement with low bias and high variance or vice versa?

247
00:26:04,270 --> 00:26:12,560
So what do I mean by this? Let's say that the actual measurement is five miles.

248
00:26:12,580 --> 00:26:16,630
It's like, what's the distance between your house and the school?

249
00:26:18,910 --> 00:26:22,360
In under a low bias Siberians estimate over repeated measurements.

250
00:26:22,360 --> 00:26:28,659
This is kind of the density curve that you get under high bias, little variance, you know, it'd be biased in one direction or another.

251
00:26:28,660 --> 00:26:35,380
This would be biased in a positive direction. So which one do you think is better?

252
00:26:35,500 --> 00:26:38,530
You have an argument with your group about what you would prefer.

253
00:26:39,160 --> 00:26:48,429
I'll just give you a couple of minutes to discuss. Our name is.

254
00:26:55,692 --> 00:26:59,352
Why don't we start with heterogeneity here, the friends.

255
00:26:59,442 --> 00:27:07,032
Do you have any thoughts about any? I will say there's not necessarily a right or wrong answer, but what are what are your thoughts for this one?

256
00:27:07,872 --> 00:27:13,852
Oh, yeah. I guess thinking about they know that you have a measure of catching it.

257
00:27:13,872 --> 00:27:19,202
True. The treatment survived.

258
00:27:20,402 --> 00:27:28,552
So although it has had very. That's due to the fact that I had a similar.

259
00:27:32,122 --> 00:27:36,052
Yeah. So you know, like five actually is in this whereas it really isn't in the other one.

260
00:27:37,102 --> 00:27:40,222
Um, what about surviving life?

261
00:27:40,222 --> 00:27:45,532
Do you have any differences or similarities in what heterogeneity just said?

262
00:27:51,632 --> 00:27:54,662
I think the merger with Google by trying be.

263
00:27:59,722 --> 00:28:05,942
And yeah, I used to be a little nervous about that.

264
00:28:08,132 --> 00:28:14,492
It was clear that that they was a little biased.

265
00:28:14,852 --> 00:28:19,732
If you haven't seen anything, if you have more opinions. Have you guys.

266
00:28:23,542 --> 00:28:26,812
Yeah. So there's a number of different ways of thinking about this.

267
00:28:26,882 --> 00:28:35,812
You know, like I'm giving you a hypothetical example. It's not try to bias you in one direction or another in bias in what you're thinking.

268
00:28:36,562 --> 00:28:40,732
But, you know, and it like it depends on the field.

269
00:28:40,732 --> 00:28:48,381
And whatever I would say in epidemiology, a lot of people would prefer this low bias,

270
00:28:48,382 --> 00:28:54,142
high variance for kind of what she was saying is that, you know, like the five is in here.

271
00:28:54,862 --> 00:28:58,552
So maybe there's a lot of variation in maybe like our standard errors will be really high.

272
00:28:58,552 --> 00:29:01,762
But you know, we at least encompass the true value.

273
00:29:02,182 --> 00:29:11,242
Um, I would say a lot of people have, you know, maybe more methodologies or better statisticians would actually prefer this high bias,

274
00:29:11,242 --> 00:29:14,061
low variance with the understanding,

275
00:29:14,062 --> 00:29:21,202
like if we can understand the directionality of the bias or if we can understand like why bias is seeping into our measurements,

276
00:29:21,562 --> 00:29:29,301
then we can, we can account for that and then we could kind of like re correct it so that,

277
00:29:29,302 --> 00:29:33,502
you know, in this case it seems that we're just like adding on to my,

278
00:29:33,652 --> 00:29:40,582
you know, maybe our, you know, pedometer or whatever is just like adding two miles on for whatever reason.

279
00:29:40,802 --> 00:29:44,272
Then of course, it'd be best to just have this and subtract out two miles.

280
00:29:46,072 --> 00:29:53,781
And that's obviously a simplistic answer. But, you know, as you go forward in the future and you're thinking about like,

281
00:29:53,782 --> 00:29:57,532
how do you measure things maybe in a survey or through a laboratory assay or whatnot?

282
00:29:58,282 --> 00:30:01,792
It's not neces. Oftentimes there is this distinction.

283
00:30:01,942 --> 00:30:05,282
And of course, what we would like is no bias, no variance, though.

284
00:30:05,392 --> 00:30:09,562
And, you know, I think with certain techniques we're getting better.

285
00:30:10,882 --> 00:30:17,452
But oftentimes there is a tradeoff between bias and variance in the sense that we can either choose to have high variance or high bias.

286
00:30:17,782 --> 00:30:23,182
And I want you do not necessarily have this kneejerk reaction of going for low bias Siberians.

287
00:30:23,362 --> 00:30:28,782
That might be the right answer, but to also think about high by slow variance if you can account for.

288
00:30:31,722 --> 00:30:35,952
Okay. So what are the problems that we have in real world data sets?

289
00:30:36,342 --> 00:30:41,792
This is what we want. We want to know what the actual values of the X and Y, you know,

290
00:30:41,862 --> 00:30:49,091
whatever their what we have in our data sets are not that we might have an unmeasured confounders.

291
00:30:49,092 --> 00:30:54,102
We just like don't have any data at all for it. So here the, the circle is just representing.

292
00:30:54,102 --> 00:31:01,662
We have that data. So we don't, we might not have like the actual value for X and instead have like an X proxy,

293
00:31:02,232 --> 00:31:06,422
and then we might just have like missing data, you know, it could be people are dropping out of the study.

294
00:31:06,432 --> 00:31:12,582
It could be that they just weren't measured. It could be that, you know, when somebody you're serving survey online, they like skip that question.

295
00:31:13,662 --> 00:31:17,202
You know, for whatever reason, we would have missing results.

296
00:31:17,472 --> 00:31:19,692
And this is just real world data. It can be messy.

297
00:31:20,832 --> 00:31:29,202
So again, I think a lot of times in epidemiology, we make it so that you can analyze these types of data sets really, really well.

298
00:31:29,532 --> 00:31:34,032
But the moment that you start having some missing this, there is there's a problem.

299
00:31:37,062 --> 00:31:41,291
So what are some ways of dealing with this? You know, we're not going to be able to go through all of these.

300
00:31:41,292 --> 00:31:43,232
I just want to kind of throw them out there.

301
00:31:43,242 --> 00:31:51,972
And certainly there are all sorts of classes that you could be even taking to talk about, like missing data or, you know, multiple imputation.

302
00:31:52,722 --> 00:31:58,452
And, you know, there's been some recession also has a class on quantitative bias analysis, which I think is really great.

303
00:32:00,042 --> 00:32:08,472
Of course, you could try to find the missing data. You could do a validated, you know, internal data so that you maybe you know, who everyone is.

304
00:32:08,472 --> 00:32:12,372
And you could just email them again and be like, please respond to this question.

305
00:32:12,942 --> 00:32:17,772
They'd be lovely. Maybe don't have as much money to email everybody or recontact everybody.

306
00:32:18,102 --> 00:32:27,622
So then you recontact a subset. But if you don't have that, maybe there's like another data set that you know of which you know,

307
00:32:27,642 --> 00:32:32,262
has that information and we can kind of compare what they found versus what's in our dataset.

308
00:32:33,582 --> 00:32:37,092
You could do multiple imputation. We'll talk about that in a moment.

309
00:32:38,142 --> 00:32:41,382
We'll talk later today about calculating value.

310
00:32:41,472 --> 00:32:46,092
I mean, there's all sorts of like modeling approaches and sensitivity analysis that you could do as well.

311
00:32:49,042 --> 00:32:52,852
Okay. So what do we mean by comparing data to an external data set?

312
00:32:53,032 --> 00:33:00,082
So maybe this external data set has the information that we want, whereas we do not.

313
00:33:01,132 --> 00:33:07,012
So what we could do is we could run regression models in the external data set,

314
00:33:08,062 --> 00:33:13,792
and then we could use the formula from that to predict what our values should be.

315
00:33:15,442 --> 00:33:20,602
So basically using this external data set to predict what our values is, you should be given maximum.

316
00:33:23,972 --> 00:33:31,261
Internal validation is just like a subset of that where, you know, we would have information from some people, but then, you know,

317
00:33:31,262 --> 00:33:33,212
we could do sensitivity analysis only limited to them,

318
00:33:33,542 --> 00:33:39,602
or we could use the regression analysis from these folks to predict what these values should be like.

319
00:33:43,592 --> 00:33:49,892
So multiple imputation. And just to orient yourself to this dataset, I'm just taking out two different numbers.

320
00:33:53,422 --> 00:34:01,762
So what you do in multiple imputation is you predict what the values should be for certain variables in your dataset.

321
00:34:04,112 --> 00:34:09,812
But it's called multiple because you impute multiple values per respondent.

322
00:34:09,812 --> 00:34:15,342
So here I think there's just like five values per respondent in basically the, the,

323
00:34:15,472 --> 00:34:20,162
the range of responses you have kind of represent the uncertainty you have about your data.

324
00:34:20,672 --> 00:34:23,251
But generally with multiple imputation, it's a data driven process.

325
00:34:23,252 --> 00:34:29,581
So you just like you tell the computer program what you think the range of values should be,

326
00:34:29,582 --> 00:34:33,302
you tell it what variables that should be related to in the computer program.

327
00:34:33,302 --> 00:34:38,911
What would do a best guess of the range of values? But you mean you could do this on your own?

328
00:34:38,912 --> 00:34:42,632
You could kind of put together some plausible values for what these are.

329
00:34:44,852 --> 00:34:47,432
But yeah, so you have multiple guesses per person.

330
00:34:48,182 --> 00:34:54,362
And then in your final analysis, you need to quantify that uncertainty across the multiple guesses per person.

331
00:34:59,062 --> 00:35:02,392
Okay. Another example. And let me just set this up.

332
00:35:02,632 --> 00:35:08,961
Maybe we have a longitudinal study and just some basic demographics.

333
00:35:08,962 --> 00:35:13,222
In Wave one, 20% of the people had low income.

334
00:35:13,222 --> 00:35:19,702
However, we're defining that and 30% of people lived in a rural area.

335
00:35:20,752 --> 00:35:28,822
Maybe we're following up with them like after a year or whatnot. And we find out that the number of people with low income dropped in our study.

336
00:35:28,822 --> 00:35:34,581
So, you know, maybe we lost a certain percentage of the study population.

337
00:35:34,582 --> 00:35:40,522
And now only 10% of the people in our study are low income and only 20% are from rural areas.

338
00:35:43,482 --> 00:35:55,062
What weighting does is we account for the fact that we lost some low income rural folks, so we update them.

339
00:35:56,652 --> 00:36:02,882
So I believe in six or two last year, you might have talked a bit about like survey methods, including the use of weights.

340
00:36:03,282 --> 00:36:12,702
So there's a number of reasons why you might want to do that if you're trying to, you know, push out results which are representative of a population.

341
00:36:13,722 --> 00:36:20,082
But yeah, so basically in longitudinal studies we can rewrite the sample to account for a lot of our work.

342
00:36:22,422 --> 00:36:26,862
So in our weighted proportion then you know, we have the same proportions as we do in the weight one sample.

343
00:36:27,132 --> 00:36:32,652
And the idea here is that, you know, if we're also looking at other measures like, you know, coffee drinking and diabetes incidence and whatnot,

344
00:36:33,012 --> 00:36:41,242
our weighted proportion will be more accurate because it accounts for all these people who are missing who we lost between.

345
00:36:41,242 --> 00:36:47,492
We got to. Okay.

346
00:36:47,492 --> 00:36:59,522
So for the homework for today, you I kind of hold your hands going through a few different problems selection bias,

347
00:36:59,852 --> 00:37:03,002
unmeasured confounding and misclassification.

348
00:37:03,662 --> 00:37:09,302
So for a selection bias because I am thinking of them, there might be loss to follow it.

349
00:37:11,042 --> 00:37:15,602
What we're going to do is we're going to update those individuals who are more similar to those last of all.

350
00:37:15,632 --> 00:37:19,112
So basically we're going to see who's kept on in the study, who is not.

351
00:37:20,462 --> 00:37:26,132
And then for those who have not kept on in the study, how do they compare with like our existing sample?

352
00:37:26,492 --> 00:37:31,562
And we are trying to rewrite the sample. So it's more similar to the baseline study.

353
00:37:33,572 --> 00:37:39,182
The other thing we're going to do is we're going to look at unmeasured confounding, I think looking at ethnicity.

354
00:37:40,712 --> 00:37:52,502
And what we will do is there's going to be like a sub sample in the dataset, like a validation subsample which has that information.

355
00:37:53,072 --> 00:38:01,802
We're going to use that to come up with a regression model to predict what the values of the unmeasured confounders should be in the rest of the data.

356
00:38:04,212 --> 00:38:12,432
And then we're going to assume that there may be some misclassification error. And similarly, we will adjust for it using a regression model.

357
00:38:13,122 --> 00:38:23,351
And yeah, so it also just like a heads up, the homework is not due on this Sunday.

358
00:38:23,352 --> 00:38:26,892
You know, this is this is a break, but it's due in a week.

359
00:38:27,402 --> 00:38:30,431
There is homework. You know, there is also one last homework assignment.

360
00:38:30,432 --> 00:38:34,932
But the the last homework assignment is relatively straightforward and relatively quick.

361
00:38:34,942 --> 00:38:38,652
So this is, you know, like a bit more of coding, but it's like your last coding assignment.

362
00:38:39,582 --> 00:38:45,542
The homework for week six is a bit more straightforward. Okay.

363
00:38:45,962 --> 00:38:50,912
Last thing before our break. Biases do not always operate in the same direction.

364
00:38:51,362 --> 00:38:57,691
So, again, I'm pushing this into your minds that there are three types of bias that you may be interested in epidemiology selection,

365
00:38:57,692 --> 00:39:04,982
bias, information bias and confounding. And let's say that are true values.

366
00:39:04,982 --> 00:39:08,522
Five Maybe this is like how many miles it is between school and.

367
00:39:10,812 --> 00:39:15,302
And your call. It's five miles. There could be information bias.

368
00:39:15,312 --> 00:39:22,301
You know, maybe how we are measuring things results in us having an even higher if we're doing some sort of

369
00:39:22,302 --> 00:39:29,202
multivariable model like the presence of confounding could even increase this relationship even more.

370
00:39:30,192 --> 00:39:34,982
And then through selection bias, we come up with an observed value of ten.

371
00:39:37,522 --> 00:39:42,232
But again, this could be this could be a totally different direction. This is all to say.

372
00:39:42,232 --> 00:39:45,622
Like, if you really are delving into quantitative bias analysis,

373
00:39:45,772 --> 00:39:50,092
it's probably important to think about like all three things, all three of these things together.

374
00:39:50,392 --> 00:39:54,292
Otherwise, you know, you could still end up with a very biased estimate.

375
00:39:58,152 --> 00:40:03,992
Okay. Um, why don't we come back here at 2:00 to finish up the rest of class?

376
00:40:11,377 --> 00:40:25,107
Okay. The last part of this is just talking about e values.

377
00:40:27,357 --> 00:40:31,467
So in the approaches we were talking about before.

378
00:40:34,397 --> 00:40:43,836
These ones. You know, we can basically through regression approaches, we can develop new weights,

379
00:40:43,837 --> 00:40:52,927
we can do multiple mutations to kind of try to recreate a better dataset, to conduct an analysis.

380
00:40:55,297 --> 00:41:00,637
And just, you know, as a heads up, I would say a lot of quantitative bias analysis aren't like your mean analysis,

381
00:41:00,637 --> 00:41:05,737
but this could be like a supplementary analysis that you put, like a sensitivity analysis that you put in a supplementary appendix.

382
00:41:09,357 --> 00:41:15,507
But one thing we could do instead is to calculate any value.

383
00:41:15,807 --> 00:41:20,697
So an E value is all about unmeasured confounders and potentially even unknown confounders.

384
00:41:23,227 --> 00:41:28,477
So what the value is trying to answer is what is the number?

385
00:41:28,807 --> 00:41:35,467
What is the strength of association that a confounder would have to have with the exposure and with the outcome?

386
00:41:35,797 --> 00:41:40,147
To explain away all of the observed X Y Association.

387
00:41:41,677 --> 00:41:44,737
So put more succinctly.

388
00:41:45,217 --> 00:41:59,857
Say that we have our. We have our analysis of coffee and diabetes and we just have like a few different confounders that we are putting in the model.

389
00:42:00,637 --> 00:42:06,787
But you know what? We you know, we find that we find a risk ratio of whatever of like 1.5.

390
00:42:07,837 --> 00:42:13,417
How strong would an unmeasured confounder have to be to make that 1.5 drop all the way to one?

391
00:42:14,017 --> 00:42:22,477
Because maybe, you know, we have some confounders and maybe those confounders will shift our value to like 1.4 and 1.6 or, you know, 1.3.

392
00:42:22,717 --> 00:42:25,777
Those are less important. But like, if it shifts it all the way down to one.

393
00:42:28,687 --> 00:42:31,657
That would mean that we don't have any significant results anymore.

394
00:42:32,347 --> 00:42:36,787
So basically the value is like at what point would we not have significance anymore?

395
00:42:37,057 --> 00:42:42,487
At what point would you know, like our confidence intervals crossed the boundary of one end,

396
00:42:42,487 --> 00:42:49,357
like in a more conceptual way, you know, how strong with the confounder have to be to explain the results that we felt.

397
00:42:55,217 --> 00:43:01,407
Okay. So what do we mean by this? This is an example of some sort of treatment and outcome.

398
00:43:02,397 --> 00:43:07,617
We have measured covariates that obviously we're controlling for in the analysis, but then we have an unmeasured confounder.

399
00:43:10,307 --> 00:43:13,327
And so for us, we have this risk ratio here.

400
00:43:13,337 --> 00:43:16,877
This is the treatment outcome. Risk ratio is the one that we're really interested in.

401
00:43:19,067 --> 00:43:29,927
But we also have a risk ratio from the the the or from the confounder to the exposure and then from the confounder to the outcome.

402
00:43:34,577 --> 00:43:40,637
So basically the value is what is the strength of these risk ratios?

403
00:43:40,637 --> 00:43:43,337
What how strong would these risk ratios have to be?

404
00:43:44,417 --> 00:43:49,787
What is the value of these risk ratios that we would have that could explain away this relationship?

405
00:43:53,267 --> 00:43:59,537
And of course, in a in a real setting, this risk ratio would have a different value from this risk ratio.

406
00:44:00,317 --> 00:44:04,067
But the value is just the lowest value for both of these.

407
00:44:04,277 --> 00:44:10,977
That's the exact same. So we'll get into some examples of this.

408
00:44:10,977 --> 00:44:16,257
But basically, you know, there's a pretty simple way of calculating the risk ratio.

409
00:44:18,897 --> 00:44:26,757
And in this example, the risk ratio is 3.9, and that means the value would be 7.26.

410
00:44:29,317 --> 00:44:37,296
So this 7.26 is kind of a value on this curve where the 7.26 is.

411
00:44:37,297 --> 00:44:45,157
What would the risk, as you have to be between the exposure and the the confounder and the confounder and the outcome,

412
00:44:45,727 --> 00:44:50,377
what would that risk ratio value have to be? And we're just assuming that be the worst.

413
00:44:50,737 --> 00:44:57,517
But there's actually a curve which is put together with this meaning that anything in this area up here,

414
00:44:58,057 --> 00:45:04,357
anything in the upper right quadrant, these are values that would explain away our results.

415
00:45:05,437 --> 00:45:07,957
So like if we had a value which was, you know,

416
00:45:07,957 --> 00:45:20,586
the confounder exposure had a value of 15 and it was ten between the confounder and the outcome that that of course,

417
00:45:20,587 --> 00:45:22,777
would be large enough to explain away everything.

418
00:45:22,987 --> 00:45:28,417
The 7.26 is just like the graphical representation of like the lowest values for both of these combined.

419
00:45:33,247 --> 00:45:43,117
Okay. So I have let's first actually do this small group discussion.

420
00:45:44,377 --> 00:45:48,607
So I will have you in your groups, calculate these values.

421
00:45:50,557 --> 00:46:02,287
And if you go online, there should be a table pasted at the end of your small group which has, you know, the equations from the, the, the slide deck.

422
00:46:04,177 --> 00:46:07,987
So I'll let you calculate these out and then we'll come back in a couple of minutes.

423
00:46:08,887 --> 00:46:15,487
I'll give you maybe until like 212 or so and then we'll we'll talk about this.

424
00:46:34,280 --> 00:46:41,080
So a risk ratio of 1.5. Here in the front, what is the value that you got for that?

425
00:46:46,860 --> 00:46:53,380
Yes. Okay. So we have 2.37 for this up here in the front.

426
00:46:53,400 --> 00:46:57,210
What is the risk ratio of 4.5? What is the value of you guys? We get 3.5.

427
00:46:58,200 --> 00:47:01,410
Yeah. 8.5. Okay.

428
00:47:01,740 --> 00:47:05,310
Pot roast for behind for risk ratio of 0.9. What did you get?

429
00:47:09,990 --> 00:47:14,600
I got a 1.46, but I'm willing to say that I got this wrong.

430
00:47:14,630 --> 00:47:22,070
The one thing with the researcher point nine is you first need to divide it by one.

431
00:47:27,330 --> 00:47:30,480
And then you use that like that inverse number.

432
00:47:34,030 --> 00:47:43,929
But I might have gotten this wrong. Did it? Did anybody else? Did anybody else have a different value?

433
00:47:43,930 --> 00:47:51,569
4.9. Fun frequencies in the back.

434
00:47:51,570 --> 00:47:56,270
4.5. Did you get something? Were you born?

435
00:47:59,050 --> 00:48:07,930
So I got 3.4. And this could be like, like a rounding error, especially since once you do inverse is like things go crazy.

436
00:48:09,850 --> 00:48:18,100
But for these, maybe the thing to do is like first you have to do like one minus this and then you put that everything.

437
00:48:37,900 --> 00:48:43,260
Okay. So odds ratio of 1.9 with the rare outcome surviving life in the back.

438
00:48:43,270 --> 00:48:58,300
What did you get for this? Yeah.

439
00:48:58,330 --> 00:49:01,970
For your group. What do you. Okay.

440
00:49:02,780 --> 00:49:06,110
What about this group over here? Did you finish it?

441
00:49:13,480 --> 00:49:18,870
3.21 and then up here in the front.

442
00:49:18,910 --> 00:49:29,050
So when they say that you have a common outcome for the odds ratio, there is you first need to do the square root of the odds ratio.

443
00:49:30,880 --> 00:49:36,710
If you remember, this is kind of a way to adjust for odds ratios just apparently being like a bit bigger,

444
00:49:36,730 --> 00:49:45,770
so square, but just like shrinks your odds ratio down a bit. Superintendent.

445
00:49:45,770 --> 00:49:49,390
Did you have an answer for that? You have to. Yeah.

446
00:49:52,070 --> 00:49:56,020
So these are the answers that I have for. This.

447
00:49:56,440 --> 00:50:03,870
I'm willing to entertain. Questions about what about this?

448
00:50:05,040 --> 00:50:09,660
I mean, I did it in Excel so hopefully I can just blame myself centered around.

449
00:50:12,470 --> 00:50:16,920
Okay. I would also like you to do an individual.

450
00:50:16,940 --> 00:50:21,560
So first, if you have any questions, please raise your hand. I can come by and talk to you about it.

451
00:50:21,800 --> 00:50:29,120
Otherwise, I put another call up for you to individually work on some questions.

452
00:53:01,079 --> 00:53:07,979
I'm sorry. I think this disconnects you. Okay.

453
00:53:09,629 --> 00:53:13,219
So again, we have a study the.

454
00:53:18,259 --> 00:53:22,309
The risk ratio that we find in this study is 3.9.

455
00:53:22,639 --> 00:53:25,999
That leads to a value of 7.7.26.

456
00:53:26,329 --> 00:53:34,249
But really, the 7.26 is just like the minimum value for both the exposure confounder and the confounder outcome relationship.

457
00:53:36,379 --> 00:53:43,399
It's the minimum value. But, you know, you could the value is sort of a crude word, like a block or a quadrant of everything above that.

458
00:53:45,079 --> 00:53:48,709
Okay. So say that we found this new variable U one.

459
00:53:49,459 --> 00:53:58,789
And for this variable, the relationship between the unmeasured confounder, you know, now newly measured confounder and the outcome is 5.2.

460
00:53:59,119 --> 00:54:03,229
In between the exposure and the confounders, 3.2.

461
00:54:03,679 --> 00:54:08,239
So basically this would just be like, you know, you need to find where this is on this chart.

462
00:54:08,629 --> 00:54:13,339
So 5.2 and 3.2 would be no link up here in here.

463
00:54:13,399 --> 00:54:22,039
So it's the numbers around here. Because this number is sort of on the lower left hand side of this curve.

464
00:54:22,369 --> 00:54:28,159
The answer is that there's a low likelihood that confounding could have explained away the original association.

465
00:54:33,739 --> 00:54:40,458
So everything over here means that there is like a large likelihood that confounding could have explained away this association here.

466
00:54:40,459 --> 00:54:45,948
It's not so, you know, this association could have you know,

467
00:54:45,949 --> 00:54:51,219
it could have dented it could have attenuated your relationship, but it's not going to completely explain it away.

468
00:54:51,319 --> 00:54:56,239
Like to explain it a pass the component of this significance.

469
00:54:59,719 --> 00:55:05,659
So another one found a value of 8.2 and 7.4.

470
00:55:06,019 --> 00:55:09,109
So 8.2 is kind of round here. 7.4 is here.

471
00:55:10,459 --> 00:55:16,759
To be honest, I don't know exactly where this would be on the slide. So this never was like a formal test question and make this a bit more obvious.

472
00:55:17,749 --> 00:55:26,419
But in my mind, this. If I had to guess myself, would it be?

473
00:55:27,379 --> 00:55:32,659
Yeah, I think it'd probably be b above this. But I also think this is very close to the line.

474
00:55:32,669 --> 00:55:35,869
So if that's what people were confused about, that's understandable.

475
00:55:36,319 --> 00:55:43,999
Again, the take away message is like if it's here in this upper right quadrant, then it'll explain away this original association.

476
00:55:43,999 --> 00:55:50,299
If it's here, it will not. Okay.

477
00:55:50,309 --> 00:55:57,329
So we have 15.2 and 6.1. So 15.2 would be like here, 6.1.

478
00:55:59,879 --> 00:56:05,539
I did not mean to make these so tricky, but but this actually might be something which does not explain very.

479
00:56:08,909 --> 00:56:13,209
Right. Well, I don't have a discussion past me about why he went so close to this line.

480
00:56:13,599 --> 00:56:18,338
But does it overall make sense, though, the idea that, like,

481
00:56:18,339 --> 00:56:23,958
if you have a value add here that represents something which could explain your association

482
00:56:23,959 --> 00:56:27,579
and could mean that like your your results are no and that there's no association,

483
00:56:27,909 --> 00:56:34,249
whereas if it's here, it's not going to be that way. So that makes sense to everyone.

484
00:56:35,149 --> 00:56:42,889
So the the p value is just like a simplified representation of like the lowest points or both of them together where they equal each other.

485
00:56:47,019 --> 00:56:51,729
Okay. That is.

486
00:56:54,639 --> 00:57:03,289
All I have for today. Again, the homework assignment is, you know, pretty straightforward, but, you know, it'll take a bit of time to code for it.

487
00:57:03,339 --> 00:57:07,658
If you have time over the next week, you know, it could be worth it just to,

488
00:57:07,659 --> 00:57:11,618
like, get it over with so that you only have one small assignment left in this,

489
00:57:11,619 --> 00:57:17,139
of course, along with the final exam, which is the president for the last year plus.

490
00:57:19,419 --> 00:57:25,899
Any questions? Okay. I hope that you all have a fabulous Thanksgiving and I will see you after the break.

