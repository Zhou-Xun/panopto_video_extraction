1
00:00:04,390 --> 00:00:13,690
All right, folks, let's bring on back where a few times I wish I had a Zoom poll or something that I could use to ask everyone these questions.

2
00:00:13,690 --> 00:00:18,310
Because I'm curious, I don't have the yelled out,

3
00:00:18,610 --> 00:00:25,390
but do you know which of these predictors has the strongest effect on aggressive, aggressive behavior?

4
00:00:25,870 --> 00:00:34,870
Raise your hand nice and high if you feel like you know. Okay.

5
00:00:34,870 --> 00:00:39,639
Second question, do you do you know which of these two models that ask you to run fits the data better

6
00:00:39,640 --> 00:00:44,950
raise your hand nice and high if you feel like you know how to do a good deal.

7
00:00:45,310 --> 00:00:48,850
All right. Well, let's go through it together. We'll see if let's see how we did.

8
00:00:49,120 --> 00:00:57,310
So the very first thing that I'm going to do and I will make this this solution set available for folks if you just kind of want to check it,

9
00:00:57,550 --> 00:01:09,340
is to read in the data here. It's just just one of multiple ways that we could have chosen to do this, the data or the two regression models.

10
00:01:09,340 --> 00:01:13,120
The first one was this just had sibling aggression and parenting style.

11
00:01:13,120 --> 00:01:16,419
I think the big thing that you would need to get here is picking out the right

12
00:01:16,420 --> 00:01:21,320
predictors and then making sure that your aggression variable is the outcome variable.

13
00:01:21,820 --> 00:01:25,059
Second one is what I call a saturated model.

14
00:01:25,060 --> 00:01:29,830
That's when we have every single predictor that we ultimately want to have in the data set.

15
00:01:29,830 --> 00:01:36,910
So that's what Line 30 is here. So it has the same two initial predictors as well as the another three.

16
00:01:37,600 --> 00:01:45,230
So starting with. Somebody interpret sibling aggression for me.

17
00:01:46,220 --> 00:01:51,530
Shout it out in anger. How would you interpret sibling aggression?

18
00:01:52,070 --> 00:01:59,690
For every unit increase of sibling aggression, there's a .09 increase in aggression.

19
00:02:00,410 --> 00:02:05,720
All right, go. So the unit increase in sibling aggression and we can look back to see what that is.

20
00:02:05,810 --> 00:02:10,310
So a unit increase, this was like some sort of means centered score.

21
00:02:10,310 --> 00:02:12,500
We'd have to look to see what kind of units might be.

22
00:02:12,500 --> 00:02:19,340
But if we have kind of we have an idea of what our variability is of like a standard deviation or something that kind of gives us a sense.

23
00:02:19,610 --> 00:02:26,810
But a one unit change in sibling aggression is associated with about 2.9 increase in aggression.

24
00:02:27,410 --> 00:02:34,220
With one important caveat one is that holding parenting style constant.

25
00:02:34,640 --> 00:02:43,160
Right. How much does this model explain how much variability in outcome but a 5% proxy that

26
00:02:43,910 --> 00:02:48,320
that's going to be the scary here one of these two conservative less conservative.

27
00:02:49,640 --> 00:02:53,510
Does this model fit the data? Well, yeah. How do you know?

28
00:02:54,290 --> 00:03:04,760
The answers to this is kind of a global fit or omnibus test of whether or not our model fits the data well, because it's a super low p value,

29
00:03:05,120 --> 00:03:11,540
we're kind of saying that our explained variability relative to our unexplained variability, that ratio is quite large.

30
00:03:11,810 --> 00:03:15,170
So our data fit the our model.

31
00:03:15,300 --> 00:03:19,940
The model fits the data with questions about any of this.

32
00:03:26,200 --> 00:03:30,190
Is this intercept interpretable? Jenna.

33
00:03:30,210 --> 00:03:34,800
You say why? Um, because there's no.

34
00:03:38,940 --> 00:03:45,550
I know. With their intercept intercept.

35
00:03:47,570 --> 00:03:55,650
Um. When?

36
00:03:58,110 --> 00:04:02,660
Absolute zero was not quite right.

37
00:04:02,670 --> 00:04:08,910
So this is our predictive value, the outcome variable when both sibling regression and parenting style are both zero.

38
00:04:09,630 --> 00:04:13,560
This is actually one of those interesting cases where a zero means has a meaningful

39
00:04:13,560 --> 00:04:17,639
value for parenting style and sibling regression because they're both mean centered.

40
00:04:17,640 --> 00:04:22,200
So when we have people at the median of parenting style in the mean of sibling regression,

41
00:04:22,830 --> 00:04:30,060
their predicted outcome is actually probably about mean aggression to how interpretable you feel that might be.

42
00:04:30,630 --> 00:04:36,900
But that's this is one case where having the intercept again predicted value

43
00:04:36,900 --> 00:04:40,250
and everything else in the model zero and could have some interpretability.

44
00:04:40,260 --> 00:04:48,650
That's one reason why folks on things that have those interpreted zeros excited to have a.

45
00:04:50,990 --> 00:04:55,460
Just that. Questions about this output. Oh, yeah.

46
00:04:56,500 --> 00:04:59,630
But just generally and I know that probably different.

47
00:04:59,660 --> 00:05:04,820
But when we're doing a little over a century.

48
00:05:05,670 --> 00:05:15,150
Does it matter? Aside from the first variable of this matter, putting in the other variables in our Allen like function.

49
00:05:15,480 --> 00:05:20,970
No. So the way that your regression outputs going to look,

50
00:05:21,390 --> 00:05:26,700
whether you have sibling regression versus different regression last, these coefficients should all stay the same.

51
00:05:27,180 --> 00:05:32,069
The caveat would be that ANOVA test that you can run afterwards to look at some of that variability.

52
00:05:32,070 --> 00:05:39,510
If you use that the default type one sums of squares, it's going to make that it's going to have that test relative to everything that came before it.

53
00:05:39,510 --> 00:05:42,839
In the model, if you use that type three sums of squares,

54
00:05:42,840 --> 00:05:48,360
that's when you can make it look essentially like the regression output where everything is tested right at once.

55
00:05:49,020 --> 00:05:56,400
So order doesn't matter for the elm part of things, it matters for the ANOVA, part of things.

56
00:05:56,850 --> 00:06:05,440
And if I were to make a decision about kind of order, I tend to put those vocal variables last just in case there was ever some,

57
00:06:05,520 --> 00:06:13,350
some situation where you were saying above and beyond everything else that I have in my model, does my focal predictor add value?

58
00:06:13,560 --> 00:06:18,930
Essentially, that's the most stringent test of whether or not my local predictor makes a difference.

59
00:06:21,170 --> 00:06:27,770
Yes. Do you run the just the first linear regression and do the summary and then your nova.

60
00:06:28,040 --> 00:06:32,900
I was having trouble remembering what really, you know, was telling us for that one regression model.

61
00:06:33,200 --> 00:06:40,730
Yeah. It's similar. It's it's essentially saying does each individual predictor explain some or reduce some of the residual variability?

62
00:06:40,740 --> 00:06:47,590
So does it explain its own significant piece of variability in the outcome or is there a little bit of redundancy there?

63
00:06:47,600 --> 00:06:57,380
So if you ever see a mismatch between the the summary of just a regression model and a nova of just a single model,

64
00:06:57,710 --> 00:07:00,130
it would be that there's probably some of the variable.

65
00:07:00,140 --> 00:07:07,180
Some of the variables are explaining the same amount of outcome variance or the same same chunk of outcome variance, a little bit of redundancy there.

66
00:07:08,990 --> 00:07:12,950
Hopefully they're going to align more often than not. There shouldn't be a whole lot of discrepancies there.

67
00:07:15,770 --> 00:07:20,030
That's one. Any questions about the outcome? Anybody get anything different than this?

68
00:07:27,940 --> 00:07:32,950
Yeah. Except for this one that what I was looking at was the.

69
00:07:35,320 --> 00:07:41,380
Multiple hours to a second one had a higher asking for our statistics.

70
00:07:42,610 --> 00:07:45,770
In that case, we're looking at the fact that the.

71
00:07:46,840 --> 00:07:49,940
One more experience, and that's Burger King.

72
00:07:52,610 --> 00:07:57,649
So you can think of this this multiple R squared with the same outcome variable,

73
00:07:57,650 --> 00:08:02,900
that's an effect size that's going to be comparable across any models where you have a regression is the outcome.

74
00:08:03,200 --> 00:08:07,100
If you're explaining more variability, that's a good thing for our particular outcome.

75
00:08:07,520 --> 00:08:14,600
This F statistic applies just to this model. It's independent of other F statistics that we would calculate with linear regression.

76
00:08:15,020 --> 00:08:23,660
So when you are just asking in this case, does the cost of having five predictors make it fit again fit the data well?

77
00:08:23,670 --> 00:08:32,090
Does the reduction in error that ratio explain variability relative to unexplained variability?

78
00:08:32,300 --> 00:08:35,480
Still quite positive. How positive?

79
00:08:36,050 --> 00:08:41,690
Based on our five degrees of freedom, our statistic is 12 compared to an F table, that type of thing.

80
00:08:46,350 --> 00:08:54,100
Any questions on any questions about this? Our statistic on the table doesn't matter.

81
00:08:54,930 --> 00:09:01,320
That's not what it does matter now, is this right?

82
00:09:01,920 --> 00:09:08,130
So this is doing what? Somebody walk me through this. What are we doing here?

83
00:09:08,250 --> 00:09:22,910
Why is 39 so important? They don't love making you see which of your regression models is the better x explanation.

84
00:09:27,530 --> 00:09:35,240
Yeah. So rather than trying to compare this F statistic with the one above it, this is actually a formal test to answer question two.

85
00:09:35,540 --> 00:09:40,960
We ran two models, both of which fit the data well. One of them is going to fit the data better.

86
00:09:40,970 --> 00:09:46,130
It's going to explain more variability in the outcome. We saw that model one explained about 5%.

87
00:09:46,430 --> 00:09:51,950
Now to explain about 8%, the eyeball test suggests that model two should be a better fitting model.

88
00:09:52,490 --> 00:09:58,790
That said, any time we add predictors, any time, all things being equal, same sample size, whatever.

89
00:09:59,090 --> 00:10:04,220
We will explain exactly as much or more variability in the outcome.

90
00:10:04,520 --> 00:10:09,080
Just by random chance, you don't explain less variability by adding predictors.

91
00:10:10,040 --> 00:10:12,690
Does that make sense? Right.

92
00:10:13,220 --> 00:10:23,450
So this is really kind of a question of whether or not the cost of adding three new predictors is worth the change in our square that we find.

93
00:10:24,170 --> 00:10:28,670
Was that 3% change in R squared kind of worth this loss of degrees of freedom?

94
00:10:29,570 --> 00:10:36,500
What this test tells us is, in fact, that, yes, model two is a better fit to our data than model one.

95
00:10:37,160 --> 00:10:42,850
And that's your first answer to this particular question. Questions about that.

96
00:10:43,930 --> 00:10:47,900
You will absolutely need to do this for your midterm. How does it sound?

97
00:10:49,790 --> 00:10:59,030
It's explaining the reduction and residual, sometimes worse relative to a cost of the cost of adding new predictors.

98
00:10:59,420 --> 00:11:07,760
So this becomes a chi square test that follows a specific distribution that we can then map on to, in this case, enough test.

99
00:11:08,090 --> 00:11:16,560
And it's just chi square transfer. So we're just looking for that significant square to see that.

100
00:11:17,990 --> 00:11:23,090
Exactly. And so these models I've said it before, but I'll say it again, these models are nested.

101
00:11:23,480 --> 00:11:28,100
This model here, model one is nested because it has two of the same predictors.

102
00:11:28,430 --> 00:11:30,680
And then this model two has a few additional ones.

103
00:11:31,130 --> 00:11:36,770
We could continue to test nested models so long, as you know, for example, another or another model.

104
00:11:36,770 --> 00:11:42,090
If we had yet one more variable and it would have to have this one, this one, this one, this one and this one.

105
00:11:42,110 --> 00:11:48,230
And then we could add one model too, and one would be nested because it has the exact same predictors.

106
00:11:48,410 --> 00:11:51,139
Nothing new when you don't have a nested variable.

107
00:11:51,140 --> 00:11:58,910
Like if we had some third variable here that was called whatever school experience, we could no longer use this test.

108
00:11:58,910 --> 00:12:02,560
It has to have the same the same covariance or the same predictors.

109
00:12:06,240 --> 00:12:11,700
So we ran into this a little bit with a homework assignment when folks to friend alcohol use heroin,

110
00:12:11,700 --> 00:12:15,510
alcohol use or adult alcohol use and future orientation.

111
00:12:15,840 --> 00:12:25,380
If you're trying to maybe if you're trying to use an egg and another test like this, you can't have a model that has parent use in future annotation.

112
00:12:25,620 --> 00:12:30,510
And to test it against one that has peer use in future agitation that makes sense for.

113
00:12:32,800 --> 00:12:37,600
Yeah. So can you explain a little bit more? What do you mean exactly?

114
00:12:37,600 --> 00:12:45,130
Like in the context is like how many accidental variable predictors you have that generally.

115
00:12:46,030 --> 00:12:52,450
Yeah. So degrees of freedom are the number of observations in your data set that are free to vary.

116
00:12:52,900 --> 00:13:01,450
That's a formal definition is basically means that we don't have to fix values when we have a lot of degrees of freedom.

117
00:13:01,450 --> 00:13:04,210
Any time that we calculate or estimate a parameter,

118
00:13:05,110 --> 00:13:13,840
we are in effect fixing a value because at least one of the observations in our dataset will no longer be free to vary.

119
00:13:14,410 --> 00:13:19,150
And the best example I can give you is that you take the mean of 5 to 5 values.

120
00:13:20,170 --> 00:13:33,910
If I tell you those first four values are all threes in the mean of our dataset is one that's right here by three.

121
00:13:34,420 --> 00:13:38,830
And then that fifth value, you know, has to be a three as well.

122
00:13:41,440 --> 00:13:47,780
Okay. Any time you calculate an intercept, a beta coefficient of variance.

123
00:13:47,780 --> 00:13:54,260
Now at some point you are going to have to take one of the values in your data set and fix it to something.

124
00:13:55,070 --> 00:13:59,420
Right? Just so that the math all works out, you lose a degree of freedom.

125
00:14:02,070 --> 00:14:09,570
More practically. Any time you add a predictor in your regression equation, you calculate a new beta coefficient.

126
00:14:10,080 --> 00:14:13,290
That beta coefficient is going to cost you one degree of freedom.

127
00:14:14,190 --> 00:14:22,950
So we can work backwards from our original Degrees of Freedom 666 and 666 observations that were free to be whatever we want them to be.

128
00:14:23,520 --> 00:14:25,530
And then as we add predictive values,

129
00:14:26,040 --> 00:14:31,080
we're going to lose some of those degrees of freedom because we're going to have to calculate these parameter estimates.

130
00:14:31,560 --> 00:14:35,270
The intercept data values the various parameters that.

131
00:14:37,300 --> 00:14:40,750
I see your furrowed brow, but your intuition is right.

132
00:14:41,110 --> 00:14:47,750
We lost three pretty we lost three degrees of freedom because we added one, two, three printers.

133
00:14:51,050 --> 00:14:56,720
That's by and large, when we're making these kind of moral comparisons,

134
00:14:56,990 --> 00:15:03,260
those are the degrees of freedom that we're talking about when we have enormous we have to think about the grouping variable as well.

135
00:15:03,590 --> 00:15:08,240
So it's the number of observations within as well as the number of groups between.

136
00:15:08,710 --> 00:15:14,870
Right. So we have to think of our degree differences a little bit differently because that group is as well as individual individual observations.

137
00:15:15,890 --> 00:15:19,580
Every time that we talk about one of those statistics from our sample,

138
00:15:20,270 --> 00:15:24,410
each one of those statistics is going to cost us the degree of freedom and the more of those we have.

139
00:15:25,550 --> 00:15:30,820
Less and less than we can do in terms of our influence.

140
00:15:31,390 --> 00:15:33,010
And that's where it really becomes tricky.

141
00:15:33,030 --> 00:15:38,890
So as you start to run really, really low in degrees of freedom, we're not going to worry about it because we have 666 people.

142
00:15:39,160 --> 00:15:44,110
But if our sample size was only 20 and we had six murders, if we lost six degrees of freedom,

143
00:15:44,500 --> 00:15:48,450
then you're going to start to see a much higher standard every month.

144
00:15:48,460 --> 00:15:53,800
A lot of you have a lot harder time trying to get across, so it really has the most implications in the small sample size.

145
00:15:56,080 --> 00:16:00,800
That means we lost that family because each one of these.

146
00:16:01,240 --> 00:16:05,800
Yeah, right. Yeah. And this is I mean, this is all pretty straightforward.

147
00:16:06,070 --> 00:16:08,560
But when we get into things like structural equation modeling,

148
00:16:08,920 --> 00:16:14,350
we actually going to be talking about tons and tons of parameters because we not only have pathways,

149
00:16:15,130 --> 00:16:20,290
data, coefficients between variables, but then we have all sorts of error terms that we're going to be adding in.

150
00:16:20,290 --> 00:16:26,439
So you're going to have models that have hundreds of degrees of freedom, which is problematic.

151
00:16:26,440 --> 00:16:39,910
We only have a couple hundred observations. Other questions about this.

152
00:16:46,010 --> 00:16:56,270
So now that I know that Model two is my favorite model, I can decide whether or not I want to play around and look at some of the diagnostics.

153
00:16:56,600 --> 00:17:00,260
So this what is the stand for and what is it doing for us?

154
00:17:02,780 --> 00:17:08,190
Now you're reading the thing. What is it? What does it mean? What does it mean?

155
00:17:08,210 --> 00:17:11,300
Why do you care about via for various inflation factors?

156
00:17:17,310 --> 00:17:24,150
There's nothing back there now. They're just doing it on purpose. PALMER Well, I mean, what is very severe he us.

157
00:17:28,740 --> 00:17:32,709
Easiest biter on Wednesday. I'm somebody sitting in reserve.

158
00:17:32,710 --> 00:17:37,470
I mean, I forget. No, that's.

159
00:17:37,900 --> 00:17:41,550
It's a good question. What does it mean? What does it mean? Multiple narrative.

160
00:17:41,610 --> 00:17:46,310
That's exactly what the app is telling us. The.

161
00:17:48,940 --> 00:17:53,000
Yeah. It's telling us we're not. Was and.

162
00:17:58,930 --> 00:18:06,490
Right. We're looking at the correlation between the opportunities for early calling .8.9.

163
00:18:06,670 --> 00:18:10,360
They're basically telling us the exact same information, the redundancy.

164
00:18:11,110 --> 00:18:13,930
So we are looking for the statistics that are like ten.

165
00:18:14,680 --> 00:18:22,860
By rule from ten is a huge that's a revenue value that probably uses them more later 2.7 or more.

166
00:18:23,460 --> 00:18:27,310
We don't want variables that correlate in the end are supporting the same things

167
00:18:27,310 --> 00:18:35,830
and we want to have some kind of revert to answer where with the reciprocal,

168
00:18:35,830 --> 00:18:40,930
the variance inflation factor. I mean, kind of just the same kind of the same sort of idea.

169
00:18:40,930 --> 00:18:45,160
It's just a linear transformation. So it should we should be seeing values that are.

170
00:18:47,630 --> 00:18:50,900
We don't want one divided by 10.1 getting.

171
00:19:00,330 --> 00:19:03,780
Right. So if you saw one value that was closer to ten,

172
00:19:03,780 --> 00:19:09,210
what I would do is run that correlation matrix and see which of you will tell you which variable is problematic,

173
00:19:10,170 --> 00:19:14,760
but you can see which ones are highly correlated as the good question.

174
00:19:19,180 --> 00:19:24,780
Yes. No. Ari Fleischer on dynamic numbers.

175
00:19:27,490 --> 00:19:31,370
I wonder why I haven't gotten here? Very.

176
00:19:34,260 --> 00:19:37,620
That's in the car package. You're going to have to build that one.

177
00:19:37,620 --> 00:19:42,780
Yeah. Either installed or in your library. Even.

178
00:19:42,900 --> 00:19:46,050
They don't have to install them for me every time.

179
00:19:46,380 --> 00:19:49,740
You should know there is a check to see if you can just load a library.

180
00:19:49,740 --> 00:19:55,229
Car is the name of the package. Uh, let's see here.

181
00:19:55,230 --> 00:19:59,400
The Durban Watson of Test. What's it telling us?

182
00:20:04,880 --> 00:20:12,520
Yeah. You got it. What does that mean? The variables are not.

183
00:20:14,610 --> 00:20:20,630
The variables. And the observations, it or not.

184
00:20:22,520 --> 00:20:27,440
Yeah. Yeah, exactly. So we're looking to make sure that there's not any sort of dependency within the data.

185
00:20:27,710 --> 00:20:31,940
And if you see that, for example, when the same people respond multiple times,

186
00:20:31,940 --> 00:20:36,019
the repeated measures we are, we'll talk about clustering in a couple of weeks.

187
00:20:36,020 --> 00:20:40,610
If it's clustering by neighborhood or by some other grouping variable and as time as another.

188
00:20:41,610 --> 00:20:45,420
Spatial autocorrelation. So things that are kind of captured in the same space.

189
00:20:46,460 --> 00:20:50,820
I'm very sorry, but let's see here.

190
00:20:50,820 --> 00:20:55,240
Histogram of residuals. It's you ever see this margin's too large.

191
00:20:55,240 --> 00:20:58,340
It's because you just need to make your table thing bigger. Longer. That right.

192
00:20:58,430 --> 00:21:01,770
That. Oh, my goodness. Never, never hear this.

193
00:21:01,800 --> 00:21:05,400
Yes, you'll never see it. But what is this telling us? What are we testing here?

194
00:21:05,400 --> 00:21:12,510
Why would we run a histogram of the residuals? What are we looking for? Normal distribution.

195
00:21:12,520 --> 00:21:17,410
Yes, yes, yes. We're looking to see if the assumption is that our errors,

196
00:21:17,770 --> 00:21:22,060
a residual is just the difference between what we predict the model and what we actually observed.

197
00:21:23,020 --> 00:21:26,590
And we would want to see most of those values clustered around zero.

198
00:21:27,400 --> 00:21:31,660
And in an ideal world, we see a relatively normal looking distribution.

199
00:21:33,560 --> 00:21:45,320
Questions about this. This is not what the data look like, but this is what the data could look like if you're, of course, the engineer.

200
00:21:45,580 --> 00:21:51,520
So you would think there's residuals when you want to make sure they're standard.

201
00:21:54,730 --> 00:21:58,960
Yes. So student students and standardized residuals are very, very similar.

202
00:21:59,320 --> 00:22:03,970
One is just forcing them into a Z distribution, like a standard normal distribution.

203
00:22:04,270 --> 00:22:11,740
The other one is forcing them into a student's T distribution, which is like a normal distribution, but it kind of has fatter tables.

204
00:22:12,460 --> 00:22:16,450
So you just have a few more observations that we might call those kind of extreme values,

205
00:22:17,050 --> 00:22:25,750
which sometimes looks a little bit better in practice with smaller data sets that still have kind of a roughly normal shape.

206
00:22:26,620 --> 00:22:26,880
Okay.

207
00:22:27,430 --> 00:22:37,840
Now as data sets get large thinking like 150 observations or more a Z distribution and a T distribution student's T distribution with the exact same,

208
00:22:38,290 --> 00:22:46,519
they become the same. They're asymptotically similar. Which means big samples.

209
00:22:46,520 --> 00:22:50,190
They become the same, sir. So that is what I want to do.

210
00:22:50,190 --> 00:22:55,469
And mainly to say that if you had 60 observations, I would use student based values.

211
00:22:55,470 --> 00:23:02,280
If you had 150 or 660 or 850, like when you would have standards find other ones, but they should not be much different.

212
00:23:02,280 --> 00:23:05,759
A matter of fact, I think I plan on both here. Let's see here.

213
00:23:05,760 --> 00:23:11,639
So here in this one, plotting the predicted values versus the residuals.

214
00:23:11,640 --> 00:23:15,780
And I throw this on here. Anybody I have an idea, remember why we do this.

215
00:23:18,120 --> 00:23:21,390
This is our field values versus our residuals.

216
00:23:22,290 --> 00:23:25,590
And I remember we we we did this a lot with Bivariate.

217
00:23:28,720 --> 00:23:34,020
I think I had Bivariate example. But you know what we're looking for here?

218
00:23:39,660 --> 00:23:44,670
A terrorist, something that you hetero something is homogeneity of variance, right?

219
00:23:45,000 --> 00:23:53,100
So what we're seeing is instead of just one X value and making sure that we have roughly kind of the same variability across each one,

220
00:23:53,310 --> 00:23:57,240
we can use the entire model. That's what these fitted values are.

221
00:23:57,240 --> 00:24:00,450
That means as put everybody's values into the equation, right?

222
00:24:00,450 --> 00:24:06,810
And so at each level of valid values, do we see roughly the same kind of distribution around zero?

223
00:24:07,840 --> 00:24:12,170
Because that's what we're looking for over there. Would you say that that's kind of cluster?

224
00:24:12,900 --> 00:24:16,410
Definitely a cluster. But what we're really care about is kind of the variability up and down.

225
00:24:16,500 --> 00:24:29,580
Yeah. Okay. Yeah. I don't know why this is so far out of order, but this is my answer to question one.

226
00:24:30,390 --> 00:24:35,180
You may remember what this commandos force 65 year mission.

227
00:24:36,190 --> 00:24:41,690
Yeah. What does it do to coefficients which. How does it do that?

228
00:24:48,590 --> 00:24:54,890
Yes. A standardized coefficient. So it standardized is every single variable, every single predictor in the model as well as the outcome variable.

229
00:24:55,280 --> 00:24:59,690
And when we do that, we put all of the predictor values on the same scale.

230
00:24:59,930 --> 00:25:03,740
Now they are actually printed. They look like they're all pretty close to the same scale anyways.

231
00:25:03,980 --> 00:25:10,580
So we might not see major deviations from what we see with the yellow beta function than we did with the actual model output.

232
00:25:11,000 --> 00:25:17,120
But what this is telling us now is which of these variables is the strongest predictor of regression?

233
00:25:22,160 --> 00:25:26,830
They may agree. Right. We can take the absolute value of all this.

234
00:25:26,960 --> 00:25:30,950
This would be you could take this as a positive point one, 1.8.11.

235
00:25:32,030 --> 00:25:36,560
But parenting style 8.18 is the strongest predictor.

236
00:25:36,570 --> 00:25:40,790
It has the largest effect size on our outcome, variable aggression.

237
00:25:41,300 --> 00:25:45,560
So if we wanted to figure out what what is, explain the most variability in our outcome variable.

238
00:25:46,040 --> 00:25:49,549
It's parenting style. If I had to choose of all these five variables,

239
00:25:49,550 --> 00:25:53,240
which one I would want to know if I'm going to try to predict at random somebody's aggressive behavior.

240
00:25:53,630 --> 00:25:54,620
Tell me about their parents.

241
00:25:55,520 --> 00:26:05,509
Don't bother telling me about how much TV time they watch or the kind of or whether or not their their siblings fight all the time.

242
00:26:05,510 --> 00:26:12,810
My kids for all the time that so. Does that make sense?

243
00:26:13,500 --> 00:26:20,280
Yeah. So does that mean that computer games would be the second predictor of aggression?

244
00:26:20,640 --> 00:26:27,090
Which one? Computer games? Yeah. Computer games is the next largest effect size because it is at point one.

245
00:26:27,750 --> 00:26:33,930
So playing, like, violent video games or something. I'm out of date.

246
00:26:34,050 --> 00:26:37,880
I have no idea if that's really what, whether it's computer games and parenting style,

247
00:26:37,950 --> 00:26:42,080
but that's how we can think about if we had five to choose from, you know,

248
00:26:42,090 --> 00:26:45,120
which of these variables seem like they're having the largest impact in our outcome,

249
00:26:45,390 --> 00:26:52,500
which is kind of interesting and gives us some guidance in terms of maybe if we're going to focus an intervention, where are we going to focus here?

250
00:26:53,310 --> 00:26:56,550
Doesn't need to be on how many hours of TV they watch. Right.

251
00:26:56,670 --> 00:27:01,770
Maybe we should be thinking about some of the relationships that are in our lives, particularly how our parents might be engaging with their kids.

252
00:27:02,310 --> 00:27:05,680
If this was really. Questions about this.

253
00:27:07,060 --> 00:27:10,390
I want to see this, too. And you see this quite as much as the whole works, and that's okay.

254
00:27:10,690 --> 00:27:15,340
But this is going to help us when we have a whole bunch of variables that are on different scales, especially.

255
00:27:15,550 --> 00:27:19,090
These are all mean centered variables. They're kind of funny because they're just an example.

256
00:27:19,330 --> 00:27:26,860
But when you have some that are 1 to 5, you have others that are ten to to 100, and you have others that are 0 to 150000.

257
00:27:27,670 --> 00:27:32,799
Those the standardization process becomes really important because now we're comparing

258
00:27:32,800 --> 00:27:39,760
apples to apples rather than apples to oranges and grapes and a name for it to do.

259
00:27:40,480 --> 00:27:45,700
I feel like this is way out of order. Sorry. Confidence intervals is just giving us an idea of the range.

260
00:27:45,700 --> 00:27:48,880
So, you know, our our regression.

261
00:27:49,330 --> 00:27:52,410
Our regression output gives us plant estimates, right?

262
00:27:52,420 --> 00:27:53,770
It's like a single value.

263
00:27:54,040 --> 00:27:59,740
We said, okay, well, that's a one unit increase means this much change, but we have to recognize that our model is never perfect.

264
00:28:00,250 --> 00:28:06,310
Right? And so we can have a range from which our values are plausible in terms of what those benefits actually could be.

265
00:28:06,730 --> 00:28:12,850
And that's what our confidence intervals is going to tell us. So we can see that well, as in parenting style, that was the most important.

266
00:28:13,690 --> 00:28:21,030
It started out our point estimate was. Point estimate for parenting style is 0.06.

267
00:28:21,030 --> 00:28:25,080
A unit change in parenting style was a .06 change in our outcome variable.

268
00:28:25,410 --> 00:28:32,850
Well, it turns out that .06 could plausibly be as small as 0.03 or as large as 0.09.

269
00:28:34,020 --> 00:28:39,360
Right. Which is kind of interesting, too. And if you see huge you like huge spreads,

270
00:28:39,870 --> 00:28:44,579
you know that that's less that's less comforting than if we have a nice kind of

271
00:28:44,580 --> 00:28:48,270
precise measurement because we we know where these things are roughly going to be.

272
00:28:48,630 --> 00:28:52,380
So in a perfect world, we would want to see nice, tight confidence intervals.

273
00:28:52,740 --> 00:28:58,110
But if they vary quite largely like computer games, I mean, look at that. That could go anywhere from point aa7 all the way up to .21.

274
00:28:58,710 --> 00:29:04,560
So it might be that we I mean, that computer games could be having some of the largest impact.

275
00:29:04,560 --> 00:29:09,390
But again, that's where your own data can be kind of helpful.

276
00:29:09,960 --> 00:29:16,140
So you're not skewed by some of those which make a lot of the original point estimates or the original metrics.

277
00:29:17,700 --> 00:29:21,120
Just say, folks, no, I think we saw this in class.

278
00:29:21,870 --> 00:29:25,530
You can just run this plot function on an on a regression outcome.

279
00:29:25,770 --> 00:29:32,849
You're going to get some of these assumptions that can be helpful for you here.

280
00:29:32,850 --> 00:29:34,440
Residual values versus stated.

281
00:29:34,740 --> 00:29:40,240
Just the same thing is that almost greater certainty is going to tell you where there's potentially not or it's kind of pulling this line down.

282
00:29:40,240 --> 00:29:44,010
That's probably also a good indication that this is an outlier or there's some leverage here.

283
00:29:44,430 --> 00:29:49,410
So ideally, we would see this line that they're trying to auto generates to be just get across zero.

284
00:29:50,160 --> 00:29:54,959
But that's the end of the scale where we might have a little bit of concern. We didn't really do this too much.

285
00:29:54,960 --> 00:29:59,100
But if you want to think about your residuals and whether or not they're normally distributed, we saw that graph.

286
00:30:00,210 --> 00:30:04,230
If you use, you would want to see all these dots more or less along this diagonal line.

287
00:30:05,010 --> 00:30:13,110
Yeah, exactly. So and when I did this moment, if I was doing something wrong now, even with perfect data, look.

288
00:30:13,260 --> 00:30:16,979
Yeah. And the problem here again is large sample sizes.

289
00:30:16,980 --> 00:30:23,370
Remember, like with correlations, anytime you have big, big sample sizes, even a small change away from zero can be significant.

290
00:30:23,700 --> 00:30:28,230
And that's what probably we're picking up on here is that we have 666 observations.

291
00:30:28,560 --> 00:30:31,620
There's going to be a little bit of divergence away from a normal distribution.

292
00:30:31,950 --> 00:30:37,740
But by and large, most of this stuff and if you were going to be worried about things, I'd be worried about the tails.

293
00:30:38,130 --> 00:30:41,310
So maybe we would take out the highest and lowest values or something like that.

294
00:30:41,310 --> 00:30:46,680
We could think about trimming our data in that regard, but that means losing observations.

295
00:30:46,680 --> 00:30:52,830
And what kind of decisions are we making this and why should we drop 157 just because they're a little bit further away from,

296
00:30:53,280 --> 00:31:03,240
you know, our expected normal distribution? Yeah. So this will just give us the two or three values for a this gives you one more.

297
00:31:05,010 --> 00:31:10,080
These are just auto generated. You could do you could calculate any of these that you wanted to you could just and by themselves,

298
00:31:10,350 --> 00:31:17,069
it's just using that plot variable for the sake of kind of expediency here or for plots that might be worth taking a

299
00:31:17,070 --> 00:31:24,480
bigger well are identify those like yeah it's doing this without me doing anything all I did was run low line 73 here.

300
00:31:24,780 --> 00:31:30,959
It's just the regression object and plot. This is just the square root of the standard standardized residuals.

301
00:31:30,960 --> 00:31:40,710
Again, you want to see something that's roughly straight across, and I really use this very often.

302
00:31:43,330 --> 00:31:50,680
All right, folks, I know we're running low on time here. We saw these last two weeks ago cooks distance.

303
00:31:50,830 --> 00:31:57,100
What is that again? It is a distance.

304
00:31:57,110 --> 00:32:03,550
What kind of distance? What does it tell us? L.

305
00:32:03,680 --> 00:32:12,889
Ayers Yes. And see, I can see my residuals, standardized residuals I'm doing in line 76 through 79 years.

306
00:32:12,890 --> 00:32:18,460
I'm creating variables hat values better head those no.

307
00:32:19,610 --> 00:32:24,030
But expect, you know, something to do with distance but not an outlier.

308
00:32:24,080 --> 00:32:29,970
It's. Certainly no leverage.

309
00:32:30,180 --> 00:32:34,570
Yes. So this is whether or not something's getting pulled like so residuals versus leverage here.

310
00:32:34,800 --> 00:32:37,440
Whether or not we have observations that are pulling this line away.

311
00:32:40,110 --> 00:32:47,930
And I sure I think so, because when we say variables like we do 76 or 80 here, I'm creating a whole bunch of new variables in my dataset.

312
00:32:48,380 --> 00:32:50,220
All right. That's what I'm taking my data frame.

313
00:32:50,460 --> 00:32:55,560
I'm adding these new names, and they're based on some things that were already created within my regression object.

314
00:32:55,830 --> 00:33:01,560
Now I have outliers, and I have residuals and standardized residuals and student times residuals.

315
00:33:01,740 --> 00:33:05,760
Same thing. Don't worry about leverage. This is my influence values.

316
00:33:06,030 --> 00:33:12,239
We can use those rules of thumb cook values over to leverage values greater or close to 5.2.

317
00:33:12,240 --> 00:33:17,010
One is what we're worried about, right? Whether or not we're really going to mess around with too much of this.

318
00:33:17,250 --> 00:33:23,100
It's kind of up to you, Gina. I was going to ask if influential observations are the same thing.

319
00:33:23,160 --> 00:33:28,800
Yep. Same thing's leverage. Yeah. So we can again use some of those rules of thumb to say, all right, well,

320
00:33:29,100 --> 00:33:34,440
do we have any Kirk's values that are or standardized residuals are the ones that are greater than to.

321
00:33:35,420 --> 00:33:37,140
And it prints out something like this.

322
00:33:40,080 --> 00:33:46,799
Let's see, this is creating so I'm using the line from 84 here to create a new variable that's going to basically say,

323
00:33:46,800 --> 00:33:50,700
if you were true for this one, you were greater than two, you're a big residual.

324
00:33:53,490 --> 00:34:02,850
And then I could sum those up. So we had 37 out of 666 observations that had standardized residuals that were greater than two or less than minus two.

325
00:34:03,360 --> 00:34:10,680
Those would be our big residuals. And we should see about what percent of those should be of 666 should be big residuals.

326
00:34:15,710 --> 00:34:25,820
Yeah. Right. 5%, right. Would do say two and a half on one side to have on the other, it's about 5% and it's 30, 75% of 666.

327
00:34:27,430 --> 00:34:31,270
It's pretty darn close. Closer than we'll ever get to practice. I'd be like 33, right.

328
00:34:31,600 --> 00:34:33,520
So this is data go figure is good.

329
00:34:34,810 --> 00:34:41,620
And you can play with some of these the the the different values to take a look at this try to figure out who is dead,

330
00:34:41,920 --> 00:34:45,490
who has high leverage statistics. Should we go look at those individual cases?

331
00:34:45,830 --> 00:34:51,610
Right. So that's more of what we can actually do in practice with some of these kind of strange things that get tucked away in a regression object.

332
00:34:52,060 --> 00:34:55,540
All right, folks, we are at time past on now.

333
00:34:58,000 --> 00:35:01,450
Are we feeling okay about this? Oh, yeah. Oh, yeah.

334
00:35:02,410 --> 00:35:05,770
Good. Because I'm to give you your exam now. I am.

335
00:35:05,860 --> 00:35:11,979
But we're going to talk about the time frame, and I'm going to give folks a lot more time than I normally would, knowing that on Thursday.

336
00:35:11,980 --> 00:35:17,080
And we're going to go through some of this measurement stuff now into next week, next week, two weeks, this fall break.

337
00:35:18,010 --> 00:35:22,450
I want folks to have enough time to work on the midterm, but I also don't want to drag until the end of the semester.

338
00:35:22,780 --> 00:35:25,810
So I'm going to give you some kind of time to eliminate the limitation.

339
00:35:26,350 --> 00:35:28,510
I don't think it's going to take you three weeks to do,

340
00:35:28,780 --> 00:35:33,670
but you'll have it for at least a good chunk of time so that you can make sure that you can apply these ideas.

341
00:35:34,000 --> 00:35:37,479
All right. Let's see, is the next week or two weeks?

342
00:35:37,480 --> 00:35:40,870
I can't remember. I don't see. But if you want now.

343
00:35:42,730 --> 00:35:47,020
So next Thursday, we have a guest speaker coming in talking about hazard modeling.

344
00:35:47,350 --> 00:35:53,650
So I would love for folks to join. That's what you do if you have a situation where you think people are going to drop.

345
00:35:54,100 --> 00:35:57,640
So like how long is it going to take before someone drops out of my study?

346
00:35:57,850 --> 00:36:02,800
How long does it need is going to take before someone expires? How long does it take before a drug stops working?

347
00:36:03,040 --> 00:36:06,910
Those are the types of models that we can your questions we can ask with Cox regression or hazard models.

348
00:36:07,720 --> 00:36:11,080
Okay well. That's it.

349
00:36:11,800 --> 00:36:16,600
Go home. Be married. We'll start. We'll talk factor analysis on Thursday.

