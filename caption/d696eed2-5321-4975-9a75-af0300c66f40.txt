1
00:00:07,560 --> 00:00:14,070
Okay. So another thing is that no one for Tuesday is not.

2
00:00:14,240 --> 00:00:19,770
And today we are looking at the overall picture of direction of this course.

3
00:00:20,400 --> 00:00:22,920
Will that are we actually all the members?

4
00:00:22,950 --> 00:00:29,760
One thing is they really do have some new concepts, but these are all these are sort of the big picture stuff.

5
00:00:30,540 --> 00:00:34,469
Later throughout this measure, go through much more detail.

6
00:00:34,470 --> 00:00:42,270
Look at each of these things we measure. So at this stage, I mean, we actually even know the details.

7
00:00:43,050 --> 00:00:48,780
So it's okay if there are if there are questions, there are things like this.

8
00:00:49,230 --> 00:00:57,000
Because later as well, we are going to dove into, you know, are you look at the more details about each of these things we mentioned.

9
00:00:58,350 --> 00:01:06,360
So I would like to start from here on the locality narrative because after the lecture on Tuesday,

10
00:01:06,420 --> 00:01:11,160
there are five questions about you know, especially about.

11
00:01:18,010 --> 00:01:23,350
Especially about the ones making it impossible to compute the patents they have.

12
00:01:24,670 --> 00:01:27,730
So here we could just think of this from two aspects.

13
00:01:28,690 --> 00:01:31,990
One is small from in terms of intuition.

14
00:01:32,200 --> 00:01:36,880
So intuitively, let's say if you run a regression model, linear regression model,

15
00:01:37,000 --> 00:01:43,690
you have two covariance lysate and let's consider a severe case where this can combat or is there exactly the same.

16
00:01:44,270 --> 00:01:55,450
And for our age, let's say you are running on a lot Azure and that's really passed on to covariance over any class that I didn't tell you.

17
00:01:56,050 --> 00:02:03,390
These two areas are the same. I'm just passing on. The data that you just saw is these two covariates and with a response and you

18
00:02:03,400 --> 00:02:08,560
are running the model now because these two covariates are exactly the same now.

19
00:02:08,920 --> 00:02:16,150
But in fact. But we cannot distinguish their effects on the on the response.

20
00:02:16,360 --> 00:02:24,309
So in other words, I could actually increase the fact of one commonality, the slightly more and decrease another one a little bit.

21
00:02:24,310 --> 00:02:29,680
Correspondingly, I could I would have down to the same model fit or because they are exactly the same covariance.

22
00:02:30,130 --> 00:02:36,459
So that's the intuition behind you know why here we see that it may be impossible to calculate this

23
00:02:36,460 --> 00:02:41,920
mean it is because we can now determine them because they are obvious to comparison exactly the same.

24
00:02:43,120 --> 00:02:48,429
And that's that's like intuitive explanation.

25
00:02:48,430 --> 00:02:56,020
So mathematically the reason that we may not be able to communicate that is that the well,

26
00:02:56,020 --> 00:03:00,010
we have two columns or two covariance that are highly correlated.

27
00:03:00,670 --> 00:03:03,850
Now even consider the later we're gonna talk about again.

28
00:03:05,010 --> 00:03:07,899
We're going to have details later when we counter this better.

29
00:03:07,900 --> 00:03:15,340
JS We have a table that emerge emerge a matrix that is our matrix that involved this two columns of X.

30
00:03:16,390 --> 00:03:25,540
And if that was are highly correlated, then the matrix is that is so-called conditioned in a way invert that matrix,

31
00:03:25,540 --> 00:03:29,780
you are going to get a really large inverse and of that order.

32
00:03:29,800 --> 00:03:34,360
But when these two column are perfectly correlated, then the matrix is not a vertical.

33
00:03:34,630 --> 00:03:46,500
So that's the reason why it's not impossible to compute this energy patch when when some cold areas are highly correlated.

34
00:03:46,510 --> 00:03:50,770
This also explains why when we have a huge there's been a JS,

35
00:03:50,770 --> 00:03:58,720
they may have extreme R center address again because what we take of the inverse of the matrix because of the matrix, it's still conditioned.

36
00:03:58,840 --> 00:04:06,159
Then again, there are large values. So this is what you call the narrative.

37
00:04:06,160 --> 00:04:11,320
And another thing is model selection. We kind of run a little bit towards the end of the last lecture.

38
00:04:12,130 --> 00:04:18,480
So notice that I showed here, we have three commonly seen ways of doing models and action.

39
00:04:18,490 --> 00:04:22,030
One is recall affirmative action, but first action.

40
00:04:22,420 --> 00:04:31,120
We start from the model that has no covariance and then let's say we have ten covariance, well, ten covariance.

41
00:04:31,660 --> 00:04:37,330
And then we start with a model that has only intercept with no values covariance.

42
00:04:37,870 --> 00:04:40,870
And then we look at each of this covariance, one by one,

43
00:04:40,870 --> 00:04:48,940
we throw each one of them into the model and see which one gives us the most increase in terms of modified.

44
00:04:50,140 --> 00:04:55,060
Or were the other words we could look at or the the p value of each of the ten

45
00:04:55,120 --> 00:04:59,320
covariates and to see which one adds and it has the most significant effect.

46
00:04:59,620 --> 00:05:05,140
And then we add of that into the model and then there are not others that are still there.

47
00:05:05,440 --> 00:05:12,250
And then we again, we look at them one by one. We add them into this model that has already one covariate in the model.

48
00:05:12,640 --> 00:05:18,910
Right? And then we look at the brief one actually decrease the model phase the most and then we out of that equal the model.

49
00:05:19,300 --> 00:05:22,630
And we do this sequentially in Q in.

50
00:05:22,690 --> 00:05:25,810
Q Well, we have a new coverage.

51
00:05:25,840 --> 00:05:29,800
You know, there is no significant improvement of the model and then we stop.

52
00:05:30,490 --> 00:05:34,870
So that's the so-called first. Yeah, maybe this is getting ahead of us.

53
00:05:34,870 --> 00:05:38,230
However, we are talking about significant improvement.

54
00:05:38,440 --> 00:05:43,280
Yeah, that's right. So that's a good question. There are different ways of looking at that.

55
00:05:43,320 --> 00:05:50,740
One simple way is actually to look at the and so you can you can you can do that because when you have if each variable,

56
00:05:50,740 --> 00:05:56,650
if you've converted into the model, you get a corresponding period of each of the coverage and then you can look at

57
00:05:56,680 --> 00:06:01,900
which one has the smallest P-value that means that is the most significant graphic.

58
00:06:02,080 --> 00:06:06,220
So we just add one until we start finding the ones that are significant.

59
00:06:06,370 --> 00:06:16,600
Yeah, right. That, that's one way. That's definitely one way. There are already ways while there are different criteria for, for, for making us.

60
00:06:16,940 --> 00:06:21,500
Mudavadi in light of regional statistics that there is good in this official statistics.

61
00:06:21,770 --> 00:06:25,680
So there are different ways. But I mean, plateau is is one way to look at this.

62
00:06:28,400 --> 00:06:32,800
Okay. So let's first imagine there were selection works the in the opposite way.

63
00:06:32,810 --> 00:06:34,460
So that was in action.

64
00:06:34,490 --> 00:06:41,750
You just throw all the covariates you have into the model and say you had a technical error as it was thrown into the model after tomorrow.

65
00:06:42,440 --> 00:06:50,450
And then you look you look at these ten covariates and you remove the one that is the least significant.

66
00:06:51,680 --> 00:06:54,830
So. Or in other words, with the largest p value. Right.

67
00:06:55,070 --> 00:07:00,740
Remove it and then you have nine errors left in the model and the value refit of the model.

68
00:07:01,070 --> 00:07:09,830
And then you look at among these nine covariates, which one has the largest values and then you remove it and you do this sequentially

69
00:07:10,100 --> 00:07:16,130
interval until you reach a point where if you look at all the covariates in the model,

70
00:07:16,550 --> 00:07:22,420
all of them are significant. Right? So so that's Banderas Bowers analogy.

71
00:07:22,730 --> 00:07:31,520
You just throw everything in and then you remove one paradigm and then we have the so-called stepwise selection.

72
00:07:32,180 --> 00:07:35,450
So that was like your word in the mix mixed away, right?

73
00:07:35,450 --> 00:07:41,270
So you just have you can either add some covariates or remove some covariates.

74
00:07:46,490 --> 00:07:55,280
Okay. Any questions about what this is? Add to what we have covered in our last lecture but at the end of questions before.

75
00:08:01,490 --> 00:08:12,760
Okay. The moto validation is another very important thing in linear, well, not only linear regression, but generally speaking in regression.

76
00:08:13,090 --> 00:08:22,120
So model validation is about how average, but the model is also new data.

77
00:08:22,600 --> 00:08:26,680
So this is particularly relevant for prediction.

78
00:08:27,100 --> 00:08:32,080
So remember that we have two major objectives in the regression model.

79
00:08:32,200 --> 00:08:36,960
One is making inference, estimation and and the making out what's happening.

80
00:08:37,360 --> 00:08:43,959
And another one is prediction. So if an individual comes, if we know there are covariates, Nevada,

81
00:08:43,960 --> 00:08:47,650
all their collaborators, can we predict their response value by making predictions?

82
00:08:48,160 --> 00:08:57,309
And in this model, validation is particularly relevant for for making prediction because there often we are

83
00:08:57,310 --> 00:09:03,310
interesting to predict prediction then the response value for some or some individual.

84
00:09:04,630 --> 00:09:10,660
Now the validation actually is, is a way to make sure that in the end we have a good prediction,

85
00:09:10,660 --> 00:09:16,900
we have an accurate prediction, and the model validation is carried out in a way such that.

86
00:09:18,010 --> 00:09:25,420
So suppose we collect our data and then we divide our data into two parts.

87
00:09:26,770 --> 00:09:33,460
One part is a so-called training data, so split the data into two.

88
00:09:52,860 --> 00:09:56,100
So do two and one part. We call you the training data.

89
00:09:56,190 --> 00:09:58,110
Another part of what's called a validation data.

90
00:09:58,830 --> 00:10:06,510
So the purpose of the training data is we will use the training data to fit our model to your to do all the model diagnostics,

91
00:10:06,510 --> 00:10:13,410
to do model selection, to refine our model to young, to fight to build the best model that we think fit to be a best teacher.

92
00:10:13,740 --> 00:10:18,630
And then of course, we use the training data to build our model.

93
00:10:19,110 --> 00:10:25,450
Of course, that if we still look at it, we, if we just look at the performance of the model on the training data that well,

94
00:10:25,470 --> 00:10:31,740
it should be satisfactory because that's, that's based on the data, that's the data we use to build our model.

95
00:10:32,370 --> 00:10:35,520
Now, what about the performance of the model in general?

96
00:10:35,580 --> 00:10:39,450
What if we have a new device that constantly how does model perform?

97
00:10:39,720 --> 00:10:48,720
Then we can we can evaluate it at using the only validation dataset and so on, because for about anything that's added,

98
00:10:48,720 --> 00:10:52,920
because it come from the same original data is just part of the original data.

99
00:10:52,920 --> 00:10:56,610
So we know what are the responses are we know what occurs when the responses are.

100
00:10:57,150 --> 00:11:01,500
And then based on the covariates and based on our model, from within the data,

101
00:11:01,770 --> 00:11:06,900
we can make a prediction on the responses for the subjects in that they didn't give us that.

102
00:11:07,350 --> 00:11:16,290
And then we can compare we can to better while we observe the true wise for subjects in the validation dataset.

103
00:11:17,020 --> 00:11:26,850
And then we make our correlation based on the model we build used in training, the research, and then we compare those two to see how close they are.

104
00:11:27,210 --> 00:11:33,630
Of course, we will ask them to be as close as possible, right? Because if they're closed, that means our Lola has a good prediction.

105
00:11:34,200 --> 00:11:37,350
If not, then it's not a very good model.

106
00:11:38,550 --> 00:11:43,810
So this is the so-called model validation approach, and this is quite intuitive, quite simple,

107
00:11:43,890 --> 00:11:49,230
but it is used widely in statistics to make predictions about not only solution,

108
00:11:49,230 --> 00:11:57,150
but in machine learning, generally speaking, to make prediction, to make sure that, you know, we have a good a prediction model in the end.

109
00:12:03,250 --> 00:12:09,940
Okay. So another thing is a so-called weighted regression.

110
00:12:10,480 --> 00:12:18,250
This is actually. Based on the wealth in eastern Italy as well.

111
00:12:18,250 --> 00:12:27,100
I think we mentioned it once last time, but this is kind of one of the fundamental things that we've never we can never overemphasize this.

112
00:12:28,600 --> 00:12:38,380
So the one fundamental idea of statistics is that our interest is about who is in the population we are.

113
00:12:38,590 --> 00:12:50,110
For example, we are interested in estimating the average average income of people living in a measured right or an average mission.

114
00:12:50,490 --> 00:12:55,120
So so we want to estimate the average income of people living in leisure.

115
00:12:55,360 --> 00:13:01,300
However, the problem is that, I mean, we cannot really clear data from every single individual living in mission.

116
00:13:02,170 --> 00:13:09,310
We just don't have the manpower doing that. So the way the proceedings that we select assemble from the population.

117
00:13:09,550 --> 00:13:18,400
So we select people from we sample people from from Ann Arbor, from Detroit, from, you know, from from Flint, from know from different places.

118
00:13:18,850 --> 00:13:23,799
And then based on the sample essay we take in the end and we take a sample of a

119
00:13:23,800 --> 00:13:29,170
thousand individuals and then we can collect data based on this 1000 individuals.

120
00:13:29,530 --> 00:13:33,160
And at that we can estimate what the average is.

121
00:13:33,250 --> 00:13:41,140
Right? And then we use assemble our range as an estimate of the population like Michigan population average.

122
00:13:42,400 --> 00:13:47,770
But in this process, of course, ideally I do or we will like to have a random sample.

123
00:13:48,130 --> 00:13:54,640
So that means each individual has the same probability of being included in the sample no matter where you live,

124
00:13:54,640 --> 00:13:59,680
whether I live in Ann Arbor, whether live in a rich neighborhood, a reporting or political matter.

125
00:13:59,680 --> 00:14:07,330
So ideally we would like to have the same inclusion probability for everyone to have in, again, a representative sample of the population.

126
00:14:08,590 --> 00:14:15,430
However, in practice, this this never happens. When done so away, we'll take a sample of different individuals.

127
00:14:15,430 --> 00:14:24,339
We will have different probabilities of being sampled. For example, let's say I am taking a sample or not because I actually I, I live in Ann Arbor,

128
00:14:24,340 --> 00:14:32,319
so I don't I probably don't have the same access to the people living up north compared to the people who live in Ann Arbor.

129
00:14:32,320 --> 00:14:36,940
So when I take the sample, I may over sample the people living in Ann Arbor, right?

130
00:14:36,970 --> 00:14:42,850
So, so that's that happens a lot. So when you oversample a particular subgroup of people,

131
00:14:43,210 --> 00:14:52,570
then that that particular subgroup got overrepresented in that in a sample and the other subgroups, they may be older represented.

132
00:14:53,080 --> 00:14:56,990
So then if you look at your sample, let's say, well,

133
00:14:57,070 --> 00:15:05,770
somehow you a sample contains more people from the rich neighborhoods and less people from the poorer neighborhoods missing.

134
00:15:05,980 --> 00:15:12,370
And that if you just naively calculate the sample average based on our sample,

135
00:15:12,370 --> 00:15:18,550
that is the average income is going to be higher than the true population and so on.

136
00:15:19,270 --> 00:15:24,870
So in this case, none of a way to address this problem is take that slide.

137
00:15:24,890 --> 00:15:30,340
And probably if you look at the weight of each individual corresponding. So that file here,

138
00:15:30,340 --> 00:15:35,860
we are not going to talk about how how to win weird because this this how this is quite a

139
00:15:35,860 --> 00:15:41,950
complex events are a complicated problem but tell us we can well then this is the idea.

140
00:15:41,980 --> 00:15:48,160
So if you are able to provide the weight different individuals, then you might be able to get to the correct answer in the end.

141
00:15:48,850 --> 00:15:50,379
And it's the same here.

142
00:15:50,380 --> 00:15:59,440
So, so when we run a regression model now because different individuals, they have different probability of being included being sampled.

143
00:16:00,040 --> 00:16:06,370
So if, if you directly run, if we ensure that, you know, different inclusion probabilities,

144
00:16:06,680 --> 00:16:16,690
if you I run a regression model based on all the data we have in end and we're going to have an incorrect estimate of the effect of the covariates.

145
00:16:17,140 --> 00:16:20,410
So in this case, we need to probably address the selection bias.

146
00:16:20,620 --> 00:16:28,990
We need to add some weight only for individuals before we run a rational so that we have the crowd estimate.

147
00:16:29,860 --> 00:16:37,670
That is, why do we do this instead of including, like you mentioned, like being comfortable, like excluding that as opposed area,

148
00:16:39,400 --> 00:16:43,180
including instead of including it as a covariate to account for that,

149
00:16:44,200 --> 00:16:54,459
including what as a comment like instead of waiting based on the different categories, including that it's like, oh, oh here.

150
00:16:54,460 --> 00:17:03,150
Oh, okay. So I think maybe I didn't explain this on this well because I was trying to actually look at this,

151
00:17:03,160 --> 00:17:07,450
explain this at a high, high level without getting into too many details.

152
00:17:08,050 --> 00:17:17,260
So here as well, it doesn't matter whether we are looking at we're estimating just the average income or we are feeding on the matrimonial law,

153
00:17:17,260 --> 00:17:21,520
nationalism figure, right, model. Right. So because this is not a central part of this course.

154
00:17:21,790 --> 00:17:31,580
So that's a very interesting of how the how people's income depends on their, for example,

155
00:17:31,660 --> 00:17:38,740
location level, their age, their their gender, for example, married to this, they want to study this.

156
00:17:40,510 --> 00:17:44,920
And then of lucky for you have a random sample from the population.

157
00:17:45,820 --> 00:17:51,610
Now of course they're going to directly run regression model and and you fail very model of

158
00:17:51,610 --> 00:17:57,220
of income on these three areas you can estimate from that in fact each of these three areas.

159
00:17:57,730 --> 00:18:05,170
However now let's say that your sample somehow you over sample the people are being.

160
00:18:05,860 --> 00:18:15,010
Let's say the the people with higher education and that in your sample let's say let's consider extreme case.

161
00:18:15,460 --> 00:18:23,230
Let's say that your sample didn't include at all and individuals with a lower average less able to attend college right out of college.

162
00:18:24,220 --> 00:18:30,730
So in that case, your sample only includes the people who have college degree or higher.

163
00:18:31,600 --> 00:18:36,429
Then if you still just run a regression model based on the data included,

164
00:18:36,430 --> 00:18:43,390
then what the estimate you have is that just for the people who have college degrees or higher.

165
00:18:44,170 --> 00:18:54,190
So in order to address that problem now, we need to probably await the individuals you have in the data section so that after reading so for example,

166
00:18:54,190 --> 00:19:10,329
if, if like for, for, for a person like me, like a, you know, a male with a college degree and, and, you know, age of 30, 38 and then a 39.

167
00:19:10,330 --> 00:19:24,130
And then so if people with the same characteristic as me has, you know, the probability of one quarter of well being.

168
00:19:24,310 --> 00:19:33,360
So I think I would argue that let's say indeed you observe data from me, then you should avoid it by data by multiplying it by four,

169
00:19:33,370 --> 00:19:39,940
because my data not only represent myself but also represents three others well, the same kind of risk as me.

170
00:19:39,950 --> 00:19:43,030
But if are not included in that sample.

171
00:19:43,420 --> 00:19:47,300
Right. So this is actually the the idea behind behind the region.

172
00:19:48,940 --> 00:19:53,850
So it doesn't matter whether we are 50 regression model or we are simply estimating that,

173
00:19:53,860 --> 00:19:59,020
you know, a simple quality like me is because the sample itself is biased.

174
00:19:59,340 --> 00:20:10,060
If you just use the wise assemble tool to do whatever you want, only then you're able to get a, you know, group of word or you crack in the hat.

175
00:20:10,510 --> 00:20:15,970
So the the the the waiting is a way of addressing that.

176
00:20:17,060 --> 00:20:23,840
Is that okay? Any other questions?

177
00:20:36,130 --> 00:20:44,230
Right. So. And then. Well, this core is of course, we will focus on the linear regression of.

178
00:20:44,890 --> 00:20:51,580
But there is also the general linear models which you will learn in 631 next semester.

179
00:20:52,840 --> 00:21:00,280
So the difference is that, you know, for your linear regression deals with a continuous outcome Y, so the Y is always continuous.

180
00:21:00,700 --> 00:21:04,540
And also we in this course, we will assume we followed normal distribution.

181
00:21:07,540 --> 00:21:11,500
Or the episode where the random error followed normal description.

182
00:21:12,070 --> 00:21:16,660
But anyway, so the media rushed to deal with a case where why is continues on.

183
00:21:16,720 --> 00:21:24,250
You could actually make a transformation. Why that's not normal. That you could make some transformation to make to make it more normal.

184
00:21:24,760 --> 00:21:37,959
But anyway, in deals with continuous outcome in public housing, in medical research, in many other areas, oftentimes the response is not continuous,

185
00:21:37,960 --> 00:21:44,260
especially for example, for example, let's say you want to study some sort of some disease,

186
00:21:44,260 --> 00:21:51,700
like if you simply want to study cataract or look at other results.

187
00:21:51,940 --> 00:21:55,210
That is, either the person has a disease or not.

188
00:21:55,600 --> 00:22:01,420
Then it becomes a binary response, right? Yes or no or one or zero response.

189
00:22:02,200 --> 00:22:09,920
So for example, if you look at a certain type of cancer, then either the person has the cancer or the person is cancer free.

190
00:22:09,940 --> 00:22:13,480
So in this case, we have two categories one and zero.

191
00:22:14,080 --> 00:22:19,720
This is widely seen in public health research or medical research.

192
00:22:20,020 --> 00:22:23,540
So why is a binary in this case? Why follow up a lose?

193
00:22:23,860 --> 00:22:28,540
Of course, that means fibroids is promoting this fusion, and in this case,

194
00:22:28,540 --> 00:22:37,710
we cannot use linear regression anymore because linear regression, it actually is for convenience of response of.

195
00:22:37,900 --> 00:22:48,780
In this case, while we do have more advanced tools of dealing with a binary response that is the so called generalized linear models gi on.

196
00:22:50,660 --> 00:23:00,350
This is used to model, not normal responses, for example, or maybe random intervals or about other other variables.

197
00:23:00,650 --> 00:23:04,340
And the corresponding model is the so called logistic regression model.

198
00:23:06,020 --> 00:23:09,350
And sometimes Y is okay.

199
00:23:09,980 --> 00:23:18,980
So for example, let's say we are trying to model a particular like a number,

200
00:23:18,980 --> 00:23:24,710
please, please determine how many number one calls they receive in the past month.

201
00:23:25,370 --> 00:23:34,970
We're in a past year. So it's then the Y is actually a positive behavior is a is a candidate like how many how many not one course in this case?

202
00:23:35,210 --> 00:23:44,090
Well, it's not a continuous and it is a count. So we have a special model for it and that's called a proposal regression, the opposite of what it is.

203
00:23:44,090 --> 00:23:49,639
Another commonly seen example, generalized models anyway.

204
00:23:49,640 --> 00:23:55,820
So the point is that a linear regression model deals with a continuous outcome and generalized

205
00:23:55,820 --> 00:24:03,140
Miyamoto deal with that and with them can deal with the other type of outcome like discrete outcome.

206
00:24:04,520 --> 00:24:11,450
And we will study the deal. M In six the focus of 651 it's going to be giant.

207
00:24:17,400 --> 00:24:24,240
So another common theme calls out is the multiple or multiple Russian or multivariate regression.

208
00:24:25,110 --> 00:24:35,220
These are different concepts. So in this course one, I do learn how big is the so-called simple linear regression.

209
00:24:36,060 --> 00:24:43,920
And while in model, the moderate model is just a little different, but a Model B,

210
00:24:43,920 --> 00:24:47,340
we are going to take a much more detailed look at some of the regression.

211
00:24:48,540 --> 00:24:52,080
So this is one of the focus of this course.

212
00:24:52,470 --> 00:24:54,690
And a single linear regression means that, well,

213
00:24:54,690 --> 00:25:03,240
we have a response y where we have an outcome variable Y and we only have one predictor X for one covariate x.

214
00:25:04,230 --> 00:25:08,310
That's why it's called a simple regression. It has only one covariate.

215
00:25:09,510 --> 00:25:16,170
But of course, I mean, in reality, you know, there are always more covariates than just one.

216
00:25:16,670 --> 00:25:27,420
So in this case, we have to consider the so-called multiple linear regression model here means that there are multiple predictors for a lot of X.

217
00:25:28,830 --> 00:25:33,120
But we will start from linear, a simple linear regression.

218
00:25:33,150 --> 00:25:42,450
This is because the the all the fundamental concepts for years as a ba ba ba they are already there for a signaling interaction.

219
00:25:42,450 --> 00:25:49,230
So it's easier to look at the fundamentals. And then we will extend that to logical linear regression.

220
00:25:50,880 --> 00:25:57,780
Now, this is actually different. Multiple linear measures differ from the model so-called multivariate regression.

221
00:25:58,590 --> 00:26:04,140
The multivariate regression as you consider multiple outcome variables Y.

222
00:26:05,670 --> 00:26:12,930
But so the simple and a multiple linear regression used to they both consider one outcome.

223
00:26:14,550 --> 00:26:21,690
So the Y is just one variable. It's just one response. But a multivariate regression, you consider multiple outcomes.

224
00:26:22,020 --> 00:26:28,290
So here I'll give two examples. One example is the so called longitudinal data.

225
00:26:28,290 --> 00:26:35,189
You will learn all general data in 653, I think over in this semester.

226
00:26:35,190 --> 00:26:39,899
But you will take it next year this nice. Okay.

227
00:26:39,900 --> 00:26:47,190
So of longitudinal review of the matter that means that you are let's say you are looking at and you have a clinical trial,

228
00:26:47,190 --> 00:26:50,490
you want to follow a samplings. You're measuring the low blood pressure.

229
00:26:51,030 --> 00:26:58,770
But A, you're the the individual or the subjects. They are going to come back to the clinic every three months as right.

230
00:26:58,830 --> 00:27:02,040
So the end of the study as a loss for over a year.

231
00:27:02,520 --> 00:27:07,140
And then you have a four visit for scheduled visits throughout the year.

232
00:27:07,440 --> 00:27:15,750
And then at each visit you measure their blood pressure, let's say, and then you have a this is the so called repeated matters or longitudinal data.

233
00:27:16,770 --> 00:27:23,070
And in this case, if you look how different the patterns and this differ different different visits.

234
00:27:23,340 --> 00:27:31,110
And then you will have a better like in this case, a four dimensional response because you have one response at each visit.

235
00:27:31,500 --> 00:27:39,360
So if you have a four visit, then you have four four matters.

236
00:27:39,600 --> 00:27:40,800
And this poor matters.

237
00:27:41,190 --> 00:27:50,129
First is if you want to study this for a matter of simultaneously and see how the matters change over time throughout the year or how you

238
00:27:50,130 --> 00:27:59,790
change the in this case is we can look at and so a multivariate regression and in six these three that's the main focus of choosing three.

239
00:27:59,970 --> 00:28:04,680
So that's one example, a matter of the same response for a marriage multiple times.

240
00:28:05,340 --> 00:28:15,900
If you add another example is sometimes we want to see the models to study two different response variables simultaneously.

241
00:28:16,440 --> 00:28:26,130
So let's say that we want to study how people's height and weight what while we want to study this two simultaneously,

242
00:28:26,820 --> 00:28:34,559
like how this tool depends on people's age and and gender and things like that or as also different covariates how

243
00:28:34,560 --> 00:28:41,820
these two so we can study each what like how height depends on people's is associated with people age and gender,

244
00:28:42,000 --> 00:28:45,120
how weight is associated with people's genders.

245
00:28:45,720 --> 00:28:54,030
So if we look at each one of the got two becomes either one that behind Margot linear regression because we are looking at one I think

246
00:28:54,090 --> 00:29:02,160
alert response black but if you want to study these two simultaneous you want to see how how these two simultaneously you know,

247
00:29:03,300 --> 00:29:06,930
depend on or vary with people's age and gender.

248
00:29:07,410 --> 00:29:11,069
Then the response has two dimensions.

249
00:29:11,070 --> 00:29:17,580
So we are looking at a tool reconnaissance in this case. Well, this is not an example of multivariate regression.

250
00:29:21,370 --> 00:29:24,940
So these are just different. Different.

251
00:29:26,050 --> 00:29:30,220
Different names. Different terminologies. Refer to different types of regressions.

252
00:29:35,120 --> 00:29:40,009
Okay. Yeah. So. So the, the moderator interaction, this is, this will be comprehensive.

253
00:29:40,010 --> 00:29:44,100
Speaker three. And questions so far.

254
00:29:54,190 --> 00:29:58,810
Okay, then. Then let's take a look at in-class exercise.

255
00:29:58,930 --> 00:30:04,870
I mean, we have you know, we have talked about some very important concept,

256
00:30:04,870 --> 00:30:12,500
fundamental concepts on which we will use extended with throughout this course.

257
00:30:12,530 --> 00:30:18,550
Of course, later leader is not going to take a much more detailed look at some some of these concepts.

258
00:30:18,940 --> 00:30:25,030
But for now, let's do a very quick in-class exercise based on some article published.

259
00:30:25,720 --> 00:30:30,790
And although the purpose of doing this is to see that in the process that we

260
00:30:30,790 --> 00:30:36,190
have talked about in the first half of this lecture and also in Tuesdays later,

261
00:30:36,580 --> 00:30:42,400
they are indeed quite useful in terms of in terms of a reality.

262
00:30:42,640 --> 00:30:46,000
And so we are not something that we re created out of nowhere.

263
00:30:46,180 --> 00:30:50,200
You can see that based on this. This is an article, published article.

264
00:30:50,200 --> 00:30:51,759
You can see that they are very,

265
00:30:51,760 --> 00:30:58,750
very all the trouble comes out of we mentioned the big important role in the study of some people requires some influenced.

266
00:30:59,440 --> 00:31:10,120
So this exercise this is based on the paper maternal bull that as you know the risk factor for fatal neural toxicity.

267
00:31:11,440 --> 00:31:19,710
So this article. He's actually.

268
00:31:28,370 --> 00:31:36,650
This article has been uploaded here. So if you're interested, you can read this article, but I don't think is necessary.

269
00:31:36,840 --> 00:31:42,050
But if you have time after all that occurred, because I believe people should look at this article.

270
00:31:45,110 --> 00:31:50,840
I think it's nice to read an article. Any use linear regression model is so sort of short.

271
00:31:51,170 --> 00:31:59,180
You know, I think especially after this course, it would be nice to as to take a detailed look at this and read this article to see how,

272
00:31:59,180 --> 00:32:06,980
like the materials we have covered in this lecture, how the way they were applied to study this significant problem.

273
00:32:07,860 --> 00:32:17,320
So but for now, while you can you can read this after the lecture, but for now, let's do this exercise.

274
00:32:17,330 --> 00:32:23,160
So we. Let me download this.

275
00:32:51,300 --> 00:32:51,570
Okay.

276
00:32:51,580 --> 00:33:02,610
I think you guys probably have in mind, it seems that most of you guys also have this out here, but I believe that is too small for the guys to read.

277
00:33:03,000 --> 00:33:16,950
So if you have your own device, you can you can download your own device and take a load of oh maybe we should go over the background first.

278
00:33:21,510 --> 00:33:21,749
Yeah.

279
00:33:21,750 --> 00:33:32,030
So here, this, this slide tried to summarize the scientific background of that paper so that for now we do not need to read our paper in the lecture,

280
00:33:32,730 --> 00:33:35,880
you know, address. You can, you can never read that after the lecture.

281
00:33:36,300 --> 00:33:48,510
So this is hey paper studying the effect of o level on the mental development of people who are famous.

282
00:33:49,440 --> 00:33:57,630
So nowadays, as we are having that or I, we know that Latin is having not always a zero participant.

283
00:33:58,230 --> 00:34:04,800
So it's is that is a is a chemical that is harmful to our immune system.

284
00:34:05,880 --> 00:34:15,180
And it is associated with that decreased amount of development in children and also accelerated mental decline in elderly.

285
00:34:16,200 --> 00:34:29,160
So it's really bad if our neuro system abnormal highly abnormal the high level so when we study the.

286
00:34:32,110 --> 00:34:36,370
The mental development of the mental development can be measured here.

287
00:34:37,810 --> 00:34:43,360
The Meadow Well, but there are different metaphors for intelligence.

288
00:34:43,370 --> 00:34:49,840
One moment, for example. One is, of course, the ideal test, another way to support the baby's mental development index.

289
00:34:50,930 --> 00:34:58,270
And if you are interested, you can definitely explore more what these two measurements are.

290
00:34:58,720 --> 00:35:05,050
But for now, let's just say that, you know, we have these different environments to measurement of development for matter of intelligence.

291
00:35:05,980 --> 00:35:14,139
And then the interest is as well to look at to to make us as an individual study how the American elements of intelligence,

292
00:35:14,140 --> 00:35:23,440
how mental development actually is associated with or what is the fact that a concentration on plant development.

293
00:35:25,930 --> 00:35:35,110
So when we measure the level of concentration now, especially in this study, the study you study the maternal.

294
00:35:35,650 --> 00:35:40,840
So as the title suggests, it's to study the maternal homeland as the mother is factor.

295
00:35:42,910 --> 00:35:55,330
So the the lower level, I mean, for the newborn baby is matter is typically measured by the amount of latch in empirical cord.

296
00:35:55,360 --> 00:36:03,490
So this is a rather illustration. Now, this here, this is the empirical court here.

297
00:36:03,700 --> 00:36:07,000
So this actually connects the baby to the to the mother.

298
00:36:07,390 --> 00:36:15,010
So so that through the court of the baby, I can get the nutrition in blunt gender and delivery.

299
00:36:15,610 --> 00:36:26,140
So when the mother deliver the baby, so that level inside of the empirical cord, it can be measured.

300
00:36:26,410 --> 00:36:33,490
So that's one measure of the black lab, blah, blah, blah, blah lab concentration.

301
00:36:35,230 --> 00:36:42,440
And that's does what matter of that level. So another matter is actually the born lab concentration.

302
00:36:42,460 --> 00:36:45,690
This is this is considered to be a more, you know,

303
00:36:45,700 --> 00:36:55,510
more reliable like long term black lab combination being in in the body as the blood that level you are.

304
00:36:55,840 --> 00:37:04,060
The matter is, you know, the reason exposure to lab exposure, but a black concentration that's sort of a long term worth.

305
00:37:05,520 --> 00:37:15,310
Is they actually measure the bonds and in this study, look at pairs of mother and babies and matter better.

306
00:37:16,040 --> 00:37:19,900
They are both. So this is a prospective study.

307
00:37:22,180 --> 00:37:33,960
So here we have a footnote. What we mean by a prosperous study is this is a very commonly seen terminology in biostatistics.

308
00:37:34,470 --> 00:37:38,090
A prospective study is actually a study where, you know,

309
00:37:38,130 --> 00:37:43,980
we recruited a cohort of patients and we followed the patients for for some period of time month.

310
00:37:44,310 --> 00:37:48,820
And this is while there is another study called the retrospective study.

311
00:37:48,820 --> 00:37:51,590
And that's actually, you know, have a look, look,

312
00:37:51,650 --> 00:38:00,750
look back what happened a personality study is that a cohort we followed a cohort for a certain time period and this is a prospective study.

313
00:38:00,750 --> 00:38:06,120
So we recruited or were the researchers they recruited out of the.

314
00:38:07,870 --> 00:38:10,150
The children mothers at birth.

315
00:38:10,780 --> 00:38:22,690
They followed the children until your 21st 24 month old end of the research question is that is Latin exposure associated with mental development?

316
00:38:23,260 --> 00:38:34,750
And if you are, that exposure is battered by both the umbilical cord blood and also by the maternal bone, that observation.

317
00:38:36,250 --> 00:38:41,140
And so you have to look at matters like the concentration matters.

318
00:38:41,440 --> 00:38:45,730
And in the mental development is a matter of the by the babies impacts on mental development.

319
00:38:47,740 --> 00:38:54,460
So the so that's a scientific question. The central question is, is latter is Fodor associated with the development?

320
00:38:56,650 --> 00:39:04,120
So if we translate this into US liturgical language, a spiritual question, then this question is what we want to test.

321
00:39:04,420 --> 00:39:08,780
If a medical cord blood and bull blood concentration,

322
00:39:08,780 --> 00:39:17,920
there's two blood better letters if they are predictors of valence and involvement index, that's the highest we are looking at.

323
00:39:21,190 --> 00:39:27,460
So before we. Yeah, before we look at that question.

324
00:39:29,800 --> 00:39:34,300
Now there's another very important culture that we need to we need to look at.

325
00:39:34,720 --> 00:39:38,140
So because here it is seem that I mean,

326
00:39:38,770 --> 00:39:46,610
in a sense that now is the first thing you do is to look at the level of exposure they found, the exposure among the government.

327
00:39:46,840 --> 00:39:51,630
So what if we just drag their feet on linear regression model like a similarly to a

328
00:39:51,640 --> 00:39:57,940
Russian model or a model linear regression model that has this two large level exposures,

329
00:39:57,940 --> 00:40:08,260
right? So we just feed a regression model with that with this as our response and we are allowed in a boomerang as our covariates.

330
00:40:08,380 --> 00:40:14,920
So what about fitting such a model right? Then we will get the effects of these two matters.

331
00:40:15,430 --> 00:40:24,759
While the this model is actually an oversimplified model and it will likely not give us the correct answer.

332
00:40:24,760 --> 00:40:30,970
In the end, this is because of the presence of the so called confounding variables, and this is a fundamental causality.

333
00:40:31,690 --> 00:40:35,290
Is that as a confounding for confounders or confounding variables?

334
00:40:35,920 --> 00:40:40,690
So what are confounders? A confounder is.

335
00:40:42,630 --> 00:40:52,860
As they see you. Confounder. Confounder actually is connected to both is related to both the coverage and the response.

336
00:40:53,280 --> 00:41:02,100
That's that's what a co-founder is. So the presence of the cofounder actually can while can make some strange things happen.

337
00:41:02,910 --> 00:41:13,020
So a confounder can make the observed association either stronger than the true association or weaker than a true association,

338
00:41:13,380 --> 00:41:17,610
or even reverse the true association.

339
00:41:18,720 --> 00:41:25,930
Well, this is a graphical illustration of this, a strange phenomenon.

340
00:41:26,590 --> 00:41:34,490
So let's say we are interested in studying the, like, basketball success rate.

341
00:41:34,510 --> 00:41:39,130
How well, you know, a person play basketball well the person's height.

342
00:41:40,210 --> 00:41:47,110
So this is Y and this is X. We are interested in studying how how these two are associated.

343
00:41:48,070 --> 00:41:53,590
Now, if we collect our data, let's say we collect our data,

344
00:41:53,920 --> 00:41:59,530
and then these these red dots and the blue dots, these represents our the data we collected.

345
00:42:00,460 --> 00:42:08,440
Now, if we forget about the color for a minute, if we look at just all these dogs, red dots and blue dots like these dots and these dots,

346
00:42:09,910 --> 00:42:19,210
and then if we look have of a trend, look, well, then this this this line here, this illustrates the trend.

347
00:42:19,860 --> 00:42:28,870
And so people who are higher, who are taller, they tend to have a, you know, a better performance in playing basketball.

348
00:42:29,140 --> 00:42:40,120
So. So this is the overall trend. So that's that's without looking at that's simply just looking at the association between Y and X.

349
00:42:41,310 --> 00:42:48,510
However, if we break these data points down into two groups, if we take age into consideration.

350
00:42:50,190 --> 00:42:55,170
So then here these dots, this red dots, these are now some.

351
00:42:56,840 --> 00:43:05,900
My child, Rachel So age aside from 5 to 10 and these are the ones from these children.

352
00:43:06,230 --> 00:43:10,550
And these are data points, clarity from, you know, this age group.

353
00:43:11,240 --> 00:43:16,220
Now, if you look at this, within each age group, you see that.

354
00:43:17,680 --> 00:43:20,410
You'll see that here. This is the trend.

355
00:43:21,970 --> 00:43:29,730
So as long as people get a caller and they have their their performance fall there, they are more successful in playing.

356
00:43:30,920 --> 00:43:35,230
Right. And this is true actually within each group.

357
00:43:37,660 --> 00:43:45,340
Within each age group. However, if you have an overall, it seems to suggest that people work harder.

358
00:43:45,820 --> 00:43:49,180
Maybe they are worse at playing basketball. Right.

359
00:43:49,510 --> 00:43:57,910
So this is actually a good illustration of what are the confounder is what a confounding fact is if your age is actually.

360
00:43:59,120 --> 00:44:07,580
A confounder so could actually modify the effect the change of the exact change the association it change even the direction of the association.

361
00:44:07,900 --> 00:44:11,420
It's really the reverse, the true association, because in the truth,

362
00:44:11,420 --> 00:44:17,420
if we take into account that people walk taller, they tend to be more successful in playing basketball.

363
00:44:17,660 --> 00:44:23,120
However, without taking into account, we see that we reach the opposite conclusion.

364
00:44:24,650 --> 00:44:27,800
So this is the importance of taking confounder into account.

365
00:44:28,670 --> 00:44:33,250
And in this study, I mean, this is not shown in this study, but generally.

366
00:44:33,460 --> 00:44:39,500
So what we see the regression model, if we want to get the correct estimate of the effect.

367
00:44:40,560 --> 00:44:46,830
We have to take confounders into account, like in this study, the potential confounders are, you know,

368
00:44:46,890 --> 00:44:57,960
some demographics like age, gender allocation, marital status and also the breastfeeding duration and the maternal IQ.

369
00:44:58,650 --> 00:45:00,660
So all of these are potential confounders.

370
00:45:01,170 --> 00:45:08,700
So what would be a regression model when we try to study the above, the level of the exact level of development?

371
00:45:09,240 --> 00:45:17,460
And then we have to include of this potential confounders in our to in again to reach a correct conclusion.

372
00:45:20,950 --> 00:45:31,059
And these confounders and predictors? Well, I mean, here, oftentimes we just simply call them the cobra.

373
00:45:31,060 --> 00:45:35,310
So COBRA is is more of a generic, generic terminology.

374
00:45:35,320 --> 00:45:40,870
It just meets all the variables of meaning as we consider what we do over all the acts,

375
00:45:40,870 --> 00:45:46,570
we consider the regression model and depending on what a special role they play.

376
00:45:46,630 --> 00:45:51,550
So if your interest is in maybe an operation, then you may call on the religious right.

377
00:45:52,300 --> 00:45:59,920
And also, depending on what the confounders confounders usually are, the variables that you have to adjust for.

378
00:46:00,220 --> 00:46:03,790
But that's not your main set of interest.

379
00:46:04,030 --> 00:46:12,640
So for example, here in this case, we are interested in studying the association between Y and passed between your basketball success and height.

380
00:46:13,420 --> 00:46:19,660
So age is something we have to adjust for in order to crack but estimated that association.

381
00:46:19,960 --> 00:46:24,520
But in fact the itself is not a main interest.

382
00:46:25,270 --> 00:46:28,480
So in this case, age is called the confounder.

383
00:46:30,010 --> 00:46:38,000
So this is a very important concept. So any questions about this confound or misconception?

384
00:46:45,590 --> 00:46:49,420
Okay. Oh, by the way, so these are these slides of this example.

385
00:46:49,530 --> 00:46:57,679
They are they're provided by famous for being embrace that Mussolini is he's trying to refer the other session

386
00:46:57,680 --> 00:47:05,360
in Brazil is she she actually she was a professor in the department and then she moved to Drexel University.

387
00:47:05,360 --> 00:47:09,520
So. Okay.

388
00:47:09,580 --> 00:47:16,420
So now I think we are going to have a communist break.

389
00:47:16,430 --> 00:47:24,730
But during the break, I think I'm going to ask you guys to look at this this in-class exercise.

390
00:47:25,060 --> 00:47:29,590
I think this is probably an event in a lot of what we resume.

391
00:47:29,620 --> 00:47:33,910
We will take a look at this. So maybe just one more word.

392
00:47:34,960 --> 00:47:38,820
So this is what we take sometimes from the articles here.

393
00:47:38,880 --> 00:47:43,420
You can you can look out of the these are some tags from the article and we want to

394
00:47:43,430 --> 00:47:49,690
actually connect whose text to the topics that we have mentioned so far in our slides.

395
00:47:49,930 --> 00:47:57,670
And this is just the purpose is just to see that, you know, the concepts we have covered so far, they are large and created from from nowhere.

396
00:47:57,820 --> 00:48:01,030
You are indeed very useful in terms of science.

397
00:48:01,240 --> 00:48:08,970
So some of the questions so during during the break, you guys can take a look at this and also coverage of this kind of thing.

398
00:48:08,980 --> 00:48:14,320
We really encourage you guys to do these kinds of coverage around the world, working with the sun.

399
00:48:14,410 --> 00:48:19,210
So and then when we come back, we will ask you to take a very quick look at this.

400
00:48:19,360 --> 00:48:24,010
And we don't need to spend a ton of time on this. We will take a very quick look at this.

401
00:48:24,460 --> 00:48:34,060
And then and again, we will, because we have some other very important things to to cover.

402
00:48:35,530 --> 00:48:39,390
Okay. So we will stop here before for a minute if we're not there.

403
00:48:39,400 --> 00:48:42,617
So we will resume at nine. If.

404
00:48:49,093 --> 00:48:53,753
And so now we are now going to look at each one of these.

405
00:48:53,783 --> 00:49:00,553
Let's just pick some some and look at how they are connected to some of the targets we mentioned so far.

406
00:49:00,883 --> 00:49:03,673
So let's for example, let's let's take a look at the first 1/1.

407
00:49:04,603 --> 00:49:13,333
So this has thousands of descriptive statistics and completely transformations in the attention of outliers were performed before.

408
00:49:13,513 --> 00:49:23,592
I've got a lot of better analysis and blah blah large conservation work learned about a natural logarithm to normalize

409
00:49:23,593 --> 00:49:35,383
the scale and exposure and this okay x are f both our values with better uncertainty exceeding ten or 15 for tban Allah,

410
00:49:35,533 --> 00:49:40,873
we're starting to work excluded from the analysis as part of its comprehensive quality control procedures.

411
00:49:41,813 --> 00:49:44,833
And as these values in tragedy that we will set something.

412
00:49:44,833 --> 00:49:49,483
And I'm not a correlated with our measure I wouldn't put a lot of concrete in themselves.

413
00:49:49,903 --> 00:50:00,943
So now after reading this content, this text, so which topics you think that like these text are based on?

414
00:50:02,173 --> 00:50:06,912
So all of this and there are many topics. So now let's just look at these one by one, right?

415
00:50:06,913 --> 00:50:08,893
So let's look at the first sentence first.

416
00:50:09,373 --> 00:50:20,233
Okay, so the first sentence about what happens to think that our well, so we withholdings the first sentence is clarity.

417
00:50:21,013 --> 00:50:24,673
So anybody who is trying.

418
00:50:32,703 --> 00:50:37,433
Yes. I've been invariance. The media and the veterans.

419
00:50:38,273 --> 00:50:44,153
Well, that's great. So that's just based on because here we talk about this group of statistics.

420
00:50:44,363 --> 00:50:47,903
Right? And then what? What else?

421
00:50:51,383 --> 00:50:57,563
And also transformation and also transformation of public transportation.

422
00:50:57,953 --> 00:51:03,653
And there anything else connected in how lives?

423
00:51:04,193 --> 00:51:12,353
Yes. So if you look at oh, and also probably by the advisory board of malware distribution analysis.

424
00:51:12,593 --> 00:51:20,843
So if you look at this for a sentence now and as we connect with several topics we have covered.

425
00:51:21,143 --> 00:51:30,743
So it has is critical statistics. Of course, this group of statistics includes me and antivirus and also includes many others like,

426
00:51:31,673 --> 00:51:36,293
you know, for categorical variables, irritating includes the frequency of different categories.

427
00:51:36,483 --> 00:51:41,723
So how they histogram, how different and how the here's where our frequency table.

428
00:51:41,933 --> 00:51:50,983
So you can create his grammar free with the table. So these are descriptive statistics and then approval transformation.

429
00:51:51,203 --> 00:51:57,863
As a leader there is another. Oh, not actually in the same.

430
00:51:57,863 --> 00:52:03,833
In the same. So here I think it measures oh yeah.

431
00:52:04,313 --> 00:52:11,323
To convert you to do that are natural logarithm value. So this means while some transformations has been taken of,

432
00:52:13,403 --> 00:52:20,753
you can see that about in black or black ball out of concentration were converted to their natural logarithm value to normalize the skill description.

433
00:52:20,993 --> 00:52:25,103
This is precisely what we talked about when we talk about log transformation.

434
00:52:25,493 --> 00:52:30,413
So large transformation. If we go back to our.

435
00:52:32,963 --> 00:52:36,083
I like your notes. Yeah.

436
00:52:36,213 --> 00:52:39,473
Here. This is where we talked about transformation of the outcome.

437
00:52:39,923 --> 00:52:49,643
So when we have a highly skilled, expensive dispute for the right decision, for very fast thinking, long transformation is a very common way.

438
00:52:49,913 --> 00:52:54,263
A very common practice. So here, this is the long transformation.

439
00:52:54,593 --> 00:53:05,823
This is to make the decision look more normal and disputed so that the assumption of linear regression is is satisfied.

440
00:53:05,873 --> 00:53:12,893
So we are going to talk about the assumption behind the intervention, and that's choosing.

441
00:53:13,523 --> 00:53:17,493
So what are the detailed assumptions? Okay.

442
00:53:17,633 --> 00:53:25,893
Well, but here you can see that indeed this is one of the Black Lives Matter.

443
00:53:26,113 --> 00:53:29,552
This is converted to natural law to make it more normal.

444
00:53:29,553 --> 00:53:36,393
It is religious. Okay, so then what about here in the next sentence?

445
00:53:36,393 --> 00:53:44,193
Let's say these. Yeah, these are. So what are what topics and this part are connected to.

446
00:53:46,263 --> 00:53:56,693
I want. Yes.

447
00:53:58,013 --> 00:54:01,373
Looking for influential points or outliers? Yeah.

448
00:54:01,403 --> 00:54:06,232
Yeah. Great. So. Exactly. So here, if you look at this one,

449
00:54:06,233 --> 00:54:14,753
this sentence says it is asked that you few matters of a matter with better concerned are you sitting ten or 15 were excluded.

450
00:54:15,053 --> 00:54:24,173
So this is trying to get rid of some influential observations or outliers and of course

451
00:54:24,173 --> 00:54:28,963
the like that it's a little bit tricky to deal with outliers or influential studies.

452
00:54:29,153 --> 00:54:33,323
I mean, removing them is is one way that people some people take.

453
00:54:33,923 --> 00:54:37,312
However, this is not it doesn't mean that a,

454
00:54:37,313 --> 00:54:43,133
we have always we have always followed this approach by removing the ally or

455
00:54:43,163 --> 00:54:50,223
influential observations because the the first thing actually we need to measure.

456
00:54:50,283 --> 00:54:54,473
So the first thing when we look at when we look at, oh,

457
00:54:54,593 --> 00:55:02,242
I was working with visions is to make sure they are indeed that the real data point there are true data points because sometimes the outlier

458
00:55:02,243 --> 00:55:10,013
is already virtual observations there because of some table because like when some people input the data may they made some errors.

459
00:55:10,333 --> 00:55:16,223
So so the model becomes then becomes extremely large or extremely small, not consistent with others.

460
00:55:16,493 --> 00:55:20,783
So if there were errors, then of course we will need to remove them from the model.

461
00:55:21,203 --> 00:55:28,403
But if they are indeed true data points, then there are there are different ways of dealing with that.

462
00:55:28,413 --> 00:55:33,142
So of course, the simplest or maybe naive way is to remove these outliers.

463
00:55:33,143 --> 00:55:36,863
Or if we're interested in this one, this may not be the best way.

464
00:55:37,313 --> 00:55:43,763
So sometimes people do some some sensitivity analysis to run to analysis.

465
00:55:43,913 --> 00:55:47,722
So what were these outliers? Well, without these outliers,

466
00:55:47,723 --> 00:55:57,943
see how much how much change there is that actually tells us what about what are the impact of this influential observations are.

467
00:55:59,993 --> 00:56:07,373
So yeah. So this is you know, this is this first.

468
00:56:07,913 --> 00:56:14,993
So now let's take a look at another that's a let's say this one right here.

469
00:56:15,593 --> 00:56:22,613
So this is I think this is quite clear and quite closely related to our.

470
00:56:23,753 --> 00:56:31,453
X. So this one actually is related to this whole so-called module selection.

471
00:56:32,083 --> 00:56:37,513
So it is clearly here. Forward, backward and satellite selection can see that.

472
00:56:39,403 --> 00:56:45,763
So this is the final one. The final or final model was selected using forward or backward and sound stabilized methods.

473
00:56:49,633 --> 00:56:52,723
So here I mean, this, as we mentioned in our lecture,

474
00:56:52,723 --> 00:57:00,303
this is one commonly used way of carrying out four words works now as an action by looking at the problem.

475
00:57:00,553 --> 00:57:07,933
So as mentioned here, so the variables significantly associated with the IE emotional development index.

476
00:57:09,543 --> 00:57:11,653
That means P-value or less than point one.

477
00:57:11,683 --> 00:57:20,063
Of course I mean in Wellington for Bowers life and sometimes we use slightly different cut up than the typical Echo Park analogy.

478
00:57:20,323 --> 00:57:26,473
But while the authors used a quarter one as the as the high threshold.

479
00:57:26,863 --> 00:57:35,803
So for the variables whose P values are less than 0.1, they were retained for entry forward.

480
00:57:35,833 --> 00:57:44,052
So that was not rational. And then you had a with back word elimination.

481
00:57:44,053 --> 00:57:47,383
So in other words, so the queries were the variables.

482
00:57:48,763 --> 00:57:55,603
There was P-value that is less than 0.01, but those are considered significant.

483
00:57:55,933 --> 00:58:03,133
And if those are retained in the model and for the others for the other covariance was p values are larger than for the one

484
00:58:03,373 --> 00:58:12,303
they are considered non-significant and they would be removed from the from the model when doing backward elimination.

485
00:58:12,943 --> 00:58:21,523
Okay. So this actually is how the final model is built based on the model selection for power and stabilization.

486
00:58:24,653 --> 00:58:33,293
Okay. So now let's take a look at another. Maybe we will take a look at this.

487
00:58:35,543 --> 00:58:39,353
So what was it like this part?

488
00:58:40,883 --> 00:58:44,693
What is how big is losing business connected to our slice?

489
00:59:02,143 --> 00:59:09,953
The way we like to write this is co-founder co-founder of.

490
00:59:14,393 --> 00:59:18,773
Yeah. Component is definitely going on with so.

491
00:59:22,163 --> 00:59:27,653
So confounder I think is probably meant it's more relevant if you look at this

492
00:59:27,803 --> 00:59:31,903
point over here as your initial model fitted by including all these different,

493
00:59:32,363 --> 00:59:40,073
different, different covariates. And this is a staff to adjust for confounders potential confounders now.

494
00:59:40,763 --> 00:59:41,452
Absolutely. Yeah.

495
00:59:41,453 --> 00:59:52,343
So we skip this particular part, but this part is to deal with confounders and this one is not explicitly to deal with the confounders.

496
00:59:56,143 --> 01:00:00,863
It is checking for linearity between those two, checking for collegiality.

497
01:00:00,863 --> 01:00:04,522
Well, that's yeah. Is sort of that is sort of that.

498
01:00:04,523 --> 01:00:10,883
So but it is not I see your point.

499
01:00:10,913 --> 01:00:14,543
So here we have the association between.

500
01:00:14,843 --> 01:00:24,813
We examined the association between. Oh, yeah, that's right.

501
01:00:24,833 --> 01:00:27,823
So sorry. I was thinking about something else. Yeah, you're right.

502
01:00:27,843 --> 01:00:36,783
So this has had a little tech clarity, because here, on the one level, I mean, this is one of the covariates, right?

503
01:00:37,023 --> 01:00:47,913
Well, with marriage and this bar that because here this is a national study, we have to follow the mother, child, a parent as before, after 24 months.

504
01:00:48,723 --> 01:00:58,983
And this is assuming to check the matters at 12 months and and 24 months, whether I mean, they have a commonality.

505
01:00:59,433 --> 01:01:06,333
And also here, another thing is actually is about with a margin of error rate model.

506
01:01:06,723 --> 01:01:11,122
So because this is a repeated. Banner.

507
01:01:11,123 --> 01:01:19,703
So this is a monsoonal setting and of the mental health of development is a matter of repeatedly and because of this.

508
01:01:19,973 --> 01:01:26,333
Now if we consider the drawing, the modeling of this different repeated a measure of the mental developmental held at the moment,

509
01:01:26,873 --> 01:01:34,793
then it's going to be a multi very model. So as we mentioned in our.

510
01:01:47,713 --> 01:01:55,543
Yeah. This slide over here. So we're talking about the simple versus modifiable versus multivariate regression.

511
01:01:55,753 --> 01:01:59,603
The minor regressions is the case where the outcome is matter.

512
01:01:59,603 --> 01:02:06,793
That repeatedly and not in this particular study is it is a longitudinal study.

513
01:02:06,863 --> 01:02:16,003
So some of the outcomes matter at different time points when you consider this don't like the draw the modeling of this different review matters.

514
01:02:16,363 --> 01:02:21,013
And again, it's out of the model, multivariate regression model.

515
01:02:21,373 --> 01:02:23,413
But also, I mean, I think you're right.

516
01:02:23,413 --> 01:02:32,113
So that when we look at the covariance, I mean, the covariance at a different matter and even time points, they are highly correlated.

517
01:02:32,593 --> 01:02:37,653
And this actually comes to a lot to the point of logical genealogy.

518
01:02:41,513 --> 01:02:51,712
Yeah. We to hit it. Right. So. So a medical reality means that even covariates they may have high correlation between that and here

519
01:02:51,713 --> 01:02:58,913
because we have this notion that different time points and of course matters from different time periods,

520
01:02:58,913 --> 01:03:05,363
they are hyphenated. So this is also indeed a crack connecting to for this type of monitoring and.

521
01:03:09,113 --> 01:03:12,593
Okay. So I think we are.

522
01:03:13,163 --> 01:03:20,213
Yeah, we probably are. Yeah. We don't have time to, you know, to take a very detailed look at each of the thing.

523
01:03:20,483 --> 01:03:27,293
But the point here is that if you look at a this has taken from this particular paper,

524
01:03:27,533 --> 01:03:31,673
you will see that indeed they are closed very close of the cladding through that.

525
01:03:31,943 --> 01:03:39,863
So the concept for the stuff we have talked about in choosing the is factoring and into the transactions.

526
01:03:40,043 --> 01:03:50,063
So this is to to to illustrate that the things that we have putting out there are indeed very useful in terms of starting some new questions.

527
01:03:50,063 --> 01:03:53,983
I think because studies, they are not defined purely because of them,

528
01:03:54,323 --> 01:04:04,042
because they're trying a the mathematical device, something not where are building all of the concepts we talk about.

529
01:04:04,043 --> 01:04:10,673
We have practical implications and indeed you can read this paper and to see how some of these

530
01:04:10,673 --> 01:04:16,733
cause and or many of this concept art are being applied or applied to solving this problem.

531
01:04:17,813 --> 01:04:24,503
And especially after the lecture, we're maybe towards the latter half of the lecture.

532
01:04:24,503 --> 01:04:28,823
Once we cover in detail these different concepts, you can actually take a look at,

533
01:04:29,033 --> 01:04:35,663
take a detailed look at this paper and see how these different techniques are applied to study.

534
01:04:35,683 --> 01:04:43,643
Nonverbals Okay, so that's a very small exercise.

535
01:04:44,693 --> 01:04:53,333
And then we're going to for the rest of this lecture, there are some very important things that we need to cover.

536
01:04:53,663 --> 01:05:01,433
That is a brief review of some basic statistics because of this alliteration, and this is statistics.

537
01:05:01,433 --> 01:05:13,073
So there are many important facts we have to know of when we deal with one available to deal with the distribution, I mean, and the IRAs and so forth.

538
01:05:13,403 --> 01:05:19,872
And most of this stuff, you will have a much more detailed look in six.

539
01:05:19,873 --> 01:05:23,123
So what I believe most of you guys are taking a six or what?

540
01:05:23,453 --> 01:05:27,893
And so you'll have a much detail, much more detail coverage.

541
01:05:28,163 --> 01:05:35,933
It takes a while. But in the meanwhile, I mean, because we do need these facts when we talk about linear regression model.

542
01:05:36,293 --> 01:05:39,323
So this is to get a review or refresh your memory.

543
01:05:39,323 --> 01:05:51,083
I think many of you have already seen this, but if you haven't that, that's okay and you will learn this in detail in six one.

544
01:05:51,083 --> 01:05:56,872
But here, because we are going to do a meta, this kind of a linear regression model.

545
01:05:56,873 --> 01:06:05,303
So we will give you take a look at this first. So I will try to this is going to be a little bit of mathematical.

546
01:06:06,113 --> 01:06:14,993
So I will try to show that whenever possible, I'm going to try to show the mathematical derivations.

547
01:06:15,893 --> 01:06:18,713
So feel free to let me know if you have any questions.

548
01:06:19,073 --> 01:06:29,513
And here our goal is to actually make sure that all the guys can have a good understanding of this basic statistics and basic calculations.

549
01:06:29,513 --> 01:06:33,773
And because later when we feed the models, we will need this facts.

550
01:06:36,643 --> 01:06:41,053
Okay. So here we will use capital ledger journalism in camera.

551
01:06:41,443 --> 01:06:46,543
You don't run the minerals and then you know what you see.

552
01:06:46,553 --> 01:06:52,613
We have a sample that means in this horse we always consider Rutland.

553
01:06:52,663 --> 01:07:00,673
So so we don't owe Genesis and we don't need to worry about whether the sample is representative of the population or not.

554
01:07:00,673 --> 01:07:06,793
We don't assume that we have a simple random sample, and here we use this end to denote the sample size.

555
01:07:10,043 --> 01:07:14,333
Brazil is the number of total number of subjects in the dataset.

556
01:07:15,323 --> 01:07:19,553
How many subjects you including were assembled? And this is why I.

557
01:07:19,733 --> 01:07:24,083
This is the value the for the arts subject.

558
01:07:24,773 --> 01:07:28,823
But because of the sample is random. So the Y is also a random variable.

559
01:07:29,633 --> 01:07:41,483
We use cattle that are already there and then for the role variables we can define the sum of these drug numerals and this is sigma i.e.

560
01:07:41,513 --> 01:07:54,203
from over one m this is just a notation saying that we are we are taking the sum of these white eyes and then we have the product.

561
01:07:54,233 --> 01:08:05,863
We consider the product of these white eyes. And this this this is a notation for for denoting product from I from one in this product.

562
01:08:08,563 --> 01:08:12,553
And then we have the so-called expanded value or exacerbation.

563
01:08:16,933 --> 01:08:20,593
Expanded. It is more of a mathematical terminology.

564
01:08:20,623 --> 01:08:25,543
You will definitely learn learned as a sexual one but generous.

565
01:08:25,543 --> 01:08:30,073
Speaking of expatriation is, as with just the meat of the record,

566
01:08:30,073 --> 01:08:41,023
men were average of the run of the meat and we will use in statistics oftentimes we use meal to denote the meeting or average rates addition.

567
01:08:41,033 --> 01:08:45,703
This is just by convention. People confuse and we use to knowledge of the meat.

568
01:08:46,123 --> 01:08:58,203
And if you want to say the meat of why that you use a substrate, why to indicate that you're talking about the meat of what they use.

569
01:08:58,213 --> 01:09:03,823
Variation here we write into this meat. So this is the expectation of running variable y.

570
01:09:04,883 --> 01:09:10,373
And of a mathematical definition of excitation in terms of this integral.

571
01:09:11,123 --> 01:09:16,193
Now, let's not worry too much about like the case where a wise, discrete or continuous.

572
01:09:16,193 --> 01:09:24,382
I mean, you guys will learn in much more detail in six a lot, but a few of us just say that, you know what?

573
01:09:24,383 --> 01:09:32,452
This you know why? Well, sometimes we also use a subsequent what we know is that it limits the density for that for the random interval.

574
01:09:32,453 --> 01:09:36,823
Why this is done. Density function.

575
01:09:39,943 --> 01:09:43,453
More pdaf. 1 p.m.

576
01:09:45,943 --> 01:09:50,893
Probably density function probably at a mass function. So the distinction is feasible.

577
01:09:51,433 --> 01:09:55,123
Is whether the running of a wide is continuous or discrete.

578
01:09:55,993 --> 01:10:05,683
I don't know. But either one mathematically it can be read in terms of integral so that its foundation is defined in terms of any room.

579
01:10:06,073 --> 01:10:10,273
The integral of y primes this.

580
01:10:11,913 --> 01:10:17,853
That's the function that taken any role over the whole range of why.

581
01:10:20,243 --> 01:10:31,163
So this is how his foundation is defined. So he's not Asian or the mean either reflects the center of the dispute.

582
01:10:31,313 --> 01:10:35,003
So let's say that let's say that a wife follows.

583
01:10:40,293 --> 01:10:43,713
Las Vegas casino general case. It may not be symmetric.

584
01:10:43,923 --> 01:10:47,663
So let's say let's say this is the the PDF of one.

585
01:10:47,673 --> 01:10:51,333
So this is this is the other one.

586
01:10:55,093 --> 01:11:01,263
I. Let's say this is the video of way.

587
01:11:07,353 --> 01:11:12,063
And then if you look at the center, the center is probably, let's say, probably somewhere here.

588
01:11:15,183 --> 01:11:26,083
And this is the foundation of what? So South Asian is actually is just up where the PDF is on.

589
01:11:30,773 --> 01:11:38,003
Like where is centered around. So by by the center we mean actually, you know, the the listening room.

590
01:11:39,863 --> 01:11:42,383
So this is what is happening. So that's why it's called expanded.

591
01:11:42,733 --> 01:11:52,763
It's called a the mean of that, this fusion, this is not very Spanish because I lived in South Asia now for installation,

592
01:11:53,063 --> 01:11:56,213
there are certain rules when we calculate the expansion.

593
01:11:58,093 --> 01:12:03,523
And these are very important roles. We need to always to keep in mind.

594
01:12:04,783 --> 01:12:11,353
So the first one says that these foundation is a linear well is actually a linear operator.

595
01:12:14,913 --> 01:12:21,393
So it means that if you are calculating the foundation of the sum of a bunch of variables,

596
01:12:21,783 --> 01:12:28,063
that is equal to the sum of the expansion of these each individual running their.

597
01:12:29,933 --> 01:12:33,533
So this is what we call the so called linear operator. So you can switch.

598
01:12:33,893 --> 01:12:36,953
You can actually move this expansion inside the sun.

599
01:12:38,063 --> 01:12:41,153
Or in other words, you can actually move this summation.

600
01:12:41,183 --> 01:12:49,753
You can move this omission out onto these foundation. So I guess that's a property of expatriation.

601
01:12:50,113 --> 01:12:58,093
So this is quite, quite a simple and there is no assumption actually behind this, no assumption of independence required.

602
01:12:58,123 --> 01:13:01,183
So these are the these differ other variables.

603
01:13:01,183 --> 01:13:05,773
Why eyes they can be correlated. They can be any part of the world they can accommodate.

604
01:13:05,773 --> 01:13:12,253
It doesn't matter much. So as long as you calculate it's manageable, the sun is equal to the sun of the expansion.

605
01:13:15,523 --> 01:13:21,553
So this is again, this is what we call exaggeration and linear operator.

606
01:13:23,323 --> 01:13:30,313
And then, well, if we use this to denote some constants, we will use lowercase letters,

607
01:13:30,913 --> 01:13:36,173
a small a small series note, for example, a small B to denote constants.

608
01:13:36,613 --> 01:13:41,833
These are not relevant. These are called cosmic and then for foundation.

609
01:13:42,943 --> 01:13:51,133
Now, if we consider the expansion of a times like that, we can actually move as a orderly expand agent like this.

610
01:13:52,213 --> 01:14:01,183
So this is. So in other words, we can move cascading effect on the memorable orderly expansion, which.

611
01:14:03,573 --> 01:14:10,443
And if we combine this linear operator with this with this fact, then that is foundation of.

612
01:14:15,063 --> 01:14:25,863
This weekend, average of a highway high is actually equal to the weighted average of each of the expansion of the expansion of each white line.

613
01:14:28,913 --> 01:14:38,303
Okay. So the whole thing here, if you look at the whole thing here, this is actually what a leading outbreak operator is.

614
01:14:38,423 --> 01:14:41,903
The operator has this has this property.

615
01:14:42,233 --> 01:14:51,563
So he's alleging some is equal to some of the Malaysian explanation of a runaway multiply by a is equal to a modified by the Malaysian

616
01:14:51,833 --> 01:15:00,413
and also he's not agent you know the weighted average of this why is equal to that same weighted average of the those explanations.

617
01:15:01,583 --> 01:15:06,803
These these properties are only about the properties of the average.

618
01:15:10,063 --> 01:15:13,093
Now for president, it's a little bit more complex.

619
01:15:13,603 --> 01:15:26,593
So if you look out of the product of expanded knowledge on the product, then the traditional product is equal to the products of the use foundations.

620
01:15:26,833 --> 01:15:32,173
This is true if Y and Y and y j are independent.

621
01:15:32,203 --> 01:15:35,863
This is actually subject to this assumption, subject to some conditions.

622
01:15:36,313 --> 01:15:41,233
This is not always true. It is true whether true or other variables are independent.

623
01:15:42,053 --> 01:15:46,513
Otherwise, otherwise, this is not true anymore.

624
01:15:56,423 --> 01:16:06,783
So any questions so far? Okay.

625
01:16:07,113 --> 01:16:10,193
So that's the foundation. Well, he's not there yet.

626
01:16:10,293 --> 01:16:12,783
He's a member of the center of the solution.

627
01:16:13,503 --> 01:16:20,413
Now, another matter, very important there is the so-called various the various matters, how spread the data are.

628
01:16:20,433 --> 01:16:28,773
So, for example, how spread of disputed. And so if you look at a sort of this fusion and if we look at a such a PDF.

629
01:16:30,073 --> 01:16:36,443
Well, they actually trying to make this metric. You can see that we both have center here.

630
01:16:42,113 --> 01:16:45,753
I say this is why I want everyone to know so.

631
01:16:47,183 --> 01:16:55,223
To me, the apps, the media apps on why one and why now they both center out of the same location.

632
01:16:55,763 --> 01:17:00,503
However you come down to see that, you know, they have different aspect.

633
01:17:01,373 --> 01:17:05,753
So this actually is quantified by the various of the distribution.

634
01:17:07,453 --> 01:17:12,823
The appearance is defined as this is the mathematical definition of virus.

635
01:17:13,693 --> 01:17:26,763
So this is precisely how how how virus is defined is that sort of y minus its foundation, then taking the square, then taking place, managing it.

636
01:17:26,803 --> 01:17:33,553
This is the mathematical definition of the virus. Now the South Asian, of course, as we mentioned it,

637
01:17:33,643 --> 01:17:43,423
Foundation is an enabler so that the various categories in the inner world of this guy, which is this guy over here modified by the PDF.

638
01:17:47,913 --> 01:17:55,113
So this is how I would define virus. Now, yeah, the virus reflects the spread of the virus.

639
01:17:56,133 --> 01:18:00,333
So how, how, how, how much variation?

640
01:18:01,143 --> 01:18:08,513
Why has not if we look at the unit of the virus, the unit of the virus is as an equal,

641
01:18:08,533 --> 01:18:14,013
because here we are taking the square of this sort of the square of the Y.

642
01:18:15,063 --> 01:18:21,243
So the unit of the virus is actually the square of the unit of light.

643
01:18:21,813 --> 01:18:29,913
So if y let's say y is h y y is better two years less same than the original y.

644
01:18:29,973 --> 01:18:35,133
The center, of course, has the same unit. It also has years as the unit.

645
01:18:35,643 --> 01:18:43,233
But if you look at the virus, the virus will have year square as the unit is taking a square away.

646
01:18:43,623 --> 01:18:51,753
And this is well, sometimes it's not a desirable because the square of a unit is not a very intuitive result.

647
01:18:52,173 --> 01:19:04,802
Like what? What has been made by your square. So then we will divide this another quantity based on the variance.

648
01:19:04,803 --> 01:19:11,463
This is that the square root of the virus, this is the so-called standard division is the square root of the variance.

649
01:19:13,613 --> 01:19:17,633
The scramble over there is now, of course, it has the same unit.

650
01:19:26,543 --> 01:19:31,673
Because we are taking the square root. So if your has. Oh, sorry, what is age?

651
01:19:31,833 --> 01:19:41,003
My early years the server division also has the same unit as here, as the unit as their division here.

652
01:19:41,173 --> 01:19:51,773
If you have a if you multiply this one by some some calls away, then the central division is just equal eight times the same region.

653
01:19:53,423 --> 01:20:02,393
So it's the same. While the element is the same thing as the variance, it also reflect the dispersion or how spread the exclusion is.

654
01:20:02,693 --> 01:20:08,093
But it is just that it's a square root of variance so that it has the same unit s as one.

655
01:20:13,443 --> 01:20:18,233
Okay. So this is the parents of a decision or another marriage.

656
01:20:20,933 --> 01:20:27,923
Now for veterans, there are also certain rules that are very important.

657
01:20:29,603 --> 01:20:32,872
It's the nurses now that we use quite, quite often excessively.

658
01:20:32,873 --> 01:20:39,953
So the virus of why by definition, the mathematical definition, as I mentioned, is this.

659
01:20:41,423 --> 01:20:45,683
But it can also be written. It can be calculated in this particular way.

660
01:20:46,823 --> 01:20:55,853
So it's not these things about these are why square the so called a second moment minus the square of the expansion, the square of the.

661
01:20:56,003 --> 01:21:00,983
First of all, this is quite easy to perceive.

662
01:21:02,363 --> 01:21:05,092
We can do this very we can cover this very easily.

663
01:21:05,093 --> 01:21:16,433
So if we do this here, so why if we separate the square, then we have y squared minus 2vy times y, then plus you y a square.

664
01:21:20,893 --> 01:21:26,383
Right. And then recall that his foundation is a linear operator.

665
01:21:27,073 --> 01:21:36,373
So we have the expansion of Y squared minus S management tool, new y times y.

666
01:21:36,703 --> 01:21:40,003
The cost is manageable. New Y squared.

667
01:21:44,573 --> 01:21:48,943
And this is because these foundations are with her. So so is foundational.

668
01:21:48,973 --> 01:21:55,933
The sum of all the three things is equal to the sum of the foundation of each one of these.

669
01:21:58,033 --> 01:22:03,373
And then here, if you look at this guy now, here are two types near one.

670
01:22:03,403 --> 01:22:08,232
This is a constant. And we know that expectations of you know with her.

671
01:22:08,233 --> 01:22:11,283
So this is actually equal to to you.

672
01:22:11,323 --> 01:22:26,363
Y times is about way. And that these foundational why is new what?

673
01:22:26,633 --> 01:22:42,393
So this is to me why square? And again, this guy here because new wife is a constant, so mosquera is also constant.

674
01:22:42,903 --> 01:22:47,013
So, of course, the Spanish I'm concerned is just equal to, you know, self.

675
01:22:53,933 --> 01:23:02,873
And then here we have pulled out of here we have a minus so remote we minus two mil square, the plus new square.

676
01:23:03,323 --> 01:23:07,163
So that means we have these foundation of Y Square.

677
01:23:10,903 --> 01:23:26,193
Minus Y squared. So that's that's why here we have this result.

678
01:23:34,323 --> 01:23:42,453
So in other words, when you come to the various, oftentimes we do not go back to examination, but rather we use this to calculate the variance.

679
01:23:42,663 --> 01:23:50,193
I mean, we just even calculate that things manager y squared and then we calculate the square of the expression y.

680
01:23:55,263 --> 01:23:58,953
And then we have the virus of linear pollination.

681
01:23:59,103 --> 01:24:02,273
So what if we have this linear information?

682
01:24:02,313 --> 01:24:15,123
What? Is various. Now here, the first thing I want to mention is that this plus B plus I caused this will not affect the variance.

683
01:24:17,033 --> 01:24:22,313
You can show this mathematically, but I'm going to leave this as an exercise to you guys.

684
01:24:22,553 --> 01:24:27,563
This is quite easy. If you just look again, go back to the definition of the virus,

685
01:24:27,563 --> 01:24:32,633
you can show this very easily that the variance of this is equal to the variance of this.

686
01:24:32,873 --> 01:24:35,633
So I'm going to leave this to you guys an exercise.

687
01:24:35,993 --> 01:24:43,973
But intuitively, what this means is that now this plus B means that if we are shifting as as illustrated in this plot of here,

688
01:24:44,693 --> 01:24:48,083
this plus B is like shifting the center of the distribution.

689
01:24:48,953 --> 01:24:55,433
So we are not changing the shape of the of the PDF, we are just shifting, contributing to the left or to the right.

690
01:24:56,363 --> 01:25:02,423
Of course, shooting that does not change the the spread of the data with the distribution.

691
01:25:02,993 --> 01:25:11,263
And so it does not change the variance. So that's why here this virus is equal to.

692
01:25:13,573 --> 01:25:21,253
This variance of hey times what so the be the plus B that does not play a role in infecting the batteries.

693
01:25:24,763 --> 01:25:32,623
And then to calculate the variance of a times why now we can again go back to the definition of the virus.

694
01:25:33,493 --> 01:25:36,733
So here we call the definition of the viruses.

695
01:25:37,513 --> 01:25:41,983
If we consider eight times why we give a name, let's say we call it a Z.

696
01:25:43,603 --> 01:25:56,623
If we call this thing Z. And again, by definition of the virus of Z is equal to Z minus the expansion of Z Square.

697
01:25:57,673 --> 01:26:02,653
And then taking that expanded. And that's precisely the definition of that variance.

698
01:26:09,703 --> 01:26:17,743
Right. And then because of this factor, A, this caused a there is a square of it,

699
01:26:17,923 --> 01:26:22,363
so we can move it because again, precisely because he's my vision, so our reader.

700
01:26:22,753 --> 01:26:26,393
So we can move this a square out of the expansion.

701
01:26:28,123 --> 01:26:31,933
And then what is left is Y minus the expansion.

702
01:26:31,933 --> 01:26:43,483
Y, then getting the square. And then again, it's based on the definition of the virus.

703
01:26:43,753 --> 01:26:55,113
This is precisely the awareness of why. Okay.

704
01:26:55,133 --> 01:26:58,553
And then we have a square here.

705
01:26:58,563 --> 01:27:10,493
So. So, in other words, a virus of linear transformation of y is equal to this squared times the this the scaling

706
01:27:10,493 --> 01:27:16,963
factor times the variance a lot and this shift this the does not play a role in factoring much.

707
01:27:17,183 --> 01:27:29,953
Yes. Okay.

708
01:27:29,983 --> 01:27:33,733
Any questions so far? Are we okay with this collision?

709
01:27:40,223 --> 01:27:40,363
Yeah.

710
01:27:40,363 --> 01:27:50,952
If you have any questions, just feel free to ask now or I mean, you can definitely go to the office hours to figure out more details on these drivers.

711
01:27:50,953 --> 01:27:56,233
And also the guys would be very happy to show this in more details.

712
01:27:57,793 --> 01:28:01,723
So that's the hours. And then there is the concept covariance.

713
01:28:02,053 --> 01:28:05,563
So x, y, run the variables and we can talk about the covariance.

714
01:28:06,913 --> 01:28:11,233
The Cobras is defined and mathematically is defined in this particular way.

715
01:28:13,753 --> 01:28:16,873
This is how common is defined as a mathematical definition.

716
01:28:17,713 --> 01:28:25,603
The common is it matters. The linear association between two other variables emphasized.

717
01:28:25,603 --> 01:28:29,682
This is sometimes people ignore this linear association,

718
01:28:29,683 --> 01:28:37,693
but essentially what it matters is how linear, how strongly, how linear variables are correlated.

719
01:28:38,293 --> 01:28:47,023
So if the covariance is positive, then and these larger values of x are associated with larger values of white,

720
01:28:49,243 --> 01:28:55,453
but if the covariance is negative, that to me is longer. Values of x are associated with the smaller values of why.

721
01:28:56,293 --> 01:28:58,813
So the change in the opposite direction.

722
01:28:59,443 --> 01:29:07,873
And when covariance is equal to zero, that means well now explain why they are not linearly associated at all.

723
01:29:07,993 --> 01:29:11,113
So there is no linear association.

724
01:29:12,523 --> 01:29:18,883
They may still be associated in other ways. That doesn't mean they're independent, but they are just not immediately associated.

725
01:29:21,433 --> 01:29:32,892
So the there is the problem of variance is that now suppose that the X here let's suppose an x is is is height, nursing and height.

726
01:29:32,893 --> 01:29:39,553
It can be measured in different units. Right. So you are talking about, let's say, let's say people's height,

727
01:29:40,573 --> 01:29:52,303
how to convert your foot 6 to 6 feet high where we're five or 5.9 feet high or can be measured in centimeters.

728
01:29:52,963 --> 01:29:58,903
And so it can be measured in different units. Now, if you change the unit, you would definitely change the value of the clearance.

729
01:29:59,803 --> 01:30:08,353
And this is not desirable because it's old. So then you can arbitrary change the value of the covariance changing unit of the example.

730
01:30:09,223 --> 01:30:14,653
So this is not skill invariant, so this is not desirable.

731
01:30:15,853 --> 01:30:28,393
So in order to well get rid of a unit to have some quality that is clear in very skilled immigrant, now we have the so called a correlation.

732
01:30:31,113 --> 01:30:38,132
Correlation of term honorable acts and why they are as well defined as well.

733
01:30:38,133 --> 01:30:48,483
This is the mathematical definition. So is the cold virus of X and Y divided by the Central Division X and of the Central

734
01:30:48,483 --> 01:30:57,573
Division or Y because of the division of this Central Division of X in a Central Division Y.

735
01:30:57,933 --> 01:31:01,983
Now the unit got canceled in the numerator and denominator.

736
01:31:02,523 --> 01:31:06,263
So this quantity, this correlation becomes units.

737
01:31:06,273 --> 01:31:10,083
There is no unit for correlation.

738
01:31:11,253 --> 01:31:20,593
So nothing about correlation needs. That correlation is always between 91 and one is always B 91 and one.

739
01:31:21,183 --> 01:31:34,592
So 91 means there is a perfect negative linear association between this tree and party.

740
01:31:34,593 --> 01:31:40,503
One means there is a perfect positive linear association between this and.

741
01:31:43,613 --> 01:31:48,923
And usually the Caucasian is somewhere in the middle. Somewhere in the middle.

742
01:31:49,283 --> 01:31:56,333
So that means, well, X and Y there is some degree of linear association, but I'm not a perfect.

743
01:31:57,513 --> 01:32:04,952
But not perfect or ended up with a negative correlation means that they are negative correlated is a larger x values corresponds to

744
01:32:04,953 --> 01:32:14,793
smaller y values and with a positive correlation that means larger y values are associated with the smaller larger x values as well.

745
01:32:15,183 --> 01:32:18,753
So. So this is what a correlation means.

746
01:32:19,743 --> 01:32:29,493
But a correlation is always if it is universal, it is always between negative one again and again just because of the centralization.

747
01:32:31,163 --> 01:32:35,213
Dividing the covariance by the two center deviations.

748
01:32:35,423 --> 01:32:47,622
So the unit got canceled. Okay.

749
01:32:47,623 --> 01:32:52,443
So but the KUMARIS, there are certain rules of coherence.

750
01:32:53,953 --> 01:32:58,033
So this is not by definition, this is the covariance.

751
01:33:00,553 --> 01:33:11,893
When we calculate the covariance or counter covariance, the covariance is in naturally equal to its valuation of x times y minus x value to max times.

752
01:33:11,893 --> 01:33:15,613
That is manager y. And a U-turn.

753
01:33:15,613 --> 01:33:20,323
And this is how we calculate the clearest new order. We do not go back to the definition.

754
01:33:20,653 --> 01:33:25,333
Usually we refer to the last formula to calculate covariance.

755
01:33:26,623 --> 01:33:33,603
And again, I'm going to leave this like a detailed derivation I worked for for this equality to you guys.

756
01:33:33,613 --> 01:33:39,253
This is, again, a very simple algebra you can actually separate in this product.

757
01:33:40,503 --> 01:33:50,163
You can separate this product and then you can then apply the facts that an experienced media operator show you can easily show that is equal to.

758
01:33:53,663 --> 01:33:56,933
This is I think it would be a very nice small exercise.

759
01:33:58,493 --> 01:34:05,632
And then when you look at the combinations of the same rhythm, they're right there.

760
01:34:05,633 --> 01:34:13,613
It becomes the various. This is very easy to see because because if we go to same, then here it becomes one might ask me why as well.

761
01:34:14,213 --> 01:34:21,913
And again, of course, this is the square of one minus one and that by definition at best, a variance of one.

762
01:34:23,063 --> 01:34:30,593
So. So the covariance of the same thing I say where the variable is just equal to that.

763
01:34:30,953 --> 01:34:40,723
Yes. And then we have the oh, the Kosovo independence.

764
01:34:40,743 --> 01:34:47,673
And I'm Canadian. So the covariance is a concept for correlation, for linear correlation.

765
01:34:49,023 --> 01:34:56,013
So while sometimes it's very easy to actually to mix those two, I invite layers and I'm uncorrelated.

766
01:34:57,153 --> 01:35:02,343
So independence is a very strong condition is a very strong condition.

767
01:35:02,853 --> 01:35:09,242
Independent means that x, y, if we say X and Y, we are in and that means there is no association,

768
01:35:09,243 --> 01:35:13,023
no relation at all, it's an X and Y, there's nothing between.

769
01:35:14,043 --> 01:35:24,393
So there is no relation between an X and Y. So of course that implies uncorrelated, uncorrelated means or linear correlation.

770
01:35:24,573 --> 01:35:31,773
So whether X in life are somehow linear correlated look worse if they are independent than they are uncorrelated.

771
01:35:32,373 --> 01:35:37,203
However, if they are uncorrelated, that does mean they are independent.

772
01:35:38,223 --> 01:35:47,553
Uncorrelated means that, you know, they they do not have a linear association, but if they are not linear, that association, then they may still be.

773
01:35:47,803 --> 01:35:52,503
For example, this is and this is a very good example.

774
01:35:52,743 --> 01:36:02,263
So let's say yeah. To Y let's say satisfied this well X and Y all the points fall along this on the circle on this.

775
01:36:04,113 --> 01:36:10,443
So X and Y. Now there is no linear association between what x and y ls are.

776
01:36:10,713 --> 01:36:15,093
If you count also the coherence, you are going to get a zero covariance.

777
01:36:15,303 --> 01:36:23,943
So they are uncorrelated. However, they're definitely not independent because we fall on the you can circle.

778
01:36:25,503 --> 01:36:34,703
And so this is a good a good example to keep in mind when we try to distinguish independence in the unincorporated.

779
01:36:37,533 --> 01:36:46,023
So whenever I mean well, so in other words, if they are independent, then the covariance is equal to zero.

780
01:36:46,053 --> 01:36:54,213
So they are unrelated. If they are uncorrelated, if the Congress is equal to zero, generous people are not independent.

781
01:36:55,443 --> 01:37:02,493
But if they followed by a very normal distribution, then they become independent.

782
01:37:02,913 --> 01:37:14,493
So this is a special case. If the R be followed by very normal that occurred in these environments, this is a similar okay, this is a well known fact.

783
01:37:15,723 --> 01:37:24,962
But generally speaking, these two are not the same. So now the covariance is actually a while.

784
01:37:24,963 --> 01:37:33,783
These are some properties of the covariance and that we will use intensively in this course and also in other persons as well.

785
01:37:34,083 --> 01:37:41,313
So the comparison, if you switch to the order of X and Y, X and Y, then you get to the same covariance.

786
01:37:41,733 --> 01:37:46,103
Doesn't matter whether it is not the comparison we do x, y or z one.

787
01:37:46,143 --> 01:37:50,073
And this is the same thing, you know.

788
01:37:50,223 --> 01:37:58,743
So here if you have one, one plus y two, if you are targeting covariance, that is equal to that, this covariance, this Congress.

789
01:38:01,843 --> 01:38:08,783
And also if you modify it by a year, then the same can be moved out of the class.

790
01:38:10,633 --> 01:38:19,183
And these are some well known facts, again. So, you know, we are going to ski with the kind of a mathematical derivation of this property.

791
01:38:19,483 --> 01:38:23,513
But all of those can be derived based on the definition of the clearance.

792
01:38:24,073 --> 01:38:29,923
And if you are interested, you can try to finish this as an exercise to this as an exercise.

793
01:38:30,423 --> 01:38:39,203
You can go back to the definition of coherence. You come to a definition, and eventually you'll find all these properties listed here.

794
01:38:39,223 --> 01:38:45,053
You are able to do back and forth.

795
01:38:45,553 --> 01:38:47,293
Okay, so we are at a time.

796
01:38:47,773 --> 01:38:59,913
So I think we will start here so that we'll continue this off next Tuesday and then we'll move on to submit your and will take a much more beautiful.

797
01:39:03,733 --> 01:39:04,033
You.

