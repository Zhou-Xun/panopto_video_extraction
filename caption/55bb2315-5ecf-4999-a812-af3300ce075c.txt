1
00:00:09,790 --> 00:00:13,190
Okay. But.

2
00:00:16,720 --> 00:00:24,500
I hope this time works. So let's get started.

3
00:00:25,640 --> 00:00:36,200
Some disclaimer. I have technical difficulties, my charger not working, so I'm going to monitor that.

4
00:00:36,200 --> 00:00:41,389
But I might need emergency help if I. If I need, need really charge this company, right?

5
00:00:41,390 --> 00:00:47,930
I think it's probably okay, but, um, just a heads up.

6
00:00:49,500 --> 00:00:53,320
Uh, uh oh. I need to turn off the light.

7
00:01:08,030 --> 00:01:17,060
Okay. And as it as I announced a extended form of due to Friday.

8
00:01:17,840 --> 00:01:23,930
Uh, I am I, I'm thinking of what I need to do for the due date.

9
00:01:23,930 --> 00:01:35,120
For the next homework. I probably will extend to Friday again, but I will let you know what the due date will be.

10
00:01:37,280 --> 00:01:43,459
And and probably there will be a lot of announcements coming out.

11
00:01:43,460 --> 00:01:51,530
So mid-term project will be coming out, uh, probably during next week.

12
00:01:51,980 --> 00:01:58,130
And you're going to give, you have an A going to be given about three weeks to solve that problem.

13
00:01:59,360 --> 00:02:05,130
And after that, you know, those are, you know, those,

14
00:02:05,220 --> 00:02:16,430
those times are reserved for final project and you need to submit your final, final project proposal by next week.

15
00:02:19,660 --> 00:02:24,300
Any any other questions? Okay.

16
00:02:25,110 --> 00:02:30,930
So let's try the random number generation.

17
00:02:32,580 --> 00:02:48,899
Okay. So we talked about through the numbers and why random number so useful and this is the one possible way to generate random numbers.

18
00:02:48,900 --> 00:03:03,150
So let's say ah, this descriptor ah is a just fine, a finite set of numbers and the random number generator is basically.

19
00:03:05,170 --> 00:03:10,680
Sort of a permutation of this are. So in a specific order.

20
00:03:10,690 --> 00:03:20,890
So let's say R zero is the first number you wanted to use as a seed or or just a previous random number generator.

21
00:03:21,340 --> 00:03:31,900
Then you can make the next random number as a function of your previous random number as a the function is G here.

22
00:03:32,350 --> 00:03:35,050
Okay. So that that's one way to generate the random numbers.

23
00:03:36,700 --> 00:03:45,130
So and this function G could be many different ways it could be generated in many different way.

24
00:03:45,520 --> 00:03:52,690
But one surprisingly simple way to do it is just doing multiple multiplication.

25
00:03:53,110 --> 00:04:01,710
Okay, so if you multiply the previous random number with a specific value.

26
00:04:01,720 --> 00:04:10,120
M Okay. And then uh, then it looks predictable, right?

27
00:04:10,120 --> 00:04:18,520
If you see the sequence of sequence of numbers, it may be predictable, but it's not predictable very well.

28
00:04:18,790 --> 00:04:31,600
If you take the mode you keep, you take the remainder of a certain certain prime number you you want you to just use here.

29
00:04:31,690 --> 00:04:37,360
Okay. The P is very large prime number here. Okay, so in.

30
00:04:40,100 --> 00:04:55,110
So in a. So in this case, if you take the mode of the prime, it's hard to predict what value it will become unless you know both and p values.

31
00:04:55,380 --> 00:05:02,130
Okay, so so this m value is just the integer.

32
00:05:02,430 --> 00:05:06,510
You you chose between two and p minus one.

33
00:05:07,740 --> 00:05:15,930
And when you choose P, you can choose very large, prime, a very practical,

34
00:05:16,230 --> 00:05:26,550
very widely used practices that you use the prime, which is once exactly one smaller than the two to the power of two.

35
00:05:26,880 --> 00:05:34,200
Those are called the Mersenne prime. And, you know, those are those are those are easy to generate.

36
00:05:34,200 --> 00:05:41,520
And those numbers are also easy to test. So to test whether they are prime or not.

37
00:05:41,880 --> 00:05:51,840
So those are, those are used quite frequently to, uh, to, to generate this kind of random number generator.

38
00:05:52,710 --> 00:06:01,950
Okay. So if you do that because a p the prime, you multiply some numbers and keep thinking remainder, then it will.

39
00:06:02,280 --> 00:06:07,020
And if the multiplier is of between the two to the two to p minus one,

40
00:06:07,290 --> 00:06:18,420
it is guaranteed that those values will just become a permutation of one one through zero entropy.

41
00:06:18,540 --> 00:06:22,970
Right. So it'll be a one through one through p minus one.

42
00:06:23,020 --> 00:06:26,370
Right. So the value will map into one through P minus one.

43
00:06:26,370 --> 00:06:30,599
It's not it's never going to be zero. So, yeah.

44
00:06:30,600 --> 00:06:34,590
So that's what l that there's one way to do it.

45
00:06:34,800 --> 00:06:39,230
Okay. So the period of the generator is the, you know.

46
00:06:42,610 --> 00:06:50,470
So we'll be basically the the minimal positive numbers that were that.

47
00:06:50,920 --> 00:07:00,440
So if you if you keep multiplying em, there can be a case that it can, uh, and it can be there.

48
00:07:00,640 --> 00:07:05,650
There'll be a circle within some small groups of numbers.

49
00:07:05,650 --> 00:07:12,700
And in that case, those periods will not be exactly two p minus one, but.

50
00:07:16,520 --> 00:07:26,470
Yeah. But it's a, it's a, it's possible to choose the reasonable number of em that that'll give you the full um,

51
00:07:27,470 --> 00:07:30,410
so full the full period which is a p minus one.

52
00:07:30,410 --> 00:07:38,840
So if you, if you choose a specific again, then that's, this is the way you can calculate the what the period should be.

53
00:07:38,840 --> 00:07:44,900
Because sometimes you can just search, you can be search circulate within a smaller circle.

54
00:07:48,030 --> 00:07:53,250
Okay. So. Uh.

55
00:07:53,480 --> 00:07:57,630
Okay. So. So in.

56
00:07:57,640 --> 00:08:01,180
Ah, there is a random number generator.

57
00:08:01,560 --> 00:08:05,280
Okay. There is a hidden function called the dot.

58
00:08:05,650 --> 00:08:12,940
So if the function start with that. Those are usually hidden function that random the C or orange kind.

59
00:08:13,210 --> 00:08:23,650
And those, if you look at the help page, there is a pretty good explanation on what all is using for for generating these random numbers.

60
00:08:23,770 --> 00:08:30,880
Okay. So our default random number generator is always in Emerson Twister.

61
00:08:31,060 --> 00:08:37,080
Okay. So basically it's very similar algorithm that I introduced before,

62
00:08:37,480 --> 00:08:45,700
but it uses specific prime and it has and it has a some some additional safeguard to make

63
00:08:45,700 --> 00:08:54,760
sure that these are always circulating the circulating almost a full circle's and so on.

64
00:08:55,090 --> 00:09:01,400
Okay. So the Mersenne twister algorithm is using this particular prime.

65
00:09:01,420 --> 00:09:06,160
22.199937 minus one is a really, really large prime.

66
00:09:06,850 --> 00:09:11,020
And in others if you if you select the seed.

67
00:09:14,530 --> 00:09:17,920
If you select a seat that is a reasonably large,

68
00:09:18,190 --> 00:09:24,740
then then it's a basically calculating the multiplying value that value with

69
00:09:24,890 --> 00:09:34,470
with M which is also large and taking the taking the taking the remainder.

70
00:09:34,480 --> 00:09:37,719
Basically, it's a it's very hard to predict what's what's going to happen.

71
00:09:37,720 --> 00:09:47,500
So for the users, it looks almost random. Okay, so and you probably know this function, but if you use a set, the C function,

72
00:09:47,950 --> 00:09:54,610
you can set the C value to to start with a specific value to generate the sequence of random value.

73
00:09:55,390 --> 00:10:00,220
Okay. So then, then, you know, you do ensure that reproducibility.

74
00:10:00,970 --> 00:10:04,360
Okay, so let me see how I'm doing.

75
00:10:04,480 --> 00:10:08,740
Okay. This should be good. Uh.

76
00:10:11,800 --> 00:10:15,160
So let's try some hands on session now.

77
00:10:16,600 --> 00:10:25,300
So I'm not going to just explain a lot of these details of version to start with you.

78
00:10:25,390 --> 00:10:34,180
If you wanted to understand that you can those those are within the well described in the Wikipedia work or other places.

79
00:10:34,180 --> 00:10:45,910
So it's a it's a good thing to know it it it it's a it's pretty clear that if you use very large prime numbers and use a simple multiplication room,

80
00:10:46,330 --> 00:10:50,890
it should it should look pretty robust in terms of the pseudo randomness.

81
00:10:52,690 --> 00:11:00,400
So here I'm just showing the how you can use the random number generator in practice.

82
00:11:00,880 --> 00:11:04,180
Probably many of you already know how to use our unit function,

83
00:11:04,210 --> 00:11:10,810
which our unit function is that you can generate a uniformly random, randomly distributed variable.

84
00:11:11,950 --> 00:11:14,410
In this case, if you give a single parameter,

85
00:11:14,440 --> 00:11:23,830
it gives a five single party with a five that gives the five random numbers and it assumes that the range is between zero and one.

86
00:11:24,970 --> 00:11:28,630
And you can specify the range. If you give max that parameter,

87
00:11:28,990 --> 00:11:38,680
extra two more parameter will give you that the range to be big ranging from this specific number, in this case, -1 to 1.

88
00:11:39,820 --> 00:11:51,900
Okay. And you can also generate a matrix of random number, obviously, just to generate the vector and reshape them into a three by three matrix.

89
00:11:52,080 --> 00:12:04,710
And that's what you can do. So and if you want to guarantee some reproducibility, then you can use specific seed here.

90
00:12:05,910 --> 00:12:10,000
Well, this is 2000 to this year, 2022.

91
00:12:10,020 --> 00:12:19,230
So why don't we change it to 1322? Then, you know, it'll it'll generate a different sequence, but those are reproducible random number.

92
00:12:19,740 --> 00:12:27,340
So you can if you wanted to debug some cases of oh, I made that some overridden with the random number.

93
00:12:27,720 --> 00:12:34,350
I didn't work the specific case. Then you can reproduce that pattern if you used a specific seed.

94
00:12:35,550 --> 00:12:41,190
Okay. So. So that's the generic and then the numbers.

95
00:12:41,610 --> 00:12:44,640
And so how about a non-uniform distribution?

96
00:12:44,760 --> 00:13:00,690
Okay. So non-uniform distribution. Uh, you have, for example, so you know that, oh, there's a not just our uniform, but there is our norm.

97
00:13:00,870 --> 00:13:06,040
So this is a normal generated, normally distributed random variable.

98
00:13:06,060 --> 00:13:15,690
So if you are, uh, maybe I should have printed it in the way I didn't do that.

99
00:13:16,560 --> 00:13:30,750
Okay. Uh, so. So if you generate the random numbers in your screen image, it might be different numbers.

100
00:13:31,570 --> 00:13:40,810
But, you know, the first one generate a random of random value that are normally distributed from 0 to 1.

101
00:13:40,830 --> 00:13:44,250
So this is quite interesting that this is very small number.

102
00:13:44,340 --> 00:13:47,550
But yeah, that that can happen.

103
00:13:48,690 --> 00:14:00,300
And in this case, it's generating the one random number from the mean of three and variance of standard deviation of two.

104
00:14:00,570 --> 00:14:03,900
So that's that, that's what it does.

105
00:14:04,230 --> 00:14:13,710
In this case, if you're generating the binomial, it is by a random variable from the binomial distribution.

106
00:14:14,610 --> 00:14:21,740
With this, if this is a zero, this means that you're giving a it's a the maximum count is one.

107
00:14:21,750 --> 00:14:29,250
So this is normally random variable and a probability of one is a 2.3.

108
00:14:29,430 --> 00:14:33,980
So I mean, you can you can change this, this argument and see what happens yourself.

109
00:14:33,990 --> 00:14:39,750
So if you put ten, each of them obviously to generate the ten, ten different numbers like this.

110
00:14:40,560 --> 00:14:46,130
So and if you change the the maximum number binomial, it'll, it'll,

111
00:14:46,200 --> 00:14:53,100
it'll show that it'll show the number between the zero and four in different probabilities.

112
00:14:53,770 --> 00:15:02,150
Okay. So so one one thing one interesting thing you can think about is that.

113
00:15:03,230 --> 00:15:08,240
How do I. So let's say I don't have our norm.

114
00:15:08,900 --> 00:15:12,740
Okay. And can you. Can you generate.

115
00:15:13,250 --> 00:15:22,400
Okay. Can you generate random number generator, random numbers that are unique, that are normally distributed?

116
00:15:23,060 --> 00:15:28,220
If you have only the random number generator that are uniformly distributed.

117
00:15:28,610 --> 00:15:34,130
So the reason why I'm asking this is.

118
00:15:34,430 --> 00:15:38,430
Oh, sorry. So.

119
00:15:39,590 --> 00:15:47,780
So when we when you look at the random number generator, there is no random number generator that generates some.

120
00:15:48,340 --> 00:15:52,239
Normally this would be value or something. Some some other distribution.

121
00:15:52,240 --> 00:15:56,530
Always this this is going to generate something that are uniformly distributed.

122
00:15:57,460 --> 00:16:08,770
Right. So we saw an example that we can generate a random number from the non-uniform distribution and we probably take it for granted.

123
00:16:09,430 --> 00:16:16,420
But how you actually do that, if you have a random number generator that is not that is just a uniform.

124
00:16:17,650 --> 00:16:22,670
Okay. But what I think. So I just.

125
00:16:22,850 --> 00:16:27,670
You probably haven't thought about this problem, so it's not testing whether you know this or not.

126
00:16:27,680 --> 00:16:30,890
Just think about it. If you if you need to generate.

127
00:16:31,700 --> 00:16:38,060
How do how do I generate? So I have on the uniform the uniform random number generation.

128
00:16:38,710 --> 00:16:40,580
Um, I would.

129
00:16:40,580 --> 00:16:53,960
And then how do I, um, you know generate a normally this would random variable if you use like the inverse CDF university of whatever you know.

130
00:16:54,020 --> 00:16:57,710
So you read my mind so. Yeah.

131
00:16:57,740 --> 00:17:01,580
Exactly inverse you can use the inverse CDF. So. So.

132
00:17:02,330 --> 00:17:08,600
Uh, if you so if you know or CDF for function F, you can get the inverse CDF.

133
00:17:08,780 --> 00:17:20,060
So inverse CDF is basically the CDF is giving a if you give a random variable, then it'll, you know,

134
00:17:20,120 --> 00:17:27,610
give you the probability that that random variable is equal or smaller than that given value.

135
00:17:27,620 --> 00:17:36,620
Right. So. So if you the inverse CDF, if you give a probability that is a zero in one skill,

136
00:17:36,890 --> 00:17:42,780
it'll give you a random variable that that is mapped to that particular probability in the C in the CDF.

137
00:17:42,800 --> 00:17:45,800
So that works really well.

138
00:17:45,810 --> 00:18:02,630
So for example, let's say you is uniformly distributed between zero and one and Xs, Xs, the inverse CDF value of this uniform of this value.

139
00:18:03,020 --> 00:18:06,980
Then you can show that X actually follows.

140
00:18:09,350 --> 00:18:20,480
These are these are CDF x f, meaning that x actually follows the primary distribution that are defined by this CDF for f f.

141
00:18:20,630 --> 00:18:23,080
So proof is quite easy.

142
00:18:23,090 --> 00:18:35,770
So if you want to calculate this value x is less than x, then if because you have a random random variable that is you here, so that is equivalent.

143
00:18:35,780 --> 00:18:41,540
The probability of these F of inverse of u is less than x.

144
00:18:41,630 --> 00:18:47,870
This is equivalent is a probability. You is less than f of x, which is a which is actually f of x.

145
00:18:47,870 --> 00:18:54,349
So you can just you just prove that a few simple, random,

146
00:18:54,350 --> 00:18:58,880
random really disagree the random uniform of this random variable and take the

147
00:18:59,540 --> 00:19:06,229
inverse of it that'll just create the random variable that follows the follows.

148
00:19:06,230 --> 00:19:14,630
The CDF F in the example here is that if you have a property of exponential this random variable,

149
00:19:15,380 --> 00:19:20,180
you can calculate the CDF and if you have a calculate CDF, you can calculate the inverse CDF.

150
00:19:20,630 --> 00:19:30,980
So this is exactly the transformation you want to do in this case to generate a random variable that are exponentially distributed.

151
00:19:35,400 --> 00:19:44,420
So, uh. So before.

152
00:19:44,420 --> 00:19:48,739
So we're going to we're going to proximal transformation for doing this.

153
00:19:48,740 --> 00:19:53,300
Let let's finish this. Okay, so there is a example here.

154
00:19:53,900 --> 00:20:03,379
So, uh, so basically the equivalent representation here is that if you didn't have our norm, you can do the same thing.

155
00:20:03,380 --> 00:20:08,030
If you have all units and Q non Q means the inverse CDF, right?

156
00:20:09,170 --> 00:20:16,490
So if you have this function, then you're going to basically have the same effect.

157
00:20:16,610 --> 00:20:32,510
So I'm going to just make something similar to make sure that the upper and lower value are at least comparable in terms of distribution.

158
00:20:32,780 --> 00:20:37,010
Okay. So if you do that, then you're going to get this.

159
00:20:37,550 --> 00:20:41,630
So it's not going to be same number because it's a different random number generator.

160
00:20:41,990 --> 00:20:46,940
Even if you make the C the same, it may not be the same because the way how they transform is different,

161
00:20:47,210 --> 00:20:56,930
but at least both of them looks like it's a giving values based on the expected distribution when you see this.

162
00:20:57,980 --> 00:21:03,540
Okay. Okay.

163
00:21:04,620 --> 00:21:08,670
Bless you. So. Uh.

164
00:21:13,330 --> 00:21:19,000
So. So then let's think about the question. Is Russian culture this Russian?

165
00:21:20,920 --> 00:21:27,370
We can we want to use something like this inverse CDF here and numerically we can just use Q the arm.

166
00:21:27,760 --> 00:21:32,380
But analytically we don't have this close form solution like this.

167
00:21:32,590 --> 00:21:37,810
Okay. CDF in Gaussian is much more complicated.

168
00:21:38,530 --> 00:21:41,650
It uses these so you usually see that.

169
00:21:41,980 --> 00:21:56,320
So PDF can be represented with a special formula, but in the CDF you need to use it into the Zeta function or something else to to represent the CDF.

170
00:21:56,320 --> 00:22:01,870
So see the CDF is a hard to describe exactly an inverse.

171
00:22:01,870 --> 00:22:18,070
CDF is also hard to describe. So it's not. There's no really good formula to use to transform the uniformly this random variable to normal is random.

172
00:22:18,700 --> 00:22:34,040
Okay. So and so using inverse KDFW is not a good way to analytically produce the Gaussian random variable central limit theorem.

173
00:22:34,250 --> 00:22:41,490
You can use that because you you can. I generate a lot of samples and take the you know,

174
00:22:41,540 --> 00:22:50,239
take the mean of them and they should follow center limit theorem so you can do that but that requires a lot of multiple random variable.

175
00:22:50,240 --> 00:22:53,800
So you may even if you generate the, you know.

176
00:22:54,940 --> 00:23:03,700
The million random sample samples that may not exactly follow the follow the exact normal distribution, but that is the problem.

177
00:23:05,380 --> 00:23:13,960
So another way to generate a Gaussian random variable is using something called the box meal transformation.

178
00:23:14,590 --> 00:23:19,840
Okay, so what is box transformation?

179
00:23:19,990 --> 00:23:27,730
Okay. So facsimile transformation is taking to uniformly distribute the random variable.

180
00:23:27,970 --> 00:23:39,280
Okay. Okay. And, uh, and they calculate something a little bit interesting here.

181
00:23:39,490 --> 00:23:43,000
Okay. So you calculate the R.

182
00:23:43,360 --> 00:23:53,360
Okay. So, so is the correspond the radius and, and the negative to, uh, natural log of u one.

183
00:23:54,130 --> 00:23:59,640
And data is calculated in to pi you want.

184
00:23:59,650 --> 00:24:06,760
So you can you can imagine that r is basically, uh, it's so.

185
00:24:07,330 --> 00:24:14,950
Uh, so R is a, it's a, it's a strange expression where we can, if we can look at it.

186
00:24:14,950 --> 00:24:19,990
But the theta is a straightforward is going from the 0 to 360 degree.

187
00:24:20,830 --> 00:24:27,970
So based on these two values, you can calculate Z1 and G two here.

188
00:24:28,260 --> 00:24:41,410
Okay. Then you can prove that this if you if you calculate as you want to do to both of them, uh, follows the normal distribution.

189
00:24:41,800 --> 00:24:47,950
Okay. That are, that have a mean zero and the variance one.

190
00:24:48,310 --> 00:24:51,730
And they are independent from each other. Okay.

191
00:24:53,530 --> 00:25:07,329
So. And our square, if you. So the reason why this works is because if you take all square is actually two so basically minus two times L and you one.

192
00:25:07,330 --> 00:25:11,950
Right. This one is actually quite good, this video.

193
00:25:12,220 --> 00:25:18,820
Okay. So the way how you can see this is a so it's a chi square distributions, the exponential distribution.

194
00:25:18,820 --> 00:25:25,450
So if you put lambda as a two and then the lambda is a one over one over half here.

195
00:25:25,720 --> 00:25:36,430
Then this is minus two and then one minus you. Right? So, uh, so and then one minus you and you basically the same because it's uniformly distributed.

196
00:25:37,160 --> 00:25:40,840
So, uh, yeah, that's. That's how it works, right?

197
00:25:40,850 --> 00:25:49,160
So, uh, because this follows Chi Square distribution we have to this.

198
00:25:50,050 --> 00:25:53,230
Uh, so if you use, use this fact,

199
00:25:53,230 --> 00:26:00,280
you can easily prove that z what zero and one follows a normal distribution and they are independent from each other.

200
00:26:00,850 --> 00:26:06,720
Okay. Okay. Any questions so far?

201
00:26:09,110 --> 00:26:12,900
So the proving park formula transformation is kind of fun.

202
00:26:12,920 --> 00:26:21,200
It's I don't think it's too hard. So if you if you're interested in this art is a good exercise for forward thinking yourself.

203
00:26:22,370 --> 00:26:27,500
What I'm going to do here is just showing that this actually works.

204
00:26:27,650 --> 00:26:30,889
Okay. So let's try to implement.

205
00:26:30,890 --> 00:26:35,280
Decide what you do so well. Ah.

206
00:26:35,450 --> 00:26:41,500
So I'm going to generate a you want you to, I'm going to generate the million variable that follows the follows these

207
00:26:42,140 --> 00:26:50,000
uniform distribution and I'm going to generate these are that are is basically

208
00:26:50,000 --> 00:27:05,420
asking is a high school disputed and a data data is this okay then then I'm going to project the G0 and Z one and what I'm going to do I can I mean,

209
00:27:05,660 --> 00:27:13,370
proving that this follows normal distribution is a little, little more challenging.

210
00:27:13,370 --> 00:27:21,739
But I can at least show that, oh, if, if I do that being of G1 to zero and G1 is very close to zero and the variance

211
00:27:21,740 --> 00:27:31,310
of digital in G1 is one and the covariance is very close to close to zero.

212
00:27:31,460 --> 00:27:43,340
Right. And if you're not convinced with this yet, I, we could, we could also try like histogram it, maybe break 900.

213
00:27:43,610 --> 00:27:46,940
Then you can see that this looks like normal speed, right?

214
00:27:47,570 --> 00:27:55,670
So it works. Okay. So standard, standard, normal distribution obviously will give us similar kind of values.

215
00:27:55,710 --> 00:28:01,250
I'm just trying to show that this also works in the standard this these values are

216
00:28:01,250 --> 00:28:05,300
comparable way to what you would would have gotten from the standard normal distribution.

217
00:28:05,540 --> 00:28:11,990
Okay. So but yeah, the bottom line is the box below transformation works.

218
00:28:13,760 --> 00:28:17,500
Any question so far? Okay.

219
00:28:18,760 --> 00:28:22,370
Okay. Okay.

220
00:28:26,280 --> 00:28:31,950
So. Okay, how about more complex, complex decisions?

221
00:28:32,160 --> 00:28:34,110
So how do I generating random numbers?

222
00:28:34,170 --> 00:28:48,090
Okay, so sometimes you're if you have some complex distribution, you may not readily have those CDF or inverse CDF.

223
00:28:48,630 --> 00:28:58,080
Okay. So in that case, you may have to implement your own way to generate a random variable that

224
00:28:58,080 --> 00:29:03,780
follows the distribution you intend to generate to generate the random numbers.

225
00:29:04,620 --> 00:29:09,870
So one good example is a mixture of two normal distribution.

226
00:29:10,170 --> 00:29:20,220
Okay. So make mixture of normal distribution is basically you are generating the random variable from either of those to normal distribution,

227
00:29:20,820 --> 00:29:26,920
but you have a certain probably to sample from this normal distribution versus sample from the other normal distribution.

228
00:29:26,940 --> 00:29:38,520
So if you want to write down the mixture, mixture of normal distribution, it is relatively simple in terms of PDF.

229
00:29:39,270 --> 00:29:46,030
So probably densities like this and DC.

230
00:29:46,290 --> 00:29:56,790
So in this case, you have alpha probability for example, from normal distribution of mean amu one and various sumo and squared and a one minus,

231
00:29:56,790 --> 00:30:01,890
therefore probability of sampling from mute two and sigma scared two.

232
00:30:02,100 --> 00:30:09,170
Okay, so pdf of simple but calculating the CDF and inverse CDF is not that simple.

233
00:30:09,180 --> 00:30:17,520
So there is a R doesn't provide a convenient CDF or inversely their function for this mixture of normal.

234
00:30:18,070 --> 00:30:23,430
Okay. So because in this case you don't have CDF, right?

235
00:30:23,850 --> 00:30:28,320
But you know the process of how to generate this random number.

236
00:30:28,980 --> 00:30:35,250
Right. So how would you create the random number generator?

237
00:30:35,790 --> 00:30:39,090
Good. So you can try the code coder with arm.

238
00:30:39,950 --> 00:30:47,070
If you if you are stuck, then you can you can look at the code that from the lecture notes, but you can think about how to do it.

239
00:30:48,570 --> 00:30:51,990
How do I generate a random variable that follows these species?

240
00:30:55,410 --> 00:31:01,870
I'll just give you one minute to think about it. Show the show.

241
00:31:02,840 --> 00:31:09,140
Show the. The one person implementation. I'm sorry.

242
00:31:09,860 --> 00:31:26,120
I had more than 40. Okay.

243
00:31:27,980 --> 00:31:38,000
So one, I mean, this is not the only way, but the one possible way is to introduce a random finally random variable.

244
00:31:38,160 --> 00:31:46,880
So because you have. So it's the this this idea is that just trying to mimic the generating process process of this random variable.

245
00:31:47,510 --> 00:31:56,630
So you so select make a the random variable W that is either zero or one the coin flip.

246
00:31:56,810 --> 00:32:01,580
So I do a coin flip where with the probability of an alpha being head.

247
00:32:02,300 --> 00:32:09,020
And if the coin flip says one, then I'm going to sample from component one.

248
00:32:09,530 --> 00:32:13,130
If the coin flips as zero, I'm going to sample from component two.

249
00:32:13,310 --> 00:32:28,130
Okay. So sample Y and Z this way and use this thing because if W is a zero or one, then this this equation is basically selecting from Y.

250
00:32:28,220 --> 00:32:31,550
If W equals one and selecting selecting from one.

251
00:32:32,210 --> 00:32:35,600
So selected to select the z w equals zero. Okay.

252
00:32:36,260 --> 00:32:39,380
So this is one possible implementation. Okay.

253
00:32:40,640 --> 00:32:53,750
So let's look at that. Okay. So here we have our focal point eight and sigma one equals one.

254
00:32:53,750 --> 00:33:01,100
Sigma two equals two. And so basically this means that the first component is a mean zero is a variance.

255
00:33:01,100 --> 00:33:04,670
1/2 component is a mean is two and the variance is phi.

256
00:33:04,790 --> 00:33:11,040
Right. And the alpha is a point eight mean meaning that the first component is 80%.

257
00:33:11,040 --> 00:33:15,620
The possibility to be sampled from. And the other has a 20% possibility.

258
00:33:16,340 --> 00:33:20,090
Okay. And I'm going to sample thousand values.

259
00:33:20,450 --> 00:33:24,770
Okay. You can you can try this. Exactly. W equal or Bynum.

260
00:33:25,130 --> 00:33:29,030
Okay. And I'm going to make X as an empty vector.

261
00:33:29,210 --> 00:33:39,650
Okay. And what I'm going to do is all you know, there's a count of how many, how many variables were sampled with, you know, w equals one.

262
00:33:40,070 --> 00:33:44,630
So. And for those samples, basically, I'm going to sample that.

263
00:33:44,840 --> 00:33:48,200
Then many samples with a view you want is sigma one.

264
00:33:48,440 --> 00:33:53,210
Okay. And I can do I can sample the rest of the sample with w equals zero.

265
00:33:54,230 --> 00:33:59,750
And the count should should be and and minus and minus one and minus n1.

266
00:33:59,900 --> 00:34:07,730
So then you can, you can sample from normal distribution like this and let's see how it looks like.

267
00:34:07,970 --> 00:34:12,920
Then the distribution of divergence. A random sample value looks like this.

268
00:34:13,250 --> 00:34:22,160
Okay. And then you can you can do again. And the distribution will change slightly, but looks pretty much similar because it's a mixture of the,

269
00:34:23,210 --> 00:34:27,590
you know, so the first component is that you don't mind your own variance.

270
00:34:27,590 --> 00:34:33,979
1/2 component is a mean mean of min five and variance two.

271
00:34:33,980 --> 00:34:38,240
I'm sorry I said I mean to in variance vibrate mean five and variance two.

272
00:34:38,810 --> 00:34:42,200
And so this looks lovely close to each other.

273
00:34:42,680 --> 00:34:50,380
And if you change this probability, instead of saying 80%, if you say 50%, then it's going to be looking like this.

274
00:34:50,390 --> 00:34:54,740
The reason why this is this looks lower because this has a higher variance.

275
00:34:54,740 --> 00:35:01,320
So it's a more spread out. Okay. So this is one way to generate it.

276
00:35:01,710 --> 00:35:07,050
So almost a similar way. I'm not saying this is a better but this is called the code is a slightly simpler.

277
00:35:07,710 --> 00:35:12,330
So one way to do it is you still need to sample W here.

278
00:35:12,360 --> 00:35:20,010
So you probably need to just copy this here if you, if you don't want to be the,

279
00:35:20,190 --> 00:35:27,299
don't want to be, uh, which is off of the one one, this is part independent.

280
00:35:27,300 --> 00:35:34,150
But I'm going to, I'm going to just, we use this w here to make sure that these are these are similar.

281
00:35:34,230 --> 00:35:46,500
So what you can do is, uh, so you can use the which functions to get the indices, indices of w one and zero.

282
00:35:47,100 --> 00:35:55,410
And, uh, you can just do this, but so what, what, what this does is that a simple, normal, uniform, normal distribution here.

283
00:35:55,710 --> 00:36:05,310
Okay. And you just rescale them differently based on whether w we could zero or w equal one.

284
00:36:05,400 --> 00:36:09,510
So this is another way to do that. Again, I'm not saying this is the better way to do it,

285
00:36:09,510 --> 00:36:16,470
but this will generate a pretty much a similar distribution from the original one, although the random numbers are still different.

286
00:36:17,880 --> 00:36:24,960
Okay. So so that's the end of the version mixture part.

287
00:36:25,350 --> 00:36:32,720
Okay. Any questions? Okay.

288
00:36:33,480 --> 00:36:39,330
Now. Okay. Now the transformation and everything is pretty good.

289
00:36:39,750 --> 00:36:50,140
Okay. And this mixture distribution set examples shows that how I can generate my own random variable even if I don't know the inverse CDF.

290
00:36:50,190 --> 00:36:57,690
So those are all great. How about sampling from correlated random variable?

291
00:36:58,440 --> 00:37:03,630
So if you look at the normal distribution, if you have a two values, you have a very normal distribution.

292
00:37:03,990 --> 00:37:07,350
Okay. So you have X and Y.

293
00:37:07,740 --> 00:37:16,110
So box transformation can provide a random randomly distributed pair of the value.

294
00:37:16,120 --> 00:37:19,499
But those are independent. I don't want to be independent. Sometimes I can't.

295
00:37:19,500 --> 00:37:22,950
I want to have correlation. How do you do it?

296
00:37:30,770 --> 00:37:38,940
Yep. Can we fix one of the sample before and then we'll be up there alphabetically.

297
00:37:38,940 --> 00:37:48,800
Conditional. Yeah. Very good idea. So get the sample one variable first x, x or y, then you can rewrite this as a condition.

298
00:37:48,810 --> 00:37:56,070
So for the other value condition on that, the sample, the value and the and get that.

299
00:37:56,070 --> 00:38:03,420
So, so again, so our students are very good at reading my mind and that's exactly what it was done here.

300
00:38:03,490 --> 00:38:10,620
Right? So simple X with a marginal distribution and you can get a conditional distribution this way.

301
00:38:10,830 --> 00:38:14,370
So in that case, you can do that.

302
00:38:14,520 --> 00:38:21,390
Okay. If you do the condition of distribution, it's a it's a little messy, but it's impossible to get.

303
00:38:21,900 --> 00:38:31,469
So just re re re scale these to mean and uh, mean a standard deviation and a means to be dependent.

304
00:38:31,470 --> 00:38:37,350
And what that X value was, you cannot do it. You cannot do it in parallel, but you can do sequentially like this.

305
00:38:37,500 --> 00:38:47,520
Okay, so very good idea. Okay. Uh, how about so how about the multi vary in normal distribution?

306
00:38:48,450 --> 00:38:53,040
Okay. What if what if you have so many values you want to sample from?

307
00:38:53,460 --> 00:38:58,500
Okay, so you are given in this case mean and vector in the covariance matrix.

308
00:38:59,080 --> 00:39:08,780
Okay. So, uh. In the matrix can be positive.

309
00:39:09,500 --> 00:39:13,360
Definite like this. Okay. So this.

310
00:39:13,670 --> 00:39:17,180
So this is just the extension of this abbreviated idea.

311
00:39:17,570 --> 00:39:21,129
But note that these are blocks of multiple variables.

312
00:39:21,130 --> 00:39:26,680
So this is this doesn't have to be single scalar. So this is these can be MBM metrics.

313
00:39:26,690 --> 00:39:34,670
This can be in by matrix and or different sized, but you can just divide the covariance matrix into two different blocks.

314
00:39:35,840 --> 00:39:47,480
In that case, you can do this same thing. Conditional distribution, then x one is you can just sample from this multivariate normal distribution.

315
00:39:47,690 --> 00:39:56,470
Okay. And you can sample this using using this equation right there.

316
00:39:56,480 --> 00:40:05,210
Well, how do I sample from multivariate normal distribution? Well, you could you could do this kind of thing recursively.

317
00:40:05,520 --> 00:40:09,110
Okay. So that's one way to do it. I'm not saying that's practical.

318
00:40:09,110 --> 00:40:15,830
That's a possible way to do it. Okay. So you can you can solve this problem using sort of divided divide and conquer kind of algorithm.

319
00:40:16,370 --> 00:40:25,100
So that's one way to do it. Okay. But the idea is that if you keep doing this conditional sampling, you should be able to get it at the end.

320
00:40:25,340 --> 00:40:33,480
Okay. But this is really the challenge with this is that you have to inverse these codes matrix and multiply.

321
00:40:33,530 --> 00:40:36,530
You need to do it multiple time. It's not very fun.

322
00:40:37,040 --> 00:40:44,989
And it's a lot of, you know, a lot of a lot of like figuring out what the right one right equation should you should be using.

323
00:40:44,990 --> 00:40:48,770
But also it's a redundant calculation.

324
00:40:49,220 --> 00:40:53,990
Okay, so how do y avoid this kind of thing?

325
00:40:54,620 --> 00:41:03,440
Okay. So if you do the sequential conditional distribution, you know, just a single conditional distribution looks this much complicated.

326
00:41:03,590 --> 00:41:11,840
Okay. If you keep using conditional description over multiple variable, this becomes can easily become intractable.

327
00:41:11,840 --> 00:41:14,840
And it could be very time consuming, too.

328
00:41:15,110 --> 00:41:23,840
So is there another way not to use conditional distribution explicitly, but use kind of same kind of concepts?

329
00:41:29,840 --> 00:41:38,590
They'll give you another one minute. You're just a temporary. So.

330
00:42:13,330 --> 00:42:32,050
Okay. So the idea here is that you can use so you can use independently distribute random variable and make them correlated.

331
00:42:32,410 --> 00:42:42,610
Okay. But if you if you add and multiply specific values there, why is it possible?

332
00:42:42,640 --> 00:42:52,570
So there is a this is this is the key principle in a multi multivariable variable.

333
00:42:52,570 --> 00:42:58,000
So if X is a caution Gaussian random variable there that has a mean,

334
00:42:58,540 --> 00:43:06,790
mean M and covariance sigma, then when you multiply some matrix arbitrary matrix A,

335
00:43:07,870 --> 00:43:20,350
then a x should be should also follow the multi normal sorry multi so multivariate so multivariate normal distribution

336
00:43:20,560 --> 00:43:32,020
with mean is just a scale like this and variance is just a multiply a in a transpose it at the beginning and the end.

337
00:43:32,780 --> 00:43:37,890
Okay. So this is a very well known effect.

338
00:43:38,260 --> 00:43:45,700
Okay. And so so this you can use this now because you know, you know this fact.

339
00:43:45,700 --> 00:43:49,510
Do you do you see what what what we're going to be going to.

340
00:43:51,720 --> 00:44:03,870
So basically instead of sampling correlate random variable directly, you can sample on independent sorry standard normal distribution here.

341
00:44:07,430 --> 00:44:14,930
Here and then if. So the question is the finding the right A and m to reskill them.

342
00:44:15,860 --> 00:44:19,219
So what I want to do is I want to start with the Z that are state,

343
00:44:19,220 --> 00:44:27,800
the normal independent normal distribution and want to make X to be the normal distribution like this.

344
00:44:28,490 --> 00:44:34,100
But if I do eight times Z plus M, I already know that this should be distributed like this.

345
00:44:35,090 --> 00:44:38,900
Okay. Do you do you get what a should be?

346
00:44:40,400 --> 00:44:47,930
There are multiple that there could. So there is no single a that that satisfies this equation.

347
00:44:47,930 --> 00:44:56,360
So there could be multiple of them. Okay. So we is a is a symmetric matrix because it is a covariance matrix.

348
00:44:56,660 --> 00:45:04,010
Okay. So if you if you see this, maybe, oh, this looks very similar to the actual ASCII composition you can use.

349
00:45:04,010 --> 00:45:10,700
Jonathan conversion. If I have ritualistic conversion of my covariance matrix, then you can use just a U.

350
00:45:10,970 --> 00:45:21,050
So there is a lower triangular part of lower triangular representation of this composition as a than that that is solved this.

351
00:45:21,270 --> 00:45:29,180
Okay. Another way to think about is that if you if you want to start with the eigen decomposition, we looks like this.

352
00:45:29,210 --> 00:45:38,360
So if you make a as the D transpose and just so this is diagonal matrix.

353
00:45:38,360 --> 00:45:44,300
So these are again decomposition of basically both both of the singular vectors are the same.

354
00:45:44,510 --> 00:45:48,260
Okay. So it's a transport form.

355
00:45:48,260 --> 00:45:53,790
So you take one of those singular vectors and this is diagonal matrix.

356
00:45:53,790 --> 00:46:06,380
So taking the square root of a super E, just taking the security of those diagonal and that this this also should be a good matrix to use to,

357
00:46:06,740 --> 00:46:11,750
uh, to sample from the multivariable models we should get.

358
00:46:12,110 --> 00:46:22,280
So there could be a lot more. So there are different ways to find the, but find the matrix that, that gives these properties.

359
00:46:24,950 --> 00:46:28,340
Ritualistic Solecki. Decomposition will have a lot of zeros.

360
00:46:28,380 --> 00:46:32,000
It's a triangular matrix, so it's kind of sequentially solving.

361
00:46:32,000 --> 00:46:36,860
If you think about this, this is more closer to the concept of a conditional sampling.

362
00:46:36,860 --> 00:46:43,280
So you you select the first one with a marginal distribution without it anything related to the second one,

363
00:46:43,280 --> 00:46:50,659
you're you're using you're taking the combination of first two thirds, one you're using combination of first three and so on.

364
00:46:50,660 --> 00:46:58,610
So it's sort of decomposition. It's probably more similar to what was describing the conditional or random sampling.

365
00:47:00,530 --> 00:47:05,960
Okay. So this is the last slide. Let's try to make it work.

366
00:47:06,290 --> 00:47:17,990
Okay. So what I'm what I'm trying to do here is, uh, I'm going to just do this.

367
00:47:18,140 --> 00:47:24,830
Okay? So in this case, first one is that we're going to just use a realistic decomposition.

368
00:47:24,980 --> 00:47:30,230
Okay? So you have a sigma given, so get ritualistic decomposition.

369
00:47:30,650 --> 00:47:37,100
And if you calculate the MU plus you transpose times Z, that's what you need.

370
00:47:37,100 --> 00:47:50,090
So just use a cross product here and this is the one way to rent sample from the the body, the normal distribution.

371
00:47:50,200 --> 00:47:54,709
Right. And I said, I guess decomposition is also possible.

372
00:47:54,710 --> 00:47:57,800
So let's try this. If you if you do this, you can do it.

373
00:47:57,810 --> 00:48:00,830
So the way how you do it is, again, decomposition.

374
00:48:00,830 --> 00:48:07,250
You can just use again. Then again has this eigenvalue.

375
00:48:07,520 --> 00:48:10,730
Okay. And these are eigenvectors, right?

376
00:48:12,620 --> 00:48:17,810
Uh. Just give me a second.

377
00:48:36,430 --> 00:48:41,799
Okay. So you can calculate this.

378
00:48:41,800 --> 00:48:46,300
The transpose times, the igen.

379
00:48:47,470 --> 00:48:53,340
So this is a diagonal vector. Are you going to matrix? They're going to matrix or they're taking the square root of them.

380
00:48:54,010 --> 00:48:58,390
Then think about it. If you do this, this is a matrix multiplication, right?

381
00:48:59,020 --> 00:49:06,560
So this will be expensive. But this time a part is all basically, you know, user lists.

382
00:49:06,820 --> 00:49:10,930
So what what we are doing is that you have some matrix here.

383
00:49:13,360 --> 00:49:16,570
You really want to get rid of this? That there's more.

384
00:49:27,480 --> 00:49:34,370
Okay. So you have you have some some complicated values here.

385
00:49:34,550 --> 00:49:39,790
Right. And what you want to do is multiply some diagonals, right?

386
00:49:39,800 --> 00:49:47,390
So everything else is, you know, maybe I should say X or or something else.

387
00:49:47,750 --> 00:49:53,960
So the E1 D to the three and so on.

388
00:49:53,970 --> 00:49:57,320
So we already covered this in one of the lectures.

389
00:49:58,040 --> 00:50:10,210
But basically if you multiply this, what you would expect is that, okay, you're, you're multiplying everything by t1p1 times this.

390
00:50:10,700 --> 00:50:17,060
So if this is x one, so I would say this is our one or two and so on.

391
00:50:17,360 --> 00:50:22,480
These two, these two will be basically V one and r one, e two times are two and so on.

392
00:50:22,490 --> 00:50:28,910
So everything, right? So you're just multiplying each of the rows by this much.

393
00:50:29,690 --> 00:50:34,760
So the doing the matrix multiplication is not the most efficient way.

394
00:50:35,180 --> 00:50:40,880
What I'm trying to do here is I'm making a matrix.

395
00:50:41,410 --> 00:50:45,010
Okay. Here. So this is.

396
00:50:51,770 --> 00:50:56,480
Actually, I did. I did not. And I'm sorry. So I did multiply here.

397
00:50:56,660 --> 00:51:07,130
Okay, but this is not the not the most efficient way to do it. Uh, no, no, I did multiply, but this one is okay.

398
00:51:07,660 --> 00:51:10,760
So, uh, yeah.

399
00:51:10,760 --> 00:51:16,040
So this. This is how I do it. Okay. So, uh, so I didn't.

400
00:51:16,220 --> 00:51:19,400
I didn't. I didn't multiply to them that right.

401
00:51:19,400 --> 00:51:22,400
So I did it. I did the multiply by in vectors.

402
00:51:23,240 --> 00:51:30,350
So the reason why I did this is that I'm just rescaling them with a security of lambda.

403
00:51:30,620 --> 00:51:40,340
Okay. So because you just need to scale them. So make the variance to be proportional to the to the security random the two to the eigenvalue.

404
00:51:40,910 --> 00:51:49,580
So when you randomly sample Z, I'm just rescaling them so that I have a proper multiplication there and everything else is the same.

405
00:51:49,590 --> 00:51:56,630
So instead of doing the uniform random here, you're just doing the B in zero in standard deviation of security of lambda.

406
00:51:57,170 --> 00:51:59,719
And just due to this math, this multiplication,

407
00:51:59,720 --> 00:52:06,200
that this is a computation more efficient than doing all of the matrix multiplication that is unnecessary.

408
00:52:06,560 --> 00:52:09,980
Okay. So that's what I want you to tell.

409
00:52:10,430 --> 00:52:16,070
Okay. So now let's try to calculate this.

410
00:52:16,220 --> 00:52:24,530
Okay. So I'm going to do is 13,000 dimension, thousand dimension, the multivariate normal distribution.

411
00:52:25,160 --> 00:52:28,580
And I I'm going to say mean it's always zero row,

412
00:52:28,580 --> 00:52:37,170
which is basically of diagonal covariance is always point five and that make it make it easier to generate the matrix in

413
00:52:37,220 --> 00:52:44,960
a let's make a 5000 replicate by 4000 replicate meaning that I'm going to generate a thousand by thousand matrix 5000,

414
00:52:45,590 --> 00:52:55,830
5000 times. Okay. So then, uh, I made this decision.

415
00:52:56,360 --> 00:53:01,730
So, uh, so let me see.

416
00:53:03,440 --> 00:53:16,620
Oh. Oh, sorry.

417
00:53:17,580 --> 00:53:25,229
Yeah, I'm sorry. So this is $1,000 that the manager of the motivated normal distribution and I'm generating the

418
00:53:25,230 --> 00:53:34,620
5000 replicate of them so that we what this will return is that 5000 column in a thousand rows,

419
00:53:34,620 --> 00:53:41,760
a thousand each of the row will have, uh, yeah, we'll have a thousand dimensions.

420
00:53:41,850 --> 00:53:48,210
So each of the column is the multivariate normal distribution, but I'm going to generate the five 5000 replicate duplicate of it.

421
00:53:49,860 --> 00:54:01,919
And if you if you do it, this takes this takes about the first one using this decomposition takes about

422
00:54:01,920 --> 00:54:08,700
1/2 second one that user in decomposition slightly slower because again,

423
00:54:08,700 --> 00:54:32,400
the composition is slower. I'm sorry. Hmm.

424
00:54:32,620 --> 00:54:36,969
So again, the competition is slower than tourist repercussions.

425
00:54:36,970 --> 00:54:42,130
So there are some some discrepancy in terms of the.

426
00:54:46,300 --> 00:54:54,250
Sorry. In terms of computation efficiency.

427
00:54:54,700 --> 00:55:01,059
So let's say if it does really do the right thing to calculate the covariance matrix.

428
00:55:01,060 --> 00:55:07,180
So because we want to evaluate the correctness of one way to do it is you just calculate the

429
00:55:07,180 --> 00:55:13,630
covariance matrix from the sample the value and calculate the empirical covariance covariance values.

430
00:55:14,230 --> 00:55:20,930
So then if you look at the diagonal diagonal, it should have all a variance of one.

431
00:55:20,950 --> 00:55:24,760
So diagonal value will have almost everything.

432
00:55:25,210 --> 00:55:30,400
All value have a variance close to one and a upper triangular.

433
00:55:32,830 --> 00:55:42,250
The value is a covariance value so that are of diagonal, that the looks of all of value have a value that is close to 0.5.

434
00:55:42,460 --> 00:55:52,510
So this looks pretty good in terms of the the showing that this does give are reasonably well simple to value based on the expected distribution.

435
00:55:53,980 --> 00:56:00,640
Okay, you can do the same thing that is generated from the competition and you will see the, you know, the,

436
00:56:01,240 --> 00:56:06,040
the, the distribution looks fairly similar to each other because both of them are doing the right thing.

437
00:56:08,260 --> 00:56:12,610
So I have some more code. So let me, let me explain this.

438
00:56:13,420 --> 00:56:20,200
So this part is not necessary to understand, but I'm just trying to show that you can do this too.

439
00:56:21,640 --> 00:56:26,620
So in this case, in this particular structure, you know, the covariance.

440
00:56:26,770 --> 00:56:30,639
Covariance is always point five between all the diagonal matrix.

441
00:56:30,640 --> 00:56:38,620
So you can actually leverage those fact to to make it a little bit easier.

442
00:56:38,620 --> 00:56:51,220
So one way to do it is that you generate a random randomly, so you just generate a tool randomly to random variable.

443
00:56:51,610 --> 00:56:55,300
So because of covariance, exactly 0.5 if you adjust it.

444
00:56:55,840 --> 00:57:00,090
So let's say you have X and Z, okay?

445
00:57:00,490 --> 00:57:09,010
And this X is a share. Share. The covariance is shared random variable and these are these are independent random variable.

446
00:57:09,680 --> 00:57:21,220
So basically y y you want is an x plus d1y2 is x plus z two and you want to g to is independent.

447
00:57:21,430 --> 00:57:32,169
So those are independent. Then if you do this way, then covariance between the y one and y two will be just, you know, proportional to this variance.

448
00:57:32,170 --> 00:57:39,130
And if they have equal variance, this will be point five. So that's what that's what this is trying to do here.

449
00:57:39,610 --> 00:57:46,270
So you have so so you have a g an X here.

450
00:57:46,570 --> 00:57:53,590
And we're trying to adjust the Adamu and Sigma here to just rescale them.

451
00:57:53,590 --> 00:58:01,870
But just basically the idea is just adding x x with Z, so then that'll make them just correlated.

452
00:58:01,870 --> 00:58:09,490
So this is not us, this is not a general solution, but this is one possible solution that could be more efficient.

453
00:58:10,210 --> 00:58:16,270
And if you do that, my point is that this can be a lot faster than the previous one.

454
00:58:16,270 --> 00:58:22,720
So which took 1/2, but this is 0.5 seconds, point 6 seconds, but it's not like huge improvement.

455
00:58:22,730 --> 00:58:28,660
So my point is that the way how we did it is not that inefficient.

456
00:58:28,660 --> 00:58:33,200
So that's the that's the point I wanted to make. Okay.

457
00:58:33,910 --> 00:58:39,040
Using the statistic, obviously the resulting outcome will be pretty much the same.

458
00:58:39,040 --> 00:58:45,700
So the summary statistic for diagonal and off diagonal covariance looks good here, too.

459
00:58:49,120 --> 00:58:55,050
So the final thing I wanted to tell is that there's a package called MBT.

460
00:58:55,090 --> 00:58:58,930
Norm okay, so these packages.

461
00:59:01,600 --> 00:59:15,420
The purpose. So this package is intended to make this multivariate normal sampling and harder analysis easier.

462
00:59:17,160 --> 00:59:22,710
So this is a library that is publicly out in the use the lot.

463
00:59:23,790 --> 00:59:33,000
And they do have a they do have a packaging page that allows to generate the right

464
00:59:34,980 --> 00:59:42,930
to generate them in the the multivariate normal distribution random variable.

465
00:59:43,740 --> 00:59:52,410
So here you're sampling and different random variable in m M is the mean that that is basically the P dimensions and if we is a P by matrix.

466
00:59:53,370 --> 00:59:58,290
So you can give a number of samples you want to sample sample from and the mean and variance.

467
00:59:58,620 --> 01:00:04,209
Then you can do that if you see how long it takes.

468
01:00:04,210 --> 01:00:09,180
The 1.3 5 seconds is actually not faster than the ritualistic.

469
01:00:09,360 --> 01:00:12,520
So let's see, the composition we developed, right?

470
01:00:12,810 --> 01:00:16,020
Just the way we implemented it was a very simple implementation.

471
01:00:16,020 --> 01:00:24,760
But the the point I wanted to make here is that the publicly available package is not always faster than what you can implement.

472
01:00:24,780 --> 01:00:32,310
So you can do pretty well, especially if you know what to what you want to do in your specific application domain.

473
01:00:32,700 --> 01:00:35,939
And this one obviously does does do the right thing.

474
01:00:35,940 --> 01:00:40,889
But it's the performance is a comparable with I get the conclusion but not not as

475
01:00:40,890 --> 01:00:46,930
comfortable with the choice of decomposition and maybe decomposition is probably safer.

476
01:00:46,950 --> 01:00:58,680
I mean the more stable because if there is a lot of you know, if the matrix is a is a rank zero problem, I think the competition more are more stable.

477
01:00:59,190 --> 01:01:05,730
So that's probably the norm is using something similar today again again the composition.

478
01:01:06,030 --> 01:01:12,000
But if if you have if you don't have that concern, you can use your conversion to make make it faster.

479
01:01:13,870 --> 01:01:18,550
Okay. So that's all I have for this lecture.

480
01:01:20,030 --> 01:01:24,990
Uh, any other questions? Okay.

481
01:01:26,240 --> 01:01:31,230
So the new homework will have this.

482
01:01:31,380 --> 01:01:32,580
Now, these random.

483
01:01:33,130 --> 01:01:42,600
Um, so there are, there are Monte Carlo methods that we will cover in the lecture ten that that have come as a homophobe problem one of them.

484
01:01:42,600 --> 01:01:48,240
So I just wanted to have a segue way and make sure that you understand this part.

485
01:01:51,940 --> 01:01:55,360
So we learned how to generate the random variables.

486
01:01:56,680 --> 01:02:02,920
Now each of our how to use those random variables in this lecture.

487
01:02:03,060 --> 01:02:07,610
Okay. There are many different ways to use the random variables in a.

488
01:02:09,460 --> 01:02:16,650
In this particular particular case, we'd like to talk about the case of these.

489
01:02:21,280 --> 01:02:25,030
So it is generating more complex, complex distribution.

490
01:02:25,030 --> 01:02:30,729
So we ve already looked at these a particular case of those mixtures of normal.

491
01:02:30,730 --> 01:02:37,720
And we can if you if we know the generating procedure, we can we can generate a random variable.

492
01:02:38,140 --> 01:02:41,350
But many cases is not quite that simple.

493
01:02:41,350 --> 01:02:51,909
So we need a more general way to get the general way to draw a random variable from arbitrary distribution.

494
01:02:51,910 --> 01:02:55,360
So that's what we're going to try. So.

495
01:02:55,840 --> 01:03:08,960
So. So when you when is it impossible to simulate directly from the inverse transform of CDF or using box mirror transformation?

496
01:03:09,170 --> 01:03:12,830
You need a general way to do it. Okay. So.

497
01:03:16,210 --> 01:03:22,690
So what we want to do is you only have the probability density function.

498
01:03:22,690 --> 01:03:28,570
Usually probabilities function is a much easier to calculate, see therefore is not always easy to calculate.

499
01:03:28,690 --> 01:03:33,249
Right? So let's say I only know the shape of the probabilities function.

500
01:03:33,250 --> 01:03:37,450
I don't even need to know the normalization factor that may be complicated to calculate.

501
01:03:37,450 --> 01:03:46,660
So I just need to know, you know, without without this normalization factor how those a pdf looks like.

502
01:03:46,870 --> 01:03:53,820
And what I want to do is to generate a random variable that that follows that the pdf right.

503
01:03:53,830 --> 01:04:05,500
So that's what we want to do. So, so f is the target is so here what we are seeing is F is a PDF the function.

504
01:04:05,770 --> 01:04:13,209
But sometimes the normalization is is hard.

505
01:04:13,210 --> 01:04:18,490
So you can use you can get rid of numerous and vectors and make make the functionality simpler.

506
01:04:18,940 --> 01:04:25,000
That could be the working density. Or if we need some approximation, we can use even simpler form of a G.

507
01:04:25,510 --> 01:04:28,630
So that's the setting we are. We're going to talk about that.

508
01:04:30,160 --> 01:04:37,660
So let's say F of X is a PDF and target density.

509
01:04:38,560 --> 01:04:43,870
Then we can write a very silly equation like this.

510
01:04:45,070 --> 01:04:51,130
Okay, so f of x is integration of zero to f of x, okay.

511
01:04:51,590 --> 01:04:54,610
Of of just one.

512
01:04:54,850 --> 01:05:05,020
Right. So you can write that way. Okay. So, but so what does this mean in terms of random variable?

513
01:05:06,500 --> 01:05:11,630
If so, I wrote as you just to be to be explicit.

514
01:05:11,950 --> 01:05:16,410
Okay. So, uh, you know.

515
01:05:39,290 --> 01:05:54,900
Mm. So, uh.

516
01:05:57,540 --> 01:06:07,230
So what? What I want to do is simulating a value of X that is that follows this pdf.

517
01:06:07,510 --> 01:06:11,010
Right. So.

518
01:06:15,150 --> 01:06:23,400
Then what you want to do is that we want to use a random number to help doing this kind of simulation.

519
01:06:23,560 --> 01:06:30,990
Right. So when you do that, what you can do is that.

520
01:06:36,510 --> 01:06:49,850
So. Mm. So.

521
01:06:56,960 --> 01:07:00,690
Mm. So how do I explain this?

522
01:07:00,730 --> 01:07:05,340
Okay, so. So this is very silly.

523
01:07:05,340 --> 01:07:15,810
Silly creation. So basically, what what you want to do is that because you you have you have you want the of f of x, right?

524
01:07:16,530 --> 01:07:20,939
So you want to simulate from this, but F of x,

525
01:07:20,940 --> 01:07:31,890
you can write these as introduce some some additional random variable and additional value variable you and try to.

526
01:07:35,100 --> 01:07:40,590
Trying to say that I'm going to just.

527
01:07:44,020 --> 01:08:03,640
Oh, actually. Yeah. So. So.

528
01:08:05,020 --> 01:08:08,560
Yeah, why don't you.

529
01:08:08,920 --> 01:08:14,229
So so basically this was I think this is easier to look at the look at the example.

530
01:08:14,230 --> 01:08:19,510
So let me let me try that way. So, uh.

531
01:08:23,670 --> 01:08:31,710
So basically what what this is trying to do is that we're trying to simulate a pair of X and Y.

532
01:08:33,150 --> 01:08:41,380
So instead of simulating the simulating from some value that follows that this distribution of X is hard.

533
01:08:41,970 --> 01:08:51,300
So what we are trying to do is that instead of simulating X, I'm going to simulate the U and use the value of F of x.

534
01:08:51,360 --> 01:09:02,910
So that's what this is coming from. So, so, you know, let's say, you know, the shape of X looks like this.

535
01:09:03,480 --> 01:09:11,370
I know the shape of f of x looks like this, but I don't know how to sample simple value.

536
01:09:11,490 --> 01:09:17,340
It follows this distribution saying, okay, then how do you do it?

537
01:09:17,640 --> 01:09:23,610
Okay. So I say I know that x x is a range from this and these to just to make make it easier.

538
01:09:24,180 --> 01:09:28,530
Okay. Then what this is trying to do is that.

539
01:09:28,530 --> 01:09:32,300
Oh. Let's simulate.

540
01:09:32,540 --> 01:09:44,330
So if f vaccines are here, let's say I know that these days, then what you can do is at home, you know, let's simulate a lot of values here, okay?

541
01:09:45,020 --> 01:09:57,800
Simulate a lot of values. And I'm going to take the value where my rent this simulated value u is less than F of x.

542
01:09:58,010 --> 01:10:01,730
So this part, these are proportional to the.

543
01:10:02,720 --> 01:10:12,380
So if I take a random variable that is only below here, they should follow F of X that that's the that's basically the principle.

544
01:10:12,560 --> 01:10:21,680
Okay. So if x x becomes small like this and if I select random variable from this larger range,

545
01:10:21,680 --> 01:10:29,960
but if I only take the random variable that are where F of x of this u is the smaller than F of x,

546
01:10:30,320 --> 01:10:35,690
then you're going to, you know, the issue followed of well, wait.

547
01:10:38,690 --> 01:10:42,110
With the distribution that we're intending because this has a law.

548
01:10:42,680 --> 01:10:50,960
So you you take the of random variable from here, but you don't take the value that is above this threshold.

549
01:10:51,500 --> 01:10:56,480
Then the remaining random remaining value here should follow.

550
01:10:56,750 --> 01:11:04,220
Well, with the distribution of F of X, that's that's what this fundamental theorem of the simulation is trying to say.

551
01:11:04,490 --> 01:11:16,490
Okay, so, so, so we're trying to simulate this because said X and W to get a two dimensional setting is explained like this.

552
01:11:17,300 --> 01:11:20,930
Okay. So this is this example I wanted to start first.

553
01:11:21,250 --> 01:11:29,490
Okay. So, so now let's think about the problem a little bit easily.

554
01:11:29,540 --> 01:11:33,260
So you have A and B, so let's say you have a support.

555
01:11:34,720 --> 01:11:39,740
Uh, what is this? Okay, it's a yeah.

556
01:11:40,370 --> 01:11:43,460
So it it has a domain.

557
01:11:43,850 --> 01:11:56,020
Okay, well, I mean, okay, so. So F of X is defined from the A, from A and B and F, let's assume that F of F of X is less than.

558
01:11:56,030 --> 01:11:59,210
And so this is the easier problem. Okay.

559
01:11:59,930 --> 01:12:02,930
So let's try to start from each problem.

560
01:12:03,200 --> 01:12:13,639
Okay. So I'm going to say that F of X is combining the A and B in terms of X value Y, you value the Y.

561
01:12:13,640 --> 01:12:19,700
I know that F of X cannot cannot be greater than is the maximum.

562
01:12:19,910 --> 01:12:26,450
And then now you have these rectangular, rectangular shape.

563
01:12:26,830 --> 01:12:45,470
Right. So then what we're going to do here is that we're going to we're going to simulate the value y.

564
01:12:45,710 --> 01:12:50,330
So why is a value that is between A and B?

565
01:12:50,900 --> 01:13:04,000
Okay. And we're going to simulate the U, a from zero to so that each value Y and you will will have the range between the A and B and during that.

566
01:13:04,340 --> 01:13:13,610
Okay. And what we want to do here is that we want to simulate from 13 so arbitrary of F, of f, of x.

567
01:13:13,610 --> 01:13:17,540
So let's say, you know, let's, let's say F of X looks like this.

568
01:13:17,960 --> 01:13:28,280
Okay. Okay. Then what this is trying to say is that so then probability of.

569
01:13:28,490 --> 01:13:39,650
So let's, let's, let's think about this. Calculating the CDF probability of x is less than less than a specific value of x is.

570
01:13:39,920 --> 01:13:42,980
So how do I calculate this value? Okay.

571
01:13:43,820 --> 01:13:51,410
So then the CDF is basically you're just trying to appropriate this area below this part, right?

572
01:13:51,410 --> 01:13:55,820
So if this is a particular of values X, so this is what you want to calculate.

573
01:13:56,810 --> 01:14:04,000
How, how do I do it. Well, you can, you can you can represent this.

574
01:14:04,130 --> 01:14:12,410
This is a probability that the Y is with this random sample, the y value should be less than X.

575
01:14:12,650 --> 01:14:21,080
Okay. And but the conditions on the the your your u value is less than F of X.

576
01:14:21,080 --> 01:14:25,460
So what it does is that I want to take.

577
01:14:27,350 --> 01:14:42,210
So these are these are two. So if I take take the values among here, if I take the value that is below this.

578
01:14:42,420 --> 01:14:49,590
So this is this is a full F of X, right? Among among these among among these values.

579
01:14:50,070 --> 01:14:57,330
If I take the one that is y so conditioning on this, if I take the probability that Y is less than X,

580
01:14:57,810 --> 01:15:05,270
that'll give me a probability that the the X is a less than x because this is a relative probability issue.

581
01:15:05,380 --> 01:15:10,980
This is these two areas correspond to the probability of one because you're conditioned on it.

582
01:15:11,730 --> 01:15:15,890
And after that, we are controlling this probability.

583
01:15:15,900 --> 01:15:22,650
So this this is the way you can calculate it. And this is equivalent to culturing the this area eventually.

584
01:15:24,990 --> 01:15:28,490
So. So then why why does it matter?

585
01:15:28,530 --> 01:15:39,060
Because now you can you can say that this is the so you can say that this is the this is the exact formula.

586
01:15:39,390 --> 01:15:44,100
But now think about the random sample. So let's say you have a lot of random samples here.

587
01:15:44,500 --> 01:15:52,260
Okay. Then you can replace this problem by counting the number of points.

588
01:15:52,380 --> 01:15:56,370
So you have you have so many uniformly distributed random sample.

589
01:15:57,000 --> 01:16:02,490
Now, what I want to do is you put if you want to count this CDF here.

590
01:16:02,700 --> 01:16:10,710
So this probability, what I can do is I want to count the total count is this is all value here.

591
01:16:11,070 --> 01:16:16,170
This is a put out put on count below the curve. And among them I'm going to count the value.

592
01:16:16,620 --> 01:16:27,210
That is where the Y value is less than x and that'll that'll give my give the probably the probability that F of X is less than x.

593
01:16:27,450 --> 01:16:41,430
So in other words, if you constrain all the values, so to to be what to do, if you select a you then use the less than f of x,

594
01:16:42,360 --> 01:16:56,790
then this will give you a property that is selected, selected well below the curve will be will be distributed by F of X.

595
01:16:57,420 --> 01:17:01,530
Okay. I don't know if that makes sense for you and I should do.

596
01:17:01,830 --> 01:17:05,040
I'll probably be it is a little bit further.

597
01:17:06,120 --> 01:17:10,770
But let me let me go through the examples so that we can at least understand.

598
01:17:11,430 --> 01:17:16,560
Okay. Okay. So this is the example I wanted to try.

599
01:17:16,860 --> 01:17:17,190
Okay.

600
01:17:17,850 --> 01:17:30,200
So, uh, so one, one easy function we can try is a beta distribution because a beta distribution is a is concentrated in one and beta distribution.

601
01:17:30,230 --> 01:17:36,209
Also, you can easily figure out where the maximum occurs. So this is the maximum value you can constrain.

602
01:17:36,210 --> 01:17:39,060
So you have some path like condition here. Okay.

603
01:17:40,650 --> 01:17:54,390
So then what I'm trying I'm going to try to do is that I'm going to I'm going to try to generate a random variable U and Y within this,

604
01:17:54,690 --> 01:18:02,130
uh, within this box. So Y is a between zero and one and U is between zero and is a maximum value.

605
01:18:02,490 --> 01:18:10,530
Okay. And so the empty is just a maximum value, maximum density that F of X can take.

606
01:18:10,920 --> 01:18:21,870
Okay. So you're just trying to random sample the value, then what am I doing is that I'm only selecting the value that is less than.

607
01:18:22,170 --> 01:18:28,709
So when the u value, when I sell it to you value I want to select the u value is less than F of X.

608
01:18:28,710 --> 01:18:32,490
In this case, F of x is a beta of density.

609
01:18:32,490 --> 01:18:35,630
So I give a data here. Okay.

610
01:18:36,780 --> 01:18:49,140
And if you simple. If you draw the random sample in this way, then what you can show is.

611
01:18:51,300 --> 01:18:55,680
I can show here. Is that all? Then.

612
01:18:57,690 --> 01:19:00,380
What am I returning? Is that the why and you value?

613
01:19:00,390 --> 01:19:07,560
But also I want I keep the index value, which is a which is a very random example that is below this curve.

614
01:19:08,100 --> 01:19:15,179
Okay. And all is basically how many of the samples are below this curve.

615
01:19:15,180 --> 01:19:23,300
But this is the acceptance ratio. Okay. So this this value that is below the 56% of them was below the curve.

616
01:19:23,820 --> 01:19:30,479
And I have 1127 the random sample that is below the curve.

617
01:19:30,480 --> 01:19:39,800
So that's that's what it is. And it's a much easier if I if you describe these in these are a plus.

618
01:19:39,820 --> 01:19:45,600
So what I did is that this is the rent, this is the beta density, this is the maximum value.

619
01:19:45,600 --> 01:19:51,030
So I'm sampling random very random variables, random points from this two dimensional plot.

620
01:19:51,630 --> 01:19:56,850
And what I want to do is I count only this value below this curve.

621
01:19:57,270 --> 01:19:58,889
And I don't have time today.

622
01:19:58,890 --> 01:20:09,120
But what I want to argue is that what I wanted to show here is that this if this read point follows the beta distribution.

623
01:20:09,660 --> 01:20:13,200
Okay. So that's that's what I want you to explain.

624
01:20:13,220 --> 01:20:18,030
I will explain again in the next lecture, because this is important.

625
01:20:20,230 --> 01:20:27,150
Okay. So any any questions that we will have out of this hour directly after this?

626
01:20:27,160 --> 01:20:31,290
So if you have more questions, feel free to come by. Okay.

