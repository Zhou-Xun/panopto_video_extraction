1
00:00:02,460 --> 00:00:09,810
As I said, I'll do a review in the second half, but let's.

2
00:00:13,780 --> 00:00:21,280
Pick up from where we left them and talking about residual model diagnostics.

3
00:00:22,120 --> 00:00:29,350
And I know you had an AP exam, so I think a few of you were not there.

4
00:00:29,440 --> 00:00:40,420
But please make sure you kind of go over the lecture recording and the slides in a far more delicate deal.

5
00:00:41,590 --> 00:00:56,440
Slide 15 And I think the last thing we talked about was basically the we've talked about various versions

6
00:00:56,440 --> 00:01:03,909
of residual stocking from conventional procedures to standardize them to internally digested wells.

7
00:01:03,910 --> 00:01:08,740
And then finally, the last one we talked about was the externally digested dual.

8
00:01:09,340 --> 00:01:16,360
And in closing, I had mentioned that basically the externally standardized residual.

9
00:01:17,860 --> 00:01:29,139
The idea is I'm just going to, you know, sort of add my closing remarks here because I know some people had to leave,

10
00:01:29,140 --> 00:01:36,160
but we don't leave because of the exam. You probably heard this, but they're going to hear you one more time.

11
00:01:37,450 --> 00:01:46,090
So the whole rationale about externally sort of data secured was that node that

12
00:01:46,270 --> 00:01:53,589
the the standardization is correct for the internal standardized version as well,

13
00:01:53,590 --> 00:01:57,940
because now in the denominator, we have the correct variance.

14
00:01:58,850 --> 00:02:14,140
But the idea is that this Sigma hat is going to be influenced by the observations that have large residual.

15
00:02:14,170 --> 00:02:27,850
So in other words, if the epsilon are impact or if the residual itself is large for a certain observation, then it will matter.

16
00:02:28,120 --> 00:02:36,910
It will influence in the estimation of sigma hat squared and see perhaps when they overestimate the true variance.

17
00:02:37,300 --> 00:02:49,540
So in other words, a large residual would tend to mask its own out blindness by inflating the sigma squared.

18
00:02:49,870 --> 00:03:06,280
So the idea is, why don't we get a more kind of honest testimony today by removing the influence of Epsilon I had and on that we Moorhead squared.

19
00:03:06,460 --> 00:03:09,970
And how do we remove that? Basically we remove that data point.

20
00:03:10,300 --> 00:03:18,220
So it's a it's so the idea is that you actually delete one observation at the time and you repeat the model.

21
00:03:20,120 --> 00:03:29,440
So if the sample size is and you basically are fitting and regression because each time you are deleting one data point and

22
00:03:30,340 --> 00:03:44,050
the denominator in that are happier subscript minus r means that calculate the residual based on the 8.8 observation remove.

23
00:03:44,470 --> 00:04:01,209
So in the denominator you have an estimate of the true standard deviation estimated of Sigma Sigma based on removing the IIB data point.

24
00:04:01,210 --> 00:04:06,670
And basically if you look at stare at this, you know,

25
00:04:06,670 --> 00:04:14,350
implicitly what we are doing is we are fitting in the regressions by leaving one observation out at a time.

26
00:04:14,380 --> 00:04:22,480
This is also that's why I refer to as leave one out or delete one residual or jackknife residual.

27
00:04:23,770 --> 00:04:34,030
And as the name suggests, you are actually implicitly putting in regressions to estimate that Sigma hat without the eye observation.

28
00:04:34,880 --> 00:04:44,200
There's a computational trick to avoid fitting the regression end times to get these MN values like Sigma ahead without the FA Sigma hat,

29
00:04:44,200 --> 00:04:47,909
without the second sigma without the third. This kind of observations.

30
00:04:47,910 --> 00:04:53,080
But now there is also a fourth outcome formula for calculating this,

31
00:04:53,650 --> 00:05:02,050
which is in the there's a formula in your book that that gives you a shortcut for calculating this.

32
00:05:03,010 --> 00:05:08,770
But in this, again, in this day and age of computing, this is hardly an issue.

33
00:05:10,060 --> 00:05:16,390
So this version of the residual. Is the most sensitive for detecting outliers.

34
00:05:17,290 --> 00:05:20,680
And once again, in terms of, you know,

35
00:05:21,040 --> 00:05:34,989
this has mean zero variance is roughly equal to one and then approximately has a distribution with degree of freedom equal to the SC minus one.

36
00:05:34,990 --> 00:05:39,910
Because remember, instead of fitting in data points, we are fitting in minus one data point.

37
00:05:39,910 --> 00:05:48,850
So if you've done so as as a so this did that I mentioned that this is also referred to as the leave one out and jackknife residual.

38
00:05:48,850 --> 00:06:01,360
So basically this is in summary what we had kind of finished or wrapped up our discussion on last Thursday was

39
00:06:01,360 --> 00:06:09,309
that so we have these different versions of the residuals and when comparing across these residual guides,

40
00:06:09,310 --> 00:06:18,970
the good news is for large samples it hardly matters which version we use because the data provide very similar information.

41
00:06:19,240 --> 00:06:26,290
Also for not samples, it's not the standardized that we did, at least does is extremely standardized.

42
00:06:26,320 --> 00:06:30,790
All these residuals follow approximately a normal distribution.

43
00:06:31,150 --> 00:06:38,740
And what's the advantage? Because I would say that you can calibrate using no cutoff, so that that's why they you know,

44
00:06:38,890 --> 00:06:46,360
oftentimes you just say, okay, is it bigger than plus minus two or outside that is plus minus two.

45
00:06:46,360 --> 00:06:54,910
And then plus minus from the 1.96 of a proof of the 98% data for a normal distribution.

46
00:06:55,240 --> 00:06:59,590
So it's basically getting to that ultimate outcome. So that's the good news.

47
00:06:59,740 --> 00:07:05,350
It doesn't really matter which version we use for large samples,

48
00:07:05,470 --> 00:07:17,720
but for smaller than that moderate sample some third and in decreasing order of sensitivity is so this are had without the E&P observation

49
00:07:17,750 --> 00:07:26,230
so the delete one residual or leave one out or the externalizing data to do it is going to be the most sensitive to detecting outliers.

50
00:07:26,410 --> 00:07:40,600
It's more sensitive because remember, you have taken out the in back of the of the residuals on Sigma hat and and you have you

51
00:07:40,600 --> 00:07:48,370
have kind of separated out the effect of a large residual masking its own outlying mass.

52
00:07:49,300 --> 00:08:01,330
So this is going to be the most sensitive and the least sensitive is going to be the crude or the conventional residual.

53
00:08:03,580 --> 00:08:09,100
Okay. So this is where we ended on Thursday.

54
00:08:11,110 --> 00:08:14,470
So kind of talking about different residual types.

55
00:08:15,070 --> 00:08:26,229
So the next basically the next topic that we are going to be going to is how do we check the function form of continuous predictor.

56
00:08:26,230 --> 00:08:36,580
So like how do we check the linearity assumption of, you know, in our linear regression model?

57
00:08:37,210 --> 00:08:49,210
So remember the line assumptions. This is why where we started with and we are going to take each at a time and try to sort of

58
00:08:50,950 --> 00:08:59,190
talk about how do we assess the validity of each of those and any linearity independence,

59
00:08:59,200 --> 00:09:06,249
longevity on standby to those for how are we going to check those assumptions

60
00:09:06,250 --> 00:09:12,760
using these different kinds of residuals using diagnostics based on residuals.

61
00:09:13,030 --> 00:09:23,920
So that's why we talked about the types of residuals. First, because these residuals form the building blocks of our model check.

62
00:09:24,370 --> 00:09:30,730
Okay. Or assessing the adequacy or the validity of the assumptions.

63
00:09:31,180 --> 00:09:35,890
So the first one that we're going to talk about is the linearity assumption now.

64
00:09:39,580 --> 00:09:52,410
So the the sort of the important aspect is the functional form of of the continuous predictor that we are trying to model.

65
00:09:52,420 --> 00:10:01,479
We do we have the right functional form and want to do is go with me have nonlinear function form of legs you

66
00:10:01,480 --> 00:10:11,980
know sort of in in terms of the relationship with the outcome for example is BP versus edge and here I'm sort of.

67
00:10:12,930 --> 00:10:20,010
In the I have been talking with ex's being wanting this again.

68
00:10:23,160 --> 00:10:29,430
So I'm basically letting the truth be told in editing modules, something like this.

69
00:10:29,430 --> 00:10:42,190
So here is my Y and here is my x and the true model is something like this.

70
00:10:42,210 --> 00:10:47,370
I'm just going to make it up. So let's see.

71
00:10:47,370 --> 00:10:53,730
This is the functional form or the relationship between x and Y.

72
00:10:56,060 --> 00:11:00,140
And this may or may not be linear.

73
00:11:10,940 --> 00:11:20,540
Soon afterwards I had y equals to be a node plus some function of x plus epsilon.

74
00:11:23,740 --> 00:11:27,400
And these effects may be or may not be linear.

75
00:11:27,550 --> 00:11:31,240
So this is the this is the function I'm talking about.

76
00:11:33,340 --> 00:11:45,790
And the fitted model, if you like, you know, in our and MLA SLR, the, the model that we are creating is.

77
00:11:49,150 --> 00:11:56,230
Assuming the line right as you mean the line resumption so the linearity.

78
00:11:56,890 --> 00:12:05,379
So basically it assumes that the functional form effects is something like veto on time.

79
00:12:05,380 --> 00:12:09,310
So so I'm just making it up like a simple linear regression scenario.

80
00:12:09,490 --> 00:12:15,400
So, so the typical assumption that we make is that if is linear.

81
00:12:25,320 --> 00:12:36,040
Is that? If you saw in this first segment,

82
00:12:36,040 --> 00:12:44,589
what we are going to talk about is how do we assess the validity of this assumption

83
00:12:44,590 --> 00:12:55,520
that it is linear and written without knowing what the true they are doing,

84
00:12:55,660 --> 00:12:58,600
what it is, whether it's something like that,

85
00:12:59,920 --> 00:13:12,700
and how do we use our data at hand to assess the adequacy of that linear, functional relationship assumption?

86
00:13:13,270 --> 00:13:20,770
So there are several approaches to check now. The first one is through what is called partial regression plots.

87
00:13:23,830 --> 00:13:29,860
The second one is about categorizing predators. And then the third one that we are not talking about.

88
00:13:30,100 --> 00:13:43,209
Now we have the first two approaches now, and the third one is using, you know, moving up to next lines, testing and smoothing approaches.

89
00:13:43,210 --> 00:13:50,320
And that is something that we hopefully will get to, but at least we are not going to talk about enough.

90
00:13:50,980 --> 00:13:55,000
So let's talk about the partial regression plots first.

91
00:13:56,080 --> 00:14:04,810
So here is the context in simple linear regression as well as in multiple linear regression.

92
00:14:05,950 --> 00:14:11,270
We use, as I said, different versions of this.

93
00:14:11,290 --> 00:14:23,710
It was most of the times the residual diagnostics. We can use the rules of the conventional version, and we use blocks like residual versus obedience.

94
00:14:25,270 --> 00:14:29,740
And this is very standard in regression diagnostics.

95
00:14:30,130 --> 00:14:37,240
So the idea is this in simple linear regression, because there is only one pool, we need only one x.

96
00:14:38,800 --> 00:14:44,020
So the only inference that you get is, I mean,

97
00:14:44,020 --> 00:14:52,090
the marginal inference and the foundational inference are the same because there is only one value in multiple linear regression.

98
00:14:53,020 --> 00:14:56,470
We are actually talking about conditional association, right?

99
00:14:56,800 --> 00:15:12,280
Like given everything else being fixed, what is the impact of x one on y adjusting for its 2x3 XP effect of x one moment on y?

100
00:15:12,310 --> 00:15:21,370
So it's it's conditional association. So in simple linear regression, because there is only one possibility,

101
00:15:21,390 --> 00:15:33,190
you can simply plot the residual epsilon at the raw on conventional residuals versus X versus the whole video or even Y that we will actually

102
00:15:33,190 --> 00:15:44,260
talk specifically about the diagnostic plot of residuals versus predicted Value Epsilon had versus Y you had in a different context later on.

103
00:15:44,530 --> 00:15:48,910
Now, when checking for the constant variance assumption, but for now,

104
00:15:49,390 --> 00:15:55,240
let's talk about plotting the residuals versus X to assess the linearity of the X Y relationship.

105
00:15:55,930 --> 00:16:02,890
And the idea is this like a plot of Epsilon had versus X and is going to draw here.

106
00:16:03,250 --> 00:16:12,610
So epsilon the had to X here and a note the residuals have mean zero.

107
00:16:13,510 --> 00:16:17,380
So a plot of epsilon head versus X.

108
00:16:18,100 --> 00:16:29,110
If the linear functional form indeed holds, then this plot would look something like a very kind of random background.

109
00:16:29,110 --> 00:16:32,180
So you actually will not see any patterns of.

110
00:16:33,010 --> 00:16:42,280
If you step away from this plot, it will look like a football field or a kind of a beyond a good football.

111
00:16:42,280 --> 00:16:55,840
So basically there will be no background. And if the current functional form has indeed captured the effect of pix,

112
00:16:56,530 --> 00:17:03,189
then you should see a plot like this that is to do with would be randomly scatter.

113
00:17:03,190 --> 00:17:07,180
Then there's no trend, no pattern with respect to X.

114
00:17:07,570 --> 00:17:21,670
If on the other hand, you see I'm going to draw a here, here is Epsilon head, here is let's say X and you see a pattern like this.

115
00:17:31,980 --> 00:17:41,530
Then this back in the residuals with respect to X is telling us that the linear functional form is in satisfied.

116
00:17:41,550 --> 00:17:54,240
There is there is some some additional factor in the residuals that the that the model was unable to kind of capture.

117
00:17:54,880 --> 00:18:04,140
So maybe what we did see when we did the departure from linearity, the nature of the nonlinear relationship in this case here,

118
00:18:04,140 --> 00:18:10,770
like a quadratic relationship, can actually tell you like what extra time to model.

119
00:18:12,600 --> 00:18:19,290
So that's the good news in simple linear regression model that we can actually plot the residuals

120
00:18:19,290 --> 00:18:28,470
versus X and you can detect a departure from linearity or even a linearity as often has been mapped.

121
00:18:29,160 --> 00:18:33,959
However, things get complicated in multiple linear regression.

122
00:18:33,960 --> 00:18:42,390
MILLER Why? Why does it get complicated? Because remember now I have multiple covariance, correct?

123
00:18:42,780 --> 00:18:52,410
So the plot of the residuals versus the X can be impacted by other covariance.

124
00:18:52,560 --> 00:19:00,510
So let's say I have IDs, BMI, income, just making it up.

125
00:19:01,710 --> 00:19:05,310
And the outcome is, as with the food,

126
00:19:05,440 --> 00:19:19,469
the residuals from that model versus if you plot against it will be impacted by BMI and income will be impacted by other covidiot.

127
00:19:19,470 --> 00:19:31,380
So and especially if the if some of the poor idiots are then sells for related, let's say income education,

128
00:19:32,730 --> 00:19:44,309
then if there is a non linear association between one covidiot and why the plot of the residuals

129
00:19:44,310 --> 00:19:53,400
versus another covariate will reflect the Nonlinear Association of Y with the income.

130
00:19:54,300 --> 00:19:59,700
So talking about the income indication, if I'm just again, this is a hypothetical situation.

131
00:19:59,700 --> 00:20:09,450
If income has a nonlinear association with systolic blood pressure and income indication are motivated,

132
00:20:09,990 --> 00:20:17,549
then the plot of the residuals versus income we versus education will reflect the

133
00:20:17,550 --> 00:20:24,070
nonlinear association between income and SBP because income and education are formulated.

134
00:20:24,570 --> 00:20:30,270
So so that the thing is that things become complicated in the MLA situation because now we are dealing

135
00:20:30,270 --> 00:20:36,840
with multiple for various and there may be non-linear association between Y and some of the covariant.

136
00:20:37,290 --> 00:20:41,970
Additionally, some of the opioids themselves might be correlated,

137
00:20:42,270 --> 00:20:48,480
so it's no longer going to be a simple diagnostic plot like the residuals versus our predictor.

138
00:20:49,710 --> 00:20:52,890
So what do we do in this situation?

139
00:20:53,190 --> 00:20:56,490
So the solution here is partial regression plots.

140
00:20:57,000 --> 00:21:00,180
What are partial regression plots? So here is the idea.

141
00:21:00,180 --> 00:21:03,480
It's a very simple idea, but it's all simple ideas.

142
00:21:04,680 --> 00:21:08,430
All all the all clever ideas are inherently simple.

143
00:21:08,430 --> 00:21:12,780
And here is another example, like a very simple idea, but it's a very clever idea.

144
00:21:13,260 --> 00:21:21,090
So think about the design matrix. We have the column of ones and then we had x1x to experience p p predictors.

145
00:21:22,500 --> 00:21:38,250
Now think about x subscript minus P as the part of the design matrix that includes all the cool baby IDs except x key.

146
00:21:39,180 --> 00:21:43,050
So I'm knocking off the column corresponding to key.

147
00:21:45,410 --> 00:21:51,010
So that is why you know the matrix x subscript minus g.

148
00:21:52,970 --> 00:22:01,430
So everything everyone signed did that. I have AIDS, BMI, income, education, and let's say income is inscape.

149
00:22:02,090 --> 00:22:10,190
Then the design matrix is everything else except the column corresponding to the data for the.

150
00:22:12,730 --> 00:22:15,850
It doesn't matter which one.

151
00:22:16,690 --> 00:22:19,930
It doesn't matter. I think we are going to bleed for everyone. So.

152
00:22:20,280 --> 00:22:23,710
So, just for now, fix one more video. Okay.

153
00:22:24,790 --> 00:22:37,180
So that's my x minus key. Now, what I do is I will regress Y on X minus key and get the residual from that model.

154
00:22:37,210 --> 00:22:45,760
So I call it Epsilon Head from a regression of Y given X minus scale.

155
00:22:46,390 --> 00:22:51,160
So regression of Y with respect to age, BMI and education.

156
00:22:51,160 --> 00:22:57,730
Let's and we are going to do this with an example. So that's my first model and the residuals.

157
00:22:58,330 --> 00:23:09,790
Then what do I do is I did this excuse all the rest of the comedy, and so I did this income on age, BMI, education,

158
00:23:10,750 --> 00:23:24,960
and I fit that model and get the residual Epsilon hack from a regression model of X squared with respect to everything else other than its game.

159
00:23:25,900 --> 00:23:32,410
Now note that this second regression here, basically this does not have any interpretation.

160
00:23:32,410 --> 00:23:35,320
Don't try to interpret the coefficients from this model.

161
00:23:35,740 --> 00:23:52,960
It's mechanistically a trick that I am doing to sort of pick out the in back of of or sort of like a covariate that does the residuals.

162
00:23:53,980 --> 00:24:01,240
Okay. So now I have two sets of residuals and I plot those two sets of residuals.

163
00:24:03,430 --> 00:24:10,430
Okay. So the residual from the first model is that's the goal of Y on everything else other than exit.

164
00:24:10,450 --> 00:24:18,850
And the residual from the second model is the residuals of from the model of 60 on everything else other than expected.

165
00:24:19,330 --> 00:24:23,200
And I plot these two sets of residuals. So what is what is going on here?

166
00:24:23,530 --> 00:24:30,130
First, let's see what these residuals correspond to. So both sets of residuals are probably dead dusted.

167
00:24:33,290 --> 00:24:44,090
Right. They're adjusted for everything else other than him then and then escape and saw.

168
00:24:44,420 --> 00:24:56,360
These two sets of residuals have removed the contribution from the other audience from age BMI indication.

169
00:24:57,650 --> 00:25:04,100
And if the plot of these two sets of procedurals looks linear,

170
00:25:04,670 --> 00:25:11,920
then basically it's saying that the adjusted effect of it, then it basically showing the adjusted effect of it.

171
00:25:12,710 --> 00:25:19,280
If that plot is non-linear, then it would suggest like a functional form of that.

172
00:25:19,280 --> 00:25:22,879
This would line up to either a Square Enix view.

173
00:25:22,880 --> 00:25:29,150
I need to add a few minutes. Do I need to meet some kind of transformation in its game?

174
00:25:29,450 --> 00:25:34,640
So you you you like what you see is what you have got of.

175
00:25:36,950 --> 00:25:49,250
And this book can also help to spot outliers or extreme situations in the Y direction as well as extreme points in the X direction.

176
00:25:50,510 --> 00:25:59,270
Okay, so both outliers and what are called high level endpoints, but we will talk about high leverage points, this name later on.

177
00:25:59,900 --> 00:26:07,430
But think about it this way. These are points that are have extreme residuals both in the X as well as in the Y direction.

178
00:26:08,300 --> 00:26:13,220
So what am I what what do I mean by what do what do you see what you have?

179
00:26:13,670 --> 00:26:26,780
So if that if you plot the two sets of residuals and if you get a model, if you get a plot like this or this and remember,

180
00:26:26,780 --> 00:26:32,509
both sets of procedurals are now for video that does if you get these kind of plots,

181
00:26:32,510 --> 00:26:39,200
basically what we what do what we are seeing is that I'm fine in terms of the linearity assumption.

182
00:26:39,200 --> 00:26:53,120
So if the plot of these two sets of residuals show a linear trend, then then the line assumption holds in the MLR model.

183
00:26:53,390 --> 00:27:03,650
If, on the other hand, once again, you you see something like, you know, I'm guessing and making it up like a plot like this,

184
00:27:04,220 --> 00:27:15,440
then basically what it's saying is that there is some other property among the set of X minus B,

185
00:27:15,740 --> 00:27:21,160
which is all related, strongly correlated with income with skin.

186
00:27:21,710 --> 00:27:26,810
And you have to somehow take account of that.

187
00:27:26,810 --> 00:27:31,150
And there's a there's a there's a functional form that's getting affected.

188
00:27:31,790 --> 00:27:40,730
Okay. So that's and that's a partial regression plot.

189
00:27:41,270 --> 00:27:45,290
Now here is an example.

190
00:27:47,270 --> 00:27:51,319
Suppose we want to study the association between systolic blood pressure and already

191
00:27:51,320 --> 00:27:58,670
it's age quetelet index and smoking from a similar to a problem that we worked on.

192
00:28:01,040 --> 00:28:11,390
So SBP is better not plus beta eight times eight plus beta q times with little next plus beta ezetimibe smoking plus up to the night.

193
00:28:12,020 --> 00:28:15,920
And we want to assess the functional relationship between SBP and H.

194
00:28:16,730 --> 00:28:29,450
So the first model that I would fit is that SBP is a function of a, you know, remember, this is the one that I'm trying to assess now and as,

195
00:28:29,480 --> 00:28:37,490
as, as I mentioned, that, you know, you can do this for every controversy correlating the models right now.

196
00:28:37,520 --> 00:28:40,610
Let's look at the functional relationship between SBP and age.

197
00:28:41,120 --> 00:28:48,830
So what is the force model that you are going to fit? Remember, how are you going to create the x minus the design matrix?

198
00:28:49,190 --> 00:28:56,390
So you will have with light index and smoking and you are living it out.

199
00:28:56,780 --> 00:29:01,430
So the fourth model is SBP as a function of Quetelet index and smoking.

200
00:29:01,790 --> 00:29:11,269
And the residuals that you get out of this model are essentially epsilon I had from

201
00:29:11,270 --> 00:29:15,770
a model regression of is we be required to work with living lives and smoking.

202
00:29:15,770 --> 00:29:20,930
So this is the first set of residuals you are excuse it.

203
00:29:21,230 --> 00:29:32,270
So now you're going to fill the second model age as a function of quetelet index and smoking and you are going to get the residuals out of this.

204
00:29:32,390 --> 00:29:39,410
Model. This is a feeling I had from a model of it on Quetelet index as walking.

205
00:29:39,410 --> 00:29:48,440
And the main one that I want to make here is don't think this model, the second model does not have any interpretation.

206
00:29:48,440 --> 00:29:54,740
Don't try to interpret this model. So don't interpret.

207
00:30:02,770 --> 00:30:10,870
Then and now you basically plot these two sets of procedures.

208
00:30:11,650 --> 00:30:20,050
And as I mentioned, the background in the plot, you describe the association between agent as quickly adjusting for living the accent and smoking.

209
00:30:20,680 --> 00:30:25,120
One thing in the background reviews what the regression model is seeing.

210
00:30:27,370 --> 00:30:32,980
Does the adjusted association for Background reveals?

211
00:30:37,700 --> 00:30:41,060
What? The regression.

212
00:30:44,990 --> 00:30:55,830
Morbi is seen. And in other words, they were saying what you see is what you have in terms of that, just in association.

213
00:30:56,190 --> 00:31:13,950
So but so if you have a plot like this that Ceylan had from, is BP the function of skewness versus epsilon?

214
00:31:17,290 --> 00:31:32,020
It is a functional team and is so these are the two sets of procedural to a party and if the plot looks like this.

215
00:31:35,740 --> 00:31:42,400
Then basically we're saying that the functional relationship with respect to age is linear.

216
00:31:43,300 --> 00:31:46,830
So excuse our age for the.

217
00:31:56,120 --> 00:32:02,670
So it's good or it's. Near.

218
00:32:07,230 --> 00:32:19,050
Okay. So that's how you said if on the other hand, the floor running out of space, if on the other hand, the plot looks something like.

219
00:32:27,740 --> 00:32:31,810
This or even like.

220
00:32:34,860 --> 00:32:49,310
Cuba gained a better. Then basically, you know that you need either quadratic or cubic dance in age.

221
00:32:49,610 --> 00:32:57,380
So that's what you see is what you have. So that's the advantage of this partial regression class.

222
00:32:58,070 --> 00:33:05,450
Okay. So. Who and.

223
00:33:07,510 --> 00:33:16,390
The polynomial does. If you feel like this.

224
00:33:21,390 --> 00:33:26,340
Okay. So that's the first approach questions.

225
00:33:31,020 --> 00:33:37,049
The second approach is to capitalize upon the continuous prediction.

226
00:33:37,050 --> 00:33:40,440
And this is something that you have kind of we have talked about.

227
00:33:41,220 --> 00:33:52,140
So what you do now is you replace the continuous for review with a categorical for of categories of

228
00:33:52,140 --> 00:33:57,690
the of the concrete and then you examine the pattern in the coefficients of the indicator value.

229
00:33:58,520 --> 00:34:06,420
So the basic assumption is that the functional form of the indicator variables cannot be specified.

230
00:34:06,810 --> 00:34:13,110
So in other words, like, you know, the indicator variables as a function, like you know,

231
00:34:13,620 --> 00:34:19,409
the relationship between why in the indicator variables linear but do we need a

232
00:34:19,410 --> 00:34:24,630
linear does doesn't want linear what we need supplies what we need is categories.

233
00:34:25,620 --> 00:34:29,630
That is the question that we are trying to address.

234
00:34:29,910 --> 00:34:34,330
See the background of the corporations are going to be equal.

235
00:34:34,360 --> 00:34:38,810
So let's talk about an example once again, the is BPH,

236
00:34:39,360 --> 00:34:46,710
which lib index and smoking data and we want to assess the functional relationship between SBP and it's just,

237
00:34:46,750 --> 00:34:50,910
you know, the same question that we addressed using the partial regression plots.

238
00:34:52,620 --> 00:34:59,970
Now I'm going to eliminate the linearity assumption by treating it as categories as capitalism.

239
00:35:00,600 --> 00:35:01,620
So what am I going to do?

240
00:35:01,620 --> 00:35:13,520
I'm going to break the age into groups and approximately equal number of subjects, and I'm going to set up the indicator completed.

241
00:35:13,530 --> 00:35:23,340
So I have age 41 to 48, it's 40 to 54, 54 to 59 and above 59.

242
00:35:23,610 --> 00:35:32,130
And I have set up these 81, 82, 83, 84 as indicators for these age groups.

243
00:35:32,640 --> 00:35:36,540
Okay. So again, all of you are familiar with this.

244
00:35:36,990 --> 00:35:42,180
So now what do I do? I fit this revised model.

245
00:35:42,570 --> 00:35:49,350
So now it is been replaced by these indicator or dummy variables for age groups.

246
00:35:50,040 --> 00:36:05,940
So together are not plus we added to with AT&T with for a default gives me the age effect and then I have the quit led and funky locations.

247
00:36:07,230 --> 00:36:11,850
Okay so my reference group here is which one?

248
00:36:12,030 --> 00:36:17,040
It's the 81 or the 41 to 48 age group.

249
00:36:18,030 --> 00:36:25,620
The way I have set up the model. So everybody with me is okay,

250
00:36:25,620 --> 00:36:37,649
so now what do I do is I floor these coefficients beta we will come to beta even have to plot

251
00:36:37,650 --> 00:36:47,370
beta Avon had beat I had betrayed feedback and beta E4 had these groups basically medians.

252
00:36:47,370 --> 00:36:50,550
So medians of those age groups.

253
00:36:52,080 --> 00:36:56,159
But I have set the four stage group as my reference.

254
00:36:56,160 --> 00:37:01,500
So what is but I even have you know, there is no better E in the model.

255
00:37:02,040 --> 00:37:09,330
So I actually by convention said beta e one had a zero by convention.

256
00:37:10,710 --> 00:37:16,170
Okay. And beta two had beta if we had been de for fallback.

257
00:37:16,500 --> 00:37:22,200
Are the estimates based on this model, this revised model?

258
00:37:24,830 --> 00:37:33,469
Okay. So these are the betas. And then for each age group, I collect the the median ages.

259
00:37:33,470 --> 00:37:41,600
So the median age in the 41 to 48 age group, the median age in 40 to 54 age group and so on.

260
00:37:43,340 --> 00:37:49,610
And I plot these coefficients against the median in each group.

261
00:37:49,610 --> 00:37:55,180
So here are the plots. Yeah.

262
00:37:55,830 --> 00:37:59,280
So this is good. This is what what happens?

263
00:37:59,790 --> 00:38:12,420
So if when I look at this floor, this floor would reflect the true nature of the association between AIDS and systolic blood pressure.

264
00:38:13,260 --> 00:38:18,480
And look at the plot, and it says, is this linear?

265
00:38:18,660 --> 00:38:21,930
Is this quadratic? Is this U-shaped? Is that a threshold?

266
00:38:22,650 --> 00:38:33,990
And depending on the factor in the floor, you can sort of decide on the nature of association.

267
00:38:33,990 --> 00:38:40,410
If the plot is approximately linear, then there is evidence in favor of the linearity assumption.

268
00:38:40,820 --> 00:38:54,330
If so, this is linear assumption, because if the plot looks something like this, then maybe I need a quadratic dorm in it.

269
00:38:54,840 --> 00:39:01,020
If I fit a disappointing math model, I could even have a plot that looks like this.

270
00:39:01,230 --> 00:39:12,850
Looks like the U-shape. Or I could even have a blog that looks like a kind of a threshold.

271
00:39:12,860 --> 00:39:26,840
I'm just making it up. So all of these these different kinds of like departures from the linear plot.

272
00:39:27,140 --> 00:39:31,880
So this this is number one. This is number two.

273
00:39:32,030 --> 00:39:41,360
This is number three. All of these different kinds of patterns in the coefficients versus the median needs.

274
00:39:41,600 --> 00:39:50,770
Each group would give me an indication of some kind of linearity or some kind of departure from the linear media.

275
00:39:52,340 --> 00:40:00,980
And once again, the back end in the floor would give us an idea about the true nature of association.

276
00:40:02,030 --> 00:40:05,120
So that's the second approach.

277
00:40:06,260 --> 00:40:14,750
But in, you know, like, again, using diagnostic blogs based on residuals, how to assess the linearity assumption.

278
00:40:16,100 --> 00:40:19,910
Okay. So now you might guess fine.

279
00:40:20,210 --> 00:40:28,260
You have told me how to assess the adequacy of the mediated resumption, but why should I care now?

280
00:40:28,520 --> 00:40:32,180
What what is the impact of the violation of the linearity assumption?

281
00:40:33,470 --> 00:40:43,130
And here is what the what is going or will be will happen.

282
00:40:45,920 --> 00:40:49,639
We kind of started talking about intuition, saying that the linearity,

283
00:40:49,640 --> 00:40:57,320
as I'm from the most more perhaps the most important assumption underlying induction model.

284
00:40:57,800 --> 00:41:02,360
So what happens if linearity fears if linearity fears.

285
00:41:02,780 --> 00:41:05,839
Before I tell you what what what happens? Maybe.

286
00:41:05,840 --> 00:41:10,460
Let's see if we can guess. So what would what do you think would happen to be a had?

287
00:41:17,590 --> 00:41:22,720
It's biased. Biased? Why?

288
00:41:23,050 --> 00:41:28,420
Can you. Can you give me like. I mean, are you intuitively.

289
00:41:32,380 --> 00:41:37,600
So, you know, we would be biased. Actually, it would be biased as a vector.

290
00:41:37,630 --> 00:41:45,490
Some some injuries of the vector may still be okay depending on, you know, if there are optimal predictors.

291
00:41:45,490 --> 00:41:52,720
But in general, that would be bias. What about why had beta had this bias?

292
00:41:52,750 --> 00:41:56,350
Why have these expert types of course we had will also be biased.

293
00:41:56,800 --> 00:42:06,600
What about Sigma Square? It will also be biased.

294
00:42:07,590 --> 00:42:13,200
And can you tell me, would it be larger on average than the true sigma spread of smaller?

295
00:42:14,850 --> 00:42:19,709
Larger. I heard pull after everybody else agrees.

296
00:42:19,710 --> 00:42:22,710
Okay. So that it would be biased.

297
00:42:23,110 --> 00:42:31,420
What about the estimated variance of between. Also biased, right?

298
00:42:31,440 --> 00:42:35,860
Because billions of people had to see must wear extra points per vaccine birth.

299
00:42:35,880 --> 00:42:44,010
So estimated variance of beta had in sigma had squared its transport ratings of beta had belonged to be bias.

300
00:42:44,050 --> 00:42:49,020
What about the confidence intervals do will be invalid and in fact they will be.

301
00:42:49,800 --> 00:42:54,290
Why there? Then.

302
00:42:57,250 --> 00:43:02,470
Then the vinegar. What about hypothesis tests?

303
00:43:02,680 --> 00:43:07,900
The standard error could be incorrect. Of course we will have a wrong inference.

304
00:43:08,140 --> 00:43:19,030
So as you can see, violation of the linearity assumption will impact from estimation to inference all across the board.

305
00:43:19,060 --> 00:43:24,310
So that's why this is such an important assumption. What are some possible solutions?

306
00:43:24,340 --> 00:43:29,680
We can modify the model. We can add more coordinates.

307
00:43:32,710 --> 00:43:45,550
So this is like the linear linearity assumption can be kind of addressed by adding maybe forwards that been left out.

308
00:43:45,580 --> 00:43:53,889
So you can modify the model, you can transform certain of the excuse based on the plots and in board the

309
00:43:53,890 --> 00:43:59,770
examples with the partial regression plot as well as the categorization approach.

310
00:44:00,580 --> 00:44:04,000
As I mentioned, what you see is what you have.

311
00:44:04,420 --> 00:44:13,930
So you can add make transformations or add extra times corresponding to x squared in the model.

312
00:44:13,930 --> 00:44:19,090
So you can add polynomial terms, you can transform x key.

313
00:44:19,510 --> 00:44:26,160
So based on the plots, you can sort of have suggested factors.

314
00:44:26,640 --> 00:44:30,250
And so this could be addressing the violation of.

315
00:44:30,760 --> 00:44:42,010
Again. Then thirdly, not another way that we can address this is to transform the outcome, transform the Y and the transformation of the Y.

316
00:44:42,040 --> 00:44:50,199
We will talk much more that when we are detailed, when we talk about the violation of the constant variance of action.

317
00:44:50,200 --> 00:45:00,560
But the good news is that oftentimes transforming the Y using like maybe logarithmic transformation or square root and really dark,

318
00:45:00,580 --> 00:45:08,200
it will be in stabilizing transformation. So in the later context, you'll see that transforming the Y can address.

319
00:45:08,500 --> 00:45:15,250
So I wanted to see violation of two different kinds of assumptions, violation of linearity, violation of cost, convenience.

320
00:45:15,970 --> 00:45:22,600
And that's the the beauty of the force formation of fly.

321
00:45:22,620 --> 00:45:33,580
So we. So these are some possible solutions that we will come to also in the context of the violation of the constant resistance assumption.

322
00:45:34,870 --> 00:45:40,000
Okay. So the any other questions here?

323
00:45:42,430 --> 00:45:47,460
Yes. So. Assess the damage and.

324
00:45:49,840 --> 00:45:53,410
And you. The best experience.

325
00:45:54,980 --> 00:46:01,370
Why? To with interrogations and take food.

326
00:46:02,640 --> 00:46:05,990
No, no. Because remember it simply navigation.

327
00:46:06,710 --> 00:46:13,150
Each Y, each x, you possess what you're going to be best in the model limited edition you.

328
00:46:13,150 --> 00:46:18,620
What kind of sign or anything is me incorporating this copy?

329
00:46:18,830 --> 00:46:22,219
And the classic example I talked about the incoming indication.

330
00:46:22,220 --> 00:46:27,980
What if some of those coordinates are strongly correlated with the contents of that?

331
00:46:27,980 --> 00:46:36,090
You will be able to detect using a filter, so know that that means up and that's why we need to work with the blockchain.

332
00:46:39,540 --> 00:46:49,760
Any other questions? Just. Variable.

333
00:46:52,580 --> 00:46:57,660
So. Yes. No, I'm not saying that.

334
00:46:58,200 --> 00:47:07,020
If the pattern shows upward pretty clear quantity, then really the fourth solution that you are going to try is to add the next great darn.

335
00:47:07,680 --> 00:47:16,110
But I'm saying like there might be other ways there linearity is violated and often times adding more code.

336
00:47:16,120 --> 00:47:19,710
Maybe it's going to be a solution. So let me give you an example.

337
00:47:21,570 --> 00:47:24,660
Where even with the quadratic, it's like supply.

338
00:47:24,660 --> 00:47:27,090
So you have what you see a quadratic factor.

339
00:47:28,500 --> 00:47:41,010
And let's say in the father said education was more important was the only will around behaved and being Miami saw like a wide variety of spectrum.

340
00:47:43,410 --> 00:47:57,959
So either hypothetically one square would one it or you bring in education and sort of the the background that

341
00:47:57,960 --> 00:48:04,290
you have seen in the school that gets reflected as a plot would be part of that if it is economic by education,

342
00:48:04,290 --> 00:48:08,070
which is strongly correlated with income. So that's the context.

343
00:48:08,730 --> 00:48:12,720
So it's not a one size fits all type of answer.

344
00:48:13,740 --> 00:48:22,530
And and I think if you, if you remember I started of the kids modern thing that this is what module regression diagnostics

345
00:48:22,530 --> 00:48:31,620
there allopathic is of course that is science but it's also like there's some subjectivity,

346
00:48:31,620 --> 00:48:39,810
some by training your eyes more and more you see the data because as you are seeing that we haven't really talked about any tests,

347
00:48:40,500 --> 00:48:46,739
we have only talked about once, you know, visual displays and oh, does this look like yoga?

348
00:48:46,740 --> 00:48:59,760
Does this. So there's a there's that's a little bit of are closer and and that solutions in these kind of scenarios are not as I said,

349
00:48:59,760 --> 00:49:04,979
not meant to not make a one size fits all type of solution.

350
00:49:04,980 --> 00:49:17,430
You you may have liberty certainly with alternative approaches, leave it transforming the Y and X or adding more covariance.

351
00:49:17,430 --> 00:49:21,210
So it's a trial and error kind of process.

352
00:49:21,460 --> 00:49:30,960
We did it. This process, if you want to get left here, one short answer by using one approach is another discipline.

353
00:49:32,130 --> 00:49:36,810
Okay. And it was the thing that you talked.

354
00:49:38,810 --> 00:49:44,570
Absolutely. That's one of the very important goals I think I've even mentioned before.

355
00:49:44,870 --> 00:49:56,479
But that what is key to the future, to taking the stand because we need to talk about that stuff in the context of constantly is.

356
00:49:56,480 --> 00:50:01,400
But yes, you can also use residual force to strengthen that.

357
00:50:17,020 --> 00:50:24,160
Let's just briefly mention the independence of mention and then I'll stop because we want to come back and do a review.

358
00:50:25,030 --> 00:50:32,320
So the next one that we are going to assess is the independence assumption that I in the line assumptions.

359
00:50:33,040 --> 00:50:44,760
So independence recall like we started off saying that if you have a mildly abnormal blast you

360
00:50:44,770 --> 00:50:52,510
are I you mean that the expectation of epsilon I epsilon zero for all I want people to date.

361
00:50:52,870 --> 00:51:08,140
This implies that y NYG are independent for all I know because to do so, the so uncorrelated in my day of normal actually implies independence.

362
00:51:09,340 --> 00:51:11,470
It's I mean, it's not.

363
00:51:12,460 --> 00:51:25,630
And even only you've sort of if and only type of situation but if it's on if the error transport related and if viewed my baby the abnormal,

364
00:51:26,050 --> 00:51:32,590
then there are also independent. And that's what the implication is.

365
00:51:33,460 --> 00:51:45,280
So so the s to assess the validity of the independence assumption, we will of course rely on the residuals.

366
00:51:45,280 --> 00:51:53,950
But one has to be before even going back to that.

367
00:51:54,160 --> 00:52:02,410
Now you have to really be give careful consideration to the study design.

368
00:52:04,540 --> 00:52:18,910
And let me just describe what I mean. So violations of independence can often be pretty P or maybe I quoted from the type of sampling design you use.

369
00:52:19,600 --> 00:52:30,160
See, for example, if the Y is a time long ago, you are looking at data from stock market, you are looking at data like climate change data.

370
00:52:30,250 --> 00:52:43,190
So there is a data to high modeling and the wise and by nature of the time modeling, then we we see information in the stock market data,

371
00:52:43,220 --> 00:52:57,190
classic example of the information climate data, whether data, no clear coordination, no subjects in the study maybe clustered.

372
00:52:57,190 --> 00:53:01,960
Let's see your study treatment and.

373
00:53:03,540 --> 00:53:09,760
JG Men backgrounds in the population and patients go to certain providers.

374
00:53:10,570 --> 00:53:13,930
Providers are practicing within hospitals.

375
00:53:14,260 --> 00:53:18,430
So these are clustered in patients, nested clusters within providers.

376
00:53:18,430 --> 00:53:25,210
Providers cluster within the hospital system, hospital systems clustered within geographic regions.

377
00:53:25,840 --> 00:53:37,540
So in situations like this, automatically because of the sharing environment, like maybe like a particular physician has his style of practice,

378
00:53:37,540 --> 00:53:47,440
his style of prescribing so that patients who see that provider are going to be coordinated because of the shared provider

379
00:53:48,100 --> 00:53:55,389
and let's say the providers who practice in a certain hospital because of infrastructural support from the hospital,

380
00:53:55,390 --> 00:54:07,870
because of, you know, machines, some whatever staff, the providers are going to be correlated within the same hospital and so on.

381
00:54:08,170 --> 00:54:15,900
So the subjects in this study, when they are clustered and you are, you are analyzing data from, from the SOC service,

382
00:54:16,360 --> 00:54:25,389
inherently the independence of that trend would be by the third is response measured repeatedly on each subject.

383
00:54:25,390 --> 00:54:26,800
So you have, you know,

384
00:54:27,730 --> 00:54:38,170
let's say you are following up a group of patients after surgery for prostate cancer and they come back for follow ups of the same patients,

385
00:54:38,770 --> 00:54:44,620
you know, pieces of the marbling, blood that tracks the sort of the progression of the disease.

386
00:54:44,920 --> 00:54:49,719
You are following up the patient over time. Every six months they've gone.

387
00:54:49,720 --> 00:54:57,220
And you a patient in the PSA. So the PSA is measured on signal dutifully or repeatedly over the same patient.

388
00:54:57,640 --> 00:55:01,420
Again, we collected data because it's from the same patient.

389
00:55:01,810 --> 00:55:12,970
So all of these will fall under like next to the because of the sampling scheme mean that to me bothered the balance of that.

390
00:55:13,630 --> 00:55:17,920
So that's why it's really, really important to pay attention to the study design.

391
00:55:18,940 --> 00:55:27,400
And lastly, as you see, we will develop this again some diagnostics and the message will get more that

392
00:55:28,180 --> 00:55:34,899
although the actual independence of the error are the residual is independent.

393
00:55:34,900 --> 00:55:39,040
No, the residuals are more independent. We can improve this.

394
00:55:40,360 --> 00:55:50,860
So that is going to be negative. And so we have to be sort of careful and vigilant about how we pass through the sampling scheme, sampling design.

395
00:55:50,860 --> 00:55:55,490
And secondly, how do we use this recipe system by national standards?

396
00:55:55,900 --> 00:56:00,680
You in a question you get how is the clustering different from having.

397
00:56:07,630 --> 00:56:10,810
Which optics make me sad.

398
00:56:13,960 --> 00:56:23,040
We just. So we have the living humans at this convenience.

399
00:56:25,340 --> 00:56:29,390
For the hospital and the provider experience. No, it will not.

400
00:56:29,540 --> 00:56:33,919
Because the so this is good question.

401
00:56:33,920 --> 00:56:41,780
So let me just read about it on that. So remember the I mean, you know, I wish I could show you the study.

402
00:56:42,020 --> 00:56:46,550
So we published a study a few years back,

403
00:56:47,330 --> 00:56:56,510
me and some of my colleagues in the Journal of the American Medical Association maybe even looking at cancer registry data.

404
00:56:56,840 --> 00:57:01,490
And here we were looking at the use of radioactive iodine for high grade cancer.

405
00:57:02,000 --> 00:57:08,660
So we looked at 1400 hospitals across the United States and we looked at, you know,

406
00:57:08,720 --> 00:57:16,100
patients with thyroid cancer with something that stayed down another age, gender, different kinds of biomarkers.

407
00:57:16,640 --> 00:57:20,360
And then whether they got radioactive iodine or not.

408
00:57:20,870 --> 00:57:25,620
Right. So the use of leakage of radioactive iodine in a binary.

409
00:57:25,620 --> 00:57:30,470
Yes. Was the outcome. And we've been measuring it at the patient level.

410
00:57:31,340 --> 00:57:40,219
Right. So if it were to be a patient from hospital to date we did by gate provider get you activated.

411
00:57:40,220 --> 00:57:44,730
I don't know. And then.

412
00:57:45,780 --> 00:57:54,629
So that's my outcome. But each patient is like clustered within a provider or within a hospital.

413
00:57:54,630 --> 00:58:00,300
So patient are in hospital one versus patient day in hospital.

414
00:58:00,520 --> 00:58:17,759
One thing that you're not comparing per patient are in hospital one and patient dean hospital two the second year of

415
00:58:17,760 --> 00:58:24,180
patients and the outcomes from then would be dependent because they're coming from two different hospitals the first year,

416
00:58:24,180 --> 00:58:26,820
because they're coming from the same hospital,

417
00:58:28,440 --> 00:58:35,640
because of the shared environment and whatever contributes to the shared environment, they need to coordinate this.

418
00:58:38,250 --> 00:58:49,450
So simply accounting for hospitality over the could not really not sort of give you the precise analysis

419
00:58:49,450 --> 00:58:57,870
that in fact it would be do you know what would be that the most anybody wants to take a guess.

420
00:59:05,400 --> 00:59:10,470
If you did not account for the coordination, if you simply assumed that within the first year,

421
00:59:10,590 --> 00:59:18,530
like patients coming from the same hospitals are going to have independent outcomes.

422
00:59:19,590 --> 00:59:23,820
If they ignored the coordination, what was going to happen?

423
00:59:26,520 --> 00:59:27,810
What would be affected more?

424
00:59:34,210 --> 00:59:44,830
So basically at the end of this long violation of independence, how does that mean that that's what we want to thinking back north?

425
00:59:45,220 --> 00:59:48,550
That's the question of asking, and I'm asking that you have a guess.

426
00:59:53,590 --> 00:59:59,140
The more we put in practice, the standard field activities have increased and the better.

427
00:59:59,980 --> 01:00:04,540
So the important thing, actually, people messed up.

428
01:00:05,980 --> 01:00:13,270
I need to stop here because we want to do the review, but this is such an interesting discussion.

429
01:00:13,270 --> 01:00:17,740
I feel like I could go on and on and I'm going to give you one more point.

430
01:00:18,100 --> 01:00:26,169
So this independence of I'm from Bali should be sort of developing faster next week and talk about the implications.

431
01:00:26,170 --> 01:00:29,290
But I'm glad you asked that question. And guess what?

432
01:00:30,760 --> 01:00:33,910
Next year we will take 653.

433
01:00:34,720 --> 01:00:39,100
653 is all about when this admission is violated.

434
01:00:40,240 --> 01:00:47,260
Imagine like a whole that basically you will talk about what you want to do when the independence

435
01:00:47,260 --> 01:00:51,819
assumption is violated and you want you are going to talk about exactly that kind of design,

436
01:00:51,820 --> 01:00:55,630
plus the data, repeated measures data.

437
01:00:57,400 --> 01:01:10,570
So the final step, 650 is when we can agree on the independence and we can we develop sort of the regression framework based at 651,

438
01:01:11,860 --> 01:01:18,310
which you are going to get next semester, is relaxing the distributional assumption.

439
01:01:18,340 --> 01:01:31,690
Then, you know, like, okay, what happens is that normality assumption is sort of violated or we have a binary use of account data as an outcome.

440
01:01:31,690 --> 01:01:41,530
So like logistic model for some model that's 651 again 44 and then 653 is like basically you relax,

441
01:01:41,630 --> 01:01:46,840
you kind of get offering from or you have repeated measures on subject.

442
01:01:46,840 --> 01:01:55,350
You are majorly not quite sure of what time you are following up with patients in terms of their hemoglobin they want see you

443
01:01:55,360 --> 01:02:06,250
are you know following the patients repeatedly measuring BTC over time you are you have cluster data so that's all you see.

444
01:02:06,970 --> 01:02:11,200
So that is how six 5651 and 653 are connected.

445
01:02:11,620 --> 01:02:17,349
And I just couldn't resist making this point because sometimes all these forces sit in

446
01:02:17,350 --> 01:02:22,270
different parts of your brain and it's hard to see where they're connected and how.

447
01:02:22,270 --> 01:02:26,170
Obviously, that's how do. Yes.

448
01:02:27,430 --> 01:02:31,410
So. I mean, if they're not paid.

449
01:02:31,420 --> 01:02:36,310
So it's not clear from. So there's no standards at the time.

450
01:02:37,850 --> 01:02:44,810
Very frustrating to watch to do that. How do you check who's coming up next week?

451
01:02:45,230 --> 01:02:52,370
Unfortunately, we won't get to it. So there is a desk that he wants to talk about.

452
01:02:54,790 --> 01:03:00,530
But. Yeah. So he said they.

453
01:03:08,100 --> 01:03:11,330
Too. You be too small. Would be great.

454
01:03:14,280 --> 01:03:23,020
And in 653, we learn about robust standard here, which is exactly what.

455
01:03:24,500 --> 01:03:30,110
I actually used to need 653 for me back.

456
01:03:31,580 --> 01:03:39,130
Yes. So that's. It's hard for me to resist not talking about it.

457
01:03:40,180 --> 01:03:43,820
But that's the one line. And Soros.

458
01:03:46,720 --> 01:03:51,220
Okay. Any other questions? This is this is really thank you for this interesting discussion.

459
01:03:51,520 --> 01:03:55,110
I know a lot of the stuff out here from the feedback that.

460
01:03:56,990 --> 01:04:01,370
So good. Okay. So let's take a break.

461
01:04:02,060 --> 01:04:08,360
It's 909 and let's so we will pick up from here next Tuesday and we'll talk

462
01:04:08,360 --> 01:04:15,590
about sort of other form of views of assessing this independence assumption.

463
01:04:17,570 --> 01:04:24,340
Let's take a break. Let's come back at 920 and we will do that in.

464
01:04:29,160 --> 01:04:34,030
Time means improvement potentially.

465
01:04:34,640 --> 01:04:42,680
Okay. We you're unclear as to whether we should treat you like as if a her own research.

466
01:04:44,000 --> 01:04:56,960
Hypothetically that we don't have our data yet. So we. Like literature to figure out which variables we think could be found in new coding literature.

467
01:04:57,800 --> 01:05:04,005
But what I mentioned is the to what I call the ballot boxes, you have to justify whatever, whatever you do.

468
01:05:05,011 --> 01:05:15,570
The original model is meanwhile you could make plus we don't want that we definitely it's two plus we got three growth product

469
01:05:15,571 --> 01:05:24,451
that takes money to the trust product arm as the interaction term and now we are centering or shifting the convenience.

470
01:05:25,741 --> 01:05:35,251
So X1 start is x1 minus C and x2 star is x2 minus B and the unknown constant.

471
01:05:35,431 --> 01:05:40,721
That's what I would say at this point. So with this shift in our system,

472
01:05:41,161 --> 01:05:49,531
then the device model becomes what in terms of the X1 starting next to start up in the

473
01:05:49,531 --> 01:05:55,461
mean Y is equal to B does not star plus we go on start x1 star plug beta from study

474
01:05:55,491 --> 01:06:03,271
to star plus bigger three star times the growth product of X1 Star and extra star and

475
01:06:04,021 --> 01:06:12,331
the Plug-in x1 minus C in place of its one star and x2 minus B in place of x2 star.

476
01:06:12,781 --> 01:06:19,111
And you get this model. Okay.

477
01:06:19,451 --> 01:06:27,311
So here is the original model. And here is the shift in model or this revised model, I should say.

478
01:06:28,421 --> 01:06:34,150
So now let's examine the parameters. So clearly we cannot start and we do not are not equal.

479
01:06:34,151 --> 01:06:43,001
Why? Because we do not. How do you get better? Not from the original model when what x1 x2 feel and how do you get better?

480
01:06:43,001 --> 01:06:50,021
Not start from the device model when x1 is equal and extremely poor to be simultaneously.

481
01:06:50,021 --> 01:06:53,441
So be that again. We cannot start up clearly not equal.

482
01:06:55,001 --> 01:07:12,641
What happens to let's look at the slope corresponding to X1 so you take the first partial derivative of the mean y, but you know, with respect to X1.

483
01:07:12,941 --> 01:07:21,250
So from the revised model, if you take the first partial derivative of this quantity with respect to explain what do you get,

484
01:07:21,251 --> 01:07:27,461
you get better one star plus beat up three start times X2 minus B.

485
01:07:28,391 --> 01:07:32,321
Yes, everybody with me, Nancy.

486
01:07:32,741 --> 01:07:36,491
Fine. Okay. So now let's direct this expression.

487
01:07:38,921 --> 01:07:43,601
When is this expression equal to the Beagle on star?

488
01:07:44,111 --> 01:07:48,311
This is going to be equal to one star when x2 is equal to B.

489
01:07:51,481 --> 01:07:55,321
Okay. So when exactly is it going to be? I did this flow.

490
01:07:55,381 --> 01:08:01,381
It is equal to Beethoven star. But what about the.

491
01:08:01,411 --> 01:08:08,311
What do you do? No more. What about in this model? Again, take the first partial derivative with respect to X1.

492
01:08:08,641 --> 01:08:14,521
What do you get? You get great one plus beta three x2 from the original model.

493
01:08:16,951 --> 01:08:22,531
And when is that equal to be demand? When x2 is equal to zero.

494
01:08:26,211 --> 01:08:32,240
Right. So, Peter, what like this slope is equal to one minute to is equal to zero.

495
01:08:32,241 --> 01:08:37,101
And in the revised model, the slope is equal to one star.

496
01:08:37,101 --> 01:08:46,821
When it is equal to B, therefore beta one star and beta one are not equal unless B self is equal to zero.

497
01:08:49,791 --> 01:08:56,970
Okay. And similarly, if you take the first partial derivative of each of the original device money

498
01:08:56,971 --> 01:09:03,421
with respect to x two and do the same sort of operation and use the same logic,

499
01:09:03,421 --> 01:09:07,201
you will see that reproduced dog is more difficult to be attached to.

500
01:09:07,201 --> 01:09:10,261
On less is equal to zero.

501
01:09:14,681 --> 01:09:19,361
So big. Come on and beat up the window even more.

502
01:09:19,361 --> 01:09:24,551
We are not the same as we come on Star and be devastated by this smartly.

503
01:09:24,941 --> 01:09:30,881
But what happens to beat up three? Stavola So we did three studies, the interaction coefficient, correct?

504
01:09:31,241 --> 01:09:42,791
So to get better three star, what you do is you take this second partial derivative with respect of the mean of y with respect to it's funny

505
01:09:42,941 --> 01:09:57,970
to do that operation in the in the device models would be there to build x1 x2 off this mean in the device model.

506
01:09:57,971 --> 01:10:05,771
So what do you get you get like the first operation with respect to X1, you get between starters beta three,

507
01:10:05,771 --> 01:10:11,171
start M60 minus B and then you take another derivative with respect to x2.

508
01:10:11,531 --> 01:10:19,031
So you get beta three, start right in the device model.

509
01:10:19,421 --> 01:10:29,261
Now do the same thing. The second partial derivative with respect to X1, an extreme, the original model, what do you get?

510
01:10:29,591 --> 01:10:38,560
You get the first operation with respect to X1 gives you better plus beta three x2 now you the derivative with respect to x2 what do you get?

511
01:10:38,561 --> 01:10:39,521
You get better three.

512
01:10:40,211 --> 01:10:53,771
So beta three star and beta three are equal in the device and always in that model and therefore the people messages in the deduction model,

513
01:10:54,341 --> 01:11:03,781
shifting the four or centering the whole body, it kind of impacts every team box thing direction 4%.

514
01:11:08,281 --> 01:11:11,641
Okay. You don't have to do this. Thank you.

515
01:11:12,081 --> 01:11:16,711
Okay, so that's one question.

516
01:11:17,461 --> 01:11:27,421
Then the second one was a problem to solve a 2019 exam.

517
01:11:28,301 --> 01:11:32,991
Mm. Uh.

518
01:11:36,961 --> 01:11:43,551
With ten one. Okay.

519
01:11:43,701 --> 01:11:53,661
So this email, you had a question about the first question, but only one part.

520
01:11:53,721 --> 01:11:58,441
But you know, since you ask that, I'm going to do this whole problem as a review.

521
01:12:00,981 --> 01:12:12,171
So this is you have the solutions uploaded, but let's kind of do it together and and see.

522
01:12:12,251 --> 01:12:24,311
So the first born and so this is a 2019 exam problem one I've just.

523
01:12:25,141 --> 01:12:29,301
You should have those exams. Blank.

524
01:12:30,741 --> 01:12:34,131
Yeah. I can upload the blank ones. Okay. Okay. Sounds good.

525
01:12:34,321 --> 01:12:39,591
Yeah. And I definitely.

526
01:12:39,591 --> 01:12:44,091
As soon as I collect stuff. Okay, so let's work on the blank, in a sense.

527
01:12:44,421 --> 01:12:50,751
So this is number question one on exam on 2019, exam two.

528
01:12:51,141 --> 01:12:56,151
So we have two models for the continuous outcome Y and ordinal predictor XIV.

529
01:12:56,151 --> 01:13:03,081
Possible values. One, two, three, four. Model E is beta naught plus indicator.

530
01:13:03,081 --> 01:13:08,511
That s funny, but one plus between we give an extra equal to x one equal to two.

531
01:13:09,291 --> 01:13:16,431
So it's equal to two. We have only one predictor. Plus we got three indicator x one, two, three, plus epsilon.

532
01:13:17,541 --> 01:13:21,530
And model b is y equal to gamma.

533
01:13:21,531 --> 01:13:24,860
One indicator x equals one plus gamma.

534
01:13:24,861 --> 01:13:36,111
Between we get an expert ca2+ gamma three x indicator x equals three plus gamma falling negative x equal to four plus delta odd and epsilon i and

535
01:13:36,271 --> 01:13:46,431
they are the error terms with the usual assumptions are is the typical indicator variable and we have beta 100 subjects to pick that up markers.

536
01:13:46,821 --> 01:13:53,481
So before even we go to the two false questions, what is the name for Model E?

537
01:13:57,691 --> 01:14:02,281
Therefore, instead of calling right in, what is the name for model B?

538
01:14:02,611 --> 01:14:05,911
So cell means. Awesome.

539
01:14:07,261 --> 01:14:20,750
So now let's. Let's go to the two phones for each of the following statements.

540
01:14:20,751 --> 01:14:26,811
And it would be circle the correct answer. The design matrix for Model B is less than full.

541
01:14:27,141 --> 01:14:30,441
Two are false or false, right?

542
01:14:31,371 --> 01:14:39,621
So the design matrix has four columns corresponding to the first column.

543
01:14:39,621 --> 01:14:45,441
There is no column of one, but the four columns together spend the whole of the funds.

544
01:14:46,851 --> 01:14:50,691
So this is false. What about part B?

545
01:14:51,501 --> 01:14:59,721
The sigma hat squared from model B will be smaller than the sigma had split from model E to enforce falls.

546
01:15:00,591 --> 01:15:09,321
Everybody agrees. Okay. This is music to my ears when I hear everybody sing falls.

547
01:15:10,461 --> 01:15:12,501
Not just one or two people. Okay.

548
01:15:15,351 --> 01:15:29,991
But see, after hitting the models, the residuals will be the same for all subjects, i.e. Epsilon Hap is equal to Delta except for all are true.

549
01:15:30,561 --> 01:15:35,431
Right? Because these two models are equal in grade.

550
01:15:36,711 --> 01:15:41,811
The regression sum of squares is the same in both models E and B.

551
01:15:42,111 --> 01:15:47,201
True or false? SSR is.

552
01:15:50,711 --> 01:15:59,811
Forbes How many people think Forbes? Well, one thing it's.

553
01:16:02,211 --> 01:16:05,600
And confidently true.

554
01:16:05,601 --> 01:16:13,731
And I'm saddened that one of our friends I don't know if you me to think it's confidence that you are confident that it's true, then please.

555
01:16:13,761 --> 01:16:17,061
They feel connected to me right now.

556
01:16:22,691 --> 01:16:27,671
And then as soon as you said it, then I think there's.

557
01:16:29,851 --> 01:16:33,551
Yes. You came to my office with this question.

558
01:16:35,701 --> 01:16:44,581
Okay, so maybe I built it because the noise question was this kind of help.

559
01:16:45,301 --> 01:16:51,151
So maybe I'd be able to explain that. So the standard means versus reference and coding.

560
01:16:51,181 --> 01:16:57,660
We know the ethnicities are the same. We did an example and we also showed mathematically why?

561
01:16:57,661 --> 01:17:01,411
Because why come from the two models are the same.

562
01:17:01,801 --> 01:17:07,651
If one three people. So if this is so mission y minus what you had square.

563
01:17:08,551 --> 01:17:18,301
So the issues are the same. So first, let me tell you, the answer to this part is false.

564
01:17:19,231 --> 01:17:22,261
But why is it false? And this was the question.

565
01:17:22,261 --> 01:17:30,691
I think the question that came, which is what I was learning to talk about that and maybe I didn't do it.

566
01:17:33,571 --> 01:17:37,291
Take this opportunity. And so the question was, hi, Dr. Brennan.

567
01:17:37,981 --> 01:17:39,541
Quick question about the regression.

568
01:17:39,541 --> 01:17:48,121
Some of squares when comparing cell means for coding versus reference coding, the residuals in both models are equal.

569
01:17:49,111 --> 01:17:52,951
From what I understand, likewise, the predicted values I think will be the same.

570
01:17:53,821 --> 01:17:59,041
Why then, is the regression sum of squares not equivalent for both models?

571
01:18:00,041 --> 01:18:06,030
The y hat is the same for both and the y values are shared, so the sum of the squared differences should be the same.

572
01:18:06,031 --> 01:18:12,541
20. Yeah. Y minus y you have a square sum would be the same size would be the same.

573
01:18:13,261 --> 01:18:17,821
But why then is the regression? Suppose there's not equal equivalent for both models.

574
01:18:18,261 --> 01:18:22,051
So the correct answer is this statement is false.

575
01:18:22,501 --> 01:18:26,041
But let me let see why it's false.

576
01:18:26,221 --> 01:18:32,081
You came to me with this question and I said exactly the ss ys are different.

577
01:18:33,151 --> 01:18:39,841
So do you remember we talked about this that in the cell means Gaudi and Sophia.

578
01:18:39,841 --> 01:18:44,071
Did you also come with this question? W and justice came together.

579
01:18:44,101 --> 01:18:56,401
Yeah. So, like, for the cell means according and that is this y is submission y squared.

580
01:18:58,921 --> 01:19:07,111
It's not summation y minus y bar squared.

581
01:19:10,171 --> 01:19:13,781
This is going to force forcing the interceptors here if I had.

582
01:19:14,371 --> 01:19:19,951
Yeah. Yeah. So. So when I will. So this is for cell means folding.

583
01:19:21,361 --> 01:19:22,440
So let me tell you,

584
01:19:22,441 --> 01:19:35,161
when Dusty Stenzel came to my office with the question what I told them and one argument you taught helped you understand better than the other.

585
01:19:35,401 --> 01:19:43,560
So the first thing I said, you know, the reason why for the cell means coding the S's y is summation y squared.

586
01:19:43,561 --> 01:19:48,901
It's the uncorrelated sum of squared and not the correct big sum of squares.

587
01:19:49,081 --> 01:19:56,461
Submission y minus white box square. It's not. That is because I'm forcing the intercept to be zero.

588
01:19:56,461 --> 01:20:09,601
There's no intercept in the cell means coding model, so there is no kind of that y bar that you see usually comes from the intercept.

589
01:20:12,391 --> 01:20:18,061
So that's why it's not corrected in the settlement coding,

590
01:20:18,061 --> 01:20:24,481
because you do not have an interest if you are actually foreseeing artificially that the intercept is zero.

591
01:20:24,481 --> 01:20:27,811
So it's an uncorrected why someone should write a script.

592
01:20:28,261 --> 01:20:37,531
So that's the first argument I give them. And they were like, okay, but the point is they were still not completely happy.

593
01:20:37,801 --> 01:20:41,341
Like, I'm using your example because I want to build that whole class.

594
01:20:41,341 --> 01:20:46,131
And the second thing I don't do and which made you say, Oh, I get it now, now.

595
01:20:46,591 --> 01:20:55,801
So the other thing I told them is if you go back to module, what was the module F, right?

596
01:21:00,511 --> 01:21:09,781
So justice module F, do you remember the slide number I showed you on slide six?

597
01:21:11,671 --> 01:21:21,941
Slide six. Right. The oak slide.

598
01:21:22,241 --> 01:21:27,191
So this is this is what I showed them. So this is more do let slide six.

599
01:21:27,821 --> 01:21:32,921
So I told them, okay, let's look at that as this slide in some of Square's matrix notation.

600
01:21:33,221 --> 01:21:48,811
So what is is this y sort of in the regular bread and butter model, it's y transpose identity matrix minus the matrix of ones divided by in times.

601
01:21:48,821 --> 01:21:57,431
Why this matrix of ones is coming from the column of ones from the design matrix.

602
01:21:58,661 --> 01:22:03,281
This matrix of ones is coming from this. A column for The Intercept.

603
01:22:03,761 --> 01:22:11,411
One, one, one, one, one. And then multiply it with the rule vector of 111111 that gives you the matrix of ones.

604
01:22:11,711 --> 01:22:16,331
And where is the column of one coming from? That's coming from The Intercept.

605
01:22:19,181 --> 01:22:23,321
So in the savings for me, there is no intercept.

606
01:22:23,861 --> 01:22:26,051
So there are more than once.

607
01:22:30,371 --> 01:22:38,681
Everybody hoping that there isn't a political plan because there's no interceptors in the design matrix for the cell means for me.

608
01:22:39,611 --> 01:22:47,131
I'll go back again to this. So for the cell means coding for this model.

609
01:22:48,101 --> 01:22:56,161
The design matrix. Doesn't have.

610
01:23:00,231 --> 01:23:05,691
Her book column of ones.

611
01:23:10,021 --> 01:23:13,231
So it doesn't have a problem of funds being swapped.

612
01:23:13,951 --> 01:23:17,541
Now, is this why you remember the quadratic form like this?

613
01:23:17,551 --> 01:23:24,051
So I don't have this. I don't have this part.

614
01:23:27,271 --> 01:23:30,691
So basically, what do I have for the settlement according.

615
01:23:34,951 --> 01:23:44,711
There is this why is why transports identity matrix sometimes why which is why?

616
01:23:44,711 --> 01:23:47,920
Transport why and what is why?

617
01:23:47,921 --> 01:23:52,511
Transport why? Why, why is simply some Asian why square?

618
01:24:03,501 --> 01:24:15,821
And we also think that it's this way as. Is this on one side?

619
01:24:16,881 --> 01:24:20,601
Yeah. So it's like, you know, while these things we're moving out.

620
01:24:21,231 --> 01:24:27,781
Yeah, yeah, yeah, yeah, yeah. It's a bit convoluted there, but.

621
01:24:28,821 --> 01:24:32,061
Yeah. So does that make sense?

622
01:24:32,121 --> 01:24:35,751
That's why the Nexus five from these two models are different.

623
01:24:36,081 --> 01:24:42,441
The is the size of this case because the quantum equivalent is this why they're different?

624
01:24:42,441 --> 01:24:49,491
And in fact, this is why from the selling point, the model 40 model is artificially increased.

625
01:24:50,391 --> 01:24:54,531
And so the SS R is also increased because this is how it is.

626
01:24:54,861 --> 01:24:58,910
If this Y minus this is right, this is these are the same.

627
01:24:58,911 --> 01:25:08,901
But if is five are different and that's as a as a byproduct of that that is this already go to actually increase in the sale means for the model.

628
01:25:09,231 --> 01:25:15,111
And that's why if you remember when we talked about the example they said do not interpret the R-squared

629
01:25:15,111 --> 01:25:22,601
from a somewhat from the settlement model from the practice of not just artificially inflated.

630
01:25:23,121 --> 01:25:36,561
Yes. So as a salary check in salary or MLR, the value of like the value or the value of the 55 year old compared to zero is going to be the mean.

631
01:25:36,871 --> 01:25:40,391
Yes, exactly. Exactly.

632
01:25:42,011 --> 01:25:47,531
Okay. So everybody. So I'm glad, you know, doing this.

633
01:25:49,001 --> 01:25:57,241
Give us the opportunity of addressing this was the other question that they had collected from from the from the class.

634
01:25:57,251 --> 01:26:02,111
So now let's go back to this question.

635
01:26:03,461 --> 01:26:09,721
So now I think this was people's question specifically, Barbie.

636
01:26:10,271 --> 01:26:18,071
Suppose we do not have these equal to five one half is equal to two better two had equal to seven and because three had equal to four,

637
01:26:18,941 --> 01:26:27,491
if the value of gamma three had can be calculated, keep the value for your otherwise right cannot be determined.

638
01:26:28,181 --> 01:26:34,150
So let's go back and look at these two models. The difference group coding versus the settlement coding.

639
01:26:34,151 --> 01:26:49,181
What did anybody wants to tell me what Gamma three corresponds to in the settlements model it's the it's the group mean for its equal to three.

640
01:26:49,331 --> 01:26:58,031
Correct. How would you get the group mean from model E for X equal between two cells.

641
01:26:59,951 --> 01:27:04,631
So intercept plus five plus beta three.

642
01:27:05,231 --> 01:27:14,411
Right. So Gamma and I gamma three have equal to be done on that plus beta three that that's

643
01:27:14,411 --> 01:27:22,121
exactly what I am going to do for Gamma three that is equal to expected value.

644
01:27:22,121 --> 01:27:26,651
So this is the mean Y given its equal to three.

645
01:27:31,481 --> 01:27:36,881
Estimated by okay. So this is based on the first model.

646
01:27:36,881 --> 01:27:50,201
The reference recording model is better not had lost that feedback which is equal to five plus four plus nine.

647
01:27:51,251 --> 01:27:54,431
Does that make sense? Okay, good.

648
01:27:54,851 --> 01:27:57,461
So now the next part is I'm saying, right,

649
01:27:57,461 --> 01:28:07,301
the hypothesis eight is not there is no association between the predicted X and outcome Y using coefficients in model e,

650
01:28:07,841 --> 01:28:11,320
specify the alternative hypothesis also.

651
01:28:11,321 --> 01:28:14,891
So the model is the reference group coding.

652
01:28:15,731 --> 01:28:21,191
So what would be the null hypothesis for no association between y in x?

653
01:28:27,301 --> 01:28:30,411
I can't hear you. Okay. I need to.

654
01:28:31,981 --> 01:28:36,261
Because they are. Because it just means no difference between what you said.

655
01:28:38,221 --> 01:28:40,471
Okay. Everybody heard it and everybody agree.

656
01:28:41,131 --> 01:28:49,501
So the null hypothesis of no association from this model is built on equal to BW, equal to make up equal to zero.

657
01:28:50,431 --> 01:29:00,171
Because if all of these are zero, then for you descriptive of what the value of x is the mean why is beta not correct?

658
01:29:00,181 --> 01:29:03,541
So there is no difference between the group means.

659
01:29:04,081 --> 01:29:07,981
So the null hypothesis is based on naught.

660
01:29:10,291 --> 01:29:17,461
So we demand equal to be equal to zero versus the alternative.

661
01:29:18,421 --> 01:29:22,141
I'm just going to write it as at least one is different from the.

662
01:29:27,811 --> 01:29:33,281
Okay. Uh, what about, um.

663
01:29:33,641 --> 01:29:37,351
Now let's go to motive. Be the next set of questions.

664
01:29:37,351 --> 01:29:38,191
Burden the model.

665
01:29:38,761 --> 01:29:46,831
So I want to write the hypothesis that there's no association between the predicted rates and outcome by using the coefficients in model B.

666
01:29:47,311 --> 01:29:50,861
So this is the same encoding part.

667
01:29:50,911 --> 01:29:56,701
Tell me what the null hypothesis is and then tell me and the alternative,

668
01:29:56,701 --> 01:30:03,091
and then tell me the contrast matrix that I can use to carry out a DNA test for that hypothesis.

669
01:30:03,571 --> 01:30:07,321
So here is the cell means coding model.

670
01:30:07,411 --> 01:30:12,811
Model B so what would be the hypothesis of no association?

671
01:30:18,341 --> 01:30:25,900
Great. So everybody. Fine. So the non is gamma one equals two.

672
01:30:25,901 --> 01:30:31,441
Gamma two equals two. Gamma three equal to gamma four level zero.

673
01:30:32,561 --> 01:30:36,311
No. Okay. So this is a delay.

674
01:30:36,731 --> 01:30:40,841
And each one is I mean, just right. It's not.

675
01:30:40,841 --> 01:30:44,531
It's not. So this is a delay.

676
01:30:46,301 --> 01:30:59,261
So who wants to tell me? Firstly, tell me, what does this reduce to and who wants to tell me what the contrast matrix will look like?

677
01:31:01,121 --> 01:31:08,661
Give me the congressman, Charles Barkley. Tell me what would be the number of rules of this contrast matrix three.

678
01:31:09,431 --> 01:31:13,481
Right. Okay. So anybody wants to give me the contrast matrix.

679
01:31:18,431 --> 01:31:22,971
Say it again for the first. And one more.

680
01:31:24,021 --> 01:31:28,341
Okay. Next one would be zero one.

681
01:31:42,121 --> 01:31:45,391
They say to me what I did was wrong.

682
01:31:45,901 --> 01:31:52,801
I thought of it as. You have one too.

683
01:31:53,871 --> 01:32:01,730
And so that yeah, you can do it that way you can just switch instead of negative one 100 against one minus one.

684
01:32:01,731 --> 01:32:12,201
That doesn't happen. So he hypothesize goes down at -1.003 minus gamma can put down for minus galaxy.

685
01:32:12,201 --> 01:32:19,190
So people you can hypothesize it like as gamma one nine is going to put a little

686
01:32:19,191 --> 01:32:28,151
gamma one minus gamma 3.201 minus gamma 40.1 bottom is the rank of this teammate.

687
01:32:28,261 --> 01:32:31,881
This has to be equal screen.

688
01:32:33,321 --> 01:32:37,041
They can only be playing the only independent political system.

689
01:32:37,071 --> 01:32:41,461
In case you have a question that you know is the same with.

690
01:32:41,651 --> 01:32:50,261
Yeah. So yes, you can see if you got that. And okay, so that's the that's the D matrix.

691
01:32:50,271 --> 01:32:54,800
Okay. What about the so the next part I see, right,

692
01:32:54,801 --> 01:33:01,341
that there's this thing that would be used to carry out the testing D including its distribution and degrees of freedom,

693
01:33:01,791 --> 01:33:08,331
give the actual numbers and identity notation for degrees of freedom and define on the time sets.

694
01:33:08,661 --> 01:33:19,070
So this would be you can do this DNA test using a, you know, then the left test and this is the dual H module.

695
01:33:19,071 --> 01:33:41,031
So what would be the best statistic like look like it would be D gamma had transpose the x transpose x inverse the transpose inverse of the

696
01:33:41,031 --> 01:34:01,581
whole thing times de gamma her divided by three length of B and what is on the in the denominator sigma head squared from which model.

697
01:34:02,631 --> 01:34:09,531
From the full model. Okay. So what would be the distribution of this.

698
01:34:09,771 --> 01:34:23,091
This would be four degrees of freedom, three forma this class 96, 9600 -496.

699
01:34:24,231 --> 01:34:30,891
Okay. And and will you be able to write the design matrix for this?

700
01:34:31,731 --> 01:34:34,791
The X matrix for this cell means quoted.

701
01:34:44,121 --> 01:34:49,371
Yeah. So the first column would be ones corresponding to group one, everything else zero.

702
01:34:49,911 --> 01:34:57,171
The second column would be one for responding to group two, everything else would be zero and so on.

703
01:34:57,561 --> 01:35:04,131
There is not a column of one's street, but those four columns together span the Intersect.

704
01:35:05,811 --> 01:35:13,311
Okay. And then the last part is suppose we want to test.

705
01:35:13,411 --> 01:35:17,211
It's not difference in means of quality across consecutive categories of x

706
01:35:17,211 --> 01:35:22,761
and all the same like the null an alternative using coefficients in model B.

707
01:35:23,151 --> 01:35:31,941
Right. The contrast matrix that will be so basically unseen in the constant means in the constitutive categories of the thing.

708
01:35:33,051 --> 01:35:43,061
So basically I'm seeing what group one and group two are the same, group two and who killed the same group three and four are the same.

709
01:35:43,071 --> 01:35:51,861
So Gamma one minus gamma two equal to gamma pool minus gamma three equals to gamma three.

710
01:35:51,861 --> 01:35:59,991
Minus gamma four. Is that a zero?

711
01:36:01,791 --> 01:36:12,481
No. So this is once again a glitch. And each one is not more.

712
01:36:14,131 --> 01:36:30,481
So who wants to tell me the contrast matrix so I can equivalently write this as the null hypothesis is gamma one minus gamma two from these sets.

713
01:36:33,641 --> 01:36:41,621
From these two sets I'm going to gamble on minus gamma, two minus gamma, last gamma be equal to zero.

714
01:36:43,751 --> 01:36:48,431
The second one I can write gamma one minus gamma two.

715
01:36:54,081 --> 01:37:00,981
Or you can boom. Minus gamma, three minus.

716
01:37:05,671 --> 01:37:14,281
Minus from here, I'm collecting gamma three plus gamma four equal to zero.

717
01:37:15,871 --> 01:37:22,711
Okay. So the 2D matrix will have two linearly independent flaws.

718
01:37:23,761 --> 01:37:28,920
And what can we fix here? I'll write it here.

719
01:37:28,921 --> 01:37:39,931
But. So this is for the female? It would be one minus two one zero.

720
01:37:43,441 --> 01:37:50,581
And then zero one minus one.

721
01:37:55,371 --> 01:38:13,071
Okay. So that's it. And if you have any more questions, please email me or see me.

722
01:38:15,911 --> 01:38:22,721
Good luck for Thursday. I will see you in the exam.

