1
00:00:00,690 --> 00:00:05,170
Hi. Hi.

2
00:00:05,190 --> 00:00:10,950
Hello. Welcome to another 523.

3
00:00:11,640 --> 00:00:17,460
So today we're going to cover homework number two that it's already posted.

4
00:00:19,260 --> 00:00:26,220
It's due on Sunday, October the second. So today we're going to walk through problems, one, a little bit of problems.

5
00:00:26,760 --> 00:00:30,990
And then next week, we're going to walk through probably my favorite.

6
00:00:31,160 --> 00:00:35,020
Okay. So very good news.

7
00:00:35,070 --> 00:00:39,930
Love today's chores compared to last week's nap.

8
00:00:40,410 --> 00:00:43,440
So today we're going to talk about a couple of statistics.

9
00:00:43,980 --> 00:00:52,260
McNamara's best for matching data on one odds ratio estimate for this time table.

10
00:00:53,460 --> 00:00:58,640
Okay. So all of this covers problem number one for the homeless.

11
00:00:58,650 --> 00:01:02,250
Problem number two, it's on r0c here.

12
00:01:02,550 --> 00:01:05,730
So the code is already the same that we used last week.

13
00:01:06,390 --> 00:01:11,400
So you can find it there. Okay. So let's go here on this slide.

14
00:01:12,840 --> 00:01:18,150
So all. What's a couple statistics?

15
00:01:18,160 --> 00:01:24,710
So let's say we have two different best to measure blood, to measure diabetes, for example.

16
00:01:25,160 --> 00:01:32,389
And each test can be either positive or negative for each subject are what we want to know.

17
00:01:32,390 --> 00:01:35,150
It's considered a better way to table something like this.

18
00:01:35,150 --> 00:01:41,240
So here we have the first method slash test and here we have the second one where that is the best.

19
00:01:41,540 --> 00:01:48,950
And we come out and we want to estimate the degree of the of how much they.

20
00:01:51,060 --> 00:01:54,450
How much they agree. So that's exactly the statistics.

21
00:01:54,810 --> 00:02:01,440
So they come up with some basic measures. The amount of agreement between to test and express statistics is the thing.

22
00:02:02,250 --> 00:02:10,220
So these are P, not minus B, E over one, minus B, where finer is this formula?

23
00:02:10,230 --> 00:02:21,650
And then. P e if this firm formula here basically be zero, it would be like the percentage of agreement they have.

24
00:02:22,040 --> 00:02:29,029
So it would be a stable because it is positive from positive the because he's negative on negative.

25
00:02:29,030 --> 00:02:36,890
So eight was the plus the divided by the total sample, which in this case is N and b e,

26
00:02:36,950 --> 00:02:43,610
it's the proportionate proportion of subjects for which Democrats would agree by chance alone.

27
00:02:44,120 --> 00:02:48,050
And based on those two things, we can construct the by statistic.

28
00:02:48,920 --> 00:02:56,720
So how are we constructed in OS on before us the corpus of this thing we have like a rule of thumb.

29
00:02:56,840 --> 00:03:02,990
So interpret that a statistic. This statistic can be negative and sometimes it is negative.

30
00:03:03,320 --> 00:03:09,440
And if it is negative, we say the two tests have poor agreement between zero and 0.2.

31
00:03:09,440 --> 00:03:19,009
They have a slight agreement between 21 and 44, fair agreement 4.41 and six moderate, then substantial.

32
00:03:19,010 --> 00:03:25,940
And then anything of all above point a will be almost perfect agreement between the two test.

33
00:03:27,980 --> 00:03:33,910
Okay. So we're going to work with this table throughout the lab.

34
00:03:34,460 --> 00:03:38,000
So let's say I want to measure of diabetes.

35
00:03:38,000 --> 00:03:45,440
And for that I have two types of tests. The first one is the type of blood test, and the second one is the oral glucose test.

36
00:03:45,920 --> 00:03:50,450
And this is the two by two table that I have according to those tests.

37
00:03:50,840 --> 00:03:54,560
I have 186 individuals.

38
00:03:54,920 --> 00:04:02,120
I have 21 people who tested positive in the standard blood test, which means they have diabetes according to that test.

39
00:04:02,630 --> 00:04:10,940
And they also tested positive using the glucose test and so on and so forth for the other four cells in that table.

40
00:04:11,660 --> 00:04:18,470
So the first thing we want to do is to assume.

41
00:04:19,980 --> 00:04:23,280
Estimated by statistics using source on PA.

42
00:04:23,730 --> 00:04:29,970
So if you're using SaaS, we create a two by two table very similarly, as we did last week.

43
00:04:31,350 --> 00:04:40,319
So create a data dataset. In this case, I'm calling it diabetes and I have three variables here, whether they're oral pestis,

44
00:04:40,320 --> 00:04:46,440
positive or negative, whether the blood test is positive or negative, and then the number of people in each category.

45
00:04:46,650 --> 00:04:53,220
So these are the four cells in the two by two table. And then after that, it's very simple.

46
00:04:53,640 --> 00:05:01,140
Let's just ah, we run approx rec and here I'm using the two by two table that I just created here.

47
00:05:01,530 --> 00:05:05,040
And then I created tables. So wait.

48
00:05:05,430 --> 00:05:08,100
By my frequency variable, I create a table.

49
00:05:08,550 --> 00:05:16,710
Two at the table for the two test and then agree on the test proper for all of the statistics that we are going to use.

50
00:05:18,120 --> 00:05:22,400
Okay. Any questions so far for this column?

51
00:05:24,050 --> 00:05:29,030
Oh, good. After that, we can just interpret our results.

52
00:05:29,360 --> 00:05:33,979
So first we have a table for the cup estimate.

53
00:05:33,980 --> 00:05:43,140
In this case is 0.68. So if we can go back to our table, 0.68, it's this range.

54
00:05:43,190 --> 00:05:52,550
So we would say that the oral test on based on our test for glucose for glucose have a substantial, substantial agreement.

55
00:05:54,200 --> 00:06:01,940
Okay. We also have the 95%, based on the error of this estimate, only the 95% confidence interval.

56
00:06:02,510 --> 00:06:08,090
And then in another table, we have the hypothesis test.

57
00:06:08,390 --> 00:06:14,360
In this hypothesis test, we are testing whether that cup on statistic is equal to zero or more different than zero.

58
00:06:15,320 --> 00:06:19,310
In this case, we have the same estimate, the same as standard error. And then.

59
00:06:21,240 --> 00:06:29,420
Oh. And then we have the. The test statistic.

60
00:06:29,420 --> 00:06:33,200
I'm sorry. That was a question that was looking for the test statistic.

61
00:06:33,770 --> 00:06:40,610
The last the last column in this table would be would be the p value.

62
00:06:40,610 --> 00:06:45,140
So in this case, the P value is less than, I don't know, so let's say 5%.

63
00:06:45,440 --> 00:06:51,650
So we would reject a null hypothesis. In this case, we have a strong evidence that the corpus statistic is different than zero.

64
00:06:53,330 --> 00:07:01,910
Okay. Another question in the homework is not only to estimate the corpus of this thing, but also to estimate the maximum process.

65
00:07:02,300 --> 00:07:09,020
So. Running only these lines of code without anything else.

66
00:07:09,410 --> 00:07:15,260
You already not only have the capacity to take on the P-value and B test for the corpus, but this thing.

67
00:07:15,260 --> 00:07:21,230
But you also have the McNamara stressed. You don't have to run anything new if you are using.

68
00:07:21,650 --> 00:07:29,180
It will be already one of the outputs. And then here we have the mathematics that we have the process that we seek,

69
00:07:29,570 --> 00:07:37,250
the techniques of freedom, which is that chi square on the variable and the p value of such specs.

70
00:07:38,630 --> 00:07:43,300
And. Okay. Any questions so far?

71
00:07:45,810 --> 00:07:50,310
The question will be, how do we do this in? Because I know that most of you use art.

72
00:07:50,820 --> 00:07:58,590
So in art, the first thing we are going to do is to create a matrix that contains the force else of that to make a table.

73
00:07:58,980 --> 00:08:05,920
That is what I'm doing here. So my matrix is going to be called diabetes, then theta itself.

74
00:08:06,110 --> 00:08:09,120
I'm using the matrix function here.

75
00:08:09,120 --> 00:08:12,149
I have the vector for it before cell.

76
00:08:12,150 --> 00:08:23,730
So that two way to table, I said that we have two columns, so it creates separate table and then I'm writing these numbers by row.

77
00:08:24,540 --> 00:08:32,190
And then here this is just to make sure when I frame the table instead of having like one some zeros,

78
00:08:32,400 --> 00:08:35,790
I have positive, I'm negative, I'm positive some negative.

79
00:08:35,790 --> 00:08:42,600
So then the labels look us the table that we just spoke.

80
00:08:43,200 --> 00:08:51,930
And then for if you're using source, this is the only code you need for three things.

81
00:08:52,380 --> 00:08:58,890
First, we copy estimate. Second, the p value on the case associated to the copy estimate.

82
00:08:59,220 --> 00:09:04,800
And thirdly, McNamara's test. So if you're using size, this is all the code unit.

83
00:09:05,250 --> 00:09:08,940
However, if you're using art, as I know most of you do,

84
00:09:09,330 --> 00:09:17,100
we need to have these three things with different packages because there is not one package that does that those the whole thing for us.

85
00:09:17,520 --> 00:09:20,730
So the first package that we are going to use is size.

86
00:09:22,260 --> 00:09:26,970
So inside packages size and then call the library into our script.

87
00:09:27,330 --> 00:09:32,490
And then just to estimate the statistic, we can use this function, go hand the problem.

88
00:09:32,820 --> 00:09:36,810
And then in parentheses we have the table that I have here.

89
00:09:38,240 --> 00:09:42,600
And that's it. That will give you the output of that function.

90
00:09:42,600 --> 00:09:52,130
It will give you the cut by estimate. However, we still need the P-value on the test for the cut by estimate and also the McNamara's test.

91
00:09:52,400 --> 00:09:56,240
So this is just part of the question. This will only give you the estimate.

92
00:09:58,090 --> 00:10:01,170
Any questions so far? Okay.

93
00:10:02,310 --> 00:10:13,350
So if we run that lot, if we run those lines, the first thing you will notice is that the table that we created would look something like this,

94
00:10:13,350 --> 00:10:25,350
which is expecting it to wait for tables that we had before. And then part of the old part of the board, part of the output would be the capacity.

95
00:10:25,600 --> 00:10:29,600
So here we have the capacity. The estimate is in the middle.

96
00:10:29,620 --> 00:10:32,390
Just make sure you know what is that estimate you've in them.

97
00:10:32,970 --> 00:10:41,280
And then here we have the lower bound for the 95% confidence interval and I have the upper bound for the 95% confidence level.

98
00:10:41,610 --> 00:10:50,550
However, as you may notice here, we don't have neither the test statistic, the P-value or the McNamara's test.

99
00:10:51,300 --> 00:10:56,970
So to have both of those things now, we need to run some more.

100
00:10:58,250 --> 00:11:03,140
Okay. So. In the library.

101
00:11:03,200 --> 00:11:11,810
I r r there's a function that is called proper, and then the number of second capacitor that will give us the estimate.

102
00:11:12,170 --> 00:11:21,620
And also as to space. However, the parameters that these function receive are so the parameter.

103
00:11:21,650 --> 00:11:30,080
Yeah, the data. But this function receives a supplement that is not the same as the two by two tables that we construct before.

104
00:11:30,440 --> 00:11:36,379
It's something that we call table in a long format. So before running this code,

105
00:11:36,380 --> 00:11:46,070
I need to make sure my two table is transformed into a long format table so I can actually positive correct for my into this function.

106
00:11:46,340 --> 00:11:48,500
And that's what I'm doing here at the top.

107
00:11:48,950 --> 00:11:59,359
So I'm using one purpose that is call it tools that has this function s on table that would create instead of the two by two table,

108
00:11:59,360 --> 00:12:03,500
a long table of like each row would be one individual.

109
00:12:04,430 --> 00:12:14,540
Okay, so I will have 186 rows in that new table and then notice up to these new table, I'm calling it diabetes.

110
00:12:14,690 --> 00:12:17,150
Diabetes, though, in the black individual.

111
00:12:17,510 --> 00:12:28,190
And then when I run this second function proper, when I pass instead of the two white to table, likewise these new tables I created diabetes,

112
00:12:28,190 --> 00:12:38,870
got individual, and then if we run that line, we will get not only the estimated but also the test statistic and the feedback.

113
00:12:39,380 --> 00:12:44,300
Does that make sense? Any questions so far?

114
00:12:46,780 --> 00:12:53,620
Okay. So if we run this code, our table would look something like this.

115
00:12:53,920 --> 00:13:02,020
So our table now, it's instead of a two way two table, it's a table where each row represent each subject of our sample.

116
00:13:02,260 --> 00:13:03,549
So, for example, subject,

117
00:13:03,550 --> 00:13:14,680
was this that positive in the or out of context and also positive in the standard blood test and so on and so forth until the 188 subjects.

118
00:13:15,100 --> 00:13:20,980
And then the output of that couple second function would look something like this.

119
00:13:21,580 --> 00:13:26,049
So here I have the by estimate, which is the same as before it is used.

120
00:13:26,050 --> 00:13:27,370
I'm using a different function.

121
00:13:27,760 --> 00:13:36,790
The advantages of using this function is that not only I have the cup, I have the capacity, but I also have the test, the statistics,

122
00:13:37,300 --> 00:13:46,210
the statistic associated with the null hypothesis cut by statistic equal to zero, and then the p value associated associated to such test.

123
00:13:47,050 --> 00:13:53,300
Does that make sense? Okay. So if you are using source code is very short.

124
00:13:53,420 --> 00:13:59,450
If you are using are you actually have to do a little bit of more of more coding here.

125
00:14:00,380 --> 00:14:03,740
Okay. Oh, yes.

126
00:14:04,070 --> 00:14:07,070
And then just find out here the true value here is zero.

127
00:14:07,340 --> 00:14:13,639
That doesn't mean that the actual P value is 0.00 is just that is very, very, very small.

128
00:14:13,640 --> 00:14:17,480
That approximates to zero. But I mean, that's just a side note.

129
00:14:18,590 --> 00:14:26,840
Okay. And then notice on here we have this is the first to spot the stick associated with the null hypothesis bias.

130
00:14:26,900 --> 00:14:31,680
It's equal to zero, but none like nowhere in this output.

131
00:14:31,730 --> 00:14:34,910
We have the McNamara's McNamara best.

132
00:14:35,090 --> 00:14:38,240
Right. So we need another code for that.

133
00:14:38,660 --> 00:14:41,750
So the code in our would be ambitious.

134
00:14:41,780 --> 00:14:51,710
These will be for the McNamara set says first I'm using one another library here for our companion.

135
00:14:52,220 --> 00:14:58,370
I didn't know. I look at this code. Remember that before running library are a companion.

136
00:14:58,610 --> 00:15:00,830
You have to install the package first.

137
00:15:01,130 --> 00:15:10,820
So before we are line of code and make sure you have one line that is install those packages and then in parentheses the name of the library.

138
00:15:11,150 --> 00:15:18,230
And then call the library into your script. And then for the McNamara's class, I have diabetes, though.

139
00:15:19,280 --> 00:15:24,439
Oh, I'm using the function Maguire aspect and then the file that there will be diabetes.

140
00:15:24,440 --> 00:15:30,379
Diabetes, the data, which is the two by two table, not the long format.

141
00:15:30,380 --> 00:15:33,800
The table with each row its one subject.

142
00:15:33,830 --> 00:15:37,990
No, this is the two white two table that we created, Betty, at the beginning.

143
00:15:39,530 --> 00:15:42,860
And then that's it. We run this code.

144
00:15:43,670 --> 00:15:55,520
The output would look something like this. Here we have the test statistic associated to the test and then the p value associated of that test.

145
00:15:57,200 --> 00:16:04,710
Any questions so far? Okay.

146
00:16:04,720 --> 00:16:08,440
Good. Okay. And now.

147
00:16:11,350 --> 00:16:19,810
Now we're going to switch globe and we are going to talk about odds ratio when I'm comparing light to test.

148
00:16:20,290 --> 00:16:30,160
So let's say I want to answer the following question What is the odds ratio for diagnosing diabetes?

149
00:16:30,550 --> 00:16:35,560
Comparing the oral glucose test to the standard blood test.

150
00:16:35,800 --> 00:16:42,430
So he's not a regular odds ratio because, you know, we don't have like to see some treatment and control we have to test.

151
00:16:42,790 --> 00:16:49,150
And in this case, I want the odds ratio for diagnosing diabetes, comparing one passed over to the other.

152
00:16:51,120 --> 00:16:53,160
So to answer this question,

153
00:16:53,640 --> 00:17:03,810
the first thing you should notice is that even though like this looks like a very wide way to table the alteration of this thing,

154
00:17:04,410 --> 00:17:15,180
I mean, if you do it like 31 times 135 divided by 1614, that's not the answer.

155
00:17:15,750 --> 00:17:25,860
Okay. But since, you know, that right equation doesn't work in this like in the question that I'm trying to ask here.

156
00:17:26,640 --> 00:17:32,970
So if that doesn't work, how can we estimate that such alteration.

157
00:17:33,600 --> 00:17:37,500
So we are not we are going to do like a little bit of a trick.

158
00:17:38,250 --> 00:17:49,420
Let us think about diabetes, like having diabetes so that a diabetes equals positive in both gets to be the outcome on each test to be the predictor.

159
00:17:49,470 --> 00:18:00,090
Okay. So yes, let's think about like instead of that to white to table diabetes being like having diabetes, it's my outcome.

160
00:18:00,150 --> 00:18:04,890
And then to predict their outcome, I have to test the oral test and the glucose test.

161
00:18:05,160 --> 00:18:07,980
That's how we are going to like switch the interpretation.

162
00:18:08,370 --> 00:18:17,730
And then based on that, I want first to estimate the appropriate odds ratio, then estimating 95% confidence interval,

163
00:18:18,030 --> 00:18:26,470
estimate the p value of that odds ratio and then provide a summary sentence of everything we did so that what we are going to do it.

164
00:18:27,670 --> 00:18:34,350
Okay. So here, this is where it's a little bit complicated, but.

165
00:18:39,240 --> 00:18:45,030
Oh. So. This is our regular Twitter table that we have been working with.

166
00:18:45,300 --> 00:18:53,440
So instead of working with this table, I'm going to create up to two tables for every subject in the sample.

167
00:18:53,460 --> 00:19:00,390
So instead of having one subjective table, I'm going to have 186 two by two table.

168
00:19:00,810 --> 00:19:06,360
That's the first thing. How am I going? How what are all those 186 tables?

169
00:19:06,690 --> 00:19:09,960
So let's just focus on the first one here.

170
00:19:13,910 --> 00:19:24,920
So we said before, let's think of having diabetes testing positive and testing positive for each stage of diabetes of the outcome.

171
00:19:25,220 --> 00:19:32,780
So here in this two by two table, these roles, the roles which would represent like diabetes.

172
00:19:35,790 --> 00:19:40,040
So my. My outcome.

173
00:19:40,520 --> 00:19:46,460
And then the. Oh, I'm sorry. The roads, which would be diabetes.

174
00:19:46,700 --> 00:19:50,000
And then the columns would would be each best.

175
00:19:50,270 --> 00:19:55,460
So I have one column for the oral test and then another column for the standard test.

176
00:19:55,940 --> 00:20:01,010
That's it. So all of my 186 table looks like that.

177
00:20:01,130 --> 00:20:16,190
Look like that. Okay, so now if I look at this 31 people, this 31 people tested positive for diabetes using the oral test and the glucose test.

178
00:20:16,640 --> 00:20:21,140
So translated, translating that into my new two by two table.

179
00:20:21,380 --> 00:20:26,140
That would mean that for the oral test they tested positive.

180
00:20:26,150 --> 00:20:30,530
So I have a one here and for the standard test they tested also positive.

181
00:20:30,540 --> 00:20:34,490
So I have one here and that's how I constructed this table.

182
00:20:34,880 --> 00:20:38,120
And this table is the same for 21 subjects.

183
00:20:38,480 --> 00:20:45,650
So that's why you here see like up 31 here, which would correspond for this one.

184
00:20:49,020 --> 00:20:57,350
Does that make sense? Okay. So for the second table, interpretation is very similar.

185
00:21:00,160 --> 00:21:06,230
So remember. Here. I have diabetes, whether they tested positive or negative.

186
00:21:06,570 --> 00:21:10,050
And then here I have my true test or this time a standard test.

187
00:21:10,440 --> 00:21:14,960
So for these six people here. We know that.

188
00:21:16,400 --> 00:21:20,750
For these six people for the oral glucose, this they tested positive.

189
00:21:21,200 --> 00:21:24,650
So that means that oral I'm positive will be one here.

190
00:21:24,830 --> 00:21:30,260
Right. And then I also know that for the standard test, they tested negative.

191
00:21:30,650 --> 00:21:34,730
So that means that for a standard unmade up, if I would have a one here.

192
00:21:35,390 --> 00:21:39,830
Does that make sense? Right.

193
00:21:41,560 --> 00:21:46,510
I bet that's exactly the same interpretation for the other two tables.

194
00:21:48,070 --> 00:21:53,020
Any question of like these new 186 two by two tables.

195
00:21:54,960 --> 00:22:01,170
Okay. So having that like in mind, how do we code that?

196
00:22:01,410 --> 00:22:09,140
So if you're using swords, the first thing we're going to do is to create a two by two table, the standard two by two table.

197
00:22:09,150 --> 00:22:12,810
So we are going to create these tables here to the left.

198
00:22:13,410 --> 00:22:17,820
To your left, yes. So that will be very simple.

199
00:22:18,570 --> 00:22:23,370
We use data and then I have four variables.

200
00:22:23,700 --> 00:22:28,650
The result of the test of the standard test, the count, the number of people and weight.

201
00:22:28,950 --> 00:22:34,260
Just because when I'm using French, it always needs a weight viable.

202
00:22:35,220 --> 00:22:38,820
Okay. And then here.

203
00:22:39,750 --> 00:22:48,630
What I'm doing here. It's based on a standard two by two table.

204
00:22:48,900 --> 00:22:58,440
I'm creating the creating like the 186 two by two, table one for each subject in my sample.

205
00:22:58,890 --> 00:23:05,220
So scenes are a lot of tables. What I'm doing source is just create a loop.

206
00:23:05,490 --> 00:23:12,210
But would do it for me. So this is the part though, and it would like create that loop that would do it for me.

207
00:23:12,510 --> 00:23:18,780
Okay. And then what I'm doing here is first notice that my new data set is called Diary.

208
00:23:19,440 --> 00:23:24,840
And that's important because that's the one that will be using when I'm running the prospect.

209
00:23:24,990 --> 00:23:28,410
Notice that here I'm using diabetes store instead of diabetes.

210
00:23:28,680 --> 00:23:33,270
So it's like this 180 62m 86 table.

211
00:23:34,050 --> 00:23:45,840
Okay. And here I'm just creating the 186 de also inside because look, what I'm doing is behind what I'm doing is.

212
00:23:45,960 --> 00:23:49,820
So I have this from my table. There you see what I'm doing here.

213
00:23:49,830 --> 00:23:57,450
It's it's going to read each of these lines and what it's going to do with 31 times is going to create a table that has one

214
00:23:57,450 --> 00:24:04,890
line and then six lines is going to create a table that was one zero and then 14 times zero one and so on and so forth.

215
00:24:05,160 --> 00:24:07,319
So it's reading that to white to table,

216
00:24:07,320 --> 00:24:15,780
and then inside the loop it reads each line and then creates as many as I have here with this character section.

217
00:24:16,140 --> 00:24:19,190
So that's why we are doing okay.

218
00:24:20,640 --> 00:24:32,570
And then. Well, I'm like, okay, once I create this loop, then I'm just going to run a across track using these every store.

219
00:24:32,750 --> 00:24:42,139
And notice that here I have like a three, three, four, three variable table, which is the idea because instead of having one,

220
00:24:42,140 --> 00:24:51,050
two by two, I have 180 and then criteria which will be my test, either standard or I'll test.

221
00:24:51,380 --> 00:24:57,720
And then the response would be like either having diabetes or no which insights and coding everything as one zeros.

222
00:24:58,130 --> 00:25:02,120
I'm meant to assess the odds ratio here.

223
00:25:02,120 --> 00:25:11,990
I'm using the Mother Hazel estimate, so it's like CMH and that would be the odds ratio of that of.

224
00:25:13,330 --> 00:25:21,910
Diagnoses diagnosing diabetes of oral tests compared to a standard the odds ratio of that.

225
00:25:23,170 --> 00:25:27,240
Any questions so far? Okay.

226
00:25:28,690 --> 00:25:37,450
So once you run that second line of code, it's the same output that you guys work on last homework.

227
00:25:38,290 --> 00:25:42,040
So here I'm interested in the Roald Dahl Association.

228
00:25:42,070 --> 00:25:47,690
This would be the basis for basic and this would be the height,

229
00:25:47,960 --> 00:25:55,240
the P-value and then for the alteration, which is like my question of interest, I have the month.

230
00:25:55,240 --> 00:26:02,890
Okay, so this is the value of the alteration and this is the 95% confidence interval of such alteration.

231
00:26:03,250 --> 00:26:13,780
Remember the least it's the odds ratio of diagnosing diabetes of oral test compared to a standard glucose test.

232
00:26:17,610 --> 00:26:21,600
Any questions so far? All right.

233
00:26:22,740 --> 00:26:30,270
So now the question is, how do we do it in art? And I think it's a little bit simple because we can work with back artists.

234
00:26:30,270 --> 00:26:37,800
We cannot do that in space. So we are going to do something very similar, as we did in the past homework.

235
00:26:38,280 --> 00:26:42,870
I'm going to create vectors for each of the different cells.

236
00:26:42,960 --> 00:26:48,180
So remember that these cells are the A, these are what we call BE.

237
00:26:48,240 --> 00:26:51,990
These are what we call C and D. This is A.

238
00:26:52,200 --> 00:26:56,580
This is V. This is C and this is the and so on and so forth.

239
00:26:56,910 --> 00:26:58,770
And what I'm going to do is, for example,

240
00:26:58,770 --> 00:27:11,070
I want to create a better a I I'm calling a vector a I that has all of the different values that in helping the a sense.

241
00:27:11,580 --> 00:27:19,440
So what value say having the A cells. I have a one for 31 people so my vector should be.

242
00:27:21,010 --> 00:27:25,600
One. One, one. And these. Da da da da da.

243
00:27:26,560 --> 00:27:30,370
31 times. You follow me in there? Okay.

244
00:27:30,760 --> 00:27:35,380
And then after that, 31 people. I have a one for six people.

245
00:27:35,920 --> 00:27:41,500
So I should be 11..46 people.

246
00:27:42,700 --> 00:27:54,220
And then after these six people that I have here, my better half of 044, I said Qatar, which is 14 in the Spanish, I'm sorry.

247
00:27:55,360 --> 00:28:04,420
So it has a zero for 14 people. So next my a vector should have 000 14 times.

248
00:28:07,520 --> 00:28:12,090
And then. It has a04 135 people.

249
00:28:12,540 --> 00:28:19,650
So it should be sero zero zero 135 times.

250
00:28:22,000 --> 00:28:27,460
Okay. Does that make sense? Okay. So that's why you're here.

251
00:28:27,550 --> 00:28:32,290
When I'm creating the a vector I have will see to create a factor.

252
00:28:32,290 --> 00:28:39,010
I'm here. I'm using rep, which is just the same number, repeated and repeated number of times in this case.

253
00:28:39,280 --> 00:28:42,680
I want this 137 times. Why?

254
00:28:42,760 --> 00:28:48,610
Because if I look at the construction of the vector and I have 31 ones,

255
00:28:48,730 --> 00:28:55,960
followed by six number ones, that means that my first 27 positions of that cycle would be a one.

256
00:28:56,230 --> 00:29:05,530
So that's what I have here. And then all of these are serious, which b, I need 14 plus 135 zeros.

257
00:29:06,070 --> 00:29:11,330
Does that make sense? Any questions so far?

258
00:29:15,180 --> 00:29:24,780
Okay. Important. Do you understand how to construct the B c are the vectors and the vectors here according to the stables.

259
00:29:29,350 --> 00:29:35,500
Okay. So let's just do one more time. One oak for the B vector.

260
00:29:36,040 --> 00:29:42,100
So I want a better that has all of the B cells that I have here.

261
00:29:43,060 --> 00:29:47,230
So my bet that should have stuck that we are one for 31 people.

262
00:29:48,550 --> 00:29:51,730
So I have I should have one, one, one.

263
00:29:54,430 --> 00:29:59,980
31 times. And then followed by a zero.

264
00:30:00,920 --> 00:30:06,170
Six times. So 000.

265
00:30:07,780 --> 00:30:11,800
Six times. Followed by a one.

266
00:30:12,250 --> 00:30:27,310
14 times. And then finally followed by a C row, 135 times.

267
00:30:34,990 --> 00:30:43,370
And that's it. Once we have created all of those vectors, then we do the exact same thing that we did in last homework.

268
00:30:43,830 --> 00:30:46,830
I'm using the metaphor library.

269
00:30:47,160 --> 00:30:55,500
I'm running the I'm using the function are a dot in age for the mother Hazel a statistic.

270
00:30:55,950 --> 00:30:59,790
So it's exactly the same code as you used before. It is just constructing that table.

271
00:31:00,030 --> 00:31:11,490
What is very hard in this case, once I run that line, I have the odds ratio estimate on the confidence interval.

272
00:31:13,790 --> 00:31:17,690
Correct. Okay. Any questions so far?

273
00:31:19,860 --> 00:31:25,710
Yes. Do you have to do that results alone?

274
00:31:25,930 --> 00:31:30,510
We didn't know if that might. Only one time in your computer.

275
00:31:30,620 --> 00:31:33,810
So as long as you already run it, that should be fine.

276
00:31:34,990 --> 00:31:46,750
This was the source code of the odds ratios and the long odds still are the know it's in the odds ratio scale and we just see.

277
00:31:47,260 --> 00:31:51,190
Yes. So it will be beats one here. Thank you.

278
00:31:54,210 --> 00:31:59,940
Okay. And then finally, just a semblance of whatever we need in this plan.

279
00:32:00,180 --> 00:32:04,110
So it would be something like the odds ratio estimate is.

280
00:32:04,110 --> 00:32:12,720
And then the value that we have, we are 95% confidence interval of the values that we become of square test is 3.2.

281
00:32:12,770 --> 00:32:16,800
With one degree of freedom, remember that chi squared pass.

282
00:32:17,490 --> 00:32:25,320
If you run this line it should give you the chi square pass and it says it's in the General Association line.

283
00:32:25,560 --> 00:32:31,120
Okay. So it should be in the output whenever you run those functions.

284
00:32:31,630 --> 00:32:37,660
So the Chi Square Press is 3.2 with one degree of freedom and the corresponding p value is.

285
00:32:38,620 --> 00:32:43,520
In this case, approximately 7%. Therefore, there is marginal.

286
00:32:43,540 --> 00:32:59,380
And why am I saying marginal here? Because normally we use a 5% significance level on if I use of 5% significance level with this p value.

287
00:32:59,710 --> 00:33:02,710
I would fail to reject general hypothesis. Right.

288
00:33:03,040 --> 00:33:11,989
But that is very close to 5%. As we all know, 5% is a rule sometimes is five, some 27 is that it depends on the data.

289
00:33:11,990 --> 00:33:17,710
The new half of this of the investigator of the publication of the journal, it depends on a lot of things.

290
00:33:17,980 --> 00:33:22,060
So that's why we are saying marginal here, that just because this is very close,

291
00:33:22,240 --> 00:33:27,850
if this will be like, I don't know, 0.2, 0.35, I mean, that's not moderate.

292
00:33:28,120 --> 00:33:31,570
That's just very, very far from the 5% line that we draw.

293
00:33:32,170 --> 00:33:40,299
Therefore, there is marginal evidence that the odds of diagnosing diabetes via the oral glucose test is lower,

294
00:33:40,300 --> 00:33:49,150
lower because that number is less than one than the odds of diagnosing the lot of standard test one the two tests these great.

295
00:33:49,690 --> 00:34:01,420
But in more general aspects, we fail to reject the null hypothesis at a 5% level and cannot conclude that there is a significant difference.

296
00:34:01,760 --> 00:34:08,530
Okay. Like statistically speaking, we fail to reject for the amount of data that we have.

297
00:34:08,800 --> 00:34:12,520
We cannot conclude that there is a significant difference between.

298
00:34:17,480 --> 00:34:21,380
Between diagnosing diabetes with either of the two tests.

299
00:34:24,250 --> 00:34:30,380
Any questions so far? Okay.

300
00:34:30,390 --> 00:34:43,140
Good. So with this, you can solve problem one completely, entirely and then problem to its IOC course, which we already covered last week.

301
00:34:43,530 --> 00:34:47,840
And then problem three is logistic regression that we are going to do next week.

302
00:34:47,850 --> 00:34:51,850
Okay. So right now, you can fully complete problem one.

303
00:34:52,620 --> 00:34:56,880
I'll be here if you have questions. I also have office hours right after this.

304
00:34:57,900 --> 00:35:01,530
So did you have questions? Just let me know, okay?

305
00:35:01,980 --> 00:35:06,370
Yes. It's not for me.

306
00:35:07,450 --> 00:35:10,380
It's like advised to check to see if I can.

