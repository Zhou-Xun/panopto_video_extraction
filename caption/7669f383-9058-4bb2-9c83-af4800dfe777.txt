1
00:00:01,050 --> 00:00:12,620
So now have. 24 on the 1st of November.

2
00:00:12,630 --> 00:00:19,140
So that week might not in class do the submission.

3
00:00:19,350 --> 00:00:29,760
So we're talk about the problem today because that needs a little bit of explanation and probably give a little bit.

4
00:00:29,880 --> 00:00:38,380
And I think. I think it's.

5
00:00:40,930 --> 00:00:45,490
This meeting minds this. All right.

6
00:00:45,580 --> 00:00:51,330
So food insecurity.

7
00:00:58,020 --> 00:01:01,530
So the most important thing, mark your calendar.

8
00:01:02,160 --> 00:01:15,210
December seven would do the second midterm and then in each.

9
00:01:15,420 --> 00:01:20,520
This is the homework for there will be one more or more that will be graded.

10
00:01:22,320 --> 00:01:27,540
Think homework six again that will be in some midterm from the previous year.

11
00:01:30,630 --> 00:01:34,860
Because of that, we're all done.

12
00:01:39,510 --> 00:01:50,190
Questions, comments or not, let's continue our journey in whole song process.

13
00:01:51,090 --> 00:01:57,070
So last time we gave that, that's the nation, of course, on process.

14
00:01:57,090 --> 00:02:03,060
So, you know, I think this is a way how we study continuous time.

15
00:02:03,420 --> 00:02:06,980
Stochastic process is usually the two paths one.

16
00:02:07,710 --> 00:02:14,370
The first part is about some global properties and conventions, including this is a counting process.

17
00:02:14,370 --> 00:02:20,760
So in zero equal to zero, let's define the state space and then the initial condition.

18
00:02:21,510 --> 00:02:31,499
And then there are two global properties related to or similar to the Markov property.

19
00:02:31,500 --> 00:02:36,809
And then the homogeneous, I would just say homogeneous Markov property,

20
00:02:36,810 --> 00:02:43,740
one has independent increment and then stationary increment and then the rest of these

21
00:02:43,830 --> 00:02:51,300
there are two more assumptions so related to how we define the marginal distribution.

22
00:02:51,480 --> 00:02:55,440
And then each one H goes to zero, right.

23
00:02:57,240 --> 00:03:04,140
Is that there are some multiple ways to define this basic idea is y you take each close to zero,

24
00:03:04,200 --> 00:03:18,850
the probability can be approximated using a simple in your functions and especially for the probability of h zero and this last page.

25
00:03:19,320 --> 00:03:22,440
So H so I like you to think of, you know,

26
00:03:22,440 --> 00:03:34,889
this is a fully defined probability distribution for such a random power of one h goes to zero and that's the probability of h equal to one km,

27
00:03:34,890 --> 00:03:39,790
h, lots o, h and then so on.

28
00:03:39,810 --> 00:03:47,220
So force. You can think of every individual values for an h kind of they are fully specified

29
00:03:47,790 --> 00:03:54,570
using this type of approximation and following that with this five assumptions.

30
00:03:56,680 --> 00:04:00,910
We last time derived the marginal distribution of an.

31
00:04:03,660 --> 00:04:13,930
So this is of course, our property. So the way we do it, it's not important for you to solve the differential equations,

32
00:04:13,930 --> 00:04:19,090
but it's important for you to understand how this differential equation is set up.

33
00:04:19,660 --> 00:04:30,790
So the strategy we use so generally can be characterized by this diagram so that you have the H and then the T.

34
00:04:30,880 --> 00:04:37,360
So this is on the timeline. So you are trying to relate an T plus H.

35
00:04:38,620 --> 00:04:45,220
So that will be the red, the variable at this point and related back to energy.

36
00:04:46,870 --> 00:04:52,240
And then the way so there is a there is a name for this type of the strategy.

37
00:04:52,280 --> 00:04:55,690
This is a call for a core member of forward equation.

38
00:04:56,110 --> 00:05:02,140
It's actually for the differential equation by drawing this diagram and trying to relate.

39
00:05:02,290 --> 00:05:06,220
And T plus h and t1h goes to zero.

40
00:05:06,670 --> 00:05:12,190
Right. I'm not going to repeat all these derivations by the end of the day.

41
00:05:12,610 --> 00:05:19,030
Yeah, we got a set of differential equations and we solve that.

42
00:05:19,240 --> 00:05:23,370
They gave us the marginal distribution of the individual run.

43
00:05:23,470 --> 00:05:31,900
The variable one t was distributed. So that's pretty much the summarize to the last class.

44
00:05:32,680 --> 00:05:37,010
So it's following that.

45
00:05:38,230 --> 00:05:43,660
So what we look at does stochastic process. So there is always two components, right?

46
00:05:43,690 --> 00:05:50,110
One is you look at the from the state space perspective, you look at that this is a counting process.

47
00:05:50,110 --> 00:06:01,540
So you're interested in another T, so the T is fixed and then you ask the question, the number of the other events occurring before.

48
00:06:02,290 --> 00:06:05,770
So that this is a kind of a state space question.

49
00:06:06,760 --> 00:06:13,270
You kind can flip the the problem around and ask from a random time perspective.

50
00:06:13,330 --> 00:06:18,850
Right. So one is the first that you had occurred. This is the same process.

51
00:06:18,860 --> 00:06:22,630
It's just different angles to look at the same problem.

52
00:06:22,640 --> 00:06:28,030
So you have two. So those two things are correlated or some in some way are equivalent.

53
00:06:28,450 --> 00:06:39,390
So the. So generally for continuous time, stochastic process, we are also interested in asking a question from the perspective of random time.

54
00:06:40,540 --> 00:06:52,060
So this is called that is the third part of the entire arrival and wait time distribution.

55
00:07:01,510 --> 00:07:06,290
So let's define the T one. So again, this is the same process.

56
00:07:06,310 --> 00:07:10,000
If you do a simulation, this is the same simulation.

57
00:07:10,000 --> 00:07:15,320
If you waiting for let's say, waiting for a bus, you know,

58
00:07:15,450 --> 00:07:23,440
you can usually curious about what the arrival time of that bus or but the waiting time for the bus.

59
00:07:23,770 --> 00:07:31,120
But if you look at the overall like the bus arrival event in the in the same in the same day or

60
00:07:31,120 --> 00:07:36,339
in the in the week are thinking about that you can formulate the problem as a counting process,

61
00:07:36,340 --> 00:07:44,040
right? By this march of time, how many busses arrive at this station?

62
00:07:44,050 --> 00:07:51,090
So let's define t one is the wait time lets you find t is a general one this time.

63
00:07:51,490 --> 00:08:07,990
So this is the waiting time or the interval we might be doing on minus one, the event and the frequency.

64
00:08:12,390 --> 00:08:19,670
So if I have a tier one that's represented the the the first the boss, the waiting time from your time zero.

65
00:08:19,680 --> 00:08:23,880
So you're going to specify a time in zero and that's fixed.

66
00:08:24,000 --> 00:08:34,980
So there's a waiting time for the first event to occur. Does the T two well represent on the waiting time between the first and second events?

67
00:08:35,100 --> 00:08:42,629
Right. So just look at this. This one is going to be a different way to partition up the timeline.

68
00:08:42,630 --> 00:08:45,630
So you start from zero and there's this t one.

69
00:08:46,200 --> 00:08:54,900
The next event occur and the T one plus t two, but the interval here is T2 and then so on and so forth.

70
00:08:55,350 --> 00:09:06,510
So the difference between this diagram, under the diagram we draw over there is we can see there the t one is a random variable, right?

71
00:09:07,560 --> 00:09:16,320
It's random. And now we want to know its distribution under the assumption of course on process it must induce some sort of a wait time.

72
00:09:16,500 --> 00:09:24,750
Right. It has to be because the nature of the process or the the random mechanism doesn't change.

73
00:09:25,380 --> 00:09:29,430
It's just different ways to look at the same problem. So keep that in mind.

74
00:09:30,090 --> 00:09:36,570
And then that perspective is important because if you know there such a relationship exists,

75
00:09:37,020 --> 00:09:41,220
so you have to find out what they are, where they are exactly are.

76
00:09:42,350 --> 00:09:44,550
And I know that's not hard.

77
00:09:49,290 --> 00:10:01,079
So for example, let's say t one if you trying to study t one so you know t one will be a non negative, not necessarily integer anymore.

78
00:10:01,080 --> 00:10:04,800
The negative real number only has a distribution.

79
00:10:05,130 --> 00:10:12,930
And then from the distribution theory, if you know something like even t one last time or equal to T,

80
00:10:14,100 --> 00:10:18,440
let's say just because it's continuous, let's just say he wasn't.

81
00:10:18,450 --> 00:10:26,640
I saw less than t, so that means what? So the t one beef occurred before affects the marker t.

82
00:10:27,940 --> 00:10:36,580
Right. So the key idea is can you write an equivalent event in the state space?

83
00:10:39,340 --> 00:10:46,390
So we're going to use the same parameter. Does that imply what does it say about an T?

84
00:10:47,980 --> 00:10:52,340
So if T one occurred before time t that.

85
00:10:52,340 --> 00:11:04,080
And we have to be. Say it again.

86
00:11:05,190 --> 00:11:10,380
Speak up. I cannot speak her one. Yes.

87
00:11:11,880 --> 00:11:15,420
Not necessarily equals one. Right. It must be greater or equal to one.

88
00:11:15,510 --> 00:11:22,110
So this is the gender. So if this one is true t one, you know, the first given before t then you know,

89
00:11:22,410 --> 00:11:28,500
at a time t the number of events occurred must be greater or equal to one.

90
00:11:29,070 --> 00:11:37,500
Vice versa. If you know 80 is greater or equal to one, a mass imply t one less than or less than t.

91
00:11:37,560 --> 00:11:40,920
While you could put that in force, there actually doesn't matter.

92
00:11:43,500 --> 00:11:46,410
If you think about this continuous on the whole thing.

93
00:11:46,800 --> 00:11:56,150
So this equivalency is sufficient for us to figure out the distribution for the random inter arrival time.

94
00:11:56,160 --> 00:12:01,229
Because if we say the problem we are trying to figure out you want less are equal to

95
00:12:01,230 --> 00:12:07,410
T and then because of this relationship this is a truly the key and there's no map.

96
00:12:07,410 --> 00:12:16,740
It's just construct the equivalency of the events until we are one.

97
00:12:17,100 --> 00:12:19,820
And then this one is pretty simple, right?

98
00:12:19,830 --> 00:12:37,350
So because we know and he is Poisson distributed and this is equal to probability zero button this gave us one minus E to the negative lambda.

99
00:12:40,620 --> 00:13:00,000
And as you may already recognize, this one gives the the CDF alpha continuous distribution which is saying that he one is the exponential lineup.

100
00:13:00,540 --> 00:13:07,560
So the way to see it you could do the differentiation on the and differentiated this of the CDF.

101
00:13:08,250 --> 00:13:18,060
I give you a the T, y equals T and then the density was clearly will be along the E to the negative lambda t so that is.

102
00:13:20,220 --> 00:13:23,820
Exponential distribution. So everything got figured.

103
00:13:23,820 --> 00:13:27,450
All of faith is simply about the logic here.

104
00:13:33,420 --> 00:13:39,050
Right. Any questions? So that does that that's be straightforward.

105
00:13:39,070 --> 00:13:46,170
But the key thing is. Well, I mean, this may looks trivial at this point.

106
00:13:46,590 --> 00:13:56,530
A lot of most difficult problems is continuous time, stochastic process related to our ability to establish this equivalency.

107
00:13:57,400 --> 00:14:07,310
All right. So that's a key thing for the saying at the top of the hospital, though, as you mentioned, the first the whole thing.

108
00:14:13,340 --> 00:14:19,460
All right. So one, this is this is a just a marginal T to what about T two?

109
00:14:19,580 --> 00:14:27,410
So that's the waiting time between this between this the first and the second time.

110
00:14:28,310 --> 00:14:32,270
42. So 42.

111
00:14:32,270 --> 00:14:36,890
It's a bit more complicated.

112
00:14:37,430 --> 00:14:41,989
So we got to figure out the marginal distribution. That's probably not the issue.

113
00:14:41,990 --> 00:14:49,970
But we're also interested in the relationship, especially the dependency or independent relationship.

114
00:14:50,360 --> 00:14:53,840
T t to our. T one key to independent.

115
00:14:55,080 --> 00:14:59,700
Or they are completely independent. Right. So this is the thing.

116
00:15:02,010 --> 00:15:06,750
We should do it without any assumption, pre assumption that he wanted to.

117
00:15:09,990 --> 00:15:15,450
There's not any correlation structure or their independence, which is do it in the general way.

118
00:15:15,720 --> 00:15:26,760
So let's do this. Let's do probability two I start equal to he conditional on we want to ask.

119
00:15:29,340 --> 00:15:37,540
The reason of doing this is because there seems to like natural relationship between the two things.

120
00:15:37,560 --> 00:15:46,170
Right. He wanted to and then the other way to do the kind of a motivation two conditional on t1t to

121
00:15:46,410 --> 00:15:51,800
y you know both he want you to you can ask the question in the person in the state space.

122
00:15:52,200 --> 00:16:03,220
Just a second perspective. If t one plus t to so that if you know this one and what is what is the the number of events occur.

123
00:16:03,240 --> 00:16:09,170
Right? So this one considering t one well bring the timeline back to zero.

124
00:16:09,180 --> 00:16:12,569
So that's kind of important perspective for counting process. Yes.

125
00:16:12,570 --> 00:16:16,680
Sorry. Oh, sorry. Oh, no. Okay. That's why.

126
00:16:18,360 --> 00:16:22,370
So there's no harm, basically considered t one you to us.

127
00:16:22,650 --> 00:16:35,340
And then if we find later on, you know, t1t to our independent is just well, the math will tell us if there are independent or not, too.

128
00:16:36,870 --> 00:16:43,019
So how do we consider this then? Well, I mean, again, this will say something.

129
00:16:43,020 --> 00:16:46,320
So if you know t one that I can write the equivalent,

130
00:16:47,880 --> 00:17:04,020
the probability is going to be s less than or equal to t one plus again from counting process perspective t one plus t two as a natural measure.

131
00:17:04,710 --> 00:17:08,010
Right. I mean, that's give you that times zero.

132
00:17:08,370 --> 00:17:13,589
So it's must be true because t two is none negative a real number.

133
00:17:13,590 --> 00:17:16,690
So T one plus t two has to be greater or equal to us.

134
00:17:17,120 --> 00:17:24,540
And at the same time they happen to be less than or equal to s plus three because we have

135
00:17:24,630 --> 00:17:33,120
this condition T to Gladstone equal to T on this one steel conditional on T once or twice.

136
00:17:36,870 --> 00:17:51,430
All right. Again, we do not do exercise like this, but this time there are more information we need to consider.

137
00:17:55,710 --> 00:18:01,290
Then. So we need to consider it.

138
00:18:01,850 --> 00:18:11,929
I mean, you raise this so the random violence we're considering is the following.

139
00:18:11,930 --> 00:18:19,240
But as less than equal to one plus two or less than you point do as a plus t.

140
00:18:21,290 --> 00:18:36,270
Okay. So what this equivalent to. I know.

141
00:18:36,520 --> 00:18:39,940
It's so noisy here.

142
00:18:41,400 --> 00:18:55,590
So one of the things it says is this must be true, as we know, the T one equal to a s.

143
00:18:55,680 --> 00:19:01,960
So this is as equal to as.

144
00:19:02,160 --> 00:19:08,910
And then. And then this is as closely.

145
00:19:11,510 --> 00:19:19,300
Well, what you want to do is a make a statement for this second interval because the second interval is really related to the T two.

146
00:19:19,690 --> 00:19:24,340
Right. So, you know, just a similar argument.

147
00:19:24,910 --> 00:19:31,600
What you can see here is that must be an empty plus as minus an as.

148
00:19:33,380 --> 00:19:46,830
Um. So they at least have one event occurred to make sure the T1 plus T2 is is in this interval.

149
00:19:47,550 --> 00:19:54,300
Right. So there are at least a wiki about occurred in this in this in the second interval here.

150
00:19:54,690 --> 00:19:59,160
So this one less are equal to sorry.

151
00:20:02,040 --> 00:20:14,430
Right. So this is a based on the same argument and you can say, well, there's something.

152
00:20:14,940 --> 00:20:41,130
All right. All right. You know, one or two months or I'm just writing everything into the in the in the in the contained in the state space.

153
00:20:42,900 --> 00:20:49,560
So you have 90 plus. So this is really the key. The second event has to occur before S plus T, that's it.

154
00:20:50,040 --> 00:20:57,470
Right. So this is basically saying the second event e two.

155
00:20:57,510 --> 00:21:01,980
Okay. So t two or less than or equal to T, that's the intertribal time.

156
00:21:01,990 --> 00:21:06,380
That means the second event has to occur before s plus.

157
00:21:06,750 --> 00:21:11,430
That's. That's all. So. So this is a really the benefit of conditioning on those.

158
00:21:11,880 --> 00:21:15,510
But if you look at the right hand side. So these are two events.

159
00:21:15,990 --> 00:21:22,710
One is a statement about this interval blend, plus S minus S.

160
00:21:22,920 --> 00:21:27,030
So that S plus T minus as is this interval.

161
00:21:27,420 --> 00:21:30,900
The second event is really about this interval.

162
00:21:31,710 --> 00:21:38,650
And then you immediately know because the independent increment assumption this two events are independent.

163
00:21:39,410 --> 00:22:05,630
Okay. So what? That. And so we say she'll be right out.

164
00:22:05,690 --> 00:22:14,150
This is going to be known as the Boston PD mindset, unless that's all great or equal to one.

165
00:22:14,630 --> 00:22:21,010
And this is a conditional on. You know, and as.

166
00:22:26,920 --> 00:22:33,610
Right. So the the conditioning part of the t y you go to a s is equivalent to an AC equal to one.

167
00:22:33,640 --> 00:22:39,840
Right. So your air conditioning on, that's now the argument is important there.

168
00:22:39,850 --> 00:22:45,770
These two events are independent. Therefore, this way you watch and pass.

169
00:22:45,940 --> 00:22:50,980
Must be mine. That's that's greater or equal to one.

170
00:22:51,610 --> 00:22:57,070
Again, I'm going to invoke the station or increment.

171
00:22:57,520 --> 00:23:03,099
This implies a probability, so only the interval matters.

172
00:23:03,100 --> 00:23:07,630
S plus T minus S is 90 to 1.

173
00:23:09,550 --> 00:23:16,630
And then this gives us that conditional probability is again the probability.

174
00:23:20,570 --> 00:23:26,740
All right, I got something wrong. So the. Which.

175
00:23:34,020 --> 00:23:40,520
This is supposed to be zero, right? No one.

176
00:23:41,090 --> 00:23:44,899
Okay. There's nothing wrong with this, so I'm just need to write.

177
00:23:44,900 --> 00:23:49,790
This one is greater than zero. And this again.

178
00:23:57,800 --> 00:24:09,430
It's one minus into the long. It's just I mean, it's just a probability to less than 1 to 2.

179
00:24:09,470 --> 00:24:13,100
And so a few things occur here.

180
00:24:13,190 --> 00:24:16,970
Need a bit? We need to digest that a little bit.

181
00:24:17,630 --> 00:24:24,290
So this is supposed to be a conditional distribution, a conditional probability.

182
00:24:24,710 --> 00:24:30,830
But if you look at this left hand side, it has nothing to do with s, regardless the value.

183
00:24:31,320 --> 00:24:37,670
So establish the the t21 and t one are indeed independent.

184
00:24:37,790 --> 00:24:45,500
Because regardless what value of as the distribution of t to this conditional distribution, the t two is invariant.

185
00:24:46,160 --> 00:24:50,480
Right, because it's not the function of s or the distribution.

186
00:24:50,500 --> 00:24:58,340
It's not the function of T one that gives us the first second you want.

187
00:25:02,240 --> 00:25:14,330
Okay. So if that's the case, then this one, this equals probability to less or equal cases.

188
00:25:14,360 --> 00:25:18,150
Greater or. Yes. Unless you go to.

189
00:25:23,160 --> 00:25:24,720
Because of independence.

190
00:25:25,020 --> 00:25:41,630
You we write the conditionals into this unconditional this probability that again says he too is also exponential under distributed.

191
00:25:43,950 --> 00:25:49,830
So the two conclusions both are drawn from this expression.

192
00:25:51,150 --> 00:26:00,660
The key thing is to realize the independence implication from this mathematical form is that the distribution, the conditional probability,

193
00:26:00,660 --> 00:26:08,550
is not a function of s and that you can make argument between 1 to 2 independent and then therefore you actually find.

194
00:26:08,880 --> 00:26:16,610
So not only they are independent, you also find that the marginal CDF in this case and then futures in spite of the.

195
00:26:22,380 --> 00:26:27,280
So not only you can do it one of two or so, this is a that's basically a general way.

196
00:26:27,300 --> 00:26:31,200
So this is what we say without loss of generality. So you can do this.

197
00:26:31,200 --> 00:26:41,580
4384. You can argue every waiting time tie are mutually independent.

198
00:26:42,030 --> 00:26:49,440
And by the same logic you can conclude all of them follow the exponential lambda distribution.

199
00:26:49,950 --> 00:26:53,170
So it's a waiting time distribution, the lump.

200
00:26:53,550 --> 00:27:02,550
So this is a probably not. A surprising conclusion from the distributional theory.

201
00:27:02,560 --> 00:27:07,660
You know, there's a memory loss distribution exponential.

202
00:27:08,230 --> 00:27:20,980
But what is interesting here is this memory loss of waiting time actually leads to a very basic pause on process.

203
00:27:21,280 --> 00:27:30,670
So if I was thinking about random arrival time, that's if there your idea exponential lambda distributed,

204
00:27:31,150 --> 00:27:43,450
then the underlying distribution is actually a poor song distribution if you're thinking about the counting the the corresponding counting process.

205
00:27:45,100 --> 00:27:52,540
Right. The other thing is thinking about this, it's really help you to simulate.

206
00:27:54,830 --> 00:28:04,090
Of course, on process. Right. So in general, it will be very difficult to simulate directly simulating.

207
00:28:06,930 --> 00:28:14,120
As you see, this is not like the discrete stochastic process at all.

208
00:28:14,150 --> 00:28:18,920
So you just simulate x1x2x3y, you have a index.

209
00:28:19,430 --> 00:28:24,919
This one is uncountable. Collection of random variables is impossible.

210
00:28:24,920 --> 00:28:28,300
Almost impossible. Well, I don't need all laws.

211
00:28:28,310 --> 00:28:31,760
It's impossible to simulate an individual. And he's.

212
00:28:35,080 --> 00:28:42,750
But the connection helps you to is you could essentially simulate the change of identity.

213
00:28:43,360 --> 00:28:48,070
Right? Also, empty will be zero. So, you know, until the first event occurs.

214
00:28:48,640 --> 00:28:52,170
But you need to know what the the t the first event occurs.

215
00:28:52,180 --> 00:28:56,350
So that's you can simulate from this waiting time the second week.

216
00:28:56,620 --> 00:29:00,520
So it almost trivial to simulate the stochastic process this way.

217
00:29:00,880 --> 00:29:07,000
That's also why it's important to study the this internal arrival time in.

218
00:29:11,340 --> 00:29:16,650
Given the. In the continuous time stochastic process.

219
00:29:23,980 --> 00:29:27,670
Great. Any questions?

220
00:29:30,780 --> 00:29:50,260
So if not, let's get to the next topic.

221
00:29:51,430 --> 00:29:57,700
I'm going to switch the order a little bit. Just just.

222
00:30:03,350 --> 00:30:07,240
So we just study the entire arrival time.

223
00:30:07,310 --> 00:30:10,700
Let's do this the next.

224
00:30:10,910 --> 00:30:17,780
Well, then, like the lecture, I do that first.

225
00:30:17,960 --> 00:30:27,170
So the conditional distribution of arrival time.

226
00:30:27,950 --> 00:30:31,670
So, no, this is not in for arrival time. This is our arrival time.

227
00:30:32,000 --> 00:30:38,130
So the difference between the entire arrival time, our arrival time is interval time is a relative time.

228
00:30:38,630 --> 00:30:49,620
It's a relative to the previous arrival. And if we say the arrival time, then this is mostly it's the absolute scale.

229
00:30:49,790 --> 00:30:53,090
It's talking about the time zero.

230
00:30:53,540 --> 00:30:59,960
Another question here is a little bit different than the entire arrival time.

231
00:30:59,990 --> 00:31:03,290
We know the interval of time will be exponential distributed.

232
00:31:03,500 --> 00:31:07,600
But in this. Oh, let me just write this.

233
00:31:08,950 --> 00:31:14,080
A rival versus interminable.

234
00:31:15,400 --> 00:31:20,890
Oh, sometimes we call this wait time distribution of internal rivals.

235
00:31:27,670 --> 00:31:31,390
So the arrival time we usually use is here.

236
00:31:32,050 --> 00:31:37,770
And then into our arrival time were usually the notations 22 and so on and so forth.

237
00:31:38,110 --> 00:31:50,680
So there is a relationship so that the S is the event of the arrival time, time of the month event occur.

238
00:31:51,100 --> 00:31:56,200
So that is I want to add a few other.

239
00:31:57,550 --> 00:32:02,590
Sorry. So just like I said, this is the arrival time.

240
00:32:02,620 --> 00:32:12,099
Always it's an absolute always refer to the time zero and into our arrival is a relative random time.

241
00:32:12,100 --> 00:32:17,620
Always refer to the previous arrival event or the previous event.

242
00:32:18,280 --> 00:32:22,930
Okay, so that's just that simple. So.

243
00:32:22,990 --> 00:32:29,020
Well, I think so. If you're interested in marginal, then you can figure this out.

244
00:32:29,360 --> 00:32:39,140
Right. So you have just a bunch of independent exponential random variable, some independent random variable.

245
00:32:39,430 --> 00:32:43,600
So you should know the marginal distribution of arrival time.

246
00:32:44,020 --> 00:32:48,760
Anybody knows what is the distribution of sum of independent exponential.

247
00:32:52,240 --> 00:33:01,549
Very good comment. Yes, it is. Exponential is a special case, of course, but even you don't know, you can figure it out.

248
00:33:01,550 --> 00:33:08,050
All right. So this is sort of that, but this is what I'm trying to say is pretty straightforward.

249
00:33:08,770 --> 00:33:14,800
What are we going to do? What's a little bit different? So this is known, but we're interested in a different question.

250
00:33:17,350 --> 00:33:23,440
We're interested in asking the question like this What is the probability as one?

251
00:33:23,440 --> 00:33:28,030
So in this case, S1 this equals t one by this definition, right?

252
00:33:28,330 --> 00:33:34,450
Because T one is a special in term arrival time corresponding to the previous.

253
00:33:34,840 --> 00:33:41,230
The previous is really time zero. So in this case s one and then t one coincides.

254
00:33:41,590 --> 00:33:52,630
But so that's one is t one. What about this one less than or equal to as given equals one.

255
00:33:54,040 --> 00:34:01,569
So this is a different problem than just ask the unconditional distribution.

256
00:34:01,570 --> 00:34:04,600
That's one less than that's why.

257
00:34:04,630 --> 00:34:15,880
Because this gave you more information because so this is s and then this is right.

258
00:34:15,880 --> 00:34:21,520
As has to be less than equal to. There is some substance.

259
00:34:22,880 --> 00:34:30,280
Otherwise the question may. Well, we usually ask with this condition put in.

260
00:34:34,610 --> 00:34:45,020
You know, it's clear this is different. Just ask the marginal distribution of what is the the s one less or the T one less than s, right?

261
00:34:45,290 --> 00:34:54,589
Because you'll also have some knowledge that the first event occurred before time.

262
00:34:54,590 --> 00:35:06,890
T Yeah, so this condition, well, regardless if you currently see this, this particular condition matters or not, you have to realize at least a from.

263
00:35:07,430 --> 00:35:12,969
Um. From the statement of the problem.

264
00:35:12,970 --> 00:35:15,650
This is different than the marginal distribution, right?

265
00:35:15,670 --> 00:35:22,330
So the same way we tried to figure out what the key to is, we set out the way that's different.

266
00:35:22,540 --> 00:35:25,660
But eventually, it turns out they're independent.

267
00:35:25,990 --> 00:35:32,980
So what I'm trying to say is you've set up the problem different and that you should respect the difference.

268
00:35:33,310 --> 00:35:37,180
And maybe in the end, the things are independent.

269
00:35:37,180 --> 00:35:44,680
Or you can use. You can use the properties of the Poisson process to simplify the secretion.

270
00:35:44,680 --> 00:35:47,980
But for now, you have to treat this as a very different problem.

271
00:35:50,470 --> 00:35:58,660
Okay. So if that's the case, the key, again, it's not necessarily doing mathematics because we have an issue here.

272
00:35:58,930 --> 00:36:03,910
So the RC event, the random event occurred in the random time.

273
00:36:06,580 --> 00:36:14,800
Domain. And then there is the thing we condition is a process domain in the state space.

274
00:36:15,160 --> 00:36:20,810
So you don't necessarily want to deal with the mixture of these two things.

275
00:36:20,830 --> 00:36:30,490
What you want to do is using this those type of equivalence relationship, turn them into the same domain and do that and then solve it.

276
00:36:30,820 --> 00:36:42,070
So the simplest way, I think in most cases you want to turn this into tilt to turn the random time event into a state space event.

277
00:36:42,370 --> 00:36:52,190
Right. And then that's not really hard to do it. So if asked one more time, one less than ass, that must mean something, right?

278
00:36:52,210 --> 00:37:01,340
So that means the first arrival occurred somewhere, right?

279
00:37:01,340 --> 00:37:07,120
Didn't know this. So this is. So as one less than.

280
00:37:07,420 --> 00:37:12,040
As is the same, he won the last one.

281
00:37:13,060 --> 00:37:23,410
It's the same odds as equivalent to and as great or equal to one.

282
00:37:24,480 --> 00:37:29,560
Right. So there is at least a white event occur. That has to be true.

283
00:37:32,760 --> 00:37:44,829
We could actually. So there is whining about it.

284
00:37:44,830 --> 00:37:50,469
But I the same thing. At the same time we have a few holes.

285
00:37:50,470 --> 00:37:54,190
One. Right, so maybe we should.

286
00:37:54,190 --> 00:37:59,320
Right this way. This is a bit.

287
00:38:06,490 --> 00:38:16,210
Right. So. So the goal here is trying to evaluate the both of the events raised because of the conditional probability.

288
00:38:16,270 --> 00:38:20,160
One, we trying to compute the conditional probability we compute the joint.

289
00:38:20,770 --> 00:38:27,240
So what is that, this event. So the best way to do it is thinking about.

290
00:38:30,500 --> 00:38:36,520
And then this is a straightforward one. So that is.

291
00:38:37,420 --> 00:38:43,450
So this one means the first that you have to occur before s.

292
00:38:44,850 --> 00:38:48,120
Right. At the same time until you quote one.

293
00:38:49,720 --> 00:38:56,890
That means what? There is no event. So this is actually a strong assumption added to this.

294
00:38:57,160 --> 00:39:02,790
There is no event occur before. Assante Right.

295
00:39:03,070 --> 00:39:07,580
So let me right this way. That's clear. So it has to be true.

296
00:39:07,600 --> 00:39:16,180
If you turn this into a complete state space description, it has to be true and as equal to one.

297
00:39:16,300 --> 00:39:20,590
So that means by the time as there is why events occur.

298
00:39:21,490 --> 00:39:35,680
Furthermore, the until equal to one t return that s also will require an E -0.

299
00:39:36,670 --> 00:39:41,680
Both are required to compute the margin of sorry, the drawing.

300
00:39:43,330 --> 00:39:50,980
Right. So as not only are they equal to one, but there has to be no events occurred in this interval.

301
00:39:52,330 --> 00:39:56,470
Okay. So if we realize that we translate that into the.

302
00:39:59,650 --> 00:40:13,090
Let's say space. And again, this becomes easier to deal with because the two events are dealing with two of them overlapping control.

303
00:40:13,420 --> 00:40:18,940
The first one is from zero to us. The other one is from T, from s t.

304
00:40:19,180 --> 00:40:24,010
So this two ins are not overlapping. Therefore the two.

305
00:40:24,910 --> 00:40:29,800
So we can write the controlling probability into the product of the two.

306
00:40:35,800 --> 00:40:46,450
So let's just write this. The probability as one less than ask, conditional on and t equals one.

307
00:40:47,380 --> 00:41:02,440
So, um. It will be the same probability as one of us, as both equal to one divided by the probability 71.

308
00:41:05,050 --> 00:41:09,190
So. So this one. We know the denominator is trivial.

309
00:41:09,310 --> 00:41:12,820
This is a popular demand function for a for some random variable.

310
00:41:13,270 --> 00:41:31,000
The top one we have just rewrite is us and that's equal to one and t minus and that's equal to zero divided by the probability of T equals.

311
00:41:31,900 --> 00:41:40,070
Right. So the next thing I'm going to invoke is the independent increment and of the poor sum process.

312
00:41:40,090 --> 00:41:50,380
So these two events are independent, so we get probability as equal to one times probability.

313
00:41:51,910 --> 00:41:55,480
All right, I'm running out of space. But you know what?

314
00:42:12,170 --> 00:42:26,570
So you have the ability as you go through one of the implied by the probability and T minus as equal to zero.

315
00:42:26,990 --> 00:42:39,710
So the the factorization is based on independent increment assumption to right and t minus and I see equal to zero.

316
00:42:39,830 --> 00:42:56,480
So T minus s equal to zero is based on stationary increment assumption and then divided by probability and T equals one.

317
00:42:57,810 --> 00:43:00,680
And what you got here and see four right there.

318
00:43:02,150 --> 00:43:20,990
But the probability mass function correctly e to belong to t minus s divided by the t e to the opposite to this give you that solver.

319
00:43:21,230 --> 00:43:31,820
So you see the exponential functions cancel out this one negative lambda as this is like diplomacy plus the task.

320
00:43:32,180 --> 00:43:41,820
So the problem. So this term cancel out there is another canceling comes from this negative lambda t and then the lambda cancel out there.

321
00:43:41,840 --> 00:43:53,610
So at the end of the day, you can over t. So you can now claim their independence because the the final result is sovereignty.

322
00:43:54,380 --> 00:44:00,620
So both Asante are in there. But what distribution is this?

323
00:44:03,620 --> 00:44:11,360
So if you're thinking about that as this is a kind of a CDF for the conditional distributions as over 80.

324
00:44:15,250 --> 00:44:18,430
Yes. This is a corresponding to the uniform distribution. Right.

325
00:44:18,440 --> 00:44:24,009
So if you do that, if you can, I'll see it to a derivative to find the density.

326
00:44:24,010 --> 00:44:27,590
And the conditional density is a one over t. Yeah.

327
00:44:27,900 --> 00:44:41,580
So that means conditional. One event occurred at the time t so that event that can occur uniformly and piece in time points, right?

328
00:44:42,630 --> 00:44:46,410
So the arrival time conditional on it has to occur.

329
00:44:46,410 --> 00:44:54,930
So the first like arrival this is the arrival time for the so this is at the Savio tell me there is a y event occurs so far

330
00:44:54,930 --> 00:45:03,840
puts on process if there is a Y event occur by the time T and then you want to know what this exactly what time it occurred.

331
00:45:04,440 --> 00:45:09,780
It's the arrival time is uniformly distributed in this time.

332
00:45:09,780 --> 00:45:19,799
And that's very different than the unconditional, you know, you have to give the the a conditional the thing a conditional.

333
00:45:19,800 --> 00:45:25,300
You know that by the time T varies one you might. Okay.

334
00:45:28,390 --> 00:45:34,230
We're going to go a little bit from the spill.

335
00:45:43,270 --> 00:45:49,470
So this is a marginal on event. What about, you know, an event occurs by cutting edge.

336
00:45:58,470 --> 00:46:05,710
So so next we're going to do a little bit just extend time that the result to an event.

337
00:46:06,040 --> 00:46:13,870
So if the ante is not one but and T equals and here so there it's essentially more than one event occurs.

338
00:46:14,350 --> 00:46:16,660
What is the arrival time distributed?

339
00:46:17,380 --> 00:46:26,500
But before that, we have to give a quick read through on the order statistics because the results related to the order statistics.

340
00:46:33,280 --> 00:46:36,390
So order statistics as well, usually it's difficult.

341
00:46:36,400 --> 00:46:44,830
So you're looking at the ranking or the orders, the magnitude of a sequence of random variable.

342
00:46:46,040 --> 00:46:59,230
So generally is a hard problem. But what we know for this in this particular context is much manageable and random variables.

343
00:47:07,660 --> 00:47:12,130
So if we are not specifying they are independent or not.

344
00:47:12,760 --> 00:47:32,980
We're just saying they're random variables. So we use this notation x1x to x and to denote its order statistic icon order statistics.

345
00:47:38,830 --> 00:47:42,460
So this has to be a concept from 601, I believe.

346
00:47:45,130 --> 00:47:48,520
The important thing here is the label.

347
00:47:49,060 --> 00:47:58,840
The order statistic doesn't have the original label, but based on the values, what's in individual x one.

348
00:47:59,380 --> 00:48:02,960
So in this case, x one has to be the smallest.

349
00:48:03,340 --> 00:48:07,900
In the end, random variable x two has to be the second smallest and so on and so forth.

350
00:48:08,170 --> 00:48:21,010
X one has to be the largest. So in the way, when you're thinking about order statistics, you lose the all regional labels but focus on the values,

351
00:48:21,010 --> 00:48:24,820
the magnitude, or the rankings of all of the random variable.

352
00:48:27,010 --> 00:48:34,660
It has some consequences. So in the case for, for example, is that fair?

353
00:48:34,960 --> 00:48:38,720
So I would like let me confirm this is a topic in six. Oh, like, okay.

354
00:48:38,760 --> 00:48:46,390
Could make it much easier. It's not easy to explain for statistics before I'd run the variables.

355
00:48:51,430 --> 00:49:01,240
So we have this. So if there are the two these there are continuous random variable and then you have is continuous random variables.

356
00:49:01,660 --> 00:49:12,459
We have this relationship, the x one equal to x1x2 equals x two and so on.

357
00:49:12,460 --> 00:49:16,690
So force x and you call it to accident. It has to be true.

358
00:49:17,020 --> 00:49:20,630
This is more x one less are equal to x two less are equal to x.

359
00:49:20,890 --> 00:49:30,670
So on. So first let's less equal to accent is important thing is this nine factorial times five equal to one two.

360
00:49:30,670 --> 00:49:34,690
And I got something. All right.

361
00:49:34,960 --> 00:49:43,090
So this maybe while every time I look at this, I feel like a little bit non-intuitive,

362
00:49:43,090 --> 00:49:48,160
not so intuitive, but if you think about this is actually quite intuitive.

363
00:49:48,170 --> 00:49:58,960
So the order statistics you can consider is raw information as much information than, you know, individual x1x2x, right?

364
00:49:59,290 --> 00:50:03,550
Because you only care about the values, the order of the values.

365
00:50:04,000 --> 00:50:10,120
There are actually different permutations can give you the same order statistic.

366
00:50:10,480 --> 00:50:23,050
Actually another factorial. That's all possible permutations of the known labels gave you the same gave you the same order statistic.

367
00:50:23,520 --> 00:50:28,139
So each of them has the same density function because their I.D.,

368
00:50:28,140 --> 00:50:33,810
you just multiply them together by if you come, the possible permutations give you the same.

369
00:50:34,200 --> 00:50:38,759
So you have to add them up. They are mutually exclusive, right? Then they are.

370
00:50:38,760 --> 00:50:40,110
And factorial ideas.

371
00:50:40,560 --> 00:50:49,590
So what you see in factorial times, something like this, you immediately your reaction is it has to be order statistics of something.

372
00:50:49,980 --> 00:50:52,980
And on top of it, you have to have x one.

373
00:50:53,100 --> 00:50:58,830
Is this the number, the actual number x one less than or equal to x two less than or equal to.

374
00:50:58,950 --> 00:51:06,580
So this has to be true. Otherwise. Right for the small.

375
00:51:07,370 --> 00:51:13,730
That's all you need to know for. You know, interpret the work conclusions.

376
00:51:15,750 --> 00:51:19,050
For this conditional general conditional distribution offer.

377
00:51:20,580 --> 00:51:41,520
All right, so we are gonna considering a density like that, but what are we going to do is using the notation of arrival time,

378
00:51:41,520 --> 00:51:49,270
let's consider this particular conditional density as one would use.

379
00:51:49,300 --> 00:52:06,660
One has one, s two, s two, so on, so forth to as you point to S and conditional on T and under the restriction.

380
00:52:07,590 --> 00:52:19,830
That's one lesson to us to. I started to ask and I can't do a lesson here.

381
00:52:21,180 --> 00:52:24,749
Well, I think probably I'm in the lecture notes.

382
00:52:24,750 --> 00:52:28,290
We would just get rid of that equal sign. So this whole thing.

383
00:52:31,760 --> 00:52:33,290
So how do we calculate this?

384
00:52:33,620 --> 00:52:46,100
Again, got the formula to do this type of the calculation as we can see the joint right and then divide it by the marginal margin though it's simple,

385
00:52:46,130 --> 00:52:56,780
it's just anti equals. And so that's a probability maths function from the force on the drawing though, is the following.

386
00:52:57,890 --> 00:53:14,340
When you consider this one as one as to make the two as two all the way up to as I said and and t equals and right.

387
00:53:14,360 --> 00:53:19,510
So this is that you must win two so that if we're trying to evaluate this condition,

388
00:53:19,790 --> 00:53:24,230
that then we need to consider what this joint event correspond to.

389
00:53:24,740 --> 00:53:33,889
Again, the reason is there are a mixture of descriptions from the time domain and the state space, right?

390
00:53:33,890 --> 00:53:42,200
So we want to make them all into the state space or make them all into the time domain.

391
00:53:42,230 --> 00:53:45,890
So in this case, the easier one is actually turn that into.

392
00:53:48,880 --> 00:53:53,040
But run them kind of surprisingly.

393
00:53:54,280 --> 00:54:02,110
So this one is one. So we just turn that into the arrival time to enter our arrival time.

394
00:54:02,440 --> 00:54:09,370
Okay. So he won. Well. Just as 1 to 2.

395
00:54:09,780 --> 00:54:14,159
On the other hand, well, be so that's inter arrival time.

396
00:54:14,160 --> 00:54:17,610
So that must be as two minus as one, right.

397
00:54:22,260 --> 00:54:28,320
And then so on and so forth. The T of and has to be as a minus as a minus one.

398
00:54:28,980 --> 00:54:36,000
The last one, though, seems to have already turned everything into a random time point and t equals.

399
00:54:36,000 --> 00:54:39,570
And that must means that t and plus one.

400
00:54:41,120 --> 00:54:44,510
Has to be greater.

401
00:54:45,700 --> 00:54:51,350
Um, so so that in my I'm plus one event that doesn't occur yet.

402
00:54:51,770 --> 00:54:55,240
So if you put that into a statement of T then plus one.

403
00:54:55,520 --> 00:55:01,130
So that means ten plus one must be greater than T minus Iceland.

404
00:55:01,140 --> 00:55:05,570
So those events are. Equivalent.

405
00:55:06,320 --> 00:55:13,670
And then the benefit of doing that is, again, we know those internal rental times are independent.

406
00:55:14,000 --> 00:55:18,560
Just show that earlier today, so on.

407
00:55:19,920 --> 00:55:25,690
So from here we can carry out the calculation.

408
00:55:30,610 --> 00:55:32,090
Yeah. I'm glad you raised that.

409
00:55:47,200 --> 00:55:59,740
So all you need to write this is that if you write the density of one, when you come to one all the way up to the T as an equal to.

410
00:56:02,070 --> 00:56:17,570
As he reports, and divided by probability and t equals and this one equals.

411
00:56:17,760 --> 00:56:20,880
So we're going to use the equivalent description of the event,

412
00:56:21,420 --> 00:56:33,750
and then we're going to factor those and be one as one of the two as to marginally, oh, these are exponential distribution.

413
00:56:33,830 --> 00:56:37,380
So the exponential density is trivial and.

414
00:56:38,710 --> 00:56:52,750
And then the probability he lost one greater than minus one divided by the possibility equals.

415
00:56:53,620 --> 00:57:02,290
All right. And then if you do this, you get a bunch of cancellations, right?

416
00:57:02,290 --> 00:57:06,340
This out of lambda.

417
00:57:08,210 --> 00:57:14,630
As one multiply by the second term you to demand as two minus as one.

418
00:57:15,050 --> 00:57:20,570
So you see in the adjacent terms, those terms are canceled.

419
00:57:21,080 --> 00:57:27,739
Nine people out on this one. You're going to get the plus lambda as one from the second term.

420
00:57:27,740 --> 00:57:33,860
So there is some cancellation going on all the way up to the last term that you get.

421
00:57:34,040 --> 00:57:37,070
This term, this probability is a little bit different.

422
00:57:37,720 --> 00:57:43,460
That's so the t one and plus one greater than T minus lambda.

423
00:57:43,790 --> 00:57:50,679
That's one reason there's no lambda in front of this.

424
00:57:50,680 --> 00:57:53,840
This is a probability, not density. Okay.

425
00:57:54,230 --> 00:58:02,710
Oh, the others are density. And then you should feel comfortable writing this because we know that the

426
00:58:02,720 --> 00:58:10,760
general definition for conditional expectation and the conditional probability.

427
00:58:10,760 --> 00:58:17,120
So for this one, this lambda clearly to the and into the long one.

428
00:58:20,410 --> 00:58:23,810
He divided by one factor.

429
00:58:24,910 --> 00:58:34,210
So that's the denominator. So a bunch of cancellations at the end of the day.

430
00:58:38,600 --> 00:58:44,490
What do we got to do? It's going to be so essentially again.

431
00:58:44,510 --> 00:58:53,510
You're going to see all the exponential functions are canceled out at the end of the day.

432
00:58:55,310 --> 00:58:59,910
What you get is only factorial divided by two.

433
00:59:00,110 --> 00:59:05,750
The power of a year. So t to the power of an come from here.

434
00:59:06,170 --> 00:59:13,910
And then all the lambdas are also canceled. All here are the terms of lambda from the norm and from the numerator.

435
00:59:15,390 --> 00:59:19,490
Right. I'm not trying to explain too much about the the algebra.

436
00:59:19,490 --> 00:59:29,560
You can verify that. So this is the result. So, so this is a where the, the order statistics comes in handy.

437
00:59:29,570 --> 00:59:32,660
So you have this factorial.

438
00:59:32,840 --> 00:59:36,680
So that's about one over two.

439
00:59:37,040 --> 00:59:46,750
So this is a really help you to or I right this way, in fact in a real one over here.

440
00:59:47,030 --> 00:59:50,450
So this is basically so this is density now.

441
00:59:51,840 --> 01:00:01,350
Right. So this is the order statistics of a uniform random variable.

442
01:00:02,460 --> 01:00:11,680
I the random variable. Right. So what that means, it's a generalization of the the result we get for a single event.

443
01:00:11,730 --> 01:00:18,660
So conditional there are an event occurs. So those events occur uniformly on this time.

444
01:00:18,660 --> 01:00:27,730
Interval zero to a t. But because the arrival times there are natural order to this so to a has to be as to

445
01:00:27,740 --> 01:00:33,350
has to be greater than this one because they are all referred to the absolute right.

446
01:00:33,350 --> 01:00:37,540
The arrival time is absolute and will always refer to the time zero.

447
01:00:37,550 --> 01:00:45,200
So they are order statistic. So this basically saying if you have an event you're conditional on there are any by the curves.

448
01:00:45,620 --> 01:00:51,330
Those arrival times are uniformly distributed on the timeline from 0 to 10.

449
01:00:52,350 --> 01:00:57,660
Okay. Why is that important?

450
01:00:57,750 --> 01:01:06,809
I'm not sure. But I think this is sort of of, you know, why you study different things, especially the stochastic process.

451
01:01:06,810 --> 01:01:11,850
This kind of a natural problem comes out of what is the arrival time,

452
01:01:11,850 --> 01:01:21,000
what is in travel time and the way done the marginal distribution you automatically think about if you can think about the.

453
01:01:23,330 --> 01:01:26,400
Interim arrival time. Okay.

454
01:01:28,820 --> 01:01:34,910
So we're going to use this conclusion next time. So thinking about thinning is probably some pulling off the pause on process,

455
01:01:35,240 --> 01:01:47,140
but then that's in next time I'm going to use the rest of the time like 15 minutes also to talk about the and CMC homework or project.

456
01:01:48,320 --> 01:01:54,080
Any questions about this? Yeah.

457
01:01:54,080 --> 01:01:58,370
So the order statistic part and we can't see it when you're trying to reinterpret the results.

458
01:01:59,360 --> 01:02:06,710
Nevertheless, it's important. If you don't know that, then this looks very possibly.

459
01:02:09,390 --> 01:02:18,510
Okay. So so this is we cannot test for too much of the.

460
01:02:19,740 --> 01:02:23,640
I know I did ask you to outline a few some color,

461
01:02:24,030 --> 01:02:32,760
but I think the more important thing is to put that into some practical usage or non-trivial usage of and CMC.

462
01:02:33,590 --> 01:02:36,640
That's really something like application wise.

463
01:02:36,920 --> 01:02:42,000
You get in probably the most irrelevant from this class.

464
01:02:42,780 --> 01:02:47,129
So the question we're going to deal with is actually a frequency.

465
01:02:47,130 --> 01:02:55,890
Is the problem also known for you through this umbrella of same constraints on distribution?

466
01:02:56,760 --> 01:03:02,159
So we're going to consider. So this is about homework for.

467
01:03:02,160 --> 01:03:11,250
Yes. So we're going to deal with this contingency table is 5.5, if significantly more one.

468
01:03:27,080 --> 01:03:44,209
So this a five by five contingency table people use the contingency table a lot in loss of a cemetery can consider early stages of

469
01:03:44,210 --> 01:03:56,570
biostatistics but the contingency table usually have this so the oh the cell numbers are non-zero so you cannot put negative numbers into it.

470
01:03:57,140 --> 01:04:05,300
And so this particular contingency table we're interested in is a contingency table with additional constraint.

471
01:04:05,780 --> 01:04:17,780
So you put only put integers into the cell and then we require the row side for each row and the column sum, the sum for each row.

472
01:04:17,780 --> 01:04:28,910
And the column has to be 17 seconds.

473
01:04:47,330 --> 01:04:47,659
Right?

474
01:04:47,660 --> 01:04:58,250
So I'm not trying to draw any of this realistically, but there are, you know, the real tables yet you can think about we can put the numbers into it,

475
01:04:58,250 --> 01:05:06,260
but the constraint is you have to have so for example, you cannot have a integer value of 18 doing this, right?

476
01:05:06,350 --> 01:05:10,820
So if you put it in, you cannot have negative numbers then automatically violate this.

477
01:05:12,770 --> 01:05:20,270
This is a for each row and column if your and then the similar things you can see from like

478
01:05:20,270 --> 01:05:26,419
the the game like secluded so you have constraints on the contingency table type of thing.

479
01:05:26,420 --> 01:05:30,290
So maybe next year or change it to some food or that's for interest.

480
01:05:30,530 --> 01:05:33,650
But this one is what I know how to do it. So let's do it.

481
01:05:35,990 --> 01:05:47,240
So the question of this is. Obviously, although you can now thinking of maybe it's difficult to make warm water right away.

482
01:05:47,630 --> 01:05:51,290
But you do know such tables exist, right?

483
01:05:51,710 --> 01:05:56,420
There are actually finite amount of those.

484
01:05:57,320 --> 01:06:04,060
It's just you don't really know the number of I don't know if you do commentary.

485
01:06:04,470 --> 01:06:16,250
So for maybe you can figure out all the numbers, you know, but we're interested in is I that's a population of tables a satisfying constraint.

486
01:06:16,730 --> 01:06:21,810
So we're interested in the distribution of the maximum element in such table.

487
01:06:24,320 --> 01:06:29,120
The reason there's this type of the problem pops up in biostatistics research.

488
01:06:30,620 --> 01:06:35,149
People get the table and then have the constraint and they want to calculate a p

489
01:06:35,150 --> 01:06:40,340
value because they observe something like the largest element in the table is 14.

490
01:06:41,180 --> 01:06:50,100
And very naturally they ask the question what the p value observe an extreme maximum value like 14 in such setting.

491
01:06:50,570 --> 01:06:54,530
Right. I mean, that's a valid question. I'm not going to be arguing for it.

492
01:06:54,530 --> 01:07:02,030
You know, p value is a good way to ask the question or not, but that's a valid statistical question.

493
01:07:02,390 --> 01:07:05,520
And this is not an easy question. Right?

494
01:07:05,600 --> 01:07:12,470
It's it's actually ask you to compute a p value. So the problem is pretty straightforward.

495
01:07:12,480 --> 01:07:15,950
You have a table like this and then you have the constraint.

496
01:07:16,520 --> 01:07:20,540
The problem is thinking about the whole populations of the table.

497
01:07:20,540 --> 01:07:24,650
With this for what is the maximum value of the serving?

498
01:07:25,010 --> 01:07:29,810
What is the distribution of the maximum element in this table?

499
01:07:30,170 --> 01:07:37,010
And if you know that you can calculate the P values, you can use this distribution and calculate p value, right?

500
01:07:37,010 --> 01:07:49,940
So this is your normal distribution. Now, the difficulty here is how do you actually figure out all about distribution?

501
01:07:50,540 --> 01:08:03,630
It seems like if you're trying to you know, I think some of you may be brilliant in you know, in combinatorics.

502
01:08:04,880 --> 01:08:08,720
I'm I'm pretty sure I don't know any solutions.

503
01:08:08,960 --> 01:08:13,790
You can use just pure math to figure out the maximum distribution.

504
01:08:14,300 --> 01:08:21,500
You may be able to figure out the number of you know in this population, how many table was are.

505
01:08:24,800 --> 01:08:27,740
Are there following this constraints.

506
01:08:28,220 --> 01:08:39,740
But it's I'm not know I don't really know how do you on a conclusion about you know maximum but you can think about some polling as a way to figure

507
01:08:39,740 --> 01:08:48,110
out that is right so the idea would be if you're some poll a table like this and now you look at the maximum number there and there was some poll,

508
01:08:48,110 --> 01:08:53,599
another one, and look at the maximum number that you view through some polling you'll be with the distribution for

509
01:08:53,600 --> 01:09:03,440
the maximum adamant in such a constraint tables by the some polling is not necessarily easy either.

510
01:09:05,190 --> 01:09:08,940
Right. So the typical thing people do, it's called a rejection sample.

511
01:09:09,600 --> 01:09:16,320
So they just so they ignore this constraint first and then just a sample table.

512
01:09:16,860 --> 01:09:23,489
Right. So what called the rejection sampling is you kind of you can't you can't draw arbitrary tables.

513
01:09:23,490 --> 01:09:29,070
And, you know, if you don't have this constraint and the only thing is you put the integers into the cell.

514
01:09:29,730 --> 01:09:33,660
Right. You can put one there, two here, three, four or five.

515
01:09:33,670 --> 01:09:40,680
So you can get each you can individually sample each cell from integer arbitrary distribution you like.

516
01:09:41,520 --> 01:09:47,100
And then the thing is, you sample a table that doesn't respect this constraint.

517
01:09:47,460 --> 01:09:52,350
Then you compare it to this strain. If it doesn't really fall, follow the constraint.

518
01:09:52,350 --> 01:09:56,850
You have to throw it out. You cannot use it. Right.

519
01:09:56,880 --> 01:10:06,210
So that's called a rejection standpoint. Only keep the table that follows the constraint or that you don't respect the constraint.

520
01:10:07,140 --> 01:10:10,770
And so in this case, you can imagine if you don't believe me,

521
01:10:10,770 --> 01:10:19,780
you can try how you fail should not this rejection something is so the rejection somebody doesn't need to use M.S., M.S., right.

522
01:10:19,800 --> 01:10:24,390
So this is just I've supporting Monte Carlo for Neil of Monte Carlo method.

523
01:10:24,660 --> 01:10:36,389
But you need to sample a table, check the constraint if not throwing away this one is make it intentionally difficult for a rejection.

524
01:10:36,390 --> 01:10:42,360
Sampling is five by five. I think the efficiency will be very, very low.

525
01:10:42,570 --> 01:10:52,080
But feel free to try. You have more than ten days because spend a day or two and see how many tables you get from the rejection sample.

526
01:10:52,500 --> 01:10:56,340
But the right way to do it is through a M.S., M.S. How so?

527
01:10:56,340 --> 01:11:03,030
The idea is if you can start with some eligible table and then try to move around.

528
01:11:03,390 --> 01:11:11,760
So this is where Markov chain come in. So if you have an eligible table and then you going to propose some random moves for the table.

529
01:11:13,110 --> 01:11:20,639
For example, if I swap with the. So that moves and this is not the correct obviously, but I'm telling you.

530
01:11:20,640 --> 01:11:25,000
So for example, swap this two corners and then swap these two corners.

531
01:11:25,260 --> 01:11:32,880
See if that. So some of the moves, well, make this constraints intact.

532
01:11:33,150 --> 01:11:41,040
So that means you change the table. You still have this kind of strings in place and not violated.

533
01:11:41,640 --> 01:11:45,030
Some of this are not. So if you swap this two elements.

534
01:11:46,410 --> 01:11:51,149
So for example this column some of the well that that will change things that's

535
01:11:51,150 --> 01:11:56,440
not a valid table but some moves you need to be a creative one that moves are.

536
01:11:58,140 --> 01:12:05,610
If you have this type of the move. So first of all the sum pulse become dependent.

537
01:12:06,720 --> 01:12:13,170
So the you only makes more moves from one table to the other and then they are

538
01:12:13,170 --> 01:12:17,640
Markov chain because you are only proposing conditional on what the table you have.

539
01:12:18,960 --> 01:12:28,020
Okay. And furthermore, if you figure out a systematic way to move things,

540
01:12:28,680 --> 01:12:37,080
then you actually store and CMC, you are actually just sampling from the sample space.

541
01:12:37,620 --> 01:12:44,420
And then this is a requires you or so now you know the sums for the each row and column must be 17.

542
01:12:44,550 --> 01:12:47,640
You can think about the uniform distribute the target.

543
01:12:47,640 --> 01:12:51,900
Distribution is a uniform distribution in this constraint sample space.

544
01:12:52,760 --> 01:12:54,750
And so we know the target distribution.

545
01:12:55,200 --> 01:13:02,850
If we can figure out the moves to figure out the Markov chain to sample that from this space, then we can solve the problem.

546
01:13:03,570 --> 01:13:14,160
Right? So this is a quite cool example to say there's just is not always for, you know, Bayesian problem or this is pretty useful.

547
01:13:15,510 --> 01:13:20,550
So think about this will probably give you more hints later off the what everybody's.

548
01:13:21,660 --> 01:13:31,290
But one of the things is well to be able to execute the CMC idea, you have to have some starting point, right?

549
01:13:31,350 --> 01:13:34,370
So you have to have a single table that satisfy this.

550
01:13:35,040 --> 01:13:41,270
If you don't, you cannot figure out any table like that then well, hope that you are in trouble.

551
01:13:41,280 --> 01:13:45,989
But there is a trivial one, right? So some of you probably already know.

552
01:13:45,990 --> 01:13:53,220
But if you don't know, I don't want to tell you. Answer today. Think about it and then think about what is the relevant, the moves.

553
01:13:53,340 --> 01:14:00,000
You can keep the table within this constraint sample space, right, and then implement that.

554
01:14:00,390 --> 01:14:10,130
So there will be why you do implement that, that you think about, you know, the right of CMC algorithm, you're going to use Metropolis Hastings.

555
01:14:12,030 --> 01:14:16,460
You're going to be it's going to be a Metropolis Hastings. Right. Keep supply doesn't apply here.

556
01:14:16,470 --> 01:14:19,500
This is not the multivariable distribution.

557
01:14:19,500 --> 01:14:26,160
There is no conditionals for conditionals. And I think about impeachment.

558
01:14:26,430 --> 01:14:32,800
So I don't really care what you implement and what kind of a language programing language you implement on.

559
01:14:33,900 --> 01:14:43,740
So our work despite the not very efficient and the programing language would not.

560
01:14:43,980 --> 01:14:49,290
So the point is not really calculate that particular our product or that distribution

561
01:14:49,290 --> 01:14:55,649
accurately is really for you to practice of how to design a markov chain.

562
01:14:55,650 --> 01:14:59,010
How do you implement this hasting algorithm?

563
01:14:59,370 --> 01:15:05,550
So again, the target distribution here is the uniform distribution in this constrain.

564
01:15:08,440 --> 01:15:12,450
In this constrained small space. Yeah.

565
01:15:12,550 --> 01:15:19,780
We're right on time. Okay. Next Monday, we're going to promise.

566
01:15:21,270 --> 01:15:50,400
The term. I think one of the things that.

