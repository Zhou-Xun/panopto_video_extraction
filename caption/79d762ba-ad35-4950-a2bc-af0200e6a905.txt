1
00:00:01,260 --> 00:00:48,690
Uh. Just like I don't think.

2
00:00:58,040 --> 00:01:09,430
Oh, I. So.

3
00:01:15,190 --> 00:01:20,530
I spoke to my. My.

4
00:01:27,980 --> 00:01:31,500
Yeah, I know. Yeah. Hi.

5
00:01:31,780 --> 00:01:39,520
All right. Good morning. Good morning.

6
00:01:41,830 --> 00:01:53,400
I hope everyone have a good weekend. So today we're talking about or this week we're talking about validity.

7
00:01:54,450 --> 00:02:04,920
Today we'll talk about internal validity. And Thursday, we'll talk about external validity announcements.

8
00:02:06,000 --> 00:02:13,830
Um, you have a quiz coming up that will open this Thursday, but you have a week to do it, so you'll have.

9
00:02:15,400 --> 00:02:26,520
I placed it so that. You can either choose to do it over fall break or you can do it before you go on fall break if you're going somewhere.

10
00:02:28,800 --> 00:02:33,240
And then, yeah, so those are the announcements that I have for today.

11
00:02:36,480 --> 00:02:41,430
Today we'll talk about validity, threats to internal validity,

12
00:02:41,760 --> 00:02:48,990
and then apply those threats to understanding how they impact different kinds of research designs.

13
00:02:50,460 --> 00:02:59,430
But first, a review. So on Thursday, we talked about outcome evaluation design.

14
00:03:02,310 --> 00:03:08,940
Some key concerns of outcome evaluation are really what we're looking for is change.

15
00:03:09,780 --> 00:03:17,130
And was there change after the intervention? Were there changes that were sustained over time?

16
00:03:18,210 --> 00:03:21,210
Were there changes that differed across groups?

17
00:03:21,930 --> 00:03:29,190
And then another concern is, were there changes that were caused by the intervention?

18
00:03:31,040 --> 00:03:38,150
And then when we think about types of research design that get that, we will use an outcome evaluation.

19
00:03:38,840 --> 00:03:47,360
Three broad categories pre experimental can also think of those as descriptive or

20
00:03:47,360 --> 00:03:53,450
exploratory is another word that can be used and that might be used in substitution,

21
00:03:54,530 --> 00:04:02,260
quasi experimental. And those are typically defined by having some kind of comparison group.

22
00:04:03,470 --> 00:04:11,720
And then we have true experimental which are considered our gold standard of research design,

23
00:04:12,410 --> 00:04:18,080
particularly when we're thinking about internal validity, which is what we'll get into today.

24
00:04:20,410 --> 00:04:31,090
But first hour before. Before I jump in, I like a good Segway, but any questions about either review or announcements?

25
00:04:35,450 --> 00:04:40,460
All right. Back to my Segway speed. But first, validity.

26
00:04:41,540 --> 00:04:45,770
Validity is really about confidence, right?

27
00:04:46,130 --> 00:04:57,410
It's an indication of how side sound, rather the design and methods of your research are in when we talk about validity.

28
00:04:57,620 --> 00:05:04,310
We're talking about how much confidence can we have in the results that come out of a study.

29
00:05:06,370 --> 00:05:14,800
And the reason why we think about validity is because there are all kinds of factors that can influence study results.

30
00:05:15,730 --> 00:05:22,120
We saw some of those even brought up and the questions from Thursday.

31
00:05:23,830 --> 00:05:35,950
And so here's a quote by Salinger in show showing me, which is any research could be affected by different kinds of factors which,

32
00:05:36,400 --> 00:05:41,410
well, extraneous to the concerns of the research can't invalidate the findings.

33
00:05:41,950 --> 00:05:51,130
So there are all kinds of factors that can emerge or already exist that can really

34
00:05:52,330 --> 00:05:58,390
cause us to have less confidence in our study design or our study results.

35
00:06:01,000 --> 00:06:07,570
And we talk about three types of validity of research, internal validity,

36
00:06:07,900 --> 00:06:20,470
which is really about how confident can we be that there is a cause and effect relationship between your independent and your dependent variable?

37
00:06:21,890 --> 00:06:24,320
We talk about external validity,

38
00:06:24,530 --> 00:06:33,110
which is the confidence that our findings can be applied in different to different populations and different settings.

39
00:06:33,710 --> 00:06:44,090
And then we also talk about construct validity, which is really about how will any instruments or protocols that we're using in.

40
00:06:46,250 --> 00:06:50,600
How will those measure what it is that we're intended tending to measure?

41
00:06:51,500 --> 00:06:54,980
This week we're going to focus on internal and external validity.

42
00:06:55,250 --> 00:06:59,390
We'll get a little bit we'll get into construct validity when we get into.

43
00:07:00,920 --> 00:07:13,059
Data collection. So internal validity that is can be defined as the degree to which our study allows us to infer

44
00:07:13,060 --> 00:07:19,060
a cause and effect relationship between our predictor variable and our outcome variable.

45
00:07:19,480 --> 00:07:26,710
Or other words are independent variable, the variable that we are manipulating on our dependent variable,

46
00:07:28,030 --> 00:07:32,140
which in this case for outcome evaluation is the outcome variable.

47
00:07:33,890 --> 00:07:38,150
In respect with respect to evaluation,

48
00:07:38,750 --> 00:07:49,670
the basic question is that we're thinking about when we think about internal validity is did our intervention cause the observed outcomes?

49
00:07:53,710 --> 00:07:59,800
So there are different threats to internal validity. You know, another quote,

50
00:08:00,280 --> 00:08:09,370
findings can be said to be internally invalid because they may have been affected by factors other than those thought to have caused them.

51
00:08:11,810 --> 00:08:18,200
So the relationship between the threat and the state of the internal validity

52
00:08:18,200 --> 00:08:24,890
is basically that the more threats you have that are mitigated in some way,

53
00:08:25,160 --> 00:08:32,160
the lower your internal validity of the study. So ideally,

54
00:08:32,160 --> 00:08:38,400
what we're doing when we're when we're designing an outcome evaluation study

55
00:08:38,880 --> 00:08:44,520
is we are trying to control for those and mitigate those as much as possible.

56
00:08:50,740 --> 00:08:53,860
External validity, which we'll talk about on Thursday,

57
00:08:54,310 --> 00:09:03,310
is the degree to which results from a study can be generalized to other settings, other populations or other points in time.

58
00:09:04,460 --> 00:09:10,760
It's kind of the central question with external validity is will our intervention have the same

59
00:09:10,760 --> 00:09:17,390
results if we implement it in another setting with different people and or a different time?

60
00:09:19,140 --> 00:09:27,990
So really we're trying to understand, could we take this intervention that takes place in 2022, you know,

61
00:09:28,110 --> 00:09:36,420
and move it to a different setting and see or a different time and see if it has the same effect.

62
00:09:42,170 --> 00:09:47,660
Here's a depiction. This is called the. You're going to write it down.

63
00:09:50,070 --> 00:09:55,520
Proximal. Similarity.

64
00:09:57,160 --> 00:10:06,300
Make sure I spoke with model, which suggests that evaluation results are more generalizable to other people,

65
00:10:06,310 --> 00:10:12,700
other settings, and other times when these other people and settings and times are similar to our study.

66
00:10:14,080 --> 00:10:22,120
So take for example, we have an evaluation for a program that is designed for rural youth.

67
00:10:23,620 --> 00:10:30,519
It'd be more likely that the findings themselves can be applied to their

68
00:10:30,520 --> 00:10:36,280
populations of rural youth versus it being applied to populations of urban youth.

69
00:10:38,200 --> 00:10:47,660
And external validity is really. Mitigate it or control for within the sampling process.

70
00:10:49,430 --> 00:10:54,170
In contrast to what we'll talk about today, internal validity, which is really.

71
00:10:56,960 --> 00:11:01,880
Controlling for it is really about how you create the design for the study.

72
00:11:05,760 --> 00:11:18,990
So there are some tradeoffs. You really can't completely eliminate threats to internal validity in terms of in whole, I should say.

73
00:11:20,190 --> 00:11:29,700
So there's always going to be some kind of concern that may compromises our confidence in that counterfactual.

74
00:11:29,700 --> 00:11:37,920
Because remember, what we're trying to do in the outcome evaluation ideally is create a counterfactual

75
00:11:39,120 --> 00:11:44,850
in a group that is similar in all respects to the intervention group,

76
00:11:45,630 --> 00:11:48,780
but they simply don't receive the intervention.

77
00:11:50,340 --> 00:11:52,770
So there are but there are some trade offs. Right.

78
00:11:54,330 --> 00:12:02,520
So it's often believed that internal validity is more important than external validity, which is not necessarily true.

79
00:12:03,090 --> 00:12:09,990
It really does. As you'll see in the next slide, depend on what it is you're trying to accomplish with the evaluation.

80
00:12:11,610 --> 00:12:19,020
And in order to improve internal validity, we have to control for all those extraneous factors.

81
00:12:19,320 --> 00:12:31,410
Right? Setting time differences and the characteristics between the intervention group and either a control or comparison group.

82
00:12:33,120 --> 00:12:41,580
But the more control that we maintain in the study, the more difficult it becomes to generalize to other settings, people and points in time.

83
00:12:42,180 --> 00:12:49,170
So there's always this continual push and pull between internal validity and external validity.

84
00:12:50,910 --> 00:13:07,480
So how do you deal with that? Really what it comes down to is you need to really dig into the purpose of the evaluation.

85
00:13:08,690 --> 00:13:19,430
So if and if you're, for example, designing a study that is really about cause and effect, say you, for example, have a.

86
00:13:21,580 --> 00:13:28,570
A novel intervention that has some new way of influencing an outcome.

87
00:13:28,930 --> 00:13:39,340
And you really need to know that in this intervention or in this program, that that new novelty, that new factor or the new.

88
00:13:41,240 --> 00:13:50,780
Predictor variable or independent variable, you really need to know that that is causing the outcome when you prioritize internal validity.

89
00:13:51,790 --> 00:13:55,069
But save it. Say your intervention study.

90
00:13:55,070 --> 00:14:03,310
Your evaluation is really about understanding whether the intervention will be successful among other populations or in other locations.

91
00:14:03,790 --> 00:14:07,900
You're going to make some decisions that improve external validity, validity.

92
00:14:08,140 --> 00:14:17,770
So again, push and pull. But you're but never are you really going to be able to eliminate both at the same time?

93
00:14:22,280 --> 00:14:26,060
So you may have heard kind of just a side note.

94
00:14:26,660 --> 00:14:34,800
You may know this that. Researchers very rarely say or they shouldn't say that they proved something.

95
00:14:36,140 --> 00:14:39,410
Especially when it comes to social science, health, science.

96
00:14:40,370 --> 00:14:43,610
It's really about suggesting that something is happening.

97
00:14:44,420 --> 00:14:56,030
And that's why because again, you can't completely eliminate all threats to both internal and external validity at the same time.

98
00:14:58,750 --> 00:15:02,590
So what we're going to discuss today are eight threats.

99
00:15:03,190 --> 00:15:10,210
There are other threats and I'll mention a few of them in the second, but these are the eight we'll focus on today.

100
00:15:11,080 --> 00:15:19,600
So the first is ambiguous temporal precedents, history, maturation testing, instrumentation,

101
00:15:20,050 --> 00:15:25,840
regression effects or regression to the mean selection bias and then attrition.

102
00:15:27,330 --> 00:15:35,720
Which is also known as mortality. So the first is ambiguous temporal precedence.

103
00:15:36,530 --> 00:15:43,640
And this is really about whether there's a lack of clarity about whether the intervention actually occurred before the intervention.

104
00:15:45,110 --> 00:15:48,830
So, you know, because we're evaluating real life programs.

105
00:15:49,980 --> 00:16:00,180
There are real life things that are happening and it can be difficult, especially depending on the timing of any pulse test,

106
00:16:00,600 --> 00:16:08,220
whether the interval, if the intervention became arcane before the outcome.

107
00:16:08,880 --> 00:16:14,580
And that's because the outcome could be influenced by something else that's acting in the environment.

108
00:16:16,620 --> 00:16:17,670
So for example,

109
00:16:17,940 --> 00:16:28,440
say you're evaluating a program that's being implemented in the school system and snow days and changes in teachers have resulted in a great

110
00:16:28,440 --> 00:16:37,890
deal of variability in the timing of when the components of the program and the uptake took place and when the observations were conducted.

111
00:16:38,920 --> 00:16:46,390
So because you don't know what happened and they could have possibly been something else happening to affect the outcome.

112
00:16:48,010 --> 00:16:53,560
You have a lack of clarity and thus ambiguous temporal precedence.

113
00:16:59,170 --> 00:17:07,800
The second threat is history. And that history is really and this is actually going to seem similar to the next one maturation.

114
00:17:07,810 --> 00:17:11,990
So. I'll try to stress the difference.

115
00:17:13,070 --> 00:17:19,010
History is when events external to participants occur between the beginning of

116
00:17:19,020 --> 00:17:25,040
an intervention and follow up that could also explain the observed outcomes.

117
00:17:26,720 --> 00:17:31,370
So the example here is that you have participants in a health education program.

118
00:17:32,450 --> 00:17:39,680
Maybe they're learning about. Safer sex behavior they're learning about.

119
00:17:42,170 --> 00:17:44,900
You know, COVID 19 prevention,

120
00:17:45,770 --> 00:17:58,910
but say they're in this health education program and in the at the same time that they are learning about these issues in the context of the program,

121
00:17:59,330 --> 00:18:01,760
they're also getting information from the Internet.

122
00:18:02,980 --> 00:18:17,440
And so it can be hard to know that how much of the pulse test score is due to the intervention and how much of it is due to the internet search?

123
00:18:18,340 --> 00:18:25,510
Oh. The a very similar concept is maturation.

124
00:18:27,290 --> 00:18:37,690
Yeah. Sorry I cracked me up back there of maturation when I'm like, Oh, sorry, I didn't mean to call you out.

125
00:18:37,710 --> 00:18:46,980
Like, that was really try. But maturation that's when changes or processes internal to participants occur.

126
00:18:47,850 --> 00:18:53,760
And this is really about time passing as we as time passes people mature.

127
00:18:55,020 --> 00:19:06,120
So it's really often it's really often about changes that people experience that are maybe rooted and biological factors,

128
00:19:06,120 --> 00:19:14,820
biological maturation or just even social maturation you learn as you grow, right?

129
00:19:15,270 --> 00:19:23,250
But it happens between the beginning of a program and the follow up that could also explain the observed outcomes.

130
00:19:26,980 --> 00:19:31,780
Give me a second. Try to turn. Whenever I hear myself echoing again.

131
00:19:31,870 --> 00:19:42,550
Okay. So just know that the longer time interval between the start and the end of a program, that's a greater threat to internal validity.

132
00:19:42,560 --> 00:19:47,750
Right? Because as time goes on, more maturation happens.

133
00:19:47,770 --> 00:19:51,970
So the longer the time gets, the longer the program gets.

134
00:19:53,050 --> 00:19:55,240
There's a greater threat to internal validity.

135
00:19:56,410 --> 00:20:07,720
So, for example, you may have an intervention with those who have been diagnosed with cancer and or even like caretakers.

136
00:20:07,750 --> 00:20:13,840
It doesn't have to be the it doesn't necessarily have to be the person who is.

137
00:20:15,120 --> 00:20:19,950
Maturing into something. It could be somebody adjacent to that.

138
00:20:21,090 --> 00:20:29,130
So, for example, care caregivers, but individuals may improve their knowledge about an illness as they get sicker.

139
00:20:29,460 --> 00:20:33,240
And that's going to be irrespective of our health education intervention.

140
00:20:35,030 --> 00:20:39,500
And it doesn't again, also have to be sick or it could just be learning.

141
00:20:41,760 --> 00:20:52,070
You know, progressing through a stage of life. The next one.

142
00:20:53,110 --> 00:20:59,850
Oh, what I meant to say is that when it comes to both test our history and maturation.

143
00:21:00,120 --> 00:21:04,290
One way to mitigate these is to. Is to have a control group.

144
00:21:07,590 --> 00:21:18,840
Testing. Testing is really about how a test or survey that is taken before an intervention affects the subsequent test.

145
00:21:20,450 --> 00:21:28,190
So for example, I might have an intervention that's focused on HIV education.

146
00:21:28,910 --> 00:21:41,600
And then I give participants as a pretest, a scale that really walks through the different four ways that one could be infected with HIV,

147
00:21:41,930 --> 00:21:45,890
different treatment options, etcetera, etcetera.

148
00:21:47,360 --> 00:21:52,040
And then what they may figure out is that or even if they don't figure it out,

149
00:21:52,340 --> 00:22:00,260
they may gain knowledge from about the illness or health issue just by taking the test.

150
00:22:01,190 --> 00:22:08,630
And so that's going to translate into better scores on the pulse test, regardless of the intervention itself.

151
00:22:11,360 --> 00:22:19,970
So without proper controls in place, you know, the more test we do, the more we open ourselves up to this particular threat.

152
00:22:20,900 --> 00:22:28,460
So what? One thing you can do to help mitigate this is to test instruments with a non-participants group first.

153
00:22:29,600 --> 00:22:33,560
You can also use a control group to help mitigate this threat.

154
00:22:39,150 --> 00:22:45,660
Instrumentation is about how changing it's about changing the way a variable is

155
00:22:45,660 --> 00:22:52,290
measured or changing who's doing the measurements between one observation and another.

156
00:22:52,620 --> 00:23:01,590
So, for example, having especially if you are measuring something where there is some type of human interaction or human interpretation,

157
00:23:03,480 --> 00:23:12,630
if you change that and it could possibly have an impact on a different measurement from pretest, a pulse test.

158
00:23:13,470 --> 00:23:22,920
So to mitigate this, it's really about having consistency from pretest, the pulse test,

159
00:23:23,310 --> 00:23:31,800
not just in the way that it's measured, but even who is doing the measurement measuring and how it's measured.

160
00:23:34,320 --> 00:23:38,730
So for example, I might edit a question on a survey.

161
00:23:39,030 --> 00:23:44,400
Maybe I find that people were confused by what the pretest said.

162
00:23:46,440 --> 00:23:55,230
And so I say, Oh, well, makes sense. Well, you know, let me reword this to clarify what the question is asking.

163
00:23:55,890 --> 00:24:00,420
That's how you're opening yourself up to instrumentation threat.

164
00:24:02,930 --> 00:24:13,550
So one thing that you can do to help mitigate that is make sure that you are testing and.

165
00:24:15,520 --> 00:24:20,230
You know, testing your instruments before you administer, though.

166
00:24:21,330 --> 00:24:25,770
And that way you're able to identify, for example, if someone is confused.

167
00:24:26,220 --> 00:24:39,150
You can also identify if there is a response to how and there's a difference in responses depending on how that particular data was collected,

168
00:24:39,720 --> 00:24:50,190
because it might be, for example, that people test, they respond differently when they complete a survey on the computer versus a piece of paper.

169
00:25:01,250 --> 00:25:08,360
Excuse me. I'm thirsty today. My throat is dry, and that's that regression to the mean.

170
00:25:09,080 --> 00:25:14,180
So this is what happened. This is when participants score really high.

171
00:25:14,180 --> 00:25:19,760
I mean, extremely high or extremely low. You know, you're basically right here.

172
00:25:23,020 --> 00:25:24,490
On a scale.

173
00:25:25,860 --> 00:25:38,640
And so eventually we statistically speaking, what is going to happen is that generally when people retest, they're going to move closer to the mean.

174
00:25:39,150 --> 00:25:42,630
And I mean, part of that is just statistical.

175
00:25:44,180 --> 00:25:52,570
Statistical walls. If you if you want or statistical rules, people are generally you know,

176
00:25:52,670 --> 00:25:58,550
they're not going to continue to screen extremely screen extremely high or extremely low.

177
00:25:59,270 --> 00:26:06,710
So if the idea is, for example, you have a screening on.

178
00:26:09,580 --> 00:26:12,880
Depression. And they score really high.

179
00:26:14,610 --> 00:26:23,120
On a scale. Chances are they're going to move a little closer to the ME on that second.

180
00:26:23,360 --> 00:26:31,200
The second test. And so you can help mitigate that by.

181
00:26:33,380 --> 00:26:42,860
Having repeat tests because again, even though people are moving toward the mean they may at that other test continue,

182
00:26:42,860 --> 00:26:54,889
they can may move back and forth. It's another example is that maybe individuals with high annual costs for health care are invited to

183
00:26:54,890 --> 00:27:02,360
participate in an intervention only to see their costs naturally decrease in the following year.

184
00:27:03,620 --> 00:27:09,230
So again, chances are they're in, you know, because we're working in the real world.

185
00:27:09,620 --> 00:27:16,190
Scores that are extremely high or extremely low are going to to change.

186
00:27:17,060 --> 00:27:20,640
So sorry. Let me turn this finger.

187
00:27:21,990 --> 00:27:32,480
I knew I was gonna forget about that one. And I should say that regression to the mean is really about recruitment into the study.

188
00:27:32,490 --> 00:27:38,190
So it's about recruiting people who are extremely high or extremely low.

189
00:27:44,940 --> 00:27:47,670
Selection bias is a common one.

190
00:27:48,810 --> 00:27:57,090
And this is when there's observed or unobserved differences between those in the intervention group and the comparison group.

191
00:27:58,350 --> 00:27:59,490
So, for example,

192
00:28:00,120 --> 00:28:10,170
individuals with high health care utilization and cost are invited to participate in the program and then compare it to the rest of the population.

193
00:28:15,550 --> 00:28:19,810
So if you are, for example. You know,

194
00:28:19,840 --> 00:28:25,270
designing a study that has an intervention group and you have a comparison

195
00:28:25,270 --> 00:28:32,550
group and you don't take care to identify that these two groups are similar.

196
00:28:32,590 --> 00:28:39,200
Remember, we did some discussion about, you know, seeing on a pretest if groups are similar.

197
00:28:39,610 --> 00:28:44,800
If you don't ensure that that happens before you move forward.

198
00:28:45,400 --> 00:28:51,760
You could bless you. You could your study could be threatened by selection bias.

199
00:28:53,730 --> 00:29:02,190
Because the key question is, are outcomes due to the intervention or preexisting differences among those who are in the two study groups?

200
00:29:13,370 --> 00:29:27,930
So here is an example. You can see here that in this study of health care utilization and cost, we have our baseline characteristics.

201
00:29:28,530 --> 00:29:37,410
We see that the sample size sizes, they're not necessarily the same, but they're at least statistically equivalent.

202
00:29:44,950 --> 00:29:53,590
And then we. Oh. And then we also can see that statistically there's not there's not a difference between the groups right here.

203
00:29:59,730 --> 00:30:09,640
And for those who have not had statistics. Just know that the p value is signaling to us that.

204
00:30:11,110 --> 00:30:14,170
They're statistically similar. Or they're not.

205
00:30:14,740 --> 00:30:20,270
They're not different. Oh, wait.

206
00:30:20,300 --> 00:30:23,660
Oops. I read that totally wrong. They're different. Sorry.

207
00:30:26,170 --> 00:30:36,510
They actually are different. So finally.

208
00:30:37,590 --> 00:30:43,319
Yeah. Attrition. So this occurs when there are differential dropout or death rates that change the

209
00:30:43,320 --> 00:30:49,080
composition of the intervention comparison or control group and lead to selection bias.

210
00:30:50,520 --> 00:30:55,590
So for example, we have an intervention where the outcome is a 30 day readmission rate.

211
00:30:56,160 --> 00:31:03,000
But participate program participants are sicker than controls, and so therefore they have a higher mortality rate.

212
00:31:04,140 --> 00:31:09,990
And then so as patients die, as patients who die can't be readmitted,

213
00:31:10,020 --> 00:31:16,710
the intervention group is naturally going to have a lower readmission rate if what we're doing is comparing readmission rates.

214
00:31:20,040 --> 00:31:27,370
But I should say that most commonly that's not how we're losing participants in this study.

215
00:31:27,390 --> 00:31:34,260
We're losing participants in the evaluation study because people are disengaging from a program.

216
00:31:34,890 --> 00:31:41,520
So there might be some reason that we need to understand that is important.

217
00:31:41,880 --> 00:31:44,850
That is driving one group to.

218
00:31:47,080 --> 00:31:58,660
One group to drop out of a program versus and then there might be a difference between that group and the control group or the comparison group.

219
00:32:05,300 --> 00:32:08,690
So there are some other threats to internal validity that.

220
00:32:10,690 --> 00:32:20,260
Sometimes come up. One is Hawthorne Effect on this is where participants respond differently when they know they are being observed and measured.

221
00:32:21,520 --> 00:32:25,690
This can apply to surveys, but it also can apply to.

222
00:32:27,300 --> 00:32:34,740
Structure observation. This can apply to interviews or focus groups.

223
00:32:36,590 --> 00:32:44,600
It's simply saying that people respond or answer differently when they know that you are accounting for whatever it is that they're saying.

224
00:32:47,320 --> 00:32:50,650
Another one is compensatory rivalry.

225
00:32:50,920 --> 00:32:57,790
This is where participants in the control group work harder because they're upset they didn't get to participate in the intervention.

226
00:32:58,570 --> 00:33:10,960
So for whatever reason or whatever mechanism, they decide that they are going to be similar to the intervention group in terms of change.

227
00:33:13,200 --> 00:33:18,870
And then the resentful demoralization is where participants in the control group withdraw

228
00:33:18,870 --> 00:33:23,520
or a comparison group withdraw because they didn't get to participate in the intervention.

229
00:33:25,630 --> 00:33:28,620
So thinking about again, we're doing this work in the real world.

230
00:33:28,860 --> 00:33:34,860
People might be aware that there is an intervention group in that they didn't receive the intervention.

231
00:33:36,390 --> 00:33:43,770
And again, problematic because any differences you're seeing might be due to these factors and not the intervention.

232
00:33:46,250 --> 00:33:51,180
So I want to stop here and before we get into how this looks and studies.

233
00:33:52,250 --> 00:33:57,820
Any questions? Yes.

234
00:34:03,300 --> 00:34:11,680
Where with the placebo effect happened in these categories. I'll try, though.

235
00:34:12,040 --> 00:34:16,510
I think that might actually be. It's all. Just not one that.

236
00:34:18,180 --> 00:34:27,630
We're talking about today. So if you aren't familiar with the placebo effect, as if you think you were saving the intervention, you.

237
00:34:30,130 --> 00:34:38,950
You experience the effect of the intervention, even though you're actually not receiving the intervention or the treatment?

238
00:34:39,670 --> 00:34:48,150
So I see that a lot and like clinical studies. Any other questions?

239
00:34:56,730 --> 00:35:04,890
All right. So let's get into what this looks like with respect to research design.

240
00:35:06,720 --> 00:35:12,220
All right. So threats to internal validity for experimental designs.

241
00:35:14,540 --> 00:35:19,160
Just, you know, just to give you a quick primer on the symbols.

242
00:35:20,300 --> 00:35:24,260
If you see an X in the box, that means that the threat exists.

243
00:35:25,680 --> 00:35:34,110
If you see a question mark, it means that it's conditionally control based on what you do see means it's

244
00:35:34,110 --> 00:35:40,380
controlled and then in a means that the threat is not applicable to the study design.

245
00:35:44,630 --> 00:35:55,220
So the two that we talked about last week in terms of experimental pretest post test control group, impulse test only control group excuse me.

246
00:36:00,700 --> 00:36:04,060
So for pretest post test control group.

247
00:36:07,010 --> 00:36:17,390
As long as the randomization is working. So again, we talked last week about randomization and how important it is to make sure that you have good,

248
00:36:18,980 --> 00:36:30,650
good project management so that people are aware or not aware, rather, that they're in a control group or intervention group.

249
00:36:32,310 --> 00:36:37,530
So as long as that randomization is working, you've done your due diligence there.

250
00:36:37,890 --> 00:36:46,140
Most threats to internal validity are going to be eliminated except attrition and possibly instrumentation.

251
00:36:47,490 --> 00:36:53,910
So your set, your selection is controlled because you've made it, but the intervention group is similar as possible.

252
00:36:56,180 --> 00:37:01,010
History, maturation testing and regression to the mean or control because.

253
00:37:02,220 --> 00:37:06,450
Theoretically any intervention and a control group, they should be the same.

254
00:37:07,790 --> 00:37:13,849
So again, think about, you know, doing those baseline characteristics analysis to make sure they are the same,

255
00:37:13,850 --> 00:37:18,950
but theoretically we should have control for that by having randomization.

256
00:37:21,700 --> 00:37:29,830
So you could have a problem with instrumentation if you change the instrumentation for one group, but don't change it for the other.

257
00:37:31,450 --> 00:37:39,310
But if the instruments station is not change and does not differ, then that threat should be controlled for.

258
00:37:40,260 --> 00:37:45,450
And then regarding attrition, there's really no guarantee that people won't drop out.

259
00:37:47,270 --> 00:37:52,190
You know, you can't guarantee either that there's not differential dropout.

260
00:37:53,120 --> 00:37:56,210
And that could actually be if you see that, it could be useful.

261
00:37:56,570 --> 00:38:02,750
It could tell you that maybe there's something. For example, if the intervention group has differential dropout,

262
00:38:02,750 --> 00:38:08,960
maybe that's telling you that there's something about the intervention that you need to be concerned about.

263
00:38:10,770 --> 00:38:18,840
But that's something you would need to explore. But if the attrition is similar, then bless you.

264
00:38:19,350 --> 00:38:25,200
If it's similar, then that attrition can likely be attributed to just.

265
00:38:27,970 --> 00:38:34,270
You know what you would naturally experience just because, again, you're applying this in a real life context.

266
00:38:36,990 --> 00:38:45,300
So here's an example. So say we have this study that's taking place with, um, employees.

267
00:38:46,230 --> 00:38:53,820
It's an employee wellness program, and you want to see whether the intervention is causing an improvement in the health of employees.

268
00:38:54,360 --> 00:38:59,560
So we randomly assign 100 employees to the program.

269
00:38:59,850 --> 00:39:03,210
We randomly assign 100 employees to the control.

270
00:39:04,970 --> 00:39:10,040
And then with this design, again, pretest, post-test, they're taking a health survey.

271
00:39:11,720 --> 00:39:17,500
That's where I got my pointer today. Taking the health survey both the.

272
00:39:18,820 --> 00:39:21,310
Both the intervention group and both the control group.

273
00:39:25,230 --> 00:39:32,790
So if we're thinking about threats to internal validity, one thing we have to think about is where these surveys are saying.

274
00:39:33,880 --> 00:39:42,680
And are they the same here as well? And then again, we have to when it comes to attrition, we have to think about that.

275
00:39:42,720 --> 00:39:46,440
The employees in one group differentially drop out.

276
00:39:48,000 --> 00:39:55,410
And if so, did it cause the two groups to be different? So there may be differential dropout, and maybe they're not different.

277
00:39:56,490 --> 00:40:03,150
But you have to do your due diligence in terms of analyzing them on different characteristics.

278
00:40:05,280 --> 00:40:08,330
And again, it might there might be something else signaling.

279
00:40:08,340 --> 00:40:18,239
So, for example, it may not be that, but well, you may find after exploring a little bit further that that wellness program isn't an issue.

280
00:40:18,240 --> 00:40:25,140
But maybe there is maybe there are some conditions that need to be there need to exist within the employers,

281
00:40:25,500 --> 00:40:31,440
the place of, you know, the place of business in order to make sure the wellness program succeeds.

282
00:40:32,650 --> 00:40:40,870
Maybe employers like managers are not releasing their employees or they to, you know, engage in the wellness program.

283
00:40:40,900 --> 00:40:49,570
Maybe it's not being marketed it very well. There are all kinds of things that could be affecting participation in the program.

284
00:40:51,490 --> 00:40:55,030
So you want to see, one, is there a differential dropout?

285
00:40:55,030 --> 00:41:00,909
And if it makes the groups different? So what?

286
00:41:00,910 --> 00:41:12,190
The post-test only group design. Some of these threats are not applicable because it's only one point of data collection.

287
00:41:12,580 --> 00:41:20,680
So that's testing instrumentation and regression to the mean because those are all associated with multiple points of data collection.

288
00:41:22,740 --> 00:41:30,300
You are also controlling for history, maturation and selection because you have the control group.

289
00:41:31,560 --> 00:41:36,900
The more you know if you have the random control group helps you control for a lot of these threats.

290
00:41:39,780 --> 00:41:44,630
So then. The biggest threat is the attrition.

291
00:41:44,840 --> 00:41:46,370
And again, it's the same thing.

292
00:41:46,700 --> 00:41:57,850
If there's differential dropout that happened, you may not even be able to necessarily capture it in a pulse test only.

293
00:41:59,540 --> 00:42:06,650
If, for example, there wasn't some record of how many people started to engage in the program.

294
00:42:08,110 --> 00:42:16,389
So the pulse test. So one thing to note is that the pulse test doesn't preclude you measuring things like outputs, right?

295
00:42:16,390 --> 00:42:22,750
You can measure outputs like the number of people that are participating without having a pretest.

296
00:42:24,700 --> 00:42:31,180
So again, looking at this example, did employers in either group complete the pulse test the differential rates?

297
00:42:32,950 --> 00:42:36,970
So again, the attrition could also be related to the pulse test.

298
00:42:37,960 --> 00:42:42,910
And then if so, did it cause the two groups to be different, statistically speaking?

299
00:42:50,440 --> 00:42:56,380
Bless you. So we also talked about cluster randomized controlled trial design,

300
00:42:57,010 --> 00:43:07,270
which are they share the same threat depending on how they are structured in terms of pretest and pulse test.

301
00:43:08,030 --> 00:43:15,980
So if they include the pretest and the pulse test, they have the same threats as the pretest pulse test control group design.

302
00:43:16,730 --> 00:43:21,030
And then if their pulse tests only, they have the same threats as a pulse test.

303
00:43:21,050 --> 00:43:33,850
Only control group design. So let's look at quasi experimental.

304
00:43:34,880 --> 00:43:40,250
So remember, your quasi experimental groups are similar to experimental,

305
00:43:40,260 --> 00:43:50,780
but then there is something, some form of manipulation that eliminates the randomization.

306
00:43:52,010 --> 00:43:55,100
For example, having a comparison group.

307
00:43:56,960 --> 00:44:05,900
Or not random assignment. Or you have a time series analysis that does not have a comparison group.

308
00:44:05,900 --> 00:44:16,940
But then the comparison is, if you will, if the multiple time or multiple measurements before and after the intervention.

309
00:44:20,590 --> 00:44:24,040
So with the pretest post-test comparison group design.

310
00:44:25,750 --> 00:44:33,310
Essentially the less similar to comparison and intervention groups are, the more problematic certain threats are going to become.

311
00:44:34,720 --> 00:44:39,820
And that's history, maturation, testing, instrumentation and regression to the mean.

312
00:44:46,810 --> 00:44:51,670
What? Two threats that are going to be present.

313
00:44:52,540 --> 00:45:00,520
Our selection and attrition. With selection, it can be reduced but not eliminate it.

314
00:45:02,080 --> 00:45:10,300
The way you can reduce selection bias in this circumstance is choosing a comparison group that is similar to the intervention group.

315
00:45:10,720 --> 00:45:21,400
So this means looking for different characteristics that you think are meaningful and ensuring that they measure similar similarly at baseline.

316
00:45:22,340 --> 00:45:34,670
So if you think about, for example, that an intervention that we showed with health care utilization, those factors were different outcome.

317
00:45:35,630 --> 00:45:47,360
Outcome variables. It could be demographic characteristics like race, gender identity, class level of education that you think are.

318
00:45:48,770 --> 00:45:53,360
Significant or important and may drive the impact of your program.

319
00:45:55,820 --> 00:46:03,750
Attrition again. You can't really guarantee that there won't be attrition and that attrition won't be differential.

320
00:46:08,500 --> 00:46:13,930
So here's an example. Say we're doing the outcome evaluation,

321
00:46:14,260 --> 00:46:22,840
and it's meant to determine whether an urban greening program is effective in reducing the number of violent crimes in the city.

322
00:46:24,250 --> 00:46:32,770
So the city that implemented the greening program is the intervention group and we've selected another nearby city to serve as a comparison group.

323
00:46:35,590 --> 00:46:39,730
So. City Intervention Group. Comparison group.

324
00:46:42,180 --> 00:46:47,219
And then say we use some data like from the Uniform Crime Reports,

325
00:46:47,220 --> 00:46:53,940
to assess the number of violent crimes that take place in each city prior to the grading program.

326
00:46:54,960 --> 00:46:59,900
And then we look and compare those. After the program.

327
00:47:03,030 --> 00:47:08,700
So with this design, we have to really look at how similar are these two cities?

328
00:47:11,780 --> 00:47:22,480
You know, if we make sure that we're matching based on selected characteristics, we can reduce the threat of history,

329
00:47:22,490 --> 00:47:29,240
maturation testing, instrumentation and regression to the mean and selection threat.

330
00:47:32,180 --> 00:47:38,690
But if we don't consider those matching characteristics or we miss some matching characteristics,

331
00:47:39,380 --> 00:47:46,490
we're, you know, we're opening ourselves up to threat. So, again, you can't you you know, it's about doing your due diligence.

332
00:47:46,910 --> 00:47:53,420
So you can't assume just because you pick these characteristics that you're A-OK.

333
00:47:53,420 --> 00:48:02,720
You need to make sure that you confirm through comparing at baseline on the, on the selected characteristics that you've matched on.

334
00:48:05,880 --> 00:48:10,020
When considering attrition. Some things that we can think about.

335
00:48:10,350 --> 00:48:17,170
Do residents in either city differentially drop out? And so did it change the composition of the two cities?

336
00:48:18,640 --> 00:48:23,200
And so that's where understanding your context can be very important and very helpful.

337
00:48:23,650 --> 00:48:26,800
Maybe there is you know, we saw it with COVID.

338
00:48:26,830 --> 00:48:31,720
Once people realized they could, you know, work virtually.

339
00:48:32,410 --> 00:48:37,000
People started working and moving because they could live where they wanted to

340
00:48:37,000 --> 00:48:43,450
and work and work in a big city or maintain their positions in big cities,

341
00:48:43,450 --> 00:48:48,909
but moved to different places. So, you know, that's just a very recent example.

342
00:48:48,910 --> 00:48:54,730
But there's always examples of ways that there are there's attrition in cities.

343
00:48:56,110 --> 00:49:00,200
Or towns. So we just have to make sure.

344
00:49:00,710 --> 00:49:04,250
Did that actually change the composition of the two cities?

345
00:49:09,600 --> 00:49:12,990
All right. So the other one that we did for Kwanzaa.

346
00:49:13,800 --> 00:49:18,790
Oh. This time. I have a question. I'm sorry.

347
00:49:18,790 --> 00:49:23,890
I thought I heard a question. When it comes to the single time series design.

348
00:49:24,280 --> 00:49:29,620
I'm happy having the multiple observation points helps to control for a few of the threads.

349
00:49:34,980 --> 00:49:44,430
In particular threats due to testing and regression to the mean or control for because those effects tend to level off over time.

350
00:49:45,270 --> 00:49:51,809
So again, think about regression to the mean. As time goes on, things are regress.

351
00:49:51,810 --> 00:49:58,150
Are going to. Naturally, statistically speaking, regress to the mean or the average.

352
00:50:00,500 --> 00:50:10,159
Having multiple observation points also has a potential to control for history and maturation in instrumentation,

353
00:50:10,160 --> 00:50:16,970
as long as the effects were at play at all observations leading up to the intervention.

354
00:50:18,380 --> 00:50:26,930
But if an outside event or internal changes or changes to an instrument happened right before or right after the intervention,

355
00:50:26,930 --> 00:50:38,070
then the threats are not controlled for. Selection bias is not applicable just because there's only one group that program, the intervention group.

356
00:50:39,900 --> 00:50:48,600
And then while there's only a single group, attrition can still be a concern because participants act as their own comparison group over time.

357
00:50:49,610 --> 00:50:57,650
Right. So the scores at the observation right before the intervention and right after are compared to their scores between other observation points.

358
00:50:58,190 --> 00:51:04,880
And so if participants are dropping out at a higher rate during the time period where the intervention itself was implemented.

359
00:51:05,990 --> 00:51:10,340
So it's possible that that dropout can explain the findings.

360
00:51:18,920 --> 00:51:24,320
So here is an example again that the greening program that we were talking about but in this case.

361
00:51:25,270 --> 00:51:30,830
In this case, there's only one city. So the history threat.

362
00:51:31,580 --> 00:51:35,510
There might be some events that occur only between three and four.

363
00:51:35,660 --> 00:51:40,080
So during the intervention. Did there?

364
00:51:40,120 --> 00:51:47,020
Were there some internal changes that occurred only between three and four that might explain the change from 3 to 4?

365
00:51:49,090 --> 00:51:57,760
Was there a change in mass measurement? Maybe, for example, you know, you can easily say, oh, well, maybe we should make this instrument shorter.

366
00:52:00,820 --> 00:52:10,870
Make this instrument shorter because. People are have taken it already like two times or three times less, make it shorter.

367
00:52:11,350 --> 00:52:19,210
So if you do that, then you open yourself up to instrumentation and them and attrition.

368
00:52:20,500 --> 00:52:26,410
Maybe residents move out at a higher rate between three and four, then between other observations.

369
00:52:26,900 --> 00:52:32,410
There's again, the idea of the multiple observations is that it's telling you what.

370
00:52:33,690 --> 00:52:39,330
Was generally going on before the intervention and what generally is happening afterwards.

371
00:52:39,870 --> 00:52:47,880
But what you want to know is that there is some kind of difference between right before the intervention and right after the intervention.

372
00:52:52,640 --> 00:53:01,690
Right. And then finally, we'll talk about threats to internal validity for pre experimental designs.

373
00:53:03,520 --> 00:53:09,700
So we talked about one group post-test, only one group pretest post test and pulse test.

374
00:53:09,740 --> 00:53:21,440
Only comparison group. So when we look at the one group post-test only design.

375
00:53:24,400 --> 00:53:29,130
With history and maturation. There's no control over.

376
00:53:31,130 --> 00:53:38,120
Once again, it makes it weak in terms of the ability to infer causality.

377
00:53:39,610 --> 00:53:45,520
So don't forget that these studies are really weak in terms of determining a cause and effect relationship.

378
00:53:47,620 --> 00:53:55,900
So the two major threats are history and maturation because you don't know if those are external factors are coming into play.

379
00:53:59,600 --> 00:54:09,920
During the intervention. You don't know if that what you're observing in the outcomes is due to what is happening in the program.

380
00:54:10,670 --> 00:54:16,300
Or it could be happening because of something external or internal to the participants.

381
00:54:17,540 --> 00:54:25,030
Um. Testing instrumentation regression to the mean.

382
00:54:25,980 --> 00:54:31,380
And well, those are not applicable because there's no there's only one measurement.

383
00:54:31,500 --> 00:54:42,000
You're only doing the pulse test. And then selection and attrition are also not applicable because there's only one.

384
00:54:42,970 --> 00:54:46,630
There's only one point of observation. There's only one group.

385
00:54:53,740 --> 00:55:04,960
So here's an example. So say you are running and you're evaluating a antidrug education program like their and then after they participate.

386
00:55:05,890 --> 00:55:09,340
They only have one protest.

387
00:55:10,230 --> 00:55:17,790
And that pulse test, the main variable that you're measuring in the main outcome is student attitudes toward drugs.

388
00:55:19,150 --> 00:55:25,900
So what history? Our students score is due to an event beyond the antidrug education program.

389
00:55:26,650 --> 00:55:36,730
So maybe there was some issue in the school or in the school district where drugs or, you know, anti-drug messages were.

390
00:55:39,230 --> 00:55:45,010
You know, became more present. So again,

391
00:55:45,010 --> 00:55:55,240
context is important in this case with maturation of our student scores due to internal changes among participants as opposed to the antidrug program.

392
00:55:56,610 --> 00:56:06,389
So, you know, for example, maybe students are getting older and so they have more pronounced attitudes toward drug use,

393
00:56:06,390 --> 00:56:10,770
whether anti-drug use or pro-drug use.

394
00:56:11,400 --> 00:56:17,310
Either way, the idea is that as they get older, the attitudes start to kind of solidify.

395
00:56:18,350 --> 00:56:22,040
And you can't measure that because you don't have you don't have your arm.

396
00:56:23,620 --> 00:56:31,430
Pretest. You're one group pretest post-test design.

397
00:56:32,740 --> 00:56:37,400
Again, you can see there's lots of threats. History and maturation.

398
00:56:37,420 --> 00:56:39,910
Similarly, there's no control or comparison group.

399
00:56:42,110 --> 00:56:50,150
So you don't know if that history or maturation is there because you don't have a way of measuring it in another group.

400
00:56:52,330 --> 00:57:02,200
When it comes to testing instrumentation and regression to the mean, there's multiple measurements and again, there's no control or comparison group.

401
00:57:02,800 --> 00:57:11,350
Now you can control for those threats, like you can control for instrumentation by not changing help you can help mitigate.

402
00:57:11,380 --> 00:57:17,800
But what you can't do is know if those factors are at play by being able to confirm

403
00:57:17,800 --> 00:57:22,810
or deny that through measure the measurement of the control or the comparison group.

404
00:57:23,750 --> 00:57:31,220
So maybe at play. But you can't pick it up, statistically speaking, because you don't have another group to compare to.

405
00:57:33,490 --> 00:57:40,630
And then selection and attrition are not applicable because there is no control or comparison group.

406
00:57:46,060 --> 00:57:52,510
So looking at the one group pretest post-test design example again.

407
00:57:52,510 --> 00:57:58,720
So we're looking at student attitudes toward drugs and we're looking at this antidrug education program.

408
00:58:00,700 --> 00:58:07,240
So history threat. So there could be outside events that caused a change in attitudes toward drugs.

409
00:58:10,050 --> 00:58:17,520
A maturation threat to internal changes among participants account for any changes in attitudes toward drugs.

410
00:58:18,560 --> 00:58:27,530
Again, you can't tell because you don't have a comparison group testing threat that taking the pretest produced a change in attitudes toward drugs.

411
00:58:28,280 --> 00:58:33,410
So now that you have the pretest and play, it could be that people learned about,

412
00:58:34,400 --> 00:58:37,460
you know, the dangers of drugs from the way your questions were formed.

413
00:58:38,650 --> 00:58:45,190
Instrumentation threat. Did anything change with our measure from pretest to pulse test and then regression to

414
00:58:45,190 --> 00:58:51,310
the main threat that students who are retested score especially high or low pretest?

415
00:58:58,070 --> 00:59:02,300
And then finally our post-test only with comparison group.

416
00:59:07,690 --> 00:59:12,700
So your history. So, you know, it's nice you have the comparison group.

417
00:59:13,420 --> 00:59:23,920
So what you might find is that with history and maturation, it could be problematic if the comparison and intervention groups differ.

418
00:59:25,440 --> 00:59:31,420
Um. Maybe, you know, again, if you're looking at youth, maybe they differ by age.

419
00:59:35,890 --> 00:59:44,080
In terms of testing, interpretation and regression to the mean the not applicable because there is only one measurement.

420
00:59:44,650 --> 00:59:48,550
So again, you have the pulse test that's only one measurement.

421
00:59:49,000 --> 00:59:57,130
So you're not going to have a testing threat because. They are not potentially learning from the pretest.

422
00:59:58,230 --> 01:00:01,500
You don't have an instrumentation of threat because.

423
01:00:02,570 --> 01:00:11,330
You only administered the survey once and then the regression to the mean because there there is no change in scores that you're looking at.

424
01:00:12,240 --> 01:00:20,490
You're only looking at the comparison of the score between the intervention group and the comparison group.

425
01:00:22,470 --> 01:00:25,020
However, you do have a selection threat.

426
01:00:25,410 --> 01:00:33,390
So if your participants are not randomized into one group, which with a comparison group are not they're not randomized.

427
01:00:33,630 --> 01:00:38,790
That's a characteristic of the biggest characteristic or difference between the control and a comparison.

428
01:00:40,080 --> 01:00:44,380
So you have a selection bias. And then attrition.

429
01:00:44,650 --> 01:00:58,820
Again, differential dropout is possible. So here's let's look at you know the post only what comparison group example.

430
01:01:03,400 --> 01:01:07,370
So you have two classes. Little typos.

431
01:01:09,450 --> 01:01:14,300
You have students who are Miss A's class who are receiving the intervention,

432
01:01:14,690 --> 01:01:20,450
and then you have students in Mr. B's class who are not receiving the intervention.

433
01:01:21,200 --> 01:01:25,010
But then you measure them both at post-test.

434
01:01:25,900 --> 01:01:29,020
To see what their attitudes about drugs are.

435
01:01:30,540 --> 01:01:37,920
So a history threat that outside events occur for students in one class, different, differently versus the other.

436
01:01:39,300 --> 01:01:48,340
Maybe there's some kind of. Well, at least I know when I was in middle school, there was a drug dealer and one of my in my health class.

437
01:01:49,840 --> 01:01:54,910
You would not know. We're like, Oh, let's see.

438
01:01:55,090 --> 01:02:01,590
Oh, he's selling weed in the class. But maybe that maybe he was just it was just our class.

439
01:02:01,620 --> 01:02:06,330
But, you know, obviously, he wasn't in the other health classes dealing drugs.

440
01:02:06,780 --> 01:02:11,510
So that can make a difference. Nor did I really.

441
01:02:12,180 --> 01:02:15,750
Come on, now. Yeah. No trifling stuff happening in middle schools to.

442
01:02:17,670 --> 01:02:23,010
Maturation threat. The internal changes differ for students of one classes versus the other.

443
01:02:24,600 --> 01:02:30,979
It could be that, you know. On a you know, on age.

444
01:02:30,980 --> 01:02:36,080
They just happened to be the older middle school students versus the younger middle school students.

445
01:02:38,980 --> 01:02:44,200
Selection threat. How do students and Ms. A's class differ from those in Mr. B's class?

446
01:02:45,190 --> 01:02:52,210
Bless you. Maybe there's a reason why some people were placed in Miss A's class.

447
01:02:52,510 --> 01:02:59,680
First, Mr. B's class. That has to do with characteristics or vulnerability to drug use.

448
01:03:02,690 --> 01:03:06,440
What you won't know unless you unless you are working with your stakeholders.

449
01:03:07,350 --> 01:03:12,840
And then attrition, where students of one class are less likely to complete the pulse test versus the other.

450
01:03:14,060 --> 01:03:23,030
Maybe one of them. Like maybe Mr. B loves to talk or may miss A loves to talk and didn't really have time to administer the test.

451
01:03:23,850 --> 01:03:34,710
And so only if, you know, there is a differential impact on the numbers and as a result, the characteristics of the groups.

452
01:03:36,090 --> 01:03:39,330
And again, we're talking about characteristics that we can observe.

453
01:03:39,990 --> 01:03:44,370
I mean, you know, I want to emphasize that like it, they may not be different at all.

454
01:03:44,580 --> 01:03:54,160
But if they're different. The if the observation is different, then that affects our ability to have confidence in the results.

455
01:03:58,940 --> 01:04:02,810
All right. Any questions about how those threats function?

456
01:04:10,960 --> 01:04:17,000
All right. So I want to end just by, you know, looking at or.

457
01:04:18,110 --> 01:04:26,800
Before I do the summary, of course, but. Looking at these different scenarios, they're really simplified.

458
01:04:29,590 --> 01:04:41,030
But we'll work with them. So the first threat over the course of an intervention designed to educate pregnant women about third trimester health risk.

459
01:04:41,660 --> 01:04:45,680
Participants progressed through their second and third trimester.

460
01:04:49,560 --> 01:04:57,740
What threat is it? I hear somebody say maturation and maturation is the answer.

461
01:05:02,990 --> 01:05:10,200
So again. Maybe it's meant to educate pregnant women about third trimester health risks,

462
01:05:10,200 --> 01:05:15,360
but as they go through the third trimester, they're going to start noticing those health risks already.

463
01:05:16,810 --> 01:05:21,670
Or at least symptoms of those health risks and might jump on the Internet to figure out why.

464
01:05:22,900 --> 01:05:28,600
All right. During a pretest, participants realized that they learned more about HIV transmission.

465
01:05:31,500 --> 01:05:32,880
Testing? Yeah.

466
01:05:38,160 --> 01:05:46,860
And I should note that in this case, although they realize that they learned they could not realize that they learned it doesn't matter.

467
01:05:49,280 --> 01:05:58,230
But they still learned it. A researcher selects one group of schools to serve as an intervention group and another for a comparison group,

468
01:05:58,680 --> 01:06:06,810
not realizing that the comparison group's schools recently hosted a guest speaker speaking on the same topic as the intervention.

469
01:06:21,600 --> 01:06:26,560
The selection bias. Because there they are.

470
01:06:26,600 --> 01:06:39,810
They've been selected into one group. And they are different and they are different in terms of what happened between the pretest and the post.

471
01:06:41,730 --> 01:06:47,220
Or I should have put that information. But theoretically, if this is a pretest post post test.

472
01:06:51,810 --> 01:06:57,180
Or even if it's a pulse test that the selection bias can have an impact.

473
01:06:58,600 --> 01:07:06,850
All right. Participants completing a pretest for an evaluation score high on knowledge and attitudes on healthy eating.

474
01:07:08,410 --> 01:07:21,260
And then they are recruited into the subsequent intervention. Yeah.

475
01:07:21,990 --> 01:07:25,320
I see you all dancing around. It's funny how you all are dancing around it.

476
01:07:25,800 --> 01:07:30,900
Regression to the mean. Yeah.

477
01:07:30,900 --> 01:07:33,990
Like yeah, but ah yeah.

478
01:07:34,260 --> 01:07:41,880
Regression to the mean. So they're extremely high and then you pull them into the study which you know, even though you know.

479
01:07:44,140 --> 01:07:47,770
Changing hot. You know, maybe this. I probably should have said scoring low.

480
01:07:48,860 --> 01:07:53,480
That makes more sense conceptually. Sorry.

481
01:07:53,750 --> 01:07:57,890
I'm sorry. And at the Somalis as we're going. But it's all learning.

482
01:07:59,370 --> 01:08:07,260
Participants in a gun violence prevention intervention live in this state that recently had a visible policy campaign for gun restriction.

483
01:08:12,320 --> 01:08:18,980
Yeah. History. Her Somebody say history and it's history because there's an external event that happened.

484
01:08:20,570 --> 01:08:25,520
In between. When the intervention started and when the intervention ended?

485
01:08:25,820 --> 01:08:35,930
Yes. Also. It could be.

486
01:08:40,340 --> 01:08:49,820
Yeah, I'm. What? Want to make sure.

487
01:08:54,100 --> 01:09:07,040
Hit. I would say that. It's it's really about like with history.

488
01:09:08,240 --> 01:09:16,760
With history, you know that it happened, whereas the ambiguous temporal precedence is about the lack of clarity of knowing.

489
01:09:18,250 --> 01:09:23,200
So like the ambiguity of knowing. So this. It could be because.

490
01:09:24,230 --> 01:09:29,600
It could be that the campaign happened before the intervention.

491
01:09:30,500 --> 01:09:36,710
It could be that it happened after and then that the outcome and this really also about the outcome.

492
01:09:37,550 --> 01:09:41,130
The ambiguity and ambiguity. So you just don't know what came first.

493
01:09:41,960 --> 01:09:46,450
So it could be. It could be. History is when you know for.

494
01:09:47,670 --> 01:09:56,520
When you are able to know for certain when the event itself occurred and the event itself occurred between the intervention and.

495
01:09:57,660 --> 01:10:01,420
And the outcome. Yes.

496
01:10:01,870 --> 01:10:09,730
Why is. History.

497
01:10:09,750 --> 01:10:18,210
It could be history. Well.

498
01:10:23,930 --> 01:10:27,140
It could be history if you know when it occur.

499
01:10:28,800 --> 01:10:43,390
Right. The reason why I wrote Selection Bias is because what I wanted to target you on is like this idea that something happened.

500
01:10:44,880 --> 01:10:53,360
And. And so there is some difference between the two groups that you need to be aware of.

501
01:11:01,700 --> 01:11:07,400
And so I'm I'm glad you asked that question, because that shows you that there can be multiple threats at play.

502
01:11:13,550 --> 01:11:18,490
Which one? Yep.

503
01:11:18,520 --> 01:11:28,740
This one could be history three. Of a big ambiguity, this ambiguous, ambiguous.

504
01:11:36,450 --> 01:11:39,600
Even I have to look at it. Oh, my Lord. I can't even spell it.

505
01:11:42,170 --> 01:11:45,530
Oh, yeah. Know what I mean? I'll finish spelling it.

506
01:11:45,530 --> 01:11:51,440
Yes, later. All right. Because of the timing of the pulse test.

507
01:11:52,290 --> 01:11:57,990
And so this number six is referring to number five because of the timing of the pulse test.

508
01:11:58,410 --> 01:12:05,750
It is unclear whether observe changes supporting gun violence prevention happen after the intervention started or after the campaign.

509
01:12:10,360 --> 01:12:24,440
Yeah. I'm going to spell it now.

510
01:12:38,070 --> 01:12:46,540
Any questions? So in summary.

511
01:12:47,920 --> 01:12:52,480
When we're talking about internal validity, we're talking about confidence and.

512
01:12:53,470 --> 01:12:57,070
At least our ability to infer a cause and effect relationship.

513
01:12:57,940 --> 01:13:04,959
And then threats to internal validity include history, maturation, regression to the mean selection,

514
01:13:04,960 --> 01:13:12,100
bias, attrition, testing, instrumentation and ambiguities and but ambiguous.

515
01:13:13,090 --> 01:13:18,620
Temporal precedent. Precedents. And my mouth is fully dry now.

516
01:13:21,440 --> 01:13:26,760
All right. So on Thursday, we'll talk about external validity.

517
01:13:26,780 --> 01:13:32,960
We'll also talk about multicultural validity as well.

518
01:13:35,000 --> 01:13:39,299
All right. Office hours will be held somewhere.

519
01:13:39,300 --> 01:13:45,210
One of those small room 1625 is technically the room, but it's never open.

