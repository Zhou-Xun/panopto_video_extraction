1
00:00:00,180 --> 00:00:05,940
Q for providing some feedback on the course and on doing discussions on, you know,

2
00:00:06,180 --> 00:00:12,389
the long term goal of the department is to revise some of these module, module classes.

3
00:00:12,390 --> 00:00:16,260
And I'm on the curriculum committee and that's a big thing that we've been doing recently.

4
00:00:17,460 --> 00:00:23,780
So, you know, things are going to change a bit, but at least from my perspective, there's just like so much material that I want to get through.

5
00:00:23,790 --> 00:00:32,580
So I do understand that there's there's a lot that we are getting through, but I'm excited about it and I hope I can pass off that excitement.

6
00:00:32,940 --> 00:00:38,640
And at the very least, I want to give you a taste of some of the code which might be useful for you in the future.

7
00:00:39,540 --> 00:00:42,899
Okay, so just like a few things.

8
00:00:42,900 --> 00:00:52,020
First off, feel free to if we're in here for, you know, water dream bio breaks like it's all very open.

9
00:00:52,800 --> 00:00:57,120
Obviously do not come to class if you are sick or not feeling well.

10
00:00:57,240 --> 00:01:01,260
Just message me or email me as soon as you are able to.

11
00:01:02,550 --> 00:01:07,170
The final exams due December 15th. That is also in the syllabus.

12
00:01:07,740 --> 00:01:11,340
I think one of the things that you mentioned with what works good in discussion

13
00:01:11,340 --> 00:01:15,450
groups is to have like a bit of time individually to think about things,

14
00:01:15,450 --> 00:01:18,390
but then also to have time to work with your group mates.

15
00:01:19,260 --> 00:01:26,640
So I'm hopefully going to be able to structure our small group work to kind of incorporate some of those comments from you.

16
00:01:28,650 --> 00:01:32,220
The other thing is, you know, I,

17
00:01:33,270 --> 00:01:42,030
I think there are certainly some people who are more open to talking more in small groups and some people who are less likely to.

18
00:01:42,060 --> 00:01:49,170
And that's all to say. If you find yourself, you know, not talking a lot, obviously feel free to paper.

19
00:01:49,170 --> 00:01:56,400
But if you feel you feel like you are talking a lot or like relatively more than other people in your group,

20
00:01:56,700 --> 00:02:04,500
I think that's a great opportunity for you to kind of ask what other people are feeling or to take a step back and start listening a bit more.

21
00:02:04,620 --> 00:02:09,239
But, you know, this is all a bit of a balance and this is part of life and part of teamwork is

22
00:02:09,240 --> 00:02:13,290
just kind of coming up with with those balances and what what feels good for you.

23
00:02:15,540 --> 00:02:18,530
Okay. So let's go over this quiz again.

24
00:02:18,540 --> 00:02:25,440
It's ungraded, but this is just my way of talking through with you some of the big topics from the previous week.

25
00:02:27,030 --> 00:02:31,590
So I guess this is the first one. It's more syllabus wide or more like a course slide.

26
00:02:32,790 --> 00:02:40,320
So how much time are you spending on this class outside of this class period?

27
00:02:40,860 --> 00:02:49,950
I would say that like the the the happy amount would be somewhere in between one and a half to 3 hours, because they do want you to have time,

28
00:02:49,950 --> 00:02:54,329
like as an individual or in groups to kind of digest this material and to go over the coding,

29
00:02:54,330 --> 00:02:58,020
which isn't really something that I'm able to do as a lecturer.

30
00:02:59,640 --> 00:03:08,549
But if you are getting above like the four hour mark, please do you know, this could be a sign to reach out to me,

31
00:03:08,550 --> 00:03:16,230
to reach out to you and maybe like a bit earlier on and just like, see if we can help you along at all.

32
00:03:17,080 --> 00:03:22,920
The other thing, and I think you were all very good this past week with it, but if you have questions,

33
00:03:23,250 --> 00:03:28,440
certainly feel free to, you know, send me an email up to like an hour before when the assignment is due.

34
00:03:28,440 --> 00:03:31,829
But I'm like a bit slower to respond to things over the weekend,

35
00:03:31,830 --> 00:03:41,430
although I do look a few times here and has requested that if you have questions for her to get them to her by Friday at noon,

36
00:03:42,150 --> 00:03:44,129
if it's related to the homework assignment,

37
00:03:44,130 --> 00:03:53,070
which is due that weekend and I think Helen is like great at troubleshooting code especially are certainly I can try to help out with that as well,

38
00:03:53,070 --> 00:03:56,490
but I think that's what she's particularly good at.

39
00:04:00,110 --> 00:04:06,680
Okay. See, we found the influenza vaccine to be 60% effective in the case control or whatever kind of study.

40
00:04:07,130 --> 00:04:15,560
Which of the following is likely true? And the answer would be probably this first one.

41
00:04:15,680 --> 00:04:20,510
The odds of having influenza is 0.4 times as high in the vaccine group compared to the unvaccinated group.

42
00:04:21,290 --> 00:04:27,739
So I think most people got like the point four times and that's the kind of the big thing because 60% effectiveness,

43
00:04:27,740 --> 00:04:33,440
we just do one minus the odds ratio of the risk ratio to get this number, it's an attributable fraction.

44
00:04:35,780 --> 00:04:42,290
So that's what's wrong. But these two answers and the reason why odds is correct is because this is a case control study.

45
00:04:42,710 --> 00:04:48,620
And again, you know, this might be a bit pedantic because some case control studies can approximate risk.

46
00:04:49,100 --> 00:04:51,950
So I'd be a bit more explicit on a test or something like that.

47
00:04:51,950 --> 00:04:56,990
But I just think this one is a bit more precise with the limited information we've given.

48
00:04:58,520 --> 00:05:05,100
But I do understand why somebody would say this. Okay.

49
00:05:05,450 --> 00:05:09,560
What is not a good reason to use the odds ratio.

50
00:05:10,910 --> 00:05:14,260
So let's go through these. It is an appropriate measure for a case control study.

51
00:05:14,270 --> 00:05:18,070
That is true in court studies.

52
00:05:18,080 --> 00:05:21,260
It can approximate a risk ratio with rare outcomes.

53
00:05:22,130 --> 00:05:25,880
That is also that is also true.

54
00:05:26,570 --> 00:05:30,740
It can be a measure of last resort if there are insurmountable convergence issues.

55
00:05:30,740 --> 00:05:38,180
That is true. I think logistic regression is again, those are relatively easy for your for your computer program to process.

56
00:05:38,180 --> 00:05:46,850
And if you ever get into more advanced methods, I think convergence issues start to become a bit of a problem because of its formula.

57
00:05:46,850 --> 00:05:51,200
It appears to have a larger effect size and a risk ratio. And obviously this is the answer I would say here.

58
00:05:51,530 --> 00:05:57,620
It's just like this is obviously we're not using an odds ratio just because it looks bigger than a risk ratio.

59
00:06:02,580 --> 00:06:06,320
Any questions on that? Okay.

60
00:06:06,470 --> 00:06:10,490
What does collapse ability mean? It is this first step.

61
00:06:10,520 --> 00:06:15,950
The total effect size is somewhere between the strata specific effect sizes and what we've seen is for the odds ratios.

62
00:06:15,950 --> 00:06:23,120
Sometimes this is the case, but sometimes it is not. And this one, the strata specific effect size equals the total effect size.

63
00:06:23,120 --> 00:06:29,629
This is just a case of this where everything's the same. So this is true, but it's not comprehensive.

64
00:06:29,630 --> 00:06:32,690
It's not incorporating this idea as well.

65
00:06:34,280 --> 00:06:36,200
So collapse ability doesn't really I mean,

66
00:06:36,200 --> 00:06:42,080
it's related to confounding in the sense that sometimes we're looking at whether something's collapsible over a confounding variable,

67
00:06:42,590 --> 00:06:47,389
but they're kind of separate concepts. Confounding is more of a theoretical issue.

68
00:06:47,390 --> 00:06:50,660
Collapsible is more of like a statistical mathematical issue.

69
00:06:53,600 --> 00:06:55,430
Any questions. Overall,

70
00:06:56,300 --> 00:07:05,330
when graphically depicting estimates for risk difference what the scale should be on and the answer is actually the normal did not log transformed.

71
00:07:05,660 --> 00:07:14,060
So we only log transform things if we have some sort of measure of something on a multiplicative scale or a ratio measure.

72
00:07:14,660 --> 00:07:19,400
So if it's a risk ratio, if it's an odds ratio for it's a rate ratio, then we use the log transformed axis.

73
00:07:19,820 --> 00:07:28,460
And again and just think about it like a log transformed axis is symmetrical around one, whereas the normal accurate axis is symmetrical around zero.

74
00:07:28,970 --> 00:07:33,110
So just think about like what is the measure of association we have and then use that according.

75
00:07:36,550 --> 00:07:43,220
Any questions on these questions? Okay.

76
00:07:43,520 --> 00:07:47,620
So let's get. Oh, yeah, I have a question.

77
00:07:50,720 --> 00:08:00,720
For the time being. Final assignments have confirmed that.

78
00:08:10,130 --> 00:08:13,970
Good question. Let me just go to the camp.

79
00:08:16,270 --> 00:08:19,819
I mean, I think the exam it should be due December 15th.

80
00:08:19,820 --> 00:08:24,950
I'm fairly certain of that. So I'm sorry if it's put on a wrong date, but.

81
00:08:29,430 --> 00:08:32,639
Lemon. Yeah. Thanks for. Let me know.

82
00:08:32,640 --> 00:08:45,820
I will change that. It should be. Okay.

83
00:08:46,320 --> 00:08:56,070
Thank you. Thank you. Okay. So today we are going to be talking about causal inference and the whole idea behind causal.

84
00:08:56,070 --> 00:09:01,770
For instance, I think we were we've been trying to get at this idea of causality probably from your first day

85
00:09:01,770 --> 00:09:07,740
of episode 600 and maybe from many of the classes which you have taken as an undergraduate.

86
00:09:08,280 --> 00:09:15,479
Um, causal inference is this concept of can we relate a cause and effect,

87
00:09:15,480 --> 00:09:23,370
can we relate to variables together and say with a high degree of confidence that by having this,

88
00:09:23,370 --> 00:09:29,370
this, this, this certain level of this exposure, that that led to a certain outcome.

89
00:09:31,260 --> 00:09:36,270
So and then also as the has ever gotten the assignment or the attendance sign in sheet.

90
00:09:37,710 --> 00:09:48,690
Okay, so but causal inference, there's not like a fancy magical way of all of a sudden snapping your fingers and deciding,

91
00:09:48,690 --> 00:09:54,450
oh, this actually is a causal relationship. And this is not like things are just much more complicated than that.

92
00:09:55,410 --> 00:10:01,010
And I think this is put really well in this article written by Rothman and Greenland,

93
00:10:01,020 --> 00:10:07,680
saying that causal inference is better viewed as an exercise in measurement rather than a criterion guided process.

94
00:10:08,040 --> 00:10:13,409
So I'm going to be talking to you today about some things, but it's not you know, it's not about that.

95
00:10:13,410 --> 00:10:19,500
There are certain criteria that we need to fulfill for us to have something, you know, have a causal relationship or not.

96
00:10:20,340 --> 00:10:23,909
It's just that, you know, I want this class in throughout this entire semester.

97
00:10:23,910 --> 00:10:31,560
First is to be thinking a bit more clearly about what are some ways that we do measurement, what are we, what are some ways we do sampling?

98
00:10:32,010 --> 00:10:36,660
And in some situations we can have more confidence in our results.

99
00:10:38,610 --> 00:10:45,870
Okay. So in your small groups, I want you to think about these words cause correlation, association, relationship.

100
00:10:47,370 --> 00:10:54,689
How are they the same? How are they the different? Are there some which are more specific than others do some kind of like or some more colloquial,

101
00:10:54,690 --> 00:11:00,690
some more statistical and maybe think of, you know, some examples which might contrast them.

102
00:11:01,440 --> 00:11:04,500
So I will give you a few minutes to work on.

103
00:11:14,785 --> 00:11:20,155
I've been hearing some really interesting discussions and we're just calling a couple of groups to hear what you have to say.

104
00:11:20,215 --> 00:11:26,905
Could we start with let's start in the back. So the dengue five, what did you have to say about this?

105
00:11:29,615 --> 00:11:33,165
So you go. Oh, just like what? What, what? What did you.

106
00:11:33,175 --> 00:11:37,765
What are you talking about as a group? What are your thoughts on the difference or the similarities between these words?

107
00:11:39,285 --> 00:11:42,445
So when we talked about I guess we have.

108
00:11:45,165 --> 00:11:51,065
Turkey's Heritage Association is making some sort of one very important.

109
00:11:52,415 --> 00:11:55,745
Passenger, please.

110
00:11:56,675 --> 00:11:59,405
Yeah, it's it's hard to not use these words over and over again. Yeah.

111
00:12:00,245 --> 00:12:06,845
The correlation is more direct in terms of like a positive or numerical, something positive compared.

112
00:12:08,465 --> 00:12:12,865
Association poverty in terms of poverty.

113
00:12:13,475 --> 00:12:18,395
And yet you have some really interesting things you said.

114
00:12:18,935 --> 00:12:22,205
Maybe I'll move on to the and then I'll come back to that in a moment.

115
00:12:23,285 --> 00:12:26,524
This new group in the back group H. Any thoughts from you all?

116
00:12:26,525 --> 00:12:32,435
Are anything different or anything the same from what the previous group said?

117
00:12:32,835 --> 00:12:36,394
Well, I think that's one of the terms.

118
00:12:36,395 --> 00:12:42,005
So say that clause makes it easier for to just.

119
00:12:44,085 --> 00:12:50,804
Yeah. So kind of putting together what you two have said clearly things like association and relationship

120
00:12:50,805 --> 00:12:55,875
are a bit broader and a bit vaguer and may be kind of like the category of us talking about.

121
00:12:55,875 --> 00:13:02,565
If there's a change in levels of some variable, then it's like kind of related to changes in another variable.

122
00:13:04,005 --> 00:13:11,445
Correlation in my mind starts to get into some more statistical concepts thinking of like a correlation coefficient,

123
00:13:11,775 --> 00:13:15,945
although I think colloquially it probably means the same thing as association relationship.

124
00:13:16,305 --> 00:13:19,965
But I would really like to reserve this word cause for one,

125
00:13:19,965 --> 00:13:28,965
we're a bit more sure that actually a change in this one variable actually does relate to a change in another variable and isn't just spurious,

126
00:13:28,965 --> 00:13:32,415
isn't just because we have sampling bias, isn't just because there's confounding.

127
00:13:34,395 --> 00:13:38,295
And, you know, this is something that we've been trying to teach you throughout this,

128
00:13:39,555 --> 00:13:42,575
throughout your time here at the University of Michigan, how to do that.

129
00:13:46,685 --> 00:13:53,275
Okay. So I'm sure you've heard this saying correlation does not mean causation.

130
00:13:53,885 --> 00:13:58,624
It's said often in a very trite manner and there's all sorts of fun graphs.

131
00:13:58,625 --> 00:14:05,825
So this is one looking at the number of pirates in the world over time and the global annual average temperature.

132
00:14:06,245 --> 00:14:15,065
And as there are fewer pirates, there is a higher amount of, you know, our average temperature is higher.

133
00:14:16,685 --> 00:14:21,125
But then people will say, like, oh, do pirates cause or they're pirates?

134
00:14:21,125 --> 00:14:24,244
The reason that we were able to tamp down on global average temperatures and

135
00:14:24,245 --> 00:14:32,915
I think we all think that's very serious and there's other things going on. But I do want to say that correlation sometimes can mean causation.

136
00:14:32,915 --> 00:14:38,375
So I don't want you to be these jaded people who whenever you look at a statistic in the future, you look at a correlation,

137
00:14:38,375 --> 00:14:43,804
doesn't mean causation because that's not fun and that's not, you know, where we exist as epidemiologists.

138
00:14:43,805 --> 00:14:49,385
Like when you work on your daily projects, I want you to think like there could be some causation here.

139
00:14:49,745 --> 00:14:55,535
Or when you're working on some research in the future or whatever, don't just think that everything is spurious and there's like,

140
00:14:55,535 --> 00:15:01,415
you know, some mystical third variable that can be driving all these associations you're seeing.

141
00:15:02,735 --> 00:15:07,775
And so Ronald Fisher is one of the fathers of statistics.

142
00:15:08,285 --> 00:15:14,255
And it turns out, you know, he a very famous person he came up with like that Fisher's test.

143
00:15:14,945 --> 00:15:17,825
He came up with this idea of an Alpha level 0.05.

144
00:15:18,095 --> 00:15:26,105
So a lot of what we do in on in epidemiology, a lot of our culture is kind of started by him in a way.

145
00:15:27,305 --> 00:15:31,745
There is this award just as an aside, there is an award from the American Statistical Association,

146
00:15:31,745 --> 00:15:34,895
which was named after him, and it was one of their biggest awards they give researchers.

147
00:15:35,705 --> 00:15:38,975
But actually they changed it a few years ago because it does sound that Fisher,

148
00:15:39,425 --> 00:15:46,865
like many statisticians and epidemiologists of the twenties and thirties, was was racist, a bit of a eugenicist.

149
00:15:47,285 --> 00:15:49,625
So we're trying to move beyond that history a bit.

150
00:15:50,195 --> 00:15:57,094
But one other thing is that he believed that the smoking lung cancer relationship was spurious because even at that point in time,

151
00:15:57,095 --> 00:16:02,465
you know, there were these observational studies out there that smokers were more likely to get lung cancer.

152
00:16:02,795 --> 00:16:05,885
But he thought there was a third like genetic variable driving it,

153
00:16:06,275 --> 00:16:12,724
basically thought there were like genes that would basically certain alleles would predispose

154
00:16:12,725 --> 00:16:16,205
you to having lung cancer and that would also predispose you to smoking behaviors.

155
00:16:17,315 --> 00:16:18,605
And whenever I hear people saying,

156
00:16:18,605 --> 00:16:25,594
like certain genes or certain to levels relate to behaviors that I always like makes me think a bit more in-depth about it.

157
00:16:25,595 --> 00:16:28,385
But, you know, this is the early days of genetics.

158
00:16:29,255 --> 00:16:35,765
But anyway, so he would it would be one of those people saying like, oh, smoking and lung cancer correlation does not mean causation.

159
00:16:35,765 --> 00:16:39,665
But, you know, I think at this point in time, we do think for that case he does.

160
00:16:41,705 --> 00:16:47,045
Okay. So, again, I'm not trying to give you a list of criteria to follow for causal inference,

161
00:16:47,045 --> 00:16:52,504
but this is sort of something to have handy and to be thoughtful about. So of course, you need to have a good sampling scheme.

162
00:16:52,505 --> 00:16:56,705
If you have a highly by a sample, you know, that's probably not going to be telling you much.

163
00:16:57,545 --> 00:17:02,885
You need to be able to correctly specify your statistical or your, you know, if you're doing a mathematical model.

164
00:17:03,545 --> 00:17:09,815
And by that I mean, you know, are you are you dichotomous in your outcome or do you have a continuous outcome?

165
00:17:10,085 --> 00:17:15,155
Think about whether using like a ratio measurement or a difference measurement, kind of the things we talked about last week,

166
00:17:17,705 --> 00:17:21,995
you'll, you know, you'll want to control for confounding if this is an observational study.

167
00:17:23,375 --> 00:17:29,644
And then I want you to be able to think thoughtfully about what a change in your exposure means.

168
00:17:29,645 --> 00:17:33,815
And that's what we'll be doing at the end of this class. So just put a pin on this doc for now.

169
00:17:34,325 --> 00:17:39,065
And then in the subsequent weeks we'll also be doing quantitative bias analysis.

170
00:17:42,935 --> 00:17:46,025
So I do really want to advocate for using drugs.

171
00:17:47,555 --> 00:17:50,825
So again, I think this is something that we've kind of planted in your head a bit.

172
00:17:51,245 --> 00:17:59,795
Directed acyclic graphs. They can depict statistical associations that are implied by the underlying causes

173
00:17:59,795 --> 00:18:03,875
structure of our our diagram or the associations that we were looking into.

174
00:18:04,325 --> 00:18:09,665
And I find them incredibly useful for helping us choose regression covariance.

175
00:18:10,895 --> 00:18:14,735
The one thing that I want you to keep in mind, though, is that as you set up a DAG,

176
00:18:15,725 --> 00:18:20,645
the the program where you're putting a DAG into an we'll be doing this indirectly today.

177
00:18:20,645 --> 00:18:29,585
But, you know, whatever you're using to to use tags like the program doesn't know if all the arrows that you come up with are true or not.

178
00:18:29,585 --> 00:18:32,585
They don't know if this is actually like real association.

179
00:18:32,595 --> 00:18:42,275
So thinking about the culture of epidemiology, maybe we always think that there's this relationship between, for instance, you know,

180
00:18:42,275 --> 00:18:48,995
maybe we think there's a relationship between like gender and people's drinking habits

181
00:18:49,925 --> 00:18:53,795
and maybe and I'm just just throwing something out there and maybe that's true.

182
00:18:53,795 --> 00:18:57,155
Maybe it's not. But like, for every arrow that you're putting into a dag,

183
00:18:57,485 --> 00:19:01,625
you should have like a strong theoretical foundation for and you should be

184
00:19:01,625 --> 00:19:06,365
able to pinpoint to some kind of like big review articles or things like that,

185
00:19:06,665 --> 00:19:11,315
which are, which are able to articulate why there actually is that causal relationship there.

186
00:19:11,645 --> 00:19:12,815
So don't just like, you know,

187
00:19:14,435 --> 00:19:22,385
I like I would advocate for you for your elite projects or for any research that you do in the future to actually come up with a dag.

188
00:19:22,835 --> 00:19:26,195
But be really thoughtful about where you're putting each of the arrows.

189
00:19:26,195 --> 00:19:30,094
And that's something to, you know, have a discussion with your advisor about as well.

190
00:19:30,095 --> 00:19:35,525
But just, you know, be be thoughtful. And that's the whole idea of this garbage in, garbage out,

191
00:19:35,525 --> 00:19:39,455
because you could put all these zeros all over the place, which don't make any sense whatsoever.

192
00:19:39,455 --> 00:19:43,654
And they'll give you a different answer. Okay.

193
00:19:43,655 --> 00:19:47,915
So what should you control for in a traditional regression model?

194
00:19:48,725 --> 00:19:54,005
And we'll be talking about some differences later today and then I'll say next week.

195
00:19:54,005 --> 00:20:01,235
But in general, you control for confounders and you do not control for meteor's mediators or colliders.

196
00:20:02,645 --> 00:20:13,865
So by confounding, we mean that a confounder is it might be a causal ancestor of the exposure and the outcome,

197
00:20:15,485 --> 00:20:20,855
or it could be in the pathway between the exposure and the outcome, but not being a mediator.

198
00:20:23,325 --> 00:20:29,685
So sometimes you see this double headed arrow. And oftentimes this is a shorthand way of saying that there's another variable,

199
00:20:29,685 --> 00:20:35,745
like a fourth variable out here, which is related to both the exposure and the confounder.

200
00:20:36,345 --> 00:20:44,475
So this is what this double header opens. So how do we deal with confounding?

201
00:20:45,855 --> 00:20:52,515
You know, do you remember from your intro AP class like the mantra translocation, indirect standardization, direct standardization.

202
00:20:53,655 --> 00:21:03,525
I will say that, you know, I remember even from my epidemiology exam as a Ph.D. student, you know, learning how to calculate amount of hands equation.

203
00:21:04,025 --> 00:21:07,355
I have never done that since.

204
00:21:07,365 --> 00:21:12,735
I've never even seen an article which has used to be until hand. So but apparently we find that important to teach to your students.

205
00:21:13,515 --> 00:21:19,754
But so I will say that like different different disciplines or different researchers might have different ways of dealing with confounding.

206
00:21:19,755 --> 00:21:25,695
That's okay. Mental handle, I think, is just like a bit more of a simplistic way when you only have like one confounder.

207
00:21:27,495 --> 00:21:35,355
Standardization is often used in demography when we're kind of doing age based standardization or age standardized death rates, things like that.

208
00:21:37,005 --> 00:21:38,105
We could stratify our models.

209
00:21:38,105 --> 00:21:44,565
So if we have a confounder, we could just create, you know, if it's a dichotomous confounder, we could just stratified based on that.

210
00:21:45,495 --> 00:21:48,404
But oftentimes what we do is multivariable models.

211
00:21:48,405 --> 00:21:55,965
And by that I mean, you know, we have a statement in in SAS where we have a model, the outcome equals the exposure.

212
00:21:55,965 --> 00:21:59,105
But then we have a number of different confounders listed after.

213
00:22:00,465 --> 00:22:05,145
And of course we can also use causal inference methods and we'll be talking about those today.

214
00:22:07,385 --> 00:22:11,644
I guess another way of dealing with confounding is student experiments where you randomize people's exposures,

215
00:22:11,645 --> 00:22:17,455
but this is just how to deal with confounding in an observational study. Okay.

216
00:22:17,465 --> 00:22:25,354
So again, only our is a belief he's actually the president of the society for after much research right

217
00:22:25,355 --> 00:22:29,885
now but at least you know a big mythologist in our field and he has a saying when in doubt,

218
00:22:29,885 --> 00:22:35,735
dig it out. And so that is what I want you to do as our small group discussion part two.

219
00:22:36,305 --> 00:22:46,685
So go to Dalgety dot net or if you don't have a computer with you, you know, just follow along with somebody else near you and try to replicate this.

220
00:22:46,985 --> 00:22:54,325
And it's always different, you know, if you have a PC versus a mac. But in general, you know, there will already be some pre-planned.

221
00:22:55,095 --> 00:23:02,645
There will be a model there. One thing you can do is, if you like, hover over it and press D, it will delete that variable.

222
00:23:04,205 --> 00:23:11,945
If you then click on something a click on like an empty area of the space, it'll create a new variable.

223
00:23:13,845 --> 00:23:20,674
One thing you'll just want to keep in common is the social support is the main exposure, and depression is the main outcome.

224
00:23:20,675 --> 00:23:25,775
So keep those those kind of need to be listed as like the mean variables.

225
00:23:26,485 --> 00:23:32,735
I will also see like I these are some of the variables that were listed in the reading for today.

226
00:23:32,915 --> 00:23:35,915
I just made up these relationships, so I do what you're not supposed to do.

227
00:23:36,155 --> 00:23:40,595
I didn't do a extravagant literature review to see how these things are related.

228
00:23:40,985 --> 00:23:46,115
So don't, you know, treat these variables or these arrows is actually what happens in reality.

229
00:23:46,385 --> 00:23:51,305
But just for the sake of us doing the small group discussion. Okay, so I will leave you to it.

230
00:23:51,935 --> 00:23:55,145
I'll be walking around if you have any questions on how to do this.

231
00:23:55,655 --> 00:24:14,145
Please, please. Time the third.

232
00:24:18,755 --> 00:24:23,485
I was for. The day. I got it.

233
00:24:27,065 --> 00:24:44,712
And when I think about. Yeah. So when we.

234
00:24:48,253 --> 00:24:51,673
Let me go to a group in the back.

235
00:24:53,293 --> 00:24:59,652
Group K, what variables did you do you think we should control?

236
00:24:59,653 --> 00:25:04,393
For? What variables do you think we should not control for given this diagram?

237
00:25:09,723 --> 00:25:13,703
Tell. Yep.

238
00:25:13,873 --> 00:25:19,473
So, you know, planned pregnancy and marriage are probably collider's in this situation.

239
00:25:19,483 --> 00:25:23,773
You can see that here because there's arrows pointing at them. That's pretty a good sign.

240
00:25:23,773 --> 00:25:32,352
But in my mind, like, you know, there are some people who are able to look at this visually and think about like back door paths and things like that.

241
00:25:32,353 --> 00:25:39,853
That never has really resonated with me. So I always just dump things into Daugherty because I find it like very intuitive and very easy to use.

242
00:25:40,273 --> 00:25:52,423
If you use AR, there's actually ways of integrating this into our but also a nice thing with this is you can save your code here.

243
00:25:52,903 --> 00:25:56,503
So if you wanted you could like paste this into your group guide for today,

244
00:25:58,003 --> 00:26:00,853
which is all to say, you know, you're probably never going to come back to this Dag.

245
00:26:01,213 --> 00:26:07,843
But for yourself, if you're like working through something, just like save your moral code and then you can always,

246
00:26:08,603 --> 00:26:15,403
you know, come back to you in the future if it has to be updated. But yeah, so this generally we're looking for adjustment for a total effect.

247
00:26:15,913 --> 00:26:22,183
And, you know, in a in a mediation class, we also talking about direct effects.

248
00:26:22,933 --> 00:26:26,293
So if you're doing like a mediator or something, you could you could do that.

249
00:26:26,293 --> 00:26:30,323
So. Okay. Any questions on this, though?

250
00:26:37,663 --> 00:26:40,663
Okay. So what do we mean by causal and print methods?

251
00:26:40,663 --> 00:26:49,453
And I've always found this to be a bit ambiguous and I think it's unfortunately people just like make it more confusing than it needs to be.

252
00:26:49,453 --> 00:26:54,903
And honestly, like, economists will often just say like a multivariable model,

253
00:26:54,913 --> 00:26:58,213
like something we've been doing or you probably been doing for a couple semesters now.

254
00:26:58,213 --> 00:27:01,513
They'll just talk about that in terms of as being a causal inference method.

255
00:27:02,983 --> 00:27:11,143
But generally in epidemiology, we want we want like a bit more evidence for us to say that something is a causal inference method.

256
00:27:12,403 --> 00:27:21,253
So here's the back story. So of course we use, you know, we use a variety of different study designs,

257
00:27:21,253 --> 00:27:27,013
but there are downsides to randomized controlled trials even, but especially to observational studies.

258
00:27:27,793 --> 00:27:32,353
So in observational studies we might have time varying confounding and I'll give an example of that later.

259
00:27:33,133 --> 00:27:36,192
We could also have unobserved or substantially observed, confounding.

260
00:27:36,193 --> 00:27:40,573
There could be like residual confounding. Unobserved just means that we're not measuring it.

261
00:27:42,223 --> 00:27:46,783
We could have unknown confounding. That's also something in randomized controlled trials.

262
00:27:46,783 --> 00:27:52,903
We could also have patient noncompliance. So it could be that people just like are not completing the treatment regimen that we gave them.

263
00:27:53,833 --> 00:28:01,273
It also could be that, like the randomization assignment is broken if patients are somehow able to self-select their own treatment.

264
00:28:04,093 --> 00:28:07,063
So there's different types of causal inference methods and really, you know,

265
00:28:07,123 --> 00:28:12,463
we'll be focusing on marginal structure models, although I'll give an example of a Mendelian randomization as well.

266
00:28:12,883 --> 00:28:14,472
But there's different families of these.

267
00:28:14,473 --> 00:28:21,043
There's the G estimation family, there's instrumental variables, there's regression discontinuities, there's difference in differences.

268
00:28:21,733 --> 00:28:26,713
Again, I don't expect you to remember all of these, but maybe just something for the future.

269
00:28:26,713 --> 00:28:34,273
If you hear some of these, it's probably because somebody is trying to do something fancy and make some assumption of causality.

270
00:28:35,773 --> 00:28:43,033
G estimation. The word g stands for general, and maybe it's a bit of hubris, but the people who kind of came up with this method,

271
00:28:43,513 --> 00:28:50,383
they thought that it would eventually become the general way that people conduct or people come up with models.

272
00:28:51,043 --> 00:28:56,923
And then, you know, it really isn't too much more difficult than a typical multivariable model that we do.

273
00:28:57,703 --> 00:29:05,203
But it is, you know, it's still an extra step and may or may not give you different answers for g estimation.

274
00:29:05,203 --> 00:29:09,012
There's a number of different there's a different number of different techniques.

275
00:29:09,013 --> 00:29:12,162
Is all of these kind of rely on this idea of propensity scores?

276
00:29:12,163 --> 00:29:16,243
And again, I'll go over that. But what you do with the propensity score is could be different.

277
00:29:16,513 --> 00:29:19,933
But if you here propensity score is if you hear inverse probability of treatment,

278
00:29:19,933 --> 00:29:23,743
if you hear marginal structural models, these are all very related things.

279
00:29:25,903 --> 00:29:29,083
Okay, so why would we do this?

280
00:29:29,263 --> 00:29:33,673
Let's say that we have this conceptual idea.

281
00:29:34,393 --> 00:29:53,143
We want to look at how easy to use leads to or prevents people from, prevents people living with HIV from coming down with AIDS.

282
00:29:55,123 --> 00:30:04,723
So first, this is, you know, we need more of a longitudinal design so we could look at what are people's use of the zidovudine, this AZT.

283
00:30:04,753 --> 00:30:07,813
What is it like at time zero? What is it like at time one?

284
00:30:08,983 --> 00:30:17,563
The problem, though, is that this is heavily influenced by this time varying confounder, which is the CD4 count levels.

285
00:30:18,043 --> 00:30:20,743
So CD4 is just a measure of immune functioning.

286
00:30:21,733 --> 00:30:29,383
I would say right now, most of the time the people living with HIV are just put on some sort of antiretroviral like start reading very early on.

287
00:30:29,383 --> 00:30:32,082
But in many places, or at least in the past,

288
00:30:32,083 --> 00:30:39,583
what would happen is they would wait until your CD4 levels decreased beyond a certain point before giving you them,

289
00:30:41,893 --> 00:30:45,523
which is all to see that in an observational study,

290
00:30:45,823 --> 00:30:56,683
your CD4 levels could be a confounder because your CD4 levels could directly relate to whether a physician prescribes you zidovudine or not.

291
00:30:57,433 --> 00:31:05,713
And, of course, your CD4 levels. This is a measure of immune functioning. This could definitely relate to whether you succumb to AIDS or not.

292
00:31:07,153 --> 00:31:14,203
But if you are given AZT at the beginning of a study, then you might have a change in your city.

293
00:31:14,203 --> 00:31:22,993
Four levels. So again, this is all to say that this CD4, it it occupies a function as both a mediator and confounder.

294
00:31:23,233 --> 00:31:30,943
And I think you can see that here, that it is a confounder at time zero, but it is a mediator at times.

295
00:31:32,023 --> 00:31:36,673
I think this is kind of an important concept. So does this make sense or is there any way could we explain this?

296
00:31:39,823 --> 00:31:42,823
Okay. Yeah, he said.

297
00:31:42,893 --> 00:31:51,463
I think I was saying D for apologies if I did say AZT, but CD4 is of course here.

298
00:31:51,463 --> 00:31:54,852
You know they're there. I get what you're potentially thinking.

299
00:31:54,853 --> 00:32:00,453
AZT at time one might be a mediator, but that's just a function of, you know, us measuring this at multiple time points.

300
00:32:00,703 --> 00:32:04,513
But you could just, you know, do your analysis with AZT at 10.0.

301
00:32:07,963 --> 00:32:17,963
So this this is the mediator right here. And this is also something which they did in the reading that you did for today.

302
00:32:18,503 --> 00:32:23,093
They were interested in social support at 10.1 and at time point to.

303
00:32:23,843 --> 00:32:27,473
The problem is, how do you deal with depression?

304
00:32:27,923 --> 00:32:37,523
Because depression is a mediator at Timepoint one, but a confounder at time two.

305
00:32:42,383 --> 00:32:48,473
Okay. So backing up again, what are the various methods? So what we're trying to do is we're going to develop a propensity score.

306
00:32:48,833 --> 00:32:53,333
And what we do with that propensity score kind of differs depending on what method you're using.

307
00:32:54,953 --> 00:33:00,443
There is a propensity score matching where you know you give a propensity score to everyone than match them based on it.

308
00:33:01,343 --> 00:33:05,213
You can also develop weights using the propensity score and that's generally what people do.

309
00:33:05,213 --> 00:33:09,082
So that's what we're going to be talking about today is this marginal structural method.

310
00:33:09,083 --> 00:33:12,053
But there are people who use propensity scores in different ways.

311
00:33:13,163 --> 00:33:17,933
So what we mean by propensity score or propensity score is your probability of being in a treatment group.

312
00:33:18,263 --> 00:33:24,023
Given a set of covariates. This set of covariates does not include the outcome.

313
00:33:24,113 --> 00:33:28,073
So like no outcome here. These are basically just like the confounders.

314
00:33:28,643 --> 00:33:35,943
So the covariates are the confounders. So what does this mean concretely?

315
00:33:35,943 --> 00:33:46,113
Say we have this study and this is just like a very simplified definition or a simplified study where there's just like one exposure,

316
00:33:46,113 --> 00:33:49,563
one outcome, and then two confounders, that's Z one and Z two.

317
00:33:51,363 --> 00:33:54,842
And of course, there would be a lot more ID numbers.

318
00:33:54,843 --> 00:33:59,163
I'm just giving you some examples, but a by a propensity score,

319
00:33:59,193 --> 00:34:05,883
we set up a logistic regression model where we model the outcome being X equals one and this is where things are confusing.

320
00:34:05,883 --> 00:34:09,123
So we're not modeling where Y equals one. That's like the main thing.

321
00:34:09,453 --> 00:34:11,163
But for the propensity score,

322
00:34:11,463 --> 00:34:19,623
we are modeling what x equals and then we only include the confounders that's covariates like we do not include the outcome.

323
00:34:21,753 --> 00:34:29,763
And then the propensity score is just a value between zero and one, which is given to us by the program generally.

324
00:34:29,763 --> 00:34:36,002
Like when you output like proc logistic or the typical logistic package in R,

325
00:34:36,003 --> 00:34:41,492
it just like won't give you the propensity score where you just kind of need to ask the program to give it to you,

326
00:34:41,493 --> 00:34:43,623
but it's not difficult for the program to do it.

327
00:34:44,463 --> 00:34:52,563
And I know I was harping on logistic regression models last week, but actually for propensity scores, logistic regression models are fine.

328
00:34:53,073 --> 00:35:00,993
So, you know, for if your outcome of doing a multivariable regression model is just to get this propensity score,

329
00:35:01,323 --> 00:35:03,273
then it's okay to use a logistic regression model.

330
00:35:05,523 --> 00:35:13,113
But yeah, so you know, this propensity, this is like what is somebody propensity for having an X equal to one?

331
00:35:14,283 --> 00:35:24,993
So theoretically, the closer we are to one and zero, the more that our model is able to completely explain everything away.

332
00:35:25,683 --> 00:35:30,633
But we kind of don't want that. We want things to hug together in the center as a propensity score.

333
00:35:35,443 --> 00:35:40,483
So what can we do with these propensities? First one is we can compare them between the control and the treatment groups.

334
00:35:42,553 --> 00:35:49,663
And here these are just histograms which are flipped sideways and then just like mirrored onto each other.

335
00:35:51,103 --> 00:35:55,153
So again, this is just these values right here and if we're just graphing them,

336
00:35:56,563 --> 00:36:00,673
so basically control again, this is in a case control study, this is the exposure level.

337
00:36:00,673 --> 00:36:06,463
So this is like people who have a placebo. So thinking about people have a placebo versus like an actual drug.

338
00:36:08,823 --> 00:36:13,233
The shorthand is B is what we want. We want there to be overlap in the propensity score.

339
00:36:13,263 --> 00:36:18,243
So we want it to seem like the people's propensity scores are the same.

340
00:36:19,023 --> 00:36:25,233
And think about it. This is like basically what a randomized controlled trial does, because in a randomized controlled trial,

341
00:36:25,443 --> 00:36:31,563
you evenly distribute the confounders between the people who got the placebo and the people who got the drug.

342
00:36:33,153 --> 00:36:39,693
So this is how a randomized controlled trial works, and this is what we want to do through with propensity scores.

343
00:36:39,993 --> 00:36:40,413
And again,

344
00:36:40,413 --> 00:36:48,543
the way that the propensity scores work is that we just lump a lot of confounders together and then we try to come up with this propensity score,

345
00:36:49,953 --> 00:36:55,352
whereas in a randomized controlled trial, we could just I mean, you could come up with a propensity score for randomized controlled trials,

346
00:36:55,353 --> 00:36:59,793
but for a randomized controlled trial, this is what it would look like for every single variable.

347
00:37:01,353 --> 00:37:07,383
It won't be that for an observational study, but in an observational study, if we developed these propensity scores, then we can even think so.

348
00:37:09,483 --> 00:37:18,003
This is a this is an example where there is a, you know, there's too much predictive power in the covariates.

349
00:37:18,513 --> 00:37:22,373
Basically, this is this is saying that if we know what the covariates are,

350
00:37:22,383 --> 00:37:26,733
we know what the confounders are, then we know what their treatment level is going to be like.

351
00:37:27,963 --> 00:37:31,293
And so it doesn't even matter that we have those covariates like that.

352
00:37:32,103 --> 00:37:36,933
There's just nothing that we can do. We can't make any assumption of causality in our study.

353
00:37:39,163 --> 00:37:40,273
This one is a bit of a hybrid.

354
00:37:40,273 --> 00:37:49,753
There's like some area of overlap, but then there are tail ends which where there isn't any similar propensity score in the other group.

355
00:37:51,283 --> 00:37:57,043
In an example like this, you might actually have to trim, you might actually have to get rid of the people up here and the people down here.

356
00:37:57,343 --> 00:38:02,353
And then in your study design, you might just have to say, Oh, we had to trim our propensity scores.

357
00:38:02,353 --> 00:38:05,413
We're removing these outliers on the top and the bottom.

358
00:38:05,743 --> 00:38:11,413
As a result, maybe your study is only generalizable to a certain group of individuals, so there'd be some limitations to that.

359
00:38:13,563 --> 00:38:17,673
This is a bit of a tough graph to kind of grapple with.

360
00:38:18,183 --> 00:38:22,173
I know I struggle just having to, like, look at this and think through what it means.

361
00:38:23,823 --> 00:38:25,563
Any questions on this?

362
00:38:40,773 --> 00:38:48,062
So for the propensity score, because the difference between a propensity score and just like X is X, at least for everything in this class,

363
00:38:48,063 --> 00:38:56,283
we're just doing dichotomous variables, so it's one or zero, but propensity score is just continuous between zero and one.

364
00:38:57,033 --> 00:39:04,593
But the idea is like if you could completely predict your values of X from Z one and Z two, like an example would be.

365
00:39:07,773 --> 00:39:14,762
Okay. So I've been doing a lot of stuff with vaccinations, so maybe we're thinking of like X being our vaccinated Y being whether you get COVID

366
00:39:14,763 --> 00:39:21,513
or not and maybe Z one and Z to our Z one is like your political affiliation.

367
00:39:22,653 --> 00:39:25,023
Z two is your age.

368
00:39:25,713 --> 00:39:31,383
And unfortunately, it happens to be the case in the United States that if we controlled for your age and your political affiliation,

369
00:39:31,713 --> 00:39:37,293
we'd have a strong predictive ability to figure out what your vaccination status is.

370
00:39:37,803 --> 00:39:44,673
So these would be like really highly dissociated, you know, so they would kind of cluster towards one and cluster term zero.

371
00:39:45,783 --> 00:39:49,593
So but like what we're trying to do is if you add enough covariates in,

372
00:39:49,833 --> 00:39:55,023
you can kind of like push the propensity scores more towards like the middle, more towards like point five.

373
00:39:56,503 --> 00:40:03,093
Yeah. So I mean, it kind of depends on what you want to use propensity score, score because like in other instances, in other situations,

374
00:40:03,093 --> 00:40:10,413
you might just want to like predict something really well, in which case like it's great if something's really close to one or really close to zero.

375
00:40:10,863 --> 00:40:18,813
But for our case, we really want these probably to be closer to 0.5 so that there's more overlap between the different groups.

376
00:40:20,223 --> 00:40:27,363
Yeah. Because like here we can kind of tell, oh, these are sort of wants, they're probably ones, these are closer to zero, they're probably zero.

377
00:40:28,113 --> 00:40:35,432
But it would be lovely to live in a world where we didn't see what this X was and the propensity score is just kind of close.

378
00:40:35,433 --> 00:40:40,353
2.5 So we're not really able to tell what the what the value of X is.

379
00:40:42,643 --> 00:40:49,823
Does that answer any other questions? Okay.

380
00:40:51,743 --> 00:40:55,402
So what you do for a marginal structure model? There's basically a two step process.

381
00:40:55,403 --> 00:40:58,823
We create a weights and then we estimate the regression model.

382
00:40:58,853 --> 00:41:04,133
So how do we create a weight? We use these propensity scores,

383
00:41:04,403 --> 00:41:11,183
and what we try to do is create this like pseudo this fake population where there's no confounding through those propensity scores.

384
00:41:11,933 --> 00:41:18,563
And then we use this propensity scores as a witness in a regression model instead of using them as covariance.

385
00:41:20,993 --> 00:41:30,263
Okay. So I think we're about at the halfway point, so why don't we take a ten minute break and then we will be back at 2 a.m.

386
00:41:42,803 --> 00:41:49,993
So a recap. For two pregnant women, they were sampled during the first and third trimesters.

387
00:41:50,753 --> 00:41:57,233
This is longitudinal of the same women. And they measured I think there is there's a couple of different measures of social support.

388
00:41:57,713 --> 00:42:01,793
And also they had their outcome measured on a depression scale.

389
00:42:04,403 --> 00:42:11,813
Okay. So this is kind of what they wanted to be able to measure.

390
00:42:12,173 --> 00:42:19,313
This is this is like the final thing they want to be able to do in their study.

391
00:42:20,153 --> 00:42:23,963
They wanted to measure what was depression like.

392
00:42:24,983 --> 00:42:26,933
They were being depression at time point, too.

393
00:42:28,973 --> 00:42:33,023
And they were interested in how is that influenced by social support at time, point one in time for two.

394
00:42:33,023 --> 00:42:37,553
And then also this interaction between social support at 10.1 and 10.2.

395
00:42:37,913 --> 00:42:42,863
So that's what this multiplicative salience and we'll be talking more about interaction next week but.

396
00:42:46,543 --> 00:42:50,853
So what we need to do is we need to develop propensity scores.

397
00:42:50,863 --> 00:42:55,843
And so this is where I'm kind of trying to explain to you a bit more in depth on what they do.

398
00:42:56,833 --> 00:43:02,833
So for the first part, if we're just looking at Timepoint one, we have social support at TIMEPOINT one,

399
00:43:02,833 --> 00:43:08,643
we have depression at Timepoint one, and then we have confounders. And these are like the time invariant confounders.

400
00:43:08,653 --> 00:43:18,433
So these are the confounders for everybody. So then what you do for the, the propensity scores is you put together this model.

401
00:43:18,433 --> 00:43:22,033
So the logic of social support being equal to one.

402
00:43:22,033 --> 00:43:30,072
And again for propensity scores, our outcome is the exposure for like the mean study.

403
00:43:30,073 --> 00:43:36,193
Of course outcome is like the outcome, it's depression, but for propensity score is the outcome is social support.

404
00:43:38,323 --> 00:43:43,183
And then basically we just do a multivariable model where we include all the different confounders.

405
00:43:44,653 --> 00:43:46,693
Does this model make sense?

406
00:43:48,663 --> 00:43:57,482
It's just your typical multivariable logistic regression model with, you know, all the confounders and again, just the content.

407
00:43:57,483 --> 00:44:00,963
You don't include depression in this, just that confounders.

408
00:44:03,463 --> 00:44:08,583
Yeah. So what's going?

409
00:44:10,693 --> 00:44:15,283
You mean this, like, right here? Yeah, so we saw that.

410
00:44:15,283 --> 00:44:23,983
So, um, you know, we have our, ah, the base of the propensity score is just this logistic regression model.

411
00:44:24,793 --> 00:44:31,153
But what we do is, if you remember from a few slides ago, this is actually called an inverse probability of selection.

412
00:44:31,513 --> 00:44:38,983
So inverse just means one over a number. So we come up with this propensity score and then we do one divided by that propensity score.

413
00:44:42,353 --> 00:44:47,333
The other thing that we added is we add in the mean value of social support.

414
00:44:48,533 --> 00:44:53,873
So this is just a fancy way of writing out what is the mean value of social support in this sample?

415
00:44:54,383 --> 00:45:00,623
This is called stabilizing the inverse. We it it doesn't really matter conceptually.

416
00:45:00,953 --> 00:45:05,603
I think that this is just like a statistically it balances out the weights a bit more.

417
00:45:05,903 --> 00:45:10,493
But it it's not an important takeaway message from my perspective.

418
00:45:11,483 --> 00:45:14,063
So you first come up with this logistic regression equation.

419
00:45:14,453 --> 00:45:22,493
You output your propensity scores to tell you these things, and then you do one divided by this.

420
00:45:27,083 --> 00:45:31,843
That's the most important part. So now let's just put a pin on that.

421
00:45:31,853 --> 00:45:37,583
That's the first part. Now, let's just do the second part. For the second part, we have an extra confounder.

422
00:45:38,093 --> 00:45:44,123
So we still have our time invariant confounders, but then we also have depression at Timepoint one.

423
00:45:44,903 --> 00:45:49,673
So in this model we are looking at.

424
00:45:53,153 --> 00:45:59,573
Sir, I want to correct this before. This is wrong, but this is actually social support at time.

425
00:45:59,573 --> 00:46:09,753
Point to that sort of speed. So social support at 10.2, and that is equal to our confounders.

426
00:46:09,753 --> 00:46:17,233
But along with depression, because depression at Timepoint one is now a confounder, not depression at time, we do not this one, this one.

427
00:46:19,473 --> 00:46:26,643
And then same thing. We also do one divided by that, and then we multiply it by the mean value of social support at temperature.

428
00:46:29,593 --> 00:46:33,103
Yeah. One thing. Very. One.

429
00:46:35,683 --> 00:46:39,553
We're all doing that in the city at risk of developing.

430
00:46:40,753 --> 00:46:44,443
That seems like somewhere from the beginning for.

431
00:46:46,893 --> 00:46:50,453
That is a great question. Um, yeah, I see what you're saying.

432
00:46:50,463 --> 00:47:00,033
So like in any. So the question is, is depression somehow even something of a confounder at some point one especially

433
00:47:00,033 --> 00:47:03,462
since depression could be related to the self support that you get at some point.

434
00:47:03,463 --> 00:47:08,853
What? So I don't have an answer for that, except that that would be something that you'd want to consider as part of your study design.

435
00:47:09,753 --> 00:47:15,243
And in any cohort study, you want everybody to be eligible for getting the outcome.

436
00:47:15,723 --> 00:47:22,503
So some people already have depression then, you know, theoretically these should have been excluded at baseline from this analysis.

437
00:47:23,073 --> 00:47:28,483
Yeah. But I don't I don't remember what these authors exactly did, but great point.

438
00:47:29,953 --> 00:47:36,322
Any other questions? Okay.

439
00:47:36,323 --> 00:47:40,853
So the beautiful thing about coming up with these weights is that we just multiply them together.

440
00:47:41,363 --> 00:47:47,753
So we had our things at 10.1. We multiply them by the things at 10.2, and then we get our total.

441
00:47:51,063 --> 00:47:54,063
Selection weights are total inverse probability rates.

442
00:47:56,403 --> 00:48:03,063
Now, if you have a more complicated study design where you have waits for the selection procedure or maybe you have weights for attrition,

443
00:48:03,393 --> 00:48:07,833
you can also multiply those. So the wonderful thing about weights is you can kind of like multiply all of these together.

444
00:48:13,033 --> 00:48:20,142
Okay. So this is and then what they were able to do is in their model, again,

445
00:48:20,143 --> 00:48:25,753
they are interested in looking at what social support is there, type one and type two.

446
00:48:26,143 --> 00:48:30,043
And through their interaction terms, they basically come up with four different exposures.

447
00:48:31,153 --> 00:48:35,473
You know, did they have low social support at both time points? Low, high, high, low, high, high.

448
00:48:36,193 --> 00:48:49,123
And then they tried to look at what is the risk of developing or the odds of developing depression.

449
00:48:51,253 --> 00:48:54,033
I will note that like, you know, they don't have it.

450
00:48:54,073 --> 00:48:59,683
If you look at this like really pedantic Leigh, they don't have anything that is statistically significant.

451
00:49:00,163 --> 00:49:07,273
You know, this number right here is it crosses one, so it probably is a P-value above 0.05.

452
00:49:07,633 --> 00:49:12,673
But in epidemiology, we're kind of moving towards us thinking a bit more broadly inclusively.

453
00:49:13,813 --> 00:49:20,563
And we want to kind of consider the whole message here. And what we're really seeing is that, you know,

454
00:49:20,593 --> 00:49:31,423
especially this low in this time point two is particularly problematic because people who all of a sudden, you know, come from low and they get high.

455
00:49:31,933 --> 00:49:35,353
They don't have much of an increased risk.

456
00:49:41,893 --> 00:49:46,983
Any questions about the study? Okay.

457
00:49:46,993 --> 00:49:52,652
So the other thing that I want to mention about this study is how it works and how

458
00:49:52,653 --> 00:50:00,003
marginal structural models work is that you have those you have this these weights.

459
00:50:00,813 --> 00:50:06,783
You have these weights here. Since you have these weights, you do not need to include covariates in your multivariable regression model.

460
00:50:07,293 --> 00:50:12,183
So basically when you're coming up with your equation, you will have a very simple model statement.

461
00:50:12,243 --> 00:50:19,923
It'll just be, you know, sort of square one or like your outcome is depression.

462
00:50:19,923 --> 00:50:24,062
So depression equals social support one. And for them the, you know, they have this interaction term.

463
00:50:24,063 --> 00:50:30,633
So they did have depression equals social support one plus social two plus the interaction between them.

464
00:50:32,313 --> 00:50:40,263
But they could have just had of for one as as their their their main thing he be able

465
00:50:40,323 --> 00:50:44,703
to straight that out because this is kind of an important thing for you to remember.

466
00:50:45,603 --> 00:50:53,883
So yeah when you do this. Use the inverse.

467
00:50:56,543 --> 00:51:07,643
Probability weights in the model do not also include covariance in the model statement.

468
00:51:11,883 --> 00:51:19,023
So generally in, you know, in any program like in SAS or an are there some way to specify what the weights should be like?

469
00:51:20,673 --> 00:51:23,613
And, you know, I have code for you for this homework assignment for this week.

470
00:51:25,873 --> 00:51:32,472
So you're saying you need to specify the weights, but then don't you know, don't also include them like all these other variables.

471
00:51:32,473 --> 00:51:39,703
And I think, you know, they had like marriage and whether this was an unintended pregnancy, race, ethnicity,

472
00:51:39,703 --> 00:51:44,442
age, like you don't need to include those as covariates and in the way it's like that's kind of double dipping.

473
00:51:44,443 --> 00:51:51,522
You only need to put them in the weights. I think they'll be like kind of a parent as you do the homework assignment.

474
00:51:51,523 --> 00:51:55,963
But any questions on that? Okay.

475
00:51:59,373 --> 00:52:07,353
Let us shift to talking about another type of causal inference method called instrumental variables.

476
00:52:08,853 --> 00:52:15,243
Instrumental variables are important for unmeasured confounders, so for marginal structural models you need to have measured the confounder.

477
00:52:15,603 --> 00:52:24,182
It's just in marginal structure models. We account for the confounder in the weights, not in the models data, but for instrumental variables.

478
00:52:24,183 --> 00:52:26,973
This is where we can deal with unmeasured confounders.

479
00:52:29,183 --> 00:52:35,093
So an instrumental variable or an IV is something which is related to the exposure and ideally highly related,

480
00:52:35,353 --> 00:52:43,643
but even weakly constantly associated with the exposure is fine, but it cannot be related to the outcome except through the exposure.

481
00:52:45,323 --> 00:52:49,943
So obviously in this example, you know, you would see some correlation between the instrumental variable and the outcome,

482
00:52:49,943 --> 00:52:54,053
but that would just be an artifact of the exposure being greater.

483
00:52:57,883 --> 00:53:07,333
You know, given a concrete example of Mendelian randomization. So Mendelian randomization is a type of ivy analysis where the ivy is a gene.

484
00:53:07,483 --> 00:53:15,883
And the idea of randomization here is that our genotype is randomly assigned to us from our parents at meiosis.

485
00:53:18,503 --> 00:53:26,363
So this is an example. So people for a long time have tried to look at this relationship between low cholesterol levels and individuals in cancer.

486
00:53:26,753 --> 00:53:34,463
Unfortunately, there are a lot of unmeasured confounders here, so there could be some things that we could probably try to measure, like smoking.

487
00:53:34,943 --> 00:53:39,083
Although smoking is kind of a tough thing to measure because people can kind of change their habits over time.

488
00:53:39,653 --> 00:53:43,583
Diet is something that we could try to measure, but the problem with that is, again,

489
00:53:43,583 --> 00:53:48,173
people's diet may change over time, that also people are kind of bad at reporting what they actually eat.

490
00:53:49,823 --> 00:53:55,073
Tumors is an interesting one. And by this it could be just like benign tumors that we have within our body,

491
00:53:55,373 --> 00:54:01,793
which maybe you don't typically get checked out unless you have like a full body scan being done like every six months.

492
00:54:02,513 --> 00:54:06,323
So it's not really reasonable for us to understand whether somebody has had a tumor before.

493
00:54:06,743 --> 00:54:15,053
But of course, tumors and all these things could be related to low cholesterol levels and they could be related to cancers.

494
00:54:15,413 --> 00:54:18,713
But it's just tough to think to measure all of these.

495
00:54:21,203 --> 00:54:31,913
So some researchers have a while back found out that the EPO Eugene had multiple Leos and that some of were related to low cholesterol.

496
00:54:32,273 --> 00:54:38,843
But importantly, this EPO gene and all the different ills were not related to cancer.

497
00:54:41,503 --> 00:54:45,013
So this appeal gene was really to cholesterol but not to cancer.

498
00:54:46,693 --> 00:54:56,832
So then, you know, basically what you can do is in your this is kind of another two step process where you

499
00:54:56,833 --> 00:55:03,693
will do a propensity score just looking at EPO genes and low cholesterol in your sample.

500
00:55:04,603 --> 00:55:09,763
And then you will use that propensity score as a direct predictor in your in your regression analysis.

501
00:55:10,033 --> 00:55:17,492
And then you want you to control for an confounders. But you don't need to do a Mendelian randomization for homework for today.

502
00:55:17,493 --> 00:55:20,103
This is just kind of like a general overview for you.

503
00:55:20,613 --> 00:55:28,052
And I do think in like certain types of in certain subfields, like Mendelian randomization has been taking off.

504
00:55:28,053 --> 00:55:33,863
So it might be something that you need to look into doing yourself or you might need to understand a bit more in the future.

505
00:55:33,873 --> 00:55:40,663
So this is just a bit of a taste of it. Okay.

506
00:55:41,563 --> 00:55:46,843
I wanted to spend a few minutes talking about a per protocol versus an intent to treat approach.

507
00:55:47,353 --> 00:55:52,123
And then have you discussed in small groups some some different counterfactual options?

508
00:55:52,843 --> 00:55:59,652
So what I will have you do right now is to go back to my quiz page.

509
00:55:59,653 --> 00:56:17,393
The let me give me a moment to change it. Okay.

510
00:56:20,513 --> 00:56:22,403
So go to this website and this is what I'm telling you.

511
00:56:22,463 --> 00:56:28,073
So you have unfortunately gone to the doctor and you've been diagnosed with a very serious case of cancer.

512
00:56:29,603 --> 00:56:32,753
And your doctor has told you that there are two different treatment options.

513
00:56:33,413 --> 00:56:42,142
Treatment one has a 20% chance of survival and treatment two has a 40% chance of survival.

514
00:56:42,143 --> 00:56:45,233
So which treatment would you like to do?

515
00:56:55,413 --> 00:56:59,492
And I realized maybe in your head you have all these other thoughts about like adverse events and things like that.

516
00:56:59,493 --> 00:57:06,123
Just ignore those that say the adverse events. Say this is the only information that you have.

517
00:57:06,183 --> 00:57:16,763
What would you choose? He.

518
00:57:21,823 --> 00:57:25,633
Okay. So first people want to maybe be right. That's that's that's your segment.

519
00:57:26,563 --> 00:57:33,493
Not trying to be tricky with this. This is one example. But let me actually get tricky.

520
00:57:33,653 --> 00:57:40,753
Okay. So say the doctor came back, she was like, oh, I just realize you are trained as an epidemiologist.

521
00:57:40,753 --> 00:57:47,833
Let me give you a bit of background because I forgot like one of these was measured in an attempt to treat paper and one was in a per protocol.

522
00:57:49,603 --> 00:57:56,892
So if you remember in an intent to treat analysis is like a pure is purely looking at the randomization scheme.

523
00:57:56,893 --> 00:58:06,613
So it's like who is randomized to get treatment A versus the placebo and then see what their survival is like,

524
00:58:07,333 --> 00:58:11,623
whereas a per protocol approach is looking at like what do actually people do?

525
00:58:11,633 --> 00:58:17,962
So like do people actually complete the regimen or not? So in this example, they say the doctor was great.

526
00:58:17,963 --> 00:58:27,923
He says, okay, so for this one paper, you know, if we actually look at the intent to treat results for treatment B, it's 15%.

527
00:58:28,613 --> 00:58:40,973
So, you know, now would you choose 20% survival with treatment 80, which is an intent to treat or 15% or B which is intact to treat.

528
00:58:42,893 --> 00:58:46,463
You know, you can go back to the question and respond. Respond again.

529
00:58:46,473 --> 00:59:03,552
I think you should be able to do multiple responses. Okay.

530
00:59:03,553 --> 00:59:05,263
So now there's more of you here, like, okay,

531
00:59:05,263 --> 00:59:10,933
so I am kind of getting confused on all these numbers and like the numbers for treatment, they might be better.

532
00:59:11,593 --> 00:59:15,013
I mean, that's very reasonable to be thinking given the set of information.

533
00:59:16,943 --> 00:59:21,513
We have to see, you know, the things that are happening.

534
00:59:22,673 --> 00:59:26,273
Oh, you're not kidding. The question are, is everyone getting the question at this?

535
00:59:27,383 --> 00:59:30,443
Feel like if you refresh, pull avo.com, everybody.

536
00:59:30,443 --> 00:59:34,552
My period for for what is it? Yeah. Yeah, don't worry.

537
00:59:34,553 --> 00:59:37,903
If like if if it has to. If it says that, like it lost your information.

538
00:59:38,033 --> 00:59:44,843
That's okay. You can ignore that. Yep, yep, yep. Um, so.

539
00:59:44,873 --> 00:59:49,912
Okay. And of course, you know, this is the worst day of your life, and the doctor comes back in now,

540
00:59:49,913 --> 00:59:57,143
you're very flustered at him or her, but the doctor says, okay, so actually we can look at the per protocol results as well.

541
00:59:57,623 --> 01:00:01,553
And for treatment A is 25%, and for treatment B, it's 40%.

542
01:00:05,103 --> 01:00:14,643
So what would you choose? So again, the intent to treat is like, you know, people did for treatment.

543
01:00:14,693 --> 01:00:18,182
A It's what they were randomized to for treatment.

544
01:00:18,183 --> 01:00:21,873
B It's what they were randomized to at the at the beginning of the study.

545
01:00:21,873 --> 01:00:26,973
Per protocol is just looking at over time, what kind of regimen did they actually complete?

546
01:00:36,343 --> 01:00:39,703
And I will say that, you know, you can have debates about this. I'll tell you my opinion on this.

547
01:00:39,703 --> 01:00:45,133
But I don't I don't think there's like a 100 or one exact response for this.

548
01:00:51,163 --> 01:00:55,333
Okay. So a lot of people are more interested in treatment.

549
01:00:55,333 --> 01:00:57,643
B Although, you know, some people are so interested in treatment.

550
01:00:58,633 --> 01:01:04,183
So I'm going to try to convince you that treatment B is the answer that you should choose.

551
01:01:04,753 --> 01:01:11,863
Because if we look behind these results, what's happening is that there is a substantial improvement for treatment.

552
01:01:11,863 --> 01:01:16,693
B, if we look at what people are actually doing versus how they were originally randomized.

553
01:01:18,583 --> 01:01:23,113
One thing we will see is oftentimes the per protocol will show better results than intent to treat.

554
01:01:23,113 --> 01:01:26,353
And that's just because of poor protocol. You're actually following what people do.

555
01:01:26,363 --> 01:01:31,993
So if there is some effect of the treatment, it's going to be better if it's, you know, limited to people who actually did what you went on to do.

556
01:01:33,463 --> 01:01:41,983
But for treatment B, it seems that there's such an increase probably is a sign that there might be some adverse events.

557
01:01:42,493 --> 01:01:45,943
Maybe it's a sign that there are like some other, you know,

558
01:01:45,943 --> 01:01:50,563
maybe there's some costs associated with this which won't be able to be covered by the study or whatnot.

559
01:01:52,333 --> 01:01:58,962
But how I would look on this as somebody trying to figure out what to do is that the 40%,

560
01:01:58,963 --> 01:02:02,203
you know, in my mind that would be substantially higher than 25%.

561
01:02:03,793 --> 01:02:11,533
And the 40% this is telling me that, like if I adhere to the treatment B, then I will have a pretty good chance.

562
01:02:12,343 --> 01:02:17,473
But it's also telling me that if I drop off a treatment B then, you know, like my chances for survival are much lower.

563
01:02:18,493 --> 01:02:23,773
But given that you are, you know, graduate students completing this epidemiology program,

564
01:02:24,073 --> 01:02:31,573
I think that probably indicates that you as individuals would be highly adherence to any treatments you're given in the future.

565
01:02:32,593 --> 01:02:37,523
So definitely, you know, don't be afraid to look at the per protocol results.

566
01:02:37,543 --> 01:02:44,023
I think one of the things and I don't want to say it's a mistake of previous classes, but we really emphasize the intent to treat in previous classes.

567
01:02:44,023 --> 01:02:48,342
And that's just because it's wonderful for breaking the randomization or it's breaking

568
01:02:48,343 --> 01:02:52,752
confounding so that you have complete randomization in a per protocol approach,

569
01:02:52,753 --> 01:02:57,523
you know, and we have to look to see how the the original authors and scientists were doing this.

570
01:02:57,943 --> 01:03:04,842
But we want to make sure that they're using good science, but they're probably analyzing it more with like observational methods.

571
01:03:04,843 --> 01:03:14,233
But I think that this is like some really good evidence that this is this could be a powerful treatment for many questions about this.

572
01:03:15,923 --> 01:03:20,513
So again, what I'm trying to say here is that like, you know, we'd be open to looking at the per protocol.

573
01:03:21,083 --> 01:03:24,652
And one of the reasons why I'm mentioning that is like causal inference methods,

574
01:03:24,653 --> 01:03:28,673
you know, like observational studies always do things on a per protocol approach.

575
01:03:30,023 --> 01:03:32,403
So with a randomized controlled trial, we could do either.

576
01:03:33,023 --> 01:03:37,133
But in general, in a randomized controlled trial, we're just like looking at intent to treat.

577
01:03:37,643 --> 01:03:40,523
Whereas, you know, in observational studies,

578
01:03:40,523 --> 01:03:46,763
there's no such thing as like intent to treat analysis with observational studies because like we really are looking at what people actually did.

579
01:03:48,773 --> 01:03:54,953
So there's been a number of studies which have tried to compare what's happened in randomized controlled trials and causal models.

580
01:03:55,643 --> 01:04:04,643
And these are just I think this is a systematic review of studies which have looked at both for like the same set of disease exposure.

581
01:04:05,093 --> 01:04:08,483
They've done a causal inference approach in a randomized controlled trial approach.

582
01:04:10,373 --> 01:04:11,392
We see some differences.

583
01:04:11,393 --> 01:04:18,803
But I think to me I wouldn't really even look so much at this because, you know, they're different once intent to treat and once per protocol.

584
01:04:23,663 --> 01:04:33,443
Any questions on this? We will definitely be talking more about this later.

585
01:04:33,473 --> 01:04:38,113
I think this is an important concept, but just priming, you know. Okay.

586
01:04:38,113 --> 01:04:45,432
So there's a number of different levels of evidence that we can distinguish between there is observational studies and observational evidence.

587
01:04:45,433 --> 01:04:48,103
There's experimental evidence from randomized controlled trials.

588
01:04:48,643 --> 01:04:57,013
We have causal inferences that we can make from, you know, having certain methods in observational studies and then we have counterfactual.

589
01:04:57,463 --> 01:05:04,423
So let me just give you an example of each of these, and then I'll send you in to your small groups to work through other examples.

590
01:05:05,173 --> 01:05:08,863
So let's think about vaccination and COVID 19.

591
01:05:08,953 --> 01:05:16,242
Observational evidence would be, you know, we have a cohort study here in Ann Arbor, people who've been vaccinated not we followed them over time.

592
01:05:16,243 --> 01:05:20,533
Who's got COVID 19? Who's done? That's observational evidence, right?

593
01:05:21,313 --> 01:05:22,453
Experimental evidence.

594
01:05:22,453 --> 01:05:27,553
As you know, from the phase three clinical trials, it's looking at who got the vaccine, who didn't, and then following them over time.

595
01:05:29,803 --> 01:05:34,542
You know, causal evidence might be, you know, we will look at our observational study, but, you know,

596
01:05:34,543 --> 01:05:39,073
maybe we're even able to do some instrumental variable analysis to deal with some unmeasured confounders or we,

597
01:05:39,073 --> 01:05:42,553
you know, do a deep dive into some marginal structural models, things like that.

598
01:05:43,303 --> 01:05:48,583
Maybe we do like a differences in differences approach, like there's a lot different types of causal inference methods we could use,

599
01:05:48,583 --> 01:05:54,433
but then we might start saying there's causal evidence where counterfactual

600
01:05:54,553 --> 01:06:00,343
is very much at the individual level and counterfactual is counter to fact,

601
01:06:00,343 --> 01:06:08,533
so it is not reality. And in a counterfactual evidence, what we are doing is basically I'm looking at myself,

602
01:06:08,533 --> 01:06:12,823
I'm vaccinated, I follow myself for two months to see if I get COVID 19,

603
01:06:13,603 --> 01:06:20,023
but then I go back in time and I do not vaccinate myself, but I still fall myself for two months and see if I get COVID 19.

604
01:06:23,393 --> 01:06:27,113
So counterfactual is like the time machine of changing something and somebody

605
01:06:27,113 --> 01:06:30,323
then going back in time and changing it to the other level of the explosion.

606
01:06:32,183 --> 01:06:41,902
Again, it's not part of reality. But the one linkage here is that a lot of causal inference methods are based on statistical equations,

607
01:06:41,903 --> 01:06:45,053
which are from counterfactual parts of evidence.

608
01:06:45,063 --> 01:06:50,603
So these are tied together in terms of like the the mathematical equations underpinning them.

609
01:06:50,933 --> 01:06:54,113
But clearly, counterfactual is something that we can never observe in real life.

610
01:06:57,223 --> 01:07:07,243
Okay. So I would like you to think about, um, you know, what is the counterfactual comparison in the following examples?

611
01:07:09,133 --> 01:07:13,933
So our outcome is diabetes. So think about high sugar diet and diabetes.

612
01:07:14,653 --> 01:07:17,982
Think about weight, somebody's weight and diabetes.

613
01:07:17,983 --> 01:07:21,043
And then also think about race and diabetes.

614
01:07:23,143 --> 01:07:28,123
And so I will and again, think about these in the counterfactual way.

615
01:07:28,213 --> 01:07:34,123
So not observationally, although because all of us could do a cohort study and and figure this out.

616
01:07:35,833 --> 01:07:42,643
But what what is like counterfactual? What does it mean to change your sugar diet, to change your weight, to change your race?

617
01:07:43,963 --> 01:07:48,673
And I will give you one scenario that we have.

618
01:07:49,923 --> 01:07:58,553
10 minutes. And if you are confused, that's totally fine.

619
01:08:00,233 --> 01:08:05,179
I think that's a real response. That's.

620
01:08:06,670 --> 01:08:07,030
Okay.

621
01:08:07,570 --> 01:08:18,639
So, again, the whole idea of vaccinated or not is we for COVID 19 is we vaccinated somebody, we follow them for a few months, then we go back in time.

622
01:08:18,640 --> 01:08:23,290
We do not vaccinate them and then we follow them for the same amount of time, see if they get COVID 19.

623
01:08:23,680 --> 01:08:28,480
So now we're talking about different risk factors for risk factors for diabetes.

624
01:08:29,050 --> 01:08:34,869
So sugar diet, maybe I'll start here with the group fun frequencies.

625
01:08:34,870 --> 01:08:35,800
How would you do?

626
01:08:37,440 --> 01:08:44,140
And before we start this, I want to give us like a bit of grace when we start talking about things like race or even somebody's weight.

627
01:08:44,920 --> 01:08:51,549
These are very sensitive topics. And I have like my point that I want to impress upon you by the end of the class today.

628
01:08:51,550 --> 01:08:59,379
But, you know, I certainly don't want people to feel bad if they, you know, say something or don't have to worry too much about like saying something.

629
01:08:59,380 --> 01:09:02,619
It is slightly across weight.

630
01:09:02,620 --> 01:09:10,150
Just because I think this goes back to like a history of how we do things in epidemiology might be a bit meaningless

631
01:09:10,150 --> 01:09:14,230
or might not actually be tied into a theoretical understanding of what is the counterfactual difference.

632
01:09:14,320 --> 01:09:18,129
But anyway, we'll will get into that. But let's start with a bit of an easier one.

633
01:09:18,130 --> 01:09:21,340
Sugar diet. So fun frequencies. How do you do a counterfactual?

634
01:09:23,260 --> 01:09:35,840
How do you look? Counterfactual of sugar, diet and diabetes? Well, here's a way.

635
01:09:38,400 --> 01:09:41,710
Or 2 to 0. Okay.

636
01:09:41,850 --> 01:09:48,630
Present to Rangers for how much you're consuming, because there's some guys that have no if you don't eat any sugar and.

637
01:09:51,750 --> 01:09:58,390
Yeah. So I mean counterfactual and we could argue like what is high sugar diet and what is not like it.

638
01:09:58,410 --> 01:10:07,080
And clearly this is very continuous, but you know, maybe it's people and I do really want you to think in your head like, what does it mean?

639
01:10:07,110 --> 01:10:13,200
Counterfactual. It could be for a high sugar diet that and we could think unethically about this like every

640
01:10:13,200 --> 01:10:17,580
time somebody has a glass of wine out of like shoveling and a teaspoon of sugar for them,

641
01:10:18,260 --> 01:10:24,870
I mean, like we make sure that they have their like all of their all of their soda and like have a dessert and,

642
01:10:24,960 --> 01:10:30,929
you know, they're having a high sugar diet. And then for somebody who's not on their we couldn't even, like, follow them around.

643
01:10:30,930 --> 01:10:36,720
And every time they reach for something which has, you know, added sugar levels above a certain amount, we like squatted over their hands.

644
01:10:38,070 --> 01:10:42,240
Again, we're not thinking about like ethics here. We're just thinking about like what does it actually mean?

645
01:10:42,930 --> 01:10:49,920
So that would be like a high sugar diet. And so I think there is some like meaning behind that because like we could actually measure

646
01:10:49,920 --> 01:10:55,850
what somebody's sugar intake is like over time and see how that relates to diabetes.

647
01:10:55,860 --> 01:10:57,870
That's how we would do things more observationally.

648
01:10:58,230 --> 01:11:02,250
And clearly we could also try to do some randomized controlled trial where we put people on different diets.

649
01:11:02,550 --> 01:11:06,420
But again, counter factually, it's really looking at the same individual.

650
01:11:06,900 --> 01:11:13,589
And this is you need to think about on the same individual, you're following them, you're seeing you're putting all this sugar in them,

651
01:11:13,590 --> 01:11:17,940
then you're going back in time and then you're making sure that they don't get sugar. Does that make sense?

652
01:11:20,410 --> 01:11:23,780
Okay. Ms. Let's make this a bit more complicated.

653
01:11:23,800 --> 01:11:27,130
Could you think about what does weight and diabetes mean?

654
01:11:29,780 --> 01:11:39,170
So we wrote that all of being equal, if an individual's weight at the start of the trial was different than the weight,

655
01:11:40,550 --> 01:11:44,140
they still have the same diabetes outcome. Yeah.

656
01:11:45,140 --> 01:11:49,220
So I like what you said at the beginning, like all else equal.

657
01:11:49,400 --> 01:11:54,830
But I really want to hone in on that because it's really hard to make everything else equal,

658
01:11:55,250 --> 01:12:01,140
because when we're comparing somebody is weight, she's like, Why do people gain or lose weight?

659
01:12:01,160 --> 01:12:07,490
There could be all sorts of like genetic, biological reasons, of course, like dietary reasons as well.

660
01:12:09,380 --> 01:12:15,530
But, you know, like, is somebody like why is somebody gaining a certain amount of weight?

661
01:12:15,830 --> 01:12:21,230
And then also, if you think of on an individual level, how would you get somebody to change their weight?

662
01:12:21,260 --> 01:12:31,040
Like, maybe what we want to do is to cheat. Like, you know, obviously we're going to have to somehow equalize across height and stuff here.

663
01:12:31,040 --> 01:12:38,840
But like, how would we compare somebody who is like £140 versus £150?

664
01:12:40,370 --> 01:12:48,590
So we follow somebody. Well, they are £140 and then we go back in time and we follow them when they're £150.

665
01:12:48,980 --> 01:12:53,180
But like, how do you get them from 140 to £150?

666
01:12:53,540 --> 01:12:57,320
Or we could think of it in the reverse way. Like, how do you get somebody from 140 to £130?

667
01:12:59,000 --> 01:13:04,280
So like that change in weight is what's really important because that's like what the counterfactual comparison is.

668
01:13:04,820 --> 01:13:09,410
And, you know, like you could change somebody's weight by like lopping off one of their legs.

669
01:13:10,400 --> 01:13:12,380
You could do it by like removing it or again,

670
01:13:13,130 --> 01:13:19,730
you could do it by like putting them in an austere diet and following them around so that they couldn't eat anything else.

671
01:13:20,630 --> 01:13:30,560
You could do it in more humane ways. But the thing is, how you do that probably has an enormous impact on diabetes.

672
01:13:30,760 --> 01:13:38,370
It's like if you are starving somebody so they don't eat anything for a week, that is very different.

673
01:13:38,370 --> 01:13:45,200
It's been like over two years, like every every month, like having their weight declined by £1.

674
01:13:45,290 --> 01:13:48,260
You know, these are these are very different things.

675
01:13:49,700 --> 01:13:55,759
And I think thinking about these counterfactuals is important because oftentimes there's all these observational studies will come out which says,

676
01:13:55,760 --> 01:14:02,630
oh, you know, we did a population based study of the United States. You know, the rate of diabetes and people with this amount of weight is this high.

677
01:14:02,960 --> 01:14:10,220
In this amount of weight is this high. But there's no counterfactual comparison that we can make there because you know,

678
01:14:10,220 --> 01:14:14,090
how people got to the weight that they are right now is like so radically different.

679
01:14:14,570 --> 01:14:19,590
Does it make sense? Okay.

680
01:14:19,640 --> 01:14:25,960
Now, let's move on to the really despicable discussion within her last couple of minutes of class, race and diabetes.

681
01:14:25,970 --> 01:14:29,480
Maybe I'll move to Wagner. What are your thoughts on this one?

682
01:14:31,370 --> 01:14:36,500
And it's okay if you're utterly flummoxed because. But any starting point for us.

683
01:14:45,240 --> 01:14:50,150
So we traced. The last 20.

684
01:14:57,410 --> 01:15:03,980
Yeah. So first off, what is that? I mean, what is the reference group is always like a bit contentious because like oftentimes we

685
01:15:04,220 --> 01:15:08,900
see like non-Hispanic whites in a lot of observational studies are the reference group,

686
01:15:08,900 --> 01:15:12,170
but statistically that actually doesn't matter too much.

687
01:15:12,170 --> 01:15:16,550
Although like from a standpoint of how you're interpreting results, it definitely could.

688
01:15:18,050 --> 01:15:26,300
But yeah, I think you kind of are pinning the points down really well that, um.

689
01:15:27,230 --> 01:15:30,920
Like, how, how do you change somebody's race? Is that even possible?

690
01:15:30,920 --> 01:15:34,310
Because again, in counterfactual, you're following somebody like you could follow me.

691
01:15:35,300 --> 01:15:38,330
I'm white for a few years if I had diabetes.

692
01:15:38,960 --> 01:15:46,789
But then what does it mean to go back in time and and change my race that any other group I can talk

693
01:15:46,790 --> 01:15:51,740
more about this but in any other groups have any like questions or or like any comments or any,

694
01:15:51,740 --> 01:15:56,630
any discussion points that they raised on this or this point.

695
01:16:02,420 --> 01:16:09,170
I guess my, my concluding thoughts and we really talk about counterfactuals more and more is that like I would say that like

696
01:16:09,230 --> 01:16:15,350
you can't look at race in a counterfactual way because we can't change somebody is we can't change somebody.

697
01:16:15,590 --> 01:16:19,760
Sometimes people say like, oh, what if you change like somebody's genes?

698
01:16:20,120 --> 01:16:24,790
I would say race is not just like one or two genes and it's not even a lot of genetics.

699
01:16:24,800 --> 01:16:34,220
Like there's a lot at play there. Um, the things that we're probably looking at are patterns of discrimination, patterns of racism.

700
01:16:34,550 --> 01:16:41,750
Those are things that you could randomize so you could, you know, have me have my life, have a relatively privileged existence.

701
01:16:41,750 --> 01:16:44,899
We could then like go back in time and then, you know,

702
01:16:44,900 --> 01:16:51,679
have somebody who is always like 10 minutes ahead of me who maybe influences things

703
01:16:51,680 --> 01:16:56,750
around me so that I have a certain amount of discrimination practiced against me.

704
01:16:56,760 --> 01:17:02,210
So that is something that like we could randomize we could also randomize, you know, people's educational attainment.

705
01:17:02,690 --> 01:17:08,360
We could randomize, you know, what kind of general racial wealth they're given.

706
01:17:08,660 --> 01:17:13,009
So there's all these things which are associated with race that we could randomize.

707
01:17:13,010 --> 01:17:16,910
But I would personally argue that you can't randomize race itself.

708
01:17:18,020 --> 01:17:18,160
Um,

709
01:17:19,040 --> 01:17:27,710
there are people doing like advanced work on how to think about race counterfactuals or how to think about it in like a causal inference perspective.

710
01:17:27,710 --> 01:17:28,790
That's probably a better way of putting it.

711
01:17:29,570 --> 01:17:34,970
And I would say, you know, like race, I think it's incredibly important to think about racial disparities in public health and to describe them,

712
01:17:35,510 --> 01:17:39,590
but more so to describe the reasons for them and like these other factors which are associated with them,

713
01:17:39,950 --> 01:17:44,720
rather than thinking that we could just directly change race itself. Okay.

714
01:17:44,900 --> 01:17:50,000
So I think we'll kind of take it off from here next week.

715
01:17:50,570 --> 01:17:56,760
But thanks for coming to class today and I hope you have a rigorous three.

716
01:17:57,170 --> 01:18:01,129
There is an assignment that is due this weekend, personal structure model some year.

717
01:18:01,130 --> 01:18:02,420
Hey you know if you having troubles with it.

