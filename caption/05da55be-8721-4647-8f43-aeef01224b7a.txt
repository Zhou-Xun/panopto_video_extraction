1
00:00:00,060 --> 00:00:00,690
Think about that.

2
00:00:01,530 --> 00:00:22,050
She wrote in the comments about how about a quarter, I would think, although I have you know, I had semesters cut my hair in two and four years.

3
00:00:23,100 --> 00:00:31,680
So what does it wasn't like spreading the reach of one class and things like that.

4
00:00:32,140 --> 00:00:48,750
So the ways I can best be added to this department for a beat or work and or is not a fun time.

5
00:00:49,680 --> 00:00:56,100
But it was like 5 hours a day, five and 5 hours a day, four days a week, which is a little bit of homework.

6
00:00:56,670 --> 00:01:00,600
That was like the most intensive class anybody had during the whole short term.

7
00:01:01,200 --> 00:01:10,110
And then other than that, he just had this really, really big time online here.

8
00:01:10,410 --> 00:01:22,170
Okay, my undergrad. Why do you think be restructuring doesn't seem like the whole new experience in college.

9
00:01:22,540 --> 00:01:26,010
I it. I think so.

10
00:01:26,060 --> 00:01:31,660
You think. Oh, sorry, sorry.

11
00:01:32,510 --> 00:01:42,210
Oh, no. Look in different areas for me, I feel like I would for the rest of your life.

12
00:01:43,920 --> 00:01:49,810
I think when you like eating outs, like like, you know, the beach, it's like whenever it's different.

13
00:01:49,860 --> 00:01:59,820
So we like to break into like a different kind of yeah, it's getting on like that.

14
00:02:03,390 --> 00:02:14,450
But like my friend classes for morning mornings from 9 to $100 with commodity prices.

15
00:02:14,520 --> 00:02:27,329
Oh, you're talking today for people to come because like such, we got this recent history.

16
00:02:27,330 --> 00:02:41,300
And I know that you go to philosophy, you also get away with stuff one semester in class for an hour and 20 minutes.

17
00:02:41,310 --> 00:02:48,000
I always read at night and then a 30 minute meeting with my advisor said, This is unreal.

18
00:02:48,100 --> 00:02:52,620
This is this is about things.

19
00:03:03,710 --> 00:03:20,160
This company is in discussions. I think it's going to be tremendous.

20
00:03:34,840 --> 00:03:45,060
And at the end of the semester, I think it's like.

21
00:04:07,740 --> 00:04:19,530
Today is going to be a I'm going to I'm going to be intentionally provocative and a little annoying sometimes because I want us to.

22
00:04:19,680 --> 00:04:29,490
I want us to wrestle with celebrities. We will not all agree, and that's probably a good thing.

23
00:04:31,260 --> 00:04:41,969
I will try to on when what I am framing is coming from my own personal perspectives of where the line should be drawn,

24
00:04:41,970 --> 00:04:47,520
about what is ethically appropriate for us to be doing in public health communications right now.

25
00:04:49,320 --> 00:04:54,270
You may find you wish to put that line someplace else, and that's understandable.

26
00:04:57,060 --> 00:05:06,780
My purpose for today is really to get us to own the power that we have as communicators.

27
00:05:07,840 --> 00:05:11,440
Ways in which we whether we're in public health or in medicine.

28
00:05:13,030 --> 00:05:28,889
And if we choose to do so. Being very direct is very absolute about the way in which we present risks and get people to do things, not do things.

29
00:05:28,890 --> 00:05:34,840
Because we said so. And then the question becomes, well, when is it appropriate to do that?

30
00:05:36,040 --> 00:05:48,400
Not appropriate. My goal is to get you to walk out of here always remembering this conversation so that when you are thinking about something,

31
00:05:50,170 --> 00:05:59,410
at least some part of you that in the back of your mind is going to be in which you across the door.

32
00:06:01,150 --> 00:06:07,450
So it's if I should feel comfortable defining a black and white, this is what you should do.

33
00:06:08,120 --> 00:06:11,420
That's it. And then you.

34
00:06:12,430 --> 00:06:19,930
No, I want it to be moving that individual or that group or that community's autonomy,

35
00:06:20,620 --> 00:06:28,030
even if what that means is they're going to pick something or put themselves at risk with others at risk.

36
00:06:29,620 --> 00:06:38,760
This is what I would just. Because that is the core tradeoff you don't control.

37
00:06:39,060 --> 00:06:46,760
People don't always do what we want them to do. And of health have been wrestling with this since its inception.

38
00:06:48,050 --> 00:06:52,990
In its most extreme form. We have quarantine, power and public health.

39
00:06:53,080 --> 00:06:56,260
We can literally remove people's bodily autonomy.

40
00:06:57,270 --> 00:07:02,909
For the purposes of health. That's even more extreme than what we're talking about today.

41
00:07:02,910 --> 00:07:12,870
But it's reflective of some of the challenges, the public health faces that we can be very active,

42
00:07:13,440 --> 00:07:19,590
we can bend things, we can give absolute mandate saying you must do X, you cannot do X.

43
00:07:20,100 --> 00:07:25,760
But I really want us to do today is to wrestle with. Why are we doing one thing or not doing one thing?

44
00:07:27,020 --> 00:07:33,710
To take a simple example, which I will just put out there and then in some sense bump to Nektar tomorrow to the Thursdays classic.

45
00:07:34,400 --> 00:07:40,290
That's where we'll spend most of our time talking about COVID. Why are COVID vaccines not required?

46
00:07:42,400 --> 00:07:49,880
We have a choice whether you get vaccinated. Why I take that back?

47
00:07:50,930 --> 00:07:55,960
We all have a choice. No, no.

48
00:08:01,200 --> 00:08:12,030
That choice has been removed. And to some degree, in certain health care settings, that choice is almost removed.

49
00:08:14,370 --> 00:08:15,480
The question that we wrestle with.

50
00:08:16,940 --> 00:08:24,560
There are consequences on the University of Michigan campus if you are not vaccinated, but that choice is still there.

51
00:08:24,730 --> 00:08:30,700
One can choose to do that and of the consequences of that. But in other contexts we might literally pick drugs.

52
00:08:32,420 --> 00:08:35,820
So that's what I want to wrestle with today. And how do we feel about that?

53
00:08:35,840 --> 00:08:40,250
And I know this having reviewed here, is that there is variance in opinion and that's good.

54
00:08:40,970 --> 00:08:48,330
I want us to do is to wrestle with this. Before I do that, I want to take a little bit of time to talk about the final paper.

55
00:08:52,920 --> 00:08:55,970
So if you've taken a look at it, you don't have to.

56
00:08:58,280 --> 00:09:09,020
The assignment is for you to basically make two arguments related to the idea of labeling bioengineered products.

57
00:09:10,820 --> 00:09:18,140
And this new law that came into effect in January this year requires a particular form of labeling.

58
00:09:20,600 --> 00:09:29,749
And one piece of what I want you to write about is basically the consequences of this

59
00:09:29,750 --> 00:09:40,010
are going to be how is this label going to change society's risk perceptions or not?

60
00:09:41,660 --> 00:09:49,050
We talk, for example, in last class about not 65 in the way in which the labels are becoming basically,

61
00:09:49,070 --> 00:09:52,250
you're either going to see that kind of thing happen.

62
00:09:53,270 --> 00:10:01,010
I know. We talked about the questions of trust, disclosure, deception.

63
00:10:02,430 --> 00:10:08,970
How is that going to play out in the context of this? Are people going to avoid buying certain products because of the labels?

64
00:10:09,470 --> 00:10:11,520
Ignore the labels. That's what I want you to wrestle with.

65
00:10:12,510 --> 00:10:19,830
What do you think based upon the principles of principles of this course is going to be the impact of this kind of labeling?

66
00:10:21,750 --> 00:10:25,350
And then as a separate section of your response,

67
00:10:25,740 --> 00:10:37,110
I also want you to answer the question Should the labels declaring a product to be bioengineered free or GMO free?

68
00:10:38,440 --> 00:10:44,710
Be required optional, which is where we are now or prohibited.

69
00:10:46,360 --> 00:10:50,230
The argument. You think that they serve the public interest?

70
00:10:50,260 --> 00:10:53,620
Do they help? They are.

71
00:10:55,700 --> 00:11:01,880
And yes, I'm intentionally choosing this particular risk because this is not let.

72
00:11:03,060 --> 00:11:10,680
Or other chemicals in which we have absolute clear sense as to whether or not there is significant.

73
00:11:11,920 --> 00:11:21,670
The harm that can be caused by this. So part of what you have to wrestle with is, well, is there actually a risk here?

74
00:11:22,450 --> 00:11:27,340
And if there is uncertainty about risk, do we have an obligation to talk to people about that risk?

75
00:11:28,150 --> 00:11:34,310
Are we causing harm when we talk to people about difference? All of those things are in bounds for us.

76
00:11:35,240 --> 00:11:45,110
So yeah, you get more about the rationale because it was it more like environmentally logical purposes or like for like.

77
00:11:48,430 --> 00:11:52,060
So there are many different justifications for labeling.

78
00:11:54,310 --> 00:11:59,260
I've given you some links to articles that talk about this particular.

79
00:11:59,560 --> 00:12:10,240
Well, I've gone into some other articles predate this law in terms of people's attitudes around labeling of animal products and whether those

80
00:12:10,330 --> 00:12:22,300
seem like a meeting to give people awareness of something that might be a risk or enabling them to make choices around one aspect of this.

81
00:12:24,520 --> 00:12:28,390
I don't want to do that. All of those things could be part of this.

82
00:12:31,060 --> 00:12:33,550
What I do want to be clear about is.

83
00:12:39,410 --> 00:12:45,770
What I want you to wrestle with here is to use this as a platform for talking about stuff that we talk about in this course.

84
00:12:46,970 --> 00:12:54,710
Most of the topics that we have already brought up will come to bear in some way on this this final assignment.

85
00:12:55,730 --> 00:13:00,050
You have things like me. You can go back to analytical versus experiential learning.

86
00:13:01,070 --> 00:13:08,600
We certainly can talk about the emotions and uncertainties that we talked about in the crisis communication.

87
00:13:09,140 --> 00:13:15,510
You certainly can bring in things like mental models and somebody's mental model of this genetically modified thing.

88
00:13:15,800 --> 00:13:18,980
Is it right? Is it wrong? Does it matter, etc.?

89
00:13:22,010 --> 00:13:30,680
What I'm looking for is for you to use this as an opportunity to to show me that you've picked up key ideas from this course.

90
00:13:33,720 --> 00:13:43,580
I sometimes say. It's not that there are not wrong answers, but there are definitely not a singular right answer here.

91
00:13:43,850 --> 00:13:51,700
You can make multiple arguments, but mostly it's going to be about bringing in, well, I think this is going to be a really big issue here.

92
00:13:51,720 --> 00:13:57,290
I don't think this is going to be a really big issue here. But either way, you get to talk about the kinds of principles that we brought up in.

93
00:14:02,480 --> 00:14:06,780
You know, and I've given you a set of questions and this is off the syllabus, but on the assignment.

94
00:14:06,900 --> 00:14:11,490
Let me read off of them things you might think about in the context of this assignment.

95
00:14:14,330 --> 00:14:21,560
How does the uncertainty regarding the existence of risk here change whether or not we ought to label something like this?

96
00:14:22,220 --> 00:14:26,000
This isn't let this is we don't know whether this causes any harm.

97
00:14:26,330 --> 00:14:30,020
Okay. So does that mean we should label it or not?

98
00:14:31,940 --> 00:14:35,060
Are all genetic modifications equivalent?

99
00:14:37,090 --> 00:14:40,300
That's sort of transparently the answer is no, but that gets you. I get it.

100
00:14:40,790 --> 00:14:46,570
You can get into that, by the way. One other thing I want to say about this assignment, if you believe.

101
00:14:47,700 --> 00:14:54,280
That the format of a label is either appropriate or inappropriate.

102
00:14:54,300 --> 00:14:59,970
I give you permission in this assignment to sort of say, Well, this label would cause that problem,

103
00:14:59,980 --> 00:15:03,990
but what we would do is this other form of label that would have a different format to it.

104
00:15:04,470 --> 00:15:15,720
So if you want to get into, hey, the label ought to include X type of arguments, you're welcome to do so for the converse.

105
00:15:16,590 --> 00:15:28,260
Hey, because the label doesn't include X, it's going to cause this kind of issue or problem or behavior, etc. So these are genetic modifications,

106
00:15:28,620 --> 00:15:35,220
similar or different from the kind of hybridization and breeding that has existed in agriculture for centuries.

107
00:15:37,180 --> 00:15:44,950
We all label that that stuff may or may not be labeling by your products.

108
00:15:45,520 --> 00:15:55,550
Is that okay? What does that say? And then going back to the more foundational things, what are the consequences of labeling something?

109
00:15:56,720 --> 00:16:01,850
People's misperceptions or the consequences of not labeling something and some of these misperceptions.

110
00:16:02,570 --> 00:16:07,610
These are all the questions I want you to wrestle. Yeah. Do you want us to cite sources at all?

111
00:16:09,320 --> 00:16:15,200
I've given you a variety of things. If you're drawing a specific argument from us, from a source, then please do cited.

112
00:16:15,980 --> 00:16:20,510
This is not going to be graded on the volume of research.

113
00:16:21,120 --> 00:16:28,250
It's going to be graded on the quality of arguments you make and the way in which you bring in concepts from this course.

114
00:16:29,270 --> 00:16:37,460
So if you bring it in sighted, but you certainly do not need to be doing a lot in order to be able to give an appropriate up.

115
00:16:37,670 --> 00:16:41,300
All the foundational issues are already here.

116
00:16:45,140 --> 00:16:51,520
I'm happy to talk this through. My piece of advice more than anything else is.

117
00:16:52,900 --> 00:16:59,860
Don't give me the big hand wavy generalized arguments, the concrete and specific.

118
00:17:01,450 --> 00:17:05,860
What do you think is going to happen when consumers see this label?

119
00:17:07,150 --> 00:17:15,000
What do you think is going to happen? Because these labels are being required to be put on products and not on other products, etc.

120
00:17:23,170 --> 00:17:31,610
This is sort of a risk perception analyst. Well, we should now have a reasonable ability to predict it.

121
00:17:32,320 --> 00:17:36,730
But if we're going to throw this label on this type of product, what's going to happen?

122
00:17:37,690 --> 00:17:41,530
What's going to happen to the producer side? What's going to happen on the consumer side? How are people going to feel?

123
00:17:41,530 --> 00:17:45,290
What are they going to do? Why are they going to do it? Etc.

124
00:17:45,310 --> 00:17:48,960
That's what I want you to get into. I'm not looking.

125
00:17:49,000 --> 00:17:54,880
There's no single right answer. Here is no checkbox of Well, if you don't get this, you're not going to get a good rate.

126
00:17:55,330 --> 00:17:58,960
I am looking for you to really tap into as much as possible from this course.

127
00:18:02,980 --> 00:18:10,240
Any questions at this point will have you start working on this?

128
00:18:10,780 --> 00:18:15,040
You can feel free to reach out to me. I'm not going to give you this is what you should say,

129
00:18:15,040 --> 00:18:19,899
but I'm more than happy to be a mirror and reflect back to you sort of thoughts

130
00:18:19,900 --> 00:18:25,240
of that seems like an interesting argument or what about X kind of responses?

131
00:18:30,610 --> 00:18:38,020
All right. Again, if you haven't looked on the syllabus, there is there are multiple links and these are all of the modules,

132
00:18:39,910 --> 00:18:47,110
various articles you've all come to find your own. But I've given you a decent amount of readings on different kinds of issues just to orient you.

133
00:18:50,650 --> 00:18:58,620
All right. So for today, we're going to talk about journalism.

134
00:18:58,630 --> 00:19:03,730
Well, how public health manifests this sort of like when should we tell you what to do and when should we not?

135
00:19:05,350 --> 00:19:12,940
And just to kick you off, I want to give us a take this really, really concreted your mind.

136
00:19:17,090 --> 00:19:21,170
Imagine that you are going to a restaurant.

137
00:19:21,820 --> 00:19:29,270
If you go to free lunch and you see a woman that you know either works in the same building.

138
00:19:29,690 --> 00:19:36,870
Somebody, you know, that's not a close friend, but somebody you know. She is obviously pregnant.

139
00:19:39,220 --> 00:19:45,900
Go over to her table. You see, as you're approaching me or put down a glass of wine.

140
00:19:52,010 --> 00:19:55,910
This is the only time you have seen her train in the last few months.

141
00:19:57,530 --> 00:20:01,790
But there's no question that she's being served up.

142
00:20:03,350 --> 00:20:07,370
My question to you to start this is to what degree?

143
00:20:08,730 --> 00:20:16,410
Do you believe that her fetus has been harmed or will be harmed by drinking?

144
00:20:16,410 --> 00:20:22,479
That she has demonstrated? Definitely.

145
00:20:22,480 --> 00:20:27,340
Yes. That's what we know. Maybe somewhere in between.

146
00:20:28,940 --> 00:20:34,280
What is your gut saying? Yeah, no question.

147
00:20:34,400 --> 00:20:39,320
Do we know this person pretty well? If you've been seeing them throughout, you know this person, you know,

148
00:20:39,830 --> 00:20:43,250
think about somebody who you would bump into in the hallway kind of level of knowledge.

149
00:20:43,250 --> 00:20:48,290
Not that you're a close friend, so you have some personal connection,

150
00:20:48,290 --> 00:20:53,510
but not one in which you would necessarily know a great deal about their behavior on a regular basis.

151
00:20:54,730 --> 00:21:00,310
So first of all, let's just start doing an analysis here. What are questions that come to mind?

152
00:21:01,490 --> 00:21:07,600
Yeah. So I guess the first immediate question is where you stand or view the science on that in the first place.

153
00:21:07,610 --> 00:21:15,830
And so obviously if she starts doing shots and then a few different felt like a glass of wine from the study that I've seen,

154
00:21:16,010 --> 00:21:21,710
like 1 to 2 drinks a week, pretty inconclusive depending on well, so let's let's back out a second here.

155
00:21:21,950 --> 00:21:27,020
Notice the way you're framing this question. There is a.

156
00:21:28,060 --> 00:21:32,140
The research is around volume of alcohol intake.

157
00:21:33,920 --> 00:21:44,540
But woven into the way you describe this is an assumption about what the alcohol is aligning with volume of intake.

158
00:21:44,540 --> 00:21:52,420
So. And by the way, several of you asked the question about what is a unit as a unit of alcohol.

159
00:21:52,730 --> 00:21:55,130
The standard calculation in many of these studies.

160
00:21:56,180 --> 00:22:08,690
My recollection is a unit of alcohol is 112 ounce relatively standard percentage alcohol, beer, one five ounce glass of wine,

161
00:22:08,690 --> 00:22:16,150
which has approximately the same amount of alcohol, one ounce at a one shot level, hard alcohol.

162
00:22:17,900 --> 00:22:22,040
But we're measuring here on the volume of alcohol being consumed.

163
00:22:22,670 --> 00:22:24,889
But there's a mental model piece that I don't want to lose here,

164
00:22:24,890 --> 00:22:31,280
which is an assumption that someone who is drinking starts will be consuming more alcohol

165
00:22:31,460 --> 00:22:35,540
than someone who is drinking wine or someone who is drinking that may or may not be correct.

166
00:22:36,500 --> 00:22:41,270
But that's a mental model piece that enters into our perception of risks.

167
00:22:43,550 --> 00:22:48,320
So one piece here is what is your perception of the science? That's certainly one element.

168
00:22:48,530 --> 00:22:55,200
What else comes to mind? My analysis. Is there a risk here or not so far?

169
00:22:57,320 --> 00:23:01,820
Yeah. Thinking about like when she started drinking in the course of her practice.

170
00:23:02,010 --> 00:23:11,749
There's another mental model. Like, do we held beliefs about the amount of harm that may or may not be occurring for alcohol consumption,

171
00:23:11,750 --> 00:23:15,570
say, early in pregnancy versus the middle of pregnancy versus later in person?

172
00:23:18,380 --> 00:23:21,560
I'm not claiming that I know the underlying science, but goodness,

173
00:23:21,560 --> 00:23:28,700
the mental model piece here rightly affects how much harm we may or may not believe is occurring.

174
00:23:30,800 --> 00:23:38,300
There's at least one other major piece of the mental model here, which is you are observing this person at one point in time.

175
00:23:40,190 --> 00:23:44,750
Is this a pattern or is this one moment?

176
00:23:46,120 --> 00:23:50,979
So our perception of risk, for understandable reasons,

177
00:23:50,980 --> 00:23:58,480
is likely driven significantly by whether or not we think this is the only time that this person is consuming alcohol.

178
00:24:00,330 --> 00:24:08,610
Versus they do so on a regular basis. So let me change my story about you.

179
00:24:08,610 --> 00:24:13,499
Look over at the restaurant and there's a big happy birthday sign and there's

180
00:24:13,500 --> 00:24:16,649
clearly a party and they're putting down a birthday cake in front of this person.

181
00:24:16,650 --> 00:24:20,220
And there's clearly a special event component of this.

182
00:24:20,880 --> 00:24:24,210
Does your perception of the risk change? Maybe.

183
00:24:26,070 --> 00:24:31,800
At least you might then be in the question of how much is this person engaging in this behavior on a regular basis?

184
00:24:35,040 --> 00:24:40,890
But at least another major question here about this behavior.

185
00:24:41,340 --> 00:24:48,480
Yes, I think I mean, like the most obvious difference between the two is like.

186
00:24:49,800 --> 00:24:50,730
There's another.

187
00:24:52,710 --> 00:25:00,420
I mean, if you're if you're carrying out a pregnancy for that long, it's going to be at some point you're going to try to select don't like.

188
00:25:01,610 --> 00:25:08,540
You are now responsible for like the help of like know like there's another body involved.

189
00:25:08,620 --> 00:25:15,589
Yeah. And that's part of why this is a complicated question is this is a situation and again,

190
00:25:15,590 --> 00:25:21,670
I do not want to get into the complex ethical, religious pieces of when does life begin its end, etc.

191
00:25:21,920 --> 00:25:30,020
But we raise the issues here. Right. There is the mother and her body and her life and how alcohol may be affected.

192
00:25:30,620 --> 00:25:33,260
And then there is, without any question,

193
00:25:33,470 --> 00:25:41,990
the knowledge that substantial alcohol consumption during pregnancy elevates the risk of fetal alcohol syndrome,

194
00:25:41,990 --> 00:25:48,670
which is a very known and well-documented risk. So there is a risk?

195
00:25:49,180 --> 00:25:57,610
No, there is no question here that at some level of consumption of global content that feeds.

196
00:26:01,320 --> 00:26:06,380
And now we get to the question of. Okay. To use.

197
00:26:09,550 --> 00:26:14,390
No one is thinking what if someone has?

198
00:26:16,200 --> 00:26:22,380
Three, two, three, four, three. That changes my perception.

199
00:26:23,100 --> 00:26:26,790
Why? I don't know. It's like maybe Daniel's a man.

200
00:26:26,790 --> 00:26:32,370
Or will we be the doctor I like because it's not socially acceptable.

201
00:26:34,590 --> 00:26:37,889
So again, I said before all of you got here, I said,

202
00:26:37,890 --> 00:26:42,840
I'm going to be annoying and provocative today because purposive desire to let us wrestle with stuff.

203
00:26:43,680 --> 00:26:47,910
So do you have the same reaction if you see someone who is pregnant, light up a cigaret?

204
00:26:50,540 --> 00:26:55,290
Why not? It's a risk.

205
00:26:56,790 --> 00:27:01,020
We know there is documented impact certainly on the mother.

206
00:27:01,770 --> 00:27:06,390
I don't think there's anything in a cigaret that i would expect to be positive to a fetus.

207
00:27:08,030 --> 00:27:12,139
Why are we saying that we don't have that kind of emotional reaction when a mother

208
00:27:12,140 --> 00:27:15,350
is lighting up a cigaret than we do when they're picking up a glass of wine.

209
00:27:17,520 --> 00:27:21,640
I think an important piece of information, too, is are they alone or the drinking alone or.

210
00:27:21,660 --> 00:27:24,809
I mean, I feel like too culturally that's a big fan of the drink.

211
00:27:24,810 --> 00:27:27,990
It all is like a kind of candy.

212
00:27:29,100 --> 00:27:33,809
I mean, I think we have a much higher like a much more prominent mental model for like

213
00:27:33,810 --> 00:27:38,730
I had a drink one time a week than like I smoke a cigaret one time a week.

214
00:27:39,300 --> 00:27:42,300
We tend to think of smoking as a more habitual action than drinking.

215
00:27:42,540 --> 00:27:50,699
Okay, but wouldn't that then make the argument that I'd be ought to be more worried and more freaked out from the cigaret than I am the alcohol?

216
00:27:50,700 --> 00:27:55,710
Because the cigaret is likely to be the repetitive behavior that goes.

217
00:27:58,010 --> 00:28:07,330
Again. I'll be really one one. Let me just throw this out. How is this different if we're not talking about.

218
00:28:08,490 --> 00:28:14,190
Cigarets. But we're talking about somebody having a plate of bacon.

219
00:28:16,870 --> 00:28:18,620
It's no question baking causes cancer.

220
00:28:19,420 --> 00:28:26,770
Absolutely no question that consumption of large volumes of processed meats is directly linked to colorectal cancer.

221
00:28:32,120 --> 00:28:35,360
Right. I'm going to be really annoying and people are not going to like me about this.

222
00:28:36,080 --> 00:28:39,280
But drinking and smoking are completely avoidable behaviors.

223
00:28:39,290 --> 00:28:43,400
You don't need to do them. You need to eat food like not eating.

224
00:28:43,910 --> 00:28:47,690
You don't need to eat bacon, but you need that. You need caloric intake to survive.

225
00:28:47,720 --> 00:28:54,700
You don't need to drink. It's a completely. I forget which one of the authors said it in the paper, but there is a quote about like.

226
00:28:57,680 --> 00:29:02,819
Something about. Forget where I was.

227
00:29:02,820 --> 00:29:06,320
But you wait. You don't have to engage in this.

228
00:29:06,330 --> 00:29:09,479
You can just not. It's not a required action.

229
00:29:09,480 --> 00:29:12,090
So. So let's extend this argument.

230
00:29:14,330 --> 00:29:20,690
If you if we take the argument that this is not a required action and there is a risk associated with which there is.

231
00:29:21,720 --> 00:29:27,910
And therefore it is more appropriate to your prohibiting that option because that will minimize the risk associated with.

232
00:29:29,080 --> 00:29:32,830
It is. I have a hard time figuring out why we don't ban candy.

233
00:29:34,090 --> 00:29:41,410
There is nothing required about sugar consumption. You absolutely can have a healthy diet with no refined sugar in your diet.

234
00:29:43,440 --> 00:29:49,970
We know sugar consumption is associated with diabetes, with all kinds of health effects.

235
00:29:51,520 --> 00:29:56,440
So there's no question of the underlying science. And, you know, I don't see anybody banning a Snickers.

236
00:29:57,580 --> 00:30:01,310
You shouldn't. But this is the thing that I have to wrestle with.

237
00:30:02,960 --> 00:30:06,640
You don't. And maybe we should.

238
00:30:06,640 --> 00:30:13,270
And that's one perspective. That's one way to go at it. Consistent. Maybe the answer is that we shouldn't, but we have to own that.

239
00:30:13,270 --> 00:30:15,730
We don't behave consistently regarding the risks.

240
00:30:16,000 --> 00:30:23,230
Certain risks evoke much stronger paternalistic responses, both societally and from public health officials than other ones do.

241
00:30:25,090 --> 00:30:27,610
The other thing I like quality of life,

242
00:30:27,610 --> 00:30:34,120
like we don't ban sugar because it makes people happy and it's enjoyable and alcohol doesn't make people happy.

243
00:30:36,980 --> 00:30:42,530
But it's not a poison. Sugar isn't cool. Oh, that's a slippery slope.

244
00:30:46,880 --> 00:30:52,280
I mean, she makes the poisoned, the dose makes the poison.

245
00:30:52,670 --> 00:30:54,469
So there's a there's a dose question here.

246
00:30:54,470 --> 00:30:59,810
And this is with all of these things, whether we're talking about alcohol, whether we're talking about cigarets,

247
00:30:59,810 --> 00:31:05,960
whether we're talking about lead in water, whether we're talking about taking all these excessive doses.

248
00:31:07,360 --> 00:31:14,350
But one strip of bacon is not likely to have any substantial impact on one's colorectal cancer risk.

249
00:31:16,340 --> 00:31:26,520
And then to all that object. But then the question comes back is one glass of wine going to have an impact on that mother or that fetus?

250
00:31:27,080 --> 00:31:30,230
And the analogy is it's hard to separate those.

251
00:31:30,860 --> 00:31:33,620
The answer is not it can't, because it absolutely could.

252
00:31:34,100 --> 00:31:43,370
But there is no question about is it poison alcohol could even at low levels of concentration have an impact, especially on a fetus?

253
00:31:43,800 --> 00:31:48,170
That logic is whole. And yet.

254
00:31:50,220 --> 00:31:56,700
We have to ask our self in the real world. What doses do we see aligning with what outcomes?

255
00:31:58,020 --> 00:32:03,630
I think another important question is, especially in the context of the pregnancy, is time.

256
00:32:04,140 --> 00:32:11,930
Most times when alcohol surprises kids for women, the moms are okay because those are the most crucial points.

257
00:32:12,870 --> 00:32:18,470
After the first trimester, alcohol consumption is less risky than in the first trimester.

258
00:32:18,930 --> 00:32:24,889
So. This is a nice start of part of the conversation we have to have here,

259
00:32:24,890 --> 00:32:32,600
which is that is a nuance that's that starts to break down again scientifically, whether you agree with it or not.

260
00:32:32,930 --> 00:32:40,760
I want to separate this to the sort of the way in which we communicate about if we say no alcohol consumption during pregnancy,

261
00:32:41,000 --> 00:32:44,330
we ignore any question of where you are in your pregnancy.

262
00:32:46,130 --> 00:32:53,210
If we start to bring in ideas that say, well, this behavior is more risky than that behavior.

263
00:32:53,660 --> 00:33:03,020
So to minimize the risk, if you're going to consume alcohol, it would be less risky to do so later in the pregnancy than earlier in the pregnancy.

264
00:33:03,410 --> 00:33:08,000
Now. Again, I'm not answering the scientific question.

265
00:33:08,030 --> 00:33:18,140
We can debate that once. But from a behavioral standpoint, is it okay for us to be communicating about risks with that level of nuance?

266
00:33:19,230 --> 00:33:24,210
Because I've seen in your musings and certainly in the readings, questions about, well, wait a second.

267
00:33:25,570 --> 00:33:30,610
That's been put in the user's hands. The judgment of how much is too much?

268
00:33:31,540 --> 00:33:39,040
What is this, safe enough? Do we trust you to manage how much risk you're going to be facing or not?

269
00:33:40,560 --> 00:33:45,780
And there's real. I mean, there are situations in which the answer might be, no, we don't trust you.

270
00:33:46,050 --> 00:33:48,990
And hence we're going to give you a very straightforward and clear guidance.

271
00:33:51,730 --> 00:33:56,260
And there may be other situations in which we say, no, actually we are going to trust you.

272
00:33:58,310 --> 00:34:01,910
That's the that's the debate I want us to wrestle part about.

273
00:34:01,910 --> 00:34:04,080
When you forget banning something,

274
00:34:04,130 --> 00:34:12,010
it's all the other variables that come in in terms of if you think about something like sugar is someone with diabetes.

275
00:34:12,020 --> 00:34:19,070
If I have almost any candy, my blood sugar is going to go up to even the 400th, which is dangerous.

276
00:34:19,270 --> 00:34:23,149
But if the rest of you guys have one piece of candy, no.

277
00:34:23,150 --> 00:34:26,300
In the long run, that's not going to have the same patients.

278
00:34:26,780 --> 00:34:36,380
So going back to the original example of all the other question that comes up is what is the rest of their health situation?

279
00:34:36,800 --> 00:34:44,090
You don't know how it would impact them specifically based on other issues that they have healthwise.

280
00:34:44,150 --> 00:34:49,790
Correct. And if I step us back to the health communicators perspective,

281
00:34:50,570 --> 00:35:00,710
I don't know as a communicator who amongst you may be more susceptible to the effects of let's run with the sugar analogy,

282
00:35:00,860 --> 00:35:04,700
who may be more susceptible to the effects of consuming candy versus somebody else?

283
00:35:05,420 --> 00:35:12,810
So should that. Affect the way in which I communicate about essentially what you're saying here is,

284
00:35:13,680 --> 00:35:17,460
you know, you are in a position where, you know, you have to behave differently than others.

285
00:35:19,290 --> 00:35:26,159
I'm going to trust you in that and enable you to make that independent choice to

286
00:35:26,160 --> 00:35:29,820
behave differently because you know that you're managing your risk separately or.

287
00:35:31,800 --> 00:35:34,170
And this is why, again, I'm being provocative and extreme here.

288
00:35:34,290 --> 00:35:38,840
I can say, well, I don't know who it is and I'm not sure, you know, all that you need to know is different.

289
00:35:38,850 --> 00:35:45,990
Let's take this off the table and not allow you to ever have a situation in which you might be faced with that risk.

290
00:35:47,630 --> 00:35:51,200
I have a baby. So I'm allergic to nuts.

291
00:35:51,680 --> 00:35:55,940
But sometimes I'm, like, moderately allergic, so I can.

292
00:35:56,090 --> 00:35:57,650
I can feel it, you know what I mean?

293
00:35:58,070 --> 00:36:04,430
And people are always trying to monitor my intake and, like, take things away from me and tell me I can't have things.

294
00:36:04,430 --> 00:36:09,950
And, like, tell me to tell the waiter that I'm allergic. And it's a perfect example of that.

295
00:36:10,280 --> 00:36:15,190
Yeah. So. Where I want to go.

296
00:36:15,210 --> 00:36:18,500
It's. Where does that behavior come from?

297
00:36:19,370 --> 00:36:24,640
The journalism. Yes. But I mean, what is this?

298
00:36:24,650 --> 00:36:28,170
Only family members and friends? Is it coworkers?

299
00:36:28,190 --> 00:36:34,760
Is it people you've never known? So I want us to reflect upon.

300
00:36:34,850 --> 00:36:38,390
Under what circumstances do we feel empowered?

301
00:36:40,030 --> 00:36:43,960
To manage the risk of somebody else. That's what they're doing.

302
00:36:44,110 --> 00:36:50,990
They say, I know that there exists a risk. Therefore, I am not going to trust you to manage this risk.

303
00:36:51,010 --> 00:36:57,910
I am going to do it for you. I have my own versions of this dating for my transplant.

304
00:36:59,620 --> 00:37:02,919
I was for a long period of time, you know, immunocompromised.

305
00:37:02,920 --> 00:37:08,740
And there were all kinds of times in which people, my parents, etc., were like, Oh, well, you carry on like this again.

306
00:37:11,470 --> 00:37:19,240
But again, it's. It's the statement of. Is that individual enabling?

307
00:37:20,060 --> 00:37:24,860
Are we allowing that individual to make their own choices? And as you say, putting yourself at risk.

308
00:37:24,860 --> 00:37:29,720
If you are knowingly eating nuts, you are knowingly putting yourself at some degree of risk.

309
00:37:30,560 --> 00:37:37,760
Like you said it was, and I think other people quoted it was like our goal is to maximize life.

310
00:37:39,240 --> 00:37:42,870
You are going to eat the cookie. I feel the same way or not.

311
00:37:44,370 --> 00:37:53,100
If I see a catch, you look irresistible. You got a handful of.

312
00:37:53,400 --> 00:37:59,250
But, yeah, it's like my. I have a way of managing it, which is like, I've been allergy tested.

313
00:37:59,250 --> 00:38:02,340
I know, like, the most allergic nuts for me.

314
00:38:02,670 --> 00:38:08,190
Which ones? They're, like, towards the bottom. And, like, you know, people just assume that you're going to drop dead.

315
00:38:08,400 --> 00:38:15,030
I think so. But maximize life for who, for yourself or for the greater society.

316
00:38:15,360 --> 00:38:22,290
Well, and let me just be clear here. When I wrote that, what I meant by maximized life is not counts of years lived.

317
00:38:22,920 --> 00:38:26,880
It was the full, expansive definition of everything that we might care about.

318
00:38:27,420 --> 00:38:36,450
So in in this context, there's an important question, which is what is it we are actually trying to maximize?

319
00:38:36,810 --> 00:38:41,420
Is it. Mortality, is it?

320
00:38:42,420 --> 00:38:50,999
Quality of life. Is it societal level quality of recognizing that there may exist trade offs between different people in terms of if I do this,

321
00:38:51,000 --> 00:38:55,890
I mean, somebody I forget who wrote about this, the helmet laws and organ donation.

322
00:38:57,210 --> 00:39:01,110
You wrote about that? That's right. Like that's a complicated dynamic there.

323
00:39:03,030 --> 00:39:09,629
So, yeah, let me not tell you. Yeah. So I don't even know how true, you know, evidence based sources.

324
00:39:09,630 --> 00:39:14,490
I just kind of heard this anecdotally and haven't looked up in detail, but so a friend of mine growing up,

325
00:39:14,490 --> 00:39:19,290
his dad was an administrator or CEO or something of one of the local hospitals.

326
00:39:19,290 --> 00:39:26,100
And just telling us one time that apparently in states that have no motorcycle helmet laws,

327
00:39:27,390 --> 00:39:31,530
it's actually kind of a net public health benefit because there's way more organ donations from,

328
00:39:32,010 --> 00:39:35,339
you know, people crashing and dying and then being able to donate organs.

329
00:39:35,340 --> 00:39:38,579
So it's just kind of an interesting example I thought of on the one side,

330
00:39:38,580 --> 00:39:44,100
it's kind of seen as a paternalistic law sometimes to to tell the laws because, you know, people get helmets.

331
00:39:44,600 --> 00:39:48,979
But on the other side, it's like if you have this knowledge of. You know,

332
00:39:48,980 --> 00:39:52,220
enforcing or not enforcing helmets kind of leads to an overall societal benefit

333
00:39:52,260 --> 00:39:58,760
that maybe not want to encourage people to wear helmets for this kind of weird, kind of morbid outcome outside kind of initiatives.

334
00:39:58,760 --> 00:40:04,640
An interesting state to talk about this. And because we had a helmet law for a few years and we repealed the helmet law.

335
00:40:05,240 --> 00:40:12,950
So within the last 15 years, there have been periods of time a free helmet law during helmet law and post helmet law.

336
00:40:15,170 --> 00:40:23,490
And obviously we have different there's lots of ethical and moral questions raised in terms of individual autonomy versus societal benefit.

337
00:40:24,460 --> 00:40:30,950
I don't want to pretend that there's a simple answer to that, but you're right in the larger sense, it's there.

338
00:40:31,550 --> 00:40:37,370
When we again, I'm saying we here sort of speaking as if I am public health, I am not public health.

339
00:40:37,370 --> 00:40:46,580
But what are the societal public health laws and regulations and organizations communicate about something?

340
00:40:46,940 --> 00:40:50,929
We care at many levels. We care about individual outcomes.

341
00:40:50,930 --> 00:41:04,130
We care about societal outcomes. And no place is that more salient than in the context of vaccination in which we literally put individuals at risk.

342
00:41:04,280 --> 00:41:10,790
We talk about, you know, cardiac problems caused by literally caused by the COVID 19 vaccines.

343
00:41:11,210 --> 00:41:21,700
We are causing harm when we vaccinate, but we do so because we care at a societal level in addition to the individual level.

344
00:41:23,730 --> 00:41:27,020
And the trade off. There is one that we say as a society we're willing to run.

345
00:41:32,440 --> 00:41:41,379
And part of that comes from a belief that the infectious nature of like we vaccinate one person because it doesn't just protect that person,

346
00:41:41,380 --> 00:41:46,330
it protects the whole society. And that's worth doing because of the societal benefits.

347
00:41:50,150 --> 00:41:56,320
You know, I. Saw this play out in an interesting way.

348
00:41:56,360 --> 00:42:03,830
So here's a here's a real world case study. My parents are nurses who live in a retirement community of Chelsea.

349
00:42:05,480 --> 00:42:13,400
And when the COVID 19 vaccine was very first becoming available, obviously there were lots of interest amongst the residents.

350
00:42:13,580 --> 00:42:19,950
These are 80 year olds. They want to get vaccinated. And they had.

351
00:42:22,880 --> 00:42:29,960
Similar push for all of the workers for obvious reasons, like vaccinating workers, you protect the residents.

352
00:42:30,860 --> 00:42:38,660
And then they ran into this, a number of the people who work in the cafeteria and the rest in the retirement community.

353
00:42:39,530 --> 00:42:46,360
High school students under 18. So the.

354
00:42:47,450 --> 00:42:53,510
Community has established a rule if you want to continue to work there, be vaccinated.

355
00:42:54,830 --> 00:43:00,300
They're certainly within their rights to do as a private employer. And some of the teams.

356
00:43:01,440 --> 00:43:04,920
Were unable to get their parents to allow them to be vaccinated.

357
00:43:06,060 --> 00:43:10,200
And thus their ability to have this job that they have been doing that they want

358
00:43:10,200 --> 00:43:15,330
to be at was inhibited because of the vaccination rule being put in place.

359
00:43:17,490 --> 00:43:19,830
And there was a lot of pushback sort of like, wait a second,

360
00:43:20,460 --> 00:43:28,020
is it appropriate for the retirement community to be essentially be depriving these kind of be very productive?

361
00:43:28,020 --> 00:43:30,930
You're depriving these kids of their jobs.

362
00:43:32,010 --> 00:43:38,310
Because they themselves cannot choose whether or not to be vaccinated, and they're dependent upon their parents approving this.

363
00:43:40,840 --> 00:43:42,640
And their final answer was yes.

364
00:43:44,490 --> 00:43:51,750
In order to protect the residents of this community, in order to derive the benefits of vaccination for this community.

365
00:43:51,750 --> 00:43:56,040
Yes, they're going to put that in place. And, yes, that was going to harm some of the people who had been working there.

366
00:43:58,030 --> 00:44:04,640
And they made that choice. So.

367
00:44:06,880 --> 00:44:12,970
I want to pull this back again to the question of like, what do we prohibit and why do we prohibit?

368
00:44:13,300 --> 00:44:16,390
We've talked about alcohol, but let me get let me throw out some random things.

369
00:44:20,530 --> 00:44:25,840
Is it appropriate to limit people's exposure to radiation?

370
00:44:29,230 --> 00:44:32,050
It's not like radiation does bad stuff causes cancer.

371
00:44:34,840 --> 00:44:42,790
What is one of the places, one of the things that we do on a regular basis that exposes us to trivial amounts of radiation.

372
00:44:44,220 --> 00:44:53,840
And fly. Fly on the plane. Fly. Airplanes takes you above the atmosphere, much more solar radiation.

373
00:44:54,320 --> 00:44:57,860
You get exposed to a nontrivial amount of radiation every time you fly an airplane.

374
00:44:59,290 --> 00:45:07,650
Why don't we ban flight? It confirms some kind of good that obviously outweighs the potential risks of flying.

375
00:45:09,200 --> 00:45:15,110
So do I have to fly? We can drive, take trains everywhere.

376
00:45:16,620 --> 00:45:21,200
Okay. So why we take boats? Not today, really.

377
00:45:21,260 --> 00:45:27,650
Can you take a boat, too? Yeah. Yeah. I used to do it all the time before airplanes.

378
00:45:27,940 --> 00:45:34,280
Inefficient. I mean, I'm pushy here, but.

379
00:45:34,280 --> 00:45:42,740
But we have to like if the argument is we don't have to have X and there is a risk associated with X, so let's say no to X,

380
00:45:43,340 --> 00:45:52,280
then there are lots of things that have risks that we don't have to have that we could say no to any and we don't have a risk free alternative.

381
00:45:52,520 --> 00:45:55,580
So there's a risk to driving. You can get an accident, you can get all kinds of things.

382
00:45:56,510 --> 00:46:00,890
Okay. So now you're making the argument that we can't look at this as a single risk.

383
00:46:01,250 --> 00:46:09,450
We have to say. Will people engage in alternative behaviors that will have their own sense of risk?

384
00:46:09,480 --> 00:46:15,390
So if we ban flying, people will not accept the idea that they have to go someplace.

385
00:46:16,440 --> 00:46:23,160
Therefore, they will drive it or they will take a train, etc. and those risks might literally outweigh the fine.

386
00:46:23,400 --> 00:46:27,810
That's actually literally probably true when we do this calculation.

387
00:46:28,320 --> 00:46:31,200
Flying is one of the safest modes of transportation that we have.

388
00:46:32,130 --> 00:46:39,540
September 11th, after September 11th, when people stopped flying and instead drove, mortality went up significantly as a result of that.

389
00:46:40,200 --> 00:46:41,550
Okay. So that's a strong argument.

390
00:46:41,940 --> 00:46:48,750
That's a societal level argument that we're saving lives by allowing people to fly, even though the flying is causing a particular risk.

391
00:46:50,020 --> 00:46:54,310
But it's grounded in the belief that we can't say no to travel.

392
00:46:58,720 --> 00:47:01,860
And that assumption is the key piece here.

393
00:47:03,000 --> 00:47:09,960
That we as a society are unwilling to deprive ourselves of the benefit that we get.

394
00:47:10,380 --> 00:47:18,030
It's not a health benefit of the of the life benefit of travel in order to reduce risk.

395
00:47:20,260 --> 00:47:22,030
And let's make this concrete.

396
00:47:22,270 --> 00:47:28,630
Like we now live in a world in which each of you with a laptop can be video conferencing with people pretty much anywhere.

397
00:47:29,660 --> 00:47:36,110
There is an alternative now to travel that did not used to exist.

398
00:47:36,590 --> 00:47:39,650
And one might say one could look at this and say, well, wait a second.

399
00:47:41,050 --> 00:47:47,320
Do I need to travel for this conference? Do I need to go to this meeting? Do I need to go physically to this family reunion?

400
00:47:47,560 --> 00:47:51,560
I can just zoom them. Yeah, I guess.

401
00:47:52,130 --> 00:47:55,310
Okay. I'm thinking of it kind of as public health in an American context.

402
00:47:55,310 --> 00:48:00,650
American legal context. I mean, and like, it's not about prescribing public health outcomes.

403
00:48:00,650 --> 00:48:06,560
It's about allowing people to make an informed choice to maximize their opportunity for public health examples.

404
00:48:06,950 --> 00:48:12,610
It's not I mean, it's one thing if it's like, yeah, we should ban someone putting their fork in a toaster or something,

405
00:48:12,620 --> 00:48:16,670
like that's obviously something that I think people can value is a bad thing.

406
00:48:17,030 --> 00:48:18,679
But it's like as long as, you know,

407
00:48:18,680 --> 00:48:25,190
the risks of tanning or you know the risks of that kind of stuff and you have a you have an actual choice as to do it or not.

408
00:48:25,580 --> 00:48:29,090
That's kind of the thing. So what are the underlying.

409
00:48:30,800 --> 00:48:33,830
It's a logical requirement for that argument.

410
00:48:35,360 --> 00:48:45,440
You have to understand the risks that you are taking fully enough in order for you to balance them against other things.

411
00:48:45,470 --> 00:48:51,200
So if we run with something like panic, that requires you to not only know that there exists a risk,

412
00:48:51,740 --> 00:48:55,490
but anticipate this risk which will accrue to you decades in the future.

413
00:48:56,150 --> 00:49:00,790
We know that we're very difficult in managing long term future risks.

414
00:49:00,800 --> 00:49:07,070
It's very difficult for people to pay attention to enough to counteract the short term.

415
00:49:07,320 --> 00:49:10,400
Hey, I like the way I look because of my training.

416
00:49:12,400 --> 00:49:16,240
I can see lots of situations here in which we might we might say, well, yes,

417
00:49:16,240 --> 00:49:20,140
if some hyper rational person truly understood this, maybe we give them the choice.

418
00:49:20,590 --> 00:49:25,300
But people aren't that. They don't fully understand the risks that they're facing.

419
00:49:25,720 --> 00:49:30,100
Therefore, they're going to actually engage in risky behaviors that they're going to regret later on in life.

420
00:49:30,880 --> 00:49:40,500
We might put. Things related to exercise or diet and other kinds of things that are associated with chronic disease.

421
00:49:40,790 --> 00:49:47,190
It's a similar, but do we truly appreciate the risks that we are running through our current day behaviors?

422
00:49:48,060 --> 00:49:51,210
If the answer is no, then that logic starts to break down.

423
00:49:53,270 --> 00:49:59,540
A little bit of the fine, but saying that there's also the societal risk of like economic benefit of like like if we,

424
00:49:59,680 --> 00:50:06,129
we realize travel is dangerous, we do everything remotely, all conferences like there's an economic downside to that because hotels aren't

425
00:50:06,130 --> 00:50:09,820
getting visitors or like restaurants and people lose jobs and that could go.

426
00:50:10,180 --> 00:50:18,040
I think like we have the argument sometimes like like it's like I don't like the pipeline when they were like shutting that down.

427
00:50:18,040 --> 00:50:23,440
We're like, this is like an environmental risk. But then the other side's argument was a lot of people are gonna be losing jobs.

428
00:50:23,980 --> 00:50:27,660
So there is like a risk on that to talk about.

429
00:50:27,670 --> 00:50:30,310
A lot of people will be losing jobs if we shut down for mining.

430
00:50:30,910 --> 00:50:35,050
It doesn't necessarily mean that I like to maintain coal as the way which we're getting our energy.

431
00:50:36,530 --> 00:50:40,680
I mean, there are economic costs of the health costs role that many of these choices.

432
00:50:46,470 --> 00:50:55,800
So. Why don't we prescribe our diets?

433
00:50:56,580 --> 00:51:00,450
Let's run with diet for a while. Lots of risk associated with diet.

434
00:51:03,870 --> 00:51:07,620
Is that full choice if you live in a food desert. Everyone has equal access.

435
00:51:07,820 --> 00:51:11,720
All right. I'll give you that one moment.

436
00:51:12,150 --> 00:51:16,530
In a hypothetical world which does not exist, everybody had access to the stuff that they need.

437
00:51:16,920 --> 00:51:20,670
Yes. But even in a.

438
00:51:22,330 --> 00:51:30,309
Wealthy community in which there is no food deserts. People have access to all different kinds of foods we create,

439
00:51:30,310 --> 00:51:38,920
and then we allow an environment to exist in which there are nice areas of the grocery store with lots of healthy

440
00:51:38,920 --> 00:51:44,560
food in them and other areas of the grocery store in which pretty much nothing on that aisle is good for you.

441
00:51:48,870 --> 00:51:57,349
That's a very complicated question of the way the industry is like hyper

442
00:51:57,350 --> 00:52:03,259
consolidated and they have like massive power and capital to controls influence our

443
00:52:03,260 --> 00:52:10,630
government unfortunately to perpetuate having highly processed foods in the

444
00:52:10,640 --> 00:52:14,210
grocery store which has led to an increased consumption of highly processed food.

445
00:52:14,330 --> 00:52:18,500
So structurally, that's absolutely right. That's where this comes from.

446
00:52:18,770 --> 00:52:22,460
I'm asking the more challenging question of let's imagine we couldn't deal with that.

447
00:52:22,850 --> 00:52:25,580
Would we actually use the power if we hadn't?

448
00:52:26,650 --> 00:52:34,990
To remove those products to make it impossible for you to buy the pudding pop or whatever it is that we're going to look at.

449
00:52:35,380 --> 00:52:40,660
And if the answer is no, then we're going to allow that unhealthy food to exist.

450
00:52:43,370 --> 00:52:48,890
Then we are saying it is acceptable for somebody from a public health standpoint.

451
00:52:49,190 --> 00:52:53,989
It is acceptable for us to tell you that it is eating.

452
00:52:53,990 --> 00:53:00,709
This is unhealthy to encourage you to change your diet, but that we will not use our coercive power,

453
00:53:00,710 --> 00:53:05,060
our persuasive power to that level of extreme to say, no, don't eat that.

454
00:53:05,060 --> 00:53:11,930
You can't eat that. And yet let's let's draw some lines here.

455
00:53:11,980 --> 00:53:21,240
Like there are we have removed in certain parts of the country soda from schools.

456
00:53:21,900 --> 00:53:27,360
You cannot buy a Coke on the campus. That is not.

457
00:53:28,970 --> 00:53:32,540
Giving people information and saying, hey, drinking coke might be unhealthy to you.

458
00:53:32,540 --> 00:53:39,770
And that is exercising the equivalent of a you know, you are removing your choice.

459
00:53:43,040 --> 00:53:49,279
Yeah. I mean, I think you do get into a difference between adults and children, and it can be hard to draw where that line is.

460
00:53:49,280 --> 00:53:53,420
But there's a point at which you become better at making decisions for yourself.

461
00:53:58,840 --> 00:54:03,130
Again, I apologize to some degree because I'm intentionally being very provocative here.

462
00:54:03,140 --> 00:54:10,810
But why does that argue for the moral right of abstinence only education?

463
00:54:12,830 --> 00:54:16,160
We don't trust kids with sex. It's dangerous.

464
00:54:17,830 --> 00:54:19,540
You know, there is danger associated with it.

465
00:54:21,480 --> 00:54:27,570
If the message here is we can't trust you having availability of a Coke or we can't have trust you with everybody with a cigaret.

466
00:54:27,920 --> 00:54:33,730
Like where does the line get drawn? Just because somebody is a minor, that doesn't mean they have judgment.

467
00:54:34,840 --> 00:54:42,360
Which things are we going to allow them to make judgments about? You're like a citizen, remember?

468
00:54:42,990 --> 00:54:44,490
I mean, I think there's a distinction in that.

469
00:54:45,090 --> 00:54:50,310
First of all, we don't, like, teach people that Coke will kill them and they should never, ever have one.

470
00:54:50,580 --> 00:54:55,770
We just don't make it available at school. And I think similarly, we don't make sex available at school.

471
00:54:56,070 --> 00:54:59,580
And I also think that, like, kids are going to drink coke. Kids are going to have sex.

472
00:54:59,790 --> 00:55:04,379
That has been borne out through research. So we teach them how to do both safely.

473
00:55:04,380 --> 00:55:07,680
We teach them nutrition, you know, teach them how to smoke safely.

474
00:55:08,490 --> 00:55:13,540
Well, that's not really established as a well, but I mean, let's let's push this.

475
00:55:13,560 --> 00:55:17,639
Like cigarets are a domain in which much of the messaging is binary.

476
00:55:17,640 --> 00:55:24,300
You quit or you don't. There's relatively little harm reduction messaging around Cigarets,

477
00:55:26,040 --> 00:55:30,870
but cigarets are there's a dose response relationship to the amount of harm associated with smoking.

478
00:55:31,880 --> 00:55:39,430
Someone who only smoked a cigaret here or a cigaret there has much, much, much, much lower risk than somebody the smoking in packaging.

479
00:55:39,980 --> 00:55:45,770
We could have messaging in that space now. And obviously there's an addiction component, just substantial.

480
00:55:45,770 --> 00:55:51,290
I not want to minimize that, but there is an addiction component to alcohol.

481
00:55:51,560 --> 00:55:55,580
There is an addiction component to processed sugar to some degree.

482
00:55:55,730 --> 00:56:07,790
There is certainly an addiction to caffeine. And yet we have those kinds of conversations with you'll be talked by people to my father

483
00:56:07,790 --> 00:56:12,110
about reducing his caffeine intake in a way that we don't generally talk about cigarets.

484
00:56:14,310 --> 00:56:18,150
You know, I'm I'm being incredibly provocative here and just, you know,

485
00:56:18,300 --> 00:56:22,050
being pushy because I want us to wrestle with, like, why do we do this here and that here?

486
00:56:23,790 --> 00:56:30,719
I worked my way that way. I feel like Cigarets are like the best comparison to show because we haven't banned cigarets.

487
00:56:30,720 --> 00:56:34,700
We've just not let people smoke where it could cause community harm.

488
00:56:34,710 --> 00:56:39,190
It's like second hand smoke. So like you can't smoke in a restaurant, but smoke in the house or outside.

489
00:56:39,210 --> 00:56:42,600
This, by the way, is a new phenomenon, at least in my lifetime.

490
00:56:42,900 --> 00:56:49,380
But like drinking soda, I don't I can't think of an instance where me drinking soda could harm someone around the edges.

491
00:56:49,460 --> 00:56:57,850
I think that's that probably by saying the health care system must not be affected in the same way that, like smoking does.

492
00:56:57,880 --> 00:57:04,230
Like we like secondhand smoke. Like you notice that there's a mental model piece that we're saying we are more

493
00:57:04,230 --> 00:57:09,330
intolerant of immediate secondary effects than we are of societal effects.

494
00:57:09,900 --> 00:57:17,160
That the fact that your obesity will have impacts on us as a society is somehow

495
00:57:17,160 --> 00:57:21,120
more tolerable to us than the fact that your cigaret is going to be caught.

496
00:57:21,360 --> 00:57:22,160
Yeah. Yeah.

497
00:57:23,490 --> 00:57:34,500
So I don't know if this is, like, too tangential to, like, just like, zoomed out, but I feel like, well, with, like, public health in general,

498
00:57:34,500 --> 00:57:42,540
like, and the stuff that actually passes when like, say, like banning cigarets in like public spaces and stuff like that in like that immediate.

499
00:57:43,770 --> 00:57:47,340
Like risk to another body that is present there.

500
00:57:50,150 --> 00:58:00,720
But those like. For the most part, like those that do end up becoming law, it's like under the assumption that we have.

501
00:58:01,650 --> 00:58:06,330
A negative right to like our individual health as in like.

502
00:58:07,310 --> 00:58:13,100
Someone else cannot or not individual have. Well, we have like this negative.

503
00:58:13,100 --> 00:58:20,470
Right. Where people cannot interfere. Like and government cannot interfere in, like, our actions.

504
00:58:21,280 --> 00:58:28,660
But then, if it harms others, you can interfere on that.

505
00:58:29,020 --> 00:58:34,499
But. But like. Okay.

506
00:58:34,500 --> 00:58:38,520
That's all I have. So here's my counter argument.

507
00:58:39,540 --> 00:58:43,050
Where does this put us with regards to mass weapons?

508
00:58:46,550 --> 00:58:50,510
Mask wearing only affects me in the short run, like I'm the one who has to wear the mask.

509
00:58:52,430 --> 00:58:58,370
There's an infectious disease management component. But part of the counter arguments that we've heard,

510
00:58:58,640 --> 00:59:05,860
especially when the mask mandates were much more politically salient than they are right now, is one of it's my bodily autonomy.

511
00:59:05,870 --> 00:59:09,529
I get to make the choice as to whether I wear that mask, that negative.

512
00:59:09,530 --> 00:59:15,530
Right. You're talking about felt violated by some people by that Band-Aid that they had to wear a mask.

513
00:59:17,050 --> 00:59:21,250
And you could come up with I mean, I'm not arguing the public health benefits of mask wearing.

514
00:59:21,280 --> 00:59:28,660
I'm certainly an advocate of something. But if we frame this in individual rights terms, why do you get to tell me what I have to wear?

515
00:59:29,230 --> 00:59:35,230
I think we want to extend that. We can easily slip into all kinds of other things about what I have to wear or not wear.

516
00:59:35,650 --> 00:59:43,120
I guess like the other side of that, not even like saying that, like relying on the assumption that we have that negative, right.

517
00:59:43,120 --> 00:59:50,620
But the idea that we don't have a positive right to public health, like like we are not obligated to to that.

518
00:59:50,620 --> 00:59:56,469
Good. Right. So let me let me I guess this is a transition I wanted to make.

519
00:59:56,470 --> 00:59:58,650
So let me go here for now and then I'll come back to you, Mark.

520
00:59:59,920 --> 01:00:05,620
Much of what we've just been talking about here has been about prohibiting actions which harm

521
01:00:07,030 --> 01:00:12,730
the we're talking about consumption of alcohol or or other kinds of things that might harm us.

522
01:00:13,330 --> 01:00:25,630
There is the flipside to conversation, to actions which we may believe have specific health benefits and the way in which we either

523
01:00:25,990 --> 01:00:32,410
recommend or almost mandate them and the societal impact on them to make a concrete example.

524
01:00:32,470 --> 01:00:36,170
Again, this is very controversial space. Breastfeeding.

525
01:00:42,570 --> 01:00:53,820
At least some evidence suggests that mothers who breastfeed have differential health outcomes for their children versus those who formula feed.

526
01:00:55,300 --> 01:01:04,730
That's a benefit. We have had lots of debate and discussion in the public health field about how much do we push this.

527
01:01:05,630 --> 01:01:10,220
Clearly, there are people for breastfeeding.

528
01:01:10,490 --> 01:01:20,090
Has it either literally impossible for medical reasons, etc., or practically impossible for work reasons for location?

529
01:01:20,600 --> 01:01:26,540
The list goes on and on and on. It is not equally accessible people.

530
01:01:29,330 --> 01:01:36,260
Does that mean that we shouldn't be recommending it because some people will feel bad because it's not something,

531
01:01:36,380 --> 01:01:42,560
because the costs of them and and plus, I mean, everything like financial cost, work cost, social costs, etc.

532
01:01:44,060 --> 01:01:49,910
And yet there is at least some evidence to suggest there is real health benefits there.

533
01:01:50,150 --> 01:01:54,580
So when should we be pulling out that that. Notch.

534
01:01:56,910 --> 01:02:03,090
I mean, I guess the nudge does exist like through with like you can get comps for three or four classes and you're

535
01:02:03,090 --> 01:02:08,819
training on breastfeeding for like in public health and in public health and maternal child nutrition.

536
01:02:08,820 --> 01:02:15,629
Like we do encourage it. And then there's also the understanding that people have to formula feed.

537
01:02:15,630 --> 01:02:22,500
And I know like there's research done at this school about like how can we make formula more similar to like breast milk composition?

538
01:02:22,500 --> 01:02:25,649
And so there's clearly harm that that's the flip of harm reduction.

539
01:02:25,650 --> 01:02:27,660
It's like it's benefit amplification.

540
01:02:27,660 --> 01:02:34,500
Like if we're going to have someone who is formula feeding, can we make it as close as possible to minimize the differential?

541
01:02:34,500 --> 01:02:41,990
And all of that is clearly a good thing. And what I want us to put our lens on is.

542
01:02:43,050 --> 01:02:50,740
Poor communication standards. We know that they exist a differential in this case in a positive direction.

543
01:02:50,740 --> 01:03:01,059
It's an alcohol case and a negative direction. When do we feel like it is appropriate for us to be communicating in ways that say you

544
01:03:01,060 --> 01:03:06,310
should be doing this to leverage that persuasive perspective versus simply to say,

545
01:03:06,490 --> 01:03:12,520
here is the evidence choice? I have no simple answer to that, by the way.

546
01:03:13,990 --> 01:03:19,450
Every time I design a communication in my work, I wrestle with the question of how persuasive am I going to be?

547
01:03:21,310 --> 01:03:30,070
And there are times when I am absolutely comfortable being persuasive, even though I know some people would argue with me.

548
01:03:30,250 --> 01:03:34,290
And there are times when I have absolutely uncomfortable with any form of bias.

549
01:03:37,050 --> 01:03:43,740
Including things like how I present them their numbers, which I know because we spent a lot of time talking about it is can be persuasive.

550
01:03:47,610 --> 01:03:59,610
Yeah, it's just totally audience dependent because like with breastfeeding, there's obviously populations where it's accessible to breastfeed.

551
01:04:00,250 --> 01:04:05,340
Oh, sure. And our audience is where it's not accessible.

552
01:04:05,340 --> 01:04:09,360
And you totally have to cater your communication to that because.

553
01:04:10,830 --> 01:04:18,240
Is unfair to say you should breastfeed, you can't formula feed or you know you shouldn't.

554
01:04:19,950 --> 01:04:23,850
So it is an accessible. Yes, yes.

555
01:04:24,390 --> 01:04:31,560
And we are valuing as a society that framing that person's work as being equal or

556
01:04:31,560 --> 01:04:37,340
more of value than the differential health outcomes that might come from naturals.

557
01:04:38,130 --> 01:04:41,850
Well, I don't know if it's about value, but it's about survival for sure.

558
01:04:42,420 --> 01:04:45,590
That's value. I mean, I'm not minimizing this.

559
01:04:45,600 --> 01:04:54,660
I'm bringing in the option to say there are times when many other things that we care about, financial life,

560
01:04:54,810 --> 01:05:02,070
circumstances, etc., are more important than whether or not it's going to kill you to take a concrete.

561
01:05:02,160 --> 01:05:05,500
I've got a few other examples I want to bring up here because I can't.

562
01:05:05,580 --> 01:05:11,890
And I. I'll work my way this way. Tobacco use.

563
01:05:14,530 --> 01:05:19,990
Has cultural significance. It's a project.

564
01:05:24,250 --> 01:05:28,850
We all know the value of that cultural heritage. We must all.

565
01:05:28,850 --> 01:05:36,640
And the fact that someone may choose to be using tobacco and accepting all of the harms that may come from that and that that is appropriate,

566
01:05:37,090 --> 01:05:41,140
not just that allowable. It is appropriate is the right choice.

567
01:05:43,210 --> 01:05:59,310
If a. And this is again, I'm intentionally picking really annoying circumstances like if an elderly person with liver damage.

568
01:06:00,580 --> 01:06:07,360
Will get substantial personal enjoyment of having a drink.

569
01:06:08,740 --> 01:06:11,990
Is it wrong to allow them to do so much?

570
01:06:13,140 --> 01:06:16,580
It's killing them. They know what's killing them.

571
01:06:18,260 --> 01:06:30,070
They wanted anyway. I think with cancer, get chemo to the point that it's no longer beneficial.

572
01:06:30,230 --> 01:06:36,220
Yes. And they keep getting chemo. Yes. And we might.

573
01:06:38,290 --> 01:06:43,630
What to communicate with gentlemen. The acceptability of not that of of choosing something else.

574
01:06:46,560 --> 01:06:51,580
And so I try to touch upon people, raise their hands raised.

575
01:06:51,580 --> 01:06:55,900
And then I've got a story I want to ask you first. Like a minute or two ago.

576
01:06:56,470 --> 01:07:06,520
So you expressed the question of when is it appropriate to simply consider the options that an individual and wait to say,

577
01:07:06,700 --> 01:07:13,389
here are options if this is what you need to do? I sometimes struggle, especially with the breastfeeding example,

578
01:07:13,390 --> 01:07:20,040
when I had a friend who told me that she did not want to breastfeed because she simply did not want.

579
01:07:20,050 --> 01:07:23,580
So there was no other option to get her away from breastfeeding.

580
01:07:23,950 --> 01:07:30,040
And I just disengaged from the conversation because I do wholeheartedly believe in just the other options.

581
01:07:30,050 --> 01:07:36,940
Take it or leave it. I'm just telling you for your information. But when she said that, she just didn't want to do it.

582
01:07:37,120 --> 01:07:42,280
It struck something to me because it's no longer because you have to work or because there's something more important.

583
01:07:42,520 --> 01:07:51,130
It's just I guess your level of comfort is more important. So and and since then, the baby is now a year and a half, and he is sick a lot.

584
01:07:52,630 --> 01:07:57,490
Oh, so, yeah. And, you know, what strikes me about that example is.

585
01:07:59,730 --> 01:08:07,860
Mutation standpoint is it could be that that belief is grounded in some misunderstandings, like a belief that,

586
01:08:07,860 --> 01:08:11,640
oh, it's going to be too hard for me or all it's going to it's going to be painful or whatever.

587
01:08:12,150 --> 01:08:20,490
Like so there is the possibilities of some failures of communication that if we provided more information to the person,

588
01:08:20,490 --> 01:08:25,290
might make a different choice. And it is also possible if there are no failures of communication.

589
01:08:25,410 --> 01:08:33,540
This person is perfectly well informed, but that their personal values, their preferences are such that they don't want to choose that system.

590
01:08:34,200 --> 01:08:39,930
And that's uncomfortable. When we look at that and we say, Yeah, there are these health outcomes coming from that.

591
01:08:40,830 --> 01:08:50,850
How much do we give credence to I just like it or I just don't want to do it in a space of weighing these kinds of risks.

592
01:08:53,310 --> 01:08:56,580
What's next? Barak has been waiting in the. Yeah.

593
01:08:56,580 --> 01:09:03,959
So I was just kind of thinking with when we're talking about, you know, banning versus kind of giving warnings and,

594
01:09:03,960 --> 01:09:10,740
you know, not banning certain things, I think there is a consideration of kind of sort of prioritization of,

595
01:09:10,740 --> 01:09:15,120
you know, if you go around banning so many things, as we saw in the, you know, COVID pandemic,

596
01:09:15,120 --> 01:09:19,679
where a lot of the bans or, you know, vaccine mandates were quite reasonable, I would think.

597
01:09:19,680 --> 01:09:23,160
But even still, there's kind of going to be pushback at some point.

598
01:09:23,610 --> 01:09:27,569
So I think that has should be taken into consideration that, you know,

599
01:09:27,570 --> 01:09:30,959
there are things that we kind of just know as public health experts that are

600
01:09:30,960 --> 01:09:36,240
kind of coming with our time in terms of advocating for and pushing for and,

601
01:09:36,240 --> 01:09:42,840
you know, going around spending time and energy on this kind of things that probably aren't as useful as, you know, we're considering.

602
01:09:43,140 --> 01:09:49,830
Prohibition wasn't exactly a rousing success. Banning marijuana hasn't been particularly valuable either.

603
01:09:50,430 --> 01:09:56,640
We could certainly make a broad argument about the entire way in which our society deals with a variety of drugs has been counterproductive.

604
01:10:00,020 --> 01:10:08,800
Notice, though, that and I fully agree with you, there's lots of arguments against that because people find their way around them.

605
01:10:09,260 --> 01:10:19,760
They they just don't work. But I started with the maternal alcohol example because this is a case in which alcohol is freely available in society.

606
01:10:20,150 --> 01:10:27,890
And yet for a very specific population, we seem to be treated very differently than we do the population as a whole.

607
01:10:29,470 --> 01:10:32,530
And we ought to at least ask the question, what is it about?

608
01:10:33,610 --> 01:10:35,080
Women, pregnant women.

609
01:10:36,060 --> 01:10:46,950
It enables that population in this particular context to be being treated differently than the person who is still able to buy alcohol,

610
01:10:46,950 --> 01:10:57,770
despite the fact it's killing their liver, for example. So I have to tell you the story of the cookie dough thing.

611
01:11:01,220 --> 01:11:10,490
I. When the when the food when the flour recall came out in 2016, I was I think it was a big flour recall.

612
01:11:10,490 --> 01:11:13,100
That's interesting. I pay attention to food recalls for obvious reasons.

613
01:11:13,790 --> 01:11:18,380
And then like three weeks later, they issued that notice to consumers saying, don't eat right now.

614
01:11:18,920 --> 01:11:23,000
And my wife will tell you that she I don't think she's ever seen me.

615
01:11:23,810 --> 01:11:35,480
That wound up when I was a single our bedroom guy, not because I felt that there was, you know, that the risk was so bad.

616
01:11:35,480 --> 01:11:44,299
But I felt like it for me personally. It felt like such an overreach of the public health authorities in a situation that

617
01:11:44,300 --> 01:11:50,270
seemed to be very much one where risk is clear and yet choices allowable and important.

618
01:11:51,860 --> 01:11:56,380
And so I wrote that thing, by the way, it's in the conversation dot com.

619
01:11:56,390 --> 01:12:01,730
I think I've talked about this. This is a space for academics to write on, on popular issues.

620
01:12:02,060 --> 01:12:10,340
I really am the case study for why this works. That piece got they track it through a sort of embedded link of stuff that I was tracking.

621
01:12:11,150 --> 01:12:18,590
It got viewed about 10,000 times in the first week. And then it got picked up by a CNN e-commerce website.

622
01:12:19,520 --> 01:12:24,470
The last time I checked, the total read Cat was somewhere in the 450,000 range.

623
01:12:24,840 --> 01:12:28,490
Has been read more than anything else I will ever write in my entire life.

624
01:12:30,110 --> 01:12:40,130
I have the cookie dough guy as well. And yet it remains one of the things that sometimes I'm most proud of,

625
01:12:41,090 --> 01:12:47,239
because that last piece that many of you cited about sort of the minimizing risk versus maximizing

626
01:12:47,240 --> 01:12:52,130
life is really at the heart of the way in which I see much of our role as communicators.

627
01:12:54,150 --> 01:13:01,650
Where I mean, life as in enjoyment, life as in autonomy, life as in everything that matters to us.

628
01:13:02,800 --> 01:13:07,360
As individuals and society, we make choices.

629
01:13:08,780 --> 01:13:12,020
I put myself and my kids at risk when I made cookie dough.

630
01:13:12,560 --> 01:13:15,900
And no, I don't go by who treated flour. And yes, I know that I could.

631
01:13:15,920 --> 01:13:22,700
And yes, I know that there is risk associated with that. Because I know that I will get enjoyment.

632
01:13:22,700 --> 01:13:26,990
And if someday I get bad food poisoning, I will I will know where it came from.

633
01:13:31,760 --> 01:13:33,829
I have this day at this end of this course,

634
01:13:33,830 --> 01:13:41,569
because one thing that I have seen over and over again in public health in particular, is that zooming in on, we find a risk.

635
01:13:41,570 --> 01:13:45,770
We know that there is a potential harm from it. And so we go all out to minimize.

636
01:13:47,140 --> 01:13:52,060
Without consideration of the other issues, without consideration of the cost to the individual.

637
01:13:52,420 --> 01:13:59,500
And oftentimes very much from a privileged perspective of, if I would do it, that you should.

638
01:14:01,880 --> 01:14:04,370
And I want you to guard against that in your future work.

639
01:14:06,140 --> 01:14:11,450
There are lots of reasons to communicate about risk, and there are certain times at which it is appropriate.

640
01:14:11,720 --> 01:14:21,320
I'm willing to stand on the moral platform and say, Yes, I can be persuasive and coercive, and I've given you lots of tools to do that.

641
01:14:23,120 --> 01:14:29,080
Know what you're doing and know why you're doing it. And make that choice each time.

642
01:14:30,160 --> 01:14:31,770
Because of.

643
01:14:34,150 --> 01:14:40,240
You could have a world in which everybody is forced to be vaccinated and nobody gets to have candy and everybody has to eat broccoli every day.

644
01:14:40,240 --> 01:14:44,500
And we would be healthier. Don't leave it out for a reason.

645
01:14:46,180 --> 01:14:49,450
All right. For the last few minutes.

646
01:14:51,100 --> 01:14:54,370
Wrestle with your favorite sport. When?

647
01:14:55,760 --> 01:15:00,960
I was comfortable giving people that choice, even if it might harm.

648
01:15:04,130 --> 01:15:06,740
And are you okay with it? And what are you not?

649
01:15:07,310 --> 01:15:12,050
And it's okay if you have different perspectives, but you're not going to have to agree with each other.

650
01:15:12,830 --> 01:15:15,530
That's an individual kind of choice, and that's something that we're all going about.

651
01:15:15,800 --> 01:15:20,690
But but spend the last few minutes of today's class wrestling with it and see where you live.

652
01:15:22,220 --> 01:15:26,050
And I'll just circulate. Feel free to call me over if you want. If you want me to try again.

653
01:15:27,990 --> 01:15:36,270
Yes. I guess the question is.

654
01:15:36,970 --> 01:15:40,960
Sorry, I surprised. Oh, really?

655
01:15:41,510 --> 01:15:45,139
Oh, thank you, sir. Oh, it's always such a shame.

656
01:15:45,140 --> 01:15:54,690
Or like having any contact with anything like finals. So I was, like, reflecting.

657
01:15:57,470 --> 01:16:03,770
I don't know, ever.

658
01:16:03,890 --> 01:16:08,080
I'm sorry. There's an element of nonsense.

659
01:16:08,310 --> 01:16:18,090
And I struggle with this a lot and trying to accept the message.

660
01:16:18,130 --> 01:16:30,250
Yeah, I just read that book that I couldn't be doing, so I decided that you're going to tell people that,

661
01:16:30,290 --> 01:16:35,510
like, you know, and I think we tried that 3 hours that was going on.

662
01:16:35,810 --> 01:16:48,230
And I was like, Oh, my own personal bias, like really easy stuff where we've tried to like that.

663
01:16:48,230 --> 01:16:54,920
We try to use today, which I have no problem with.

664
01:16:54,920 --> 01:16:59,720
For example, I'm telling you guys easy as possible to hit with.

665
01:17:01,340 --> 01:17:04,600
Yeah, we're always looking for a minute or whatever.

666
01:17:05,870 --> 01:17:22,460
It takes less when it comes to the user judgment is not going to be on the grounds that this is different from what I'm doing.

667
01:17:23,230 --> 01:17:35,820
Yeah, like I guess I was like, oh yeah, that's right.

668
01:17:36,130 --> 01:17:54,470
Similar things. A lot of thinking about that rather than just like thinking that it was me in public.

669
01:17:54,710 --> 01:18:04,250
I know I like someone.

670
01:18:04,940 --> 01:18:23,860
I don't want to say that. When you say go for everything you want, you want to know how other.

671
01:18:24,860 --> 01:18:30,980
But they could not be friends in 99.

672
01:18:32,540 --> 01:18:36,790
I don't I don't think about driving usually.

673
01:18:36,860 --> 01:18:43,220
Like what does that actually mean for me?

674
01:18:43,730 --> 01:18:50,000
Probably because I struggle with things like, well, you know, I don't know really.

675
01:18:50,420 --> 01:18:54,140
You know, things are true.

676
01:18:54,890 --> 01:19:02,780
I feel like it's always been like you are like, all right, you got to drink alcohol.

677
01:19:03,260 --> 01:19:17,989
And I want that to be like like an entertainment on the line.

678
01:19:17,990 --> 01:19:25,250
I really knew I was actually with you on that as well.

679
01:19:26,910 --> 01:19:37,450
I also want to point out something else.

680
01:19:38,700 --> 01:19:56,510
So like a parody of a place like this, but I don't know what that is.

681
01:19:58,280 --> 01:20:02,020
I don't know. I guess it's not exactly like a sexual.

682
01:20:03,840 --> 01:20:15,340
Said that obviously there is obviously this is a role I have to bring myself to do

683
01:20:17,470 --> 01:20:26,470
that in the same way that like anything like everything one was eight years later,

684
01:20:26,930 --> 01:20:39,530
I'm like, well, you know, versus I'm not going going to have three say, well,

685
01:20:39,700 --> 01:21:03,460
it's like I feel like I have like a certain point of how this kind of work is not to do this to a whole bunch of other stuff like that.

686
01:21:05,890 --> 01:21:33,520
But I feel like, you know, I feel like I don't feel like we have to feel free to do something more greater society,

687
01:21:33,520 --> 01:21:47,030
more so now you question I think it's really dangerous to bring for the doctor who could have all sort of thing where they said,

688
01:21:47,260 --> 01:22:02,320
I don't trust these people. Like I'm like, I want to talk to him for a long time, but you're not crazy about it.

689
01:22:03,430 --> 01:22:07,839
All right. All right. Out of time.

690
01:22:07,840 --> 01:22:10,989
We're we're out of time, which is like hour and a half.

691
01:22:10,990 --> 01:22:24,570
It's still not being anywhere close to being done. First of all, I'm asking you to about Tobin, but all the stuff related to COVID back, for example,

692
01:22:24,580 --> 01:22:33,070
this last class that could connect directly to pretty much everything we've talked about in this course, the subjects.

693
01:22:33,090 --> 01:22:47,220
Are you going out to places that people in the UK with?

694
01:22:47,310 --> 01:23:11,530
Maybe it's because I love a question that I love that I was going to say that people are saying there is no way that.

695
01:23:16,390 --> 01:23:21,160
I think that's right. That's right.

696
01:23:21,600 --> 01:23:39,250
Yeah, yeah, yeah, yeah, yeah, yeah.

697
01:23:39,660 --> 01:23:56,200
I like that. I guess that was the actually for out of this obviously to talk with you in a moment.

698
01:23:56,200 --> 01:24:12,909
So this is the third series I am working on.

699
01:24:12,910 --> 01:24:16,540
Wonderful. Yeah, but I do not remember.

700
01:24:16,540 --> 01:24:27,549
I was like, I know you're here to bury me, but here's the shorthand.

701
01:24:27,550 --> 01:24:33,090
Yes. During the last year we were excited about it.

702
01:24:33,310 --> 01:24:37,510
We do not like on the list.

703
01:24:37,950 --> 01:24:51,310
I don't think it was going to be a year to be able to do I was that I was going to make is a hybrid of all three of us.

704
01:24:51,520 --> 01:24:58,000
It wasn't intended to do anything for the first time I could.

